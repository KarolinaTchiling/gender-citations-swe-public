FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Alshaer, HN
   Otair, MA
   Abualigah, L
   Alshinwan, M
   Khasawneh, AM
AF Alshaer, Hadeel N.
   Otair, Mohammed A.
   Abualigah, Laith
   Alshinwan, Mohammad
   Khasawneh, Ahmad M.
TI Feature selection method using improved CHI Square on Arabic text
   classifiers: analysis and application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text classification algorithms; Bayes net; Na&#239; ve Bayes; Random
   Forest; Decision tree; Artificial neural networks; CHI Square
ID CLASSIFICATION; ALGORITHMS; REDUCTION
AB Text classification could be defined as the way of allocating text into predefined groups according to its contents. Over the past few years, an increase emerged in the volume of information in the varied fields on the Internet, thus making the classification of texts one of the most important, yet challenging. Text classification is commonly employed in numerous applications and for different objectives. The extensive and broad use of the Internet, particularly in the Arab world, as well as the massive number of the documents and pages which are provided in the Arabic language, raised the need for having suitable tools for classification of these pages and documents by their main categories. The aim of this paper to study the effect of the improved CHI (ImpCHI) Square on the performance of six well-known classifiers: Random Forest, Decision Tree, Naive Bayes, Naive Bayes Multinomial, Bayes Net, and Artificial Neural Networks. These proposed techniques are quite important for improving classification of Arabic documents and can be regarded as a promising basis for the stage of text classification because it contributes to the classification of the texts into predefined categories. This combination method takes the advantages of more than one technique, which can produce better results in the final outcomes. The dataset employed in this paper includes 9055 Arabic documents that were collected from various Arabic resources. Based on their content, these documents were divided into twelve categories. Four performance evaluation criteria were used: the F-measure, recall, precision, and Time build model. The experimental results show that the use of ImpCHI square gives better classification results than the normal CHI square method with all studied classifiers, in terms of all used performance criteria.
C1 [Alshaer, Hadeel N.; Otair, Mohammed A.; Abualigah, Laith; Alshinwan, Mohammad; Khasawneh, Ahmad M.] Amman Arab Univ, Fac Comp Sci & Informat, Amman, Jordan.
RP Abualigah, L (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman, Jordan.
EM HadeelAlshaer94@outlook.com; Otair@aau.edu.jo; aligah.2020@gmail.com;
   mohmdsh@aau.edu.jo; a.khasawneh@aau.edu.jo
RI Khasawneh, Ahmad Mohammad/AFJ-8626-2022; Al Shinwan,
   Mohammad/AAY-6940-2020; Abualigah, Laith/ABC-9695-2020
OI Khasawneh, Ahmad Mohammad/0000-0002-1850-3269; Al Shinwan,
   Mohammad/0000-0002-3864-7323; Abualigah, Laith/0000-0002-2203-4549;
   Otair, Mohammed/0000-0002-9141-7412
CR Abualigah L., 2015, INT J COMPUTER SCI E, V5, P19, DOI [10.5121/ijcsea.2015.5102, DOI 10.5121/ijcsea.2015.5102]
   Abualigah L., 2020, RECENT ADV NLP CASE, P129, DOI DOI 10.1007/978-3-030-34614-0_7
   Abualigah L., 2020, ENG COMPUT, P1
   Abualigah L.M.Q., 2019, STUDIES COMPUTATIONA, V816, DOI [10.1007/978-3-030-10674-4, DOI 10.1007/978-3-030-10674-4]
   Abualigah L, 2021, INT J MACH LEARN CYB, V12, P783, DOI 10.1007/s13042-020-01202-7
   Abualigah L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113827
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Abualigah LM, 2018, ENG APPL ARTIF INTEL, V73, P111, DOI 10.1016/j.engappai.2018.05.003
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abualigah LM, 2017, EXPERT SYST APPL, V84, P24, DOI 10.1016/j.eswa.2017.05.002
   Aliwy A.H., 2012, INT J INFORM ED TECH, V2, P348, DOI 10.7763/IJIET.2012.V2.149
   Alshaer H., 2017, Int J Inform Syst Comput Sci
   [Anonymous], 2014, Int. J. Ambient Syst. Appl., DOI [DOI 10.5121/IJASA.2014.2402, 10.5121/ijasa.2014, DOI 10.5121/IJASA.2014]
   [Anonymous], 2013, INT J COMPUT APPL
   Ayedh A, 2016, ALGORITHMS, V9, DOI 10.3390/a9020027
   Bahassine S., 2016, 11 INT C INTELLIGENT, P1, DOI DOI 10.1109/SITA.2016.7772289
   Bahassine S, 2020, J KING SAUD UNIV-COM, V32, P225, DOI 10.1016/j.jksuci.2018.05.010
   Bawaneh M.J., 2008, J COMPUTER SCI, V4, P600
   Chanod JP, 1996, P WORKSH EXT FIN STA
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Cutler DR, 2007, ECOLOGY, V88, P2783, DOI 10.1890/07-0539.1
   Gharib Tarek Fouad, 2009, International Journal of Computers and Their Applications, V16, P192
   Hawashin B., 2013, INT J COMPUTER APPL, V83, P1, DOI 10.5120/14666-2588
   Hmeidi I, 2015, J INF SCI, V41, P114, DOI 10.1177/0165551514558172
   Jadon E., 2017, International Journal of Computer Applications (0975 - 8887), V167, P13, DOI [10.5120/ijca2017913925, DOI 10.5120/IJCA2017913925]
   Kanan T, 2016, J ASSOC INF SCI TECH, V67, P2667, DOI 10.1002/asi.23609
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Mesleh AM, 2011, PATTERN RECOGN LETT, V32, P1922, DOI 10.1016/j.patrec.2011.07.010
   Moh'd Abdelwadood, 2007, Journal of Computer Sciences, V3, P430, DOI 10.3844/jcssp.2007.430.435
   Mohammad A.H., 2016, GSTF Journal on Computing (JoC), V5, P5, DOI 10.7603/s40601-016-0016-9
   Osisanwo F., 2017, Int. J. Comput. Trends Technol., V48, P128, DOI [DOI 10.14445/22312803/IJCTT-V48P126, 10.14445/22312803/ijctt-v48p126]
   Otair M., 2013, International Journal of Managing Information Technology IJMIT, V5, P1, DOI [10.5121/ijmit.2013.5201, DOI 10.5121/IJMIT.2013.5201]
   Parekh R, 2000, IEEE T NEURAL NETWOR, V11, P436, DOI 10.1109/72.839013
   R Mohana, 2014, INT J SCI ENG TECHNO, V3, P1557
   Raho G, 2015, INT J ADV COMPUT SC, V6, P192
   Sembok Tengku Mohd T., 2011, European Computing Conference. Proceedings of the European Computing Conference (ECC '11), P392
   Sharma D., 2015, International Journal of Scientific Research in Computer Science and Engineering, V3, P1
   Xu QZ, 2019, CLUSTER COMPUT, V22, pS2731, DOI 10.1007/s10586-017-1436-9
   Xu QZ, 2019, SOFT COMPUT, V23, P9413, DOI 10.1007/s00500-018-3608-9
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu QZ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0904-y
   Zakariah Mohammed., 2014, International Journal of Engineering and Innovative Technology (IJEIT), V4
NR 45
TC 27
Z9 27
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10373
EP 10390
DI 10.1007/s11042-020-10074-6
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000591261400002
DA 2024-07-18
ER

PT J
AU Malik, M
   Malik, MK
   Mehmood, K
   Makhdoom, I
AF Malik, Mishaim
   Malik, Muhammad Kamran
   Mehmood, Khawar
   Makhdoom, Imran
TI Automatic speech recognition: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; ASR; Automatic speech recognition; Feature
   extraction; Classification models; Language models
ID HIDDEN MARKOV-MODELS; SUPPORT VECTOR MACHINES; NEURAL-NETWORKS;
   EXTRACTION; OPTIMIZATION; COMBINATION; FEATURES
AB Recently great strides have been made in the field of automatic speech recognition (ASR) by using various deep learning techniques. In this study, we present a thorough comparison between cutting-edged techniques currently being used in this area, with a special focus on the various deep learning methods. This study explores different feature extraction methods, state-of-the-art classification models, and vis-a-vis their impact on an ASR. As deep learning techniques are very data-dependent different speech datasets that are available online are also discussed in detail. In the end, the various online toolkits, resources, and language models that can be helpful in the formulation of an ASR are also proffered. In this study, we captured every aspect that can impact the performance of an ASR. Hence, we speculate that this work is a good starting point for academics interested in ASR research.
C1 [Malik, Mishaim; Malik, Muhammad Kamran] Punjab Univ Coll Informat Technol PUCIT, Lahore, Pakistan.
   [Mehmood, Khawar] Univ New South Wales UNSW Canberra, ADFA, Sch Engn & Informat Technol, Canberra, ACT, Australia.
   [Makhdoom, Imran] Univ Technol Sydney, Fac Engn & IT, Ultimo, Australia.
C3 Australian Defense Force Academy; University of New South Wales Sydney;
   University of Technology Sydney
RP Malik, M (corresponding author), Punjab Univ Coll Informat Technol PUCIT, Lahore, Pakistan.
EM mishaimmalik30@gmail.com; kamran.malik@pucit.edu.pk;
   k.mehmood@unsw.edu.au; imran.makhdoom@uts.edu.au
RI Makhdoom, Imran/AAL-2956-2020; Malik, Muhammad Imran/ADP-9538-2022;
   Makhdoom, Imran/W-4740-2019
OI Makhdoom, Imran/0000-0002-6205-5897; Malik, Muhammad
   Imran/0000-0002-5938-8797; Makhdoom, Imran/0000-0002-6205-5897; Malik,
   Mishaim/0000-0002-4917-7144
CR Abdulla W., 1999, The Concepts of Hidden Markov Model in Speech Recognition
   Alkhaldi W, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, CONFERENCE PROCEEDINGS, P463
   [Anonymous], 2019, SYMMETRY BASEL, DOI DOI 10.3390/sym11050644
   [Anonymous], 1992, Wavelets and their Applications
   [Anonymous], 1993, FUNDAMENTAL SPEECH R
   [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], 2007, P 19 C COMP LING SPE
   [Anonymous], 2003, THYROID
   [Anonymous], 1993, Wavelets: Algorithms and Applications
   [Anonymous], 2011, P 6 C SPEECH TECHNOL, DOI DOI 10.1109/SPED.2011.5940729
   [Anonymous], 1994, SST C ASSTA INC PERT
   [Anonymous], 2003, CYBERNETICS+
   Anusuya MA, 2011, INT J SPEECH TECHNOL, V14, P99, DOI 10.1007/s10772-010-9088-7
   Anusuya M. A., 2011, Int. J. Comput. Appl., V26, P19
   Atmaja BT, 2020, ASIAPAC SIGN INFO PR, P325
   BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278
   Barker J, 2018, INTERSPEECH, P1561, DOI 10.21437/Interspeech.2018-1768
   Batuwita R, 2010, IEEE T FUZZY SYST, V18, P558, DOI 10.1109/TFUZZ.2010.2042721
   BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8
   Ben Messaoud Z, 2010, IEEE MEDITERR ELECT, P253, DOI 10.1109/MELCON.2010.5476290
   Besacier L, 2014, SPEECH COMMUN, V56, P85, DOI 10.1016/j.specom.2013.07.008
   Birkenes O, 2010, IEEE T AUDIO SPEECH, V18, P1440, DOI 10.1109/TASL.2009.2035151
   Bishop C.M., 2007, Bayesian Stat., V8, P3, DOI [DOI 10.1007/978-3-642-93220-5_6, 10.1093/oso/9780199214655.003.0001, DOI 10.1093/OSO/9780199214655.003.0001]
   Bourlard H., 2012, Connectionist speech recognition: a hybrid approach, V247
   Bu H, 2017, 2017 20TH CONFERENCE OF THE ORIENTAL CHAPTER OF THE INTERNATIONAL COORDINATING COMMITTEE ON SPEECH DATABASES AND SPEECH I/O SYSTEMS AND ASSESSMENT (O-COCOSDA), P58, DOI 10.1109/ICSDA.2017.8384449
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Campos MM, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P763, DOI 10.1109/IJCNN.1998.682377
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chang TH, 2008, INT CONF ACOUST SPEE, P4053
   Chen CP, 2005, INT CONF ACOUST SPEE, P525
   Cheng O., 2005, school of engineering report No. 621
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Chow Y. L., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P89
   CHOW YL, 1989, SPEECH AND NATURAL LANGUAGE, P199
   Clarkson P, 1999, INT CONF ACOUST SPEE, P585, DOI 10.1109/ICASSP.1999.759734
   Collobert Ronan, 2016, Wav2letter: An end-to-end convnet-based speech recognition system
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Cutajar M, 2010, IEEE MEDITERR ELECT, P1123, DOI 10.1109/MELCON.2010.5476361
   Cutajar M, 2013, IET SIGNAL PROCESS, V7, P25, DOI 10.1049/iet-spr.2012.0151
   Paulson LD, 2006, COMPUTER, V39, P15, DOI 10.1109/MC.2006.401
   Dansena D. K., SURVEY PAPER AUTOMAT
   DAVIS KH, 1952, J ACOUST SOC AM, V24, P637, DOI 10.1121/1.1906946
   Deshmukh N., 1995, Proceedings IEEE Southeastcon '95. Visualize the Future (Cat. No.95CH35793), P192, DOI 10.1109/SECON.1995.513083
   Du XP, 2006, LECT NOTES COMPUT SC, V3972, P150
   Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278
   Dumitru CO, 2006, PROCEEDINGS ELMAR-2006, P115
   Fontaine V, 1996, 1996 8 EUR SIGN PROC, P1
   FORGIE JW, 1959, J ACOUST SOC AM, V31, P1480, DOI 10.1121/1.1907653
   Forsberg Markus., 2003, WHY IS SPEECH RECOGN
   Friedman Jerome H., 1996, Technical Report
   Gaikwad S., 2010, INT J COMPUT APPL, V10, P16
   Gamulkiewicz B, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P678
   Ganapathy S, 2009, J ACOUST SOC AM, V125, pEL8, DOI 10.1121/1.3040022
   Garofolo John, 1993, TIMIT ACOUSTIC PHONE
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Gupta M., 2001, Proc of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), P445
   Hai J, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1614
   Halabi N., 2016, Modern standard arabic phonetics for speech synthesis
   Hannun Awni, 2014, ARXIV
   HARDY RL, 1971, J GEOPHYS RES, V76, P1905, DOI 10.1029/JB076i008p01905
   Helmi N, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 7, PROCEEDINGS, P265, DOI 10.1109/ICNC.2008.666
   Hemakumar G., 2013, INT J INFORM SCI INT, V2, P1
   Hennebert J, 1994, NEURAL NETWORKS SPEE, P1015
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H., 1991, P IEEE INT C AC SPEE, V1, P121
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Hou X, 2009, PIAGENG 2009 INTELLI, V7490, p74902O
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu XH, 2011, IEEE SYS MAN CYBERN, P1481, DOI 10.1109/ICSMC.2011.6083880
   Huang XD, 2014, COMMUN ACM, V57, P94, DOI 10.1145/2500887
   Hung JW, 2009, IEEE SIGNAL PROC LET, V16, P806, DOI 10.1109/LSP.2009.2024113
   Illina I, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P2147, DOI 10.1109/ICSLP.1996.607228
   Islam J, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P73, DOI [10.1109/CCOMS.2019.8821629, 10.1109/ccoms.2019.8821629]
   Jan-Yee Lee, 2011, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2011), P1947, DOI 10.1109/FSKD.2011.6019893
   Jiang H, 2006, IEEE T AUDIO SPEECH, V14, P1584, DOI 10.1109/TASL.2006.879805
   Juang B.-H., 2005, AUTOMATIC SPEECH REC, V1, P67
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Jung S, 2004, LECT NOTES ARTIF INT, V3339, P1154
   Kaur P., 2012, INT J COMPUT SCI INF, V3, P3989
   Kesarkar M., 2003, Feature extraction for speech recognition
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Köhn A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4644
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Korba M.C. A., 2008, Informatica, V32
   Kriman S, 2020, INT CONF ACOUST SPEE, P6124, DOI [10.1109/ICASSP40776.2020.9053889, 10.1109/icassp40776.2020.9053889]
   Kruger SvenE., 2005, P INTERSPEECH, P993
   Kupiec J, 1989, SPEECH NATURAL LANGU
   Lamere P., 2003, P IEEE INT C ACOUSTI, V1, P2
   Lawrence R., 2008, FUNDAMENTALS SPEECH
   Lazli L, 2003, LECT NOTES ARTIF INT, V2734, P379
   Lee Akinobu, 2001, JULIUS OPEN SOURCE R
   Lekshmi K.R, 2016, INT J COMPUT SCI INF, V7, P2422
   Leung KF, 2003, IEEE INT CONF FUZZY, P190
   Lin C.-.T., 1996, Neural Fuzzy Systems: A Neuro-Fuzzy Synergism to Intelligent Systems
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Liu XF, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P310, DOI 10.1109/APCIP.2009.212
   Lowerre Bruce T., 1976, HARPY SPEECH RECOGNI
   Maheswari NU, 2010, INT J COMPUTER THEOR, V2, P912, DOI [10.7763/IJCTE.2010.V2.262, DOI 10.7763/IJCTE.2010.V2.262]
   Makino T, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P905, DOI [10.1109/asru46091.2019.9004036, 10.1109/ASRU46091.2019.9004036]
   Malekzadeh S, 2018, ARXIV181206953
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mehla R., 2014, INT J ADV RES COMPUT, V3, P45
   Milone DH, 2008, REV IBEROAMERICANA I, V12, P7
   Modic R, 2003, ISCA TUT RES WORKSH
   Molau S, 2001, INT CONF ACOUST SPEE, P73, DOI 10.1109/ICASSP.2001.940770
   MORGAN N, 1990, INT CONF ACOUST SPEE, P413, DOI 10.1109/ICASSP.1990.115720
   Mporas Iosif, 2007, Journal of Computer Sciences, V3, P608, DOI 10.3844/jcssp.2007.608.616
   Müller DN, 2006, IEEE IJCNN, P3790
   Nehe N. S., 2009, International Journal of Recent Trends in Engineering, V2, P22
   Nehe NS, 2012, EURASIP J AUDIO SPEE, P1, DOI 10.1186/1687-4722-2012-7
   Nguyen P, 2010, IEEE J-STSP, V4, P994, DOI 10.1109/JSTSP.2010.2080812
   Nouza J, 2010, IEEE MEDITERR ELECT, P202, DOI 10.1109/MELCON.2010.5476306
   O'Shaughnessy D, 2003, P IEEE, V91, P1272, DOI 10.1109/JPROC.2003.817117
   O'Shaughnessy D., 1988, IEEE Potentials, V7, P29
   O'Shaughnessy D, 2008, PATTERN RECOGN, V41, P2965, DOI 10.1016/j.patcog.2008.05.008
   Pallett DS, 1990, SPEECH NATURAL LANGU, P298
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Paul AK, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P171, DOI 10.1109/ICAPR.2009.80
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532
   Polikar R., 1996, The Wavelet Tutorial
   Pour MM, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P153, DOI 10.1109/IADCC.2009.4808998
   Povey D., 2011, IEEE 2011 WORKSH AUT
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RABINER LR, 1981, IEEE T COMMUN, V29, P621, DOI 10.1109/TCOM.1981.1095031
   Ranjan S, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P345, DOI 10.1109/ICSAP.2010.21
   Rosenblatt F., 1961, AD0256582 CORN AER L
   ROSENFELD R, 1992, SPEECH AND NATURAL LANGUAGE, P107
   Rosenfeld R, 1994, HYBRID APPROACH ADAP
   Rousseau A, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P125
   Rybach D, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2063
   Sabah R, 2009, 2009 THIRD ASIA INTERNATIONAL CONFERENCE ON MODELLING & SIMULATION, VOLS 1 AND 2, P336, DOI 10.1109/AMS.2009.101
   Saeed TR, 2019, INT J ELECT COMPUT E, V9, P2088
   Saha G., 2005, P NCC, P56
   Sainath T., 2019, INTERSPEECH
   Sak H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1468
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sayers C, 1991, SELF ORG FEATURE MAP
   Sha Fei, 2007, in Advances in Neural Information Processing Systems, V19, P1249
   Shanthi T, 2013, International Journal of Scientific Engineering and Technology, V2, P479
   Shewalkar A, 2019, J ARTIF INTELL SOFT, V9, P235, DOI 10.2478/jaiscr-2019-0006
   Singh MT, 2015, INT J COMPUT APPL, V121
   Sivaram GSVS, 2012, IEEE T AUDIO SPEECH, V20, P23, DOI 10.1109/TASL.2011.2129510
   Sivaram GSVS, 2011, INT CONF ACOUST SPEE, P5336
   Smaragdis P, 2009, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-0-387-76569-3_1
   Solera-Ureña R, 2007, LECT NOTES COMPUT SC, V4391, P190
   Sonkamble BA, 2009, PROCEEDINGS OF THE 8TH WSEAS INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, MAN-MACHINE SYSTEMS AND CYBERNETICS (CIMMACS '09), P117
   Sukumar AR, 2010, 2010 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P33, DOI 10.1109/CICSyN.2010.56
   Tang H, 2010, INT CONF ACOUST SPEE, P4926, DOI 10.1109/ICASSP.2010.5495097
   Tang X, 2009, PROCEEDINGS OF THE 2009 PACIFIC-ASIA CONFERENCE ON CIRCUITS, COMMUNICATIONS AND SYSTEM, P682, DOI 10.1109/PACCS.2009.138
   Tavanaei A., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P138, DOI 10.1109/AISP.2011.5960989
   Thubthong N, 2001, INT J UNCERTAIN FUZZ, V9, P803, DOI 10.1142/S0218488501001253
   Toshniwal S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4904, DOI 10.1109/ICASSP.2018.8461972
   Tóth L, 2011, INT CONF ACOUST SPEE, P5040
   Trentin E, 2003, IEEE T NEURAL NETWOR, V14, P1519, DOI 10.1109/TNN.2003.820838
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Umarani SD, 2009, IAMA: 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT & MULTI-AGENT SYSTEMS, P344
   Vadwala A.Y., 2017, INT J COMPUT APPL, V175, P31
   Vapnik V., 1999, NATURE STAT LEARNING
   Veaux C., 2016, SupersededCSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit
   Veisi H, 2011, DIGIT SIGNAL PROCESS, V21, P36, DOI 10.1016/j.dsp.2010.07.004
   VELICHKO VM, 1970, INT J MAN MACH STUD, V2, P223, DOI 10.1016/S0020-7373(70)80008-6
   Venkatasubramanian R, 2011, PROC EUR TEST SYMP, P215, DOI 10.1109/ETS.2011.50
   Venkateswarlu R. L. K., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P441, DOI 10.1109/ICECTECH.2011.5941788
   Vimal Krishnan V. R., 2009, International Journal of Recent Trends in Engineering, V1, P93
   Vimala C., 2012, WORLD COMPUTER SCI I, V2, P1
   Wang B., 2020, ARXIV200508497
   Wang YQ, 2005, IEEE T FUZZY SYST, V13, P820, DOI 10.1109/TFUZZ.2005.859320
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459
   Weston J., 1999, 7th European Symposium on Artificial Neural Networks. ESANN'99. Proceedings, P219
   Weston J., 1998, CSDTR9804
   Wijoyo S., 2011, proceedings of 2011 international conference on information and electronics engineering (ICIEE 2011), P28
   WOODLAND PC, 1995, INT CONF ACOUST SPEE, P73, DOI 10.1109/ICASSP.1995.479276
   Xuedong Huang, 1993, Computer Speech and Language, V7, P137, DOI 10.1006/csla.1993.1007
   Yegnanarayana B, 1998, IEEE T SPEECH AUDI P, V6, P313, DOI 10.1109/89.701359
   Yu H, 2011, IEEE T IND ELECTRON, V58, P5438, DOI 10.1109/TIE.2011.2164773
   Zamani B, 2011, PATTERN RECOGN LETT, V32, P948, DOI 10.1016/j.patrec.2011.01.017
   ZHAO YX, 1991, INT CONF ACOUST SPEE, P333, DOI 10.1109/ICASSP.1991.150344
   Zhou Ping, 2009, Information Technology Journal, V8, P796, DOI 10.3923/itj.2009.796.800
NR 179
TC 106
Z9 117
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9411
EP 9457
DI 10.1007/s11042-020-10073-7
EA NOV 2020
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000588276000004
DA 2024-07-18
ER

PT J
AU Ansari, MA
   Singh, DK
AF Ansari, Mohd. Aquib
   Singh, Dushyant Kumar
TI Human detection techniques for real time surveillance: a comprehensive
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human detection; Feature description; Deep convolutional neural
   networks; Recent progress; Surveillance; Computer vision
ID PARTIALLY OCCLUDED HUMANS; PEDESTRIAN DETECTION; OBJECT DETECTION; FACE
   DETECTION; HUMAN SKIN; BAYESIAN COMBINATION; FEATURE-EXTRACTION; COLOR
   IMAGES; TRACKING; RECOGNITION
AB Real-time detection of humans is an evolutionary research topic. It is an essential and prominent component of various vision based applications. Detection of humans in real-time video sequences is an arduous and challenging task due to various constraints like cluttered environment, occlusion, noise, etc. Many researchers are doing their research in this area and have published the number of researches so far. Determining humans in visual monitoring system is prominent for different types of applications like person detection and identification, fall detection for an elder person, abnormal surveillance, gender classification, crowd analysis, person gait characterization, etc. The main objective of this paper is to provide a comprehensive survey of the various challenges and modern developments seen for human detection methodologies in day vision. This paper consists of an overview of different human detection techniques and their classification based on various underlying factors. The algorithmic technicalities with their applicability to these techniques are deliberated in detail in the manuscript. Different humanitarian imperative factors have also been highlighted for comparative analysis of each human detection methodology. Our survey shows the difference between current research and future requirements.
C1 [Ansari, Mohd. Aquib; Singh, Dushyant Kumar] MNNIT Allahabad, CSED, Prayagraj, UP, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Ansari, MA (corresponding author), MNNIT Allahabad, CSED, Prayagraj, UP, India.
EM mansari@mnnit.ac.in
RI Singh, Dushyant Kumar/AAD-8512-2021; Ansari, Aquib/AHC-0974-2022
OI Singh, Dushyant/0000-0002-1897-1660; ANSARI, MOHD.
   AQUIB/0000-0002-9083-1523
CR Abughalieh K, 2020, TECH REP
   Ahmed A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P144, DOI 10.1109/ICAIBD.2018.8396183
   Aibinu AM, 2012, PROCEDIA ENGINEER, V41, P1183, DOI 10.1016/j.proeng.2012.07.299
   Al-Mohair HK, 2015, APPL SOFT COMPUT, V33, P337, DOI 10.1016/j.asoc.2015.04.046
   Al-Mohair HK, 2013, 1 WSEAS INT C IM PRO, V2
   AlDahoul N, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/1639561
   Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   [Anonymous], 2018, ARXIV180202531
   [Anonymous], 2011, 2011 IEEE WORKSHOP A
   [Anonymous], COMPUT VIS PATTERN R
   Ansari M., 2017, INT J MULTIMEDIA UBI, V12, P1, DOI [10.14257/ijmue.2017.12.11.01, DOI 10.14257/IJMUE.2017.12.11.01]
   Ansari MA, 2017, INT J ADV RES COMPUT, V8
   Ansari MA, 2017, INT J SIGNAL PROCESS, V10, P43
   Ansari MHR, 2018, I CONF VLSI DESIGN, P422, DOI 10.1109/VLSID.2018.101
   Astawa I., 2017, TELKOMNIKA, V15, P1894
   Bajaj Komal, 2020, Procedia Computer Science, V171, P1535, DOI 10.1016/j.procs.2020.04.164
   Bhoyar K. K., 2010, Journal of Computer Sciences, V6, P963, DOI 10.3844/jcssp.2010.963.968
   Bhuvaneswari K, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION, COMMUNICATION AND ENERGY CONSERVATION INCACEC 2009 VOL 1, P90
   Bianconi F, 2015, LECT NOTES COMPUT SC, V9281, P71, DOI 10.1007/978-3-319-23222-5_9
   Bin Ghazali KH, 2012, PHYSCS PROC, V25, P2116, DOI 10.1016/j.phpro.2012.03.358
   Brand J, 2000, INT C PATT RECOG, P1056, DOI 10.1109/ICPR.2000.905653
   Brown D.A., 2001, Proceedings of the 2001 British Machine Vision Conference, V1, P491
   Burger W, 2016, DIGITAL IMAGE PROCES, P341
   Bush Idoko John, 2018, ITM Web of Conferences, V16, DOI 10.1051/itmconf/20181602004
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   Chahyati D, 2017, PROCEDIA COMPUT SCI, V124, P167, DOI 10.1016/j.procs.2017.12.143
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chakraborty B, 2007, COMPONENT BASED HUMA
   Chandrappa D. N., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P254, DOI 10.1109/ICECTECH.2011.5941600
   Cheddad A, 2009, IEEE IMAGE PROC, P497, DOI 10.1109/ICIP.2009.5413947
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chen N, 2015, SIGNAL PROCESS, V110, P155, DOI 10.1016/j.sigpro.2014.08.044
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Chiachia G, 2011, INT J PATTERN RECOGN, V25, P1337, DOI 10.1142/S0218001411009068
   Choudhury SK, 2018, MULTIMED TOOLS APPL, V77, P13075, DOI 10.1007/s11042-017-4933-1
   Connolly T., 2009, GAMES BASED LEARNING, P1, DOI [10.4018/978-1-60566-360-9.ch001, DOI 10.4018/978-1-60566-360-9.CH001]
   Cotrina C, 2018, PEERJ PREPRINTS
   Dai Y, 1996, PATTERN RECOGN, V29, P1007, DOI 10.1016/0031-3203(95)00139-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Das D, 2014, INT J COMPUTATIONAL, V4, P49, DOI DOI 10.5121/IJCSA.2014.4206
   de Souza F, 2017, SIBGRAPI, P323, DOI 10.1109/SIBGRAPI.2017.49
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dong L, 2017, FRONT COMPUT SCI-CHI, V11, P1023, DOI 10.1007/s11704-016-5538-y
   Dow CR, 2020, SOFTWARE PRACT EXPER, V50, P630, DOI 10.1002/spe.2742
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Duda RO., 2012, Pattern classificatio
   Dwivedi N, 2020, MULTIMED TOOLS APPL, V79, P21037, DOI 10.1007/s11042-020-08902-w
   El-dosuky Mohamed A., 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P137, DOI 10.1007/978-3-030-44289-7_14
   Elgammal A., 2009, ENCY BIOMETRICS, V4, P1218, DOI DOI 10.1007/978-0-387-73003-5_89
   Endah SN, 2017, SCI J INFORM, V4, P143, DOI [10.15294/sji.v4i2.12013, DOI 10.15294/SJI.V4I2.12013]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Féraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Firoze A, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING (ICIGP 2018), P14, DOI 10.1145/3191442.3191467
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gaikwad V, 2015, PROCEDIA COMPUT SCI, V46, P321, DOI 10.1016/j.procs.2015.02.027
   Gajjar V, 2017, IEEE INT CONF COMP V, P2805, DOI 10.1109/ICCVW.2017.330
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   García-Martín A, 2012, IMAGE VISION COMPUT, V30, P345, DOI 10.1016/j.imavis.2012.03.005
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gomez G., 2002, MICAI 2002: Advances in Artificial Intelligence.Second Mexican International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol. 2313), P69
   González A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Greche L, 2016, 2016 INT C INF TECHN, P1
   Guo JJ, 2017, IOP CONF SER-MAT SCI, V242, DOI 10.1088/1757-899X/242/1/012115
   Hapsari G. C., 2010, Journal of Applied Sciences, V10, P2793, DOI 10.3923/jas.2010.2793.2798
   Hassanpour R., 2008, P WORLD ACAD SCI ENG, V31, P1
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112699
   Hong Han, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P459, DOI 10.1109/ICIG.2013.96
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Hsu FC, 2013, 2013 7 INT C SIGN PR, P1, DOI DOI 10.1109/ICSPCS.2013.6723967
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Jedynak B., 2003, 2003 C COMP VIS PATT, V8, P92
   Jie Yang, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P687
   Jingxiao Zheng, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P194, DOI 10.1109/TBIOM.2020.2973504
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kahu SY, 2019, COLOR RES APPL, V44, P8, DOI 10.1002/col.22291
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kale Kiran, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359323
   Kalwa U, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060790
   Khalifa AF, 2019, IMAGE VISION COMPUT, V85, P1, DOI 10.1016/j.imavis.2019.02.010
   KHAN MA, 2020, MULTIMED TOOLS, P1
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Khelalef A, 2019, PATTERN RECOGN IMAGE, V29, P702, DOI 10.1134/S1054661819040084
   Kim B, 2020, SOFT COMPUT, V24, P17081, DOI 10.1007/s00500-020-04999-1
   Kim HK, 2018, J ADV TRANSPORT, P2018
   Kumar SH, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1247
   Kwon D, 2019, CLUSTER COMPUT, V22, P949, DOI 10.1007/s10586-017-1117-8
   Ladjailia A, 2020, NEURAL COMPUT APPL, V32, P16387, DOI 10.1007/s00521-018-3951-x
   Lee JY, 2002, P 2002 INT C IM SCI
   Li Cuimei, 2017, 2017 13th IEEE International Conference on Electronic Measurement & Instruments (ICEMI), P483, DOI 10.1109/ICEMI.2017.8265863
   Li HT, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/7297960
   Li Z, 2017, ARXIV171107264
   Liu CL, 2010, EXPERT SYST APPL, V37, P7174, DOI 10.1016/j.eswa.2010.04.014
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loesdau M, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P38
   Luo R, 2016, ENCY COLOR SCI TECHN
   Luo XM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081738
   Ma M, 2020, MULTIMED TOOLS APPL, V79, P9267, DOI 10.1007/s11042-019-7444-4
   Maheswari S, 2017, ENHANCED SKIN TONE D
   Mahmoodi MR, 2017, ARXIV170105595
   Mateus A, 2019, ROBOT AUTON SYST, V113, P23, DOI 10.1016/j.robot.2018.12.007
   Matsumura R, 2019, HUMAN DETECTION USIN
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Montufar-Chaveznava R, 2006, PROC WRLD ACAD SCI E, V18, P161
   Mulyanto A, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2019), DOI 10.1109/icicos48119.2019.8982396
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Nambiar A., 2014, Int. J. Mach. Intell. Sens. Signal Process, V1, P267, DOI DOI 10.1504/IJMISSP.2014.066428
   Ogale Neeti A, 2006, SURVEY, V125, P133
   Ojha U., 2017, 2017 8th International Conference on Computing, Communication and Networking Technologies (ICCCNT), P1, DOI DOI 10.1109/ICCCNT.2017.8204031
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Ozturk C, 2018, P EUR C COMP VIS ECC
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Petrovic N, 2008, LECT NOTES COMPUT SC, V5259, P775, DOI 10.1007/978-3-540-88458-3_70
   Peyre G, 2004, MATH IMAGE ANAL MIA, P4
   Phung SL, 2004, IEEE IMAGE PROC, P1385
   Phung SL, 2001, IEEE IJCNN, P2844, DOI 10.1109/IJCNN.2001.938827
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Popov A, 2008, 2008 4TH INTERNATIONAL IEEE CONFERENCE INTELLIGENT SYSTEMS, VOLS 1 AND 2, P558
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Rahim AHMA, 2017, INT CONF ADV ELECTR, P1, DOI 10.1109/ICAEE.2017.8255316
   Reddy RVK., 2016, Int J Comput Appl, V147
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riaz I, 2013, IADIS-INT J COMPUT S, V8, P1
   Rusia MK, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P612, DOI 10.1109/ICIIP47207.2019.8985867
   Sayed U, 2018, ELLIPTICAL BOUNDARY
   Schmidt A, 2007, ADV INTEL SOFT COMPU, V45, P816
   Schneider N, 2013, LECT NOTES COMPUT SC, V8142, P174, DOI 10.1007/978-3-642-40602-7_18
   Schwerdt K., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P90, DOI 10.1109/AFGR.2000.840617
   Sebe N, 2004, INT C PATT RECOG, P903, DOI 10.1109/ICPR.2004.1334405
   Seemanthini K., 2018, Procedia Computer Science, V132, P1317, DOI 10.1016/j.procs.2018.05.048
   Setjo CH, 2017, 2017 7TH INTERNATIONAL ANNUAL ENGINEERING SEMINAR (INAES), P88
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Sharma SK, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2216, DOI 10.1109/WiSPNET.2017.8300153
   Singh DK, 2016, INDIAN J SCI TECHNOL, V9, P32
   Singh DK., 2016, International Journal of Control Theory and Applications, V9, P173
   Singh DK, 2018, INT C ADV INFORMATIC, P54
   Singh DK, 2017, 2017 IEEE 8TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P197, DOI 10.1109/ICSGRC.2017.8070594
   Singh DK, 2017, DEFENCE SCI J, V67, P50, DOI 10.14429/dsj.67.10286
   Singh DK, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P379, DOI 10.1109/ICCSP.2015.7322912
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Störring M, 2003, PATTERN RECOGN LETT, V24, P1715, DOI 10.1016/S0167-8655(02)00327-6
   Subban R, 2013, INT C ADV REC TECHN, P68
   Sultana F., 2020, Intelligent Computing: Image Processing Based Applications. Advances in Intelligent Systems and Computing (AISC 1157), P1, DOI 10.1007/978-981-15-4288-6_1
   Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83
   Tamgade Sukeshni N., 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P914, DOI 10.1109/ICETET.2009.154
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Teixeira T., 2010, ACM Comput. Surv., V5, P59
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Terrillon JC, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P112, DOI 10.1109/AFGR.1998.670934
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Hoang VD, 2014, LECT NOTES COMPUT SC, V8588, P338, DOI 10.1007/978-3-319-09333-8_37
   Vezhnevets V., 2003, GRAPHICON03, P85
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wai Kit Wong, 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P366, DOI 10.1109/ICSIPA.2011.6144091
   Walia GS, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414550040
   Wang LM, 2007, LECT NOTES COMPUT SC, V4843, P189
   Wang XD, 2019, IEEE T CIRC SYST VID, V29, P3454, DOI 10.1109/TCSVT.2018.2877694
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang YJ, 2001, PATTERN RECOGN, V34, P1983, DOI 10.1016/S0031-3203(00)00119-9
   Wong A, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P95, DOI 10.1109/CRV.2018.00023
   Wong WK, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P881
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu HY, 1999, IEEE T PATTERN ANAL, V21, P557, DOI 10.1109/34.771326
   Wu JX, 2011, IEEE INT CONF ROBOT, P860
   Wu X, 2022, NEURAL COMPUT APPL, V34, P11491, DOI 10.1007/s00521-020-04873-z
   Yamashita A., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1664, DOI 10.1109/ROBIO.2011.6181528
   Yang B, 2016, IEEE SENS J, V16, P216, DOI 10.1109/JSEN.2015.2477540
   Yang MH, 1998, PROC SPIE, V3656, P458, DOI 10.1117/12.333865
   Yuan BH, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.025003
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang B, 2010, INT J IND ERGONOM, V40, P414, DOI 10.1016/j.ergon.2010.02.003
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang HM, 2000, LECT NOTES COMPUT SC, V1948, P237
   Zhu AC, 2019, MULTIMED TOOLS APPL, V78, P16077, DOI 10.1007/s11042-018-6964-7
NR 187
TC 20
Z9 20
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8759
EP 8808
DI 10.1007/s11042-020-10103-4
EA NOV 2020
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038000001
DA 2024-07-18
ER

PT J
AU Winata, HN
   Nasution, MA
   Ahamed, T
   Noguchi, R
AF Winata, Haikal Nando
   Nasution, Muhammad Ansori
   Ahamed, Tofael
   Noguchi, Ryozo
TI Prediction of concentration for microalgae using image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dry cell weight; Microalgae; Concentration; Luminance method; Viscosity
   method
ID RHEOLOGICAL CHARACTERIZATION; DISEASE DETECTION; DUAL CAMERA; BIOMASS;
   PHOTOBIOREACTOR; BIODIESEL; VISCOSITY; COLOR; IDENTIFICATION;
   PRODUCTIVITY
AB Maintaining the optimum growth rate and estimating the concentration of microalgae are critical in improving microalgae production. An efficient concentration assessment of microalgae is essential for a timely and effective determination of the harvest period. This study proposes the luminance and viscosity methods to predict the concentration of microalgae. Image analysis was applied to measure the concentration of native microalgae: Desmodesmus sp., Scenedesmus sp., Dictyosphaerium sp., and Klebsormidium sp. The experiments were performed using different concentrations of the dry cell weight (DCW) of these microalgae species. A dual-camera device was used to capture the images of the DCW solution in a flask. For the confirmation of viscosity, a viscometer was used to determine the concentration of microalgae. A comparative analysis was performed between the data from the image analysis and viscosity method. The results from the viscosity method showed a higher accuracy with R-2 = 0.9784 and the luminance method with R-2 = 0.8266. Further investigations revealed that the brightness of the DCW image had a limitation at a specific concentration where the color was unrecognized. The current image processing method has the potential to be applied in an outdoor cultivation facility for real-time data acquisition. Both methods have advantages in terms of required time and experimental costs. The image analysis method provides an alternative way to efficiently monitor the cultivation and harvesting of microalgae.
C1 [Winata, Haikal Nando] Univ Tsukuba, Grad Sch Life & Environm Sci, Tsukuba, Ibaraki 3058572, Japan.
   [Winata, Haikal Nando] Inst Technol Medan ITM, Jalan Gedung Arca 52, Teladan 20217, Medan, Indonesia.
   [Nasution, Muhammad Ansori] Indonesian Oil Palm Res Inst IOPRI, Jalan Brigjend Katamso 51,POB 1103, Medan 20158, Indonesia.
   [Ahamed, Tofael; Noguchi, Ryozo] Univ Tsukuba, Fac Life & Environm Sci, Tsukuba, Ibaraki 3058572, Japan.
C3 University of Tsukuba; Riset Perkebunan Nusantara; Indonesian Oil Palm
   Research Institute (IOPRI); University of Tsukuba
RP Noguchi, R (corresponding author), Univ Tsukuba, Fac Life & Environm Sci, Tsukuba, Ibaraki 3058572, Japan.
EM hayafans@gmail.com; ansoricca@gmail.com;
   tofael.ahamed.gp@u.tsukuba.ac.jp; noguchi.ryozo.gm@u.tsukuba.ac.jp
OI Nasution, Muhammad/0000-0003-1385-4999
FU Algae Biomass and Energy System (ABES) R&D Center, University of
   Tsukuba, Japan; Ministry of Education and Culture, Japan
FX This work was supported by the Algae Biomass and Energy System (ABES)
   R&D Center, University of Tsukuba, Japan. The authors would like to
   acknowledge the Ministry of Education and Culture, Japan for the MEXT
   Scholarship.
CR Adesanya VO, 2012, J RHEOL, V56, P925, DOI 10.1122/1.4717494
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Asoiro F. U., 2019, Journal of Environmental Science and Technology, V12, P164, DOI 10.3923/jest.2019.164.176
   Benavides M, 2015, SENSORS-BASEL, V15, P4766, DOI 10.3390/s150304766
   Bernaerts TMM, 2017, ALGAL RES, V25, P452, DOI 10.1016/j.algal.2017.05.014
   BJORNSEN PK, 1986, APPL ENVIRON MICROB, V51, P1199
   Brown LM., 1989, J APPL PHYCOL, V1, P211, DOI [DOI 10.1007/BF00003647, 10.1007/BF00003647]
   Chen C, 2018, NANOTECHNOL REV, V7, P11, DOI 10.1515/ntrev-2017-0165
   Chen JX, 2018, RENEW SUST ENERG REV, V90, P336, DOI 10.1016/j.rser.2018.03.073
   Chen X, 2011, BIORESOURCE TECHNOL, V102, P6005, DOI 10.1016/j.biortech.2011.02.061
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Coltelli P, 2013, ENVIRON SCI-PROC IMP, V15, P1397, DOI 10.1039/c3em00160a
   Córdoba-Matson MV, 2010, J APPL PHYCOL, V22, P427, DOI 10.1007/s10811-009-9475-0
   de Carvalho CCCR, 2005, J MICROBIOL METH, V60, P135, DOI 10.1016/j.mimet.2004.09.014
   Demura M, 2018, ALGAL RES, V29, P22, DOI 10.1016/j.algal.2017.11.008
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Dierssen HM, 2006, LIMNOL OCEANOGR, V51, P2646, DOI 10.4319/lo.2006.51.6.2646
   Estime B, 2017, SCI REP-UK, V7, DOI 10.1038/srep40725
   Gohad PR, 2019, INT J SCI TECHNOL RE, V8, P215
   Gouveia L, 2009, J IND MICROBIOL BIOT, V36, P269, DOI 10.1007/s10295-008-0495-6
   Gray AJ, 2002, J APPL PHYCOL, V14, P193, DOI 10.1023/A:1019976310527
   Gruber-Brunhumer MR, 2019, J BIOTECHNOL, V295, P80, DOI 10.1016/j.jbiotec.2019.02.004
   Havlik I, 2013, TRENDS BIOTECHNOL, V31, P406, DOI 10.1016/j.tibtech.2013.04.005
   Jung SK, 2006, BIOTECHNOL PROGR, V22, P1443, DOI 10.1021/bp0600886
   Kadhum HJ, 2019, BIORESOURCE TECHNOL, V275, P328, DOI 10.1016/j.biortech.2018.12.071
   Kalaivani S, 2020, MULTIMED TOOLS APPL, V79, P9145, DOI 10.1007/s11042-018-7126-7
   Karmakar R, 2018, PETROL SCI, V15, P164, DOI 10.1007/s12182-017-0203-0
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Kumar K, 2013, BIORESOURCE TECHNOL, V143, P88, DOI 10.1016/j.biortech.2013.05.117
   LAWRENCE JR, 1992, J BACTERIOL, V174, P5732, DOI 10.1128/JB.174.17.5732-5739.1992
   Li XZ, 2014, COMM COM INF SC, V483, P293
   Liu S, 2016, MULTIMED TOOLS APPL, V75, P15525, DOI 10.1007/s11042-014-2446-8
   Marie D., 2005, ALGAL CULTURING TECH, V1, P253, DOI DOI 10.1016/B978-012088426-1/50018-4
   Martínez C, 2017, IFAC PAPERSONLINE, V50, P8734, DOI 10.1016/j.ifacol.2017.08.1725
   Meireles LA, 2002, BIOTECHNOL PROGR, V18, P1387, DOI 10.1021/bp020283u
   Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724
   Ogbonna IO, 2019, BIOFUELS-UK, V10, P657, DOI 10.1080/17597269.2018.1426164
   Petkov G.D., 1996, Arch. Hydrobiol. Suppl., V81, P99, DOI 10.1127/algol_stud/81/1996/99
   Promdaen S, 2014, PROCEDIA COMPUT SCI, V29, P1981, DOI 10.1016/j.procs.2014.05.182
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Rafaï S, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.098102
   Rajni C, 2017, J ENERGY ENV SUSTAIN, V4, P58
   Rodriguez G, 2018, CHEM ENG RES DES, V132, P890, DOI 10.1016/j.cherd.2018.01.018
   Sandnes JM, 2006, J BIOTECHNOL, V122, P209, DOI 10.1016/j.jbiotec.2005.08.034
   Santhi N, 2013, BIOINFORM BIOL INSIG, V7, P327, DOI 10.4137/BBI.S12844
   Sarrafzadeh MH, 2015, J APPL PHYCOL, V27, P205, DOI 10.1007/s10811-014-0285-7
   Schneider N, 2014, BIORESOURCE TECHNOL, V170, P293, DOI 10.1016/j.biortech.2014.07.107
   Shrivastava S, 2017, MULTIMED TOOLS APPL, V76, P26647, DOI 10.1007/s11042-016-4191-7
   Slade R, 2013, BIOMASS BIOENERG, V53, P29, DOI 10.1016/j.biombioe.2012.12.019
   Tan WX, 2016, MULTIMED TOOLS APPL, V75, P16741, DOI 10.1007/s11042-015-2940-7
   TORZILLO G, 1993, BIOTECHNOL BIOENG, V42, P891, DOI 10.1002/bit.260420714
   Uyar B, 2013, J CHEM TECHNOL BIOT, V88, P1144, DOI 10.1002/jctb.3954
   Winata HN, 2019, J JPN I ENERGY, V98, P73, DOI 10.3775/jie.98.73
   Xu YQ, 2018, OPT EXPRESS, V26, P34609, DOI 10.1364/OE.26.034609
   Yang FX, 2017, J MOL LIQ, V248, P626, DOI 10.1016/j.molliq.2017.10.107
   Yin ZH, 2020, BIORESOURCE TECHNOL, V301, DOI 10.1016/j.biortech.2020.122804
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang XR, 2013, BIORESOURCE TECHNOL, V139, P209, DOI 10.1016/j.biortech.2013.03.195
NR 58
TC 12
Z9 13
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8541
EP 8561
DI 10.1007/s11042-020-10052-y
EA NOV 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587038500005
DA 2024-07-18
ER

PT J
AU Guo, FH
   Zhang, CM
   Zhang, ML
AF Guo, Fenghua
   Zhang, Caiming
   Zhang, Mingli
TI Hyperspectral image super-resolution through clustering-based sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imaging; Sparse representation; Structural prior
ID RESOLUTION; HALLUCINATION
AB Promoting the spatial resolution of hyperspectral sensors is expected to improve computer vision tasks. However, due to the physical limitations of imaging sensors, the hyperspectral image is often of low spatial resolution. In this paper, we propose a new hyperspectral image super-resolution method from a low-resolution (LR) hyperspectral image and a high resolution (HR) multispectral image of the same scene. The reconstruction of HR hyperspectral image is formulated as a joint estimation of the hyperspectral dictionary and the sparse codes based on the spatial-spectral sparsity of the hyperspectral image. The hyperspectral dictionary is learned from the LR hyperspectral image. The sparse codes with respect to the learned dictionary are estimated from LR hyperspectral image and the corresponding HR multispectral image. To improve the accuracy, both spectral dictionary learning and sparse coefficients estimation exploit the spatial correlation of the HR hyperspectral image. Experiments show that the proposed method outperforms several state-of-art hyperspectral image super-resolution methods in objective quality metrics and visual performance.
C1 [Guo, Fenghua; Zhang, Caiming] Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
   [Zhang, Mingli] McGill Univ, McConnell Brain Imaging Ctr, Montreal Neurol Inst, Montreal, PQ, Canada.
C3 Shandong University; McGill University
RP Zhang, CM (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Peoples R China.
EM czhang@sdu.edu.cn
RI Cheng, Lin/KFQ-3111-2024
FU National Natural Science Foundation of China [61772312]; NSFC
   [U1609218]; Natural Science Foundation of Shandong Province, China
   [ZR2017MF033]
FX The authors would like to thank the reviewers for their invaluable
   comments. This work is supported in part by National Natural Science
   Foundation of China under Grant 61772312, NSFC Joint Fund with Zhejiang
   Integration of Informatization and Industrialization under Grant
   U1609218 and Natural Science Foundation of Shandong Province, China
   under Grant ZR2017MF033.
CR Akhtar N, 2015, PROC CVPR IEEE, P3631, DOI 10.1109/CVPR.2015.7298986
   Akhtar N, 2014, LECT NOTES COMPUT SC, V8695, P63, DOI 10.1007/978-3-319-10584-0_5
   Babu RS, 2018, ADV INTELL SYST, V668, P503, DOI 10.1007/978-981-10-7868-2_49
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Casalino G, 2017, PATTERN RECOGN, V63, P15, DOI 10.1016/j.patcog.2016.09.006
   Dell'Acqua F, 2004, IEEE GEOSCI REMOTE S, V1, P322, DOI 10.1109/LGRS.2004.837009
   Dian RW, 2019, IEEE T IMAGE PROCESS, V28, P5135, DOI 10.1109/TIP.2019.2916734
   Dian RW, 2017, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2017.411
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Du B, 2016, IEEE T IMAGE PROCESS, V25, P5345, DOI 10.1109/TIP.2016.2601268
   Guo FH, 2019, MULTIMED TOOLS APPL, V78, P16601, DOI 10.1007/s11042-018-7004-3
   Guo FH, 2018, IET IMAGE PROCESS, V12, P1394, DOI 10.1049/iet-ipr.2017.0880
   Hardie RC, 2004, IEEE T IMAGE PROCESS, V13, P1174, DOI 10.1109/TIP.2004.829779
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Huang FR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1874, DOI 10.1145/3240508.3240614
   Huang FR, 2018, APPL SOFT COMPUT, V73, P106, DOI 10.1016/j.asoc.2018.08.010
   Iordache MD, 2011, IEEE T GEOSCI REMOTE, V49, P2014, DOI 10.1109/TGRS.2010.2098413
   Jian MW, 2019, INFORM SCIENCES, V488, P181, DOI 10.1016/j.ins.2019.03.026
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Kawakami R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2329, DOI 10.1109/CVPR.2011.5995457
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Lanaras C, 2015, IEEE I CONF COMP VIS, P3586, DOI 10.1109/ICCV.2015.409
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li ST, 2018, IEEE T IMAGE PROCESS, V27, P4118, DOI 10.1109/TIP.2018.2836307
   Molina R, 1999, IEEE T IMAGE PROCESS, V8, P231, DOI 10.1109/83.743857
   Molina R, 2008, APPL COMPUT HARMON A, V24, P251, DOI 10.1016/j.acha.2007.03.006
   Qi Wei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3176, DOI 10.1109/ICASSP.2014.6854186
   Simoes M, 2015, IEEE T GEOSCI REMOTE, V53, P3373, DOI 10.1109/TGRS.2014.2375320
   Veganzones MA, 2016, IEEE T IMAGE PROCESS, V25, P274, DOI 10.1109/TIP.2015.2496263
   Wald L., 2000, 3 C FUS EARTH DAT ME, P99
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei Q, 2016, IEEE T GEOSCI REMOTE, V54, P7236, DOI 10.1109/TGRS.2016.2598784
   Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Wycoff E, 2013, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2013.6637883
   Xu Y, 2019, IEEE T IMAGE PROCESS, V28, P3034, DOI 10.1109/TIP.2019.2893530
   Yasuma F, 2010, IEEE T IMAGE PROCESS, V19, P2241, DOI 10.1109/TIP.2010.2046811
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yuan Y, 2017, IEEE T IMAGE PROCESS, V26, P51, DOI 10.1109/TIP.2016.2617462
   Zhang YF, 2012, IEEE T GEOSCI REMOTE, V50, P3453, DOI 10.1109/TGRS.2012.2184122
   Zhang YF, 2009, IEEE T GEOSCI REMOTE, V47, P3834, DOI 10.1109/TGRS.2009.2017737
NR 46
TC 2
Z9 2
U1 14
U2 123
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7351
EP 7366
DI 10.1007/s11042-020-09952-w
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000584858400007
DA 2024-07-18
ER

PT J
AU Akhlaghi, S
   Hassanpour, H
AF Akhlaghi, S.
   Hassanpour, H.
TI Frontal face modeling using morphing-based averaging and Low-rank
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Frontalization; Head pose image; Image morphing; Matrix decomposition;
   Spatial translation
ID RECOGNITION; REPRESENTATION; ALIGNMENT
AB Head pose variations are a major problem in face recognition. Many advanced methods exist for synthesizing frontal face images with head pose variations. These methods are generally categorized into three groups: 3D based methods which use 3D face models, path based methods which exploit linear transformations of small segments of the face, and deep learning methods. Frontalization methods usually use a single head pose image for frontal face synthesizing and heuristics for filling the hidden parts of the face in the reference model. This causes some artifact in the image, and reduces similarity between the synthesized and actual frontal face image. In this research, frontalization is done by a weighted averaging algorithm, as an extended version of the path based frontalization method powered by matrix rank minimization, which exploits from classical image domain transform. This preprocessing technique grants matrix decomposition methods the ability to eliminate head pose variations. Representing the actual face models and robustness to facial landmark detection errors are the advantages of this method compared to other existing methods. Quantitative and qualitative comparison results indicate superiority of the proposed method in face frontalization.
C1 [Akhlaghi, S.; Hassanpour, H.] Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
EM h.hassanpour@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   Aravkin A, 2014, ARXIV14061089, V1406, P1089
   Ashraf U, 2008, IEEE VTS VEH TECHNOL, P1
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen CH, 2013, IEEE INT WORKS GENET, P16, DOI 10.1109/GEFS.2013.6601050
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Crowley J. L., 2004, P WORKSH VIS OBS DEI
   Fei MJ, 2015, NEUROCOMPUTING, V152, P413, DOI 10.1016/j.neucom.2014.09.060
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Lee SY, 1996, J VISUAL COMP ANIMAT, V7, P3, DOI 10.1002/(SICI)1099-1778(199601)7:1<3::AID-VIS131>3.0.CO;2-U
   Li AN, 2012, IEEE T IMAGE PROCESS, V21, P305, DOI 10.1109/TIP.2011.2160957
   Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Peng X, 2017, IEEE I CONF COMP VIS, P1632, DOI 10.1109/ICCV.2017.180
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Sagonas C, 2017, INT J COMPUT VISION, V122, P270, DOI 10.1007/s11263-016-0920-7
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wu YH, 2018, MACH VISION APPL, V29, P375, DOI 10.1007/s00138-017-0887-6
   Yi Dong, 2014, ARXIV14117923
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Yin XX, 2017, HEALTH INFOR SCI, P1, DOI [10.1109/ICCV.2017.430, 10.1007/978-3-319-57027-3_1]
   Ying S, 2020, IET IMAGE PROCESS
   Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 45
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7125
EP 7144
DI 10.1007/s11042-020-09878-3
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000583943700004
DA 2024-07-18
ER

PT J
AU Cheng, KY
   Khokhar, MS
   Ayoub, M
   Jamali, Z
AF Cheng, Keyang
   Khokhar, Muhammad Saddam
   Ayoub, Misbah
   Jamali, Zakria
TI Nonlinear dimensionality reduction in robot vision for industrial
   monitoring process via deep three dimensional Spearman correlation
   analysis (D3D-SCA)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep features correlation analysis; Robot vision; Dimension reduction;
   Transfer learning
ID CANONICAL CORRELATION-ANALYSIS
AB During the era of Industry 4.0, the industrial robot monitoring process is getting success and popularity day by day. It also plays a vital role in the enhancement of robot vision algorithms. This paper proposed a model Deep Three Dimensional Spearman Correlation Analysis (D3D-SCA) to address nonlinear dimensionality reduction in robot vision for three-dimensional data. Dealing with three-dimensional multimedia datasets using traditional algorithms, to date, researchers have been facing limitations and challenges because mostly sub-space learning algorithms and their developments cannot perform satisfactorily in most of the time with linear and non-linear data dependency. The proposed model directly finds the relations between two sets of three-dimensional data without reshaping the data into 2D-matrices or vectors and dramatically reduces the dimensional reduction and computational algorithm complexity. The proposed model extracts deep information and translates it into a decision. To do so, three components are employed in the proposed model: customized deep learning model Inception_V3 for deep feature mapping, three-dimensional spearman correlation analysis for comparing pairwise deep features without a singular matrix and spatial dilemma problem, and the customized Xception classifier with automatic online updating ability and adjustable neural architecture for low latency models. The motivation of the proposed model is to advance the scalability of existing industrial robot vision applications which based on recognition, detection and re-identification approaches. Extensive findings on industrial datasets named "3D Objects on turntable and Caltech 101" demonstrate the effectiveness of the proposed model.
C1 [Cheng, Keyang; Khokhar, Muhammad Saddam] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Ayoub, Misbah] Xian Jiaotong Liverpool Univ, Sch Comp Sci & Software Engn, Suzhou, Peoples R China.
   [Jamali, Zakria] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Chengdu 610054, Peoples R China.
C3 Jiangsu University; Xi'an Jiaotong-Liverpool University; University of
   Electronic Science & Technology of China
RP Khokhar, MS (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM saddam_khokhar@hotmail.com; engr.Misbahayoub@gmail.com;
   Zakria.uestc@hotmail.com
RI Khokhar, Muhammad Saddam/AAD-3395-2019
OI Khokhar, Muhammad Saddam/0000-0001-7489-0542
FU National Natural Science Foundation of China [61972183, 61672268];
   National Engineering Laboratory Director Foundation of Big Data
   Application for Social Security Risk Perception and Prevention
FX This research is supported by National Natural Science Foundation of
   China (61972183, 61672268) and National Engineering Laboratory Director
   Foundation of Big Data Application for Social Security Risk Perception
   and Prevention.
CR Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Alsaqre F, 2022, APPL COMPUT INFORM, V18, P136, DOI 10.1016/j.aci.2019.02.001
   [Anonymous], 2011, ARXIV11053422
   Bessaoudi M, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Bilenko NY, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00049
   Cheng KY, 2019, I C DATA ENGIN WORKS, P319, DOI 10.1109/ICDEW.2019.00058
   Cheng KY, 2019, IEEE ACCESS, V7, P159466, DOI 10.1109/ACCESS.2019.2951164
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Griffin G., 2007, CALTECH 256 OBJECT C
   Haopeng Lei, 2016, 2016 6th International Conference on Digital Home (ICDH), P261, DOI 10.1109/ICDH.2016.060
   Hassan SNHB, 2019, J OPTIMIZ THEORY APP, V181, P883, DOI 10.1007/s10957-019-01488-w
   Hoffman G, 2019, IEEE T HUM-MACH SYST, V49, P209, DOI 10.1109/THMS.2019.2904558
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Janocha Katarzyna, 2017, Theor Found Mach Learn, DOI [DOI 10.4467/20838476SI.16.004.6185, 10.4467/20838476SI.16. 004.6185]
   Jansen E., 2019, OCEAN SCI DISCUSS, V2019, P1
   Khokhar MS, 2019, INT CONF INF COMMUN, P14, DOI [10.1109/ICICT47744.2019.9001973, 10.1109/icict47744.2019.9001973]
   Koush Y, 2019, NEUROIMAGE, V184, P214, DOI 10.1016/j.neuroimage.2018.08.067
   Lin M., 2014, P INT C LEARN REPR I
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Malhotra A, 2018, IEEE SENS J, V18, P8085, DOI 10.1109/JSEN.2018.2864207
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Mingyuan Zhang, 2019, IOP Conference Series: Earth and Environmental Science, V310, DOI 10.1088/1755-1315/310/4/042026
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Sahoo D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2660
   Schwab K, 2018, FUTURE JOBS 2018
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang, 2016, ESANN 2017 P, P589
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   You XG, 2019, PATTERN RECOGN, V92, P37, DOI 10.1016/j.patcog.2019.03.008
   Zhang GH, 2018, LECT NOTES ARTIF INT, V10956, P134, DOI 10.1007/978-3-319-95957-3_15
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang JX, 2019, IEEE T CYBERNETICS, V49, P198, DOI 10.1109/TCYB.2017.2771229
   Zhu QQ, 2018, IEEE T GEOSCI REMOTE, V56, P2689, DOI 10.1109/TGRS.2017.2781712
NR 36
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5997
EP 6017
DI 10.1007/s11042-020-09859-6
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800001
DA 2024-07-18
ER

PT J
AU Mahmoud, AA
   El-Shafai, W
   Taha, TE
   El-Rabaie, ESM
   Zahran, O
   El-Fishawy, AS
   Abd El-Samie, FE
AF Mahmoud, Amira A.
   El-Shafai, Walid
   Taha, Taha E.
   El-Rabaie, El-Sayed M.
   Zahran, Osama
   El-Fishawy, Adel S.
   Abd El-Samie, Fathi E.
TI A statistical framework for breast tumor classification from ultrasonic
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Image classification; DWT; PCA; LDA; Active contour
   segmentation; Ultrasonic images
AB Segmentation and classification of ultrasonic breast images is extremely critical for medical diagnosis. Over the last years, various techniques have already been presented for this objective. In this paper, a proposed framework is presented to segment a given ultrasonic image with breast tumor and classify the tumor as being benign or malignant. The proposed framework depends on an active contour segmentation model to determine the tumor region, and then extract it from the ultrasonic image. After that, the Discrete Wavelet Transform (DWT) is used to extract features from the segmented images. Then, the dimensions of the resulting features are reduced by applying feature reduction approaches, namely, the Principal Component Analysis (PCA), the Linear Discriminant Analysis (LDA) and both of them together. The obtained features are submitted to a statistical classifier and the strategy of voting is used to classify the tumor. In the simulation work, 160 benign and malignant breast tumor images collected from Sirindhorn International Institute of Technology (SIIT) website are used. The average processing time for a 256 x 256 image on a laptop with Core i5, 2.3 GHz processor and 8GB RAM is 1.8 s. From the simulation results, it is found that the utilization of the PCA approach provides the best accuracy of 99.23% among the three feature reduction approaches applied. Finally, the proposed framework is compared with the Support Vector Machine (SVM) classification to evaluate its performance in terms of accuracy, sensitivity, precision, and specificity. It is noticed that the proposed framework is efficient and rapid, and it can be applied for ultrasonic breast image segmentation and classification, and thus it can assist the specialists to segment and decide whether a tumor is benign or malignant.
C1 [Mahmoud, Amira A.; El-Shafai, Walid; Taha, Taha E.; El-Rabaie, El-Sayed M.; Zahran, Osama; El-Fishawy, Adel S.; Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Princess Nourah bint
   Abdulrahman University
RP Mahmoud, AA (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
EM ameragreeda@yahoo.com; walid.elshafai@el-menofia.edu.eg;
   taha117@hotmail.com; elsayedelrabaie@gmail.com;
   osama_zahran@el-eng.menofia.edu.eg; aelfishawy@hotmail.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Shafai, Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881; El-Fishawy,
   Adel/0000-0003-1567-457X
CR [Anonymous], 2015, C INT C COMP SCI INF
   Barman PC, 2011, COMPUTER SCI ENG INT, V1
   Camacho J, 2010, ANAL CHIM ACTA, V658, P106, DOI 10.1016/j.aca.2009.10.054
   Chen WS, 2011, COMPUT MATH APPL, V62, P2696, DOI 10.1016/j.camwa.2011.06.051
   Ding J, 2012, US NATL LIB MED NATL, V25
   Gupta Dipalee., 2015, International Journal of Emerging Technology and Advanced Engineering, V4
   Hagar AAM, 2016, PROCEEDINGS OF 2016 11TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P141, DOI 10.1109/ICCES.2016.7821990
   Leng L, 2010, 2010 INT C INF COMM
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li HL, 2016, NEUROCOMPUTING, V171, P744, DOI 10.1016/j.neucom.2015.07.010
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Makandar A., 2018, P INT C COGN REC ICC, P371
   Malik B, 2016, SCI REP-UK, V6, DOI 10.1038/srep38857
   Murgante B., 2011, COMPUTATIONAL SCI IT, DOI [10.1007/978-3-642-21934-4, DOI 10.1007/978-3-642-21934-4]
   Ng SC, 2017, PROCEDIA COMPUT SCI, V111, P113, DOI 10.1016/j.procs.2017.06.017
   Nosrati SM, 2015, THESIS
   Prabhakar T, 2017, INT J PURE APPL MATH, V114, P119
   Qin Y, 2008, ALPIT 2008: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, PROCEEDINGS, P503, DOI 10.1109/ALPIT.2008.89
   Sadek I, 2016, AUTOMATED BREAST LES
   Shereena VB, 2015, SIGNAL IMAGE PROCESS, V6
   Tagluk ME, 2010, EXPERT SYST APPL, V37, P1600, DOI 10.1016/j.eswa.2009.06.049
   Tammireddy PR, 2014, IMAGE RECONSTRUCTION
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Xiang B, 2013, THESIS
   Yang Z, 2013, P SPIE
NR 26
TC 11
Z9 11
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5977
EP 5996
DI 10.1007/s11042-020-08693-0
EA OCT 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000578564800005
DA 2024-07-18
ER

PT J
AU Acharya, A
   Meher, S
AF Acharya, Aditya
   Meher, Sukadev
TI Iterative spatial domain 2-D signal decomposition for effectual image
   up-scaling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Up-scaling; Interpolation; de-blurring; Signal decomposition; Image
   pre-processing; Filter bank
ID WIENER-BASED INTERPOLATION; SCHEME; SUPERRESOLUTION; MODEL
AB Image up-scaling employs various polynomial interpolation schemes for their reduced computational complexity and suitability for various real-time applications. However, they give blurring artifacts in up-scaled images due to the loss of high frequency (HF) information. Likewise, most of the other edge directed and transform domain interpolation schemes available in the literature though produce lesser blurring as compared to polynomial interpolation schemes but are computationally more complex. To overcome these problems, an iterative spatial domain 2-D signal decomposition technique is proposed. It is meant for extracting the very high frequency (VHF) information from a low resolution (LR) image. The VHF information is obtained by performing the signal decomposition for an estimated number of iterations. Subsequently, the superimposition of this VHF extract with the low resolution image prior to image up-scaling reduces the blurring in its up-scaled counterpart. Since the degradation of higher order sub-band information such as HF and VHF is more than the low and medium frequency information during an up-scaling process, restoration of the most degraded VHF sub-band information would produce much lesser blurring. Simulation results reveal that the proposed scheme gives better performance than many of the existing schemes in terms of objective and subjective measures.
C1 [Acharya, Aditya] Silicon Inst Technol Bhubaneswar, Dept Elect & Commun Engn, Bhubaneswar 751024, India.
   [Meher, Sukadev] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Rourkela 769008, India.
C3 Silicon Institute of Technology; National Institute of Technology (NIT
   System); National Institute of Technology Rourkela
RP Acharya, A (corresponding author), Silicon Inst Technol Bhubaneswar, Dept Elect & Commun Engn, Bhubaneswar 751024, India.
EM aditya@silicon.ac.in; smeher@nitrkl.ac.in
RI Meher, Sukadev/O-4489-2017
OI Meher, Sukadev/0000-0003-4397-3139
CR Acharya A, 2018, MULTIMED TOOLS APPL, V77, P2153, DOI 10.1007/s11042-017-4346-1
   Acharya RP, 2015, INT FOREST REV, V17, P1
   Arif F, 2005, 2005 IEEE International Conference on Mechatronics, P62
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Burger R, 2009, EUROPE-REV LIT MENS, P223
   Chang SG, 2006, IEEE T IMAGE PROCESS, V15, P1471, DOI 10.1109/TIP.2006.871162
   Chen CH, 2014, J MATH IMAGING VIS, V48, P488, DOI 10.1007/s10851-013-0424-9
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Cho MK, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2234736
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   Feng D, 2020, IEEE T CIRCUITS SYST, DOI [10.1109/TCSVT.2019.2963715, DOI 10.1109/TCSVT.2019.2963715]
   Haris M, 2017, IEEE T GEOSCI REMOTE, V55, P4047, DOI 10.1109/TGRS.2017.2687419
   Hung KW, 2013, INT CONF ACOUST SPEE, P1419, DOI 10.1109/ICASSP.2013.6637885
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Hung KW, 2010, IEEE IMAGE PROC, P3297, DOI 10.1109/ICIP.2010.5652082
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lee S. W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P177, DOI 10.1109/ICASSP.1993.319776
   Lehmann TM, 2001, IEEE T MED IMAGING, V20, P660, DOI 10.1109/42.932749
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lim H, 2011, IEEE T CIRC SYST VID, V21, P879, DOI 10.1109/TCSVT.2011.2133250
   Maalouf A, 2013, IMAGE SUPER RESOLUTI, P181
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   Sajjad M., 2013, MULTIMED TOOLS APPL, V74, P8961
   Sha W, 2011, WOODHEAD PUBL MATER, P62
   SMIT T, 1990, IEEE T ACOUST SPEECH, V38, P1512, DOI 10.1109/29.60071
   Tsai P, 2006, P JOINT C INF SCI JC, P1078, DOI [10.2991/jcis.2006.340, DOI 10.2991/JCIS.2006.340]
   Vázquez-Padín D, 2017, IEEE T INF FOREN SEC, V12, P2115, DOI 10.1109/TIFS.2017.2699638
   Wong C-S, 2010, P ICCCN 2010 WORKSH, P1
   Wong CS, 2010, EUR SIGNAL PR CONF, P309
   Wu ZY, 2010, IEEE SIGNAL PROC LET, V17, P827, DOI 10.1109/LSP.2010.2059700
   Yang S, 2008, IEEE T CONSUM ELECTR, V54, P1761, DOI 10.1109/TCE.2008.4711232
   Yaroslavsky L. P., 1996, Bioimaging, V4, P225, DOI 10.1002/1361-6374(199612)4:4<225::AID-BIO1>3.0.CO;2-G
   Ye W, 2011, IEEE T IMAGE PROCESS, V19
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zou CZ, 2017, IEEE GEOSCI REMOTE S, V14, P1022, DOI 10.1109/LGRS.2017.2692958
NR 38
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5577
EP 5616
DI 10.1007/s11042-020-09947-7
EA OCT 2020
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000577469600002
DA 2024-07-18
ER

PT J
AU Pichl, M
   Zangerle, E
AF Pichl, Martin
   Zangerle, Eva
TI User models for multi-context-aware music recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Context-aware recommender systems; Personalization;
   User modeling
ID SYSTEMS
AB In the last decade, music consumption has changed dramatically as humans have increasingly started to use music streaming platforms. While such platforms provide access to millions of songs, the sheer volume of choices available renders it hard for users to find songs they like. Consequently, the task of finding music the user likes is often mitigated by music recommender systems, which aim to provide recommendations that match the user's current context. Particularly in the field of music recommendation, adapting recommendations to the user's current context is critical as, throughout the day, users listen to different music in numerous different contexts and situations. Therefore, we propose a multi-context-aware user model and track recommender system thatjointlyexploit information about the current situation and musical preferences of users. Our proposed system clusters users based on their situational context features and similarly, clusters music tracks based on their content features. By conducting a series of offline experiments, we show that by relying on Factorization Machines for the computation of recommendations, the proposed multi-context-aware user model successfully leverages interaction effects between user listening histories, situational, and track content information, substantially outperforming a set of baseline recommender systems.
C1 [Pichl, Martin; Zangerle, Eva] Univ Innsbruck, Dept Comp Sci, Innsbruck, Austria.
C3 University of Innsbruck
RP Zangerle, E (corresponding author), Univ Innsbruck, Dept Comp Sci, Innsbruck, Austria.
EM eva.zangerle@uibk.ac.at
RI Zangerle, Eva/AAB-3833-2020
OI Zangerle, Eva/0000-0003-3195-8273
FU University of Innsbruck; Medical University of Innsbruck
FX Open access funding provided by University of Innsbruck and Medical
   University of Innsbruck.
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Andersen JS, 2014, INT WORK COGNIT INFO
   Anderson C, 2006, The Long Tail: Why the Future of Business is Selling Less of More
   [Anonymous], 2012, Dimensionality reduction and topic modeling: From latent semantic indexing to latent dirichlet allocation and beyond, DOI [DOI 10.1007/978-1-4614-3223-4_5, 10.1007/978-1-4614-3223-4_52,4, DOI 10.1007/978-1-4614-3223-4_52,4]
   Baltrunas L., 2011, P 5 ACM C REC SYST, P301, DOI DOI 10.1145/2043932.2043988
   Baltrunas L, 2011, LECT NOTES BUS INF P, V85, P89
   Bellogin A., 2011, P 5 ACM C REC SYST R, P333, DOI [10.1145/2043932.2043996, DOI 10.1145/2043932.2043996]
   Blondel M, 2016, ADV NEUR IN, V29
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Chen CM, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P65, DOI 10.1109/WI-IAT.2013.10
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Cunningham S. J., 2006, P 7 INT S MUS INF RE
   Flexer A, 2008, INPR INT S MUS INF R
   Freudenthaler Christoph., 2011, Bayesian factorization machines
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Jannach D., 2015, P RECSYS, P187
   Jannach D, 2014, RSWEB RECSYS
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Juan YC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P43, DOI 10.1145/2959100.2959134
   Kamalzadeh M., 2012, P 13 INT S MUS INF R
   Kaminskas M., 2013, P 7 ACM C REC SYST N, P17
   Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720
   Kaminskas M, 2012, COMPUT SCI REV, V6, P89, DOI 10.1016/j.cosrev.2012.04.002
   Kim JL, 2002, FINITE FIELDS WITH APPLICATIONS TO CODING THEORY, CRYPTOGRAPHY AND RELATED AREAS, P209
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Koren Y, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P447
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lee J. H., 2004, ISMIR, V2004, P5
   Lee JC, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17091435
   Leys C, 2013, J EXP SOC PSYCHOL, V49, P764, DOI 10.1016/j.jesp.2013.03.013
   McFee B., 2012, The International Society for Music Information Retrieval (ISMIR), P343
   McFee B, 2012, IEEE T AUDIO SPEECH, V20, P2207, DOI 10.1109/TASL.2012.2199109
   McVicar Matt., 2011, P 12 INT SOC MUS INF, P783
   Millecamp M, 2018, PROCEEDINGS OF THE 26TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'18), P101, DOI 10.1145/3209219.3209223
   Miller George, 1998, WORDNET ELECT LEXICA
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pichl M, 2018, INT WORK CONTENT MUL
   Pichl M, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P206, DOI 10.1145/3078971.3078980
   Pichl M, 2017, INT J MULTIMED DATA, V8, P44, DOI 10.4018/IJMDEM.2017100103
   Pichl M, 2016, IEEE INT SYM MULTIM, P475, DOI [10.1109/ISM.2016.0107, 10.1109/ISM.2016.139]
   Pichl M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1360, DOI 10.1109/ICDMW.2015.145
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771
   Rendle Steffen, 2010, P 3 ACM INT C WEB SE, P81, DOI DOI 10.1145/1718487.1718498
   Schedl M, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P987, DOI 10.1145/2600428.2609491
   Trofimov A. N. Mikhail, 2016, TFFM TENSORFLOW IMPL
   Vall A, 2019, USER MODEL USER-ADAP, V29, P527, DOI 10.1007/s11257-018-9215-8
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Wei H, 2007, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2007/09/015
   Wu G, 2017, IEEE INT CONF BIG DA, P2766, DOI 10.1109/BigData.2017.8258242
   ZANGERLE E, 2012, P 2 WORKSH MAK SENS, P14
   Zangerle E, 2018, 19 INT SOC MUS INF R
   Zangerle E, 2018, PROCEEDINGS OF THE 26TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'18), P357, DOI 10.1145/3209219.3209258
   Zangerle E, 2021, IEEE T AFFECT COMPUT, V12, P78, DOI 10.1109/TAFFC.2018.2846596
NR 56
TC 7
Z9 8
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22509
EP 22531
DI 10.1007/s11042-020-09890-7
EA OCT 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000574376900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, P
   Liu, L
   Zhou, XL
AF Zhu, Pan
   Liu, Lu
   Zhou, Xinglin
TI Infrared polarization and intensity image fusion based on bivariate BEMD
   and sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Sparse representation; B-BEMD; Common and innovation
   features
ID TRANSFORM; DECOMPOSITION
AB The issue of infrared polarization and intensity images fusion has shown important value in both military and civilian areas. In this paper, a novel fusion approach is addressed by reasonably integrating the common and innovation features between the above two patterns of images, employing Bivariate Bidimensional Empirical Mode Decomposition (B-BEMD) and Sparse Representation (SR) together. Firstly, the high and low frequency components of source images are separated by B-BEMD, and the "max-absolute" rule is used as the activity level measurement to merge the high frequency components in order to effectively retain the details of the source images. Then, the common and innovation features between low frequency components are extracted by the tactfully designed SR-based method, and are combined respectively by the proper fusion rules for the sake of highlighting the common features and reserving the innovation features. Finally, the inverse B-BEMD is performed to reconstruct the fused image. Experimental results indicate the effectiveness of the proposed algorithm compared with traditional MST-and SR-based methods in both aspects of subjective visual and objective performance.
C1 [Zhu, Pan; Liu, Lu; Zhou, Xinglin] Wuhan Univ Sci & Technol, Minist Educ, Key Lab Met Equipment & Control Technol, Wuhan 430081, Peoples R China.
   [Zhu, Pan; Liu, Lu; Zhou, Xinglin] Wuhan Univ Sci & Technol, Hubei Key Lab Mech Transmiss & Mfg Engn, Wuhan 430081, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology
RP Zhu, P (corresponding author), Wuhan Univ Sci & Technol, Minist Educ, Key Lab Met Equipment & Control Technol, Wuhan 430081, Peoples R China.; Zhu, P (corresponding author), Wuhan Univ Sci & Technol, Hubei Key Lab Mech Transmiss & Mfg Engn, Wuhan 430081, Peoples R China.
EM panzhuyang@tju.edu.cn
FU National Natural Science Foundation of China [61901310, E080703,
   51778509]
FX We would like to thank the editors and the reviewers for their careful
   work and invaluable suggestions for helping us to improve this paper. We
   express our sincere thanks to Yu Liu [19] for sharing MST-SR toolbox.
   This work is supported by the National Natural Science Foundation of
   China (Grant No: 61901310, E080703, 51778509).
CR Agrafioti F, 2011, 17 INT C DIG SIGN PR, P1
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aishwarya N, 2018, MULTIMED TOOLS APPL, V77, P9719, DOI 10.1007/s11042-017-5562-4
   An FP, 2019, MULTIMED TOOLS APPL, V78, P17239, DOI 10.1007/s11042-018-7097-8
   Bhuiyan SMA, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/728356
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Chen SH, 2008, PATTERN RECOGN LETT, V29, P330, DOI 10.1016/j.patrec.2007.10.013
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Engan K, 2000, SIGNAL PROCESS, V80, P2121, DOI 10.1016/S0165-1684(00)00072-4
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Huang NE, 1999, ANNU REV FLUID MECH, V31, P417, DOI 10.1146/annurev.fluid.31.1.417
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Huang Y, 2019, NEUROCOMPUTING, V349, P31, DOI 10.1016/j.neucom.2019.04.021
   Jong WD, 2000, P SOC PHOTO-OPT INS, V4038, P1
   Kong WW, 2013, OPTIK, V124, P6423, DOI 10.1016/j.ijleo.2013.05.038
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu ZD, 2015, OPT COMMUN, V335, P168, DOI 10.1016/j.optcom.2014.07.093
   Looney D, 2009, IEEE T SIGNAL PROCES, V57, P1626, DOI 10.1109/TSP.2008.2011836
   Ma CY, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02065-0
   Ma XM, 2019, MULTIMED TOOLS APPL, V78, P8889, DOI 10.1007/s11042-018-6629-6
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Rahman SMM, 2010, IET IMAGE PROCESS, V4, P374, DOI 10.1049/iet-ipr.2009.0163
   Rehman N, 2010, P ROY SOC A-MATH PHY, V466, P1291, DOI 10.1098/rspa.2009.0502
   Rilling G, 2007, IEEE SIGNAL PROC LET, V14, P936, DOI 10.1109/LSP.2007.904710
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Shi DF, 2014, OPT LETT, V39, P1231, DOI 10.1364/OL.39.001231
   Tyo JS, 2006, APPL OPTICS, V45, P5453, DOI 10.1364/AO.45.005453
   Tyo JS, 2006, APPL OPTICS, V45, P5451, DOI 10.1364/AO.45.005451
   Wang DY, 2019, MULTIMED TOOLS APPL, V78, P8927, DOI 10.1007/s11042-018-6685-y
   Wang ZB, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103823
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang FB, 2013, INFRARED PHYS TECHN, V60, P235, DOI 10.1016/j.infrared.2013.05.008
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Yue Z, 2014, PROC SPIE, V9142, DOI 10.1117/12.2054074
   Zhu P, 2016, INFRARED PHYS TECHN, V77, P82, DOI 10.1016/j.infrared.2016.05.008
NR 39
TC 5
Z9 8
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4455
EP 4471
DI 10.1007/s11042-020-09860-z
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100010
DA 2024-07-18
ER

PT J
AU Madichetty, S
   Sridevi, M
AF Madichetty, Sreenivasulu
   Sridevi, M.
TI A stacked convolutional neural network for detecting the resource tweets
   during a disaster
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAR; CNN; Disaster; Stacking
ID EVENT DETECTION; MICROBLOGS
AB Social media platform like Twitter is one of the primary sources for sharing real-time information at the time of events such as disasters, political events, etc. Detecting the resource tweets during a disaster is an essential task because tweets contain different types of information such as infrastructure damage, resources, opinions and sympathies of disaster events, etc. Tweets are posted related to Need and Availability of Resources (NAR) by humanitarian organizations and victims. Hence, reliable methodologies are required for detecting the NAR tweets during a disaster. The existing works don't focus well on NAR tweets detection and also had poor performance. Hence, this paper focus on detection of NAR tweets during a disaster. Existing works often use features and appropriate machine learning algorithms on several Natural Language Processing (NLP) tasks. Recently, there is a wide use of Convolutional Neural Networks (CNN) in text classification problems. However, it requires a large amount of manual labeled data. There is no such large labeled data is available for NAR tweets during a disaster. To overcome this problem, stacking of Convolutional Neural Networks with traditional feature based classifiers is proposed for detecting the NAR tweets. In our approach, we propose several informative features such as aid, need, food, packets, earthquake, etc. are used in the classifier and CNN. The learned features (output of CNN and classifier with informative features) are utilized in another classifier (meta-classifier) for detection of NAR tweets. The classifiers such as SVM, KNN, Decision tree, and Naive Bayes are used in the proposed model. From the experiments, we found that the usage of KNN (base classifier) and SVM (meta classifier) with the combination of CNN in the proposed model outperform the other algorithms. This paper uses 2015 and 2016 Nepal and Italy earthquake datasets for experimentation. The experimental results proved that the proposed model achieves the best accuracy compared to baseline methods.
C1 [Madichetty, Sreenivasulu; Sridevi, M.] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Madichetty, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirappalli, India.
EM sreea568@gmail.com; msridevi@nitt.edu
RI M, Sreenivasulu/AAM-6040-2021; Madichetty, sreedhar/N-9849-2017
OI Madichetty, sreedhar/0000-0002-0373-9092
CR [Anonymous], CONVOLUTIONAL NEURAL
   Basu Moumita, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P427, DOI 10.1145/3110025.3110036
   Basu M, 2015, PROG INFLAMM RES SER, P171, DOI 10.1007/978-3-319-21927-1_10
   Basu M, 2019, IEEE T COMPUT SOC SY, V6, P604, DOI 10.1109/TCSS.2019.2914179
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dutt R, 2019, INFORM PROCESS MANAG, V56, P1680, DOI 10.1016/j.ipm.2019.05.010
   Ganguly D, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P73, DOI 10.1145/3184558.3186935
   Gupta H, 2018, INT CONF COMMUN SYST, P380, DOI 10.1109/COMSNETS.2018.8328222
   Imran M, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P159, DOI 10.1145/2567948.2577034
   Imran M, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2771588
   Khosla P, 2017, ARXIV170706112
   Li LF, 2020, IEEE T COMPUT SOC SY, V7, P556, DOI 10.1109/TCSS.2020.2980007
   Madichetty S, 2019, INT CONF COMMUN SYST, P709, DOI [10.1109/COMSNETS.2019.8711095, 10.1109/comsnets.2019.8711095]
   Madisetty Sreekanth, 2017, Mining Intelligence and Knowledge Exploration. 5th International Conference, MIKE 2017. Proceedings: LNAI 10682, P359, DOI 10.1007/978-3-319-71928-3_34
   Madisetty S, 2017, EXPLOITING METAATTRI
   Madisetty S., 2017, P 8 WORKSH COMP APPR, P219
   Madisetty S, 2017, INT JOINT C KNOWL DI, P82
   Madisetty S, 2018, IEEE T COMPUT SOC SY, V5, P973, DOI 10.1109/TCSS.2018.2878852
   Martin J., 2011, P INT AAAI C WEB SOC, P5
   Moh'd Abdelwadood, 2007, Journal of Computer Sciences, V3, P430, DOI 10.3844/jcssp.2007.430.435
   Nazer TH, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1410, DOI 10.1109/ASONAM.2016.7752432
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Purohit H, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-0633-3
   Qazi Umair, 2020, SIGSPATIAL Special, V12, P6, DOI 10.1145/3404820.3404823
   Rajdev M, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 1, P17, DOI 10.1109/WI-IAT.2015.102
   Rios Anthony, 2015, ACM BCB, V2015, P258, DOI 10.1145/2808719.2808746
   Rudra K, 2018, ACM T WEB, V12, DOI 10.1145/3178541
   Rudra K, 2018, IEEE T COMPUT SOC SY, V5, P403, DOI 10.1109/TCSS.2018.2802942
   Rudra K, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P96, DOI 10.1109/ASONAM.2016.7752219
   Rudra S., 2015, P 24 ACM INT C INF K, P583, DOI DOI 10.1145/2806416.2806485
   Sakaki T, 2013, IEEE T KNOWL DATA EN, V25, P919, DOI 10.1109/TKDE.2012.29
   Sarkar A, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P338, DOI 10.1145/3297001.3297055
   Socher R., 2012, NIPS, V3, P8
   Sreenivasulu Madichetty, 2017, Mining Intelligence and Knowledge Exploration. 5th International Conference, MIKE 2017. Proceedings: LNAI 10682, P348, DOI 10.1007/978-3-319-71928-3_33
   Sreenivasulu M, 2018, ADV INTELL SYST COMP, V709, P87, DOI 10.1007/978-981-10-8633-5_9
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Torkildson MK, 2014, LECT NOTES COMPUT SC, V8683, P64, DOI 10.1007/978-3-319-10831-5_9
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Varga Istvan, 2013, P 51 ANN M ASS COMP, V1, P1619
   Wang G, 2011, EXPERT SYST APPL, V38, P223, DOI 10.1016/j.eswa.2010.06.048
   Wang S, 2016, AAAI CONF ARTIF INTE, P3052
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yan W, 2016, ASIA COMMUN PHOTON
   Yang Y., 1997, ICML, V97, P412
   Zeiler M. D., 2012, CoRR
NR 46
TC 16
Z9 16
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3927
EP 3949
DI 10.1007/s11042-020-09873-8
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572719800005
PM 32994750
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Gao, YL
   Chen, XB
   Xu, G
   Liu, W
   Dong, MX
   Liu, X
AF Gao, Yu-Long
   Chen, Xiu-Bo
   Xu, Gang
   Liu, Wen
   Dong, Mian-Xiong
   Liu, Xin
TI A new blockchain-based personal privacy protection scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Multimedia security; Information security; Privacy
   protection; Data mining
ID ACCESS-CONTROL; FRAMEWORK; INTERNET; TRANSMISSION; CLOUD; IOT
AB Nowadays, personal privacy disclosure issues become increasingly prominent in the process of data publishing. Targeting at this issue, a secure blockchain-based personal privacy protection scheme is proposed. In this paper, firstly, the information is stored in cloud service, and its hash value is used for the index, which is encrypted and stored on the blockchain. Secondly, based on the principles of cryptography and the characters of blockchain technology, we propose our scheme and use it to provide an access control mechanism for personal privacy. It can make the personal privacy protection easier and more efficient. At last, through our analysis, this scheme can sufficiently protect personal privacy in using mobile devices and provide a safe and trustworthy information acquisition method for data mining. More importantly, this proposed scheme also can provide a reliable and unique source tracing for multimedia copyright protection in terms of multimedia security.
C1 [Gao, Yu-Long; Chen, Xiu-Bo] Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
   [Xu, Gang] North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
   [Liu, Wen] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
   [Liu, Wen] Commun Univ China, Sch Comp Sci & Cybersecur, Beijing 100024, Peoples R China.
   [Dong, Mian-Xiong] Muroran Inst Technol, Informat & Elect Engn, Muroran, Hokkaido, Japan.
   [Liu, Xin] Inner Mongolia Univ Sci & Technol, Sch Informat Engn, Baotou 014010, Peoples R China.
C3 Beijing University of Posts & Telecommunications; North China University
   of Technology; Communication University of China; Communication
   University of China; Muroran Institute of Technology; Inner Mongolia
   University of Science & Technology
RP Xu, G (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
EM gangxu_bupt@163.com
RI Xu, Gang/HNI-9325-2023; Dong, Mianxiong/O-7489-2019
OI Dong, Mianxiong/0000-0002-2788-3451; Gao, Yu-Long/0000-0001-7202-5264
FU NSFC [61671087, 61962009, 61572246, 61602232]; Fundamental Research
   Funds for the Central Universities [2019XD-A02]; Open Foundation of
   Guizhou Provincial Key Laboratory of Public Big Data [2018BDKFJJ018,
   2019BDKFJJ010]; BUPT Excellent Ph.D. Students Foundation [CX2019232];
   High-quality and Cutting-edge Disciplines Construction Project for
   Universities in Beijing (Internet Information, Communication University
   of China); Open Research Project of the State Key Laboratory of Media
   Convergence and Communication (Communication University of China)
   [SKLMCC2020KF006]; Scientific Research Foundation of North China
   University of Technology; JSPS KAKENHI [JP20F20080]; Grants-in-Aid for
   Scientific Research [20F20080] Funding Source: KAKEN
FX This work is supported by the NSFC (Grant Nos. 61671087, 61962009,
   61572246, 61602232), the Fundamental Research Funds for the Central
   Universities (Grant No. 2019XD-A02), the Open Foundation of Guizhou
   Provincial Key Laboratory of Public Big Data (Grant Nos. 2018BDKFJJ018,
   2019BDKFJJ010), the BUPT Excellent Ph.D. Students Foundation (Grant No.
   CX2019232), the High-quality and Cutting-edge Disciplines Construction
   Project for Universities in Beijing (Internet Information, Communication
   University of China), the Open Research Project of the State Key
   Laboratory of Media Convergence and Communication (Communication
   University of China) (Grant No. SKLMCC2020KF006), the Scientific
   Research Foundation of North China University of Technology, the JSPS
   KAKENHI(Grant No. JP20F20080).
CR Al Omar Abdullah, 2017, Security, Privacy and Anonymity in Computation, Communication and Storage, SpaCCS 2017: International Workshops. Proceedings: LNCS 10658, P534, DOI 10.1007/978-3-319-72395-2_49
   Anjum A, 2017, IEEE CLOUD COMPUT, V4, P84, DOI 10.1109/MCC.2017.3791019
   Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8
   Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878
   Buterin V., 2014, ETHEREUM NEXT GENERA, V3, P2
   Cheng HJ, 2016, INFORM SCIENCES, V329, P461, DOI 10.1016/j.ins.2015.09.039
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Dagher GG, 2018, SUSTAIN CITIES SOC, V39, P283, DOI 10.1016/j.scs.2018.02.014
   Decker C., 2013, IEEE INT CONF PEER, P1, DOI 10.1109/P2P.2013.6688704
   Deng ZL, 2019, CMC-COMPUT MATER CON, V58, P135, DOI 10.32604/cmc.2019.02967
   Es-Samaali H., 2017, INT J COMPUTER NETWO, V5, P137
   Eyal I, 2017, COMPUTER, V50, P38, DOI 10.1109/MC.2017.3571042
   Fang WW, 2014, INFORM SCIENCES, V283, P79, DOI 10.1016/j.ins.2014.06.022
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Fayyad U, 1996, AI MAG, V17, P37
   Feng JY, 2019, IEEE VEH TECHNOL MAG, V14, P28, DOI 10.1109/MVT.2018.2879647
   Ferraiolo D. E., 1995, Proceedings. 11th Annual Computer Security Applications Conference, P241
   Gao F, 2018, IEEE NETWORK, V32, P184, DOI 10.1109/MNET.2018.1700269
   Gao YL, 2018, IEEE ACCESS, V6, P27205, DOI 10.1109/ACCESS.2018.2827203
   Giungato P, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9122214
   Gusmeroli S, 2013, MATH COMPUT MODEL, V58, P1189, DOI 10.1016/j.mcm.2013.02.006
   Jianbing Ni, 2018, IEEE Communications Surveys & Tutorials, V20, P601, DOI 10.1109/COMST.2017.2762345
   Johnson D., 2001, International Journal of Information Security, V1, P36, DOI 10.1007/s102070100002
   Li HW, 2018, IEEE T EMERG TOP COM, V6, P97, DOI 10.1109/TETC.2015.2511457
   Liu X, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3061-0
   Liu Z, 2019, MOBILE NETW APPL, V24, P991, DOI 10.1007/s11036-018-1031-1
   Long F, 2010, WIREL NETW, V16, P1657, DOI 10.1007/s11276-009-0220-z
   Mervis J, 2012, SCIENCE, V336, P22, DOI 10.1126/science.336.6077.22
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Novo O, 2018, IEEE INTERNET THINGS, V5, P1184, DOI 10.1109/JIOT.2018.2812239
   Ouaddah A, 2016, SECUR COMMUN NETW, V9, P5943, DOI 10.1002/sec.1748
   Puthal D, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2017.2776459
   Schulz P, 2017, IEEE COMMUN MAG, V55, P70, DOI 10.1109/MCOM.2017.1600435CM
   Song R, 2019, CMC-COMPUT MATER CON, V60, P973, DOI 10.32604/cmc.2019.06035
   Vishwa A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1941, DOI 10.1109/SSCI.2018.8628636
   Wan Z, 2014, MULTIMED TOOLS APPL, V72, P541, DOI 10.1007/s11042-013-1378-z
   Wang JZ, 2018, IEEE ACCESS, V6, P17545, DOI 10.1109/ACCESS.2018.2805837
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Zhang Guoping, 2011, Journal of Software, V6, P724, DOI 10.4304/jsw.6.4.724-731
   Zhu QY, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359982
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 41
TC 10
Z9 10
U1 10
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30677
EP 30690
DI 10.1007/s11042-020-09867-6
EA SEP 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000571253200006
DA 2024-07-18
ER

PT J
AU Harikrishnan, PM
   Thomas, A
   Nisha, JS
   Gopi, VP
   Palanisamy, P
AF Harikrishnan, P. M.
   Thomas, Anju
   Nisha, J. S.
   Gopi, Varun P.
   Palanisamy, P.
TI Pixel matching search algorithm for counting moving vehicle in highway
   traffic videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Approximated median filter; Integral projection; Vehicle counting;
   Vehicle detection; Intelligent transportation systems
ID MODEL
AB Traffic monitoring through video processing is one of the hot research areas in the Intelligent Transportation System (ITS). Vehicle counting systems should be simple enough to be applied in real-time circumstances. A novel and fast algorithm for vehicle counting from a traffic video sequence is proposed in this paper where the vehicle tracking step is not necessary. A reference model is only created in the video frames for a narrow area. When going through this narrow area, the moving vehicles are identified as foreground objects. Detection of moving vehicles is achieved by integrating approximated median filter based background subtraction with binary integral projection. The detected candidates are counted as a vehicle using a novel pixel matching search algorithm. The proposed algorithm does not rely on every video frame. It only requires every third frame for processing and thus increases the computation speed by three times compared to existing techniques. The proposed algorithm is tested and validated on a standard data set as well as a custom data set. Two parameters such as accuracy and processing time are used for the system evaluation where an overall accuracy of 96.84% is achieved. The processing time results show that the proposed system can perform in real-time with an average real-time processing speed of 93.92%.
C1 [Harikrishnan, P. M.; Thomas, Anju; Nisha, J. S.; Gopi, Varun P.; Palanisamy, P.] Natl Inst Technol Tiruchirapalli, Tiruchirapalli, Tamaulipas, Mexico.
RP Gopi, VP (corresponding author), Natl Inst Technol Tiruchirapalli, Tiruchirapalli, Tamaulipas, Mexico.
EM haripm033@gmail.com; anjukandathil.thomas@gmail.com;
   nishajs2007@gmail.com; varun@nitt.edu; palan@nitt.edu
RI m, h/HLX-4348-2023; H M, Prof.Omprakash/AAC-4394-2022; Thomas,
   Anju/ABF-6145-2021; M, H/IAR-0454-2023; P Gopi, Varun/S-3943-2019;
   PONNUSAMY, PALANISAMY/AAM-5285-2020; M, Harikrishnan P/AAR-3451-2021
OI Thomas, Anju/0000-0002-2178-0531; P Gopi, Varun/0000-0001-5593-3949;
   PONNUSAMY, PALANISAMY/0000-0003-3687-5944; M, Harikrishnan
   P/0000-0003-1844-9503; J S, Nisha/0000-0002-9284-6729
FU Vandi Technologies PTE LTD Singapore [VANDI/PS01/NITT1821]
FX This work was funded by Vandi Technologies PTE LTD Singapore, (Grant No.
   VANDI/PS01/NITT1821 dated 10-09-2018)
CR Abd-Elmagid MA, 2019, IEEE GLOB COMM CONF, DOI [10.1109/globecom38437.2019.9013924, 10.1109/itce.2019.8646549, 10.1109/ITCE.2019.8646549]
   Alessandretti G, 2007, IEEE T INTELL TRANSP, V8, P95, DOI 10.1109/TITS.2006.888597
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bas E, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1085
   Bouaich S, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Bouvié C, 2013, IEEE IMTC P, P812
   Chen LL, 2018, IET INTELL TRANSP SY, V12, P1406, DOI 10.1049/iet-its.2018.5005
   Dai Z, 2019, IEEE ACCESS, V7, P64460, DOI 10.1109/ACCESS.2019.2914254
   Garcia-Mateos G, 2002, FACE DETECTION USING, V2396, P644, DOI [10.1007/3-540-70659-3_67, DOI 10.1007/3-540-70659-3_67]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guerrero-Gomez-Olmedo Ricardo, 2013, Natural and Artificial Computation in Engineering and Medical Applications. 5th International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2013. Proceedings: LNCS 7931, P306, DOI 10.1007/978-3-642-38622-0_32
   Guo J, 2020, J MACH LEARN RES, V21
   Engel JI, 2017, IEEE T INTELL TRANSP, V18, P1279, DOI 10.1109/TITS.2016.2603069
   Jo Y, 2014, SENSORS-BASEL, V14, P14050, DOI 10.3390/s140814050
   Kamkar S, 2016, IET INTELL TRANSP SY, V10, P406, DOI 10.1049/iet-its.2015.0157
   LI D, 2020, INT J PROD RES 0324, DOI [DOI 10.1080/00207543.2020.1740341, DOI 10.1155/2020/761701]
   Liu FY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173287
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mimbela LEY, 2000, TECH REP
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park MW, 2017, MULTIMED TOOLS APPL, V76, P25343, DOI 10.1007/s11042-017-4521-4
   Perttunen M, 2015, PERS UBIQUIT COMPUT, V19, P709, DOI 10.1007/s00779-015-0833-4
   Quesada J, 2016, IEEE IMAGE PROC, P3822, DOI 10.1109/ICIP.2016.7533075
   Rabbouch H, 2017, NEUROCOMPUTING, V260, P157, DOI 10.1016/j.neucom.2017.04.026
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seenouvong N, 2016, INT CONF KNOWL SMART, P224, DOI 10.1109/KST.2016.7440510
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Tao HJ, 2018, MULTIMED TOOLS APPL, V77, P32153, DOI 10.1007/s11042-018-6248-2
   Tourani A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA)
   Wang GL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2961, DOI 10.1109/ICAL.2008.4636684
   WANG H, 2015, MULTIMED TOOLS APPL, DOI DOI 10.1007/S11042-015-3141-0
   Wang PM, 2020, INTERFACING BIOELECTRONICS AND BIOMEDICAL SENSING, P1, DOI 10.1007/978-3-030-34467-2_1
   Wicaksono D.W., 2017, International Journal of Computing and Applied Mathematics, V3, P21, DOI 10.12962/J24775401.V3I1.2117
   Wu CF, 2012, IEEE T SYST MAN CY C, V42, P577, DOI 10.1109/TSMCC.2011.2166067
   Xia YJ, 2016, SIGNAL PROCESS, V120, P672, DOI 10.1016/j.sigpro.2014.10.035
   Xu HX, 2017, SIGNAL IMAGE VIDEO P, V11, P905, DOI 10.1007/s11760-016-1038-7
   Yang B, 2017, IET INTELL TRANSP SY, V11, P76, DOI [10.1049/iet-its.2017.0047, 10.1049/iet-its.2016.0084]
   Zhang YS, 2017, IET INTELL TRANSP SY, V11, P61, DOI 10.1049/iet-its.2016.0162
   Zhao K, 2018, MULTIMED TOOLS APPL, V77, P30891, DOI 10.1007/s11042-018-6173-4
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 43
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3153
EP 3172
DI 10.1007/s11042-020-09666-z
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000571253200012
DA 2024-07-18
ER

PT J
AU Zhou, MQ
   Liu, D
   Zheng, YH
   Zhu, QS
   Guo, P
AF Zhou, Mingqiang
   Liu, Dan
   Zheng, Yanhui
   Zhu, Qingsheng
   Guo, Ping
TI A text sentiment classification model using double word embedding
   methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double Word Embedding; Convolutional Neural Network; Sentiment
   Classification; Natural Language Processing
AB Sentiment analysis is an important topic in natural language processing (NLP) and text classifications. The existing algorithms of lexicon-based sentiment classification can deal with small corpus datasets or simple semantic texts. With the growth of text corpus data, word embedding methods have been gaining more attention. However, the single static word vector obtained by these methods can not accurately express the semantic information of the text. To optimize the word vector, we propose a text sentiment classification model using the double word embedding methods (DWE), which combines two models, GloVe and Word2vec, to represent the text to form a combinatory input of dual channels of convolution neural network (CNN). Based on the word vector fine-tuning strategy, the initial word vector is continuously learned and adjusted to find the CNN sentiment classification model with better combination input than a single vector representation. Experiment results show that DWE can effectively improve the accuracy of sentiment classification, which reaches 94.8%.
C1 [Zhou, Mingqiang; Liu, Dan; Zheng, Yanhui; Zhu, Qingsheng; Guo, Ping] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
   [Zhou, Mingqiang; Liu, Dan; Zheng, Yanhui; Zhu, Qingsheng; Guo, Ping] Chongqing Key Lab Software Theory & Technol, Chongqing, Peoples R China.
C3 Chongqing University
RP Zhou, MQ (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.; Zhou, MQ (corresponding author), Chongqing Key Lab Software Theory & Technol, Chongqing, Peoples R China.
EM zmqmail@cqu.edu.cn
RI zhu, qingsheng/D-1173-2015
OI Zhou, MingQiang/0000-0003-3217-9503; Guo, Ping/0000-0002-5239-8896
FU National Nature Science Foundation of China [61802360, 61701051]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grant 61802360 and 61701051.
CR Alharbi ASM, 2019, COGN SYST RES, V54, P50, DOI 10.1016/j.cogsys.2018.10.001
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Barkan Oren, 2016, IEEE INT WORKSHOP MA
   Catal C, 2017, APPL SOFT COMPUT, V50, P135, DOI 10.1016/j.asoc.2016.11.022
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Hinton GE, 1986, P 8 ANN C C SCI SOC, V1, P12
   Huang SL, 2015, ELECTRON COMMER R A, V14, P582, DOI 10.1016/j.elerap.2015.08.007
   Jain VK, 2018, INT J ENTERP INF SYS, V14, P77, DOI 10.4018/IJEIS.2018040105
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Li Q, 2019, SPR SER TRANSL STROK, P27, DOI 10.1007/978-3-030-16715-8_3
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Naderalvojoud B, 2020, NEUROCOMPUTING, V405, P149, DOI 10.1016/j.neucom.2020.03.094
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Polpinij J, 2016, RECENT ADV INFORM CO, P27
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Wang X, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1343
   WANG Y, 2016, MM16 P 2016 ACM
   Xia YQ, 2015, COGN COMPUT, V7, P369, DOI 10.1007/s12559-014-9298-4
   Xiao LW, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030957
   Xiong Y, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-1045-z
   Zhang HL, 2014, 2014 11TH WEB INFORMATION SYSTEM AND APPLICATION CONFERENCE (WISA), P262, DOI 10.1109/WISA.2014.55
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
NR 27
TC 2
Z9 2
U1 3
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 18993
EP 19012
DI 10.1007/s11042-020-09846-x
EA SEP 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000571253200005
DA 2024-07-18
ER

PT J
AU Barbhuiya, AA
   Karsh, RK
   Jain, R
AF Barbhuiya, Abul Abbas
   Karsh, Ram Kumar
   Jain, Rahul
TI CNN based feature extraction and classification for sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture; CNN; American sign language (ASL); Human-computer
   interface (HCI)
ID GESTURE RECOGNITION; NETWORK
AB Hand gesture is one of the most prominent ways of communication since the beginning of the human era. Hand gesture recognition extends human-computer interaction (HCI) more convenient and flexible. Therefore, it is important to identify each character correctly for calm and error-free HCI. Literature survey reveals that most of the existing hand gesture recognition (HGR) systems have considered only a few simple discriminating gestures for recognition performance. This paper applies deep learning-based convolutional neural networks (CNNs) for robust modeling of static signs in the context of sign language recognition. In this work, CNN is employed for HGR where both alphabets and numerals of ASL are considered simultaneously. The pros and cons of CNNs used for HGR are also highlighted. The CNN architecture is based on modified AlexNet and modified VGG16 models for classification. Modified pre-trained AlexNet and modified pre-trained VGG16 based architectures are used for feature extraction followed by a multiclass support vector machine (SVM) classifier. The results are evaluated based on different layer features for best recognition performance. To examine the accuracy of the HGR schemes, both the leave-one-subject-out and a random 70-30 form of cross-validation approach were adopted. This work also highlights the recognition accuracy of each character, and their similarities with identical gestures. The experiments are performed in a simple CPU system instead of high-end GPU systems to demonstrate the cost-effectiveness of this work. The proposed system has achieved a recognition accuracy of 99.82%, which is better than some of the state-of-art methods.
C1 [Barbhuiya, Abul Abbas; Karsh, Ram Kumar; Jain, Rahul] Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Barbhuiya, AA (corresponding author), Natl Inst Technol, Elect & Commun Engn Dept, Speech & Image Proc Grp, Silchar 788010, Assam, India.
EM abulabbasnet@gmail.com
OI Karsh, Ram/0000-0002-2341-341X; Jain, Rahul/0000-0003-4894-3721
FU people of Speech and Image Processing Laboratory, National Institute of
   Technology, Silchar, India
FX The authors would like to acknowledge people of Speech and Image
   Processing Laboratory, National Institute of Technology, Silchar, India,
   for providing support and necessary facilities for carrying out this
   work. The authors are thankful to Dr. Amarjit Roy, School of
   Electronics, VIT-AP University, for the constructive criticism and
   suggestions.
CR [Anonymous], 2011, Res Lett Inf Math Sci
   Badi H, 2016, INT J DATA SCI ANAL, V1, P77, DOI DOI 10.1007/S41060-016-0008-Z
   Bheda V, 2018, ARXIV171006836
   Chevtchenko SF, 2018, APPL SOFT COMPUT, V73, P748, DOI 10.1016/j.asoc.2018.09.010
   Czuszynski K, 2018, IEEE SENS J, V18, P5429, DOI 10.1109/JSEN.2018.2834968
   Dadashzadeh A, 2019, IET COMPUT VIS, V13, P700, DOI 10.1049/iet-cvi.2018.5796
   Dehankar AV, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P404, DOI 10.1109/ICECA.2017.8203715
   Fang LP, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115729
   Fang YF, 2015, INT J HUM ROBOT, V12, DOI 10.1142/S0219843615500115
   Gupta P, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P19, DOI 10.1109/ICCSP.2016.7754217
   Hasan H, 2012, INT CONF ADV COMPUT, P55, DOI 10.1109/ACSAT.2012.37
   Hassene BA, 2019, THESIS
   Hsien-I Lin, 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P1038, DOI 10.1109/CoASE.2014.6899454
   Jadooki S, 2017, NEURAL COMPUT APPL, V28, P3285, DOI 10.1007/s00521-016-2244-5
   Jiang D, 2019, CLUSTER COMPUT, V22, P13261, DOI 10.1007/s10586-018-1844-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lamar MV, 2001, THESIS
   Li GF, 2019, MULTIMED TOOLS APPL, V78, P29765, DOI 10.1007/s11042-018-6293-x
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Li Y, 2018, INFORM SCIENCES, V441, P66, DOI 10.1016/j.ins.2018.02.024
   Liu PD, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3258018
   Nagarajan S., 2013, Int. J. Comput. Appl, V82, DOI [10.5120/14106-2145, DOI 10.5120/14106-2145]
   Neethu PS, 2020, SOFT COMPUT, V24, P15239, DOI 10.1007/s00500-020-04860-5
   Oyedotun OK, 2017, NEURAL COMPUT APPL, V28, P3941, DOI 10.1007/s00521-016-2294-8
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Ranga V, 2018, J ENG SCI TECHNOL, V13, P2655
   Rathi P, 2019, 5 INT C NEXT GEN COM
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2018, MOBILE NETW APPL, V23, P797, DOI 10.1007/s11036-018-1008-0
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   [王成山 Wang Chengshan], 2014, [电工技术学报, Transactions of China Electrotechnical Society], V29, P1
   Wu CM, 2019, 3D RES, V10, DOI 10.1007/s13319-018-0210-y
   Zhong Xi, 2018, Journal of Computer Aided Design & Computer Graphics, V30, P173, DOI 10.3724/SP.J.1089.2018.16176
NR 38
TC 59
Z9 59
U1 3
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 3051
EP 3069
DI 10.1007/s11042-020-09829-y
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570841100004
DA 2024-07-18
ER

PT J
AU Maurya, SK
   Singh, RK
AF Maurya, Sanjay Kumar
   Singh, Ravindra Kumar
TI Image super-resolution by prediction of dual tree-CWT coefficient at a
   finer scale
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution; Dual-tree complex wavelet transform (DT-CWT);
   Interpolation; Phase estimation; Wavelet coefficients
ID RESOLUTION ENHANCEMENT; INTERPOLATION
AB This paper presents an image of Super-Resolution (SR) technique by the construction of DT-CWT coefficients for a larger scale from the information at a smaller scale for all the subbands. The DT-CWT coefficients prediction for each subband of an image at a finer level is based on phase prediction and estimation of the magnitude separately, followed by combining the magnitude and phase. Inverse DT-CWT is taken with the coefficients at a finer level of each subband along with a Low-Resolution (LR) image in place of a low subband to reconstruct a high-resolution image. The proposed technique is applied to various images, including satellite and standard images. The quantitative and visual results have established the superiority of the proposed scheme over conventional and various state-of-the-art techniques.
C1 [Maurya, Sanjay Kumar] GLA Univ, Dept Elect Engn, Mathura 281406, UP, India.
   [Singh, Ravindra Kumar] MNNIT, Dept Elect Engn, Prayagraj 211004, UP, India.
C3 GLA University; National Institute of Technology (NIT System); Motilal
   Nehru National Institute of Technology
RP Maurya, SK (corresponding author), GLA Univ, Dept Elect Engn, Mathura 281406, UP, India.
EM sanjay.maurya@gla.ac.in; rksingh@mnnit.ac.in
RI Maurya, Sanjay Kumar/AAV-6988-2020
OI Maurya, Sanjay Kumar/0000-0002-7436-3870
CR Al-Shabili A, 2015, 2015 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY RESEARCH (ICTRC), P48, DOI 10.1109/ICTRC.2015.7156418
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P554, DOI 10.1109/LGRS.2010.2041324
   Chang SG, 2006, IEEE T IMAGE PROCESS, V15, P1471, DOI 10.1109/TIP.2006.871162
   Dan Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2307, DOI 10.1109/CISP.2010.5647786
   De Rivaz P, 2000, THESIS
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Demirel H, 2011, IEEE T GEOSCI REMOTE, V49, P1997, DOI 10.1109/TGRS.2010.2100401
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gajjar PP, 2010, IEEE T IMAGE PROCESS, V19, P1201, DOI 10.1109/TIP.2010.2041408
   Gonzalez R.C., 2018, IEEE COMMUN MAG, V19, DOI [10.1109/MCOM.1981.1090535, DOI 10.1109/MCOM.1981.1090535]
   Hong SH, 2018, IEEE IMAGE PROC, P1468, DOI 10.1109/ICIP.2018.8451362
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Kingsbury, 1998, P 8 IEEE DSP WORKSH, V86, P120
   Kumar CNR, 2010, INT J IMAGE PROCESS, V4, P401
   Kumar Maurya S, 2012, IEEE INT C ADV ENG S
   LAM EP, 2006, IEEE NUCL SCI CONF R, V2006, P2042, DOI DOI 10.1109/NSSMIC.2006.354315
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lu XQ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P97
   Maurya SK, 2012, ICPCES 2012 2012 2 I
   Reeves TH, 2000, INT CONF ACOUST SPEE, P508, DOI 10.1109/ICASSP.2000.862029
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Temizel A, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2061247
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2004, ADV NEURAL INFORM PR
   Xie C, 2019, SIGNAL IMAGE VIDEO P, V13, P557, DOI 10.1007/s11760-018-1382-x
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhao F, 2019, MULTIMED TOOLS APPL, V78, P28453, DOI 10.1007/s11042-017-5493-0
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
NR 30
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2875
EP 2886
DI 10.1007/s11042-020-09843-0
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000570470300006
DA 2024-07-18
ER

PT J
AU Hemdan, EE
AF Hemdan, Ezz El-Din
TI An efficient and robust watermarking approach based on single value
   decompression, multi-level DWT, and wavelet fusion with scrambled
   medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Wavelet fusion; SVD; Multi-level DWT; Chaotic baker
   map; And Arnold transform
ID DIGITAL IMAGE; SCHEME; SVD; TRANSFORM; SECURE
AB This paper offers a medical image watermarking approach based on Wavelet Fusion (WF), Singular Value Decomposition (SVD), and Multi-Level Discrete Wavelet Transform (M-DWT) with scrambling techniques for securing the watermarks images. The proposed approach can be used for providing multi-level security in various applications such as military, copyright protection, and telemedicine systems. The key idea of the projected approach is to first combine two digital watermark images into a single fused watermark to increase the embedded information payload. Then, the fused watermark is scrambled using Arnold and Chaotic algorithms. Finally, the scrambled fused watermark is embedded in the cover image using the SVD and three-level DWT algorithms. The selection of the Arnold and chaotic for watermark encryption is attributed to confirm robustness which resists several types of multimedia attacks and upturn the security level. This paper also presents a comparative study of the proposed approach for different digital images to determine its robustness and stability. Several simulation results reveal that the proposed system improves the capacity and security of embedded medical watermarks without affecting the cover image quality. In conclusion, the proposed approach achieved not only precise acceptable perceptual quality with admired Peak Signal-to-Noise Ratio (PSNR) values but similarly high Correlation Coefficient (Cr) and SSIM values in the existence of severe attacks.
C1 [Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Hemdan, EE (corresponding author), Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia, Egypt.
EM ezzvip@yahoo.com
CR Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   [Anonymous], 2013, IOSR J COMPUTER ENG
   Atlam Hany F, 2020, INTERNET OF THINGS
   Chakraborty S, 2013, BLOOD CANCER J, V3, DOI 10.1038/bcj.2013.41
   Dhanalakshmi R, 2010, ARXIV10022414
   Dhar P.K., 2018, Digital Image and Video Watermarking and Steganography
   El-Din E., 2019, MENOUFIA J ELECT ENG, V28, P337
   El-Din HE, 2017, STUD BIG DATA, V25, P109, DOI 10.1007/978-3-319-53472-5_5
   El-Din HE, 2017, STUD BIG DATA, V25, P299, DOI 10.1007/978-3-319-53472-5_15
   El-Naby A., 2019, MENOUFIA J ELECT ENG, V28, P332
   El-Refaey Amir E, 2019, MENOUFIA J ELECT ENG, V28, P43
   Elashry IF, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3167847
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Hemdan EE-D., 2017, INTERNET THINGS IOT, P143
   Hemdan EED., P 3 INT C ADV CONTR
   Hemdan EE, 2018, LECT NOTE DATA ENG, V14, P39, DOI 10.1007/978-3-319-70688-7_2
   Hemdan Ezz El-Din, 2013, 2013 30 NAT RAD SCI
   Hemdan Ezz El-Din, 2020, DEEP LEARNING NEURAL, P615
   I Selim Gamal Eldin, 2019, MENOUFIA J ELECT ENG, V28, P343
   Jindal Himanshu, 2016, P INT C REC COGN WIR
   Kannammal A., 2012, EUR J SCI RES, V70, P46
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Lagzian Samira, 2011, 2011 INT S ART INT S
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Leng L, 2010, 2010 INT C INF COMM
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Mahajan LH, 2013, INT J ADV RES SCI EN, V2, P69
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Potdar Vidyasagar M., 2005, INDIN 05 2005 3 IEEE
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh Vipula, 2011, CYBER J MULTIDISCIPL
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Wang Qiang, 2008, 2008 4 INT C NAT COM, V5
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 51
TC 34
Z9 34
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1749
EP 1777
DI 10.1007/s11042-020-09769-7
EA SEP 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100003
DA 2024-07-18
ER

PT J
AU Pereira, DMG
   Silva, FJDE
   Neto, CDS
   dos Santos, DV
   Coutinho, LR
   Guedes, ALV
AF Pereira, Danne Makleyston G.
   da S e Silva, Francisco Jose
   de Salles S. Neto, Carlos
   dos Santos, Davi Viana
   Coutinho, Luciano Reis
   Guedes, Alan L. V.
TI An ontology-based approach to integrate TV and IoT middlewares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Digital TV; Mulsemedia; Multimedia immersion;
   Multimodal interaction
ID INTERNET; THINGS
AB Internet of Things (IoT) is the interconnection of physical devices, known of smart objects, that share data and collaborate among them to support users. There are IoT usage scenarios in several domains. In-home domain, the use of smart objects may support monitoring and automation of the environment. In a home, the TV is one of the most used devices. It may also collaborate with the smart objects to enhance the interactive experience of viewers on watching. To support such a meeting, we propose an (i) conceptual model, IoTTV-Ont, that allows modeling entire homes, with smart objects, people' profile, and viewers' interaction events with TV applications; (ii) a software architecture that integrates and interoperates digital TV and IoT middleware. This architecture allows the TV applications: to be aware of the physical environment context, to change aspects of the physical environment, to identify the viewers, and to receive multimodal interactions performed by viewers. We demonstrate our work through use cases. For this, we implement a prototype of our software architecture and modeled home using IoTTV-Ont. Then we developed usage scenarios that enhance TV viewers' experience by supporting features such as content adaptation, multi-sensorial immersive experience, and multimodal user interaction.
C1 [Pereira, Danne Makleyston G.] Fed Inst Tocantins, Colinas Of Tocantins, TO, Brazil.
   [da S e Silva, Francisco Jose; de Salles S. Neto, Carlos; dos Santos, Davi Viana; Coutinho, Luciano Reis] Univ Fed Maranhao, Sao Luis, Maranhao, Brazil.
   [Guedes, Alan L. V.] Pontifical Catholic Univ Rio de Janeiro, Rio De Janeiro, RJ, Brazil.
C3 Instituto Federal do Tocantins (IFTO); Universidade Federal do Maranhao;
   Pontificia Universidade Catolica do Rio de Janeiro
RP Pereira, DMG (corresponding author), Fed Inst Tocantins, Colinas Of Tocantins, TO, Brazil.
EM danne.pereira@lsdi.ufma.br; fssilva@lsdi.ufma.br; csallesneto@gmail.com;
   davi.viana@lsdi.ufma.br; luciano.rc@lsdi.ufma.br;
   alan@telemidia.puc-rio.br
RI Viana, Davi/ISA-6998-2023; Coutinho, Luciano Reis/D-9056-2019; Guedes,
   Alan L. V./ABS-3947-2022; Da+Silva+E+Silva, Francisco/AGM-5640-2022;
   Viana, Davi/AAV-2674-2021
OI Viana, Davi/0000-0003-0470-549X; Coutinho, Luciano
   Reis/0000-0001-7996-7334; Guedes, Alan L. V./0000-0003-0110-9975;
   Da+Silva+E+Silva, Francisco/0000-0001-8339-3679; Viana,
   Davi/0000-0003-0470-549X; Pereira, Danne/0000-0002-8260-5382
CR Abreu R, 2019, WEBMEDIA 2019: PROCEEDINGS OF THE 25TH BRAZILLIAN SYMPOSIUM ON MULTIMEDIA AND THE WEB, P201, DOI 10.1145/3323503.3360302
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   [Anonymous], 2011, EVENT PROCESSING ACT
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bonino D, 2008, LECT NOTES COMPUT SC, V5318, P790, DOI 10.1007/978-3-540-88564-1_51
   Brickley D, 2007, TECH REP
   Cesar Pablo, 2008, Foundations and Trends in Human-Computer Interaction, V2, P279, DOI 10.1561/1100000008
   Chen H, 2005, WHITESTEIN SER SOFTW, P233, DOI 10.1007/3-7643-7361-X_10
   Christophe J, 2013, AN AMBIENT ASSISTED, V5
   Da Silva VJ, 2016, IEEE ICCE, DOI 10.1109/ICCE.2016.7430622
   Eugster PT, 2003, ACM COMPUT SURV, V35, P114, DOI 10.1145/857076.857078
   Gorgu L, 2013, ENABLING A MOBILE DY, P287
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Guarino N, 1998, FR ART INT, V46, P3
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guedes A lan L. V., 2016, ANAIS ESTENDIDOS 22, P184
   Hunkeler U, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P791, DOI 10.1109/COMSWA.2008.4554519
   ISO, 2016, 2300532016 ISOIEC
   ITU-T, 2014, NEST CONT LANG NCL G
   Kapri A, 2017, US Patent App., Patent No. [15/087,813, 15087813]
   Lima EG, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1102, DOI 10.1109/ICCNC.2015.7069503
   Lojka M, 2016, MULTIMED TOOLS APPL, V75, P10441, DOI 10.1007/s11042-015-2903-z
   Luckham D, 2008, LECT NOTES COMPUT SC, V5321, P3, DOI 10.1007/978-3-540-88808-6_2
   Miorandi D, 2012, AD HOC NETW, V10, P1497, DOI 10.1016/j.adhoc.2012.02.016
   Noy N. F., 2001, TECH REP
   Gomes BDP, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4043
   Perera C, 2014, P ANN HICSS, P1053, DOI 10.1109/HICSS.2014.137
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Punt M, 2015, MULTIMED TOOLS APPL, V74, P8137, DOI 10.1007/s11042-014-2045-8
   Qian Zhu, 2010, Proceedings 2010 IEEE/IFIP 8th International Conference on Embedded and Ubiquitous Computing (EUC 2010), P347, DOI 10.1109/EUC.2010.58
   Rosa REVD, 2017, MULTIMED TOOLS APPL, V76, P8573, DOI 10.1007/s11042-016-3489-9
   Saleme E. B., 2015, P 21 BRAZ S 15 MULT, P145
   Sommaruga L., 2011, Proceedings of the 6th International Workshop on Enhanced Web Service Technologies, P9, DOI DOI 10.1145/2031325.2031327
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Sulema Y, 2016, INT CONF SYST SIGNAL, P19
   Talavera LE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P123, DOI 10.1109/PERCOMW.2015.7134005
   Wehbi A, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P842
NR 37
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1813
EP 1837
DI 10.1007/s11042-020-09645-4
EA SEP 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100001
DA 2024-07-18
ER

PT J
AU Avola, D
   Bernardi, M
   Cinque, L
   Foresti, GL
   Pannone, D
   Petrioli, C
AF Avola, Danilo
   Bernardi, Marco
   Cinque, Luigi
   Foresti, Gian Luca
   Pannone, Daniele
   Petrioli, Chiara
TI Forward-looking sonar image compression by integrating keypoint
   clustering and morphological skeleton
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forward-Looking sonar; Image compression; Keypoint clustering;
   Morphological skeleton; Color indexing
AB Forward-Looking Sonar (FLS) is one of the most effective devices for underwater exploration which provides high-resolution images that can be used for several tasks in marine research, oceanographic, and deep-sea exploration. The limitation of current underwater acoustic channels does not allow transmitting these images in real-time, therefore image compression is required. Since acoustic images are characterized by speckle noise, an important challenge, in this area, is how to perform the compression while preserving relevant information. In this paper, a novel lossy forward-looking acoustic image compression method based on the combination between keypoint clustering and Morphological Skeleton (MS) is proposed. Keypoints are extracted by using A-KAZE feature extractor, while Density-Based Spatial Clustering of Application with Noise (DBSCAN) is used to find keypoint clusters representing a region-of-interest (ROI). Then, MS is executed to compact the ROI. The rest of the image is down-sampled and quantized through K-Means Clustering and represented via colour indexing. Finally, the information is compressed by using Brotli data compression. The experimental results on real FLS images demonstrate that our method achieves good outcomes in terms of quality metrics and compression ratio.
C1 [Avola, Danilo; Bernardi, Marco; Cinque, Luigi; Pannone, Daniele; Petrioli, Chiara] Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.
   [Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Via Sci 206, I-33100 Udine, Italy.
   [Avola, Danilo] Sapienza Univ, Dept Commun & Social Res, Via Salaria 113, I-00198 Rome, Italy.
   [Avola, Danilo; Bernardi, Marco; Pannone, Daniele; Petrioli, Chiara] WSENSE Srl, Via Gaetano Donizetti 4, I-00198 Rome, Italy.
C3 Sapienza University Rome; University of Udine; Sapienza University Rome
RP Avola, D (corresponding author), Sapienza Univ, Dept Comp Sci, Via Salaria 113, I-00198 Rome, Italy.; Avola, D (corresponding author), Sapienza Univ, Dept Commun & Social Res, Via Salaria 113, I-00198 Rome, Italy.; Avola, D (corresponding author), WSENSE Srl, Via Gaetano Donizetti 4, I-00198 Rome, Italy.
EM avola@di.uniroma1.it; bernardi@di.uniroma1.it; cinque@di.uniroma1.it;
   gianluca.foresti@uniud.it; pannone@di.uniroma1.it;
   petrioli@di.uniroma1.it
RI Pannone, Daniele/ABD-2058-2021; Petrioli, Chiara/F-6297-2012
OI PANNONE, DANIELE/0000-0001-6446-6473
FU MIUR under grant "Departments of Excellence 2018-2022" of the Department
   of Computer Science of Sapienza University; European Union within the
   Project ARCHEOSUb "Autonomous underwater Robotic and sensing systems for
   Cultural Heritage discovery Conservation and in situ valorization"
FX This work was supported in part by the MIUR under grant "Departments of
   Excellence 2018-2022" of the Department of Computer Science of Sapienza
   University and by the European Union within the Project ARCHEOSUb
   "Autonomous underwater Robotic and sensing systems for Cultural Heritage
   discovery Conservation and in situ valorization". The authors wish to
   thank the Teledyne Marine group (part of the Teledyne Technologies
   Incorporated) to have provided us with sample data for experimental
   purposes.
CR Ahn JM, 2019, IMMUNOL INVEST, V48, P242, DOI 10.1080/08820139.2018.1506476
   Alakuijala J, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3231935
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Amiri SA, 2018, MULTIMED TOOLS APPL, V77, P8677, DOI 10.1007/s11042-017-4763-1
   [Anonymous], 2015, OCEANS 2015 GENOVA
   Avola D, 2018, INTEL SYST REF LIBR, V145, P7, DOI 10.1007/978-3-319-73891-8_2
   Avola D, 2019, LECT NOTES COMPUT SC, V11751, P15, DOI 10.1007/978-3-030-30642-7_2
   Avola D, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500161
   Avola D, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P638, DOI 10.5220/0006722506380645
   Avola D, 2017, PATTERN RECOGN LETT, V100, P110, DOI 10.1016/j.patrec.2017.10.029
   Avola D, 2017, PATTERN RECOGN LETT, V96, P96, DOI 10.1016/j.patrec.2016.10.015
   Bernardi M. L., 2019, 2019 INT JOINT C NEU, P1
   Binnerts B., 2018, P 2018 OCEANS MTSIEE, P1, DOI [10.1109/OCEANSKOBE.2018.8559159, DOI 10.1109/OCEANSKOBE.2018.8559159]
   Celebi ME, 2011, IMAGE VISION COMPUT, V29, P260, DOI 10.1016/j.imavis.2010.10.002
   Chen TS, 2002, LECT NOTES COMPUT SC, V2532, P720
   Cheng WC, 2017, INT J GEOMECH, V17, DOI 10.1061/(ASCE)GM.1943-5622.0000810
   Cho H, 2015, IEEE MTTS INT MICROW, P14
   Chuang JC, 2019, MULTIMED TOOLS APPL, V78, P35537, DOI 10.1007/s11042-019-08193-w
   Danckaers A, 2019, TRANSMISSION IMAGES, P1
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Grewenig S, 2010, LECT NOTES COMPUT SC, V6376, P533
   Grosse HJ, 2000, PATTERN RECOGN LETT, V21, P1061, DOI 10.1016/S0167-8655(00)00065-9
   Haghshenas M, 2016, OCEANS 2016 MTS IEEE, P1
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Karoui I, 2015, IEEE T GEOSCI REMOTE, V53, P4661, DOI 10.1109/TGRS.2015.2405672
   Kwan C, 2019, COMPUTERS, V8, DOI 10.3390/computers8020032
   Li B, 2013, INT CONF MEASURE, P1315, DOI 10.1109/MIC.2013.6758201
   Truong MTN, 2018, SOFT COMPUT, V22, P4197, DOI 10.1007/s00500-017-2709-1
   Mirizzi N, 2018, OCEANS 2018 MTS IEEE, P1
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ravisankar P, 2018, MULTIMED TOOLS APPL, V77, P5547, DOI 10.1007/s11042-017-4466-7
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Stankovi I., 2018, P OCEANS 2018 MTS IE, P1, DOI [10.1109/OCEANS.2018.8604657, DOI 10.1109/OCEANS.2018.8604657]
   Tareen S.A.K., 2018, 2018 INT C COMPUTING, P1, DOI DOI 10.1109/ICOMET.2018.8346440
   Ya-Qiong C., 2016, OCEANS 2016 SHANGHAI, P1
   Zhang J, 2018, EVID-BASED COMPL ALT, V2018, P1
   Zhang JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI 10.1007/s11042-016-3496-x
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 39
TC 4
Z9 4
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1625
EP 1639
DI 10.1007/s11042-020-09670-3
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765600005
DA 2024-07-18
ER

PT J
AU Sawant, S
   Manoharan, P
AF Sawant, Shrutika
   Manoharan, Prabukumar
TI A hybrid optimization approach for hyperspectral band selection based on
   wind driven optimization and modified cuckoo search optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Band selection; Wind driven optimization; Cuckoo
   search algorithm; Chebyshev chaotic map
ID PARTICLE SWARM OPTIMIZATION; CHAOS OPTIMIZATION; INFORMATION; ALGORITHM;
   IMAGES
AB Selection of useful bands plays a very important role in hyperspectral image classification. In the past decade, metaheuristic algorithms have been used as promising methods for solving this problem. However, many metaheuristic algorithms may provide unsatisfactory performance due to their slow or premature convergence. Therefore, how to develop algorithms well balancing the exploration and exploitation, and find the suitable bands precisely is still a challenge. In this paper, a new hybrid global optimization algorithm, which is based on the Wind Driven Optimization (WDO) and Cuckoo Search (CS) is proposed to solve hyperspectral band selection problems. Both WDO and CS have strong searching ability and require less control parameters, but easily suffer from premature convergence due to loss of diversity of population. The proposed approach uses the Chebyshev chaotic map to initialize the population at initial step. The population is divided into two subgroups and WDO and CS are adopted for these two subgroups independently. By division, these two subgroups can share suitable information and utilize each other's pros, thus avoid premature convergence, and obtain best optimal solution. Furthermore, the Levy flight step size in CS algorithm is adaptively adjusted based on fitness value and current iteration number, which helps in boosting the convergence speed of algorithm. The experimental results on three standard benchmark datasets namely, Pavia University, Botswana and Indian Pines, prove the superiority of the proposed approach over standard WDO and CS approaches as well as the other traditional approaches in terms of classification accuracy with fewer bands.
C1 [Sawant, Shrutika; Manoharan, Prabukumar] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Manoharan, P (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM shrutika.sawant1@gmail.com; mprabukumar@vit.ac.in
RI M, Prabukumar/P-9012-2016
OI M, Prabukumar/0000-0002-8127-653X
FU Council of Scientific AMP; Industrial Research (CSIR), New Delhi, India;
   VIT seed grant
FX The authors thank the Council of Scientific & Industrial Research
   (CSIR), New Delhi, India for the award of CSIR-SRF and VIT for providing
   a VIT seed grant for carrying out this research work.
CR Abed-alguni BH, 2020, J KING SAUD UNIV-COM, V32, P159, DOI 10.1016/j.jksuci.2018.05.003
   Bayraktar Z, 2010, 2010 IEEE INT S ANTE
   Bayraktar Z, 2013, IEEE T ANTENN PROPAG, V61, P2745, DOI 10.1109/TAP.2013.2238654
   Boggavarapu LNP, 2020, CLASSIFICATION HYPER
   Bouyer A, 2018, APPL SOFT COMPUT, V67, P172, DOI 10.1016/j.asoc.2018.03.011
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389
   Feng J, 2014, IEEE T GEOSCI REMOTE, V52, P4092, DOI 10.1109/TGRS.2013.2279591
   Feng SW, 2017, IEEE T GEOSCI REMOTE, V55, P2111, DOI 10.1109/TGRS.2016.2636850
   Garg H, 2019, INFORM SCIENCES, V478, P499, DOI 10.1016/j.ins.2018.11.041
   Ghamisi P, 2015, IEEE GEOSCI REMOTE S, V12, P309, DOI 10.1109/LGRS.2014.2337320
   Jia JH, 2013, MATH COMPUT MODEL, V58, P619, DOI 10.1016/j.mcm.2011.10.045
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kumar GVS, 2017, MULTIMED TOOLS APPL, V76, P8355, DOI 10.1007/s11042-016-3420-4
   Li SJ, 2011, KNOWL-BASED SYST, V24, P40, DOI 10.1016/j.knosys.2010.07.003
   Liu YN, 2011, J BIONIC ENG, V8, P191, DOI 10.1016/S1672-6529(11)60020-6
   Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951
   Max-dependency C, 2005, FEAT SELECT BASED MU, V27, P1226
   Medjahed Seyyid Ahmed, 2015, IAENG International Journal of Computer Science, V42, P183
   Medjahed SA, 2016, APPL SOFT COMPUT, V40, P178, DOI 10.1016/j.asoc.2015.09.045
   Medjahed S.A., 2018, Egypt. J. Remote Sens. Space Sci., V21, P413, DOI DOI 10.1016/J.EJRS.2018.01.003
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Phaneendra Kumar BLN, 2020, INFRARED PHYS TECHN, V110, DOI 10.1016/j.infrared.2020.103455
   Phaneendra Kumar BLN, 2020, J APPL REMOTE SENS, V14, DOI [10.1117/JRS.14.024501, 10.1117/1.JRS.14.024501]
   Prabukumar M, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.046015
   Prabukumar M, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.046010
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Sawant S, 2018, P AS C REM SENS, P2305
   Sawant S, 2020, J SPECTR IMAGING, V1, P1, DOI [10.1255/jsi.2020.a6, DOI 10.1255/JSI.2020.A6]
   Sawant S, 2020, J SPECTR IMAGING, V1, P1, DOI DOI 10.1255/JSI.2020.A5
   Sawant SS, 2019, WORK HYPERSP IMAG, DOI 10.1109/whispers.2019.8920950
   Sawant SS, 2020, INT J REMOTE SENS, V41, P3948, DOI 10.1080/01431161.2019.1711242
   Sawant SS, 2020, EGYPT J REMOTE SENS, V23, P243, DOI 10.1016/j.ejrs.2018.11.001
   Sawant SS, 2019, INT J REMOTE SENS, V40, P7852, DOI 10.1080/01431161.2019.1607609
   Sawant U, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P1, DOI 10.1109/UEMCON.2017.8248968
   Science N., 2011, J NONLINEAR SCI NONE, V44, P710, DOI [10.1016/j.chaos.2011.06.004, DOI 10.1016/J.CHAOS.2011.06.004]
   Senthil V, 2018, MAXIMIN DISTANCE BAS, P7221, DOI [10.1007/s11042-017-4630-0, DOI 10.1007/S11042-017-4630-0]
   Su HJ, 2017, IEEE J-STARS, V10, P309, DOI 10.1109/JSTARS.2016.2591004
   Su HJ, 2014, IEEE J-STARS, V7, P2659, DOI 10.1109/JSTARS.2014.2312539
   Sui CH, 2015, IEEE GEOSCI REMOTE S, V12, P185, DOI 10.1109/LGRS.2014.2331674
   Tavazoei MS, 2007, APPL MATH COMPUT, V187, P1076, DOI 10.1016/j.amc.2006.09.087
   Taylor P., 2013, Hum Vaccines Immunother, P37, DOI [DOI 10.1080/2150704X.2013.777485, 10.4161/hv.23412, DOI 10.4161/HV.23412]
   Tschannerl J, 2019, INFORM FUSION, V51, P189, DOI 10.1016/j.inffus.2019.02.005
   Vaddi R, 2020, PROBABILISTIC PCA BA, DOI [10.1007/978-3-030-16660-1, DOI 10.1007/978-3-030-16660-1]
   Vaddi R, 2020, INFRARED PHYS TECHN, V110, DOI 10.1016/j.infrared.2020.103457
   Vaddi R, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103296
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Xie FD, 2019, APPL SOFT COMPUT, V75, P428, DOI 10.1016/j.asoc.2018.11.014
   Xu MX, 2016, J COMPUT METHODS SCI, V16, P629, DOI 10.3233/JCM-160645
   Yang DX, 2007, CHAOS SOLITON FRACT, V34, P1366, DOI 10.1016/j.chaos.2006.04.057
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang WQ, 2018, IEEE GEOSCI REMOTE S, V15, P1750, DOI 10.1109/LGRS.2018.2853805
NR 53
TC 20
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1725
EP 1748
DI 10.1007/s11042-020-09705-9
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568765600002
DA 2024-07-18
ER

PT J
AU Kamarujjaman
   Maitra, M
   Chakraborty, S
AF Kamarujjaman
   Maitra, Mausumi
   Chakraborty, Susanta
TI A novel decision-based adaptive feedback median filter for high density
   impulse noise suppression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decision based median filter; Image denoising; Impulse noise; Peak
   signal-to-noise ratio; Salt and pepper
ID WEIGHTED MEAN FILTER; PEPPER NOISE; FUZZY FILTER; REMOVAL; SALT;
   RESTORATION; IMAGES
AB The qualitative performances of the digital image processing methods are degraded due to the presence of impulse noise. The conventional median filter and its advanced versions somehow manage to remove the noise from image but cannot preserve the image details. In this paper, a novel decision based adaptive feedback median filter is proposed to suppress the high density noise and preserve the details of the image. The proposed method detects the corrupted or noisy pixels by analyzing the neighbours in a decisive manner, which is a challenging task for the different types of images and noise. It predicts a local threshold by analyzing the neighbours to decide the adaptive nature of the feedback median filter. The feedback mechanism is adapted to enhance the qualitative results. Various types of images and noise densities have been used to evaluate the performance of the proposed method. The qualitative and quantitative performances have been measured in terms of Peak Signal-to-Noise Ratio, Image Enhancement Factor and Structural Similarity Index. The experimental results show that the qualitative and quantitative performances are superior over existing methods and the computational time is comparable as well.
C1 [Kamarujjaman; Maitra, Mausumi] Govt Coll Engn & Ceram Technol, Dept Informat Technol, 73 AC Banerjee Lane, Kolkata, India.
   [Chakraborty, Susanta] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Sibpur, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Maitra, M (corresponding author), Govt Coll Engn & Ceram Technol, Dept Informat Technol, 73 AC Banerjee Lane, Kolkata, India.
EM skmasum000@gmail.com; mou1232005@yahoo.com; susanta.chak@gmail.com
OI , Dr. Kamarujjaman/0000-0003-1403-241X
FU University Grants Commission (UGC), Govt. of India through the Maulana
   Azad National Fellowship for PhD [MANF-2014-15-MUS-WES-40715]
FX We acknowledge the University Grants Commission (UGC), Govt. of India,
   for providing necessary fund through the Maulana Azad National
   Fellowship for PhD (MANF-2014-15-MUS-WES-40715). We would also like to
   thank the editor and reviewers for their valuable suggestions toward the
   improvement in this paper.
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   Balandin S, 2009, AUGMENT ALTERN COMM, V25, P1, DOI 10.1080/07434610902813549
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2011, COMMUN ACM, V54, P109, DOI 10.1145/1941487.1941513
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov K, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI [10.1109/TIP.2012.2210725, DOI 10.1109/TIP.2012.2210725]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dash A, 2015, INT C ADV COMPUT COM, P96, DOI 10.1109/ACCT.2015.100
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fareed SBS, 2018, IET IMAGE PROCESS, V12, P1378, DOI 10.1049/iet-ipr.2017.0199
   Fu B, 2019, MULTIMED TOOLS APPL, V78, P12043, DOI 10.1007/s11042-018-6732-8
   Fu B, 2015, NEUROCOMPUTING, V169, P119, DOI 10.1016/j.neucom.2014.11.094
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Kamamjjaman, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P125, DOI 10.1109/ICACCI.2016.7732035
   Kamarujjaman, 2019, PATTERN ANAL APPL, V22, P1561, DOI 10.1007/s10044-019-00806-2
   Kamarujjaman M, 2015, IEEE INT C RES COMPU, DOI [10.1109/ICRCICN.2015.7434247, DOI 10.1109/ICRCICN.2015.7434247]
   Kamarujjaman S, 2014, INT C DEV CIRC COMM, DOI [10.1109/ICDCCom.2014.7024689., DOI 10.1109/ICDCC0M.2014.7024689]
   Kandemir C, 2015, DIGIT SIGNAL PROCESS, V46, P164, DOI 10.1016/j.dsp.2015.08.012
   Ma CB, 2019, MULTIMED TOOLS APPL, V78, P1131, DOI 10.1007/s11042-018-6442-2
   Mafi M, 2018, IEEE T IMAGE PROCESS, V27, P5475, DOI 10.1109/TIP.2018.2857448
   Murugan K, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1124-1
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Raza M.T., 2012, P IEEE INT C ENG NUI, P1
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Varghese J, 2014, IET IMAGE PROCESS, V8, P199, DOI 10.1049/iet-ipr.2013.0297
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V48, P29, DOI [10.1016/j.procs.2015.04.106, DOI 10.1016/J.PROCS.2015.04.106]
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 35
TC 5
Z9 6
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 299
EP 321
DI 10.1007/s11042-020-09473-6
EA SEP 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565480700001
DA 2024-07-18
ER

PT J
AU Nikzad, M
   Bohlooli, A
   Jamshidi, K
AF Nikzad, Mortaza
   Bohlooli, Ali
   Jamshidi, Kamal
TI An adaptive, cross layer error control scheme for Distributed Video
   Coding over Wireless Multimedia Sensor Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless Multimedia Sensor Networks; Distributed Video Coding; Error
   control
ID INFORMATION; FRAMEWORK
AB Distributed Video Coding with low computational complexity at the encoder side has a high potential for use in Wireless Multimedia Sensor Networks. However, the different architecture of this coding and resource constraints in WMSNs require the design of new efficient transmission protocols for transmission of DVC through WMSNs. In view of these protocols, error control mechanisms have more importance in reliable multimedia communication over WMSN. These mechanisms provide higher video quality in receiver nodes while saving the energy of sender nodes by the reliable transmission of packets. Given the importance of this issue, in this paper, we propose an adaptive, cross-layer error control scheme to protect video frames in the transmission of DVC over WMSN, which serves QOS while considering energy consumption and frames' delay constraints. To propose this scheme, we used the accurate results from our previous works on error resiliency of DVC and comparative performance analysis of error control methods for this codec. The proposed scheme has been analyzed and compared to all standard, layer and, multi-layer error control schemes against the most important criteria in video communication over WSNs such as energy consumption, delay, and PSNR. Simulation results show that this scheme saves the quality of video in different channel conditions by consuming the least possible amount of energy based on the maximum allowable delay at the receiver.
C1 [Nikzad, Mortaza] Kateb Univ, Fac Comp Sci, Kabul, Afghanistan.
   [Bohlooli, Ali; Jamshidi, Kamal] Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Bohlooli, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan, Iran.
EM m.nikzad@kateb.edu.af; bohlooli@eng.ui.ac.ir; jamshidi@eng.ui.ac.ir
RI Bohlooli, Ali/ABG-4510-2021
OI Bohlooli, Ali/0000-0003-2678-8281; Nikzad, Mortaza/0000-0001-7318-8954;
   zam, abdulaziz/0000-0002-9063-8862
CR Akyildiz IF, 2007, IEEE WIREL COMMUN, V14, P32, DOI 10.1109/MWC.2007.4407225
   Al-Ariki HDE, 2017, WIREL NETW, V23, P1823, DOI 10.1007/s11276-016-1256-5
   [Anonymous], 2007, PICT COD S PCS 07
   [Anonymous], 2010, WIRELESS SENSOR NETW
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P1121, DOI 10.1109/TMM.2008.2001371
   Blackard K. L., 1991, P IEEE INT C COMM SY, V1, P28
   Chiasserini CF, 2004, TELECOMMUN SYST, V26, P369, DOI 10.1023/B:TELS.0000029047.09283.d2
   Contla PA, 2003, TELECOMMUN SYST, V22, P109, DOI 10.1023/A:1023434702987
   Costa DB, 2017, CAD SAUDE PUBLICA, V33, DOI [10.1590/0102-311x00126215, 10.1590/0102-311X00126215]
   Darnell M., 1985, IEE P F COMMUNICATIO, V132, P68, DOI [DOI 10.1049/IP-F-1:19850011, 10.1049/ip-f-1:19850011]
   Ehsan S, 2012, IEEE COMMUN SURV TUT, V14, P265, DOI 10.1109/SURV.2011.020211.00058
   Fautier T, 2019, SMPTE MOTION IMAG J, V128, P21, DOI [10.5594/JMI.2018.2887250, DOI 10.5594/JMI.2018.2887250]
   Fu B, 2014, IEEE COMMUN SURV TUT, V16, P110, DOI 10.1109/SURV.2013.081313.00231
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Imran N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1300-4
   Kambhatla KKR, 2016, MULTIMED TOOLS APPL, V75, P3235, DOI 10.1007/s11042-014-2432-1
   Khan MAR, 2012, INT CONF COMPUT INFO, P305, DOI 10.1109/ICCITechn.2012.6509769
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Kodavalla V. K., 2012, 2012 International Conference on Devices, Circuits and Systems (ICDCS 2012), P614, DOI 10.1109/ICDCSyst.2012.6188644
   Kumari R, 2018, HDB RES NETWORK FORE, P38
   Liu B, 2008, IEEE ICC, P4407, DOI 10.1109/ICC.2008.827
   Mor V., 2018, NEXT GENERATION NETW, P135
   MUSHKIN M, 1989, IEEE T INFORM THEORY, V35, P1277, DOI 10.1109/18.45284
   Naderi MY, 2012, AD HOC NETW, V10, P1028, DOI 10.1016/j.adhoc.2012.01.003
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P72, DOI 10.1109/MCOM.2008.4427233
   Nikzad M, 2014, INT J INFORM TECHNOL, V7, P1
   Nikzad M, 2018, MULTIMED TOOLS APPL, V77, P19547, DOI 10.1007/s11042-017-5397-z
   Perkins C., 2003, RFC3561
   Petrazzuoli G, 2014, IEEE T MULTIMEDIA, V16, P1834, DOI 10.1109/TMM.2014.2342201
   Raisinghani VT, 2004, COMPUT COMMUN, V27, P720, DOI 10.1016/j.comcom.2003.10.011
   Sankarasubramaniam Y, 2003, PROCEEDINGS OF THE FIRST IEEE INTERNATIONAL WORKSHOP ON SENSOR NETWORK PROTOCOLS AND APPLICATIONS, P1, DOI 10.1109/SNPA.2003.1203351
   Sarvi B, 2017, ADAPTIVE CROSS LAYER
   Shah GA, 2012, IEEE T MULTIMEDIA, V14, P1442, DOI 10.1109/TMM.2012.2196510
   Sharma K, 2017, PRACTICE EXPERIENCE, V18, piii
   Shen H, 2016, J NETW COMPUT APPL, V71, P30, DOI 10.1016/j.jnca.2016.05.013
   Shen YC, 2017, IEEE SENS J, V17, P1872, DOI 10.1109/JSEN.2017.2653100
   Shrivastava G., 2018, HDB RES NETWORK FORE
   Shrivastava G, 2018, SPECIAL ISSUE ADV RE
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2017, ADV VIDEO COMMUNICAT, P27
   Tekin N, 2020, COMPUT STAND INTER, V70, DOI 10.1016/j.csi.2020.103417
   Vuran MC, 2009, IEEE ACM T NETWORK, V17, P1186, DOI 10.1109/TNET.2008.2009971
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yang H, 2018, MULTIMED TOOLS APPL, V77, P4453, DOI 10.1007/s11042-016-4245-x
   Zam A, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2019.106014
   Zam A, 2019, MULTIMED TOOLS APPL, V78, P18921, DOI 10.1007/s11042-019-7204-5
NR 47
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32999
EP 33021
DI 10.1007/s11042-020-09594-y
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000567296900001
DA 2024-07-18
ER

PT J
AU Wang, ZS
   Zou, C
   Cui, XP
AF Wang, Zesong
   Zou, Cui
   Cui, Xianping
TI Low-sample size remote sensing image recognition based on a multihead
   attention integration network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multihead attention mechanism; Multiscale convolution; Bidirectional
   independent recurrent neural network
ID CLASSIFICATION
AB For a long time, small sample recognition for hyperspectral images has been a popular research topic. It is very difficult for an algorithm to simultaneously satisfy the requirements of feature mining, feature selection and feature integration. The traditional single model has difficulty completing multiple tasks at the same time, ultimately leading to poor small sample recognition results for remote sensing images. This paper proposes a multimodel joint algorithm for deep feature mining based on multiscale convolution (MC) under multihead attention (MA) and deep feature integration based on bidirectional independent recurrent neural networks (BiIndRNNs), MACBINet. First, this paper proposes a multihead attention mechanism that assigns multiple weight coefficients to each feature to better select remote sensing image features; then, it implements the deep mining of features and the retention of multiple deep features through multiscale convolution. Subsequently, it implements contextual semantic information integration for long-sequence features through bidirectional independent recurrent neural networks to avoid the problem of gradient disappearance during training on a small sample of data. Finally, the softmax function is used to perform recognition on three public remote sensing data sets. The experimental results prove that our proposed MACBINet achieves the best results to date for small sample classification.
C1 [Wang, Zesong] Qingdao Huanghai Univ, Qingdao 266427, Peoples R China.
   [Wang, Zesong; Zou, Cui; Cui, Xianping] Qingdao Huanghai Univ, Big Data Inst, Qingdao 266427, Peoples R China.
RP Wang, ZS (corresponding author), Qingdao Huanghai Univ, Qingdao 266427, Peoples R China.; Wang, ZS (corresponding author), Qingdao Huanghai Univ, Big Data Inst, Qingdao 266427, Peoples R China.
EM cxphwp@163.com; zoucui0204@163.com; wzs2296@163.com
CR Achour S, 2022, GEOCARTO INT, V37, P196, DOI 10.1080/10106049.2020.1713228
   Akhlaq MLM, 2020, 1 BOR INT S HUM EC S, P992
   Anders K, 2020, ISPRS J PHOTOGRAMM, V159, P352, DOI 10.1016/j.isprsjprs.2019.11.025
   [Anonymous], 2020, Deep Learning in Computer Vision: Principles and Applications
   Bakhti K, 2020, 2020 MEDITERRANEAN AND MIDDLE-EAST GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (M2GARSS), P160, DOI [10.1109/m2garss47143.2020.9105156, 10.1109/M2GARSS47143.2020.9105156]
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen JZ, 2019, IEEE ACCESS, V7, P81407, DOI 10.1109/ACCESS.2019.2923776
   Chen T, 2020, NEURAL COMPUT APPL, V32, P6513, DOI 10.1007/s00521-019-04046-7
   Cui JT, 2020, INT J AGR BIOL ENG, V13, P178, DOI 10.25165/j.ijabe.20201301.5285
   Feng J, 2019, INT GEOSCI REMOTE SE, P588, DOI [10.1109/igarss.2019.8897819, 10.1109/IGARSS.2019.8897819]
   Gao HM, 2019, IEEE ACCESS, V7, P176587, DOI 10.1109/ACCESS.2019.2957163
   Ghaffari R, 2020, INT J REMOTE SENS, V41, P3535, DOI 10.1080/01431161.2019.1706202
   Hou YZ, 2020, MAT SCI ENG A-STRUCT, V780, DOI 10.1016/j.msea.2020.139217
   Huang MX, 2020, MULTIMED TOOLS APPL, V79, P4597, DOI 10.1007/s11042-019-07920-7
   Ji CX, 2019, INT GEOSCI REMOTE SE, P1092, DOI [10.1109/igarss.2019.8897894, 10.1109/IGARSS.2019.8897894]
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li GD, 2020, REMOTE SENS LETT, V11, P195, DOI 10.1080/2150704X.2019.1697001
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li P, 2020, IEEE T GEOSCI REMOTE
   Li YY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060939
   Liu XN, 2020, NEUROCOMPUTING, V381, P298, DOI 10.1016/j.neucom.2019.11.097
   Pan ET, 2020, NEUROCOMPUTING, V387, P150, DOI 10.1016/j.neucom.2020.01.029
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shafaey MA, 2020, P INT C ART INT COMP
   Shahabi H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020266
   Sowmya V, 2019, RECENT ADV COMPUTER, P401, DOI DOI 10.1007/978-3-030-03000-1_16
   Uddin MP, 2021, IETE TECH REV, V38, P377, DOI 10.1080/02564602.2020.1740615
   Wagner FH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101544
   Wan YT, 2020, IEEE T GEOSCI REMOTE, V58, P3601, DOI 10.1109/TGRS.2019.2958812
   Wang HM, 2021, J OPER RES SOC, V72, P923, DOI 10.1080/01605682.2019.1705193
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zhang K, 2020, IEEE GEOSCI REMOTE S, V17, P1303, DOI 10.1109/LGRS.2019.2947170
   Zhang YJ, 2020, N AM J ECON FINANC, V52, DOI 10.1016/j.najef.2020.101145
   Zhou W, 2020, REMOTE SENS ENVIRON, V236, DOI 10.1016/j.rse.2019.111458
   Zhu PP, 2020, IEEE T GEOSCI REMOTE, V58, P4047, DOI 10.1109/TGRS.2019.2960466
   Zhu XL, 2019, J INDIAN SOC REMOTE, V47, P413, DOI 10.1007/s12524-018-0930-8
   ZHU Z, 2020, SCI CHINA EARTH SCI, P1
NR 39
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32525
EP 32540
DI 10.1007/s11042-020-09641-8
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606600003
DA 2024-07-18
ER

PT J
AU Ma, R
   Li, T
   Bo, DZ
   Wu, Q
   An, P
AF Ma, Ran
   Li, Tong
   Bo, Dezhi
   Wu, Qiang
   An, Ping
TI Error sensitivity model based on spatial and temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Packet loss; Spatial and temporal features; Error sensitivity;
   Regression
ID QUALITY ASSESSMENT; PACKET LOSS; VIDEO; IMPACT
AB Packet loss and error propagation induced by it are significant causes of visual impairments in video applications. Most of the existing video quality assessment models are developed at frame or sequence level, which can not accurately describe the impact of packet loss on the local regions in one frame. In this paper, we propose an error sensitivity model to evaluate the impact of a single packet loss. We also make full use of the spatio-temporal correlation of the video and analyze a set of features that directly impact the perceptual quality of videos, based on the specific situation of video packet loss. With the aid of the support vector regression (SVR), these features are used to predict the error sensitivity of the local region. The proposed model is tested on six video sequences. Experimental results show that the proposed model predicts sensitivity of videos to different packet loss cases with certain reasonable accuracy, and provides good generalization ability, which turns out outperform the state-of-art image and video quality assessment methods.
C1 [Ma, Ran; Li, Tong; Bo, Dezhi; An, Ping] Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
   [Ma, Ran; An, Ping] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, 99 Shangda Rd, Shanghai 200444, Peoples R China.
   [Wu, Qiang] Univ Technol Sydney, Global Big Data Technol Ctr, Sydney, NSW 2007, Australia.
C3 Shanghai University; Shanghai University; University of Technology
   Sydney
RP Ma, R (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 99 Shangda Rd, Shanghai 200444, Peoples R China.
EM maran@shu.edu.cn
OI Wu, Qiang/0000-0001-5641-2483
FU National Natural Science Foundation of China [61301112, 61828105,
   61601278]; Shanghai Municipal Education Commission; Shanghai Education
   Development Foundation [17CG41]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61301112, 61828105 and 61601278, Chen Guang
   Project supported by Shanghai Municipal Education Commission and
   Shanghai Education Development Foundation under Grant No.17CG41.
CR Adeyemi-Ejeye A, 2017, IEEE I C CONS ELECT, P258, DOI 10.1109/ICCE-Berlin.2017.8210644
   [Anonymous], 1999, SUBJ VID QUAL ASS ME
   Bayrak H., 2018, 26 SIGN PROC COMM AP, P1
   Bondzulic BP, 2016, ELECTRON LETT, V52, P454, DOI 10.1049/el.2015.3784
   Chen N, 2011, P CISP SHANGH CHIN, P282
   Chen N, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P38, DOI 10.1109/CISP.2012.6469970
   Frnda J, 2016, TELECOMMUN SYST, V62, P265, DOI 10.1007/s11235-015-0037-2
   Gao P, 2017, IEEE T IMAGE PROCESS, V26, P2781, DOI 10.1109/TIP.2017.2690058
   Garcia M. N., 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P349, DOI 10.1109/ISSPA.2010.5605528
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hewage CTER, 2013, IEEE INT CONF COMM, P662, DOI 10.1109/ICCW.2013.6649316
   Hewage CTER, 2012, PROC SPIE, V8290, DOI 10.1117/12.910561
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Hu ZG, 2018, MULTIMED TOOLS APPL, V77, P11589, DOI 10.1007/s11042-016-3566-0
   Joskowicz J, 2012, IEEE INT SYM BROADB
   Joskowicz J, 2014, INT J DIGIT MULTIMED, V2014, DOI 10.1155/2014/242531
   Korhonen J., 2018, 2018 10 INT C QUAL M, P1, DOI DOI 10.1109/QOMEX.2018.8463394
   Korhonen J, 2018, IEEE T BROADCAST, V64, P354, DOI 10.1109/TBC.2018.2832465
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Li YM, 2016, IEEE T CIRC SYST VID, V26, P1044, DOI 10.1109/TCSVT.2015.2430711
   Manasa K., 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P67, DOI 10.1109/QoMEX.2014.6982296
   Mittal A, 2014, IEEE IMAGE PROC, P571, DOI 10.1109/ICIP.2014.7025114
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Oszust M, 2017, IEEE SIGNAL PROC LET, V24, P1656, DOI 10.1109/LSP.2017.2754539
   Paul R, 2015, P APMEDIACAST KUT IN, P1
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Saputra RW, 2016, INT CONF ICT SMART S, P1, DOI 10.1109/ICTSS.2016.7792846
   Shahid M, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053012
   Song J, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/606493
   Tang SY, 2014, IEEE T MULTIMEDIA, V16, P2256, DOI 10.1109/TMM.2014.2348947
   Uhrina Miroslav, 2015, 2015 38th International Conference on Telecommunications and Signal Processing (TSP), P1, DOI 10.1109/TSP.2015.7296473
   Valenzise G, 2012, IEEE T CIRC SYST VID, V22, P605, DOI 10.1109/TCSVT.2011.2171211
   Wan S, 2010, P 18 INT S INT SIGN, P1
   Wang ZJ, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/475389
   Yang FZ, 2010, IEEE T CIRC SYST VID, V20, P1544, DOI 10.1109/TCSVT.2010.2087433
NR 35
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31913
EP 31930
DI 10.1007/s11042-020-09407-2
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400003
DA 2024-07-18
ER

PT J
AU Zhu, SQ
   Zhu, CX
   Fu, Y
   Zhang, WM
   Wu, XT
AF Zhu, Shuqin
   Zhu, Congxu
   Fu, Yu
   Zhang, Weimeng
   Wu, Xiaoting
TI A secure image encryption scheme with compression-confusion-diffusion
   structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image encryption; Compressive sensing; Discrete hyper-chaotic map
ID ALGORITHM
AB This paper presents a novel image compression-encryption scheme, which has the compression-confusion-diffusion Structure. Firstly, based on Chebyshev chaotic map, a Gauss measurement matrix is constructed and optimized, which is applied to compressive sensing. Then, an image compression-encryption algorithm is proposed by using a six-dimensional discrete chaotic map. In the proposed scheme, the original image is transformed into a sparse coefficient matrix by discrete wavelet transform, and the sparse coefficients are measured by using the optimized Gauss measurement matrix to get the measured values. Then, the measured values are quantized into integer values and the compressed image is obtained. Furtherly, the compressed image is encrypted by using a six-dimensional chaotic map. In the process of encryption, the plaintext image is divided into two parts, when encrypting the second part, the first part is used as part of the key. While encrypting the first part, the ciphertext of the second part is used as part of the key. Thus, the algorithm has strong confusion and diffusion effect and makes ciphertext sensitive to plaintext. Experimental results such as effects of compression-encryption, key space analysis, key sensitivity analysis, differential analysis, histograms analysis, information entropy analysis, and correlation coefficients analysis show that the proposed scheme is secure and has high application potential.
C1 [Zhu, Shuqin; Fu, Yu; Zhang, Weimeng; Wu, Xiaoting] Liaocheng Univ, Sch Comp Sci, Liaocheng 252059, Shandong, Peoples R China.
   [Zhu, Congxu] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
   [Zhu, Congxu] Hunan Police Acad, Key Lab Network Crime Invest Hunan Prov Coll, Changsha 410138, Peoples R China.
C3 Liaocheng University; Central South University
RP Zhu, CX (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.; Zhu, CX (corresponding author), Hunan Police Acad, Key Lab Network Crime Invest Hunan Prov Coll, Changsha 410138, Peoples R China.
EM shuqinzhu2008@163.com; zhucx@csu.edu.cn
OI Zhu, Congxu/0000-0002-9662-0532
FU Open Research Fund of Key Laboratory of Network Crime Investigation of
   Hunan Provincial Colleges [2020WLFZZC002]; National innovation and
   entrepreneurship training program for college students [S201910447044];
   Liaocheng University innovation and entrepreneurship training program
   for college students [cxcy2019y091]
FX This work was Supported by the Open Research Fund of Key Laboratory of
   Network Crime Investigation of Hunan Provincial Colleges under Grant NO.
   2020WLFZZC002, in part by National innovation and entrepreneurship
   training program for college students under Grant NO. S201910447044 and
   Liaocheng University innovation and entrepreneurship training program
   for college students under Grant NO. cxcy2019y091.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hua ZY, 2018, IEEE T CIRCUITS-I, V65, P235, DOI 10.1109/TCSI.2017.2717943
   Li CQ, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102361
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Peng Y., 2012, J COMPUT INFORM SYST, V8, P6025
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   [任越美 Ren Yuemei], 2014, [自动化学报, Acta Automatica Sinica], V40, P1563
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiao D, 2017, OPT LASER TECHNOL, V91, P212, DOI 10.1016/j.optlastec.2016.12.024
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu CX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090399
   Zhu CX, 2018, IEEE ACCESS, V6, P18759, DOI 10.1109/ACCESS.2018.2817600
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   ZHU CX, 2018, ENTROPY, V20
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
   Zhu SQ, 2019, MULTIMED TOOLS APPL, V78, P20855, DOI 10.1007/s11042-019-7405-y
   Zhu SQ, 2019, IEEE ACCESS, V7, P34141, DOI 10.1109/ACCESS.2019.2902873
   Zhu SQ, 2018, IEEE ACCESS, V6, P67095, DOI 10.1109/ACCESS.2018.2874336
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 41
TC 11
Z9 11
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31957
EP 31980
DI 10.1007/s11042-020-09699-4
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562697400008
DA 2024-07-18
ER

PT J
AU Li, B
   Sun, ZX
   Xu, JF
   Wang, S
   Yu, PW
AF Li, Bo
   Sun, Zhengxing
   Xu, Junfeng
   Wang, Shuang
   Yu, Peiwen
TI Saliency based multiple object cosegmentation by ensemble MIML learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple foreground cosegmentation; Saliency pseudo-annotation; Label
   propagation; Ensemble MIML learning
ID CO-SEGMENTATION; ALGORITHM; NETWORKS
AB As an interesting and emerging topic, multiple foreground cosegmentation (MFC) aims at extracting a finite number of common objects from an image collection, which is useful to variety of visual media applications. Although a number of approaches have been proposed to address this problem, many of them are designed with the misleading consistent information, suboptimal image representation, or inefficient segmentation assist and thus still suffer from certain limitations, which reduces their capability in the real-world scenarios. To alleviate these limitations, we propose a novel unsupervised MFC framework, which is composed of three components: unsupervised label generation, saliency based pseudo-annotation and cosegmentation by MIML learning. Specifically, we combine the high-level and low-level feature to represent the proposal objects, and adopt a novel SPAP clustering scheme to obtain more accurate consistent information of common objects. Then the saliency based pseudo-annotation help us reformulate the MFC problem as a Multi-Instance Multi-Label (MIML) learning problem by label propagation. Finally, by introducing a novel ensemble MIML learning scheme, the consistent information of common objects can more efficiently assist the segmentation of the images and get the more accurate segmentation results. We evaluate our framework on widely used public databases including the ICoseg dataset, MSRC dataset and FlickrMFC dataset for single and multiple common object cosegmentation respectively. Comparison results show that the proposed methods reach advanced and efficient performance.
C1 [Li, Bo; Sun, Zhengxing; Xu, Junfeng; Wang, Shuang; Yu, Peiwen] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Li, Bo] Tencent, Youtu Lab, Shanghai, Peoples R China.
C3 Nanjing University; Tencent
RP Sun, ZX (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM njumagiclibo@gmail.com; szx@nju.edu.cn; 347034723@qq.com;
   wangshuang_nju@hotmail.com; 731357238@qq.com
RI Yu, Peiwen/M-1905-2018; Sun, Zhengxing/A-7411-2011
OI Wang, Shuang/0000-0003-2224-5108
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; National Key Research and Development Program of China
   [2018YFC0309100, 2018YFC0309104]; China Postdoctoral Science Foundation
   [2017M621700]; Innovation Fund of State Key Laboratory for Novel
   Software Technology [ZZKT2018A09]
FX This work was supported by National High Technology Research and
   Development Program of China (No. 2007AA01Z334), National Natural
   Science Foundation of China (Nos. 61321491 and 61272219), National Key
   Research and Development Program of China (Nos. 2018YFC0309100,
   2018YFC0309104), the China Postdoctoral Science Foundation (Grant No.
   2017M621700) and Innovation Fund of State Key Laboratory for Novel
   Software Technology (Nos. ZZKT2018A09).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji A, 2016, IEEE T NEUR NET LEAR, V27, P1214, DOI 10.1109/TNNLS.2015.2480683
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Briggs F, 2012, P 18 ACM SIGKDD INT, P534, DOI [DOI 10.1145/2339530.2339616, 10.1145/2339530.2339616]
   Briggs F, 2015, KNOWL INF SYST, V43, P53, DOI 10.1007/s10115-014-0781-8
   Chang HS, 2015, COMPUT VIS IMAGE UND, V141, P18, DOI 10.1016/j.cviu.2015.06.004
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Chen Y, 2019, CONCURRENCY AND COMP, V10
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   CHO M, 2015, PROC CVPR IEEE, P1201, DOI DOI 10.1109/CVPR.2015.7298724
   Cinbis RG, 2014, PROC CVPR IEEE, P2409, DOI 10.1109/CVPR.2014.309
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   Fan DP, 2020, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR42600.2020.00299
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan JQ, 2021, IEEE T CIRC SYST VID, V31, P1296, DOI 10.1109/TCSVT.2020.2987601
   Fern X. Z., 2003, P 20 INT C MACHINE L, P186
   Fred ALN, 2005, IEEE T PATTERN ANAL, V27, P835, DOI 10.1109/TPAMI.2005.113
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Huang GH, 2017, MULTIMED TOOLS APPL, V76, P12941, DOI 10.1007/s11042-016-3709-3
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin Armand, 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539868
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P818
   Li B, 2019, IEEE I CONF COMP VIS, P8518, DOI 10.1109/ICCV.2019.00861
   Li B, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1392, DOI 10.1145/3343031.3351016
   Li B, 2019, AAAI CONF ARTIF INTE, P8569
   Li B, 2019, INT CONF ACOUST SPEE, P1662, DOI [10.1109/ICASSP.2019.8683022, 10.1109/icassp.2019.8683022]
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li H, 2005, COMPUTER MODERNIZATI, V4
   Li HL, 2014, IEEE T CIRC SYST VID, V24, P789, DOI 10.1109/TCSVT.2013.2280851
   Li KQ, 2016, IEEE T IMAGE PROCESS, V25, P1898, DOI 10.1109/TIP.2016.2526900
   Li L, 2015, PROC SPIE, V9812, DOI 10.1117/12.2210737
   Li TP, 2020, NEUROCOMPUTING, V389, P170, DOI 10.1016/j.neucom.2019.12.109
   Li TP, 2019, MULTIMED TOOLS APPL, V78, P21309, DOI 10.1007/s11042-019-7403-0
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Liu CJ, 2016, MULTIMED TOOLS APPL, V75, P12263, DOI 10.1007/s11042-016-3494-z
   Liu GC, 2019, IEEE T IMAGE PROCESS, V28, P5161, DOI 10.1109/TIP.2019.2917857
   Liu LM, 2017, CIRC SYST SIGNAL PR, V36, P4423, DOI 10.1007/s00034-017-0518-5
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu ZY, 2020, NEUROCOMPUTING, V387, P210, DOI 10.1016/j.neucom.2020.01.045
   Lu Chia-Ju, 2013, ACM MULT C MM 13 BAR, P401
   Luo YJ, 2020, J BIOMOL STRUCT DYN, V38, P4210, DOI 10.1080/07391102.2019.1676824
   Ma TY, 2013, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2013.255
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Meng FM, 2015, IEEE T CIRC SYST VID, V25, P1735, DOI 10.1109/TCSVT.2015.2402891
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Piao Y, EXPLOIT REPLACE ASYM
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190
   Tsai YH, 2016, LECT NOTES COMPUT SC, V9908, P760, DOI 10.1007/978-3-319-46493-0_46
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang F, 2014, PROC CVPR IEEE, P3142, DOI 10.1109/CVPR.2014.402
   Wang W., 2019, ARXIV190409146
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Xie YF, 2019, MULTIMED TOOLS APPL, V78, P10353, DOI 10.1007/s11042-018-6614-0
   Xu X.-S., 2011, P 19 ACM INT C MULT, P1153, DOI [10.1145/2072298.2071962, DOI 10.1145/2072298.2071962]
   Yang WC, 2017, LECT NOTES COMPUT SC, V10133, P393, DOI 10.1007/978-3-319-51814-5_33
   Yuan ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371
   Zha Z-J, 2008, 2008 IEEE COMP SOC C
   Zhang JM, 2019, IEEE ACCESS, V7, P83873, DOI 10.1109/ACCESS.2019.2924944
   Zhang K., 2019, ARXIV191112950
   Zhang K., 2020, P IEEE CVF C COMP VI, P9050
   Zhang KH, 2019, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2019.00321
   Zhang ML, 2008, IEEE DATA MINING, P688, DOI 10.1109/ICDM.2008.27
   Zhang XL, 2020, NEUROCOMPUTING, V398, P531, DOI 10.1016/j.neucom.2019.04.097
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
   Zhou Z., 2006, Advances in Neural Information Processing Systems, P1609
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
   Zhu HY, 2014, IEEE WINT CONF APPL, P485, DOI 10.1109/WACV.2014.6836062
NR 103
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31299
EP 31328
DI 10.1007/s11042-020-09458-5
EA AUG 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400008
DA 2024-07-18
ER

PT J
AU Cheng, YJ
   Hou, MZ
   Wang, J
AF Cheng, Yang-Jin
   Hou, Muzhou
   Wang, Juan
TI An improved optimal trigonometric ELM algorithm for numerical solution
   to ruin probability of Erlang(2) risk model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Erlang(2) risk model; Ruin probability; Renewal integral-differential
   equation; IOTELM algorithm
ID EXTREME LEARNING-MACHINE; NEURAL-NETWORK; MULTIOBJECTIVE OPTIMIZATION;
   EXPERT-SYSTEM; CONSTRUCTIVE APPROXIMATION; EQUATION; TIME;
   CLASSIFICATION; PREDICTION; SEARCH
AB In this paper, we focus on accurately calculating the numerical solution of the integral-differential equation for ruin probability in Erlang(2) renewal risk model with arbitrary claim distribution. Because the analytical solutions of the equation do not usually exist, firstly, using machine learning method in modern artificial intelligence, the activation functions in the ELM model are changed to trigonometric function, the initial conditions in the integral-differential equation are added to the ELM linear solver to get the ITELM model, and the steps and feasibility of the algorithm are strictly deduced in theory. As the analytic solution for the integral-differential equation only exists when the claim is subject to exponential distribution, and the numerical solution can be gotten with the pareto distribution. And, since the number of hidden neurons in the ITELM model is uncertain, a good numerical value of hidden neurons can only be determined through a large number of iterative tests and comparisons in the actual calculation. Then, we construct a multi-objective optimization model and algorithm, which can get the optimal number of hidden neurons to obtain the IOTELM model and algorithm. Then, in the above two cases for exponential distribution and pareto distribution, the optimal number of hidden neurons is calculated by IOTELM model and algorithm, and then corresponding ITELM models and algorithms are constructed to calculate the corresponding ruin probability. Compared with the previous numerical experiments, it can be seen that the numerical accuracy is greatly improved, which verified the versatility, feasibility and superiority of the proposed IOTELM model and algorithm.
C1 [Cheng, Yang-Jin] Xiangtan Univ, Sch Math & Computat Sci, Xiangtan 411105, Hunan, Peoples R China.
   [Hou, Muzhou] Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
   [Wang, Juan] Hunan Univ, Coll Finance & Stat, Changsha, Peoples R China.
C3 Xiangtan University; Central South University; Hunan University
RP Hou, MZ (corresponding author), Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
EM yjcheng@xtu.edu.cn; houmuzhou@sina.com; 20101720717@hnu.edu.cn
RI , houmuzhou/N-2357-2019
OI , houmuzhou/0000-0001-6658-2187
FU Key Program of The National Social Science Fund of China [16ATJ003]
FX This work was supported by The Key Program of The National Social
   Science Fund of China under Grant 16ATJ003.
CR Aboulaich R, 2007, CR MATH, V345, P425, DOI 10.1016/j.crma.2007.09.009
   Aiolli F, 2017, NEUROCOMPUTING, V268, P1, DOI 10.1016/j.neucom.2017.04.038
   Andersen E.S., 1957, Bull. Inst. Math. Appl, V12, P275
   [Anonymous], 2008, MODERN ACTUARIAL RIS
   [Anonymous], 2005, INT SYST APPL POW SY
   [Anonymous], 2005, JOURNALS
   [Anonymous], 2000, THEORY FINANCIAL RIS
   [Anonymous], 2017, J IND MANAGEMENT OPT
   [Anonymous], 1995, APPL MATH FINANCE, DOI 10.1080/3504869500000002
   [Anonymous], 2003, MATHEMATICAL THEORY
   [Anonymous], 1996, MATH METHODS RISK TH
   Avram F, 2016, INSUR MATH ECON, V71, P27, DOI 10.1016/j.insmatheco.2016.08.001
   Bouchaud JP, 2000, THEORY FINANCIAL RIS, P18
   Chen YH, 2020, J FORECASTING, V39, P986, DOI 10.1002/for.2663
   [成世学 Cheng Shixue], 2002, [数学进展, Advances in Mathematics], V31, P403
   Deb Kalyanmoy, 2005, Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques, P273, DOI [10.1007/0-387-28356-010, DOI 10.1007/0-387-28356-010, DOI 10.1007/0-387-28356-0_10]
   Dickson D C M, 1998, N AM ACTUARIAL J, V2, P60, DOI [DOI 10.1080/10920277.1998.10595723, 10.1080/10920277.1998.10595723]
   Dickson DCM, 2008, ASTIN BULL, V38, P259, DOI 10.2143/AST.38.1.2030413
   Dickson DCM, 2010, INSUR MATH ECON, V46, P12, DOI 10.1016/j.insmatheco.2009.05.001
   Dickson DCM, 1998, INSUR MATH ECON, V22, P251, DOI 10.1016/S0167-6687(98)00003-1
   Etemad SA, 2014, NEUROCOMPUTING, V129, P585, DOI 10.1016/j.neucom.2013.09.001
   Fan LY, 2016, ACSR ADV COMPUT, V37, P423
   Galeshchuk S, 2016, NEUROCOMPUTING, V172, P446, DOI 10.1016/j.neucom.2015.03.100
   Gerber H. U., 1982, Insur. Math. Econ., V1, P213, DOI [10.1016/0167-6687(82)90011-7, DOI 10.1016/0167-6687(82)90011-7]
   Giebel S, 2013, CENT EUR J OPER RES, V21, P277, DOI 10.1007/s10100-011-0234-3
   Guo GX, 2019, SYST SCI CONTROL ENG, V7, P346, DOI 10.1080/21642583.2019.1681033
   Han X, 2008, INT C ADV GEOM MOD P
   Han X, 2007, INT C NAT COMP
   Hanafizadeh P, 2010, EXPERT SYST APPL, V37, P8879, DOI 10.1016/j.eswa.2010.06.008
   He X, 2015, NEUROCOMPUTING, V149, P608, DOI 10.1016/j.neucom.2014.08.014
   Hjouji A, 2019, PATTERN RECOGN IMAGE, V29, P296, DOI 10.1134/S1054661819020020
   Hou M, 2017, APPL INTELL, P1
   Hou MZ, 2012, NEURAL COMPUT APPL, V21, P25, DOI 10.1007/s00521-011-0604-8
   Hou MZ, 2011, APPL SOFT COMPUT, V11, P2173, DOI 10.1016/j.asoc.2010.07.016
   Hou MZ, 2010, IEEE T NEURAL NETWOR, V21, P1517, DOI 10.1109/TNN.2010.2055888
   Hou MZ, 2009, NEURAL COMPUT APPL, V18, P883, DOI 10.1007/s00521-008-0194-2
   Huang E, 2019, IEEE INT CONF ROBOT, P211, DOI [10.1109/icra.2019.8793946, 10.1109/ICRA.2019.8793946]
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008
   Huang GB, 2007, NEUROCOMPUTING, V70, P3056, DOI 10.1016/j.neucom.2007.02.009
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Injadat M, 2016, NEUROCOMPUTING, V214, P654, DOI 10.1016/j.neucom.2016.06.045
   Jack Copper JW, 2001, NEURALWARE
   Jin C, 2016, INSUR MATH ECON, V71, P304, DOI 10.1016/j.insmatheco.2016.10.001
   Khan A, 2014, NEUROCOMPUTING, V128, P113, DOI 10.1016/j.neucom.2013.03.053
   Li A, 2016, NEUROCOMPUTING, V206, P1, DOI 10.1016/j.neucom.2016.05.055
   Li SM, 2006, INSUR MATH ECON, V38, P529, DOI 10.1016/j.insmatheco.2005.11.005
   Li XD, 2014, NEUROCOMPUTING, V142, P228, DOI 10.1016/j.neucom.2014.04.043
   Li Y, 2013, NEUROCOMPUTING, V110, P111, DOI 10.1016/j.neucom.2012.11.024
   Liu DQ, 2017, NEUROCOMPUTING, V249, P212, DOI 10.1016/j.neucom.2017.04.003
   Liu JF, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.113134
   Liu QS, 2016, NEUROCOMPUTING, V198, P1, DOI 10.1016/j.neucom.2016.01.085
   Lu YF, 2020, DIGIT SIGNAL PROCESS, V99, DOI 10.1016/j.dsp.2019.102634
   Lundberg F, 1903, 1 APPROXIMERAD FRANS, pII
   Mahmoodi S, 2006, IMAGE VISION COMPUT, V24, P202, DOI 10.1016/j.imavis.2005.11.002
   Marler RT, 2010, STRUCT MULTIDISCIP O, V41, P853, DOI 10.1007/s00158-009-0460-7
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Martínez-Martínez V, 2015, EXPERT SYST APPL, V42, P6433, DOI 10.1016/j.eswa.2015.04.018
   Meng M, 2017, NEUROCOMPUTING, V257, P128, DOI 10.1016/j.neucom.2016.11.066
   Moghadas Nejad F, 2011, EXPERT SYST APPL, V38, P7088, DOI 10.1016/j.eswa.2010.12.060
   Nan LD, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102610
   Nedjah N, 2017, NEUROCOMPUTING, V265, P1, DOI 10.1016/j.neucom.2017.05.080
   Nguyen HH, 2020, UKR MATH J+, V71, P1636, DOI 10.1007/s11253-020-01736-7
   Nnolim UA, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/8157205
   PAULSEN J, 1993, STOCH PROC APPL, V46, P327, DOI 10.1016/0304-4149(93)90010-2
   Paulsen J, 1997, ADV APPL PROBAB, V29, P965, DOI 10.2307/1427849
   Saxen T, 2011, SCAND ACTUAR J, V1-2
   Sun BQ, 2015, NEUROCOMPUTING, V151, P1528, DOI 10.1016/j.neucom.2014.09.018
   Sun HL, 2019, NEURAL PROCESS LETT, V50, P1153, DOI 10.1007/s11063-018-9911-8
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tao Z, FORECASTING STOCK IN
   Tasdemir S, 2011, EXPERT SYST APPL, V38, P13912, DOI 10.1016/j.eswa.2011.04.198
   Wang HG, 2019, ANN OPER RES, V279, P343, DOI 10.1007/s10479-018-3060-3
   Wang N, 2019, J ENG-JOE, V2019, P8198, DOI 10.1049/joe.2018.5443
   Wei L., 2004, ACTA MATH APPL SIN-E, V20, P495, DOI DOI 10.1007/s10255-004-0187-6
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu JD, 2009, EXPERT SYST APPL, V36, P4278, DOI 10.1016/j.eswa.2008.03.008
   Yang YL, 2020, J INTELL FUZZY SYST, V38, P3445, DOI 10.3233/JIFS-190406
   Yang YL, 2020, SOFT COMPUT, V24, P1083, DOI 10.1007/s00500-019-03944-1
   You HL, 2020, COMPUT STAT DATA AN, V144, DOI 10.1016/j.csda.2019.106890
   Zhang J, 2017, STUDY RUIN PROBABILI
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P365, DOI 10.1109/TNNLS.2011.2178124
   Zhang XJ, 2019, MULTIMED TOOLS APPL, V78, P18095, DOI 10.1007/s11042-019-7170-y
   Zhao ZY, 2019, INT CONF ACOUST SPEE, P3782, DOI 10.1109/ICASSP.2019.8682944
NR 84
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30235
EP 30255
DI 10.1007/s11042-020-09382-8
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900006
DA 2024-07-18
ER

PT J
AU Su, QT
   Wang, HY
   Liu, DC
   Yuan, ZH
   Zhang, XT
AF Su, Qingtang
   Wang, Huanying
   Liu, DeCheng
   Yuan, Zihan
   Zhang, Xueting
TI A combined domain watermarking algorithm of color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Spatial-domain; color image; watermarking
   technique
ID SCHEME
AB At present, some watermarking techniques have been proposed to protect the copyright of image either in frequency domain or in spatial domain. Designing a combined-domain watermarking algorithm is a difficult problem, which not only has short running time of spatial-domain watermarking algorithm but also has strong robustness of transform-domain watermarking algorithm. In this paper, a novel color image watermarking algorithm in spatial domain combining the principle of discrete Wavelet transform (DWT) is presented to embed color watermark image into color carrier image. At first, how to get the first low-frequency coefficient of DWT in spatial domain is analyzed. Then, the changing quantity of the first low-frequency coefficient in spatial domain is calculated by the presented algorithm. According to the presented features of the first low-frequency coefficient, the processes of embedding watermark and extracting watermark information are finished in spatial-domain instead of DWT. This presented algorithm has the following two innovations: (i) the first low-frequency coefficient of DWT is computed by image pixels in spatial domain; (ii) the presented algorithm is as robust as the transform-domain watermarking methods, and it is as rapid as the spatial-domain watermarking methods. The simulation data shows the presented algorithm has good watermarking performances as respect to visual imperceptibility, robustness, payload, and running time.
C1 [Su, Qingtang; Wang, Huanying; Liu, DeCheng; Yuan, Zihan; Zhang, Xueting] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsqt@163.com
FU Natural Science Foundation of China [61771231, 61772253, 61873117,
   61872170]; Key Research and Development Program of Shandong Province
   [2019GGX101025]
FX The research was partially supported by the Natural Science Foundation
   of China (61771231, 61772253, 61873117, and 61872170), and Key Research
   and Development Program of Shandong Province (2019GGX101025).
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Run RS, 2011, EXPERT SYST APPL, V38, P14357, DOI 10.1016/j.eswa.2011.03.024
   Saboori A, 2016, P 2016 10 INT S COMM, P1
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Thien HT, 2016, EXPERT SYST APPL, V62, P177, DOI 10.1016/j.eswa.2016.06.015
   University of Granada. Computer Vision Group, 2012, CVG UGR IM DAT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 26
TC 17
Z9 17
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 30023
EP 30043
DI 10.1007/s11042-020-09436-x
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400002
DA 2024-07-18
ER

PT J
AU AlShehri, L
   Hussain, M
   Aboalsamh, H
   Wadood, A
AF AlShehri, Laila
   Hussain, Muhammad
   Aboalsamh, Hatim
   Wadood, Abdul
TI Fragile watermarking for image authentication using BRINT and ELM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Fragile watermarking; BRINT; ELM
ID EXTREME LEARNING-MACHINE; TAMPER DETECTION; SCHEME; LOCALIZATION;
   ALGORITHM; WAVELET
AB Privacy and security concerns regarding digital information have been increasing with advancements in multimedia and network technologies. Digital images are an integral component of online-distributed content, which plays a crucial role in forming public perceptions and opinions. They also play a major role in sensitive areas, such as law and defense. Any attempt to tamper with them is, therefore, a serious issue. One common approach to this problem is fragile image watermarking, which is used to ensure the authenticity of digital content. In this paper, a new fragile watermarking method for the authentication of digital images is proposed based on a binary rotation invariant and noise tolerant (BRINT) local texture descriptor and an extreme learning machine (ELM). BRINT is used to generate and retrieve the watermark in both the embedding and extraction procedures. In parallel, ELM is used in both procedures to learn and recover any tampered areas. The experimental results showed that the proposed scheme does not degrade image quality, allows for tamper detection, and has a recovery ability comparable with state-of-the-art fragile and semi-fragile watermarking schemes. Moreover, the proposed scheme has been validated as a fragile watermarking method with the potential to detect and locate modifications in digital images, such as copy-paste forgery, JPEG compression, and noise addition. This method is useful in sensitive fields, like defense, law, and journalism, in which decision-making based on digital visual information is necessary, to ensure that an image is authentic and has not been tampered with.
C1 [AlShehri, Laila; Hussain, Muhammad; Aboalsamh, Hatim] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Wadood, Abdul] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
C3 King Saud University; King Saud University
RP Hussain, M (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
EM mhussain@ksu.edu.sa
RI Hussain, Muhammad/A-8487-2014; Abdul, Wadood/ABD-2040-2020; Hussain,
   Muhammad/KGL-0395-2024; Hussain, Muhammad/AAD-2380-2022; Aboalsamh,
   Hatim/AAO-6311-2021
OI Hussain, Muhammad/0000-0002-5847-8539; Abdul,
   Wadood/0000-0002-6871-6633; Aboalsamh, Hatim/0000-0002-8000-5105
FU Deanship of Scientific Research, King Saud University, Riyadh, Saudi
   Arabia [RGP-1439-067]
FX The authors are thankful to the Deanship of Scientific Research, King
   Saud University, Riyadh, Saudi Arabia for funding this work through the
   Research Group No. RGP-1439-067.
CR AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   Aslantas V, 2015, PROC SPIE, V9443, DOI 10.1117/12.2178988
   Chalamala SR, 2015, I C ARTIF INTELL, P159, DOI 10.1109/AIMS.2015.34
   Chen CM, 2019, IEEE ACCESS, V7, P12047, DOI 10.1109/ACCESS.2019.2891105
   El'arbi M, 2014, IET IMAGE PROCESS, V8, P619, DOI 10.1049/iet-ipr.2013.0646
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hsieh M. S., 2010, INTERNET J MULTIMEDI, V2, P1
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jun-Dong Chang, 2013, 2013 2nd International Symposium on Next-Generation Electronics (ISNE 2013), P173, DOI 10.1109/ISNE.2013.6512330
   Lin E., 1999, P MULTIMEDIA SECURIT, P25
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu X.-L., 2016, J. Inf. Hiding Multimedia Signal Process., V7, P1282
   Nayak DR, 2020, MULTIMED TOOLS APPL, V79, P15381, DOI 10.1007/s11042-019-7233-0
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P22705, DOI 10.1007/s11042-017-5281-x
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Pinjari Shakil A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P194, DOI 10.1109/ICGTSPICC.2016.7955296
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rosales-Roldan L, 2013, SIGNAL PROCESS-IMAGE, V28, P69, DOI 10.1016/j.image.2012.11.006
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2017, MULTIMED TOOLS APPL, V76, P6389, DOI 10.1007/s11042-015-3198-9
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Som S, 2015, ADV INTELL SYST, V305, P17, DOI 10.1007/978-81-322-1988-0_2
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Walia E, 2013, IET COMPUT VIS, V7, P9, DOI 10.1049/iet-cvi.2012.0109
   Wu TY, 2019, J CHIN INST ENG, V42, P20, DOI 10.1080/02533839.2018.1537807
   XIE TS, 2019, MULTIMED TOOLS APPL, P1
   Xu XK, 2013, IEEE IMAGE PROC, P4422, DOI 10.1109/ICIP.2013.6738911
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 33
TC 5
Z9 5
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29199
EP 29223
DI 10.1007/s11042-020-09441-0
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557319800001
DA 2024-07-18
ER

PT J
AU Neupane, A
   Alsadoon, A
   Prasad, PWC
   Ali, RS
   Haddad, S
AF Neupane, Aabha
   Alsadoon, Abeer
   Prasad, P. W. C.
   Ali, Rasha Subhi
   Haddad, Sami
TI A novel Modified Chaotic Simplified Advanced Encryption System
   (MCS-AES): mixed reality for a secure surgical tele-presence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surgical telepresence; Hybrid encryption system; Modified chaotic
   simplified AES; Modified simplified Zhongtang chaotic system; Modifies
   AES
ID ALGORITHM; STORAGE; HEVC
AB Mixed Reality (MR) surgery has not been effectively implemented in telemedicine due to strict requirements of security and delay minimization during real-time video transmission. Hence, this paper aims to propose a novel solution for Surgical Telepresence with highly secured and faster real-time video transmission. The proposed system consists of three components: Authentication (Pre-surgery), Data transmission (During-Surgery), and Storage (Post-Surgery). For Authentication, Pass-Matrix technique is used at both ends to provide graphical passwords. During the surgery, a hybrid system is used to provide highly secured and faster real-time video transmission. This system includes a Feistel Encryption System (FES), Modified Scaled Zhongtang Chaotic System (M-SCZS), and Modified Advanced Encryption System (M-AES) algorithm. After Surgery, the transmitted data am stored using the Information Accountability Framework (IAF) for future purposes. The results are obtained from the during-surgery stage for jaw, breast, and bowel surgery. Both solutions are simulated in MATLAB on a personal computer with average processing capability. The proposed solution improves the entropy from 7.733 similar to 7.782 to 7.798-7.996 and reduces the processing time from 8.642 similar to 9.911 s/frames to 5.071 similar to 6.563 s/frames. The proposed focus on reducing the total processing time for the encryption and decryption process with improving security during the surgery process. Finally, this solution provides a fast security system for surgical telepresence that helps both local and remote surgeons for secure real-time communication. The complexity for this work need to know the used chaotic method, the values of the chaotic parameters and for which this method was used, in addition to the complexity of state of the art.
C1 [Neupane, Aabha; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
   [Ali, Rasha Subhi] AL Nisour Univ Coll, Dept Comp Tech Engn, Baghdad, Iraq.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Mt Druitt, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Al-Nisour University College; Florey Institute
   of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com; drsamihaddad@gmail.com
RI ALI, Rasha/JBJ-4318-2023; Ali, Rasha Subhi/X-9445-2018; Alsadoon,
   A/Prof. Abeer/AAU-1532-2021
OI Ali, Rasha Subhi/0000-0002-9767-7151; Alsadoon, A/Prof.
   Abeer/0000-0002-2309-3540; withana, chandana/0000-0002-3007-687X; Subhi,
   Rasha/0000-0001-6718-5618; Ali, Rasha/0000-0003-3427-423X
CR Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Altaf M, 2018, MULTIMED TOOLS APPL, V77, P27981, DOI 10.1007/s11042-018-6022-5
   Arya A, 2016, INT J ENG COMPUTER S, DOI [10.18535/ijecs/v4i12.52, DOI 10.18535/IJECS/V4I12.52]
   Atteya AM, 2014, IEEE INT NEW CIRC, P217, DOI 10.1109/NEWCAS.2014.6934022
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Fairchild AJ, 2017, IEEE T CIRC SYST VID, V27, P814, DOI 10.1109/TCSVT.2016.2580425
   Harba ESI, 2017, ENG TECHNOL APPL SCI, V7, P1781
   Hayajneh T, 2017, IEEE SYST J, V11, P2536, DOI 10.1109/JSYST.2015.2424702
   Hazra A, 2017, J THORAC DIS, V9, P4125, DOI 10.21037/jtd.2017.09.14
   Jevdjic D, 2017, ACM SIGPLAN NOTICES, V52, P361, DOI 10.1145/3093336.3037718
   Liu RS, 2018, INT J DIGIT MULTIMED, V2018, DOI [10.1155/2018/7543875, 10.1109/TMM.2018.2812605]
   Meenpal T, 2017, MULTIMED TOOLS APPL, V76, P3699, DOI 10.1007/s11042-016-3973-2
   Musa MA, 2003, CRYPTOLOGIA, V27, P148, DOI 10.1080/0161-110391891838
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Pan J, 2012, IET COMMUN, V6, P3274, DOI 10.1049/iet-com.2011.0097
   Pande AP, 2017, INT RES J ENG TECHNO, V5, P407
   Preetha M., 2013, IJCSMC, V2, P126
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P13225, DOI 10.1007/s11042-017-4942-0
   Roman H, 2017, YOUTUBE
   Roy S, 2016, IEEE IPCCC
   Sallam AI, 2018, IEEE T MULTIMEDIA, V20, P1636, DOI 10.1109/TMM.2017.2777470
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sobh TS., 2011, Journal of Information Security, V2, P39, DOI DOI 10.4236/JIS.2011.21004
   Tabash FK, 2019, MULTIMED TOOLS APPL, V78, P7365, DOI 10.1007/s11042-018-6494-3
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Usman M, 2017, INFORM SCIENCES, V387, P90, DOI 10.1016/j.ins.2016.08.059
   Wickramage C, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P43
   Wu TS, 2014, INT J INF SECUR, V13, P245, DOI 10.1007/s10207-013-0216-7
   YouTube, 2018, PAUS WATCH HIST
NR 32
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29043
EP 29067
DI 10.1007/s11042-020-09478-1
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000557319900003
DA 2024-07-18
ER

PT J
AU alZahir, S
   Hammad, R
AF alZahir, Saif
   Hammad, Radwa
TI Image forgery detection using image similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copula; Blind image forgery detection; Image quality measures; Mutual
   information; Human visual system; Steerable pyramid
AB Ideally, sophisticated image forgery methods leave no perceptible evidence of tampering. In response to such stringent context, researchers have proposed digital methods to detect such indiscernible tampering. In this paper, we present a blind image forgery detection method that uses a steerable pyramid decomposition technique and copulas ensemble. This method can accurately detect forgery in regions as small as 16 pixels, which is the smallest size reported in the literature with perfect accuracy. The proposed method is innovative in that: (i) it works on both grey scale images as well as colored images; (ii) the copula functions are used to calculate image similarity (or dissimilarity) which represents image forgery; (iii) the precision of the copula results on the image steerable pyramid bands motivated the idea of selecting the band with minimum number of elements to represent the block(s) in the image, which is 16 elements, in our case. The idea of using smallest number of elements to represent the blocks can significantly speed up the method as the testing is done on such small number of pixels; finally (iv) this method can be applied to more than one kind of image forgery with similar results. To verify the performance of the proposed method, we tested it on the well-known Copy Move Forgery Detection database (CoMoFoD) using 5123 image variations of the database. Also, we compared our results with five previously published algorithms and found that the proposed method outperformed those algorithms even when the forged images were subjected to postprocessing manipulations and transformations.
C1 [alZahir, Saif] Concordia Univ, ECE Dept, 1455 De Maisonneuve Blvd W EV 5-139, Montreal, PQ H3G 1M8, Canada.
   [Hammad, Radwa] UNBC, Dept Comp Sci, Prince George, BC, Canada.
C3 Concordia University - Canada; University of British Columbia;
   University of Northern British Columbia
RP alZahir, S (corresponding author), Concordia Univ, ECE Dept, 1455 De Maisonneuve Blvd W EV 5-139, Montreal, PQ H3G 1M8, Canada.
EM saifalzahir@gmail.com; hammad@unbc.ca
OI alZahir, Saif/0000-0003-1955-5834
CR alZahir S, 2013, 26 IEEE CAN C EL COM
   alZahir S, 2015, 28 IEEE CAN C EL COM
   alZahir S, 2017, IEEE ICCE
   Amerini I, 2014, PROC SPIE, V9028, DOI 10.1117/12.2039509
   [Anonymous], 2006, Multimedia Security Technologies for Digital Rights, chapter Passive-Blind Image Forensics
   [Anonymous], 2010, SICHERHEIT
   [Anonymous], 2010, International Journal on Computer Science and Engineering
   Bayram S, 2008, IEEE W NY IMAG PROC
   Calsaverini RS Vicente R, 2009, LETT J EXPLORING FRO, V88, P1
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Durrani T. S., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1309
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Fridrich J, 2003, P DIG FRO RES WORKSH
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Sarode TK, 2014, P INT J COMPUTER APP, V90
   Shaid S., 2009, THESIS
   Shivakumar BL., 2010, Glob J Comput Sci, P61
   Sklar M., 1959, FONCTIONS REPARTITIO, V8, P229
   Sridevi M., 2012, COMPUTER SCI INFORM, P19
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Unser M, 2011, IEEE T IMAGE PROCESS, V20, P2705, DOI 10.1109/TIP.2011.2138147
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Wang W, 2009, LECT NOTES COMPUT SC, V5703, P308, DOI 10.1007/978-3-642-03688-0_27
   Warbhe A, 2012, IJCA P NAT C REC TRE, V6, P18
   Warbhe AD, 2012, NAT C INN PAR ENG TE, P37
   Wei Y, 2018, P IEEE INT C TRUST S
   Wu Y., 2018, IEEE WINT CONF APPL, P168, DOI DOI 10.1109/WACV.2018.00211
   Yang C.-K., 2004, ELECT LETT COMPUTER, V3, P1
   Zeng X, 2011, ELECTRON LETT, V47, P493, DOI 10.1049/el.2011.0778
   Zhang Z, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3463, DOI 10.1109/ICMLC.2008.4621003
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhou Z., 2001, 2010 2 INT C ED TEDN, V4, P242
NR 34
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28643
EP 28659
DI 10.1007/s11042-020-09502-4
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556182200007
DA 2024-07-18
ER

PT J
AU Jeon, Y
AF Jeon, Youchan
TI RF channel management scheme for seamless multimedia service in 802.11
   wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RF channel management; Handoff; IEEE 802; 11; WLAN
ID HANDOFF SCHEME; IEEE-802.11
AB The latest mobile devices such as smartphone, laptop, and tablet PC have supported IEEE 802.11 interfaces for broadband wireless data services. To extend the coverage in medium or large-scale areas such as office buildings, airports, campuses, or convention center, multiple access points (APs) need to be deployed. When a mobile station (MS) moves an AP to another, it typically experiences a long delay time for reconnection and communications to an AP due to the four sequential phases such as detection, channel scanning, authentication and reassociation. Consequently, the traditional WLAN is not adequate for mobile multimedia services such as real-time video conferences, augmented reality (AR), virtual reality (VR), etc., especially, in a mobile environment where requires to deploy several APs. This paper proposes a new handoff scheme where the channel scanning is completely omitted by having active MSs hold the channel consistently which is acquired at an initial connection stage to an AP even when it moves to a neighboring AP. Each AP changes its own channel periodically in a predetermined order while providing the orthogonality between the channels of the neighboring APs to mitigate interference. Therefore, seamless mobility can be supported for multimedia services by eliminating link layer handoff in the IEEE 802.11 WLAN. Moreover, any IEEE 802.11-based mobile devices can roam seamlessly without any modification. In other words, the proposed scheme can maintain backward compatibility with the legacy DCF and only requires the modification of APs. By adopting the periodic channel switching scheme, additionally, the proposed scheme can uniformly distribute all the MSs over the entire channels. This distribution can also reduce collision probability by decreasing the number of competing MSs over the same channel. Performance evaluation shows that the proposed scheme can provide low handoff latency and enhance throughput performance due to the decrease of collision probability.
C1 [Jeon, Youchan] Shinhan Univ, Sch IT Convergence Engn, Uijongbu, Gyeonggi Do, South Korea.
RP Jeon, Y (corresponding author), Shinhan Univ, Sch IT Convergence Engn, Uijongbu, Gyeonggi Do, South Korea.
EM ycjeon@shinhan.ac.kr
RI Jeon, Youchan/GON-7634-2022
CR [Anonymous], 2016, IEEE Std 802.11-2016, DOI [DOI 10.1109/IEEESTD.2016.7460875, 10.1109/IEEESTD.2016.7433918]
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Cardona N, 2017, COMM COMP COLCOM 201, P1, DOI [10.1109/ColComCon.2017.8088204, DOI 10.1109/COLCOMCON.2017.8088204]
   Chatzimisios P, 2002, 5TH IEEE INTERNATIONAL WORKSHOP ON NETWORKED APPLIANCES, PROCEEDINGS, P168
   Chatzimisios P, 2003, ELECTRON LETT, V39, P1358, DOI 10.1049/el:20030868
   Chen YS, 2008, IEEE T VEH TECHNOL, V57, P1126, DOI 10.1109/TVT.2007.907027
   Crow BP, 1997, IEEE COMMUN MAG, V35, P116, DOI 10.1109/35.620533
   Dwijaksara MH, 2017, P 32 ACM SIGAPP S AP, P634, DOI [10.1145/3019612.3019772, DOI 10.1145/3019612.3019772]
   Ghini V, 2005, COMPUT NETW, V49, P4, DOI 10.1016/j.comnet.2005.04.002
   Ghini V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P73, DOI 10.1109/ICC.2004.1312455
   Jeon Y, 2012, IEICE T COMMUN, VE95B, P345, DOI 10.1587/transcom.E95.B.345
   Jin S, 2014, IEEE T VEH TECHNOL, V63, P1408, DOI 10.1109/TVT.2013.2283914
   Kim I, 2011, IEEE T CONSUM ELECTR, V57, P386, DOI 10.1109/TCE.2011.5955171
   Lei T, 2016, INT SYM WIRELESS COM, P555, DOI 10.1109/ISWCS.2016.7600966
   Mishra A., 2003, Computer Communication Review, V33, P93, DOI 10.1145/956981.956990
   Mishra A, 2006, MOBICOM 2006, P170
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Purushothaman I, 2010, WIREL NETW, V16, P2049, DOI 10.1007/s11276-010-0243-5
   Ramani I, 2005, IEEE INFOCOM SER, P675
   Shin M, 2004, P ACM MOB C BOST MA, DOI [10.1145/990064.990076, DOI 10.1145/990064.990076]
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2017, INT J NETW MANAG, V27, DOI 10.1002/nem.1930
   Tewari BP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Velayos H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P3844, DOI 10.1109/ICC.2004.1313272
   Xiao Y, 2002, IEEE COMMUN LETT, V6, P355, DOI 10.1109/LCOMM.2002.802035
   Yang H, 2006, P IEEE, V94, P442, DOI 10.1109/JPROC.2005.862321
   Yao G, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154342
NR 27
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28207
EP 28224
DI 10.1007/s11042-020-09390-8
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554436800001
DA 2024-07-18
ER

PT J
AU Naiemi, F
   Ghods, V
   Khalesi, H
AF Naiemi, Fatemeh
   Ghods, Vahid
   Khalesi, Hassan
TI Scene text detection using enhanced Extremal region and convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text detection; Extremal region; ER method; CNN; Natural image
ID LOCALIZATION; RECOGNITION; COMPETITION
AB Text in scene images usually contains significant information. Text detection and recognition in the scene is important for a variety of advanced machine vision applications, such as image and video retrieval, automotive assistance, and multilingual translation. In particular, most text recognition systems require texts to be localized in images beforehand and this is a significant demand. The purpose of this study is to provide a method to detect texts in natural images. The proposed approach combines advantages of extremal region, ER, methods and classification of convolutional neural network, CNN. This significantly reduces the false positives and increases the accuracy of detection. The method of sliding windows is employed with different sizes in order to determine text candidates. Extraction of enhanced ERs is performed in three consecutive stages on three distinct color channels, R, G, and B. Then, the results are combined together by an add method. After grouping, the word candidates are classified to two classes of text and non-text sections by a CNN classifier. By applying non-maximum suppression (NMS) algorithm to the same words, words with the highest probability are selected. The average values of accuracy, recall, precision and F-measure of the proposed text detection model on the ICDAR2013 database are 0.893, 0.962, 0.948, and 0.955, respectively. The optimal cut point of the proposed method is 0.648, which has the highest average accuracy, 91.93%. The AUC of ROC and PR diagrams for the proposed model are 0.851 and 0.718, respectively. These results of AUC for ROC and PR curves showed an outstanding enhancement in comparison with the best detection rate of previous methods. Experimental results on the ICDAR2011, ICDAR2013 and ICDAR2015 databases also demonstrate that our algorithm outperforms the state-of-the-art scene text detection methods.
C1 [Naiemi, Fatemeh; Ghods, Vahid] Islamic Azad Univ, Semnan Branch, Dept Elect & Comp Engn, Semnan, Iran.
   [Khalesi, Hassan] Islamic Azad Univ, Garmsar Branch, Dept Elect & Comp Engn, Garmsar, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Ghods, V (corresponding author), Islamic Azad Univ, Semnan Branch, Dept Elect & Comp Engn, Semnan, Iran.
EM daneshjo_naimi@yahoo.com; v.ghods@semnaniau.ac.ir; khalesih@gmail.com
RI Naiemi, fatemeh/AAR-7469-2020
OI Naiemi, fatemeh/0000-0001-5571-8560
CR Aramaki Y, 2016, IEEE IMAGE PROC, P2901, DOI 10.1109/ICIP.2016.7532890
   Bai Nong, 2016, ARXIV160609002
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Baran R, 2018, ADV INTELL SYST COMP, V722, P42, DOI 10.1007/978-3-319-73888-8_8
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Bernardo D, 2013, SOFT COMPUT, V17, P2185, DOI 10.1007/s00500-013-1102-y
   Chao Wang, 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P290, DOI 10.1109/ICCCAS.2010.5581998
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   Han JW, 2022, IEEE T PATTERN ANAL, V44, P579, DOI 10.1109/TPAMI.2019.2933510
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   Jaderberg M., 2014, Deep Features for Text Spotting, P512
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Naiemi F, 2019, EFFICIENT CHARACTER, P1
   Narudin FA, 2016, SOFT COMPUT, V20, P343, DOI 10.1007/s00500-014-1511-6
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Neumann L, 2016, IEEE T PATTERN ANAL, V38, P1872, DOI 10.1109/TPAMI.2015.2496234
   Neumann L, 2013, IEEE I CONF COMP VIS, P97, DOI 10.1109/ICCV.2013.19
   Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144
   Neycharan JG, 2018, MULTIMED TOOLS APPL, V77, P7615, DOI 10.1007/s11042-017-4663-4
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith L. N., 2018, A disciplined approach to neural network hyper-parameters: Part 1 learning rate, batch size, momentum, and weight decay
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Sung MC, 2015, PROC INT CONF DOC, P426, DOI 10.1109/ICDAR.2015.7333797
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Yuan J, 2015, MULTIMED TOOLS APPL, V74, P859, DOI 10.1007/s11042-013-1702-7
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang J, 2011, SOFT COMPUT, V15, P1195, DOI 10.1007/s00500-010-0575-1
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhu W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182227
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 47
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27137
EP 27159
DI 10.1007/s11042-020-09318-2
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551375500004
DA 2024-07-18
ER

PT J
AU Nebili, W
   Farou, B
   Seridi, H
AF Nebili, Wafa
   Farou, Brahim
   Seridi, Hamid
TI Background subtraction using Artificial Immune Recognition System and
   Single Gaussian (AIRS-SG)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; SG; Background subtraction; Moving objects;
   Foreground pixel; AIRS
ID OBJECT DETECTION; VIDEO; MODEL
AB Background subtraction is an essential step in the video monitoring process. Several models have been proposed to differentiate background pixels from foreground pixels. However, most of these methods fail to distinguish them in highly dynamic environments. In this paper, we propose a new method robust and more efficient for distinguishing moving objects from static objects in dynamic scenes. For this purpose, we propose to use a bio-inspired approach based on the Artificial Immune Recognition System (AIRS) as a classification tool. AIRS separates antibodies, represented by the pixels of the background model, from the antigens that model foreground pixels representing moving objects. Each pixel is modeled by a feature vector containing the attributes of a Gaussian. Only the pixels classified as background are taken into account by the system and updated in the model. This combination has allowed to benefit from two advantages: the power of AIRS to provide an online update of system parameters and the ability of Gaussians to adapt to scene variations at the pixel level. To test the proposed approach, six videos representing the dynamic background category of the CDnet 2014 dataset are selected. Obtained results proved the effectiveness of this new process in terms of quality and complexity compared to other state-of-the-art methods.
C1 [Nebili, Wafa; Farou, Brahim; Seridi, Hamid] 8 Mai 1945 Guelma Univ, LabSTIC, POB 401, Guelma 24000, Algeria.
C3 Universite 8 Mai 1945 de Guelma
RP Nebili, W (corresponding author), 8 Mai 1945 Guelma Univ, LabSTIC, POB 401, Guelma 24000, Algeria.
EM nebili.wafa@univ-guelma.dz; farou.brahim@univ-guelma.dz;
   seridi.hamid@univ-guelma.dz
CR Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1
   Allebosch Gianni., 2015, Computer Vision, Imaging and Computer Graphics Theory and Applications, P433
   [Anonymous], 2010, ARXIV10031409
   [Anonymous], 2018, FOREGROUND SEGMENTAT
   [Anonymous], 2017, IEEE T CIRCUITS SYST
   [Anonymous], THESIS
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Cheung SCS, 2005, EURASIP J APPL SIG P, V2005, P2330, DOI 10.1155/ASP.2005.2330
   De Gregorio M., 2017, P ESANN, P453
   Dong E, 2018, 2018 IEEE INT C MECH, P1179
   El Baf F, 2007, SIGMAP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS, P153
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Farou B, 2017, ENG APPL ARTIF INTEL, V64, P1, DOI 10.1016/j.engappai.2017.05.013
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Haq Anwaar-ul, 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P529, DOI 10.1109/ISCC.2010.5546791
   He W, 2019, IEEE ACCESS, V7, P92329, DOI 10.1109/ACCESS.2019.2927745
   Hongwei X, 2016, LASER OPTOELECTRON P, V4, P3
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Ishibuchi H, 2008, IEEE C EVOL COMPUTAT, P2419, DOI 10.1109/CEC.2008.4631121
   Jianzhao C, 2017, 2017 9 INT C MOD ID, P133
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Krungkaew R., 2016, 2016 13 INT C ELECT, P1
   Laugraud B, 2018, J IMAGING, V4, DOI 10.3390/jimaging4070086
   Lee SH, 2018, ARXIV 1805 09277
   Li HR, 2019, APPL MATH SER B, V34, P1, DOI 10.1007/s11766-019-3706-1
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Lim L. A., 2018, ARXIV180801477
   López-Rubio E, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500563
   Lu XQ, 2014, IEEE IMAGE PROC, P3268, DOI 10.1109/ICIP.2014.7025661
   Ma CY, 2019, J VIS COMMUN IMAGE R, V60, P426, DOI 10.1016/j.jvcir.2019.03.009
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2010, NEURAL COMPUT APPL, V19, P179, DOI 10.1007/s00521-009-0285-8
   Martins I, 2017, IB C PATT REC IM AN, P50
   Men Y, 2016, VIDEO ENG, V24, P5
   Meng GF, 2014, PROC CVPR IEEE, P3890, DOI 10.1109/CVPR.2014.497
   Miron A, 2015, INT CONF SYST SIGNAL, P273, DOI 10.1109/IWSSIP.2015.7314229
   Mondejar-Guerra V, 2019, BRIT MACH VIS C BMVC
   Ramírez-Alonso G, 2016, NEUROCOMPUTING, V175, P990, DOI 10.1016/j.neucom.2015.04.118
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sehairi K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023025
   Srivastava S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P60, DOI 10.1109/AVSS.2011.6027295
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Wang B., 2014, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P395
   Wang HY, 2003, ICIP 2003, V1, pI
   Wang KF, 2018, IEEE ACCESS, V6, P15505, DOI 10.1109/ACCESS.2018.2812880
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Watkins A., 2004, Genetic Programming and Evolvable Machines, V5, P291, DOI 10.1023/B:GENP.0000030197.83685.94
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xu Y, 2015, IEEE INT CONF RFID, P1, DOI 10.1109/RFID.2015.7113066
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu TM, 2019, IEEE ACCESS, V7, P14671, DOI 10.1109/ACCESS.2019.2893771
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhao M, 2002, PROC SPIE, V4861, P325, DOI 10.1117/12.456333
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 64
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26099
EP 26121
DI 10.1007/s11042-020-08935-1
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547247600002
DA 2024-07-18
ER

PT J
AU Chattopadhyay, AK
   Nag, A
   Singh, JP
   Singh, AK
AF Chattopadhyay, Arup Kumar
   Nag, Amitava
   Singh, Jyoti Prakash
   Singh, Amit Kumar
TI A verifiable multi-secret image sharing scheme using XOR operation and
   hash function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-secret image sharing; Verifiable; Hash function; XOR
ID VISUAL CRYPTOGRAPHY; EFFICIENT
AB In a secret image sharing (SIS) scheme, a dealer (the data owner or a trusted third-party) encodes a secret image into some share images and distributes them among some participants such that each participant receives exactly one share. Most of the secret image sharing schemes assume a trusted dealer and participants. They do not use any verification of the share images while they are presented for secret reconstruction. In this article, we propose a verifiable multi-secret image sharing scheme using Boolean operations and a secure hash function. We considernsecret images for sharing and convert each secret image to a complete noisy image by using a secure hash function, XOR operations, and a specially designed pseudo-random image-matrix generator function. Then, we use XOR operations to generate the share images. The hash function calls are chained in a unique way to enable reconstruction and verification at a low cost for the secret images. The use of hash function also ensures that secrecy of share images and secret images remains consistent. The experimental results and security analysis prove that the scheme is secure and verifiable.
C1 [Chattopadhyay, Arup Kumar] Inst Engn & Management, Kolkata, W Bengal, India.
   [Nag, Amitava] Cent Inst Technol Kokrajhar, Kokrajhar, Assam, India.
   [Singh, Jyoti Prakash; Singh, Amit Kumar] Natl Inst Technol Patna, Patna, Bihar, India.
C3 Institute of Engineering & Management (IEM), Kolkata; National Institute
   of Technology (NIT System); National Institute of Technology Patna
RP Chattopadhyay, AK (corresponding author), Inst Engn & Management, Kolkata, W Bengal, India.
EM ardent.arup@gmail.com; amitava.nag@cit.ac.in; jps@nitp.ac.in;
   amit.singh@nitp.ac.in
RI Chattopadhyay, Arup Kumar/AAR-5145-2020; Nag, Amitava/C-5421-2016;
   Singh, Jyoti Prakash/I-4953-2016; Singh, Amit Kumar/D-1300-2015
OI Nag, Amitava/0000-0003-4408-7307; Singh, Jyoti
   Prakash/0000-0002-3742-7484; Singh, Amit Kumar/0000-0001-7359-2068
CR Chattopadhyay AK, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P1025, DOI 10.1109/UEMCON.2018.8796568
   Chattopadhyay AK, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P1374, DOI 10.1109/IEMCON.2018.8614998
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen D, 2019, IEEE ACCESS, V7, P107104, DOI 10.1109/ACCESS.2019.2929090
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chen YR, 2017, MULTIMED TOOLS APPL, V76, P1721, DOI 10.1007/s11042-015-3143-y
   Chen YC, 2013, DIGIT SIGNAL PROCESS, V23, P1496, DOI 10.1016/j.dsp.2013.05.014
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Chor B., 1985, 26th Annual Symposium on Foundations of Computer Science (Cat. No.85CH2224-4), P383, DOI 10.1109/SFCS.1985.64
   Das A, 2010, APPL MATH LETT, V23, P993, DOI 10.1016/j.aml.2010.04.024
   Dehkordi MH, 2008, COMPUT COMMUN, V31, P1777, DOI 10.1016/j.comcom.2007.11.014
   Dehkordi MH, 2008, INFORM SCIENCES, V178, P2262, DOI 10.1016/j.ins.2007.11.031
   Dehkordi MH, 2008, COMPUT STAND INTER, V30, P187, DOI 10.1016/j.csi.2007.08.004
   Dehkordi MH, 2019, IET INFORM SECUR, V13, P343, DOI 10.1049/iet-ifs.2018.5306
   dela Cruz R, 2013, CRYPTOGR COMMUN, V5, P67, DOI 10.1007/s12095-012-0076-4
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Guo C, 2018, MULTIMED TOOLS APPL, V77, P19569, DOI 10.1007/s11042-017-5412-4
   Harn L, 2013, SECURITY COMMUNICATI, V7, P950
   Harn L, 2009, DESIGN CODE CRYPTOGR, V52, P15, DOI 10.1007/s10623-008-9265-8
   Hu CQ, 2012, THEOR COMPUT SCI, V445, P52, DOI 10.1016/j.tcs.2012.05.006
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kandar S, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102430
   Kanso A, 2018, J VIS COMMUN IMAGE R, V56, P245, DOI 10.1016/j.jvcir.2018.09.018
   Lin PY, 2015, INFORM SCIENCES, V301, P61, DOI 10.1016/j.ins.2014.12.046
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Liu YX, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1084-7
   Liu YJ, 2015, INT J COMMUN SYST, V28, P1282, DOI 10.1002/dac.2760
   Liu YX, 2018, INFORM SCIENCES, V453, P21, DOI 10.1016/j.ins.2018.04.043
   Mashhadi S, 2015, INFORM SCIENCES, V294, P31, DOI 10.1016/j.ins.2014.08.046
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   OU D, 2015, SIGNAL PROCESS, V108, P604, DOI DOI 10.1016/J.SIGPRO.2014.10.011
   Prasetyo H, 2019, MULTIMED TOOLS APPL, V78, P24837, DOI 10.1007/s11042-019-7710-5
   Prasetyo H, 2019, IEEE ACCESS, V7, P37473, DOI 10.1109/ACCESS.2019.2902853
   Qu DH, 2015, J VIS COMMUN IMAGE R, V29, P46, DOI 10.1016/j.jvcir.2015.01.017
   Rajabi B, 2019, INFORM SCIENCES, V501, P655, DOI 10.1016/j.ins.2018.11.004
   Reyad Z., 2016, Appl.Math. Inf. Sci., V10, P1283
   Shao J, 2014, INFORM SCIENCES, V278, P104, DOI 10.1016/j.ins.2014.03.025
   Sheikhi-Garjan M, 2019, IET INFORM SECUR, V13, P278, DOI 10.1049/iet-ifs.2018.5174
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Verma OP, 2020, ARAB J SCI ENG, V45, P2395, DOI 10.1007/s13369-019-03992-7
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Wu TY, 2011, J SYST SCI COMPLEX, V24, P186, DOI 10.1007/s11424-011-8408-6
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Zhao JJ, 2007, COMPUT STAND INTER, V29, P138, DOI 10.1016/j.csi.2006.02.004
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 51
TC 9
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35051
EP 35080
DI 10.1007/s11042-020-09174-0
EA JUL 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000546222500005
DA 2024-07-18
ER

PT J
AU Chakraborty, BK
   Bhuyan, MK
AF Chakraborty, Biplab Ketan
   Bhuyan, M. K.
TI Image specific discriminative feature extraction for skin segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin segmentation; Adaptive discriminative analysis; Dynamic region
   growing
ID FACE SEGMENTATION; ALGORITHM
AB In recent times, the majority of colour-based skin detection methods used skin modelling in different colour spaces, and they are capable of skin classification at a pixel level. However, the accuracy of these methods is significantly affected by different issues, such as the presence of skin-like colours in scene background, variations in skin pigmentation, scene illumination, etc. Recent developments show that the discriminating power of a colour-based skin classifier can be increased by employing texture and spatial features. However, we observed that discriminability between skin and non-skin regions does not follow any statistics, and the discrimination is extremely image specific. In this paper, a novel adaptive discriminative analysis (ADA) is proposed to extract most discriminant features between skin and non-skin regions from an image itself in an unsupervised manner. Experimental results for standard databases show that the proposed method can efficiently segment out skin pixels in the presence of skin-like background colours.
C1 [Chakraborty, Biplab Ketan] Sankhyasutra Labs Pvt Ltd, Bangalore, Karnataka, India.
   [Bhuyan, M. K.] IIT Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Chakraborty, BK (corresponding author), Sankhyasutra Labs Pvt Ltd, Bangalore, Karnataka, India.
EM ketanbiplab@gmail.com
RI Bhuyan, Manoj Kumar/D-1562-2012
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], P NAT C COMM SEPT
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chakraborty BK, 2017, PATTERN RECOGN LETT, V88, P33, DOI 10.1016/j.patrec.2017.01.005
   Chakraborty BK, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2133, DOI 10.1109/WiSPNET.2016.7566519
   Chakraborty BK, 2015, PROCEEDINGS OF THE 2015 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P246, DOI 10.1109/RAICS.2015.7488422
   Chakraborty BK, 2016, P 10 IND C COMP VIS
   Chen L, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P615, DOI 10.1109/ICCCAS.2002.1180694
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W, 2016, MULTIMED TOOLS APPL, V75, P839, DOI 10.1007/s11042-014-2328-0
   Dan Xu, 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P952, DOI 10.1109/ROBIO.2011.6181410
   Dumitrescu CM, 2013, ADV INTELL SYST, V187, P59
   Fouad RM, 2019, IEEE ACCESS, V7, P76513, DOI 10.1109/ACCESS.2019.2922304
   Han JW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P237
   Hettiarachchi R, 2016, J VIS COMMUN IMAGE R, V41, P123, DOI 10.1016/j.jvcir.2016.09.011
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Ikonen L, 2007, PATTERN RECOGN LETT, V28, P604, DOI 10.1016/j.patrec.2006.10.010
   Jiang ZW, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P366, DOI 10.1109/FSKD.2007.518
   Jie Yang, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P687
   Jones D, 2012, AHA MOMENT: A SCIENTIST'S TAKE ON CREATIVITY, P81
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553733
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kawulok M, 2013, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2013.6738767
   Khan R, 2010, IEEE IMAGE PROC, P4613, DOI 10.1109/ICIP.2010.5651638
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Ladicky L, 2009, P IEEE ICCV
   Lei Y, 2017, IEEE T MULTIMEDIA, V19, P740, DOI 10.1109/TMM.2016.2638204
   Li B, 2007, PATTERN RECOGN, V40, P3621, DOI 10.1016/j.patcog.2007.04.018
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Y, 2017, IET COMPUT VIS, V11, P550, DOI 10.1049/iet-cvi.2016.0295
   Ma CH, 2018, IEEE GLOB CONF CONSU, P168, DOI 10.1109/GCCE.2018.8574747
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Naji S, 2019, ARTIF INTELL REV, V52, P1041, DOI 10.1007/s10462-018-9664-9
   Nalepa J, 2014, ADV INTEL SOFT COMPU, V242, P79, DOI 10.1007/978-3-319-02309-0_8
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NR, 2005, IEEE T FUZZY SYST, V13, P517, DOI 10.1109/TFUZZ.2004.840099
   Pan Ng, 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P213, DOI 10.1109/CICSyN.2011.54
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sawicki DJ, 2015, IET IMAGE PROCESS, V9, P751, DOI 10.1049/iet-ipr.2014.0859
   Shih H, 2019, IEEE T EMERG TOP COM, V1, P1
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Tan WR, 2012, IEEE T IND INFORM, V8, P138, DOI 10.1109/TII.2011.2172451
   Trindade P., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P71, DOI 10.1109/MFI.2012.6343032
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Xiaojin Zhu, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P446, DOI 10.1109/AFGR.2000.840673
   Xu T, 2013, IET IMAGE PROCESS, V7, P751, DOI 10.1049/iet-ipr.2012.0657
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 52
TC 3
Z9 3
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 18981
EP 19004
DI 10.1007/s11042-020-08762-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000558544500005
DA 2024-07-18
ER

PT J
AU Hemida, O
   He, HJ
AF Hemida, Omer
   He, Hongjie
TI A self-recovery watermarking scheme based on block truncation coding and
   quantum chaos map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile watermarking; Block truncation coding; Quantum chaos; Recovery
   performance
ID EMBEDDING FRAGILE WATERMARKING; TAMPER DETECTION; IMAGE AUTHENTICATION;
   LOCALIZATION
AB To take into account the invisibility, recovery quality, detection ability, and security, a new digital image fragile watermarking method based on block truncation coding (BTC) and quantum chaos map is proposed. In this method generates the authentication watermark for each 4x4 block and generates the recovery watermark for each 2x2 block by block truncation coding. For each block, the block truncation coding is used to classify the image blocks into smooth blocks and rough blocks. For different blocks, recovery data can be generated by allocating fewer bits to the smooth blocks and more bits to the rough blocks to encoding the block content. Quantum chaos map is used to generate the block mapping sequence for embedding recovery watermark to improve the shortcoming of watermarking such as small keyspace and low security. The experimental results show that the proposed scheme improves the quality of watermarked and recovered images. Additionally, this approach achieves higher security than the existing methods, under different attacks, such as general tampering, collage attack, content-only, and a hybrid attack.
C1 [Hemida, Omer; He, Hongjie] Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Hemida, O (corresponding author), Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
EM omerharoun1@yahoo.com; hjhe@swjtu.cn
OI haraon, omer/0000-0002-1669-7696
CR [Anonymous], 1999, P S CONT SEC DAT HID
   Behnia S, 2012, TEL NETW STRAT PLANN, P1
   Benrhouma O, 2015, NONLINEAR DYNAM, V79, P1817, DOI 10.1007/s11071-014-1777-3
   Betancourth GP, 2012, C HUM SYST INTERACT, P168, DOI 10.1109/HSI.2012.32
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Edupuganti VG, 2011, INTELL AUTOM SOFT CO, V17, P257, DOI 10.1080/10798587.2011.10643147
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J., 1999, P IEEE INT C IM PROC, V3, P792, DOI DOI 10.1109/ICIP.1999.817228
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Hemida O, 2018, MULTIMED TOOLS APPL
   Hemida O, 2017, ASIAPAC SIGN INFO PR, P846, DOI 10.1109/APSIPA.2017.8282151
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CT, 2004, IEE P-VIS IMAGE SIGN, V151, P460, DOI 10.1049/ip-vis:20040812
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Nyeem H, 2016, MULTIMED TOOLS APPL, V75, P15849, DOI 10.1007/s11042-015-2893-x
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Piper A, 2013, IET INFORM SECUR, V7, P300, DOI 10.1049/iet-ifs.2010.0059
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Shi H, 2017, MULTIMED TOOLS APPL, V76, P6941, DOI 10.1007/s11042-016-3328-z
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2_1
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yaoran Huo, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P608, DOI 10.1109/ICITIS.2010.5689517
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zhang Hong-bin, 2004, Acta Electronica Sinica, V32, P196
NR 37
TC 19
Z9 20
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18695
EP 18725
DI 10.1007/s11042-020-08727-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800064
DA 2024-07-18
ER

PT J
AU Su, ZY
   Li, J
   Chang, J
   Song, CF
   Xiao, YF
   Wan, J
AF Su, Zhenyang
   Li, Jing
   Chang, Jun
   Song, Chengfang
   Xiao, Yafu
   Wan, Jun
TI Learning spatial-temporally regularized complementary kernelized
   correlation filters for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Spatial-temporal regularization; Correlation filter;
   Multi-kernel learning
ID OBJECT TRACKING
AB Despite excellent performance shown by spatially regularized discriminative correlation filters (SRDCF) for visual tracking, some issues remain open that hinder further boosting their performance: first, SRDCF utilizes multiple training images to formulate its model, which makes it unable to exploit the circulant structure of the training samples in learning, leading to high computational burden; second, SRDCF is unable to efficiently exploit the powerfully discriminative nonlinear kernels, further negatively affecting its performance. In this paper, we present a novel spatial-temporally regularized complementary kernelized CFs (STRCKCF) based tracking approach. First, by introducing spatial-temporal regularization to the filter learning, the STRCKCF formulates its model with only one training image, which can not only facilitate exploiting the circulant structure in learning, but also reasonably approximate the SRDCF with multiple training images. Furthermore, by incorporating two types of kernels whose matrices are circulant, the STRCKCF is able to fully take advantage of the complementary traits of the color and HOG features to learn a robust target representation efficiently. Besides, our STRCKCF can be efficiently optimized via the alternating direction method of multipliers (ADMM). Extensive evaluations on OTB100 and VOT2016 visual tracking benchmarks demonstrate that the proposed method achieves favorable performance against state-of-the-art trackers with a speed of 40fpson a single CPU. Compared with SRDCF, STRCKCF provides a 8 x speedup and achieves a gain of 5.5% AUC score on OTB100 and 8.4% EAO score on VOT2016.
C1 [Su, Zhenyang; Li, Jing; Chang, Jun; Song, Chengfang; Xiao, Yafu; Wan, Jun] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Su, Zhenyang] Huanggang Normal Univ, Dept Digital Media Technol, Huangzhou 438000, Peoples R China.
C3 Wuhan University; Huanggang Normal University
RP Li, J (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
EM leejingcn@whu.edu.cn
RI wu, jd/IST-2336-2023
OI Wan, Jun/0000-0002-9961-7902
FU National Nature Science Foundation of China [41201404]; Fundamental
   Research Funds for the Central Universities of China [2042018gf0008]
FX This work was supported in part by the National Nature Science
   Foundation of China (41201404) and the Fundamental Research Funds for
   the Central Universities of China (2042018gf0008).
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2007, Computer Vision
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen W, 2016, NEUROCOMPUTING, V214, P607, DOI 10.1016/j.neucom.2016.06.048
   Chen Z., 2015, Comput. Sci., V53, P68
   Chen ZJ, 2017, IEEE T CYBERNETICS, V47, P3706, DOI 10.1109/TCYB.2016.2577718
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Fan JQ, 2018, IEEE ACCESS, V6, P56526, DOI 10.1109/ACCESS.2018.2872691
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Lee H, 2018, IEEE WINT CONF APPL, P1170, DOI 10.1109/WACV.2018.00133
   Li C, 2019, ARXIV190801442
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin YT, 2019, IEEE ACCESS, V7, P99441, DOI 10.1109/ACCESS.2019.2930550
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Qi Y., 2018, NEUROCOMPUTING
   Qi YW, 2020, IEEE T SYST MAN CY-S, V50, P1442, DOI 10.1109/TSMC.2018.2801284
   Qi YK, 2019, AAAI CONF ARTIF INTE, P8835
   Qi YK, 2018, IEEE T IMAGE PROCESS, V27, P3857, DOI 10.1109/TIP.2018.2797482
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Su ZY, 2020, FRONT COMPUT SCI-CHI, V14, P417, DOI 10.1007/s11704-018-8116-1
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Tang M, 2018, PROC CVPR IEEE, P4874, DOI 10.1109/CVPR.2018.00512
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yang J, 2016, COMPUT VIS IMAGE UND, V153, P100, DOI 10.1016/j.cviu.2016.02.003
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P479, DOI 10.1109/TIP.2018.2868561
   Zhang KH, 2018, PATTERN RECOGN, V83, P185, DOI 10.1016/j.patcog.2018.05.017
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2018, IEEE T IMAGE PROCESS, V27, P2676, DOI 10.1109/TIP.2017.2781304
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zheng Y, 2019, IEEE T NEURAL NETWOR
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
NR 65
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25171
EP 25188
DI 10.1007/s11042-020-09028-9
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544843700006
DA 2024-07-18
ER

PT J
AU Lee, S
   Lee, C
AF Lee, Sanghun
   Lee, Chulhee
TI Revisiting spatial dropout for regularizing convolutional neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network regularization; Convolutional neural network; Spatial dropout;
   Deep learning
AB Overfitting is one of the most challenging problems in deep neural networks with a large number of trainable parameters. To prevent networks from overfitting, the dropout method, which is a strong regularization technique, has been widely used in fully-connected neural networks. In several state-of-the-art convolutional neural network architectures for object classification, however, dropout was partially or not even applied since its accuracy gain was relatively insignificant in most cases. Also, the batch normalization technique reduced the need for the dropout method because of its regularization effect. In this paper, we show that conventional element-wise dropout can be ineffective for convolutional layers. We found that dropout between channels in the CNNs can be functionally similar to dropout in the FCNNs, and spatial dropout can be an effective way to take advantage of the dropout technique for regularizing. To prove our points, we conducted several experiments using the CIFAR-10 and CIFAR-100 databases. For comparison, we only replaced the dropout layers with spatial dropout layers and kept all other hyperparameters and methods intact. DenseNet-BC with spatial dropout showed promising results (3.32% error rates with CIFAR-10, 3.0 M parameters) compared to other existing competitive methods.
C1 [Lee, Sanghun; Lee, Chulhee] Yonsei Univ, Dept Elect & Elect Engn, 134 Shinchon Dong, Seoul, South Korea.
C3 Yonsei University
RP Lee, C (corresponding author), Yonsei Univ, Dept Elect & Elect Engn, 134 Shinchon Dong, Seoul, South Korea.
EM chulhee@yonsei.ac.kr
RI Lee, SangHun/GPW-6306-2022
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2017R1E1A2A01079495]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (2017R1E1A2A01079495).
CR Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fortunato M., 2017, Bayesian recurrent neural networks
   Gal Y, 2016, ADV NEURAL INFORM PR, P1019, DOI DOI 10.48550/ARXIV.1512.05287
   Ghiasi G, 2018, ADV NEUR IN, V31
   Gross Sam, 2016, Facebook AI Res.
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton G. E., 2012, 12070580 ARXIV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G., 2017, group, V3, P11
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Yanping, 2018, Advances in Neural Information Processing Systems
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Khan SH, 2019, NEURAL NETWORKS, V110, P82, DOI 10.1016/j.neunet.2018.09.009
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 27
TC 27
Z9 29
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34195
EP 34207
DI 10.1007/s11042-020-09054-7
EA JUN 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000542142900001
DA 2024-07-18
ER

PT J
AU Videnovik, M
   Trajkovik, V
   Kionig, LV
   Vold, T
AF Videnovik, Maja
   Trajkovik, Vladimir
   Kionig, Linda Vibeke
   Vold, Tone
TI Increasing quality of learning experience using augmented reality
   educational games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality educational games; Quality of experience of learning;
   Game-based learning; Interactive learning environments
ID USER ACCEPTANCE; DESIGN
AB Adequate pedagogical approaches for integration of technology in the learning process create new opportunities for improving the quality of teaching and learning experiences, raising students' interest and motivation for the classroom activities at the same time. Game-based learning implemented with different technologies can utilize students' energy and enthusiasm for educational purposes. In order to increase the quality of experience of the learning process, elements of popular games (e.g., mobile games and augmented reality games) should be used in the educational context. This paper proposes methodological guideline that can be used for the integration of games in education. The methodological guideline defines the two steps process of creating educational games starting from students' attitudes and needs, and then incorporates educational outcomes. As a case-study augmented reality educational games platform was designed in order to illustrate the possibilities and benefits of the proposed approach.
C1 [Videnovik, Maja] Ctr Innovat & Digital Educ DIG ED, Solunska Glava 3, Skopje 1000, North Macedonia.
   [Trajkovik, Vladimir] Ss Cyril & Methodius Univ, Fac Comp Sci & Engn, Rugjer Boshkovikj 16, Skopje 1000, North Macedonia.
   [Kionig, Linda Vibeke; Vold, Tone] Inland Norway Univ Appl Sci, POB 400, N-2418 Elverum, Norway.
C3 Saints Cyril & Methodius University of Skopje; Inland Norway University
   of Applied Sciences
RP Videnovik, M (corresponding author), Ctr Innovat & Digital Educ DIG ED, Solunska Glava 3, Skopje 1000, North Macedonia.
EM maja@dig-ed.org; trvlado@finki.ukim.mk; linda.kionig@inn.no;
   tone.vold@inn.no
RI Hidayat, Ima Kusumawati/ABF-6870-2021; Trajkovik, Vladimir/K-9758-2019
OI Hidayat, Ima Kusumawati/0000-0002-3387-9213; Videnovik,
   Maja/0000-0002-9859-5051; Trajkovik, Vladimir/0000-0001-8103-8059
CR Agrawal A, 2014, ELEC COMP C, P2014, DOI 10.1109/ECTC.2014.6897579
   Annetta Leonard., 2012, SCI SCOPE, P54
   Bacca Jorge., 2014, Augmented reality trends in education: a systematic review of research and applications
   Barma S., 2015, International Journal of Serious Games, V2, DOI DOI 10.17083/IJSG.V2I2.66
   Barrow J, 2019, P VISUAL
   Bellotti F, 2011, PROCEEDINGS OF THE 5TH EUROPEAN CONFERENCE ON GAMES BASED LEARNING, P26
   Bennett A, 2011, 33 EV PULL LECT
   Burton Erin Peters, 2011, Journal of Technology and Teacher Education, V19, P303
   Cerqueira CS, 2012, HYP TEL P WORLD C ED, P2816
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Costa MC, 2020, INFORMATION, V11, DOI 10.3390/info11030127
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Dede C, 2012, DIGITAL TEACHING PLA, P282
   Dunleavy M, 2014, TECHTRENDS, V58, P28, DOI 10.1007/s11528-013-0717-2
   Elmqaddem N, 2019, INT J EMERG TECHNOL, V14, P234, DOI 10.3991/ijet.v14i03.9289
   Hainey T, 2016, COMPUT EDUC, V102, P202, DOI 10.1016/j.compedu.2016.09.001
   Hamari J, 2019, INT J HUM-COMPUT INT, V35, P804, DOI 10.1080/10447318.2018.1497115
   Holden C, 2014, TECHTRENDS, V58, P42, DOI 10.1007/s11528-013-0719-0
   Huizenga J, 2009, J COMPUT ASSIST LEAR, V25, P332, DOI [10.1111/J.1365-2729.2009.00316.x, 10.1111/j.1365-2729.2009.00316.x]
   Karakus M., 2019, EURASIA J MATH SCI T, V15, pem1755, DOI [10.29333/ejmste/103904, DOI 10.29333/EJMSTE/103904]
   Kearney M, 2012, RES LEARN TECHNOL, V20, DOI 10.3402/rlt.v20i0.14406
   Klopfer E, 2008, ETR&D-EDUC TECH RES, V56, P203, DOI 10.1007/s11423-007-9037-6
   Klopfer Eric, 2010, New Dir Youth Dev, V2010, P85, DOI 10.1002/yd.378
   Koivisto J, 2014, COMPUT HUM BEHAV, V35, P179, DOI 10.1016/j.chb.2014.03.007
   Lee DY, 2013, COMPUT EDUC, V61, P193, DOI 10.1016/j.compedu.2012.10.001
   Lee K., 2012, InSight: A Journal of Scholarly Teaching, V7, P31
   Lin HCK, 2015, INTERACT LEARN ENVIR, V23, P799, DOI 10.1080/10494820.2013.817435
   Lymbery J., 2012, Computers in New Zealand Schools, V24, P21
   Martin J, 2014, TECHTRENDS, V58, P35, DOI 10.1007/s11528-013-0718-1
   McClarty KL., 2012, Research Report
   Melles G, 2011, CODESIGN, V7, P143, DOI 10.1080/15710882.2011.630473
   Miller D.R., 2015, ISSUES TRENDS ED TEC, V3
   Nicholson S., 2018, Childhood Education, V94, P44, DOI DOI 10.1080/00094056.2018.1420363
   Nincarean D, 2013, PROCD SOC BEHV, V103, P657, DOI 10.1016/j.sbspro.2013.10.385
   Pedaste M, 2020, WHAT IS EFFECT USING
   Prensky M., 2007, DIGITAL GAME BASED L
   Quinn C., 2008, ELEARN MAGAZINE
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Sahin D, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103710
   Saidin NF., 2015, International education studies, V8, P1, DOI DOI 10.5539/IES.V8N13P1
   Spires HA, 2008, LA ANNETTA SERIOUS E
   Trajkovik V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202172
   Van Eck R., 2006, EDUCAUSE REV, V41, P16, DOI DOI 10.1145/950566.950596
   Videnovik Maja., 2018, 2018 17th International Conference on Information Technology Based Higher Education and Training (ITHET), Information Technology Based Higher Education and Training (ITHET), 2018 17th International Conference On, P1, DOI [DOI 10.1109/ITHET.2018.8424786, DOI 10.1109/ITHET.2018.8424777]
   Wali E., 2008, ALT J, V16, P41, DOI DOI 10.1080/09687760701850190
   Wang X, 2012, NEW YORK MAGAZINE EL
   Wei XD, 2015, COMPUT EDUC, V81, P221, DOI 10.1016/j.compedu.2014.10.017
   Wen Y, 2019, SMART COMPUT INTELL, P179, DOI 10.1007/978-981-13-8265-9_9
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yang YTC, 2012, COMPUT EDUC, V59, P365, DOI 10.1016/j.compedu.2012.01.012
   Zaibon S.B., 2010, GLOBAL LEARN, P1862
NR 51
TC 21
Z9 21
U1 6
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23861
EP 23885
DI 10.1007/s11042-020-09046-7
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539939100001
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhang, JD
   Xu, JB
   Zhu, LY
   Zhang, KP
   Liu, T
   Wang, DH
   Wang, X
AF Zhang, Jindong
   Xu, Jiabin
   Zhu, Linyao
   Zhang, Kunpeng
   Liu, Tong
   Wang, Donghui
   Wang, Xue
TI An improved MobileNet-SSD algorithm for automatic defect detection on
   vehicle body paint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data enhancement; Defect detection; Deep learning; Machine vision
AB In order to improve the efficiency and accuracy of manual vehicle paint defect detection, the computer vision technology and deep learning methods is used to achieve automatic detection of vehicle paint defects based on small samples in this study. The vehicle body paint defect image was collected in real time, and a new data enhancement algorithm was proposed to enhance the database for the over-fitting phenomenon caused by small sample data. Aiming at the defect characteristics inherent in vehicle paints, an improved MobileNet-SSD algorithm for automatic detection of paint defects is proposed by improving the feature layer of MobileNet-SSD network and optimizing the matching strategy of bounding box. The experimental results show that the improved MobileNet-SSD algorithm can detect the defects of six traditional body paint films with an accuracy rate of over 95%, which is 10% faster than the traditional SSD algorithm, and can realize real-time and accurate detection of body paint defects.
C1 [Zhang, Jindong; Xu, Jiabin; Zhang, Kunpeng; Liu, Tong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
   [Zhu, Linyao; Wang, Donghui; Wang, Xue] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM zhangjindong_100@163.com; 15843715316@163.com; Zhuly16@mails.jlu.edu.cn;
   zkp0113@sina.com; 15165434950@163.com; 1547976690@qq.com;
   892881066@qq.com
RI li, yao/IYJ-1364-2023; Liu, Gui/JHU-8707-2023; Yang, Ying/ABD-2481-2022
OI Zhang, Kunpeng/0000-0002-4299-9129
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies; National Natural Science Foundation of
   China [61872158]; Science and Technology Development Plan Project of
   Jilin Province [20190701019GH]; Fundamental Research Funds for the
   Central Universities; Jilin University [5157050847, 2017XYB252]
FX This work is supported by National Key Research and Development Program
   of China (2017YFB0102500), Natural Science Foundation of Jilin province
   (20170101133JC), Korea Foundation for Advanced Studies' International
   Scholar Exchange Fellowship for the academic year of 2017-2018, the
   National Natural Science Foundation of China (61872158), Science and
   Technology Development Plan Project of Jilin Province (20190701019GH),
   the Fundamental Research Funds for the Central Universities, and Jilin
   University (5157050847, 2017XYB252).
CR Armesto L, 2011, IEEE INT CONF ROBOT
   Chang F, 2019, MOBILE VISION INSPEC
   Edris MZB, 2015, Proceedings 5th IEEE International Conference on Control System, Computing and Engineering (ICCSCE 2015), P117, DOI 10.1109/ICCSCE.2015.7482169
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu HJ, 2014, MULTIMED TOOLS APPL, V69, P199, DOI 10.1007/s11042-012-1248-0
   Hua GL, 2018, J ENG-JOE, P1662, DOI 10.1049/joe.2018.8272
   Jawaid M, 2019, MICRO NANO TECHNOL, P1
   Jo YJ, 2018, IEEE ACCESS, V6, P1476, DOI [10.1109/ICI.2011.47, DOI 10.1109/ICI.2011.47]
   Kamani P, 2012, 2011 INTERNATIONAL CONFERENCE ON COMPUTER AND COMPUTATIONAL INTELLIGENCE (ICCCI 2011), P267
   Li YT, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091678
   Lin JH, 2018, INT J ADV MANUF TECH, V97, P573, DOI 10.1007/s00170-018-1894-0
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZF, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING (ICGSP 2018), P74, DOI 10.1145/3282286.3282300
   Lu ZS, 2018, J ENG-JOE, P1741, DOI 10.1049/joe.2018.8270
   Lv L, 2019, J ENG-JOE, P605, DOI 10.1049/joe.2018.9390
   Molina J, 2017, ROBOT CIM-INT MANUF, V48, P263, DOI 10.1016/j.rcim.2017.04.009
   Rao CP, 2020, INT J SPEECH TECHNOL, V23, P327, DOI 10.1007/s10772-020-09699-7
   Rebeggiani S, 2018, SURF TOPOGR-METROL, V6, DOI 10.1088/2051-672X/aabfb5
   Shang LD, 2018, INT CONF ADV COMMUN, P45, DOI 10.23919/ICACT.2018.8323642
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao X, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091575
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Wu SL, 2019, MULTIMED TOOLS APPL, V78, P34627, DOI 10.1007/s11042-019-08042-w
   Yan C, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P680, DOI 10.1109/ICNC.2015.7378072
   Zhang C, 2018, J ENG-JOE, P1415, DOI 10.1049/joe.2018.8275
   Zhang HW, 2018, PROCEEDINGS OF 2018 IEEE 7TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS), P170, DOI 10.1109/DDCLS.2018.8516094
   Zhang LL, 2018, J ENG-JOE, P1612, DOI 10.1049/joe.2018.8279
NR 27
TC 17
Z9 19
U1 12
U2 138
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23367
EP 23385
DI 10.1007/s11042-020-09152-6
EA JUN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538977700004
DA 2024-07-18
ER

PT J
AU Liu, DQ
   Wu, Z
   Sun, SR
AF Liu, Deqiang
   Wu, Zhong
   Sun, Shaorong
TI Study on Subway passenger flow prediction based on deep recurrent neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subway passenger flow; Passenger flow prediction; Deep recurrent neural
   network; Time series prediction
AB As the construction and management of subway transit system becomes increasingly mature, analyzing the passenger flow information of the normal transportation network and accurately predicting the passenger flow in a short time have become the core of subway transit system operation and management. However, it is difficult for traditional intelligent prediction algorithms to meet the high accuracy and fast response capabilities required for predicting passenger flow in a short time in unexpected situations. In order to improve the prediction performance, this paper proposes a time series prediction model based on deep recurrent neural network (DRNN). Using DRNN's unique memory function to capture the dynamic information of the time series, we can better learn the "trend" between data at different moments, so that we can more accurately predict the output at the next moment. The comparison among the case studies based on the measured data of subway passenger flow with time series characteristics, the traditional support vector machine and the neural network method, shows that DRNN prediction has the smallest overall deviation, small deviation fluctuation and good robustness.
C1 [Liu, Deqiang; Wu, Zhong; Sun, Shaorong] Univ Shanghai Sci & Technol, Business Sch, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Liu, DQ (corresponding author), Univ Shanghai Sci & Technol, Business Sch, Shanghai 200093, Peoples R China.
EM liudqusst@163.com
FU National Natural Science Foundation of China [71771151]
FX project supported by the National Natural Science Foundation of China
   (71771151)
CR Chai YC, 2016, CHIN CONT DECIS CONF, P7030, DOI 10.1109/CCDC.2016.7532264
   De Gooijer JG, 2006, INT J FORECASTING, V22, P443, DOI 10.1016/j.ijforecast.2006.01.001
   Dia H, 2001, EUR J OPER RES, V131, P253, DOI 10.1016/S0377-2217(00)00125-9
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Enjian Y, 2018, CHIN RAILW SCI, V02, P119
   Gensuo M, 2015, COMPUT ENG SCI, V37, P104
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Gregor K, 2015, PROCEEDING 32ND INT, P37
   Guo JY, 2019, IEEE ACCESS, V7, P42946, DOI 10.1109/ACCESS.2019.2907739
   Han Y, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090366
   Jie L, 2014, T INFO SAFETY, V32, P41
   Ma S, 2016, T INTEL SYST, V11, P728
   Pascanu R., 2013, NEUR NETWORKS, P1
   Sak H, 2014, INTERSPEECH, P338
   Shengwei Dong, 2013, STUDY SHORT TERM PAS
   Smith BL, 2002, TRANSPORT RES C-EMER, V10, P303, DOI 10.1016/S0968-090X(02)00009-8
   VanArem B, 1997, INT J FORECASTING, V13, P1, DOI 10.1016/S0169-2070(96)00695-4
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Wang H, 2016, J DALIAN JIAOTONG U, V37, P6
   Xiaoxue Y, 2016, COMPUT ENG APPL, V52, P227
   Zhu KE, 2019, IEEE ACCESS, V7, P142272, DOI 10.1109/ACCESS.2019.2944744
NR 21
TC 9
Z9 9
U1 9
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 18979
EP 18992
DI 10.1007/s11042-020-09088-x
EA JUN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000538196300003
DA 2024-07-18
ER

PT J
AU Bin, CZ
   Gu, TL
   Jia, ZH
   Zhu, GM
   Xiao, CH
AF Bin, Chenzhong
   Gu, Tianlong
   Jia, Zhonghao
   Zhu, Guimin
   Xiao, Cihan
TI A neural multi-context modeling framework for personalized attraction
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attraction recommendation; Multi-context modeling; Network
   representation learning; Trajectory mining
AB In attraction recommendation scenarios, how to model multifaceted tourism contexts so as to accurately learn tourist preferences and attraction tourism features is a keystone of generating personalized recommendations. However, most of existing works generally focused on modeling spatiotemporal contexts of historical travel trajectories to learn tourists' preferences, while neglected rich heterogeneous tourism side information, i.e., personal tourism constraints of tourists and tourism attributes of attractions. To this end, we propose a Neural Multi-context Modeling Framework (NMMF) to learn tourism feature representations of tourists and attractions by modeling multiple tourism contexts. Initially, we leverage a travel knowledge graph and massive original travelogues to construct the tourism attribute context of attractions and the travel trajectory context of tourists. Then, we design two context embedding models, named TKG2vec and Traj2vec, to model two kinds of context respectively. Both models learn feature vectors of tourist and attraction in contexts by elaborating neural networks to project each tourist and attraction into a uniform latent feature space. Finally, our framework integrates feature vectors derived from two models to acquire complete feature representations of tourists and attractions, and recommends personalized attractions by calculating the similarity between tourist and candidate attractions in the latent space. Experimental results on a real-world tourism dataset demonstrate our framework outperforms state-of-the-art methods in two personalized attraction recommendation tasks.
C1 [Bin, Chenzhong] Guilin Univ Elect Technol, Sch Informat & Commun, Guilin 541004, Peoples R China.
   [Bin, Chenzhong; Gu, Tianlong; Jia, Zhonghao; Zhu, Guimin] Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
   [Xiao, Cihan] Virginia Polytech Inst & State Univ, Sch Comp Sci, Blacksburg, VA 24061 USA.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology; Virginia Polytechnic Institute & State University
RP Bin, CZ (corresponding author), Guilin Univ Elect Technol, Sch Informat & Commun, Guilin 541004, Peoples R China.; Bin, CZ (corresponding author), Guilin Univ Elect Technol, Guangxi Key Lab Trusted Software, Guilin 541004, Peoples R China.
EM binchenzhong@guet.edu.cn; cctlgu@guet.edu.cn; 1090994959@qq.com;
   18770914075@163.com; borrisonxiao@gmail.com
RI bin, chen/HZI-0300-2023
OI Bin, Chenzhong/0000-0002-7200-0929; Gu, Tianlong/0000-0002-1662-7110
CR [Anonymous], 2012, ACM SIGSPATIAL
   [Anonymous], 2013, 1 INT C LEARN REPR I
   Bao J, 2015, GEOINFORMATICA, V19, P525, DOI 10.1007/s10707-014-0220-8
   Barkan Oren, 2016, IEEE INT WORKSHOP MA
   Bhargava P, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P130, DOI 10.1145/2736277.2741077
   Bin CZ, 2019, MULTIMED TOOLS APPL, V78, P35135, DOI 10.1007/s11042-019-08096-w
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Chang L, 2017, IEEE ACCESS, V5, P20898, DOI 10.1109/ACCESS.2017.2759139
   Chen CH, 2012, ACTIVATION AND DETOXIFICATION ENZYMES: FUNCTIONS AND IMPLICATIONS, P17, DOI 10.1007/978-1-4614-1049-2_3
   Cheng C., 2013, 23 INT JOINT C ART I
   Fang Q, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2842631
   Feng SS, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2069
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Kesorn K, 2017, IEEE ACCESS, V5, P26703, DOI 10.1109/ACCESS.2017.2778293
   Lan RS, 2020, IEEE T CYBERNETICS, V50, P1498, DOI 10.1109/TCYB.2018.2880290
   Le Quoc V., 2014, P INT C MACH LEARN I
   Li XT, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P433, DOI 10.1145/2766462.2767722
   Lian DF, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P231
   Lv MQ, 2016, NEUROCOMPUTING, V173, P1142, DOI 10.1016/j.neucom.2015.08.071
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Mikolov Tomas, 2013, NEURAL INFORM PROCES, P3111
   Oramas S, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2926718
   Palumbo E, 2018, LECT NOTES COMPUT SC, V11155, P117, DOI 10.1007/978-3-319-98192-5_22
   Palumbo E, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P32, DOI 10.1145/3109859.3109889
   Perozzi B., 2014, KDD, P701, DOI DOI 10.1145/2623330.2623732
   Quadrana M, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P130, DOI 10.1145/3109859.3109896
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Shen JG, 2016, NEUROCOMPUTING, V173, P789, DOI 10.1016/j.neucom.2015.08.030
   Shuhui Jiang, 2016, IEEE Transactions on Big Data, V2, P43, DOI 10.1109/TBDATA.2016.2541160
   Sun YP, 2018, LECT NOTES ARTIF INT, V11012, P463, DOI 10.1007/978-3-319-97304-3_36
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tay Y, 2017, AAAI CONF ARTIF INTE, P1243
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1835, DOI 10.1145/3178876.3186175
   Wang Z, 2014, AAAI CONF ARTIF INTE, P1112
   Yang C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1245, DOI 10.1145/3097983.3098094
   Yang SY, 2016, COMPUT ELECTR ENG, V54, P87, DOI 10.1016/j.compeleceng.2015.11.020
   Yin HZ, 2016, IEEE T KNOWL DATA EN, V28, P2566, DOI 10.1109/TKDE.2016.2580511
   Yin HZ, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P221
   Zhang D, 2018, IEEE TRANS BIG DATA
   Zhang W, 2018, INTERNATIONAL LOW IMPACT DEVELOPMENT CONFERENCE 2018: GETTING IN TUNE WITH GREEN INFRASTRUCTURE, P213
   Zhao WX, 2018, KNOWL INF SYST, V56, P559, DOI 10.1007/s10115-017-1107-4
   Zhou NN, 2016, IEEE T KNOWL DATA EN, V28, P1945, DOI 10.1109/TKDE.2016.2550436
NR 45
TC 9
Z9 9
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14951
EP 14979
DI 10.1007/s11042-019-08554-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900036
DA 2024-07-18
ER

PT J
AU Juneja, M
   Singh, S
   Agarwal, N
   Bali, S
   Gupta, S
   Thakur, N
   Jindal, P
AF Juneja, Mamta
   Singh, Shaswat
   Agarwal, Naman
   Bali, Shivank
   Gupta, Shubham
   Thakur, Niharika
   Jindal, Prashant
TI Automated detection of Glaucoma using deep learning convolution network
   (G-net)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma detection; Optic disc; Optic cup; Retinal fundus image; Neural
   network; Image segmentation
ID OPTIC CUP SEGMENTATION; FUNDUS IMAGES; DISC; DIAGNOSIS
AB Glaucoma is an ocular disease that is the leading cause of irreversible blindness due to an increased Intraocular pressure resulting in damage to the optic nerve of eye. A common method for diagnosing glaucoma progression is through examination of dilated pupil in the eye by expert ophthalmologist. But this approach is laborious and consumes a large amount of time, thus the issue can be resolved using automation by using the concept of machine learning. Convolution neural networks (CNN's) are well suited to resolve this class of problems as they can infer hierarchical information from the image which helps them to distinguish between glaucomic and non-glaucomic image patterns for diagnostic decisions. This paper presents an Artificially Intelligent glaucoma expert system based on segmentation of optic disc and optic cup. A Deep Learning architecture is developed with CNN working at its core for automating the detection of glaucoma. The proposed system uses two neural networks working in conjunction to segment optic cup and disc. The model was tested on 50 fundus images and achieved an accuracy of 95.8% for disc and 93% for cup segmentation.
C1 [Juneja, Mamta; Singh, Shaswat; Agarwal, Naman; Bali, Shivank; Gupta, Shubham; Thakur, Niharika; Jindal, Prashant] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Jindal, P (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM mamtajuneja@pu.ac.in; shaswats.007@gmail.com;
   namanagarwal8968@gmail.com; shivank565@gmail.com; sbhmguptal7@gmail.com;
   niharikathakur04@gmail.com; jindalp@pu.ac.in
OI Thakur, Niharika/0000-0002-4177-3750; Juneja, Mamta/0000-0002-2611-9005
CR Abdullah M, 2016, PEERJ, V4, DOI 10.7717/peerj.2003
   ALGAZI VR, 1985, INVEST OPHTH VIS SCI, V26, P1759
   Almazroa A, 2017, CLIN OPHTHALMOL, V11, P841, DOI 10.2147/OPTH.S117157
   [Anonymous], 2018, COMPUTERS ELECT ENG
   Arnay R, 2017, APPL SOFT COMPUT, V52, P409, DOI 10.1016/j.asoc.2016.10.026
   Bach M, 2001, EUR J OPHTHALMOL, V11, pS41, DOI 10.1177/112067210101102S05
   Bharkad S, 2017, BIOMED SIGNAL PROCES, V31, P483, DOI 10.1016/j.bspc.2016.09.009
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Chen XY, 2015, LECT NOTES COMPUT SC, V9351, P669, DOI 10.1007/978-3-319-24574-4_80
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Chrastek R., 2002, Bildverarbeitung fur die Medizin 2002, P263
   Garg G, 2018, CURR MED IMAGING, V14, P19, DOI 10.2174/1573405613666170504145842
   Garg N, 2018, INT CONF CLOUD COMP, P1, DOI 10.1109/CloudCom2018.2018.00017
   Goh KG, 2001, STUD FUZZ SOFT COMP, V60, P181
   Joshi GD, 2010, I S BIOMED IMAGING, P948, DOI 10.1109/ISBI.2010.5490144
   Kande GB, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P535
   Kaur R, 2018, MULTIMED TOOLS APPL, P1
   Kaur R, 2018, CURR MED IMAGING REV, V14, P238, DOI 10.2174/1573405613666161221164146
   KLEIN BEK, 1985, OPHTHALMOLOGY, V92, P1654
   Li HQ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P394
   Liu SP, 2011, J MED BIOL ENG, V31, P405, DOI 10.5405/jmbe.773
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Lu SJ, 2011, IEEE T MED IMAGING, V30, P2126, DOI 10.1109/TMI.2011.2164261
   Miri MS, 2015, IEEE T MED IMAGING, V34, P1854, DOI 10.1109/TMI.2015.2412881
   Pallawala PMDS, 2004, LECT NOTES COMPUT SC, V3022, P139
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sevastopolsky A., 2017, Pattern Recognition and Image Analysis, V27, P618, DOI 10.1134/S1054661817030269
   Sivaswamy J., 2015, JSM Biomedical Imaging Data Papers, V2, P1004
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Thakur N, 2018, BIOMED SIGNAL PROCES, V42, P162, DOI 10.1016/j.bspc.2018.01.014
   Thakur N, 2017, CURR MED IMAGING REV, V13, P99, DOI 10.2174/1573405612666160606124044
   Tobin KW, 2006, PROC SPIE, V6144, DOI 10.1117/12.641670
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wong DWK, 2008, IEEE ENG MED BIO, P2266, DOI 10.1109/IEMBS.2008.4649648
   Zahoor MN, 2017, IEEE ACCESS, V5, P12293, DOI 10.1109/ACCESS.2017.2723320
   Zhu XL, 2010, J DIGIT IMAGING, V23, P332, DOI 10.1007/s10278-009-9189-5
   Zilly JG, INT WORKSH MACH LEAR, P136
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 39
TC 70
Z9 70
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15531
EP 15553
DI 10.1007/s11042-019-7460-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900064
DA 2024-07-18
ER

PT J
AU Kwak, S
   Choe, J
   Seo, S
AF Kwak, Suhwan
   Choe, Jongin
   Seo, Sanghyun
TI Harmonic rendering for visual coherence on mobile outdoor AR environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Harmonic rendering; Outdoor illumination; Shadow
   generation
AB Rapid developments in augmented reality (AR) and related technologies have led to increasing interest in immersive content. AR environments are created by combining virtual 3D models with a real-world video background. It is important to merge these two worlds seamlessly if users are to enjoy AR applications, but, all too often, the illumination and shading of virtual objects is not consider the real world lighting condition or does not match that of nearby real objects. In addition, visual artifacts produced when blending real and virtual objects further limit realism. In this paper, we propose a harmonic rendering technique that minimizes the visual discrepancy between the real and virtual environments to maintain visual coherence in outdoor AR. To do this, we introduce a method of estimating and approximating the Sun's position and the sunlight direction to estimate the real sunlight intensity, as this is the most significant illumination source in outdoor AR and it provides a more realistic lighting environment for such content, reducing the mismatch between real and virtual objects.
C1 [Kwak, Suhwan; Choe, Jongin] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Seo, Sanghyun] Chung Ang Univ, Coll Art & Technol, Sch Comp Art, Anseong, South Korea.
C3 Chung Ang University; Chung Ang University
RP Seo, S (corresponding author), Chung Ang Univ, Coll Art & Technol, Sch Comp Art, Anseong, South Korea.
EM shkwak@cslab.cau.ac.kr; jongin@cglab.cau.ac.kr; sanghyun@cau.ac.kr
RI Sanghyun, Seo/ADZ-4404-2022
OI Sanghyun, Seo/0000-0002-4824-3517; Kwak, Suhwan/0000-0002-0793-3132
CR [Anonymous], 2005, EUROPEAN C VISUAL ME
   Boom BJ, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1686
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Farshad E, 2015, BMVC, P43
   Hollerer T., 2004, Mobile augmented reality. Telegeoinformatics: Location-Based Computing and Services, P21
   Iqbal Y, 1983, INTRO SOLAR RAD, DOI [10.1016/B978-0-12-373750-2.X5001-0, DOI 10.1016/B978-0-12-373750-2.X5001-0]
   Jensen T, 2006, GRAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P364
   Kanbara M, 2004, INT C PATT RECOG, P911, DOI 10.1109/ICPR.2004.1334407
   Kang DW, 2017, J REAL-TIME IMAGE PR, V13, P581, DOI 10.1007/s11554-016-0612-0
   Kang D, 2015, MULTIMED TOOLS APPL, V74, P245, DOI 10.1007/s11042-013-1759-3
   Kasapakis V, 2017, MULTIMED TOOLS APPL, V76, P9829, DOI 10.1007/s11042-016-3581-1
   Kolivand H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108334
   Liu YL, 2010, COMPUT ANIMAT VIRT W, V21, P321, DOI 10.1002/cav.357
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Mekni M., 2014, APPL COMPUTER SCI, P205
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Okura F, 2017, MULTIMED TOOLS APPL, V76, P2671, DOI 10.1007/s11042-015-3222-0
   Park JH, 2014, SECUR COMMUN NETW, V7, P1599, DOI 10.1002/sec.722
   Park J, 2017, J REAL-TIME IMAGE PR, V13, P571, DOI 10.1007/s11554-016-0640-9
   Parra L, 2016, MULTIMED TOOLS APPL, V75, P13271, DOI 10.1007/s11042-015-2745-8
   Reda I, 2004, SOL ENERGY, V76, P577, DOI 10.1016/j.solener.2003.12.003
   Sebillo M, 2016, MULTIMED TOOLS APPL, V75, P9609, DOI 10.1007/s11042-015-2955-0
   Seo S, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0357-8
   Seo S, 2015, MULTIMED TOOLS APPL, V74, P3317, DOI 10.1007/s11042-013-1835-8
   Shapley R., 1984, Prog Retin Res, V3, P263, DOI [10.1016/0278-4327(84)90011-7, DOI 10.1016/0278-4327(84)90011~7]
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   Yu L, 2016, MULTIMED TOOLS APPL, V75, P3199, DOI 10.1007/s11042-014-2430-3
NR 29
TC 1
Z9 1
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16141
EP 16154
DI 10.1007/s11042-019-7628-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600019
OA Bronze
DA 2024-07-18
ER

PT J
AU Pollastri, F
   Bolelli, F
   Paredes, R
   Grana, C
AF Pollastri, Federico
   Bolelli, Federico
   Paredes, Roberto
   Grana, Costantino
TI Augmenting data with GANs to segment melanoma skin lesions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Adversarial learning; Skin
   lesion segmentation
AB This paper presents a novel strategy that employs Generative Adversarial Networks (GANs) to augment data in the skin lesion segmentation task, which is a fundamental first step in the automated melanoma detection process. The proposed framework generates both skin lesion images and their segmentation masks, making the data augmentation process extremely straightforward. In order to thoroughly analyze how the quality and diversity of synthetic images impact the efficiency of the method, we remodel two different well known GANs: a Deep Convolutional GAN (DCGAN) and a Laplacian GAN (LAPGAN). Experimental results reveal that, by introducing such kind of synthetic data into the training process, the overall accuracy of a state-of-the-art Convolutional/Deconvolutional Neural Network for melanoma skin lesion segmentation is increased.
C1 [Pollastri, Federico; Bolelli, Federico; Grana, Costantino] Univ Modena & Reggio Emilia, DIEF, Modena, Italy.
   [Paredes, Roberto] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
C3 Universita di Modena e Reggio Emilia; Universitat Politecnica de
   Valencia
RP Bolelli, F (corresponding author), Univ Modena & Reggio Emilia, DIEF, Modena, Italy.
EM federico.pollastri@unimore.it; federico.bolelli@unimore.it;
   rparedes@dsic.upv.es; costantino.grana@unimore.it
RI Grana, Costantino/B-4555-2012
OI Grana, Costantino/0000-0002-4792-2358; POLLASTRI,
   FEDERICO/0000-0001-8036-1559; Bolelli, Federico/0000-0002-5299-6351
CR [Anonymous], 2017, CORR
   [Anonymous], 2013, RECTIFIER NONLINEARI
   [Anonymous], 2015, Dermoscopy image analysis, DOI DOI 10.1201/B19107
   [Anonymous], 2015, P INT C LEARNING REP
   Antoniou Antreas, 2017, ARXIV171104340
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bolelli F, 2018, INT C PATT REC
   Bolelli F, 2017, LECT NOTES COMPUT SC, V10485, P48, DOI 10.1007/978-3-319-68548-9_5
   Denton Emily, 2015, Advances in Neural Information Processing Systems
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Kittler H, 2002, LANCET ONCOL, V3, P159, DOI 10.1016/S1470-2045(02)00679-4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan ZY, 2015, INT C INTEL HUM MACH, DOI 10.1109/IHMSC.2015.220
   Lipkus AH, 1999, J MATH CHEM, V26, P263, DOI 10.1023/A:1019154432472
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mishkin D., 2016, ICLR
   Navab N., 2018, ARXIV180404338
   Neff T, 2017, PROC OAGM ARW JOINT, P140, DOI [10.3217/978-3-85125-524-9-30, 10.3217/978-3-85125- 524-9-30., DOI 10.3217/978-3-85125-524-9-30]
   Pollastri F., 2018, 31 INT S COMP BAS ME
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Yuan Y, 2017, ARXIV170305165
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 28
TC 52
Z9 54
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15575
EP 15592
DI 10.1007/s11042-019-7717-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900066
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Choi, US
   Cho, SJ
   Kim, JG
   Kang, SW
   Kim, HD
AF Choi, Un Sook
   Cho, Sung Jin
   Kim, Jin Gyoung
   Kang, Sung Won
   Kim, Han Doo
TI Color image encryption based on programmable complemented maximum length
   cellular automata and generalized 3-D chaotic cat map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Programmable cellular automata; Complemented CA;
   PC-MLCA; 3-D chaotic cat map; PRNG; Color image
ID HYBRID GENETIC ALGORITHM; PERMUTATION; SYSTEM
AB With the advent of cloud and social networking sites, information security has become a major issue. Images are the most searched, uploaded, and shared data in multimedia. However, existing encryption algorithms such as DES and AES may not be suitable for image encryption because digital images have large data size, high redundancy, and strong correlation between pixels. To overcome these problems, we propose a new color image encryption algorithm using a generalized three-dimensional chaotic cat map and a programmable complemented maximum length cellular automata (PC-MLCA) in this paper. Also we design the PC-MLCA which can be implemented by hardware and has a long period and can output a nonlinear sequence as a pseudo random number generator (PRNG). The key sequence generated by the proposed PC-MLCA changes the pixel value of the original image to an unpredictable value. And to resist noise and delete attacks we design and use a generalized chaotic cat map that can perform different modular operations to simultaneously change the pixel position of color images horizontally, vertically as well as R, G, and B color components.
C1 [Choi, Un Sook] Tongmyong Univ, Dept Informat & Commun Engn, Busan, South Korea.
   [Cho, Sung Jin; Kim, Jin Gyoung; Kang, Sung Won] Pukyong Natl Univ, Dept Appl Math, Busan, South Korea.
   [Kim, Han Doo] Inje Univ, Inst Basic Sci, Gyeongnam, South Korea.
   [Kim, Han Doo] Inje Univ, Dept Comp Engn, Gyeongnam, South Korea.
C3 Tongmyong University; Pukyong National University; Inje University; Inje
   University
RP Cho, SJ (corresponding author), Pukyong Natl Univ, Dept Appl Math, Busan, South Korea.
EM choies@tu.ac.kr; sjcho@pknu.ac.kr
FU Research Grant of Pukyong National University(2019)
FX This paper is the revised and expanded version of a paper entitled
   "Color Image Encryption based on PC-MLCA and 3-D Chaotic Cat Map"
   presented at 2019 4th International Conference on Computer and
   Communication Systems (ICCCS), Singapore, Singapore, 23-25 February
   2019. This work was supported by a Research Grant of Pukyong National
   University(2019).
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Broumandnia A, 2019, FUTURE GENER COMP SY, V99, P489, DOI 10.1016/j.future.2019.04.005
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chaudhuri P. P., 1997, ADDITIVE CELLULAR AU, V1
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cho SJ, 2007, IEEE T COMPUT AID D, V26, P1720, DOI 10.1109/TCAD.2007.895784
   Dagadu JC, 2017, J MULTIDISCIPLINARY, V4, P8096
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Han CY, 2019, OPTIK, V181, P779, DOI 10.1016/j.ijleo.2018.12.178
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Jeong H.S., 2018, P INT C UB FUT NETW, P801
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu H, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI [10.1016/j.image.2013.09.006, DOI 10.1016/J.IMAGE.2013.09.006]
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu J, 2017, OPT COMMUN, V396, P174, DOI 10.1016/j.optcom.2017.03.049
   Mohamed FK, 2014, OPT LASER TECHNOL, V64, P145, DOI 10.1016/j.optlastec.2014.05.012
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tralic D, 2016, RADIOENGINEERING, V25, P548, DOI 10.13164/re.2016.0548
   Wang XY, 2016, OPT LASER ENG, V82, P79, DOI 10.1016/j.optlaseng.2015.12.006
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2016, IEEE T CYBERNETICS, V46, P2622, DOI 10.1109/TCYB.2015.2483621
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
NR 33
TC 18
Z9 18
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22825
EP 22842
DI 10.1007/s11042-020-09033-y
EA MAY 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000536433700001
DA 2024-07-18
ER

PT J
AU Yang, XC
   Wang, TS
   Ji, GL
AF Yang, Xichen
   Wang, Tianshu
   Ji, Genlin
TI A local structural information representation method for image quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No reference; Image quality assessment; Gray-scale fluctuations;
   Structural information
AB Image is a typical example of visual data, and its quality inevitably affects its application. Hence, measuring image quality accurately is a beneficial task. In practical application, there are different image types e.g. natural image and screen content image (SCIs). And the distortion types contained in images are various. Most image quality assessment (IQA) methods concentrate on a single image type with limited distortion types. In this paper, we present a no-reference IQA method which can accurately measure the quality for both natural image and SCI, and is robust for various distortion types. Human visual system is sensitive to the changes in image structural information which are usually caused by image quality degradation. Therefore, the new method employs local structural information representation for IQA. We first analyze the gray-scale fluctuation of each pixel in four detection directions to obtain four gray-scale fluctuation maps (GFMs) and one gray-scale fluctuation direction map (GFD). And then, the structural features extracted from GFMs and GFD are used for representing local structural information. Finally, the mapping function from the features to image subjective scores is trained by support vector regression (SVR). The experimental results on the public databases demonstrate that SVR is suitable for IQA and the proposed method can accurately predict the quality of both natural images and SCIs with various distortion types.
C1 [Yang, Xichen; Ji, Genlin] Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan Rd, Nanjing 210046, Peoples R China.
   [Wang, Tianshu] Nanjing Univ Chinese Med, Sch Artificial Intelligence & Informat Technol, 138 Xianlin Rd, Nanjing 210023, Peoples R China.
C3 Nanjing Normal University; Nanjing University of Chinese Medicine
RP Yang, XC (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan Rd, Nanjing 210046, Peoples R China.
EM xichen_yang@njnu.edu.cn
OI Yang, Xichen/0000-0002-9949-4818
FU National Natural Science Foundation of China [41971343]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 41971343.
CR Amiri SA, 2018, MULTIMED TOOLS APPL, V77, P787, DOI 10.1007/s11042-016-4246-9
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P31581, DOI 10.1007/s11042-018-6112-4
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Freitas PG, 2018, IEEE T MULTIMEDIA, V20, P3353, DOI 10.1109/TMM.2018.2839529
   Freitas PG, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2018, IEEE T VIS COMPUT GR, V24, P2689, DOI 10.1109/TVCG.2017.2771284
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, NEUROCOMPUTING, V196, P140, DOI 10.1016/j.neucom.2015.11.101
   Hu B, 2018, IET COMPUT VIS, V12, P796, DOI 10.1049/iet-cvi.2017.0478
   Hu MQ, 2017, IEEE T IMAGE PROCESS, V26, P4871, DOI 10.1109/TIP.2017.2717185
   Jerripothula KR, 2018, IEEE T MULTIMEDIA, V20, P2466, DOI 10.1109/TMM.2018.2798294
   Ji H, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P14, DOI 10.1109/ISISE.2008.282
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li YQ, 2018, IEEE T PATTERN ANAL, V40, P1526, DOI 10.1109/TPAMI.2017.2710186
   Liu HH, 2020, IEEE T IMAGE PROCESS, V29, P641, DOI 10.1109/TIP.2019.2933743
   Liu LX, 2019, IEEE T MULTIMEDIA, V21, P2305, DOI 10.1109/TMM.2019.2900941
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu YT, 2018, IEEE T MULTIMEDIA, V20, P379, DOI 10.1109/TMM.2017.2729020
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Song XD, 2017, IEEE T MULTIMEDIA, V19, P1351, DOI 10.1109/TMM.2017.2654123
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   VQEG, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Wang SQ, 2018, IEEE T CIRC SYST VID, V28, P1, DOI 10.1109/TCSVT.2016.2602764
   Wang SQ, 2016, IEEE J EM SEL TOP C, V6, P532, DOI 10.1109/JETCAS.2016.2598756
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang JC, 2018, ELECTRON LETT, V54, P754, DOI 10.1049/el.2018.0958
   Yang XC, 2019, NEURAL COMPUT APPL, V31, P6643, DOI 10.1007/s00521-018-3497-y
   Yang XC, 2018, COMPUT ELECTR ENG, V70, P349, DOI 10.1016/j.compeleceng.2016.08.014
   Yang XC, 2018, APPL OPTICS, V57, P3268, DOI 10.1364/AO.57.003268
   Yang XC, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064357
   Yao JC, 2018, IET IMAGE PROCESS, V12, P872, DOI 10.1049/iet-ipr.2017.0209
   Yeh CH, 2019, IEEE T CIRC SYST VID, V29, P3393, DOI 10.1109/TCSVT.2018.2879094
   Yue GH, 2018, IEEE T MULTIMEDIA, V20, P2722, DOI 10.1109/TMM.2018.2807589
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 52
TC 1
Z9 1
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22797
EP 22823
DI 10.1007/s11042-020-09022-1
EA MAY 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789300001
DA 2024-07-18
ER

PT J
AU Ilyas, M
   Othmani, A
   Nait-ali, A
AF Ilyas, Muhammad
   Othmani, Alice
   Nait-ali, Amine
TI Computer-aided prediction of hearing loss based on auditory perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Auditory perception; Computer-aided; Healthcare technology; Health
   informatics; Predictive intelligence; Age estimation; Hearing loss
   prediction; Level of hearing loss prediction
ID NOISE EXPOSURE; ASSOCIATION; IMPAIRMENT; HEALTH
AB Hearing loss is the principle cause behind hearing impairment and deafness around the world. It is a significant health problem affecting our world today and it is growing exponentially among young and adults due to aging, hearing impairment, listening to music and noise exposure. Treatment options for hearing loss are very limited and it can only be controlled by taking precautions in the early stages. Thus, proper education is required to spread awareness among people to use hearing protections, reduce exposure to loud music and other risk factors. In this paper, we present a computer-aided method to predict and then prevent hearing loss. Three predictive models (human age estimation, prediction of hearing loss and level of hearing loss) based on auditory perception are presented. Our predictive model of human age estimation is very robust with a Mean Absolute Error (MAE) value of 4.1 years, while the accuracy of the second predictive model of hearing loss is equal to 94% and the third predictive model of the level of hearing loss present an accuracy of 90%. Our computer-aided prediction methods of hearing loss is found very promising and can be used in real application systems and 503 subjects participated to conduct the experiment.
C1 [Ilyas, Muhammad; Othmani, Alice; Nait-ali, Amine] Univ Paris Est, UPEC, LISSI, F-94400 Vitry Sur Seine, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Ilyas, M (corresponding author), Univ Paris Est, UPEC, LISSI, F-94400 Vitry Sur Seine, France.
EM ilyaskhantmg@hotmail.com
CR Attias J, 2004, CLIN OTOLARYNGOL, V29, P635, DOI 10.1111/j.1365-2273.2004.00866.x
   Bogoch II, 2005, CAN J PUBLIC HEALTH, V96, P69, DOI 10.1007/BF03404022
   BRONZAFT A, 1996, NUTR HLTH REV, V78, P2
   CDC (Centers for Disease Control and Prevention), 1998, CRIT REC STAND OCC N
   Chung JH, 2005, PEDIATRICS, V115, P861, DOI 10.1542/peds.2004-0173
   Cristell M, 1998, SCAND AUDIOL, V27, P219, DOI 10.1080/010503998420522
   Cruickshanks KJ, 1998, JAMA-J AM MED ASSOC, V279, P1715, DOI 10.1001/jama.279.21.1715
   Dawes P, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0119616
   Fortunato S, 2016, ACTA OTORHINOLARYNGO, V36, P155, DOI 10.14639/0392-100X-993
   Hilgert N, 2009, CURR MOL MED, V9, P546, DOI 10.2174/156652409788488775
   Hoffman H.J., 2016, JAMA OTOLARYNGOLOGY
   Ilyas M, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON BIO-ENGINEERING FOR SMART TECHNOLOGIES (BIOSMART)
   Lin FR, 2011, ARCH NEUROL-CHICAGO, V68, P214, DOI 10.1001/archneurol.2010.362
   Lopez D, 2011, MATURITAS, V69, P359, DOI 10.1016/j.maturitas.2011.05.006
   Lusk SL, 2002, ARCH ENVIRON HEALTH, V57, P273, DOI 10.1080/00039890209601410
   MUHAMMAD I, 2018, INT WORKSH PRED INT
   Niskar AS, 2001, PEDIATRICS, V108, P40, DOI 10.1542/peds.108.1.40
   Schmuziger N, 2006, INT J AUDIOL, V45, P46, DOI 10.1080/14992020500377089
   SERGEI K, VALIDITY RELIABILITY
   Serra MR, 2005, INT J AUDIOL, V44, P65, DOI 10.1080/14992020400030010
   Torre P, 2005, J SPEECH LANG HEAR R, V48, P473, DOI 10.1044/1092-4388(2005/032)
   UHLMANN RF, 1989, JAMA-J AM MED ASSOC, V261, P1916, DOI 10.1001/jama.261.13.1916
   World Health Organization, 2015, DEAFN HEAR LOSS FACT
NR 23
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15765
EP 15789
DI 10.1007/s11042-020-08910-w
EA MAY 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000534982800005
DA 2024-07-18
ER

PT J
AU Li, R
   Pan, ZB
   Wang, Y
AF Li, Rui
   Pan, Zhibin
   Wang, Yang
TI Correlation-based initialization algorithm for tensor-based HSI
   compression methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tensor decomposition (TD); Hyperspectral image compression;
   Initialization
ID HYPERSPECTRAL IMAGE CLASSIFICATION; CONTRAST ENHANCEMENT ALGORITHM;
   WAVELET TRANSFORM; LOW-RANK; REPRESENTATION; DECOMPOSITION
AB Tensor decomposition (TD) is widely used in hyperspectral image (HSI) compression. we note that the correlation in HSI may be helpful to improve the HSI compression performance of TD methods. The initialization of factor matrix in TD can determine the HSI compression performance. Meanwhile, it is worth noting that HSI is highly correlated in bands. In this paper, we propose a method called correlation-based TD initialization algorithm. By analyzing the optimization of TD, we find that the initialization of TD can be well approximated by a matrix decomposition. Thus, we adopt the mean band of HSI to approximate the initialization of TD. In accordance with the SVD result of the reference band, the initialized factor matrices of TD are produced. We compare our methods with other compression methods. The experimental results reveal that our correlation-based TD initialization method is capable of significantly reducing the computational cost of TD while keeping the initialization quality and compression performance.
C1 [Li, Rui; Pan, Zhibin] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin; Wang, Yang] Xi An Jiao Tong Univ, Res Inst, Hangzhou 311215, Zhejiang, Peoples R China.
   [Wang, Yang] Xian Univ Technol, Dept Informat Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University; Xi'an University
   of Technology
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.; Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Res Inst, Hangzhou 311215, Zhejiang, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU National Science Foundation of China [U1903213]; Major Science Program
   of Xiaoshan District, Hangzhou, Zhejiang [2018225]; Zhejiang Provincial
   Natural Science Foundation of China [LQY19F010001]
FX This work is supported in part by the National Science Foundation of
   China (Grant No. U1903213), the Major Science Program of Xiaoshan
   District, Hangzhou, Zhejiang (Grant No. 2018225) and the Zhejiang
   Provincial Natural Science Foundation of China (Grant No. LQY19F010001).
CR Akbari H, 2010, IEEE T BIO-MED ENG, V57, P2011, DOI 10.1109/TBME.2010.2049110
   Bader B. W., 2015, MATLAB TENSOR TOOLBO
   Cichocki A, 2008, IEEE SIGNAL PROC MAG, V25, P142, DOI 10.1109/MSP.2008.4408452
   Coutinho VD, 2017, IEEE T IMAGE PROCESS, V26, P2296, DOI 10.1109/TIP.2017.2679442
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   Du YH, 2014, I S BIOMED IMAGING, P1, DOI 10.1109/ISBI.2014.6867794
   Fang LY, 2017, IEEE T INSTRUM MEAS, V66, P1646, DOI 10.1109/TIM.2017.2664480
   Fernandes S, 2017, PR INT CONF DATA SC, P99, DOI 10.1109/DSAA.2017.83
   Jiang B, 2019, IEEE T CYBERNETICS, V49, P1417, DOI 10.1109/TCYB.2018.2802934
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kanmani M, 2017, MULTIMED TOOLS APPL, V76, P20989, DOI 10.1007/s11042-016-4030-x
   Karami A, 2012, IEEE J-STARS, V5, P444, DOI 10.1109/JSTARS.2012.2189200
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Li J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070759
   Ma Y, 2018, IEEE GEOSCI REMOTE S, V15, P587, DOI 10.1109/LGRS.2018.2800080
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Mei XG, 2018, NEUROCOMPUTING, V275, P2783, DOI 10.1016/j.neucom.2017.11.052
   Mengfei Zhang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P141, DOI 10.1007/978-3-319-48890-5_14
   Narmadha D, 2014, INT J ELECT COMPUTER, V4, P411
   Noor SSM, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112644
   Rajan K, 2016, INT ARAB J INF TECHN, V13, P435
   Shi C, 2017, INFORM SCIENCES, V420, P49, DOI 10.1016/j.ins.2017.08.051
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang Y, 2017, IEEE GEOSCI REMOTE S, V14, P2457, DOI 10.1109/LGRS.2017.2771212
   Xue J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020193
   Zeng WJ, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.035019
   Zhang EL, 2016, NEUROCOMPUTING, V178, P71, DOI 10.1016/j.neucom.2015.07.114
   Zhang LF, 2015, NEUROCOMPUTING, V147, P358, DOI 10.1016/j.neucom.2014.06.052
NR 30
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21925
EP 21940
DI 10.1007/s11042-020-09007-0
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532899600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gu, YC
   Zeng, ZT
   Chen, HB
   Wei, J
   Zhang, YQ
   Chen, BH
   Li, YQ
   Qin, YJ
   Xie, Q
   Jiang, ZR
   Lu, Y
AF Gu, Yuchong
   Zeng, Zitao
   Chen, Haibin
   Wei, Jun
   Zhang, Yaqin
   Chen, Binghui
   Li, Yingqin
   Qin, Yujuan
   Xie, Qing
   Jiang, Zhuoren
   Lu, Yao
TI MedSRGAN: medical images super-resolution using generative adversarial
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical images; Super-resolution (SR); Deep learning; Generative
   adversarial networks (GAN)
ID FOLLOW-UP; CT; NODULES; CANCER
AB Super-resolution (SR) in medical imaging is an emerging application in medical imaging due to the needs of high quality images acquired with limited radiation dose, such as low dose Computer Tomography (CT), low field magnetic resonance imaging (MRI). However, because of its complexity and higher visual requirements of medical images, SR is still a challenging task in medical imaging. In this study, we developed a deep learning based method called Medical Images SR using Generative Adversarial Networks (MedSRGAN) for SR in medical imaging. A novel convolutional neural network, Residual Whole Map Attention Network (RWMAN) was developed as the generator network for our MedSRGAN in extracting the useful information through different channels, as well as paying more attention on meaningful regions. In addition, a weighted sum of content loss, adversarial loss, and adversarial feature loss were fused to form a multi-task loss function during the MedSRGAN training. 242 thoracic CT scans and 110 brain MRI scans were collected for training and evaluation of MedSRGAN. The results showed that MedSRGAN not only preserves more texture details but also generates more realistic patterns on reconstructed SR images. A mean opinion score (MOS) test on CT slices scored by five experienced radiologists demonstrates the efficiency of our methods.
C1 [Gu, Yuchong; Zeng, Zitao; Chen, Haibin; Jiang, Zhuoren; Lu, Yao] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.
   [Wei, Jun] Univ Michigan, Dept Radiol, Ann Arbor, MI 48109 USA.
   [Zhang, Yaqin; Chen, Binghui; Li, Yingqin; Qin, Yujuan; Xie, Qing] Sun Yat Sen Univ, Affiliated Hosp 5, Dept Radiol, Zhuhai, Peoples R China.
   [Lu, Yao] Guangdong Prov Key Lab Computat Sci, Guangzhou, Peoples R China.
C3 Sun Yat Sen University; University of Michigan System; University of
   Michigan; Sun Yat Sen University
RP Chen, HB; Jiang, ZR; Lu, Y (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Peoples R China.; Lu, Y (corresponding author), Guangdong Prov Key Lab Computat Sci, Guangzhou, Peoples R China.
EM chenhb63@mail.sysu.edu.cn; jiangzhr3@mail.sysu.edu.cn;
   luyao23@mail.sysu.edu.cn
RI zheng, yuan/JCN-7781-2023
FU National Key RAMP;D Program of China [2018YFC1704206, 2016YFB0200602];
   NSFC [81971691, 81801809, 81830052, 81827802, U1811461, 11401601];
   Science and Technology Program of Guangzhou [20180420053]; Science and
   Technology Innovative Project of Guangdong Province [2016B030307003,
   2015B010110003, 2015B020233008]; Science and Technology Planning Project
   of Guangdong Province [2017B020210001]; Guangzhou Science and Technology
   Creative Project [201604020003]; Guangdong Province Key Laboratory of
   Computational Science Open Grant [2018009]; Construction Project of
   Shanghai Key Laboratory of Molecular Imaging [18DZ2260400]; China
   postdoctoral science foundation [2019M653185]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018YFC1704206, Grant 2016YFB0200602, in part by the NSFC
   under Grant 81971691, Grant 81801809, Grant 81830052, Grant 81827802,
   Grant U1811461, and Grant 11401601, in part by the Science and
   Technology Program of Guangzhou under Grant 20180420053, in part by the
   Science and Technology Innovative Project of Guangdong Province under
   Grant 2016B030307003, Grant 2015B010110003, and Grant 2015B020233008, in
   part by the Science and Technology Planning Project of Guangdong
   Province under Key Grant 2017B020210001, in part by the Guangzhou
   Science and Technology Creative Project under Key Grant 201604020003, in
   part by the Guangdong Province Key Laboratory of Computational Science
   Open Grant 2018009, in part by the Construction Project of Shanghai Key
   Laboratory of Molecular Imaging 18DZ2260400, and in part by China
   postdoctoral science foundation No.2019M653185.
CR [Anonymous], IEEE transactions on pattern analysis and machine intelligence
   [Anonymous], 2018, ARXIV180606397CSCV
   [Anonymous], 2008, J MED SCREEN
   [Anonymous], 2017, P 25 ANN M ISMRM
   [Anonymous], 2018, ARXIV180700734CSLG
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Chen YH, 2018, I S BIOMED IMAGING, P739
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Christe A, 2011, AM J ROENTGENOL, V197, P623, DOI 10.2214/AJR.10.5288
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hunink MGM, 2003, J CLIN INVEST, V111, P1612, DOI 10.1172/JCI200318842
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang GF, 2019, LECT NOTES COMPUT SC, V11769, P801, DOI 10.1007/978-3-030-32226-7_89
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karadi RL, 2006, THORAX, V61, P548
   Kavanagh J, 2018, RADIOLOGY, V289, P218, DOI 10.1148/radiol.2018180053
   Kingma D. P., 2014, arXiv
   Kouamé D, 2009, I S BIOMED IMAGING, P249, DOI 10.1109/ISBI.2009.5193030
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Libby DM, 2006, CHEST, V129, P1039, DOI 10.1378/chest.129.4.1039
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lingala SG, 2011, IEEE T MED IMAGING, V30, P1042, DOI 10.1109/TMI.2010.2100850
   Manjunath M, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.155
   Mardani M, 2019, IEEE T MED IMAGING, V38, P167, DOI 10.1109/TMI.2018.2858752
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mohammed RHA, 2011, RHEUMATOL INT, V31, P667, DOI 10.1007/s00296-009-1325-5
   Rampinelli C, 2013, CANCER IMAGING, V12, P548, DOI 10.1102/1470-7330.2012.0049
   Ravishankar S, 2011, IEEE T MED IMAGING, V30, P1028, DOI 10.1109/TMI.2010.2090538
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ulus S, 2016, POL J RADIOL, V81, P407, DOI 10.12659/PJR.897570
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yasuda S, 2005, ANN NUCL MED, V19, P167, DOI 10.1007/BF02984601
   Zhao Z, 2018, ARXIV180804256
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
NR 48
TC 40
Z9 43
U1 4
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21815
EP 21840
DI 10.1007/s11042-020-08980-w
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532672800003
DA 2024-07-18
ER

PT J
AU Caballero, D
AF Caballero, Daniel
TI Radial textures: a new algorithm to analyze meat quality on MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture features; Computer vision algorithms; Data mining; Iberian loin;
   Food technology
ID COMPUTER VISION TECHNIQUES; SENSORY CHARACTERISTICS; IBERIAN HAM;
   PREDICT; FEATURES; TRAITS; CLASSIFICATION; PARAMETERS; REGRESSION;
   ATTRIBUTES
AB Magnetic Resonance Imaging (MRI) was introduced as an alternative to destructive methods for determining the quality parameters of meat products, since MRI is a non-destructive, non-ionizing, and innocuous technique. The use of MRI is linked to the use of computer vision algorithms and data mining techniques. Thus, the success of MRI could not be understood without referring to the implementation of powerful algorithms to handle all data generated. In this study, a new texture algorithm was developed in order to obtain new features based on the radial distribution of the textures from MRI. This new algorithm is called Radial Texture Algorithm (RTA) and it was compared with four classical texture features approaches. The results obtained allow describing the semantic context of the texture features for this new algorithm and the relationship among the features from this algorithm and the classical approaches. Besides, the results obtained by means of these computer vision algorithms were correlated with the results obtained by means of physico-chemical and sensory parameters of the Iberian loins. All of computer vision algorithms achieved correlation coefficients higher than 0.500, noting that RTA reached the highest correlation coefficients in almost all cases. These high correlation coefficients confirm the proposed algorithm as an alternative to the other computational texture features approaches in order to compute the physico-chemical and sensory parameters of meat products in an accurate, fast, non-destructive and efficient way.
C1 [Caballero, Daniel] Univ Copenhagen, Chemometr & Analyt Technol, Dept Food Sci, Rolighedsvej 26, DK-1958 Frederiksberg C, Denmark.
   [Caballero, Daniel] Univ Extremadura, Comp Sci Dept, Res Inst Meat & Meat Prod IproCar, Av Ciencias S-N, ES-10003 Caceres, Spain.
C3 University of Copenhagen; Universidad de Extremadura
RP Caballero, D (corresponding author), Univ Copenhagen, Chemometr & Analyt Technol, Dept Food Sci, Rolighedsvej 26, DK-1958 Frederiksberg C, Denmark.; Caballero, D (corresponding author), Univ Extremadura, Comp Sci Dept, Res Inst Meat & Meat Prod IproCar, Av Ciencias S-N, ES-10003 Caceres, Spain.
EM dcaballero@unex.es
RI Caballero, Daniel/ABE-1854-2020
OI Caballero, Daniel/0000-0003-2822-0323
FU Junta de Extremadura [PO17017]; "Junta de Extremadura" (Regional
   Government Board. Research Project) [IB16089]; "Junta de Extremadura"
   (economic support for research group) [GRU15113, GRU15173]; FEDER-MICCIN
   Infrastructure Research Project [UNEX-10-1E-402]
FX Daniel Caballero thanks the "Junta de Extremadura" for the post-doctoral
   grant (PO17017). The author wishes to acknowledge the funding received
   for this research from both the "Junta de Extremadura" (Regional
   Government Board. Research Project (IB16089) and economic support for
   research group (GRU15113 and GRU15173)). The author also thanks the
   funding received from the FEDER-MICCIN Infrastructure Research Project
   (UNEX-10-1E-402). Daniel Caballero also thanks the "Montesano" company
   from Jerez de los Caballeros (Badajoz, Spain) and the Animal Source
   Foodstuffs Innovation Service (SiPA) (Caceres, Spain) from the
   University of Extremadura. Thus, He also thanks to Dr. Jose Manuel Amigo
   from the University of Copenhagen (Copenhagen, Denmark), Dr. Andres
   Caro, Dra. Trinidad Perez-Palacios and Dra. Teresa Antequera from the
   University of Extremadura (Caceres, Spain) for their direct contribution
   and support.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], [No title captured]
   Antequera T, 2003, J SCI FOOD AGR, V83, P268, DOI 10.1002/jsfa.1306
   Antequera T, 2007, MEAT SCI, V76, P561, DOI 10.1016/j.meatsci.2007.01.014
   AOAC (Association of Official Analytical Chemists), 1995, OFFICIAL METHODS ANA, V16th
   Austin PC, 2004, J CLIN EPIDEMIOL, V57, P1138, DOI 10.1016/j.jclinepi.2004.04.003
   Avila MM, 2007, LECT NOTES COMPUT SC, V4477, P145
   Avila MM, 2019, ENG APPL ARTIF INTEL, V82, P110, DOI 10.1016/j.engappai.2019.03.026
   Avila M, 2018, J FOOD ENG, V222, P258, DOI 10.1016/j.jfoodeng.2017.11.028
   Bonny JM, 2001, J SCI FOOD AGR, V81, P337, DOI 10.1002/1097-0010(200102)81:3<337::AID-JSFA827>3.0.CO;2-W
   Caballero D, 2018, CHEMOMETR INTELL LAB, V180, P54, DOI 10.1016/j.chemolab.2018.04.008
   Caballero D, 2018, J FOOD ENG, V227, P1, DOI 10.1016/j.jfoodeng.2018.02.005
   Caballero D, 2017, FOOD RES INT, V99, P739, DOI 10.1016/j.foodres.2017.06.048
   Caballero D, 2017, J SCI FOOD AGR, V97, P2942, DOI 10.1002/jsfa.8132
   Caballero D, 2016, J FOOD ENG, V189, P115, DOI 10.1016/j.jfoodeng.2016.06.003
   Caballero D, 2016, FOOD BIOPROCESS TECH, V9, P699, DOI 10.1007/s11947-015-1662-1
   Cernadas E, 2005, COMPUT VIS IMAGE UND, V98, P345, DOI 10.1016/j.cviu.2004.08.004
   Colton T., 1974, STAT MED
   Cortez P, 2006, NEURAL PROCESS LETT, V24, P41, DOI 10.1007/s11063-006-9009-6
   Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   DIFOGGIO R, 1995, APPL SPECTROSC, V49, P67, DOI 10.1366/0003702953963247
   Faber K, 1996, CHEMOMETR INTELL LAB, V34, P283, DOI 10.1016/0169-7439(96)00022-6
   Fantazzini P, 2009, MEAT SCI, V82, P219, DOI 10.1016/j.meatsci.2009.01.014
   Fayyad U, 1996, AI MAG, V17, P37
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Grassi S, 2014, FOOD CHEM, V155, P279, DOI 10.1016/j.foodchem.2014.01.060
   Grossman Robert., 2010, Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions
   Haiwei P, 2007, APPL MATH COMPUT, V185, P844, DOI 10.1016/j.amc.2006.06.083
   Haralick R.M., 1993, COMPUTER ROBOT VISIO
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Jackman P, 2013, TRENDS FOOD SCI TECH, V29, P35, DOI 10.1016/j.tifs.2012.08.008
   Jackman P, 2011, TRENDS FOOD SCI TECH, V22, P185, DOI 10.1016/j.tifs.2011.01.008
   KIRA K, 1992, MACHINE LEARNING /, P249
   Li J, 1999, MEAT SCI, V53, P17, DOI 10.1016/S0309-1740(99)00031-5
   Mahendran R., 2012, Journal of Food Process and Technology, pS1, DOI [10.4172/2157-7110.S1-001, DOI 10.4172/2157-7110.S1-001]
   Manzocco L, 2013, FOOD CHEM, V141, P2246, DOI 10.1016/j.foodchem.2013.04.068
   Avila MM, 2015, LECT NOTES COMPUT SC, V9163, P456, DOI 10.1007/978-3-319-20904-3_41
   Molano R, 2012, APPL MATH COMPUT, V218, P9866, DOI 10.1016/j.amc.2012.03.063
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PECKINPAUGH SH, 1991, CVGIP-GRAPH MODEL IM, V53, P574, DOI 10.1016/1049-9652(91)90007-7
   Pérez-Palacios T, 2008, FOOD CHEM, V110, P1025, DOI 10.1016/j.foodchem.2008.03.026
   Pérez-Palacios T, 2017, FOOD BIOPROCESS TECH, V10, P750, DOI 10.1007/s11947-016-1853-4
   Pérez-Palacios T, 2014, J FOOD ENG, V131, P82, DOI 10.1016/j.jfoodeng.2014.01.015
   Pérez-Palacios T, 2011, FOOD CHEM, V126, P1366, DOI 10.1016/j.foodchem.2010.11.101
   Pérez-Palacios T, 2010, FOOD RES INT, V43, P248, DOI 10.1016/j.foodres.2009.09.020
   PEREZPALACIOS T, 2015, 4 FARM AN IM C FAIM
   Ruiz J, 2002, MEAT SCI, V61, P347, DOI 10.1016/S0309-1740(01)00204-2
   Sayad Saed., 2011, Real time data mining
   Shiranita K, 1998, PATTERN RECOGN LETT, V19, P1319, DOI 10.1016/S0167-8655(98)00113-5
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Song YH, 2002, ASIAN AUSTRAL J ANIM, V15, P591, DOI 10.5713/ajas.2002.591
   Sonka M., 2014, Image processing, analysis, and machine vision
   SUN CJ, 1983, COMPUT VISION GRAPH, V23, P341, DOI 10.1016/0734-189X(83)90032-4
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
NR 59
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21557
EP 21578
DI 10.1007/s11042-020-08924-4
EA MAY 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531131500001
DA 2024-07-18
ER

PT J
AU Mukherjee, A
   Goswami, P
   Yang, LX
AF Mukherjee, Amrit
   Goswami, Pratik
   Yang, Lixia
TI DAI based wireless sensor network for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless communication; Wireless multimedia cognitive radio sensor
   network; Cognitive radio; Cooperative communication; Channel models;
   DAI; Energy efficiency; Spectral analysis
ID POWER ALLOCATION; COMMUNICATION; HML
AB In Wireless Multimedia Sensor Network (WMSN), the time critical and delay sensitive applications like video, audio, image demands high bandwidth and transmission resources. The provision of Cognitive Radio (CR) can effectively utilize the available spectrum in the most appropriate way to provide high bandwidth in the Wireless Sensor Network (WSN) environment as Cognitive Radio sensor network (CRSN). The CR features are applicable in WMSN paradigm with required changes in transmission parameter for bandwidth hungry multimedia applications. In this paper, we propose an approach for setting up a cost-efficient and higher data rates communication in Wireless Multimedia Cognitive Radio Sensor Network (WMCRSN). The process analyses power allocation for sensor nodes by dynamic channel modelling and allocates power using multi-agent based Distributed Artificial Intelligence (DAI) in WMCRSN applications. The novelty in the approach lies in analyzing the real-time spectrum sensing outputs system for high data rate wireless multimedia applications. The DAI makes the process of power allocation in a smart way for having low latency based intra and inter cluster communication between sensor nodes. The performance parameters of the network, i.e. probability of detection and false alarm with the modelled error rates are presented. The mathematical analysis and simulation results justifies the feasibility and merits of the proposed method over conventional methods.
C1 [Mukherjee, Amrit; Yang, Lixia] Anhui Univ, Dept Commun, Sch Elect & Informat Engn, Hefei, Anhui, Peoples R China.
   [Goswami, Pratik] Jiangsu Univ, Sch Comp Sci & Commun Engn, Nanjing, Jiangsu, Peoples R China.
C3 Anhui University; Jiangsu University
RP Yang, LX (corresponding author), Anhui Univ, Dept Commun, Sch Elect & Informat Engn, Hefei, Anhui, Peoples R China.
EM amrit1460@gmail.com; lixiayang@yeah.net
RI Mukherjee, Amrit/Q-3174-2016; Yang, Lixia/AAB-7890-2022; Goswami,
   Pratik/AAB-4602-2019
OI Mukherjee, Amrit/0000-0002-6714-5568; Goswami,
   Pratik/0000-0002-4226-4536
CR Akyildiz IF, 2006, COMPUT NETW, V50, P2127, DOI 10.1016/j.comnet.2006.05.001
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   Amjad M, 2018, IEEE COMMUN SURV TUT, V20, P1056, DOI 10.1109/COMST.2018.2794358
   [Anonymous], 2004, P 42 ALL C COMM CONT
   Atapattu S, 2011, IEEE T WIREL COMMUN, V10, P1232, DOI 10.1109/TWC.2011.012411.100611
   Cabric D, 2004, CONF REC ASILOMAR C, P772, DOI 10.1109/acssc.2004.1399240
   Charalambos D, 2000, IEEE T AUTOMAT CONTR, V45, P24, DOI [10.1109/9.827353, DOI 10.1109/9.827353]
   Crohas, 2008, THESIS
   Demetrio O, 2010, SMART SENSOR NETWORK
   Duong TQ, 2016, IEEE WIREL COMMUN LE, V5, P516, DOI 10.1109/LWC.2016.2597278
   Farhang-Borotijeny B, 2008, IEEE T SIGNAL PROCES, V56, P1801, DOI 10.1109/TSP.2007.911490
   GARDNER WA, 1988, IEEE T COMMUN, V36, P897, DOI 10.1109/26.3769
   Goswami P., 2016, INRIA INFORMATICS MA, P1
   Goswami P, 2019, OPTIK, V182, P181, DOI 10.1016/j.ijleo.2018.12.191
   Javaid S, 2018, MULTIMED TOOLS APPL, V77, P4433, DOI 10.1007/s11042-016-4224-2
   Li P, 2015, IEEE T COMPUT, V64, P1670, DOI 10.1109/TC.2014.2345397
   Ma J, 2009, P IEEE, V97, P805, DOI 10.1109/JPROC.2009.2015707
   Malla PP, 2018, OPTIK, V170, P48, DOI 10.1016/j.ijleo.2018.05.083
   Manz G, 2012, IEEE C, P7803
   Matlou OG, 2017, ANN C IEEE IND EL SO, DOI [10.1109/IECON.2017.8217065, DOI 10.1109/IEC0N.2017.8217065]
   Mitola J, 1992, IEEE NAT TEL C 13 15, P19
   Mukherjee A., 2016, J ENG SCI TECHNOL RE, V9, P85
   Mukherjee A, 2019, IEEE ACCESS, V7, P131163, DOI 10.1109/ACCESS.2019.2940821
   Mukherjee A, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2019.2933908
   Mukherjee A, 2019, COMPUT ELECTR ENG, V75, P301, DOI 10.1016/j.compeleceng.2018.03.006
   Mukherjee A, 2016, IEEE COMMUN LETT, V20, P2261, DOI 10.1109/LCOMM.2016.2602266
   Mukherjee A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P133, DOI 10.1109/ICISCON.2014.6965233
   Pan H, 2017, MULTIMED TOOLS APPL, V76, P19479, DOI 10.1007/s11042-015-3150-z
   Penna F, 2009, IEEE P
   Qian H, 2007, IEEE T POWER DELIVER, V22, P1064, DOI 10.1109/TPWRD.2007.893187
   Qilin Qi, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P2069, DOI 10.1109/ICSAI.2012.6223460
   Samant T, 2016, INDIAN J SCI TECHNOL, P9
   SOLOMON OM, 1994, IEEE T INSTRUM MEAS, V43, P194, DOI 10.1109/19.293419
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Yan ZW, 2019, OPTIK, V178, P461, DOI 10.1016/j.ijleo.2018.09.186
   Yucek T, 2009, IEEE COMMUN SURVTUT, V11
   Zhu J, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COGNITIVE RADIO ORIENTED WIRELESS NETWORKS AND COMMUNICATIONS, P22
   Zhu J, 2016, MULTIMED TOOLS APPL, V75, P14329, DOI 10.1007/s11042-016-3403-5
NR 38
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16619
EP 16633
DI 10.1007/s11042-020-08909-3
EA MAY 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000530987600001
DA 2024-07-18
ER

PT J
AU Hashemi, M
AF Hashemi, Mahdi
TI Web page classification: a survey of perspectives, gaps, and future
   directions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web page classification; Image classification; Text classification; Deep
   learning; Machine learning; Artificial intelligence
ID NEURAL-NETWORKS; SYSTEM; ALGORITHM; ENGINE; TERMS; COLOR
AB The explosive growth of the amount of information on Internet has made Web page classification essential for Web information management, retrieval, and integration, Web page indexing, topic-specific Web crawling, topic-specific information extraction models, advertisement removal, filtering out unwanted, futile, or harmful contents, and parental control systems. Owing to the recent staggering growth of performance and memory space in computing machines, along with specialization of machine learning models for text and image classification, many researchers have begun to target the Web page classification problem. Yet, automatic Web page classification remains at its early stages because of its complexity, diversity of Web pages' contents (images of different sizes, text, hyperlinks, etc.), and its computational cost. This paper not only surveys the proposed methodologies in the literature, but also traces their evolution and portrays different perspectives toward this problem. Our study investigates the following: (a) metadata and contextual information surrounding the terms are mostly ignored in textual content classification, (b) the structure and distribution of text in HTML tags and hyperlinks are understudied in textual content classification, (c) measuring the effectives of features in distinguishing among Web page classes or measuring the contribution of each feature in the classification accuracy is a prominent research gap, (d) image classification methods rely heavily on computationally intensive and problem-specific analyses for feature extraction, (e) semi-supervised learning is understudied, despite its importance in Web page classification because of the massive amount of unlabeled Web pages and the high cost of labeling, (f) deep learning, convolutional and recurrent networks, and reinforcement learning remain underexplored but intriguing for Web page classification, and last but not least (g) developing a detailed testbed along with evaluation metrics and establishing standard benchmarks remain a gap in assessing Web page classifiers.
C1 [Hashemi, Mahdi] George Mason Univ, Dept Informat Sci & Technol, 4400 Univ Dr, Fairfax, VA 22030 USA.
C3 George Mason University
RP Hashemi, M (corresponding author), George Mason Univ, Dept Informat Sci & Technol, 4400 Univ Dr, Fairfax, VA 22030 USA.
EM mhashem2@gmu.edu
RI Hashemi/AAH-8526-2020
OI Hashemi/0000-0003-0212-0228
CR Abbasi A, 2009, COMPUTER, V42, P78, DOI 10.1109/MC.2009.306
   Ahmadi A, 2011, APPL SOFT COMPUT, V11, P1638, DOI 10.1016/j.asoc.2010.05.003
   Alvari Hamidreza, 2017, Security Informatics, V6, DOI 10.1186/s13388-017-0029-8
   [Anonymous], 2016, P NAACL HLT
   [Anonymous], 2014, P 2014 C EMP METH NA, DOI 10.3115/v1/D14-1003
   [Anonymous], 2016, NAACL
   [Anonymous], 10 EUR SIGN PROC C
   [Anonymous], 14 ANN NETW DISTR SY
   [Anonymous], 2016, COMPUT SCI
   [Anonymous], 2016, P 7 INT WORKSH HLTH, DOI DOI 10.18653/V1/W16-6109
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 17 ANN WORKSH INF TE
   [Anonymous], J BIG DATA
   [Anonymous], 6 INT C ADV MOB COMP
   [Anonymous], P AS C COMP VIS
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2015, 7 PAC RIM S IM VID T
   [Anonymous], 2015, ARXIV150803720
   [Anonymous], 2010, INTERSPEECH, DOI DOI 10.1016/J.CSL.2010.08.008
   [Anonymous], 2016, 5 INT C LEARN REPR
   Apid R.A., 2005, International Conference on Philippine Computing Science Congress, P201
   Arentz WA, 2004, COMPUT VIS IMAGE UND, V94, P295, DOI 10.1016/j.cviu.2003.10.007
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS
   Bai JH, 2012, PHYSCS PROC, V25, P499, DOI 10.1016/j.phpro.2012.03.117
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bosson A, 2002, LECT NOTES COMPUT SC, V2383, P50
   Chou N., 2004, P 11 ANN NETWORK DIS
   Chua CEH, 2004, COMPUTER, V37, P31, DOI 10.1109/MC.2004.165
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Denoyer L, 2004, INFORM PROCESS MANAG, V40, P807, DOI 10.1016/j.ipm.2004.04.009
   Diligenti M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P849, DOI 10.1109/ICDAR.2001.953907
   Du RB, 2003, ICON 2003: 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, P325
   Dumais S., 2000, SIGIR Forum, V34, P256
   Fakeri-Tabrizi A, 2015, NEUROCOMPUTING, V155, P117, DOI 10.1016/j.neucom.2014.12.041
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Fauzi F, 2013, INFORM PROCESS MANAG, V49, P420, DOI 10.1016/j.ipm.2012.08.001
   Fauzi F, 2010, INT J HUM-COMPUT ST, V68, P270, DOI 10.1016/j.ijhcs.2010.01.001
   Feng Jiao, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P378, DOI 10.1109/ICII.2001.983086
   Fersini E, 2008, INFORM PROCESS MANAG, V44, P1431, DOI 10.1016/j.ipm.2007.11.003
   Forsyth DA, 1999, INT J COMPUT VISION, V32, P63, DOI 10.1023/A:1008145029462
   Hammami M, 2006, IEEE T KNOWL DATA EN, V18, P272, DOI 10.1109/TKDE.2006.34
   Hammami M, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P574
   Hashemi H, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0411-0
   Hashemi M, 2018, IEEE ACCESS, V6, P70164, DOI 10.1109/ACCESS.2018.2879056
   Hashemi M, 2018, LECT NOTES COMPUT SC, V10923, P594, DOI 10.1007/978-3-319-91716-0_47
   Hashemi M, 2019, IMAGE VISION COMPUT, V89, P95, DOI 10.1016/j.imavis.2019.06.001
   Ho WH, 2004, IEEE SYS MAN CYBERN, P4792
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Hu WM, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037685
   Huang Z., 2015, ARXIV
   Ioffe S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1092, DOI 10.1109/ICCV.1999.790398
   Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708
   Ioffe S, 1999, ADV NEUR IN, V11, P782
   Jeonghee Yi, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P340
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Jurafsky Dan, 2014, Speech and language processing, V3
   Kim S, 2003, APPL INTELL, V18, P243, DOI 10.1023/A:1023293820057
   Lee JH, 2015, APPL MATH COMPUT, V270, P13, DOI 10.1016/j.amc.2015.07.120
   Lee PY, 2005, IEEE T MULTIMEDIA, V7, P1183, DOI 10.1109/TMM.2005.858414
   Lee PY, 2002, IEEE INTELL SYST, V17, P48, DOI 10.1109/MIS.2002.1039832
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Li H, 2017, FUTURE GENER COMP SY, V76, P510, DOI 10.1016/j.future.2017.03.003
   Li L, 2007, J COMPUT VIROL HACKI, V3, P163, DOI 10.1007/s11416-007-0050-4
   Li XS, 2017, IEEE T AFFECT COMPUT, V8, P428, DOI 10.1109/TAFFC.2017.2716930
   Liparas Dimitris, 2014, Multidisciplinary Information Retrieval. 7th Information Retrieval Facility Conference, IRFC 2014. Proceedings: LNCS 8849, P63, DOI 10.1007/978-3-319-12979-2_6
   Liu WY, 2006, IEEE INTERNET COMPUT, V10, P58, DOI 10.1109/MIC.2006.23
   Luo Y, 2017, J BIOMED INFORM, V72, P85, DOI 10.1016/j.jbi.2017.07.006
   McKenna SJ, 1998, PATTERN RECOGN, V31, P1883, DOI 10.1016/S0031-3203(98)00066-1
   Munkhdalai T, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P11
   Munkhdalai Tsendsuren, 2017, Proc Conf Assoc Comput Linguist Meet, V1, P397
   Nian FD, 2016, NEUROCOMPUTING, V210, P283, DOI 10.1016/j.neucom.2015.09.135
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Özel SA, 2011, EXPERT SYST APPL, V38, P3407, DOI 10.1016/j.eswa.2010.08.126
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Ribeiro A, 2003, IEEE INT CONF FUZZY, P1032
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Segalin C, 2017, COMPUT VIS IMAGE UND, V156, P34, DOI 10.1016/j.cviu.2016.10.013
   Selamat A, 2004, INFORM SCIENCES, V158, P69, DOI 10.1016/j.ins.2003.03.003
   Simonyan K., 2014, 14091556 ARXIV
   Sun WC, 2018, NEUROCOMPUTING, V278, P34, DOI 10.1016/j.neucom.2017.05.103
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tamura A, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1470
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Tian LX, 2013, INT J INTELL SYST, V28, P242, DOI 10.1002/int.21567
   Trotman A, 2005, INFORM PROCESS MANAG, V41, P243, DOI 10.1016/j.ipm.2003.10.003
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707
   Wang J, 1997, P SOC PHOTO-OPT INS, V3201, P20, DOI 10.1117/12.279206
   Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wang XZ, 2018, IEEE IMAGE PROC, P2989, DOI 10.1109/ICIP.2018.8451366
   Xiong SF, 2018, NEUROCOMPUTING, V275, P2459, DOI 10.1016/j.neucom.2017.11.023
   Xu Y, 2005, TRANSPORT RES REC, P1
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yang YM, 2002, J INTELL INF SYST, V18, P219, DOI 10.1023/A:1013685612819
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang HJ, 2011, IEEE T NEURAL NETWOR, V22, P1532, DOI 10.1109/TNN.2011.2161999
   Zhao XG, 2011, NEUROCOMPUTING, V74, P2444, DOI 10.1016/j.neucom.2010.12.038
   Zheng HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1223, DOI 10.1109/ICME.2004.1394442
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 106
TC 36
Z9 39
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11921
EP 11945
DI 10.1007/s11042-019-08373-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400030
DA 2024-07-18
ER

PT J
AU Huan, EY
   Wen, GH
AF Huan, Er-Yang
   Wen, Gui-Hua
TI Transfer learning with deep convolutional neural network for
   constitution classification with face image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Constitution classification; Convolutional neural networks; Transfer
   learning; DenseNet-169; ConstitutionNet; Integrated test
ID QUESTIONNAIRE; BCQ
AB Constitution classification is the basis and core content of constitution research in Traditional Chinese medicine. The convolutional neural networks have successfully established many models for image classification, but it requires a lot of training data. In the field of Traditional Chinese medicine, the available clinical data is very limited. To solve this problem, we propose a method for constitution classification through transfer learning. Firstly, the DenseNet-169 model trained in ImageNet is applied. Secondly, we carefully modify the DenseNet-169 structure according to the constitution characteristics, and then the modified model is trained in the clinical data to obtain the constitution identification network called ConstitutionNet. In order to further improve the accuracy of classification, we integrate the ConstitutionNet with Vgg-16, Inception v3 and DenseNet-121 to test according to the integrated learning idea, and judge the input face image to its constitution type. The experimental results show that transfer learning can achieve better results in small clinical dataset, and the final accuracy of constitution recognition is 66.79%.
C1 [Huan, Er-Yang; Wen, Gui-Hua] South China Univ Technol, Sch Comp Sci & Engn, China Guangdong Artificial Intelligence Engn Res, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Wen, GH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, China Guangdong Artificial Intelligence Engn Res, Guangzhou, Peoples R China.
EM crghwen@scut.edu.cn
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], YB CHIN MED PHARM
   [Anonymous], CHINESE J INFORM TRA
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2018, MACH LEARN PYTH
   [Anonymous], 2017, P 31 AAAI C ART INT
   [Anonymous], SUGGESTION ANAL REVI
   [Anonymous], J TRADIT CHIN MED
   [Anonymous], YB CHIN MED PHARM
   [Anonymous], J TRADIT CHIN MED
   [Anonymous], YUNNAN J TRADITIONAL
   [Anonymous], 2017, ARXIV171106897
   [Anonymous], IEEE T POWER ELECT
   [Anonymous], 2014, J TRADIT CHIN MED
   [Anonymous], ARXIV PREPRINT 1610
   [Anonymous], 2018, ARXIV180300219
   [Anonymous], IEEE T IND ELECT
   Bermejo P, 2014, KNOWL-BASED SYST, V55, P140, DOI 10.1016/j.knosys.2013.10.016
   Burdick J, 2018, J DIGIT IMAGING, V31, P435, DOI 10.1007/s10278-017-0026-y
   Chen KH, 2014, APPL SOFT COMPUT, V24, P773, DOI 10.1016/j.asoc.2014.08.032
   China Association of Chinese Medicine, 2009, World J Integr Trad West Med, V4, P303
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Geng YS, 2016, IEEE T MOBILE COMPUT, V15, P656, DOI 10.1109/TMC.2015.2416186
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Howard A. G., 2017, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huan EY, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/9846707
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Jiang ZH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SAFETY FOR ROBOTICS (ISR), P13, DOI 10.1109/IISR.2018.8535762
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Law H., 2018, PROC EUR C COMPUT VI, P734
   Li HT, 2016, LECT NOTES COMPUT SC, V9887, P128, DOI 10.1007/978-3-319-44781-0_16
   Lin JS, 2012, FORSCH KOMPLEMENTMED, V19, P285, DOI 10.1159/000346060
   Lin JD, 2012, EUR J INTEGR MED, V4, pE379, DOI 10.1016/j.eujim.2012.05.001
   Lin JD, 2012, FORSCH KOMPLEMENTMED, V19, P234, DOI 10.1159/000343580
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Masetic Z, 2016, COMPUT METH PROG BIO, V130, P54, DOI 10.1016/j.cmpb.2016.03.020
   Samanthula BK, 2015, IEEE T KNOWL DATA EN, V27, P1261, DOI 10.1109/TKDE.2014.2364027
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, 14091556 ARXIV
   Su SY, 2013, J ALTERN COMPLEM MED, V19, P569, DOI 10.1089/acm.2012.0478
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2019, PR MACH LEARN RES, V97
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Fei, 2017, ARXIV170406904
   [王琦 Wang Qi], 2005, [北京中医药大学学报, Journal of Beijing University of Traditional Chinese Medicine], V28, P1
   Wong WD, 2014, COMPLEMENT THER MED, V22, P670, DOI 10.1016/j.ctim.2014.05.009
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang XC, 2017, PROC CVPR IEEE, P3900, DOI 10.1109/CVPR.2017.415
NR 61
TC 11
Z9 14
U1 2
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11905
EP 11919
DI 10.1007/s11042-019-08376-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400029
DA 2024-07-18
ER

PT J
AU Kaur, H
   Khanna, P
AF Kaur, Harkeerat
   Khanna, Pritee
TI PolyCodes: generating cancelable biometric features using polynomial
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Log-Gabor features; Non-invertibility; Polynomial
   transformation; PolyCodes; Revocablity
ID TEMPLATE PROTECTION; FINGERPRINT TEMPLATES; PRIVACY; FILTERS
AB Cancelable biometrics is a template protection technique proposed to bridge the growing gap between 'biometrics for security' and 'security for biometrics'. Various approaches have been reported in literature, yet transforming a biometric template for privacy preservation is a challenging task. The manuscript proposes a random polynomial based template transformation technique to generate protected biometric templates named as 'PolyCodes'. These protected versions are privacy and discriminability preserving, revocable, and provide significant dimensionality reduction. Several polynomial functions with dimensionality reduction factor ranging from 65% to 90% are designed and evaluated for security and performance. Further, applicability of the proposed 'PolyCodes' is experimentally verified for many biometric modalities such as visible and thermal face, palmprint, palmvein, and fingervein.
C1 [Kaur, Harkeerat; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, Dumna, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Kaur, H (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Jabalpur 482005, Dumna, India.
EM harkeerat.kaur@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019
OI Khanna, Pritee/0000-0003-0518-2133
FU BRNS, DAE, Government of India [36(3)/14/58/2016-BRNS]
FX This work is supported by BRNS, DAE, Government of India, Grant. No:
   36(3)/14/58/2016-BRNS.
CR Alam B, 2018, J NETW COMPUT APPL, V115, P20, DOI 10.1016/j.jnca.2018.04.013
   [Anonymous], 1994, ORL FAC DAT
   [Anonymous], P 30 ANN INT CARN C
   [Anonymous], 2005, IRIS THERMAL VISIBLE
   [Anonymous], 2008, IEEE 19 INT C PATT R
   CASIA palmprint database, 2005, CASIA PALMPR DAT
   CASIA-FaceV5, 2005, CASIA FACEV5
   CASIA-MS-Palmprint V1, 2007, CASIA MS PALMPR V1
   DEBOOR C, 1990, CONSTR APPROX, V6, P287, DOI 10.1007/BF01890412
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   Farooq F., 2007, Conference Proceedings presented in Signal Processing and Its Applications, P1
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Hermand Jean-Pierre, 2014, OCEANS 2014, DOI 10.1109/OCEANS-TAIPEI.2014.6964569
   Hiew BY, 2006, I C CONT AUTOMAT ROB, P600
   Ignatenko T, 2010, IEEE T INF FOREN SEC, V5, P337, DOI 10.1109/TIFS.2010.2046984
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kaur H, 2017, MULTIMED TOOLS APPL, V76, P4673, DOI 10.1007/s11042-016-3652-3
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Lacbarme P., 2013, 2013 INT C SEC CRYPT, P1
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li J, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053014
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Maiorana E, 2011, ANN IEEE SYST CONF, P495
   Nagar A, 2008, INT C PATT RECOG, P822
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Ratha N, 2006, INT C PATT RECOG, P370
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2013, INT CONF BIOMETR
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Scheirer WJ, 2007, 2007 BIOMETRICS SYMPOSIUM, P30
   Tamayo-Rios M., 2017, IACR CRYPTOL EPRINT, V458
   Teoh ABJ, 2018, MULTIMED TOOLS APPL, P1
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2007, IEICE ELECTRON EXPR, V4, P724, DOI 10.1587/elex.4.724
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Teoh ABJ, 2010, PATTERN ANAL APPL, V13, P301, DOI 10.1007/s10044-009-0158-x
   Tuttle SE, 2017, SPRING REMOTE SENS P, P21, DOI 10.1007/978-3-319-43744-6_2
   Wang S, 2013, J INEQUAL APPL, DOI 10.1186/1029-242X-2013-81
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2014, PATTERN RECOGN, V47, P1321, DOI 10.1016/j.patcog.2013.10.003
   Wang Y, 2010, IEEE T SYST MAN CY B, V40, P1280, DOI 10.1109/TSMCB.2009.2037131
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Yin Y, 2011, DECIS ENG, P269
NR 49
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20729
EP 20752
DI 10.1007/s11042-020-08734-8
EA APR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528521300005
DA 2024-07-18
ER

PT J
AU Islam, R
   Islam, MR
   Talukder, KH
AF Islam, Rashedul
   Islam, Md Rafiqul
   Talukder, Kamrul Hasan
TI An efficient method for extraction and recognition of bangla characters
   from vehicle license plates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HOG; SVM; Image processing; Aspect ratio; License plate detection;
   Character recognition
AB Recognition of characters from vehicle license plate plays a vital role in vehicle tracking, controlling, and maintaining traffic on the roads and high ways. This paper presents an automatic system to detect plate area and recognize characters. The research is carried out on Bangladeshi vehicle license plates because this is a demandable research area in the present age. The method has been implemented using the five consecutive steps such as license plate detection, extraction, character localization, extraction of characters, and recognition of extracted characters. We have introduced an algorithm to detect the Region of Interest (ROI) from the input image. It is performed by applying morphological operation and histogram analysis of vertical and horizontal projection profiles. A dynamic threshold is used to filter out both horizontal and vertical histogram values and ROI is extracted from the license plate image using different geometric properties such as area, bounding box, and aspect ratio. Character segmentation is performed by applying the method of connected component analysis and bounding box technology. Finally, character recognition is carried out using Support Vector Machine (SVM) classifier where extracted Histogram of Oriented Gradient (HOG) features are used as input. The proposed algorithm is applied to 630 images of license plates of different categories of vehicles and achieved 91% accuracy in the extraction of ROI and 94.6% accuracy in the extraction of characters. We have also achieved 100% accuracy in recognition of Bangla characters from a total of 4725 Bangla characters extracted from 630 images of license plates.
C1 [Islam, Rashedul; Islam, Md Rafiqul; Talukder, Kamrul Hasan] Khulna Univ, Comp Sci & Engn Discipline, Khulna 9208, Bangladesh.
C3 Khulna University
RP Islam, R (corresponding author), Khulna Univ, Comp Sci & Engn Discipline, Khulna 9208, Bangladesh.
EM rashedcse98@gmail.com; dmri1978@gmail.com; k.h.t@alumni.nus.edu.sg
RI Islam, Md Rashedul/HNB-8604-2023
OI Talukder, Kamrul Hasan/0000-0001-5811-4201; Islam,
   Rashedul/0000-0002-6692-501X
CR Amin MR, 2014, INT J COMPUT APPL, V93, P15
   Baten RA, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P776, DOI 10.1109/ICECE.2014.7026925
   Cao GZ, 2003, IEEE IND ELEC, P1786
   Chandra S, 2017, CRIT CARE, V21, DOI 10.1186/s13054-017-1912-x
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deb K., 2012, P 7 INT FOR STRAT TE, V1, P686
   Deb K, 2008, 2008 INTERNATIONAL CONFERENCE ON SMART MANUFACTURING APPLICATION, P349, DOI 10.1109/ICSMA.2008.4505550
   Deb K, 2009, INTEL SERV ROBOT, V2, P173, DOI 10.1007/s11370-009-0043-x
   Gao Q, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2964, DOI 10.1109/ICAL.2007.4339089
   Ghosh A. K, 2011, GLOBAL J COMPUTER SC
   Hsieh JW, 2002, P 16 INT C PATT REC, V03
   Islam R, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P138, DOI 10.1109/CAST.2016.7914955
   Kim KI, 2002, LECT NOTES COMPUT SC, V2388, P293
   Kim S, 2002, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2002.1047833
   Mashuk M. S., 2010, Proceedings 2010 Second International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2010), P166, DOI 10.1109/CIMSiM.2010.73
   Moustafa A. A., 2015, INT BUSINESS RES, V8, P13, DOI DOI 10.5539/ibr.v8n11p13
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rabee A, 2014, INT CONF SYST SIGNAL, P59
   Roy A., 2016, Proc. Int. Conf. Circuit, P1, DOI [10.1109/ICCPCT.2016.7530150, DOI 10.1109/ICCPCT.2016.7530150]
   Saha Satadal, 2009, International Journal of Recent Trends in Engineering, V1, P284
   Sarfraz M, 2003, 2003 INTERNATIONAL CONFERENCE ON GEOMETRIC MODELING AND GRAPHICS, PROCEEDINGS, P36, DOI 10.1109/GMAG.2003.1219663
   Uddin MA, 2016, P INT C ADV INF COMM
NR 24
TC 8
Z9 9
U1 8
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20107
EP 20132
DI 10.1007/s11042-020-08629-8
EA APR 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526353800001
DA 2024-07-18
ER

PT J
AU Hemamalini, B
   Nagarajan, V
AF Hemamalini, B.
   Nagarajan, V
TI Wavelet transform and pixel strength-based robust watermarking using
   dragonflyoptimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ENeGW; DWT; Watermark; Dragonfly optimization; Gradient decomposition
ID REVERSIBLE WATERMARKING; IMAGE WATERMARKING
AB The exponential growth of the information technology has created a pathetic panorama in the field of Health Information System (HIS) that draws the attention of the researchers. Watermarking is a trending topic that provides security to the encapsulated secret code in the medical image and hence, ensures security to the medical images and contributes towards efficient information extraction. The images arelikely to be attacked by intruders, which may be intentional or accidental attack of noises. Therefore, the verification of the image and its related data is necessary.Keeping the security and distortion free watermarking as an objective, this paper proposes a robust watermarking approach that depends upon weight of the pixels. The image makes use of DWT to extract the high and the low frequency bands to select the effective pixels for watermarking. The dragonfly optimization determines the effective pixel that follows the objective function based on ENeGW (Edge level, Neighbourhood strength, Gradient energy, and Wavelet energy) of the pixel. Experimentation is rendered on medical retinal image using patient data as a watermark, and the comparative study is made on the suggested watermarking procedure with the existing methods, such as random selection, PSO, and genetic algorithm. The comparative performance analysis is done and its outcome shows the supremacy of the suggested methodology.
C1 [Hemamalini, B.; Nagarajan, V] Adhiparasakthi Engn Coll, Dept Elect & Commun Engn, Melmaruvathur, Tamil Nadu, India.
RP Hemamalini, B (corresponding author), Adhiparasakthi Engn Coll, Dept Elect & Commun Engn, Melmaruvathur, Tamil Nadu, India.
EM hemavatchalu1@gmail.com; nagarajanece31@gmail.com
RI velmurugan, nagarajan/AAD-6724-2020
OI velmurugan, nagarajan/0000-0002-1031-0737
CR Arda Ustubioglu, 2017, J DIGIT IMAGING, P1
   Arsalan M, 2017, APPL SOFT COMPUT, V51, P168, DOI 10.1016/j.asoc.2016.11.044
   Bhagat A, 2014, INT J ENG COMPUT SCI, V3, P7204
   Eswaraiah R, 2015, IET IMAGE PROCESS, V9, P615, DOI 10.1049/iet-ipr.2014.0986
   Garg K., 2015, INT J SCI ENG COMPUT, V5, P48
   Garcia-Hernandez JJ, 2016, COMPUT BIOL MED, V68, P37, DOI 10.1016/j.compbiomed.2015.10.014
   Li X, 2011, IEEE T IMAGE PROCESS, V20, P971, DOI 10.1109/TIP.2010.2081681
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P1053, DOI 10.1007/s00521-015-1920-1
   Naskar R, 2016, J SIGNAL PROCESS SYS, V82, P373, DOI 10.1007/s11265-015-1009-1
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Nin J, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P1553, DOI 10.1109/WAINA.2013.171
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Priyanka, 2017, MULTIMED TOOLS APPL, V76, P3617, DOI 10.1007/s11042-016-3913-1
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Turuk MP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0608-0
   Zhang Nana, 2016, AUD LANG IM PROC ICA, P361
NR 22
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8727
EP 8746
DI 10.1007/s11042-018-6096-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600019
DA 2024-07-18
ER

PT J
AU Liu, CP
   Wang, XD
   Mao, JX
AF Liu, Caiping
   Wang, Xudong
   Mao, Jianxu
TI Research on multi-focus image fusion algorithm based on total variation
   and quad-tree decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total variation filter; Sum-modified-Laplacian; Quad-tree decomposition
ID CONTOURLET TRANSFORM; WAVELET TRANSFORM
AB In order to get the focus region from the two or more source image more effectively and to represent the source image completely and effectively, a decomposition strategy based on the combination of total variation and quad-tree and an improved fusion method of focus region detection are proposed. The theory of total variation and quad-tree is applied to the fusion of multi-focus images. Firstly, two registered experimental images are decomposed into the optimal block decomposition graph by total variation and quad-tree decomposition, respectively. For each block, the initial focus region decision map of the source image is found by using improved Sum-Modified-Laplacian, and the final focus region decision map is obtained by consistency test and morphological processing for the initial focus region decision map. Furthermore, compared with other algorithms, the improved algorithm has more advantages in extracting the focus area, because of improved focus evaluation function and more accurate detection of the focus area. According to the fusion source image of the final focus region decision map, the results of four sets of experiments show that the fusion quality and effect are significantly improved compared with the existing algorithm.
C1 [Liu, Caiping; Wang, Xudong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Mao, Jianxu] Hunan Univ, Sch Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University; Hunan University
RP Mao, JX (corresponding author), Hunan Univ, Sch Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
EM maojianxu@hnu.edu.cn
CR Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605
   Chen Z, 2016, CHINESE J SCI INSTRU
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Fakhari F, 2017, IET IMAGE PROCESSING, V11
   Fu Z, 2016, INFRARED PHYS TECHN
   Gao R., 2017, IEEE SIGNAL PROCESSI, V99, P1
   Jameel A, 2015, OPTIK, V126, P3920, DOI 10.1016/j.ijleo.2015.07.173
   Koley S, 2016, J MED BIOL ENG, V36, P470, DOI 10.1007/s40846-016-0149-5
   Li HF, 2016, INFRARED PHYS TECHN, V76, P174, DOI 10.1016/j.infrared.2016.02.005
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu B, 2016, ACTA ELECT SIN, V24, P3297
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Meyer Y, 2001, OSCILLATING PATTERNS, V22, P122
   Patil U., 2011, P 2011 INT C IM INF, P1, DOI DOI 10.1109/ICIIP.2011.6108966
   Srivastava R, 2016, IET COMPUT VIS, V10, P513, DOI 10.1049/iet-cvi.2015.0251
   Tilly N, 2015, REMOTE SENS-BASEL, V7, P11449, DOI 10.3390/rs70911449
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang Q, 2016, COMPUTER SCI
   Xu J, 2010, INVERSE PROBL IMAG, V4, P523, DOI 10.3934/ipi.2010.4.523
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yin M, 2016, J COMPUTER AIDED DES
   Zhang Y, 2017, INFRARED PHYS TECHN, V83, P227, DOI 10.1016/j.infrared.2017.05.007
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhu Qiang-bo, 2016, Journal of Chinese Computer Systems, V37, P1583
NR 27
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10475
EP 10488
DI 10.1007/s11042-019-7563-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600040
DA 2024-07-18
ER

PT J
AU Nie, HL
   Jiang, XT
   Tang, WD
   Zhang, S
   Dou, WC
AF Nie, Hongli
   Jiang, Xutong
   Tang, Wenda
   Zhang, Song
   Dou, Wanchun
TI Data security over wireless transmission for enterprise multimedia
   security with fountain codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fountain codes; Wireless transmission; Security; Edge computing;
   Enterprise multimedia
ID COMPUTATION OFFLOADING METHOD; PRIVACY PRESERVATION
AB With the explosive growth of multimedia data, Enterprise Multimedia Security (EMS) is a serious matter to maintain enterprise information security. As the rise of social media applications triggers higher bandwidth demand and shorter end-to-end delay requirements, edge computing has emerged as a promising technique to reduce delay. Edge servers are often deployed around mobile devices via a one-hop wireless network connection. However, migrating multimedia data over wireless networks to edge servers for edge computing is vulnerable to eavesdroppers. Ensuring the security of enterprise multimedia data in the edge computing is a top priority. To cater for the data security over wireless transmisson for edge computing, window-based fountain codes, is treated as a feasible technology to compensate this gap. Based on the characteristics of the fountain codes, data security over wireless transmisson is implemented only when the target receiver accumulates enough coding packets in advance of the eavesdropper. In the general wireless transmission, the eavesdropper receives data packets or not depends on whether the wireless channel lose packets. To ensure data security, we introduce the constellation-rotation technique and interfering noise into wireless signal which can disturb the eavesdropper's signal quality and increase the packet loss in the eavesdropper. Specifically, we study how to partition the video streaming into windows, which takes the end-to-end delay into consideration while guaranteeing lower intercept probability which indicates the probability video data is leaked to the eavesdropper.
C1 [Nie, Hongli; Jiang, Xutong; Tang, Wenda; Zhang, Song; Dou, Wanchun] Nanjing Univ, Dept Comp Sci & Technol, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
C3 Nanjing University
RP Dou, WC (corresponding author), Nanjing Univ, Dept Comp Sci & Technol, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
EM douwc@nju.edu.cn
CR Ahmad S, 2011, IEEE T MULTIMEDIA, V13, P92, DOI 10.1109/TMM.2010.2093511
   [Anonymous], SHOCK VIB
   [Anonymous], THESIS
   Bogino MCO, 2007, IEEE INT SYMP CIRC S, P3467, DOI 10.1109/ISCAS.2007.378373
   Bohli JM, 2009, C LOCAL COMPUT NETW, P850, DOI 10.1109/LCN.2009.5355011
   Byers JW, 2002, IEEE J SEL AREA COMM, V20, P1528, DOI 10.1109/JSAC.2002.803996
   Cataldi P, 2010, IEEE T IMAGE PROCESS, V19, P1491, DOI 10.1109/TIP.2010.2042985
   Chen SX, 2015, IEEE T INF FOREN SEC, V10, P28, DOI 10.1109/TIFS.2014.2362848
   Dong BX, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P707, DOI 10.1145/3132847.3132854
   Du Q., 2018, Wirel. Commun. Mob. Comput., V2018, P1
   Du QH, 2017, LECT NOTES COMPUT SC, V10251, P509, DOI 10.1007/978-3-319-60033-8_44
   Lopez PG, 2015, ACM SIGCOMM COMP COM, V45, P37, DOI 10.1145/2831347.2831354
   Gong WW, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/3075849
   Hallman RA, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2173, DOI 10.1145/3243734.3243876
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   HUANG T, 2017, MULTIMED TOOLS APPL, V76, p13,38, DOI DOI 10.1007/s11042-016-3745-z
   Huang WT, 2016, INT J ADV MANUF TECH, V85, P2155, DOI 10.1007/s00170-015-7382-x
   Lee W., 1982, MOBILE COMMUNICATION
   Li T., 2018, WIRELESS COMMUNICATI
   Liva G, 2010, IEEE COMMUN LETT, V14, P178, DOI 10.1109/LCOMM.2010.02.092080
   Luby M., 2002, 43 ANN IEEE S FDN CO, P271
   MASSEY JL, 1988, P IEEE, V76, P533, DOI 10.1109/5.4440
   Niu H, 2014, IEEE COMMUN LETT, V18, P777, DOI 10.1109/LCOMM.2014.030914.140030
   Qi LY, 2018, IEEE ACCESS, V6, P46926, DOI 10.1109/ACCESS.2018.2866641
   Qi LY, 2018, FUTURE GENER COMP SY, V88, P636, DOI 10.1016/j.future.2018.02.050
   Seba A, 2019, J NETW COMPUT APPL, V126, P150, DOI 10.1016/j.jnca.2018.11.010
   Sejdinovic D, 2009, IEEE T COMMUN, V57, P2510, DOI 10.1109/TCOMM.2009.09.070616
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Sorokin R, 2018, ANN TELECOMMUN, V73, P305, DOI 10.1007/s12243-017-0613-4
   Stecklina O, 2015, 2015 15 INT C INN CO, P1
   Sun K, 2016, ARXIV160503236
   Sun K, 2017, IEEE T NEUR NET LEAR, V28, P1386, DOI 10.1109/TNNLS.2016.2542866
   Sun KR, 2018, IEEE INTERNET THINGS, V5, P415, DOI 10.1109/JIOT.2016.2577520
   Sun L, 2016, IEEE T IND INFORM, V12, P291, DOI 10.1109/TII.2015.2509442
   Vukobratovic D, 2009, IEEE T MULTIMEDIA, V11, P1094, DOI 10.1109/TMM.2009.2026087
   Wagner JP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1501, DOI 10.1109/ICME.2006.262827
   Wang XJ, 2011, IEEE T VEH TECHNOL, V60, P4427, DOI 10.1109/TVT.2011.2171773
   Xu XL, 2019, J NETW COMPUT APPL, V133, P75, DOI 10.1016/j.jnca.2019.02.008
   Xu XL, 2019, FUTURE GENER COMP SY, V95, P522, DOI 10.1016/j.future.2018.12.055
   Xu XL, 2019, FUTURE GENER COMP SY, V96, P89, DOI 10.1016/j.future.2019.01.012
   Xu XL, 2018, J NETW COMPUT APPL, V124, P148, DOI 10.1016/j.jnca.2018.09.006
   Yu H, 2016, IEEE I C NETW INFRAS, P337, DOI 10.1109/ICNIDC.2016.7974592
   Zhang X, 2006, IEEE T VEH TECHNOL, V55, P1633, DOI 10.1109/TVT.2006.874547
NR 43
TC 11
Z9 11
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10781
EP 10803
DI 10.1007/s11042-019-08479-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600058
DA 2024-07-18
ER

PT J
AU Ramji, DR
   Palagan, CA
   Nithya, A
   Appathurai, A
   Alex, EJ
AF Ramji, D. R.
   Palagan, C. Anna
   Nithya, A.
   Appathurai, Ahilan
   Alex, E. John
TI Soft computing based color image demosaicing for medical Image
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Charge coupled devices (CCD); Fuzzy logic (FL); Genetic algorithm (GA);
   Peak signal to noise ratio (PSNR); Hue transition (HT); Adaptive
   CFA-ACFA; Hybrid algorithm (HA)
ID FILTER ARRAY; INTERPOLATION
AB As digital cameras become more enhanced and small, CCD sensors can relate to only one color of a pixel. This color mosaic pattern is called as Bayer Pattern(BP) which requires processing to obtain a color image with a higher resolution. Each image pixel that undergoes interpolation has a full color spectrum based on surrounding pixel colors. Here we introduce Adaptive CFA(ACFA) interpolation model. For normal image regions hue technique is used while edge regions adapt the new technique. It is proposed to apply fuzzy logic and fuzzy rule which is based on Genetic Algorithm that uses random local search to enhance the PSNR. Medical image reconstruction by this proposed fuzzy based method outperforms the other medical image reconstruction methods.
C1 [Ramji, D. R.; Nithya, A.] Vaagdevi Coll Engn, Dept ECE, Warangal, Telungana, India.
   [Palagan, C. Anna] Teegala Krishna Reddy Engn Coll, Dept ECE, Hyderabad, Telangana, India.
   [Appathurai, Ahilan] Infant Jesus Coll Engn, Dept ECE, Tuticorin, India.
   [Alex, E. John] CMR Inst Technol, Dept ECE, Hyderabad, Telangana, India.
RP Ramji, DR (corresponding author), Vaagdevi Coll Engn, Dept ECE, Warangal, Telungana, India.
EM ramjidr@gmail.com
RI A, Ahilan/D-9797-2018; E, J/GYR-2359-2022; E, John Alex/ABB-8402-2021;
   PALAGAN C, ANNA/AAX-8207-2021
OI PALAGAN C, ANNA/0000-0002-4549-0539; E, JOHN ALEX/0000-0003-2918-0474;
   Ramji, DR/0000-0002-2945-2487
CR Andriantiatsaholiniaina LA, 2004, ECOL ECON, V48, P149, DOI 10.1016/j.ecolecon.2003.08.009
   [Anonymous], IEEE INT C IM INF PR
   [Anonymous], 25 IEEE INT C IM VIS
   [Anonymous], J PURE APPL MICROBIO
   [Anonymous], 2010, P INT KHARKOV S PHYS
   [Anonymous], INT J ENG TRENDS TEC
   [Anonymous], JOER
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Chen WG, 2012, IET IMAGE PROCESS, V6, P901, DOI 10.1049/iet-ipr.2011.0248
   Chen WJ, 2012, DIGIT SIGNAL PROCESS, V22, P163, DOI 10.1016/j.dsp.2011.09.006
   Chen X, 2014, IEEE T CIRC SYST VID, V24, P255, DOI 10.1109/TCSVT.2013.2255421
   Condat L, 2009, IEEE IMAGE PROC, P457, DOI 10.1109/ICIP.2009.5414383
   Dengwen Z, 2012, IET IMAGE PROCESS, V6, P1084, DOI 10.1049/iet-ipr.2012.0196
   Devi E. Sree, 2014, Journal of Theoretical and Applied Information Technology, V59, P527
   Dubois E, 2005, IEEE SIGNAL PROC LET, V12, P847, DOI 10.1109/LSP.2005.859503
   El-Mihoub TA, 2006, ENG LET, V13
   García-Martínez C, 2008, NAT COMPUT SER, P199, DOI 10.1007/978-3-540-72960-0_10
   Gu J, 2010, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2010.5649949
   He FL, 2012, IEEE IMAGE PROC, P2765
   Hirakawa K, 2008, IEEE T IMAGE PROCESS, V17, P1876, DOI 10.1109/TIP.2008.2002164
   Hirakawa K, 2008, PROC SPIE, V6822, DOI 10.1117/12.767058
   Ishibuchi H, 2004, FUZZY SET SYST, V141, P59, DOI 10.1016/S0165-0114(03)00114-3
   Ishibuchi H., 2002, P GEN EV COMP C, P399
   Jayachandran A, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P282, DOI 10.1109/ICACCCT.2012.6320787
   Jeong BG, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P316, DOI 10.1109/CISP.2008.660
   Jeong BG, 2008, INT CONF SIGN PROCES, P836, DOI 10.1109/ICOSP.2008.4697258
   Kapoor M., 2012, INT J ADV RES COMPUT, V1, P35
   Karloff A, 2009, INT CONF ELECTRO INF, P144
   Kim S., 2011, 11 NATL PUBLIC MANAG, P1, DOI DOI 10.1109/MMSP.2011.6093801
   Koczy LT, 1997, IEEE T SYST MAN CY B, V27, P14, DOI 10.1109/3477.552182
   MANTERE T, 2001, ARPAKANNUS, V1, P39
   Roubos JA, 2003, INFORM SCIENCES, V150, P77, DOI 10.1016/S0020-0255(02)00369-9
   Tsai PS, 2002, J ELECTRON IMAGING, V11, P293, DOI 10.1117/1.1479702
   Yi-Nung Liu, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P365, DOI 10.1109/ICCE.2010.5418700
NR 34
TC 16
Z9 16
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10047
EP 10063
DI 10.1007/s11042-019-08091-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600017
DA 2024-07-18
ER

PT J
AU Sujatha, K
AF Sujatha, Krishnamoorthy
TI Automatic epilepsy detection using hybrid decomposition with multi class
   support vector method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram; Epilepsy; Multi class support vector method;
   Signal decomposition
AB The epilepsy has been detected from the electroencephalogram (EEG) by utilizing the complex wavelet transform with support vector machine. These methods successfully examine each and every frequency in the EEG signal for detecting the epilepsy with effective manner because epilepsy is one of the most important brain abnormalities which affect the entire brain function. The epilepsy is occurring due to the brain stroke, lack of blood flow, brain fever and so on, these lead to create the number of human deaths. So, the brain epilepsy needs to be analyzed and it has to be detected for improving the epilepsy recognition rate. But the major problem with the epilepsy recognition is the accuracy and efficiency of the classifier because of the traditional approximation entropy only extracts the minimum number of features which is difficult to detect the epilepsy with effective manner. These problems increase the false classification rate while analyzing the brain features. So, brain abnormalities has been automatically recognized by using the various machine learning steps like preprocessing, signal decomposition, feature extraction, feature selection and classification. In this research, the brain Epilepsy is recognized by applying the Hybrid Multi Class Support Vector Machine (HMCSVM). Then the performance of the system is analyzed using the experimental results and discussions.
C1 [Sujatha, Krishnamoorthy] Wenzhou Kean Univ, Dept Comp Sci, Sch Sci & Technol, 88 Daxue Rd, Wenzhou, Zhejiang, Peoples R China.
C3 Wenzhou-Kean University
RP Sujatha, K (corresponding author), Wenzhou Kean Univ, Dept Comp Sci, Sch Sci & Technol, 88 Daxue Rd, Wenzhou, Zhejiang, Peoples R China.
EM sujatha@wku.edu.cn
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Bafna Y, 2018, ADV INTELL SYST, V696, P729, DOI 10.1007/978-981-10-7386-1_61
   Behri Miznan., 2018, 2018 Advances in Science and Engineering Technology International Conferences (ASET), P1
   Ben Naceur M, 2018, COMPUT METH PROG BIO, V166, P39, DOI 10.1016/j.cmpb.2018.09.007
   Gomathi M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P1, DOI 10.1109/iss1.2019.8908057
   Gupta D., 2018, International Journal of Advanced Technology and Engineering Exploration, V5, P11
   Islam MN, 2018, INT SYMPOS VLSI DES
   Manogaran G., 2018, IEEE ACCESS
   Manogaran G, 2019, IEEE ACCESS, V7, P12, DOI 10.1109/ACCESS.2018.2878276
   Mitra S., 2018, ARXIV180607589
   Mohammed MA, 2020, J SUPERCOMPUT, V76, P1086, DOI 10.1007/s11227-018-2587-z
   Mohan G, 2018, BIOMED SIGNAL PROCES, V39, P139, DOI 10.1016/j.bspc.2017.07.007
   Morgan SE, 2018, NETW NEUROSCI, V2, P285, DOI 10.1162/netn_a_00038
   Saini N, 2019, ADV INTELL SYST, V697, P551, DOI 10.1007/978-981-13-1822-1_51
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Sharma M, 2018, LECT NOTE DATA ENG, V4, P145, DOI 10.1007/978-981-10-4600-1_14
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Tahernezhad-Javazm F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aa8063
   Tolba A, 2018, J MED IMAG HEALTH IN, V8, P775, DOI 10.1166/jmihi.2018.2349
   Varuna Shree N, 2018, Brain Inform, V5, P23, DOI 10.1007/s40708-017-0075-5
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
NR 21
TC 4
Z9 5
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9871
EP 9890
DI 10.1007/s11042-019-08359-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600008
DA 2024-07-18
ER

PT J
AU Sakkari, M
   Zaied, M
AF Sakkari, Mohamed
   Zaied, Mourad
TI A Convolutional Deep Self-Organizing Map Feature extraction for machine
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep-SOMs; Unsupervised learning; Automatic feature extraction; Machine
   learning
ID NETWORK
AB In this work we propose a new Unsupervised Deep Self-Organizing Map (UDSOM) algorithm for feature extraction, quite similar to the existing multi-layer SOM architectures. The principal underlying idea of using SOMs is that if a neuron is wins n times, these n inputs that activated this neuron are similar. The basic principle consists of an alternation of phases of splitting and abstraction of regions, based on a non-linear projection of high-dimensional data over a small space using Kohonen maps following a deep architecture. The proposed architecture consists of a splitting process, layers of alternating self-organizing, a rectification function RELU and an abstraction layer (convolution-pooling). The self-organizing layer is composed of a few SOMs with each map focusing on modelling a local sub-region. The most winning neurons of each SOM are then organized in a second sampling layer to generate a new 2D map. In parallel to this transmission of the winning neurons, an abstraction of the data space is obtained after the convolution-pooling module. The ReLU is then applied. This treatment is applied more than once, changing the size of the splitting window and the displacement step on the reconstructed input image each time. In this way, local information is gathered to form more global information in the upper layers by applying each time a convolution filter of the level. The architecture of the Unsupervised Deep Self-Organizing Map is unique and retains the same principle of deep learning algorithms. This architecture can be very interesting in a Big Data environment for machine learning tasks. Experiments have been conducted to discuss how the proposed architecture shows this performance.
C1 [Sakkari, Mohamed; Zaied, Mourad] Univ Gabes, Natl Sch Engn Gabes, RTIM, 77 Rue Barcelone, Zrig 6033, Gabes, Tunisia.
C3 Universite de Gabes
RP Sakkari, M (corresponding author), Univ Gabes, Natl Sch Engn Gabes, RTIM, 77 Rue Barcelone, Zrig 6033, Gabes, Tunisia.
EM med.benahmed.sakkari@gmail.com; mourad.zaied@ieee.org
RI SAKKARI, Mohamed/JKJ-2841-2023
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR [Anonymous], ARXIV151106241
   [Anonymous], INTEGRATION UNSUPERV
   Bakalos N, 2019, IEEE SIGNAL PROC MAG, V36, P36, DOI 10.1109/MSP.2018.2885359
   Barbalho JM, 2003, IEEE IJCNN, P753
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   BO L, 2013, EXPT ROBOTICS SPRING, V88
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Coates Adam., 2011, P 14 INT C ART INT S, P215
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Dosovitskiy Alexey, 2013, ARXIV13125242
   Dozono H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P767, DOI [10.1109/CSCI.2016.0149, 10.1109/CSCI.2016.148]
   ELEND L, 2019, INT WORKSH SELF ORG, P23
   Furao S, 2008, NEURAL NETWORKS, V21, P1537, DOI 10.1016/j.neunet.2008.07.001
   Gens R., 2012, P NIPS, P3248
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   IEEE, 2017, I C COMP SYST APPLIC, P196, DOI 10.1109/AICCSA.2017.104
   Jaitly N, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P2577
   JOSHI AV, 2020, MACHINE LEARNING ART, P133
   Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lichodzijewski P, 2002, IEEE IJCNN, P1714, DOI 10.1109/IJCNN.2002.1007776
   Liu MZ, 2016, INT J ADV MANUF TECH, V85, P1471, DOI 10.1007/s00170-015-8026-x
   MICLUT B, 2014, LECT NOTES COMPUTER, V8753
   Najjar T, 2013, LECT NOTES COMPUT SC, V7902, P321, DOI 10.1007/978-3-642-38679-4_31
   NAKAYAMA H, 2013, BMVC
   Ranzato M., 2008, P 25 INT C MACH LEAR, P792
   Ren X., 2017, INT WORKSH DIG WAT, P378
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   SAKKARI M, 2016, 9 INT C MACH VIS ICM
   Shen FR, 2006, NEURAL NETWORKS, V19, P90, DOI 10.1016/j.neunet.2005.04.006
   Shen FR, 2010, LECT NOTES COMPUT SC, V6354, P535, DOI 10.1007/978-3-642-15825-4_74
   VELLIDO A, 2019, P 13 INT WORKSH WSOM, P26
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Walczak S., 2019, Advanced Methodologies and Technologies in Artificial Intelligence, Computer Simulation, and Human-Computer Interaction, DOI [10.4018/978-1-5225-7368-5, DOI 10.4018/978-1-5225-7368-5.CH004]
   Wicramasinghe C.S., 2019, IEEE T IND INFORM
   Wong HS, 2008, PATTERN RECOGN, V41, P468, DOI 10.1016/j.patcog.2007.06.009
NR 41
TC 12
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19451
EP 19470
DI 10.1007/s11042-020-08822-9
EA MAR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521701400001
DA 2024-07-18
ER

PT J
AU Yang, DS
   Liu, CY
   Liao, WH
   Ruan, SJ
AF Yang, Deng-Shun
   Liu, Chun-Yu
   Liao, Wei-Hao
   Ruan, Shanq-Jang
TI Crowd gathering and commotion detection based on the stillness and
   motion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd abnormal behaviors; Surveillance application; Crowd feature
   engineering; Image recognition
ID BEHAVIOR; CNN
AB The abnormal event detection becomes an important topic recently. This paper presents a method to detect the crowd gathering, as well as the commotion event after the crowd gathering. The proposed stillness model and the motion model are based on the improved background subtraction and the optical flow feature. We construct the long-term stillness level by the break bucket model and clustering the instantaneous stillness level. Then the crowd gathering event is decided by the threshold with the long-term stillness level. Furthermore, the motion model is applied for detecting the commotion event after the crowd gathering. In the experiment, we used the dataset of PET2009. The proposed method is verified by the experiment with 97% accuracy.
C1 [Yang, Deng-Shun; Liu, Chun-Yu; Liao, Wei-Hao; Ruan, Shanq-Jang] NTUST, Dept Elect & Comp Engn, 43 Keelung Rd,Sec 4, Taipei 10607, Taiwan.
C3 National Taiwan University of Science & Technology
RP Ruan, SJ (corresponding author), NTUST, Dept Elect & Comp Engn, 43 Keelung Rd,Sec 4, Taipei 10607, Taiwan.
EM dengshun83@gmail.com; neil.sorrow2012@gmail.com; m505082003@gmail.com;
   sjruan@mail.ntust.edu.tw
CR Albiol A, 2009, IEEE IMAGE PROC, P2569, DOI 10.1109/ICIP.2009.5414002
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Chebiyyam M, 2018, MULTIMED TOOLS APPL, V77, P16223, DOI 10.1007/s11042-017-5196-6
   Cheriyadat A. M., 2008, P 6 IEEE COMP SOC WO, P1, DOI DOI 10.1109/CVPRW.2008.4562983
   Chondro P, 2019, IEEE CONSUM ELECTR M, V8, P32, DOI 10.1109/MCE.2019.2905486
   El Harrouss O., 2016, 2016 18 C OP INN, P1
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Fradi H, 2016, J MULTIMODAL USER IN, V10, P307, DOI 10.1007/s12193-015-0179-2
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Gong C, 2015, OPT EXPRESS, V23, P20576, DOI 10.1364/OE.23.020576
   Guogang Xiong, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P495, DOI 10.1109/ICINFA.2011.5949043
   Gupta T, 2019, IEEE SYS MAN CYBERN, P2877, DOI [10.1109/SMC.2019.8914152, 10.1109/smc.2019.8914152]
   Hussain N, 2011, SAFETY SCI, V49, P824, DOI 10.1016/j.ssci.2011.01.005
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   La Vigne NG, 2011, TECH REP
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Liu CY, 2018, IEICE T INF SYST, VE101D, P1968, DOI 10.1587/transinf.2018EDL8005
   Myo T, 2013, INTELLIGENT MULTIMED, P17
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Swathi HY, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ELECTRONICS AND COMMUNICATION TECHNOLOGY (ICRAECT), P169, DOI 10.1109/ICRAECT.2017.66
   Xie SC, 2019, NEURAL COMPUT APPL, V31, P175, DOI 10.1007/s00521-018-3692-x
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Xu YP, 2019, MACH VISION APPL, V30, P945, DOI 10.1007/s00138-018-0971-6
   Yugendar P, 2019, JORDAN J CIV ENG, V13, P446
   Zhang Z, 2012, OPTICAL ENG CROWD DE, V51
   Zhao R, 2019, J PHYS C SER, V77, P1176
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
NR 29
TC 3
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19435
EP 19449
DI 10.1007/s11042-020-08827-4
EA MAR 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521671800001
DA 2024-07-18
ER

PT J
AU Zhu, XY
   Yuan, J
   Xiao, Y
   Zheng, Y
   Qin, Z
AF Zhu, Xianyi
   Yuan, Jin
   Xiao, Yi
   Zheng, Yan
   Qin, Zheng
TI Stroke classification for sketch segmentation by fine-tuning a
   developmental VGGNet16
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stroke classification; Sketch segmentation; Transfer learning;
   Fine-tuning; Convolutional neural network
AB Sketch segmentation and labeling face two challenges: few samples and few features. 3D data-driven methods use additional labeled 3D meshes to increase samples. However, they are not feasible for the abstract sketches that have no corresponding 3D meshes. And handcrafted feature based methods, although need no 3D meshes, are sensitive to various strokes. To address the challenges, we explore transfer learning based on convolutional neural network (CNN) by fine-tuning a pre-trained CNN to classify strokes for sketch segmentation. We propose a novel informative input for the CNN, making the position information of strokes clear. To improve fine-tuning during transfer learning, we propose to add grouped filter layers to the CNN, making the CNN's representational capacity incremental. Compared with the state-of-arts, our experimental results achieve 9.7% improvement on the abstract sketch dataset, and 2% improvement on the sketch dataset that has corresponding 3D meshes.
C1 [Zhu, Xianyi; Yuan, Jin; Xiao, Yi; Qin, Zheng] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Zheng, Yan] Hunan Univ, Coll Elect & Informat Engn, Changsha, Peoples R China.
C3 Hunan University; Hunan University
RP Yuan, J (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
EM yuanjin@hnu.edu.cn
RI Wang, Zejun/KBB-8454-2024
FU National Key R&D Program of China [2018YFB0203904]; NSFC from PRC
   [61872137, 61502158, 61502157, 61472131, 61772191]; Hunan NSF
   [2017JJ3042]; Science and Technology Key Projects of Hunan Province
   [2015TP1004, 2015SK2087, 2015JC1001, 2016JC2012]
FX The work is supported by the National Key R&D Program of China
   (2018YFB0203904), NSFC from PRC (61872137, 61502158, 61502157, 61472131,
   61772191), Hunan NSF (2017JJ3042), and Science and Technology Key
   Projects of Hunan Province (2015TP1004, 2015SK2087, 2015JC1001,
   2016JC2012).
CR [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34
   Ding ZM, 2019, IEEE T NEUR NET LEAR, V30, P1768, DOI 10.1109/TNNLS.2018.2874567
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Fan LB, 2013, COMPUT GRAPH FORUM, V32, P157, DOI 10.1111/cgf.12223
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He JY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P448, DOI 10.1145/3123266.3123321
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoffman Judy, 2018, ICML, P1994
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Huh Minyoung, 2016, ABS160808614 CORR
   Ioannou Y, 2017, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2017.633
   Kim B, 2018, COMPUT GRAPH FORUM, V37, P329, DOI 10.1111/cgf.13365
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2017, MULTIMED TOOLS APPL, V76, P26603, DOI 10.1007/s11042-016-4187-3
   Li CJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275051
   Li JJ, 2019, IEEE T IMAGE PROCESS, V28, P6103, DOI 10.1109/TIP.2019.2924174
   Li JJ, 2019, IEEE T NEUR NET LEAR, V30, P1381, DOI 10.1109/TNNLS.2018.2868854
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li L, 2019, IEEE COMPUT GRAPH, V39, P38, DOI 10.1109/MCG.2018.2884192
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mou L., 2016, P C EMP METH NAT LAN, P479, DOI 10.18653/v1/D16-1046
   Noris G, 2012, COMPUT GRAPH FORUM, V31, P2516, DOI 10.1111/j.1467-8659.2012.03224.x
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Qi YG, 2015, PROC CVPR IEEE, P1856, DOI 10.1109/CVPR.2015.7298795
   Qi YG, 2013, IEEE IMAGE PROC, P270, DOI 10.1109/ICIP.2013.6738056
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A.A., 2016, ARXIV
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Sarvadevabhatla RK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P10, DOI 10.1145/3123266.3123270
   Schneider RG, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2898351
   Seddati O, 2017, MULTIMED TOOLS APPL, V76, P22333, DOI 10.1007/s11042-017-4799-2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan G, 2020, INVESTMENT IN EARLY CHILDHOOD EDUCATION IN A GLOBALIZED WORLD: POLICIES, PRACTICES, AND PARENTAL PHILOSOPHIES IN CHINA, INDIA, AND THE UNITED STATES, P1, DOI 10.1057/978-1-137-60041-7
   Tan GH, 2017, MULTIMED TOOLS APPL, V76, P6429, DOI 10.1007/s11042-016-3305-6
   Tan GH, 2016, MULTIMED TOOLS APPL, V75, P10213, DOI 10.1007/s11042-015-3160-x
   Wan L, 2018, MULTIMED TOOLS APPL, V77, P13753, DOI 10.1007/s11042-017-4987-0
   Wang W., 2012, Proceedings of the 1st International Workshop on Cross Domain Knowledge Discovery in Web and Social Network Mining, P10, DOI DOI 10.1145/2351333.2351335
   Wang YX, 2017, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2017.323
   Wang Z, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P626, DOI 10.1109/ICInfA.2012.6246889
   Xie GT, 2018, PROC CVPR IEEE, P8847, DOI 10.1109/CVPR.2018.00922
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V58, P53, DOI 10.1016/j.jvcir.2018.11.028
   Zhou SZ, 2018, COMPUT GRAPH-UK, V73, P80, DOI 10.1016/j.cag.2018.03.002
NR 60
TC 7
Z9 8
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33891
EP 33906
DI 10.1007/s11042-020-08706-y
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000527911500001
DA 2024-07-18
ER

PT J
AU Smitha, JA
   Rajkumar, N
AF Smitha, J. A.
   Rajkumar, N.
TI Optimal feed forward neural network based automatic moving vehicle
   detection system in traffic surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic surveillance system; Moving vehicle detection; Tracking;
   Hypothesis generation; Hypothesis verification; Feedforward neural
   network; Grasshopper optimization algorithm
ID ROAD; TRACKING; RECOGNITION; ALGORITHM; FEATURES
AB In intelligent transportation system, traffic surveillance is an important topic. One challenging problem for complex urban traffic surveillance system is robust vehicle detection and tracking. Therefore, in this paper, we develop a two-stage approach for moving vehicle detection system. The proposed system mainly consists of two stages such as hypothesis generation (HG) and hypothesis verification (HV). In the first step, we generate the hypotheses using shadows under vehicles is darker than road region concept. In the second step, we verify hypotheses generated in the first step whether correct or not using optimal feedforward neural network (OFFNN). Here, to extract vehicle features, we utilize two types of histogram orientation gradients descriptors (HOG). In training stage, the histogram orientation gradients features are given to the OFFNN classifier. The weights corresponding FFNN is optimally select using improved grasshopper optimization algorithm (IGOA). The experimental results show that the proposed moving vehicle detection system performs better accuracy compare to other methods.
C1 [Smitha, J. A.] AMC Engn Coll, Bangalore 560083, Karnataka, India.
   [Rajkumar, N.] Hindusthan Coll Engn & Technol, Coimbatore 641032, Tamil Nadu, India.
RP Smitha, JA (corresponding author), AMC Engn Coll, Bangalore 560083, Karnataka, India.
EM smithaja3362@gmail.com
CR Alonso D, 2007, IEEE IMAGE PROC, P2017
   APPATHURAI A, 2019, CIRCUITS SYSTEMS SIG, P1
   Arróspide J, 2012, INT J AUTO TECH-KOR, V13, P955, DOI 10.1007/s12239-012-0097-1
   Bertozzi M, 1997, J SYST ARCHITECT, V43, P317, DOI 10.1016/S1383-7621(96)00106-3
   Chen BH, 2015, INFORM SCIENCES, V299, P283, DOI 10.1016/j.ins.2014.12.033
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chintalacheruvu N., 2012, Journal of Transportation Technologies, V2, P305, DOI DOI 10.4236/JTTS.2012.24033
   Fossati A, 2011, MACH VISION APPL, V22, P439, DOI 10.1007/s00138-009-0243-6
   Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   KUEHNLE A, 1991, PATTERN RECOGN LETT, V12, P249, DOI 10.1016/0167-8655(91)90039-O
   Kumar T, 2016, PROCEDIA COMPUT SCI, V89, P726, DOI 10.1016/j.procs.2016.06.045
   LE X, 2018, ROBOT INTELLIGENCE T, P491
   Lin BF, 2012, IEEE T INTELL TRANSP, V13, P737, DOI 10.1109/TITS.2011.2182649
   Mandelbaum R, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P288, DOI 10.1109/ACV.1998.732909
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Matthews ND, 1996, CONTROL ENG PRACT, V4, P473, DOI 10.1016/0967-0661(96)00028-7
   MINI TV, 2019, EAI INT C BIG DAT IN, P221
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Rosenberg Yoav., 1998, Real-time object tracking from a moving video camera: A software approach on a pc
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   SMITHA JA, 2018, INT J BUS INTELL DAT
   SUN Z, 2002, P IEEE INT WORKSH AP
   SUN Z, 2006, IEEE T IMAGE PROCESS, V15
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Tian B, 2014, IEEE T INTELL TRANSP, V15, P597, DOI 10.1109/TITS.2013.2283302
   TZOMAKAS C, 1998, 9806 RUHRUNIVERSITY
   Wang XM, 2016, NEUROCOMPUTING, V173, P450, DOI 10.1016/j.neucom.2015.04.117
   Wong CC, 2016, IEEE ICCE
   Yuan QA, 2011, IEEE T PATTERN ANAL, V33, P514, DOI 10.1109/TPAMI.2010.117
   ZHANG FH, 2016, SENSORS BASEL, V16
   Zhang FK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030594
   Zhang W, 2012, IEEE T INTELL TRANSP, V13, P140, DOI 10.1109/TITS.2011.2165338
NR 36
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18591
EP 18610
DI 10.1007/s11042-020-08757-1
EA MAR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518345200001
DA 2024-07-18
ER

PT J
AU Jeong, YS
AF Jeong, Yoon-Su
TI Multi-hash chain based multimedia search technology optimized for
   distributed environments using IoT devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia search; Multi-hash based; Distribution environment; IoT
   devices; Accuracy; Knowledge discovery computing
ID PRODUCT QUANTIZATION; IMAGE
AB Recently, research has been active in various fields in relation to multimedia data retrieval to reduce the accuracy and calculation costs of multimedia retrieval. In particular, various search methods using multimedia has been developed. However, in many applications currently operating in the system, large multimedia data is distributed across servers or sites at different locations, so assembling multimedia data only as a hash presents huge computational, communication, and storage costs. In this paper, when searching for multimedia information stored in distributed environments using IoT devices, multiple hash chain-based multimedia retrieval techniques are proposed to minimize accuracy and calculation costs. The proposed technique is aimed at improving the accuracy of multimedia by using IoT devices to divide-and-conquer multimedia information that is collected and stored distributed. The proposed technique provides probability values for each segmented multimedia information by disaggregating the various attribute information that is composed of multimedia as much as possible, thereby increasing the accuracy of the multimedia that users want. Suggestion techniques determine the group size of multimedia data according to the priority of layered multimedia data. Multimedia group data include multimedia data contained in higher layers and subdivides the various attribute information constituting multimedia data. In addition, the proposed techniques improve the accessibility of multimedia data over existing ones by linking priority information between multimedia data.
C1 [Jeong, Yoon-Su] Mokwon Univ, Dept Informat & Commun Convergence Engn, 88 Doanbuk Ro, Daejeon 35349, South Korea.
C3 Mokwon University
RP Jeong, YS (corresponding author), Mokwon Univ, Dept Informat & Commun Convergence Engn, 88 Doanbuk Ro, Daejeon 35349, South Korea.
EM bukmunro@mokwon.ac.kr
CR Amato F, 2018, MULTIMED TOOLS APPL, V77, P17803, DOI 10.1007/s11042-017-5556-2
   Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226
   Chen CC, 2015, J VIS COMMUN IMAGE R, V30, P86, DOI 10.1016/j.jvcir.2015.02.014
   Chen Q, 2016, INT SYM COMPUT INTEL, P118, DOI [10.1109/ISCID.2016.141, 10.1109/ISCID.2016.2036]
   Chowdhury M, 2017, MULTIMED TOOLS APPL, V76, P21839, DOI 10.1007/s11042-016-4172-x
   DO TT, 2015, DISCRETE HASHING DEE, P1
   Dongbao Yang, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P525, DOI 10.1109/ICMEW.2017.8026290
   Eschenauer L., 2002, P 9 ACM C COMPUTER C, P41, DOI [10.1145/586110.586117, DOI 10.1145/586110.586117]
   Ge TZ, 2013, PROC CVPR IEEE, P2946, DOI 10.1109/CVPR.2013.379
   Guo D, 2016, NEUROCOMPUTING, V217, P92, DOI 10.1016/j.neucom.2016.04.061
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Jain M., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1441
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kalantidis Y, 2014, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR.2014.298
   Kamen A, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/6183218
   Li FY, 2018, MULTIMED TOOLS APPL, V77, P17953, DOI 10.1007/s11042-017-4759-x
   Lin J, 2016, IEEE DATA COMPR CONF, P397, DOI 10.1109/DCC.2016.23
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   LIU W, 2011, P INT C MACH LEARN, P1, DOI DOI 10.1109/VPPC.2011.6043110
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   NOROUZI M, 2011, P 28 INT C MACH LEAR, P353
   Ren GX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P769, DOI 10.1145/2647868.2654956
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Zhai DM, 2018, IEEE T MULTIMEDIA, V20, P675, DOI 10.1109/TMM.2017.2749160
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3025, DOI 10.1109/TIP.2014.2326010
   Zhang XF, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2461671
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   ZHOU W, 2012, P 20 ACM INT C MULT, P169
   Zhou WG, 2014, IEEE T MULTIMEDIA, V16, P601, DOI 10.1109/TMM.2014.2301979
NR 37
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34661
EP 34678
DI 10.1007/s11042-020-08772-2
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000518068900003
DA 2024-07-18
ER

PT J
AU Alouache, D
   Ameur, Z
   Kachi, D
AF Alouache, Djamal
   Ameur, Zohra
   Kachi, Djemaa
TI Catadioptric images compression using an adapted neighborhood and the
   shape-adaptive DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Catadioptric images; SA DCT (shape adaptive DCT); Adapted neighborhood;
   Spherical image; Low bit rate coding
AB In the catadioptric images, the neighborhood topology is usually modified by the mirror shape which consists of significant radial distortions and low non-uniform resolution because of its convexity geometry. Consequently, conventional compression approaches (i.e. H.264 intra-frame coding or JPEG standard) based on rectangular block partitioning cannot be applied directly to catadioptric images because they inevitably produce significant block effects. In this investigation, we propose a new coding scheme based on an adaptive block partitioning. Particularly, to reduce the blocking artifacts, we propose the shape-adaptive discrete cosine transform (SA-DCT) and adapted neighborhood. The adapted neighborhood is obtained from the equivalence between the catadioptric image and the scene point's projection on the unit sphere. The adapted blocks shape correctly follows the geometric context and varies according to the resolution of the catadioptric images. Such changes improve considerably the compression efficiency using the block partitioning in catadioptric images. Experimental results figured out that our proposal scheme outperforms the JPEG standard and the Intra-frame coder H264. Moreover the proposed coding scheme based on SA-DCT transform and the suitable partitioning for catadioptric images provides high PSNR and a considerable reduction of block effects compared to conventional approaches, especially in the case of low bit rate.
C1 [Alouache, Djamal; Ameur, Zohra] Univ Mouloud Mammeri UMMTO, Dept Elect Fac Genie Elect, Lab Anal & Modeling Random Phenomena LAMPA, Tizi Ouzou 15000, Algeria.
   [Kachi, Djemaa] Univ Picardie Jules Verne, Lab Modeling Informat & Syst MIS, 33 Rue St Leu, F-80039 Amiens 1, France.
C3 Universite Mouloud Mammeri de Tizi Ouzou; Universite de Picardie Jules
   Verne (UPJV)
RP Alouache, D (corresponding author), Univ Mouloud Mammeri UMMTO, Dept Elect Fac Genie Elect, Lab Anal & Modeling Random Phenomena LAMPA, Tizi Ouzou 15000, Algeria.
EM djamal.alouache@yahoo.fr
CR Alouache D, 2014, INT CONF MULTIMED, P69, DOI 10.1109/ICMCS.2014.6911139
   Amiri SA, 2018, MULTIMED TOOLS APPL, V77, P8677, DOI 10.1007/s11042-017-4763-1
   [Anonymous], IMAGE PROCESSING
   [Anonymous], APPL DIGITAL IMAGE P
   [Anonymous], 8R8 ISOIEC JTC1
   [Anonymous], INT C COMP AN IM PAT
   [Anonymous], 2014, DISCRETE COSINE TRAN
   [Anonymous], 2005 IEEE 7 WORKSH M
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2002, LECT NOTES COMPUT SC, V2353, P237
   Bastanlar Y, 2012, IMAGE VISION COMPUT, V30, P557, DOI 10.1016/j.imavis.2012.06.001
   Bauermann I, 2006, COMPUT IMAGING VIS, V32, P209, DOI 10.1007/1-4020-4179-9_30
   Belalia A, 2016, MULTIMED TOOLS APPL, V75, P10175, DOI 10.1007/s11042-015-3026-2
   Benamar F, 2015, ROBOT AUTON SYST, V64, P100, DOI 10.1016/j.robot.2014.09.036
   De Simone F, 2016, PICT COD SYMP
   Demonceaux C, 2006, PATTERN RECOGN LETT, V27, P1957, DOI 10.1016/j.patrec.2006.05.007
   Ding JJ, 2013, IEEE T IMAGE PROCESS, V22, P3664, DOI 10.1109/TIP.2013.2268971
   Ding JJ, 2011, LECT NOTES COMPUT SC, V6524, P252
   Ding JX, 2011, PROCEEDINGS OF THE 2011 EXCHANGE CONFERENCE - INTERNATIONAL MARKETING SCIENCE AND INFORMATION TECHNOLOGY, P168
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Djamal Alouache, 2014, International Journal of Image, Graphics and Signal Processing, V6, P20, DOI 10.5815/ijigsp.2014.09.03
   Du D, 2019, MAGN RESON IMAGING, V55, P60, DOI 10.1016/j.mri.2018.09.014
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Peng H, 2016, SCI REP-UK, V6, DOI 10.1038/srep22000
   Radgui A, 2011, COMPUT VIS IMAGE UND, V115, P1263, DOI 10.1016/j.cviu.2011.05.002
   Rameau F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P328, DOI 10.1109/ICCVW.2011.6130260
   Rizkallah M, 2018, EUR SIGNAL PR CONF, P897, DOI 10.23919/EUSIPCO.2018.8553080
   SIKORA T, 1995, SIGNAL PROCESS-IMAGE, V7, P381, DOI 10.1016/0923-5965(95)00009-9
   Tian P, 2019, MULTIMED TOOLS APPL, V78, P1117, DOI 10.1007/s11042-018-6397-3
   Tosic I, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P53
   Vermeirsch K, 2012, MULTIMED TOOLS APPL, V56, P385, DOI 10.1007/s11042-010-0593-0
   Wang YL, 2019, MULTIMED TOOLS APPL, V78, P12223, DOI 10.1007/s11042-018-6763-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
NR 34
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6781
EP 6797
DI 10.1007/s11042-019-08536-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900060
DA 2024-07-18
ER

PT J
AU Kumar, PB
   Parhi, DR
AF Kumar, Priyadarshi Biplab
   Parhi, Dayal R.
TI Navigational analysis of a humanoid using genetic algorithm with vision
   assistance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE GA; V-REP; Humanoid; Navigation; OpenCV; Computer vision
ID OPTIMIZATION; SYSTEM
AB In this paper, a novel vision assisted genetic algorithm based navigational controller has been designed for smooth and collision-free path generation of a humanoid robot. Here, sensory information regarding the nearest obstacle distance and path left to the destination are considered as the inputs to the genetic algorithm controller, and necessary turning angle is generated as the required output to avoid the obstacles present in the path and advance towards the destination. The vision based technique is integrated along with the sensor based navigational model to assist in deciding a safe direction of turn in case the humanoid encounters a dead end situation while negotiating with complicated obstacle settings. The developed model has been verified by navigational analysis of a NAO humanoid in a V-REP simulation arena. The simulation results are also validated against an experimental set-up prepared under laboratory conditions that resembles the simulation arena. The results obtained from both the platforms are compared in terms of selected navigational parameters, and a close agreement has been found between them with a minimal percentage of errors. Finally, the developed model is also evaluated against other existing navigational schemes, and substantial performance improvements have been observed.
C1 [Kumar, Priyadarshi Biplab] Natl Inst Technol Hamirpur, Dept Mech Engn, Hamirpur 177005, Himachal Prades, India.
   [Parhi, Dayal R.] Natl Inst Technol Rourkela, Mech Engn Dept, Robot Lab, Rourkela, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Hamirpur; National Institute of Technology (NIT System);
   National Institute of Technology Rourkela
RP Kumar, PB (corresponding author), Natl Inst Technol Hamirpur, Dept Mech Engn, Hamirpur 177005, Himachal Prades, India.
EM p.biplabkumar@gmail.com; dayaldoc@yahoo.com
RI Parhi, Dayal/M-7935-2018
OI Parhi, Dayal/0000-0002-2073-7136
CR Akdas D, 2014, ACTA POLYTECH HUNG, V11, P115
   Alsouly H, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL INTELLIGENCE, VOL 1: ECTA, P121, DOI 10.5220/0006033401210131
   [Anonymous], INT J ADV ENG TECHNO
   Assis LD, 2016, PROCEDIA COMPUT SCI, V80, P2261, DOI 10.1016/j.procs.2016.05.404
   Bagherian M, 2015, AERONAUT J, V119, P1271
   Bertram D, 2006, IEEE INT CONF ROBOT, P1874
   Cheng L., 2017, SYM SENSOR CONTR, DOI DOI 10.1155/2017/6305295
   Cosio FA, AUTONOMOUS ROBOT NAV
   Deepu R, 2015, PROCEDIA COMPUT SCI, V46, P1425, DOI 10.1016/j.procs.2015.02.061
   Erinc G, 2007, IEEE INT CONF ROBOT, P1843, DOI 10.1109/ROBOT.2007.363590
   Ferro M, 2016, IEEE-RAS INT C HUMAN, P75, DOI 10.1109/HUMANOIDS.2016.7803257
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gaspar J, 2000, IEEE T ROBOTIC AUTOM, V16, P890, DOI 10.1109/70.897802
   Güzel MS, 2013, ADV MECH ENG, DOI 10.1155/2013/234747
   Han ZL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181747
   Hartjes S, 2017, P I MECH ENG G-J AER, V231, P1115, DOI 10.1177/0954410016648980
   Hermanu A, 2004, INTELLIGENT ENG SYST, P319
   Hui N. B., 2016, GRD J GLOBAL RES DEV, V1, P53
   Huwedi A, 2012, 13 INT AR C INF TECH, P200
   Ibrahim MF, 2009, INT EL SEM
   Iossifidis I., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2204, DOI 10.1109/ROBIO.2011.6181619
   Kia C, 2005, INT J ADV ROBOT SYST, V2, P25, DOI [10.5772/5782, DOI 10.5772/5782]
   Klidbary Sajad Haghzad, 2013, International Journal of Materials, Mechanics and Manufacturing, V1, P360, DOI 10.7763/IJMMM.2013.V1.78
   Kofinas N, 2013, P 13 INT C AUT ROB S, P13
   Konolige K, 2008, SPRINGER TRAC ADV RO, V39, P179
   Kuffner J, 2003, IEEE INT CONF ROBOT, P932
   Kwasniewski KK, 2018, ACTA MECH AUTOMATICA, V12, P151, DOI 10.2478/ama-2018-0024
   Macesanu G, 2010, B TRANSILV U BRASOV, V3, P259
   McGookin EW, 2000, T I MEAS CONTROL, V22, P141, DOI 10.1177/014233120002200203
   Miao JB, 2017, AIP CONF PROC, V1864, DOI 10.1063/1.4992818
   Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352
   Ngangbam H. S., 2017, INT RES J ENG TECHNO, V4, P24
   Shi WR, 2009, INTELL AUTOM SOFT CO, V15, P289, DOI 10.1080/10798587.2009.10643032
   Silva CAD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124322
   Tamilselvi D, 2011, INT J COMPUT SCI ISS, V8, P433
   Tuncer A, 2012, ADV ELECTR COMPUT EN, V12, P57, DOI 10.4316/AECE.2012.01010
   Zhang JR, 2015, ADV MECH ENG, V7, DOI 10.1177/1687814015573783
NR 37
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8125
EP 8144
DI 10.1007/s11042-019-08307-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100056
DA 2024-07-18
ER

PT J
AU Shi, KX
   Zhu, LH
   Zhang, C
   Xu, L
   Gao, F
AF Shi, Kexin
   Zhu, Liehuang
   Zhang, Can
   Xu, Lei
   Gao, Feng
TI Blockchain-based multimedia sharing in vehicular social networks with
   privacy protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Multimedia sharing; Privacy protection; Vehicular social
   networks
ID INTERNET; VEHICLE
AB The rapid development of the vehicular ad-hoc network (VANET) promotes the development of vehicle electronics, networking, and intelligence. In addition, each vehicle can establish social relationships with others freely in vehicular social networks (VSNs). Multimedia also plays an important entity in vehicles' data sharing. However, VSNs are still in the early stage of development, and it may bring many security challenges in the process of sharing multimedia data. Both the users' and vehicles' privacy may be leaked, and users' communication habits are easy to be analyzed by adversaries. In addition, the shared multimedia data are more likely to be maliciously tampered with or forged. In this paper, we propose a privacy-preserving scheme based on blockchain for multimedia data sharing in VSNs. We use cryptographical primitives to hide the real identity of users, vehicles and RSUs. At the same time, we use blockchain to ensure reliable data sources and keep attackers from tampering or forging multimedia data. Finally, the feasibility of our scheme is proved by theoretical security analysis and comprehensive experimental evaluation.
C1 [Shi, Kexin; Zhu, Liehuang; Zhang, Can; Xu, Lei; Gao, Feng] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Shi, KX; Gao, F (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
EM 2120171049@bit.edu.cn; gaofengbit@foxmail.com
RI ZHU, LIEHUANG/A-6174-2018
CR [Anonymous], INT C EL
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], ACM S APPL COMP
   Atzori L, 2018, COMPUT NETW, V147, P132, DOI 10.1016/j.comnet.2018.10.001
   Chan CC, 2001, POWER ENG, V16, P240
   Fan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0993-7
   Gai KK, 2018, IEEE CLOUD COMPUT, V5, P21, DOI 10.1109/MCC.2018.064181116
   Gao F, 2018, IEEE NETWORK, V32, P184, DOI 10.1109/MNET.2018.1700269
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Guan ZT, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9451-y
   Guan ZT, 2019, J NETW COMPUT APPL, V125, P82, DOI 10.1016/j.jnca.2018.09.019
   Hasrouny H, 2017, VEH COMMUN, V7, P7, DOI 10.1016/j.vehcom.2017.01.002
   Meng FB, 2017, IEEE ACCESS, V5, P22796, DOI 10.1109/ACCESS.2017.2764098
   Mwasilu F, 2014, RENEW SUST ENERG REV, V34, P501, DOI 10.1016/j.rser.2014.03.031
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Sharma R, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2337, DOI 10.1109/ICACCI.2018.8554369
   Singh M., 2017, ARXIV170809721
   Wan SH, 2019, FUTURE GENER COMP SY, V91, P382, DOI 10.1016/j.future.2018.08.007
   Zhang AQ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0995-5
   Zheng BK, 2018, J COMPUT SCI TECH-CH, V33, P557, DOI 10.1007/s11390-018-1840-5
   Zhu LH, 2019, FUTURE GENER COMP SY, V91, P527, DOI 10.1016/j.future.2018.09.019
NR 21
TC 34
Z9 36
U1 2
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8085
EP 8105
DI 10.1007/s11042-019-08284-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100054
DA 2024-07-18
ER

PT J
AU Hekmatmanesh, A
   Wu, HP
   Jamaloo, F
   Li, M
   Handroos, H
AF Hekmatmanesh, Amin
   Wu, Huapeng
   Jamaloo, Fatemeh
   Li, Ming
   Handroos, Heikki
TI A combination of CSP-based method with soft margin SVM classifier and
   generalized RBF kernel for imagery-based brain computer interface
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain computer interface; Common spacial pattern (CSP); Kernel linear
   discriminator analysis (KLDA); Kernel principal component analysis
   (KPCA); Generalized radial basis function (GRBF); Soft margin support
   vector machine (SSVM)
ID SPATIAL-PATTERN METHOD; DISCRIMINANT-ANALYSIS; PCA; EEG; MACHINE;
   FILTERS
AB Several methods utilizing common spatial pattern (CSP) algorithm have been presented for improving the identification of imagery movement patterns for brain computer interface applications. The present study focuses on improving a CSP-based algorithm for detecting the motor imagery movement patterns. A discriminative filter bank of CSP method using a discriminative sensitive learning vector quantization (DFBCSP-DSLVQ) system is implemented. Four algorithms are then combined to form three methods for improving the efficiency of the DFBCSP-DSLVQ method, namely the kernel linear discriminant analysis (KLDA), the kernel principal component analysis (KPCA), the soft margin support vector machine (SSVM) classifier and the generalized radial bases functions (GRBF) kernel. The GRBF is used as a kernel for the KLDA, the KPCA feature selection algorithms and the SSVM classifier. In addition, three types of classifiers, namely K-nearest neighbor (K-NN), neural network (NN) and traditional support vector machine (SVM), are employed to evaluate the efficiency of the classifiers. Results show that the best algorithm is the combination of the DFBCSP-DSLVQ method using the SSVM classifier with GRBF kernel (SSVM-GRBF), in which the best average accuracy, attained are 92.70% and 83.21%, respectively. Results of the Repeated Measures ANOVA shows the statistically significant dominance of this method at p < 0.05. The presented algorithms are then compared with the base algorithm of this study i.e. the DFBCSP-DSLVQ with the SVM-RBF classifier. It is concluded that the algorithms, which are based on the SSVM-GRBF classifier and the KLDA with the SSVM-GRBF classifiers give sufficient accuracy and reliable results.
C1 [Hekmatmanesh, Amin; Wu, Huapeng; Li, Ming; Handroos, Heikki] Lappeenranta Univ Technol, Dept Mech Engn, Lab Intelligent Machines, Lappeenranta, Finland.
   [Jamaloo, Fatemeh] Shahed Univ, Dept Biomed Engn, Fac Engn, Tehran, Iran.
C3 Lappeenranta-Lahti University of Technology LUT; Shahed University
RP Hekmatmanesh, A (corresponding author), Lappeenranta Univ Technol, Dept Mech Engn, Lab Intelligent Machines, Lappeenranta, Finland.
EM Amin.Hekmatmanesh@lut.fi; huapeng.wu@lut.fi; f.jamaloo@shahed.ac.ir;
   ming.li@lut.fi; heikki.handroos@lut.fi
RI hekmatmanesh, amin/ABA-5750-2021
OI hekmatmanesh, amin/0000-0003-1220-0723; jamaloo,
   fatemeh/0009-0002-7944-9734; Li, Ming/0000-0002-7921-1307; wu,
   Huapeng/0000-0001-6759-6038
FU LUT University
FX Open access funding provided by LUT University.
CR Ang KK, 2008, IEEE IJCNN, P2390, DOI 10.1109/IJCNN.2008.4634130
   Ang KK, 2012, FRONTIERS NEUROSCIEN, P6
   [Anonymous], PRACTICAL GUIDE SUPP
   Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dornhege G, 2006, IEEE T BIO-MED ENG, V53, P2274, DOI 10.1109/TBME.2006.883649
   Fernández-Navarro F, 2011, NEUROCOMPUTING, V74, P2502, DOI 10.1016/j.neucom.2010.11.032
   Girden ER., 1992, ANOVA: Repeated measures
   HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989
   Hekmatmanesh A., 2018, NEW TRENDS MED SERVI, P186
   Hekmatmanesh A, 2019, MULTIMED TOOLS APPL, P1
   Hekmatmanesh A, 2018, AIP CONF PROC, V1956, DOI 10.1063/1.5034255
   Hekmatmanesh A, 2017, ADV ELECTR ELECTRON, V15, P435, DOI 10.15598/aeee.v15i3.2174
   Hekmatmanesh A, 2014, IRAN CONF ELECTR ENG, P1898, DOI 10.1109/IranianCEE.2014.6999850
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Jamaloo Fatemeh, 2015, J Med Signals Sens, V5, P156
   Khalaf A, 2019, J NEUROSCIENCE METHO
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Krauss T., 1994, SIGNAL PROCESSING TO
   Lemm S, 2005, IEEE T BIO-MED ENG, V52, P1541, DOI 10.1109/TBME.2005.851521
   Lotte F, 2011, IEEE T BIO-MED ENG, V58, P355, DOI 10.1109/TBME.2010.2082539
   Mahato Shalini, 2019, Nanoelectronics, Circuits and Communication Systems. Proceeding of NCCS 2017. Lecture Notes in Electrical Engineering (LNEE 511), P323, DOI 10.1007/978-981-13-0776-8_30
   Marseken S. F., 2010, TUKEYS RANGE TEST
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Noori SMR, 2014, 2014 21TH IRANIAN CONFERENCE ON BIOMEDICAL ENGINEERING (ICBME), P119, DOI 10.1109/ICBME.2014.7043905
   Novi Q, 2007, 2007 3RD INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING, VOLS 1 AND 2, P204, DOI 10.1109/CNE.2007.369647
   Ozgen C., 2010, THESIS
   Park S, 2008, J INTEL MAT SYST STR, V19, P509, DOI 10.1177/1045389X07077400
   Peters J, 2017, ADAPT COMPUT MACH LE
   Pregenzer M, 1995, DISTINCTION SENSITIV, P433
   Ramoser H, 2000, IEEE T REHABIL ENG, V8, P441, DOI 10.1109/86.895946
   Ro D., 1973, Pattern classification and scene analysis
   Roth V, 2000, ADV NEUR IN, V12, P568
   Santamaria L, 2018, HEALTHC TECHNOL LETT, V5, P88, DOI 10.1049/htl.2017.0049
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Subasi A, 2005, COMPUT METH PROG BIO, V78, P87, DOI 10.1016/j.cmpb.2004.10.009
   Sun GQ, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL II, P1
   Surhone L.M., 2010, Wilcoxon Signed-Rank test
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Thomas KP, 2009, IEEE T BIO-MED ENG, V56, P2730, DOI 10.1109/TBME.2009.2026181
   Wang YJ, 2005, P ANN INT IEEE EMBS, P5392
   Widjaja D, 2012, IEEE T BIO-MED ENG, V59, P1169, DOI 10.1109/TBME.2012.2186448
   Xu Y, 2018, J CIRCUIT SYST COMP, V5, P1950123
   Ye BG, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090701
   Zhao XM, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-20
   Zou Jim, 2018, 2018 European Conference on Optical Communication (ECOC), DOI 10.1109/ECOC.2018.8535392
NR 47
TC 33
Z9 34
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17521
EP 17549
DI 10.1007/s11042-020-08675-2
EA FEB 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516442500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Wang, Y
   Yan, J
   Chen, ZX
   Wang, DH
AF Zhang, Xufan
   Wang, Yong
   Yan, Jun
   Chen, Zhenxing
   Wang, Dianhong
TI A unified saliency detection framework for visible and infrared images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Saliency detection; Compressed sensing; Feature
   coefficients
ID OBJECT DETECTION
AB Conventional saliency detection algorithms usually achieve good detection performance at the cost of high computational complexity, and most of them focus on visible images. In this paper, we propose a simple and effective saliency detection framework, which can adapt to the characteristics of visible or infrared images. The proposed approach can be seen a three-step solution. On the first step block-based image compressed reconstruction is applied to the input image for reducing the computational complexity. On a second step a local contrast technique is used at the block level to obtain a primary saliency map. In this step, the appropriate features such as color or intensity will be selected for different kinds of input images. Finally, the last step uses a linear combination of feature coefficients to refine the salient regions from the primary saliency map so as to generate the final saliency map. The experimental results show that the proposed method has desirable detection performance in terms of accuracy and runtime.
C1 [Zhang, Xufan; Wang, Yong; Yan, Jun; Chen, Zhenxing; Wang, Dianhong] China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
C3 China University of Geosciences
RP Wang, Y (corresponding author), China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
EM wy112708@163.com
FU National Natural Science Foundation of China [61771436, 61973283]
FX This work was supported in part by the National Natural Science
   Foundation of China under grants No. 61771436 and 61973283.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2006, P CVPR
   [Anonymous], 2003, ACMMM
   Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen CLZ, 2015, PATTERN RECOGN, V48, P2885, DOI 10.1016/j.patcog.2015.01.025
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cruz G, 2015, LECT NOTES COMPUT SC, V9163, P511, DOI 10.1007/978-3-319-20904-3_46
   Davis J. W, OTCBVS BENCHMARK DAT
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x
   Guo MW, 2014, NEUROCOMPUTING, V144, P184, DOI 10.1016/j.neucom.2014.04.054
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 1999, ADV NEUR IN, V11, P789
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Kim S, 2009, J INFRARED MILLIM TE, V30, P994, DOI 10.1007/s10762-009-9518-2
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu ST, 2018, J SYST ENG ELECTRON, V29, P483, DOI 10.21629/JSEE.2018.03.05
   [刘松涛 Liu Songtao], 2018, [光电子·激光, Journal of Optoelectronics·Laser], V29, P333
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang QZ, 2015, INFORM FUSION, V26, P103, DOI 10.1016/j.inffus.2015.01.001
   Wang X, 2017, INFRARED PHYS TECHN, V87, P91, DOI 10.1016/j.infrared.2017.10.005
   Wang X, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/2483169
   Wang Y, 2015, SENSORS-BASEL, V15, P3116, DOI 10.3390/s150203116
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang XF, 2018, MULTIMED TOOLS APPL, V77, P13679, DOI 10.1007/s11042-017-4981-6
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 44
TC 2
Z9 2
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17331
EP 17348
DI 10.1007/s11042-020-08697-w
EA FEB 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516318400001
DA 2024-07-18
ER

PT J
AU Chen, R
   Chang, YS
   Hua, QY
   Gao, QL
   Ji, X
   Wang, B
AF Chen, Rui
   Chang, Yan-Shuo
   Hua, Qingyi
   Gao, Quanli
   Ji, Xiang
   Wang, Bo
TI An enhanced social matrix factorization model for recommendation based
   on social networks using social interaction factors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Matrix factorization;
   Social interaction; Trust networks
ID TRUST; SYSTEMS
AB Recommender systems are recently becoming more significant in the age of rapid development of Internet technology and pervasive computing due to their ability in making appropriate choices to users. Collaborative filtering is one of the most successful recommendation techniques, which recommends items to an active user based on past ratings from like-minded users. However, the user-item rating matrix, namely one of the inputs to the recommendation algorithm, is often highly sparse, thus collaborative filtering may lead to the poor recommendation. To solve this problem, social networks can be employed to improve the accuracy of recommendations. Some of the social factors have been used in recommender system, but have not been fully considered. In this paper, we fuse personal cognition behavior, cognition relationships between users, and time decay factor for rated items into a unified probabilistic matrix factorization model and propose an enhanced social matrix factorization approach for personalized recommendation using social interaction factors. In this study, we integrate propagation enhancement, common user relationship enhancement, and common interest enhancement into social relationship between users, and propose a novel trust relationship calculation to alleviate the negative impact of sparsity of data rating. The proposed model is compared with the existing social recommendation algorithms on real world datasets including the Epinions and Movielens datasets. Experimental results demonstrate that our proposed approach achieves superior performance to the other recommendation algorithms.
C1 [Chen, Rui] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450002, Peoples R China.
   [Chang, Yan-Shuo] Xian Univ Finance & Econ, Insititute Silk Rd Res, Xian 710100, Peoples R China.
   [Hua, Qingyi; Ji, Xiang; Wang, Bo] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
   [Gao, Quanli] Xian Polytech Univ, Coll Comp Sci, Xian 710048, Peoples R China.
   [Wang, Bo] Xian Univ Posts & Telecommun, Sch Comp, Xian 710121, Peoples R China.
C3 Zhengzhou University of Light Industry; Xi'an University of Finance &
   Economics; Northwest University Xi'an; Xi'an Polytechnic University;
   Xi'an University of Posts & Telecommunications
RP Chang, YS (corresponding author), Xian Univ Finance & Econ, Insititute Silk Rd Res, Xian 710100, Peoples R China.; Hua, QY (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
EM nwuchenrui@126.com; 396336805@qq.com; hua_qy@126.com;
   jsjgaoquanli@126.com; 1457369801@qq.com; xiyouwangbo@126.com
FU National Natural Science Foundation of China [61975187, 61503206];
   Special Scientific Research Fund for doctoral program of Higher
   Education [20126101110006]; Blue Book of Science Research Report on the
   "Belt and Road" Tourism Development Grant [2017sz01]; Shaanxi innovation
   capability support plan [2018KRM071]; Industrial Science and Technology
   Research Project of Shaanxi Province [2016GY-123]; Industrial Science
   and Technology Research Project of Henan Province [202102210387,
   182102310969]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61975187, and 61503206, in part by
   joint funded projects of the Special Scientific Research Fund for
   doctoral program of Higher Education under Grant 20126101110006, in part
   by the Blue Book of Science Research Report on the "Belt and Road"
   Tourism Development Grant 2017sz01, in part by Shaanxi innovation
   capability support plan under Grant 2018KRM071, in part by the
   Industrial Science and Technology Research Project of Shaanxi Province
   under Grant 2016GY-123 in part by the Industrial Science and Technology
   Research Project of Henan Province under Grants 202102210387, and
   182102310969.
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Aldayel M, 2017, IEICE T INF SYST, VE100D, P1484, DOI 10.1587/transinf.2016EDP7441
   [Anonymous], 2015, P 9 ACM C RECOMMENDE, DOI [10.1145/2792838.2800193, DOI 10.1145/2792838.2800193]
   [Anonymous], 2018, WIRELESS PERSONAL CO
   [Anonymous], 2007, 2007 ACM C REC SYST
   Azadjalal MM, 2017, KNOWL-BASED SYST, V116, P130, DOI 10.1016/j.knosys.2016.10.025
   Chai Y, 2017, COMPUTER STANDARDS I, P1
   Champiri Z.D., 2015, Int. J. Soc. Sci. Human., V5, DOI [DOI 10.7763/IJSSH.2015.V5.585, 10.7763/IJSSH.2015.V5.585]
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen R, 2018, IEEE ACCESS, V6, P64301, DOI 10.1109/ACCESS.2018.2877208
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Cheng ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P639, DOI 10.1145/3178876.3186145
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Comi A, 2016, INFORM SCIENCES, V367, P246, DOI 10.1016/j.ins.2016.05.051
   Cremonesi P., 2010, P 4 ACM C REC SYST, P39, DOI [DOI 10.1145/1864708.1864721, 10.1145/1864708.1864721]
   De Meo P, 2017, INFORM SCIENCES, V414, P117, DOI 10.1016/j.ins.2017.05.048
   DEMEO P, 2018, INFORM SYSTEMS
   Fotia L, 2017, COMPUT J, V60, P1717, DOI 10.1093/comjnl/bxx072
   GAO Q, 2017, RES KEY ISSUES CONTE
   Golbeck J.A., 2005, COMPUTING APPL TRUST
   GUI L, 2014, COMPUTER SCI
   Guo L, 2015, SOFT COMPUT, V19, P1351, DOI 10.1007/s00500-014-1347-0
   [黄波 Huang Bo], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P725
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Jamali M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P397
   JI K, 2016, RES HYBRID COLLABORA
   Jiang R, 2012, KALLIKREIN-RELATED PEPTIDASES, VOL 2: NOVEL CANCER-RELATED BIOMARKERS, P45
   Koohi H, 2017, EXPERT SYST APPL, V83, P30, DOI 10.1016/j.eswa.2017.04.027
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li J, 2017, KNOWL-BASED SYST, V127, P58, DOI 10.1016/j.knosys.2017.02.032
   Li YS, 2015, IEICE T INF SYST, VE98D, P346, DOI 10.1587/transinf.2014EDP7174
   Li Yuxing, 2016, RES SOME KEY TECHNOL
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6073, DOI 10.1109/TNNLS.2018.2817538
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu HF, 2015, IEEE ACCESS, V3, P1695, DOI 10.1109/ACCESS.2015.2481320
   Liu ZG, 2018, KSII T INTERNET INF, V12, P2082, DOI 10.3837/tiis.2018.05.010
   Lü LY, 2012, PHYS REP, V519, P1, DOI 10.1016/j.physrep.2012.02.006
   Luo X, 2014, IEEE T IND INFORM, V10, P1273, DOI 10.1109/TII.2014.2308433
   MA H, 2008, CIKM 08, P26
   Ma H, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P203, DOI 10.1145/1571941.1571978
   Massa P, 2004, LECT NOTES COMPUT SC, V3290, P492, DOI 10.1007/978-3-540-30468-5_31
   Meng Xiang-Wu, 2015, Journal of Software, V26, P1356, DOI 10.13328/j.cnki.jos.004831
   Moradi P, 2015, EXPERT SYST APPL, V42, P7386, DOI 10.1016/j.eswa.2015.05.027
   Moradi P, 2015, PHYSICA A, V436, P462, DOI 10.1016/j.physa.2015.05.008
   Najafabadi MK, 2017, COMPUT HUM BEHAV, V67, P113, DOI 10.1016/j.chb.2016.11.010
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   [潘一腾 Pan Yiteng], 2018, [计算机学报, Chinese Journal of Computers], V41, P65
   Qian XM, 2014, IEEE T KNOWL DATA EN, V26, P1763, DOI 10.1109/TKDE.2013.168
   Rafailidis D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P5, DOI 10.1145/3109859.3109879
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Wang F, 2011, DATA MIN KNOWL DISC, V22, P493, DOI 10.1007/s10618-010-0181-y
   Wang LF, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029432
   Wang XX, 2017, AER ADV ENG RES, V124, P5
   Wang Ying, 2014, Journal of Software, V25, P2893, DOI 10.13328/j.cnki.jos.004731
   Xi WP, 2017, HORTIC PLANT J, V3, P1, DOI 10.1016/j.hpj.2017.01.012
   Xu ZZ, 2016, IEEE ACCESS, V4, P2398, DOI 10.1109/ACCESS.2016.2566658
   Yang B, 2017, IEEE T PATTERN ANAL, V39, P1633, DOI 10.1109/TPAMI.2016.2605085
   [杨秀霞 Yang Xiuxia], 2016, [江西农业大学学报, Acta Agriculturae Universitatis Jiangxiensis], V38, P616
   Yang XW, 2014, COMPUT COMMUN, V41, P1, DOI 10.1016/j.comcom.2013.06.009
   Yang Z, 2016, IEEE ACCESS, V4, P3273, DOI 10.1109/ACCESS.2016.2573314
   Yao WL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P975, DOI 10.1145/2600428.2609488
   Yu W, 2018, FUTURE GENER COMP SY, V87, P312, DOI 10.1016/j.future.2018.04.079
   [余永红 Yu Yonghong], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P113
   Zeng ZQ, 2018, IEEE T IND ELECTRON, V65, P9804, DOI 10.1109/TIE.2017.2786205
   Zhang ZJ, 2015, APPL INTELL, V43, P695, DOI 10.1007/s10489-015-0681-y
   Zhou X, 2015, J COMPUT SYST SCI, V81, P717, DOI 10.1016/j.jcss.2014.11.016
   ZIEGLER C, 2004, JOINT ICDE EDBT PH D
NR 71
TC 14
Z9 16
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14147
EP 14177
DI 10.1007/s11042-020-08620-3
EA FEB 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515999700001
DA 2024-07-18
ER

PT J
AU Gracewell, J
   John, M
AF Gracewell, Jeffin
   John, Mala
TI Dynamic background modeling using deep learning autoencoder network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background modeling; Background subtraction; Deep learning; Foreground
   extraction; Intruder detection; Unattended object detection; Visual
   surveillance
ID NEURAL-NETWORK; SUBTRACTION
AB Background modeling is a major prerequisite for a variety of multimedia applications like video surveillance, traffic monitoring, etc. Numerous approaches have been proposed for the same over the past few decades. However, the need for real time artificial intelligent based low cost approach still exists. Moreover, few recently proposed efficient approaches are not validated on the basis of some of the challenging applications in which they may fail in its efficiency when tested. In this paper, an efficient deep learning technique based on autoencoder network is used for modeling the background. The background model generated herein is obtained by training the incoming frames of the surveillance video with the deep learning network in an unsupervised manner. In order to optimize the weights of the network, greedy layer wise pre-training approach is used initially and the fine tuning of the network is done using conjugate gradient based back propagation algorithm. The performance of the algorithm is validated based on the application of unattended object detection in a dynamic environment. Comprehensive assessment of the proposed method using CDNET 2014 dataset and other datasets demonstrates the efficiency of the technique in background modeling.
C1 [Gracewell, Jeffin; John, Mala] Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Madras Institute of Technology
RP John, M (corresponding author), Madras Inst Technol, Dept Elect Engn, Chennai, Tamil Nadu, India.
EM malajohnmit@gmail.com
RI Gracewell, Jeffin/IST-4980-2023; JOHN, MALA/AAI-7508-2021; Gracewell,
   Jeffin/KEI-5205-2024
OI Gracewell, Jeffin/0000-0001-6980-8751; JOHN, MALA/0000-0001-5034-3405;
   Gracewell, Jeffin/0000-0001-6980-8751
CR [Anonymous], EUR S ART NEUR NETW
   [Anonymous], IEEE INT WORKSH PETS
   [Anonymous], 2000, P 4 AS C COMP VIS SI
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Benedek C, 2008, IEEE T IMAGE PROCESS, V17, P608, DOI 10.1109/TIP.2008.916989
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Bhargava M, 2009, MACH VISION APPL, V20, P271, DOI 10.1007/s00138-008-0181-8
   CHARALAMBOUS C, 1992, IEE PROC-G, V139, P301, DOI 10.1049/ip-g-2.1992.0050
   Culibrk D, 2007, IEEE T NEURAL NETWOR, V18, P1614, DOI 10.1109/TNN.2007.896861
   De Gregorio M, 2017, PATTERN RECOGN LETT, V96, P55, DOI 10.1016/j.patrec.2017.05.029
   Deng GY, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P59, DOI 10.1109/IWECA.2014.6845556
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Guo HY, 2016, IET COMPUT VIS, V10, P268, DOI 10.1049/iet-cvi.2015.0291
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Kim K, 2004, P IEEE INT C IM PROC
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laugraud B, 2015, P ICIAP
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li LY, 2002, IEEE T IMAGE PROCESS, V11, P105, DOI 10.1109/83.982818
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Lin HH, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P893, DOI 10.1109/ICIP.2002.1039116
   Liu T, 2017, P 22 INT C DIG SIGN, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu X, 2014, P IEEE INT C IM PROC
   Maddalena L, 2012, P COMP VIS PATT REC
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Marsden Mark, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078482
   Martins I, 2017, LECT NOTES COMPUT SC, V10255, P50, DOI 10.1007/978-3-319-58838-4_6
   Miron A, 2015, P INT C SYST SIGN IM
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sehairi K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023025
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tang Z, 2007, LECT NOTES COMPUT SC, V4740, P411
   Tian YH, 2013, IEEE T CIRC SYST VID, V23, P1849, DOI 10.1109/TCSVT.2013.2248239
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Varadarajan S, 2013, P IEEE INT C ADV VID
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yi S, 2016, IEEE T IMAGE PROCESS, V25, P4354, DOI 10.1109/TIP.2016.2590322
   Zhang S, 2008, P 8 INT WORKSH VIS S
   Zhao ZJ, 2015, IEEE T IMAGE PROCESS, V24, P2841, DOI 10.1109/TIP.2015.2427519
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 48
TC 17
Z9 17
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4639
EP 4659
DI 10.1007/s11042-019-7411-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500022
DA 2024-07-18
ER

PT J
AU Gurunathan, K
   Rajagopalan, P
AF Gurunathan, K.
   Rajagopalan, P.
TI A stegano-visual cryptography technique for multimedia security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Information hiding; Multimedia; Visual cryptography (VC);
   Joint photographic experts group (JPEG); Joint quantization table
   modification (JQTM) and cuckoo search (CS) algorithm
ID IMAGE STEGANOGRAPHY; JPEG; SEARCH; SCHEME
AB Owing to the increasing growth in digital communication as well as the multimedia applications, security has now become a very significant problem in the communication as well as storage space of such images. The Visual Cryptography (VC) has been used for hiding the information that are in the images which is a special technique of encryption that is decrypted by a human visual system. In this paper, a technique for embedding a secret message within that of a cover-image to ensure the interceptors will not observe the presence of such hidden data is presented. The method has an essential conception by means of a simple Least Significant Bit (LSB) substitution. Being inspired by the steganography approach, the current work splits the cover images into n blocks of 8X 8 pixels and into a secret message of n partitions in order to improve the image quality and to increase the capacity of secret message along with its security level. For the purpose of improving this stego-image quality and for increasing the capacity of secret message along with its security level, being inspired by the current work that splits cover images into the n blocks of 8X 8 pixels and into a secret message of n partitions. In the proposed method, the Cuckoo Search (CS) is used for searching an approximate and optimal solution of finding any optimal substitution matrix to transform the message in every block as opposed to finding a single optimal matrix for substitution and the entire cover-image is presented. The final quality of its resulting in the stego-image, and its secret message and its capacity with the level of security of this method proposed will be calculated and then comparted to the other different methods. The results of the experiment proved that the proposed method outperformed all the Joint Photographic Experts Group (the JPEG) and the Joint Quantization Table Modification (the JQTM) based method in terms of quality of image, security level and embedding capacity.
C1 [Gurunathan, K.] Anna Univ, Chennai, Tamil Nadu, India.
   [Gurunathan, K.] Mother Therasa Coll Engn & Technol, Dept CSE, Pudukottai, Tamil Nadu, India.
   [Rajagopalan, P.] GKM Coll Engn & Technol, Dept CSE, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Gurunathan, K (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.; Gurunathan, K (corresponding author), Mother Therasa Coll Engn & Technol, Dept CSE, Pudukottai, Tamil Nadu, India.
EM iamalsoguru01@gmail.com; sasirekaraj@yahoo.co.in
CR Abbas SA, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P572, DOI 10.1109/IntelCIS.2015.7397279
   Almohammad A, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P544, DOI 10.1109/ARES.2008.72
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   [Anonymous], 2018, International Journal of Engineering & Technology, DOI DOI 10.14419/IJET.V7I1.9.9729
   [Anonymous], 2016, Int. J. Comput. Sci. Inf. Sec
   Awad A, 2017, J ED COLL WASIT U, V1, P497, DOI [10.31185/eduj.Vol1.Iss26.105, DOI 10.31185/EDUJ.VOL1.ISS26.105]
   Bloisi Domenico, 2007, VISAPP 2007. Second International Conference on Computer Vision Theory and Applications, P127
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chhabra N, 2012, INT J COMPUT SCI NET, V12, P126
   Fazli S, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P100, DOI 10.1109/INMIC.2008.4777716
   Geetha P, 2018, COMPUT SECUR, V78, P301, DOI 10.1016/j.cose.2018.07.009
   Gupta R., 2012, INT J COMPUTER SCI I, V3, P4366
   Li XX, 2007, INFORM SCIENCES, V177, P3099, DOI 10.1016/j.ins.2007.02.008
   Mishra A, 2017, INT J INNOV ADV COMP, V6
   Muhammad K, 2016, FUTUR GENER COMPUT S
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Prema G, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES), P727, DOI 10.1109/ICICES.2013.6508373
   RAMALINGAM M, 2015, INDIAN J SCI TECHNOL, V8, P79
   Rani M. Mary Shanthi, 2015, ADV INTELLIGENT SYST, P403
   Rani M. Mary Shanthi, 2016, ARTIF INTELL, P31
   Ranjan Kumar H. S, 2013, INT J ADV ENG TECHNO, V6, P1211
   Roy S., 2014, Electrical, Electronics and Computer Science, V2, P1, DOI [DOI 10.1186/S40712-014-0010-Y, DOI 10.1109/SCEECS.2014.6804449, 10.1109/SCEECS.2014.6804449]
   Samuel AB, 2016, RES J PHARM BIOL CHE, V7, P6
   Sarmah DK, 2018, INFORM SCIENCES, V430, P378, DOI 10.1016/j.ins.2017.11.027
   Walia GS, 2018, OPTIK, V170, P106, DOI 10.1016/j.ijleo.2018.04.135
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
NR 29
TC 12
Z9 12
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3893
EP 3911
DI 10.1007/s11042-019-7471-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700044
DA 2024-07-18
ER

PT J
AU Li, YY
   Shuai, B
AF Li, Yueyang
   Shuai, Bin
TI Origin and destination forecasting on dockless shared bicycle in a
   hybrid deep-learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dockless shared bicycle; OD distribution; Deep learning; CLTFP
ID PASSENGER DEMAND; FLOW
AB Nowadays, the dockless shared bicycle has a positive influence on people's travel, thus it is useful to analyze the spatio-temporal features of shared bike. Due to the limitations of CNN or LSTM, the spatial correlation and time dependence is inferior to capture. In this paper, a combination of CNN and LSTM named CLTFP in deep learning model is applied to predict the travel distance and OD distribution of shared bicycles under different conditions of time and space. Experiments show that CLTFP has better performance to capture spatiotemporal correlations.
C1 [Li, Yueyang; Shuai, Bin] Southwest Jiaotong Univ, Sch Transportat & Logist, Chengdu, Peoples R China.
C3 Southwest Jiaotong University
RP Li, YY (corresponding author), Southwest Jiaotong Univ, Sch Transportat & Logist, Chengdu, Peoples R China.
EM liyueyang@my.swjtu.edu.cn
CR [Anonymous], NEURAL COMPUT APPL O
   Bai Y, 2017, APPL SOFT COMPUT, V58, P669, DOI 10.1016/j.asoc.2017.05.011
   Beroud B, 2012, TRANSP SUSTAIN, P269, DOI 10.1108/S2044-9941(2012)0000001013
   Castillo-Manzano JI, 2013, TRANSPORTATION, V40, P459, DOI 10.1007/s11116-012-9424-7
   Cervero R, 2013, J PUBLIC TRANSPORT, V16, P83, DOI 10.5038/2375-0901.16.4.5
   Fishman E, 2016, TRANSPORT REV, V36, P92, DOI 10.1080/01441647.2015.1033036
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu J, 2017, IEEE DATA MINING, P167, DOI 10.1109/ICDM.2017.26
   Huang WH, 2014, IEEE T INTELL TRANSP, V15, P2191, DOI 10.1109/TITS.2014.2311123
   Jin X., 2015, ARXIV151207030
   Ke JT, 2017, TRANSPORT RES C-EMER, V85, P591, DOI 10.1016/j.trc.2017.10.016
   Krizek KJ, 2011, TRANSPORT RES REC, P162, DOI 10.3141/2217-20
   Ma XY, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117294
   Ma XL, 2015, TRANSPORT RES C-EMER, V54, P187, DOI 10.1016/j.trc.2015.03.014
   Ma ZL, 2014, TRANSPORT RES C-EMER, V39, P148, DOI 10.1016/j.trc.2013.12.008
   Polson N., 2016, ARXIV160404527
   Shaheen SA, 2013, INT J SUSTAIN TRANSP, V7, P1, DOI 10.1080/15568318.2012.660095
   Shen Y, 2018, INT J SUSTAIN TRANSP, V12, P686, DOI 10.1080/15568318.2018.1429696
   Tian ZP, 2018, J CLEAN PROD, V171, P1068, DOI 10.1016/j.jclepro.2017.10.098
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wei Y, 2012, TRANSPORT RES C-EMER, V21, P148, DOI 10.1016/j.trc.2011.06.009
   Yahya BN, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112070
   Yang H, 2011, TRANSPORT RES B-METH, V45, P696, DOI 10.1016/j.trb.2011.01.002
   Yang H, 2010, TRANSPORT RES B-METH, V44, P1067, DOI 10.1016/j.trb.2009.12.010
NR 24
TC 42
Z9 52
U1 0
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5269
EP 5280
DI 10.1007/s11042-018-6374-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500059
DA 2024-07-18
ER

PT J
AU Remolar, I
   Chover, M
   Rebollo, C
   Gasch, C
AF Remolar, Inmaculada
   Chover, Miguel
   Rebollo, Cristina
   Gasch, Cristina
TI Image mapping system for simulating ceramic environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image composition; Virtual composing; Virtual design; Automatic tiling
AB Minimizing costs and increasing sales are a goal for every busi- ness nowadays. This fact, together with the development of new technologies, have driven the emergence of virtual applications where the customers can configure the product they are interested in only interacting with the images where the products appear. Many applications are available on Internet or app stores for this purpose. In all of them, a high realism is required. However, this fact is directly related to a high cost of storage of data and to the difficulty of generating the images of the scenes where the product is exposed. This paper presents a virtual configurator addressed to tile factories that solves these problems maintaining a high realism. The developed application generates the configurable images by rendering 3D modeled environments and the customization is performed taking advantage of the graphics hardware. It is in charge of performing the tiling of any size tiles in real time. The presented image mapping system is based on the real measurements of the walls or floor of the environment that appear in the image and on the dimensions of the tile to map. Taking these data into account, the application performs the final appearance adapting the final image to the requirements of the user. The presented method reduces the amount of stored information maintaining the realism of the customized images.
C1 [Remolar, Inmaculada; Chover, Miguel; Rebollo, Cristina; Gasch, Cristina] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
C3 Universitat Jaume I
RP Remolar, I (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
EM remolar@uji.es; chover@uji.es; rebollo@uji.es; cgasch@uji.es
RI Rebollo Santamaría, Cristina/T-1272-2017; Chover Sellés,
   Miguel/P-9933-2018; Remolar Quintana, Inmaculada/T-1268-2017
OI Rebollo Santamaría, Cristina/0000-0002-1328-2110; Chover Sellés,
   Miguel/0000-0002-0525-7038; Remolar Quintana,
   Inmaculada/0000-0002-7743-2579; Gasch, Cristina/0000-0003-2013-2839
CR CARD SK, 1980, COMMUN ACM, V23, P396, DOI 10.1145/358886.358895
   Dahan E, 2002, J PROD INNOVAT MANAG, V19, P332, DOI 10.1016/S0737-6782(02)00151-0
   Ebert D, 2002, TEXTURING MODELING P, P600
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   HECKBERT PS, 1986, IEEE COMPUT GRAPH, V6, P56, DOI 10.1109/MCG.1986.276672
   Khurana P, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P3822
   Lengyel J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P233, DOI 10.1145/258734.258856
   Linares J, 2003, REALISTIC IMAGE MAPP, P27
   MOLNAR S, 1992, COMP GRAPH, V26, P231, DOI 10.1145/142920.134067
   Pharr M., 2005, GPU Gems 2: Programming techniques for highperformance graphics and general purpose computation
   Remolar I, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P208, DOI 10.1109/CW.2010.52
   Santonja J, 2002, INT C COMP VIS GRAPH, V1, P121
   Schied C., 2015, P 7 C HIGH PERF GRAP, P43
   Schnitzer Stephan, 2014, Proceedings of the 2014 9th IEEE International Symposium on Industrial Embedded Systems (SIES 2014), P160, DOI 10.1109/SIES.2014.6871200
   Soler C, 2010, P SIGGRAPH 2010 TALK
   Sukanya C.M., 2016, Int. J. Sci. Eng. Comput. Technol, V6, P48
   Trentin A, 2014, COMPUT IND, V65, P693, DOI 10.1016/j.compind.2014.02.004
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Xin L, 2015, ACM COMPUTING SURVEY, V47
NR 19
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3261
EP 3283
DI 10.1007/s11042-018-7021-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700011
OA Green Published
DA 2024-07-18
ER

PT J
AU Voulodimos, A
   Rallis, I
   Doulamis, N
AF Voulodimos, Athanasios
   Rallis, Ioannis
   Doulamis, Nikolaos
TI Physics-based keyframe selection for human motion summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data; Motion summarization; Kinematics; 3D; Keyframe
   selection; Dance analysis
ID CAPTURE DATA; RETRIEVAL; EXTRACTION
AB Analysis of human motion is a field of research that attracts significant interest because of the wide range of associated application domains. Intangible Cultural Heritage (ICH), including the performing arts and in particular dance, is one of the domains where related research is especially useful and challenging. Effective keyframe selection from motion sequences can provide an abstract and compact representation of the semantic information encoded therein, contributing towards useful functionality, such as fast browsing, matching and indexing of ICH content. The availability of powerful 3D motion capture sensors along with the fact that video summarization techniques are not always applicable to the particular case of dance movement create the need for effective and efficient summarization techniques for keyframe selection from 3D human motion capture data sequences. In this paper, we introduce two techniques: a "time-independent" method based on k-means++ clustering algorithm for the extraction of prominent representative instances of a dance, and a physics-based technique that creates temporal summaries of the sequence at different levels of detail. The proposed methods are evaluated on two dance motion datasets and show promising results.
C1 [Voulodimos, Athanasios] Univ West Attica, Dept Informat & Comp Engn, Agiou Spyridonos Str, Athens 12243, Greece.
   [Rallis, Ioannis; Doulamis, Nikolaos] Natl Tech Univ Athens, 9 Heroon Polytech Str, GR-15773 Athens, Greece.
C3 University of West Attica; National Technical University of Athens
RP Voulodimos, A (corresponding author), Univ West Attica, Dept Informat & Comp Engn, Agiou Spyridonos Str, Athens 12243, Greece.
EM avoulod@uniwa.gr
RI Doulamis, Anastasios/AAL-5972-2021; Voulodimos, Athanasios/ABC-1836-2021
OI Rallis, Ioannis/0000-0003-4491-5854
CR [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], 2017, VICON MOTION CAPTURE
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   [Anonymous], 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D'13
   [Anonymous], 2007, COMPUTER ANIMATION S
   [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   Arai Kohei, 2007, Reports of the Faculty of Science and Engineering, Saga University, V36, P25
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Aristidou A, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099566
   Aristidou A, 2018, VISUAL COMPUT, V34, P1725, DOI 10.1007/s00371-017-1452-z
   Aristidou A, 2015, COMPUT GRAPH FORUM, V34, P262, DOI 10.1111/cgf.12598
   Aristidou A, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2755566
   Assa J, 2005, ACM T GRAPHIC, V24, P667, DOI 10.1145/1073204.1073246
   Baraff D, 1997, SIGGRAPH, V97
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Bernard J, 2013, IEEE T VIS COMPUT GR, V19, P2257, DOI 10.1109/TVCG.2013.178
   Bertschek I, 2006, CONTRIB STAT, P130, DOI 10.1007/3-7908-1701-5_9
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Chen C, 2011, IEEE T VIS COMPUT GR, V17, P1676, DOI 10.1109/TVCG.2010.272
   Chen SL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P411, DOI 10.1145/2671188.2749384
   Choi B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925970
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Doulamis A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P451, DOI 10.5220/0006347304510460
   Doulamis N. D., 2010, P 1 ACM INT WORKSH A, P39, DOI [10.1145/1877868.1877880, DOI 10.1145/1877868.1877880]
   Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852
   Felder E, 2009, WISSEN DURCH SPRACHE: THEORIE, PRAXIS UND ERKENNTNISINTERESSE DES FORSCHUNGSNETZWERKES SPRACHE UND WISSEN, P1
   Field M, 2015, PATTERN RECOGN, V48, P2394, DOI 10.1016/j.patcog.2015.03.004
   Forbes N, 2005, IMITATION OF LIFE: HOW BIOLOGY IS INSPIRING COMPUTING, P67
   Halit C, 2011, COMPUT ANIMAT VIRT W, V22, P3, DOI 10.1002/cav.380
   Hisatomi K, 2011, INT J COMPUT VISION, V94, P78, DOI 10.1007/s11263-011-0434-2
   Kitsikidis A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P789
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Laganiere R, 2008, P ACM TRECVID VID SU, P144
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Liu XM, 2013, VISUAL COMPUT, V29, P85, DOI 10.1007/s00371-012-0676-1
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Protopapadakis E, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P91, DOI 10.1145/3197768.3201533
   Protopapadakis E, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010031
   Rallis I, 2017, INT CONF GAMES VIRTU, P94, DOI 10.1109/VS-GAMES.2017.8056576
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sheppard Renata M., 2008, P 16 ACM INT C MULTI, P579
   Voulodimos AS, 2014, MULTIMED TOOLS APPL, V69, P293, DOI 10.1007/s11042-012-0993-4
   Wu T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1053, DOI 10.1109/ICCVW.2015.138
   Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 47
TC 15
Z9 16
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3243
EP 3259
DI 10.1007/s11042-018-6935-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700010
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhong, ZY
   Hu, YM
AF Zhong, Zhiyan
   Hu, Yueming
TI Feature extraction method of halftone images based on pixel aggregation
   descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Error-diffused halftone images; Set operation; Pixel
   aggregation descriptors; BP neural network
ID CLASSIFICATION
AB Since halftone images only have the values of 0 and 1, the amount of information that can be used in the feature extraction process is relatively little. The existed feature extraction methods have some disadvantages such as too many dimensions, longer extraction time, and lower classification accuracy. In view of the above questions, a pixel aggregation descriptor is proposed to extract the feature of halftone images in this paper. Set operations are introduced to obtain this pixel aggregation descriptor, which makes the texture of the images clearly visible and greatly reduces the dimension of feature and the time consumption of classification. Then, the correlations between pixels, including distance and angle are taken as factors to improve the accuracy in image classification. In experiments, the reliability and stability of the feature extraction methods are evaluated and compared. Then, the influence of parameters, time complexity, and the limitations are discussed. Experiments show that our method realized the effect of higher speed and precision in feature extraction.
C1 [Zhong, Zhiyan; Hu, Yueming] South China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhong, Zhiyan; Hu, Yueming] Minist Educ, Engn Res Ctr Precis Elect Mfg Equipments, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhong, Zhiyan; Hu, Yueming] Guangdong Prov Engn Lab Adv Chip Intelligent Pack, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Hu, YM (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.; Hu, YM (corresponding author), Minist Educ, Engn Res Ctr Precis Elect Mfg Equipments, Guangzhou 510640, Guangdong, Peoples R China.; Hu, YM (corresponding author), Guangdong Prov Engn Lab Adv Chip Intelligent Pack, Guangzhou 510640, Guangdong, Peoples R China.
EM zzy150735@163.com; auymhu@scut.edu.cn
RI Hu, Yueming/GLN-2642-2022
FU National Natural Science Foundation of China [61573146]; National
   Science and Technology Major Project of the Ministry of Science and
   Technology of China [2014ZX 02503]; Applied Science and Technology
   Research and Development Special Fund Project of Guangdong Province,
   China [2015B010133003]; Natural Science Foundation of Guangdong
   Province, China [2016A030313454]
FX This study was supported by the National Natural Science Foundation of
   China (Grant No. 61573146), the National Science and Technology Major
   Project of the Ministry of Science and Technology of China (Grant
   No.2014ZX 02503), the Applied Science and Technology Research and
   Development Special Fund Project of Guangdong Province, China (Grant No.
   2015B010133003), the Natural Science Foundation of Guangdong Province,
   China (Grant No. 2016A030313454).
CR Chang PC, 1997, P SOC PHOTO-OPT INS, V3309, P592
   Ding SF, 2017, IET BIOMETRICS, V6, P438, DOI 10.1049/iet-bmt.2016.0161
   Hodeish ME, 2018, MULTIMED TOOLS APPL, V77, P24937, DOI 10.1007/s11042-018-5724-z
   Hwang W, 2018, MULTIMED TOOLS APPL, V77, P23429, DOI 10.1007/s11042-017-5571-3
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Li N, 2018, MULTIMED TOOLS APPL, V77, P30633, DOI 10.1007/s11042-018-6131-1
   Liu YF, 2011, IEEE T IMAGE PROCESS, V20, P2837, DOI 10.1109/TIP.2011.2136354
   Liu YF, 2011, IEEE T IMAGE PROCESS, V20, P1077, DOI 10.1109/TIP.2010.2087765
   Mese M, 2002, IEEE T CIRCUITS-I, V49, P790, DOI 10.1109/TCSI.2002.1010034
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   SELDOWITZ MA, 1987, APPL OPTICS, V26, P2788, DOI 10.1364/AO.26.002788
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shandoosti HR, 2018, MULTIMED TOOLS APPL, V77, P23633, DOI 10.1007/s11042-018-5695-0
   Shang J, 2016, IET IMAGE PROCESS, V10, P662, DOI 10.1049/iet-ipr.2016.0058
   Stevenson RL, 1997, IEEE T IMAGE PROCESS, V6, P574, DOI 10.1109/83.563322
   Su PC, 2018, MULTIMED TOOLS APPL, V77, P12111, DOI 10.1007/s11042-017-4861-0
   ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288
   Nguyen VL, 2017, MULTIMED TOOLS APPL, V76, P22425, DOI 10.1007/s11042-017-4824-5
   Wang SL, 2017, IET IMAGE PROCESS, V11, P1205, DOI 10.1049/iet-ipr.2016.0875
   Wazarkar S, 2018, MULTIMED TOOLS APPL, V77, P25941, DOI 10.1007/s11042-018-5829-4
   Wen ZQ, 2014, IEEE T IMAGE PROCESS, V23, P4724, DOI 10.1109/TIP.2014.2348862
   WEN ZQ, 2014, OPEN AUTOM CONTROL S, V6, P250
   YAN CG, 2019, STAT SPATIAL TEMPORA
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   ZHANG X, 2017, SENSORS BASEL, V17
   Zhang Y, 2018, ENG APPL ARTIF INTEL, V72, P43, DOI 10.1016/j.engappai.2018.03.012
   Zhang Y, 2016, ENG APPL ARTIF INTEL, V50, P245, DOI 10.1016/j.engappai.2016.01.032
   Zhou DX, 2018, MULTIMED TOOLS APPL, V77, P18957, DOI 10.1007/s11042-017-5319-0
NR 30
TC 1
Z9 1
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7763
EP 7781
DI 10.1007/s11042-019-08410-6
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600007
DA 2024-07-18
ER

PT J
AU Bhinder, P
   Jindal, N
   Singh, K
AF Bhinder, Preeti
   Jindal, Neeru
   Singh, Kulbir
TI An improved robust image-adaptive watermarking with two watermarks using
   statistical decoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple image-adaptive watermarking; Kurtosis; Statistical modeling;
   Gradient mean structural deviation (GMSD); Maximum likelihood (ML)
   decoder
ID MULTIPLE WATERMARKING; REVERSIBLE WATERMARKING; WAVELET TRANSFORM; DUAL
   WATERMARKING; SCHEME; SECURE; DOMAIN
AB This paper presents an improved image-adaptive watermarking technique. Two image watermarks are embedded in the high entropy 8x8 blocks of the host image. DWT is applied on these blocks using the principle of sub band coding. This decomposes the high entropy blocks into four sub band coefficients, wherein the approximation and vertical frequency coefficients are modeled using Gaussian (or Normal) distribution. The two watermarks are inserted in the host image using Adjustable Strength Factor (ASF). It is calculated adaptively using the fourth statistical moment known as kurtosis. A limited side information is also transmitted along with the watermarked image. This side information consists of high entropy block positions and Gaussian distribution parameters. To extract both watermarks from the received watermarked image, the high entropy block positions sent in the side information help in applying DWT to calculate the approximation and vertical frequency coefficients. Gaussian (or Normal) distribution is similarly used for modeling and calculating the distribution parameters. This helps the Maximum Likelihood (ML) decoder to recover the watermarks successfully using a statistical approach. Two important contributions are presented in this paper. Firstly, adjustable kurtosis values are used which improves the capacity and robustness of the proposed technique. Secondly, the proposed work is implemented on medical applications and gives better performance as compared to the existing methods. Further, the efficiency of the proposed work is evaluated by better simulation results using PSNR, NCC, SSIM and GMSD under different attacks. The technique is highly robust as watermarks survive under different attacks. This increases security and ensures copyright protection.
C1 [Bhinder, Preeti; Jindal, Neeru; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
   [Bhinder, Preeti] Chitkara Univ, Inst Engn & Technol, Dept Elect & Commun, Rajpura, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Chitkara University,
   Punjab
RP Singh, K (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM preeti@thapar.edu; neeru.jindal@thapar.edu; ksingh@thapar.edu
RI , Preeti/AFL-5961-2022; , Preeti/AAG-5733-2022; Singh,
   Kulbir/T-7453-2019
OI , Preeti/0000-0001-9126-3858; , Preeti/0000-0001-9126-3858; Singh,
   Kulbir/0000-0001-8070-3395
CR Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], DUAL WATERMARKING TE
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Bhatnagar G, 2009, J DIGITAL INFORM MAN, V7, P2
   Bhatnagar G, 2015, MULTIMED TOOLS APPL, V74, P8421, DOI 10.1007/s11042-013-1681-8
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Ganic E, 2004, NEW YORK METR AR NET, P1
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Hu YJ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P584
   Inamdar VS, 2014, SADHANA-ACAD P ENG S, V39, P3, DOI 10.1007/s12046-013-0208-3
   Kallel M., 2007, GVIP J, V7, P37
   Lu W, 2012, MULTIMED TOOLS APPL, V60, P31, DOI 10.1007/s11042-011-0794-1
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Mohammed AHA, 2010, ADV TECHNIQUES MULTI
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Rangel-Espinoza K, 2018, MULTIMED TOOLS APPL, V77, P13047, DOI 10.1007/s11042-017-4931-3
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh AK, 2015, WIRELESS PERS COMMUN, V83, P2133, DOI 10.1007/s11277-015-2505-0
   Singh H, 2014, J COMMUN TECHNOL EL+, V59, P1234, DOI 10.1134/S1064226914110199
   Singh H, 2014, SADHANA-ACAD P ENG S, V39, P345, DOI 10.1007/s12046-013-0217-2
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Tao PN, 2004, PROC SPIE, V5601, P133, DOI 10.1117/12.569641
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2002, P SOC PHOTO-OPT INS, V4675, P679, DOI 10.1117/12.465329
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yadav N, 2018, ARAB J SCI ENG, V43, P4131, DOI 10.1007/s13369-017-2793-7
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yadav N, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1121, DOI 10.1109/CCAA.2015.7148543
   Yadav R, 2017, INT J ENG MANUF IJEM, V7, P50, DOI DOI 10.5815/IJEM.2017.02.05
   Yaghmaee F, 2008, LECT NOTES COMPUTER, V5112
   Yao T, 2013, ADV SCI LETT, V19, P1234
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 39
TC 22
Z9 22
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 183
EP 217
DI 10.1007/s11042-019-07941-2
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600009
DA 2024-07-18
ER

PT J
AU Bukenya, F
AF Bukenya, Faiza
TI A hybrid approach for stain normalisation in digital histopathological
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histopathology images; Stain normalisation; Image processing
ID NONNEGATIVE MATRIX FACTORIZATION; SINGULAR-VALUE DECOMPOSITION; COLOR
   NORMALIZATION; FEATURE-EXTRACTION; SPARSE; SEGMENTATION; SEPARATION;
   QUANTIZATION
AB Stain in-homogeneity adversely affects segmentation and quantification of tissues in histology images. Stain normalisation techniques have been used to standardise the appearance of images. However, most the available stain normalisation techniques only work on a particular kind of stain images. In addition, some of these techniques fail to utilise both the spatial and textural information in histology images, leading to image tissue distortion. In this paper, a hybrid approach has been developed, based on an octree colour quantisation algorithm combined with the Beer-Lambert law, a modified blind source separation algorithm, and a modified colour transfer approach. The hybrid method consists of two stages the stain separation stage and colour transfer stage. An octree colour quantisation algorithm combined with Beer-Lambert law, and a modified blind source separation algorithm are used during the stain separation stage to computationally estimate the amount of stain in an histology image based on its chromatic and luminous response. A modified colour transfer algorithm is used during the colour transfer stage to minimise the effect of varying staining and illumination. The hybrid method addresses the colour variation problem in both H&DAB (Haemotoxylin and Diaminobenzidine) and H&E (Haemotoxylin and Eosin) stain images. The stain normalisation method is validated against ground truth data. It is widely known that the Beer-Lambert law applies to only stains (such as haematoxylin, eosin) that absorb light. We demonstrate that the Beer-Lambert law applies is applicable to images containing a DAB stain. Better stain normalisation results are obtained in both H&E and H&DAB images.
C1 [Bukenya, Faiza] Univ Nottingham, Sch Comp Sci, Nottingham, England.
C3 University of Nottingham
RP Bukenya, F (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham, England.
EM faiza.bukenya@nottingham.ac.uk
RI Bukenya, Faiza/ABE-4477-2021
OI Bukenya, Faiza/0000-0002-9316-173X
CR Alsubaie N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169875
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], SPIE MED IMAGING
   [Anonymous], 2016, INT J COMPUTER APPL
   [Anonymous], 2013, Matrix Computations
   [Anonymous], 2018, ARXIV180401601
   Asiedu L, 2016, STAT ASSESSMENT PCA
   Babaee M, 2016, NEUROCOMPUTING, V173, P212, DOI 10.1016/j.neucom.2014.12.124
   Berry MW, 2009, IEEE INT SYMP CIRC S, P2782, DOI 10.1109/ISCAS.2009.5118379
   Bogaardt L, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8020055
   Bougacha A, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1048164
   Burns PD, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P32
   Cahill ND, 2015, PROC SPIE, V9472, DOI 10.1117/12.2177139
   Cahill ND, 2014, SCHROEDINGER EIGENMA
   Carey D., 2015, P 19 C MED IM UND AN, P156
   Celis R, 2015, J MICROSC-OXFORD, V260, P377, DOI 10.1111/jmi.12304
   Charles RM, 2015, ARXIV150608110
   Ciompi F, 2017, I S BIOMED IMAGING, P160, DOI 10.1109/ISBI.2017.7950492
   Dera D, 2016, B MATH BIOL, V78, P1450, DOI 10.1007/s11538-016-0190-0
   Ebied A, 2018, MED ENG PHYS, V57, P51, DOI 10.1016/j.medengphy.2018.04.003
   Finlayson G. D., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P475, DOI 10.1007/BFb0055685
   Fu Xiao, 2018, ARXIV180301257
   Garcia-Torres L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091275
   Gavrilovic M, 2013, BLIND COLOR DECOMPOS
   Ghosh B., 2016, IEEE ANN IND C, P1
   Guillamet D, 2002, INT C PATT RECOG, P116, DOI 10.1109/ICPR.2002.1048251
   Guo Lili., 2016, P IEEE C COMP VIS PA, P86
   Hamidinekoo A, 2017, LECT NOTES COMPUT SC, V10553, P213, DOI 10.1007/978-3-319-67558-9_25
   Hauta-Kasari M, 1999, PATTERN ANAL APPL, V2, P275, DOI 10.1007/s100440050036
   Hoffman RA, 2014, IEEE ENG MED BIO, P194, DOI 10.1109/EMBC.2014.6943562
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Horn RA, 1987, ZAMM-Z ANGEW MATH ME, V67, P212
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Janowczyk A, 2017, COMPUT MED IMAG GRAP, V57, P50, DOI 10.1016/j.compmedimag.2016.05.003
   Jensen EC, 2013, ANAT REC, V296, P378, DOI 10.1002/ar.22641
   Jia ZX, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aab92d
   Kalatehjari E, 2018, MULTIMED TOOLS APPL, V77, P25053, DOI 10.1007/s11042-018-5757-3
   Karsh R. K., 2017, EURASIP J IMAGE VIDE, V2017, P1
   Kather JN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145572
   Khan AM, 2014, IEEE T BIO-MED ENG, V61, P1729, DOI 10.1109/TBME.2014.2303294
   Khan HA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072045
   KIM HH, 1990, INT J REMOTE SENS, V11, P1331, DOI 10.1080/01431169008955098
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Kothari S, 2011, I S BIOMED IMAGING, P657, DOI 10.1109/ISBI.2011.5872492
   Krutsch R., 2011, Histogram equalization
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leuschner J, 2019, BIOINFORMATICS, V35, P1940, DOI 10.1093/bioinformatics/bty909
   Li K, 2004, ADV IMAGE PROCESSING
   Li L, 2017, 2017 HANDS-FREE SPEECH COMMUNICATIONS AND MICROPHONE ARRAYS (HSCMA 2017), P141, DOI 10.1109/HSCMA.2017.7895578
   Li S, 2012, 2012 INTERNATIONAL CONFERENCE ON FUTURE COMMUNICATION AND COMPUTER TECHNOLOGY (ICFCCT 2012), P272, DOI 10.1109/ICDMA.2012.66
   Li XY, 2015, IEEE T BIO-MED ENG, V62, P1862, DOI 10.1109/TBME.2015.2405791
   Liang L, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040755
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu W., 2008, MED BIOM 1 INT C, V4901, P41
   Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
   Muhimmah I, 2017, IOP CONF SER-MAT SCI, V185, DOI 10.1088/1757-899X/185/1/012029
   Naylor P, 2017, I S BIOMED IMAGING, P933, DOI 10.1109/ISBI.2017.7950669
   Odegård J, 2018, GENET SEL EVOL, V50, DOI 10.1186/s12711-018-0373-2
   Ortega-Martorell S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047824
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Papadias CB, 2000, IEEE T SIGNAL PROCES, V48, P3508, DOI 10.1109/78.887044
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Peters LWH, 2014, SCIENTIFICA, V2014, DOI 10.1155/2014/415849
   Rabinovich A, 2004, ADV NEUR IN, V16, P667
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rey W, 2007, ARXIV07060096
   Reyes-Aldasoro CC, 2010, J MICROSC-OXFORD, V242, P262
   Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291
   Sadek R.A., 2012, ARXIV12117102
   Sampath RS, 2010, SIAM J SCI COMPUT, V32, P1361, DOI 10.1137/090747774
   Saraswat M, 2013, COMP M BIO BIO E-IV, V1, P185, DOI 10.1080/21681163.2013.794522
   Saraswat M, 2014, MICRON, V65, P20, DOI 10.1016/j.micron.2014.04.001
   Schott RK., 2021, BEST TRANSCRIPT SET
   Sertel O, 2008, INT CONF ACOUST SPEE, P597, DOI 10.1109/ICASSP.2008.4517680
   Sha ASL, 2017, COLOR NORMALIZATION
   Shan D, 2018, COGN COMPUT, V10, P506, DOI 10.1007/s12559-018-9546-0
   Soelter J, 2014, NEUROIMAGE, V98, P279, DOI 10.1016/j.neuroimage.2014.04.041
   Squires S, 2017, NEURAL COMPUT, V29, P2164, DOI [10.1162/neco_a_00980, 10.1162/NECO_a_00980]
   Sun WW, 2017, IEEE T GEOSCI REMOTE, V55, P4032, DOI 10.1109/TGRS.2017.2686842
   Tsai YW, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON CONTROL AND ROBOTICS ENGINEERING, P1
   Vahadane A, 2016, IEEE T MED IMAGING, V35, P1962, DOI 10.1109/TMI.2016.2529665
   Vahadane A, 2015, I S BIOMED IMAGING, P1012, DOI 10.1109/ISBI.2015.7164042
   Van Eycke YR, 2017, SCI REP-UK, V7, P1, DOI 10.1038/srep42964
   Vanrell M, 2001, IEEE IMAGE PROC, P874, DOI 10.1109/ICIP.2001.959185
   Vicory J, 2015, COMPUT MED IMAG GRAP, V43, P89, DOI 10.1016/j.compmedimag.2015.03.005
   Vollmer C, 2014, NEUROCOMPUTING, V124, P22, DOI 10.1016/j.neucom.2012.12.054
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Wang ZF, 2015, IEEE IMAGE PROC, P3500, DOI 10.1109/ICIP.2015.7351455
   Xu J, 2015, COMPUT MED IMAG GRAP, V46, P20, DOI 10.1016/j.compmedimag.2015.04.002
   Xu XW, 2004, PROC SPIE, V5306, P725, DOI 10.1117/12.527514
   YANG JF, 1995, IEEE T IMAGE PROCESS, V4, P1141, DOI 10.1109/83.403419
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zanjani FG, 2018, I S BIOMED IMAGING, P573, DOI 10.1109/ISBI.2018.8363641
   Zdunek R, 2015, ARTIFICIAL NEURAL NETWORKS, P31, DOI 10.1007/978-3-319-09903-3_2
   Zhang JL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080922
   Zhang YG, 2017, NEUROCOMPUTING, V269, P21, DOI 10.1016/j.neucom.2016.08.144
   Zheng YS, 2019, COMPUT METH PROG BIO, V170, P107, DOI 10.1016/j.cmpb.2019.01.008
NR 99
TC 7
Z9 7
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2339
EP 2362
DI 10.1007/s11042-019-08262-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000027
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Rodrigues, TB
   Salgado, DP
   Catháin, CO
   O'Connor, N
   Murray, N
AF Rodrigues, Thiago Braga
   Salgado, Debora Pereira
   Cathain, Ciaran O.
   O'Connor, Noel
   Murray, Niall
TI Human gait assessment using a 3D marker-less multimodal motion capture
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model; Gait analysis; Motion capture; Multimodal sensors
ID MICROSOFT KINECT; OSTEOARTHRITIS; VALIDITY
AB Gait analysis is the measurement, processing and systematic interpretation of biomechanical parameters that characterize human locomotion. It supports the identification of movement limitations and development of rehabilitation procedures. Accurate Gait analysis is important in sports analysis, medical field, and rehabilitation. Although Gait analysis is performed in several laboratories in many countries, there are many issues such as: (i) the high cost of precise Motion Capture systems; (ii) the scarcity of qualified personnel to operate them; (iii) expertise required to interpret their results; (iv) space requirements to install and store these systems; as well as difficulties related to the measurement protocols of each system; (vi) limited availability (vii) and the use of markers can be a barrier for some clinical use cases (e.g. patients recovering from orthopedics surgeries). In this work, we present a low cost and more accessible system based on the integration of a Multiple Microsoft Kinect sensors and multiple Shimmer inertial sensors to capture human Gait. The novel multimodal system combines data from inertial and 3D depth cameras and outputs spatiotemporal Gait variables. A comparison of this system with the VICON system (the gold standard in Motion Capture) was performed. Our relatively low-cost marker-less multimodal motion generates a complete 360-degree skeleton view. We compare our system with the VICON via gait spatiotemporal variables: Gait cycle time, stride time, Gait length (distance between two strides), stride length, and velocity. The system was also evaluated with knee and hip joint angles measurement accuracy. The results show high correlation for spatiotemporal variables and joint angles inside the 95% bootstrap prediction when compared with VICON.
C1 [Rodrigues, Thiago Braga; Salgado, Debora Pereira; Murray, Niall] Athlone Inst Technol, Fac Engn & Informat, Dublin Rd, Athlone, Westmeath, Ireland.
   [Cathain, Ciaran O.] Athlone Inst Technol, Fac Sci & Hlth, Dublin Rd, Athlone, Westmeath, Ireland.
   [O'Connor, Noel] Dublin City Univ, Insight Ctr Data Analyt, Dublin 9, Ireland.
C3 Technological University of the Shannon: Midlands Midwest; Technological
   University of the Shannon: Midlands Midwest; Dublin City University
RP Rodrigues, TB (corresponding author), Athlone Inst Technol, Fac Engn & Informat, Dublin Rd, Athlone, Westmeath, Ireland.
EM t.brodrigues@research.ait.ie; d.psalgado@research.ait.ie;
   ciaranocathain@ait.ie; noel.oconnor@dcu.ie; nmurray@research.ait.ie
RI Rodrigues, Thiago/JEP-6411-2023
OI Braga Rodrigues, Thiago/0000-0002-2017-4492; O Cathain,
   Ciaran/0000-0002-8526-8924
FU Irish Research Council [GOIPG/2017/803]; Science Foundation Ireland
   (SFI) [SFI/13/RC/2106, SFI/12/RC/2289]; Irish Research Council (IRC)
   [GOIPG/2017/803] Funding Source: Irish Research Council (IRC)
FX In addition, the work presented in this paper has been supported by the
   Irish Research Council under grant GOIPG/2017/803. In addition, this
   publication has emanated from research conducted with the financial
   support of Science Foundation Ireland (SFI) under grant numbers
   SFI/13/RC/2106 and SFI/12/RC/2289.
CR Abdelgawad H, 2014, MICROSCOPIC MODELING, V48
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   Andriacchi TP, 2000, J BIOMECH, V33, P1217, DOI 10.1016/S0021-9290(00)00061-0
   [Anonymous], 2015, KIN WIND SDK 2 0
   [Anonymous], 2011, INERTIAL MEMS PRINCI, pXiii
   [Anonymous], 2018, FILL GAPS TRIAL DAT
   [Anonymous], 2015, KIN WIND
   [Anonymous], IMPROVING HAJJ UMRAH
   Bacon-Shone V C., 2000, Hong Kong Physiotherapy Journal, V18, P21, DOI [DOI 10.1016/S1013-7025(09)70013-2, 10.1016/S1013-7025(09)70013-2]
   BRodrigues T, 2019, ACM MULT SYST C 2019
   Calce SE, 2018, INT J PALEOPATHOL, V22, P45, DOI 10.1016/j.ijpp.2018.04.001
   Castelli A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/186780
   Ceseracciu E, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087640
   Chen PZ, 2015, INT J COMPUT GAMES T, V2015, DOI 10.1155/2015/695874
   Choppin S., 2014, SPORTS TECHNOLOGY, V7, P98, DOI DOI 10.1080/19346182.2014.968165
   Clark RA, 2013, J BIOMECH, V46, P2722, DOI 10.1016/j.jbiomech.2013.08.011
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   De Vroey H, 2018, CLIN BIOMECH, V54, P22, DOI 10.1016/j.clinbiomech.2018.03.002
   Derlatka M, 2012, INT C ART INT SOFT C
   Eichelberger P, 2016, J BIOMECH, V49, P2085, DOI 10.1016/j.jbiomech.2016.05.007
   Ferrari A, 2016, IEEE T NEUR SYS REH, V24, P764, DOI 10.1109/TNSRE.2015.2457511
   Ferreira A.V.S., 2015, Acta Fisiatrica, V22, P51, DOI [10.11606/issn.2317-0190.v22i2a114497, DOI 10.11606/ISSN.2317-0190.V22I2A114497]
   Gabel M, 2012, 34 ANN INT C IEEE EM
   GAITRite, 2018, GAITRITE GOLD STAND
   Gutub A, 2014, VELOCITY BASED MODEL, V31
   Gutub A, 2015, 3 ANN DIG GRID SMART, DOI [10.13140/RG.2.1.2694.1528, DOI 10.13140/RG.2.1.2694.1528]
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Howell AM, 2013, IEEE T BIO-MED ENG, V60, P3284, DOI 10.1109/TBME.2013.2250972
   Jana A, 2014, KINECT WINDOWS SDK P, P392
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   Kaysi I, 2013, TRANSPORT RES REC, P111, DOI 10.3141/2350-13
   KUJALA UM, 1994, BRIT MED J, V308, P231, DOI 10.1136/bmj.308.6923.231
   Lau EC, 2000, AM J EPIDEMIOL, V152, P855, DOI 10.1093/aje/152.9.855
   Lei J, 2014, 2014 IEEE 9 C IND EL
   Lenhoff MW, 1999, GAIT POSTURE, V9, P10, DOI 10.1016/S0966-6362(98)00043-5
   Müller B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175813
   Mündermann L, 2006, J NEUROENG REHABIL, V3, DOI 10.1186/1743-0003-3-6
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Papandreou N, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Pennestri E., 2015, COMP LOW COST MARKER, V59, P1
   Saboune J, 2007, INT J ARTIF INTELL T, V16, P593, DOI 10.1142/S021821300700345X
   Sellers WI, 2014, BIOL OPEN, V3, P656, DOI 10.1242/bio.20148086
   Shimmer, 2017, SHIMMER3 IMU UN
   Shivesh K, 2015, CONTRIBUTION MODELIN
   Stt Systems, 2018, CLIN 3DMA
   Tarnita D, 2016, ROM J MORPHOL EMBRYO, V57, P373
   VICON, 2019, FILL GAPS TRIAL DAT
   Windolj M, 2008, J BIOMECH, V41, P2276
   Zhao G, 2006, 7 INT C AUT FAC GEST
NR 50
TC 13
Z9 14
U1 3
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2629
EP 2651
DI 10.1007/s11042-019-08275-9
EA DEC 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500863700002
DA 2024-07-18
ER

PT J
AU Afonso, AP
   Carmo, MB
   Goncalves, T
   Vieira, P
AF Afonso, Ana Paula
   Carmo, Maria Beatriz
   Goncalves, Tiago
   Vieira, Pedro
TI VisuaLeague: Player performance analysis using spatial-temporal data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-temporal visualization; Trajectory analysis; Player performance
   analysis; Animated maps
ID VISUALIZATION; TRAJECTORIES; ANIMATION
AB In recent years, the phenomenon of eSports has been a growing trend and consequently, in addition to players, other groups of users, including coaches and analysts, took an interest in online video games and the data extracted from them. Among many types of video games, one of the most widely played is the MOBA (Multiplayer Online Battle Arena) League of Legend (LoL) game. Similary to traditional sports, players and coaches/analysts analyse all game events, such as, players' movements, to understand how they play to define new strategies and improve their performance. Our main goal is to get a better understanding of which visualizations techniques are more adequate to handle this type of spatio-temporal information data, associated to player performance analysis in video games. To address this goal, we inquired players to identify the analytical questions they need to support for performance analysis and designed the VisuaLeague prototype for the visualization of ingame player trajectories, using animated maps, and events during a LoL match. This paper presents a user study to evaluate the adequacy of animated maps and the analytical strategies followed by players when using spatio-temporal data to analyse player performance. The results support the adequacy of using the animated maps technique to convey information to users in this context. Moreover, they also point out towards a high degree of importance given to the spatio-temporal components of the data for player performance analysis.
C1 [Afonso, Ana Paula; Goncalves, Tiago; Vieira, Pedro] Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
   [Carmo, Maria Beatriz] Univ Lisbon, Fac Ciencias, BioISI, Lisbon, Portugal.
C3 Universidade de Lisboa; BIOISI; Universidade de Lisboa
RP Afonso, AP (corresponding author), Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
EM apafonso@fc.ul.pt
RI Vieira, Pedro M C/H-9830-2016; Carmo, Maria Beatriz/B-4003-2016; Afonso,
   Ana Paula/O-7793-2015
OI Vieira, Pedro M C/0000-0002-3823-1184; Carmo, Maria
   Beatriz/0000-0002-4768-9517; Afonso, Ana Paula/0000-0002-0687-5540
FU FCT (Portuguese Science and Technology Foundation) [UID/CEC/00408/2013,
   UID/MULTI/04046/2013]
FX This work was supported by FCT (Portuguese Science and Technology
   Foundation) through founding of LASIGE Research Unit, ref.
   UID/CEC/00408/2013 and BioISI Research Unit, ref. UID/MULTI/04046/2013.
   The authors are also thankful to the volunteers that participated in the
   user study.
CR Andrienko N, 2013, VISUAL ANAL MOVEMENT, P1
   Bowman B, 2012, IEEE T VIS COMPUT GR, V18, P1956, DOI 10.1109/TVCG.2012.77
   Cotton J.W, 2013, Analyzing Within-Subjects Experiments
   Demsar U, 2010, INT J GEOGR INF SCI, V24, P1527, DOI 10.1080/13658816.2010.511223
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Dodge M., 2011, Geographic Visualization: Concepts, Tools and Applications
   Drachen A., 2013, Game Analytics, Maximizing the Value of Player Data, V1st, P365
   Drachen Anders., 2014, 2014 IEEE GAMES MEDI, P1, DOI DOI 10.1109/GEM.2014.7048109
   Goncalves T., 2016, P 30 INT BCS HUM COM, DOI [10.14236/ewic/HCI2016.22, DOI 10.14236/EWIC/HCI2016.22]
   Gonçalves T, 2018, IEEE INT CON INF VIS, P103, DOI 10.1109/iV.2018.00028
   Gonçalves T, 2015, LECT NOTES COMPUT SC, V9299, P327, DOI 10.1007/978-3-319-22723-8_26
   Gudmundsson J, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054132
   Gudmundsson J, 2014, COMPUT ENVIRON URBAN, V47, P16, DOI 10.1016/j.compenvurbsys.2013.09.004
   Hagerstrand T, 1970, PAPERS REGIONAL SCI, V24, P7, DOI [10.1007/BF01936872, DOI 10.1111/J.1435-5597.1970.TB01464.X]
   Hoobler N, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P163, DOI 10.1109/VISUAL.2004.120
   Huang DD, 2015, IEEE T VIS COMPUT GR, V21, P420, DOI 10.1109/TVCG.2014.2359887
   Kang SJ, 2015, MULTIMED TOOLS APPL, V74, P6323, DOI 10.1007/s11042-014-2121-0
   Kjellin A, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1773965.1773970
   Kraak M.-J., 2003, P 21 INT CARTOGRAPHI, P1988, DOI [10. 1007 / 3 - 540 - 26772 - 7_15, DOI 10.1007/3-540-26772-7_15]
   Li Q, 2017, IEEE T VIS COMPUT GR, V23, P211, DOI 10.1109/TVCG.2016.2598415
   Lobben A, 2008, ANN ASSOC AM GEOGR, V98, P583, DOI 10.1080/00045600802046577
   Loh C. S., 2015, SERIOUS GAMES ANAL, P3
   MacEachren AM, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P87, DOI 10.1109/INFVIS.1998.729563
   Miller J., 2009, PROC HT2009, P1
   Ogao P.J., 2002, Int. J. Appl. Earth Obs. Geoinf, V4, P23, DOI DOI 10.1016/S0303-2434(02)00005-3
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Perse M, 2009, COMPUT VIS IMAGE UND, V113, P612, DOI 10.1016/j.cviu.2008.03.001
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Vieira P, 2017, P 24 ENC PORT COMP G, P1
   Walker A., 2016, More people watched league of legends than the nba finals
   Wallner G, 2013, ENTERTAIN COMPUT, V4, P143, DOI 10.1016/j.entcom.2013.02.002
   Wallner G, 2018, INFORM VISUAL, V17, P239, DOI 10.1177/1473871617713338
   Wallner M, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 1: DIGITIZATION & ACQUISITION, COMPUTER GRAPHICS & INTERACTION, P159, DOI 10.1109/DigitalHeritage.2015.7413859
   Zammitto V, 2008, P EL INF VIS ARTS, P22
NR 39
TC 10
Z9 12
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33069
EP 33090
DI 10.1007/s11042-019-07952-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600021
DA 2024-07-18
ER

PT J
AU Corbatto, M
   Dattolo, A
AF Corbatto, Marco
   Dattolo, Antonina
TI Exploring AppInventory, a visual catalog of applications for assisting
   teachers and students
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web 2.0 applications repository; App 2.0 taxonomy; Multimedia design and
   development for smart e-learning; Innovative smart teaching and learning
   technologies; Multimedia for user engagement and motivation in
   education; Visual organizers; Semantic knowledge structures
AB We are witnessing a meaningful transformation of teaching and learning practices and widespread experimentation of new didactic methodologies. The availability of a huge amount of contents and learning objects on the Web is progressively transforming traditional learning design activity of teachers. However, the Web also offers another great opportunity in helping teachers adopt student centred methodologies: the availability of hundreds of Web 2.0 and mobile applications for creating and sharing digital artefacts. If incorporated into daily teaching and learning activities, they can improve the collaborative, cognitive and creative work of the students, enhancing and redefining traditional educational practices. Nevertheless, although these applications are generally easy to find and use, there is a lack of knowledge about their existence, their functions and their potential in an educational setting. In this paper we present AppInventory, a Web platform which enables teachers (and students) to visually browse through a catalog of 271 apps, semantically organized in a multi-dimensional, purpose-based taxonomy. Users can explore the catalog following personal associative paths; assign ratings, and leave comments.
C1 [Corbatto, Marco; Dattolo, Antonina] Univ Udine, Dept Math Comp Sci & Phys, SASWEB Res Lab, I-34170 Gorizia, Italy.
C3 University of Udine
RP Dattolo, A (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, SASWEB Res Lab, I-34170 Gorizia, Italy.
EM marco.corbatto@uniud.it; antonina.dattolo@uniud.it
RI DATTOLO, Antonina/B-9545-2018
OI DATTOLO, Antonina/0000-0002-8511-524X; CORBATTO,
   Marco/0000-0003-0723-8241
FU University of Udine [2017-19]
FX This work has been partially supported by the project SMARTLAND,
   financed by the University of Udine (2017-19).
CR [Anonymous], 2001, EDUC HORIZONS
   [Anonymous], [No title captured]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cherner Todd, 2014, Contemporary Issues in Technology and Teacher Education, V14, P158
   Corbatto Marco, 2018, Semantics, Analytics, Visualization. 3rd International Workshop, SAVE-SD 2017 and 4th International Workshop, SAVE-SD 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 10959), P78, DOI 10.1007/978-3-030-01379-0_6
   Corbatto M, 2017, ADJUNCT PUBLICATION OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P117, DOI 10.1145/3099023.3099028
   Corbatto M, 2018, IEEE INT CON INF VIS, P530, DOI 10.1109/iV.2018.00098
   Costagliola G, 2002, J VISUAL LANG COMPUT, V13, P573, DOI 10.1006/S1045-926X(02)00025-3
   Costagliola G, 2018, INFORM VISUAL, V17, P335, DOI 10.1177/1473871617714520
   Dattolo A., 2009, P 1 WORKSH NEW FORMS, P1
   Dattolo A, 2008, WEBIST 2008: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, VOL 1, P339
   Dattolo A, 2009, LECT NOTES BUS INF P, V18, P404
   Kerren A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187341
   Kucher K, 2018, COMPUT GRAPH FORUM, V37, P71, DOI 10.1111/cgf.13217
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Lee CY, 2015, J INF TECHNOL EDUC-R, V14, P21
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Nelson Theodor Holm, 2004, J DIGIT INF, V5
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   [No title captured]
   [No title captured]
NR 22
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32891
EP 32918
DI 10.1007/s11042-019-08000-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600014
DA 2024-07-18
ER

PT J
AU Di, FQ
   Zhang, MQ
   Huang, FJ
   Liu, J
   Kong, YJ
AF Di, Fuqiang
   Zhang, Minqing
   Huang, Fangjun
   Liu, Jia
   Kong, Yongjun
TI Reversible data hiding in JPEG images based on zero coefficients and
   distortion cost function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; JPEG images; Zero coefficients; Distortion cost
   function
ID HIGH-CAPACITY; SCHEME; WATERMARKING
AB Recently, reversible data hiding (RDH) in joint photographic experts group (JPEG) images has received a great deal of attention since the JPEG image is one of the most popularly used image formats nowadays. Generally in JPEG image, the quantized discrete cosine transform (DCT) coefficients with the value of zero are far more than those with nonzero coefficients. However, most existing methods are avoided to change these zero coefficients for fear of JPEG file size increase, and the designed distortion cost functions are not perfect. In this paper, we propose a new JPEG RDH method in which the numerous zero coefficients can be modified. Based on an improved distortion cost function, a strategy which can measure the distortion for each coefficient and select coefficient positions which are most suitable for embedding is proposed. With this strategy, zero coefficients are applied to data embedding and the embedding performance is improved. Experimental results have proved that the proposed method can effectively reduce the embedding distortion and increase the embedding capacity while maintaining a relative good file size.
C1 [Di, Fuqiang; Zhang, Minqing; Liu, Jia; Kong, Yongjun] Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Peoples R China.
   [Huang, Fangjun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
   [Huang, Fangjun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Zhang, MQ (corresponding author), Engn Univ Chinese Peoples Armed Police, Dept Elect Technol, Xian 710086, Peoples R China.
EM 1054165690@qq.com
FU National Natural Science Foundation of China [61379152, 61403417,
   61772572, 61872384]; Natural Science Foundation of Guangdong Province of
   China [2017A030313366]; Fundamental Research Funds for the Central
   Universities [17lgjc45]
FX This work is partially supported by National Natural Science Foundation
   of China (No. 61379152, 61403417, 61772572 and 61872384), Natural
   Science Foundation of Guangdong Province of China (2017A030313366), and
   Fundamental Research Funds for the Central Universities (17lgjc45).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Di FQ, 2018, MULTIMED TOOLS APPL, V77, P20917, DOI 10.1007/s11042-017-5498-8
   El-Bendary M, 2013, INT C SCI EL SCI EL, P573
   El-Bendary MAMM, 2012, INT J ELECTRON, V99, P1497, DOI 10.1080/00207217.2012.680786
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   LEE S, 2010, INT J PATTERN RECOGN, V24, P433
   Li QM, 2010, LECT NOTES COMPUT SC, V6297, P653, DOI 10.1007/978-3-642-15702-8_60
   Lin CC, 2010, J SOFT, V5, P327
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Sakai K, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/12/001
   Song XH, 2013, QUANTUM INF PROCESS, V12, P3689, DOI 10.1007/s11128-013-0629-2
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   WOODS L, 1988, J PHYSL, V393, P213
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
NR 26
TC 19
Z9 21
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34541
EP 34561
DI 10.1007/s11042-019-08109-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800014
DA 2024-07-18
ER

PT J
AU Misra, S
   Laskar, RH
AF Misra, Songhita
   Laskar, R. H.
TI Integrated features and GMM Based Hand Detector Applied to Character
   Recognition System under Practical Conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion detection; Bare-hand detection; Character recognition; Pattern
   analysis; Classification
ID DYNAMIC GESTURE RECOGNITION; LINGUISTIC HEDGES; FEATURE-SELECTION
AB Detection of bare-hand under non-ideal conditions is a challenging task. Most of the existing hand detection systems are developed under limited environmental constraints. In this study, a robust two-level bare-hand detector is integrated with a 58 keyboard characters recognition model. At first, the Gaussian mixture model (GMM) based foreground detector is used to segment the region of interest (ROI), which is further classified using Color-texture and texture based models to detect the actual fist. The detected hand is tracked using modified Kanade-Lucas-Tomasi (KLT) tracker to generate the required trajectory points of the character. The feature space for character recognition consists of existing features and three new features, namely, Local Geometrical Area Ratio (LGAR), Area of two halves (ATH), Curve-Area feature (CAF) that are extracted from the trajectory points. Feature space is optimized using statistical analysis algorithms. Multi-factor analysis of individual character subsets such as alphabets, numbers, ASCII characters, etc., are carried out using multiple conventional classifiers along with Support vector machine (SVM), extreme learning machine (ELM), artificial neural network (ANN), and proposed Neuro-fuzzy classifiers. The proposed GMM based motion detection method achieves an accuracy of 100% during the segmentation of ROI, followed by an increase of 46.77% in the accuracy of two-level hand detection under non-ideal conditions. Maximum accuracy of 58 character system using proposed features and ANN classifier is observed to be 92.56%.
C1 [Misra, Songhita] Aditya Engn Coll A, Dept ECE, Surampelam 533437, Andhra Pradesh, India.
   [Laskar, R. H.] NIT Silchar, Dept ECE, Silchar 788010, Assam, India.
C3 Aditya Engineering College, Surampalem; National Institute of Technology
   (NIT System); National Institute of Technology Silchar
RP Misra, S (corresponding author), Aditya Engn Coll A, Dept ECE, Surampelam 533437, Andhra Pradesh, India.
EM songhitam@aec.edu.in; rhlaskar@ece.nits.ac.in
RI MISRA, SONGHITA/AAF-7585-2020; Laskar, Rabul Hussain/AFU-7180-2022
OI MISRA, SONGHITA/0000-0002-0341-2655; Laskar, Rabul
   Hussain/0000-0003-3988-394X
FU Science & Engineering Research Board (SERB) under Department of Science
   & Technology (DST), Government of India [SERB/F/I0220/2018-2019]; MEITY,
   Government of India [PhD-MLA/4(74)/2015-16]
FX Authors are thankful to Science & Engineering Research Board (SERB)
   under Department of Science & Technology (DST), Government of India for
   the financial support under IMPRINT-II project with Diary No.
   SERB/F/I0220/2018-2019. Authors are thankful to MEITY, Government of
   India for the financial support under the Visvesvaraya Ph.D. scheme with
   Grant no. PhD-MLA/4(74)/2015-16. The authors are also thankful to NIT
   Silchar and Aditya Engineering College, Surampelam, India for proving
   the authors with equipments for carrying out the research work.
CR [Anonymous], 2011, MVA
   [Anonymous], 2005, Graphicon
   [Anonymous], 2006, THESIS U SOUTHAMPTON
   [Anonymous], 2017, NEURAL COMPUT APPL
   Barros P, 2017, COMPUT VIS IMAGE UND, V155, P139, DOI 10.1016/j.cviu.2016.10.006
   Bengio S., 2005, MACHINE LEARNING MUL
   Bhuyan MK, 2014, J MULTIMODAL USER IN, V8, P333, DOI 10.1007/s12193-014-0165-0
   Bianconi F, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3651210
   Cetisli B, 2010, EXPERT SYST APPL, V37, P6093, DOI 10.1016/j.eswa.2010.02.108
   Cetisli B, 2010, EXPERT SYST APPL, V37, P6102, DOI 10.1016/j.eswa.2010.02.115
   Cetisli B, 2010, SOFT COMPUT, V14, P365, DOI 10.1007/s00500-009-0410-8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding H, 2014, MOL BIOSYST, V10, P2229, DOI 10.1039/c4mb00316k
   Douglas L, 2011, PUBLIC SPACES, PRIVATE GARDENS: A HISTORY OF DESIGNED LANDSCAPES IN NEW ORLEANS, P15
   Drew LJ, 2007, MOL PAIN, V3, DOI 10.1186/1744-8069-3-1
   Dürre J, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P163, DOI 10.1145/3174243.3174249
   Elmezain M, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P1170
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Haria A, 2017, PROCEDIA COMPUT SCI, V115, P367, DOI 10.1016/j.procs.2017.09.092
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P14343, DOI 10.1007/s11042-017-5032-z
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jiang D, 2007, IEEE INT CONF MOB, P1001
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kao CY, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.700
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V5302, P346, DOI 10.1007/978-3-540-88682-2_27
   Kodituwakku S.R., 2004, INDIAN J COMPUTER SC, V1, P207
   Kuncheva LI, 2002, IEEE T PATTERN ANAL, V24, P281, DOI 10.1109/34.982906
   Lepistö L, 2005, LECT NOTES COMPUT SC, V3540, P901
   Li C, 2018, PATTERN RECOGN, V77, P276, DOI 10.1016/j.patcog.2017.12.023
   Lin J, 2013, OPTIK, V124, P6795, DOI 10.1016/j.ijleo.2013.05.097
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P209, DOI 10.1007/s11042-016-4265-6
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   McCue R., 2009, SPAM CLASSIFICATION
   Misra S, 2017, TENCON IEEE REGION, P1165, DOI 10.1109/TENCON.2017.8228033
   Pietikainen M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P833, DOI 10.1109/ICPR.1996.547285
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rekha J., 2011, Proceedings of the 2011 International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV 2011), P80
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Singh C, 2017, COLOR TEXTURE DESCRI
   Singh J, 2015, INT C ADV COMPUT COM, P4, DOI 10.1109/ACCT.2015.65
   Singha J, 2016, J MULTIMODAL USER IN, V10, P77, DOI 10.1007/s12193-016-0212-0
   Stancic I, 2017, ENG APPL ARTIF INTEL, V66, P33, DOI 10.1016/j.engappai.2017.08.013
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SUN CT, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P94, DOI 10.1109/FUZZY.1993.327457
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tripathy Debi Prasad, 2017, Journal of the Institution of Engineers (India): Series D (Metallurgical & Materials and Mining Engineering), V98, P109, DOI 10.1007/s40033-015-0106-4
   WOODS RE, 1981, P IEEE, V69, P643, DOI 10.1109/PROC.1981.12031
   Xu D, 2015, J INTELL ROBOT SYST, V77, P583, DOI 10.1007/s10846-014-0039-4
   Xu YC, 2009, INSIDE THE WORLD BANK: EXPLODING THE MYTH OF THE MONOLITHIC BANK, P1, DOI 10.1002/cta.587
   Yang C, 2017, PATTERN RECOGN LETT, V99, P39, DOI 10.1016/j.patrec.2017.05.016
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Zaki MM, 2011, PATTERN RECOGN LETT, V32, P572, DOI 10.1016/j.patrec.2010.11.013
   Zeng Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P1, DOI 10.1109/CBS.2018.8612214
NR 59
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34927
EP 34961
DI 10.1007/s11042-019-08105-y
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800031
DA 2024-07-18
ER

PT J
AU Song, D
   Li, TB
   Mao, ZD
   Liu, AA
AF Song, Dan
   Li, Tianbao
   Mao, Zhendong
   Liu, An-An
TI SP-VITON: shape-preserving image-based virtual try-on network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual try-on; Shape-preserving; Person image synthesis; Image
   alignment
ID BODY SHAPE
AB Image-based virtual try-on networks for changing the outfit of a person in an image with the desired clothes of another image have attracted increasing research interests. Previous work try to extract a clothing-agnostic person representation from the original person image and then synthesize it with the given clothes image through a try-on network. However, their body shape representation just downsamples the clothed body segmentation to a low resolution, which is too coarse and still contains noises of original clothes and may result in unrealistic artifacts. Correspondingly, we propose an SP-VITON (Shape-Preserving VIrtual Try-On Network) to keep the user's original body shape while getting rid of the original clothes. Firstly, we augment the shape variety of the dataset and estimate the 2D shape under clothes of the person using DensePose. Then a try-on network is trained with the augmented dataset and new shape representation. Experiment results show our improvements for applying to various shapes and clothes types of the input person image, compared with the state-of-the-art image-based try-on methods.
C1 [Song, Dan; Li, Tianbao; Liu, An-An] Tianjin Univ, Sch Elect & Informat Engn, Multimedia Inst, Tianjin 300072, Peoples R China.
   [Mao, Zhendong] Chinese Acad Sci, Inst Informat Engn, Beijing 100049, Peoples R China.
   [Mao, Zhendong] Univ CAS, Sch Cyber Secur, Beijing 100049, Peoples R China.
C3 Tianjin University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Multimedia Inst, Tianjin 300072, Peoples R China.
EM dan.song@tju.edu.cn; anan0422@gmail.com
FU National Nature Science Foundation of China [61902277, 61772359,
   61872267, 61702471]; Open Project Program of the State Key Lab of CAD &
   CG, Zhejiang University [A1907]; grant of Elite Scholar Program of
   Tianjin University [2019XRX-0035]; grant of 2018 Tianjin New Generation
   Artificial Intelligence Major Program [18ZXZNGX00150]; grant of 2019
   Tianjin New Generation Artificial Intelligence Major Program
FX This work was supported in part by the National Nature Science
   Foundation of China (61902277, 61772359, 61872267, 61702471), the grant
   of 2019 Tianjin New Generation Artificial Intelligence Major Program,
   the grant of 2018 Tianjin New Generation Artificial Intelligence Major
   Program (18ZXZNGX00150), the Open Project Program of the State Key Lab
   of CAD & CG, Zhejiang University (Grant No.A1907), the grant of Elite
   Scholar Program of Tianjin University (2019XRX-0035).
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2018, ARXIV180207938
   [Anonymous], 2017, ACM Trans Graph
   Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bender J., 2015, EUROGRAPHICS TUTORIA
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cheng Z, 2018, A3NCF ADAPTIVE ASPEC
   Dong H., 2018, NeurIPS, P474
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   Hao T, 2018, IEEE ACCESS, V6, P79235, DOI 10.1109/ACCESS.2018.2885005
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Hasler N, 2009, COMPUT GRAPH-UK, V33, P211, DOI 10.1016/j.cag.2009.03.026
   Kingma D. P., 2014, arXiv
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Macklin M, 2016, P 9 INT C MOT GAM, P49, DOI [10.1145/2994258.2994272, DOI 10.1145/2994258.2994272]
   Miguel E, 2012, COMPUT GRAPH FORUM, V31, P519, DOI 10.1111/j.1467-8659.2012.03031.x
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Raj A, 2018, LECT NOTES COMPUT SC, V11216, P679, DOI 10.1007/978-3-030-01258-8_41
   Sabar NR, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2801792
   Salimans T, 2016, ADV NEUR IN, V29
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song D, 2016, COMPUT GRAPH FORUM, V35, P147, DOI 10.1111/cgf.13012
   Tang M, 2013, COMPUT GRAPH FORUM, V32, P21, DOI 10.1111/cgf.12208
   Tsoli A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601225
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wu Zhonghua, 2018, ARXIV181108599
   Wuhrer S, 2014, COMPUT VIS IMAGE UND, V127, P31, DOI 10.1016/j.cviu.2014.06.012
   Yang S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3026479
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhou SZ, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778863
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
NR 38
TC 13
Z9 16
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33757
EP 33769
DI 10.1007/s11042-019-08363-w
EA NOV 2019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000498945600001
DA 2024-07-18
ER

PT J
AU Chen, L
   Li, Q
   Jiang, JJ
AF Chen, Liang
   Li, Qing
   Jiang, Junjun
TI Noisy practical facial super-resolution method via deformable
   constrained model with small dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face super resolution (FSR); Deformable constrained model (DCM); Latent
   distance constraint; Facial image pattern
ID FACE HALLUCINATION; IMAGE SUPERRESOLUTION
AB Face Super-Resolution (FSR) is to infer high resolution facial image(s) from given low resolution one(s). But when large-scale training samples are absent, FSR may fail in inferring high resolution image for practical low resolution facial image with complex degradation. To solve this problem, we present a novel position patch-based FSR method via latent Deformable Constrained Model (FSR-DCM). Different from conventional FSR methods that view an image patch as a fixed-length vector, we train the target image patch as a matrix in a flexible deformation flow form. This enables the dictionary to cover patterns that do not appear in training examples, resulting in our FSR method to be more expressive and able to solve the outlier (heterogeneous) problem. Besides, instead of explicit Euclidean distance, we use latent deformable similarity as distance criteria to measure the patch similarity, which facilitates our FSR method to work in low-quality scene by emphasizing neighbor relationship and enlarging the distance difference. Through enforcing such a constraint, the expressive capability of the FSR method can be improved, and the restoration failure caused by the coefficients of wrongly emphasized candidates can be overcome. Experiments on the public face datasets CAS-PEAL-R1 [9] and FEI [25] demonstrate the superiority of the proposed algorithm against the existing solutions to the problem of enhancing facial images of very low resolution both quantitatively (Peak-Singal-to-Noise Ratio, i.e., PSNR and Structural Similarity, i.e., the SSIM [29]) and qualitatively (subjective performance).
C1 [Chen, Liang] Fujian Normal Univ, Fujian Prov Engn Technol Res Ctr Photoelect Sensi, Key Lab OptoElect Sci & Technol Med, Fujian Prov Key Lab Photon Technol,Minist Educ, Fuzhou, Fujian, Peoples R China.
   [Li, Qing] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
   [Jiang, Junjun] Harbin Inst Technol, Harbin, Heilongjiang, Peoples R China.
C3 Fujian Normal University; Hong Kong Polytechnic University; Harbin
   Institute of Technology
RP Chen, L (corresponding author), Fujian Normal Univ, Fujian Prov Engn Technol Res Ctr Photoelect Sensi, Key Lab OptoElect Sci & Technol Med, Fujian Prov Key Lab Photon Technol,Minist Educ, Fuzhou, Fujian, Peoples R China.
EM cl_0827@126.com
RI Li, Qing/JMH-1365-2023; Jiang, Junjun/L-7087-2019
OI Li, Qing/0000-0003-3370-471X; Jiang, Junjun/0000-0002-5694-505X
FU National Nature Science Foundation of China [61901117, U1805262];
   Natural Science Foundation of Fujian Province [2019J05060, 2019J01271];
   Fujian Provincial Education Department Project [JT180094, JT180095];
   Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of Technology
   [HBIR201906]; Special Funds of the Central Government Guiding Local
   Science and Technology Development [2017L3009]; National Key Research
   and Development Program of China [2016YFB1001001]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grant No. 61901117, U1805262, in part by the
   Natural Science Foundation of Fujian Province under the Grant 2019J05060
   and Grant 2019J01271, in part by the Fujian Provincial Education
   Department Project under Grant JT180094 and Grant JT180095, in part by
   the Hubei Key Laboratory of Intelligent Robot, Wuhan Institute of
   Technology, under Grant HBIR201906, in part by the Special Funds of the
   Central Government Guiding Local Science and Technology Development
   under Grant 2017L3009, and in part by the National Key Research and
   Development Program of China under Grant 2016YFB1001001.
CR [Anonymous], 2006, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.20.92
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P IEEE INT C IM PROC
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen L, 2017, MULTIMED TOOLS APPL, V76, P2467, DOI 10.1007/s11042-015-3145-9
   Chen L, 2014, IEEE INT SYMP CIRC S, P2057, DOI 10.1109/ISCAS.2014.6865570
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Gao W, 2008, CAS PEAL LARGE SCALE
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Huang H, 2011, IEEE T CIRC SYST VID, V21, P1363, DOI 10.1109/TCSVT.2011.2163461
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Jiang JJ, 2014, SIGNAL PROCESS, V103, P168, DOI 10.1016/j.sigpro.2014.02.014
   Lan C, 2010, P INT C MULT, P883
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu SF, 2014, IEEE IMAGE PROC, P4032, DOI 10.1109/ICIP.2014.7025819
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma X, 2009, ICME 2009 IEEE INT C
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sun J, 2003, PROC CVPR IEEE, P729
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiaohui Dong, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P183, DOI 10.1007/978-3-319-13168-9_19
   Yang CY, 2013, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR.2013.146
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang J, 2008, IEEE IMAGE PROC, P1264, DOI 10.1109/ICIP.2008.4711992
   Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871
NR 33
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2577
EP 2600
DI 10.1007/s11042-019-08277-7
EA NOV 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000498201300002
DA 2024-07-18
ER

PT J
AU Jalali, A
   Farsi, H
AF Jalali, Arash
   Farsi, Hassan
TI A new steganography algorithm based on video sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete Cosine Transform (DCT); Dictionary Learning; KSVD; OMP; Sparse
   Representation; Video Sparse Representation; Video Steganography
ID SIGNAL RECOVERY; DIGITAL VIDEO; CLASSIFICATION; RECONSTRUCTION; FUSION;
   SYSTEM
AB Steganography has been a great interest since long time ago. There are a lot of methods that have been widely used since long past. Recently, there has been a growing interest in the use of sparse representation in signal processing. Sparse representation can efficiently model signals in different applications to facilitate processing. Much of the previous work was focused on image and audio sparse representation for steganography. In this paper, a new steganography scheme based on video sparse representation (VSR) is proposed. To exploit proper dictionary, KSVD algorithm is applied to DCT coefficients of Y component related to video (cover) frames. Both I and Q components of video frames are used for secure message insertion. The aim is to hide secret messages into non-zero coefficients of sparse representation of DCT called, I and Q video frames. Several experiments are performed to evaluate the performance of the proposed algorithm, in case of some metrics such as pick signal to noise ratio (PSNR), the hiding ratio (HR), bit error rate (BER) and similarity (Sim) of secret message, and also runtime. The simulation results show that the proposed method exhibits appropriate invisibility and robustness.
C1 [Jalali, Arash; Farsi, Hassan] Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
C3 University of Birjand
RP Farsi, H (corresponding author), Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
EM hfarsi@birjand.ac.ir
RI Farsi, hassan/AAF-5297-2021
OI farsi, hassan/0000-0001-6038-9757
CR Ahani S., 2010, 2010 IEEE International Conference on Information Theory and Information Security, P632, DOI 10.1109/ICITIS.2010.5689508
   Ahani S, 2015, IET IMAGE PROCESS, V9, P496, DOI 10.1049/iet-ipr.2014.0351
   Ahani S, 2015, IEEE-ACM T AUDIO SPE, V23, P80, DOI 10.1109/TASLP.2014.2372313
   [Anonymous], 2019, MULTIMED TOOLS APPL
   [Anonymous], INT J COMPUT ELECT E
   Aziz Sbai SM, 2012, IEEE C INF SCI SIGN, P625
   Blanchard JD, 2015, NUMER LINEAR ALGEBR, V22, P254, DOI 10.1002/nla.1948
   Budhia U, 2006, IEEE T INF FOREN SEC, V1, P502, DOI 10.1109/TIFS.2006.885020
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chae J. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P311, DOI 10.1109/ICIP.1999.821620
   Chandramouli R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1019, DOI 10.1109/ICIP.2001.958299
   Cheddad A, 2008, FIFTEENTH IEEE INTERNATIONAL CONFERENCE AND WORKSHOPS ON THE ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P159, DOI 10.1109/ECBS.2008.11
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2013, IEEE T GEOSCI REMOTE, V51, P217, DOI 10.1109/TGRS.2012.2201730
   Cong YL, 2015, INT SYM COMPUT INTEL, P254, DOI 10.1109/ISCID.2015.148
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Escoda OD, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P490
   Etezadifar P, 2017, MULTIMED TOOLS APPL, V76, P7947, DOI 10.1007/s11042-016-3433-z
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Farsi H., 2010, Signal Processing, Int. J, V4, P17
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Förster EC, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P1, DOI 10.1109/PCS.2015.7170035
   Garnaut R, 2012, PRIVATE ENTERPRISE IN CHINA, P1
   Geng Q, 2014, IEEE INT SYMP INFO, P3180
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Hasheminejad M, 2018, MULTIMED TOOLS APPL, V77, P15273, DOI 10.1007/s11042-017-5114-y
   Hasheminejad M, 2017, MULTIMED TOOLS APPL, V76, P21211, DOI 10.1007/s11042-016-4071-1
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1231
   Hua G, 2016, IEEE SIGNAL PROC LET, V23, P473, DOI 10.1109/LSP.2016.2536110
   Jalali A, 2018, MULTIMED TOOLS APPL, V77, P16347, DOI 10.1007/s11042-017-5201-0
   Jamil T., 1999, IEEE Potentials, V18, P10, DOI 10.1109/45.747237
   Jingjing Huang, 2014, 2014 7th International Symposium on Computational Intelligence and Design (ISCID), P564, DOI 10.1109/ISCID.2014.158
   Keshavarz Seyed Noorodin, 2010, Proceedings of The Fourth International Conference on Next Generation Mobile Applications, Services and Technologies (NGMAST 2010), P168, DOI 10.1109/NGMAST.2010.42
   Keshavarz Seyed Noorodin, 2010, Proceedings of the 2010 Second International Conference on Computer and Network Technology (ICCNT 2010), P249, DOI 10.1109/ICCNT.2010.42
   Keshavarz SN, 2010, SCI RES ESSAYS, V5, P3049
   Knez M, 2017, ADV KARST SCI, P3, DOI 10.1007/978-3-319-45465-8_1
   Krstulovic S., 2006, Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, V3, P496
   Kumar BP, 2018, IEEE T AERO ELEC SYS, V54, P1381, DOI 10.1109/TAES.2017.2785938
   Kumar V, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P223, DOI 10.1109/IADCC.2010.5423005
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Liu H, 2015, INT CONF ASIAN LANG, P1, DOI 10.1109/IALP.2015.7451517
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Lou DC, 2008, INFORM SECURITY ETHI, P438
   Luo B., 2018, IEEE T SYSTEMS MAN C P IEEE 4 INT C MULT, P1
   Maechler P, 2010, CONF REC ASILOMAR C, P400, DOI 10.1109/ACSSC.2010.5757587
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mansouri J, 2009, INT J IMAG SYST TECH, V19, P306, DOI 10.1002/ima.20207
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Mohamadzadeh S, 2016, IMAGE ANAL STEREOL, V35, P67, DOI 10.5566/ias.1346
   Mstafa R.J., 2015, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI 10.1109/LISAT.2015.7160192
   Mstafa R.J., 2015, Wireless Telecommunications Symposium (WTS), P1
   Mstafa RJ, 2016, IEEE SARNOFF SYMPOS, P208
   Mstafa RJ, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P335, DOI 10.1109/ICMLA.2015.117
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D, 2009, FOUND COMPUT MATH, V9, P317, DOI 10.1007/s10208-008-9031-3
   Pan JS, 2015, MULTIMED TOOLS APPL, V74, P9191, DOI 10.1007/s11042-014-2076-1
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Raja K. B., 2005, P 3 INT C INT SENS I, P170
   Rajesh G. R., 2013, IET Chennai Fourth International Conference on Sustainable Energy and Intelligent Systems (SEISCON 2013), P554
   Rencker L, 2017, INT CONF ACOUST SPEE, P4775, DOI 10.1109/ICASSP.2017.7953063
   RoselinKiruba R, 2018, INT C COMP COMM SIGN, P1
   Rubing Xi, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2066, DOI 10.1109/CISP.2010.5646695
   Saha B, 2012, DEFENCE SCI J, V62, P11, DOI 10.14429/dsj.62.1436
   Schepker H. F., 2011, 2011 8th International Symposium on Wireless Communication Systems, P291, DOI 10.1109/ISWCS.2011.6125356
   Singh Ashwani, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P663, DOI 10.1109/ICOEI.2017.8300785
   Su PC, 2013, MULTIMED TOOLS APPL, V66, P247, DOI 10.1007/s11042-011-0799-9
   Sun G, 2018, IEEE ACCESS, P1962
   Sung TY, 2006, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P191
   Swanson MD, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P676, DOI 10.1109/ICIP.1997.638586
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Wang D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P699, DOI 10.1109/SIPROCESS.2016.7888353
   Wang H, 2017, IEEE IMAGE PROC, P3235, DOI 10.1109/ICIP.2017.8296880
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yadav S, 2013, LIT VOICE, V1, P5
   Yan XF, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME), P419, DOI [10.1109/ITME.2016.191, 10.1109/ITME.2016.0100]
   Zaheer M, 2017, INT J COMPUT SCI NET, V17, P133
   Zeki Akram M., 2011, Information Technology Journal, V10, P1367, DOI 10.3923/itj.2011.1367.1373
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhao XM, 2017, J CRYST GROWTH, V470, P1, DOI 10.1016/j.jcrysgro.2017.03.051
   Zhao YQ, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P331, DOI 10.1109/WARTIA.2014.6976263
   Zhao Y, 2016, ASIA-PAC POWER ENERG, P252, DOI 10.1109/APPEEC.2016.7779507
   Zhu X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1720, DOI 10.1109/ICInfA.2016.7832095
   Zhu X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P776, DOI 10.1109/ICInfA.2015.7279389
   Zibulevsky M, 2010, IEEE SIGNAL PROC MAG, V27, P76, DOI 10.1109/MSP.2010.936023
NR 91
TC 12
Z9 12
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1821
EP 1846
DI 10.1007/s11042-019-08233-5
EA NOV 2019
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495944500001
DA 2024-07-18
ER

PT J
AU Guo, C
   Liu, YL
   Jiao, X
AF Guo, Chen
   Liu, Yue-lan
   Jiao, Xuan
TI Study on the influence of variable stride scale change on image
   recognition in CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CNN; Stride; Characteristic mapping; Multimedia
AB After the research based on the progressing image classification recognition method of CNN, the paper aims at the problem that the size of feature size of output map of image with different complexity cannot be well solved by the constant value stride. We bring up the idea which based on the variable stride length for constraint parameters to selectively select the size of the stride. It is helpful to improve the efficiency of selective extraction and recognition of important features. Later studies have proved that the deficiency issue of complex image characteristic extraction due to the large stride size could be averted by adopting the variable stride length method based on constraint parameters. In the meantime, the method also avoids low recognition efficiency due to the image complexity is sparse and, also, the stride size of the image is too small. The theoretically calculated results are in good agreement with the experimental results.
C1 [Guo, Chen] Dalian Jiaotong Univ, Software Technol Inst, Dalian 116021, Peoples R China.
   [Liu, Yue-lan] Harbin Normal Univ, Coll Comp Sci, Harbin 150025, Heilongjiang, Peoples R China.
   [Jiao, Xuan] Dalian Neusoft Univ Informat, Sch Informat & Business Management, Dalian 116021, Peoples R China.
C3 Dalian Jiaotong University; Harbin Normal University
RP Liu, YL (corresponding author), Harbin Normal Univ, Coll Comp Sci, Harbin 150025, Heilongjiang, Peoples R China.
EM gc0094@126.com; gc0094@126.com; gc0094@126.com
RI guo, chen/KTR-9590-2024
FU Natural Science Foundation of Liaoning Province [20170540131]; Nature
   Science Foundation of Heilongjiang Province [C201437]; Natural Science
   Foundation of Heilongjiang Province [QC2018082]; Basic Scientific
   Research Funds of Heilongjing Provincial Higher Education lnstitutions
   [2017-KYYWF-0140]
FX The Project was supported by the Natural Science Foundation of Liaoning
   Province (Grant No. 20170540131), Nature Science Foundation of
   Heilongjiang Province (Grant No.C201437), Natural Science Foundation of
   Heilongjiang Province (Grant No. QC2018082) and Basic Scientific
   Research Funds of Heilongjing Provincial Higher Education lnstitutions
   (Grant No. 2017-KYYWF-0140). And we wish to thank the anonymous
   reviewers who helped to improve the quality of the paper.
CR Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L., 2016, CS231N: Convolutional Neural Networks for Visual Recognition
   Goodfellow I, 2016, DEEPLEARNING UNPUB
   Han FY, 2010, JCNU, V29, P129
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Koutník J, 2014, PR MACH LEARN RES, V32, P1863
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee S, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P609, DOI 10.1109/ICNIDC.2009.5360944
   Meng Dan, 2017, RES IMAGE CLASSIFICA, P5
   Qian Y, 2012, JEIJP, V28, P140
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Wang B., 2015, RES IMAGE CLASSIFICA, P1
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Ye XY, 2006, ED TECHNOLOGY GUIDE, P19
   Yu K, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2211, DOI 10.1145/2505515.2514699
   Zhang C, 2014, INT C PATT RECOG, P827, DOI 10.1109/ICPR.2014.152
   Zhang J., 2018, The collective Forest tenure reform, V7, P1, DOI DOI 10.1038/S41419-018-0946-6
   Zhu J, 2015, IEEE PR SER POWER, P1, DOI 10.1002/9781118887004
NR 26
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30027
EP 30037
DI 10.1007/s11042-018-6861-0
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200022
DA 2024-07-18
ER

PT J
AU Dou, K
   Guo, B
   Kuang, L
AF Dou, Kai
   Guo, Bin
   Kuang, Li
TI A privacy-preserving multimedia recommendation in the context of social
   network based on weighted noise injection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Privacy preserving; Multimedia recommendation; Noise
   injection
AB With the popularity of social networks such as Facebook and Twitter, more information such as individual's social connections is considered to make personalized multimedia recommendation, compared to traditional approaches based on the rating matrix. However, the massive data information used for recommendation often contains much personal privacy information. Once the information is obtained by attackers, user's privacy will be revealed directly or indirectly. This paper proposes a privacy preserving method based on weighted noise injection technique to address the issue of multimedia recommendation in the context of social networks. More specifically, first, we extract core users from entire users. The extracted core users can represent the features of all users adequately. Only the relevant data of core users are then used for rating prediction. Second, we inject different noises to the rating matrix of core users according to different relations between the target user and core users. Third, we use the perturbed matrix to predict the ratings of unused multimedia resources for the target user based on a mixed collaborative filtering approach. By comparing with the traditional noise injection method, the experimental results show that the proposed approach can get better performance of privacy preserving multimedia recommendation.
C1 [Dou, Kai; Guo, Bin; Kuang, Li] Cent S Univ, Sch Software, Changsha 410075, Hunan, Peoples R China.
C3 Central South University
RP Kuang, L (corresponding author), Cent S Univ, Sch Software, Changsha 410075, Hunan, Peoples R China.
EM doukai@csu.edu.cn; guobin@csu.edu.cn; kuangli@csu.edu.cn
FU Natural Science Foundation of Hunan Province [2016JJ3154]; National
   Natural Science Foundation of China [61202095]; Scientific Research
   Project for Professors in Central South University, China [904010001];
   "Innovation Project for Graduate Students in Central South University
   [502210017]
FX The research is supported by "Natural Science Foundation of Hunan
   Province" (No. 2016JJ3154), "National Natural Science Foundation of
   China" (No. 61202095), "Scientific Research Project for Professors in
   Central South University, China" (No. 904010001), and "Innovation
   Project for Graduate Students in Central South University" (No.
   502210017).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], 2016, STAT REPORT INTERNET
   [Anonymous], 2004, Proceedings of the thirteenth ACM international conference on Information and knowledge management, DOI [10.1145/1031171.1031252, DOI 10.1145/1031171.1031252]
   Banerjee S, 2012, ANN ALLERTON CONF, P920, DOI 10.1109/Allerton.2012.6483317
   Berkvosky S, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P9
   Calandrino JA, 2011, P IEEE S SECUR PRIV, P231, DOI 10.1109/SP.2011.40
   Canny J., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P238, DOI 10.1145/564376.564419
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen P, 2007, J INFORMETR, V1, P8, DOI 10.1016/j.joi.2006.06.001
   Das Abhinandan S, 2007, P 16 INT C WORLD WID, P271
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Fagin R, 2005, THEOR COMPUT SCI, V336, P89, DOI 10.1016/j.tcs.2004.10.033
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Iacobucci D, 2005, REFLECTIONS, V61
   Kim BM, 2004, IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2004), PROCEEDINGS, P185
   Lei T, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ENERGY, P213
   Li TC, 2009, PROC INT CONF DATA, P6, DOI 10.1109/ICDE.2009.86
   Lin HL, 2014, J DIGIT IMAGING, V27, P449, DOI 10.1007/s10278-014-9678-z
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Liu X., 2016, J COMPUT SYST SCI
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Liu Xingjie., 2012, Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '12, P1032
   Liu XJ, 2013, IEEE INT CONF TRUST, P477, DOI 10.1109/TrustCom.2013.60
   McSherry F, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P627
   Narayanan A, 2009, P IEEE S SECUR PRIV, P173, DOI 10.1109/SP.2009.22
   Narayanan P, 2004, U. S. Patent Application, Patent No. [10/709, 161, 10709161]
   Parameswaran R, 2007, GRC: 2007 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, PROCEEDINGS, P380, DOI 10.1109/GrC.2007.133
   Park ST, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P550
   Polat H., 2003, Privacy-preserving collaborative filtering using randomized perturbation techniques
   Salakhutdinov Ruslan, 2008, P INT C MACH LEARN, P880, DOI [10.1145/1390156.1390267, DOI 10.1145/1390156.1390267]
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Schafer J. B., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P291
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Tuzhilin A., 2008, KDD P
   Xia YJ, 2016, MULTIMED TOOLS APPL, V75, P8829, DOI 10.1007/s11042-014-2256-z
   Xia YJ, 2016, THEOR COMPUT SCI, V618, P1, DOI 10.1016/j.tcs.2015.12.025
   Zhan J, 2010, IEEE T SYST MAN CY C, V40, P472, DOI 10.1109/TSMCC.2010.2040275
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang W, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P910
NR 46
TC 20
Z9 21
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26907
EP 26926
DI 10.1007/s11042-017-4352-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000005
DA 2024-07-18
ER

PT J
AU Kamarajugadda, KK
   Polipalli, TR
AF Kamarajugadda, Kishore Kumar
   Polipalli, Trinatha Rao
TI Age-invariant face recognition using multiple descriptors along with
   modified dimensionality reduction approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periocular region; Scale invariant feature transform (SIFT); Speeded up
   robust features (SURF); Enhanced principal components analysis (EPCA);
   Artificial neural network (ANN)
ID COMPONENT ANALYSIS; NEURAL-NETWORK
AB Face recognition on the basis of age variation is a significant yet challenging issue. One among the effective methods to age-invariant face recognition is to form a face aging model that can be utilized to recompense for the aging process in face matching or age assessment. The periocular region of a face is the most age-invariant facial region, to abstract discriminative local features that are distinct for every subject. Feature vector space can be reduced by utilizing the features only from the periocular region. So, in this article, features are only extracted from the periocular region of a face. For feature extraction, multiple descriptors such as Scale Invariant Feature Transform (SIFT) and then Speeded Up Robust Features (SURF). As the extracted features vector has high dimensionality, it is decreased to the low dimensionality using the Enhanced Principal Components Analysis (EPCA) method. Finally, these extracted features are given as input to the Artificial Neural Network (ANN) based classifier which performs to recognize the face of the input image. Our projected method is applied and tested by Matlab for FG-NET face aging dataset Simulation results show that the performance of the proposed approach outperforms that of the existing age-invariant face recognition schemes in terms of accuracy, complexity and false recognition ratio.
C1 [Kamarajugadda, Kishore Kumar] IFHE, Fac Sci & Technol, Hyderabad, India.
   [Polipalli, Trinatha Rao] GITAM Univ, Dept ECE, Hyderabad, India.
C3 The ICFAI Foundation for Higher Education (IFHE); ICFAI Tech (Faculty of
   Science & Technology); Gandhi Institute of Technology & Management
   (GITAM)
RP Kamarajugadda, KK (corresponding author), IFHE, Fac Sci & Technol, Hyderabad, India.
EM kkishore@ifheindia.org
RI , Polipalli/ABG-8543-2020; KAMARAJUGADDA, KISHORE KUMAR/AAV-3802-2021
OI , Polipalli/0000-0002-2456-4957; KAMARAJUGADDA, KISHORE
   KUMAR/0000-0002-6286-1186
CR Ali ASO, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415560066
   Ali ASO, 2015, IET BIOMETRICS, V4, P98, DOI 10.1049/iet-bmt.2014.0018
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bouchaffra D, 2015, IEEE T NEUR NET LEAR, V26, P1375, DOI 10.1109/TNNLS.2014.2341634
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Du JX, 2013, NEUROCOMPUTING, V116, P250, DOI 10.1016/j.neucom.2012.08.030
   Fang Er-Qing, 2011, Journal of Software, V22, P1503, DOI 10.3724/SP.J.1001.2011.04012
   Kasar MM, 2016, INT J SECUR APPL, V10, P81, DOI 10.14257/ijsia.2016.10.3.08
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Sahni S., 2014, MIT International Journal of Computer Science and Information Technology, V4, P82
   Song J, 2018, P 27 INT JOINT C ART
   SunitaDevi N, 2013, INT J COMPUT APPL, V83, P10
   Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578
   Zhou HL, 2018, PATTERN RECOGN, V76, P191, DOI 10.1016/j.patcog.2017.10.036
NR 20
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27639
EP 27661
DI 10.1007/s11042-019-7741-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000039
DA 2024-07-18
ER

PT J
AU Qi, MB
   Han, JX
   Jiang, JG
   Liu, H
AF Qi, Meibin
   Han, Jingxian
   Jiang, Jianguo
   Liu, Hao
TI Deep feature representation and multiple metric ensembles for person
   re-identification in security surveillance system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Convolutional neural network; Multiple metric
   ensembles; Video surveillance
ID FUSION; CUES
AB With the increasing concern about social public security and the development of large scale data storage technology, person re-identification in security surveillance system becomes a hot topic. Large variations in viewpoint and lighting across different camera views could change the appearance of the person a lot, which makes person re-identification still a challenging problem. Therefore, developing robust feature descriptors and designing discriminative distance metrics to measure the similarity between pedestrian images are two key aspects in person re-identification. In this paper, we propose a method using both deep learning and multiple metric ensembles to improve the performance of the re-identification. Firstly, we jointly use the various datasets to train a general Convolutional Neural Network (CNN) which is employed to extract the deep features of training and testing set afterwards. The deep architecture makes it possible to learn more abstract and internal features which are robust against the variations in viewpoint and lighting. Then we utilize the deep features of the training set to learn the specific distance metric of different datasets and combine it with Cosine distance metric together, multiple metric ensembles can measure the similarity between different images in a more comprehensive way. Finally, extensive experiments demonstrate that our method can improve the recognition performance effectively when compared with the state-of-the-art methods.
C1 [Qi, Meibin; Han, Jingxian; Jiang, Jianguo; Liu, Hao] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Han, JX (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM jingxhan@163.com
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   An L, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P244, DOI 10.1109/AVSS.2013.6636647
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 3 INT C ED REF MOD
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], FCV
   [Anonymous], COMPUTER SCI
   [Anonymous], PREDICTING URBAN WAT
   [Anonymous], LARGE MARGIN LOCAL M
   [Anonymous], 2009, BMVC
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Davis J. V., 2007, ICML, P209
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Liu L, 2016, 30 AAAI C ART INT
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao H, 2007, 10 INT WORKSH PERF E
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
NR 54
TC 12
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27029
EP 27043
DI 10.1007/s11042-017-4649-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000011
DA 2024-07-18
ER

PT J
AU Wu, KW
AF Wu, Kewei
TI Monocular relative depth reordering by propagating confidence of local
   and global cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth ordering; Graph model; Belief propagation
AB Local occlusion cue has been successfully exploited to infer depth ordering from monocular image. However, due to uncertainty of occluded relations, inconsistent results frequently arise, especially for the image of complex scenarios. We propose a depth propagation mechanism which incorporates local occlusion and global ground cues together in the way of probabilistic-to-energetic Bayesian framework. By maximizing posterior namely minimizing energy of latent relative depth variables with well-defined pairwise occlusion priori, we recover correct depth ordering in monocular setting. Our model can guarantee the consistency of relative depth labeling in automatically constructed topological graph via transferring more confident aligned multi-depth cues amongst different segments. Experiments demonstrate that more reasonable and accurate outcomes can be achieved by our depth propagation mechanism and they are also superior to common-used occlusion-based approaches in complex nature.
C1 [Wu, Kewei] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
   [Wu, Kewei] Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Wu, KW (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.; Wu, KW (corresponding author), Hefei Univ Technol, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Anhui, Peoples R China.
EM wu_kewei1984@163.com
FU National Key Research and Development Program of China [2017YFB1002203];
   National Nature Science Foundation of China [61503111, 61501467]; Anhui
   Province Key Laboratory of Industry Safety and Emergency Technology
FX This research was supported by National Key Research and Development
   Program of China (2017YFB1002203), National Nature Science Foundation of
   China (61503111, 61501467), and Anhui Province Key Laboratory of
   Industry Safety and Emergency Technology.
CR Amer MR, 2015, INT J COMPUT VISION, V112, P23, DOI 10.1007/s11263-014-0752-2
   [Anonymous], EUR C COMP VIS
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Calderero F, 2013, INT J COMPUT VISION, V104, P38, DOI 10.1007/s11263-013-0613-4
   Cheng HM, 2013, IEEE IMAGE PROC, P2121, DOI 10.1109/ICIP.2013.6738437
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2008, COMPUT VIS PATTERN R, P1
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4
   Jia ZY, 2012, PROC CVPR IEEE, P294, DOI 10.1109/CVPR.2012.6247688
   Kang ZH, 2016, CARBON NANOSTRUCT, P257, DOI 10.1007/978-3-319-28782-9_8
   Kosecká J, 2002, LECT NOTES COMPUT SC, V2353, P476
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ming AL, 2016, IEEE INTELL SYST, V31, P54, DOI 10.1109/MIS.2015.94
   Ming AL, 2015, IEEE IMAGE PROC, P2525, DOI 10.1109/ICIP.2015.7351257
   Nagata S., 1991, PICTORIAL COMMUNICAT, P527
   Palou G, 2013, IEEE T IMAGE PROCESS, V22, P1926, DOI 10.1109/TIP.2013.2240002
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang ZY, 2015, IEEE I CONF COMP VIS, P2614, DOI 10.1109/ICCV.2015.300
   Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660
NR 28
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27155
EP 27173
DI 10.1007/s11042-017-5432-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000017
DA 2024-07-18
ER

PT J
AU Zhang, LH
   Li, LQ
   Pan, XP
   Cao, ZW
   Chen, QY
   Yang, HH
AF Zhang, Longhao
   Li, Lingqiao
   Pan, Xipeng
   Cao, Zhiwei
   Chen, Qianyu
   Yang, Huihua
TI Multi-Level Ensemble Network for Scene Recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene recognition; Neural network; Small object-supported scenes;
   Ensemble learning; Feature fusion
AB Scene recognition is an important branch of computer vision and a common task for deep learning. As is known to all, different scenes are supported by different "key objects". Therefore, the neural network used for the scene recognition task needs to extract the features of these key objects in the scene, sometimes even has to integrate the positional relation between objects to determine the class to which the scene belongs. Under some circumstances, key objects in the scenes are very small and the features of them become extremely inconspicuous or even disappear in the deep layers of the network. Such kind of phenomenon is called "small object-supported scenes". In this paper, Multi-Level Ensemble Network (MLEN), a convolutional neural network, has been proposed, to improve the recognition accuracy of these "small object-supported scenes". Features from multiple levels of the net are used to make separate predictions. Then ensemble learning is performed within the net to make the final prediction. Apart from all this, "Feature Transfer Path" is added and feature fusion methods are adopted to make full use of low-level and high-level features. Moreover, a class-weight loss function for the problem of non-uniform class distribution has been designed. This function can help further improve accuracy in most scene recognition datasets. The experiments involve the Urban Management Case (UMC) dataset collated from two smart urban management system databases by ourselves, and the Places-mini dataset, which is a subset of the well-known Places dataset [36]. The results show that our Multi-Level Ensemble Network achieves much higher accuracy than the state-of-the-art scene recognition networks on both datasets.
C1 [Zhang, Longhao; Li, Lingqiao; Pan, Xipeng; Cao, Zhiwei; Yang, Huihua] Beijing Univ Posts & Telecommun, Automat Sch, Beijing Shi, Peoples R China.
   [Chen, Qianyu] Beijing Univ Posts & Telecommun, Beijing Shi, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Yang, HH (corresponding author), Beijing Univ Posts & Telecommun, Automat Sch, Beijing Shi, Peoples R China.
EM yhh@bupt.edu.cn
RI Li, Lingqiao/HNQ-2741-2023; Yang, Huihua/ABI-3520-2020
OI Li, Lingqiao/0000-0001-9402-0421; Yang, Huihua/0000-0001-6334-4044
CR [Anonymous], 2016, Densely Connected Convolutional Networks
   [Anonymous], 2017, Dual path networks
   [Anonymous], 2016, Fully Convolutional Instance-aware Semantic Segmentation
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cheng Z, 2018, ACM Transactions on Information Systems
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   George M, 2016, LECT NOTES COMPUT SC, V9905, P783, DOI 10.1007/978-3-319-46448-0_47
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Hariharan B, EUROPEAN C COMPUTER, V297, P312
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Romera-Paredes B, 2016, LECT NOTES COMPUT SC, V9910, P312, DOI 10.1007/978-3-319-46466-4_19
   Shen Li, 2016, Computer Vision-ECCV 2016, DOI DOI 10.1007/978-3-319-46478-7_29
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang YX, 2016, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2016.233
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao S., 2017, IEEE Transactions on Cybernetics, P1
   Zhao S, 2016, IEEE T MULTIMEDIA, VPP, P1
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou Bolei, 2018, IEEE T PATTERN ANAL
NR 34
TC 2
Z9 3
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28209
EP 28230
DI 10.1007/s11042-019-07933-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000064
DA 2024-07-18
ER

PT J
AU Ezatzadeh, S
   Keyvanpour, MR
AF Ezatzadeh, Shabnam
   Keyvanpour, Mohammad Reza
TI ViFa: an analytical framework for vision-based fall detection in a
   surveillance environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aged population; Fall detection; Machine vision; Monitoring;
   Comprehensive framework; Analytical comparison
ID ACTIVITY CLASSIFICATION; DETECTION SYSTEM; ELDERLY PERSON; REAL-TIME
AB The decrease in fertility rates and the increase in the average age of individuals are the main reasons behind the aging of the population. Challenges that come with an aging population include proper nursing care. Because the cost of healthcare is high and falls that cause injury or death in the elderly are escalating, they are a challenge for public welfare and research into reliable surveillance is essential. Non-intrusive fall detection systems are vital for reducing fall trauma and machine vision is an appropriate solution for detecting unusual events such as falls. Because there are varieties of vision-based fall detection (VBFD) methods and a comprehensive framework is lacking, comparison and evaluation of existing methods are difficult. In the current study, an analytical framework having three main components is proposed. First, existing VBFD methods are classified into three categories. Next, general evaluation criteria are defined for analysis of the proposed categorizations. Finally, each method is qualitatively analyzed using the proposed categorizations. The proposed framework can accurately provide identification and analytical comparison of existing methods. In addition, it can allow selection of the most appropriate methods and suggest improvements for existing methods.
C1 [Ezatzadeh, Shabnam; Keyvanpour, Mohammad Reza] Alzahra Univ, Dept Comp Engn, Tehran, Iran.
C3 Alzahra University
RP Keyvanpour, MR (corresponding author), Alzahra Univ, Dept Comp Engn, Tehran, Iran.
EM keyvanpour@alzahra.ac.ir
RI Keyvanpour, Mohammad Reza/AAL-5574-2020
OI Keyvanpour, Mohammad Reza/0000-0003-2115-9099
CR [Anonymous], 2015, P 8 ACM INT C PERV T
   [Anonymous], 2 INT C PHOT OPT ENG
   [Anonymous], WHO GLOB REP FALLP
   [Anonymous], 2013, THESIS
   [Anonymous], 2016, 2016 INT C IND POS I, DOI DOI 10.1109/IPIN.2016.7743617
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], THESIS
   [Anonymous], 2013, P VIS COMM IM PROC
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], THESIS
   [Anonymous], CHALLENGES ISSUES TR
   [Anonymous], 2017, ARXIV170707608
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 1350 DIRO U NONTR
   [Anonymous], 2018, THESIS
   [Anonymous], 2017, WIREL COMMUN MOB COM, DOI DOI 10.1155/2017/9474806
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Baldewijns G, 2016, HEALTHC TECHNOL LETT, V3, P6, DOI 10.1049/htl.2015.0047
   Castillo JC, 2014, INT J SYST SCI, V45, P810, DOI 10.1080/00207721.2013.784372
   Chen MC, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016642914
   Chen YT, 2010, IEEE IMAGE PROC, P3485, DOI 10.1109/ICIP.2010.5650127
   Cheng WC, 2013, IEEE J BIOMED HEALTH, V17, P411, DOI 10.1109/JBHI.2012.2237034
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Cucchiara R, 2007, EXPERT SYST, V24, P334, DOI 10.1111/j.1468-0394.2007.00438.x
   Delahoz YS, 2014, SENSORS-BASEL, V14, P19806, DOI 10.3390/s141019806
   Doukas CN, 2011, IEEE T INF TECHNOL B, V15, P277, DOI 10.1109/TITB.2010.2091140
   Doulamis A, 2010, INT ARCH PHOTOGRAMM, V38, P207
   El-Bendary N, 2013, INT J SMART SENS INT, V6, P1230, DOI 10.21307/ijssis-2017-588
   Ezatzadeh S, 2017, 2017 9TH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT 2017), P93, DOI 10.1109/IKT.2017.8258624
   Fan K, 2018, Multimedia Tools and Applications, P1
   Fan KB, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717707418
   Feng WG, 2014, SIGNAL IMAGE VIDEO P, V8, P1129, DOI 10.1007/s11760-014-0645-4
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Foroughi H, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P413, DOI 10.1109/ICVGIP.2008.49
   Hijaz F., 2010, 2010 International Conference on Information and Emerging Technologies, P1, DOI DOI 10.1109/ICIET.2010.5625702
   Hsieh CY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020307
   Htike Z. Z., 2011, 2011 7th International Conference on Intelligent Environments, P40, DOI 10.1109/IE.2011.54
   Igual R, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-66
   Jansen B., 2006, PERVASIVE HLTH C WOR, P1, DOI DOI 10.1109/PCTHEALTH.2006.361657
   Khan SS, 2017, MED ENG PHYS, V39, P12, DOI 10.1016/j.medengphy.2016.10.014
   Koohzadi M, 2015, SIGNAL IMAGE VIDEO P, V9, P1235, DOI 10.1007/s11760-013-0557-8
   Koohzadi M, 2014, ARTIF INTELL REV, V41, P401, DOI 10.1007/s10462-012-9315-5
   Koshmak G, 2016, J SENSORS, V2016, DOI 10.1155/2016/6931789
   Lotfi A, 2018, IEEE ACCESS, V6, P70272, DOI 10.1109/ACCESS.2018.2881237
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P15017, DOI 10.1007/s11042-015-2513-9
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mohamed O., 2014, Proc. IEEE Int. Conf. New Technol., Mobility, P1
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nadi M, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION TECHNOLOGY AND SENSOR APPLICATION (AITS), P71, DOI 10.1109/AITS.2015.27
   Nizam Y, 2016, INT J INTEGR ENG, V8, P35
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Rajabi Hamid., 2015, Pattern Recognition and Image Analysis (IPRIA), 2nd International Conference on, P1
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Rougier Caroline, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6384
   Shoaib M., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P52, DOI 10.1109/PSIVT.2010.16
   Su SZ, 2016, MULTIMED TOOLS APPL, V75, P8469, DOI 10.1007/s11042-015-2766-3
   Suriani N. S., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P519, DOI 10.1109/CSPA.2012.6194784
   Thome N, 2008, IEEE T CIRC SYST VID, V18, P1522, DOI 10.1109/TCSVT.2008.2005606
   Töreyin BU, 2005, LECT NOTES COMPUT SC, V3766, P211, DOI 10.1007/11573425_21
   Tu Z, 2007, PROC CVPR IEEE, P500
   Vaidehi V., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P1016, DOI 10.1109/ICRTIT.2011.5972252
   Vishwakarma V, 2007, LECT NOTES COMPUT SC, V4815, P616
   Wang K, 2016, IEEE INT C BIOINFORM, P1228, DOI 10.1109/BIBM.2016.7822694
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang L, 2016, DIGIT COMMUN NETW, V2, P24, DOI 10.1016/j.dcan.2015.12.001
   Yang L, 2015, SENSORS-BASEL, V15, P23004, DOI 10.3390/s150923004
   Yu M, 2012, IEEE T INF TECHNOL B, V16, P1274, DOI 10.1109/TITB.2012.2214786
   Yu XG, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P42, DOI 10.1109/HEALTH.2008.4600107
   Zandian ZK, 2017, INT J KNOWL-BASED IN, V21, P123, DOI 10.3233/KES-170357
   Zerrouki N, 2018, MULTIMED TOOLS APPL, V77, P6405, DOI 10.1007/s11042-017-4549-5
   Zhang Z, 2012, INT C PATT RECOG, P3626
   Zolfaghari S, 2017, INT J E-BUS RES, V13, P58, DOI 10.4018/IJEBR.2017040104
   Zolfaghari S, 2016, ACSIS-ANN COMPUT SCI, V8, P1435, DOI 10.15439/2016F132
NR 77
TC 5
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25515
EP 25537
DI 10.1007/s11042-019-7720-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700013
DA 2024-07-18
ER

PT J
AU Hawas, AR
   El-Khobby, HA
   Abd-Elnaby, M
   Abd El-Samie, FE
AF Hawas, Ahmed R.
   El-Khobby, Heba A.
   Abd-Elnaby, M.
   Abd El-Samie, Fathi E.
TI Gait identification by convolutional neural networks and optical flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; OPGEI; Convolution neural network; OPGEINet
ID RECOGNITION
AB Non-interactive biometric systems have gained an enormous interest from computer vision researchers as they provide more efficient and reliable ways of identification and authorization from a distance. Gait and face recognition are types of non-interactive biometric systems without users' cooperation with the surveillance system. On the contrary to face recognition, gait recognition can manage low-resolution and low-brightness images. It aims to know the individuals based on their style and way of walking. Gait recognition has numerous applications in several domains, such as healthcare monitoring, security systems, and surveillance systems for indoor and outdoor activities. Yet, gait recognition performance is frequently deteriorated by some variety of factors, such as viewing angle variations, and clothing changes. Recently, deep learning models have been employed efficiently in gait recognition systems. They are more generic, since the feature construction process is completely automated. This paper presents gait features measured automatically in the midst of walking for the recognition system. To extract these features from a video of a moving object, two vital modules are used, namely the motion detection and tracking, and the feature extraction. Accordingly, the principal module serves to distinguish the walking style in an image sequence or video. A background subtraction technique is executed to fragment the movement of the background, and the moving area related to the spatial silhouette is correctly tracked and segmented. The second module "Feature Extraction" is used to extract the features from the sequence of silhouette images. The gait cycle is calculated from the shape changes of the silhouettes, and it is used to construct a small sequence of Gait Energy Images (GEI). The optical flow of the GEI is measured to extract only the moving parts and exclude the static ones. Finally, the Convolution Neural Network (CNN) is fed with the optical flow output to build unique features. These features are used for neural network training, and evaluation is performed on popular gait benchmark datasets. The obtained results reveal an accuracy level of 95% with more resistance to view and probe changes.
C1 [Hawas, Ahmed R.; El-Khobby, Heba A.; Abd-Elnaby, M.] Tanta Univ, Fac Engn, Elect & Elect Commun Dept, Tanta, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Elect & Elect Commun Dept, Menoufia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Menofia University
RP El-Khobby, HA (corresponding author), Tanta Univ, Fac Engn, Elect & Elect Commun Dept, Tanta, Egypt.
EM h_khobby@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518
CR [Anonymous], CHIN C BIOM REC
   [Anonymous], AUT FAC GEST REC 200
   [Anonymous], IM SIGN PROC CISP 20
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], 2014, ARXIV14062199CS
   [Anonymous], AUT FAC GEST REC 200
   [Anonymous], IM PROC ICIP 2013 20
   [Anonymous], 2016, IEEE T PATTERN ANAL
   Bashir K., 2009, Gait recognition using gait entropy image, P1
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu HF, 2013, IEEE T CIRC SYST VID, V23, P1274, DOI 10.1109/TCSVT.2013.2242640
   Hu MD, 2013, IEEE T CYBERNETICS, V43, P77, DOI 10.1109/TSMCB.2012.2199310
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Uddin MZ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P156, DOI 10.1109/MFI.2017.8170422
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Yee-Hong Yang, 1992, Machine Vision and Applications, V5, P17, DOI 10.1007/BF01213527
NR 24
TC 21
Z9 25
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25873
EP 25888
DI 10.1007/s11042-019-7638-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700029
DA 2024-07-18
ER

PT J
AU He, QQ
   He, B
   Zhang, Y
   Fang, H
AF He, Qinqing
   He, Bin
   Zhang, Yun
   Fang, Hui
TI Multimedia based fast face recognition algorithm of speed up robust
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Speed up robust feature; Descriptor vector; Matching
   of interest points; K-means clustering
ID IMAGE
AB For the problem that the HAAR descriptors in the speed up robust feature (SURF) algorithm cannot make full use of the information around the feature points, the K-Mean clustering technology is used in this paper to improve the SURF, thus proposing a new face recognition algorithm. Firstly, the problem that the main direction is too dependent on the direction of the local area is avoided by expanding the scope of the main direction; then the information around the subblock that is masked by the 3 x 3 window template is made full use of to construct a descriptor with stronger recognition ability; finally, the problems of excessive time consumed and incorrect matching of interest points are solved by introducing the K-Mean clustering idea. The results of the experiment on FERET and Yale face database show that the proposed algorithm has higher recognition rate and efficiency than other face recognition techniques.
C1 [He, Qinqing; He, Bin; Zhang, Yun; Fang, Hui] Guangdong Univ Technol, Sch Management, Guangzhou 510520, Guangdong, Peoples R China.
   [Zhang, Yun] Wuzhou Univ, Sch Econ & Management, Wuzhou 543002, Guangxi, Peoples R China.
C3 Guangdong University of Technology; Wuzhou University
RP He, QQ (corresponding author), Guangdong Univ Technol, Sch Management, Guangzhou 510520, Guangdong, Peoples R China.
EM heqinqq2@163.com
RI Wang, Yue/JRY-8962-2023; Ling, Jie/JJF-9995-2023
OI Wang, Yue/0000-0001-8673-6358; 
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   [Anonymous], B SCI TECHNOL
   [Anonymous], COMPUTER DIGITAL ENG
   [Anonymous], INT J PATTERN RECOGN
   [Anonymous], POWER SYSTEMS BIG DA
   [Anonymous], 2018, CAAI T INTELL TECHNO
   Galar M, 2015, PATTERN RECOGN, V48, P28, DOI 10.1016/j.patcog.2014.07.023
   He HX, 2007, COMPUTATIONAL INTELLIGENCE IN ECONOMICS AND FINANCE, VOL II, P123, DOI 10.1007/978-3-540-72821-4_7
   Liu Y, 2012, EXPERT SYST APPL, V39, P10500, DOI 10.1016/j.eswa.2012.02.139
   Mohammed MA, 2018, COMPUT ELECTR ENG, V71, P372, DOI 10.1016/j.compeleceng.2018.07.044
   Momeni H, 2009, INT C WIRELESS COMMU, P1
   Qian C., 2018, INTELL TECHNOL, V3, P18, DOI DOI 10.1049/trit.2018.0007
   Wang YQ, 2015, MATEC WEB CONF, V22, DOI 10.1051/matecconf/20152202015
   Younus ZS, 2015, ARAB J GEOSCI, V8, P6211, DOI 10.1007/s12517-014-1584-7
NR 14
TC 12
Z9 13
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24035
EP 24045
DI 10.1007/s11042-019-7209-0
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900013
DA 2024-07-18
ER

PT J
AU Qamar, S
   Jin, H
   Zheng, R
   Ahmad, P
AF Qamar, Saqib
   Jin, Hai
   Zheng, Ran
   Ahmad, Parvez
TI Multi stream 3D hyper-densely connected network for multi modality
   isointense infant brain MRI segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; 3D CNN; Infant brain segmentation; Multi modality MRI
ID AUTOMATIC SEGMENTATION; NEURAL-NETWORKS; IMAGES; ALGORITHM
AB Automatic accurate segmentation of medical images has significant role in computer-aided diagnosis and disease treatment. The segmentation of cerebrospinal fluid (CSF), gray matter (GM), and white matter (WM) tissues plays an important role in infant brain structure for studying early brain development. However, this task is very challenging due to low contrast between GM and WM in isointense phase (approximately 6-8 months of age). In this study, we develop a hyper-densely connected convolutional neural network (CNN) for segmentation of volumetric infant brain. The proposed model provides dense connection between layers to improve the performance of flow information in the network. It also allows the multiscale contextual information by concatenating the feature maps of early, intermediate, and later layers. This architecture employs MR-T1 and T2 as input, which are processed in two separate independent paths, and then their low, intermediate, and high layer features are fused for final segmentation. An important change relative to earlier densely connected networks is the application of direct layer connections from the same and different paths. In this scenario, each modality is processed in an independent path, and dense connections occur not only between layers within the same path, but also between layers in different paths. Adopting such dense connectivity leads to benefits of deep supervision and improved gradient flow. Furthermore, by combining the feature maps of early, intermediate, and late convolutional layers, our architecture injects multiscale information into the final segmentation. This suggested approach is examined in the MICCAI Grand Challenge iSEG and obtains significant advantages over existing approaches in terms of parameter efficiency and segmentation accuracy on 6-month infant brain MRI segmentation.
C1 [Qamar, Saqib; Jin, Hai; Zheng, Ran; Ahmad, Parvez] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.
   [Qamar, Saqib; Jin, Hai; Zheng, Ran; Ahmad, Parvez] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Wuhan 430074, Hubei, Peoples R China.
   [Qamar, Saqib; Jin, Hai; Zheng, Ran; Ahmad, Parvez] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Big Data Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Huazhong University of Science & Technology
RP Qamar, S (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.; Qamar, S (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Cluster & Grid Comp Lab, Wuhan 430074, Hubei, Peoples R China.; Qamar, S (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Big Data Technol & Syst Lab, Wuhan 430074, Hubei, Peoples R China.
EM sqbqamar@hust.edu.cn; hjin@hust.edu.cn; zhraner@hust.edu.cn;
   parvezamu@hust.edu.cn
RI AHMAD, PARVEZ/AEB-0771-2022; Qamar, Saqib/AAP-2938-2021
OI AHMAD, PARVEZ/0000-0003-1409-3175; Qamar, Saqib/0000-0002-5980-5976
FU National Key Research and Development Program of China [2018YFB1003500]
FX This research is supported by National Key Research and Development
   Program of China under grant 2018YFB1003500.
CR Anbeek P, 2008, PEDIATR RES, V63, P158, DOI 10.1203/PDR.0b013e31815ed071
   [Anonymous], 2017, 3D densely convolutional networks for volumetric segmentation
   [Anonymous], 2012, P MICCAI GRAND CHALL
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2019, IEEE T MED IMAGING
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, MICCAI NEOBRAINS12
   [Anonymous], 2016, ARXIV 1608 04117
   [Anonymous], P 14 INT C ART INT S
   Cardoso MJ, 2013, NEUROIMAGE, V65, P97, DOI 10.1016/j.neuroimage.2012.08.009
   Chen Hao, 2018, Neuroimage, V170, P446, DOI 10.1016/j.neuroimage.2017.04.041
   Chen H, 2015, I S BIOMED IMAGING, P764, DOI 10.1109/ISBI.2015.7163984
   Chen SQ, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171205001
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Criminisi A, 2014, IEEE Trans Med Imaging
   Dolz J, 2015, IRBM, V36, P200, DOI 10.1016/j.irbm.2015.06.001
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Dou Q, 2016, IEEE T MED IMAGING, V35, P1182, DOI 10.1109/TMI.2016.2528129
   Fechter T, 2017, MED PHYS, V44, P6341, DOI 10.1002/mp.12593
   Gui L, 2012, MED IMAGE ANAL, V16, P1565, DOI 10.1016/j.media.2012.07.006
   Havaei M, 2016, LECT NOTES COMPUT SC, V9605, P125, DOI 10.1007/978-3-319-50478-0_6
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kontschieder P, 2011, IEEE I CONF COMP VIS, P2190, DOI 10.1109/ICCV.2011.6126496
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lequan Yu, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P287, DOI 10.1007/978-3-319-66185-8_33
   Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Moeskops P, 2015, NEUROIMAGE, V118, P628, DOI 10.1016/j.neuroimage.2015.06.007
   Nie D, 2016, I S BIOMED IMAGING, P1342, DOI 10.1109/ISBI.2016.7493515
   Prasoon A, 2013, LECT NOTES COMPUT SC, V8150, P246, DOI 10.1007/978-3-642-40763-5_31
   Prastawa M, 2005, MED IMAGE ANAL, V9, P457, DOI 10.1016/j.media.2005.05.007
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2014, LECT NOTES COMPUT SC, V8673, P520, DOI 10.1007/978-3-319-10404-1_65
   Shi F, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018746
   Shi F, 2010, NEUROIMAGE, V51, P684, DOI 10.1016/j.neuroimage.2010.02.025
   Shi F, 2010, NEUROIMAGE, V49, P391, DOI 10.1016/j.neuroimage.2009.07.066
   Song Z, 2007, LECT NOTES COMPUT SC, V4791, P883
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang L, 2014, NEUROIMAGE, V84, P141, DOI 10.1016/j.neuroimage.2013.08.008
   Wang L, 2011, NEUROIMAGE, V58, P805, DOI 10.1016/j.neuroimage.2011.06.064
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Weisenfeld NI, 2006, I S BIOMED IMAGING, P766
   Weisenfeld NI, 2009, NEUROIMAGE, V47, P564, DOI 10.1016/j.neuroimage.2009.04.068
   Wu J., 2012, MICCAI GRAND CHALLEN, P36, DOI DOI 10.1007/S10142-012-0262-7
   Xue H, 2007, NEUROIMAGE, V38, P461, DOI 10.1016/j.neuroimage.2007.07.030
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Zhang WL, 2015, NEUROIMAGE, V108, P214, DOI 10.1016/j.neuroimage.2014.12.061
NR 60
TC 13
Z9 14
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25807
EP 25828
DI 10.1007/s11042-019-07829-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700026
DA 2024-07-18
ER

PT J
AU Raja, DRK
   Pushpa, S
AF Raja, D. R. Kumar
   Pushpa, S.
TI Diversifying personalized mobile multimedia application recommendations
   through the Latent Dirichlet Allocation and clustering optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Mobile multimedia application; LDA; Popularity; PCA;
   Diversity; Application category
ID SYSTEMS
AB The rapid development of mobile multimedia applications explosively increased the availability of the number of applications in the apps market. Among the crowd of mobile multimedia applications with diverse functions, identifying the appropriate application is a significant challenge. Hence, it is essential for the app stores to recommend the desired applications to the users in the surge of applications. Several research works lack to consider the interactions among the contextual information of applications such as application category and features in different aspects instead of user preferences. Thus, it is of significance to developing a practical approach that provides high-quality application recommendations for users according to personal preferences. This paper presents the DIversifying Personalized Mobile Multimedia Application Recommendation (DIPMMAR) by fusing the user ratings, review texts, application description, and application popularity. Initially, the DIPMMAR approach analyzes the user reviews and application descriptions by applying the Latent Dirichlet Allocation (LDA) based topic model. It employs the Principle Component Analysis (PCA) principal components are the continuous solutions to the discrete cluster membership indicators for K-means clustering among all the extracted features of the applications and retains the optimal latent features alone. Further, the DIPMMAR approach computes the user-specific local popularity score on applications and exploits the application-specific global popularity score to generate the top-N personalized recommendation. Moreover, by exploring the mobile application categories and sub-categories, the DIPMMAR approach ensures the relevance and diversified applications in the recommendation list. The experiments on the real-world mobile app store dataset demonstrate the accuracy of the personalized recommendation.
C1 [Raja, D. R. Kumar; Pushpa, S.] St Peters Inst Higher Educ & Res, Dept CSE, Chennai, Tamil Nadu, India.
   [Raja, D. R. Kumar] Sree Vidyanikethan Engn Coll Autonomous, Dept CSSE, Tirupati, AP, India.
C3 St. Peter's Institute of Higher Education & Research
RP Raja, DRK (corresponding author), St Peters Inst Higher Educ & Res, Dept CSE, Chennai, Tamil Nadu, India.; Raja, DRK (corresponding author), Sree Vidyanikethan Engn Coll Autonomous, Dept CSSE, Tirupati, AP, India.
EM kumarraja.phd.cse@stpetersuniversity.org; cse@stpetersuniversity.org
RI s, pushpa/S-9817-2019; Raja, D R Kumar/R-4458-2018
OI Raja, D R Kumar/0000-0001-7593-4519; sangaralingam,
   pushpa/0000-0002-7166-7836
CR [Anonymous], 2010, ARXIV10065278
   Bao Y, 2014, AAAI CONF ARTIF INTE, P2
   Bhandari Upasna, 2013, Information Retrieval Technology. 9th Asia Information Retrieval Societies Conference, AIRS 2013. Proceedings: LNCS 8281, P440, DOI 10.1007/978-3-642-45068-6_38
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Bohmer M., 2013, Proceedings of the 2013 international conference on Intelligent user interfaces, P267
   Chen N, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P305, DOI 10.1145/2684822.2685305
   Davidsson C., 2010, Mobile Application Recommender System
   He XN, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P233, DOI 10.1145/2600428.2609558
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Karatzoglou Alexandros., 2012, Proceedings of ACM International Con- ference on Information and Knowledge Management, P2527, DOI [10.1145/2396761.2398683, DOI 10.1145/2396761.2398683]
   Kumar Raja D. R., 2017, Future Computing and Informatics Journal, V2, P118, DOI 10.1016/j.fcij.2017.09.002
   Liao ZX, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P609, DOI 10.1145/2505515.2505529
   Ling G, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P105, DOI 10.1145/2645710.2645728
   Liu Q, 2013, INT J INF TECH DECIS, V12, P139, DOI 10.1142/S0219622013500077
   Lu C.-T., 2016, Item Recommendation for Emerging Online Businesses, P3797
   Matthias B, 2010, 2 WORKSH CONT AW REC, V5
   McAuley Julian, 2013, RECSYS
   Raja DRK, 2018, INT J COMMUN SYST
   Ran WX, 2015, INTERNATIONAL CONFERENCE ON SIMULATION, MODELLING AND MATHEMATICAL STATISTICS (SMMS 2015), P315
   Villegas NM, 2018, KNOWL-BASED SYST, V140, P173, DOI 10.1016/j.knosys.2017.11.003
   Woo-Hyun Rho, 2013, Journal of KIISE: Software and Applications, V40, P809
   Xia X, 2014, MOBILE UBIQUITOUS IN, P405
   Xu XY, 2018, J ASSOC INF SCI TECH, V69, P242, DOI 10.1002/asi.23932
   Yan Bo., 2011, P 9 INT C MOBILE SYS, P113
   Yan X., 2013, P 22 INT C WORLD WID, P1445, DOI DOI 10.1145/2488388.2488514
   Yankov D, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P857
   Yin HZ, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1543, DOI 10.1145/2588555.2593685
   Yin Peifeng., 2013, Proceedings of ACM Interna- tional Conference on Web Search and Data Mining, P395
   Zhu HS, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532515
   Zhu HS, 2015, IEEE T CYBERNETICS, V45, P1303, DOI 10.1109/TCYB.2014.2349954
   Zhu M, 2014, ASIA PAC CONF ANTEN, P951, DOI 10.1109/APCAP.2014.6992660
NR 31
TC 4
Z9 5
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24047
EP 24066
DI 10.1007/s11042-019-7190-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900014
DA 2024-07-18
ER

PT J
AU Sohrabi, MK
   Hemmatian, F
AF Sohrabi, Mohammad Karim
   Hemmatian, Fatemeh
TI An efficient preprocessing method for supervised sentiment analysis by
   converting sentences to numerical vectors: a twitter case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Opinion mining; Python; Sentiment analysis; word2vec; Supervised
   learning
ID MATERIALIZED VIEW SELECTION; INFORMATION FUSION; MINING TECHNIQUES;
   CLUSTERING METHOD; CLASSIFICATION; MODEL; ENSEMBLE; ONTOLOGY; RULE;
   EXTRACTION
AB Along with the significant growth of social media, individuals and companies are increasingly receiving public opinions which direct their decisions. Opinion mining, which is considered as a sub-field of natural language processing, information retrieval, and text mining, is the process of understanding the users' views from their comment, which have been represented as unstructured texts. Emergence of online social media has led to the production of a huge amount of user comments on websites, and thus, has raised opinion mining as a very useful and challenging problem. In this paper, an efficient preprocessing method for opinion mining is presented and will be used for analyzing users' comments on Twitter social network. For this purpose, different text preprocessing techniques have been used on the dataset to achieve an acceptable standard text. Word2vec method which is a fast and accurate method have been also exploited to convert the words' arrays to numerical vectors. Machine learning methods, with supervised learning approach, have been applied on the obtained data after this fast and accurate preprocessing phase. Python and RapidMiner have been used to implement different opinion mining methods and the results of these implementations have been compared and evaluated. The experimental results show that the combined use of the preprocessing method of this paper and support vector machine and artificial neural network have the highest accuracy compared to other methods.
C1 [Sohrabi, Mohammad Karim; Hemmatian, Fatemeh] Islamic Azad Univ, Semnan Branch, Dept Comp Engn, Semnan, Iran.
C3 Islamic Azad University
RP Sohrabi, MK (corresponding author), Islamic Azad Univ, Semnan Branch, Dept Comp Engn, Semnan, Iran.
EM Amir_sohraby@aut.ac.ir; Fatemehammatian@gmail.com
RI Sohrabi, Mohammad Karim/AAD-8618-2019
OI Sohrabi, Mohammad Karim/0000-0001-8066-0356
CR Al-Amin M, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P186, DOI 10.1109/ECACE.2017.7912903
   Alarifi A, 2020, J SUPERCOMPUT, V76, P4414, DOI 10.1007/s11227-018-2398-2
   Alfaro C, 2016, ANN OPER RES, V236, P197, DOI 10.1007/s10479-013-1449-6
   Ali F, 2017, TRANSPORT RES C-EMER, V77, P33, DOI 10.1016/j.trc.2017.01.014
   Ali F, 2016, APPL SOFT COMPUT, V47, P235, DOI 10.1016/j.asoc.2016.06.003
   Ali F, 2015, APPL INTELL, V42, P481, DOI 10.1007/s10489-014-0609-y
   Anjaria M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0181-9
   [Anonymous], 2007, USENIX ANN TECH C
   [Anonymous], P 6 INT C GRAPH IM P
   [Anonymous], SPRINGER SCI BUS MED
   [Anonymous], 2018, IEEE Trans. Multimed.
   [Anonymous], ARXIV150305123
   [Anonymous], 1998, P 10 EUROPEAN C MACH
   [Anonymous], 2013, RapidMiner: Data Mining Use Cases and Business Analytics Applications
   [Anonymous], 2012, Mining Text Data, DOI [10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-4_13, DOI 10.1007/978-1-4614-3223-413]
   [Anonymous], 2003, P 12 INT C WORLD WID, DOI DOI 10.1145/775152.775226
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Appel O, 2016, KNOWL-BASED SYST, V108, P110, DOI 10.1016/j.knosys.2016.05.040
   Arab M, 2017, TURK J ELECTR ENG CO, V25, P4757, DOI 10.3906/elk-1612-279
   Azgomi H, 2018, ENG APPL ARTIF INTEL, V71, P125, DOI 10.1016/j.engappai.2018.02.018
   Baecchi C, 2016, MULTIMED TOOLS APPL, V75, P2507, DOI 10.1007/s11042-015-2646-x
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bai X, 2014, IEEE INT CONGR BIG, P358, DOI 10.1109/BigData.Congress.2014.59
   Balazs JA, 2016, INFORM FUSION, V27, P95, DOI 10.1016/j.inffus.2015.06.002
   Basti E, 2015, DECIS SUPPORT SYST, V73, P15, DOI 10.1016/j.dss.2015.02.011
   Bhatt CA, 2011, MULTIMED TOOLS APPL, V51, P35, DOI 10.1007/s11042-010-0645-5
   Bui TH, 2017, MULTIMED TOOLS APPL, V76, P23435, DOI 10.1007/s11042-016-4114-7
   Cardoso M, 2016, INT J UNCERTAIN FUZZ, V24, P93, DOI 10.1142/S0218488516400122
   Charalampakis B, 2016, ENG APPL ARTIF INTEL, V51, P50, DOI 10.1016/j.engappai.2016.01.007
   Chen FH, 2018, IEEE T MULTIMEDIA, V20, P997, DOI 10.1109/TMM.2017.2757769
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen LS, 2011, J INFORMETR, V5, P313, DOI 10.1016/j.joi.2011.01.003
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P889, DOI 10.1007/s11042-011-0885-z
   Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003
   Doudpota SM, 2014, MULTIMED TOOLS APPL, V69, P359, DOI 10.1007/s11042-012-1021-4
   Dragoni M, 2018, IEEE INTELL SYST, V33, P77, DOI 10.1109/MIS.2018.033001419
   Fernández-Gavilanes M, 2016, EXPERT SYST APPL, V58, P57, DOI 10.1016/j.eswa.2016.03.031
   Fu XH, 2018, IEEE ACCESS, V6, P71884, DOI 10.1109/ACCESS.2018.2878425
   Fu XH, 2017, NEUROCOMPUTING, V241, P18, DOI 10.1016/j.neucom.2017.01.079
   Tran HN, 2018, MEMET COMPUT, V10, P3, DOI 10.1007/s12293-017-0228-3
   Harakawa R, 2018, MULTIMED TOOLS APPL, V77, P18741, DOI 10.1007/s11042-018-5876-x
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Fusilier DH, 2015, INFORM PROCESS MANAG, V51, P433, DOI 10.1016/j.ipm.2014.11.001
   Hosseini AS, 2017, ENG APPL ARTIF INTEL, V65, P361, DOI 10.1016/j.engappai.2017.08.006
   Huo WG, 2016, INT J UNCERTAIN FUZZ, V24, P367, DOI 10.1142/S0218488516500185
   Ji RR, 2019, IEEE T MULTIMEDIA, V21, P1062, DOI 10.1109/TMM.2018.2867718
   Joshi Mahesh., 2009, P 47 ACL 4 IJCNLP C, P313
   Kavakiotis I, 2017, COMPUT BIOL MED, V90, P146, DOI 10.1016/j.compbiomed.2017.09.020
   Keshavarz H, 2017, KNOWL-BASED SYST, V122, P1, DOI 10.1016/j.knosys.2017.01.028
   Khan FH, 2014, DECIS SUPPORT SYST, V57, P245, DOI 10.1016/j.dss.2013.09.004
   Kisioglu P, 2011, EXPERT SYST APPL, V38, P7151, DOI 10.1016/j.eswa.2010.12.045
   Kranjc J, 2015, INFORM PROCESS MANAG, V51, P187, DOI 10.1016/j.ipm.2014.04.001
   Kumar RS, 2017, INT J UNCERTAIN FUZZ, V25, P385, DOI 10.1142/S0218488517500167
   Lee G, 2018, KNOWL-BASED SYST, V152, P70, DOI 10.1016/j.knosys.2018.04.006
   Li G, 2012, J INF SCI, V38, P127, DOI 10.1177/0165551511432670
   Li JD, 2019, MULTIMED TOOLS APPL, V78, P5989, DOI 10.1007/s11042-018-6405-7
   Li WF, 2018, IEEE T KNOWL DATA EN, V30, P1192, DOI 10.1109/TKDE.2017.2786727
   Li Y, 2015, MULTIMED TOOLS APPL, V74, P10177, DOI 10.1007/s11042-014-2158-0
   Li ZH, 2019, MULTIMED TOOLS APPL, V78, P6939, DOI 10.1007/s11042-018-6445-z
   Lin F, 2016, MULTIMED TOOLS APPL, V75, P14203, DOI 10.1007/s11042-016-3363-9
   Liu B., 2012, SYNTHESIS LECT HUMAN, V5, P1, DOI [DOI 10.2200/S00416ED1V01Y201204HLT016, 10.2200/s00416ed1v01y201204hlt016]
   Liu J., 2007, P 2007 JOINT C EMP M, P334
   Liu W, 2019, MULTIMED TOOLS APPL, V78, P747, DOI 10.1007/s11042-017-5553-5
   López M, 2019, INFORM SCIENCES, V480, P273, DOI 10.1016/j.ins.2018.12.038
   Ma X, 2019, FUTURE GENER COMP SY, V93, P304, DOI 10.1016/j.future.2018.10.041
   Majumder N, 2018, KNOWL-BASED SYST, V161, P124, DOI 10.1016/j.knosys.2018.07.041
   Manaman HS, 2016, COMPUT HUM BEHAV, V54, P94, DOI 10.1016/j.chb.2015.07.061
   Minh DL, 2018, IEEE ACCESS, V6, P55392, DOI 10.1109/ACCESS.2018.2868970
   Moraes R, 2013, EXPERT SYST APPL, V40, P621, DOI 10.1016/j.eswa.2012.07.059
   Nakagawa T., 2010, HUMAN LANGUAGE TECHN, P786
   Pandey AC, 2017, INFORM PROCESS MANAG, V53, P764, DOI 10.1016/j.ipm.2017.02.004
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Peñalver-Martinez I, 2014, EXPERT SYST APPL, V41, P5995, DOI 10.1016/j.eswa.2014.03.022
   Lucas JP, 2012, INT J UNCERTAIN FUZZ, V20, P579, DOI 10.1142/S0218488512500274
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Poria S, 2013, IEEE INTELL SYST, V28, P31, DOI 10.1109/MIS.2013.4
   Pu XJ, 2019, MULTIMEDIA SYST, V25, P21, DOI 10.1007/s00530-017-0550-0
   Ramos J, 2018, MULTIMED TOOLS APPL, V77, P17755, DOI 10.1007/s11042-017-5382-6
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Ren FJ, 2013, COMPUT SPEECH LANG, V27, P943, DOI 10.1016/j.csl.2012.07.012
   Rong WG, 2015, FRONT COMPUT SCI-CHI, V9, P171, DOI 10.1007/s11704-014-4085-7
   Rosas VP, 2013, IEEE INTELL SYST, V28, P38, DOI 10.1109/MIS.2013.9
   Saleh MR, 2011, EXPERT SYST APPL, V38, P14799, DOI 10.1016/j.eswa.2011.05.070
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shang L, 2016, SOFT COMPUT, V20, P3821, DOI 10.1007/s00500-016-2093-2
   Shuang K, 2019, NEUROCOMPUTING, V334, P25, DOI 10.1016/j.neucom.2018.11.084
   Sohrabi MK, 2016, J ADV COMPUTER RES, V7, P23
   Sohrabi MK, 2020, ARCH COMPUT METHOD E, V27, P59, DOI 10.1007/s11831-018-9300-5
   Sohrabi MK, 2019, KNOWL-BASED SYST, V163, P558, DOI 10.1016/j.knosys.2018.09.012
   Sohrabi MK, 2018, ENTERP INF SYST-UK, V12, P674, DOI 10.1080/17517575.2017.1405286
   Sohrabi MK, 2018, J CHIN INST ENG, V41, P229, DOI 10.1080/02533839.2018.1454853
   Sohrabi MK, 2018, ARAB J SCI ENG, V43, P949, DOI 10.1007/s13369-017-2855-x
   Sohrabi MK, 2017, TURK J ELECTR ENG CO, V25, P3175, DOI 10.3906/elk-1608-112
   Sohrabi MK, 2017, COMPUT BIOL CHEM, V69, P126, DOI 10.1016/j.compbiolchem.2017.06.002
   Sohrabi MK, 2017, SCI COMPUT PROGRAM, V145, P1, DOI 10.1016/j.scico.2017.04.006
   Sohrabi MK, 2017, COMPUT HUM BEHAV, V68, P244, DOI 10.1016/j.chb.2016.11.036
   Sohrabi MK, 2016, 2016 4TH INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P186, DOI 10.1109/ISCBI.2016.7743281
   Sohrabi MK, 2016, COMPUT HUM BEHAV, V60, P534, DOI 10.1016/j.chb.2016.02.092
   Sohrabi MK, 2016, J COMPUT, V11, P140, DOI 10.17706/jcp.11.2.140-148
   Sohrabi MK, 2013, KNOWL-BASED SYST, V37, P462, DOI 10.1016/j.knosys.2012.09.005
   Sohrabi MK, 2012, KNOWL-BASED SYST, V33, P41, DOI 10.1016/j.knosys.2012.03.003
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Su Z, 2014, IEEE INT C MULTISENS, P1
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tang DY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1340
   Tazaree A, 2014, MULTIMED TOOLS APPL, V69, P921, DOI 10.1007/s11042-012-1123-z
   Tripathy A, 2017, KNOWL INF SYST, V53, P805, DOI 10.1007/s10115-017-1055-z
   Tubishat M, 2019, APPL INTELL, V49, P1688, DOI 10.1007/s10489-018-1334-8
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Vilares D, 2017, KNOWL-BASED SYST, V118, P45, DOI 10.1016/j.knosys.2016.11.014
   Vinodhini G, 2016, J KING SAUD UNIV-COM, V28, P2, DOI 10.1016/j.jksuci.2014.03.024
   Wang J, 2018, NEUROCOMPUTING, V322, P93, DOI 10.1016/j.neucom.2018.09.049
   Wu CH, 2019, KNOWL-BASED SYST, V165, P30, DOI 10.1016/j.knosys.2018.11.018
   Wu CH, 2018, KNOWL-BASED SYST, V148, P66, DOI 10.1016/j.knosys.2018.01.019
   Xia R, 2016, INFORM PROCESS MANAG, V52, P36, DOI 10.1016/j.ipm.2015.04.003
   Xuan JY, 2015, IEEE T CYBERNETICS, V45, P2792, DOI 10.1109/TCYB.2014.2386282
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yang SY, 2017, NEUROCOMPUTING, V264, P29, DOI 10.1016/j.neucom.2016.10.103
   Yang W, 2002, COMPUT LANG SYST STR, V28, P273, DOI 10.1016/S0096-0551(02)00014-0
   Yun U, 2016, EXPERT SYST APPL, V54, P304, DOI 10.1016/j.eswa.2016.01.049
   Yun U, 2014, INT J UNCERTAIN FUZZ, V22, P879, DOI 10.1142/S0218488514500470
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zhang DW, 2015, EXPERT SYST APPL, V42, P1857, DOI 10.1016/j.eswa.2014.09.011
   Zhang YZ, 2018, THEOR COMPUT SCI, V752, P21, DOI 10.1016/j.tcs.2018.04.029
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
   Zhao W, 2018, IEEE T KNOWL DATA EN, V30, P185, DOI 10.1109/TKDE.2017.2756658
   Zhu D, 2018, DECIS SUPPORT SYST, V107, P116, DOI 10.1016/j.dss.2018.01.011
   Zhu DJ, 2016, MULTIMED TOOLS APPL, V75, P17647, DOI 10.1007/s11042-016-3466-3
   Zimmermann M, 2016, INFORM SCIENCES, V329, P876, DOI 10.1016/j.ins.2015.06.050
   Zuo Y, 2018, IEEE T KNOWL DATA EN, V30, P249, DOI 10.1109/TKDE.2017.2764084
NR 137
TC 19
Z9 19
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24863
EP 24882
DI 10.1007/s11042-019-7586-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900054
DA 2024-07-18
ER

PT J
AU Tripathi, A
   Gupta, A
   Chaudhury, S
   Singh, A
AF Tripathi, Anurag
   Gupta, Abhinav
   Chaudhury, Santanu
   Singh, Arun
TI Image super resolution using distributed locality sensitive hashing for
   manifold learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super resolution; Locality sensitive hashing; Manifold learning;
   Locally liner embedding
ID SUPERRESOLUTION
AB In this paper we propose a distributed locality sensitive hashing based framework for image super resolution exploiting computational and storage efficiency of cloud. Now days huge multimedia data is available on the cloud which can be utilized using store anywhere and excess anywhere model. It may be noted that super resolution is required for consumer electronics display devices due to various reasons. The propose framework exploits the image correlation for image super resolution using locality sensitive hashing (LSH) for manifold learning. In our work we have exploited the benefits of manifold learning for image super resolution, which in-turn is a highly time complex operation. The time complexity is involved due to finding the approximate nearest neighbors from trillion of image patches for locally linear embedding (LLE) operation. In our approach it is mitigated by using a distributed framework which internally uses hash tables for mapping of patches in the target image from a database of internet picture collection. The proposed framework for super resolution provides promising results in comparison to existing approaches.
C1 [Tripathi, Anurag; Chaudhury, Santanu; Singh, Arun] Indian Inst Technol, Dept Elect Engn, Delhi, India.
   [Gupta, Abhinav] Jaypee Inst Informat Technol, ECE Dept, Noida, India.
   [Chaudhury, Santanu] Indian Inst Technol, Jodhpur, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; Jaypee Institute of Information Technology
   (JIIT); Indian Institute of Technology System (IIT System); Indian
   Institute of Technology (IIT) - Jodhpur
RP Gupta, A (corresponding author), Jaypee Inst Informat Technol, ECE Dept, Noida, India.
EM anurag.iitg@gmail.com; abhinav.gupta@jiit.ac.in;
   santanuc@ee.iitd.ernet.in; mailtoarunkus@gmail.com
RI SINGH, ASHUTOSH KUMAR/KHY-2988-2024; Singh, Ashwani/GQP-2566-2022;
   Singh, Arun/C-7956-2012
OI Singh, Arun/0000-0002-2032-2694; GUPTA, ABHINAV/0000-0002-1939-5407
CR [Anonymous], 2018, IEEE T PATTERN ANAL
   Belkin M, 2002, P ADV NEUR INF SYST, V14
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cruz C, 2018, IEEE T IMAGE PROCESS, V27, P1376, DOI 10.1109/TIP.2017.2779265
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   He S., 2018, ARXIV180711643
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lu XQ, 2013, IEEE T CIRC SYST VID, V23, P2022, DOI 10.1109/TCSVT.2013.2244798
   Romano Y, 2017, IEEE T COMPUT IMAG, V3, P110, DOI 10.1109/TCI.2016.2629284
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Slaney M, 2008, IEEE SIGNAL PROC MAG, V25, P128, DOI 10.1109/MSP.2007.914237
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SY, 2014, IEEE T IMAGE PROCESS, V23, P2793, DOI 10.1109/TIP.2014.2319742
   Zeng K, 2017, IEEE T CYBERNETICS, V47, P27, DOI 10.1109/TCYB.2015.2501373
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
NR 20
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25673
EP 25684
DI 10.1007/s11042-019-07799-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700020
DA 2024-07-18
ER

PT J
AU Xue, ML
   Shivakumara, P
   Zhang, C
   Lu, T
   Pal, U
AF Xue, Minglong
   Shivakumara, Palaiahnakote
   Zhang, Chao
   Lu, Tong
   Pal, Umapada
TI Curved text detection in blurred/non-blurred video/scene images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient magnitude; Gradient direction; Degree of blurriness; K-means
   clustering; Motion blurred images
AB Text detection in video/images is challenging due to the presence of multiple blur caused by defocus and motion. In this paper, we present a new method for detecting texts in blurred/non-blurred images. Unlike the existing methods that use deblurring or classifiers, the proposed method estimates degree of blur in images based on contrast variations in neighbor pixels and a low pass filter, which results in candidate pixels for deblurring. We consider gradient values of each pixel as the weight for the degree of blur. The proposed method then performs K-means clustering on weighted values of candidate pixels to get text candidates irrespective of blur types. Next, Bhattacharyya distance is used to extract symmetry property of texts to remove false text candidates, which provides text components. Further, the proposed method fixes bounding box for each text component based on the nearest neighbor criteria and direction of the text component. Experimental results on defocus, motion, non-blurred images and standard datasets of curved text show that the proposed method outperforms the existing methods.
C1 [Xue, Minglong; Zhang, Chao; Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recog Unit, Kolkata, India.
C3 Nanjing University; Universiti Malaya; Indian Statistical Institute;
   Indian Statistical Institute Kolkata
RP Lu, T (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM xueml@smail.nju.edu.cn; shiva@um.edu.my; 1291602059@qq.com;
   lutong@nju.edu.cn; umapada@isical.ac.in
RI Pal, Umapada/AAC-4930-2022; Palaiahnakote, Shivakumara/ITU-6488-2023;
   Palaiahnakote, Shivakumara/B-6261-2013; Liu, Donghua/KEJ-1974-2024
OI Liu, Donghua/0000-0002-5830-9540
FU Natural Science Foundation of China [61672273, 61272218]; Science
   Foundation for Distinguished Young Scholars of Jiangsu [BK20160021];
   University of Malaya [UM. 0000520/HRU.BK (BKS003-2018)]
FX The work described in this paper was supported by the Natural Science
   Foundation of China under Grant No. 61672273 and No. 61272218, and the
   Science Foundation for Distinguished Young Scholars of Jiangsu under
   Grant No. BK20160021. This work is also partly supported by University
   of Malaya under Grant No: UM. 0000520/HRU.BK (BKS003-2018).
CR Abdullah Y, 2017, IEEE ENER CONV, P2645, DOI 10.1109/ECCE.2017.8096499
   [Anonymous], 2019, ADV INTELLIGENT SYST
   [Anonymous], 2017, P AAAI
   Chun MG, 2014, PATTERN RECOGN LETT, V38, P20, DOI 10.1016/j.patrec.2013.10.023
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   Khare V, 2017, MULTIMED TOOLS APPL, V76, P16625, DOI 10.1007/s11042-016-3941-x
   Khare V, 2016, INT C PATT RECOG, P4023, DOI 10.1109/ICPR.2016.7900263
   Khare V, 2016, PATTERN RECOGN, V54, P128, DOI 10.1016/j.patcog.2016.01.008
   Lee H, 2014, IEEE IMAGE PROC, P4427, DOI 10.1109/ICIP.2014.7025898
   Liu JH, 2016, SIGNAL PROCESS, V124, P259, DOI 10.1016/j.sigpro.2015.06.025
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   S Cao, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI [10. 1109/TIP. 2015. 2463223 1408. 94067, DOI 10.1109/TIP.2015.2463223]
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Nwe TL, 2013, INT CONF ACOUST SPEE, P7512, DOI 10.1109/ICASSP.2013.6639123
   Veit A, 2017, ARXIV160107140V2
   Wang XB, 2017, MULTIMED TOOLS APPL, V76, P26201, DOI 10.1007/s11042-016-4099-2
   Wei YW, 2017, SIGNAL PROCESS-IMAGE, V50, P1, DOI 10.1016/j.image.2016.10.003
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Zhang XN, 2018, NEUROCOMPUTING, V307, P61, DOI 10.1016/j.neucom.2018.03.070
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhao F, 2018, MULTIMED TOOLS APPL, P1
NR 25
TC 6
Z9 6
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25629
EP 25653
DI 10.1007/s11042-019-7721-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700018
DA 2024-07-18
ER

PT J
AU Elsharkawy, ZF
   Abdelwahab, SAS
   Abd El-Samie, FE
   Dessouky, M
   Elaraby, S
AF Elsharkawy, Zeinab F.
   Abdelwahab, Safey A. S.
   Abd El-Samie, Fathi E.
   Dessouky, Moawad
   Elaraby, Sayed
TI New and efficient blind detection algorithm for digital image forgery
   using homomorphic image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Forgery detection; Homomorphic image processing; SVM
   and NN classifiers; Color coordinate systems; JPEG compression
ID WAVELET; CURVE; DCT
AB Digital image forgery detection is an important task in digital life as the image may be easily manipulated. This paper presents a novel blind tampering detection algorithm for images acquired from digital cameras and scanners. The algorithm is based on applying homomorphic image processing on each suspicious image to separate illumination from reflectance components. In natural images, it is known that the illumination component is approximately constant, while changes can be detected in tampered ones. Support Vector Machine (SVM) and Neural Network (NN) classifiers are used for classification of tampered images based on the illumination component, and their results are compared to obtain the best classifier performance. The Receiver Operating Characteristic (ROC) curve is used to depict the classifier performance. Three different color coordinate systems are tested with the proposed algorithm, and their results are compared to obtain the highest accuracy level. Joint Photographic Experts Group (JPEG) compressed images with different Quality Factors (QFs) are also tested with the proposed algorithm, and the performance of the proposed algorithm in the presence of noise is studied. The performance of the SVM classifier is better than that of the NN classifier as it is more accurate and faster. A 96.93% detection accuracy has been obtained regardless of the acquisition device.
C1 [Elsharkawy, Zeinab F.; Abdelwahab, Safey A. S.; Elaraby, Sayed] Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
   [Abd El-Samie, Fathi E.; Dessouky, Moawad] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Egyptian Knowledge Bank (EKB); Menofia University
RP Elsharkawy, ZF (corresponding author), Atom Energy Author, Nucl Res Ctr, Engn Dept, Cairo, Egypt.
EM zeinab_elsharkawy@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Elsharkawy, Zeinab/0000-0002-6167-8435
CR AL-AMRI S S., 2010, International Journal of Computer Science Issues, (IIJCS), vol, V7, issue, P32
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Alherbawi N, 2018, MULTIMED TOOLS APPL, V77, P12805, DOI 10.1007/s11042-017-4915-3
   [Anonymous], 2014, IOSR J COMP ENG, DOI DOI 10.9790/0661-16123135
   [Anonymous], 2004, TECHNICAL REPORT
   [Anonymous], 2014, INT C MACH LEARN
   [Anonymous], 2013, THESIS FUDAN U
   Ashiba H. I., 2008, Progress In Electromagnetics Research C, V1, P123, DOI 10.2528/PIERC08012301
   Bhartiya G, 2017, MULTIMED TOOLS APPL, V76, P20799, DOI 10.1007/s11042-016-3964-3
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Birajdar GK, 2018, MULTIMED TOOLS APPL, V77, P14153, DOI 10.1007/s11042-017-5021-2
   Cheng Y, 2011, INT C MULT SIGN PROC, P316
   Chien CL, 2011, INT J INNOV COMPUT I, V7, P6691
   Choi C, 2012, LECT NOTES ELECT ENG, V114, P687, DOI [10.1007/978-94-007-2792-2_67, DOI 10.1007/978-94-007-2792-2_67]
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Dixit Priyanka, 2013, INT J INTERDISCIPLIN, V1, P32
   Elsharkawy Z, 2013, INT J COMPUT APPL, V83, P40
   Elsharkawy Z. F, 2013, DIGIT IMAGE PROCESS, V5, P397
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fang Y, 2009, IEEE INT WORKSH MULT
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Gupta B, 2014, IJARCSSE, V4, P808
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Hilal A, 2018, FORENSIC SCI INT, V287, P25, DOI 10.1016/j.forsciint.2018.03.024
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Khanna N, 2008, SPIE SECURITY FORENS
   Kumar R, 2011, INDIAN PEDIATR, V48, P277, DOI 10.1007/s13312-011-0055-4
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Lin GS, 2011, IEEE T CIRC SYST VID, V21, P421, DOI 10.1109/TCSVT.2011.2125370
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Liu K., 2014, P COLING 2014 25 INT, P2335
   Mohsen Saleh SamiAbdulla., 2012, Proceedings of the International Conference on Information and Knowledge Management, P74
   Pipariya T., 2014, INT J ADV RES COMPUT, V3, P7453
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pradeepthi T., 2011, INT J VLSI DESIGN CO, V2, P99, DOI DOI 10.5121/vlsic.2011.2308
   Pradhan A., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P82, DOI 10.1007/978-3-662-47926-1_26
   Singh S.K., 2003, TAMKANG J SCI ENG, V6, P227
   Sridhar S., 2014, I J IMAGE GRAPHICS S, V2, P54
   Srinivas V., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P109
   Sun P, 2018, FORENSIC SCI INT, V289, P1, DOI 10.1016/j.forsciint.2018.04.049
   Sundermeyer M, 2013, INT CONF ACOUST SPEE, P8430, DOI 10.1109/ICASSP.2013.6639310
   Weimo Liu, 2012, Database Systems for Advanced Applications. Proceedings 17th International Conference, DASFAA 2012, P126, DOI 10.1007/978-3-642-29035-0_9
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zheng JB, 2009, LECT NOTES COMPUT SC, V5450, P152, DOI 10.1007/978-3-642-04438-0_13
   Zhulong L, 2011, INT C INTELLIGENT CO, P663
NR 49
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21585
EP 21611
DI 10.1007/s11042-019-7206-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400047
DA 2024-07-18
ER

PT J
AU Moon, SK
   Raut, RD
AF Moon, Sunil K.
   Raut, Rajshree D.
TI Hardware-based application of data security system using general
   modified secured diamond encoding embedding approach for enhancing
   imperceptibility and authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conceal capacity and security; GMSDE; Audio-crypto video steganography;
   Attacks; Reversible forensic detection
ID STEGANOGRAPHY
AB As today's world are switching to the digital media through the Internet and multimedia tools like Facebook, YouTube, Twitter and WhatsApp which consists of a number of videos, hence it always better to take urgent problems of such digitally transmitted video in terms of information security. The current video steganography approach is not so effective for imperceptibility, robustness, security of hidden secret data, embedding capacity and very good visual recovery of a secret as well as original data. Hence, to maintain the balance between these issues is another big challenge. This work employs a novel and efficient Field Programmable Gate Array (FPGA) implementation of audio, video crypto steganography using General Modified Secured Diamond Encoding (GMSDE) scheme. The new proposed scheme is based on Diamond Encoding (DE), Exploiting Modification Direction (EMD) and Adaptive Pixel Pairing Matching (APPM) algorithms called as General Modified Secured Diamond Encoding (GMSDE). The DE method is always used for k>1 which produces distortion, less embedding capacity and security of hidden data. The GMSDE scheme changed the Diamond Characteristic Value (DCV) to conceal more than one secret bit vertically and horizontally to create a modified diamond shape of secret data which is equal to log(2)(2x(2)+6x+5)- ary and produces the conceal capacity of 1.16 to 4.82 bpp for the values of x=0 to 25 where x is the embedding parameter. Experimental results confirm that the conceal capacity measured by bit per pixel (bpp), security of hidden secret data, very good visual recovery of both original and secret data, Cross-Correlation (CC) and Peak Signal to Noise Ratio (PSNR) values are better than existing approaches. Further through many attacks on stego video during transmission using forensic detection approach, the imperceptibility, security of hidden data and robustness is increased for secure communication.
C1 [Moon, Sunil K.] Pune Inst Comp Technol PICT Pune, Dept Elect & Telecommun, Pune, Maharashtra, India.
   [Raut, Rajshree D.] Goverment Coll Engn, Dept Elect & Commun, Nagpur, Maharashtra, India.
RP Moon, SK (corresponding author), Pune Inst Comp Technol PICT Pune, Dept Elect & Telecommun, Pune, Maharashtra, India.
EM skmoon@pict.edu; raut.rajshree@gmail.com
RI Moon, Sunil/HHN-2680-2022
OI moon, sunil/0000-0002-8828-6300
CR Abed S, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S021812661950083X
   [Anonymous], ELSEVIER SCI REV J
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], 2015, UBIQUITOUS INT J INF
   [Anonymous], 2017, INT J COMPUTER SCI I
   [Anonymous], ELSEVIER J SIGNAL PR
   [Anonymous], NOVEL IMAGE DATA HID
   [Anonymous], IEEE 2 INT C EL COMM
   [Anonymous], J INFORM PROCESSING
   [Anonymous], IEEE ONL INT C GREEN
   Arab F, 2016, SPRINGER J MULTIMEDI, DOI [10.1007/s11042-015-2800-5, DOI 10.1007/S11042-015-2800-5]
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   Das S, 2018, ADV INTELL SYST, V563, P3, DOI 10.1007/978-981-10-6872-0_1
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Elshazly E. A., 2016, INT J COMPUTER APPL, V145, P43, DOI DOI 10.5120/IJCA2016910796
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Ho LH, 2012, OPTO-ELECTRON REV, V20, P367, DOI 10.2478/s11772-012-0046-6
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Musto Ronald., 2017, INTRO NAPLES MYTH HI, P1, DOI DOI 10.1109/LISAT.2017.8001965
   Ramalingam M., 2011, Int J Informat Commun Eng, V5, P170, DOI [10.5281/zenodo.1070343, DOI 10.5281/ZENODO.1070343]
   Sadek MM, 2014, SPRINGER SCI J, P1
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 31
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 22045
EP 22076
DI 10.1007/s11042-019-7503-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400066
DA 2024-07-18
ER

PT J
AU Shinde, A
   Rahulkar, A
   Patil, C
AF Shinde, Amita
   Rahulkar, Amol
   Patil, Chetankumar
TI Biomedical image indexing and retrieval based on new efficient hybrid
   approach using directional decomposition and a novel local directional
   frequency encoded pattern: a post feature descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical image retrieval; Directional decomposition; Directional
   filter bank; Feature extraction; Local directional frequency encoded
   pattern; Triplet half-band filter bank
ID FILTER BANKS; CURVELET TRANSFORM; WAVELET TRANSFORM; EXTREMA PATTERN;
   DESIGN; TRIPLET; TEXTURE; CLASSIFICATION; FACTORIZATION; EXTRACTION
AB In this paper, a new efficient hybrid approach based on directional decomposition and post local feature extraction is proposed for biomedical image indexing and retrieval. Initially, triplet half-band filter bank (THFB) is modified and used in directional filter bank (DFB) for directional decomposition of images. DFB decomposes image into directional frequency sub-bands. To acquire local information in each directional sub-band of images, a novel local directional frequency encoded pattern (LDFEP) feature descriptor is proposed as post feature descriptor. The LDFEP is based on establishing the relationship between 0(0), 45(0), 90(0), and 135(0) directional frequency components. The deliberation of directional as well as local information composes hybrid approach which is more efficient than the existing descriptors for biomedical image retrieval. Manhattan distance is selected to compute analogy between the query feature vector and the feature vector of images from the database. The efficacy of the proposed approach in terms of precision and recall has been evaluated by conducting the experiments on three well-known biomedical databases: Open access series of imaging studies (OASIS)-MRI, EXACT 09-CT and NEMA-CT. The experimental results confirmed the superiority of the proposed approach in comparison with the state-of-the-art feature descriptors for biomedical image retrieval.
C1 [Shinde, Amita; Patil, Chetankumar] Coll Engn Pune, Instrumentat & Control, Pune, Maharashtra, India.
   [Rahulkar, Amol] Natl Inst Technol Goa, Elect & Elect Engn, Farmagudi, Goa, India.
C3 College of Engineering Pune; National Institute of Technology (NIT
   System); National Institute of Technology Goa
RP Shinde, A (corresponding author), Coll Engn Pune, Instrumentat & Control, Pune, Maharashtra, India.
EM amitashinde4u@gmail.com; amol.rahulkar@gmail.com; cypatil@gmail.com
OI Shinde, Amita/0000-0003-1854-3532
CR Ansari R, 1999, IEEE T CIRCUITS-II, V46, P1487, DOI 10.1109/82.809534
   ANSARI R, 1987, IEEE T CIRCUITS SYST, V34, P941, DOI 10.1109/TCS.1987.1086224
   Atto AM, 2013, IEEE T IMAGE PROCESS, V22, P2495, DOI 10.1109/TIP.2013.2246524
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Cai TW, 2008, ACAD PR SER BIOM ENG, P83, DOI 10.1016/B978-012373583-6.50008-6
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cha S.-H., 2007, Int. J. Math. Models Methods Appl. Sci., V1, P300
   Chan SC, 2004, IEEE T CIRCUITS-I, V51, P1476, DOI 10.1109/TCSI.2004.832795
   Cheng KO, 2007, PATTERN RECOGN, V40, P1182, DOI 10.1016/j.patcog.2006.07.014
   Deep G, 2016, ENG SCI TECHNOL, V19, P1895, DOI 10.1016/j.jestch.2016.05.006
   Deserno TM, 2009, J DIGIT IMAGING, V22, P202, DOI 10.1007/s10278-007-9092-x
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Ellmauthaler A, 2013, IEEE T IMAGE PROCESS, V22, P1005, DOI 10.1109/TIP.2012.2226045
   Eslami R, 2010, IEEE T SIGNAL PROCES, V58, P2088, DOI 10.1109/TSP.2009.2039822
   Gawande JP, 2016, DIGIT SIGNAL PROCESS, V56, P123, DOI 10.1016/j.dsp.2016.06.001
   Gawande JP, 2015, SIGNAL IMAGE VIDEO P, V9, P265, DOI 10.1007/s11760-015-0814-0
   Iakovidis DK, 2009, IEEE T INF TECHNOL B, V13, P442, DOI 10.1109/TITB.2008.923144
   Kalpathy-Cramer J, 2015, COMPUT MED IMAG GRAP, V39, P55, DOI 10.1016/j.compmedimag.2014.03.004
   Kha HH, 2011, IEEE T IMAGE PROCESS, V20, P586, DOI 10.1109/TIP.2010.2059450
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Lacoste C, 2007, IEEE T CIRC SYST VID, V17, P889, DOI 10.1109/TCSVT.2007.897114
   Lo P, 2012, IEEE T MED IMAGING, V31, P2093, DOI 10.1109/TMI.2012.2209674
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Murala S, 2013, IEEE COMPUT SOC CONF, P444, DOI 10.1109/CVPRW.2013.73
   Murala S, 2012, J MED SYST, V36, P2865, DOI 10.1007/s10916-011-9764-4
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nguyen T.H.L., 2006, THESIS
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Park SI, 2004, IEEE T IMAGE PROCESS, V13, P1424, DOI 10.1109/TIP.2004.836186
   PARK SI, 1999, ACOUST SPEECH SIG PR, P1417
   Patil BD, 2008, IEEE SIGNAL PROC LET, V15, P485, DOI 10.1109/LSP.2008.922295
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Quellec G, 2010, IEEE T IMAGE PROCESS, V19, P25, DOI 10.1109/TIP.2009.2030479
   Rahman MM, 2007, IEEE T INF TECHNOL B, V11, P58, DOI 10.1109/TITB.2006.884364
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rahulkar AD, 2014, SIGNAL IMAGE VIDEO P, V8, P1451, DOI 10.1007/s11760-012-0378-1
   Rahulkar AD, 2012, IEEE T INF FOREN SEC, V7, P230, DOI 10.1109/TIFS.2011.2166069
   Rosiles JG, 2001, INT CONF ACOUST SPEE, P1549, DOI 10.1109/ICASSP.2001.941228
   Shinde AA, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P154, DOI 10.1109/SIPROCESS.2017.8124524
   Shinde AA, 2017, INT J MULTIMED INF R, V6, P281, DOI 10.1007/s13735-017-0132-0
   Singha M, 2012, IET IMAGE PROCESS, V6, P1221, DOI 10.1049/iet-ipr.2011.0453
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Suzuki T, 2015, IEEE T IMAGE PROCESS, V24, P4943, DOI 10.1109/TIP.2015.2472294
   Swanson MD, 1996, IEEE T IMAGE PROCESS, V5, P1637, DOI 10.1109/83.544571
   Tay DBH, 2004, IEEE T CIRCUITS-II, V51, P378, DOI 10.1109/TCSII.2004.831430
   Unay D, 2010, IEEE T INF TECHNOL B, V14, P897, DOI 10.1109/TITB.2009.2038152
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
NR 58
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23489
EP 23519
DI 10.1007/s11042-019-7697-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400057
DA 2024-07-18
ER

PT J
AU You, WK
   Zhao, XF
   Ma, S
   Liu, YQ
AF You, Weike
   Zhao, Xianfeng
   Ma, Sai
   Liu, Yaqi
TI RestegNet: a residual steganalytic network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep learning; Image steganography;
   Steganalysis; Residual connections
AB Deep convolutional networks bring new energy to image steganography. It is an opportunity for steganalysis research. However, the operations to widen the gap between covers and stegos are only in the preprocessing layers for most existing networks. In this paper, a residual steganalytic network (RestegNet) is proposed to overcome this limitation. We design a novel building block group, which consists of two alternating building blocks: 1) A sharpening block based on residual connections (ShRC), which makes the noise of steganography overwhelm the image content, and aims to enhance steganographic signal detectability. 2) A smoothing block based on residual connections (SmRC), which seeks to downsample the feature maps to boil them down to useful data. First, we use the same preprocessing layers as previous methods to ensure minimum performance. Then, we use these building block groups to exaggerate the traces of steganography further and make the difference between covers and stegos in the feature extraction layers. Contrastive experiments with previous methods conducted on the BOSSbase 1.01 demonstrate the effectiveness and the superior performance of the proposed network.
C1 [You, Weike; Zhao, Xianfeng; Ma, Sai; Liu, Yaqi] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [You, Weike; Zhao, Xianfeng; Ma, Sai; Liu, Yaqi] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Zhao, XF (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM youweike@iie.ac.cn; zhaoxianfeng@iie.ac.cn; masai@iie.ac.cn;
   liuyaqi@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [61802393, U1736214, U1636102, 61872356]; National Key Technology
   RD Program [2016YFB0801003, 2016QY15Z2500]; Project of Beijing Municipal
   Science & Technology Commission [Z181100002718001]
FX This work was supported by NSFC under 61802393, U1736214, U1636102 and
   61872356, National Key Technology R&D Program under 2016YFB0801003 and
   2016QY15Z2500, and Project of Beijing Municipal Science & Technology
   Commission under Z181100002718001.
CR [Anonymous], CORR
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Li BH, 2019, IEEE T CIRC SYST VID, V29, P930, DOI 10.1109/TCSVT.2018.2793359
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan SJ, 2014, MEDIAT INFLAMM, V2014, DOI 10.1155/2014/924296
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 19
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22711
EP 22725
DI 10.1007/s11042-019-7601-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400024
DA 2024-07-18
ER

PT J
AU Bahreini, K
   van der Vegt, W
   Westera, W
AF Bahreini, Kiavash
   van der Vegt, Wim
   Westera, Wim
TI A fuzzy logic approach to reliable real-time recognition of facial
   emotions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Affective computing; Software development;
   Statistical data analysis; Fuzzy logic; Webcam; E-learning
ID EXPRESSION RECOGNITION; SERIOUS GAMES; EDUCATION; FUSION
AB This paper represents our newly developed software for emotion recognition from facial expressions. Besides allowing emotion recognition from image files and recorded video files, it uses webcam data to provide real-time, continuous, and unobtrusive facial emotional expressions. It uses FURIA algorithm for unordered fuzzy rule induction to offer timely and appropriate feedback based on learners' facial expressions. The main objective of this study was first to validate the use of webcam data for a real-time and accurate analysis of facial expressions in e-learning environments. Second, transform these facial expressions to detected emotional states using the FURIA algorithm. We measured the performance of the software with ten participants, provided them with the same computer-based tasks, requested them a hundred times to mimic specific facial expressions, and recorded all sessions on video. We used the recorded video files to feed our newly developed software. We then used two experts' opinions to annotate and rate participants' recorded behaviours and to validate the software's results. The software provides accurate and reliable results with the overall accuracy of 83.2%, which is comparable to the recognition by humans. This study will help to increase the quality of e-learning.
C1 [Bahreini, Kiavash; van der Vegt, Wim; Westera, Wim] Open Univ Netherlands, Welten Inst, Res Ctr Learning Teaching & Technol, Fac Psychol & Educ Sci, Heerlen, Netherlands.
C3 Open University Netherlands
RP Bahreini, K (corresponding author), Open Univ Netherlands, Welten Inst, Res Ctr Learning Teaching & Technol, Fac Psychol & Educ Sci, Heerlen, Netherlands.
EM kiavash.bahreini@ou.nl
OI van der Vegt, Wim/0000-0002-7732-1561
FU EC H2020 project RAGE (Realising an Applied Gaming Eco-System) [644187]
FX This work has been partially funded by the EC H2020 project RAGE
   (Realising an Applied Gaming Eco-System); http://www.rageproject.eu/;
   Grant agreement No 644187.
CR Ali H, 2015, EXPERT SYST APPL, V42, P1261, DOI 10.1016/j.eswa.2014.08.049
   Anisetti M, 2009, INT C INT HUM COMP I
   [Anonymous], COMMUNICATION ORG BA
   [Anonymous], 2010, 3 IEEE WORKSH CVPR H
   [Anonymous], 2006, RECOVERING INFORM LE
   [Anonymous], PSYCHOL GESPREKSVOER
   [Anonymous], 2012, ARXIV12036722
   Arroyo I, 2009, FRONT ARTIF INTEL AP, V200, P17, DOI 10.3233/978-1-60750-028-5-17
   Bachiller C, 2010, P INT C ENG ED ICEE, P1
   Bahreini Kiavash, 2008, 2008 IEEE 32nd International Computer Software and Applications Conference (COMPSAC), P902, DOI 10.1109/COMPSAC.2008.102
   Bahreini Kiavash, 2008, 2008 IEEE 32nd International Computer Software and Applications Conference (COMPSAC), P553, DOI 10.1109/COMPSAC.2008.100
   Bahreini K, 2017, INTERACT LEARN ENVIR, V25, P1065, DOI 10.1080/10494820.2016.1247286
   Bahreini K, 2016, EDUC INF TECHNOL, V21, P1367, DOI 10.1007/s10639-015-9388-2
   Bahreini K, 2016, INTERACT LEARN ENVIR, V24, P590, DOI 10.1080/10494820.2014.908927
   Bahreini K, 2016, INT J HUM-COMPUT INT, V32, P415, DOI 10.1080/10447318.2016.1159799
   Ben Ammar M, 2010, EXPERT SYST APPL, V37, P3013, DOI 10.1016/j.eswa.2009.09.031
   BRUSILOVSKIY PL, 1994, J COMPUT SYS SC INT+, V32, P70
   Brusilovsky P., 1994, Proc. Of Fourth international conference on User Modeling, p. 15-19 August, Hyannis, MA, P31
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   D'Mello S.K., 2012, ACM Transactions on Interactive Intelligent Systems, V2, P1, DOI DOI 10.1145/2395123.2395128
   De Gloria A, 2014, INT J SERIOUS GAMES, V1, P1, DOI 10.17083/ijsg.v1i4.55
   Devi J.S., 2014, INT J COMPUTATIONAL, V4, P35
   Ekman P, 1978, FACIAL ACTION CODING
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Esau N., 2007, IEEE INT FUZZ SYST C
   Faundez-Zanuy M, 2005, IEEE AERO EL SYS MAG, V20, P23, DOI 10.1109/MAES.2005.1576071
   Feidakis M., 2011, Proceedings of the 2011 Third International Conference on Intelligent Networking and Collaborative Systems (INCoS 2011), P807, DOI 10.1109/INCoS.2011.82
   Francese R, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P116, DOI 10.1145/2254556.2254580
   Goetz T, 2013, CONTEMP EDUC PSYCHOL, V38, P383, DOI 10.1016/j.cedpsych.2013.08.001
   Gu WF, 2010, SOFT COMPUT, V14, P113, DOI 10.1007/s00500-009-0441-1
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Hühn J, 2009, DATA MIN KNOWL DISC, V19, P293, DOI 10.1007/s10618-009-0131-8
   Hühnel I, 2014, J EXP SOC PSYCHOL, V50, P136, DOI 10.1016/j.jesp.2013.09.011
   Hussain MS, 2011, LECT NOTES ARTIF INT, V6738, P131, DOI 10.1007/978-3-642-21869-9_19
   Ilbeygi M, 2012, ENG APPL ARTIF INTEL, V25, P130, DOI 10.1016/j.engappai.2011.07.004
   Ip HHS, 2018, COMPUT EDUC, V117, P1, DOI 10.1016/j.compedu.2017.09.010
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kazmi SB, 2012, SOFT COMPUT, V16, P369, DOI 10.1007/s00500-011-0721-4
   Kharat GU, 2009, ADV INTEL SOFT COMPU, V60, P207
   Kim D. J., 2016, Pattern Recognition and Image Analysis, V26, P576
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kipp M., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1, DOI DOI 10.1109/ACII.2009.5349544
   Krahmer E, 2011, PHILIPS RES BOOK SER, V12, P85, DOI 10.1007/978-90-481-3258-4_6
   Kushki A, 2011, PHYSIOL MEAS, V32, P1529, DOI 10.1088/0967-3334/32/10/002
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee H, 2012, CONSUM COMM NETWORK, P260, DOI 10.1109/CCNC.2012.6181098
   Li HL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1-3, P1112
   Li S. Z., 2011, HDB FACE RECOGNITION, DOI [10.1007/978-0-85729-932-1, DOI 10.1007/978-0-85729-932-1]
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Ma CL, 2005, LECT NOTES COMPUT SC, V3711, P535
   Magdin M, 2016, INT J INTERACT MULTI, V4, P61, DOI 10.9781/ijimai.2016.4112
   Marston WM, 1917, J EXP PSYCHOL, V2, P117, DOI 10.1037/h0073583
   Murthy G.R. S., 2009, INT J COMPUTER THEOR, V1, P638
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Pantic M, 2005, P 13 ANN ACM INT C M, V5, P669
   Patel S, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-21
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Piana S, 2014, CORR
   Preeti K, 2013, THESIS
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sarrafzadeh A, 2008, COMPUT HUM BEHAV, V24, P1342, DOI 10.1016/j.chb.2007.07.008
   Sebe N, 2005, PROC SPIE, V5670, P56, DOI 10.1117/12.600746
   Sebe N, 2009, J AMB INTEL SMART EN, V1, P23, DOI 10.3233/AIS-2009-0003
   Sgouropoulos K, 2014, J INTELL ROBOT SYST, V76, P283, DOI 10.1007/s10846-013-9983-7
   Shaheen S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P383, DOI 10.1109/ICDMW.2014.80
   Shen LP, 2009, EDUC TECHNOL SOC, V12, P176
   Shotton J, 2011, IEEE EXPERT P CVPR
   Smith TC, 2016, METHODS MOL BIOL, V1418, P353, DOI 10.1007/978-1-4939-3578-9_17
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Tettegah S. Y., 2015, Emotions, technology, and learning
   van der Vegt W, LECT NOTES COMPUTER, P165
   van der Vegt W, 2016, INT J COMPUT GAMES T, V2016, DOI 10.1155/2016/5680526
   Vayrynen E. (Eero), 2014, EMOTION RECOGNITION
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wang Z, 2010, INT CONF SIGN PROCES, P1358, DOI 10.1109/ICOSP.2010.5656884
   Westera W, 2008, J COMPUT ASSIST LEAR, V24, P420, DOI 10.1111/j.1365-2729.2008.00279.x
   Westera W, 2016, PROC EUR CONF GAME, P765
   White K., 1999, The online teaching guide: A handbook of attitudes, strategies and techniques for the virtual classroom
   Wright A., 2009, New York Times
   Wu C.H., 2006, ACM Trans. Asian Lang. Inf. Process. (TALIP), V5, P165, DOI DOI 10.1145/1165255.1165259
   Yang S, 2011, IEEE INT SYMP INFO, P2866, DOI 10.1109/ISIT.2011.6034099
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
NR 84
TC 16
Z9 16
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 18943
EP 18966
DI 10.1007/s11042-019-7250-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Hassan, SA
   Sayed, MS
   Abdalla, MI
   Rashwan, MA
AF Hassan, Shayma'a A.
   Sayed, Mohammed S.
   Abdalla, Mahmoud I.
   Rashwan, Mohsen A.
TI Detection of breast cancer mass using MSER detector and features
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram images; Computer-aided diagnosis; MSER regions; Feature
   matching
ID COMPUTER-AIDED DIAGNOSIS; SEGMENTATION; MAMMOGRAMS
AB Detection of breast cancer masses in mammogram images is an essential step in any computer-aided system for breast cancer diagnosis. In this paper, we propose a novel technique for breast cancer masses detection in mammograms based on the feature matching of different regions using Maximally Stable Extremal Regions (MSER). Firstly, a pre-processing step is applied to the original mammogram image to produce an enhanced version of this image. Then, MSER regions are extracted from both the original image and its enhanced version using MSER detector. Finally, feature matching process is applied between these regions to detect the mass area. The proposed algorithm has been tested on a collected set of 300 mammogram images containing abnormalities (i.e. benign and malignant masses) from four different databases. The proposed algorithm is able to accurately detect locations of masses with an accuracy of 95%. There aren't any processing steps for pectoral muscle removal, this results in reducing the processing time. The average time taken by the proposed method to process one mammogram image is 0.14s. The proposed method is fully automated and there is no need for user intervention or any readjustment. The proposed algorithm is robust against noise and it is not affected by the image quality, breast density category, or mass nature. The results show that the proposed algorithm has higher accuracy than the state of the art approaches.
C1 [Hassan, Shayma'a A.; Sayed, Mohammed S.; Abdalla, Mahmoud I.] Zagazig Univ, Dept Elect & Commun Engn, Zagazig, Egypt.
   [Sayed, Mohammed S.] Egypt Japan Univ Sci & Technol, Dept Elect & Commun Engn, Alexandria, Egypt.
   [Rashwan, Mohsen A.] Cairo Univ, Dept Elect & Commun Engn, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Egypt-Japan University of Science & Technology; Egyptian
   Knowledge Bank (EKB); Cairo University
RP Hassan, SA (corresponding author), Zagazig Univ, Dept Elect & Commun Engn, Zagazig, Egypt.
EM shafayad@zu.edu.eg; mohammed.sayed@ejust.edu.eg; mabdallah@zu.edu.eg;
   mrashwan@rdi-eg.com
RI rashwan, mohsen/AAA-5747-2020
OI Ahmed, Shaymaa/0000-0003-4886-2315
CR Al-antari MA, 2018, J MED BIOL ENG, V38, P443, DOI 10.1007/s40846-017-0321-6
   Anitha J, 2017, COMPUT METH PROG BIO, V138, P93, DOI 10.1016/j.cmpb.2016.10.026
   [Anonymous], 2016, Curated Breast Imaging Subset of DDSM
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cordeiro FR, 2016, APPL SOFT COMPUT, V46, P613, DOI 10.1016/j.asoc.2015.11.040
   Deshmukh J, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P134, DOI 10.1109/WiSPNET.2017.8299734
   Elsawy N, 2017, P JAPAN AFRICA C ELE, P123
   Hassan SA, 2014, CAIRO INT BIOM ENG, P103, DOI 10.1109/CIBEC.2014.7020928
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Jasmin MR, 2015, INT J ENG RES TECHNO, V3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makandar A, 2016, J COMPUT, V11, P472, DOI 10.17706/jcp.11.6.472-478
   Matos CEF, 2018, MULTIMED TOOLS APPL, P1
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Mustafa M., 2017, Indonesian J Electr Eng Comput Sci, V5, P577, DOI [10.11591/ijeecs.v5.i3.pp577-583, DOI 10.11591/IJEECS.V5.I3.PP577-583]
   Neto OPS, 2017, MULTIMED TOOLS APPL, V76, P19263, DOI 10.1007/s11042-017-4710-1
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Oliver Arnau, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2528, DOI 10.1109/ICPR.2010.619
   Pereira DC, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.014
   Pui S, 2018, LECT NOTES ELECT ENG
   Rahmati P, 2012, MED IMAGE ANAL, V16, P1167, DOI 10.1016/j.media.2012.05.005
   Rajkumar K., 2015, BR J APPL SCI TECHNO, V6, P378, DOI DOI 10.9734/BJAST/2015/14383
   Rouhi R, 2015, EXPERT SYST APPL, V42, P990, DOI 10.1016/j.eswa.2014.09.020
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   Singh SP, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0454-0
   Soulami KB, 2018, MULTIMED TOOLS APPL, P1
   Suckling J., 2015, MAMMOGRAPHIC IMAGE A, DOI 10.250394
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang HY, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4015613
   WHO, Cancer Fact Sheet
   Xu SZ, 2011, J DIGIT IMAGING, V24, P754, DOI 10.1007/s10278-011-9365-2
NR 31
TC 17
Z9 18
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20239
EP 20262
DI 10.1007/s11042-019-7358-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800059
DA 2024-07-18
ER

PT J
AU Karajeh, H
   Khatib, T
   Rajab, L
   Maqableh, M
AF Karajeh, Huda
   Khatib, Tahani
   Rajab, Lama
   Maqableh, Mahmoud
TI A robust digital audio watermarking scheme based on DWT and Schur
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Discrete wavelet transform; Schur decomposition;
   Copyright protection
ID SINGULAR-VALUE DECOMPOSITION; VECTOR MODULATION; ALGORITHM; SVD
AB The vulnerability of digital audio signals for different types of risks requires an imperceptible and robust digital audio watermarking scheme. In this research, we propose creating one such imperceptible and robust hybrid watermarking scheme based on a discrete wavelet transform (DWT) and Schur decomposition hybrid method. The proposed scheme embeds the foreground bits of the watermarking image into the least significant bit of the diagonal coefficients of the triangular matrix S generated from Schur decomposition. Schur decomposition is applied on the second sub-band HL2 generated from applying a second-level 2D-Haar DWT on the first channel of the original audio signal. We analyze the proposed digital audio watermarking scheme's performance in terms of signal to noise ratio (SNR), objective difference grades (ODG), and subjective difference grades (SDG) that resulting 81.43, 4.78 and 0.184, respectively. The resulting of payload capacity, NC, and BER are as high as 319.29bps, 0.9911, and 0.0135, respectively. Experimental results confirm that the proposed scheme is inaudible and robust against common types of attacks such as Gaussian noise, re-quantization, re-sampling, low-pass filter, high-pass filter, echo, MP3 compression, and cropping. In comparison with state-of-the-art audio watermarking schemes, the proposed scheme's performance is superior in term of imperceptibility, robustness, and data payload size.
C1 [Karajeh, Huda; Khatib, Tahani; Rajab, Lama] Univ Jordan, King Abdullah II Sch Informat Technol, Amman 11942, Jordan.
   [Maqableh, Mahmoud] Univ Jordan, Sch Business, Dept Management Informat Syst, Amman 11942, Jordan.
C3 University of Jordan; University of Jordan
RP Maqableh, M (corresponding author), Univ Jordan, Sch Business, Dept Management Informat Syst, Amman 11942, Jordan.
EM h.karajeh@ju.edu.jo; tahani.khatib@ju.edu.jo; lama.rajab@ju.edu.jo;
   maqableh@ju.edu.jo
RI Karajeh, Huda/P-4397-2016; Maqableh, Mahmoud M./C-9632-2014; Al-Khatib,
   Tahani/B-9565-2015
OI Maqableh, Mahmoud/0000-0003-2376-7143; Al-Khatib,
   Tahani/0000-0002-8309-8634
CR Abd El-Samie FE, 2009, INT J SPEECH TECHNOL, V12, P27, DOI 10.1007/s10772-009-9056-2
   Al-Haj Ali, 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P525, DOI 10.1109/ICDIM.2010.5664651
   Al-Haj A, 2014, MULTIMED TOOLS APPL, V73, P1897, DOI 10.1007/s11042-013-1645-z
   Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2005, P ACM MMSEC
   Attari AA, 2017, P INT C GRAPH SIGN P, P69
   Bansal N, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P40
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chandra B., 2010, INT J COMPUT ELECT E, V2, P781, DOI DOI 10.7763/IJCEE.2010.V2.228
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Choudhary A., 2012, C P P CUBE INT TECHN, P744, DOI DOI 10.1145/2381716.2381858
   Deb Kaushik, 2014, [The Journal of Korea Institute of Convergence Signal Processing, 융합신호처리학회 논문지], V15, P1
   Deokar SM, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P264, DOI 10.1109/IIC.2015.7150750
   Dhar PK, 2017, RADIOENGINEERING, V26, P552, DOI 10.13164/re.2017.0552
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Dutt S, 2011, DWT HAAR BASED AUDIO, P416
   El Gamal A F, 2013, INT J COMPUTER APPL, V66, P33
   Full EWK, 2014, INT J INF COMPUT TEC, V4, P1155
   Ganic Emir., 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Hemalatha S., 2012, P 2 INT C COMP SCI E, P223
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2017, WIRELESS PERS COMMUN, V94, P221, DOI 10.1007/s11277-016-3178-z
   Hu HT, 2016, CIRC SYST SIGNAL PR, V35, P553, DOI 10.1007/s00034-015-0074-9
   Hu HT, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P748, DOI 10.1109/IIH-MSP.2014.191
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, SIGNAL PROCESS, V105, P316, DOI 10.1016/j.sigpro.2014.05.003
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Kabal P., 2003, EXAMINATION INTERPRE
   Karajeh H, 2019, ANALOG INTEGR CIRC S, V99, P571, DOI 10.1007/s10470-018-1332-0
   Kaur A, 2017, J INF SECUR APPL, V33, P1, DOI 10.1016/j.jisa.2016.12.003
   Kaur Navijot, 2013, IJCSE, V2, P286
   Kavadia C., 2013, INT J ADV RES COMPUT, V4, P20
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li D, 2011, COMM COM INF SC, V263, P339
   Li JF, 2018, MULTIMED TOOLS APPL, V77, P14481, DOI 10.1007/s11042-017-5024-z
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Liu JH, 2012, CIRC SYST SIGNAL PR, V31, P797, DOI 10.1007/s00034-011-9331-8
   Maha C, 2010, SIGMAP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATION, P139
   Meenakshi K, 2014, INT J RES ENG TECHNO, V3, P7
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Mohan B. C., 2011, IJCA P INT C VLSI CO, V14, P25
   Pattanshetti P., 2015, INT J COMPUTER SCI I, V6, P3688
   Rajab L., 2015, J Softw Eng Appl, V08, P224, DOI [10.4236/jsea.2015.84023, DOI 10.4236/JSEA.2015.84023]
   Razafindradina HB, 2013, IJCSN INT J COMPUT S, V02, P25
   Roy S, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P362, DOI 10.1109/ICCITechn.2015.7488097
   Sathya SPA, 2018, WIRELESS PERS COMMUN, V102, P2011, DOI 10.1007/s11277-018-5252-1
   Sego V, 2014, LINEAR ALGEBRA APPL, V440, P90, DOI 10.1016/j.laa.2013.10.037
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Subir, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P79, DOI 10.1109/SPIN.2016.7566666
   Suresh G., 2012, 2012 International Conference on Devices, Circuits and Systems (ICDCS 2012), P177, DOI 10.1109/ICDCSyst.2012.6188699
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Tsai HH, 2003, EURASIP J APPL SIG P, V2003, P252, DOI 10.1155/S1110865703208027
   Wang HQ, 2008, APPL ACOUST, V69, P868, DOI 10.1016/j.apacoust.2007.06.001
   Wang XY, 2009, PATTERN RECOGN, V42, P3057, DOI 10.1016/j.patcog.2009.01.015
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
   Yang Y, 2016, CHINA COMMUN, V13, P122, DOI 10.1109/CC.2016.7559084
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang JQ, 2015, INT J SPEECH TECHNOL, V18, P443, DOI 10.1007/s10772-015-9287-3
NR 70
TC 21
Z9 23
U1 2
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18395
EP 18418
DI 10.1007/s11042-019-7214-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200048
DA 2024-07-18
ER

PT J
AU Mourchid, Y
   El Hassouni, M
   Cherifi, H
AF Mourchid, Youssef
   El Hassouni, Mohammed
   Cherifi, Hocine
TI A general framework for complex network-based image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex networks; Image segmentation; Community detection
AB With the recent advances in complex networks theory, graph-based techniques for image segmentation has attracted great attention recently. In order to segment the image into meaningful connected components, this paper proposes an image segmentation general framework using complex networks based community detection algorithms. If we consider regions as communities, using community detection algorithms directly can lead to an over-segmented image. To address this problem, we start by splitting the image into small regions using an initial segmentation. The obtained regions are used for building the complex network. To produce meaningful connected components and detect homogeneous communities, some combinations of color and texture based features are employed in order to quantify the regions similarities. To sum up, the network of regions is constructed adaptively to avoid many small regions in the image, and then, community detection algorithms are applied on the resulting adaptive similarity matrix to obtain the final segmented image. Experiments are conducted on Berkeley Segmentation Dataset and four of the most influential community detection algorithms are tested. Experimental results have shown that the proposed general framework increases the segmentation performances compared to some existing methods.
C1 [Mourchid, Youssef; El Hassouni, Mohammed] Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT,CNRST URAC 29, Rabat, Morocco.
   [El Hassouni, Mohammed] Mohammed V Univ Rabat, FLSH, Rabat IT Ctr, LRIT,CNRST URAC 29, Rabat, Morocco.
   [Cherifi, Hocine] Univ Burgundy, CNRS, LE2I, UMR 6306, Dijon, France.
C3 Centre National de la Recherche Scientifique & Technologique (CNRST);
   Mohammed V University in Rabat; Mohammed V University in Rabat; Centre
   National de la Recherche Scientifique & Technologique (CNRST);
   Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS)
RP Mourchid, Y (corresponding author), Mohammed V Univ Rabat, Fac Sci, Rabat IT Ctr, LRIT,CNRST URAC 29, Rabat, Morocco.
EM youssefmour@gmail.com; mohamed.elhassouni@gmail.com;
   hocine.cherifi@gmail.com
RI Cherifi, Hocine/X-9376-2019; Mourchid, Youssef/AAK-3314-2021; El
   Hassouni, Mohammed/AAL-8452-2020
OI Cherifi, Hocine/0000-0001-9124-4921; Mourchid,
   Youssef/0000-0003-4108-4557; El Hassouni, Mohammed/0000-0002-6741-4799
CR Abin AA, 2014, IMAGING SCI J, V62, P327, DOI 10.1179/1743131X13Y.0000000069
   [Anonymous], P NATL ACAD SCI
   [Anonymous], IET IMAGE PROCESSING
   [Anonymous], 2005 CVPR IEEE COMP
   [Anonymous], ARXIV11124134
   [Anonymous], IJCAI
   [Anonymous], EMPIRICAL EVALUATION
   [Anonymous], 2010 17 IEEE INT C I
   [Anonymous], 2006 CVPRW 06 C COMP
   [Anonymous], 2010, NETWORKS INTRO, DOI DOI 10.1093/ACPROF:OSO/9780199206650.001.0001
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Çigla C, 2010, IEEE IMAGE PROC, P3013, DOI 10.1109/ICIP.2010.5653963
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lancichinetti A, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.056117
   Li SJ, 2015, IEEE T CIRC SYST VID, V25, P570, DOI 10.1109/TCSVT.2014.2360028
   Linares O. A. C., 2016, ABS161203705 CORR
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Mori G, 2005, IEEE I CONF COMP VIS, P1417
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   Orman GK, 2011, COMM COM INF SC, V167, P265
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Ronhovde P, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.046114
   Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Trémeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WANI MA, 1994, IEEE T PATTERN ANAL, V16, P314, DOI 10.1109/34.276131
   Wright WD., 1967, Physics Bulletin, V18, P353, DOI DOI 10.1088/0031-9112/18/10/010
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Zou QY, 2018, WIRELESS PERS COMMUN, V103, P715, DOI 10.1007/s11277-018-5472-4
NR 42
TC 9
Z9 9
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20191
EP 20216
DI 10.1007/s11042-019-7304-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800057
DA 2024-07-18
ER

PT J
AU Stottinger, J
   Bhatti, N
   Hanbury, A
AF Stottinger, Julian
   Bhatti, Naeem
   Hanbury, Allan
TI An in-depth evaluation framework for spatio-temporal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local feature; Evaluation; Video; Spatio-temporal
ID PARALLEL FRAMEWORK; SCALE; RECOGNITION
AB The most successful approaches to video understanding and video matching use local spatio-temporal features as a sparse representation for video content. In the last decade, a great interest in evaluation of local visual features in the domain of images is observed. The aim is to provide researchers with guidance when selecting the best approaches for new applications and data-sets. FeEval is presented, a framework for the evaluation of spatio-temporal features. For the first time, this framework allows for a systematic measurement of the stability and the invariance of local features in videos. FeEval consists of 30 original videos from a great variety of different sources, including HDTV shows, 1080p HD movies and surveillance cameras. The videos are iteratively varied by well defined challenges leading to a total of 1710 video clips. We measure coverage, repeatability and matching performance under these challenges. Similar to prior work on 2D images, this leads to a new robustness and matching measurement. Supporting the choices of recent state of the art benchmarks, this allows for a in-depth analysis of spatio-temporal features in comparison to recent benchmark results.
C1 [Stottinger, Julian] Univ Trento, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
   [Bhatti, Naeem] Quaid I Azam Univ, Dept Elect, Islamabad, Pakistan.
   [Hanbury, Allan] Vienna Univ Technol, Inst Informat Syst Engn, Favoritenstr 9-11-194-04, A-1040 Vienna, Austria.
C3 University of Trento; Quaid I Azam University; Technische Universitat
   Wien
RP Bhatti, N (corresponding author), Quaid I Azam Univ, Dept Elect, Islamabad, Pakistan.
EM nbhatti@qau.edu.pk
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], CVPR
   [Anonymous], 2018, IEEE Trans. Multimed.
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE CAN C COMP ROB
   [Anonymous], PAMI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ICCV
   [Anonymous], AAPR
   [Anonymous], 2011, CVPR
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bilinski Piotr, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P61, DOI 10.1007/978-3-642-23968-7_7
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Everts I, 2014, IEEE T IMAGE PROCESS, V23, P1569, DOI 10.1109/TIP.2014.2302677
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Harris C., 1988, ALVEY VISION C, P147151
   He YS, 2009, 2009 ISECS INTERNATIONAL COLLOQUIUM ON COMPUTING, COMMUNICATION, CONTROL, AND MANAGEMENT, VOL II, P127, DOI 10.1109/CCCM.2009.5267964
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ke QF, 2005, IEEE I CONF COMP VIS, P986
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, LECT NOTES COMPUT SC, V2695, P372
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Stottinger Julian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P499, DOI 10.1109/ICPR.2010.128
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Wang L, 2008, LECT NOTES COMPUT SC, V5305, P719, DOI 10.1007/978-3-540-88693-8_53
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Xian Y, 2017, IEEE T CIRC SYST VID, V27, P624, DOI 10.1109/TCSVT.2016.2589838
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
NR 50
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17359
EP 17390
DI 10.1007/s11042-018-7032-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200003
DA 2024-07-18
ER

PT J
AU Zhang, XJ
   Ye, WZ
AF Zhang, Xiaojuan
   Ye, Wanzhou
TI An adaptive second-order partial differential equation based on TV
   equation and p-Laplacian equation for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; TV; p-Laplacian; Adaptive equation; Weak solution
ID DIFFUSION; SPACE; EFFICIENT
AB This paper introduces an adaptive diffusion partial differential equation (PDE) for noise removal, which combines a total variation (TV) term and a p-Laplacian (1 < p <= 2) term. Utilizing the edge indicator, we can adaptively control the diffusion model, which alternates between the TV and the p-Laplacian(1 < p <= 2) in accordance with the image feature. The main advantage of the proposed model is able to alleviate the staircase effect in smooth regions and preserve edges while removing the noise. The existence of a weak solution of the proposed model is proved. Experimental results confirm the performance of the proposed method with regard to peak signal-to-noise ratio (PSNR), mean structural similarity (MSSIM) and visual quality.
C1 [Zhang, Xiaojuan; Ye, Wanzhou] Shanghai Univ, Coll Sci, Dept Math, Shanghai, Peoples R China.
   [Zhang, Xiaojuan] North China Univ Water Resources & Elect Power, Sch Math & Stat Sci, Zhengzhou, Henan, Peoples R China.
C3 Shanghai University; North China University of Water Resources &
   Electric Power
RP Ye, WZ (corresponding author), Shanghai Univ, Coll Sci, Dept Math, Shanghai, Peoples R China.
EM zhangxiaojuan@ncwu.edu.cn; wzhy@shu.edu.cn
CR Andreu F, 2002, J FUNCT ANAL, V188, P516, DOI 10.1006/jfan.2001.3829
   Andreu F, 2001, J FUNCT ANAL, V180, P347, DOI 10.1006/jfan.2000.3698
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Blomgren P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P384, DOI 10.1109/ICIP.1997.632128
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan TF, 2007, J VIS COMMUN IMAGE R, V18, P464, DOI 10.1016/j.jvcir.2006.12.004
   Chen YM, 2006, SIAM J APPL MATH, V66, P1383, DOI 10.1137/050624522
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Guidotti P, 2011, J MATH IMAGING VIS, V40, P188, DOI 10.1007/s10851-010-0256-9
   Kuijper A., 2007, IEEE INT C IM PROC, V5, P257
   Li F, 2010, APPL MATH COMPUT, V216, P870, DOI 10.1016/j.amc.2010.01.094
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prasath VBS, 2015, IEEE T IMAGE PROCESS, V24, P5220, DOI 10.1109/TIP.2015.2479471
   Prasath VBS, 2015, INVERSE PROBL, V31, DOI 10.1088/0266-5611/31/10/105008
   Rafsanjani HK, 2016, COMPUT MATH APPL, V72, P893, DOI 10.1016/j.camwa.2016.06.005
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SIMON J, 1986, ANN MAT PUR APPL, V146, P65, DOI 10.1007/BF01762360
   Temam R., 1979, STUDIES MATH ITS APP, V2
   Vorotnikov D, 2012, NONLINEARITY, V25, P309, DOI 10.1088/0951-7715/25/2/309
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   Zhou B, 2012, APPL MATH MODEL, V36, P3779, DOI 10.1016/j.apm.2011.11.026
   Zvyagin VG, 2008, DEGRUYTER SER NONLIN, V12, P1, DOI 10.1515/9783110208283
NR 25
TC 8
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18095
EP 18112
DI 10.1007/s11042-019-7170-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200035
DA 2024-07-18
ER

PT J
AU Babiker, A
   Faye, I
   Mumtaz, W
   Malik, AS
   Sato, H
AF Babiker, Areej
   Faye, Ibrahima
   Mumtaz, Wajid
   Malik, Aamir Saeed
   Sato, Hiroki
TI EEG in classroom: EMD features to detect situational interest of
   students during learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram; Classroom; Empirical mode decomposition;
   Classification; Situational interest levels
ID EMPIRICAL MODE DECOMPOSITION; NEURONAL SYNCHRONIZATION;
   INDIVIDUAL-DIFFERENCES; WORKING-MEMORY; ATTENTION; PARIETAL
AB Situational interest is widely explored in the psychology and education domains. It is proven to have positive effect on learning and academic achievement. Nonetheless, not much attention is given for assessing the feasibility of detecting this interest in natural classroom physiologically. Therefore, this study investigates the possibility of detecting situational interest using Electroencephalogram (EEG) in classroom. After preprocessing of EEG data, they were decomposed using Empirical Mode Decomposition (EMD). The resulted Intrinsic Mode Functions (IMFs) were ranked based on their significance using T-test and Receiver Operator Characteristics (ROC) in descending order. A matrix was constructed for all participants using the best six features from four EEG channels. These selected features were fed into Support Vector Machine (SVM) and K-Nearest Neighbor (KNN) classifiers with 10 cross validation. While SVM achieved high accuracy of 93.3% and 87.5% for two data sets using features from the four EEG channels, KNN classifier achieved high accuracy of 87.5% and 86.7% in the same datasets using single EEG channel. It is found that gamma and delta bands can be used successfully to detect situational interest of students during learning in classrooms. Furthermore, data of single EEG channel - F3 in this study- was efficient to detect student's situational interest in simultaneous recording of EEG in classroom.
C1 [Babiker, Areej; Faye, Ibrahima; Mumtaz, Wajid; Malik, Aamir Saeed] Ctr Intelligent Signal & Imaging Res CISIR, Seri Iskandar, Malaysia.
   [Babiker, Areej; Mumtaz, Wajid; Malik, Aamir Saeed] Univ Teknol PETRONAS, Elect & Elect Engn Dept, Seri Iskandar, Malaysia.
   [Faye, Ibrahima] Univ Teknol PETRONAS, Fundamental & Appl Sci Dept, Seri Iskandar, Malaysia.
   [Sato, Hiroki] Shibaura Inst Technol, Biosci & Engn Dept, Coll Syst Engn & Sci, Saitama, Japan.
C3 Universiti Teknologi Petronas; Universiti Teknologi Petronas; Shibaura
   Institute of Technology
RP Babiker, A (corresponding author), Ctr Intelligent Signal & Imaging Res CISIR, Seri Iskandar, Malaysia.; Babiker, A (corresponding author), Univ Teknol PETRONAS, Elect & Elect Engn Dept, Seri Iskandar, Malaysia.
EM areej555@gmail.com
RI Babiker, Areej/IZD-4825-2023; Faye, Ibrahima/AAH-5032-2020; Malik, Aamir
   S/C-6904-2009
OI Faye, Ibrahima/0000-0001-7777-1119; Malik, Aamir S/0000-0003-1085-3157;
   Sato, Hiroki/0000-0002-1364-2198; Babiker, Areej/0000-0002-8105-1664;
   mumtaz, wajid/0000-0001-6468-8666
FU Ministry of Higher Education Malaysia [0153CA-002]
FX This research was funded partially by a grant from the Ministry of
   Higher Education Malaysia for HiCoE for CISIR [0153CA-002].
CR [Anonymous], 1 INT C NEXT GEN COM
   [Anonymous], TELKOMNIKA
   [Anonymous], 2014, COMPUT MATH METHODS
   [Anonymous], HIGHER ED STUD
   [Anonymous], U J ED RES
   [Anonymous], IEEE 10 INT C ICT KN
   [Anonymous], HCI INT 2011 HCI 201
   [Anonymous], 2016 6 INT C INT ADV
   Azcarraga J, 2013, INT J DIST EDUC, V11, P1, DOI 10.4018/jdet.2013040101
   Baars BJ, 2010, COGNITION, BRAIN, AND CONSCIOUSNESS: INTRODUCTION TO COGNITIVE NEUROSCIENCE, 2ND EDITION, P127
   Barbey AK, 2013, CORTEX, V49, P1195, DOI 10.1016/j.cortex.2012.05.022
   Bauer EP, 2007, J NEUROSCI, V27, P9369, DOI 10.1523/JNEUROSCI.2153-07.2007
   Beam W, 2009, BRAIN STIMUL, V2, P50, DOI 10.1016/j.brs.2008.09.006
   Biju KS, 2017, BIOCYBERN BIOMED ENG, V37, P172, DOI 10.1016/j.bbe.2016.12.005
   Börner D, 2014, COMPUT EDUC, V78, P10, DOI 10.1016/j.compedu.2014.04.017
   Chen CM, 2018, INTERACT LEARN ENVIR, V26, P427, DOI 10.1080/10494820.2017.1341938
   Essex BG, 2012, J NEUROSCI, V32, P15403, DOI 10.1523/JNEUROSCI.6106-11.2012
   Fries P, 2001, SCIENCE, V291, P1560, DOI 10.1126/science.1055465
   Ghergulescu I, 2014, INTERACT COMPUT, V26, P305, DOI 10.1093/iwc/iwu013
   Gullick MM, 2014, HUM BRAIN MAPP, V35, P539, DOI 10.1002/hbm.22201
   Güntekin B, 2016, INT J PSYCHOPHYSIOL, V103, P43, DOI 10.1016/j.ijpsycho.2015.02.001
   Harackiewicz JM, 2010, SOC PERSONAL PSYCHOL, V4, P42, DOI 10.1111/j.1751-9004.2009.00207.x
   Harmony T, 1996, INT J PSYCHOPHYSIOL, V24, P161, DOI 10.1016/S0167-8760(96)00053-0
   HIDI S, 1990, REV EDUC RES, V60, P549, DOI 10.2307/1170506
   Hidi S., 2006, ED RES REV, V1, P69, DOI DOI 10.1016/J.EDUREV.2006.09.001
   Hidi S, 2006, EDUC PSYCHOL-US, V41, P111, DOI 10.1207/s15326985ep4102_4
   Hogervorst MA, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00322
   Hsu CH, 2016, J NEUROSCI METH, V264, P78, DOI 10.1016/j.jneumeth.2016.02.015
   Huang NE, 1999, ANNU REV FLUID MECH, V31, P417, DOI 10.1146/annurev.fluid.31.1.417
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jeneson A, 2012, LEARN MEMORY, V19, P15, DOI 10.1101/lm.024018.111
   Jia XX, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001045
   Jimenez-Molina A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020458
   Jones R, 2001, NAT REV NEUROSCI, V2, P760, DOI 10.1038/35097503
   Kaiser J, 2006, NEUROIMAGE, V30, P1376, DOI 10.1016/j.neuroimage.2005.10.042
   Kane MJ, 2002, PSYCHON B REV, V9, P637, DOI 10.3758/BF03196323
   Kounios J, 2009, CURR DIR PSYCHOL SCI, V18, P210, DOI 10.1111/j.1467-8721.2009.01638.x
   Kumfor F, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00225
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   Liang HL, 2005, NEUROCOMPUTING, V65, P801, DOI 10.1016/j.neucom.2004.10.077
   Liu NH, 2013, SENSORS-BASEL, V13, P10273, DOI 10.3390/s130810273
   Lotte F, 2007, J NEURAL ENG, V4, pR1, DOI 10.1088/1741-2560/4/2/R01
   Matthews G, 2017, HUM FACTORS, V59, P44, DOI 10.1177/0018720816673782
   Mitchell M., 1993, J EDUC PSYCHOL, V85, P424, DOI [10.1037/0022-0663.85.3.424, DOI 10.1037/0022-0663.85.3.424]
   Moldovan AN, 2017, IEEE INT CONF ADV LE, P398, DOI 10.1109/ICALT.2017.93
   Myrden A, 2017, IEEE T NEUR SYS REH, V25, P345, DOI 10.1109/TNSRE.2016.2641956
   Pesaran B, 2002, NAT NEUROSCI, V5, P805, DOI 10.1038/nn890
   Peterson CK, 2008, PSYCHOPHYSIOLOGY, V45, P86, DOI 10.1111/j.1469-8986.2007.00597.x
   Poulsen AT, 2017, SCI REP-UK, V7, DOI 10.1038/srep43916
   Quitadamo LR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/14/1/011001
   Root JC, 2006, EMOTION, V6, P473, DOI 10.1037/1528-3542.6.3.473
   Rose M, 2006, CEREB CORTEX, V16, P1522, DOI 10.1093/cercor/bhj089
   Rotgans JI, 2017, CONTEMP EDUC PSYCHOL, V49, P175, DOI 10.1016/j.cedpsych.2017.02.003
   Rotgans JI, 2014, LEARN INSTR, V32, P37, DOI 10.1016/j.learninstruc.2014.01.002
   Sandkühler S, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001459
   Shen LP, 2009, EDUC TECHNOL SOC, V12, P176
   So WKY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174949
   Somers DC, 2013, WIRES COGN SCI, V4, P327, DOI 10.1002/wcs.1230
   Stern J.M., 2004, ATLAS EEG PATTERNS
   Womelsdorf T, 2007, CURR OPIN NEUROBIOL, V17, P154, DOI 10.1016/j.conb.2007.02.002
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
NR 61
TC 21
Z9 22
U1 3
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16261
EP 16281
DI 10.1007/s11042-018-7016-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500024
DA 2024-07-18
ER

PT J
AU Choudhary, N
   Bharadwaj, KK
AF Choudhary, Nirmal
   Bharadwaj, K. K.
TI Evolutionary learning approach to multi-agent negotiation for group
   recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Group recommender systems; Negotiation; Genetic
   algorithm; Multi-agent negotiation
ID CLASSIFICATION; NETWORK; IMPROVE; QUALITY
AB Recommender systems (RSs) have emerged as a solution to the information overload problem by filtering and presenting the users with information, services etc. according to their preferences. RSs research has focused on algorithms for recommending items for individual users. However, in certain domains, it may be desirable to be able to recommend items for a group of persons, e.g., movies, restaurants, etc. for which some remarkable group recommender systems (GRSs) have been developed. GRSs provide recommendations to groups, i.e., they take all individual group members' preferences into account and satisfy them optimally with a sequence of items. Taking into consideration the fact that each group member has different behaviour with respect to other members in the group, we propose a genetic algorithm (GA) based multi-agent negotiation scheme for GRS (GA-MANS-GRS) where each agent acts on behalf of one group member. The GA-MANS-GRS is modelled as many one-to-one bilateral negotiation schemes with two phases. In the negotiation phase, we have applied GA to obtain the maximum utility offer for each user and generated the most appropriate ranking for each individual in the group. For the recommendation generation phase, again GA is employed to produce the list of ratings with that minimizes the sum of distances among the preferences of the group members. Finally, the results of computational experiments are presented that establish the superiority of our proposed model over baseline GRSs techniques.
C1 [Choudhary, Nirmal; Bharadwaj, K. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Choudhary, N (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM nirmal32_scs@jnu.ac.in; kbharadwaj@gmail.com
CR Agarwal S, 2017, IEEE INT CONF VLSI, P1
   Agarwal V, 2015, WIRES DATA MIN KNOWL, V5, P113, DOI 10.1002/widm.1150
   Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Anand D, 2013, SOC NETW ANAL MIN, V3, P65, DOI 10.1007/s13278-012-0049-9
   [Anonymous], AUTON AGENT MULTIAGE
   [Anonymous], INTRO EVOLUTIONARY C
   [Anonymous], 2002, P WORKSH MOB TOUR SY
   [Anonymous], WORKSH SOC NAV COMM
   [Anonymous], EJETA
   [Anonymous], 2016, J INTELLIGENT INFORM
   [Anonymous], 2016, INT C ADV COMP DAT S
   [Anonymous], JAAMS
   Ardissono L, 2003, APPL ARTIF INTELL, V17, P687, DOI [10.1080/713827254, 10.1080/08839510390225050]
   Awal GK, 2014, APPL INTELL, V41, P627, DOI 10.1007/s10489-014-0528-y
   Baarslag T, 2016, AUTON AGENT MULTI-AG, V30, P849, DOI 10.1007/s10458-015-9309-1
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Baskin J.P., 2009, P 3 ACM C REC SYST, P337, DOI DOI 10.1145/1639714.1639782
   Beheshti R, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON FUTURE INFORMATION TECHNOLOGY AND MANAGEMENT ENGINEERING, FITME 2009, P596, DOI 10.1109/FITME.2009.154
   Bekkerman P., 2006, P WORKSH REC SYST 17, P72
   Bharadwaj K. K., 2017, WIRES DATA MINING KN, V7, P1
   Boratto L, 2015, J INTELL INF SYST, V45, P221, DOI 10.1007/s10844-014-0346-z
   Boratto L, 2010, STUD COMPUT INTELL, V324, P1
   Bosse T, 2013, AUTON AGENT MULTIAGE, P1
   de la Iglesia B, 2013, WIRES DATA MIN KNOWL, V3, P381, DOI 10.1002/widm.1106
   Del Vasto-Terrientes L, 2016, J INTELL INF SYST, V46, P313, DOI 10.1007/s10844-015-0362-7
   Frolov E, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1201
   Garcia I, 2014, EXPERT SYST APPL, V41, P1245, DOI 10.1016/j.eswa.2013.07.111
   Garcia I, 2012, INFORM SCIENCES, V189, P155, DOI 10.1016/j.ins.2011.11.037
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Jameson A., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P596
   Jameson Anthony, 2003, P IJCAI
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Jonker CM, 2007, AUTON AGENT MULTI-AG, V15, P221, DOI 10.1007/s10458-006-9009-y
   Kant V, 2012, PROCEDIA ENGINEER, V38, P939, DOI 10.1016/j.proeng.2012.06.118
   Kim JK, 2010, INT J INFORM MANAGE, V30, P212, DOI 10.1016/j.ijinfomgt.2009.09.006
   Lau RYK, 2006, INT J INTELL SYST, V21, P41, DOI 10.1002/int.20120
   Lenar M, 2007, J UNIVERS COMPUT SCI, V13, P267
   Li B, 2013, WORLD WIDE WEB, V16, P677, DOI 10.1007/s11280-012-0161-9
   Lieberman H, 1999, KNOWL-BASED SYST, V12, P427, DOI 10.1016/S0950-7051(99)00036-2
   de la Rosa JL, 2011, IEEE T IND ELECTRON, V58, P2073, DOI 10.1109/TIE.2009.2027917
   Lopez PD, 2011, BLACKW COMPANION ANT, P547
   Mandl M, 2011, J INTELL INF SYST, V37, P1, DOI 10.1007/s10844-010-0134-3
   Manouselis N, 2007, WORLD WIDE WEB, V10, P415, DOI 10.1007/s11280-007-0019-8
   Masthoff J, 2005, LECT NOTES ARTIF INT, V3538, P297
   McCarthy J. F., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P363, DOI 10.1145/289444.289511
   Meena Ritu, 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P663, DOI 10.1007/978-3-319-03844-5_65
   Nepal S, 2015, WORLD WIDE WEB, V18, P1, DOI 10.1007/s11280-013-0252-2
   Niknafs A. A., 2010, Journal of Applied Sciences, V10, P3084, DOI 10.3923/jas.2010.3084.3090
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Quijano-Sanchez L, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414433
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Vairavasundaram S, 2015, WIRES DATA MIN KNOWL, V5, P87, DOI 10.1002/widm.1149
   Villavicencio C, 2016, LECT NOTES ARTIF INT, V9662, P294, DOI 10.1007/978-3-319-39324-7_34
   Wang Y, 2015, WORLD WIDE WEB, V18, P159, DOI 10.1007/s11280-013-0241-5
   Yi HW, 2016, J INTELL INF SYST, V46, P349, DOI 10.1007/s10844-015-0375-2
   Zhang W, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 2, P354, DOI 10.1109/ISCID.2008.54
NR 56
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16221
EP 16243
DI 10.1007/s11042-018-6984-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500022
DA 2024-07-18
ER

PT J
AU Elhadad, MI
   Abd-Elnaby, M
   El-Rabaie, EM
AF Elhadad, Mohamad I.
   Abd-Elnaby, Mohammed
   El-Rabaie, El-Sayed M.
TI Optimized delay threshold scheduler for multimedia traffic over LTE
   downlink network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LTE; RRM; QoS; RT; EDD
AB Allocation of radio resources is very critical to Long Term Evolution (LTE) mobile network. Therefore, it is essential to design and implement optimum scheduling schemes to satisfy the required Quality of Service (QoS) that is vital for Real Time (RT) applications. In this paper, a new scheduling strategy for supporting both RT and Non-RT (NRT) applications is presented. The proposed scheduling scheme performs the allocation process of the available radio resources at two levels. At the first level of the scheduler, an optimized delay threshold is proposed to efficiently control Resource Blocks (RBs) allocation for video traffic. At this level, all video packets are investigated, and only users with Head of Line (HoL) packets delay greater than the optimized delay threshold will be considered for the allocation process in the next level. However, at the introduced scheduler's second level, RBs are assigned to RT packets according to HoL delays, based on an enhanced algorithm that depends on Earliest Due Date (EDD) mechanism. The behaviour of the introduced scheduling strategy is investigated and compared to the behaviour of other schedulers considered in this research. Simulation results demonstrate that the introduced two-level scheduling strategy provides the best level of quality for the supported services, especially for RT applications. It provides the lowest Packet Loss Rate (PLR) and packet delay, while achieving the highest throughput when compared to other schedulers considered in this research. In addition, the proposed two-level scheduler achieves the highest efficiency of the spectral and system capacity.
C1 [Elhadad, Mohamad I.; Abd-Elnaby, Mohammed; El-Rabaie, El-Sayed M.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Elhadad, MI (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
EM mhmd_elhdad@yahoo.com; moh_naby@yahoo.com; srabie1@yahoo.com
RI Abd-Elnaby, Mohammed/AAD-6573-2022
OI Abd-Elnaby, Mohammed/0000-0002-8217-1190; EL-Rabaie,
   El-Sayed/0000-0001-6854-5881
CR Ali S, 2012, IEEE WCNC, P1450, DOI 10.1109/WCNC.2012.6214009
   [Anonymous], 2007, Fundamentals of WiMAX: understanding broadband wireless networking
   Aryafar E, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P257
   Capozzi F, 2013, IEEE COMMUN MAG, V15, P2, DOI DOI 10.1109/SURV.2012.060912
   Chadchan S.M., 2010, International Journal of Computer and Electrical Engineering, V5, P806, DOI DOI 10.7763/IJCEE.2010.V2.249
   Chakravarthy C.Khalyana., 2010, INT J UBICOMP IJU, V1, P34
   Clark MA, 2017, IEEE T WIREL COMMUN, V16, P58, DOI 10.1109/TWC.2016.2618376
   Dahlman E., 2007, 3G Evolution: HSPA and LTE for Mobile Broadband
   Dardouri S, 2015, WIRELESS PERS COMMUN, V82, P1405, DOI 10.1007/s11277-015-2289-2
   Elhadad M, 2014, MOB COMPUT J, V3, P1
   Elhadad MI, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P9, DOI 10.1109/JEC-ECC.2016.7518956
   Elsayed KMF, 2006, WIRELESS PERS COMMUN, V38, P233, DOI 10.1007/s11277-006-9013-1
   Guo YS, 2017, IEEE T VEH TECHNOL, V66, P4133, DOI 10.1109/TVT.2016.2606644
   Halonen T., 2003, GSM, GPRS And EDGE Performance
   Hashem M, 2017, J NETW COMPUT APPL, V100, P69, DOI 10.1016/j.jnca.2017.10.020
   He HL, 2017, IEEE ACCESS, V5, P4720, DOI 10.1109/ACCESS.2016.2604822
   Hsu CC, 2017, IEEE T MOBILE COMPUT, V16, P1449, DOI 10.1109/TMC.2016.2584046
   Kakuba S, 2017, INT J DIGIT INFO WIR, V7, P75
   Karachontzitis S, 2012, INT WIREL COMMUN, P1006, DOI 10.1109/IWCMC.2012.6314343
   Khan N, 2012, IEEE WCNC, P1456, DOI 10.1109/WCNC.2012.6214010
   LABYAD Younes, 2014, INT J INNOVATIVE RES, V2, P5974
   Larmo A, 2009, IEEE COMMUN MAG, V47, P52, DOI 10.1109/MCOM.2009.4907407
   Lee YL, 2017, WIRELESS PERS COMMUN, V92, P565, DOI 10.1007/s11277-016-3557-5
   Nardini G, 2017, WIREL NETW, V23, P787, DOI 10.1007/s11276-016-1193-3
   Nnamani CO, 2016, INT J ELECTRON, V103, P1857, DOI 10.1080/00207217.2016.1138536
   Piro G, 2011, IEEE T MULTIMEDIA, V13, P1052, DOI 10.1109/TMM.2011.2152381
   Piro G, 2011, IEEE T VEH TECHNOL, V60, P498, DOI 10.1109/TVT.2010.2091660
   Rama S. Kalangiam, 2014, INT J INNOVATIVE RES, V3, P17613
   Rodriguez Demostenes Z., 2016, International Journal of Digital Information and Wireless Communications, V6, P241
   Sadiq B, 2009, EURASIP J WIREL COMM, DOI 10.1155/2009/510617
   Sindhwani N, 2017, INT J ELECTRON, V104, P1238, DOI 10.1080/00207217.2017.1293173
   Takeda K, 2011, IEEE 8 INT S WIR COM
   Talevski D, 2012, TELFOR J, V4, P1
   Wang YC, 2017, J INF SCI ENG, V33, P123
   Yaacoub E., 2012, PROC 2012 19 INT C T, V1, P1
   Yildiz Ö, 2017, INT CONF UBIQ FUTUR, P300
NR 36
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15507
EP 15525
DI 10.1007/s11042-018-6968-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700059
DA 2024-07-18
ER

PT J
AU Hajjaji, MA
   Dridi, M
   Mtibaa, A
AF Hajjaji, Mohamed Ali
   Dridi, Manel
   Mtibaa, Abdellatif
TI A medical image crypto-compression algorithm based on neural network and
   PWLCM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Medical image; Compression; Encryption;
   Chaotic system
ID ENCRYPTION SCHEME
AB In this work, we propose a novel medical image crypto-compression algorithm based on the Artificial Neural Network (ANN) and the chaotic system. The main objective of this algorithm is to improve the safety of medical images and to preserve the information they contain. First, ANN was used to compress the image. Then, the Arnold cat map was used to shuffle the weight matrix and Piecewice linear chaotic map (PWLCM) to modify the value of the hidden layer. The proposed algorithm was applied on medical images, of different types, such as MRI, Echographic and Radiographic images, coded on 8 bits/pixel and 12 bits/pixel. The proposed algorithm was validated over two steps. The first step was destined to show the robustness and feasibility of the encryption algorithm. Thus, several tests were carried on such as the Key space and sensitivity analysis, statistical attacks, differential analysis and the NIST statistical tests. The second step was destined to validate the compression process. In this case two main types of evaluation were applied. The first one was applied to control the robustness, through the study of the influence of the size of the sub-blocks to compress. The second was used to evaluate the quality of uncompressed images through PSNR, UIQ, SNR and Correlation factor. Experimental results, confirm the performance and the efficiency of the proposed algorithm in terms of the security and the quality of the uncompressed images.
C1 [Hajjaji, Mohamed Ali; Dridi, Manel; Mtibaa, Abdellatif] Univ Monastir, Elect & Microelect Lab E E, Monastir, Tunisia.
   [Hajjaji, Mohamed Ali] Univ Kairouan, Higher Inst Appl Sci & Technol Kasserine, Kairouan, Tunisia.
C3 Universite de Monastir; Universite de Kairouan
RP Hajjaji, MA (corresponding author), Univ Monastir, Elect & Microelect Lab E E, Monastir, Tunisia.; Hajjaji, MA (corresponding author), Univ Kairouan, Higher Inst Appl Sci & Technol Kasserine, Kairouan, Tunisia.
EM these.dijon@gmail.com
RI Ali, HAJJAJI Mohamed/AAQ-2344-2021; Hajjaji, mohamed/JOK-1304-2023;
   Mohamed Ali, HAJJAJI/GNM-8164-2022
OI Ali, HAJJAJI Mohamed/0000-0002-6372-2831; Hajjaji,
   mohamed/0000-0003-4317-6308; MTIBAA, Abdellatif/0000-0001-5180-9975
CR Abdmouleh MK, 2017, PROCEDIA COMPUT SCI, V112, P369, DOI 10.1016/j.procs.2017.08.026
   Al-Husainy MAF, 2012, INT J SEC ITS APPL, V6
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2012, INT J TELEMEDICINE A
   Borie J. C., 2004, MEDSIP 04 2 MED IMAG, P327
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dridi M, 2016, IET IMAGE PROCESS, V10, P830, DOI 10.1049/iet-ipr.2015.0868
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   ElZorkany M, 2014, ADV INTELLIGENT SYST, V233
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Liu H, 2012, PROCEEDINGS OF THE 2012 SECOND INTERNATIONAL CONFERENCE ON INSTRUMENTATION & MEASUREMENT, COMPUTER, COMMUNICATION AND CONTROL (IMCCC 2012), P1457, DOI 10.1109/IMCCC.2012.341
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Manimurugan S, 2011, SECURE MED IMAGE COM
   Masmoudi A, 2014, IET IMAGE PROCESS, V8, P671, DOI 10.1049/iet-ipr.2013.0598
   Meng XM, 2015, INFORM PROCESS LETT, V115, P858, DOI 10.1016/j.ipl.2015.06.013
   Rao PV, 2010, C MACH LEARN COMP IC, P100
   Seiert U, 2014, NEUROCOMPUTING, V125, P229
   Singh YS, 2012, PROCEEDINGS OF THE 2012 WORLD CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGIES, P976, DOI 10.1109/WICT.2012.6409216
   Soleymani A, 2014, SCI WORLD J, DOI 10.1155/2014/536930
   Uhl A., 2005, ADV INFORM SECURITY, V15, P31
   Xiao D, 2008, PHYS LETT A, V372, P4682, DOI 10.1016/j.physleta.2008.04.060
   Yeo W. K., 2011, 2011 6th International Conference on Broadband and Biomedical Communications (IB2Com), P39, DOI 10.1109/IB2Com.2011.6217939
   Zhang L, 2015, MED IMAGE ENCRYPTION
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou R, 2014, IOP CONF SER-MAT SCI, V62, DOI 10.1088/1757-899X/62/1/012015
   Zhu H, 2013, SIGNAL PROCESS-IMAGE, V28
NR 28
TC 25
Z9 25
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14379
EP 14396
DI 10.1007/s11042-018-6795-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700012
DA 2024-07-18
ER

PT J
AU Rana, S
   Sur, A
AF Rana, Shuvendu
   Sur, Arijit
TI View invariant DIBR-3D image watermarking using DT-CWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D image watermarking; View invariant watermarking; DT-CWT; DIBR
ID QUALITY
AB In 3D image compression, depth image based rendering (DIBR) is one of the latest techniques where the center image (say the main view, is used to synthesise the left and the right view image) and the depth image are communicated to the receiver side. It has been observed in the literature that most of the existing 3D image watermarking schemes are not resilient to the view synthesis process used in the DIBR technique. In this paper, a 3D image watermarking scheme is proposed which is invariant to the DIBR view synthesis process. In this proposed scheme, 2D-dual-tree complex wavelet transform (2D-DT-CWT) coefficients of centre view are used for watermark embedding such that shift invariance and directional property of the DT-CWT can be exploited to make the scheme robust against view synthesis process. A comprehensive set of experiments has been carried out to justify the robustness of the proposed scheme over the related existing schemes with respect to the JPEG compression and synthesis view attack.
C1 [Rana, Shuvendu] Univ Strathclyde, Elect & Elect Engn, Glasgow G1 1XQ, Lanark, Scotland.
   [Rana, Shuvendu; Sur, Arijit] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 University of Strathclyde; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Rana, S (corresponding author), Univ Strathclyde, Elect & Elect Engn, Glasgow G1 1XQ, Lanark, Scotland.; Rana, S (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM shuvendu@iitg.ernet.in; arijit@iitg.ernet.in
RI Sur, Arijit/AAB-4216-2020; Rana, Shuvendu/ACC-7002-2022
OI Rana, Shuvendu/0000-0002-8372-5669
CR Anderson R, 2005, LECT NOTES COMPUT SC, V3656, P490, DOI 10.1007/11559573_61
   [Anonymous], 23 EUR SIGN PROC C E
   [Anonymous], 2013, INT C COMP COMM NETW
   [Anonymous], 2004, DEPTH IMAGE BASED RE
   Asikuzzaman M, 2014, IEEE IMAGE PROC, P5497, DOI 10.1109/ICIP.2014.7026112
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Chen Y, 2014, JCT3VH1003 ISOIEC JT
   De Silva V, 2011, IEEE T MULTIMEDIA, V13, P498, DOI 10.1109/TMM.2011.2129500
   Egiazarian K., 2006, proceedings of the second international workshop on video processing and quality metrics, P4
   Fan SL, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P549, DOI 10.1109/CIS.2012.129
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Franco-Contreras J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2761, DOI 10.1109/ICIP.2011.6116242
   Guan Y, 2014, I C CONT AUTOMAT ROB, P346, DOI 10.1109/ICARCV.2014.7064330
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Han YM, 2005, IEEE T CIRC SYST VID, V15, P269, DOI 10.1109/TCSVT.2004.841541
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Jaipuria Smita Jagdishprasad, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P181, DOI 10.1109/ICCSP.2014.6949824
   Kim H, 2015, IEEE T MULTIMEDIA, V17, P2198, DOI 10.1109/TMM.2015.2493367
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kingsbury N. G., 1998, IEEE DIG SIGN PROC W, P319
   Korus P, 2015, IEEE T MULTIMEDIA, V17, P157, DOI 10.1109/TMM.2014.2368696
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   Patterson R, 2007, J SOC INF DISPLAY, V15, P861, DOI 10.1889/1.2812986
   Rana S, 2014, P 9 INDIAN C COMPUTE, DOI [10.1145/2683483.2683535, DOI 10.1145/2683483.2683535]
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Trick D, 2013, IEEE INT WORKSH MULT, P418, DOI 10.1109/MMSP.2013.6659325
   Valizadeh Sima, 2016, 2016 IEEE International Conference on Consumer Electronics (ICCE), P347, DOI 10.1109/ICCE.2016.7430642
   Valizadeh S, 2018, MULTIMED TOOLS APPL, V77, P22985, DOI 10.1007/s11042-017-5486-z
   Vinod P., 2006, IEE Proceedings-Information Security, V153, P61, DOI 10.1049/ip-ifs:20055088
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Yonggang Fu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P437, DOI 10.1109/FSKD.2009.19
   Yu-Cheng Fan, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P325
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 36
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16665
EP 16693
DI 10.1007/s11042-018-7024-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500042
OA hybrid
DA 2024-07-18
ER

PT J
AU Sasikala, N
   Kishore, PVV
   Kumar, DA
   Prasad, CR
AF Sasikala, N.
   Kishore, P. V. V.
   Kumar, D. Anil
   Prasad, Ch. Raghava
TI Localized region based active contours with a weakly supervised shape
   image for inhomogeneous video segmentation of train bogie parts in
   building an automated train rolling examination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action contours; Localized regions; Shape priors; Train rolling stock;
   High speed video segmentation
ID MODEL
AB Active Contours have been widely acknowledged for providing a dependable solution to complex image segmentation problems which are represented as a functional optimization problem. Inhomogeneous image intensity regions present difficulties for the evolving curve, which are driven by nonlinear variations in a region's intensity pixels. The problem was approached using the local region's statistical information for improving the segmentation accuracies. However, the local information of the region was calculated using the inhomogeneous pixel intensities, which in turn degrade the segmentation outputs. In this paper, we approach this problem by introducing a weakly supervised shape image (WSSI), which form a pre-defied shape term within a local window and a local region difference term to improve the segmentation results. The proposed model is robust to image intensity variations and are computationally efficient on high-resolution images. To test and validate the proposed active contour model, we choose a real-time application, Automated Rolling Stock Examination using computer vision. The problem here is to extract the bogie parts using the proposed method to monitor their conditional health on a moving train from the captured high speed video sequence. We have created the bogie dataset with five trains at different time zones using a 240fps sports action camera in full HD mode. We apply our proposed method on these video frames to segment 10 vital parts of the train bogie on a 10000-frame video sequence per train. The proposed method has been compared with similar state-of-the-art localized region based active contour methods for segmentation accuracy.
C1 [Sasikala, N.; Kishore, P. V. V.; Kumar, D. Anil; Prasad, Ch. Raghava] Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Biomech & Vis Comp Res Ctr, Green Fields, Vaddeswaram, Andhra Prades, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Sasikala, N (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Biomech & Vis Comp Res Ctr, Green Fields, Vaddeswaram, Andhra Prades, India.
EM sasikala.nellutla@gmail.com; pvvkishore@kluniversity.in;
   danilmurali@kluniversity.in; chrp@kluniversity.in
RI D, Anil Kumar/AAY-6919-2020; prasad, raghava ch/U-5280-2018; Kishore,
   P.V.V./R-3293-2017
OI D, Anil Kumar/0000-0002-6051-2169; prasad, raghava
   ch/0000-0001-6479-4207; Kishore, P.V.V./0000-0002-3247-3043
CR Ali H, 2016, PATTERN RECOGN, V51, P27, DOI 10.1016/j.patcog.2015.08.022
   [Anonymous], P 8 WORLD C RAILW RE
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   Blake A.Isard., 2012, Active Contours: The Application of Techniques from Graphics, Vision, Control Theory and Statistics to Visual Tracking of Shapes in Motion
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T, 2005, 2005 IEEE COMP SOC C, DOI [10.1109/cvpr.2005.212, DOI 10.1109/CVPR.2005.212]
   Chan T. F., 2005, Image processing and analysis: variational, PDE, wavelet, and stochastic methods, V94
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z
   Freid Benjamin, 2007, P 9 INT HEAV HAUL C, P11
   Hoogi A, 2017, IEEE T MED IMAGING, V36, P781, DOI 10.1109/TMI.2016.2628084
   Jarzebowicz L, 2014, APPLIED ELECTRONICS, P139, DOI 10.1109/AE.2014.7011686
   Jehan-Besson S., 2003, IEEE International Conference on Computer Vision, V1, P408, DOI [DOI 10.1109/ICCV.2003.1238375, 10.1109/iccv.2003.1238375]
   Kazanskiy N. L., 2015, Pattern Recognition and Image Analysis, V25, P215, DOI 10.1134/S1054661815020133
   Kim H, 2011, IEEE T INSTRUM MEAS, V60, P2835, DOI 10.1109/TIM.2011.2119110
   Kishore PVV, 2017, OPTIK, V132, P427, DOI 10.1016/j.ijleo.2016.12.060
   Kumar EK, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2018.2817179
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Luo SY, 2018, IEEE T IMAGE PROCESS, V27, P2560, DOI 10.1109/TIP.2018.2806201
   Morel J.-M., 2012, Variational Methods in Image Segmentation: With Seven Image Processing Experiments, V14
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Plueimpitiwiriyawej C, 2005, IEEE T MED IMAGING, V24, P593, DOI 10.1109/TMI.2005.843740
   Prasad C.R., 2015, INT REV COMPUTERS SO, V10, P1233
   Riaz F, 2019, IEEE J BIOMED HEALTH, V23, P489, DOI 10.1109/JBHI.2018.2832455
   Saito A, 2016, MED IMAGE ANAL, V28, P46, DOI 10.1016/j.media.2015.11.003
   Sanchez-Revuelta A. L., 1998, Patent No. [5808906A, 5808906]
   Sasikala N, 2020, J KING SAUD UNIV-COM, V32, P608, DOI 10.1016/j.jksuci.2017.10.001
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Vese LA., 2016, Variational methods in image processing, DOI DOI 10.1201/B19554
   Wang H, 2016, NEUROCOMPUTING, V205, P130, DOI 10.1016/j.neucom.2016.03.050
   Wang L, 2017, INFORM SCIENCES, V418, P61, DOI 10.1016/j.ins.2017.06.042
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yang T, 2018, SIGNAL IMAGE VIDEO P, V12, P951, DOI 10.1007/s11760-018-1239-3
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang Y, 2017, OPTIK, V131, P749, DOI 10.1016/j.ijleo.2016.11.194
NR 37
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14917
EP 14946
DI 10.1007/s11042-018-6896-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700035
DA 2024-07-18
ER

PT J
AU Tang, GC
   Liang, RY
   Xie, Y
   Bao, YQ
   Wang, SJ
AF Tang, Guichen
   Liang, Ruiyu
   Xie, Yue
   Bao, Yongqiang
   Wang, Shijia
TI Improved Convolutional Neural Networks for Acoustic Event Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Acoustic event classification;
   Mel-spectrogram; Deep learning
AB To further exploit the potential performance of convolutional neural networks in acoustic event classification, an improved convolutional neural network called AecNet (Acoustic event classification net) is proposed. For traditional convolutional neural network lacks the representation of low-level features, the proposed model includes more feature layers to reserve the information of low-level and high-level features of the input. In order to extract the features of different level effectively, 1x1 convolutions are adopted to compress the feature maps of all convolutional layers except the top convolutional layer. Then the condensed features are concatenated into one layer, which contains all features in different levels. So, the feature learning is enhanced and multi-scale convolutional neural network is constructed. In order to extract the dynamic features of the sound clip better, multi-channels spectrogram features comprised of mel-spectrogram, its first order delta along frequency and time, second order delta along frequency and time are adopted. In experiment, point of FFT, number of mel-bands and type of mel-spectrogram deltas are detailedly discussed and reasonable choice are suggested in practice. Experiments results on datasets ESC-10, ESC-50 and DCASE show that the proposed method yields improvements of recognition accuracy in various degrees compared with some state-of-art results on standard benchmark.
C1 [Tang, Guichen; Liang, Ruiyu; Bao, Yongqiang] Nanjing Inst Technol, Sch Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.
   [Liang, Ruiyu; Xie, Yue; Wang, Shijia] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing Institute of Technology; Southeast University - China
RP Liang, RY (corresponding author), Nanjing Inst Technol, Sch Commun Engn, Nanjing 211167, Jiangsu, Peoples R China.; Liang, RY (corresponding author), Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM lly1711@163.com
FU National Natural Science Foundation of China [61871213]; Six Talent
   Peaks Project in Jiangsu Province [2016-DZXX-023]; China Postdoctoral
   Science Foundation [2016M601696]; Qing Lan Project of Jiangsu Province;
   Jiangsu Planned Projects for Postdoctoral Research Funds [1601011B]
FX The work was supported by the National Natural Science Foundation of
   China under Grant No. 61871213, Six Talent Peaks Project in Jiangsu
   Province under Grant No. 2016-DZXX-023, China Postdoctoral Science
   Foundation funded project under Grant No. 2016M601696, Qing Lan Project
   of Jiangsu Province, Jiangsu Planned Projects for Postdoctoral Research
   Funds under Grant No. 1601011B.
CR [Anonymous], 29 IEEE C COMP VIS P
   [Anonymous], 2011, 2011 INT JOINT C NEU
   [Anonymous], P DET CLASS AC SCEN
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], ARXIV14107455V3
   [Anonymous], 2016, ARXIV160407160
   [Anonymous], 12 INT C COMP VIS IC
   [Anonymous], 2016, PROF DCASE
   [Anonymous], 23 ACM INT C MULT MM
   [Anonymous], 2016, P 24 ACM INT C MULTI
   [Anonymous], 2013, 30 INT C MACH LEARN
   [Anonymous], 2016, ARXIV161009001
   [Anonymous], 2016, ARXIV160702383
   [Anonymous], 2017, 2017 IEEE INT C AC S
   [Anonymous], P DET CLASS AC SCEN
   [Anonymous], INTERSPEECH 2008 9 A
   [Anonymous], 40 IEEE INT C AC SPE
   [Anonymous], 2014 ACM C MULT MM 2
   [Anonymous], INT JOINT C NEUR NET
   [Anonymous], 22 EUR SIGN PROC C E
   [Anonymous], 2015 IEEE 25 INT WOR
   [Anonymous], P DET CLASS AC SCEN
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   Phan H, 2015, IEEE-ACM T AUDIO SPE, V23, P20, DOI 10.1109/TASLP.2014.2367814
   Kim HG, 2017, ETRI J, V39, P832, DOI 10.4218/etrij.17.0117.0157
   Kingma D. P., 2014, arXiv
   Lin M., 2013, P 2 INT C LEARNING R
   McLoughlin I, 2015, IEEE-ACM T AUDIO SPE, V23, P540, DOI 10.1109/TASLP.2015.2389618
   Mesaros A, 2018, IEEE-ACM T AUDIO SPE, V26, P379, DOI 10.1109/TASLP.2017.2778423
   Mikolov T., 2015, 3 INT C LEARN REPR I
   Radford A., 2015, ARXIV151106434
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Xu Y, 2017, IEEE-ACM T AUDIO SPE, V25, P1230, DOI 10.1109/TASLP.2017.2690563
NR 36
TC 14
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15801
EP 15816
DI 10.1007/s11042-018-6991-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500004
DA 2024-07-18
ER

PT J
AU Yan, LY
   Lu, HL
   Wang, CZ
   Ye, ZW
   Chen, HW
   Ling, HF
AF Yan, Lingyu
   Lu, Hanlin
   Wang, Chunzhi
   Ye, Zhiwei
   Chen, Hongwei
   Ling, Hefei
TI Deep linear discriminant analysis hashing for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Hashing; Deep network; Image
   fingerprinting
ID QUANTIZATION
AB Currently, due to the exponential growth of online images, it is necessary to consider image retrieval among large number of images, which is very time-consuming and unscalable. Although many hashing methods has been proposed, they did not show excellent performance in decreasing semantic loss during the process of hashing. In this paper, we propose a novel Deep Linear Discriminant Analysis Hashing(DLDAH) algorithm, which consists of Hash label generation stage and Deep hash model construction stage. In hash label generation stage, using extract image features, we construct an objective function based on Linear Discriminant Analysis(LDA), and minimize it to map image features into hash labels. In deep hash model construction stage, we use the generated hash labels to train a simple deep learning network for image hashing and get discriminative hash codes corresponding to training images. Then the deep hash model is used to map a new image feature into hash code for fast image retrieval. The scheme obtain a deep hash model which obtains deep semantic information without using network with a lot of layers, simplifying the process of mapping new images into hash codes. Experimental results show that our approach significantly outperforms state-of-art methods.
C1 [Yan, Lingyu; Lu, Hanlin; Wang, Chunzhi; Ye, Zhiwei; Chen, Hongwei] Hubei Univ Technol, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Hubei University of Technology; Huazhong University of Science &
   Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
EM yanlingyu@hbut.edu.cn; hanlinglu@163.com; chunzhiwang@vip.163.com;
   weizhiye121@163.com; chw2001@sina.com; hefei_ing@hust.edu.cn
FU National Natural Science Foundation of China [61502155, 61772180,
   U1536203, 61602161]; National key research and development program of
   China [2016QY01W0200]; Natural Science Foundation of Hubei University of
   Technology [BSQD15029, BSQD15028]
FX Thanks for the funding supported by the National Natural Science
   Foundation of China (No. 61502155, No. 61772180, No. U1536203, No.
   61602161), National key research and development program of China
   (2016QY01W0200), Natural Science Foundation of Hubei University of
   Technology (No. BSQD15029, No. BSQD15028).
CR [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2009, NIPS
   Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Norouzi M.E., 2011, ICML
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
NR 35
TC 10
Z9 10
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15101
EP 15119
DI 10.1007/s11042-018-6855-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700043
DA 2024-07-18
ER

PT J
AU Yang, LY
   Dong, YN
   Tian, W
   Wang, ZJ
AF Yang, Ling-Yun
   Dong, Yu-Ning
   Tian, Wei
   Wang, Zai-Jian
TI The study of new features for video traffic classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video feature; Traffic classification; Probability distribution; Feature
   mining
ID FEATURE-SELECTION
AB Network traffic classification is important for the management of network resource and the support quality of multimedia services. To realize the fine-grained classification of typical Internet video traffic, this paper studies and analyses the characteristics of video flow change in transmission process and the statistic characteristics of its main protocol data. According to different service models from the network services and the users' demand of video quality, we propose two new sets of features for video traffic classification, including: downlink rate probability distribution model and main protocol data statistics. The experimental results show that the two sets of features can improve the performance of classification compared to existing methods.
C1 [Yang, Ling-Yun; Dong, Yu-Ning; Tian, Wei] Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
   [Yang, Ling-Yun; Wang, Zai-Jian] Anhui Normal Univ, Coll Phys & Elect Informat, Wuhu 241000, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Anhui Normal
   University
RP Yang, LY (corresponding author), Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.; Yang, LY (corresponding author), Anhui Normal Univ, Coll Phys & Elect Informat, Wuhu 241000, Peoples R China.
EM lingyun716@126.com; dongyn@njust.edu.cn; tianw@njupt.edu.cn;
   wangzaijian@ustc.edu
RI Dong, Yuning/AAW-6970-2020
OI Dong, Yuning/0000-0003-4898-331X
FU National Natural Science Foundation of China [61271233, 61401004,
   61601005]; Ph.D Programs Foundation of Anhui Normal university
   [2016XJJ129]; Plan of introduction and cultivation of university leading
   talents in Anhui [gxfxZD2016013]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61271233, 61401004, 61601005), the Ph.D
   Programs Foundation of Anhui Normal university (No. 2016XJJ129), Plan of
   introduction and cultivation of university leading talents in Anhui
   (No.gxfxZD2016013).
CR Amaral P., 2016, 2016 IEEE 24th International conference on network protocols (ICNP), P1
   [Anonymous], 2012, PARAMETRIC NONINTRUS
   Bai J, 2015, NEUROCOMPUTING, V165, P280, DOI 10.1016/j.neucom.2015.03.017
   Bolón-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042
   Cai W, 2016, CHIN CONT DECIS CONF, P2126, DOI 10.1109/CCDC.2016.7531336
   Deng ZY, 2016, NEUROCOMPUTING, V195, P143, DOI 10.1016/j.neucom.2015.08.112
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Dong YN, 2017, NOVEL FEATURE SELECT
   Dong YN, 2016, P IEEE COMM, P580
   Dong YN, 2017, COMPUT NETW, V119, P102, DOI 10.1016/j.comnet.2017.03.019
   Dong YN, 2015, ASIA-PAC CONF COMMUN, P580, DOI 10.1109/APCC.2015.7412578
   Dubin R, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P213, DOI 10.1109/DMIAF.2016.7574935
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Liu MY, 2017, MOBILE NETW APPL, V22, P418, DOI 10.1007/s11036-016-0797-2
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Manek AS, 2017, WORLD WIDE WEB, V20, P135, DOI 10.1007/s11280-015-0381-x
   Miao Y, 2017, P IEEE INT C COMP IN, P4181
   Raveendran R, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P225, DOI 10.1109/SAPIENCE.2016.7684123
   Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082
   Thay C., 2015, P 2015 COMP SCI ENG, P1, DOI DOI 10.1109/ICSEC.2015.7401433
   Tseng CM, 2016, IEEE/SICE I S SYS IN, P174, DOI 10.1109/SII.2016.7843994
   Valenti S, 2013, Reviewing traffic classification. Data traffic monitoring and analysis from measurement, classification, and anomaly detection to quality of experience
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Wang LY, 2016, NEUROCOMPUTING, V174, P278, DOI 10.1016/j.neucom.2015.03.114
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Yamansavascilar B, 2016, INT CONF COMPUT NETW, P843
   Yang XD, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P978, DOI 10.1145/2964284.2964297
   Zhang J, 2013, IEEE T PARALL DISTR, V24, P104, DOI 10.1109/TPDS.2012.98
   Zhu X, 2016, P COMP VIS PATT REC, P4141
NR 30
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15839
EP 15859
DI 10.1007/s11042-018-6965-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500006
DA 2024-07-18
ER

PT J
AU Zaatour, R
   Bouzidi, S
   Zagrouba, E
AF Zaatour, Rania
   Bouzidi, Sonia
   Zagrouba, Ezzeddine
TI Class-adapted local fisher discriminant analysis to reduce
   highly-dimensioned data on commodity hardware: application to
   hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local fisher discriminant analysis; Dimensionality reduction; Feature
   extraction; Commodity hardware; Python; Hyperspectral image
   classification
ID PYTHON
AB Local Fisher Discriminant Analysis (LFDA) is a supervised feature extraction technique that proved to be efficient in reducing several types of data. However, it depends on the number of samples per class in a way that can lead, when classes are too large, to a consumption of all the memory of a commodity hardware, or to a disability to even run. To work around this limit, we hereby propose to introduce a parameter that adapts LFDA to the data's classes while accounting for the available resources on the used machine. In fact, according to this parameter, LFDA will consider a larger class as a set of smaller sub-classes and will process these latter instead of the larger one. We are calling our proposed optimization the class-adapted LFDA, noted caLFDA. We also propose a Python implementation of LFDA and prove it more effective than the existent MATLAB implementation. To assess the efficiency of caLFDA, we applied it to reduce several hyperspectral images and compared the results of classifying the reduced images to the ones we get when using the original LFDA to reduce the data. When the hyperspectral images are too large for LFDA to be able to reduce them, we compare caLFDA's results to the ones we get with the most commonly used Principle Component Analysis (PCA).
C1 [Zaatour, Rania; Bouzidi, Sonia; Zagrouba, Ezzeddine] Univ Tunis El Manar, Inst Super Informat El Manar, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Raihane Bayrouni, Lariana 2080, Tunisia.
C3 Universite de Tunis-El-Manar
RP Zaatour, R (corresponding author), Univ Tunis El Manar, Inst Super Informat El Manar, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Raihane Bayrouni, Lariana 2080, Tunisia.
EM rania.zaatour@fst.utm.tn
RI Zaatour, Rania/AAA-5937-2019; Zagrouba, Ezzeddine/D-7896-2014; Bouzidi,
   Sonia/AAJ-7915-2020
OI Zaatour, Rania/0000-0002-8581-3718; Zagrouba,
   Ezzeddine/0000-0002-2574-9080; Bouzidi, Sonia/0000-0002-8519-6369
CR [Anonymous], 2018, MATLAB
   [Anonymous], 2006, Guide to NumPy
   Carbonnelle P., 2018, PYPL POPULARITY PROG
   Cass Stephen, 2017, IEEE SPECTRUM 2017 T
   Chen HL, 2011, EXPERT SYST APPL, V38, P11796, DOI 10.1016/j.eswa.2011.03.066
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Fangohr H, 2004, LECT NOTES COMPUT SC, V3039, P1210
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   He XF, 2004, ADV NEUR IN, V16, P153
   Huang H, 2012, FUTURE GENER COMP SY, V28, P244, DOI 10.1016/j.future.2010.11.005
   Jinyu Guo, 2014, Journal of Software, V9, P287, DOI 10.4304/jsw.9.2.287-292
   Li W, 2014, IEEE GEOSCI REMOTE S, V11, P153, DOI 10.1109/LGRS.2013.2250905
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Liu ZH, 2012, INT J BIOMETRICS, V4, P338
   Millman KJ, 2011, COMPUT SCI ENG, V13, P9, DOI 10.1109/MCSE.2011.36
   O'Grady S, 2018, REDMONK PROGRAMMING
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Shen P, 2016, INT CONF ACOUST SPEE, P5825, DOI 10.1109/ICASSP.2016.7472794
   Shiqing Zhang, 2012, WSEAS Transactions on Signal Processing, V8, P21
   Song BQ, 2014, IEEE T GEOSCI REMOTE, V52, P5122, DOI 10.1109/TGRS.2013.2286953
   Sugiyama M, 2008, LECT NOTES ARTIF INT, V5012, P333, DOI 10.1007/978-3-540-68125-0_30
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Sugiyama M, 2009, IEICE T INF SYST, VE92D, P1204, DOI 10.1587/transinf.E92.D.1204
   Wu ZB, 2016, IEEE J-STARS, V9, P2270, DOI 10.1109/JSTARS.2016.2542193
   Yu J, 2011, AICHE J, V57, P1817, DOI 10.1002/aic.12392
   Zaatour R, 2018, LECT NOTES COMPUT SC, V11182, P245, DOI 10.1007/978-3-030-01449-0_21
   Zaatour R, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P579, DOI 10.5220/0006171305790586
   Zhang SQ, 2011, COMM COM INF SC, V214, P443
   Zhang SQ, 2010, INT CONF SIGN PROCES, P538, DOI 10.1109/ICOSP.2010.5656091
NR 31
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17113
EP 17134
DI 10.1007/s11042-018-6887-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500062
DA 2024-07-18
ER

PT J
AU Bakkouri, I
   Afdel, K
AF Bakkouri, Ibtissam
   Afdel, Karim
TI Multi-scale CNN based on region proposals for efficient breast
   abnormality recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Pattern recognition; Convolutional neural network (CNN);
   Multi-scale analysis
ID COMPUTER-AIDED DIAGNOSIS; DEEP; CLASSIFICATION; MASSES; FUZZY
AB Mammographic pattern recognition is one of the most essential tasks in breast cancer diagnosis, and has been studied for several years now to make it suitable and faster. In this paper, we developed a novel deep Convolutional Neural Network (CNN) approach to discriminate normal from abnormal breast tissues using Gaussian pyramid representation for multi-scale analysis (Pyramid-CNN). In order to improve image processing time, we extracted representative region proposals from each mammogram using determinant of the Hessian operator. To improve performance of our model and avoid overfitting, data augmentation techniques based on geometric transformation and sub-histogram equalization were applied on all regions to increase the variance of significant mammographic samples. We evaluated our methodology on the publicly available mammography dataset such as Breast Cancer Digital Repository (BCDR) database. In comparison with the current state-of-the-art methods, the experiments show that our proposed system provides efficient results, achieving the average accuracy of 96.84%, sensitivity of 92.12%, specificity of 98.02%, precision of 92.15%, F1-score of 92.12%, and area under the receiver operating characteristic curve (AUC) of 96.76%. Hence, the study demonstrates that our proposed approach has the potential to significantly improve the conventional recognition and classification strategies for use in advanced clinical application and practice or in general, biomedical imaging field.
C1 [Bakkouri, Ibtissam; Afdel, Karim] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Bakkouri, I (corresponding author), Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
EM ibtissam.bakkouri@gmail.com
RI Bakkouri, Ibtissam/Z-1275-2018; Karim, AFDEL/AAC-7992-2019
OI Bakkouri, Ibtissam/0000-0003-4827-9007; Karim, AFDEL/0000-0002-0828-2116
CR ABEYRATNE U R, 1991, Brain Topography, V4, P3, DOI 10.1007/BF01129661
   Aminikhanghahi S, 2017, MULTIMED TOOLS APPL, V76, P10191, DOI 10.1007/s11042-016-3605-x
   Aslan F, 2018, INT OPHTHALMOL, V38, P2005, DOI 10.1007/s10792-017-0691-3
   Bakkouri I, 2017, 2017 INT C ADV TECHN, P1, DOI 10.1109/ATSIP.2017.8075562
   Bodai Balazs I, 2015, Perm J, V19, P48, DOI 10.7812/TPP/14-241
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Carney PA, 2004, MED DECIS MAKING, V24, P255, DOI 10.1177/0272989X04265480
   Chen SX, 2013, ULTRAMICROSCOPY, V135, P24, DOI 10.1016/j.ultramic.2013.06.004
   Chen W, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20140016
   Choromanska A, 2015, JMLR WORKSH CONF PRO, V38, P192
   Coates A, 2013, PROC INT C MACH LEAR, P1337
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Diz J, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0561-y
   Dobruch-Sobczak K, 2012, J ULTRASON, V12, P402, DOI 10.15557/JoU.2012.0029
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Hepsag PU, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P418, DOI 10.1109/UBMK.2017.8093429
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jia Li, 2012, Advances in Neural Networks - ISNN 2012. Proceedings 9th International Symposium on Neural Networks, P110, DOI 10.1007/978-3-642-31362-2_13
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Keller BM, 2015, J MED IMAGING, V2, DOI 10.1117/1.JMI.2.2.024501
   Kumar I, 2017, MULTIMED TOOLS APPL, V76, P18789, DOI 10.1007/s11042-016-4340-z
   Lan Z, 2015, IEEE C COMP VIS PATT, DOI [10. 1109/cvpr. 2015. 7298616, DOI 10.1109/CVPR.2015.7298616]
   Laroum S, 2010, LECT NOTES COMPUT SC, V6023, P134, DOI 10.1007/978-3-642-12211-8_12
   Laserson J., 2011, ACM Crossroads, V18, P29
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JG, 2017, KOREAN J RADIOL, V18, P570, DOI 10.3348/kjr.2017.18.4.570
   Levy D, 2016, NIPS 2016 ML4HC WORK
   López M, 2012, TRANS-REV LITT GEN C, V14, DOI 10.4000/trans.575
   Malar E, 2013, LECT NOTES COMPUT SC, V8298, P658, DOI 10.1007/978-3-319-03756-1_59
   Martins LDO, 2007, LECT NOTES ARTIF INT, V4571, P784
   Moura DC, 2013, INT J COMPUT ASS RAD, V8, P561, DOI 10.1007/s11548-013-0838-2
   Mousa R, 2005, EXPERT SYST APPL, V28, P713, DOI 10.1016/j.eswa.2004.12.028
   Narvaez Fabian, 2012, Breast Imaging. Proceedings 11th International Workshop, IWDM 2012, P64, DOI 10.1007/978-3-642-31271-7_9
   Palma G, 2014, PATTERN RECOGN, V47, P2467, DOI 10.1016/j.patcog.2014.01.009
   Perez N., 2014, Proceedings of the 2014 Federated Conference on Computer Science and Information Systems, P209, DOI DOI 10.15439/2014F249
   Petrick N, 2013, MED PHYS, V40, DOI 10.1118/1.4816310
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodríguez-López V, 2014, LECT NOTES ARTIF INT, V8857, P474, DOI 10.1007/978-3-319-13650-9_41
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sharma K, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2743, DOI 10.1109/ICACCI.2016.7732477
   Sharma S, 2015, J DIGIT IMAGING, V28, P77, DOI 10.1007/s10278-014-9719-7
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suzuki S, 2016, 55 ANN C SOC INSTR C, DOI [10. 1109/sice. 2016. 7749265, DOI 10.1109/SICE.2016.7749265]
   Tsochatzidis L, 2017, PATTERN RECOGN, V71, P106, DOI 10.1016/j.patcog.2017.05.023
   Wu S., 2013, COMP MATH MATH PHYS, P1, DOI DOI 10.1155/2013/3
   Xu XP, 2014, COMM COM INF SC, V483, P72
   Yoon Hyunsup., 2009, INT J ELECT COMPUTER, V3, P189
NR 52
TC 17
Z9 17
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12939
EP 12960
DI 10.1007/s11042-018-6267-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900013
DA 2024-07-18
ER

PT J
AU Chen, L
   Zhao, JY
AF Chen, Lei
   Zhao, Jiying
TI Perceptual quality assessment of stereoscopic images based on local and
   global visual characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality assessment; Stereoscopic images; Local amplitude and phase;
   Global structure change
ID NATURAL IMAGES; WATERMARKING; INFORMATION; STATISTICS
AB The quality assessment of stereoscopic images has attracted considerable attention and become an important issue in 3D multimedia applications. The 3D image quality assessment (IQA) encounters many challenges and simple extension of the 2D quality metrics to the 3D case is not satisfying. In this paper, we propose a new perceptual quality assessment scheme for stereoscopic 3D images by considering the local and global visual characteristics. The design of this scheme is motivated by studies on the perception of distorted stereoscopic images. To be more specific, after the log-Gabor filter processing, the local amplitude and phase from the left and right views of the reference and distorted 3D images are utilized as features in local quality evaluation. Meanwhile, the global structure changes of the left and right views are also incorporated into the final quality pooling. The overall 3D quality score is obtained by combining the local and global quality indexes together. The effectiveness of the designed metric is verified on publicly available 3D image quality assessment databases. Experimental results show that the proposed scheme exhibits better performance than other related algorithms in terms of consistency with subjective assessment of stereoscopic 3D images.
C1 [Chen, Lei; Zhao, Jiying] Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Chen, L (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM lchen148@uottawa.ca; jzhao@uottawa.ca
CR [Anonymous], 2010, P 5 INT WORKSH VID P
   [Anonymous], TIP
   [Anonymous], P SPIE
   [Anonymous], TIP
   [Anonymous], TIP
   [Anonymous], TIP
   [Anonymous], TIP
   Benoit A, 2008, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2008.4711773
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Cao Y, 2016, IEEE ICC, P80, DOI 10.1109/ICC.2016.7510612
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen ZB, 2017, IEEE T IMAGE PROCESS, V26, P5138, DOI 10.1109/TIP.2017.2736422
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Fan Y, 2017, IEEE IMAGE PROC, P760, DOI 10.1109/ICIP.2017.8296383
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gottschalk PG, 2005, ANAL BIOCHEM, V343, P54, DOI 10.1016/j.ab.2005.04.035
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Howard I. P., 1995, BINOCULAR FUSION RIV
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Lebreton P, 2012, IEEE J-STSP, V6, P710, DOI 10.1109/JSTSP.2012.2213236
   Lee K, 2015, IEEE J-STSP, V9, P533, DOI 10.1109/JSTSP.2015.2393296
   Lei Chen, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P61, DOI 10.1109/ICMEW.2017.8026266
   Liu Y, 2016, SIGNAL PROCESS, V125, P237, DOI 10.1016/j.sigpro.2016.01.019
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Qi F, 2012, IEEE INT SYMP CIRC S, P1712
   REHMAN A, 1989, TIP, V21, P3378, DOI DOI 10.1109/TIP.2012.2197011
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Sazzad ZMP, 2009, INT WORK QUAL MULTIM, P180, DOI 10.1109/QOMEX.2009.5246956
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   SHAO F, 1953, TIP, V22, P1940, DOI DOI 10.1109/TIP.2013.2240003
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Song R, 2015, J INF SCI ENG, V31, P1593
   Tam WJ, 2011, IEEE T BROADCAST, V57, P335, DOI 10.1109/TBC.2011.2125070
   Thomson MGA, 2000, PERCEPTION, V29, P1057, DOI 10.1068/p2867
   Tong F, 1998, NEURON, V21, P753, DOI 10.1016/S0896-6273(00)80592-9
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wang X., 2011, P IEEE VIS COMM IM P, P1, DOI DOI 10.1109/VCIP.2011.6116015
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 51
TC 5
Z9 5
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12139
EP 12156
DI 10.1007/s11042-018-6759-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900048
DA 2024-07-18
ER

PT J
AU Deepa, AR
   Emmanuel, WRS
AF Deepa, A. R.
   Emmanuel, W. R. Sam
TI An efficient detection of brain tumor using fused feature adaptive
   firefly backpropagation neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical resonance imaging; Brain tumor; Neural network; Adaptive firefly
ID IMAGE CLASSIFICATION; MR-IMAGES; SEGMENTATION; DIAGNOSIS
AB Early diagnosis of tumor will increase the survival probability from a deadly disease called a brain tumor. Classification of the tumor from the tumor affected MRI using the concept of medical image processing assist better treatment and surgical planning. This paper proposes a fused feature adaptive firefly backpropagation neural network for classification which comprises preprocessing, feature extraction, selection, and fusion to achieve high classification accuracy. The preprocessing step uses the average filter for reducing the intensity variation of the images. The Gabor wavelet feature extraction extracts the locality, orientation, and frequency of the tumor image which provides texture information for classification. The kernel principal component analysis (KPCA) feature selection selects the small subset of features to reduce the redundancy and increase the relevancy of the feature. The Gaussian radial basis function (GRBF) for feature fusion provides the distinguished information from the multiple sets of features. Finally, the proposed approach accurately classify the tumor with high accuracy after applying the fusion results. The results are simulated in MATLAB and it proves the improved accuracy, sensitivity, specificity of the classified tumor of the proposed approach.
C1 [Deepa, A. R.] Nesamony Mem Christian Coll, Marthandam, Tamil Nadu, India.
   [Deepa, A. R.] Manonmanium Sundaranar Univ, Tirunelveli 627012, Tamil Nadu, India.
   [Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Dept Comp Sci, Tirunelveli, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Deepa, AR (corresponding author), Nesamony Mem Christian Coll, Marthandam, Tamil Nadu, India.; Deepa, AR (corresponding author), Manonmanium Sundaranar Univ, Tirunelveli 627012, Tamil Nadu, India.
EM deepaamuth@gmail.com
RI Amuth, Deepa/JFK-9747-2023; EMMANUEL, W R SAM/E-5526-2018
OI Amuth, Deepa/0000-0002-3690-076X; 
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   [Anonymous], 2011 4 INT C MOD SIM
   [Anonymous], 2016, INT J LATEST ENG RES
   Azad S, 2016, 2016 IEEE INTERNATIONAL WIE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (IEEE WIECON-ECE 2016), P254, DOI 10.1109/WIECON-ECE.2016.8009130
   Banday SA, 2017, MULTIMED TOOLS APPL, V76, P3809, DOI 10.1007/s11042-016-3979-9
   Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   García-Gómez JM, 2009, MAGN RESON MATER PHY, V22, P5, DOI 10.1007/s10334-008-0146-y
   GUPTA M, 2016, INFORMATION TECHNOLO, P2016, DOI DOI 10.1109/T4E.2016.30
   Gupta T, 2017, J INTELL FUZZY SYST, V32, P3575, DOI 10.3233/JIFS-169293
   Joshi Anjali, 2015, 2015 International Conference on Advanced Computing and Communication Systems (ICACCS). Proceedings, P1, DOI 10.1109/ICACCS.2015.7324127
   Jothi G, 2016, APPL SOFT COMPUT, V46, P639, DOI 10.1016/j.asoc.2016.03.014
   Koley S, 2016, APPL SOFT COMPUT, V41, P453, DOI 10.1016/j.asoc.2016.01.022
   Lahmiri S, 2017, BIOMED SIGNAL PROCES, V31, P148, DOI 10.1016/j.bspc.2016.07.008
   Lang RX, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1402, DOI 10.1109/CISP-BMEI.2016.7852936
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Othman M. F., 2011, Proceedings of the 2011 2nd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2011), P136, DOI 10.1109/ISMS.2011.32
   Samanta AK, 2018, ADV INTELL SYST COMP, V723, P343, DOI 10.1007/978-3-319-74690-6_34
   Saritha M, 2013, PATTERN RECOGN LETT, V34, P2151, DOI 10.1016/j.patrec.2013.08.017
   Selvapandian A, 2018, COMPUT METHODS PROG
   Sridhar D, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P92, DOI 10.1109/ICSIPR.2013.6497966
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Wu MN, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P245
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang YD, 2015, PATTERN RECOGN LETT, V62, P14, DOI 10.1016/j.patrec.2015.04.016
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 28
TC 16
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11799
EP 11814
DI 10.1007/s11042-018-6731-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900032
DA 2024-07-18
ER

PT J
AU Roberto, V
   Toppano, E
AF Roberto, Vito
   Toppano, Elio
TI Multimedia analysis and design: a conceptual framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Analysis; Semiotic; Design; Commercials; Advertisements
AB The paper proposes a conceptual model inspired to semiotic theories, to be applied to the analysis and design of multimedia. We introduce a meta-model with four levels of semantic aggregation. There results a framework of concepts, relations and processes accounting for the multiple meanings that arise from a multimedia text. We explore the effectiveness of the model by considering four commercial clips by the brand Lancome. Our analysis confirms that the framework is well suited to the analysis, indexing, design of narrative multimedia.
C1 [Roberto, Vito; Toppano, Elio] Univ Udine, Dipartim Sci Matemat Informat & Fis DMIF, Udine, Italy.
C3 University of Udine
RP Roberto, V (corresponding author), Univ Udine, Dipartim Sci Matemat Informat & Fis DMIF, Udine, Italy.
EM vito.roberto@uniud.it; elio.toppano@uniud.it
OI ROBERTO, Vito/0000-0001-5950-907X
CR Bailey BrianP., 2001, P MULTIMEDIA MODELIN, P267
   Bardzell J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2357
   Bateman JA, 2007, SEMIOTICA, V167, P13, DOI 10.1515/SEM.2007.070
   Bianchi C, 2011, SEMIOTICA, V183, P243, DOI 10.1515/semi.2011.012
   Bolchini D, 2009, SIGDOC'09: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P67
   Bouvier G, 2013, MULTIMODAL ANAL TELE
   Chandler Daniel, 2002, SEMIOTICS BASICS
   Cockton G., 2006, P 4 NORDIC C HUMAN C, P165
   Colombo C, 2001, MULTIMED TOOLS APPL, V13, P93, DOI 10.1023/A:1009681324605
   DAVIS M, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P120
   de Saussure Ferdinand., 1922, Cours de linguistique generale
   De Souza C.S., 2004, SEMIOTIC ENG HUMAN C
   de Souza CS, 2013, J VISUAL LANG COMPUT, V24, P218, DOI 10.1016/j.jvlc.2013.03.002
   Desmet PMA, 2013, INT J DES, V7, P5
   Eugeni R., 2011, INT WORKSH PRACT THE
   Floch Jean-Marie., 2001, VISUAL IDENTITIES
   Fogg B. J., 2003, PERSUASIVE TECHNOLOG, P89
   Friedman B, 2006, ADV MANAG INFORM SYS, V5, P348
   Gabrielsson A., 2001, Music And Emotion, P223, DOI DOI 10.1525/MP.2004.21.4.561
   Greimas A.J., 1982, Semiotics and language : An analytical dictionary
   Greimas AJ, 1984, DOCUMENTS
   Harrison C, 2003, TECH COMMUN, V50, P46
   Hassenzahl M., 2010, Experience design: Technology for all the right reasons
   Hebert L, 2008, TOOLS TEXT IMAGE ANA
   Ines Sastre, 2007, TRESOR LANCOME
   Isabella Rossellini, 1990, TRESOR LANCOME
   Islam MN, 2016, INT J HUM-COMPUT ST, V86, P121, DOI 10.1016/j.ijhcs.2015.10.003
   Kate Winslet, 2009, TRESOR LANCOME
   Kress Gunther., 2006, READING IMAGES
   Kujala S., 2009, Journal of Information Technology Theory and Application (JITTA), V9, P4
   Lauer Claire, 2009, Computers and Composition, V26, P225, DOI 10.1016/j.compcom.2009.09.001
   Lombardo V, 2010, LECT NOTES COMPUT SC, V6432, P62, DOI 10.1007/978-3-642-16638-9_10
   Mancini C, 2001, P HYP
   Mann W., 1988, Text, V8, P243, DOI [10.1515/text.1.1988.8.3.243, DOI 10.1515/TEXT.1.1988.8.3.243]
   McQuarrie EF, 1999, J CONSUM RES, V26, P37, DOI 10.1086/209549
   Montero S, 2003, P IASTED INT C SOFTW, P1053
   NADIN M, 1988, SEMIOTICA, V69, P269, DOI 10.1515/semi.1988.69.3-4.269
   O'Halloran K.L., 2011, The Continuum Companion to Discourse Analysis, P120
   Penelope Cruz, 2010, TRESOR LANCOME
   Purchase HC, 2001, DESIGN AND MANAGEMENT OF MULTIMEDIA INFORMATION SYSTEMS: OPPORTUNITIES AND CHALLENGES, P1
   Rogers Y, 2004, ANNU REV INFORM SCI, V38, P87, DOI 10.1002/aris.1440380103
   Scharfe H, 2007, CHALLENGING BOUNDARI, P95
   Sieckenius de Souza C, 2001, SEMIOTIC APPROACHES, V14, P415
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Toppano E, 2014, PROCEEDINGS OF THE INTERNATIONAL CONFERENCES ON ICT, SOCIETY AND HUMAN BEINGS 2014, WEB BASED COMMUNITIES AND SOCIAL MEDIA 2014, E-COMMERCE 2014, INFORMATION SYSTEMS POST-IMPLEMENTATION AND CHANGE MANAGEMENT 2014 AND E-HEALTH 2014, P167
   Toppano E, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P367
   Tromp N, 2011, DES ISSUES, V27, P3, DOI 10.1162/DESI_a_00087
   Tseng CI, 2013, SOC SEMIOT, V23, P587, DOI 10.1080/10350330.2012.752158
   Verbeek PP, 2006, SCI TECHNOL HUM VAL, V31, P361, DOI 10.1177/0162243905285847
   Wingstedt J, 2010, VISUAL COMMUN-US, V9, P193, DOI 10.1177/1470357210369886
   Wouken A, 2002, ECSTRIAM03002 U SOUT
   Wright P, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460360
NR 52
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 14029
EP 14043
DI 10.1007/s11042-018-7136-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900064
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Singh, G
   Singh, K
AF Singh, Gurvinder
   Singh, Kulbir
TI Video frame and region duplication forgery detection based on
   correlation coefficient and coefficient of variation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move; Frame duplication; Region duplication; Correlation
   coefficient; Coefficient of variation
ID DETECTION ALGORITHM; DELETION
AB In this paper, we present a passive blind scheme consisting of two different algorithms to detect frame and region duplication forgeries in videos. We have examined the video frame duplication forgery in three different forms such as duplication of a sequence of consecutive video frames at long continue running position, duplication of many such sequences having different lengths at many different locations and duplication from other videos having different and same dimensions which can raise a serious problem in the real world scenario. The algorithm I of proposed scheme has detected these three different forms of copy-moved frame duplication forgery in videos by obtaining the mean features of each video frame for evaluating the correlation between sequences. In this paper, we have also analysed forged regular and irregular region within same frame at different locations and from other frame to one or more sequences of consecutive frames of the same video at same locations. It creates a challenge to detect this copy-move forgery due to slightly change in pixel intensity values in the duplicated region and providing high correlation as authentic region. The algorithm II of proposed scheme has detected these copy-moved region duplication forgeries in videos by locating the position of error with threshold process in order to calculate the similarities between regions of two frames or within affected frame. In this paper, the experimental results show the higher detection accuracy and execution time efficiency of proposed scheme than the latest algorithms with satisfactory performance.
C1 [Singh, Gurvinder; Singh, Kulbir] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, G (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM gsingh2_phd16@thapar.edu; ksingh@thapar.edu
RI Singh, Kulbir/T-7453-2019
OI Singh, Kulbir/0000-0001-8070-3395
CR Al-Sanjary Omar Ismael, 2015, Journal of Theoretical and Applied Information Technology, V74, P207
   [Anonymous], INT J ADV INFORM TEC
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bozkurt I, 2017, TURK J ELECTR ENG CO, V25, P4558, DOI 10.3906/elk-1703-125
   Cabeen K., IMAGE COMPRESSION DI
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chetty Girija, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P606, DOI 10.1109/NSS.2010.8
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Goodwin J., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P608, DOI 10.1109/DICTA.2011.108
   Ke Yan., 2004, MULTIMEDIA 04 P 12 A, P869, DOI DOI 10.1145/1027527.1027729
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Liu YQ, 2017, MULTIMEDIA SYST, V23, P223, DOI [10.1007/s00530-015-0478-1, 10.1007/s00530-015-0461-x]
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Shanableh T, 2013, DIGIT INVEST, V10, P350, DOI 10.1016/j.diin.2013.10.004
   Sharma S, 2016, P IEEE INT C ADV COM
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Su Y, 2009, IEEE INT C COMP INT
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Thajeel Salam A., 2013, IJCSI INT J COMPUTER, V10, P2
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P10393, DOI 10.1007/s11042-016-4222-4
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang W, 2014, LECT NOTES COMPUT SC, V8389, P244, DOI 10.1007/978-3-662-43886-2_18
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Xu ZJ, 2011, PROCEDIA ENVIRON SCI, V10, P1129, DOI 10.1016/j.proenv.2011.09.180
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   ZHANG J, 2009, PROCEEDINGS OF THE F, V49, P54, DOI DOI 10.1109/ETCS.2009.273
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P21825, DOI 10.1007/s11042-017-4383-9
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 39
TC 31
Z9 33
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11527
EP 11562
DI 10.1007/s11042-018-6585-1
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900020
DA 2024-07-18
ER

PT J
AU Xia, HY
   Zhao, WX
   Jiang, F
   Li, HS
   Xin, J
   Zhou, Z
AF Xia, Haiying
   Zhao, Wenxian
   Jiang, Frank
   Li, Haisheng
   Xin, Jing
   Zhou, Zheng
TI Fast template matching based on deformable best-buddies similarity
   measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Template matching; Best buddies similarity; Deformable; Proposal
   generation; Proposal selection
AB Accuracy and speed are the essential metrics for the template matching algorithms in solving object tracking problems. Since the method based on Best Buddies Similarity (BBS) has achieved the state-of-the-art performance in terms of accuracy, matching speed becomes the shortest piece of wood of the bucket. In this paper, we propose a fast template matching method based on our deformable BBS measure. The deformable BBS measure enables matching to be performed between the patches in varying sizes, and hence leads to even higher accuracy than the original BBS-based methods. More important, we develop a fast potential-area discovery algorithm based on proposal generation and selection. It significantly reduces the numbers of useless attempts on calculating and comparing similarities of impossible image patches. The experimental results show that, with the deformable BBS measure and the fast potential-area discovery, our template matching method outperforms the state-of-the-art methods in terms of accuracy, speed and robustness.
C1 [Xia, Haiying; Jiang, Frank; Li, Haisheng; Zhou, Zheng] Guangxi Normal Univ, Guilin, Peoples R China.
   [Zhao, Wenxian] Guangxi Normal Univ, Sch Elect Engn, Guilin, Peoples R China.
   [Xia, Haiying] Guilin Univ Aerosp Technol, Guilin, Peoples R China.
   [Xia, Haiying] Guilin Univ Elect Technol, Guilin, Peoples R China.
   [Zhao, Wenxian] China United Network Telecommun Co Ltd, Jining, Peoples R China.
   [Xin, Jing] Xian Univ Technol, Xian, Shaanxi, Peoples R China.
C3 Guangxi Normal University; Guangxi Normal University; Guilin University
   of Aerospace Technology; Guilin University of Electronic Technology;
   Xi'an University of Technology
RP Xia, HY (corresponding author), Guangxi Normal Univ, Guilin, Peoples R China.; Xia, HY (corresponding author), Guilin Univ Aerosp Technol, Guilin, Peoples R China.; Xia, HY (corresponding author), Guilin Univ Elect Technol, Guilin, Peoples R China.
EM 573023049@qq.com; 348223395@qq.com; franksydney2008@qq.com;
   187373363@qq.com; xinj@xaut.edu.cn; dr.ike.zhou@foxmail.com
RI j, f/KLZ-9192-2024; Li, Hai-sheng/L-4658-2017
FU National Natural Science Foundation of China [61762012, 61462026,
   61762014]; Opening Project of Guangxi Colleges and Universities Key
   Laboratory of robot & welding (Guilin University of Aerospace
   Technology); Opening Project of Shaanxi Key Laboratory of Complex
   Control System and Intelligent Information Processing; Research Fund of
   Guangxi Key Lab of Multi-source Information Mining Security [MIMS15-05];
   Research Fund of Guangxi Key Lab of intelligent integrated automation
FX This work is supported by the National Natural Science Foundation of
   China (No. 61762014), the Opening Project of Guangxi Colleges and
   Universities Key Laboratory of robot & welding (Guilin University of
   Aerospace Technology), the Opening Project of Shaanxi Key Laboratory of
   Complex Control System and Intelligent Information Processing, and the
   Research Fund of Guangxi Key Lab of Multi-source Information Mining &
   Security (MIMS15-05), and and the Research Fund of Guangxi Key Lab of
   intelligent integrated automation. This work is also partly supported by
   the National Natural Science Foundation of China (No. 61762012 and No.
   61462026).
CR Amiri M, 2010, PATTERN RECOGN, V43, P2485, DOI 10.1016/j.patcog.2009.12.014
   [Anonymous], 1992, Active perception and robot vision, DOI [10.1007/978-3-642-77225-2_13, DOI 10.1007/978-3-642-77225-2_13]
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Assari SM, 2016, LECT NOTES COMPUT SC, V9906, P119, DOI 10.1007/978-3-319-46475-6_8
   Chen YS, 2001, IEEE T IMAGE PROCESS, V10, P1212, DOI 10.1109/83.935037
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Dekel T, 2015, PROC CVPR IEEE, P2021, DOI 10.1109/CVPR.2015.7298813
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FUH CS, 1991, OPT ENG, V30, P881, DOI 10.1117/12.55885
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Jain AK, 1998, SIGNAL PROCESS, V71, P109, DOI 10.1016/S0165-1684(98)00139-X
   Jin Z, 2007, NEUROCOMPUTING, V70, P794, DOI 10.1016/j.neucom.2006.10.043
   KIM HS, 2011, INFORM SYST, V83, P2008
   Korman S, 2013, PROC CVPR IEEE, P2331, DOI 10.1109/CVPR.2013.302
   Lee CH, 1997, IEEE T IMAGE PROCESS, V6, P1587, DOI 10.1109/83.641419
   Lee H, 2016, INT CONF ACOUST SPEE, P1966, DOI 10.1109/ICASSP.2016.7472020
   Lee Y, 2001, IEEE T MED IMAGING, V20, P595, DOI 10.1109/42.932744
   Lin YH, 2008, PATTERN RECOGN, V41, P2413, DOI 10.1016/j.patcog.2008.01.017
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Talmi I, 2017, PROC CVPR IEEE, P1311, DOI 10.1109/CVPR.2017.144
   Tian YD, 2012, INT J COMPUT VISION, V98, P279, DOI 10.1007/s11263-011-0509-0
   WEI SD, 2008, TIP, V17, P2227, DOI DOI 10.1109/TIP.2008.2004615
   WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 27
TC 10
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11905
EP 11925
DI 10.1007/s11042-018-6722-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900037
DA 2024-07-18
ER

PT J
AU Arora, T
   Dhir, R
AF Arora, Tanvi
   Dhir, Renu
TI A variable region scalable fitting energy approach for human Metaspread
   chromosome image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Medical images; Intensity inhomogeneity; Region based
   active contours
ID ACTIVE CONTOUR MODEL; LEVEL-SET; LOCAL SEGMENTATION; DRIVEN;
   INITIALIZATION; ALGORITHMS; SPEED
AB The medical images often suffer from intensity inhomogeneity and therefore they are difficult to segment using the conventional image segmentation approaches. In this work an image segmentation approach is being presented, in which the region scalable fitting energy is variable for the regions inside and outside the contours. The energy term is defined along the two sides of the contour, by considering different scale parameters for the foreground and background regions. Two fitting functions are used to approximate the intensities of the foreground and background regions. The proposed method is able to deal with intensity inhomogeneity as a Gaussian kernel function has been used in the energy formulation. The kernel function is used to assign weights to the intensity values during energy formulation. Different scale parameters are used for the kernel function for background and foreground regions. The proposed method proves to be robust as it has the self-regularization capability, partial differential equations have been discretized by approximations and the method does not require computationally expensive re-initialization procedure. The proposed method is capable of efficiently segmenting the human metaspread chromosome images that suffer from intensity inhomogeneity. The chromosomes that have very low contrast with the background or the group of chromosomes that appear to be nearly touching each other are segmented correctly from the metaspread images.
C1 [Arora, Tanvi] Chandigarh Grp Coll, Coll Engn, Dept Comp Sci & Engn, Mohali, Punjab, India.
   [Dhir, Renu] Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar, Punjab, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Arora, T (corresponding author), Chandigarh Grp Coll, Coll Engn, Dept Comp Sci & Engn, Mohali, Punjab, India.
EM tanviverma@rediffmail.com
RI Dhir, Renu/Y-4453-2019
OI Dhir, Renu/0000-0003-1641-2619
CR Akram F, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/710326
   [Anonymous], COMPUTATIONAL MATH M
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], TIP
   [Anonymous], INT J COMPUT VIS
   [Anonymous], TIP
   Arora T, 2018, INT ARAB J INF TECHN, V19, P1
   Arora T, 2016, INT C MASS DAT AN IM
   Arora T, 2017, MED BIOL ENG COMPUT, V55, P733, DOI 10.1007/s11517-016-1553-2
   Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7
   Ben Ayed I, 2005, IEEE T PATTERN ANAL, V27, P793, DOI 10.1109/TPAMI.2005.106
   Ben Ayed I, 2006, IEEE T IMAGE PROCESS, V15, P3431, DOI 10.1109/TIP.2006.881961
   Bernard O, 2009, IEEE T IMAGE PROCESS, V18, P1179, DOI 10.1109/TIP.2009.2017343
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YF, 2017, KNOWL-BASED SYST, V120, P57, DOI 10.1016/j.knosys.2016.12.023
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   Grisan E., 2009, 11th International Congress of the IUPESM. World Congress on Medical Physics and Biomedical Engineering. Image Processing, Biosignal Processing, Modelling and Simulation, Biomechanics, P748, DOI 10.1007/978-3-642-03882-2_199
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Hu R.L., 2017, ARXIV171207639V1CSCV, P1
   Karvelis PS, 2008, IEEE T MED IMAGING, V27, P697, DOI 10.1109/TMI.2008.916962
   Karvelis Petros S, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3009
   Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442
   Li CM, 2005, PROC CVPR IEEE, P430
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu WP, 2013, PATTERN RECOGN LETT, V34, P655, DOI 10.1016/j.patrec.2013.01.005
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Moallem Payman, 2013, International Journal of Image, Graphics and Signal Processing, V5, P22, DOI 10.5815/ijigsp.2013.05.03
   Mukherjee S, 2015, IEEE SIGNAL PROC LET, V22, P298, DOI 10.1109/LSP.2014.2346538
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park J, 2001, IEEE T PATTERN ANAL, V23, P1201, DOI 10.1109/34.954609
   Samson C, 2000, INT J COMPUT VISION, V40, P187, DOI 10.1023/A:1008183109594
   Sarti A, 2005, IEEE T ULTRASON FERR, V52, P947, DOI 10.1109/TUFFC.2005.1504017
   Shi Y, 2008, IEEE T IMAGE PROCESS, V17, P645, DOI 10.1109/TIP.2008.920737
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   VASILEVSKIY A, 2001, TPAMI, V24, P1565, DOI DOI 10.1109/TPAMI.2002.1114849
   Wang H, 2014, INFORM SCIENCES, V263, P43, DOI 10.1016/j.ins.2013.10.033
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Xiang Y, 2006, J COMPUT PHYS, V219, P455, DOI 10.1016/j.jcp.2006.03.026
   Xu HY, 2014, COMPUT ELECTR ENG, V40, P858, DOI 10.1016/j.compeleceng.2013.07.026
   YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zheng Q, 2014, SIGNAL PROCESS, V97, P117, DOI 10.1016/j.sigpro.2013.10.008
   Zheng Q, 2013, SIGNAL PROCESS, V93, P961, DOI 10.1016/j.sigpro.2012.10.005
NR 48
TC 5
Z9 5
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9383
EP 9404
DI 10.1007/s11042-018-6550-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800078
DA 2024-07-18
ER

PT J
AU Ding, F
   Shi, YX
   Zhu, GP
   Shi, YQ
AF Ding, Feng
   Shi, Yuxi
   Zhu, Guopu
   Shi, Yun-Qing
TI Smoothing identification for digital image forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Smoothing detection; Bilateral filter; Texture
   analysis; Machine learning
ID FILTER
AB With the explosive development in digital techniques, ordinary people without professional training are capable to edit digital images with applications. As a common image processing manipulation, smoothing is important in editing digital images for denoising and producing blur effect. Besides, in recent years, people prefer to retouch images with smoothing algorithms to pursue better appearance. Hence it is required to expose such manipulations in digital image forensics. In this paper, a new scheme for detecting the operation of smoothing is proposed. The proposed scheme is based on analyzing the statistical property which can be considered as computation efficiently when compares to machine learning algorithms. Furthermore, a method for texture analysis is also proposed to specify the algorithm that used for smoothing. The second method adopt the features extracted from edge area. The features are fed into support vector machine for classification.
C1 [Ding, Feng; Shi, Yuxi; Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
   [Zhu, Guopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.
   [Zhu, Guopu] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 New Jersey Institute of Technology; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Zhu, GP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.; Zhu, GP (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM gp.zhu@siat.ac.cn
OI Zhu, Guopu/0000-0001-7956-5343
FU National Natural Science Foundation of China [61572489, 61872350]; Basic
   Research Program of Shenzhen [JCYJ20170818163403748]; Youth Innovation
   Promotion Association of CAS [2015299]; CAS Light of West China Program
   [2016-QNXZ-A-5]; Science and Technology Planning Project of Guangdong
   Province [2017A050501027]; Shenzhen Discipline Construction Project for
   Urban Computing and Data Intelligence
FX The authors greatly appreciate the anonymous reviewers for their
   valuable comments. This work was supported in part by the National
   Natural Science Foundation of China under Grant 61572489 and Grant
   61872350, in part by the Basic Research Program of Shenzhen under Grant
   JCYJ20170818163403748, in part by the Youth Innovation Promotion
   Association of CAS under Grant 2015299, in part by the CAS Light of West
   China Program under Grant 2016-QNXZ-A-5, in part by the Science and
   Technology Planning Project of Guangdong Province under Grant
   2017A050501027, and in part by the Shenzhen Discipline Construction
   Project for Urban Computing and Data Intelligence.
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   BAYAR B, 2016, PROCEEDINGS OF THE 4, V4, P5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao G., 2010, Journal of Information Hiding and Multimedia Signal Processing, V1, P20
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Ding F, 2018, J VIS COMMUN IMAGE R, V50, P93, DOI 10.1016/j.jvcir.2017.11.009
   Ding F, 2015, IEEE SIGNAL PROC LET, V22, P327, DOI 10.1109/LSP.2014.2359033
   Drucker H, 1999, IEEE T NEURAL NETWOR, V10, P1048, DOI 10.1109/72.788645
   Elad M, 2002, IEEE T IMAGE PROCESS, V11, P1141, DOI 10.1109/TIP.2002.801126
   Farid H, 2008, SCI AM, V298, P66, DOI 10.1038/scientificamerican0608-66
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   González ER, 2002, ORG DIVERS EVOL, V2
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Haddock LJ, 2013, J OPHTHALMOL, V2013, DOI 10.1155/2013/518479
   Hu R, 2018, MULTIMED TOOLS APPL, V77, P6863, DOI 10.1007/s11042-017-4604-2
   Idaho N, 2012, THE PLANTS DATABASE
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchner M, 2010, MEDIA FORENSICS SECU, V7541
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   LUO X, 2016, TOOLS, V75, P13557, DOI DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Pasquini C, 2014, IEEE INT WORKS INFOR, P113, DOI 10.1109/WIFS.2014.7084313
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang P, 2018, J VISUAL COMMUNICATI
   Wang P, 2018, SIGNAL PROCESS-IMAGE, V64, P33, DOI 10.1016/j.image.2018.02.011
   Wu R., 2011, IEEE International Conference on Image Processing, P1933
   Wu YH, 2017, ASIAPAC SIGN INFO PR, P842, DOI 10.1109/APSIPA.2017.8282150
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 45
TC 10
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8225
EP 8245
DI 10.1007/s11042-018-6807-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800020
DA 2024-07-18
ER

PT J
AU Ferreira, PM
   Cardoso, JS
   Rebelo, A
AF Ferreira, Pedro M.
   Cardoso, Jaime S.
   Rebelo, Ana
TI On the role of multimodal learning in the recognition of sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language recognition; Multimodal learning; Convolutional neural
   networks; Kinect; Leap motion
AB Sign Language Recognition (SLR) has become one of the most important research areas in the field of human computer interaction. SLR systems are meant to automatically translate sign language into text or speech, in order to reduce the communicational gap between deaf and hearing people. The aim of this paper is to exploit multimodal learning techniques for an accurate SLR, making use of data provided by Kinect and Leap Motion. In this regard, single-modality approaches as well as different multimodal methods, mainly based on convolutional neural networks, are proposed. Our main contribution is a novel multimodal end-to-end neural network that explicitly models private feature representations that are specific to each modality and shared feature representations that are similar between modalities. By imposing such regularization in the learning process, the underlying idea is to increase the discriminative ability of the learned features and, hence, improve the generalization capability of the model. Experimental results demonstrate that multimodal learning yields an overall improvement in the sign recognition performance. In particular, the novel neural network architecture outperforms the current state-of-the-art methods for the SLR task.
C1 [Ferreira, Pedro M.] INESC TEC, Porto, Portugal.
   [Cardoso, Jaime S.] INESC TEC, Informat Proc & Pattern Recognit Area, Ctr Telecommun & Multimedia, Porto, Portugal.
   [Ferreira, Pedro M.] Univ Porto, Porto, Portugal.
   [Cardoso, Jaime S.] Univ Porto, Fac Engn, Habilitat, Porto, Portugal.
   [Rebelo, Ana] INESC TEC, Oporto, Portugal.
   [Rebelo, Ana] Univ Portucalense, Oporto, Portugal.
C3 INESC TEC; INESC TEC; Universidade do Porto; Universidade do Porto;
   INESC TEC; Universidade Portucalense Infante D. Henrique
RP Ferreira, PM (corresponding author), INESC TEC, Porto, Portugal.
EM pmmf@inesctec.pt
RI Cardoso, Jaime S/I-3286-2013; ARSLAN, Okan/AAA-3232-2020; Rebelo,
   Ana/I-1121-2015
OI Cardoso, Jaime S/0000-0002-3760-2473; Rebelo, Ana/0000-0003-4776-6057
FU Protect "NanoSTIMA: Macro-to-Nano Human Sensing: Towards Integrated
   Multimodal Health Monitoring and Analytics - North Portugal Regional
   Operational Programme (NORTE 2020), under PORTUGAL 2020 Partnership
   Agreement [NORTE010145-FEDER000016]; European Regional Development FUND
   (ERDF); FundacAo para a Ciencia e a Tecnologia (FCT)
   [SFRH/BD/102177/2014, SFRH/BPD/101439/2014]; Fundação para a Ciência e a
   Tecnologia [SFRH/BPD/101439/2014, SFRH/BD/102177/2014] Funding Source:
   FCT
FX This work was funded by the Protect "NanoSTIMA: Macro-to-Nano Human
   Sensing: Towards Integrated Multimodal Health Monitoring and
   Analytics/NORTE010145-FEDER000016 " financed by the North Portugal
   Regional Operational Programme (NORTE 2020), under PORTUGAL 2020
   Partnership Agreement, and through the European Regional Development
   FUND (ERDF), and also by FundacAo para a Ciencia e a Tecnologia (FCT)
   within PhD and BPD grants with numbers SFRH/BD/102177/2014 and
   SFRH/BPD/101439/2014.
CR Adithya V, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1080
   Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   [Anonymous], 2012, DEEP LEARNING UNSUPE
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], ARXIV180309733
   [Anonymous], 2014, Advances in neural information processing systems
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], ARXIV160406620
   [Anonymous], ARXIV160908417
   Bousmalis K, 2016, ADV NEUR IN, V29
   Cooper H, 2007, LECT NOTES COMPUT SC, V4796, P88
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Ferreira PM, 2017, LECT NOTES COMPUT SC, V10255, P313, DOI 10.1007/978-3-319-58838-4_35
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Huang C., 2016, ADV NEURAL INFORM PR, P1262
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Wang AR, 2015, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2015.134
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Wang JJY, 2015, ENG APPL ARTIF INTEL, V37, P1, DOI 10.1016/j.engappai.2014.08.009
   Wu ZX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P167, DOI 10.1145/2647868.2654931
   Yang HD, 2015, SENSORS-BASEL, V15, P135, DOI 10.3390/s150100135
   Zhang G., 2017, MEDIAT INFLAMM, V2017, P1, DOI [DOI 10.1155/2017/3578702, 10.1155/2017/3578702, DOI 10.1155/2017/3126010]
   Zhang SW, 2017, CLUSTER COMPUT, V20, P1517, DOI 10.1007/s10586-017-0859-7
NR 31
TC 13
Z9 15
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10035
EP 10056
DI 10.1007/s11042-018-6565-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400025
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gao, W
   Jiang, GY
   Yu, M
   Luo, T
AF Gao, Wei
   Jiang, Gangyi
   Yu, Mei
   Luo, Ting
TI Lossless fragile watermarking algorithm in compressed domain for
   multiview video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview video coding; Compressed domain; Fragile watermarking;
   Lossless; B_SKIP; B_DIRECT_16x16
ID DATA HIDING ALGORITHM; H.264/AVC; STREAMS
AB The hierarchical B picture (HBP) prediction structure is a typical coding scheme used for multiview video coding (MVC). This paper proposes a fragile watermarking algorithm for HBP-based multiview video coding. B_DIRECT_16x16 and B_SKIP are two types of macroblocks used for H.264/AVC coding, and are respectively generated in the DIRECT and SKIP prediction modes. Modification of the syntactic elements enables the watermark to be embedded while the B_SKIP macroblock is converted into the B_DIRECT_16x16 macroblock. To authenticate the integrity of the multiview video content, the watermark is generated from the content-based features of the cross-view of the multiview video bitstream. Experimental implementation revealed that the structural similarity index (SSIM) of the video quality was not affected by the proposed watermarking scheme. Compared to current algorithms, the proposed algorithm has a higher embedding capacity, produces less bitrate increase, and is less complex. It satisfies the transparency, bitrate stability, fragility, and real-time performance requirements of multiview video authentication.
C1 [Gao, Wei; Jiang, Gangyi; Yu, Mei; Luo, Ting] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315000, Zhejiang, Peoples R China.
   [Gao, Wei; Luo, Ting] Ningbo Univ, Coll Sci & Technol, Ningbo 315000, Zhejiang, Peoples R China.
   [Yu, Mei] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Ningbo University; Ningbo University; Nanjing University
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315000, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI jiang, gang/KII-8233-2024
FU Natural Science Foundation of China [61671258, 61871247, 61671412,
   61501270]; National High-tech R&D Program of China [2015AA015901];
   Natural Science Foundation of Zhejiang Province [LY15F010005]; Natural
   Science Foundation of Ningbo [2017A610127]; K.C. Wong Magna Fund in
   Ningbo University
FX This work was supported by the Natural Science Foundation of China under
   Grant nos. 61671258, 61871247,61671412, and 61501270, the National
   High-tech R&D Program of China under Grant no. 2015AA015901, the Natural
   Science Foundation of Zhejiang Province under Grant no. LY15F010005,
   theNatural Science Foundation of Ningbo under Grant No. 2017A610127.It
   is also sponsored by K.C. Wong Magna Fund in Ningbo University.
CR Al-Haj A, 2017, MEASUREMENT, V95, P405, DOI 10.1016/j.measurement.2016.10.016
   [Anonymous], 2010, 1 ITUT ISOIEC JTC
   [Anonymous], MULTIMEDIA TOOLS APP
   Ekmekcioglu E, 2016, IEEE T CIRCUITS SYST, P1
   Fang LY, 2015, IEEE T MED IMAGING, V34, P1306, DOI 10.1109/TMI.2014.2387336
   Lee J, 2015, IEEE T BROADCAST, V61, P222, DOI 10.1109/TBC.2015.2419193
   Li WF, 2015, ADV INTEL SYS RES, V121, P680
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Park Scott, 2015, Journal of Information and Communication Convergence Engineering, V13, P62, DOI 10.6109/jicce.2015.13.1.062
   Profrock D, 2005, VISUAL COMMUNICATION, V2005
   Shafai WE, 2018, INT J COMMUN SYST, V31, P1
   Son JY, 2013, P IEEE, V101, P190, DOI 10.1109/JPROC.2011.2178052
   Song GH, 2014, LECT NOTES COMPUT SC, V8588, P541, DOI 10.1007/978-3-319-09333-8_60
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Tian LH, 2015, MULTIMED TOOLS APPL, V74, P2991, DOI 10.1007/s11042-013-1765-5
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang C., 2015, INT J IMAGE PROCESS, V9, P156
   Wang CC, 2010, OPT ENG, V49, DOI 10.1117/1.3309472
   Wang CC, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, PROCEEDINGS, P77, DOI 10.1109/ISDA.2008.279
   Wang RD, 2012, J INFORM COMPUTATION, V9, P3693
   Wang S, 2014, MEASUREMENT, V48, P54, DOI 10.1016/j.measurement.2013.10.028
   Weiwei Zhang, 2012, Journal of Networks, V7, P1150, DOI 10.4304/jnw.7.8.1150-1154
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu DW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033028
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2011, OPT ENG, V50, DOI 10.1117/1.3622759
   Zhang Y, 2011, IEEE T BROADCAST, V57, P15, DOI 10.1109/TBC.2010.2082670
   Zhao J, 2018, MULTIMEDIA SYST, V24, P95, DOI 10.1007/s00530-016-0529-2
   Zhou Y, 2012, COMPUT ELECTR ENG, V38, P217, DOI 10.1016/j.compeleceng.2011.12.011
   Zou DK, 2008, INT CONF ACOUST SPEE, P1749, DOI 10.1109/ICASSP.2008.4517968
NR 40
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9737
EP 9762
DI 10.1007/s11042-018-6538-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400011
DA 2024-07-18
ER

PT J
AU Liu, G
   Huang, FJ
   Li, ZH
AF Liu, Ge
   Huang, Fangjun
   Li, Zhonghua
TI Designing adaptive JPEG steganography based on the statistical
   properties in spatial domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE steganography; JPEG; spatial domain characteristic
AB Steganography is an important branch of information hiding, which is an effective way to solve the problem of communication security. Steganography can hide specific secret information in some kind of public information, such as images, documents, audio and video, without any suspicion. Joint Photographic Experts Group (JPEG) compressed image is the most widely used image format on the Internet. Recently, a series of JPEG image steganographic algorithms have been proposed. However, the existing JPEG steganography usually designs the cost function based on the statistical distribution in the DCT domain. In this paper, with the help of a Microscope, which can enhance the JPEG images in the spatial domain and highlight the texture regions, we design the steganographic cost function based on the statistical distribution of JPEG images in spatial domain and work out a JPEG image steganography with high security performance. Experimental results demonstrate that the proposed designing strategy is a practical approach to against several existing state-of-the-art steganalytic tools.
C1 [Liu, Ge; Li, Zhonghua] Sun Yat Sen Univ, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Fangjun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Fangjun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Huang, FJ (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.; Huang, FJ (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM huangfj@mail.sysu.edu.cn
FU National Natural Science Foundation of China [61772572]; NSFC-NRF
   Scientific Cooperation Program [61811540409]; Natural Science Foundation
   of Guangdong Province of China [2017A030313366]; Fundamental Research
   Funds for Central Universities [17lgjc45]
FX This work is partially supported by the National Natural Science
   Foundation of China (61772572), the NSFC-NRF Scientific Cooperation
   Program (61811540409), the Natural Science Foundation of Guangdong
   Province of China (2017A030313366), and the Fundamental Research Funds
   for Central Universities (17lgjc45).
CR [Anonymous], IEEE T INFORM FORENS
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], P 1 ACM INF HID MULT
   [Anonymous], 2011, P 13 INF HID C PRAG
   Chen KJ, 2016, IEEE INT WORKS INFOR
   Crandall R., 1998, Steganography Mailing List
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2004, MMSEC 04, P4
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Sallee P, 2005, INT J IMAGE GRAPH, V5, P167, DOI 10.1142/S0219467805001719
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Zhang RY, 2009, LECT NOTES COMPUT SC, V5806, P48, DOI 10.1007/978-3-642-04431-1_4
   Zhang WM, 2010, IEEE T INFORM THEORY, V56, P1262, DOI 10.1109/TIT.2009.2039087
   Zhang WM, 2009, IEEE T INF FOREN SEC, V4, P564, DOI 10.1109/TIFS.2009.2024720
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 23
TC 0
Z9 0
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8655
EP 8665
DI 10.1007/s11042-018-6747-1
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800041
DA 2024-07-18
ER

PT J
AU Qi, WF
   Yang, GY
   Zhang, T
   Guo, ZM
AF Qi, Wenfa
   Yang, Guangyuan
   Zhang, Tong
   Guo, Zongming
TI Improved reversible visible image watermarking based on HVS and
   ROI-selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible visible watermarking; Adaptive block partition; Visual effect
   factor; ROI-selection; Human visual system
ID SCHEME; RECOVERY; ROBUST
AB Reversible visible watermarking is used to combat the copyright infringement which can perfectly restore the original cover image by removing the embedded visible watermark. This paper proposes an improved reversible visible image watermarking scheme based on human visual system (HVS) and a region of interest selection (ROI-selection) strategy. Firstly, the cover image is partitioned into non-overlapped blocks. Then, a visual effect factor (VEF) based on HVS is adopted to adaptively modify the pixel values, which can provide a better fusion effect for the visible watermark and the cover image. The VEF value is determined by using the estimated watermarked and non-watermarked blocks within the neighborhood of each block. Finally, the visible watermark is embedded into the divided blocks using the traditional difference-expansion method, and a ROI-selection strategy is designed to find the most suitable regions for watermark embedding. Experimental results show the effectiveness and superiority of the proposed scheme compared to some existing works.
C1 [Qi, Wenfa; Yang, Guangyuan; Zhang, Tong; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
C3 Peking University
RP Guo, ZM (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM qiwenfa@pku.edu.cn; yanggy@pku.edu.cn; zhangtong1204@pku.edu.cn;
   guozongming@pku.edu.cn
RI Yang, Guangyuan/B-9256-2012; zhang, tong/JAO-3571-2023; zhen,
   wang/KBA-3844-2024
FU National Science Foundation of China [61572052, U1636206]; National R&D
   project of China [2018YFB0803402]
FX This work is supported by the National Science Foundation of China
   (Nos.61572052, U1636206 and National R&D project of China under contract
   No. 2018YFB0803402).
CR [Anonymous], ACCESS
   Barni M, 2002, IEEE T CIRC SYST VID, V12, P142, DOI 10.1109/76.993436
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   LI X, 1991, TIP, V22, P2181, DOI DOI 10.1109/TIP.2013.2246179
   LI X, 1933, TIP, V20, P3524, DOI DOI 10.1109/TIP.2011.2150233
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   LIU TY, 1935, TIP, V19, P1224, DOI DOI 10.1109/TIP.2010.2040757
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma Y, 2018, IEEE T CIRCUITS SYST, V10, P2799
   Ma Y, 2018, IEEE T CIRCUITS SYST, V10, P243
   Ng TM, 2005, IEEE SIGNAL PROC LET, V12, P285, DOI 10.1109/LSP.2005.843776
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   OU B, 2013, TIP, V22, P5010, DOI DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2016, INFORM SCIENCES, V361, P84, DOI 10.1016/j.ins.2016.04.036
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2106
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Yang GY, 2017, LECT NOTES COMPUT SC, V10431, P303, DOI 10.1007/978-3-319-64185-0_23
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Yip SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P853, DOI 10.1109/ICME.2006.262635
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P826, DOI 10.1109/ChinaSIP.2015.7230520
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 45
TC 8
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8289
EP 8310
DI 10.1007/s11042-018-6812-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800023
DA 2024-07-18
ER

PT J
AU Valandar, MY
   Barani, MJ
   Ayubi, P
   Aghazadeh, M
AF Valandar, Milad Yousefi
   Barani, Milad Jafari
   Ayubi, Peyman
   Aghazadeh, Maryam
TI An integer wavelet transform image steganography method based on 3D sine
   chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image steganography; Integer wavelet transform; Sine chaotic map;
   Data hiding
ID DATA HIDING SCHEME; ENCRYPTION ALGORITHM; WATERMARKING; CRYPTANALYSIS
AB Steganography is one of the well-known data hiding methods, which is used in many security companies and government communications. In this technique, the various types of digital media can be used as a cover to hide secret information without impress the general form of them. Generally, key space and security are two important matters in most steganography methods, and they have the direct impact in proposed method's security. Moreover, Chaotic maps have been used in many data hiding algorithms to increase the security and key space of proposed schemes. The main reasons of using chaotic maps in steganography methods are sensitivity to initial conditions and control parameters. This paper proposes a new steganography technique based on new 3d sine chaotic map. This map is used in embedding and extracting processes to increase the security of the proposed algorithm. Satisfactory performance, acceptable image distortion and stronger robustness against some attacks are the main features of proposed method, and they are shown in experimental results. Comparison with some existing method shows that the quality and performance of the proposed algorithm are good, and it has high security and acceptable robustness against cropping and salt & pepper attacks.
C1 [Valandar, Milad Yousefi; Barani, Milad Jafari] Islamic Azad Univ, Young Researchers & Elite Club, Urmia Branch, Orumiyeh, Iran.
   [Ayubi, Peyman; Aghazadeh, Maryam] Islamic Azad Univ, Dept Comp Engn, Urmia Branch, Orumiyeh, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Valandar, MY (corresponding author), Islamic Azad Univ, Young Researchers & Elite Club, Urmia Branch, Orumiyeh, Iran.
EM milad_yousefi@hotmail.com; milad.jafare@gmail.com;
   p.ayubi@iaurmia.ac.ir; maryam_aghazadeh@hotmail.com
RI Barani, Milad Jafari/AAE-4503-2019; Valandar, Milad/AAD-4670-2019;
   Ayubi, Peyman/Q-3006-2019
OI Barani, Milad Jafari/0000-0002-9631-9889; Valandar,
   Milad/0000-0003-3637-9262; Ayubi, Peyman/0000-0002-2765-6224
CR Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Barani MJ, 2015, SECUR COMMUN NETW, V8, P4343, DOI 10.1002/sec.1365
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chakraborty S, 2017, STUD COMPUT INTELL, V660, P133, DOI 10.1007/978-3-319-44790-2_7
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Chen XY, 2016, CHINA COMMUN, V13, P66, DOI 10.1109/CC.2016.7559077
   Cheng WC, 2004, IEEE T CONSUM ELECTR, V50, P320, DOI 10.1109/TCE.2004.1277880
   El Hennawy HMS, 2015, AIN SHAMS ENG J, V6, P57, DOI 10.1016/j.asej.2014.08.001
   Martínez-González RF, 2016, COMPUT ELECTR ENG, V54, P435, DOI 10.1016/j.compeleceng.2015.12.005
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hilborn R. C., 2000, CHAOS NONLINEAR DYNA
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Jassim FA, ARXIV13070642
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kumar M, 2017, J INF SECUR APPL, V32, P47, DOI 10.1016/j.jisa.2016.09.002
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li YB, 2017, INFORM SCIENCES, V387, P103, DOI 10.1016/j.ins.2016.09.005
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Muhammad K, ARXIV151004413
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Parah SA, 2017, INTEL SYST REF LIBR, V115, P223, DOI 10.1007/978-3-319-44270-9_10
   Parah SA, 2017, MULTIDIM SYST SIGN P, V28, P549, DOI 10.1007/s11045-015-0358-z
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2014, MULTIMED TOOLS APPL, V72, P987, DOI 10.1007/s11042-013-1653-z
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Zhang LH, 2016, OPT LASER ENG, V86, P329, DOI 10.1016/j.optlaseng.2016.06.025
NR 45
TC 57
Z9 57
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9971
EP 9989
DI 10.1007/s11042-018-6584-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400022
DA 2024-07-18
ER

PT J
AU Zhang, HL
   Xia, CX
   Gao, XJ
AF Zhang, Hanling
   Xia, Chenxing
   Gao, Xiuju
TI Action recognition based on multi-stage jointly training convolutional
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Convolutional neural network; Multi-stage training
AB In this paper, we consider multi-stage jointly training two-stream convolutional neural network for action recognition in videos. The challenge of action recognition is to extract appearance and motion information to describe actions efficiently and to classify videos of different levels correctly. The proposed architecture has preferable model capacity and it enables us to obtain appearance and motion information validly from images in videos. Besides, with the proposed multi-stage jointly training strategy, multiple classifiers are jointly optimized to process different qualities samples of action videos. Finally, the Support Vector Machine classifier is employed to replace Softmax classifier, achieving decent classification results. Our model is trained and evaluated on the standard actions benchmark of UCF-101, and we also test the model on HMDB51 dataset through transfer learning, proving that our method is competitive with the state of the art.
C1 [Zhang, Hanling; Xia, Chenxing; Gao, Xiuju] Hunan Univ, Coll Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Zhang, Hanling] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
C3 Hunan University; Nanjing University of Information Science & Technology
RP Xia, CX (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM jt_hlzhang@hnu.edu.cn; starry@hnu.edu.cn; S131010061@hnu.edu.cn
RI Xia, Chenxing/GYQ-6472-2022
OI Xia, Chenxing/0000-0003-0750-1265
FU National Natural Science Foundation of China [61672222, 61572183]; Key
   Science and Technology Planning Project of Hunan province, China
   [2014GK2007]; Priority Academic Program Development of Jiangsu Higer
   Education Institutions; Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology
FX This work was Supported by the National Natural Science Foundation of
   China (Grant No.61672222, 61572183), the Key Science and Technology
   Planning Project of Hunan province, China (Grant No.2014GK2007), the
   Priority Academic Program Development of Jiangsu Higer Education
   Institutions; Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology.
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2015, ARXIV150702159
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, ARXIV
   [Anonymous], 2012, CoRR
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kaynak C, 1997, PROCEEDINGS OF THE 1997 IEEE INTERNATIONAL SYMPOSIUM ON INTELLIGENT CONTROL, P95, DOI 10.1109/ISIC.1997.626420
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan T, 2015, IEEE I CONF COMP VIS, P4552, DOI 10.1109/ICCV.2015.517
   Liang D, 2014, INT CONF INFO SCI, P401, DOI 10.1109/ICIST.2014.6920502
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Murthy OVR, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P412, DOI 10.1109/ICCVW.2013.61
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Simonyan K., 2014, 14091556 ARXIV
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Visin F., 2015, CoRR
   Wang KZ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P97, DOI 10.1145/2647868.2654912
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xu WR, 2015, MULTIMED TOOLS APPL, V74, P7711, DOI 10.1007/s11042-014-2007-1
NR 30
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9919
EP 9931
DI 10.1007/s11042-018-6622-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400019
DA 2024-07-18
ER

PT J
AU Zhang, R
   Dong, SQ
   Liu, JY
AF Zhang, Ru
   Dong, Shiqi
   Liu, Jianyi
TI Invisible steganography via generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Generative adversarial networks; Convolutional
   neural network
ID IMAGE QUALITY ASSESSMENT; STEGANALYSIS
AB Nowadays, there are plenty of works introducing convolutional neural networks (CNNs) to the steganalysis and exceeding conventional steganalysis algorithms. These works have shown the improving potential of deep learning in information hiding domain. There are also several works based on deep learning to do image steganography, but these works still have problems in capacity, invisibility and security. In this paper, we propose a novel CNN architecture named as ISGAN to conceal a secret gray image into a color cover image on the sender side and exactly extract the secret image out on the receiver side. There are three contributions in our work: (i) we improve the invisibility by hiding the secret image only in the Y channel of the cover image; (ii) We introduce the generative adversarial networks to strengthen the security by minimizing the divergence between the empirical probability distributions of stego images and natural images. (iii) In order to associate with the human visual system better, we construct a mixed loss function which is more appropriate for steganography to generate more realistic stego images and reveal out more better secret images. Experiment results show that ISGAN can achieve start-of-art performances on LFW, PASCAL-VOC12 and ImageNet datasets.
C1 [Zhang, Ru; Dong, Shiqi; Liu, Jianyi] Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Xitucheng Rd 10, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Dong, SQ (corresponding author), Beijing Univ Posts & Telecommun, Sch Cyberspace Secur, Xitucheng Rd 10, Beijing, Peoples R China.
EM zhangru@bupt.edu.cn; shiqidong@bupt.edu.cn
FU National key Research and Development Program of China [2016YFB0800404];
   NSF of China [U1636112, U1636212]
FX This work was supported by the National key Research and Development
   Program of China(No.2016YFB0800404) and the NSF of
   China(U1636112,U1636212).
CR [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ARXIV171107201
   [Anonymous], 2016, P INT C LEARN REPR I
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, ICLR 2016 OPEN REV
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2016.2572683
   [Anonymous], 2017, P 5 ACM WORKSH INF H
   Arjovsky M, 2017, arXiv preprint arXiv:1701.07875
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Glorot X., 2010, P INT C ART INT STAT, P249
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hayes J, 2017, ADV NEUR IN, V30
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Huang G.B., 2008, PROC WORKSHOP FACES
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang J., 2018, ARXIV180407939
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zeng JS, 2018, IEEE T INF FOREN SEC, V13, P1200, DOI 10.1109/TIFS.2017.2779446
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
NR 32
TC 93
Z9 106
U1 7
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8559
EP 8575
DI 10.1007/s11042-018-6951-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800037
OA hybrid
DA 2024-07-18
ER

PT J
AU Amiri, MD
   Meghdadi, M
   Amiri, A
AF Amiri, Mehran Deljavan
   Meghdadi, Majid
   Amiri, Ali
TI HVS-based scalable image watermarking: A novel approach to image
   copyright protection against scalable compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Scalable watermarking; Image compression; Scalability;
   Human vision system; DWT coding
ID HUMAN VISUAL-SYSTEM; ROBUST; ALGORITHM; SCHEME
AB This paper proposes a novel human vision system based, spread spectrum method to scalable image watermarking. A scalable decomposition of the watermark is spread into the entire frequency sub-bands of the wavelet decomposed image. At each wavelet sub-band, the watermark data are inserted into the selected coefficients of the sub-band in a manner that the watermark embedding visual artifact occurs in the highly textured, highly contrasted and very dark/bright areas of the image. In the lowest frequency sub-band of wavelet transform, the coefficients are selected by independent analysis of texture, contrast and luminance information. In high frequency sub-bands, the coefficient selection is done by analyzing coefficients amplitude and local entropy. The experimental results show that the watermarked test images are highly transparent and robust against scalable wavelet-based image coding even at very low bit-rate coding. The proposed approach can guarantee content authentication for scalable coded images, especially on heterogeneous networks which different users with different process capabilities and network access bandwidth use unique multimedia sources.
C1 [Amiri, Mehran Deljavan] Univ Zanjan, Artificial Intelligence, Zanjan, Iran.
   [Meghdadi, Majid; Amiri, Ali] Univ Zanjan, Comp Engn Dept, Zanjan, Iran.
C3 University Zanjan; University Zanjan
RP Meghdadi, M (corresponding author), Univ Zanjan, Comp Engn Dept, Zanjan, Iran.
EM meghdadi@znu.ac.ir
RI Amiri, Ali/AAF-8693-2019
CR Abhayaratne C, 2013, J REAL-TIME IMAGE PR, V8, P307, DOI 10.1007/s11554-011-0218-5
   Akhaee MA, 2013, ISECURE-ISC INT J IN, V5, P5
   Amiri MD, 2011, ISECURE-ISC INT J IN, V3, P51
   [Anonymous], P TENCON 2005 2005 I
   [Anonymous], 2017, 2017 7 INT S EMBEDDE, DOI [DOI 10.1109/ISED.2017.8303936, 10.1109/ISED.2017.8303936]
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Bansal Dimple, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P630, DOI 10.1109/ICOEI.2017.8300779
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bhatnagar G, 2012, COMPUT ELECTR ENG, V38, P1164, DOI 10.1016/j.compeleceng.2012.02.002
   Bhowmik D, 2009, P INT WORKSH DIG SIG, P1
   Bhowmik D., 2011, THESIS
   Bhowmik D, 2016, IEEE T IMAGE PROCESS, V25, P5158, DOI 10.1109/TIP.2016.2599785
   Bhowmik D, 2014, MULTIMEDIA SYST, V20, P239, DOI 10.1007/s00530-013-0334-0
   Boroumand Mehdi, 2009, 2009 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2009), P268, DOI 10.1109/ICSIPA.2009.5478604
   Charrier M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P131, DOI 10.1109/MMCS.1999.779134
   Chen TPC, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1025, DOI 10.1109/ICME.2000.871534
   Chen TS, 2004, MULTIMEDIA SYST, V10, P16, DOI 10.1007/s00530-004-0133-8
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Chunhua L., 2011, INT C E BUS E GOV IC, P1
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Danyali H, 2004, IEE P-VIS IMAGE SIGN, V151, P498, DOI 10.1049/ip-vis:20040734
   Danyali H, 2004, HIGHLY SCALABLE WAVE
   Danyali H., 2003, J TELECOMMUNICATIONS, V2, P92
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Davis GM, 1999, APPL COMPUT CONT SIG, V1, P369
   Deb K., 2010, MULTIOBJECTIVE OPTIM
   Dufaux F, 2004, SPIE P APPL DIG IM P
   Fatemizadeh E, 2012, COMPUT INFORM, V31, P877
   Feng XC, 2005, LECT NOTES ARTIF INT, V3802, P1122
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hmida A. B., 2018, 2018 4th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P1
   Hsiang S, 2003, HIGHLY SCALABLE SUBB
   Huo FF, 2006, IEEE IMAGE PROC, P2573, DOI 10.1109/ICIP.2006.312985
   Islam M, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING, INSTRUMENTATION AND CONTROL TECHNOLOGIES (ICICICT), P1426, DOI 10.1109/ICICICT1.2017.8342779
   Jin C., 2006, INFORM TECHNOLOGY J, V5, P358, DOI DOI 10.3923/itj.2006.358.363
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Lewis AS, 1992, IEEE T IMAGE PROCESS, V1, P244, DOI 10.1109/83.136601
   Li W, 1998, JTC1SC29WG11 ISOIEC
   Lumini A., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P122, DOI 10.1109/ITCC.2000.844194
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marusic S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P463
   Mazumdar H., 2015, INT C WORKSH COMP CO, P1
   Meerwald P, 2001, COMMUNICATIONS MULTI, P69
   Meerwald P, 2009, LECT NOTES COMPUT SC, V5450, P61, DOI 10.1007/978-3-642-04438-0_6
   Mekarsari Yudit Arum, 2018, 2018 International Conference on Information and Communications Technology (ICOIACT), P623, DOI 10.1109/ICOIACT.2018.8350793
   Mittal Ninny, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P561, DOI 10.1109/ICOEI.2017.8300763
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Petitcolas FAP, 2001, PROC SPIE, V4314, P575, DOI 10.1117/12.435442
   Piper A, 2010, SCALABLE WATERMARKIN
   PIPER A, 2005, P 7 WORKSH MULT SEC, P79, DOI DOI 10.1145/1073170.1073186
   Piper A, 2013, IET INFORM SECUR, V7, P300, DOI 10.1049/iet-ifs.2010.0059
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Selvan S, 2007, IEEE T IMAGE PROCESS, V16, P2688, DOI 10.1109/TIP.2007.908082
   Soheili Mohammad Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1449, DOI 10.1109/ICPR.2010.358
   Sorkhabi AE, 2017, SOFT COMPUT, V21, P7251, DOI 10.1007/s00500-016-2422-5
   Su PC, 2001, J VLSI SIG PROC SYST, V27, P35, DOI 10.1023/A:1008111228727
   Suhail MA, 2003, INFORM SCIENCES, V151, P93, DOI 10.1016/S0020-0255(02)00291-8
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sun QB, 2005, IEEE T MULTIMEDIA, V7, P480, DOI 10.1109/TMM.2005.846776
   Tao HJ, 2001, P SOC PHOTO-OPT INS, V4551, P239, DOI 10.1117/12.442919
   Verma P. K., 2017, 2017 8 INT C COMP CO, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SPIE, V1913
   Xie LH, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P427, DOI 10.1109/ICIP.1998.723409
   Zhang ZP, 2001, PROC SPIE, V4551, P127, DOI 10.1117/12.442900
NR 68
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7097
EP 7124
DI 10.1007/s11042-018-6419-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700031
DA 2024-07-18
ER

PT J
AU Huang, XD
AF Huang, Xiaodong
TI A new video text extraction using local laplacian filters and mean shift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video text; Text extraction; Local laplacian filters; Mean shift
ID SEGMENTATION
AB Video text constitutes the semantic context of the video. For that reason, robust extraction of text is essential for successful video understanding, search and retrieval. Extracting text from background is an important phrase before the text can be recognized correctly. It is a challenging task because of the difficulties in text segmentation from the varied and complicated backgrounds. Therefore, this paper proposes a novel text extraction method to tackle this issue. First, we perform background complexity determination to distinguish the text lines with clear and simple background from those with complex background, which will increase the extraction speed. Then, for the text lines with complicated background and low contrast, we utilize the Local Laplacian Filters Commun ACM 58(3):81-91 [18] to enhance the details of text regions and get the Integrated Enhanced Map (IEM). Finally, we perform the Mean Shift IEEE Trans Pattern Anal Mach Intell 24(5):603-619 [4] for the segmentation on IEM and retrieve the text extraction results. Experimental evaluations based on a variety of videos dataset we collected demonstrate that our method significantly outperforms the other three video text extraction algorithms in terms of recall, precision and F-score, especially when there are challenges such as video text with different font sizes, font styles, languages, and background complexities.
C1 [Huang, Xiaodong] Capital Normal Univ, Beijing 100048, Peoples R China.
C3 Capital Normal University
RP Huang, XD (corresponding author), Capital Normal Univ, Beijing 100048, Peoples R China.
EM hxd@cnu.edu.cn
FU Beijing Natural Science Foundation [4173073]; Surface Project of Beijing
   Committee of Education [KM201710028021]; Capacity Building for Sci-Tech
   Innovation - Fundamental Scientific Research Funds [025185305000/152]
FX This work reported in this paper is supported by Beijing Natural Science
   Foundation(4173073); the Surface Project of Beijing Committee of
   Education under Grant No. KM201710028021; Supported by Capacity Building
   for Sci-Tech Innovation - Fundamental Scientific Research Funds
   (025185305000/152).
CR [Anonymous], 2013, P 12 INT C DOC AN RE
   Bai B, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P262, DOI 10.1109/DAS.2014.34
   Cho MS, 2011, PROC INT CONF DOC, P1034, DOI 10.1109/ICDAR.2011.209
   Clavelli A., 2010, Proceedings of the 9th IAPR International Workshop on Document Analysis Systems, P19
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Gómez L, 2013, PROC INT CONF DOC, P467, DOI 10.1109/ICDAR.2013.100
   Hedjam R, 2011, PROC INT CONF DOC, P172, DOI 10.1109/ICDAR.2011.43
   Kachouri R, 2015, IEEE IMAGE PROC, P527, DOI 10.1109/ICIP.2015.7350854
   Kavitha AS, 2016, EGYPT INFORM J, V17, P189, DOI 10.1016/j.eij.2015.11.003
   Kim W, 2009, IEEE T IMAGE PROCESS, V18, P401, DOI 10.1109/TIP.2008.2008225
   Lee S, 2010, SCENE TEXT EXTRACTIO, P3983
   Lee S, 2013, IMAGE VISION COMPUT, V31, P823, DOI 10.1016/j.imavis.2013.08.007
   Li XJ, 2009, IEEE INT CON MULTI, P510, DOI 10.1109/ICME.2009.5202545
   Li Z, 2011, IET IMAGE PROCESS, V5, P671, DOI 10.1049/iet-ipr.2010.0397
   Liu Y, 2013, PROC INT CONF DOC, P1355, DOI 10.1109/ICDAR.2013.274
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   Paris S, 2015, COMMUN ACM, V58, P81, DOI 10.1145/2723694
   Roy A, 2013, PROC INT CONF DOC, P892, DOI 10.1109/ICDAR.2013.182
   Saric M, 2017, NEUROCOMPUTING, V266, P56, DOI 10.1016/j.neucom.2017.05.021
   Sumathi C. P., 2014, Journal of Computer Science, V10, P705, DOI 10.3844/jcssp.2014.705.715
   Wang R, P 17 INT C PATT REC
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Zhang ZK, 2014, INT C PATT RECOG, P2938, DOI 10.1109/ICPR.2014.506
NR 23
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6989
EP 7004
DI 10.1007/s11042-018-6451-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700026
DA 2024-07-18
ER

PT J
AU Liu, D
   Chen, XY
AF Liu, Di
   Chen, Xiyuan
TI Image denoising based on improved bidimensional empirical mode
   decomposition thresholding technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BEMD; Image denoising; Noise compression
ID PARALLEL FRAMEWORK; SIGNAL; EMD; FILTER
AB In this paper, a novel image denoising methodology based on improved bidimensional empirical mode decomposition and soft interval thresholding technique is proposed. First, a noise compressed image is constructed. Then, the noise compressed image is decomposed by means of bidimensional empirical mode decomposition (BEMD) into a series of intrinsic mode functions (IMFs), which are separated into signal-dominant IMFs and noise-dominant IMFs using a similarity measure based on 2-norm and a probability density function, and a soft interval thresholding technique is used adaptively to remove the noise inherent in noise-dominant IMFs. Finally, a denoised image is reconstructed by combining the signal-dominant IMFs and the denoised noise-dominant IMFs. The performance of the proposed denoising method is evaluated by using multiple images with different types of noise, and results from the proposed method are compared with those of other conventional methods in various noisy environments. Simulation results demonstrate that the proposed denoising method outperforms other denoising methods in terms of peak signal-to-noise ratio, mean square error and energy of the first IMF.
C1 [Liu, Di; Chen, Xiyuan] Southeast Univ, Sch Instrument Sci & Engn, Minist Educ, Key Lab Microinertial Instrument & Adv Nav Techno, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Chen, XY (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, Minist Educ, Key Lab Microinertial Instrument & Adv Nav Techno, Nanjing 210096, Jiangsu, Peoples R China.
EM chxiyuan@seu.edu.cn
RI Chen, Xiyuan/AAA-1144-2020
FU National Natural Science Foundation of China [51375087, 51405203];
   Transformation Program of Science and Technology Achievements of Jiangsu
   Province [BA2016139]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 51375087, 51405203) and the Transformation Program of
   Science and Technology Achievements of Jiangsu Province (Grant No.
   BA2016139).
CR Abergel Remy, 2015, Scale Space and Variational Methods in Computer Vision. 5th International Conference, SSVM 2015. Proceedings: LNCS 9087, P178, DOI 10.1007/978-3-319-18461-6_15
   Ahn JH, 2014, SENSORS-BASEL, V14, P15022, DOI 10.3390/s140815022
   Amo C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17050989
   An FP, 2015, INT J ANTENN PROPAG, V2015, DOI 10.1155/2015/769478
   [Anonymous], 2008, EUROPEAN SIGNAL PROC
   Bindilatti AA, 2018, SIGNAL PROCESS, V144, P68, DOI 10.1016/j.sigpro.2017.10.001
   Bindilatti AA, 2013, IEEE SIGNAL PROC LET, V20, P1010, DOI 10.1109/LSP.2013.2277111
   BIOUCASDIAS JM, 1971, TIP, V19, P1720, DOI DOI 10.1109/TIP.2010.2045029
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   CUI BB, 1987, TSP, V65, P2975, DOI DOI 10.1109/TSP.2017.2679685
   Cui BB, 2015, SENSOR ACTUAT A-PHYS, V230, P150, DOI 10.1016/j.sna.2015.04.021
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deering R, 2005, INT CONF ACOUST SPEE, P485
   Deledalle CA, 2010, IEEE IMAGE PROC, P801, DOI 10.1109/ICIP.2010.5653394
   DEZA M, 2009, ENCY DISTANCES, P94
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Flandrin P., 2005, INTERDISCIPLINARY MA, P99, DOI [10.1142/9789814508247_0005, DOI 10.1142/9789814508247_0005]
   Gan L, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P328, DOI 10.1109/SPAC.2014.6982709
   He Z, 2013, IEEE T INSTRUM MEAS, V62, P889, DOI 10.1109/TIM.2013.2246917
   Huang N.E., 1971, Series A: mathematical, physical and engineering sciences, V454, P903
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Kabir MA, 2012, BIOMED SIGNAL PROCES, V7, P481, DOI 10.1016/j.bspc.2011.11.003
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   Khaldi K, 2014, J ACOUST SOC AM, V135, P451, DOI 10.1121/1.4837835
   Komaty A, 2014, IEEE T INSTRUM MEAS, V63, P27, DOI 10.1109/TIM.2013.2275243
   KOPSINIS Y, 1991, TSP, V57, P1351, DOI DOI 10.1109/TSP.2009.2013885
   Labate D, 2013, IEEE SENS J, V13, P2666, DOI 10.1109/JSEN.2013.2257742
   Louchet C, 2014, EUR SIGNAL PR CONF, P1592
   MAGGIONI M, 1973, TIP, V22, P119, DOI DOI 10.1109/TIP.2012.2210725
   Niu J, 2017, MULTIMED TOOLS APPL, V76, P10427, DOI 10.1007/s11042-016-3430-2
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Omitaomu OA, 2011, IEEE SENS J, V11, P2565, DOI 10.1109/JSEN.2011.2142302
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Valles-Novo R, 2015, IEEE T INSTRUM MEAS, V64, P1118, DOI 10.1109/TIM.2014.2373513
   Wang SH, 2018, COMPLEXITY, DOI 10.1155/2018/3198184
   Xu Y, 2018, MEASUREMENT, V123, P1, DOI 10.1016/j.measurement.2018.03.043
   YAN CC, 2018, TMM, V14, P1, DOI DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yu B, 2017, J MOL GRAPH MODEL, V76, P260, DOI 10.1016/j.jmgm.2017.07.012
   ZAO L, 2014, PROCESS, V22, P899, DOI DOI 10.1109/TASLP.2014.2312541
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
NR 46
TC 20
Z9 21
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7381
EP 7417
DI 10.1007/s11042-018-6503-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700044
DA 2024-07-18
ER

PT J
AU Mahmoudi, N
   Ahadi, SM
   Rahmati, M
AF Mahmoudi, Nima
   Ahadi, Seyed Mohammad
   Rahmati, Mohammad
TI Multi-target tracking using CNN-based features: CNNMTT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-target tracking; Machine vision; Tracking-by-detection;
   Multi-Object tracking; Video surveillance; Pedestrian tracking
ID MOTION PATTERNS
AB In this paper, we focus mainly on designing a Multi-Target Object Tracking algorithm that would produce high-quality trajectories while maintaining low computational costs. Using online association, such features enable this algorithm to be used in applications like autonomous driving and autonomous surveillance. We propose CNN-based, instead of hand-crafted, features to lead to higher accuracies. We also present a novel grouping method for 2-D online environments without prior knowledge of camera parameters and an affinity measure based on the groups maintained in previous frames. Comprehensive evaluations of our algorithm (CNNMTT) on a publicly available and widely used dataset (MOT16) reveal that the CNNMTT method achieves high quality tracking results in comparison to the state of the art while being faster and involving much less computational cost.
C1 [Mahmoudi, Nima; Ahadi, Seyed Mohammad; Rahmati, Mohammad] Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Mahmoudi, N (corresponding author), Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
EM nima_mahmoudi@aut.ac.ir; sma@aut.ac.ir; rahmati@aut.ac.ir
RI Mahmoudi, Nima/AAD-2390-2020
OI Mahmoudi, Nima/0000-0002-2592-9559
CR Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   [Anonymous], 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]
   [Anonymous], 2006, P INT EVAL WORKSH CL
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Donahue J, 2014, PR MACH LEARN RES, V32
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532
   Henschel R., 2016, ARXIV160707304
   Hu M, 2008, INT C PATT RECOG, P9
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Keuper M, 2016, arXiv preprint arXiv:1607.06317
   Kratz L, 2010, PROC CVPR IEEE, P693, DOI 10.1109/CVPR.2010.5540149
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee B., 2016, ARXIV160808434
   Lee B, 2016, LECT NOTES COMPUT SC, V9914, P68, DOI 10.1007/978-3-319-48881-3_6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milan A., 2016, ARXIV160300831
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Mitzel D, 2011, COMP VIS WORKSH ICCV, P974
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Possegger H, 2014, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2014.170
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sanchez-Matilla R., 2016, ECCV Workshops-Benchmarking Multi-Target Tracking, V5, page, P18
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Sugimura D, 2009, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2009.5459286
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang M, 2007, IEEE I CONF COMP VIS, P897
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao XM, 2012, LECT NOTES COMPUT SC, V7573, P315, DOI 10.1007/978-3-642-33709-3_23
NR 43
TC 98
Z9 116
U1 6
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7077
EP 7096
DI 10.1007/s11042-018-6467-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700030
DA 2024-07-18
ER

PT J
AU Martin, V
   Séguier, R
   Porcheron, A
   Morizot, F
AF Martin, Victor
   Seguier, Renaud
   Porcheron, Aurelie
   Morizot, Frederique
TI Face aging simulation with a new wrinkle oriented active appearance
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face aging; Age progression; Age estimation; Active appearance model
ID AGE; PERCEPTION; SHAPE; ATTRACTIVENESS; PREDICTION
AB The use of computer simulation to understand how human faces age has been a growing area of research since decades. It has been applied to the search for missing children as well as to the fields of entertainment, cosmetics and dermatology research. Our objective is to elaborate a model for the age-related changes of visual cues which affect the perception of age, so that we may better predict them. Traditional approaches based on the Active Appearance Model (AAM) tend to blurry appearance and wipe out texture details such as wrinkles. We introduce Wrinkle Oriented Active Appearance Model (WOAAM) where a new channel is added to the AAM dedicated to analyze wrinkles. Firstly, we propose to represent both the shape and texture of each wrinkle on a face by a compact and interpretable vector. Afterwards, to model the distribution of wrinkles on a face, we introduce a new way to approximate an empiric joint probability density by creating an ensemble of joint probability densities estimated by Kernel Density Estimation. Finally, we show how to create new samples from such an ensemble of densities, and thus synthesize new plausible wrinkles. In comparison to other methods which add wrinkles at post-processing level, our method fully integrates them in AAM. Thereby, the wrinkles generated are statistically representative of a specific age in terms of number, length, shape and intensity. With an age estimation Convolutional Neural Network, we found that age-progressed faces produced by the WOAAM better reduces the gap between the expected age and the estimated age than those produced by a classic AAM.
C1 [Martin, Victor; Seguier, Renaud] Cent Supelec, Ave Boulaie, F-35510 Cesson Sevigne, France.
   [Martin, Victor; Porcheron, Aurelie; Morizot, Frederique] Chanel, 8 Rue Cheval Blanc, F-93500 Pantin, France.
C3 Universite Paris Saclay
RP Martin, V (corresponding author), Cent Supelec, Ave Boulaie, F-35510 Cesson Sevigne, France.; Martin, V (corresponding author), Chanel, 8 Rue Cheval Blanc, F-93500 Pantin, France.
EM victor@vmartin.fr
OI Seguier, Renaud/0000-0001-7199-7563
CR Aarabi P, 2013, BRANDS ARE USING FAC
   [Anonymous], 2017, ARXIV170208423
   [Anonymous], 2017, ARXIV170201983
   Boissieux L, 2000, SPRING COMP SCI, P15
   Bukar Ali Maina, 2016, ADV INTELLIGENT SYST, P465
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   Donofrio LM, 2000, DERMATOL SURG, V26, P1107, DOI 10.1046/j.1524-4725.2000.00270.x
   Farkas LG, 2004, J CRANIOFAC SURG, V15, P288, DOI 10.1097/00001665-200403000-00027
   Fink B, 2006, EVOL HUM BEHAV, V27, P433, DOI 10.1016/j.evolhumbehav.2006.08.007
   FU Y, 1976, TPAMI, V32, P1955, DOI DOI 10.1109/TPAMI.2010.36
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guyuron B, 2009, PLAST RECONSTR SURG, V123, P1321, DOI 10.1097/PRS.0b013e31819c4d42
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P131, DOI 10.1109/ICCV.1999.791208
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Latreille J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044490
   Liu S, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P82, DOI 10.1145/3123266.3123431
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   MARK LS, 1980, PERCEPT PSYCHOPHYS, V27, P117, DOI 10.3758/BF03204298
   RAMANATHAN N, 2008, MODELING SHAPE AND T, P1, DOI DOI 10.1109/AFGR.2008.4813337
   Restylane, 2012, REST IM TOOL
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   ROWLAND DA, 1995, IEEE COMPUT GRAPH, V15, P70, DOI 10.1109/38.403830
   Samson N, 2010, J COSMET DERMATOL-US, V9, P79, DOI 10.1111/j.1473-2165.2010.00489.x
   Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Simonite T, 2006, VIRTUAL FACE AGEING
   Simonyan K., 2014, 14091556 ARXIV
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Sydell L, 2009, BUILDING CURIOUS FAC
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   Tiddeman BP, 2005, COMPUT GRAPH FORUM, V24, P449, DOI 10.1111/j.1467-8659.2005.00870.x
   Tsai MH, 2014, MULTIMED TOOLS APPL, V72, P801, DOI 10.1007/s11042-013-1399-7
   Vezzetti E, 2018, MULTIMED TOOLS APPL, V77, P14177, DOI 10.1007/s11042-017-5025-y
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wang Weitian., 2018, IEEE T AUTOM SCI ENG, V99, P1
   Yaar M, 2007, BRIT J DERMATOL, V157, P874, DOI 10.1111/j.1365-2133.2007.08108.x
NR 40
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6309
EP 6327
DI 10.1007/s11042-018-6311-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100061
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ji, WT
   Wang, RL
   Ma, JB
AF Ji, Wanting
   Wang, Ruili
   Ma, Junbo
TI Dictionary-based active learning for sound event classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active learning; k-medoids clustering; Dictionary learning; Sound event
   classification
ID MATCHING PURSUITS; RECOGNITION
AB This paper proposes a new dictionary-based active learning method for sound event classification, which significantly reduces the required amount of labeled samples in the process of classifier training. Active learning is a process of selecting samples to be labeled. In our method, the active learning is based on clustering. We use dictionary-based clustering as the dictionary learning is more suitable to sound event classification. Our classifier will be trained using both unlabelled sound segments (that have predicted labels), and a small number of labeled samples. The proposed method and other reference methods are implemented on a public urban sound dataset with 8732 sound segments, the classification accuracy is used to measure the performance of these classifiers. Experimental results show that the proposed method has higher classification accuracy but requires much less labeled samples than other methods.
C1 [Ji, Wanting; Wang, Ruili; Ma, Junbo] Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Ji, Wanting; Wang, Ruili; Ma, Junbo] Masssy Univ, Auckland, New Zealand.
C3 Zhejiang Gongshang University
RP Ji, WT (corresponding author), Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.; Ji, WT (corresponding author), Masssy Univ, Auckland, New Zealand.
EM jwt@escience.cn; prof.ruili.wang@gmail.com
RI Ma, Junbo/AAT-5699-2021
OI Ma, Junbo/0000-0002-5859-8389
FU Natural Science Foundation of Zhejiang Province [LY18F010008]; Marsden
   Fund of New Zealand
FX This work was supported in part by the Natural Science Foundation of
   Zhejiang Province (No. LY18F010008) and the Marsden Fund of New Zealand.
CR [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], 1530 U WISC MAD
   [Anonymous], 2011, Speech and Audio Signal Processing: Processing and Perception of Speech and Music, DOI 10.1002/9781118142882
   [Anonymous], PATTERN RECOGN LETT
   Barkana BD, 2011, APPL ACOUST, V72, P841, DOI 10.1016/j.apacoust.2011.05.008
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211
   Duan SF, 2014, ARTIF INTELL REV, V42, P637, DOI 10.1007/s10462-012-9362-y
   Fleury A, 2008, IEEE ENG MED BIO, P4644, DOI 10.1109/IEMBS.2008.4650248
   Foggia P, 2016, IEEE T INTELL TRANSP, V17, P279, DOI 10.1109/TITS.2015.2470216
   Gadde A, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P492, DOI 10.1145/2623330.2623760
   Ghofrani S, 2003, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P713
   Han WJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162075
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Lei C, 2018, MULTIMED TOOLS APPL, V77, P29605, DOI 10.1007/s11042-017-5381-7
   Maijala P, 2018, APPL ACOUST, V129, P258, DOI 10.1016/j.apacoust.2017.08.006
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   Phuong NC, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P330, DOI 10.1109/ComManTel.2013.6482415
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Riccardi G, 2005, IEEE T SPEECH AUDI P, V13, P504, DOI 10.1109/TSA.2005.848882
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Schroeder J, 2016, INT CONF ACOUST SPEE, P6455, DOI 10.1109/ICASSP.2016.7472920
   Sharan RV, 2017, INFORM SCIENCES, V396, P24, DOI 10.1016/j.ins.2017.02.013
   Sugden P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P557
   Vera-Candeas P, 2004, IEEE SIGNAL PROC LET, V11, P349, DOI 10.1109/LSP.2003.822904
   Wang CS, 2017, ADV MATH PHYS, V2017, DOI 10.1155/2017/8278161
   Wang JC, 2014, IEEE T AUTOM SCI ENG, V11, P607, DOI 10.1109/TASE.2013.2285131
   Wang RL, 2018, WORLD WIDE WEB, V21, P1745, DOI 10.1007/s11280-017-0508-3
   Zhang ZX, 2012, INT CONF ACOUST SPEE, P333, DOI 10.1109/ICASSP.2012.6287884
   Zhao SY, 2017, INT CONF ACOUST SPEE, P751, DOI 10.1109/ICASSP.2017.7952256
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 36
TC 8
Z9 9
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3831
EP 3842
DI 10.1007/s11042-018-6380-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600064
DA 2024-07-18
ER

PT J
AU Kwon, JH
   Cha, M
   Lee, SB
   Kim, EJ
AF Kwon, Jung-Hyok
   Cha, Minki
   Lee, Sol-Bee
   Kim, Eui-Jik
TI Variable-categorized clustering algorithm using fuzzy logic for Internet
   of things local networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering algorithm; Fuzzy inference system; Fuzzy logic; IoT local
   network; Variable categorization
ID ROUTING PROTOCOLS; WIRELESS; ENERGY; WSN
AB This paper presents a variable-categorized clustering algorithm (VCCA) using fuzzy logic for Internet of Things (IoT) local networks. The VCCA selects the cluster head (CH) that has the highest network capacity through a classification process of cluster variables in accordance with the characteristics in order to configure a clustered network, which differs for different IoT applications. To achieve this, the VCCA employs a fuzzy inference system (FIS) that calculates an outcome through rule-based variable mapping for low complexity in the CH election and high scalability of cluster variables. In addition, experimental simulations using MATLAB are conducted to evaluate the performance of the VCCA. The simulation results show that the VCCA exhibits better network performance compared to the existing algorithms in terms of throughput, end-to-end latency, network lifetime, and energy consumption.
C1 [Kwon, Jung-Hyok; Cha, Minki; Lee, Sol-Bee; Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
C3 Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
FU Leading Human Resource Training Program of Regional Neo Industry through
   the National Research Foundation of Korea (NRF) - Ministry of Science,
   ICT and Future Planning [2016H1D5A1910427]; Basic Science Research
   Program through the NRF - Ministry of Education
   [NRF-2017R1D1A1B03031055]; NRF Grant - Korean Government
   (NRF-2016-Fostering Core Leaders of the Future Basic Science
   Program/Global Ph.D. Fellowship Program) [2016H1A2A1908620]; Hallym
   University [HRF-201702-009]
FX This research was supported in part by the Leading Human Resource
   Training Program of Regional Neo Industry through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Science, ICT and
   Future Planning (2016H1D5A1910427), by Basic Science Research Program
   through the NRF funded by the Ministry of Education
   (NRF-2017R1D1A1B03031055), by NRF Grant funded by the Korean Government
   (NRF-2016-Fostering Core Leaders of the Future Basic Science
   Program/Global Ph.D. Fellowship Program) (2016H1A2A1908620), and by
   Hallym University Research Fund, 2017 (HRF-201702-009).
CR Adhikary DRD, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P285, DOI 10.1109/NGCT.2015.7375127
   Akkaya K., 2005, Ad Hoc Networks, V3, P325, DOI 10.1016/j.adhoc.2003.09.010
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   [Anonymous], P 2 INT C COMP ENG T
   [Anonymous], IJCTT
   [Anonymous], SENSORS BASEL
   [Anonymous], 2007, PROC IEEE REGION 10
   [Anonymous], IOT DEV LOC NETW 1
   Bai Y., 2006, Advanced Fuzzy Logic Technologies in Industrial Applications, P17, DOI [DOI 10.1007/978-1-84628-469-4_2, DOI 10.1007/978-1-84628-469-42]
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gupta I, 2005, PROCEEDINGS OF THE 3RD ANNUAL COMMUNICATION NETWORKS AND SERVICES RESEARCH CONFERENCE, P255
   Handy MJ, 2002, 2002 4TH INTERNATIONAL WORKSHOP ON MOBILE AND WIRELESS COMMUNICATION NETWORK, P368, DOI 10.1109/MWCN.2002.1045790
   HUSSAIN K, 2013, WORLD APPL SCI J, V23, P611, DOI DOI 10.5829/idosi.wasj.2013.23.05.902
   Imtiaz Shariar, 2013, International Journal of Intelligent Systems and Applications, V5, P64, DOI 10.5815/ijisa.2013.12.05
   Jung K, 2017, MULTIMED TOOLS APPL, V76, P18175, DOI 10.1007/s11042-016-4190-8
   Kim JM, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P654
   Lee JS, 2012, IEEE SENS J, V12, P2891, DOI 10.1109/JSEN.2012.2204737
   Li CL, 2011, SENSORS-BASEL, V11, P3498, DOI 10.3390/s110403498
   Li N, 2015, SENSORS-BASEL, V15, P19541, DOI 10.3390/s150819541
   Lin K, 2010, EURASIP J WIREL COMM, DOI 10.1155/2010/567952
   Liu X, 2012, SENSORS-BASEL, V12, P11113, DOI 10.3390/s120811113
   Machado K, 2013, SENSORS-BASEL, V13, P1942, DOI 10.3390/s130201942
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Nayak P, 2017, IEEE SENS J, V17, P4492, DOI 10.1109/JSEN.2017.2711432
   Nayak P, 2016, IEEE SENS J, V16, P137, DOI 10.1109/JSEN.2015.2472970
   Ni QJ, 2017, IEEE ACM T COMPUT BI, V14, P76, DOI 10.1109/TCBB.2015.2446475
   Park SH, 2014, J APPL MATH, DOI 10.1155/2014/213106
   Qin JH, 2017, IEEE T CYBERNETICS, V47, P772, DOI 10.1109/TCYB.2016.2526683
   Ross T. J., 2009, Fuzzy logic with engineering applications, V3rd
   Siew Z. W., 2011, 2011 IEEE Colloquium on Humanities, Science and Engineering (CHUSER 2011), P392, DOI 10.1109/CHUSER.2011.6163758
   Vermesan O, 2014, RIVER PUBL SER COMM, P7
NR 32
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2963
EP 2982
DI 10.1007/s11042-017-5176-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600017
DA 2024-07-18
ER

PT J
AU Li, ZL
   Zhang, YQ
AF Li, Zhaolei
   Zhang, Yaqi
TI RETRACTED: Hierarchical evaluation algorithm of logistics carrying
   capacity based on transfer learning in multimedia environment (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Multimedia environment; Transfer learning; Logistics carrying capacity;
   Network capability; Hierarchical evaluation; Algorithm
AB In order to measure and enhance the carrying capacity of regional logistics system scientifically and give full play to the efficiency of regional logistics system, based on the perspective of sustainable development, this paper analyzes the network topology structure of regional logistics system. Combining the component elements and operation flow of regional logistics system, we take link line, operation capacity and energy environment as constraint conditions, and construct the measurement model of regional logistics system carrying capacity. The integrated management of logistics requires systematic integration of various modes of transportation, such as highway transportation, water transportation, rail transportation and air transportation, as well as the network of key nodes and their network. Therefore, we need to solve the different transportation models and the nodal carrying capacity calculation methods that constitute the logistics system. Therefore, this paper analyzes the connotation, various transportation mode and port capacity related to the concept of research ideas, research tools and methods, the related calculation formula, traffic flow as the main line to construct different modes of transport carrying capacity between the inner link, and the bearing capacity formula of each transport mode into a unified unit, the transportation mode of coordinated development that is the basis of the overall optimization and decision of logistics system.
C1 [Li, Zhaolei] Changan Univ, Sch Econ & Management, Xian, Shaanxi, Peoples R China.
   [Zhang, Yaqi] Xian Univ Technol, Fac Econ & Management, Xian, Shaanxi, Peoples R China.
C3 Chang'an University; Xi'an University of Technology
RP Li, ZL (corresponding author), Changan Univ, Sch Econ & Management, Xian, Shaanxi, Peoples R China.
EM ek56517@163.com
RI Zhang, Yaqi/AAR-9163-2020
FU Fundamental Research Funds for the Central Universities [310823171001]
FX This paper is supported by the Fundamental Research Funds for the
   Central Universities (no. 310823171001).
CR Alves-Pinto HN, 2017, LAND USE POLICY, V60, P419, DOI 10.1016/j.landusepol.2016.08.004
   [Anonymous], 2014, International Journal of Education and Research, DOI DOI 10.12735/ier.v2i2p01
   Bjerck HB, 2017, J ISL COAST ARCHAEOL, V12, P276, DOI 10.1080/15564894.2016.1190425
   Bogue R, 2016, IND ROBOT, V43, P583, DOI 10.1108/IR-07-2016-0194
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Cherrett T, 2017, TRANSPORT RES C-EMER, V78, P111, DOI 10.1016/j.trc.2017.02.021
   CHOMBA C, 2013, INT J BIODIVERS CONS, V5, P109, DOI DOI 10.5897/IJBC12.023
   DENG FM, 2017, SUSTAINABILITY-BASEL, V9, DOI DOI 10.3390/su9112047
   Deng LB, 2019, CLUSTER COMPUT, V22, pS9889, DOI 10.1007/s10586-018-1847-2
   Du QQ, 2017, RES TRANSP BUS MANAG, V23, P86, DOI 10.1016/j.rtbm.2017.02.002
   Dybskaya VV, 2017, TRANSP TELECOMMUN J, V18, P181, DOI 10.1515/ttj-2017-0016
   Faris H, 2018, NEURAL COMPUT APPL, V30, P2355, DOI 10.1007/s00521-016-2818-2
   Gladkovska V, 2017, TECHNOLOGY AUDIT PRO, V5, P49, DOI [10.15587/2312-8372.2017.112066, DOI 10.15587/2312-8372.2017.112066]
   Jiang G, 2017, J SHIP PROD DES, V33, P212, DOI 10.5957/JSPD.33.3.160019
   Liu BW, 2017, NEURAL COMPUT APPL, V28, P1927, DOI 10.1007/s00521-015-2165-8
   Mahindroo Ankit, 2018, International Journal of Logistics Systems and Management, V29, P215
   Mansouri I, 2018, NEURAL COMPUT APPL, V29, P873, DOI 10.1007/s00521-016-2492-4
   Muñoz AR, 2015, DIVERS DISTRIB, V21, P1388, DOI 10.1111/ddi.12352
   Rodriguez-Rodriguez L, 2017, POPULATION, V400, P800
   Sharma S, 2017, J TRAFFIC TRANSPORTA, V5, P147
   Snyder JD, 2013, POTENTIAL IMPACTS PA
   Venkatesh V., 2015, INT J AUTOMATION LOG, V1, P273, DOI DOI 10.1504/IJAL.2015.071725
   Wang W, 2017, CITIES, V62, P1, DOI 10.1016/j.cities.2016.11.009
NR 23
TC 6
Z9 6
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4481
EP 4501
DI 10.1007/s11042-018-6000-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200030
DA 2024-07-18
ER

PT J
AU Song, PH
   Zheng, YY
   Jia, JY
   Gao, Y
AF Song, Peihua
   Zheng, Youyi
   Jia, Jinyuan
   Gao, Yan
TI Web3D-based automatic furniture layout system using recursive case-based
   reasoning and floor field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Furniture layout; Case-based reasoning; Floor field; Recursive
   techniques
AB Furniture layout in a virtual 3D scene is an important and challenging task, as it is time-consuming and requires experience. To address this issue, we propose automatic furniture layout algorithms to help users to rapidly generate reasonable layout results. Specifically, our algorithms divide a scene layout into four layout modes, namely, coupled mode, enclosed mode, matrix mode, and circular mode. Then each model is solved independently. The coupled mode is solved using recursive techniques and case-based reasoning. The enclosed mode is solved using floor field. The distance and angle among the furniture are determined by ergonomics guidelines. Finally, the layout results of the scene can be obtained by combining the solutions from these layout modes, and an evaluation method for the layout results based on user feedback is proposed. For a room with non-rectangular floor, our algorithms can also handle this case using shape standardization techniques. Based on our algorithms, an online 3D furniture layout system is developed. Many experiments are conducted on the system with the real interior design cases, and we compared our algorithms with other popular algorithms. The experimental results show that our algorithms are efficient and can meet the real response requirements of online furniture layout.
C1 [Song, Peihua; Jia, Jinyuan] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
   [Zheng, Youyi] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Gao, Yan] Clarkson Univ, Elect & Comp Engn, Potsdam, NY 13676 USA.
C3 Tongji University; Zhejiang University; Clarkson University
RP Jia, JY (corresponding author), Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
EM sph2000@126.com; youyizheng@zju.edu.cn; jiajytj@126.com;
   gaoy@clarkson.edu
RI Gao, Yan/ISU-7881-2023
OI Jia, Jinyuan/0000-0002-7772-4766
FU Key Research Projects of Central University of Basic Scientific Research
   Funds for Cross Cooperation [201510-02]; Research Fund for the Doctoral
   Program of Higher Education of China [2013007211-0035]; National Nature
   Science Foundation of China [61741203]; Key project in scientific and
   technological of Jilin Province in China [20140204088GX]
FX The authors appreciate the comments and suggestions of all anonymous
   reviewers, whose comments significantly improved this paper. This work
   is supported by The Key Research Projects of Central University of Basic
   Scientific Research Funds for Cross Cooperation (201510-02), Research
   Fund for the Doctoral Program of Higher Education of China (No.
   2013007211-0035), National Nature Science Foundation of China (No.
   61502306), National Nature Science Foundation of China (No. 61741203),
   and Key project in scientific and technological of Jilin Province in
   China (No. 20140204088GX).
CR Akase R, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P726, DOI 10.1109/CISIS.2013.130
   Akazawa Y, 2002, 8 INT C COMP GRAPH A, P593
   [Anonymous], 2013, ACM T GRAPHIC, DOI DOI 10.1145/2461912.2461968
   Besbes G, 2015, MULTIMED TOOLS APPL, V74, P8053, DOI 10.1007/s11042-014-2041-z
   Bukowski R. W., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P131, DOI 10.1145/199404.199427
   Chen G., 2007, ACM Trans. Graph, V27, P35, DOI [10.1145/1278780.1278822, DOI 10.1145/1278780.1278822]
   Chen Guangming, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P1603
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fu ZJ, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500590
   Germer T, 2009, COMPUT GRAPH FORUM, V28, P2068, DOI 10.1111/j.1467-8659.2009.01351.x
   Guimaraes MD, 2018, MULTIMED TOOLS APPL, V77, P347, DOI 10.1007/s11042-016-4256-7
   Huang HJ, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.021131
   Jin BW, 2018, MULTIMED TOOLS APPL, V77, P5417, DOI 10.1007/s11042-017-4457-8
   Kjolaas K. A. H., 2000, THESIS
   KOLODNER JL, 1992, ARTIF INTELL REV, V6, P3, DOI 10.1007/BF00155578
   Larive Mathieu, 2004, P INT C COMP GRAPH A
   Liu M, 2016, CHINESE J COMPUTERS, V39, DOI 10. 11897/SP. J. 1016. 2017. 02533
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   Liu Y, 2013, ERGONOMICS INTERIOR
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Merrell P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866203
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Muller P., 2006, Acm siggraph 2006 courses, P139
   Nishinari K, 2004, IEICE T INF SYST, VE87D, P726
   Quax P, 2016, MULTIMED TOOLS APPL, V75, P4383, DOI 10.1007/s11042-015-2481-0
   Sanchez S, 2003, P C COMP GRAPH ART I
   Schwarz M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629573
   Smith G., 2001, P GRAPH INT C OTT ON, P135
   Song Peihua, 2016, Journal of System Simulation, V28, P2438
   Xu K, 2002, PROC GRAPH INTERF, P25
   Xu WZ, 2015, COMPUT GRAPH-UK, V46, P231, DOI 10.1016/j.cag.2014.09.032
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zorrilla M, 2014, MULTIMED TOOLS APPL, V71, P533, DOI 10.1007/s11042-013-1516-7
NR 33
TC 3
Z9 3
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 5051
EP 5079
DI 10.1007/s11042-018-6334-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200058
DA 2024-07-18
ER

PT J
AU Sun, JY
   Shao, J
   He, CK
AF Sun, Jiayu
   Shao, Jie
   He, Chengkun
TI Abnormal event detection for video surveillance using deep one-class
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abnormal event detection; Deep learning; One-class SVM; Video
   surveillance
ID ANOMALY DETECTION; LOCALIZATION
AB Abnormal event detection and localization is a challenging research problem in intelligent video surveillance. It is designed to automatically identify abnormal events from monitoring videos. The main difficulty of this task lies in that there is only one class called normal event in training video sequences. In recent years, many advanced algorithms have been proposed on the basis of hand-crafted features. Only a few algorithms are based on high-level features, but almost all these methods use two-stage learning. In this paper, we propose a novel end-to-end model which integrates the one-class Support Vector Machine (SVM) into Convolutional Neural Network (CNN), named Deep One-Class (DOC) model. Specifically, the robust loss function derived from the one-class SVM is proposed to optimize the parameters of this model. Compared with the hierarchical models, our model not only simplifies the complexity of the process, but also obtains the global optimal solution of the whole process. In the experiments, we validate our DOC model with a publicly available dataset and compare it with some state-of-art methods. The comparison results demonstrate that our model has great performance and it is effective for abnormal events detection from surveillance videos.
C1 [Sun, Jiayu; Shao, Jie; He, Chengkun] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Future Media, Chengdu, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Shao, J (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Future Media, Chengdu, Sichuan, Peoples R China.
EM jiayusun@std.uestc.edu.cn; shaojie@uestc.edu.cn;
   matthewhe@std.uestc.edu.cn
FU National Natural Science Foundation of China [61672133, 61632007];
   Fundamental Research Funds for the Central Universities [ZYGX2015J058,
   ZYGX2014Z007]
FX This work is supported by the National Natural Science Foundation of
   China (grants No. 61672133 and No. 61632007), and the Fundamental
   Research Funds for the Central Universities (grants No. ZYGX2015J058 and
   No. ZYGX2014Z007).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2015, P BRIT MACH VIS C BM
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Fanello SR, 2013, LECT NOTES COMPUT SC, V7887, P31
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   Feng YC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2964284.2967290
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Itti L, 2005, PROC CVPR IEEE, P631
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Pouget V., 2017, IEEE T NEUR NET LEAR, V64, P13, DOI DOI 10.1109/TNNLS.2016.2521602
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Wang P, 2017, PROC CVPR IEEE, P6212, DOI 10.1109/CVPR.2017.658
   Wang P, 2016, PROC CVPR IEEE, P1573, DOI 10.1109/CVPR.2016.174
   Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Yuan Y, 2017, IEEE T CYBERNETICS, V47, P3597, DOI 10.1109/TCYB.2016.2572609
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 28
TC 42
Z9 46
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3633
EP 3647
DI 10.1007/s11042-017-5244-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600054
OA Bronze
DA 2024-07-18
ER

PT J
AU Yanez-Gomez, R
   Font, JL
   Cascado-Caballero, D
   Sevillano, JL
AF Yanez-Gomez, Rosa
   Luis Font, Juan
   Cascado-Caballero, Daniel
   Sevillano, Jose-Luis
TI Heuristic usability evaluation on games: a modular approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heuristic evaluation; Games; Usability; Heuristic guidelines
ID USER EXPERIENCE; COMPUTER GAME; PLAY
AB Heuristic evaluation is the preferred method to assess usability in games when experts conduct this evaluation. Many heuristics guidelines have been proposed attending to specificities of games but they only focus on specific subsets of games or platforms. In fact, to date the most used guideline to evaluate games usability is still Nielsen's proposal, which is focused on generic software. As a result, most evaluations do not cover important aspects in games such as mobility, multiplayer interactions, enjoyability and playability, etc. To promote the usage of new heuristics adapted to different game and platform aspects we propose a modular approach based on the classification of existing game heuristics using metadata and a tool, MUSE (Meta-heUristics uSability Evaluation tool) for games, which allows a rebuild of heuristic guidelines based on metadata selection in order to obtain a customized list for every real evaluation case. The usage of these new rebuilt heuristic guidelines allows an explicit attendance to a wide range of usability aspects in games and a better detection of usability issues. We preliminarily evaluate MUSE with an analysis of two different games, using both the Nielsen's heuristics and the customized heuristic lists generated by our tool.
C1 [Yanez-Gomez, Rosa; Luis Font, Juan; Cascado-Caballero, Daniel; Sevillano, Jose-Luis] Univ Seville, Dept Comp Technol & Architecture, ETS Ingn Informat, Avda Reina Mercedes S-N, E-41012 Seville, Spain.
C3 University of Sevilla
RP Yanez-Gomez, R (corresponding author), Univ Seville, Dept Comp Technol & Architecture, ETS Ingn Informat, Avda Reina Mercedes S-N, E-41012 Seville, Spain.
EM ryanez@us.es
RI Sevillano, Jose Luis/K-2484-2013
OI Font, Juan Luis/0000-0001-5232-6078
FU EU project SmokeFreeBrain [PI055-15/E03]; Telefonica Chair "Intelligence
   in Networks" of the Universidad de Sevilla, Spain
FX This work has been partially supported by the EU project SmokeFreeBrain
   (PI055-15/E03) and by the Telefonica Chair "Intelligence in Networks" of
   the Universidad de Sevilla, Spain. The licences for the Grim Fandango
   Remastered copies used during the tests where kindly provided by the
   creator of the remastered version and owner of its Intellectual
   Property, Double Fine Productions.
CR [Anonymous], 1998, 924111 ISO, P45
   [Anonymous], 2002, THESIS
   [Anonymous], 2009, 92412102009 FDIS ISO
   [Anonymous], 2010, FUTUREPLAY 10 FUTURE, DOI DOI 10.1145/1920778.1920786
   Apperley TH, 2006, SIMULAT GAMING, V37, P6, DOI 10.1177/1046878105282278
   Barendregt W, 2006, INT J HUM-COMPUT ST, V64, P830, DOI 10.1016/j.ijhcs.2006.03.004
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brown E., 2004, CHI 04 HUM FACT COMP, P1297, DOI DOI 10.1145/985921.986048
   Caillois R., 1961, MAN PLAY GAMES
   Cheng K.Cairns., 2005, ACM C HUMAN FACTORS, P1272, DOI [DOI 10.1145/1056808.1056894, 10.1145/1056808.1056894]
   Clanton C., 1998, CHI 98 C SUMMARY HUM, P1
   Cowley B., 2008, COMPUT ENTERTAINMENT, V6, P1, DOI [10.1145/1371216.1371223, DOI 10.1145/1371216.1371223]
   Csikszentmihalyi Mihaly, 1975, J HUMANISTIC PSYCHOL, V1975
   Dempsey JV, 1997, EXPLORATORY STUDY FO
   Desurvire H., 2004, EXTENDED ABSTRACTS 2, P1509, DOI [DOI 10.1145/985921.986102, 10.1145/985921.986102]
   Desurvire H, 2009, LECT NOTES COMPUT SC, V5621, P557, DOI 10.1007/978-3-642-02774-1_60
   Franca G., 2007, Proceedings of the 6th international conference on Interaction design and children, P29, DOI DOI 10.1145/1297277.1297284
   Frokjaer E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P345, DOI 10.1145/332040.332455
   Sánchez JLG, 2012, BEHAV INFORM TECHNOL, V31, P1033, DOI 10.1080/0144929X.2012.710648
   Hassenzahl Marc, 2008, P 20 C INT HOMM MACH, P11, DOI [10.1145/1512714.1512717, DOI 10.1145/1512714.1512717]
   Hazlett R. L., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1023
   Hertzum M, 2001, INT J HUM-COMPUT INT, V13, P421, DOI 10.1207/S15327590IJHC1304_05
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   IJsselsteijn W.A., 2007, INT C ADV COMPUTER E, V2, P27
   Jarvinen A., 2002, PRESTUDY RES REPORT
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   Ke FF, 2008, INT J COMP-SUPP COLL, V3, P429, DOI 10.1007/s11412-008-9048-2
   King Geoff., 2002, Screenplay: Cinema / Videogames / Interfaces
   Koeffel C, 2010, HUM-COMPUT INT-SPRIN, P233, DOI 10.1007/978-1-84882-963-3_13
   Korhonen H., 2009, Proceedings of the 13th International MindTrek Conference: Everyday Life in the Ubiquitous Era, ACM New York, USA, P74, DOI DOI 10.1145/1621841.1621856
   Korhonen H., 2007, Proceedings of the 2nd International Conference on Digital Interactive Media in Entertainment and Arts, P28, DOI [10.1145/1306813.1306828, DOI 10.1145/1306813.1306828]
   Korhonen H., 2006, P 8 C HUMAN COMPUTER, P9, DOI [DOI 10.1145/1152215.1152218, 10.1145/1152215.1152218, DOI 10.1145/1306813.1306828]
   Korhonen H, 2011, P 8 INT C ADV COMP E, P40
   Korhonen Hannu, 2010, P 3 INT C FUN GAM, P18, DOI [10.1145/1823818.1823820, DOI 10.1145/1823818.1823820]
   Larsen JM, 2008, EVALUATING USER EXPE
   Law E, 2008, Proceeding of the Twenty-Sixth Annual CHI Conference Extended Abstracts, P2395, DOI [10.1086/521592, DOI 10.1086/521592]
   Lazar J., 2017, RES METHODS HUMAN CO, DOI DOI 10.1016/B978-0-12-805390-4.00014-5
   Malone T.W., 1982, P 1982 C HUM FACT CO, P63, DOI DOI 10.1145/800049.801756
   MALONE TW, 1981, COGNITIVE SCI, V5, P333, DOI 10.1207/s15516709cog0504_2
   Mandryk RL, 2007, INT J HUM-COMPUT ST, V65, P329, DOI 10.1016/j.ijhcs.2006.11.011
   Myers D, 2003, DIGITAL FORMATIONS, P16
   Nacke LennartE., 2009, Proceedings of the 2009 Conference on Future Play on @ GDC Canada, P2, DOI DOI 10.1145/1639601.1639609
   Nielsen, 1994, USABILITY ENG
   Nielsen J, 1990, Proceedings ACM CHI'90 Conf, DOI [DOI 10.1145/97243.97281, 10.1145/97243.97281]
   Nielsen J., 1994, USABILITY ENG, P1
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Papaloukas S, 2009, 13TH PANHELLENIC CONFERENCE ON INFORMATICS, PROCEEDINGS, P202, DOI 10.1109/PCI.2009.14
   Pinelle D, 2009, GROUP 2009 PROCEEDINGS, P169
   Pinelle D, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1453
   Rocker C, 2006, P 3 INT WORKSH PERV, P199
   Susi T, 2007, TR07001 HS IKI U SKO
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   Wolf MarkJ. P., 2001, The Medium of the Video Game
   Gómez RY, 2014, SCI WORLD J, DOI 10.1155/2014/434326
   Yáñez-Gómez R, 2017, MULTIMED TOOLS APPL, V76, P5755, DOI 10.1007/s11042-016-3845-9
NR 55
TC 12
Z9 12
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4937
EP 4964
DI 10.1007/s11042-018-6593-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200052
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, ZN
   Jing, PG
   Liu, Y
   Su, YT
AF Zhang, Jing
   Li, Zhengnan
   Jing, Peiguang
   Liu, Ye
   Su, Yuting
TI Tensor-driven low-rank discriminant analysis for image set
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image set classification; Low-rank; Tensor-driven; Discriminant
   analysis; Grassmann manifold
ID FACE RECOGNITION; REPRESENTATION; APPEARANCE
AB Classification based on image sets has recently attracted great interest in computer vision community. In this paper, we proposed a transductive Tensor-driven Low-rank Discriminant Analysis (TLRDA) model for image set classification, in which the tensor-driven low-rank approximation and the discriminant graph embedding are integrated to improve the representativeness of image sets. In addition, we develop an iterative shrinkage thresholding algorithm to better optimize the objective function of the proposed TLRDA. Experiments on seven publicly available datasets demonstrate that our proposed method is guaranteed to converge within a small number of iterations during the training procedure and obtains promising results compared with state-of-the-art methods.
C1 [Zhang, Jing; Li, Zhengnan; Jing, Peiguang; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Liu, Ye] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Tianjin University; National University of Singapore
RP Jing, PG (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM zhangjing@tju.edu.cn; pgjing@tju.edu.cn; pgjing@tju.edu.cn;
   liuye.cis@gmail.com; ytsu@tju.edu.cn
RI LI, HAO/KBD-0866-2024; Liu, Ye/D-9148-2018
OI Liu, Ye/0000-0002-1969-2639; Jing, Peiguang/0000-0003-2648-7358
CR [Anonymous], TSP
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], BINARY LABELS POLITI
   [Anonymous], PERSONALITY INDIVIDU
   [Anonymous], TPAMI
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], ARXIV150902027 CORR
   [Anonymous], 2009, SPECTRAL REGRESSION
   [Anonymous], 2002, Adv. Neural Inf. Process. Syst.
   [Anonymous], 2013, Proceedings the 27th Annual Conference on Neural Information Processing Systems
   [Anonymous], 2011, COMPUTER
   [Anonymous], LOG EUCLIDEAN METRIC
   [Anonymous], 2014, P AS C COMP VIS
   [Anonymous], P 25 INT C ART INT
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Brenner CJ, 2015, EUR J SOC PSYCHOL, V45, P27, DOI 10.1002/ejsp.2072
   Cai D, 2007, P IEEE INT C COMPUTE, P1
   Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Ding ZM, 2016, AAAI CONF ARTIF INTE, P1181
   Ding ZM, 2014, IEEE DATA MINING, P110, DOI 10.1109/ICDM.2014.29
   Dong WS, 2015, IEEE I CONF COMP VIS, P442, DOI 10.1109/ICCV.2015.58
   Dou JF, 2015, NEUROCOMPUTING, V168, P382, DOI 10.1016/j.neucom.2015.05.088
   Farahani M., 2010, proceedings of the 2nd International Conference on Engineering Optimization, P1
   Gross R, 2001, CITESEER
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Harandi M, 2015, IEEE I CONF COMP VIS, P4112, DOI 10.1109/ICCV.2015.468
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Nguyen H, 2015, NEUROCOMPUTING, V155, P32, DOI 10.1016/j.neucom.2014.12.051
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Jia CC, 2014, AAAI CONF ARTIF INTE, P1228
   Kim TK, 2006, LECT NOTES COMPUT SC, V3953, P251
   KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KC, 2003, PROC CVPR IEEE, P313
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P103, DOI 10.1109/TNN.2008.2004625
   Lu YF, 2017, MATH MECH SOLIDS, V22, P1997, DOI 10.1177/1081286516653272
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Rodriguez-Aseretto D, 2013, PROCEDIA COMPUT SCI, V18, P1861, DOI 10.1016/j.procs.2013.05.355
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864
   Su YT, 2017, MULTIMED TOOLS APPL, V76, P10635, DOI 10.1007/s11042-015-3090-7
   Tao DC, 2008, NEUROCOMPUTING, V71, P1866, DOI 10.1016/j.neucom.2007.08.036
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   van Prooijen JW, 2015, PERS SOC PSYCHOL B, V41, P485, DOI 10.1177/0146167215569706
   Wang BY, 2016, AAAI CONF ARTIF INTE, P2122
   Wang GJ, 2015, NEUROCOMPUTING, V151, P1500, DOI 10.1016/j.neucom.2014.10.032
   Wang J, 2016, NEUROCOMPUTING, V214, P1026, DOI 10.1016/j.neucom.2016.07.015
   Wang RP, 2008, PROC CVPR IEEE, P2940
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang TS, 2009, PATTERN RECOGN LETT, V30, P1161, DOI 10.1016/j.patrec.2009.06.002
   Welch G, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.1046626
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yun XP, 2006, IEEE T ROBOT, V22, P1216, DOI 10.1109/TRO.2006.886270
   Zhang J, 2016, IEEE SIGNAL PROC LET, V23, P1246, DOI 10.1109/LSP.2016.2577601
   Zheng CH, 2016, NEUROCOMPUTING, V198, P114, DOI 10.1016/j.neucom.2015.07.146
   Zhong GQ, 2014, NEURAL COMPUT, V26, P761, DOI 10.1162/NECO_a_00570
   Zhou BL, 2014, ADV NEUR IN, V27
NR 68
TC 10
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4001
EP 4020
DI 10.1007/s11042-017-5173-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200008
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Cheng, YQ
   Yu, B
AF Fu, Zhengxin
   Cheng, Yuqiao
   Yu, Bin
TI Perfect recovery of XOR-based visual cryptography scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; XOR Operation; Ideal access structure; Perfect
   recovery; General access structure; Color image; Multiple secret images
ID PIXEL EXPANSION
AB Visual cryptography is an interesting secret sharing scheme, in which participants can observe the secret image by stacking their shares. However, the size expansion and distorted visual effect are two disadvantages of visual cryptography. In this paper, we focus on how to realize the perfect recovery by XOR-ing shares directly. First, we propose the definition of ideal access structure, which is the key point of perfect recovery of XOR-based visual cryptography scheme. The characteristics of ideal access structure are analyzed, and the construction algorithm of shares under ideal access structure is designed. Based on the ideal access structure, a new algorithm is proposed for dividing the general access structure into several ideal access structures, and the secret sharing and recovering algorithms for general access structure are presented. Furthermore, our method can also be utilized in color visual cryptography and multi-secret visual cryptography. The security and perfect recovery of our method have been proved theoretically. Compared with the previous schemes, the proposed scheme realizes the perfect recovery of secret image by XOR-ing shares directly, and the sizes of shares can be decreased efficiently compared with the previous schemes.
C1 [Fu, Zhengxin; Cheng, Yuqiao; Yu, Bin] Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Cheng, YQ (corresponding author), Informat Engn Univ, Zhengzhou, Henan, Peoples R China.
EM xdqiao2015@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU National Natural Science Foundation of China [61602513]; Outstanding
   Youth Foundation of Zhengzhou Information Science and Technology
   Institute [2016611303]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant No.61602513 and the Outstanding Youth
   Foundation of Zhengzhou Information Science and Technology Institute
   under Grant No.2016611303.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chao KY, 2009, INT J PATTERN RECOGN, V23, P263, DOI 10.1142/S0218001409007090
   Chen YC, 2017, IEEE T INF FOREN SEC, V12, P1082, DOI 10.1109/TIFS.2016.2641378
   Fu ZX, 2014, MULTIMED TOOLS APPL, V73, P1177, DOI 10.1007/s11042-013-1625-3
   Itzkovitz A, 1997, VISUAL CRYPTOGRAPHY
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Viet DQ, 2004, TOPICS CRYPTOLOGY CT
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2008, VISUAL CRYPTOGRAPHY
NR 18
TC 14
Z9 14
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2367
EP 2384
DI 10.1007/s11042-018-6364-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700047
DA 2024-07-18
ER

PT J
AU Guo, Y
   Zong, X
   Qi, M
AF Guo, Ying
   Zong, Xiang
   Qi, Ming
TI Feasibility study on quality evaluation of Jadeite-jade color green
   based on GemDialogue color chip
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Jadeite-jade color green; GemDialogue; Color chip; Color band; Color
   mask
AB The paper studied quality evaluation of Jadeite-jade color green through GemDialogue. There are five green-related color codes in GemDialogue, including G2Y, Y2G, G, B2G and G2B. After parametric analysis on three measured color masks with different combinations, we clarified the color change rules of different color codes and zones superimposed by different color masks. First of all, based on CIE 1976L(*)a(*)b(*) uniform color space system, the color range of 728-piece Jadeite-jade color green was determined: L-*(5.64, 64.17), h(0)(125.21, 171.10), and C-*(10.53, 85.89), namely conforming the appearance characteristics of Jadeite-jade color green. Then, five green-related color codes in GemDialogue color chip system were selected to test the color changes of 50 color bands with combination of three color masks in different superposition forms. The changes of color hue, lightness and chroma between the color codes and zones before and after combination were considered as the indicators. The results show that changes of hue angle for standard green color codes is consistent with that of yellow color codes, but opposite to that of blue color codes. In the process changing from yellow to blue, the overall lightness moves from high to low values, in line with the sensory fact that naked eyes perceives higher lightness of yellow color than that of the blue. The overall color chroma of five color bands significantly reduces with fading yellow hue and increasing blue hue.
C1 [Guo, Ying; Zong, Xiang] China Univ Geosci Beijing, Sch Gemmol, 29 Xueyuan Rd, Beijing, Peoples R China.
   [Qi, Ming] Liaoning Geol Engn Vocat Coll, Gemmol Teaching & Res Sect, Dandong, Peoples R China.
C3 China University of Geosciences
RP Guo, Y (corresponding author), China Univ Geosci Beijing, Sch Gemmol, 29 Xueyuan Rd, Beijing, Peoples R China.
EM yingguocugb@126.com
CR [Anonymous], 2009, GBT238852009
   Boukouvalas C, 1999, IEEE T IND ELECTRON, V46, P219, DOI 10.1109/41.744415
   Braun KM, 1997, COLOR RES APPL, V22, P165, DOI 10.1002/(SICI)1520-6378(199706)22:3<165::AID-COL5>3.0.CO;2-P
   Cha HS, 2009, AM J DENT, V22, P350
   Daugirdiene A, 2016, J OPT SOC AM A, V33, pA77, DOI 10.1364/JOSAA.33.000A77
   Fuchs EC, 2008, CENT EUR J CHEM, V6, P497, DOI 10.2478/s11532-008-0052-1
   Guo Y, 2017, CLUSTER COMPUT, V20, P3393, DOI 10.1007/s10586-017-1091-1
   Guo Y, 2016, ACTA GEOL SIN-ENGL, V90, P2097, DOI 10.1111/1755-6724.13024
   Guo Y, 2016, MULTIMED TOOLS APPL, V75, P14491, DOI 10.1007/s11042-016-3291-8
   Hsiao SW, 2015, COLOR RES APPL, V40, P243, DOI 10.1002/col.21883
   Jiang Y., 2017, ARXIV PREPRINT ARXIV, P1, DOI [10.1007/978-3-319-53316-2_1, DOI 10.1007/S10586-017-1449-4]
   Kim SH, 2007, DENT MATER, V23, P374, DOI 10.1016/j.dental.2006.01.027
   Liu RR, 2017, CLUSTER COMPUT, V20, P1493, DOI 10.1007/s10586-017-0871-y
   Liu RR, 2017, CLUSTER COMPUT, V20, P25, DOI 10.1007/s10586-016-0688-0
   Morgan GB, 2016, AM MINERAL, V101, P111, DOI 10.2138/am-2016-5392
   Park Y, 2015, COLOR RES APPL, V40, P114, DOI 10.1002/col.21872
   Sánchez-Marañón M, 2011, SOIL SCI SOC AM J, V75, P984, DOI 10.2136/sssaj2010.0336
   Shams-Nateri A, 2009, COLOR RES APPL, V34, P100, DOI 10.1002/col.20477
   Sheridan C, 2007, J OPT A-PURE APPL OP, V9, pS32, DOI 10.1088/1464-4258/9/6/S06
   Wang Huan, 2012, Key Engineering Materials, V492, P374, DOI 10.4028/www.scientific.net/KEM.492.374
   Wang XC, 2005, COLOR RES APPL, V30, P118, DOI 10.1002/col.20089
NR 21
TC 26
Z9 26
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 841
EP 856
DI 10.1007/s11042-018-5753-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500048
DA 2024-07-18
ER

PT J
AU Liu, YN
   Zhang, SS
   Sang, Y
   Wang, SM
AF Liu, Yu-Nan
   Zhang, Shan-Shan
   Sang, Yu
   Wang, Si-Miao
TI Improving image retrieval by integrating shape and texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Non-subsampled shearlet transform; BKF
   distribution; Quaternion polar harmonic transforms
ID COLOR; WATERMARKING; SCALE; FORM
AB Content-based image retrieval (CBIR) has been an active research topic in the last decade. Multiple feature extraction and representation is one of the most important issues in the CBIR. In this paper, we propose a new CBIR method based on an efficient integration of texture and shape features. The texture features are extracted on the decomposed images processed by the optimal non-subsampled shearlet transform (NSST), and are represented by the high-frequency sub-band coefficients, which can be modeled by Bessel K Form (BKF) distribution; the shape features are represented by low-order quaternion polar harmonic transforms (QPHTs). The two kinds of features are then integrated by a weighted distance measurement, where Kullback-Leibler distance (KLD) and Euclidean distance (ED) are used for texture and shape features respectively. The integration of shape and texture information provides a robust feature set for image retrieval. Experimental results on standard benchmarks show significant improvements on retrieval performance using the proposed method compared with previous state-of-the-art methods.
C1 [Liu, Yu-Nan; Zhang, Shan-Shan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
   [Sang, Yu] Liaoning Tech Univ, Sch Elect & Informat Engn, Huludao 125105, Peoples R China.
   [Wang, Si-Miao] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Nanjing University of Science & Technology; Liaoning Technical
   University; Liaoning Normal University
RP Liu, YN (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Minist Educ, Key Lab Intelligent Percept & Syst High Dimens In, Nanjing 210094, Jiangsu, Peoples R China.
EM lynphd@163.com
RI Zhang, shanshan/HLP-6320-2023; Liu, Yunan/JGM-3801-2023; Liu,
   Yunan/GXH-9776-2022; Zhang, Shuo/IUO-8909-2023
FU National Science Fund of China [61702262, 61602226, U1713208, 61472187];
   973 Program [2014CB349303]; Program for Changjiang Scholars; Fundamental
   Research Funds for the Central Universities [30918011322]
FX This work was partially supported by the National Science Fund of China
   under Grant Nos. 61702262, 61602226,U1713208 and 61472187, the 973
   Program No. 2014CB349303, Program for Changjiang Scholars, and "the
   Fundamental Research Funds for the Central Universities" No.
   30918011322.
CR Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   [Anonymous], 2015, IEEE T COMPON PACKAG
   [Anonymous], 2014, ADV INTELL SYST COMP, DOI DOI 10.1007/978-3-319-07692-8
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2016, INT J SIGNAL PROCESS
   Anuar FM, 2013, EXPERT SYST APPL, V40, P105, DOI 10.1016/j.eswa.2012.07.031
   Aptoula E, 2014, IEEE T GEOSCI REMOTE, V52, P3023, DOI 10.1109/TGRS.2013.2268736
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Atto AM, 2013, IEEE T IMAGE PROCESS, V22, P2495, DOI 10.1109/TIP.2013.2246524
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chen WT, 2010, IEEE T IMAGE PROCESS, V19, P2005, DOI 10.1109/TIP.2010.2051753
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   F Radenovi, 2017, ARXIV171102512
   Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704
   Farsi H, 2013, IET IMAGE PROCESS, V7, P212, DOI 10.1049/iet-ipr.2012.0203
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang J, 2010, NEUROCOMPUTING, V73, P883, DOI 10.1016/j.neucom.2009.09.016
   Jain V, 2013, INT J ENG RES APPL, V3, P1166
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Khokher A, 2017, MULTIMED TOOLS APPL, V76, P21787, DOI 10.1007/s11042-016-4096-5
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Park U, 2014, IEEE SIGNAL PROC LET, V21, P962, DOI 10.1109/LSP.2014.2321755
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Rakvongthai Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1494, DOI 10.1016/j.image.2013.06.005
   Seetharaman K, 2014, J VIS COMMUN IMAGE R, V25, P727, DOI 10.1016/j.jvcir.2014.01.004
   Shahdoosti HR, 2016, SIGNAL IMAGE VIDEO P, V10, P1081, DOI 10.1007/s11760-016-0862-0
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Singha M, 2012, IET IMAGE PROCESS, V6, P1221, DOI 10.1049/iet-ipr.2011.0453
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P1
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P7633, DOI 10.1007/s11042-016-3416-0
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2010, MULTIMED TOOLS APPL, V49, P323, DOI 10.1007/s11042-009-0362-0
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yap PT, 2006, IEE P-VIS IMAGE SIGN, V153, P17, DOI 10.1049/ip-vis:20045064
   Yu J, 2012, IEEE T SYST MAN CY B, V42, P1413, DOI 10.1109/TSMCB.2012.2192108
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 60
TC 12
Z9 12
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2525
EP 2550
DI 10.1007/s11042-018-6386-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700055
DA 2024-07-18
ER

PT J
AU Zhang, MM
   Zhang, J
   Liu, Z
   An, CZ
AF Zhang, Mengmeng
   Zhang, Jing
   Liu, Zhi
   An, Changzhi
TI An efficient coding algorithm for 360-degree video based on improved
   adaptive QP Compensation and early CU partition termination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 360-degree video encoding; CU partition; Mode selection; Adaptive QP
   compensation
ID INTRA MODE DECISION; SIZE DECISION
AB Virtual reality technology enables people to experience the video content immersively. In order to provide realistic presence and dynamic view, the virtual reality video requires higher resolution (4K or 8K) image and more data to display relative to traditional video. Therefore, to improve the coding efficiency of 360-degree video becomes a key consideration. In the coding of 360-degree video, the spherical image is projected to a 2D image (such as ERP projection) and the standard video coding framework is utilized to accomplish the rest work. However, such a projection introduces much different levels of distortion according to coordinates, which degrades performance of rate distortion optimization in video encoding process. In this paper, we propose a compression optimization algorithm by using adaptive QP compensation based on coordinates to improve compression efficiency, and utilizing early termination of CU partition based on spatial correlation to reduce encoding time. To further reduce encoding complexity, the prewitt operator and the adaptive mode selection are adopted to reduce unnecessary intra prediction modes. Experimental results show that compared with HM-16.16, the proposed algorithm can reduce time by 42.4%, increase WSPSNR by 0.03 and decrease BD-rate by 0.3%.
C1 [Zhang, Mengmeng; Zhang, Jing; Liu, Zhi] North China Univ Technol, Beijing, Peoples R China.
   [An, Changzhi] Commun Technol Co Ltd, Beijing China Elect Intelligent, Beijing, Peoples R China.
C3 North China University of Technology
RP Zhang, MM (corresponding author), North China Univ Technol, Beijing, Peoples R China.
EM muchmeng@126.com; 381889962@qq.com; lzliu@ncut.edu.cn;
   changzhi.an@ceict.com.cn
FU National Natural Science Foundation of China [61370111]; Beijing
   Municipal Natural Science Foundation [4172020]; Great Wall Scholar
   Project of Beijing Municipal Education Commission [CITTCD20180304];
   Beijing Youth Talent Project [CITTCD 201504001]; Beijing Municipal
   Education Commission General Program [KM201610009003]
FX This work is supported by the National Natural Science Foundation of
   China (No.61370111), Beijing Municipal Natural Science Foundation
   (No.4172020), Great Wall Scholar Project of Beijing Municipal Education
   Commission (CIT&TCD20180304), Beijing Youth Talent Project (CIT&TCD
   201504001), and Beijing Municipal Education Commission General Program
   (KM201610009003).
CR Abbas A, 2016, JOINT VIDEO EXPLORAT
   Alshina E, 2017, JOINT VIDEO EXPLORAT
   Asbun E., 2016, AHG8 INTERDIGITAL TE
   Bai C, 2014, ICCE CHIN WORKSH, P28
   Chen ZY, 2017, J VIS COMMUN IMAGE R, V43, P77, DOI 10.1016/j.jvcir.2016.12.007
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2016, JOINT VIDEO EXPLORAT
   Goswami K, 2014, ETRI J, V36, P407, DOI 10.4218/etrij.14.0113.0458
   Gu J, 2017, IEEE SIGN P LETT, P1
   Hu J, 2016, J VIS COMMUN IMAGE R, V40, P671, DOI 10.1016/j.jvcir.2016.08.007
   Kim B G, 2017, FAST CODING UNIT CU
   Lee D, 2017, SIGNAL PROCESS-IMAGE, V55, P121, DOI 10.1016/j.image.2017.03.019
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Li YM, 2017, IEEE INT CON MULTI, P709, DOI 10.1109/ICME.2017.8019492
   Liu X, 2016, IEEE T CIRCUIT SYST, P1
   MIN B, 2015, TECHNOLOGY, V25, P892, DOI DOI 10.1109/TCSVT.2014.2363739
   Nishikori T, 2014, IND ELECT APPL, P52
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ruiz D, 2016, SIGNAL PROCESS-IMAGE, V44, P12, DOI 10.1016/j.image.2016.03.002
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun Y. L., 2016, JOINT VIDEO EXPLORAT
   Tan Zhang, 2016, 2016 IEEE Power and Energy Society General Meeting (PESGM), DOI 10.1109/PESGM.2016.7741692
   Tran HTT, 2017, INT CONF UBIQ FUTUR, P7
   Tseng CF, 2016, IET IMAGE PROCESS, V10, P215, DOI 10.1049/iet-ipr.2015.0154
   Wang TT, 2017, INT CONF ACOUST SPEE, P1532, DOI 10.1109/ICASSP.2017.7952413
   Yang MY, 2017, J REAL-TIME IMAGE PR, V13, P797, DOI 10.1007/s11554-014-0445-7
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang M, 2015, IEEE DATA COMPR CONF, P477, DOI 10.1109/DCC.2015.12
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhu S, 2016, MULTIMED TOOLS APPL, V76, P1
NR 32
TC 5
Z9 5
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1081
EP 1101
DI 10.1007/s11042-018-6283-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500061
DA 2024-07-18
ER

PT J
AU Dong, QC
   Feng, JQ
AF Dong, Qicong
   Feng, Jieqing
TI Adaptive disparity computation using local and non-local cost
   aggregations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Adaptive disparity computation; Fusion move; Disparity
   selection; Texture-based sub-pixel refinement
ID GRAPH CUTS; STEREO; REALITY; OCCLUSIONS; ACCURATE
AB A new method is proposed to adaptively compute the disparity of stereo matching by choosing one of the alternative disparities from local and non-local disparity maps. The initial two disparity maps can be obtained from state-of-the-art local and non-local stereo algorithms. Then, the more reasonable disparity is selected. We propose two strategies to select the disparity. One is based on the magnitude of the gradient in the left image, which is simple and fast. The other utilizes the fusion move to combine the two proposal labelings (disparity maps) in a theoretically sound manner, which is more accurate. Finally, we propose a texture-based sub-pixel refinement to refine the disparity map. Experimental results using Middlebury datasets demonstrate that the two proposed selection strategies both perform better than individual local or non-local algorithms. Moreover, the proposed method is compatible with many local and non-local algorithms that are widely used in stereo matching.
C1 [Dong, Qicong; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD, CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD, CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM qicongdong@zju.edu.cn; jqfeng@cad.zju.edu.cn
FU National Natural Science Foundation of China [61732015, 61472349]
FX The authors would like to thank Qing Ran for her instructive discussion
   of this paper. This work was supported by the National Natural Science
   Foundation of China under Grants Nos. 61732015 and 61472349.
CR [Anonymous], COMPUTER VISION PATT
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], INTERACTIVE SHADOW R
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2015, J SOFTWARE ENG APPL
   [Anonymous], IEEE T PATT AN
   [Anonymous], 3 DIMENSIONAL IMAGE
   [Anonymous], CORTEX
   [Anonymous], IEEE ACCESS
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Crouzil A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P632, DOI 10.1109/ICPR.1996.546101
   Drouyer S, 2017, LECT NOTES COMPUT SC, V10225, P172, DOI 10.1007/978-3-319-57240-6_14
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Huang XS, 2015, LECT NOTES COMPUT SC, V9315, P14, DOI 10.1007/978-3-319-24078-7_2
   Jiao JB, 2014, IEEE MULTIMEDIA, V21, P16, DOI 10.1109/MMUL.2014.51
   Kim KR, 2016, IEEE IMAGE PROC, P3429, DOI 10.1109/ICIP.2016.7532996
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031
   Kong D., 2004, BRIT MACHINE VISION, V1, P2
   Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143
   Li L., 2016, IEEE T CIRCUITS SYST
   Li L, 2017, Applied optics, V5th
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mizukami Y, 2012, INT C PATT RECOG, P364
   Narducci F, 2016, MULTIMED TOOLS APPL, V75, P9549, DOI 10.1007/s11042-016-3276-7
   Ogawara Koichi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1368, DOI 10.1109/ICPR.2010.338
   Olsson C, 2013, PROC CVPR IEEE, P1730, DOI 10.1109/CVPR.2013.226
   Osep A, 2016, IEEE INT CONF ROBOT, P3180, DOI 10.1109/ICRA.2016.7487487
   Park H., 2016, IEEE SIGNAL PROCESS
   Rameau F, 2016, IEEE T VIS COMPUT GR, V22, P2395, DOI 10.1109/TVCG.2016.2593768
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SCHARSTEIN D, 1994, INT C PATT RECOG, P572, DOI 10.1109/ICPR.1994.576363
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shu XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P35, DOI 10.1145/2733373.2806216
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Tan P, 2014, IMAGE PROCESS ON LIN, V4, P252, DOI 10.5201/ipol.2014.78
   Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   Vu DT, 2014, IEEE T IMAGE PROCESS, V23, P3428, DOI 10.1109/TIP.2014.2329389
   Wang L, 2014, J REAL-TIME IMAGE PR, V9, P447, DOI 10.1007/s11554-012-0275-4
   Woodford O.J., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Yu T, 2007, IEEE C COMPUTER VISI, P1
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 54
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31647
EP 31663
DI 10.1007/s11042-018-6236-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000006
DA 2024-07-18
ER

PT J
AU Jie, YM
   Guo, C
   Li, MC
   Feng, B
AF Jie, Yingmo
   Guo, Cheng
   Li, Mingchu
   Feng, Bin
TI Construction of compressed sensing matrices for signal processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing matrices; Signal processing; Singular linear spaces;
   Pooling design (PD); Restricted isometry property (RIP); Sparsity
ID DETERMINISTIC CONSTRUCTION; RECOVERY; BINARY
AB To cope with the huge expenditure associated with the fast growing sampling rate, compressed sensing (CS) is proposed as an effective technique of signal processing. In this paper, first, we construct a type of CS matrix to process signals based on singular linear spaces over finite fields. Second, we analyze two kinds of attributes of sensing matrices. One is the recovery performance corresponding to compressing and recovering signals. In particular, we apply two types of criteria, error-correcting pooling designs (PD) and restricted isometry property (RIP), to investigate this attribute. Another is the sparsity corresponding to storage and transmission signals. Third, in order to improve the ability associated with our matrices, we use an embedding approach to merge our binary matrices with some other matrices owing low coherence. At last, we compare our matrices with other existing ones via numerical simulations and the results show that ours outperform others.
C1 [Jie, Yingmo] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.
   [Jie, Yingmo; Guo, Cheng; Li, Mingchu; Feng, Bin] Dalian Univ Technol, Sch Software Technol, Dalian 116620, Peoples R China.
   [Guo, Cheng; Li, Mingchu; Feng, Bin] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Guo, C (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian 116620, Peoples R China.; Guo, C (corresponding author), Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
EM guocheng@dlut.edu.cn
OI Guo, Cheng/0000-0001-7489-7381; Li, Mingchu/0000-0001-8280-2936
FU National Natural Science Foundation of China [61501080, 61572095];
   Fundamental Research Funds for the Central Universities [DUT16QY09]
FX This paper is supported by the National Natural Science Foundation of
   China under grant No. 61501080, 61572095, and the Fundamental Research
   Funds for the Central Universities' under No. DUT16QY09.
CR Amini A, 2012, IEEE T SIGNAL PROCES, V60, P172, DOI 10.1109/TSP.2011.2169249
   Amini A, 2011, IEEE T INFORM THEORY, V57, P2360, DOI 10.1109/TIT.2011.2111670
   Applebaum L, 2009, APPL COMPUT HARMON A, V26, P283, DOI 10.1016/j.acha.2008.08.002
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Berinde R, 2014, P 46 ANN ALL C COMM, P798
   Bourgain J, 2011, DUKE MATH J, V159, P145, DOI 10.1215/00127094-1384809
   Calderbank R, 2010, IEEE J-STSP, V4, P358, DOI 10.1109/JSTSP.2010.2043161
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653
   DeVore RA, 2007, J COMPLEXITY, V23, P918, DOI 10.1016/j.jco.2007.04.002
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dyachkov AG, 2007, NONADAPTIVE TRIVIAL, P71
   Ionin Y, 2007, CRC HDB COMBINATORIA, P306
   Jie YM, 2017, J COMB OPTIM, V34, P245, DOI 10.1007/s10878-016-0068-y
   Karystinos GN, 2003, IEEE T COMMUN, V51, P48, DOI 10.1109/TCOMM.2002.807628
   Li Shuai, 2016, The art of clustering bandits
   Li SX, 2014, IEEE T SIGNAL PROCES, V62, P2850, DOI 10.1109/TSP.2014.2318139
   Li SX, 2014, IEEE T INFORM THEORY, V60, P2291, DOI 10.1109/TIT.2014.2303973
   Li SX, 2012, IEEE T INFORM THEORY, V58, P5035, DOI 10.1109/TIT.2012.2196256
   Li X, 2010, THESIS, P25
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Macula AJ, 1996, DISCRETE MATH, V162, P311, DOI 10.1016/0012-365X(95)00296-9
   Naidu RR, 2016, IEEE T SIGNAL PROCES, V64, P3566, DOI 10.1109/TSP.2016.2550020
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Rao K. R., 2000, The transform and data compression handbook
   Strohmer T, 2003, APPL COMPUT HARMON A, V14, P257, DOI 10.1016/S1063-5203(03)00023-X
   Sun YJ, 2017, INT J SENS NETW, V23, P258, DOI 10.1504/IJSNET.2017.083531
   Sylvester James J., 1867, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, V34, P461
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Wan Z., 2002, Geometry of Classical Groups over Finite Fields, V2nd
   Wang KS, 2011, FINITE FIELDS TH APP, V17, P395, DOI 10.1016/j.ffa.2011.02.001
   WOOTTERS WK, 1989, ANN PHYS-NEW YORK, V191, P363, DOI 10.1016/0003-4916(89)90322-9
   Wu H, 2012, J MILITARY COMMUNICA, V33, P90
   Xu L, 2015, SCI WISE 2015
   Xuemei Liu, 2017, Journal of Combinatorial Mathematics and Combinatorial Computing, V100, P255
   Zhang J, 2015, IEEE SIGNAL PROC LET, V22, P1960, DOI 10.1109/LSP.2015.2447934
NR 50
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30551
EP 30574
DI 10.1007/s11042-018-6120-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600019
DA 2024-07-18
ER

PT J
AU Liang, JH
   Wang, LF
   Ma, M
   Zhang, J
AF Liang, Jianhui
   Wang, Lifang
   Ma, Miao
   Zhang, Jian
TI A fast SAR image segmentation method based on improved chicken swarm
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Chicken swarm optimization algorithm; Swarm
   intelligence; SAR image
ID COLONY OPTIMIZATION
AB Severe speckle noise existed in synthetic aperture radar (SAR) image presents a challenge to image segmentation. Though some traditional segmentation methods for SAR image have some success, most of them fail to consider segmentation effects and segmentation speed at the same time. In this paper, we propose a novel method of SAR image fast segmentation which is based on an improved chicken swarm optimization algorithm. In this method, the positions of the whole chicken swarm are firstly initialized in a narrowed foraging space. Secondly, the grey entropy model is selected as the fitness function of the improved chicken swarm optimization algorithm. Hence, the optimal threshold value is located gradually and quickly by virtue of the foraging behaviors of chicken swarm with a hierarchal order. Experimental results show that our method is superior to some segmentation methods based on genetic algorithm, artificial fish swarm algorithm in convergence, stability and segmentation effects.
C1 [Liang, Jianhui; Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Liang, Jianhui; Zhang, Jian] HaiNan Univ, Inst Trop Agr & Forestry, Dan Zhou 571737, Peoples R China.
   [Ma, Miao] Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Hainan University; Shaanxi Normal
   University
RP Wang, LF (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.; Ma, M (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian 710062, Shaanxi, Peoples R China.
EM wanglf@nwpu.edu.cn; mmthp@snnu.edu.cn
RI Lin, Lin/JTU-1595-2023; liang, jian/HNI-8846-2023; Zhang,
   Jian/AAD-9385-2022
FU Hainan Provincial Natural Science Foundation of China [618QN220];
   Education and Teaching Reform Research object of Hainan University of
   China [hdjy1730]; Agricultural Science and Technology Innovation and
   Public Relations project of Shaanxi Province of China [2016NY-176];
   Fundamental Research Funds for the Central Universities of Shaanxi
   Normal University [GK201703054, GK201603083, GK201703058]; Key Science
   and Technology Innovation Team in Shaanxi Province of China
   [2014KTC-18]; National Natural Science Foundation of China [61373120]
FX This work is supported by Hainan Provincial Natural Science Foundation
   of China(618QN220), the Education and Teaching Reform Research object of
   Hainan University of China(hdjy1730), the Agricultural Science and
   Technology Innovation and Public Relations project of Shaanxi Province
   of China (2016NY-176), the Fundamental Research Funds for the Central
   Universities of Shaanxi Normal University (GK201703054, GK201603083,
   GK201703058), the Key Science and Technology Innovation Team in Shaanxi
   Province of China(2014KTC-18) and the National Natural Science
   Foundation of China (61373120).
CR Aghajari E, 2017, APPL SOFT COMPUT, V54, P347, DOI 10.1016/j.asoc.2017.01.003
   Bi DJ, 2017, IEEE T INSTRUM MEAS, V66, P777, DOI 10.1109/TIM.2017.2654578
   Bose A, 2016, SIGNAL IMAGE VIDEO P, V10, P1089, DOI 10.1007/s11760-016-0863-z
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Galante Negri Rogerio, 2016, Journal of Applied Remote Sensing, V10, DOI 10.1117/1.JRS.10.045005
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Jiang Feng, 2017, Journal of Software, V28, P160, DOI 10.13328/j.cnki.jos.005136
   [寇光杰 Kou Guangjie], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P122
   Li HJ, 2016, PATTERN RECOGN, V49, P237, DOI 10.1016/j.patcog.2015.05.028
   Li YF, 2016, PATTERN RECOGN, V52, P332, DOI 10.1016/j.patcog.2015.10.004
   Liang S, 2017, IET MICROW ANTENNA P, V11, P209, DOI 10.1049/iet-map.2016.0083
   [廖艳萍 Liao Yanping], 2015, [哈尔滨工业大学学报, Journal of Harbin Institute of Technology], V47, P89
   Liu LM, 2015, OPTIK, V126, P626, DOI 10.1016/j.ijleo.2015.01.033
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ma Miao, 2011, Journal of Xidian University, V38, P152, DOI 10.3969/j.issn.1001-2400.2011.06.025
   Ma M, 2011, APPL SOFT COMPUT, V11, P5205, DOI 10.1016/j.asoc.2011.05.039
   Ma Miao, 2009, Journal of Xidian University, V136, P1114
   Medeiros RS, 2016, COMPUT VIS IMAGE UND, V142, P23, DOI 10.1016/j.cviu.2015.06.001
   Meng XB, 2014, LECT NOTES COMPUT SC, V8794, P86, DOI 10.1007/978-3-319-11857-4_10
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   [潘喆 Pan Zhe], 2009, [光学学报, Acta Optica Sinica], V29, P2115
   Peng B, 2016, IEEE SIGNAL PROC LET, V23, P459, DOI 10.1109/LSP.2016.2517101
   Qu C., 2017, MATH PROBL ENG, V2017, P1
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Sun YJ, 2017, IEEE COMMUN LETT, V21, P1317, DOI 10.1109/LCOMM.2017.2672959
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Thittai AK, 2015, ULTRASONICS, V55, P58, DOI 10.1016/j.ultras.2014.08.005
   Wu DH, 2016, IEEE ACCESS, V4, P9400, DOI 10.1109/ACCESS.2016.2604738
   Zhang ZH, 2016, LASER J, V37, P84
   Zhou De-long, 2001, Journal of Software, V12, P1420
NR 31
TC 11
Z9 13
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31787
EP 31805
DI 10.1007/s11042-018-6119-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000012
DA 2024-07-18
ER

PT J
AU Taime, A
   Saaidi, A
   Satori, K
AF Taime, Abderazzak
   Saaidi, Abderrahim
   Satori, Khalid
TI Fast point matching using corresponding circles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Matching; Corresponding circles; Outliers; Putative correspondences
ID STEREO; OUTLIER
AB Point matching via corresponding circles (ICC) is a technique for removing outliers (mismatches) from given putative point correspondences in image pairs. It can be used as a basis for a wide range of applications including structure-from-motion, 3D reconstruction, tracking, image retrieval, registration, and object recognition. In this paper, we propose a new method called Fast Identification of point correspondences by Corresponding Circles (FICC) that improves the quality of the rejection mismatches and reduces the cost of computing it. In particular, we propose a new strategy that aims to take better advantage of the corresponding circles and reduces the number of putative points correspondences tested by the corresponding circles in each iteration rather than all set of putative correspondences, as in the original ICC. This reduces the computing time and together with a more efficient tool for rejecting mismatches which leads to significant gains in efficiency. We provide comparative results illustrating the improvements obtained by FICC over ICC, and we compare with many state-of-the-art methods.
C1 [Taime, Abderazzak; Saaidi, Abderrahim; Satori, Khalid] Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, Dept Math & Comp Sci, LIIAN, Fac Sci, BP 1796, Atlas Fez, Morocco.
   [Saaidi, Abderrahim] Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, LSI, Dept Math Phys & Comp Sci, Polydisciplinary Fac Taza, BP 1223, Taza, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Taime, A (corresponding author), Dhar Mahraz Sidi Mohamed Ben Abdellah Univ, Dept Math & Comp Sci, LIIAN, Fac Sci, BP 1796, Atlas Fez, Morocco.
EM taime35550@gmail.com; abderrahim.saaidi@usmba.ac.ma;
   khalidsatorim3i@yahoo.fr
RI Saaidi, Abderrahim/R-1916-2019; satori, khalid/GSE-3077-2022
OI SATORI, khalid/0000-0001-6055-4169; Saaidi,
   Abderrahim/0000-0003-1708-0468
CR [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], P 2003 I E COMP SOC
   [Anonymous], WILEY SERIES PROBABI
   [Anonymous], 2000, 2 INT S ROBOTICS AUT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cao DS, 2010, J COMPUT CHEM, V31, P592, DOI 10.1002/jcc.21351
   Chen YH, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P25, DOI 10.1109/IIH-MSP.2013.15
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Ke Y, 2004, PROC CVPR IEEE, P506
   Knuth D.E., 2011, The Art of Computer Programming: Seminumerical Algorithms, V1st
   Li XR, 2010, INT J COMPUT VISION, V89, P1, DOI 10.1007/s11263-010-0318-x
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MASSART DL, 1986, ANAL CHIM ACTA, V187, P171, DOI 10.1016/S0003-2670(00)82910-4
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D., 2007, COMPUTER VISION PATT, P1
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Taime A, 2018, MULTIMED TOOLS APPL, V77, P15027, DOI 10.1007/s11042-017-5086-y
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Yang J., 2016, MEASUREMENT, V7, P448
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
NR 29
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31139
EP 31157
DI 10.1007/s11042-018-6167-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600044
DA 2024-07-18
ER

PT J
AU Wang, CR
   Zhang, QL
   Duan, XD
   Gan, JH
AF Wang, Cunrui
   Zhang, Qingling
   Duan, Xiaodong
   Gan, Jianhou
TI Multi-ethnical Chinese facial characterization and analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese ethnicity; Manifold learning; Ethnicity classification
ID FEATURE-SELECTION; FACE; CLASSIFICATION; DATABASE; GENDER
AB Facial image based characterization and analysis of ethnicity, which is an important index of human demography, have become increasingly popular in the research areas of pattern recognition, computer vision, and machine learning. Many applications, such as face recognition and facial expression recognition, are affected by ethnicity information of individuals. In this study, we first create a human face database, which focuses on human ethnicity information and includes individuals from eight ethnic groups in China. This dataset can be used to conduct psychological experiments or evaluate the performance of computational algorithms. To evaluate the usefulness of this created dataset, some critical landmarks of these face images are detected and three types of features are extracted as ethnicity representations. Next, the ethnicity manifolds are learnt to demonstrate the discriminative power of the extracted features. Finally, ethnicity classifications with different popular classifiers are conducted on the constructed database, and the results indicate the effectiveness of the proposed features.
C1 [Wang, Cunrui; Zhang, Qingling] Northeastern Univ, Inst Syst Sci, Shenyang, Liaoning, Peoples R China.
   [Wang, Cunrui; Duan, Xiaodong] Dalian Nationalities Univ, Dalian Key Lab Digital Technol Natl Culture, Dalian, Peoples R China.
   [Gan, Jianhou] Yunnan Normal Univ, Key Lab Educ Informatizat Nationalities, Kunming 650500, Yunnan, Peoples R China.
C3 Northeastern University - China; Dalian Minzu University; Yunnan Normal
   University
RP Duan, XD (corresponding author), Dalian Nationalities Univ, Dalian Key Lab Digital Technol Natl Culture, Dalian, Peoples R China.
EM curui@mail.neu.edu.cn; qlzhang@mail.neu.edu.cn; duanxd@dlnu.edu.cn;
   ganjh@ynnu.edu.cn
RI Zhang, Qing/IZQ-5273-2023; cunrui, wang/AAO-3589-2021; Zhang,
   Qing/HTT-5047-2023
FU Natural Science Foundation of China [61370146, 61672132]; National
   Science and Technology Support Program [2013BAJ07B02]; Science &
   Technology Project of Liaoning Province [2013405003]
FX This work is sponsored by Natural Science Foundation of China (61370146,
   61672132), National Science and Technology Support Program
   (2013BAJ07B02) and Science & Technology Project of Liaoning Province
   (No.2013405003).
CR [Anonymous], P ICIP
   Balasubramanian M, 2002, SCIENCE, V295
   Ball R. M., 2011, REV LIT ARTS AM
   Benlamoudi A., 2015, CVA, DOI [10.13140/RG.2.1.2027.4723, DOI 10.13140/RG.2.1.2027.4723]
   Choe Kyle S, 2004, Arch Facial Plast Surg, V6, P244, DOI 10.1001/archfaci.6.4.244
   Dailey MN, 2010, EMOTION, V10, P874, DOI 10.1037/a0020019
   Das S., 2001, P 18 INT C MACHINE L, P74, DOI DOI 10.5555/645530.658297
   Enlow D. H., 1982, HDB FACIAL GROWTH
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Fu SY, 2012, COMPUT INTEL NEUROSC, V2012, DOI 10.1155/2012/946589
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Guyomarc'h P, 2014, J FORENSIC SCI, V59, P1502, DOI 10.1111/1556-4029.12547
   [郝建文 HAO Jian-wen], 2010, [重庆医科大学学报, Acta Universitatis Scientiae Medicinae Chongqing], V35, P297
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hosoi S, 2010, uS Patent App, Patent No. [13/059,424, 13059424]
   Huang YH, 2017, MULTIMED TOOLS APPL, V76, P123, DOI 10.1007/s11042-015-3009-3
   Lin H., 2006, Intelligent Control and Automation, V2, P9988
   Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554
   Ou Y, 2005, REAL TIME RACE CLASS
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiu XC, 2006, LECT NOTES COMPUT SC, V3832, P411
   Robinette K. M., 1999, 2 INT C 3D DIG IM MO, P380, DOI DOI 10.1109/IM.1999.805368
   SAUTER SL, 1990, AM PSYCHOL, V45, P1146, DOI 10.1037/0003-066X.45.10.1146
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Siffert W, 1999, J AM SOC NEPHROL, V10, P1921
   SNOW CC, 1970, AM J PHYS ANTHROPOL, V33, P221, DOI 10.1002/ajpa.1330330207
   Strom MA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041193
   Yao YG, 2002, AM J PHYS ANTHROPOL, V118, P63, DOI 10.1002/ajpa.10052
   [宇克莉 Yu Keli], 2016, [解剖学报, Acta Anatomica Sinica], V47, P404
   Zhang H, 1997, ACTA GENET SIN, V25, P381
   Zhang H, 2011, LECT NOTES COMPUT SC, V7098, P82, DOI 10.1007/978-3-642-25449-9_11
   Zhang YD, 2014, KNOWL-BASED SYST, V64, P22, DOI 10.1016/j.knosys.2014.03.015
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhuang Z., 2010, ANN OCCUP HYG
   Zhuang ZQ, 2005, J OCCUP ENVIRON HYG, V2, P567, DOI 10.1080/15459620500324727
NR 44
TC 4
Z9 4
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30311
EP 30329
DI 10.1007/s11042-018-6018-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600008
DA 2024-07-18
ER

PT J
AU Böschen, F
   Beck, T
   Scherp, A
AF Boeschen, Falk
   Beck, Tilman
   Scherp, Ansgar
TI Survey and empirical comparison of different approaches for text
   extraction from scholarly figures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scholarly figures; Text extraction; Comparison; Figure search
ID RECOGNITION; IMAGES
AB Different approaches have been proposed in the past to address the challenge of extracting text from scholarly figures. However, until recently, no comparative evaluation of the different approaches had been conducted. Thus, we performed an extensive study of the related work and evaluated in total 32 different approaches. In this work, we perform a more detailed comparison of the 7 most relevant approaches described in the literature and extend to 37 systematic linear combinations of methods for extracting text from scholarly figures. Our generic pipeline, consisting of six steps, allows us to freely combine the different possible methods and perform a fair comparison. Overall, we have evaluated 44 different linear pipeline configurations and systematically compared the different methods. We then derived two non-linear configurations and a two-pass approach. We evaluate all pipeline configurations over four datasets of scholarly figures of different origin and characteristics. The quality of the extraction results is assessed using F-measure and Levenshtein distance, and we measure the runtime performance. Our experiments showed that there is a linear configuration that overall shows the best text extraction quality on all datasets. Further experiments showed that the best configuration can be improved by extending it to a two-pass approach. Regarding the runtime, we observed huge differences from very fast approaches to those running for several weeks. Our experiments found the best working configuration for text extraction from our method set. However, they also showed that further improvements regarding region extraction and classification are needed.
C1 [Boeschen, Falk] Univ Kiel, Knowledge Discovery Res Grp Prof Ansgar Scherp, CAU, Kiel, Germany.
   [Beck, Tilman] Univ Kiel, CAU, Comp Sci, Kiel, Germany.
   [Scherp, Ansgar] ZBW Leibniz Informat Ctr Econ, Kiel, Germany.
C3 University of Kiel; University of Kiel; Deutsche Zentralbibliothek fur
   Wirtschaftswissenschaften (ZBW)
RP Böschen, F (corresponding author), Univ Kiel, Knowledge Discovery Res Grp Prof Ansgar Scherp, CAU, Kiel, Germany.
EM fboe@informatik.uni-kiel.de; stu127568@informatik.uni-kiel.de;
   a.scherp@zbw.eu
RI Scherp, Ansgar/Q-2315-2016
OI Boschen, Falk/0000-0003-4223-5353
FU EU [693092]
FX This research was co-financed by the EU H2020 project MOVING
   (http://www.moving-project.eu/) under contract no 693092. We thank ABBYY
   Europe GmbH for providing us with a test license of the ABBYY FineReader
   for our experiments.
CR [Anonymous], 2013, ACM Trans. Interact. Intell. Syst., DOI [DOI 10.1145/2395123.2395126, 10.1145/2395123.2395126]
   [Anonymous], 2011, P 24 ANN ACM S US IN
   Böschen F, 2017, LECT NOTES COMPUT SC, V10132, P15, DOI 10.1007/978-3-319-51811-4_2
   Boschen F, 2015, LWA 2015 WORKSH KDML, V1458, P20
   Boschen Falk., 2015, P 2015 ACM S DOCUMEN, P35, DOI DOI 10.1145/2682571.2797092
   Carberry S., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P581, DOI 10.1145/1148170.1148270
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Chester D, 2005, LECT NOTES COMPUT SC, V3488, P660
   Chiang YY, 2015, GEOINFORMATICA, V19, P1, DOI 10.1007/s10707-014-0203-9
   Chiang YY, 2013, INT J DOC ANAL RECOG, V16, P55, DOI 10.1007/s10032-011-0177-1
   Choudhury SR, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P667, DOI 10.1145/2740908.2741712
   Deseilligny MP, 1995, PATTERN RECOGN LETT, V16, P1297, DOI 10.1016/0167-8655(95)00084-5
   Fraz M, 2015, INT J DOC ANAL RECOG, V18, P153, DOI 10.1007/s10032-015-0239-x
   Gao GY, 2015, LECT NOTES COMPUT SC, V9314, P507, DOI 10.1007/978-3-319-24075-6_49
   Gllavata J, 2005, LECT NOTES COMPUT SC, V3691, P756
   Huang W, 2005, 8 INT C DOC AN REC I
   Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   Jayant C, 2007, ASSETS'07: PROCEEDINGS OF THE NINTH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P75
   Jiuzhou Z, 2006, HONORS YEAR PROJECT
   Khurshid K., 2009, SPIE P 16 DOC REC RE, V7247, P1
   Lu SJ, 2015, INT J DOC ANAL RECOG, V18, P125, DOI 10.1007/s10032-015-0237-z
   Lu XN, 2009, INT J DOC ANAL RECOG, V12, P65, DOI 10.1007/s10032-009-0081-0
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918
   Sas J, 2013, ADV INTELL SYST, V226, P527, DOI 10.1007/978-3-319-00969-8_52
   Strohmaier CM, 2003, 7 INT C DOC AN REC I, V2
   Xu SH, 2010, J BIOMED INFORM, V43, P924, DOI 10.1016/j.jbi.2010.09.006
   Yang L, 2006, LECT NOTES COMPUT SC, V3872, P324
NR 30
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29475
EP 29505
DI 10.1007/s11042-018-6162-7
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800016
DA 2024-07-18
ER

PT J
AU Chen, JJ
   Pang, L
   Ngo, CW
AF Chen, Jing-Jing
   Pang, Lei
   Ngo, Chong-Wah
TI Cross-modal recipe retrieval with stacked attention model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recipe retrieval; Cross-modal retrieval; Multi-modality embedding
AB Taking a picture of delicious food and sharing it in social media has been a popular trend. The ability to recommend recipes along will benefit users who want to cook a particular dish, and the feature is yet to be available. The challenge of recipe retrieval, nevertheless, comes from two aspects. First, the current technology in food recognition can only scale up to few hundreds of categories, which are yet to be practical for recognizing tens of thousands of food categories. Second, even one food category can have variants of recipes that differ in ingredient composition. Finding the best-match recipe requires knowledge of ingredients, which is a fine-grained recognition problem. In this paper, we consider the problem from the viewpoint of cross-modality analysis. Given a large number of image and recipe pairs acquired from the Internet, a joint space is learnt to locally capture the ingredient correspondence between images and recipes. As learning happens at the regional level for image and ingredient level for recipe, the model has the ability to generalize recognition to unseen food categories. Furthermore, the embedded multi-modal ingredient feature sheds light on the retrieval of best-match recipes. On an in-house dataset, our model can double the retrieval performance of DeViSE, a popular cross-modality model but not considering region information during learning.
C1 [Chen, Jing-Jing] City Univ Hong Kong, Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
   [Chen, Jing-Jing] City Univ Hong Kong, VIREO Grp, Kowloon Tong, Hong Kong, Peoples R China.
   [Pang, Lei] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
   [Ngo, Chong-Wah] City Univ Hong Kong, Dept Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong; City
   University of Hong Kong; City University of Hong Kong
RP Chen, JJ (corresponding author), City Univ Hong Kong, Comp Sci, Kowloon Tong, Hong Kong, Peoples R China.; Chen, JJ (corresponding author), City Univ Hong Kong, VIREO Grp, Kowloon Tong, Hong Kong, Peoples R China.
EM jingjchen9-c@my.cityu.edu.hk; leipang3-c@my.cityu.edu.hk;
   cscwngo@cityu.edu.hk
RI chen, JJ/HGB-6029-2022
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CityU 11203517]
FX This work described in this paper was supported by a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (CityU 11203517).
CR Aizawa K, 2015, IEEE MULTIMEDIA, V22, P4, DOI 10.1109/MMUL.2015.39
   Andrew G., 2013, P ICML, P1247
   [Anonymous], 2008, Proceeding of the 16th ACM international conference on Multimedia-MM'08, DOI [DOI 10.1145/1459359, 10.1145/1459359]
   [Anonymous], P INT C MULT EXP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], MHEALTH
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2012, Proceedings of the 2nd ACM international workshop on Interactive multimedia on mobile and portable devices
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], ARXIV151102274
   Beijbom O, 2015, IEEE WINT CONF APPL, P844, DOI 10.1109/WACV.2015.117
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen J., 2016, P ACM INT C MULT
   Chen JJ, 2017, LECT NOTES COMPUT SC, V10132, P588, DOI 10.1007/978-3-319-51811-4_48
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Haoran Xie, 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P254, DOI 10.1109/ISM.2010.44
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Karpathy A, 2014, ADV NEUR IN, V27
   Kawano Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P761, DOI 10.1145/2647868.2654869
   Matsunaga H, 2015, LECT NOTES COMPUT SC, V9281, P326, DOI 10.1007/978-3-319-23222-5_40
   Mikolov T., 2013, P ADV NEUR INF PROC
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su H, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P565, DOI 10.1145/2638728.2641335
   Wang X, 2015, IEEE INT CONF MULTI
   Xu RH, 2015, IEEE T MULTIMEDIA, V17, P1187, DOI 10.1109/TMM.2015.2438717
   Yamakata Yoko., 2016, 2016 IEEE INT C MULT, DOI [10.1109/ICMEW.2016.7574705, DOI 10.1109/ICMEW.2016.7574705]
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Zhang Weiyu, 2015, J Diabetes Sci Technol, V9, P525, DOI 10.1177/1932296815582222
NR 32
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29457
EP 29473
DI 10.1007/s11042-018-5964-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800015
DA 2024-07-18
ER

PT J
AU Connie, T
   Goh, MKO
   Teoh, ABJ
AF Connie, Tee
   Goh, Michael Kah Ong
   Teoh, Andrew Beng Jin
TI Human gait recognition using localized Grassmann mean representatives
   with partial least squares regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Grassmann manifold; Grassmann means; Tangent spaces;
   Partial least squares regression
ID WALKING SPEEDS; FEATURES; MOTION; MODEL
AB Gait recognition has become popular due to the rising demand for nonintrusive biometrics. At its nascent stage of development, gait recognition faces a number of challenges. The performance of a gait recognition system is sensitive towards factors like viewing angle, clothing, shoe type, load carriage and speed changes. In this paper, the problems of gait are formulated on the Grassmann manifold. It is not difficult to obtain multiple snapshots of a walking subjects with the wide availability of camera networks. These sets of images can be modelled as low-dimensional subspaces, which can be realized naturally as points on the Grassmann manifold. Modelling image sets as low-dimensional subspaces provides not only possible clue of one's gait, but also the common patterns of variation in the set. We present a method called Localized Grassmann Mean Representatives with Partial Least Squares Regression (LoGPLS) to infer a low-dimensional Euclidean approximation of the manifold. The notion of local mean representatives is introduced to construct multiple tangent spaces to better approximate the topological structure of the manifold. As the properties of the tangent spaces allows the Grassmann points to be evaluated in the vector space, partial least squares is applied to allow a more accurate classification of the points in a reduced space. Experiments have been conducted on four different publicly available gait databases. Empirical evidences demonstrate the effectiveness of the proposed approach in solving the various covariates in gait recognition.
C1 [Connie, Tee; Goh, Michael Kah Ong] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
C3 Multimedia University; Yonsei University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul, South Korea.
EM tee.connie@mmu.edu.my; michael.goh@mmu.edu.my; bjteoh@yonsei.ac.kr
RI Teoh, Andrew Beng Jin/F-4422-2010; Goh, Kah Ong Michael/F-8404-2012
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484; Tee,
   Connie/0000-0002-0901-3831; Goh, Kah Ong Michael/0000-0002-9217-6390
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [2016R1A2B4011656]; Fundamental Research Grant Scheme under the
   Malaysian Ministry of Education
FX The authors wish to thank the Institute of Automation, Chinese Academy
   of Sciences, and the Institute of Scientific and Industrial Research,
   Osaka University for sharing their gait databases. This research is
   supported in part by the National Research Foundation of Korea (NRF)
   grant funded by the Korea government (MSIP) (NO. 2016R1A2B4011656) and
   also Fundamental Research Grant Scheme under the Malaysian Ministry of
   Education.
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2012, THESIS
   [Anonymous], J MACH LEARN RES
   [Anonymous], CASIA GAIT DATABASE
   [Anonymous], FACE RECOGNITION USI
   [Anonymous], GRAPH EMBEDDING DISC
   Begelfor Evgeni, 2006, P IEEE C COMP VIS PA, V2, P2087, DOI DOI 10.1109/CVPR.2006.50
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Chang J.-M., 2008, CLASSIFICATION GRASS
   Chen X, 2016, PATTERN RECOGN, V53, P116, DOI 10.1016/j.patcog.2015.11.016
   Connie T, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-15
   Das Choudhury S, 2016, PATTERN RECOGN LETT, V80, P1, DOI 10.1016/j.patrec.2016.05.009
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hong J, 2014, MULTIMED TOOLS APPL, V71, P1999, DOI 10.1007/s11042-012-1319-2
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu HF, 2014, IEEE T CIRC SYST VID, V24, P617, DOI 10.1109/TCSVT.2013.2280098
   Jean F, 2009, PATTERN RECOGN, V42, P2936, DOI 10.1016/j.patcog.2009.05.006
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, IEEE T SYST MAN CY B, V42, P1654, DOI 10.1109/TSMCB.2012.2197823
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lee CS, 2006, LECT NOTES COMPUT SC, V4069, P315
   Lee TKM, 2014, MULTIMED TOOLS APPL, V72, P2833, DOI 10.1007/s11042-013-1574-x
   Li F, 2009, IEEE SIGNAL PROC LET, V16, P227, DOI 10.1109/LSP.2008.2010819
   Li X, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1132
   Liu N., 2011, P 2011 IEEE WORKSHOP, P1
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   López-Fernández D, 2016, J VIS COMMUN IMAGE R, V38, P396, DOI 10.1016/j.jvcir.2016.03.020
   Lu W, 2014, J VISUAL LANG COMPUT, V25, P754, DOI 10.1016/j.jvlc.2014.10.004
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   Nishiyama M, 2005, LECT NOTES COMPUT SC, V3546, P71
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Shiraga K, 2016, INT CONF BIOMETR
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Takemura Noriko, 2018, IPSJ Transactions on Computer Vision and Applications, V10, DOI 10.1186/s41074-018-0039-6
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tanawongsuwan R, 2004, PROC CVPR IEEE, P783
   Tsuji A, 2010, PROC CVPR IEEE, P717, DOI 10.1109/CVPR.2010.5540144
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Wold H, 1985, ENCY STAT SCI, P581, DOI DOI 10.1002/0471667196.ESS1914.PUB2
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Zeng W, 2015, NEUROCOMPUTING, V152, P139, DOI 10.1016/j.neucom.2014.10.079
   Zeng W, 2014, PATTERN RECOGN, V47, P3568, DOI 10.1016/j.patcog.2014.04.014
   Zhou ZH, 2006, IEEE T PATTERN ANAL, V28, P1738, DOI 10.1109/TPAMI.2006.214
NR 55
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28457
EP 28482
DI 10.1007/s11042-018-6045-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500030
DA 2024-07-18
ER

PT J
AU Hu, YC
   Lu, XB
AF Hu, Yaocong
   Lu, Xiaobo
TI Real-time video fire smoke detection by utilizing spatial-temporal
   ConvNet features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke detection; Convolutional neural networks; Spatial-temporal;
   Multi-task learning
ID CONVOLUTIONAL NEURAL-NETWORK; IMAGE
AB Fire is one of the most dangerous disasters threatening human life and property globally. In order to reduce fire losses, researches on video analysis for early smoke detection have become particularly significant. However, it is still a challenging task to extract stable features for smoke recognition, largely due to its variations in color, shapes and texture. Classical convolutional neural networks can automatically learn feature representations of appearance from a single frame but fail to capture motion information between frames. For addressing this issue, in this paper, we propose a spatial-temporal based convolutional neural network for video smoke detection, and for real-time detection, propose an enhanced architecture, which utilizes a multitask learning strategy to jointly recognize smoke and estimate optical flow, capturing intra-frame appearance features and inter-frame motion features simultaneously. The effectiveness and efficiency of our proposed method is validated by experiments carried out on our self-created dataset, which achieves 97.0% detection rate and 3.5% false alarm rate with processing time of 5ms per frame, obviously outperforming existing methods.
C1 [Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
FU National Key Science & Technology Pillar Program of China
   [2014BAG01B03]; National Natural Science Foundation of China [61374194];
   Key Research and Development Program of Jiangsu Province [BE2016739];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments and constructive suggestions. This work was
   supported by the National Key Science & Technology Pillar Program of
   China (No. 2014BAG01B03), the National Natural Science Foundation of
   China (No. 61374194), Key Research and Development Program of Jiangsu
   Province (No. BE2016739), and a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions.
CR [Anonymous], CORR
   [Anonymous], MM 2014 P 2014 ACM C
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], P 13 EUR SIGN PROC C
   [Anonymous], 2016, CORR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, CORR
   [Anonymous], DEEP CONVOLUTIONAL N
   [Anonymous], P SPIE INT SOC OPTIC
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   da Penha Osman S.  Jr., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P107, DOI 10.1109/ISCC.2010.5546519
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Huang XD, 2018, MULTIMED TOOLS APPL, V77, P7033, DOI 10.1007/s11042-017-4619-8
   Kaiser T, 2000, 34TH ANNUAL 2000 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P262, DOI 10.1109/CCST.2000.891198
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P315, DOI 10.1109/ASRU.2013.6707749
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tao CY, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P150, DOI [10.1109/ICIICII.2016.68, 10.1109/ICIICII.2016.0045]
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Xu G., 2017, ARXIV170908142
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
NR 39
TC 45
Z9 52
U1 1
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29283
EP 29301
DI 10.1007/s11042-018-5978-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800006
DA 2024-07-18
ER

PT J
AU Yang, DM
   Zhang, JG
   Xu, SB
   Ge, SY
   Kumar, GH
   Zhang, XP
AF Yang, Dongming
   Zhang, Jiguang
   Xu, Shibiao
   Ge, Shuiying
   Kumar, G. Hemantha
   Zhang, Xiaopeng
TI Real-time pedestrian detection via hierarchical convolutional feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Deep learning; Real-time
AB With the development of pedestrian detection technologies, existing methods can not simultaneously satisfy high quality detection and fast calculation for practical applications. Therefore, the goal of our research is to balance of pedestrian detection in aspects of the accuracy and efficiency, then get a relatively better method compared with current advanced pedestrian detection algorithms. Inspired from recent outstanding multi-category objects detector SSD (Single Shot MultiBox Detector), we proposed a hierarchical convolution based pedestrians detection algorithm, which can provide competitive accuracy of pedestrian detection at real-time speed. In this work, we proposed a fully convolutional network where the features from lower layers are responsible for small-scale pedestrians and the higher layers are for large-scale, which will further improve the recall rate of pedestrians with different scales, especially for small-scale. Meanwhile, a novel prediction box with a single specific aspect ratio is designed to reduce the miss rate and accelerate the speed of pedestrian detection. Then, the original loss function of SSD is also optimized by eliminating interference of the classifier to more adapt pedestrian detection while also reduce the time complexity. Experimental results on Caltech Benchmark demonstrates that our proposed deep model can reach 11.88% average miss rate with the real-time level speed of 20 fps in pedestrian detection compared with current state-of-the-art methods, which can be the most suitable model for practical pedestrian detection applications.
C1 [Yang, Dongming; Ge, Shuiying] Chinese Acad Sci, Natl Sci Lib, Beijing, Peoples R China.
   [Zhang, Jiguang; Kumar, G. Hemantha] Univ Mysore, Dept Comp Sci, Mysore, Karnataka, India.
   [Xu, Shibiao; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; National Science Library, CAS; University
   of Mysore; Chinese Academy of Sciences; Institute of Automation, CAS
RP Xu, SB (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
EM shibiao.xu@ia.ac.cn
FU National Natural Science Foundation of China [61620106003, 91646207,
   61671451, 61771026, 61502490];  [6140001010207]
FX This work is supported in part by National Natural Science Foundation of
   China with Nos. 61620106003, 91646207, 61671451, 61771026, 61502490, and
   in part by Project 6140001010207.
CR Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Zeng XY, 2013, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2013.22
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang Shanshan., 2015, CVPR, V1, P4
NR 20
TC 5
Z9 9
U1 1
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25841
EP 25860
DI 10.1007/s11042-018-5819-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400052
DA 2024-07-18
ER

PT J
AU Chang, KC
AF Chang, Ko-Chin
TI Efficient lossless watermarking algorithm using gradient sorting and
   selective embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless Watennarking; Reversible Data Hiding; Prediction-Error
   Expansion
ID HIDING SCHEME; DIFFERENCE EXPANSION
AB Prediction-error expansion based lossless watermarking techniques for images have received extensive attention due to versatile performance. In particular, the capacity-distortion control is one of the most important studies. This paper investigates that data-hiding distortion is mainly affected by the occurrence order of the prediction-error distribution, and capacity is affected by the occurrence number of the prediction errors. To make better control of the prediction-error distortion, we propose a novel scheme with three components: the gradient adjacent prediction (GAP), gradient sorting, and selective embedding. The capacity of the proposed scheme is high because GAP generates highly concentrated prediction-error histogram. Furthermore, the gradient sorting and selective embedding could avoid and reduce the unnecessary distortion. Experimental results show that the proposed scheme outperforms the competitors in terms of capacity enhancement and distortion reduction.
C1 [Chang, Ko-Chin] Natl Def Univ, Dept Elect & Elect Engn, Chung Cheng Inst Technol, Taoyuan, Taiwan.
C3 National Defense University - Taiwan
RP Chang, KC (corresponding author), Natl Def Univ, Dept Elect & Elect Engn, Chung Cheng Inst Technol, Taoyuan, Taiwan.
EM kcchang@ndu.edu.tw
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alotaibi N, 2015, 12 LEARN TECHN C WEA, P12
   [Anonymous], 2012, INTRO DATA COMPRESSI
   [Anonymous], 1997, D LIB MAGAZINE
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen M, 2010, IEEE J-STSP, V4, P592, DOI 10.1109/JSTSP.2010.2049222
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Forbes C., 2010, STAT DISTRIBUTIONS
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liang RZ, 2016, PROC INT C TOOLS ART, P299, DOI [10.1109/ICTAI.2016.50, 10.1109/ICTAI.2016.0053]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Sachnev V, 2009, IEEE T CIRCUITS SYST, V19, P89
   Shi Y. Q., 2004, Digital Watermarking. Third International Workshop, IWDW 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3304), P1
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xianting Zeng, 2009, Journal of Multimedia, V4, P145
   Xuan GR, 2008, LECT NOTES COMPUT SC, V5041, P264
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
NR 39
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23579
EP 23606
DI 10.1007/s11042-017-5547-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900023
DA 2024-07-18
ER

PT J
AU Jiao, ZQ
   Ma, K
   Wang, H
   Zou, L
   Zhang, YD
AF Jiao, Zhuqing
   Ma, Kai
   Wang, Huan
   Zou, Ling
   Zhang, Yudong
TI Research on node properties of resting-state brain functional networks
   by using node activity and ALFF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain functional networks; Resting-state; Functional magnetic resonance
   imaging (fMRI); Node activity; Complex networks
ID ALZHEIMERS-DISEASE; CONNECTIVITY ANALYSIS; AMPLITUDE; EIGENBRAIN
AB Human brain functional networks have some attractive topological properties in anatomical space, whereas relatively few literatures to discuss the local properties of brain networks. In this paper, a method for judging nodes properties of resting-state brain functional networks is proposed based on node activity and Amplitude of Low Frequency Fluctuation (ALFF). We utilized it to research the active degree of brain regions. Firstly, functional Magnetic Resonance Imaging (fMRI) data are employed to construct the resting-state brain functional network, and calculate node degree, clustering coefficient and average distance. Then, by comparing the differences in the above indexes between stroke patients and normal subjects, we further analyzed the distribution of active degree in various brain regions and their connection states through node activity of brain functional networks. Finally, the ALFF values of normal subjects and patients are measured respectively in contrast experiment, and the activity of the related nodes was compared and judged. The node activities of some brain regions in stroke patients are lower than that of normal subjects and even zero, and the ALFF values of the normal are generally higher than those of the stroke patients. The experimental results verify the feasibility of node activity in judging active degree of various brain regions from physiological significance of ALFF in resting-state brain functional networks.
C1 [Jiao, Zhuqing; Wang, Huan; Zou, Ling] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.
   [Ma, Kai] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
   [Zhang, Yudong] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Changzhou University; Nanjing University of Aeronautics & Astronautics;
   Nanjing Normal University
RP Jiao, ZQ (corresponding author), Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Peoples R China.; Zhang, YD (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM jzqtec@163.com; zhangyudong@njnu.edu.cn
RI Ma, kai/KSL-8338-2024; Jiao, Zhuqing/JDD-4102-2023; Zhang,
   Yudong/I-7633-2013
OI Ma, kai/0009-0004-3748-2549; Zhang, Yudong/0000-0002-4870-1493
FU National Natural Science Foundation of China [51307010, 61602250];
   University Natural Science Research Program of Jiangsu Province
   [17KJB510003]
FX The authors would like to thank the reviewers and the editors for their
   valuable comments and suggestions on improving this paper. This work is
   supported by the National Natural Science Foundation of China (Nos.
   51307010 and 61602250) and the University Natural Science Research
   Program of Jiangsu Province (No. 17KJB510003).
CR Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Damaraju E, 2014, NEUROIMAGE-CLIN, V5, P298, DOI 10.1016/j.nicl.2014.07.003
   Grefkes C, 2011, BRAIN, V134, P1264, DOI 10.1093/brain/awr033
   Han Y, 2011, NEUROIMAGE, V55, P287, DOI 10.1016/j.neuroimage.2010.11.059
   Hoptman MJ, 2010, SCHIZOPHR RES, V117, P13, DOI 10.1016/j.schres.2009.09.030
   Jiao ZQ, 2017, J MED IMAG HEALTH IN, V7, P407, DOI 10.1166/jmihi.2017.2029
   Jiao ZQ, 2017, FRONT BIOSCI-LANDMRK, V22, P1634, DOI 10.2741/4562
   Jiao ZQ, 2017, CNS NEUROL DISORD-DR, V16, P44, DOI 10.2174/1871527314666161124120040
   Jiao ZQ, 2016, INT J SENS NETW, V21, P197, DOI 10.1504/IJSNET.2016.078374
   Lang S, 2017, MED HYPOTHESES, V98, P49, DOI 10.1016/j.mehy.2016.11.010
   Li CM, 2014, BEHAV BRAIN RES, V274, P205, DOI 10.1016/j.bbr.2014.08.019
   Li Wei, 2012, Chinese Journal of Biomedical Engineering, V31, P344, DOI 10.3969/j.issn.0258-8021.2012.03.05
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   [罗扬眉 Luo Yangmei], 2015, [科学通报, Chinese Science Bulletin], V60, P170
   Park JY, 2007, P NATL ACAD SCI USA, V104, P17916, DOI 10.1073/pnas.0705081104
   Redies C, 2001, BIOESSAYS, V23, P1100, DOI 10.1002/bies.10014
   Schindler KA, 2008, CHAOS, V18, DOI 10.1063/1.2966112
   Smith R, 2016, PSYCHIAT RES-NEUROIM, V248, P39, DOI 10.1016/j.pscychresns.2016.01.009
   Smith SM, 2011, NEUROIMAGE, V54, P875, DOI 10.1016/j.neuroimage.2010.08.063
   Su Q, 2016, NEW J PHYS, V18, DOI 10.1088/1367-2630/18/10/103007
   Supekar K, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000100
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Wang SH, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18050194
   Wang SX, 2016, INT J COGN INFORM NA, V10, P1, DOI 10.4018/IJCINI.2016010101
   Wee CY, 2016, BRAIN IMAGING BEHAV, V10, P342, DOI 10.1007/s11682-015-9408-2
   Wei LQ, 2014, HUM BRAIN MAPP, V35, P331, DOI 10.1002/hbm.22176
   Yang H, 2007, NEUROIMAGE, V36, P144, DOI 10.1016/j.neuroimage.2007.01.054
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yonggang Lu, 2017, Multimedia Tools and Applications, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Yu RJ, 2014, HUM BRAIN MAPP, V35, P627, DOI 10.1002/hbm.22203
   Zang YF, 2007, BRAIN DEV-JPN, V29, P83, DOI 10.1016/j.braindev.2006.07.002
   Zhang YR, 2016, J STAT MECH-THEORY E, P1, DOI 10.1088/1742-5468/2016/11/113207
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
NR 40
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22689
EP 22704
DI 10.1007/s11042-017-5163-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500050
DA 2024-07-18
ER

PT J
AU Kong, FQ
   Govindaraj, VV
   Zhang, YD
AF Kong, Fanqiang
   Govindaraj, Vishnu Varthanan
   Zhang, Yu-Dong
TI Ridge-based curvilinear structure detection for identifying road in
   remote sensing image and backbone in neuron dendrite image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ridge-based curvilinear structure detection; Road detection; Remote
   sensing; Backbone detection; Neuron dendrite
ID TRANSFORM; TRACKING; SPINE
AB The curvilinear structure detection is widely applied in many real tasks, such as the fiber classification, river finding, blood vessel detection, and so on. In this paper, we proposed to use the ridge-based curvilinear structure detection (RCSD) for the road extraction from the remote sensing images. First, we employed the morphology trivial opening operation to filter out almost all the small clusters of noise and the small paths. Then RCSD was used to find the road from the remote sensing images. The experiments showed that our proposed method is efficient and give better results than the current existing road-detection methods. Considering the similar structure between backbone in the neuron dendrite images and the road in remote sensing images, we extended the application of RCSD to the backbone detection in neuron dendrite images. The results on backbone detection also proved the efficiency of RCSD.
C1 [Kong, Fanqiang] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing, Jiangsu, Peoples R China.
   [Govindaraj, Vishnu Varthanan] Kalasalingam Univ, Dept Instrumentat & Control Engn, Virudunagar, Tamil Nadu, India.
   [Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Nanjing University of Aeronautics & Astronautics; Kalasalingam Academy
   of Research & Education; University of Leicester
RP Kong, FQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing, Jiangsu, Peoples R China.; Govindaraj, VV (corresponding author), Kalasalingam Univ, Dept Instrumentat & Control Engn, Virudunagar, Tamil Nadu, India.; Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM kongfq@nuaa.edu.cn; g.vishnuvarthanan@klu.ac.in; yudongzhang@ieee.org
RI Govindaraj, Vishnuvarthanan/AAE-7400-2020; Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493; govindaraj,
   vishnuvarthanan/0000-0001-9136-3461
FU National Natural Science Foundation of China [61401200, 61602250]; Open
   Fund of Guangxi Key Laboratory of Manufacturing System AMP; Advanced
   Manufacturing Technology [17-259-05-011 K]; Open fund for Jiangsu Key
   Laboratory of Advanced Manufacturing Technology [HGAMTL1601,
   HGAMTL-1703]; National key research and development plan
   [2017YFB1103202]; Henan Key Research and Development Project
   [182102310629]
FX This work was supported by National Natural Science Foundation of China
   (61401200 & 61602250), Open Fund of Guangxi Key Laboratory of
   Manufacturing System & Advanced Manufacturing Technology (17-259-05-011
   K), Open fund for Jiangsu Key Laboratory of Advanced Manufacturing
   Technology (HGAMTL1601, HGAMTL-1703), National key research and
   development plan (2017YFB1103202) and Henan Key Research and Development
   Project (182102310629).
CR Alvarez JM, 2014, IEEE T INTELL TRANSP, V15, P1168, DOI 10.1109/TITS.2013.2295427
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   BARSI A, 2008, GEOLOGICAL MAGAZINE, V70, P180
   Byun J, 2015, ETRI J, V37, P606, DOI 10.4218/etrij.15.0113.1131
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3813, DOI 10.1007/s11042-016-4161-0
   Cheng J, 2007, J NEUROSCI METH, V165, P122, DOI 10.1016/j.jneumeth.2007.05.020
   Dong D, 1994, COMPUT CHEM ENG, V20, P65
   Einbeck J, 2011, TRANSPORTMETRICA, V7, P229, DOI 10.1080/18128600903500110
   Fan J, 2017, IEEE NIH LIF SCI SYS, P233
   Fan J, 2009, NEUROINFORMATICS, V7, P113, DOI 10.1007/s12021-009-9047-0
   Guo CZ, 2012, IEEE T INTELL TRANSP, V13, P1338, DOI 10.1109/TITS.2012.2187896
   HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936
   Jia WJ, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0814-4
   Koh IYY, 2002, NEURAL COMPUT, V14, P1283, DOI 10.1162/089976602753712945
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Li XF, 2010, INT J REMOTE SENS, V31, P5041, DOI 10.1080/01431160903283835
   Li Y, 2016, ROBOT AUTON SYST, V85, P1, DOI 10.1016/j.robot.2016.08.003
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Martínez Z, 2011, COMPUT STAT DATA AN, V55, P2158, DOI 10.1016/j.csda.2011.01.008
   Meijering E, 2004, CYTOM PART A, V58A, P167, DOI 10.1002/cyto.a.20022
   Ozertem U, 2011, J MACH LEARN RES, V12, P1249
   Pulkkinen S, 2015, COMPUT STAT DATA AN, V82, P89, DOI 10.1016/j.csda.2014.08.007
   Shi Q, 2018, IEEE ACCESS, V6, P25486, DOI 10.1109/ACCESS.2017.2773142
   Shih FY, 2003, SOL PHYS, V218, P99, DOI 10.1023/B:SOLA.0000013052.34180.58
   Silva G, 2017, NEURORADIOL J, V30, DOI 10.1177/1971400917709627
   Stanford DC, 2000, IEEE T PATTERN ANAL, V22, P601, DOI 10.1109/34.862198
   Su J, 2013, DETECTION CLASSIFICA, P227
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2018, MULTIMED TOOLS APPL, V77, P3701, DOI 10.1007/s11042-016-3401-7
   Wang SH, 2017, IEEE ACCESS, V5, P16576, DOI 10.1109/ACCESS.2017.2736558
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P116, DOI 10.2174/1871527315666161111123638
   Wang SH, 2017, FUND INFORM, V151, P325, DOI 10.3233/FI-2017-1495
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P637, DOI 10.1177/0037549715623847
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P601, DOI 10.1177/0037549715603481
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang SH, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/454076
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wu XY, 2018, MULTIMED TOOLS APPL, V77, P3745, DOI 10.1007/s11042-016-3931-z
   Xu XY, 2006, I S BIOMED IMAGING, P554
   Zhang Y, 2007, NEUROIMAGE, V36, P346, DOI 10.1016/j.neuroimage.2007.02.044
   Zhou HL, 2015, IEEE T INTELL TRANSP, V16, P297, DOI 10.1109/TITS.2014.2331353
NR 43
TC 5
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22857
EP 22873
DI 10.1007/s11042-018-5976-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500058
DA 2024-07-18
ER

PT J
AU Kumaran, N
   Vadivel, A
   Kumar, SS
AF Kumaran, N.
   Vadivel, A.
   Kumar, S. Saravana
TI Recognition of human actions using CNN-GWO: a novel modeling of CNN for
   enhancement of classification performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action bank features; Local spatio temporal features; CNN (Convolutional
   neural network); GWO (Grey wolf optimization); Human action recognition
ID FRAMEWORK; ALGORITHM
AB Recognizing human actions from unconstrained videos turns to be a major challenging task in computer visualization approaches due to decreased accuracy in the feature classification performance. Therefore to improve the classification performance it is essential to minimize the 'classification' errors. Here, in this work, we propose a hybrid CNN-GWO approach for the recognition of human actions from the unconstrained videos. The weight initializations for the proposed deep Convolutional Neural Network (CNN) classifiers highly depend on the generated solutions of GWO (Grey Wolf Optimization) algorithm, which in turn minimizes the 'classification' errors. The action bank and local spatio-temporal features are generated for a video and fed into the 'CNN' classifiers. The 'CNN' classifiers are trained by a gradient descent algorithm to detect a 'local minimum' during the fitness computation of GWO 'search agents'. The GWO algorithms 'global search' capability as well as the gradient descent algorithms `local search' capabilities are subjected for the identification of a solution which is nearer to the global optimum. Finally, the classification performance can be further enhanced by fusing the classifiers evidences produced by the GWO algorithm. The proposed classification frameworks efficiency for the recognition of human actions is evaluated with the help of four achievable action recognition datasets namely HMDB51, UCF50, Olympic Sports and Virat Release 2.0. The experimental validation of our proposed approach shows better achievable results on the recognition of human actions with 99.9% recognition accuracy.
C1 [Kumaran, N.; Vadivel, A.] NIT, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
   [Kumar, S. Saravana] Sree Dattha Inst Engn & Sci, Hyderabad, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Kumaran, N (corresponding author), NIT, Dept Comp Applicat, Tiruchirappalli, Tamil Nadu, India.
EM kumarann5050@gmail.com
RI Kumar, S Saravana/B-5229-2018; A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676
CR [Anonymous], IEEE T NEURAL NETW
   [Anonymous], J SOC ARTIFICIAL INT
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], LNCS
   [Anonymous], IEEE C COMPUT VIS PA
   [Anonymous], CORR
   [Anonymous], ECCV
   Ballas N, 2013, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2013.336
   Bengio Y, 2011, LECT NOTES ARTIF INT, V6925, P18, DOI 10.1007/978-3-642-24412-4_3
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Ding SF, 2013, ARTIF INTELL REV, V39, P251, DOI 10.1007/s10462-011-9270-6
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang HJ, 2007, P ICCV, P1
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev IT Lindberg., 2003, Space-time interest points
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Lim MK, 2014, EXPERT SYST APPL, V41, P4704, DOI 10.1016/j.eswa.2014.02.003
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Lu YY, 2014, NEUROCOMPUTING, V126, P132, DOI 10.1016/j.neucom.2012.08.071
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadi E, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P335, DOI 10.1109/CRV.2016.46
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Qiu Q, 2011, IEEE I CONF COMP VIS, P707, DOI 10.1109/ICCV.2011.6126307
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Rodriguez M, 2016, IMAGE VISION COMPUT, V48-49, P26, DOI 10.1016/j.imavis.2015.12.006
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schaffer J. D., 1992, COGANN-92. International Workshop on Combinations of Genetic Algorithms and Neural Networks (Cat. No.92TH0435-8), P1, DOI 10.1109/COGANN.1992.273950
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sundararaj V., 2016, INT J INTELLIGENT EN, V9, P117, DOI DOI 10.22266/ijies2016.0930.12
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yao X, 1999, P IEEE, V87, P1423, DOI 10.1109/5.784219
   Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001
   Zhang EH, 2016, NEUROCOMPUTING, V208, P281, DOI 10.1016/j.neucom.2015.12.122
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
NR 51
TC 22
Z9 24
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23115
EP 23147
DI 10.1007/s11042-017-5591-z
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900003
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Sun, JD
AF Zhang, Yu-Dong
   Sun, Junding
TI Preliminary study on angiosperm genus classification by weight decay and
   combination of most abundant color index with fractional Fourier entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Angiosperm genus; Weight decay; Classification; Fractional fourier
   entropy; Feature extraction; Most abundant color index; Color histogram;
   Single-hidden layer feedforward neural-network; Petal image; AlexNet
ID NEURAL-NETWORK; BACKPROPAGATION; OPTIMIZATION; FLOWERS; POWER
AB In order to develop an efficient angiosperm-genus classification system, we first collected petal image of Hibiscus, Orchis, and Prunus, by digital camera, and remove the backgrounds by region-growing method. Next, we proposed a novel feature-extraction method, which combined most abundant color index (MACI) and introduced the fractional Fourier entropy (FRFE). Third, we submitted the 41 features to a single-hidden layer feedforward neural-network (SLFN), with weight decay (WD) to avoid overfitting. The 10 x 10-fold cross validation showed our method achieved an overall accuracy of 98.92%. Without weight decay, the overall accuracy decreased to 95.50%. Our experiments validated that optimal decay factor is 0.1, and optimal number of hidden neurons is 15. This proposed method is excellent. It performs better than six state-of-the-art approaches and AlexNet. The weight decay helps to enhance generalization of our classifier.
C1 [Zhang, Yu-Dong; Sun, Junding] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Yu-Dong] Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.
   [Zhang, Yu-Dong] Columbia Univ, MRI Unit, New York, NY 10032 USA.
   [Zhang, Yu-Dong] New York State Psychiat Inst & Hosp, New York, NY 10032 USA.
   [Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
C3 Henan Polytechnic University; Columbia University; Columbia University;
   New York State Psychiatry Institute; University of Leicester
RP Zhang, YD (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Zhang, YD (corresponding author), Columbia Univ, Translat Imaging Div, New York, NY 10032 USA.; Zhang, YD (corresponding author), Columbia Univ, MRI Unit, New York, NY 10032 USA.; Zhang, YD (corresponding author), New York State Psychiat Inst & Hosp, New York, NY 10032 USA.; Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
EM yudongzhang@ieee.org
RI Zhang, Yudong/I-7633-2013
OI Zhang, Yudong/0000-0002-4870-1493
FU Natural Science Foundation of Jiangsu Province [BK20150983]; Natural
   Science Foundation of China [61602250]
FX This paper was supported by Natural Science Foundation of Jiangsu
   Province (BK20150983), Natural Science Foundation of China (61602250).
CR Abdelali HA, 2016, J VIS COMMUN IMAGE R, V34, P219, DOI 10.1016/j.jvcir.2015.11.010
   Alves CT, 2014, FUTURE MICROBIOL, V9, P139, DOI 10.2217/fmb.13.147
   [Anonymous], 2014, INT J HYBRID INF TEC
   [Anonymous], 2010, TAXONOMY ANGIOSPERMS
   [Anonymous], 2010, Int. J. Comput. Appl.
   Bartrina I, 2011, PLANT CELL, V23, P69, DOI 10.1105/tpc.110.079079
   Bhalke DG, 2016, J INTELL INF SYST, V46, P425, DOI 10.1007/s10844-015-0360-9
   Chamberlain CJ, 1961, GYMNOSPERMS STRUCTUR
   Cheng KY, 2014, NEUROCOMPUTING, V145, P416, DOI 10.1016/j.neucom.2014.05.011
   Connor P, 2015, NEURAL NETWORKS, V67, P121, DOI 10.1016/j.neunet.2015.03.005
   Elgamel SA, 2016, IET RADAR SONAR NAV, V10, P892, DOI 10.1049/iet-rsn.2014.0455
   Gaxiola F, 2016, APPL SOFT COMPUT, V38, P860, DOI 10.1016/j.asoc.2015.10.027
   Goulianas K, 2016, MATH METHOD APPL SCI, V39, P2602, DOI 10.1002/mma.3715
   Grzeszczuk M, 2016, ACTA SCI POL-HORTORU, V15, P109
   Guru DS, 2011, MATH COMPUT MODEL, V54, P1030, DOI 10.1016/j.mcm.2010.11.032
   Jiang P, 2016, NEUROCOMPUTING, V198, P40, DOI 10.1016/j.neucom.2015.08.118
   Kumar YHS, 2015, PROCEDIA COMPUT SCI, V45, P226, DOI 10.1016/j.procs.2015.03.125
   Laber EB, 2011, J AM STAT ASSOC, V106, P904, DOI 10.1198/jasa.2010.tm10053
   Lee HH, 2015, ELECTRON LETT, V51, P2
   Leung ACS, 2012, NEURAL COMPUT APPL, V21, P1709, DOI 10.1007/s00521-012-0832-6
   Maparyan L, 2016, WORLDVIEWS, V20, P48, DOI 10.1163/15685357-02001005
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pacifico LDS, 2012, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2012.6377769
   Pwasong A, 2016, NEUROCOMPUTING, V182, P197, DOI 10.1016/j.neucom.2015.12.034
   Rudall PJ, 2009, AM J BOT, V96, P67, DOI 10.3732/ajb.0800027
   Rundo L, 2016, MED BIOL ENG COMPUT, V54, P1071, DOI 10.1007/s11517-015-1404-6
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Sasaki K, 2016, JARQ-JPN AGR RES Q, V50, P79, DOI 10.6090/jarq.50.79
   Spyropoulos A, 2016, INT J COMPUT VISION, V118, P300, DOI 10.1007/s11263-015-0877-y
   Stemplewski S, 2016, ADV INTELL SYST, V432, P197, DOI 10.1007/978-3-319-28567-2_17
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Yeh IC, 2012, COMM COM INF SC, V304, P10
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030077
NR 39
TC 18
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22671
EP 22688
DI 10.1007/s11042-017-5146-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500049
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Lin, CY
   Muchtar, K
   Liu, PH
AF Yeh, Chia-Hung
   Lin, Chih-Yang
   Muchtar, Kahlil
   Liu, Pin-Hsian
TI Rain streak removal based on non-negative matrix factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rain removal; Non-negative matrix factorization (NMF); Canny edge
   detection
ID IMAGE; OBJECTS
AB A rain streak in an image can degrade visual quality of that image to the human eye. Unfortunately, removing the rain streak from a single image represents a very challenging task. In this paper, a single image rain removal process based on non-negative matrix factorization is proposed. First, the rain image is broken down into a low-frequency and high-frequency part by a Gaussian filter. Therefore, the rain component, which lies mostly in the middle frequency range, can be discarded in high and low frequency domains. Next, non-negative matrix factorization (NMF) method is applied to deal with the rain streak in the low frequency domain. Finally, Canny edge detection and block copy strategy are performed separately to remove the rain component in the high frequency domain to improve image quality. In comparison with state-of-the-art approaches, the proposed method achieves competitive results without the need for an extra image database to train the dictionary.
C1 [Yeh, Chia-Hung] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
   [Yeh, Chia-Hung; Liu, Pin-Hsian] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
   [Lin, Chih-Yang] Yuan Ze Univ, Dept Commun Engn, Taoyuan, Taiwan.
   [Muchtar, Kahlil] Syiah Kuala Univ, Dept Elect & Comp Engn, Banda Aceh, Indonesia.
C3 National Taiwan Normal University; National Sun Yat Sen University; Yuan
   Ze University; Universitas Syiah Kuala
RP Lin, CY (corresponding author), Yuan Ze Univ, Dept Commun Engn, Taoyuan, Taiwan.
EM andrewlin@saturn.yzu.edu.tw
RI Lin, Chih-Yang/HOF-2583-2023; Muchtar, Kahlil/P-8532-2019
OI Lin, Chih-Yang/0000-0002-0401-8473; Muchtar, Kahlil/0000-0001-5740-1938
FU Ministry of Science and Technology, Taiwan [MOST 103-2221-E-468-007-MY2,
   MOST 105-2221-E-155-083, MOST 103-2221-E-110-045-MY3, NSC
   102-2221-E-110-032-MY3]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   under Grants MOST 103-2221-E-468-007-MY2, MOST 105-2221-E-155-083, MOST
   103-2221-E-110-045-MY3, and NSC 102-2221-E-110-032-MY3.
CR [Anonymous], 2001, P ADV NEUR INF PROC
   Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Brewer N, 2008, LECT NOTES COMPUT SC, V5342, P451, DOI 10.1007/978-3-540-89689-0_49
   Chen DY, 2014, IEEE T CIRC SYST VID, V24, P1430, DOI 10.1109/TCSVT.2014.2308627
   De-An Huang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P164, DOI 10.1109/ICME.2012.92
   Fang S, 2014, OPT EXPRESS, V22, P19523, DOI 10.1364/OE.22.019523
   Garg K, 2005, IEEE I CONF COMP VIS, P1067
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   Gregor K., 2010, P 27 INT C INT C MAC, P399
   Grindlay G, 2010, NMFLIB EFFICIENT MAT
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Kang L. W., 2013, P IEEE INT WORKSH MU
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Krishnan S., 2012, INT J COMPUTER SCI E, V2, P19, DOI DOI 10.5121/IJCSEA.2012.2202
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Manu BN, 2015, 2015 7TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND ELECTRICAL ENGINEERING (ICITEE), P263, DOI 10.1109/ICITEED.2015.7408953
   Shi ZW, 2014, OPTIK, V125, P3868, DOI 10.1016/j.ijleo.2014.01.170
   Utaminingrum F, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P139, DOI 10.1109/SITIS.2015.81
   Wixson L, 2000, IEEE T PATTERN ANAL, V22, P774, DOI 10.1109/34.868680
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xue XW, 2012, IEEE INT WORKSH MULT, P170, DOI 10.1109/MMSP.2012.6343435
   Yeh C-H, 2012, P COMP VIS GRAPH IM
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
NR 31
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20001
EP 20020
DI 10.1007/s11042-017-5430-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500049
DA 2024-07-18
ER

PT J
AU Chang, V
AF Chang, Victor
TI Data analytics and visualization for inspecting cancers and genes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Analytics and visualization for bioinformatics and healthcare;
   Simulation for malignant tumor inspection; Simulation for gene
   inspection; Big data processing an analytics for bio-science
ID HUMAN COGNITION MODEL; VISUAL ANALYTICS; MANAGEMENT; SIMULATION;
   MAPREDUCE; FRAMEWORK; TOOLKIT; CLOUD
AB This paper describes our latest research in data analytics and visualization for bioinformatics and healthcare. Each year many patients have suffered cancers. Analytics and visualization can help to simulate the development of malignant tumors and help identify weak spots of tumor for treatment, inspect malignant tumors in general and inspect whether genes have cancerous cells. Related literature, technologies, simulation results with explanation, performance evaluation and comparisons with other work have been discussed in details. We can process training data with a low completion time to achieve simulations of malignant tumors and genes to inspect their status, as well as the querying the output data within seconds. Our malignant tumor and gene simulation can achieve 360 degrees for an inspection of cancerous presence. We conclude that data analytics and visualization can provide effective and efficient healthcare research and also other type of interdisciplinary research.
C1 [Chang, Victor] Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.
   [Chang, Victor] Xian Jiaotong Liverpool Univ, IBSS, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; Xi'an Jiaotong-Liverpool University
RP Chang, V (corresponding author), Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.; Chang, V (corresponding author), Xian Jiaotong Liverpool Univ, IBSS, Suzhou, Peoples R China.
EM Victor.Chang@xjtlu.edu.cn
RI Chang, Victor/AAC-7582-2019
OI Chang, Victor/0000-0002-8012-5852
CR Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   [Anonymous], 2010, SYNTHESIS LECT HUMAN, DOI DOI 10.2200/S00274ED1V01Y201006HLT007
   [Anonymous], 2011, Stochastic modelling for systems biology
   [Anonymous], 2015, MODELLING SURVIVAL D, DOI DOI 10.1201/B18041
   [Anonymous], 1996, Math. Commun.
   Boik J., 2001, NATURAL COMPOUNDS CA
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Cao JF, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157551
   Chang V, 2017, KNOWL-BASED SYST, V127, P29, DOI 10.1016/j.knosys.2017.03.003
   Chang V, 2014, FUTURE GENER COMP SY, V37, P512, DOI 10.1016/j.future.2013.12.028
   Christopher R, 2004, ANN NY ACAD SCI, V1020, P132, DOI 10.1196/annals.1310.014
   Cios KJ, 2002, ARTIF INTELL MED, V26, P1, DOI 10.1016/S0933-3657(02)00049-0
   Cuomo MI, 2012, WORLD CANC MAKING NE
   Green TM, 2009, INFORM VISUAL, V8, P1, DOI 10.1057/ivs.2008.28
   Green TM, 2008, IEEE CONF VIS ANAL, P91, DOI 10.1109/VAST.2008.4677361
   Hu JY, 2018, COMPUT ELECTR ENG, V65, P332, DOI 10.1016/j.compeleceng.2017.04.010
   Huang DD, 2015, IEEE T VIS COMPUT GR, V21, P420, DOI 10.1109/TVCG.2014.2359887
   Matsunaga Andrea., 2008, eScience, P222, DOI DOI 10.1109/ESCIENCE.2008.62.[3]B
   McKenna A, 2010, GENOME RES, V20, P1297, DOI 10.1101/gr.107524.110
   Pienta KJ, 2012, DIAGNOSIS TREATMENT, V88
   Priestman T., 2012, CANC CHEMOTHERAPY CL
   Quinn G. P., 2002, EXPT DESIGN DATA ANA
   Roose T, 2007, SIAM REV, V49, P179, DOI 10.1137/S0036144504446291
   Schadt EE, 2010, NAT REV GENET, V11, P647, DOI 10.1038/nrg2857
   Schatz MC, 2009, BIOINFORMATICS, V25, P1363, DOI 10.1093/bioinformatics/btp236
   Siddiqa A, 2017, CLUSTER COMPUT, V20, P1193, DOI 10.1007/s10586-016-0712-4
   Suresh P, 2010, IND ENG CHEM RES, V49, P7768, DOI 10.1021/ie100258p
   Venkitaraman AR, 2002, CELL, V108, P171, DOI 10.1016/S0092-8674(02)00615-3
NR 28
TC 23
Z9 23
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17693
EP 17707
DI 10.1007/s11042-017-5186-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900008
DA 2024-07-18
ER

PT J
AU Fayed, S
   Youssef, SM
   El-Helw, A
   Patwary, M
   Moniri, M
AF Fayed, Salema
   Youssef, Sherin M.
   El-Helw, Amr
   Patwary, Mohammad
   Moniri, Mansour
TI Analytical framework for adaptive compressive sensing for target
   detection within wireless visual sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Duty cycles; Target detection; Wireless visual
   sensor networks
AB Wireless visual sensor networks (WVSNs) are composed of a large number of visual sensor nodes covering a specific geographical region. This paper addresses the target detection problem within WVSNs where visual sensor nodes are left unattended for long-term deployment. As battery energy is a critical issue it is always challenging to maximize the network's lifetime. In order to reduce energy consumption, nodes undergo cycles of active-sleep periods that save their battery energy by switching sensor nodes ON and OFF, according to predefined duty cycles. Moreover, adaptive compressive sensing is expected to dynamically reduce the size of transmitted data through the wireless channel, saving communication bandwidth and consequently saving energy. This paper derives for the first time an analytical framework for selecting node's duty cycles and dynamically choosing the appropriate compression rates for the captured images and videos based on their sparsity nature. This reduces energy waste by reaching the maximum compression rate for each dataset without compromising the probability of detection. Experiments were conducted on different standard datasets resembling different scenes; indoor and outdoor, for single and multiple targets detection. Moreover, datasets were chosen with different sparsity levels to investigate the effect of sparsity on the compression rates. Results showed that by selecting duty cycles and dynamically choosing the appropriate compression rates, the desired performance of detection can be achieved with adaptive CS and at the same time saving energy, where the proposed framework results in an 70% on average energy saving as compared to transmitting the captured image without CS.
C1 [Fayed, Salema; Youssef, Sherin M.] AAST, Comp Engn Dept, Coll Engn & Technol, Alexandria, Egypt.
   [El-Helw, Amr] AAST, Coll Engn & Technol, Elect & Commun Dept, Alexandria, Egypt.
   [Patwary, Mohammad] Birmingham City Univ, Sch Comp & Digital Technol, Birmingham B47XG, W Midlands, England.
   [Moniri, Mansour] Univ East London, Sch Architecture Comp & Engn, London, England.
C3 University of East London
RP Fayed, S (corresponding author), AAST, Comp Engn Dept, Coll Engn & Technol, Alexandria, Egypt.
EM salema.fayed@gmail.com
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Candes EJ, 2006, P INT C MATH ZUR 199, P118
   Candes EJ, 2008, EXACT MATRIX COMPLET
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Cao Q, 2005, LECT NOTES COMPUT SC, V3560, P276
   Cevher Volkan., 2008, Compressive sensing for Background subtraction
   Charfi Y, 2009, IEEE WIREL COMMUN, V16, P44, DOI 10.1109/MWC.2009.4907559
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Chou CT, 2009, IEEE 34 C LOC COMP N, P443
   Davenport M., 2006, DETECTION ESTIMATION
   Demigha O, 2013, IEEE COMMUNICATIONS, V15
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fayed S, 2016, MULTIMED TOOLS APPL, V75, P6347, DOI 10.1007/s11042-015-2575-8
   Hormati A, 2010, IEEE T SIGNAL PROCES, V58, P1095, DOI 10.1109/TSP.2009.2034908
   Huang H.-C., 2014, J INFORM HIDING MULT, V5, P275
   Jiang H., 2013, ARXIV13021942
   Mahalanobis A, 2009, IEEE T AERO ELEC SYS, V45, P1167, DOI 10.1109/TAES.2009.5259191
   Medagliani Paolo, 2010, 2010 IEEE International Conference on Pervasive Computing and Communications (PerCom 2010), P31, DOI 10.1109/PERCOM.2010.5466994
   Medagliani P, 2012, PERVASIVE MOB COMPUT, V8, P429, DOI 10.1016/j.pmcj.2011.02.004
   Mohanty P, 2012, COMM COM INF SC, V292, P56
   MuthuLakshmi MsV, 2013, INT J SCI ENG RES, V4, P248
   Patsakis Constantinos., 2014, Journal of Information Hiding and Multimedia Signal Processing, V5, P20
   Redondi A, 2014, IEEE T CIRC SYST VID, V24, P2117, DOI 10.1109/TCSVT.2014.2329378
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   Rui Tan, 2008, 2008 16th International Workshop on Quality of Service, P150
   Soro S, 2009, ADV MULTIMED, V2009, DOI 10.1155/2009/640386
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang E, 2009, 2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P233, DOI 10.1109/SSP.2009.5278595
   Wang F, 2010, IEEE COMMUN SURV TUT, V99, P1
   Wang Y, 2013, ENERGY EFFICIENT NOD, V2013
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
   Wu Y, 2013, VISUAL TRACKER BEMCH
   Yap FGH, 2014, SENSORS-BASEL, V14, P3506, DOI 10.3390/s140203506
   Zhao M., 2014, UBIQUITOUS INT J INF, V5, P475
   Zhongmin W., 2007, ULTRA WIDEBAND, P393
NR 36
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16533
EP 16559
DI 10.1007/s11042-017-5227-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300025
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Han, XF
   Jin, J
   Wang, MJ
   Jiang, W
AF Han, Xian-Feng
   Jin, Jesse S.
   Wang, Ming-Jie
   Jiang, Wei
TI Guided 3D point cloud filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; Guided filtering; Noise removal; Efficiency
ID RECOGNITION
AB 3D point cloud has gained significant attention in recent years. However, raw point clouds captured by 3D sensors are unavoidably contaminated with noise resulting in detrimental efforts on the practical applications. Although many widely used point cloud filters such as normal-based bilateral filter, can produce results as expected, they require a higher running time. Therefore, inspired by guided image filter, this paper takes the position information of the point into account to derive the linear model with respect to guidance point cloud and filtered point cloud. Experimental results show that the proposed algorithm, which can successfully remove the undesirable noise while offering better performance in feature-preserving, is significantly superior to several state-of-the-art methods, particularly in terms of efficiency.
C1 [Han, Xian-Feng; Wang, Ming-Jie; Jiang, Wei] Tianjin Univ, High Dimens Informat Proc Lab, Tianjin, Peoples R China.
   [Jin, Jesse S.] Tianjin Univ, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Jin, J (corresponding author), Tianjin Univ, Tianjin, Peoples R China.
EM hanxianf@163.com; jinsheng@tju.edu.cn; 18768126670@163.com;
   jiangweitju@163.com
RI wang, ming/HPC-6329-2023; Zhang, Jianjun/KEJ-3941-2024
CR Aldoma A, 2012, IEEE ROBOT AUTOM MAG, V19, P80, DOI 10.1109/MRA.2012.2206675
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   [Anonymous], 2009, ACM T GR
   [Anonymous], 2004, P 9 ACM S SOLID MODE
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han XF, 2018, MULTIMED TOOLS APPL, V77, P16887, DOI 10.1007/s11042-017-5258-9
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu GF, 2006, VISUAL COMPUT, V22, P147, DOI 10.1007/s00371-006-0372-0
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huhle Benjamin, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563158
   Jenke P, 2006, COMPUT GRAPH FORUM, V25, P379, DOI 10.1111/j.1467-8659.2006.00957.x
   Jones TR, 2004, IEEE COMPUT GRAPH, V24, P53, DOI 10.1109/MCG.2004.14
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Kobbelt L, 2004, COMPUT GRAPH-UK, V28, P801, DOI 10.1016/j.cag.2004.08.009
   Lee KW, 2005, INT C COMP AID DES C, P275
   Liu SJ, 2012, IEEE COMPUT GRAPH, V32, P70, DOI 10.1109/MCG.2011.14
   Ma S, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3315, DOI 10.1109/WCICA.2014.7053264
   Moorfield B, 2015, LECT NOTES COMPUT SC, V9257, P394, DOI 10.1007/978-3-319-23117-4_34
   Nasab SE, 2014, INT S TEL
   Oliva N, 2017, INT EL DEVICES MEET
   Paris S, 2007, SIGGRAPH, P853
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Pfister H, 2004, IEEE COMPUT GRAPH, V24, P22, DOI 10.1109/MCG.2004.15
   Rangel J. C., 2016, P ANN C S AFR I COMP, P1
   Rosli NAIM, 2014, AIP CONF PROC, V1605, P149, DOI 10.1063/1.4887580
   Shi BQ, 2011, COMPUT AIDED DESIGN, V43, P910, DOI 10.1016/j.cad.2011.04.001
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wand M, 2008, COMPUT GRAPH-UK, V32, P204, DOI 10.1016/j.cag.2008.01.010
   Xu WK, 2015, KSII T INTERNET INF, V9, P2585, DOI 10.3837/tiis.2015.07.0014
NR 32
TC 25
Z9 31
U1 14
U2 104
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17397
EP 17411
DI 10.1007/s11042-017-5310-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300063
DA 2024-07-18
ER

PT J
AU Jin, JC
   Lee, JH
   Kim, ES
   Kim, YJ
AF Jin, Jeong-Chan
   Lee, Jae-Hyeok
   Kim, Eun-Sil
   Kim, Young-Jin
TI OPT: optimal human visual system-aware and power-saving color
   transformation for mobile AMOLED displays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile AMOLED display; Image quality assessment; Human visual system;
   Power saving; Color transformation
AB Organic light-emitting diode (OLED) displays have a high power efficiency; however, the frequent use of user interaction-based applications such as instant messengers, video players, and games contributes strongly to the total power consumption. The power consumption varies significantly depending on the display contents, and thus, color transformation, which is a representative low-power technique, is used for OLED displays. Previously developed low-power color transformation methods have not been thoroughly researched for satisfying the human visual system and have not considered optimal visual satisfaction and power consumption simultaneously. In this paper, a novel low-power color transformation approach is proposed, which is aimed at simultaneously optimizing both visual satisfaction and power consumption. In addition, it is implemented on an active-matrix OLED (AMOLED) display-based Android smartphone at runtime. Experimental results show that the proposed technique achieves better human visual satisfaction and shows up to 22.32% power saving on average on the AMOLED display and offers 6.23% more extended battery life over that of an existing leading technique.
C1 [Jin, Jeong-Chan; Kim, Young-Jin] Ajou Univ, Dept Elect & Comp Engn, 206 World Cup Ro, Suwon 16499, South Korea.
   [Lee, Jae-Hyeok] Korea Adv Inst Sci & Technol, Sch Elect Engn, 291 Daehakro, Daejeon 34141, South Korea.
   [Kim, Eun-Sil] Synapsoft Corp, Rm 906,Woolim E Biz Ctr 2,12 Digital Ro,33 Gil, Seoul 08377, South Korea.
C3 Ajou University; Korea Advanced Institute of Science & Technology
   (KAIST)
RP Kim, YJ (corresponding author), Ajou Univ, Dept Elect & Comp Engn, 206 World Cup Ro, Suwon 16499, South Korea.
EM youngkim@ajou.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - the Ministry of Science and ICT [2015R1A2A2A01008434]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science and ICT(No. 2015R1A2A2A01008434).
CR Anand B, 2014, 2014 SEVENTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORKING (ICMU), P21, DOI 10.1109/ICMU.2014.6799052
   Anand Bhojan., 2011, P 9 INT C MOBILE SYS, P57
   [Anonymous], 2001, P 8 IEEE INT C COMP
   [Anonymous], 2007, Color Constancy
   Chen X, 2013, P 16 INT WORKSH MOB
   Chen X, 2012, P 17 AS S PAC DES AU
   Dong M., 2011, Proceedings of the 9th international conference on Mobile systems, applications, and services, MobiSys '11, P85
   Jang M, 2011, P 2011 ACM S RES APP
   Kim D, 2014, P 51 ANN DES AUT C D
   Lee C, 2010, P 17 IEEE INT C IM P
   Mian D, 2009, P 2009 ACM IEEE INT
   Shin D, 2011, P 48 ANN DES AUT C D
   Wang J, 2012, TR1209 VIRT TECH DEP
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wee TK, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P573, DOI 10.1145/2493432.2493445
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 16
TC 5
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16699
EP 16720
DI 10.1007/s11042-017-5234-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300032
DA 2024-07-18
ER

PT J
AU Mezzanzanica, M
   Mercorio, F
   Cesarini, M
   Moscato, V
   Picariello, A
AF Mezzanzanica, Mario
   Mercorio, Fabio
   Cesarini, Mirko
   Moscato, Vincenzo
   Picariello, Antonio
TI GraphDBLP: a system for analysing networks of computer scientists
   through graph databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph database; Word embedding; Knowledge extraction; Semantic
   analytics; Social network analysis
ID DBLP; RECOMMENDATION
AB This paper presents GraphDBLP, a system that models the DBLP bibliography as a graph database for performing graph-based queries and social network analyses. GraphDBLP also enriches the DBLP data through semantic keyword similarities computed via word-embedding. In this paper, we discuss how the system was formalized as a multi-graph, and how similarity relations were identified through word2vec. We also provide three meaningful queries for exploring the DBLP community to (i) investigate author profiles by analysing their publication records; (ii) identify the most prolific authors on a given topic, and (iii) perform social network analyses over the whole community. To date, GraphDBLP contains 5+ million nodes and 24+ million relationships, enabling users to explore the DBLP data by referencing more than 3.3 million publications, 1.7 million authors, and more than 5 thousand publication venues. Through the use of word-embedding, more than 7.5 thousand keywords and related similarity values were collected. GraphDBLP was implemented on top of the Neo4j graph database. The whole dataset and the source code are publicly available to foster the improvement of GraphDBLP in the whole computer science community.
C1 [Mezzanzanica, Mario; Mercorio, Fabio; Cesarini, Mirko] Univ Milano Bicocca, CRISP Res Ctr, Dept Stat & Quantitat Methods, Milan, Italy.
   [Moscato, Vincenzo; Picariello, Antonio] Univ Naples Federico II, Dept Elect Engn & Informat Technol DIETI, Naples, Italy.
C3 University of Milano-Bicocca; University of Naples Federico II
RP Mercorio, F (corresponding author), Univ Milano Bicocca, CRISP Res Ctr, Dept Stat & Quantitat Methods, Milan, Italy.
EM fabio.mercorio@unimib.it
RI Moscato, Vincenzo/H-2526-2012; Mercorio, Fabio/E-4369-2013; Picariello,
   Antonio/L-6820-2015; Cesarini, Mirko/N-8839-2016
OI Mercorio, Fabio/0000-0001-6864-2702; Cesarini,
   Mirko/0000-0001-9601-0403; MEZZANZANICA, MARIO/0000-0003-0399-2810
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   Aggarwal CC, 2011, SOCIAL NETWORK DATA ANALYTICS, P1
   Albanese M, 2013, ACM T INTERNET TECHN, V13, DOI 10.1145/2532640
   Amato F, 2017, FUT GEN COMPUT SYST
   Angles R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322433
   [Anonymous], 2017, DISTRIBUTED GRAPH DA
   [Anonymous], 2015, RECOMMENDER SYSTEMS
   Bao J, 2015, GEOINFORMATICA, V19, P525, DOI 10.1007/s10707-014-0220-8
   Barrat A, 2004, P NATL ACAD SCI USA, V101, P3747, DOI 10.1073/pnas.0400087101
   Belk V., 2012, PROC 6 INT C WEBLOGS, P34
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Bird S., 2009, NATURAL LANGUAGE PRO
   Boselli R, 2017, LECT NOTES ARTIF INT, V10536, P330, DOI 10.1007/978-3-319-71273-4_27
   Boselli R, 2018, J INTELL INF SYST, V51, P477, DOI 10.1007/s10844-017-0488-x
   Boselli R, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P343, DOI 10.5220/0006490703430349
   Cattell R, 2010, SIGMOD REC, V39, P12, DOI 10.1145/1978915.1978919
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chikhaoui B, 2015, AAAI CONF ARTIF INTE, P51
   Colace F, 2015, COMPUT HUM BEHAV, V51, P694, DOI 10.1016/j.chb.2014.12.011
   CONSENS MP, 1990, PROCEEDINGS OF THE NINTH ACM SIGACT-SIGMOD-SIGART SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P404, DOI 10.1145/298514.298591
   Deng HB, 2008, IEEE DATA MINING, P163, DOI 10.1109/ICDM.2008.29
   Diederich J, 2007, ACM-IEEE J CONF DIG, P505, DOI 10.1145/1255175.1255305
   DU N., 2007, P 9 WEBKDD 1 SNA KDD, P16, DOI [DOI 10.1145/1348549.1348552, 10.1145/1348549.1348552]
   Elmacioglu E, 2005, SIGMOD REC, V34, P33, DOI 10.1145/1083784.1083791
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Jiang M, 2015, IEEE T KNOWL DATA EN, V27, P3084, DOI 10.1109/TKDE.2015.2432811
   Jing Han, 2011, Proceedings 2011 6th International Conference on Pervasive Computing and Applications (ICPCA 2011), P363, DOI 10.1109/ICPCA.2011.6106531
   Le T, 2015, 2015 IEEE 16TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P435, DOI 10.1109/IRI.2015.73
   Lee S., 2011, PROC RECSYS 11, P93, DOI [DOI 10.1145/2043932.2043952, 10.1145/2043932.2043952]
   Ley M, 2009, PROC VLDB ENDOW, V2, P1493, DOI 10.14778/1687553.1687577
   Li X, 2013, DECIS SUPPORT SYST, V54, P880, DOI 10.1016/j.dss.2012.09.019
   Liu Lu., 2010, CIKM, DOI DOI 10.1145/1871437.1871467
   Marrara S, P INT C WEB INT ACM, P1026, DOI [10.1145/3106426.3109035, DOI 10.1145/3106426.3109035]
   Mehmood Yasir, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P48, DOI 10.1007/978-3-642-40991-2_4
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Moreira C, 2015, EXPERT SYST, V32, P477, DOI 10.1111/exsy.12062
   Nascimento MA, 2003, SIGMOD RECORD, V32, P8
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Newman MEJ, 2004, LECT NOTES PHYS, V650, P337
   Papadopoulos S, 2012, DATA MIN KNOWL DISC, V24, P515, DOI 10.1007/s10618-011-0224-z
   SCOTT J., 2017, Social Network Analysis, V4th
   Stonebraker M, 2010, COMMUN ACM, V53, P10, DOI 10.1145/1721654.1721659
   Tagarelli Andrea, 2013, Digital Libraries: Social Media and Community Networks. 15th International Conference on Asia-Pacific Digital Libraries, ICADL 2013. Proceedings: LNCS 8279, P93, DOI 10.1007/978-3-319-03599-4_11
   Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807
   Tesoriero Claudio, 2013, Getting started with OrientDB
   Pham TAN, 2015, PROC INT CONF DATA, P567, DOI 10.1109/ICDE.2015.7113315
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Webber J., 2012, P 3 ANN C SYST PROGR, P217, DOI DOI 10.1145/2384716.2384777
   Wu YC, 2016, IEEE T MULTIMEDIA, V18, P2135, DOI 10.1109/TMM.2016.2614220
   Zaiane O.R., 2007, P 9 WEBKDD 1 SNA KDD, P74, DOI DOI 10.1145/1348549.1348558
NR 51
TC 12
Z9 16
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18657
EP 18688
DI 10.1007/s11042-017-5503-2
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900055
DA 2024-07-18
ER

PT J
AU Mishra, D
   Vijayakumar, P
   Sureshkumar, V
   Amin, R
   Islam, SKH
   Gope, P
AF Mishra, Dheerendra
   Vijayakumar, P.
   Sureshkumar, Venkatasamy
   Amin, Ruhul
   Islam, S. K. Hafizul
   Gope, Prosanta
TI Efficient authentication protocol for secure multimedia communications
   in IoT-enabled wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; IoT-based WSN; Anonymity; Sensor node; Gateway node;
   Smartcard
ID KEY AGREEMENT SCHEME; 2-FACTOR USER AUTHENTICATION; MUTUAL
   AUTHENTICATION; IMPROVEMENTS; INTERNET
AB In current times, multimedia application includes integrated sensors, mobile networks and Internet-of-Things (IoT) services. In IoT services, if more devices are connected without much constrains, the problem of security, trust and privacy remain a challenge. For multimedia communications through Wireless Sensor Network (WSN), sensor nodes transmit confidential data to the gateway nodes via public channels. In such an environment, the security remains a serious issue from past many years. Only few works are available to support secure multimedia communications performed in IoT-enabled WSNs. Among the few works, Kumari and Om recently proposed an authentication protocol for multimedia communications in IoT-enabled WSNs, which is applicable in coal mine for safety monitoring. The authors claimed in their work that their contributory protocol strongly withstands several security threats such as, user impersonation attack, sensor node impersonation attack, sensor node anonymity issue and others technical design issues. However, this article proved that Kumari and Om's protocol has some design flaws and is susceptible to various security attacks including, user and sensor node impersonation attacks. As a remedy, a robust authentication protocol using smartcard is constructed to solve the security issues found in Kumari and Om's protocol. The proof of correctness of mutual authentication is performed using the BAN logic model. In addition, our further security investigation claimed strong protection against known security attacks. Our protocol is analyzed comprehensively and compared against the similar protocols and the results showed that it is efficient and robust than earlier protocols.
C1 [Mishra, Dheerendra] LNM Inst Informat Technol, Dept Math, Jaipur, Rajasthan, India.
   [Vijayakumar, P.] Univ Coll Engn, Dept Comp Sci & Engn, Melpakkam 604001, Tamil Nadu, India.
   [Sureshkumar, Venkatasamy] PSG Coll Technol, Dept Appl Math & Computat Sci, Coimbatore, Tamil Nadu, India.
   [Amin, Ruhul] Dr Shyama Prasad Mukherjee Int Inst Informat Tech, Dept Comp Sci & Engn, Naya Raipur, India.
   [Islam, S. K. Hafizul] Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
   [Gope, Prosanta] Natl Univ Singapore, Dept Comp Sci, Singapore 119077, Singapore.
C3 LNM Institute of Information Technology; PSG College Technology;
   National University of Singapore
RP Islam, SKH (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Kalyani 741235, W Bengal, India.
EM hafi786@gmail.com
RI sureshkumar, venkatasamy/AAC-1245-2019; Ruhul Amin, Md./KRP-9631-2024;
   Mishra, Dheerendra/C-4208-2017; Pandi, Vijayakumar/Y-4636-2019; Islam,
   SK Hafizul/K-5724-2017
OI sureshkumar, venkatasamy/0000-0003-0691-0905; Mishra,
   Dheerendra/0000-0001-8115-6397; Pandi, Vijayakumar/0000-0001-5451-8946; 
CR Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   Amin R, 2016, COMPUT NETW, V101, P42, DOI 10.1016/j.comnet.2016.01.006
   Amin R, 2016, AD HOC NETW, V36, P58, DOI 10.1016/j.adhoc.2015.05.020
   [Anonymous], 2013, P INT S WIR PERV COM
   Anwar S, 2017, ALGORITHMS, V10, DOI 10.3390/a10020039
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chang V, 2016, FUTURE GENER COMP SY, V57, P24, DOI 10.1016/j.future.2015.09.031
   Chang V, 2015, AD HOC NETW, V35, P65, DOI 10.1016/j.adhoc.2015.07.012
   Chen TH, 2010, ETRI J, V32, P704, DOI 10.4218/etrij.10.1510.0134
   Choi Y, 2014, SENSORS-BASEL, V14, P10081, DOI 10.3390/s140610081
   Das AK, 2012, J NETW COMPUT APPL, V35, P1646, DOI 10.1016/j.jnca.2012.03.011
   Das ML, 2009, IEEE T WIREL COMMUN, V8, P1086, DOI 10.1109/TWC.2008.080128
   Doshi N, 2017, MULTIMED TOOLS APPL, V76, P25893, DOI 10.1007/s11042-017-4701-2
   Farash MS, 2016, AD HOC NETW, V36, P152, DOI 10.1016/j.adhoc.2015.05.014
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Hamid Z, 2016, MULTIMED TOOLS APPL, V75, P8195, DOI 10.1007/s11042-015-2737-8
   Han K, 2015, MULTIMED TOOLS APPL, V74, P1541, DOI 10.1007/s11042-013-1520-y
   Han W, 2011, IACR CRYPTOLOGY EPRI, V2011, P293
   He DB, 2015, MULTIMEDIA SYST, V21, P49, DOI 10.1007/s00530-013-0346-9
   He LJ, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0196-4
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Jiang Q, 2015, PEER PEER NETW APPL, V8, P1070, DOI 10.1007/s12083-014-0285-z
   Khan MK, 2010, SENSORS-BASEL, V10, P2450, DOI 10.3390/s100302450
   Kim J, 2014, SENSORS-BASEL, V14, P6443, DOI 10.3390/s140406443
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kumar P, 2012, SENSORS-BASEL, V12, P1625, DOI 10.3390/s120201625
   Kumari S, 2016, COMPUT NETW, V104, P137, DOI 10.1016/j.comnet.2016.05.007
   Li CT, 2013, SENSORS-BASEL, V13, P9589, DOI 10.3390/s130809589
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Nam J, 2015, PLOS ONE, V10
   Shi W, 2013, INT J DISTRIB SENSOR
   Song RG, 2010, COMPUT STAND INTER, V32, P321, DOI 10.1016/j.csi.2010.03.008
   Sun G, 2017, J NETW COMPUT APPL, V89, P3, DOI 10.1016/j.jnca.2016.10.011
   Tseng HR, 2007, GLOB TELECOMM CONF, P986
   Turkanovic M, 2013, ELEKTRON ELEKTROTECH, V19, P109, DOI 10.5755/j01.eee.19.6.2038
   Turkanovic M, 2014, WIRELESS PERS COMMUN, V77, P907, DOI 10.1007/s11277-013-1543-8
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Vaidya B., 2012, SECUR COMMUN NETW
   Vaidya B, 2010, IEEE CONF WIREL MOB, P600, DOI 10.1109/WIMOB.2010.5645004
   Wang D, 2014, COMPUT NETW, V73, P41, DOI 10.1016/j.comnet.2014.07.010
   Wang D, 2014, AD HOC NETW, V20, P1, DOI 10.1016/j.adhoc.2014.03.003
   Wang ZW, 2017, J COMPUT SYST SCI, V89, P41, DOI 10.1016/j.jcss.2016.12.006
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Xu S., 2013, Int Rev Comput Softw, V8, P197
   Xue KP, 2013, J NETW COMPUT APPL, V36, P316, DOI 10.1016/j.jnca.2012.05.010
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yeh HL, 2011, SENSORS-BASEL, V11, P4767, DOI 10.3390/s110504767
   Zhang YH, 2012, PROCEDIA ENGINEER, V43, P233, DOI 10.1016/j.proeng.2012.08.040
NR 48
TC 67
Z9 68
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18295
EP 18325
DI 10.1007/s11042-017-5376-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900039
DA 2024-07-18
ER

PT J
AU Tian, T
   Gao, L
   Song, WJ
   Choo, KKR
   He, JJ
AF Tian, Tian
   Gao, Lang
   Song, Weijing
   Choo, Kim-Kwang Raymond
   He, Jijun
TI Feature extraction and classification of VHR images with attribute
   profiles and convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Image classification; Attribute profiles; Convolutional
   neural networks; Support vector machine
ID SPECTRAL-SPATIAL CLASSIFICATION; HYPERSPECTRAL DATA; INFORMATION
AB Effective feature extraction plays an important role in the classification of very high resolution (VHR) remote sensing (RS) images. Current researches mainly focus on individual shallow or deep feature extraction methods, remarkable representatives of which include Morphological Attribute Profiles (APs) and Convolutional Neural Networks (CNNs). Actually, to combine low-level and high-level features may take advantages of each approach and fully exploit the description capability. In this paper, APs and CNNs are integrated to characterize VHR RS images in order to improve the pixel description. Moreover, during the training of CNNs, regularization, dropout and fine-tuning strategies are all utilized to mitigate over-fitting problems due to insufficient samples in RS applications. Evaluations using QuickBird datasets demonstrate that our proposed method leads to a higher classification accuracy compared to individual method for VHR images.
C1 [Tian, Tian; Gao, Lang; Song, Weijing] China Univ Geosci, Sch Comp Sci, Hubei Key Lab Intelligent Geoinformat Proc, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
   [He, Jijun] Capital Normal Univ, Base State Lab Urban Environm Proc & Digital Mode, Key Lab Resources Environm & GIS Beijing, Beijing 100048, Peoples R China.
C3 China University of Geosciences; University of Texas System; University
   of Texas at San Antonio (UTSA); Capital Normal University
RP He, JJ (corresponding author), Capital Normal Univ, Base State Lab Urban Environm Proc & Digital Mode, Key Lab Resources Environm & GIS Beijing, Beijing 100048, Peoples R China.
EM tiantian@cug.edu.cn; raymond.choo@fulbrightmail.org;
   hejiun_200018@163.com
RI Choo, Kim-Kwang Raymond/A-3634-2009; Tian, Tian/AAO-6980-2021
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; 
FU National Natural Science Foundation [41701417]; China Postdoctoral
   Science Foundation [2016M602390]; Provincial Natural Science Foundation
   of Hubei [2016CFB278]; Open Research Project of Hubei Key Laboratory of
   Intelligent Geo-Information Processing [KLIGIP1608]; fundamental
   Research Funds for the Central Universities, China University of
   Geosciences (Wuhan)
FX We would like to thank Prof. Yun Zhang, Prof. Hengjian Tong and CFB
   Gagetown for providing the QuickBird images, and thank Prof. Mauro Dalla
   Mura for kindly sharing the implementation of attribute profiles. We
   also want to thank all the anonymous reviewers who provided constructive
   comments to help us improve the quality of this manuscript. And this
   work is supported by the National Natural Science Foundation under Grant
   41701417, China Postdoctoral Science Foundation under Grant 2016M602390,
   the Provincial Natural Science Foundation of Hubei under Grant
   2016CFB278, the Open Research Project of Hubei Key Laboratory of
   Intelligent Geo-Information Processing (KLIGIP1608), and the fundamental
   Research Funds for the Central Universities, China University of
   Geosciences (Wuhan).
CR Akçay HG, 2008, IEEE T GEOSCI REMOTE, V46, P2097, DOI 10.1109/TGRS.2008.916644
   [Anonymous], 2017, P JOINT URB REM SENS
   Aptoula E, 2016, IEEE GEOSCI REMOTE S, V13, P1970, DOI 10.1109/LGRS.2016.2619354
   Aptoula E, 2016, IEEE T GEOSCI REMOTE, V54, P3208, DOI 10.1109/TGRS.2015.2513424
   Bellens R, 2008, IEEE T GEOSCI REMOTE, V46, P2803, DOI 10.1109/TGRS.2008.2000628
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Benediktsson JA, 2003, IEEE T GEOSCI REMOTE, V41, P1940, DOI 10.1109/TGRS.2003.814625
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Dou MG, 2014, FUTURE GENER COMP SY, V37, P367, DOI 10.1016/j.future.2013.12.018
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Fan C, 2016, MULTIMED TOOLS APPL, V75, P12201, DOI 10.1007/s11042-015-3004-8
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1537, DOI 10.1109/LGRS.2016.2595108
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P5771, DOI 10.1109/TGRS.2013.2292544
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong X, 2014, NEUROCOMPUTING, V133, P25, DOI 10.1016/j.neucom.2013.11.035
   Huang X, 2007, IEEE GEOSCI REMOTE S, V4, P654, DOI 10.1109/LGRS.2007.905121
   Huang X, 2007, IEEE GEOSCI REMOTE S, V4, P260, DOI 10.1109/LGRS.2006.890540
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Jiang JJ, 2017, IEEE GEOSCI REMOTE S, V14, P404, DOI 10.1109/LGRS.2016.2645708
   Li X, 2015, J AMB INTEL HUM COMP, V6, P141, DOI 10.1007/s12652-015-0255-1
   Lu HY, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060499
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma XR, 2016, IEEE J-STARS, V9, P4073, DOI 10.1109/JSTARS.2016.2517204
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Ma Y, 2015, INFORM SCIENCES, V319, P171, DOI 10.1016/j.ins.2014.10.006
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   Soille P, 2002, IEEE T GEOSCI REMOTE, V40, P2042, DOI 10.1109/TGRS.2002.804618
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Wang LZ, 2017, SOFT COMPUT, V21, P213, DOI 10.1007/s00500-016-2246-3
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Wang LZ, 2015, KNOWL-BASED SYST, V79, P43, DOI 10.1016/j.knosys.2014.10.004
   Wei JB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010021
   Wei JB, 2016, IEEE GEOSCI REMOTE S, V13, P1557, DOI 10.1109/LGRS.2016.2595863
   Zhang LP, 2006, IEEE T GEOSCI REMOTE, V44, P2950, DOI 10.1109/TGRS.2006.876704
   Zhang Q, 2016, IEEE GEOSCI REMOTE S, V13, P1388, DOI 10.1109/LGRS.2016.2590481
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P4141, DOI 10.1109/TGRS.2017.2689018
   Zhao WZ, 2015, INT J REMOTE SENS, V36, P3368, DOI 10.1080/2150704X.2015.1062157
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
   Zhou XC, 2017, IEEE GEOSCI REMOTE S, V14, P97, DOI 10.1109/LGRS.2016.2630045
   Zhu CQ, 1998, INT J REMOTE SENS, V19, P3197, DOI 10.1080/014311698214262
NR 46
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18637
EP 18656
DI 10.1007/s11042-017-5331-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900054
DA 2024-07-18
ER

PT J
AU Varatharajan, R
   Preethi, AP
   Manogaran, G
   Kumar, PM
   Sundarasekar, R
AF Varatharajan, R.
   Preethi, Angelin Peace
   Manogaran, Gunasekaran
   Kumar, Priyan Malarvizhi
   Sundarasekar, Revathi
TI Stealthy attack detection in multi-channel multi-radio wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stealthy attack; Multi-channel multi-radio wireless network; Cumulative
   sum; Bootstrap analysis; Binary segmentation pruned exact linear time;
   Segment neighborhood
ID INTRUSION DETECTION; SYSTEM; AUTHENTICATION; SURVEILLANCE; INTERNET;
   SCHEME
AB In recent years, the lack of network traffic analysis and flexible network topologies reduce the performance of the multi-channel multi-radio wireless networks. As high scalability of its participants and routing structure, multicast communication of wireless networks is vulnerable to stealthy attacks. Stealthy packet dropping disrupts the packet from reaching the destination through malicious behavior at an intermediate node. A network table is maintained in each hop to transfer the data packet from source to destination. The main contribution of this paper is to use that network table to monitor the drastic changes incoming packet as well as an outgoing packet. More specifically, we have proposed Cumulative Sum algorithm (CuSum) with bootstrap analysis method to monitor the changes in the network packet transmission. We have used NS-2 network simulator to simulate the proposed CUSUM algorithm with a bootstrap method is compared with various other existing change detection methods such as such as Binary Segmentation (BinSeg), Pruned Exact Linear Time (PELT) and Segment Neighborhood (SegNeigh) method. The simulation results proved the efficiency of the proposed CuSum with bootstrap analysis method.
C1 [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
   [Preethi, Angelin Peace; Sundarasekar, Revathi] Anna Univ, Chennai, Tamil Nadu, India.
   [Manogaran, Gunasekaran] Univ Calif Davis, Davis, CA 95616 USA.
   [Kumar, Priyan Malarvizhi] VIT Univ, Vellore, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; University of California
   System; University of California Davis; Vellore Institute of Technology
   (VIT); VIT Vellore
RP Varatharajan, R (corresponding author), Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
EM varathu21@yahoo.com; gunavit@gmail.com; priyanit085@gmail.com;
   revathisundar161@gmail.com
RI KUMAR, PRIYAN MALARVIZHI/GYV-1373-2022; MALARVIZHI KUMAR,
   PRIYAN/U-3908-2018; Manogaran, Gunasekaran/K-7621-2017
OI MALARVIZHI KUMAR, PRIYAN/0000-0001-6149-2705; Manogaran,
   Gunasekaran/0000-0003-4083-6163
CR Anantvalee T, 2007, SIGNALS COMMUN TECHN, P159, DOI 10.1007/978-0-387-33112-6_7
   [Anonymous], INFORM SCI
   [Anonymous], WIRELESS PERSONAL CO
   [Anonymous], ANN TELECOMMUNICATIO
   [Anonymous], IEEE COMMUNICATIONS
   [Anonymous], 2009, IEEE COMMUNICATIONS
   [Anonymous], 2009, IEEE INT C MANAGEMEN, DOI DOI 10.1109/IWQ0S.2009.5201403
   [Anonymous], IEEE WIRELESS COMMUN
   [Anonymous], 2014, SECURITY ISSUES MOBI
   [Anonymous], 2017, INFORM SECURITY HIGH
   [Anonymous], 2017, WIRELESS NETWORKS
   [Anonymous], 2018, WIRELESS PERS COMMUN
   [Anonymous], ARXIV PREPRINT ARXIV
   [Anonymous], IEEE WIRELESS COMMUN
   Arthur MP, 2015, ETRI J, V37, P1108, DOI 10.4218/etrij.15.0114.1011
   Bishop M., 2003, IEEE Security & Privacy, V1, P67, DOI 10.1109/MSECP.2003.1176998
   Buchegger S, 2005, IEEE COMMUN MAG, V43, P101, DOI 10.1109/MCOM.2005.1470831
   Chhaya L, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6010005
   Devi R, 2017, AEU-INT J ELECTRON C, V74, P94, DOI 10.1016/j.aeue.2017.01.025
   Gandhi UD, 2018, WIRELESS PERS COMMUN, V103, P1179, DOI 10.1007/s11277-018-5307-3
   Jow J, 2017, INT J SENS NETW, V23, P170, DOI 10.1504/IJSNET.2017.083410
   Khalil I, 2011, IEEE T MOBILE COMPUT, V10, P1096, DOI 10.1109/TMC.2010.249
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Latha P, 2016, 2016 Second International Conference on Science Technology Engineering and Management (ICONSTEM), P172, DOI 10.1109/ICONSTEM.2016.7560945
   Leu FY, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 2, PROCEEDINGS, P251, DOI 10.1109/IAS.2009.294
   Li WJ, 2017, J NETW COMPUT APPL, V77, P135, DOI 10.1016/j.jnca.2016.09.014
   Li X, 2018, J NETW COMPUT APPL, V103, P194, DOI 10.1016/j.jnca.2017.07.001
   Li X, 2018, FUTURE GENER COMP SY, V83, P607, DOI 10.1016/j.future.2017.04.012
   Li X, 2017, COMPUT NETW, V129, P429, DOI 10.1016/j.comnet.2017.03.013
   Lijun Qian, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P1026, DOI 10.1109/ICCNC.2013.6504232
   Lopez D, 2016, INT J INFECT DIS, V45, P23, DOI 10.1016/j.ijid.2016.02.084
   Lopez D, 2017, BIOMED RES, V28, P1
   Lopez D, 2016, HUMAN ELEMENT BIG DA
   Lopez D, 2017, HDB STAT, V37, P301, DOI DOI 10.1590/S0034-76122011000200003
   Lopez D, 2015, ADV INTELL SYST, V415, P195, DOI 10.1007/978-3-319-27212-2_16
   Lopez Daphne, 2014, Proc IEEE Int Conf Big Data, V2014, P19, DOI 10.1109/BigData.2014.7004422
   Manickam A, 2019, MULTIMED TOOLS APPL, V78, P3065, DOI 10.1007/s11042-018-5633-1
   Manogaran G., 2016, INT J ADV INTELLIGEN, V9, P1
   Manogaran G, 2017, COMPUTERS ELECT ENG
   Manogaran G, 2018, HCI CHALLENGES PRIVA, P1
   Manogaran G, 2017, Cluster Comput, P1
   Manogaran G, 2017, FUTURE GENERATION CO
   Manogaran G., 2017, Big Data Analytics in Healthcare Internet of Things. Innovative Healthcare Systems for the 21st Century, P263, DOI DOI 10.1007/978-3-319-55774-8_10
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Manogaran G, 2017, INT J AMBIENT COMPUT, V8, P88, DOI 10.4018/IJACI.2017040106
   Marchang N, 2017, IEEE T VEH TECHNOL, V66, P1684, DOI 10.1109/TVT.2016.2557808
   Mishra A, 2004, IEEE WIREL COMMUN, V11, P48, DOI 10.1109/MWC.2004.1269717
   Singh R, 2017, WIREL TELECOMM SYMP
   Suresh A., 2019, Cluster Computing, V22, P11039, DOI 10.1007/s10586-017-1293-6
   Thota C., 2018, Exploring the convergence of big data and the internet of things, P141
   Van Phuong T, 2006, LECT NOTES COMPUT SC, V3975, P735
   Varatharajan R., 2018, Cluster Computing, V21, P681, DOI 10.1007/s10586-017-0977-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Varatharajan R, 2017, COMPUTERS ELECT ENG
   Verma D. K., 2017, International Journal of Applied Engineering Research, V12, P1956
   Wu B, 2007, SIGNALS COMMUN TECHN, P103, DOI 10.1007/978-0-387-33112-6_5
   Yang Y, 2018, FUTURE GENER COMP SY, V84, P160, DOI 10.1016/j.future.2017.06.025
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
NR 61
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18503
EP 18526
DI 10.1007/s11042-018-5866-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900046
DA 2024-07-18
ER

PT J
AU Becerra, A
   de la Rosa, J
   González, E
AF Becerra, Aldonso
   Ismael de la Rosa, J.
   Gonzalez, Efren
TI Speech recognition in a dialog system: from conventional to deep
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Neural networks; Gaussian mixture models; Hidden
   Markov models; Deep learning; Spoken dialog system
ID HIDDEN MARKOV-MODELS; NEURAL-NETWORKS; MIXTURE OBSERVATIONS;
   MAXIMUM-LIKELIHOOD; REPRESENTATIONS; ALGORITHM; GMM
AB The aim of this paper is to illustrate an overview of the automatic speech recognition (ASR) module in a spoken dialog system and how it has evolved from the conventional GMM-HMM (Gaussian mixture model - hidden Markov model) architecture toward the recent nonlinear DNN-HMM (deep neural network) scheme. GMMs have dominated for a long time the baseline of speech recognition, but in the past years with the resurgence of artificial neural networks (ANNs), the former models have been surpassed in most recognition tasks. An outstanding consideration for ANNs-based acoustic model is the fact that their weights can be adjusted in two training steps: i) initialization of the weights (with or without pre-training) and ii) fine-tuning. To exemplify these frameworks, a case study is realized by using the Kaldi toolkit, employing a mid-vocabulary with a personalized speaker-independent voice corpus on a connected-words phone dialing environment operated for recognition of digit strings and personal name lists in Spanish from Mexico. The obtained results show a reasonable accuracy in the speech recognition performance through the DNN acoustic modeling. A word error rate (WER) of 1.49% for context-dependent DNN-HMM is achieved, providing a 30% relative improvement with regard to the best GMM-HMM result in these experiments (2.12% WER).
C1 [Becerra, Aldonso; Ismael de la Rosa, J.; Gonzalez, Efren] Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Ave Lopez Velarde 801, Zacatecas 98068, Mexico.
C3 Universidad Autonoma de Zacatecas
RP Becerra, A (corresponding author), Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Ave Lopez Velarde 801, Zacatecas 98068, Mexico.
EM a7donso@uaz.edu.mx; ismaelrv@ieee.org; gonzalez_efren@hotmail.com
RI De la Rosa, José Ismael/N-7394-2019
OI De la Rosa, José Ismael/0000-0002-7337-8974; GONZALEZ-RAMIREZ,
   EFREN/0000-0002-8060-6170; Becerra, Aldonso/0000-0002-4274-4396
FU Universidad Autonoma de Zacatecas (UAZ); CONACyT
FX The first author acknowledge all support given by the Universidad
   Autonoma de Zacatecas (UAZ) during the years 2014-2017 to realize his
   PhD academic formation. Additional acknowledgements for the support
   given by CONACyT during his stay of postgraduate studies.
CR Ali A, 2014, IEEE W SP LANG TECH, P525, DOI 10.1109/SLT.2014.7078629
   [Anonymous], 2009, NIPS WORKSH DEEP LEA
   [Anonymous], DISCRIMINATIVE PRETR
   [Anonymous], 2006, The HTK book (for HTK version 3.4) [Computer software manual]
   [Anonymous], 2009, International Journal of Computer Science and Information Security, DOI DOI 10.1109/PROC.1976.10158
   [Anonymous], 2011, P INT C FLOR IT 27 3, DOI DOI 10.5555/3042573.3042574
   [Anonymous], 2014, P IEEE INT C AC SPEE
   Bacchiani M, 2014, P INTERSPEECH, P1900
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bilmes JA, 2006, IEICE T INF SYST, VE89D, P869, DOI 10.1093/ietisy/e89-d.3.869
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cai M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P291, DOI 10.1109/ASRU.2013.6707745
   Chen X, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P26
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Dahl GE, 2011, INT CONF ACOUST SPEE, P4688
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DENG L, 1991, IEEE T SIGNAL PROCES, V39, P1677, DOI 10.1109/78.134406
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Deng L, 2013, IEEE T AUDIO SPEECH, V21, P1060, DOI 10.1109/TASL.2013.2244083
   Deng L, 2012, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2012.6288333
   Deng L, 2013, IEEE INT NEW CIRC
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   Gose E., 1996, PATTERN RECOGNITION
   Gupta S., 2013, SIGNAL IMAGE PROCESS, V4, P101, DOI [DOI 10.5121/SIPIJ.2013.4408, 10.5121/sipij.2013.4408]
   Heigold G, 2013, IEEE T AUDIO SPEECH, V21, P2616, DOI 10.1109/TASL.2013.2280234
   Heigold G, 2012, IEEE SIGNAL PROC MAG, V29, P58, DOI 10.1109/MSP.2012.2197232
   Hen Hu Y, 2002, HDB NEURAL NETWORKS
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton G. E., 2012, 12070580 ARXIV
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang Y, 2014, INTERSPEECH, P845
   Huang Z, 2014, INTERSPEECH, P1214
   Jaitly N, 2014, THESIS
   Jaitly N, 2013, INTERSPEECH, P1736
   Jaitly Navdeep, 2012, APPL PRETRAINED DEEP
   Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002
   JUANG BH, 1986, IEEE T INFORM THEORY, V32, P307, DOI 10.1109/TIT.1986.1057145
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kaur K., 2015, INT J ADV RES COMPUT, V5, P1
   Li JY, 2012, IEEE W SP LANG TECH, P131, DOI 10.1109/SLT.2012.6424210
   Li XG, 2015, NEUROCOMPUTING, V170, P251, DOI 10.1016/j.neucom.2014.07.087
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Macho D, 2002, P INT C SPOKEN LANGU, P16
   McLachlan G., 1988, MIXTURE MODELS
   Miao YJ, 2013, INTERSPEECH, P2236
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Morgan N., 1995, IEEE Signal Processing Magazine, V12, P24, DOI 10.1109/79.382443
   Nakagawa S, 2006, IEICE T INF SYST, VE89D, P1058, DOI 10.1093/ietisy/e89-d.3.1058
   Niu J, 2013, ASIAPAC SIGN INFO PR
   Noguchi H, 2011, IEICE T ELECTRON, VE94C, P458, DOI 10.1587/transele.E94.C.458
   Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301, DOI 10.1109/ISCSLP.2012.6423452
   PICONE JW, 1993, P IEEE, V81, P1215, DOI 10.1109/5.237532
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Povey D, 2011, COMPUT SPEECH LANG, V25, P404, DOI 10.1016/j.csl.2010.06.003
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rabiner LR, 2007, FOUND TRENDS SIGNAL, V1, P1, DOI 10.1561/2000000001
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rath SP, 2013, INTERSPEECH, P109
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sainath T. N., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P30, DOI 10.1109/ASRU.2011.6163900
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sainath TN, 2012, P NEUR INF PROC SYST
   Saon G, 2012, ASIAPAC SIGN INFO PR
   Saon G, 2012, IEEE SIGNAL PROC MAG, V29, P18, DOI 10.1109/MSP.2012.2197156
   Scowen R. S., 1993, Proceedings 1993 Software Engineering Standards Symposium (Cat. No.93TH0568-6), P25, DOI 10.1109/SESS.1993.263968
   Seide F., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P24, DOI 10.1109/ASRU.2011.6163899
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Sharma S, 2000, INT CONF ACOUST SPEE, P1117
   Siniscalchi SM, 2013, NEUROCOMPUTING, V106, P148, DOI 10.1016/j.neucom.2012.11.008
   Stahlberg Felix, 2014, P 4 INT WORKSH SPOK, P73
   Strik H., 1997, International Journal of Speech Technology, V2, P121, DOI 10.1007/BF02208824
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Trentin E, 2001, NEUROCOMPUTING, V37, P91, DOI 10.1016/S0925-2312(00)00308-8
   Vesely K, 2013, INTERSPEECH, P2344
   Vesely K, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P267, DOI 10.1109/ASRU.2013.6707741
   Wang G H, 2014, THESIS
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Xu Y, 2014, IEEE SIGNAL PROCESS, V21, P1070
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yao KS, 2012, IEEE W SP LANG TECH, P366, DOI 10.1109/SLT.2012.6424251
   Young S, 1996, IEEE SIGNAL PROC MAG, V13, P45, DOI 10.1109/79.536824
   Young S., 2008, Springer Handbook of Speech Processing, P539, DOI DOI 10.1007/978-3-540-49127-9_27
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yu D., 2010, P NIPS WORKSH DEEP L
   Zhang C., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5597, DOI 10.1109/ICASSP.2014.6854674
   Zhang S, 2014, P INT C AC SPEECH SI, P6899
NR 98
TC 9
Z9 10
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15875
EP 15911
DI 10.1007/s11042-017-5160-5
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200062
DA 2024-07-18
ER

PT J
AU Jallouli, O
   El Assad, S
   Chetto, M
   Lozi, R
AF Jallouli, Ons
   El Assad, Safwan
   Chetto, Maryline
   Lozi, Rene
TI Design and analysis of two stream ciphers based on chaotic coupling and
   multiplexing techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos-based cryptography; Stream cipher; Pseudo-chaotic number
   generator; Discrete chaotic maps; Coupling and multiplexing techniques
AB In this paper, we design and implement two new stream ciphers based on Pseudo Chaotic Number Generators (PCNGs) which integrate discrete chaotic maps, namely, Piecewise Linear Chaotic Map (PWLCM), Skewtent and Logistic map. They are weakly coupled by a predefined matrix A for the first PCNG and they are coupled by a binary diffusion matrix D for the second one. Each PCNG includes a chaotic multiplexing technique that allows the enhancement of the robustness of the system. The structure is implemented with finite precision N = 32 bits in C language. Security performance of the proposed stream ciphers is analysed and several cryptanalytic and statistical tests are applied. Experimental results highlight robustness as well as efficiency in terms of computation time of these two stream ciphers.
C1 [Jallouli, Ons; El Assad, Safwan] CNRS, UMR 6164, IETR, Polytech Nantes Rue Christian Pauc, F-44306 Nantes, France.
   [Chetto, Maryline] Ecole Cent Nantes, IRCCyN, 1 Rue Noe, F-44321 Nantes, France.
   [Lozi, Rene] Univ Cote Azur, CNRS, UMR 7351, Lab JA Dieudonne, Nice 02, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Nantes Universite; Ecole
   Centrale de Nantes; Universite Cote d'Azur; Centre National de la
   Recherche Scientifique (CNRS)
RP Jallouli, O (corresponding author), CNRS, UMR 6164, IETR, Polytech Nantes Rue Christian Pauc, F-44306 Nantes, France.
EM ons.jallouli@univ-nantes.fr
RI Lozi, René P/N-9303-2013; Lozi, René/Y-7474-2019
OI Lozi, René/0000-0003-0451-4255; chetto, maryline/0000-0003-1118-2279;
   jallouli, ons/0000-0001-5198-5813
CR Ahmed HEdH, 2007, INFORMATICA, V31
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Amato P, 2006, US Patent App, Patent No. [11/381:474, 11381474]
   [Anonymous], 2014, CRYPTOGRAPHY NETWORK
   [Anonymous], STREAM CIPHERS
   Arlicot A, 2014, TECH REP IETR
   Barkan E, 2003, LECT NOTES COMPUT SC, V2729, P600
   Bougouin M, 2015, TECH REP
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Ekdahl P., 2000, P 1 OP NESSIE WORKSH, P167
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Elaine B, 2012, TECH REP
   Farajallah M, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500218
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Jallouli O, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1340, DOI 10.1109/ICACCI.2016.7732234
   Klein A, 2008, DESIGN CODE CRYPTOGR, V48, P269, DOI 10.1007/s10623-008-9206-6
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Lozi R, 2012, INT J BIFURCAT CHAOS, V22, DOI 10.1142/S0218127412500216
   Lozi R., 2007, INDIAN J IND APPL MA, V1, P1
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Manifavas C, 2015, SURVEY LIGHTWEIGHT S
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Petersen MV, 2007, US Patent, Patent No. [7,170,997, 7170997]
   Robshaw M, 2008, LECT NOTES COMPUT SC, V4986, P1
   Rogaway P, 1998, J CRYPTOL, V11, P273, DOI 10.1007/s001459900048
   Rukhin AL, 2008, TECH REP
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Taralova I, 2012, INT CONF INTERNET, P56
   Vidal G, 2014, EUR PHYS J-SPEC TOP, V223, P1601, DOI 10.1140/epjst/e2014-02185-y
   Wang Y, 2016, NONLINEAR DYNAM, V83, P2373, DOI 10.1007/s11071-015-2488-0
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
NR 36
TC 23
Z9 23
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13391
EP 13417
DI 10.1007/s11042-017-4953-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900015
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Wang, Y
   Wang, DH
   Li, YM
AF Zhang, Xufan
   Wang, Yong
   Wang, Dianhong
   Li, Yamin
TI Adaptive image compression based on compressive sensing for video sensor
   nodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless video sensor networks; compressive sensing; image
   communication; image quality control
ID SIGNAL RECOVERY; TRANSMISSION
AB Monitoring applications based on wireless video sensor networks are becoming highly attractive. However, due to constrained resources such as energy budget, communication bandwidth and computing ability, it is imperative for video sensor nodes to compress images before transmission via wireless networks. In this paper, we propose a novel image compression scheme based on compressive sensing, which has low complexity and good compression performance. The image quality can be adaptively adjusted by the residual energy of sensor nodes and the link quality of network. Furthermore, the image compression algorithm has been validated on the actual hardware platforms. The experimental results show that the proposed scheme is suitable for resource-constrained video sensor nodes, and is feasible for the practical application.
C1 [Zhang, Xufan; Wang, Yong; Wang, Dianhong; Li, Yamin] China Univ Geosci, Fac Mech & Elect Informat, Wuhan 430074, Hubei, Peoples R China.
C3 China University of Geosciences
RP Wang, Y (corresponding author), China Univ Geosci, Fac Mech & Elect Informat, Wuhan 430074, Hubei, Peoples R China.
EM wy112708@163.com
FU Natural Science Foundation of China [41202232, 61271274]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 41202232 and 61271274.
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   [Anonymous], P IASTED INT C INT M
   Baccour N, 2010, LECT NOTES COMPUT SC, V5970, P240, DOI 10.1007/978-3-642-11917-0_16
   Boano C. A., 2010, PROC 19 INT C COMPUT, P1
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duran-Faundez C, 2011, SIGNAL PROCESS-IMAGE, V26, P466, DOI 10.1016/j.image.2011.07.005
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   He ZH, 2006, IEEE T CIRC SYST VID, V16, P590, DOI 10.1109/TCSVT.2006.873154
   Lee DU, 2009, IEEE T IMAGE PROCESS, V18, P2100, DOI 10.1109/TIP.2009.2022438
   Pekhteryev G, 2005, IEEE INT SYMP CIRC S, P3539, DOI 10.1109/ISCAS.2005.1465393
   Pudlewski S, 2013, IEEE COMMUN SURV TUT, V15, P754, DOI 10.1109/SURV.2012.121912.00154
   Qureshi MA, 2016, MULTIMED TOOLS APPL, V75, P6737, DOI 10.1007/s11042-015-2590-9
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Srinivasan K., 2006, P 3 WORKSHOP EMBEDDE
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 2016, IEEE SENS J, V16, P3875, DOI 10.1109/JSEN.2016.2536941
   Yang Yang, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5303161
   Yian Qin, 2011, 2011 The 10th IFIP Annual Mediterranean Ad Hoc Networking Workshop (Med-Hoc-Net 2011), P179, DOI 10.1109/Med-Hoc-Net.2011.5970486
   Zhang J, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P941, DOI 10.1109/IWECA.2014.6845776
   Zhu SY, 2015, J VIS COMMUN IMAGE R, V30, P94, DOI 10.1016/j.jvcir.2015.03.006
NR 30
TC 5
Z9 5
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13679
EP 13699
DI 10.1007/s11042-017-4981-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900028
DA 2024-07-18
ER

PT J
AU Zhao, MH
   Zhang, X
   Shi, ZH
   Chen, T
   Zhang, FF
AF Zhao, Minghua
   Zhang, Xin
   Shi, Zhenghao
   Chen, Tang
   Zhang, Feifei
TI Eyeglasses detection, location and frame discriminant based on edge
   information projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eyeglasses detection; Eyeglasses location; Frame discriminant; Edge
   information projection; Face recognition
ID REMOVAL
AB Eyeglasses have a significant effect on the accuracy of face feature extraction and face recognition. In order to improve the performance of face feature extraction and face recognition, a method that achieves eyeglasses detection, location and frame discriminant, based on edge information is proposed in this paper. First, the horizontal nose bridge area is determined by the location of the mouth, and the vertical nose bridge area is determined by the edge information projection method. Next, the spectacle beam is searched in the nose bridge area to determine the existence of eyeglasses. Subsequently, the eyeglasses areas are located according to the bidirectional edge information projection method and the existence of frames is determined. Finally, the frame width of the eyeglasses is measured based on the location of the left and the right glasses. Experimental results show that detection rate of eyeglasses using the proposed method is higher than the traditional methods and it can make a distinction between rimmed and rimless eyeglasses accurately. In addition, the proposed method can locate the eyeglasses areas and measure the frame width effectively.
C1 [Zhao, Minghua; Zhang, Xin; Shi, Zhenghao; Chen, Tang; Zhang, Feifei] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Zhao, MH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
EM mh_zhao@126.com
RI Zhang, Feifei/A-3199-2015
FU National Natural Science Foundation of China [61401355, 61502382,
   61472319]; Key Laboratory Foundation of Shaanxi Education Department,
   China [14JS072]; Science and Technology Project Foundation of Beilin
   District, Xi'an City, China [GX1621]
FX This work was partially supported by a grant from the National Natural
   Science Foundation of China (No. 61401355, No. 61502382, No. 61472319),
   a grant from the Key Laboratory Foundation of Shaanxi Education
   Department, China (No. 14JS072) and a grant from Science and Technology
   Project Foundation of Beilin District, Xi'an City, China (No. GX1621).
   The authors also thank anonymous reviewers for their valuable comments.
CR Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   [陈文青 Chen Wenqing], 2016, [计算机工程与应用, Computer Engineering and Application], V52, P178
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan HC, 2014, INT J GEOGR INF SCI, V28, P700, DOI 10.1080/13658816.2013.867495
   Guo P., 2014, GLASSES REMOVAL REGI
   Hossain MF, 2012, INT J INNOV COMPUT I, V8, P1135
   Jiang X, 2000, PATTERN ANAL APPL, V3, P9, DOI 10.1007/s100440050002
   Li ZM, 2014, IND INSTRUMENTATION, V3, P51
   [刘仲民 Liu Zhongmin], 2014, [光学技术, Optical Technology], V40, P429
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Park JS, 2005, IEEE T PATTERN ANAL, V27, P805, DOI 10.1109/TPAMI.2005.103
   Pei G, 2014, IEEE I C NETW INFRAS, P359, DOI 10.1109/ICNIDC.2014.7000325
   Prema CE, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1229, DOI 10.1109/ICCPCT.2014.7054883
   Ren MG, 2014, SOFTWARE GUIDE, V13, P141
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang Li, 2008, Chinese Journal of Liquid Crystals and Displays, V23, P87
   Wang YK, 2010, P 6 INT C INT INF HI, P228
   Wu CY, 2004, IEEE T PATTERN ANAL, V26, P322, DOI 10.1109/TPAMI.2004.1262319
   Wu HY, 2002, INT C PATT RECOG, P346, DOI 10.1109/ICPR.2002.1048310
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yamauchi T, 2013, INT CONF AFFECT, P399, DOI 10.1109/ACII.2013.72
   Zhang XL, 2015, INT CONF SOFTW ENG, P587, DOI 10.1109/ICSESS.2015.7339126
   Zhong J, 2000, LECT NOTES COMPUT SC, V1948, P127
NR 25
TC 2
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14931
EP 14949
DI 10.1007/s11042-017-5080-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200022
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, SK
   Singh, AK
   Tiwari, S
   Singh, RS
AF Kumar, Santosh
   Singh, Sanjay Kumar
   Singh, Amit Kumar
   Tiwari, Shrikant
   Singh, Ravi Shankar
TI Privacy preserving security using biometrics in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Security; Privacy Preservation; Face recognition;
   Biometrics identification; Encrypted Biometrics; Elliptical encryption
ID FACE-RECOGNITION; IDENTIFICATION; ISSUES
AB Cloud computing and the efficient storage provide new paradigms and approaches designed at efficiently utilization of resources through computation and many alternatives to guarantee the privacy preservation of individual user. It also ensures the integrity of stored cloud data, and processing of stored data in the various data centers. However, to provide better protection and management of sensitive information (data) are big challenge to maintain the confidentiality and integrity of data in the cloud computation. Thus, there is an urgent need for storing and processing the data in the cloud environment without any information leakage. The sensitive data require the storing and processing mechanism and techniques to assurance the privacy preservation of individual user, to maintain the data integrity, and preserve confidentiality. Face recognition has recently achieved advancements in the unobtrusive recognition of individuals to maintain the privacy-preservation in the cloud computing. This paper emphasizes on cloud security and privacy issues and provides the solution using biometric face recognition. We propose a biometrics face recognition approach for security and privacy preservation of cloud users during their access to cloud resources. The proposed approach has three steps: (1) acquisition of face images (2) preprocessing and extraction of facial feature (3) recognition of individual using encrypted biometric feature. The experimental results establish that our proposed recognition approach can ensure the privacy and security of biometrics data.
C1 [Kumar, Santosh] IIIT Naya Raipur, CSE, Naya Raipur, Madhya Pradesh, India.
   [Singh, Sanjay Kumar; Singh, Ravi Shankar] Indian Inst Technol BHU, Dept Comp Sci & Engn, Varanasi, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
   [Tiwari, Shrikant] SSGI, Dept Comp Sci & Engn, Durg, Chattisgrah, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Jaypee University of
   Information Technology; Shri Shankaracharya Group of Institutions
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM santosh@iiitnr.edu.in; sks.cse@iitbhu.ac.in; amit_245singh@yahoo.com;
   shrikanttiwari15@gmail.com; ravi.cse@iitbhu.ac.in
RI Tiwari, Dr. Shrikant/I-3296-2017; Kumar, Sanjay/F-8509-2013; Kumar,
   Santosh/JVO-5600-2024; Singh, R S/H-6142-2019; Singh, Sanjay
   Prithviraj/IQV-1492-2023; Singh, Sanjay Kumar/AAC-2031-2022; kumar,
   Sanjay/ITT-3680-2023; Singh, Amit Kumar/D-1300-2015
OI Tiwari, Dr. Shrikant/0000-0001-6947-2362; Kumar,
   Sanjay/0000-0003-3659-5387; Singh, R S/0000-0001-6358-489X; Singh,
   Sanjay Prithviraj/0000-0001-5043-8762; Singh, Sanjay
   Kumar/0000-0002-9061-6313; Singh, Amit Kumar/0000-0001-7359-2068; Singh,
   Ravi Shankar/0000-0002-5394-7551; Kumar, Dr. Santosh/0000-0003-2264-9014
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ali M, 2015, INFORM SCIENCES, V305, P357, DOI 10.1016/j.ins.2015.01.025
   [Anonymous], 2014, INT J PHOTOENER, DOI DOI 10.1155/2014/513051
   Atawneh Samer, 2016, MULTIMED TOOLS APPL
   Barni M, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P231
   Bharadi VA, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P65, DOI 10.1109/ICCUBEA.2015.208
   Blanton M, 2011, LECT NOTES COMPUT SC, V6879, P190, DOI 10.1007/978-3-642-23822-2_11
   Bringer J., 2014, P ACM INF HID MULT S
   Bringer J, 2013, LECT NOTES COMPUT SC, V7862, P164, DOI 10.1007/978-3-642-41320-9_11
   Bringer J, 2011, SECUR COMMUN NETW, V4, P548, DOI 10.1002/sec.206
   Brinkworth IF., 2013, PRIMATES PATHOGENS E, P1
   Damgård I, 2001, LECT NOTES COMPUT SC, V1992, P119
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Fernandes DAB, 2014, INT J INF SECUR, V13, P113, DOI 10.1007/s10207-013-0208-7
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   Fu Z., IEEE T INFORM FORENS, P1
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Hankerson D., 2006, Guide to Elliptic Curve Cryptography, DOI DOI 10.1007/0-387-21846-73
   Jaber AN, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P179, DOI 10.1109/ICCSCE.2013.6719955
   Jain A K, 2011, Introduction to Biometrics
   Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jain P., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P456, DOI 10.1109/WICT.2011.6141288
   Jegede A, 2015, INT J SECUR APPL, V9, P149, DOI 10.14257/ijsia.2015.9.12.15
   Krbecek M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INTERACTIVE MOBILE COMMUNICATION TECHNOLOGIES AND LEARNING (IMCL), P1, DOI 10.1109/IMCTL.2016.7753759
   Li Jianzhong, 2017, MULTIMED TOOLS APPL
   Li J, 2017, IEEE SYST J, V11, P439, DOI 10.1109/JSYST.2015.2415835
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li P, 2016, SOFT COMPUT, V21, P1
   Martinez V.G., 2010, ratio, V80, P160
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Osadchy M, 2013, US Patent, Patent No. [8,542,886, 8542886]
   Pagnin E, 2014, LECT NOTES COMPUT SC, V8885, P265, DOI 10.1007/978-3-319-13039-2_16
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Philip J, 2016, PROCEDIA COMPUT SCI, V79, P410, DOI 10.1016/j.procs.2016.03.053
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Shu T, 2015, IEEE ACM T NETWORK, V23, P1688, DOI 10.1109/TNET.2015.2478881
   Sowmya R, 2015, INT J APPL INFORM CO, V1, P3
   Subashini S, 2011, J NETW COMPUT APPL, V34, P1, DOI 10.1016/j.jnca.2010.07.006
   Suryadevara S, 2011, INT C INF NETW TECHN, V4
   Takabi H, 2010, IEEE SECUR PRIV, V8, P24, DOI 10.1109/MSP.2010.186
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Victor GM, 2010, J COMPUT SCI ENG, V2, P7
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Q, 2015, LECT NOTES COMPUT SC, V9327, P186, DOI 10.1007/978-3-319-24177-7_10
   Wang W, 2015, COMPUT NETW, V88, P136, DOI 10.1016/j.comnet.2015.06.014
   Wang X, 2015, PROD LOGIST, P1, DOI 10.1007/978-3-658-06869-1
   Wang YJ, 2017, IEEE T INF FOREN SEC, V12, P1182, DOI 10.1109/TIFS.2017.2656461
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yu Y, 2017, IEEE T INF FOREN SEC, V12, P767, DOI 10.1109/TIFS.2016.2615853
   Yuan JW, 2013, IEEE INFOCOM SER, P2652
   Zhu YW, 2016, J PARALLEL DISTR COM, V89, P1, DOI 10.1016/j.jpdc.2015.11.004
   ZHU YW, 2016, PAC AS CONF KNOWL, V9652, P401, DOI DOI 10.1007/978-3-319-31750-2_32
NR 58
TC 40
Z9 47
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11017
EP 11039
DI 10.1007/s11042-017-4966-5
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900038
DA 2024-07-18
ER

PT J
AU Liu, Y
   Li, LF
   Liu, J
AF Liu, Yang
   Li, Linfeng
   Liu, Jun
TI Bilateral neural embedding for collaborative filtering-based multimedia
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural language model; Collaborative filtering; Recommender system;
   Multimedia representation learning
AB As one of the most popular and successfully applied recommendation methods, collaborative filtering aims to extract low-dimensional user and item representation from historic user-item interaction matrix. The similarity between the user and item representation vectors in the same space well measures the degree of interest and thus can be directly used for recommendation. This paper proposes to leverage the emerging deep neural language model to solve the collaborative filtering-based multimedia recommendation problem. By applying the standard Word2Vec model on the user-item interaction data, we can obtain the item embedding representation. Based on this, three strategies are introduced to derive the user embedded representation in the same space, which exploit both the user-item interaction and the correlation among items. Experiments on article recommendation application demonstrate that the proposed deep neural language models achieve superior performance than the traditional collaborative filtering methods based on matrix factorization and topic model.
C1 [Liu, Yang] Henan Univ Econ & Law, Cloud Comp & Big Data Inst, Zhengzhou 450046, Henan, Peoples R China.
   [Li, Linfeng] Henan Ind & Trade Coll, Dept Comp Sci & Technol, Zhengzhou 450003, Henan, Peoples R China.
   [Liu, Jun] Henan Univ Engn, Sch Comp Sci, Zhengzhou 451191, Henan, Peoples R China.
C3 Henan University of Economics & Law; Henan University of Engineering
RP Liu, Y (corresponding author), Henan Univ Econ & Law, Cloud Comp & Big Data Inst, Zhengzhou 450046, Henan, Peoples R China.
EM liuyang19801029@21cn.com; lilinfeng1971@21cn.com; liujun_hnue@21cn.com
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2007, NIPS
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Katarya R, 2016, MULTIMED TOOLS APPL, V75, P9225, DOI 10.1007/s11042-016-3481-4
   Levy O, 2014, ADV NEUR IN, V27
   Ma X, 2017, MULTIMED TOOLS APPL, P1
   McAuley Julian, 2013, RECSYS
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Sang JT, 2016, IEEE INT SYM MULTIM, P481, DOI 10.1109/ISM.2016.130
   Sang JT, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700468
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Song F, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P316, DOI 10.1145/319950.320022
   Wang Chong, 2011, P 17 ACM SIGKDD INT, P448, DOI [DOI 10.1145/2020408.2020480, 10.1145/2020408.2020480]
   Wilson B.J., 2015, ARXIV151002675
   Yan M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P557, DOI 10.1145/2647868.2654920
   Yu K, 2004, IEEE T KNOWL DATA EN, V16, P56, DOI 10.1109/TKDE.2004.1264822
NR 17
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12533
EP 12544
DI 10.1007/s11042-017-4902-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100039
DA 2024-07-18
ER

PT J
AU Mohamadi, N
   Soheili, AR
   Toutounian, F
AF Mohamadi, Neda
   Soheili, Ali R.
   Toutounian, Faezeh
TI A new hybrid denoising model based on PDEs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Stochastic optimization algorithm; PDE-based model
ID PARTIAL-DIFFERENTIAL-EQUATION; NOISE REMOVAL; ANISOTROPIC DIFFUSION;
   SPARSE REPRESENTATION; IMAGE-RESTORATION; ALGORITHM; DOMAIN;
   DICTIONARIES; FLOW
AB In this paper, a novel denoising algorithm based on the denoising methods of partial differential equations is presented. The proposed algorithm is obtained by using a stochastic algorithm for combining two denoising methods based on partial differential equations. The model provides a new approach for solving the contradiction in the image restoration. The new hybrid model has more ability to restore the image in terms of peak signal to noise ratio, blind/referenceless image spatial quality evaluator and visual quality, compared with each of denoising methods separately used. Experimental results show that our approach is more efficient in image denoising than the used denoising methods.
C1 [Mohamadi, Neda; Soheili, Ali R.; Toutounian, Faezeh] Ferdowsi Univ Mashhad, Fac Math Sci, Dept Appl Math, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Soheili, AR (corresponding author), Ferdowsi Univ Mashhad, Fac Math Sci, Dept Appl Math, Mashhad, Iran.
EM soheili@um.ac.ir
RI Soheili, Ali R./J-2191-2017; Mohamadi, Neda/AAN-9666-2021; Soheili, Ali
   R./R-7111-2019
OI Mohamadi, Neda/0000-0002-0519-5973; Soheili, Ali R./0000-0002-6990-5401
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Andreu F, 2005, ASYMPTOTIC ANAL, V43, P9
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Barbu T, 2009, NONLINEAR ANAL-REAL, V10, P1351, DOI 10.1016/j.nonrwa.2008.01.017
   Barcelos CAZ, 2003, IEEE T IMAGE PROCESS, V12, P751, DOI 10.1109/TIP.2003.814242
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan T, 1999, 9921 UCLA DEP MATH C
   Chan T. F., 2003, Notices AMS, V50, P14
   Chaux C, 2008, IEEE T SIGNAL PROCES, V56, P3855, DOI 10.1109/TSP.2008.921757
   Chen B, 2012, APPL MATH MODEL, V36, P1197, DOI 10.1016/j.apm.2011.07.073
   Dong W, 2011, CVPR 2011
   Drapaca CS, 2009, IEEE T BIO-MED ENG, V56, P582, DOI 10.1109/TBME.2008.2011561
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fouskakis D, 2002, INT STAT REV, V70, P315, DOI 10.2307/1403861
   Gai S, 2015, MULTIMED TOOLS APPL, V74, P1107, DOI 10.1007/s11042-013-1812-2
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Isgrò F, 2008, PARALLEL COMPUT, V34, P727, DOI 10.1016/j.parco.2008.09.005
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jain P, 2017, MULTIMED TOOLS APPL, V76, P1659, DOI 10.1007/s11042-015-3154-8
   Jin JS, 2000, IEEE T INF TECHNOL B, V4, P298, DOI 10.1109/4233.897062
   Kaisar S, 2008, INT J COMPUT SCI NET, V8, P271
   Katkovnik V, 2006, MONOGRAPH, V157
   Korürek M, 2010, EXPERT SYST APPL, V37, P1946, DOI 10.1016/j.eswa.2009.07.018
   Kumar M, 2009, IEEE T IMAGE PROCESS, V18, P2137, DOI 10.1109/TIP.2009.2025006
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Monteil J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P254, DOI 10.1109/ICIP.1998.999015
   Pargas RP, 1993, IEEE P 9 INT C ART I, P18
   Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Prasath VBS, 2014, NONLINEAR ANAL-REAL, V17, P33, DOI 10.1016/j.nonrwa.2013.10.004
   Ram I, 2011, IEEE T SIGNAL PROCES, V59, P4199, DOI 10.1109/TSP.2011.2158428
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Russo F, 2003, IEEE T INSTRUM MEAS, V52, P1148, DOI 10.1109/TIM.2003.815989
   Russo F, 2004, I W IMAG SYST TECHNI, P7, DOI 10.1109/IST.2004.1397271
   Sethian J., 1999, LEVEL SET METHODS FA
   Toledo CFM, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P1294
   Tukey J., 1974, Conference Records of Electronics and Aerospace Systems Convention (EASCOM), P673
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Windyga PS, 2001, IEEE T IMAGE PROCESS, V10, P173, DOI 10.1109/83.892455
   Xu PF, 2014, MULTIMED TOOLS APPL, V71, P1529, DOI 10.1007/s11042-012-1290-y
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   Yin XH, 2016, MULTIMED TOOLS APPL, V75, P4505, DOI 10.1007/s11042-015-2488-6
   Zeng W, 2015, MULTIMED TOOLS APPL, V74, P743, DOI 10.1007/s11042-013-1692-5
   Zhang XB, 2015, MULTIMED TOOLS APPL, V74, P10495, DOI 10.1007/s11042-014-2182-0
NR 49
TC 2
Z9 4
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12057
EP 12072
DI 10.1007/s11042-017-4858-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100020
DA 2024-07-18
ER

PT J
AU Muñoz, JE
   Gouveia, ER
   Cameirao, MS
   Badia, SBI
AF Munoz, John Edison
   Gouveia, Elvio Rubio
   Cameirao, Monica S.
   Bermudez i Badia, Sergi
TI PhysioLab - a multivariate physiological computing toolbox for ECG, EMG
   and EDA signals: a case of study of cardiorespiratory fitness assessment
   in the elderly population
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physiological computing; Electrocardiography; Electromyography;
   Electrodermal activity; Cardiorespiratory fitness; Elderly
ID HEART-RATE-VARIABILITY; PERFORMANCE; ENDURANCE; SOFTWARE; MEMORY
AB The exponential increase of wearable health-tracking technologies offers new possibilities but also poses new challenges in signal processing to enable fitness monitoring through multimodal physiological recordings. Although there are several software tools used for postprocessing in physiological computing applications, limitations in the analysis, incorporating signals from multiple sources, integrating contextual information and providing information visualization tools prevent a widespread use of this technology. To address these issues, we introduce PhysioLab, a multimodal processing Matlab tool for the data analysis of Electromyography (EMG), Electrocardiography (ECG) and Electrodermal Activity (EDA). The software is intended to facilitate the processing and comprehension of multimodal physiological data with the aim of assessing fitness in several domains. A unique feature of PhysioLab is that is informed by nonnative data grouped by age and sex, allowing contextualization of data based on users' demographics. Besides signal processing, PhysioLab includes a novel approach to multivariable data visualization with the aim of simplifying interpretation by non-experts users. The system computes a set of ECG features based on heart rate variability analysis, EMG parameters to quantify force and fatigue levels, and galvanic skin level/responses from EDA signals. Furthermore, PhysioLab provides compatibility with data from multiple low-cost wearable sensors. We conducted an experiment with 17 community-dwelling older adults (64.5 +/- 6.4) to assess the feasibility of the tool in characterizing cardiorespiratory profiles during physical activity. Correlation analyses and regression models showed significant interactions between physiology and fitness evaluations. Our results suggest novel ways that physiological parameters could be effectively used to complement traditional fitness assessment.
C1 [Munoz, John Edison; Gouveia, Elvio Rubio; Cameirao, Monica S.; Bermudez i Badia, Sergi] M Iti, P-9020105 Caminho Da Penteada, Funchal, Portugal.
   [Munoz, John Edison; Cameirao, Monica S.; Bermudez i Badia, Sergi] Univ Madeira, Fac Ciencias Exatas & Engn, P-9020105 Caminho Da Penteada, Funchal, Portugal.
   [Gouveia, Elvio Rubio] Univ Madeira, Fac Ciencias Sociais, P-9020105 Caminho Da Penteada, Funchal, Portugal.
C3 Universidade da Madeira; Universidade da Madeira
RP Muñoz, JE (corresponding author), M Iti, P-9020105 Caminho Da Penteada, Funchal, Portugal.; Muñoz, JE (corresponding author), Univ Madeira, Fac Ciencias Exatas & Engn, P-9020105 Caminho Da Penteada, Funchal, Portugal.
EM john.cardona@m-iti.org; erubiog@uma.pt; monica.cameirao@m-iti.org;
   sergi.bermudez@m-iti.org
RI Gouveia, Elvio/F-9156-2015; Badia, Sergi Bermúdez i/C-8681-2018;
   Cameirao, Monica/KQV-2089-2024; Cameirao, Monica/P-2078-2019; Cameirao,
   Monica/C-8675-2018
OI Gouveia, Elvio/0000-0003-0927-692X; Badia, Sergi Bermúdez
   i/0000-0003-4452-0414; Cameirao, Monica/0000-0002-5352-0128; Cameirao,
   Monica/0000-0002-5352-0128; Cameirao, Monica/0000-0002-5352-0128
FU Portuguese Foundation for Science and Technology [CMUPERI/HCI/0046/2013,
   Estrategico LA 9 - UID/EEA/50009/2013]; ARDITI (Agencia Regional para o
   Desenvolvimento da Investigacao, Tecnologia e Inovacao) institution
FX This work is supported by the Portuguese Foundation for Science and
   Technology through the Augmented Human Assistance project
   (CMUPERI/HCI/0046/2013), Projeto Estrategico LA 9 - UID/EEA/50009/2013
   and ARDITI (Agencia Regional para o Desenvolvimento da Investigacao,
   Tecnologia e Inovacao) institution.
CR Al Hazzouri AZ, 2014, HYPERTENSION, V63, P181, DOI 10.1161/HYPERTENSIONAHA.113.01888
   Albentosa Marina, 1994, Aquaculture, V126, P315, DOI 10.1016/0044-8486(94)90048-5
   Albinet CT, 2010, EUR J APPL PHYSIOL, V109, P617, DOI 10.1007/s00421-010-1393-y
   [Anonymous], AUGSBERG BIOSIGNAL T
   [Anonymous], 2000, MANUAL INTERPRETATIO
   [Anonymous], 2017, FRONTIERS ICT, DOI DOI 10.3389/FICT.2017.00001
   [Anonymous], PERSONAL TRAINING TH
   [Anonymous], SPORTS SCI HDB ESSEN
   [Anonymous], 2014, J PHYS ACT HEALTH, DOI DOI 10.1123/jpah.2012-0405
   [Anonymous], 2009, IFMBE PROC
   [Anonymous], USER 6 MIN WALK TEST
   [Anonymous], 2014, FRONT PSYCHOL
   Bartlett R., 2007, Introduction to Sports Biomechanics: Analysing Human Movement Patterns, V2nd
   Blanch A, 2013, COMPUT METH PROG BIO, V110, P89, DOI 10.1016/j.cmpb.2012.10.013
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.2277/ 0521844711
   Cifrek M, 2009, CLIN BIOMECH, V24, P327, DOI 10.1016/j.clinbiomech.2009.01.010
   Compostella Leonida, 2014, Res Cardiovasc Med, V3, pe25237, DOI 10.5812/cardiovascmed.25237
   da Silva HP, 2014, IEEE PERVAS COMPUT, V13, P64, DOI 10.1109/MPRV.2014.61
   Dawson ME, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P159, DOI 10.1017/cbo9780511546396.007
   De Luca CJ, 1997, J APPL BIOMECH, V13, P135, DOI 10.1123/jab.13.2.135
   Edlin Gordon., 2012, Health Wellness
   Ernst G., 2014, Heart rate variability
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Gacek A, 2012, ECG SIGNAL PROCESSING, CLASSIFICATION AND INTERPRETATION: A COMPREHENSIVE FRAMEWORK OF COMPUTATIONAL INTELLIGENCE, P1, DOI 10.1007/978-0-85729-868-3
   Goldberger AryL., 2012, Clinical Electrocardiography: A Simplified Approach
   Gupta R., 2014, ECG Acquisition and Automated Remote Processing, P51
   Hallman DM, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/907482
   Hansen AL, 2003, INT J PSYCHOPHYSIOL, V48, P263, DOI 10.1016/S0167-8760(03)00073-4
   Hautala AJ, 2006, EUR J APPL PHYSIOL, V96, P535, DOI 10.1007/s00421-005-0116-2
   Heyward V., 2014, ADV FITNESS ASSESSME
   Jung J, 1997, CLIN CARDIOL, V20, P341, DOI 10.1002/clc.4960200408
   Kamen G., 2010, ESSENTIALS ELECTROMY
   Keytel LR, 2005, J SPORT SCI, V23, P289, DOI 10.1080/02640410470001730089
   Kiviniemi AM, 2007, EUR J APPL PHYSIOL, V101, P743, DOI 10.1007/s00421-007-0552-2
   Kleiger RE, 2005, ANN NONINVAS ELECTRO, V10, P88, DOI 10.1111/j.1542-474X.2005.10101.x
   Loue S., 2008, Encyclopedia of aging and public health
   Macfarlane P.W., 2010, COMPREHENSIVE ELECTR, V4
   Mahinrad S, 2015, J HYPERTENS, V33, pE57, DOI 10.1097/01.hjh.0000467497.22224.3b
   Munoz JE, 2016, EHEALTH NETWORKING A, P1
   Niskanen JP, 2004, COMPUT METH PROG BIO, V76, P73, DOI 10.1016/j.cmpb.2004.03.004
   Nuwer R, 2013, NEW SCI, V217, P21, DOI 10.1016/S0262-4079(13)60542-4
   Pfurtscheller G, 2006, NEUROIMAGE, V31, P153, DOI 10.1016/j.neuroimage.2005.12.003
   Plecido da Silva Hugo, 2014, International Conference on Physiological Computing Systems (PhyCS 2014). Proceedings, P246
   Poon L., 2006, Active Living, Cognitive Functioning, and Aging, V1
   Prokasy W., 2012, Electrodermal Activity in Psychological Research
   Rikli RE, 2012, SENIOR FITNESS TEST
   Schäfer A, 2013, INT J CARDIOL, V166, P15, DOI 10.1016/j.ijcard.2012.03.119
   Shah AJ, 2011, PSYCHOSOM MED, V73, P475, DOI 10.1097/PSY.0b013e3182227d6a
   Singh B., 2015, Int. J. Recent Sci. Res, V6, P3501
   Stein PK, 1999, AM HEART J, V138, P567, DOI 10.1016/S0002-8703(99)70162-6
   Tanaka H, 2001, J AM COLL CARDIOL, V37, P153, DOI 10.1016/S0735-1097(00)01054-8
   Thongpanja S, 2013, ELEKTRON ELEKTROTECH, V19, P51, DOI 10.5755/j01.eee.19.3.3697
   Uth N, 2004, EUR J APPL PHYSIOL, V91, P111, DOI 10.1007/s00421-003-0988-y
   Vidaurre C, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/935364
   Voss A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118308
   Wang HM, 2012, MOD SIMUL ENG, V2012, DOI 10.1155/2012/931943
   Zhang F, 2014, MED ENG PHYS, V36, P1007, DOI 10.1016/j.medengphy.2014.05.009
NR 58
TC 11
Z9 13
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11521
EP 11546
DI 10.1007/s11042-017-5069-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900062
DA 2024-07-18
ER

PT J
AU Pratikakis, I
   Savelonas, MA
   Mavridis, P
   Papaioannou, G
   Sfikas, K
   Arnaoutoglou, F
   Rieke-Zapp, D
AF Pratikakis, Ioannis
   Savelonas, Michalis A.
   Mavridis, Pavlos
   Papaioannou, Georgios
   Sfikas, Konstantinos
   Arnaoutoglou, Fotis
   Rieke-Zapp, Dirk
TI Predictive digitisation of cultural heritage objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object retrieval; Rigid registration; Non-rigid registration;
   Cultural heritage
AB 3D digitisation has been instrumental in the cultural heritage domain for over a decade, contributing to the digital preservation and dissemination of cultural heritage. Still, the typical 3D acquisition workflow remains complex and time-consuming. This work presents the concept of predictive digitisation by means of a platform, aiming to speed-up and simplify 3D digitisation, exploiting similarities in digital repositories of Cultural Heritage objects.
C1 [Pratikakis, Ioannis] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Arnaoutoglou, Fotis] Democritus Univ Thrace, Xanthi, Greece.
   [Pratikakis, Ioannis; Arnaoutoglou, Fotis] ATHENA Res & Innovat Ctr, Xanthi, Greece.
   [Mavridis, Pavlos] Graz Univ Technol, Inst Comp Graph & Knowledge Visualizat, Graz, Austria.
   [Savelonas, Michalis A.] Athens Univ Econ & Business, Dept Informat, Athens, Greece.
   [Papaioannou, Georgios] Athens Univ Econ & Business, Dept Informat, Athens, Greece.
   [Sfikas, Konstantinos] NTNU, Dept Comp & Informat Sci, Trondheim, Norway.
   [Rieke-Zapp, Dirk] GmbH, AICON 3D Syst, Braunschweig, Germany.
C3 Democritus University of Thrace; Democritus University of Thrace; Graz
   University of Technology; Athens University of Economics & Business;
   Athens University of Economics & Business; Norwegian University of
   Science & Technology (NTNU)
RP Pratikakis, I (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.; Pratikakis, I (corresponding author), ATHENA Res & Innovat Ctr, Xanthi, Greece.
EM ipratika@ee.duth.gr; msavelonas@gmail.com; p.mavridis@cvg.tugraz.at;
   gepap@aueb.gr; konstantinos.sfikas@idi.ntnu.no; fotarny@ceti.gr;
   dirk.rieke-zapp@aicon.de
RI Papaioannou, Georgios/AAH-9642-2021; PRATIKAKIS, IOANNIS/AAD-3387-2019
OI Papaioannou, Georgios/0000-0003-4774-0746; PRATIKAKIS,
   IOANNIS/0000-0002-4124-3688
FU EC FP7 STREP Project PRESIOUS [600533]
FX This work was supported by the EC FP7 STREP Project PRESIOUS, grant no.
   600533.
CR [Anonymous], 2016, ARXIV160600185
   [Anonymous], 2010, P ECCV
   [Anonymous], P CVPR
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Deng BL, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12021
   Furuya T., 2009, P ACM INT C IM VID R, P1
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Long MS, 2014, IEEE T KNOWL DATA EN, V26, P1805, DOI 10.1109/TKDE.2013.97
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu GY, 2015, IEEE I CONF COMP VIS, P2434, DOI 10.1109/ICCV.2015.280
   Mavridis P, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12741
   Mavridis P, 2015, COMPUT AIDED GEOM D, V35-36, P16, DOI 10.1016/j.cagd.2015.03.022
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Papazov C, 2011, COMPUT GRAPH FORUM, V30, P1493, DOI 10.1111/j.1467-8659.2011.02023.x
   Pauly M., 2005, P SGP
   Pratikakis I., 2016, P 3DOR, P79
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Sfikas K, 2016, MULTIMED TOOLS APPL, V75, P3693, DOI 10.1007/s11042-014-2069-0
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Tao R, 2014, PROC CVPR IEEE, P2099, DOI 10.1109/CVPR.2014.269
NR 28
TC 4
Z9 4
U1 9
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12991
EP 13021
DI 10.1007/s11042-017-4928-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100060
DA 2024-07-18
ER

PT J
AU Xu, YL
   Guo, J
   Huang, Z
   Qiu, WD
AF Xu, Yunlu
   Guo, Jie
   Huang, Zheng
   Qiu, Weidong
TI Sparse coding with cross-view invariant dictionaries for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dictionary learning; Sparse coding; Person re-identification;
   Intelligent surveillance
ID SHRINKAGE; ALGORITHM
AB The task of matching observations of the same person in disjoint views captured by non-overlapping cameras is known as the person re-identification problem. It is challenging owing to low-quality images, inter-object occlusions, and variations in illumination, viewpoints and poses. Unlike previous approaches that learn Mahalanobis-like distance metrics, we propose a novel approach based on dictionary learning that takes the advances of sparse coding of discriminatingly and cross-view invariantly encoding features representing different people. Firstly, we propose a robust and discriminative feature extraction method of different feature levels. The feature representations are projected to a lower computation common subspace. Secondly, we learn a single cross-view invariant dictionary for each feature level for different camera views and a fusion strategy is utilized to generate the final matching results. Experimental statistics show the superior performance of our approach by comparing with state-of-the-art methods on two publicly available benchmark datasets VIPeR and PRID 2011.
C1 [Xu, Yunlu; Guo, Jie; Huang, Zheng; Qiu, Weidong] Shanghai Jiao Tong Univ, Dept Informat Secur Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Guo, J (corresponding author), Shanghai Jiao Tong Univ, Dept Informat Secur Engn, Shanghai 200240, Peoples R China.
EM guojie@sjtu.edu.cn
FU New Century Excellent Talents in University of Ministry of Education
   [NCET-12-0358]; Program of Shanghai Technology Research Leader
   [16XD1424400]
FX This work has been supported by New Century Excellent Talents in
   University of Ministry of Education under Grant NCET-12-0358, and
   Program of Shanghai Technology Research Leader under Grant 16XD1424400.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   [Anonymous], MOBILE NETW APPL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, MOBILE NETWORKS APPL, DOI DOI 10.1007/S1103601708634
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], 2015, BMVC
   [Anonymous], 2016, PERSONNET PERSON REI
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], P INT C DISTR SMART
   [Anonymous], ANN EUGEN
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], CONCURRENCY COMPUTAT
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gong S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Gu SH, 2014, ADV NEUR IN, V27
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Liu XK, 2015, IEEE WINT CONF APPL, P868, DOI 10.1109/WACV.2015.120
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moghaddam B, 2000, PATTERN RECOGN, V33, P1771, DOI 10.1016/S0031-3203(99)00179-X
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Tibshirani R, 2011, J R STAT SOC B, V73, P273, DOI 10.1111/j.1467-9868.2011.00771.x
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zeng MY, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301296
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
NR 50
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10715
EP 10732
DI 10.1007/s11042-017-4893-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900020
DA 2024-07-18
ER

PT J
AU Añorga, J
   Arrizabalaga, S
   Sedano, B
   Goya, J
   Alonso-Arce, M
   Mendizabal, J
AF Anorga, Javier
   Arrizabalaga, Saioa
   Sedano, Beatriz
   Goya, Jon
   Alonso-Arce, Maykel
   Mendizabal, Jaizki
TI Analysis of YouTube's traffic adaptation to dynamic environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YouTube; Dash; Streaming; Bandwidth; Video quality
ID DASH
AB The popular Internet service, YouTube, has adopted by default the HyperText Markup Language version 5 (HTML5). With this adoption, YouTube has moved to Dynamic Adaptive Streaming over HTTP (DASH) as Adaptive BitRate (ABR) video streaming technology. Furthermore, rate adaptation in DASH is solely receiver-driven. This issue motivates this work to make a deep analysis of YouTube's particular DASH implementation. Firstly, this article provides a state of the art about DASH and adaptive streaming technology, and also YouTube traffic characterization related work. Secondly, this paper describes a new methodology and test-bed for YouTube's DASH implementation traffic characterization and performance measurement. This methodology and test-bed do not make use of proxies and, moreover, they are able to cope with YouTube traffic redirections. Finally, a set of experimental results are provided, involving a dataset of 310 YouTube's videos. The depicted results show a YouTube's traffic pattern characterization and a discussion about allowed download bandwidth, YouTube's consumed bitrate and quality of the video. Moreover, the obtained results are cross-validated with the analysis of HTTP requests performed by YouTube's video player. The outcomes of this article are applicable in the field of Quality of Service (QoS) and Quality of Experience (QoE) management. This is valuable information for Internet Service Providers (ISPs), because QoS management based on assured download bandwidth can be used in order to provide a target end-user's QoE when YouTube service is being consumed.
C1 [Anorga, Javier; Arrizabalaga, Saioa; Sedano, Beatriz; Goya, Jon; Alonso-Arce, Maykel; Mendizabal, Jaizki] Univ Navarra, Ceit & Tecnun, Paseo Manuel Lardizabal 15, San Sebastian 20018, Spain.
C3 University of Navarra
RP Añorga, J (corresponding author), Univ Navarra, Ceit & Tecnun, Paseo Manuel Lardizabal 15, San Sebastian 20018, Spain.
EM jabenito@tecnun.es
RI Arrizabalaga, Saioa/D-9757-2016
OI Arrizabalaga, Saioa/0000-0001-9958-9799; Goya, Jon/0000-0001-5321-0579;
   Anorga, Javier/0000-0003-3799-1410
CR Akhshabi S, 2012, SIGNAL PROCESS-IMAGE, V27, P271, DOI 10.1016/j.image.2011.10.003
   Alcock S, 2011, ACM SIGCOMM COMP COM, V41, P25, DOI 10.1145/1971162.1971166
   Alexa Corporation, TOP 500 SIT WEB
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], 2014, P 5 ACM MULT SYST C, DOI DOI 10.1145/2557642.2563671
   [Anonymous], P IFIP WIR DAYS WD R
   Anorga J, 2015, 19 INT C CIRC SYST C
   Balan DG, 2009, NDT: 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKED DIGITAL TECHNOLOGIES, P122, DOI 10.1109/NDT.2009.5272182
   Casas P, 2014, IEEE T NETW SERV MAN, V11, P441, DOI 10.1109/TNSM.2014.2377691
   Casas P, 2012, IEEE GLOBE WORK, P1269, DOI 10.1109/GLOCOMW.2012.6477764
   Chen L, 2015, RECENT RES APPL INF, P158
   Chen YJ, 2015, IEEE COMMUN SURV TUT, V17, P1126, DOI 10.1109/COMST.2014.2363139
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Enache A, 2013, P 12 WSEAS INT C CIR, P173
   Finamore A., 2011, ACM IMC, P345, DOI DOI 10.1145/2068816.2068849
   Google YouTube, ENG DEV BLOG YOUTUBE
   Hossfeld T, 2012, INT WORK QUAL MULTIM, P1, DOI 10.1109/QoMEX.2012.6263849
   Ito M, 2014, INT J PHOTOENERGY, V2014, DOI 10.1155/2014/694541
   ITTF, 2014, 23009 ISOIEC
   Kelley Simon., Dnsmasq - network services for small networks
   Krishnappa DK, 2013, C LOCAL COMPUT NETW, P407, DOI 10.1109/LCN.2013.6761273
   Lederer S., 2012, P 3 MULT SYST C, P89
   Liu Y., 2013, PASSIVE ACTIVE MEASU, P104
   Mok R. K. P., 2011, 2011 IFIP/IEEE International Symposium on Integrated Network Management (IM 2011), P485, DOI 10.1109/INM.2011.5990550
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Plissonneau L, 2012, P 24 INT TEL C INT T, P28
   Sieber C, 2016, 2016 IFIP NETWORKING CONFERENCE (IFIP NETWORKING) AND WORKSHOPS, P503, DOI 10.1109/IFIPNetworking.2016.7497231
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Timmerer C, 2010, HTTP STREAMING MPEG
   Torres R, 2011, INT CON DISTR COMP S, P248, DOI 10.1109/ICDCS.2011.43
   Wamser F, 2016, COMPUT NETW, V109, P211, DOI 10.1016/j.comnet.2016.03.020
   Yetgin Z, 2015, RECENT RESEARCHES IN, P75
   YouTube, SEARCH LIST YOUTUBE
   YouTube, YOUTUBE PLAYER API R
   Zink M, 2009, COMPUT NETW, V53, P501, DOI 10.1016/j.comnet.2008.09.022
NR 36
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7977
EP 8000
DI 10.1007/s11042-017-4695-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800010
DA 2024-07-18
ER

PT J
AU Bhatti, N
   Hanbury, A
   Stottinger, J
AF Bhatti, Naeem
   Hanbury, Allan
   Stottinger, Julian
TI Contextual local primitives for binary patent image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Patent image retrieval; Local features; Local primitives; Contextual
   features
ID RECOGNITION; SIMILARITY; DRAWINGS
AB Local features and descriptors that perform well in the case of photographic images are often unable to capture the content of binary technical drawings due to their different characteristics. Motivated by this, a new local feature representation, the contextual local primitives, is proposed in this paper. It is based on the detection of the junction and end points, classification of the local primitives to local primitive words and establishment of the geodesic connections of the local primitives. We exploit the granulometric information of the binary patent images to set all the necessary parameters of the involved mathematical morphology operators and window size for the local primitive extraction, which makes the whole framework parameter free. The contextual local primitives and, their spatial areas as a histogram weighting factor are evaluated by performing binary patent image retrieval experiments. It is found that the proposed contextual local primitives perform better than the local primitives only, the SIFT description of the contextual Hessian points, the SIFT description of local primitives and state of the art local content capturing methods. Moreover, an analysis of the approach in the perspective of a general patent image retrieval system reveals of its being efficient in multiple aspects.
C1 [Bhatti, Naeem] Quaid I Azam Univ, Dept Elect, Islamabad, Pakistan.
   [Hanbury, Allan] Vienna Univ Technol, Inst Software Technol & Interact Syst, Favoritenstr 9-188, A-1040 Vienna, Austria.
   [Stottinger, Julian] Univ Trento, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
C3 Quaid I Azam University; Technische Universitat Wien; University of
   Trento
RP Bhatti, N (corresponding author), Quaid I Azam Univ, Dept Elect, Islamabad, Pakistan.
EM nbhatti@qau.edu.pk; allan.hanbury@tuwien.ac.at
CR [Anonymous], 2008, CVPR
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587420
   [Anonymous], FDN TRENDS COMPUT GR
   [Anonymous], 2012, P 25 IEEE CAN C EL C, DOI DOI 10.1109/CCECE.2012.6334823
   [Anonymous], 1985, P 8 ANN INT ACM SIGI, DOI DOI 10.1145/253495.253506
   [Anonymous], THESIS
   Attali D, 2009, MATH VIS, P109, DOI 10.1007/b106657_6
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bergevin R, 2007, LECT NOTES COMPUT SC, V4633, P222
   Bhatti NA, 2011, P AAPR WORKSH
   Bhatti NA, 2011, LECT NOTES COMPUT SC, V7042, P165, DOI 10.1007/978-3-642-25085-9_19
   Bhatti NA, 2011, INT SYMP IMAGE SIG, P307
   Castanedo F., 2013, The Scientific World Journal, V2013, P1
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Csurka G, 2011, CLEF NOTEBOOK PAPERS
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Das M, 1999, IEEE INTELL SYST APP, V14, P24, DOI 10.1109/5254.796084
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deseilligny MP, 1998, IEEE T PATTERN ANAL, V20, P505, DOI 10.1109/34.682180
   Desolneux A, 2004, THEORY DECIS LIB A, V38, P71
   Fonseca MJ, 2009, COMPUT AIDED DESIGN, V41, P1067, DOI 10.1016/j.cad.2009.09.004
   Fonseca MJ, 2004, SPECIAL ISSUE INT J
   Forstner W, 1999, MUSTERERKENNUNG 1999, P213
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Hanbury A., 2011, WORKSHOP PATENT INFO, DOI DOI 10.1145/2064975.2064979
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Heuel S, 1998, WORKSH PERC ORG COMP
   Huet B, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P737, DOI 10.1109/ICIP.2001.958599
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leung WH, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P29
   Leung WH, 2002, INT CONF ACOUST SPEE, P2029
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   List J, 2007, WORLD PAT INF, V29, P210, DOI 10.1016/j.wpi.2007.01.001
   Liu RJ, 2010, PATTERN RECOGN, V43, P1907, DOI 10.1016/j.patcog.2009.11.022
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Newby GB, 1997, TREC, P735
   Olson CF, 2016, COMPLEMENTARY KEYPOI, P341
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Park JH, 1999, PATTERN RECOGN LETT, V20, P591, DOI 10.1016/S0167-8655(99)00022-7
   Santosh KC, 2010, LECT NOTES COMPUT SC, V6020, P163
   Shen JL, 2009, PATTERN RECOGN, V42, P293, DOI 10.1016/j.patcog.2008.04.016
   Shen JL, 2015, PATTERN RECOGN, V48, P3227, DOI 10.1016/j.patcog.2015.02.027
   Sidiropoulos P, 2010, CBMI, P1
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Tiwari A, 2004, SHAPING BUSINESS STRATEGY IN A NETWORKED WORLD, VOLS 1 AND 2, PROCEEDINGS, P1167
   Vrochidis S, 2010, WORLD PAT INF, V32, P94, DOI 10.1016/j.wpi.2009.05.010
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Yang M, 2006, INT C PATT RECOG, P958
   Zhiyuan Z, 2007, 2007 JAPAN-CHINA JOINT WORKSHOP ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY, PROCEEDINGS, P86, DOI 10.1109/FCST.2007.14
NR 52
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9111
EP 9151
DI 10.1007/s11042-017-4808-5
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800060
DA 2024-07-18
ER

PT J
AU Bhunia, AK
   Kumar, G
   Roy, PP
   Balasubramanian, R
   Pal, U
AF Bhunia, Ayan Kumar
   Kumar, Gautam
   Roy, Partha Pratim
   Balasubramanian, R.
   Pal, Umapada
TI Text recognition in scene image and video frame using Color Channel
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene text recognition; Color channel selection; Hidden Markov model;
   Multi script recognition
ID CLASSIFICATION; MODEL; ROTATION
AB In recent years, recognition of text from natural scene image and video frame has got increased attention among the researchers due to its various complexities and challenges. Because of low resolution, blurring effect, complex background, different fonts, color and variant alignment of text within images and video frames, etc., text recognition in such scenario is difficult. Most of the current approaches usually apply a binarization algorithm to convert them into binary images and next OCR is applied to get the recognition result. In this paper, we present a novel approach based on color channel selection for text recognition from scene images and video frames. In the approach, at first, a color channel is automatically selected and then selected color channel is considered for text recognition. Our text recognition framework is based on Hidden Markov Model (HMM) which uses Pyramidal Histogram of Oriented Gradient features extracted from selected color channel. From each sliding window of a color channel our color-channel selection approach analyzes the image properties from the sliding window and then a multi-label Support Vector Machine (SVM) classifier is applied to select the color channel that will provide the best recognition results in the sliding window. This color channel selection for each sliding window has been found to be more fruitful than considering a single color channel for the whole word image. Five different features have been analyzed for multi-label SVM based color channel selection where wavelet transform based feature outperforms others. Our framework of color channel selection is script-independent. It has been tested in English (Roman) and Devanagari (Indic) scripts. We have tested our approach on English datasets (ICDAR 2003, ICDAR 2013, MSRA-TD500, IIIT5K, SVT, YVT) publicly available for both video and scene images. For Devanagari script, we collected our own dataset. The performances obtained from experimental results are encouraging and show the advantage of the proposed method.
C1 [Bhunia, Ayan Kumar] Inst Engn & Management, Dept ECE, Kolkata, India.
   [Kumar, Gautam; Roy, Partha Pratim; Balasubramanian, R.] Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata, India.
C3 Institute of Engineering & Management (IEM), Kolkata; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Roorkee; Indian Statistical Institute; Indian Statistical Institute
   Kolkata
RP Roy, PP (corresponding author), Indian Inst Technol Roorkee, Dept CSE, Roorkee, Uttar Pradesh, India.
EM proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/GPF-4253-2022; Roy, Partha Pratim/AAW-2994-2020; Pal,
   Umapada/AAC-4930-2022; Roy, Partha Pratim/AAV-9061-2020
OI Roy, Partha Pratim/0000-0002-5735-5254; 
CR [Anonymous], ARXIV13101811
   Bhunia AK, 2015, PROC INT CONF DOC, P636, DOI 10.1109/ICDAR.2015.7333839
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chattopadhyay T, 2013, PROC INT CONF DOC, P1170, DOI 10.1109/ICDAR.2013.237
   Chen DT, 2005, PATTERN RECOGN LETT, V26, P1386, DOI 10.1016/j.patrec.2004.11.019
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   González A, 2014, IEEE T INTELL TRANSP, V15, P228, DOI 10.1109/TITS.2013.2277662
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Greenhalgh J, 2015, IEEE T INTELL TRANSP, V16, P1360, DOI 10.1109/TITS.2014.2363167
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang R, 2012, INT C PATT RECOG, P717
   Huang WL, 2013, IEEE I CONF COMP VIS, P1241, DOI 10.1109/ICCV.2013.157
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jain A, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853796
   Jetley S, 2012, INT C PATT RECOG, P343
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khare V, 2016, PATTERN RECOGN, V54, P128, DOI 10.1016/j.patcog.2016.01.008
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liangchen Liu, 2012, 2012 19th IEEE International Conference on Image Processing (ICIP 2012), P1849, DOI 10.1109/ICIP.2012.6467243
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Liu MX, 2014, NEUROCOMPUTING, V139, P34, DOI 10.1016/j.neucom.2013.09.056
   Lucas SM, 2003, PROC INT CONF DOC, P682
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mishra A, 2012, PROC CVPR IEEE, P2687, DOI 10.1109/CVPR.2012.6247990
   Mittal A, 2017, J VIS COMMUN IMAGE R, V46, P187, DOI 10.1016/j.jvcir.2017.03.002
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Novikova T, 2012, LECT NOTES COMPUT SC, V7577, P752, DOI 10.1007/978-3-642-33783-3_54
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pal U, 2010, PATTERN RECOGN, V43, P4124, DOI 10.1016/j.patcog.2010.06.017
   Nguyen PX, 2014, IEEE WINT CONF APPL, P776, DOI 10.1109/WACV.2014.6836024
   Roy PP, 2012, PATTERN RECOGN, V45, P1972, DOI 10.1016/j.patcog.2011.09.026
   Roy S, 2016, PATTERN RECOGN, V52, P433, DOI 10.1016/j.patcog.2015.10.011
   Roy S, 2015, EXPERT SYST APPL, V42, P5554, DOI 10.1016/j.eswa.2015.02.030
   Roy S, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P288, DOI 10.1109/ACPR.2013.60
   Roy S, 2012, INT C PATT RECOG, P3300
   Saidane Z., 2007, International Workshop on Camera- Based Document Analysis and Recognition CBDAR 2007, P100
   Saidane Z, 2007, PROC INT CONF DOC, P874
   Shivakumara P, 2017, PATTERN RECOGN, V61, P479, DOI 10.1016/j.patcog.2016.08.021
   Phan TQ, 2013, IEEE I CONF COMP VIS, P569, DOI 10.1109/ICCV.2013.76
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wu YR, 2016, IEEE T IMAGE PROCESS, V25, P5622, DOI 10.1109/TIP.2016.2607426
   Xin L, 2013, P INT JOINT C ART IN
   Yang HJ, 2014, MULTIMED TOOLS APPL, V69, P217, DOI 10.1007/s11042-012-1250-6
   Yao C, 2014, PROC CVPR IEEE, P4042, DOI 10.1109/CVPR.2014.515
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
NR 56
TC 19
Z9 19
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8551
EP 8578
DI 10.1007/s11042-017-4750-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800035
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mondal, J
   Kundu, MK
   Das, S
   Chowdhury, M
AF Mondal, Jaydeb
   Kundu, Malay Kumar
   Das, Sudeb
   Chowdhury, Manish
TI Video shot boundary detection using multiscale geometric analysis of
   nsct and least squares support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Abrupt transition; Gradual transition;
   Principal component analysis; Non-subsampled contourlet transform; Least
   squares support vector machine
ID CONTOURLET TRANSFORM; EXTRACTION; FRAMEWORK; MODEL
AB The fundamental step in video content analysis is the temporal segmentation of video stream into shots, which is known as Shot Boundary Detection (SBD). The sudden transition from one shot to another is known as Abrupt Transition (AT), whereas if the transition occurs over several frames, it is called Gradual Transition (GT). A unified framework for the simultaneous detection of both AT and GT have been proposed in this article. The proposed method uses the multiscale geometric analysis of Non-Subsampled Contourlet Transform (NSCT) for feature extraction from the video frames. The dimension of the feature vectors generated using NSCT is reduced through principal component analysis to simultaneously achieve computational efficiency and performance improvement. Finally, cost efficient Least Squares Support Vector Machine (LS-SVM) classifier is used to classify the frames of a given video sequence based on the feature vectors into No-Transition (NT), AT and GT classes. A novel efficient method of training set generation is also proposed which not only reduces the training time but also improves the performance. The performance of the proposed technique is compared with several state-of-the-art SBD methods on TRECVID 2007 and TRECVID 2001 test data. The empirical results show the effectiveness of the proposed algorithm.
C1 [Mondal, Jaydeb; Kundu, Malay Kumar] Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Kolkata 700108, India.
   [Das, Sudeb] Videonet Technol Pvt Ltd, Salt Lake City 700091, UT, India.
   [Chowdhury, Manish] KTH Sch Technol & Hlth, SE-14152 Stockholm, Sweden.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata
RP Mondal, J (corresponding author), Indian Stat Inst, Machine Intelligence Unit, 203 BT Rd, Kolkata 700108, India.
EM maharaj305@gmail.com; malay@isical.ac.in; sudeb.das@videonetics.com;
   manchowd@kth.se
OI Chowdhury, Manish/0000-0002-7767-3399
FU Tata Consultancy Services (TCS); Indian National Academy of Engineering
   (INAE)
FX The first author acknowledges Tata Consultancy Services (TCS) for
   providing fellowship to carry out the research work. Malay K. Kundu
   acknowledges the Indian National Academy of Engineering (INAE) for their
   support through INAE Distinguished Professor fellowship. The authors
   would like to thank the National Institute of Standards & Technology
   (NIST) for providing TRECVID data set.
CR [Anonymous], [No title captured]
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Arman F., 1994, MULTIMEDIA SYST, V1, P211, DOI DOI 10.1007/BF01268945
   Bescós J, 2005, IEEE T MULTIMEDIA, V7, P293, DOI 10.1109/TMM.2004.840598
   Brabanter KD, 2011, 10146 ESAT SISTA, P1
   Chasanis V, 2009, PATTERN RECOGN LETT, V30, P55, DOI 10.1016/j.patrec.2008.08.015
   Choudhury A, 2012, IEEE T CIRC SYST VID, V22, P1266, DOI 10.1109/TCSVT.2012.2198136
   Chowdhury M., 2014, MULTIMED TOOLS APPL, V72, P1
   Chua TS, 2003, INT CONF ACOUST SPEE, P845
   Cooper M, 2007, IEEE T MULTIMEDIA, V9, P610, DOI 10.1109/TMM.2006.888015
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   GARCIA-PEREZ M A, 1992, Spatial Vision, V6, P89, DOI 10.1163/156856892X00163
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jang H, 2006, GRADUAL SHOT BOUNDAR, V28
   Kawai Y., 2007, P TREC VIDEO RETR EV
   Kundu MK, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, DEVICES AND INTELLIGENT SYSTEMS (CODLS), P628, DOI 10.1109/CODIS.2012.6422281
   Lakshmi Priya GG, 2014, IEEE T IMAGE PROCESS, V12, P23
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li WK, 2002, LECT NOTES COMPUT SC, V2532, P336
   Liu Z., 2007, P TRECVID WORKSH
   López F, 2005, LECT NOTES COMPUT SC, V3523, P666
   MIENE A, 2001, P ECDL WS GEN DOC, P39
   Mithling M, 2007, P REC VIDEO RETR EVA
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Omidyeganeh M, 2011, IEEE T IMAGE PROCESS, V20, P2730, DOI 10.1109/TIP.2011.2143421
   Ren J., 2007, P TREC VIDEO RETR EV
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   SRRR AS., 2016, IJCTA, V9, P3231
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yuan, 2007, P TREC VIDEO RETR EV
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
NR 36
TC 22
Z9 23
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8139
EP 8161
DI 10.1007/s11042-017-4707-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800017
DA 2024-07-18
ER

PT J
AU Qin, P
   Pun, CM
AF Qin, Peng
   Pun, Chi-Man
TI Object tracking using distribution fields with correlation coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Distribution fields; Particle filters; Correlation
   coefficients
ID VISUAL TRACKING
AB A real-time object tracking method based on distribution field (DF) constructs with correlation coefficients is proposed to solve the drawbacks of local search and poor real-time performance exhibited by traditional DF tracking methods. With the goal of adapting to complex environments and changes in tracking speed, we propose an algorithm based on DFs and global searching by dense sampling. First, we use the DFs to construct an appearance model that functions as a target descriptor in the particle filter framework, allowing dynamic updating of the appearance model. Then, we measure the similarity using correlation coefficients based on fast Fourier transforms (FFTs) instead of the L1-norm of DFs to reduce the time complexity, overcome the drawback of randomness when using sparse sampling, and avoid falling into local optima from the gradient descent used in traditional DF methods. The results of experiments show that our proposed algorithm not only performs in real time but is also more robust for a variety of complex environments than those of six state-of-the-art algorithms on eight challenging video sequences.
C1 [Qin, Peng; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China.
EM cmpun@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746; Qin, Peng/0000-0002-2602-2641
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [093-2014-A2]
FX This work was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (093-2014-A2).
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], ARXIV160406620
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Chenggang Y, 2013, DAT COMPR C DCC SNOW
   Chenggang Y, 2014, ELECTRON LETT, V50, P805
   Collins RT, 2003, PROC CVPR IEEE, P234
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hager G.D., 2006, Computer Vision and Pattern Recognition, P798
   Heideman M. T., 1984, IEEE ASSP Magazine, V1, P14, DOI 10.1109/MASSP.1984.1162257
   Huang GH, 2016, MULTIMED TOOLS APPL, V75, P5473, DOI 10.1007/s11042-015-2516-6
   Khenouchi H, 2016, LIVING PLANET S, V740
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Koutra D, 2016, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2824443
   Lin C, 2017, MULTIMED TOOLS APPL, V76, P9565, DOI 10.1007/s11042-016-3563-3
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   Maggio E., 2010, Video Tracking: Theory and Practice, P15
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Tang A, 2016, INT S VIS COMP
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   [夏瑜 Xia Yu], 2012, [光电工程, Opto-Electronic Engineering], V39, P67
   Xie Y, 2012, PATTERN RECOGN LETT, V33, P1075, DOI 10.1016/j.patrec.2012.01.020
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
NR 32
TC 2
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8979
EP 9002
DI 10.1007/s11042-017-4790-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800053
DA 2024-07-18
ER

PT J
AU Shen, LL
   Lei, JY
   Hou, CP
AF Shen, Lili
   Lei, Jinyi
   Hou, Chunping
TI No-reference stereoscopic 3D image quality assessment via combined model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference 3D IQA; Human visual system; Statistic feature; SSIM
ID INTEGRATION; STATISTICS
AB Currently, stereoscopic 3D image has been widely applied in many fields. However, it may suffer from various quality degradations during the acquisition and transmission. Therefore, an effective 3D image quality assessment (IQA) method has great significance for 3D multimedia applications. Since 3D image pair has two images, it is easily distorted asymmetrically. In this paper, we have designed a no-reference quality assessment algorithm for asymmetrically distorted 3D images by utilizing combined model. First, in order to extract the distorted information in different frequency, the Gabor filter bank is employed to decompose the 3D image pair. Second, the "Cyclopean" and difference maps, representing for binocular characteristic and asymmetric information, are generated from the Gabor filter results. Then, the statistical characteristics of "Cyclopean" and difference maps are estimated by utilizing the generalized Gaussian distribution (GGD) fitting. Finally, a SVR regression is learned to map the feature vector to the recorded subjective difference mean opinion scores (DMOS). Besides, we also make an attempt to utilize structural similarity index (SSIM) to measure the asymmetric information of 3D image pair. The performance of our algorithm is evaluated on the popular 3D IQA databases. Extensive results show that the proposed algorithm outperforms state-of-the-art no-reference 3D IQA algorithms and is comparable to some full-reference 3D IQA algorithms.
C1 [Shen, Lili; Lei, Jinyi; Hou, Chunping] Tianjin Univ, Sch Elect & Informat Engn, Weijin Rd, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Lei, JY (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Weijin Rd, Tianjin 300072, Peoples R China.
EM sll@tju.edu.cn; leijinyi@163.com; hcp@tju.edu.cn
RI shen, lili/IUQ-2187-2023
FU National Natural Science Foundation of China [61302123, 61520106002,
   61471262]
FX This research is partially supported by the National Natural Science
   Foundation of China (Nos. 61302123, 61520106002 and 61471262).
CR [Anonymous], 2010, P INT WORKSH VID PRO
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Campisi Patrizio, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2110
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Kaufman L., 1974, Sight and mind: An introduction to visual perception
   Kumano H, 2008, J NEUROPHYSIOL, V99, P402, DOI 10.1152/jn.00096.2007
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Pokorny J, 1972, FDN CYCLOPEAN PERCEP
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2015, IEEE SIGNAL PROC LET, V22, P1548, DOI 10.1109/LSP.2015.2413946
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Su CC, 2015, IEEE T IMAGE PROCESS, V24, P1685, DOI 10.1109/TIP.2015.2409558
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang C, 2016, NEUROCOMPUTING, V173, P462, DOI 10.1016/j.neucom.2015.01.105
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P3810, DOI 10.1109/TIP.2015.2456414
   Zhao S, 2016, IEEE T MULT IN PRESS
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhou W, 2016, NEUROCOMPUT IN PRESS
NR 34
TC 7
Z9 8
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8195
EP 8212
DI 10.1007/s11042-017-4709-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800019
DA 2024-07-18
ER

PT J
AU Taneja, A
   Ranjan, P
   Ujlayan, A
AF Taneja, Arti
   Ranjan, Priya
   Ujlayan, Amit
TI Multi-cell nuclei segmentation in cervical cancer images by integrated
   feature vectors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical image analysis; Geometric features; Gray level co-occurrence
   matrix; Multi-cell images; Neighborhood-Concentric filtering; Neural
   network-relevance vector Machine; Optimal weight update
ID CELL-NUCLEI
AB Automated analysis of cervical cancer images is considered as an attractive research in the biological fields. Due to the intensive advances in the digital technology and the light microscopy, the cellular imaging requires the continuous growing importance. Sophisticated methods are adopted to isolate the nuclei from the cytoplasm based on the boundary estimation and the analysis of intensity of blue cells to improve the abnormality prediction. The cell-based segmentation evolved in research studies assures the automatic assistance with an assumption of a single cell. Previous work [21] concentrates on the segmentation of abnormal region on single-cell images. This paper extends that work into the multi-cell images with the addition of geometrical features. The complex cell structure, poor contrast, and overlapping affect the cell segmentation performance. This paper enhances the performance of single-cell segmentation with the integrated feature vectors of geometrical (area, cell size, cell intensity and the maximum intensity) and Gray level Co-occurrence Matrix (GLCM) to improve the abnormality level prediction.. Initially, the Neighborhood Concentric Filtering (NCF) is applied on the input slides to remove the noise present in the image and enhance the intensity level. Then, the initial level cluster formation and masking are performed on the noise-free image. The Optimal Weight Updating with the Multi-Level set (OWU-ML) estimates the Region of Interest (ROI) and segments the blue cell and cytoplasm. The clear analysis of blue cell indicates the exact classification of abnormal levels in the images. The combination of geometrical and GLCM extracts the texture pattern features of the blue cell, cytoplasm and the nucleus portions in the form of angle variations. Finally, the Neural Network-based RVM classifier predicts the classes of (normal and abnormal) cervical images. The integration of novel methods such as OWU-ML segmentation, GLCM + geometrical feature extraction and NN-RVM classification improves the abnormal prediction performance and assures the suitability in multi-cell cervical image handling in biological applications.
C1 [Taneja, Arti] Amity Inst Informat Technol, Noida 201303, Uttar Pradesh, India.
   [Ranjan, Priya] Amity Univ, Noida, Uttar Pradesh, India.
   [Ujlayan, Amit] Gautam Budha Univ, Greater Noida, India.
C3 Amity University Noida; Amity University Noida; Gautam Buddha University
RP Taneja, A (corresponding author), Amity Inst Informat Technol, Noida 201303, Uttar Pradesh, India.
EM arti.taneja@gmail.com
RI Ranjan, Priya/GMX-0072-2022
OI Ranjan, Priya/0000-0003-1236-9481; Ujlayan, Amit/0000-0002-6045-8385
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Allwin S, 2010, IEEE INT C COMP INT, P1
   Csikász-Nagy A, 2013, SEMIN CANCER BIOL, V23, P293, DOI 10.1016/j.semcancer.2013.05.009
   Guan T, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P107, DOI 10.1109/ROBIO.2014.7090315
   Guan T, 2015, IEEE J BIOMED HEALTH, V19, P1494, DOI 10.1109/JBHI.2014.2346239
   Happy S, 2015, ARXIV150505601
   Jakob PH, 2016, CYTOTECHNOLOGY, V68, P1813, DOI 10.1007/s10616-015-9935-0
   Li K, 2012, PATTERN RECOGN, V45, P1255, DOI 10.1016/j.patcog.2011.09.018
   Lucchi A, 2012, IEEE T MED IMAGING, V31, P474, DOI 10.1109/TMI.2011.2171705
   Mahanta LB., 2012, J EMERG TREND COMPUT, V3, P245
   Morales RO, 2013, MONOGRAFIA EDITORIAL
   Nosrati MS, 2015, I S BIOMED IMAGING, P186, DOI 10.1109/ISBI.2015.7163846
   Orfanoudaki IM, 2011, ARCH GYNECOL OBSTET, V284, P1197, DOI 10.1007/s00404-011-2009-4
   Pai PY, 2012, EXPERT SYST APPL, V39, P154, DOI 10.1016/j.eswa.2011.06.034
   Plissiti ME, 2012, IEEE T IMAGE PROCESS, V21, P4568, DOI 10.1109/TIP.2012.2206041
   Plissiti ME, 2011, IEEE T INF TECHNOL B, V15, P233, DOI 10.1109/TITB.2010.2087030
   Plissiti ME, 2011, PATTERN RECOGN LETT, V32, P838, DOI 10.1016/j.patrec.2011.01.008
   Ramos IRM, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/561242
   Saslow D, 2012, AM J CLIN PATHOL, V137, P516, DOI [10.1309/AJCPTGD94EVRSJCG, 10.3322/caac.21139]
   Siegel RL., 2019, ANTI-CANCER DRUG, V69, P7, DOI [DOI 10.3322/caac.20115, DOI 10.1097/CAD.0000000000000617]
   Taneja A, 2016, P INT C IM PROC COMP, P76
   Tasoglu S, 2015, P IEEE, V103, P161, DOI 10.1109/JPROC.2014.2384836
   Wang F, 2014, LECT NOTES COMPUT SC, V8795, P253, DOI 10.1007/978-3-319-11897-0_30
   Wang YL, 2016, IEEE J SEL TOP QUANT, V22, DOI 10.1109/JSTQE.2015.2498478
   Zhao LL, 2016, COMPUT BIOL MED, V71, P46, DOI 10.1016/j.compbiomed.2016.01.025
NR 25
TC 11
Z9 11
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9271
EP 9290
DI 10.1007/s11042-017-4864-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200005
DA 2024-07-18
ER

PT J
AU Chen, L
   Zhao, JY
AF Chen, Lei
   Zhao, Jiying
TI Contourlet-based image and video watermarking robust to geometric
   attacks and compressions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image and video watermarking; Contourlet transform (CT); Principal
   component analysis (PCA); Noise visibility function (NVF); Normalized
   correlation (NC)
ID SCHEME; TRANSFORM
AB In this paper, we first propose a new blind image watermarking scheme robust to geometric attacks and compressions. The scheme is based on contourlet transform (CT) and principal component analysis (PCA). The scheme uses the principal components of the largest contourlet coefficients of the last directional subband of the cover image to embed the watermark. Meanwhile, with the noise visibility function (NVF), the watermarking strength is adjusted adaptively to preserve the perceptual quality of the image. The watermark can be detected with high accuracy after various possible distortions. The normalized correlation (NC) between the original watermark and the watermark extracted from the distorted watermarked image is used as the robustness evaluation criterion. The simulation results demonstrate that the proposed scheme has good performance in terms of both quality and robustness against a variety of image-processing attacks, such as rotation, scaling and image compressions. Then we extend the scheme to blind video watermarking. The performance of the video watermarking scheme is evaluated against video attacks like rotation, frame averaging, noise additions and video compressions. The introduction of the CT produces robustness against image and video compressions, and the PCA yields resistance to geometric attacks.
C1 [Chen, Lei; Zhao, Jiying] Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Zhao, JY (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM lchen148@uottawa.ca; jzhao@uottawa.ca
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Alavianmehr M. A., 2012, 2012 2nd International eConference on Computer and Knowledge Engineering (ICCKE 2012), P194, DOI 10.1109/ICCKE.2012.6395377
   Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Chen L, 2016, IEEE IMTC P, P996
   Chen L, 2015, MED IMAGE ANAL, V23, P1, DOI 10.1016/j.media.2015.03.004
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Hajizadeh M, 2010, ADV ELECTR COMPUT EN, V10, P96, DOI 10.4316/AECE.2010.03016
   Hien TD, 2003, LECT NOTES ARTIF INT, V2773, P1427
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Khalighi S, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/540723
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Liu Y, 2007, MULTIMED TOOLS APPL, V34, P57, DOI 10.1007/s11042-006-0072-9
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Nguyen SC, 2015, PROC INT CONF ADV, P445, DOI 10.1109/ATC.2015.7388369
   Ni RR, 2005, PATTERN RECOGN, V38, P357, DOI 10.1016/j.patcog.2004.08.006
   Ogawa K, 2015, I SYMP CONSUM ELECTR, P102, DOI 10.1109/ICCE.2015.7066337
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Sadreazami H, 2012, INT CONF SIGN PROCES, P628, DOI 10.1109/ICoSP.2012.6491566
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Song HH, 2008, SIGNAL PROCESS-IMAGE, V23, P162, DOI 10.1016/j.image.2008.01.005
   Tashk A, 2012, INT ISC CONF INFO SE, P60, DOI 10.1109/ISCISC.2012.6408192
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P311, DOI 10.1109/TMM.2013.2291658
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhao QJ, 2007, PATTERN RECOGN, V40, P1334, DOI 10.1016/j.patcog.2006.04.047
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
NR 33
TC 28
Z9 28
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7187
EP 7204
DI 10.1007/s11042-017-4628-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700035
DA 2024-07-18
ER

PT J
AU Ghebleh, M
   Kanso, A
   Stevanovic, D
AF Ghebleh, M.
   Kanso, A.
   Stevanovic, D.
TI A novel image encryption algorithm based on piecewise linear chaotic
   maps and least squares approximation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Pseudorandom numbers; Least squares
   approximation
ID SCHEME; CRYPTANALYSIS; COMPRESSION; BREAKING
AB In this paper, we propose a novel image encryption algorithm based on chaotic maps and least squares approximations. The proposed algorithm consists of two main phases, which are applied sequentially in several rounds, namely a shuffling phase and a masking phase. Both phases are based on 1-dimensional piecewise linear chaotic maps and act on the rows/columns of the input plain image. Least squares approximations are used to strengthen the security of the proposed algorithm by providing strong mixing between the rows/columns of the image. Simulation results show that the proposed image encryption algorithm is robust against common statistical and security attacks. We present thorough comparison of the proposed algorithm with some existing image encryption algorithms.
C1 [Ghebleh, M.; Kanso, A.; Stevanovic, D.] Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
C3 Kuwait University
RP Ghebleh, M (corresponding author), Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
EM mamad@sci.kuniv.edu.kw; akanso@sci.kuniv.edu.kw; dragance106@yahoo.com
RI Kanso, Ali/GVT-1076-2022; Stevanovic, Dragan/B-1230-2015; Ghebleh,
   Mohammad/I-1040-2014
OI Kanso, Ali/0000-0002-4366-841X; Ghebleh, Mohammad/0000-0003-2291-0892
CR Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Alvarez G, 2006, PHYS LETT A, V352, P78, DOI 10.1016/j.physleta.2005.11.055
   Arroyo D, 2008, CHAOS, V18, DOI 10.1063/1.2959102
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Behnia S, 2008, INT J BIFURCAT CHAOS, V18, P251, DOI 10.1142/S0218127408020288
   Bluman A.G., 1997, Elementary Statistics: A Step by Step Approach
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen H, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0669-9
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Li CQ, 2007, PHYS LETT A, V369, P23, DOI 10.1016/j.physleta.2007.04.023
   Li CQ, 2010, INT J BIFURCAT CHAOS, V20, P2561, DOI 10.1142/S0218127410027192
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Li SJ, 2006, INT J BIFURCAT CHAOS, V16, P1557, DOI 10.1142/S0218127406015507
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   National Institute of Standards and Technology (NIST), 2010, CERT 3 NIST REN SOIL
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Poole D., 2014, Linear algebra: A modern introduction (Fourth), Vfourth
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Solak E, 2010, OPT COMMUN, V283, P232, DOI 10.1016/j.optcom.2009.09.070
   Subramanyan B., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P217, DOI 10.1109/EAIT.2011.60
   Sui LS, 2013, OPT LASER TECHNOL, V48, P117, DOI 10.1016/j.optlastec.2012.10.016
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wadi SM, 2013, PROC TECH, V11, P51, DOI 10.1016/j.protcy.2013.12.161
   Wang XY, 2011, OPT COMMUN, V284, P5804, DOI 10.1016/j.optcom.2011.08.053
   Wong KW, 2008, IEEE T CIRCUITS-II, V55, P1193, DOI 10.1109/TCSII.2008.2002565
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yue Wu, 2011, Proceedings of the 2011 International Conference on System Science and Engineering (ICSSE), P23, DOI 10.1109/ICSSE.2011.5961867
   ZHAO G, 2010, 2010 2 INT C SIGN PR, V0002, P00002
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 52
TC 25
Z9 25
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7305
EP 7326
DI 10.1007/s11042-017-4634-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700041
DA 2024-07-18
ER

PT J
AU Wang, XY
   Li, P
   Zhang, YQ
   Liu, LY
   Zhang, HZ
   Wang, XK
AF Wang, Xing-Yuan
   Li, Pi
   Zhang, Ying-Qian
   Liu, Li-Yan
   Zhang, Hengzhi
   Wang, Xiukun
TI A novel color image encryption scheme using DNA permutation based on the
   Lorenz system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lorenz system; DNA permutation; Color image encryption
ID SEQUENCE OPERATION
AB We propose a novel color image encryption scheme based on DNA permutations. In the proposed scheme, the chaotic pseudo-random sequences for encryption depend on the plaintext image and secret keys. Besides, the proposed DNA permutation and addition/subtraction operations can break the bit planes of the plaintext image entirely. Therefore, the proposed scheme is sensitive to the plaintext image and can resist common attacks such as differential attack, brute-force attack, and statistical attack. Simulation results show the feasibility and effectiveness of the proposed scheme.
C1 [Wang, Xing-Yuan; Li, Pi; Wang, Xiukun] Dalian Univ Technol, Fac Elect Informat & Elect Engn, 2 Linggong Rd, Dalian 116024, Peoples R China.
   [Zhang, Ying-Qian] Xiamen Univ Zhangzhou Campus, Xiamen Univ Tan Kah Kee Coll, Sch Informat Sci & Technol, Xiamen 363105, Peoples R China.
   [Liu, Li-Yan; Zhang, Hengzhi] Dalian Univ Technol, City Inst, 31 Tieshanxi Rd, Dalian 116600, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Zhang, YQ (corresponding author), Xiamen Univ Zhangzhou Campus, Xiamen Univ Tan Kah Kee Coll, Sch Informat Sci & Technol, Xiamen 363105, Peoples R China.
EM zhangyq@dlut.edu.cn
RI Zhang, Ying-Qian/N-2058-2018; Zhang, Ying-Qian/AGS-3457-2022; Wang,
   Xing-yuan/I-6353-2015; Wang, Xiukun/Z-1270-2019; Zhang,
   Yingqian/CAI-2129-2022
OI Zhang, Ying-Qian/0000-0001-9568-0392; Wang, Xiukun/0000-0001-9138-5652;
   Zhang, Yingqian/0000-0001-9568-0392
FU Program for Liaoning Excellent Talents in University [LR2012003];
   National Natural Science Foundation of China [61370145, 61173183,
   61672124]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61672124, 61370145, and 61173183), Program for Liaoning
   Excellent Talents in University (No: LR2012003).
CR [Anonymous], EPL
   Chang WL, 2011, J SUPERCOMPUT, V56, P129, DOI 10.1007/s11227-009-0347-9
   Chen Y, 2006, IEEE T CIRCUITS-II, V53, P527, DOI 10.1109/TCSII.2006.875319
   Chen ZH, 2010, J COMPUT THEOR NANOS, V7, P840, DOI 10.1166/jctn.2010.1429
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Head T, 2000, BIOSYSTEMS, V57, P87, DOI 10.1016/S0303-2647(00)00091-5
   [廖琪男 LIAO Qinan], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P509
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Masuda N, 2002, IEEE T CIRCUITS-I, V49, P28, DOI 10.1109/81.974872
   Schneier B., 1995, CRYPTOGRAPHY THEORY
   Solak E, 2011, INFORM SCIENCES, V181, P227, DOI 10.1016/j.ins.2010.09.009
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xiang T, 2007, CHAOS, V17, P415
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zheng XD, 2009, APPL MATH COMPUT, V212, P177, DOI 10.1016/j.amc.2009.02.011
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 24
TC 70
Z9 70
U1 2
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6243
EP 6265
DI 10.1007/s11042-017-4534-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800052
DA 2024-07-18
ER

PT J
AU Zhang, GY
   Zou, WB
   Zhang, XJ
   Zhao, Y
AF Zhang, Guiying
   Zou, Wenbin
   Zhang, Xianjie
   Zhao, Yong
TI Singular value decomposition based virtual representation for face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual samples; Singular value decomposition (SVD); Sparse
   representation; Face recognition; Image classification; Collaborative
   representation
ID SPARSE REPRESENTATION; IMAGE; SVD; PCA
AB Sparse representation, which uses a test sample to represent a linear combination of an entire set of training samples, has achieved great success in face recognition, and it results in good performance when sufficient training samples exist. However, the available number of images of a subject's face is usually limited in real face recognition systems. In this paper, to obtain more facial representations, we propose a novel method that applies singular value decomposition (SVD) to produce virtual images from original images. The obtained virtual images not only enlarge the size of the set of training samples but also represent relatively stable low frequency facial information; thereby improving the robustness and classification accuracy. We also integrate these virtual samples with the original samples, providing more available information for object classification and, consequently, achieving better performance. To the best of our knowledge, this paper is the first work to use the product of a singular value matrix and right singular vectors to generate virtual samples for face recognition. Experiments on the most widely used and challenging benchmark datasets demonstrate that our method obtains better accuracy and is more robust compared with previous methods.
C1 [Zhang, Guiying] Guizhou Univ, Coll Comp Sci & Technol, Guiyang, Guizhou, Peoples R China.
   [Zhang, Guiying; Zhang, Xianjie] Zunyi Med Univ, Dept Med Informat Engn, Zunyi, Peoples R China.
   [Zou, Wenbin] Shenzhen Univ, Coll Informat Engn, Shenzhen Key Lab Adv Telecommun & Informat Proc, Shenzhen, Peoples R China.
   [Zhao, Yong] Peking Univ, Key Lab Integrated Microsyst, Shenzhen Grad Sch, Shenzhen, Peoples R China.
C3 Guizhou University; Zunyi Medical University; Shenzhen University;
   Peking University
RP Zhao, Y (corresponding author), Peking Univ, Key Lab Integrated Microsyst, Shenzhen Grad Sch, Shenzhen, Peoples R China.
EM zhaoyong@pkusz.edu.cn
OI Zou, Wenbin/0000-0003-1389-9089
FU Science and Technology Foundation of Guizhou province [LH20147597];
   Natural Science Foundation of Shenzhen [JCYJ20160506172651253,
   JCYJ20160307154003475]; National Natural Science Foundation of China
   [61401287]
FX The work reported in this paper is supported in part by the Science and
   Technology Foundation of Guizhou province under Grant LH20147597, in
   part by the Natural Science Foundation of Shenzhen under Grant
   JCYJ20160506172651253 and Grant JCYJ20160307154003475, and in part by
   the National Natural Science Foundation of China under Grant 61401287.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], PATTERN RECOGNIT LET
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Guo Z., 2011, 2011 IEEE Aerospace Conference, P1
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   Li X, 2012, IEEE C COMP VIS PATT
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Meng FR, 2017, MULTIMED TOOLS APPL, V76, P895, DOI 10.1007/s11042-015-3083-6
   Minghui Jiang, 2015, International Journal of Computational Geometry & Applications, V25, P1, DOI 10.1142/S0218195915500016
   Mohammed AA, 2011, PATTERN RECOGN, V44, P2588, DOI 10.1016/j.patcog.2011.03.013
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Shan S, 2006, ENSEMBLE PIECEWISE F
   Shen B, 2016, MULTIMED TOOLS APPL, V75, P8861, DOI 10.1007/s11042-014-2257-y
   Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9
   Sugiyama M, 2006, INT C
   Tan KR, 2005, NEUROCOMPUTING, V64, P505, DOI 10.1016/j.neucom.2004.10.113
   Tang DY, 2014, NEURAL COMPUT APPL, V24, P513, DOI 10.1007/s00521-012-1252-3
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Vinje W. E., 2000, Science, V287, P1273, DOI 10.1126/science.287.5456.1273
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Waqas J, 2014, INT J PATTERN RECOGN, V28, P285
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2004, PATTERN RECOGN, V37, P381, DOI 10.1016/S0031-3203(03)00232-2
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2013, INT J INNOV COMPUT I, V9, P543
   Xu Y, 2013, NEURAL COMPUT APPL, V22, P1543, DOI 10.1007/s00521-012-0833-5
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhang GY, 2016, OPTIK, V127, P9658, DOI 10.1016/j.ijleo.2016.05.093
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhu P., 2012, MULTISCALE PATCH BAS, P822
NR 50
TC 12
Z9 12
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7171
EP 7186
DI 10.1007/s11042-017-4627-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700034
DA 2024-07-18
ER

PT J
AU Chen, HY
   Qian, CS
   Zheng, H
   Wang, H
AF Chen, Haiyan
   Qian, Chengshan
   Zheng, Hao
   Wang, Huan
TI A multilinear unsupervised discriminant projections method for feature
   extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UDP; Tensor; Multilinear; Feature extraction; Face recognition
ID PRINCIPAL COMPONENT ANALYSIS; FACE-RECOGNITION; DIMENSIONALITY
   REDUCTION; 2-DIMENSIONAL PCA; REPRESENTATION; SAMPLE; LDA; EIGENFACES;
   ALGORITHM; FRAMEWORK
AB Despite considering the distribution information of data, unsupervised discriminant projection (UDP) ignores the space structure information of data for high order tensor objects. To address these problems, many tensor methods are developed for charactering the space structure information. Albeit effective, these methods ignore the local manifold structure of the samples, and thus achieve sub-optimal performance. In this paper, we formulate UDP in a high order tensor space and develop a Multilinear UDP (MUDP) for feature extraction on tensor objects. MUDP inherits the merits of UDP and Tensor based methods. The experiments tell that MUDP is an efficient and effective method and works well.
C1 [Chen, Haiyan; Wang, Huan] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Chen, Haiyan; Zheng, Hao; Wang, Huan] Nanjing Xiaozhuang Univ, Key Lab Trusted Cloud Comp & Big Data Anal, Nanjing 211171, Jiangsu, Peoples R China.
   [Qian, Chengshan] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing Xiaozhuang
   University; Nanjing University of Information Science & Technology
RP Wang, H (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.; Wang, H (corresponding author), Nanjing Xiaozhuang Univ, Key Lab Trusted Cloud Comp & Big Data Anal, Nanjing 211171, Jiangsu, Peoples R China.
EM huan_wang_nust@163.com
RI Li, Shiyue/KFA-3709-2024; Chen, Haiyan/HGB-6216-2022; zheng,
   hao/JQI-4215-2023; LEE, YU/JXY-2338-2024; Wang, Yue/JRY-8962-2023
OI Wang, Yue/0000-0001-8673-6358
FU Natural Science Foundation of China [61603190, 31671006]; Natural
   Science Foundation of Jiangsu Province [BK20140638, BK2012437]
FX This work is partly supported by Natural Science Foundation of China
   (61603190, 31671006) and the Natural Science Foundation of Jiangsu
   Province (No. BK20140638, BK2012437).
CR [Anonymous], 2007, CVPR
   [Anonymous], SOFT COMPUT
   [Anonymous], 2005, ADV NEURAL INFORM PR
   [Anonymous], KNOWLEDGE INFORM SYS
   [Anonymous], IEEE T NEURAL NETW L, DOI [10.1109/TNNLS.2016.2527796, DOI 10.1109/TNNLS.2016.2527796]
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   HASTIE T, 1994, J AM STAT ASSOC, V89, P1255, DOI 10.2307/2290989
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HONG ZQ, 1991, PATTERN RECOGN, V24, P317, DOI 10.1016/0031-3203(91)90074-F
   Jiang R, 2018, FUTURE GENER COMP SY, V78, P392, DOI 10.1016/j.future.2016.05.005
   Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1942, DOI 10.1109/TNNLS.2013.2297381
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ., 2004, The facial recognition technology (feret) database
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Quick D, 2014, TRENDS ISS CRIME CRI, P1
   Quick D, 2017, SOFTWARE PRACT EXPER, V47, P1095, DOI 10.1002/spe.2429
   Quick D, 2016, CLUSTER COMPUT, V19, P723, DOI 10.1007/s10586-016-0553-1
   Quick D, 2014, DIGIT INVEST, V11, P273, DOI 10.1016/j.diin.2014.09.002
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Ren CX, 2010, PATTERN RECOGN, V43, P318, DOI 10.1016/j.patcog.2009.05.020
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vapnik V., 1999, NATURE STAT LEARNING
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang WK, 2017, MULTIMED TOOLS APPL, V76, P4491, DOI 10.1007/s11042-016-3446-7
   Yang WK, 2016, NEUROCOMPUTING, V175, P198, DOI 10.1016/j.neucom.2015.10.049
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Yang WK, 2009, PATTERN RECOGN, V42, P2327, DOI 10.1016/j.patcog.2009.03.017
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang ZH, 2016, MULTIMED TOOLS APPL, V75, P3973, DOI 10.1007/s11042-015-3136-x
   Zhao HT, 2006, IEEE T SYST MAN CY B, V36, P873, DOI 10.1109/TSMCB.2006.870645
   Zuo WM, 2006, IEEE T SYST MAN CY B, V36, P863, DOI 10.1109/TSMCB.2006.872274
   Zuo WM, 2006, IEEE T SYST MAN CY B, V36, P946, DOI 10.1109/TSMCB.2005.863377
NR 55
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3857
EP 3870
DI 10.1007/s11042-016-4243-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600053
DA 2024-07-18
ER

PT J
AU Gao, LP
   Gao, DF
   Xiong, NX
   Lee, C
AF Gao, Liping
   Gao, Dongfang
   Xiong, Naixue
   Lee, Changhoon
TI CoWebDraw: a real-time collaborative graphical editing system supporting
   multi-clients based on HTML5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time collaboration; Consistency maintenance; Graphical editing;
   HTML5; WebSocket
ID SENSOR NETWORKS
AB Real-time collaborative graphical editing system allows a group of users simultaneously to view and edit the shared graphical documents from geographically dispersed sites connected by networks. The strategy of consistency maintenance is the key technique to ensure correctness in this editing system. This paper maps the two-dimensional drawing area into the linear structure in the real-time collaborative graphical editing system in the Web environment, and transforms the two-dimensional graphical operations to the linear operations. Based on the above, this paper improves the ABST algorithm to be suitable for this new environment. In order to verify the correctness and feasibility of the algorithm, this paper develops the real-time collaborative graphical editing system CoWebDraw based on Web, which adopts the HTML5 WebSocket protocol to achieve the real-time transformation of the information. In this system, geographically dispersed users can edit the shared graphical documents through web browsers. In the mobile internet era, the CoWebDraw system supports the concurrent editing of the same documents by multi-clients.
C1 [Gao, Liping; Gao, Dongfang; Xiong, Naixue] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Gao, Liping] Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Lee, Changhoon] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
C3 University of Shanghai for Science & Technology; Fudan University; Seoul
   National University of Science & Technology
RP Gao, LP (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.; Gao, LP (corresponding author), Fudan Univ, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM lipinggao@usst.edu.cn
RI xiong, naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635; Lee, Changhoon/0000-0003-4292-5792
FU National Science Foundation of China (NSFC) [61202376, 61572325];
   Shanghai Natural Science Foundation [17ZR1419100, 15ZR1429100]; Shanghai
   Key Laboratory of Data Science [201609060003]
FX We would like to thank the reviewers, whose valuable critique and
   comments helped to improve this paper. Moreover, this work is supported
   by the National Science Foundation of China (NSFC) under Grant No.
   61202376 and 61572325, Shanghai Natural Science Foundation under Grant
   No. No. 17ZR1419100 & No. 15ZR1429100, and the Open Project Program of
   Shanghai Key Laboratory of Data Science (No. 201609060003).
CR Chengzheng Sun, 2002, ACM Transactions on Computer-Human Interaction, V9, P1, DOI 10.1145/505151.505152
   Ellis CA, 1989, P ACM C MAN DAT 1989, P9
   Google Docs, 2011, CREAT SHAR YOUR WORK
   GREENBERG S, 1992, P HAW INT C SYST SCI, P138
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Gutwin C., 2011, Proceedings of Computer Supported Cooperative Work CSCW, P167, DOI [DOI 10.1145/1958824.1958850, 10.1145/1958824.1958850]
   Heinrich M., 2012, P 21 INT C WORLD WID
   Inoue R, 2012, INT SYMP PARAL ARCH, P186, DOI 10.1109/PAAP.2012.35
   Ionescu B, 2015, 2015 IEEE 10TH JUBILEE INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P105, DOI 10.1109/SACI.2015.7208180
   Karsenty A., 1993, Proceedings the 13th International Conference on Distributed Computing Systems (Cat. No.93CH3282-1), P195, DOI 10.1109/ICDCS.1993.287708
   Katayama S, 2013, 2013 14TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD 2013), P663, DOI 10.1109/SNPD.2013.13
   Liu Y, 2010, IET COMMUN, V4, P810, DOI 10.1049/iet-com.2009.0164
   Newman-Wolfe R. E., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P265, DOI 10.1145/143457.143524
   OpenCoWeb, 2011, OP COOP WEB FRAM PRO
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Shao B, 2010, IEEE T PARALL DISTR, V21, P1707, DOI 10.1109/TPDS.2010.64
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Sun D., 2004, Computer Supported Cooperative Work Conference Proceedings, P437, DOI 10.1145/1031607.1031681
   Wang SS, 2014, INT C COMP SUPP COOP, P689, DOI 10.1109/CSCWD.2014.6846928
   WANG X, 2002, P 2002 ACM C COMP SU, P68
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiong NX, 2009, IEEE J SEL AREA COMM, V27, P495, DOI 10.1109/JSAC.2009.090512
   Yin JW, 2015, IEEE T PARALL DISTR, V26, P668, DOI 10.1109/TPDS.2014.2315204
NR 23
TC 12
Z9 15
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 5067
EP 5082
DI 10.1007/s11042-017-5242-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500055
DA 2024-07-18
ER

PT J
AU Gupta, S
   Gupta, BB
AF Gupta, Shashank
   Gupta, B. B.
TI XSS-secure as a service for the platforms of online social network-based
   multimedia web applications in cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud security; Cross-site scripting (XSS) worms; Online social
   networking (OSN) security; Web security; JavaScript code injection
   attacks; Sanitization routines
AB This article presents a novel framework XSS-Secure, which detects and alleviates the propagation of Cross-Site Scripting (XSS) worms from the Online Social Network (OSN)-based multimedia web applications on the cloud environment. It operates in two modes: training and detection mode. The former mode sanitizes the extracted untrusted variables of JavaScript code in a context-aware manner. This mode stores such sanitized code in sanitizer snapshot repository and OSN web server for further instrumentation in the detection mode. The detection mode compares the sanitized HTTP response (HRES) generated at the OSN web server with the sanitized response stored at the sanitizer snapshot repository. Any variation observed in this HRES message will indicate the injection of XSS worms from the remote OSN servers. XSS-Secure determines the context of such worms, perform the context-aware sanitization on them and finally sanitized HRES is transmitted to the OSN user. The prototype of our framework was developed in Java and integrated its components on the virtual machines of cloud environment. The detection and alleviation capability of our cloud-based framework was tested on the platforms of real world multimedia-based web applications including the OSN-based Web applications. Experimental outcomes reveal that our framework is capable enough to mitigate the dissemination of XSS worm from the platforms of non-OSN Web applications as well as OSN web sites with acceptable false negative and false positive rate.
C1 [Gupta, Shashank; Gupta, B. B.] Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Gupta, BB (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Engn, Kurukshetra, Haryana, India.
EM gupta.brij@gmail.com
RI GUPTA, SHASHANK/AAU-3371-2021; Gupta, Brij B/E-9813-2011
OI GUPTA, SHASHANK/0000-0002-2124-9388; Gupta, Brij B/0000-0003-4929-4698
FU TEQIP-II
FX The authors would like to thank members of Information and Cyber
   Security Research Group working in the National Institute of Technology
   Kurukshetra, India for their valuable feedback and worthwhile
   discussions. This work was financially supported by TEQIP-II.
CR Almorsy M, 2010, P 2010 AQS PAC CLOUD
   [Anonymous], 2017, INT J SYST ASSUR ENG, DOI DOI 10.1007/S13198-015-0376-0
   [Anonymous], 2010, P 19 INT C WORLD WID, DOI [DOI 10.1145/1772690.1772701, 10.1145/1772690.1772701]
   [Anonymous], IGI GLOBALS ADV INFO
   [Anonymous], 2012, P 7 ACM S INFORM COM, DOI DOI 10.1145/2414456.2414458
   [Anonymous], PATHCUTTER SEVERING
   Balzarotti D, 2008, P IEEE S SECUR PRIV, P387, DOI 10.1109/SP.2008.22
   Byong JH, 2013, EURASIP J WIREL COMM, P63
   Gupta B B, 2015, J. Inf. Priv. Secur, V11, P118, DOI DOI 10.1080/15536548.2015.1044865
   Gupta MK, 2015, ADV COMP COMM INF IC
   Gupta S, 2015, INT J SYST ASSURANCE
   Gupta S, 2016, PROCEDIA COMPUT SCI, V78, P82, DOI 10.1016/j.procs.2016.02.014
   Hooimeijer Pieter., 2011, Proceedings of the 20th USENIX Conference on Security, SEC'11, P1
   Jabbar S, 2016, J SUPERCOMPUT JOS, V72, P247
   Parameshwaran I, 2015, P 2015 10 JOINT M FO
   Saxena P, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P601
   Stock B, 2015, P 22 ACM SIGSAC C CO
   Weinberger J, 2011, LECT NOTES COMPUT SC, V6879, P150, DOI 10.1007/978-3-642-23822-2_9
   Xiao W, 2014, ALG PROG PAAP 2014 6
NR 19
TC 47
Z9 48
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4829
EP 4861
DI 10.1007/s11042-016-3735-1
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500043
DA 2024-07-18
ER

PT J
AU Ren, C
   Chen, J
   Kuo, YH
   Wu, D
   Yang, MQ
AF Ren, Chao
   Chen, Jian
   Kuo, Yonghong
   Wu, Di
   Yang, Mengqi
TI Recommender system for mobile users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Internet of things; Device-to-device
ID 2-STAGE COOPERATIVE MULTICAST; TO-DEVICE COMMUNICATION;
   RESOURCE-ALLOCATION; SERVICES; SCHEME
AB As predicted, trillions of devices and billions of services will be integrated into Internet of Things (IoT), where most value added applications rely on wireless physical links. In this paper, we develop a recommender system to overcome the challenges of large-scale mobile IoT. The proposed recommender system socially matches wireless devices to communicate and share their contents based on similarities, distance, velocity, wireless channel quality and remaining energy. The physical layer connections are realized by device-to-device spectrum sharing techniques, and we accordingly designed a cooperative multicast service case to make full use of the wireless broadcasting nature. A "green communication" orientated algorithm is proposed to allocate power resources, adaptively adjust data rate and recommend partners as mobile relays. Simulation results show that the proposed system can efficiently utilize the wireless resource of mobile IoT and appropriately recommend partners to assist more users into IoT services.
C1 [Ren, Chao; Chen, Jian; Kuo, Yonghong; Wu, Di; Yang, Mengqi] Xidian Univ, 2 South Taibai Rd, Xian 710071, Peoples R China.
C3 Xidian University
RP Chen, J (corresponding author), Xidian Univ, 2 South Taibai Rd, Xian 710071, Peoples R China.
EM renchao@stu.xidian.edu.cn; jianchen@mail.xidian.edu.cn;
   yhkuo@mail.xidian.edu.cn; diwu_xidian@hotmail.com;
   mqyang_xidian@hotmail.com
RI Wu, Di/W-6541-2019; Wu, Di/HNP-3772-2023; Ren, Chao/W-2376-2019; KUO,
   Yong-Hong/M-9078-2015; wu, di/IYS-9217-2023
OI Wu, Di/0000-0003-3266-0612; Ren, Chao/0000-0002-3088-0008; 
FU National Natural Science Foundation of China [61540046, 61601347]; "111"
   project of China [B08038]; China Scholarship Council (CSC)
   [201506960024]
FX This work is supported in part by National Natural Science Foundation of
   China under grants 61540046 and 61601347, by "111" project of China
   under grant B08038, and by the scholarship from China Scholarship
   Council (CSC) under grant No. 201506960024.
CR Adomavicius G, 2015, IEEE T KNOWL DATA EN, V27, P1573, DOI 10.1109/TKDE.2014.2384502
   [Anonymous], 2015, 2015 IEEE 81 VEH TEC, DOI DOI 10.1109/VTCSPRING.2015.7145948
   Brenev E, 2016, MISHELTI M5 LOVE
   Chen L., 1998, Proceedings of the Second International Conference on Autonomous Agents, P132, DOI 10.1145/280765.280789
   Doppler K, 2009, IEEE COMMUN MAG, V47, P42, DOI 10.1109/MCOM.2009.5350367
   Fuller B, 2016, TRILOBITES TRILLION
   Fuller B, 2016, DO WE GET 1 TRILLION
   Hou F, 2009, IEEE T WIREL COMMUN, V8, P1508, DOI 10.1109/TWC.2009.080417
   Kenteris M., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P840, DOI 10.1109/ISCC.2010.5546758
   Kim T, 2014, IEEE WIREL COMMUN LE, V3, P625, DOI 10.1109/LWC.2014.2338318
   Li XH, 2008, IEEE T SIGNAL PROCES, V56, P675, DOI 10.1109/TSP.2007.907820
   Luo CB, 2011, IEEE T VEH TECHNOL, V60, P343, DOI 10.1109/TVT.2010.2090676
   Ma C, 2013, IEEE GLOB COMM CONF, P3890, DOI 10.1109/GLOCOM.2013.6831680
   Mandyam GD, 2008, INT S WORLD WIR MOB, P1
   Mashal I, 2016, IEEE WCNC
   Moukas A, 1997, APPL ARTIF INTELL, V11, P437, DOI 10.1080/088395197118127
   Niu BL, 2010, IEEE T VEH TECHNOL, V59, P3136, DOI 10.1109/TVT.2010.2046431
   Ren C, 2016, WIREL COMMUN MOB COM, V16, P2778, DOI 10.1002/wcm.2724
   Ren C, 2015, IET COMMUN, V9, P1088, DOI 10.1049/iet-com.2014.0830
   Schweizer D, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1123, DOI 10.1109/ICMLA.2015.62
   Suh CH, 2008, IEEE T WIREL COMMUN, V7, P27, DOI 10.1109/TWC.2008.060467
   Wache H, 2015, IEEE INT SMART CIT C
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Wen JM, 2016, IEEE T WIREL COMMUN, V15, P6541, DOI 10.1109/TWC.2016.2585493
   Wen JM, 2016, IEEE COMMUN LETT, V20, P2031, DOI 10.1109/LCOMM.2016.2594196
   Yin C, 2014, IEEE GLOBE WORK, P839, DOI 10.1109/GLOCOMW.2014.7063537
   Zanardi V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P51
   Zhang Y., 2009, MOBILE COMPUTING COM, V13, P1, DOI DOI 10.1145/1740437.1740439
   Zhou B, 2013, IEEE T VEH TECHNOL, V62, P2315, DOI 10.1109/TVT.2012.2237557
   Zhou YQ, 2014, IEEE J SEL AREA COMM, V32, P274, DOI 10.1109/JSAC.2014.141208
NR 30
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4133
EP 4153
DI 10.1007/s11042-017-4527-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500004
DA 2024-07-18
ER

PT J
AU Yan, CX
   Luo, MN
   Liu, WH
   Zheng, QH
AF Yan, Caixia
   Luo, Minnan
   Liu, Wenhe
   Zheng, Qinghua
TI Robust dictionary learning with graph regularization for unsupervised
   person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust dictionary learning; Graph regularization; Unsupervised person
   re-identification
AB Most existing approaches for person re-identification are designed in a supervised way, undergoing a prohibitively high labeling cost and poor scalability. Besides establishing effective similarity distance metrics, these supervised methods usually focus on constructing discriminative and robust features, which is extremely difficult due to the significant viewpoint variations. To overcome these challenges, we propose a novel unsupervised method, termed as Robust Dictionary Learning with Graph Regularization (RDLGR), which can guarantee view-invariance through learning a dictionary shared by all the camera views. To avoid the significant degradation of performance caused by outliers, we employ a capped l (2,1)-norm based loss to make our model more robust, addressing the problem that traditional quadratic loss is known to be easily dominated by outliers. Considering the lack of labeled cross-view discriminative information in our unsupervised method, we further introduce a cross-view graph Laplacian regularization term into the framework of dictionary learning. As a result, the geographical structure of original data space can be preserved in the learned latent subspace as discriminative information, making it possible to further boost the matching accuracy. Extensive experimental results over four widely used benchmark datasets demonstrate the superiority of the proposed model over the state-of-the-art methods.
C1 [Yan, Caixia; Luo, Minnan; Zheng, Qinghua] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, SPKLSTN Lab, Xian, Shaanxi, Peoples R China.
   [Liu, Wenhe] Univ Technol Sydney, CAI, Sydney, NSW, Australia.
C3 Xi'an Jiaotong University; University of Technology Sydney
RP Luo, MN (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, SPKLSTN Lab, Xian, Shaanxi, Peoples R China.
EM yancaixia@stu.xjtu.edu.cn; minnluo@mail.xjtu.edu.cn; allenlwh@gmail.com;
   qhzheng@mail.xjtu.edu.cn
FU National Science Foundation of China [61502377, 61532004]; National Key
   Research and Development Program of China [2016YFB1000903]; Ministry of
   Education Innovation Research Team [IRT 17R86]; Project of China
   Knowledge Center for Engineering Science and Technology; China
   Postdoctoral Science Foundation [2015M582662]
FX This work was funded by the National Science Foundation of China (Nos.
   61502377, 61532004), the National Key Research and Development Program
   of China (No. 2016YFB1000903); Ministry of Education Innovation Research
   Team (No. IRT 17R86); Project of China Knowledge Center for Engineering
   Science and Technology, and China Postdoctoral Science Foundation (No.
   2015M582662).
CR An L, 2016, INFORM SCIENCES, V355, P74, DOI 10.1016/j.ins.2016.02.055
   [Anonymous], 2009, P ADV NEUR INF PROC
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2010, Asian Conference on Computer Vision
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chang JY, 2016, IEEE T PATTERN ANAL, V38, P1612, DOI 10.1109/TPAMI.2016.2519021
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Davis J. V., 2007, ICML, P209
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gong Shaogang., 2014, Person reidentification, V1
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Guo XJ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3547
   Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jing XY, 2015, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2015.7298669
   Karanam S, 2015, IEEE I CONF COMP VIS, P4516, DOI 10.1109/ICCV.2015.513
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Li Sheng, 2015, IJCAI
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Lisanti G., 2014, Proceedings of the International Conference on Distributed Smart Cameras, p10:1
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu BD, 2013, PATTERN RECOGN, V46, P1879, DOI 10.1016/j.patcog.2012.11.018
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Matsukawa T, 2014, INT C PATT RECOG, P3975, DOI 10.1109/ICPR.2014.681
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Nie FP, 2014, PR MACH LEARN RES, V32, P1062
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Wang H, 2014, XIANG UNSUPERVISED L
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu Y, 2017, MULTIMED TOOLS APPL
   Yang Y, 2017, AAAI CONF ARTIF INTE, P2831
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang T., 2009, NIPS
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
NR 60
TC 13
Z9 15
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3553
EP 3577
DI 10.1007/s11042-017-5202-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600036
DA 2024-07-18
ER

PT J
AU Ye, F
AF Ye, Fei
TI Evolving the SVM model based on a hybrid method using swarm optimization
   techniques in combination with a genetic algorithm for medical diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE feature selection; medical diagnosis; fruit fly optimization; particle
   swarm optimization; SVM optimization
ID FINANCIAL DISTRESS MODEL; PARTICLE; RECOGNITION
AB In this paper, we introduce a novel hybrid method that uses a genetic algorithm (GA) in combination with a swarm optimization algorithm (particle swarm optimization (PSO) or fruit fly optimization algorithm (FOA)) for medical diagnosis. The proposed approaches, called GAPSO-FS and GAFOA-FS, simultaneously employ the genetic algorithm (GA) to choose the optimal feature subset and the swarm optimization algorithms (PSO/FOA) to optimize the SVM parameters. This procedure primarily comprises three synchronized parallel layers, including two optimization layers and an intermediate layer. The intermediate layer is mainly responsible for harmonizing the information from the two optimization layers and then distributing the processed information back to those layers. The major contribution of the proposed approaches is that they fully exploit the advantages of the different algorithms. The genetic algorithm (GA) excels at selecting the optimal feature subset, whereas swarm optimization algorithms (PSO/FOA) are optimal for searching the most appropriate continuous variables, including the penalty parameter C and the hyperplane parameter. We performed several groups of experiments on real-world medical cases from the UCI machine learning data repository to compare our hybrid approaches with well-known optimization techniques. The empirical results demonstrated that the proposed GAPSO-FS and GAFOA-FS can select the best SVM model parameters and a more highly relevant feature subset for the SVM classifier than a single algorithm can, thus improving the classification performance when solving a medical diagnosis problem. Therefore, the proposed approach has potential as a useful tool in medical diagnosis.
C1 [Ye, Fei] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP Ye, F (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu, Sichuan, Peoples R China.
EM 122404504@qq.com
CR Adankon MM, 2010, NEURAL COMPUT APPL, V19, P1197, DOI 10.1007/s00521-010-0358-8
   [Anonymous], POW EN SOC GEN M 200
   [Anonymous], 2016, INT J INF COMMUN TEC, DOI DOI 10.1504/IJICT.2016.077693
   [Anonymous], 2011, P INT C POWER ENERGY
   Bamakan SMH, 2016, NEUROCOMPUTING, V199, P90, DOI 10.1016/j.neucom.2016.03.031
   Bhullar P.S., 2016, P 5 INT C SOFT COMP, V436, P823, DOI [10.1007/978-981-10-0448-3_68, DOI 10.1007/978-981-10-0448-3_68]
   Bouchlaghem R., 2015, 12 INT C COMPUTER SY, P1, DOI [10.1109/AICCSA.2015.7507153, DOI 10.1109/AICCSA.2015.7507153]
   Chen HL, 2014, APPL MATH COMPUT, V239, P180, DOI 10.1016/j.amc.2014.04.039
   Chen HL, 2011, EXPERT SYST APPL, V38, P9014, DOI 10.1016/j.eswa.2011.01.120
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai HD, 2014, KNOWL-BASED SYST, V59, P159, DOI 10.1016/j.knosys.2014.01.010
   del Valle Y, 2008, IEEE T EVOLUT COMPUT, V12, P171, DOI 10.1109/TEVC.2007.896686
   Devroye Luc., 1996, A Probabilistic Theory of Pattern Recognition, P187
   Eggermont J, P 2004 ACM S APPL CO, P1001
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Jordehi AR, 2015, ARTIF INTELL REV, V43, P243, DOI 10.1007/s10462-012-9373-8
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Khare A, 2013, APPL SOFT COMPUT, V13, P2997, DOI 10.1016/j.asoc.2012.11.033
   Liming Shen, 2015, Advances in Swarm and Computational Intelligence. 6th International Conference, ICSI 2015 held in conjunction with the Second BRICS Congress, CCI 2015. Proceedings: LNCS 9141, P98, DOI 10.1007/978-3-319-20472-7_11
   Little MA, 2009, IEEE T BIO-MED ENG, V56, P1015, DOI 10.1109/TBME.2008.2005954
   Löpprich M, 2016, METHOD INFORM MED, V55, P373, DOI 10.3414/ME15-02-0019
   Lu CH, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0097-y
   Lubaib P, 2016, PROC TECH, V24, P1024, DOI 10.1016/j.protcy.2016.05.225
   Murugavel ASM, 2014, INT J BIOMED ENG TEC, V16, P343, DOI 10.1504/IJBET.2014.066229
   Pan WT, 2012, KNOWL-BASED SYST, V26, P69, DOI 10.1016/j.knosys.2011.07.001
   Selvathi D., 2016, INTELL DECIS TECHNOL, P1, DOI DOI 10.3233/IDT-160260D
   Shen L, 2016, KNOWL-BASED SYST, V96, P61, DOI 10.1016/j.knosys.2016.01.002
   STREET WN, 1993, P SOC PHOTO-OPT INS, V1905, P861, DOI 10.1117/12.148698
   Vijayan A, 2016, PROC TECH, V24, P1366, DOI 10.1016/j.protcy.2016.05.150
   Wang FS, 2014, APPL MECH MAT, V556-562, P3965
   Wang L, 2016, KNOWL-BASED SYST, V97, P158, DOI 10.1016/j.knosys.2016.01.006
   Wenwen L., 2014, Int. J. Multimed. Ubiquitous Eng., V9, P181, DOI DOI 10.14257/IJMUE.2014.9.11.18
   Weronika Piatkowska MJ, 2011, INT WORKSH MACH LEAR, P362
   WOLBERG WH, 1990, P NATL ACAD SCI USA, V87, P9193, DOI 10.1073/pnas.87.23.9193
   Zainuddin N, 2016, LECT NOTES ARTIF INT, V9799, P269, DOI 10.1007/978-3-319-42007-3_23
   Zheng XL, 2014, KNOWL-BASED SYST, V57, P95, DOI 10.1016/j.knosys.2013.12.011
NR 36
TC 15
Z9 16
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3889
EP 3918
DI 10.1007/s11042-016-4233-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600056
DA 2024-07-18
ER

PT J
AU Yue, Q
   Ma, CW
AF Yue, Qi
   Ma, Caiwen
TI Hyperspectral data classification based on flexible momentum deep
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Deep neural network; Elastic momentum; Hyperspectral
   data classification; Target detection; Support vector machine (SVM)
AB Classification is a hot topic in hyperspectral remote sensing community. In the last decades, numerous effort has been concentrate on the classification problem. However, most of the methods accuracy is not high enough due to the fact that they do not extract features in a deep manner. In this paper, a new hyperspectral data classification skeleton based on exponential flexible momentum deep convolution neural network (EFM-CNN) is proposed. First, the fitness of convolution neural network is substantiated by following classical spectral information-based classification. Then, a novel deep architecture is proposed, which is a hybrid of principle component analysis (PCA), improved convolution neural network based on exponential flexible momentum and support vector machine (SVM). Experimental results indicate that the classifier can effectively improve the accuracy with the state-of-the-art algorithms. And compared with homologous parameters momentum updating methods such as adaptive momentum method, standard momentum gradient method and elastic momentum method, on LeNet5 net and multiple neural network, the accuracy obtained of proposed algorithm increases by 2.6% and 6.5% on average respectively.
C1 [Yue, Qi] Xian Univ Posts & Telecommun, Xian 710121, Shaanxi, Peoples R China.
   [Yue, Qi; Ma, Caiwen] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
   [Yue, Qi; Ma, Caiwen] Univ Chinese Acad Sci, Beijing 100039, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Chinese Academy of
   Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP Yue, Q (corresponding author), Xian Univ Posts & Telecommun, Xian 710121, Shaanxi, Peoples R China.; Yue, Q (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.; Yue, Q (corresponding author), Univ Chinese Acad Sci, Beijing 100039, Peoples R China.
EM ganshi3237@yeah.net
RI li, liu/JXN-7328-2024
FU National 863 High Tech Research and Development Program, China
   [2010AA7080302]
FX The study was supported by "National 863 High Tech Research and
   Development Program, China (Grant No. 2010AA7080302)".
CR [Anonymous], 2013, P INT C LEARN REPR
   [Anonymous], 2014, PROC IEEE C COMPUTER, P580, DOI [10.1109/CVPR.2014.81, DOI 10.1109/CVPR.2014.81]
   [Anonymous], TR2010003 UTML DEP C
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Ciresan DC, 2011, PROC INT CONF DOC, P1135, DOI 10.1109/ICDAR.2011.229
   Foody GM, 2004, IEEE T GEOSCI REMOTE, V42, P1335, DOI 10.1109/TGRS.2004.827257
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Hege K, 2003, P SOC PHOTO-OPT INS, V5159, P380, DOI 10.1117/12.506426
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H., 2007, An empirical evaluation of deep architectures on problems with many factors of variation, V227, P473
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Rajan S, 2008, IEEE T GEOSCI REMOTE, V46, P1231, DOI 10.1109/TGRS.2007.910220
   Sakano H, 2012, LECT NOTES COMPUT SC, V7626, P409, DOI 10.1007/978-3-642-34166-3_45
   Salakhutdinov R., 2009, AISTATS
   Van der Meer F., 2004, INT J APPL EARTH OBS, V5, P55, DOI DOI 10.1016/J.JAG.2003.09.001
   Yu D., 2009, NIPS WORKSH DEEP LEA, P1848
   Yuen PWT, 2010, IMAGING SCI J, V58, P241, DOI 10.1179/174313110X12771950995716
   Zhu Z, 2012, REMOTE SENS ENVIRON, V117, P72, DOI 10.1016/j.rse.2011.07.020
NR 26
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4417
EP 4429
DI 10.1007/s11042-017-4734-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500021
DA 2024-07-18
ER

PT J
AU Parah, SA
   Sheikh, JA
   Akhoon, JA
   Loan, NA
   Bhat, GM
AF Parah, Shabir A.
   Sheikh, Javaid A.
   Akhoon, Jahangir A.
   Loan, Nazir A.
   Bhat, Ghulam M.
TI Information hiding in edges: A high capacity information hiding
   technique using hybrid edge detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Canny edge detection; Prewitt edge detection; Pixel value differencing
   (PVD); Hybrid edge detection; Human visual system (HVS); Ciphering
ID IMAGES
AB The multimedia security is becoming more and more important as the data being exchanged on the Internet is increasing exponentially. Though cryptography is one of the methods which is used to secure the data during transit, but the camouflaged appearance of the scrambled data alerts the adversary about some critical information being shared. In such a scenario, steganography has been used as an alternate solution to secure the secret information. In this paper a color image steganographic algorithm based on hybrid edge detection is proposed. The color image is partitioned into constituent Red (R), Green (G) and Blue (B) planes. Hybrid edge detection is used for finding the edge and non-edge pixels of Green and Blue planes of cover image. The Green and Blue planes are used for hiding the data while Red plane holds the pixel status (whether edge or non-edge) of these planes. The RC4 encryption algorithm is used to encrypt secret message before embedding it in the cover image to enhance security of the secret data. A fragile watermark/logo (whose size is less than 1% of total secret data) has been embedded, besides secret data in the cover image, to facilitate content authentication and early tamper detection. At the receiver, firstly logo is extracted. If it is same as one embedded at transmitter, indicating that secret data has not been altered during transit, secret data is extracted. Otherwise (if extracted logo is not same as used at input) the receiver does not waste critical time to extract compromised data but sends an automatic retransmission request. Experimental investigations reveal that the proposed scheme is capable of providing high quality of stego-images for a fairly high pay load. A comparison of the proposed technique with some state of art schemes substantiates the above arguments.
C1 [Parah, Shabir A.; Sheikh, Javaid A.; Akhoon, Jahangir A.; Loan, Nazir A.; Bhat, Ghulam M.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
EM shabireltr@gmail.com
RI Parah, Shabir/AAB-7603-2021
OI Parah, Shabir/0000-0001-5983-0912; Sheikh, Javaid A/0000-0003-3113-3802;
   Bhat, Ghulam Mohiuddin/0000-0001-9106-4699
CR Amanpreet K, 2012, INT J ENG INNOV TECH, V1, P2
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2013, PROC QUALITY RELIABI
   [Anonymous], 2012, ELIXIR COMP SCI ENG
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chung MW, 2007, J SYST STWARE, V81, P150
   Dawson E., 2002, EVALUATION RC4 UNPUB
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Kwong CM, 2004, COMPUT J PATTERN REC, V37, P469
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Parah SA, 2017, MULTIDIM SYST SIGN P, V28, P549, DOI 10.1007/s11045-015-0358-z
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Saurabh S, 2014, IMPROVED HASH BASED, V14, P7
   Schyndel R. G., 1996, P IEEE INT C IM PROC, V2, P86
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   Tove M J., 2008, An Introduction to the Visual System
   Wang RZ, 2000, ELECTRON LETT, V36, P2069, DOI 10.1049/el:20001429
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yu JG, 2008, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, P563, DOI 10.1109/ITNG.2008.101
NR 22
TC 45
Z9 45
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 185
EP 207
DI 10.1007/s11042-016-4253-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400009
DA 2024-07-18
ER

PT J
AU Song, CL
   Sang, J
   Sudirman, S
AF Song, Chunlin
   Sang, Jie
   Sudirman, Sud
TI A buyer-seller watermarking protocol for digital secondary market
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Watermarking protocols; Digital products;
   Copyright protection; Digital secondary market; Cryptography
ID IMAGE
AB In the digital right management value chain, digital watermarking technology plays a very important role in digital product's security, especially on its usage tracking and copyrights infringement authentication. However, watermark procedures can only effectively support copyright protection processes if they are applied as part of an appropriate watermark protocol. In this regard, a number of watermark protocols have been proposed in the literature and have been shown to facilitate the use of digital watermarking technology as copyright protection. One example of such protocols is the anonymous buyer-seller watermarking protocol. Although there are a number of protocols that have been proposed in the literature and provide suitable solutions, they are mainly designed as a watermarking protocol for the first-hand market and are unsuitable for second-hand transactions. As the complexity of online transaction increases, so does the size of the digital second-hand market. In this paper, we present a new buyer-seller watermark protocol that addresses the needs of customer's rights problem in the digital secondary market. The proposed protocol consists of five sub-protocols that cover the registration process, watermarking process for the first, second and third-hand transactions as well as the identification & arbitration processes. This paper provides analysis that compares the proposed protocols with existing state-of-the-arts and shows that it has met not only all the buyer's and seller's requirements in the traditional sense but also accommodates the same requirements in the secondary market.
C1 [Song, Chunlin; Sang, Jie] Jiangnan Univ, Sch Comp Sci, Wuxi, Peoples R China.
   [Sudirman, Sud] Liverpool John Moores Univ, Dept Comp Sci, Liverpool, Merseyside, England.
C3 Jiangnan University; University of Liverpool; Liverpool John Moores
   University
RP Song, CL (corresponding author), Jiangnan Univ, Sch Comp Sci, Wuxi, Peoples R China.
EM chunlin.song@hotmail.com; sarlly2016@hotmail.com; s.sudirman@ljmu.ac.uk
RI Sudirman, Sud/AAF-6901-2020
OI Sudirman, Sud/0000-0003-4083-0810
FU Jiangnan University of Science & Technology Young Scholar Grant
   [JUSRP11462]; Jiangnan University Fund Grant [JUSRP51414A]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD); Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET)
FX The work was sponsored by Jiangnan University of Science & Technology
   Young Scholar Grant (No. JUSRP11462); Key Project of Jiangnan University
   Fund Grant (No. JUSRP51414A); the Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD) and Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET).
CR [Anonymous], 2009, FULLY HOMOMORPHIC EN, DOI 10.1145/1536414.1536440
   Chen CL, 2015, IETE TECH REV, V32, P104, DOI 10.1080/02564602.2014.983565
   Cox I., 2001, Digital Watermarking
   Frattolillo F, 2007, IEEE T INF FOREN SEC, V2, P350, DOI 10.1109/TIFS.2007.903849
   Frattolillo F, 2016, ACM T WEB, V10, DOI 10.1145/2856036
   Frattolillo F, 2015, COMPUT J, V58, P944, DOI 10.1093/comjnl/bxu015
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Gittleson K, 2012, US COURT RULE REDIGI
   Hu DF, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P105, DOI 10.1109/MINES.2009.132
   Hu ZQ, 2014, CHINA COMMUN, V11, P114, DOI 10.1109/CC.2014.6880467
   Katzenbeisser S, 2001, 12TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P815, DOI 10.1109/DEXA.2001.953156
   Khan KM, 2010, IT PROF, V12, P20, DOI 10.1109/MITP.2010.128
   Khan M, 2011, 17 AS PAC C COMM MAL
   Langr D, 2016, IEEE T PARALL DISTR, V27, P428, DOI 10.1109/TPDS.2015.2401575
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6
   Ochi H, 2013, IEEE INT SOC CONF, P262, DOI 10.1109/SOCC.2013.6749698
   Qiao LT, 1998, J VIS COMMUN IMAGE R, V9, P194, DOI 10.1006/jvci.1998.0391
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Ren YJ, 2015, J INTERNET TECHNOL, V16, P317, DOI 10.6138/JIT.2015.16.2.20140918
   Rial A, 2011, IEEE T INF FOREN SEC, V6, P202, DOI 10.1109/TIFS.2010.2095844
   Rial A, 2010, IEEE T INF FOREN SEC, V5, P920, DOI 10.1109/TIFS.2010.2072830
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Waleed J, 2014, INT J SECUR APPL, V8, P349, DOI 10.14257/ijsia.2014.8.5.31
   Wang X, 2016, THEOR APPL CLIMATOL, V126, P1, DOI 10.1007/s00704-015-1550-7
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yuwei Peng, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P2095, DOI 10.1109/CSSS.2012.521
   [臧国全 Zang Guoquan], 2010, [情报科学, Information Science], V28, P1737
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 36
TC 3
Z9 3
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 225
EP 249
DI 10.1007/s11042-016-4247-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yang, GY
   Li, XL
   Wang, JW
   Guo, ZM
AF Yang, Guangyuan
   Li, Xiaolong
   Wang, Jinwei
   Guo, Zongming
TI Efficient large payloads ternary matrix embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ternary matrix embedding; Matrix construction; Sub-optimal search;
   Embedding performance; Computational complexity
ID DATA HIDING SCHEME; WET PAPER; IMAGE STEGANOGRAPHY; STEGANALYSIS
AB Matrix embedding (ME) can be exploited to improve the embedding efficiency for steganography by making fewer changes to the cover data. In ME, the sender and recipient agree on a parity check matrix (PCM) in advance. The PCM will be used by the sender to embed secret message into the cover data and later by the decoder to extract the embedded message. The embedding performance of ME is greatly influenced by the PCM thus the choice of PCM is crucial for ME. On the other hand, since larger sized PCM usually leads to higher embedding efficiency, how to keep the balance between the computational complexity and the embedding efficiency is also an important problem of ME. Based on these considerations, an efficient ternary ME method for large payloads data embedding is proposed in this paper. We utilize a specific matrix construction for PCM to improve embedding efficiency and a sub-optimal search strategy to reduce the computational complexity. The experimental results show that the proposed method achieves good embedding efficiency at low time cost and it outperforms some state-of-the-art works. For example, for a cover image with 512 x 512 pixels at an embedding rate of 1 bit per pixel, the proposed method can be implemented within 0.5 second in a personal computer with a rather high embedding efficiency as 3.89.
C1 [Yang, Guangyuan; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Li, Xiaolong] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Peking University; Beijing Jiaotong University; Nanjing University of
   Information Science & Technology
RP Guo, ZM (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
EM yanggy@pku.edu.cn; lixl@bjtu.edu.cn; wjwei_2004@163.com;
   guozongming@pku.edu.cn
RI li, xiao/GSN-6181-2022; Yang, Guangyuan/B-9256-2012; Li,
   xiaolong/GRS-9148-2022
FU National Science Foundation of China [61572052, U1636206, 61272421];
   PAPD fund; CICAEET fund
FX This work is supported by the National Science Foundation of China (Nos.
   61572052, U1636206 and 61272421), the PAPD fund, and the CICAEET fund.
CR [Anonymous], P 12 INF HID WORKSH
   Bierbrauer J, 2008, LECT NOTES COMPUT SC, V4920, P1, DOI 10.1007/978-3-540-69019-1_1
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Crandall R., 1998, SOME NOTES STEGANOGR
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J., 2006, International Workshop on Information Hiding, P282, DOI DOI 10.1007/978-3-540-74124-4-19
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao YK, 2009, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2009.5414128
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Iranpour M, 2015, MULTIMED TOOLS APPL, V74, P6657, DOI 10.1007/s11042-014-1921-6
   Kuo W.C., 2015, J INF HIDING MULTIME, V6, P1167
   Kuo WC, 2016, INFORM PROCESS LETT, V116, P183, DOI 10.1016/j.ipl.2015.08.003
   Kuo WC, 2015, AEU-INT J ELECTRON C, V69, P1574, DOI 10.1016/j.aeue.2015.07.007
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li Jian., 2016, Mobile Information Systems, P1, DOI [10.1155/2016/4502867, DOI 10.1007/S00170-016-9066-6, DOI 10.1155/2016/4502867]
   Li XL, 2015, INFORM SCIENCES, V324, P257, DOI 10.1016/j.ins.2015.06.046
   Li XL, 2013, SIGNAL PROCESS, V93, P2529, DOI 10.1016/j.sigpro.2013.03.029
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Van Dijk M., 2001, P 22 S INF COMM THEO, P147
   Wang C, 2012, IEEE T INF FOREN SEC, V7, P346, DOI 10.1109/TIFS.2011.2164907
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yunkai Gao, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P161, DOI 10.1109/IIH-MSP.2009.59
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 32
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1605
EP 1622
DI 10.1007/s11042-016-4301-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400006
DA 2024-07-18
ER

PT J
AU Choi, HY
   Jang, HU
   Son, J
   Lee, HK
AF Choi, Hak-Yeol
   Jang, Han-Ul
   Son, Jeongho
   Lee, Heung-Kyu
TI Blind 3D mesh watermarking based on cropping-resilient synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; 3D mesh watermarking; Anti-cropping 3D mesh
   watermarking; Cropping-resilient watermarking
ID ROBUST
AB This paper proposes a novel anti-cropping blind 3D mesh watermarking method. Although there have been many mesh watermarking studies, methods with robustness to cropping attack are rare. Existing anti-cropping watermarking methods show only slight robustness to cropping and signal processing attack. Cropping is one of the most severe attack, since it significantly undermines the synchronization of watermarking. In this paper, we solve the synchronization problem in a blind environment which is a core part of the anti-cropping watermarking method using local shape-based synchronization. The proposed local shape-based synchronization is robust to not only cropping attack, but also similarity and distortion attack, since it uses the shape information of the mesh, not the surface information. In the watermark embedding process, the distortion from the watermark was minimized by using the method of spreading based on segmented bin. Additionally, the method has higher security than the existing method. In the experimental results, the proposed method shows high robustness against common signal processing attacks as well as severe cropping attacks with high invisibility.
C1 [Choi, Hak-Yeol; Jang, Han-Ul; Son, Jeongho; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
EM hychoi@mmc.kaist.ac.kr; hanulj@mmc.kaist.ac.kr; sonjh@kaist.ac.kr;
   hklee@mmc.kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B2009595]; Institute for Information & communications
   Technology Promotion (IITP) - Korean government (MSIP) [R0126-15-1024]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No. 2016R1A2B2009595)
   and by the Institute for Information & communications Technology
   Promotion (IITP) grant funded by the Korean government (MSIP) (No.
   R0126-15-1024, Managerial Technology Development and Digital Contents
   Security of 3D Printing based on Micro Licensing Technology).
CR Adrian G, 2006, IEEE T IMAGE PROCESS, V15, P687
   Alface PR, 2007, IEEE IMAGE PROC, P2717
   Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Hou J.U., 2015, P 3 ACM WORKSHOP INF, P115
   Kai Wang, 2010, Proceedings of the Shape Modeling International (SMI 2010), P231, DOI 10.1109/SMI.2010.33
   Konstantinides JM, 2009, IEEE T MULTIMEDIA, V11, P23, DOI 10.1109/TMM.2008.2008913
   Lavoue G, 2006, SPIE APPL DIGITAL IM
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Liu Y, 2012, IEEE T INF FOREN SEC, V7, P1459, DOI 10.1109/TIFS.2012.2204251
   Mun SM, 2015, INT C 3D IM IC3D, P14, DOI DOI 10.1109/IC3D.2015.7391820
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Rolland-Neviere Xavier, 2014, IEEE Transactions on Information Forensics and Security, V9, P1491, DOI 10.1109/TIFS.2014.2336376
   Rolland-Nevière X, 2015, INT CONF ACOUST SPEE, P1702, DOI 10.1109/ICASSP.2015.7178261
   Sales MM, 2011, SPIE MEDIA WATERMARK, V7880, P7880
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P113, DOI 10.1109/TVCG.2004.1260763
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T INF FOREN SEC, V3, P620, DOI 10.1109/TIFS.2008.2007229
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Yu ZQ, 2003, PATTERN RECOGN, V36, P2603, DOI 10.1016/S0031-3203(03)00086-4
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
NR 25
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26695
EP 26721
DI 10.1007/s11042-016-4194-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500052
DA 2024-07-18
ER

PT J
AU Khalifeh, AF
   Al-Taee, MA
   Murshed, AN
AF Khalifeh, Ala' F.
   Al-Taee, Majid A.
   Murshed, Ayman N.
TI Network-status aware quality adaptation algorithm for improving
   real-time video streaming over the internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality; Video rate adaptation; Real-time video streaming; Video
   conferencing; Video over internet; RTMFP
ID WIRELESS CHANNELS; TRANSMISSION; COMPRESSION; IMAGE
AB Video streaming over Internet has been gaining momentum and several quality adaptation schemes have been reported to improve quality of the streamed videos. Most of these schemes focus on adjusting the video encoding rate to match certain network conditions. This paper presents a new quality adaptation algorithm for real-time video streaming over Internet. The proposed algorithm is based upon simultaneous adaptation of multiple key parameters such as video frame rate, resolution, and frame quality to achieve the best possible video quality and minimize possibility of service interruption in lossy networks. Furthermore, the current network status and motion of the streamed video sequence have also been taken into account throughout the adaptation process. A video conferencing test-bed which incorporates the Adobe Flash Real-Time Media Flow Protocol (RTMFP) is built and utilized to investigate the effect of various combinations of the video parameters under study on the quality of sample video clips streamed at slow, medium and fast motions. A quality-adaptation algorithm based on experimental investigations is then developed and its performance is assessed using both subjective and objective evaluations. The obtained results and observations demonstrate superior performance of the developed adaptation algorithm as compared to equivalent algorithms with fixed video quality settings at similar test conditions.
C1 [Khalifeh, Ala' F.] German Jordanian Univ, Sch Elect Engn & IT, Amman 213146, Jordan.
   [Al-Taee, Majid A.] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3GJ, Merseyside, England.
   [Murshed, Ayman N.] Univ Siegen, Dept Elect Engn & Comp Sci, Siegen, Germany.
C3 German-Jordanian University; University of Liverpool; Universitat Siegen
RP Khalifeh, AF (corresponding author), German Jordanian Univ, Sch Elect Engn & IT, Amman 213146, Jordan.
EM ala.khalifeh@gju.edu.jo
RI Khalifeh, Ala/ACU-7567-2022
OI Khalifeh, Ala/0000-0003-3600-8090; Al-Taee, Majid/0000-0002-3252-3637
FU Jordanian Scientific Research Fund [ICT/1/04/2014]
FX The authors would like to thank the Jordanian Scientific Research Fund
   (grant no. ICT/1/04/2014) for funding this project throughout the
   different phases of its development lifecycle.
CR Annadurai S., 2007, FUNDAMENTAL DIGITAL
   [Anonymous], 2000, APS COMM NETW MULTIM
   [Anonymous], SUBJ VID QUAL ASS ME
   Arregoces M., 2003, DATA CTR FUNDAMENTAL
   Baset SA, 2006, P INFOCOM 25 IEEE IN, DOI [10.1109/INFOCOM.2006.312, DOI 10.1109/INFOCOM.2006.312]
   Braun T, 1997, IEEE MULTIMEDIA, V4, P85, DOI 10.1109/93.621586
   Chan A, 2010, P IEEE INFOCOM, DOI [10.1109/INFCOM.2010.5461979, DOI 10.1109/INFCOM.2010.5461979]
   Choi J, 2012, IEEE COMMUN SURV TUT, V14, P156, DOI 10.1109/SURV.2011.030811.00051
   Ciavattone L, 2003, IEEE COMMUN MAG, V41, P90, DOI 10.1109/MCOM.2003.1204753
   Hadar O, 2004, P 2 INT C INF TECHN, DOI [10.1109/ITRE.2004.1393644, DOI 10.1109/ITRE.2004.1393644]
   Hsu CY, 1999, IEEE J SEL AREA COMM, V17, P756, DOI 10.1109/49.768193
   Jammeh E, 2012, TELECOMMUN SYST, V49, P99, DOI 10.1007/s11235-010-9356-5
   Khalifeh A, 2010, IEEE T MULTIMEDIA, V12, P204, DOI 10.1109/TMM.2010.2041096
   Khan Asiya, 2009, Journal of Multimedia, V4, P228, DOI 10.4304/jmm.4.4.228-239
   Koul M, 2008, TECHNICAL REPORT
   Murshed A, 2013, P IEEE APPL EL ENG C
   Nejati N, 2010, IEEE J SEL AREA COMM, V28, P510, DOI 10.1109/JSAC.2010.100421
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shmueli R, 2008, IEEE T BROADCAST, V54, P628, DOI 10.1109/TBC.2008.2001242
   Singh K, 2011, ARXIV11070011
   Sudarshan S, 2013, REAL TIME VIDEO SEGM
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Trestian R, 2013, IEEE T BROADCAST, V59, P340, DOI 10.1109/TBC.2013.2244790
   Uti V, 2009, P 21 IEEE INT C TOOL, DOI [10.1109/ICTAI.2009.34, DOI 10.1109/ICTAI.2009.34]
   Venkata M.G., 2009, IPDPS 2009. IEEE International Symposium on Parallel Distributed Processing, P1
   Wu H, 2006, P P IASTED INT C INT
NR 28
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26129
EP 26152
DI 10.1007/s11042-016-3999-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500029
DA 2024-07-18
ER

PT J
AU Kim, H
   Matuszka, T
   Kim, JI
   Kim, J
   Woo, W
AF Kim, Hayun
   Matuszka, Tamas
   Kim, Jea-In
   Kim, Jungwha
   Woo, Woontack
TI Ontology-based mobile augmented reality in cultural heritage sites:
   information modeling and user study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Contextual information; Cultural heritage; Heritage
   site; Mobile application; Ontology
ID SYSTEM
AB Augmented reality (AR) has received much attention in the cultural heritage domain as an interactive medium for requesting and accessing information regarding heritage sites. In this study, we developed a mobile AR system based on Semantic Web technology to provide contextual information about cultural heritage sites. Most location-based AR systems are designed to present simple information about a point of interest (POI), but the proposed system offers information related to various aspects of cultural heritage, both tangible and intangible, linked to the POI. This is achieved via an information modeling framework where a cultural heritage ontology is used to aggregate heterogeneous data and semantically connect them with each other. We extracted cultural heritage data from five web databases and modeled contextual information for a target heritage site (Injeongjeon Hall and its vicinity in Changdeokgung Palace in South Korea) using the selected ontology. We then implemented a mobile AR application and conducted a user study to assess the learning and engagement impacts of the proposed system. We found that the application provides an agreeable user experience in terms of its affective, cognitive, and operative features. The results of our analysis showed that specific usage patterns were significant with regard to learning outcomes. Finally, we explored how the study's key findings can provide practical design guidance for system designers to enhance mobile AR information systems for heritage sites, and to show system designers how to support particular usage patterns in order to accommodate specific user experiences better.
C1 [Kim, Hayun; Kim, Jea-In; Kim, Jungwha; Woo, Woontack] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon, South Korea.
   [Matuszka, Tamas] Eotvos Lorand Univ, Dept Informat Syst, Budapest, Hungary.
C3 Korea Advanced Institute of Science & Technology (KAIST); Eotvos Lorand
   University
RP Kim, H (corresponding author), Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon, South Korea.
EM hayunkim@kaist.ac.kr; tomintt@inf.elte.hu; jeainkim86@kaist.ac.kr;
   jungwhakim@kaist.ac.kr; wwoo@kaist.ac.kr
RI Wang, Jiahui/GRR-4965-2022; Matuszka, Tamás/I-4854-2019; Woo,
   Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421; Matuszka, Tamas/0009-0001-8827-2275
FU Ministry of Culture, Sports and Tourism(MCST); Korea Creative Content
   Agency(KOCCA) in the Culture Technology(CT) Research & Development
   Program
FX This research is supported by Ministry of Culture, Sports and
   Tourism(MCST) and Korea Creative Content Agency(KOCCA) in the Culture
   Technology(CT) Research & Development Program 2014.
CR Akker CVD, 2013, P 5 ANN ACM WEB SCI, DOI [10.1145/2464464.2464491, DOI 10.1145/2464464.2464491]
   Akker CVD, 2011, P 3 INT WEB SCI C WE, DOI [10.1145/2527031.2527039, DOI 10.1145/2527031.2527039]
   Almeida MB, 2009, APPL ONTOL, V4, P245, DOI 10.3233/AO-2009-0070
   Balduini M, 2012, J WEB SEMANT, V16, P33, DOI 10.1016/j.websem.2012.06.004
   Barak M, 2009, COMPUT EDUC, V53, P841, DOI 10.1016/j.compedu.2009.05.004
   Becker Christian, 2008, P SEMANTIC WEB CHALL, P13
   Boeuf P L., 2008, Int J Cult Prop, V15, P377, DOI DOI 10.1017/S0940739108080417
   Chianese A, 2017, FUTURE GENER COMP SY, V66, P187, DOI 10.1016/j.future.2016.04.015
   Cuomo S, 2017, EXPERT SYST APPL, V79, P101, DOI 10.1016/j.eswa.2017.02.034
   da Silva D.P., 2015, J APPL COMPUT RES, V4, P23, DOI [10.4013/jacr.2014.41.03, DOI 10.4013/JACR.2014.41.03]
   Dähne P, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P263, DOI 10.1109/ISMAR.2002.1115103
   Fresa A, 2013, INT J HUMANIT ARTS C, V7, P29, DOI 10.3366/ijhac.2013.0058
   Kelley MJ, 2014, GEOJOURNAL, V79, P15, DOI 10.1007/s10708-013-9482-1
   Kim E, 2016, LECT NOTES COMPUT SC, V9735, P278, DOI 10.1007/978-3-319-40397-7_27
   Kim H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P468, DOI 10.1109/SITIS.2016.79
   Kim S, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P275, DOI 10.1109/DigitalHeritage.2015.7419508
   Lee GA, 2013, 2013 IE INT S MIX AU, DOI [10.1109/ismar-amh.2013.6671264, DOI 10.1109/ISMAR-AMH.2013.6671264]
   Lee GA, 2012, INT SYM MIX AUGMENT
   Lombard M., 2006, J. Comput. Mediat. Commun, V3, P72, DOI [DOI 10.1111/J.1083-6101.1997.TB00072.X, https://doi.org/10.1111/j.1083-6101.1997.tb00072.x]
   Louw M, 2013, INT J DESIGNS LEARNI, V4
   Martínez JL, 2015, INT ARCH PHOTOGRAMM, V40-5, P61, DOI 10.5194/isprsarchives-XL-5-W4-61-2015
   Matuszka T., 2014, Int. J. Comput. Inf. Sci. Eng, V8, P32
   Papagiannakis G, 2005, COMPUT ANIMAT VIRT W, V16, P11, DOI 10.1002/cav.53
   Park NY, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P484, DOI 10.1109/SITIS.2016.81
   van Aart C, 2010, LECT NOTES ARTIF INT, V6317, P257, DOI 10.1007/978-3-642-16438-5_18
   Vert B., 2014, ISWC, P185
   Vert S, 2014, COMM COM INF SC, V465, P324
   Wetzel R, 2011, MENSCH COMPUTER, V2011, P487, DOI [10.1524/9783486712742.487, DOI 10.1524/9783486712742.487]
NR 28
TC 29
Z9 29
U1 13
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26001
EP 26029
DI 10.1007/s11042-017-4868-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500024
DA 2024-07-18
ER

PT J
AU Kim, PW
   Lee, S
AF Kim, Pyoung Won
   Lee, Suzie
TI Audience real-time bio-signal-processing-based computational
   intelligence model for narrative scene editing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Continuity editing; Electrodermal activity (EDA); Galvanic skin response
   (GSR); Narrative immersion; Psychical distance
ID IMAGE MOTION; TELEVISION; AROUSAL; MEMORY; INFORMATION; ATTENTION;
   DISTANCE; EMOTION; SPORTS; NEWS
AB Narrative scene editing is carried out by directors as an eidetic technique. Continuity editing is a style of editing used in film making to make films as realistic as possible for the audience. While non-continuity editing (e.g., flashbacks, jump cuts, montages, etc.) is also a critical factor that reflects the character of a director, most scenes demand continuity editing to maximize the audience's narrative immersion. In this paper, we present an algorithm for continuity editing that determines the size of a shot (field of view) by evaluating the psychical distance between the characters and viewers via the measurement of electrodermal activity (or the galvanic skin response). The use of this continuity editing algorithm is expected to result in more audience-friendly videos by reflecting the level of identification between the actors and the audience.
C1 [Kim, Pyoung Won] Incheon Natl Univ, Korean Language Educ, Coll Educ, 12 Gaetbeol Ro, Incheon, South Korea.
   [Lee, Suzie] Korean Minjok Leadership Acad, 800 Bonghwa Ro, Hoengseong Gun, Gangwon Do, South Korea.
C3 Incheon National University
RP Kim, PW (corresponding author), Incheon Natl Univ, Korean Language Educ, Coll Educ, 12 Gaetbeol Ro, Incheon, South Korea.
EM pwkim@inu.ac.kr
OI Kim, Pyoung Won/0000-0002-3621-9480
FU Incheon National University
FX This work was supported by the Incheon National University Research
   Grant in 2014.
CR Angelini JR, 2008, J BROADCAST ELECTRON, V52, P16, DOI 10.1080/10934520701820752
   [Anonymous], 1976, Grammar of the film language
   [Anonymous], 1985, TECHNIQUE TELEVISION
   [Anonymous], 2001, ANXIETY ITS DISORDER
   [Anonymous], 2013, Film Art: An Introduction
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Booth WayneC., 1983, The Rhetoric of Fiction, V2d
   Bullough E, 1912, BRIT J PSYCHOL, V5, P87, DOI 10.1111/j.2044-8295.1912.tb00057.x
   DILLARD JP, 1993, COMMUN RES, V20, P637, DOI 10.1177/009365093020005001
   Figner B., 2011, A Handbook of Process Tracing Methods for Decision Research, P163, DOI [10.4324/9780203875292, DOI 10.4324/9780203875292-18/USING-SKIN-CONDUCTANCE-JUDGMENT-DECISION-MAKING-RESEARCH-MICHAEL-SCHULTE-MECKLENBECK-ANTON-KUEHBERGER-JOSEPH-JOHNSON-JOSEPH-JOHNSON]
   Fox S. I., 2008, HUMAN PHYSL
   Garcia TB., 2011, Introduction to 12-Lead ECG: The Art of Interpretation
   GERBER GL, 1971, J CONSULT CLIN PSYCH, V36, P370, DOI 10.1037/h0031108
   Gustavo M, 2010, FILMMAKERS EYE LEAR
   Hasson U, 2008, PROJECTIONS, V2, P1, DOI 10.3167/proj.2008.020102
   John, 2006, CONVERSATION ANAL, VI, pxxxiv
   KIPPER P, 1986, J BROADCAST ELECTRON, V30, P295
   Lang A, 2005, J BROADCAST ELECTRON, V49, P3, DOI 10.1207/s15506878jobem4901_2
   LANG A, 1995, J BROADCAST ELECTRON, V39, P313, DOI 10.1080/08838159509364309
   Lang A, 2000, J BROADCAST ELECTRON, V44, P94, DOI 10.1207/s15506878jobem4401_7
   양희경, 2009, [Science of Emotion & Sensibility, 감성과학], V12, P161
   MATTES J, 1982, J BROADCASTING, V26, P553, DOI 10.1080/08838158209364024
   Monaco James., 1981, HOW TO READ A FILM
   Rada JA, 2005, J BROADCAST ELECTRON, V49, P65, DOI 10.1207/s15506878jobem4901_5
   Ravaja N, 2004, J BROADCAST ELECTRON, V48, P108, DOI 10.1207/s15506878jobem4801_6
   Sherburne Donald W., 1961, A Whiteheadean Aesthetic
   Simons RF, 2000, PSYCHOPHYSIOLOGY, V37, P706, DOI 10.1017/S004857720000158X
   van der Molen JHW, 2004, J BROADCAST ELECTRON, V48, P89, DOI 10.1207/s15506878jobem4801_5
   Zettl H., 1998, Sight, Sound, Motion: Applied Media Aesthetics, V3rd
NR 29
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24833
EP 24845
DI 10.1007/s11042-016-4144-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300014
DA 2024-07-18
ER

PT J
AU Liu, AN
   Zhao, ZY
   Zhang, CQ
   Su, YT
AF Liu, Anan
   Zhao, Zhengyu
   Zhang, Chengqian
   Su, Yuting
TI Median filtering forensics in digital images based on frequency-domain
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Median filtering detection; Feature extraction;
   Frequency domain; Copy-paste forgery
ID TRACES
AB Tampering detection has been increasingly attracting attention in the field of digital forensics. As a popular nonlinear smoothing filter, median filtering is often used as a post-processing operation after image forgeries such as copy-paste forgery (including copy-move and image splicing), which is of particular interest to researchers. To implement the blind detection of median filtering, this paper proposes a novel approach based on a frequency-domain feature coined the annular accumulated points (AAP). Experimental results obtained on widely used databases, which consists of various real-world photos, show that the proposed method achieves outstanding performance in distinguishing median-filtered images from original images or images that have undergone other types of manipulations, especially in the scenarios of low resolution and JPEG compression with a low quality factor. Moreover, our approach remains reliable even when the feature dimension decreases to 5, which is significant to save the computing time required for classification, demonstrating its great advantage to be applied in real-time processing of big multimedia data.
C1 [Liu, Anan; Zhao, Zhengyu; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Zhang, Chengqian] Southwest Petr Univ, Sch Elect Engn & Informat, Chengdu 610500, Sichuan, Peoples R China.
C3 Tianjin University; Southwest Petroleum University
RP Su, YT (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM liuanan@tju.edu.cn; zyzhao2014@tju.edu.cn; zhangcqj@tju.edu.cn;
   ytsu@tju.edu.cn
RI Zhao, Zhengyu/GYD-5093-2022
FU National Natural Science Foundation of China [61472275, 61572356];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [15JCYBJC16200]; China Scholarship Council [201506255073];
   Elite Scholar Program of Tianjin University [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61472275, 61572356), the Tianjin Research Program
   of Application Foundation and Advanced Technology (15JCYBJC16200), a
   grant from the China Scholarship Council (201506255073), and a grant
   from the Elite Scholar Program of Tianjin University (2014XRG-0046).
CR [Anonymous], 2004, ELECT IMAGING
   Bas P., 2007, Bows-2
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Gloe T., 2010, Proceedings of the ACM Symposium on Applied Computing, P1584, DOI DOI 10.1145/1774088.1774427
   HEYGSTER G, 1982, COMPUT VISION GRAPH, V19, P148, DOI 10.1016/0146-664X(82)90105-8
   Huang T.S., 1981, Two-Dimensional Digital Signal Processing II
   Justusson B.I., 1981, Median Filtering: Statistical Properties
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kirchberg M., 2010, System Sciences (HICSS), 2010 43rd Hawaii International Conference on, P1
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Liu A., 2016, MULTIMED TOOLS APPL, P1
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Ravi H, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2857069
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   VELLEMAN PF, 1980, J AM STAT ASSOC, V75, P609, DOI 10.2307/2287657
   Wang B, 2016, MOL BIOSYST, V12, P246, DOI 10.1039/c5mb00571j
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2013, IEEE IMAGE PROC, P2837
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 32
TC 22
Z9 23
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22119
EP 22132
DI 10.1007/s11042-017-4845-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200014
DA 2024-07-18
ER

PT J
AU Quan, W
   Liu, ZG
   Chen, JX
   Liang, DC
AF Quan, Wei
   Liu, Zhigang
   Chen, Jim X.
   Liang, Decui
TI Adaptive relay detection using primary and auxiliary detectors for
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Relay detection; Primary and auxiliary detectors;
   Feature selection; Mutual information
ID DISCRIMINATIVE TRACKING; PARALLEL FRAMEWORK; VISUAL TRACKING; ROBUST
   TRACKING; OBJECT TRACKING; OCCLUSION; SELECTION
AB A tracking method based on adaptive relay detection using primary and auxiliary detectors is proposed. In this framework, the tracking problem is formulated as the continuous relay detection, where primary detector and auxiliary detectors collaborate to locate the target and are updated online. Each of the detectors corresponds to one of the appearances of target that have appeared. Primary detector that always corresponds to the current appearance of target is set to conduct object detection, while auxiliary detectors that correspond to the previous appearances of target are used to re-detect the target when it shows a previous appearance. To achieve better classification with less features and ferns, the detectors are constructed based on the feature selection by the mutual information. As the previous appearances of target are recorded by the detectors correspondingly and only primary detector needs to update, our tracker can achieve long-term real-time object tracking in unconstrained environments. Experimental results on challenging real-world video sequences demonstrate that our tracker outperforms most of the state-of-the-art methods.
C1 [Quan, Wei; Liu, Zhigang] Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
   [Chen, Jim X.] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
   [Liang, Decui] Univ Elect Sci & Technol, Sch Management & Econ, Chengdu 611731, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; George Mason University; University of
   Electronic Science & Technology of China
RP Quan, W (corresponding author), Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
EM wquan@swjtu.edu.cn; liuzg@swjtu.edu.cn; jchen@gmu.edu;
   dcliang@uestc.edu.cn
RI Liu, Zhigang/H-4818-2016
OI Liu, Zhigang/0000-0002-6863-6561
FU Science and Technology Project of Sichuan Province of China
   [2015JY0141]; Fundamental Research Funds for the Central Universities of
   China [2682014cx024]
FX This work was supported in part by the Science and Technology Project of
   Sichuan Province of China (Grant No. 2015JY0141) and the Fundamental
   Research Funds for the Central Universities of China (Grant No.
   2682014cx024).
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], VISION INTERFACE
   [Anonymous], IEEE C PATT REC IM P
   [Anonymous], EUR CONF COMP VIS
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2004, IEEE SYS MAN CYBERN, DOI DOI 10.1109/ICSMC.2004.1400815
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Godec M., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Hua Y, 2014, LECT NOTES COMPUT SC, V8694, P172, DOI 10.1007/978-3-319-10599-4_12
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Lee DY, 2014, PROC CVPR IEEE, P3486, DOI 10.1109/CVPR.2014.446
   Li X, 2008, IEEE C COMPUT VIS PA, P1
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Lucey S., 2008, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587564
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Özuysal M, 2006, LECT NOTES COMPUT SC, V3953, P592, DOI 10.1007/11744078_46
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Pernici F, 2012, LECT NOTES COMPUT SC, V7585, P597, DOI 10.1007/978-3-642-33885-4_61
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Wang XY, 2010, LECT NOTES COMPUT SC, V6313, P200
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 46
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24299
EP 24313
DI 10.1007/s11042-016-4147-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700052
DA 2024-07-18
ER

PT J
AU Sebti, A
   Hassanpour, H
AF Sebti, Ali
   Hassanpour, Hamid
TI Body orientation estimation with the ensemble of logistic regression
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Body orientation; Logistic regression; Ensemble methods
ID PEDESTRIAN DETECTION; TRACKING
AB Orientation of human body is an important feature that can be used for behavioral analysis in surveillance systems. This cue contains useful information such as the direction of movement or attention. Difficulties such as low quality images, cluttered background and partial occlusion harden orientation estimation. In this paper, we propose a novel approach for determining body orientation using the ensemble of logistic regression classifiers. The logistic regression is a discriminative model that is very efficient in time and space complexities. In addition to these desirable properties, we show that this classifier provides a good classification performance in our problem. These classifiers are trained using Histogram of Oriented Gradient (HOG) descriptors which are extracted from four regions in the bounding box of the subjects. Two types of regions are considered in our method: static and dynamic regions. Static regions include: the whole body, upper half and the lower half of the body. Dynamic region includes the region of head and shoulder, which is located dynamically in various images and should be localized for each instance. To enhance the output of each classifier, we propose a weighting scheme based on the inherent characteristics of the orientation estimation problem and finally combine these outputs in an ensemble method to improve the accuracy. Experimental results show the superiority of the proposed method in accuracy and time complexity as compared to the state-of-the-art methods.
C1 [Sebti, Ali; Hassanpour, Hamid] Shahrood Univ Technol, Lab Image Proc & Data Min, Shahrood, Iran.
C3 Shahrood University of Technology
RP Sebti, A (corresponding author), Shahrood Univ Technol, Lab Image Proc & Data Min, Shahrood, Iran.
EM ali.sebti@shahroodut.ac.ir; h.hassanpour@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020; Sebti, Ali/JJD-7886-2023
OI Hassanpour, Hamid/0000-0002-5513-9822; Sebti, Ali/0000-0001-8166-3591
CR Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], 9 EUR C PRINC PRACT
   [Anonymous], 2009, IEEE COMP SOC C COMP
   Baltieri D, 2015, INT J COMPUT VISION, V111, P345, DOI 10.1007/s11263-014-0747-z
   Baltieri D, 2012, LECT NOTES COMPUT SC, V7576, P270, DOI 10.1007/978-3-642-33715-4_20
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Chavel I., 2006, RIEMANNIAN GEOMETRY, V98
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPR.2011.5995683
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gandhi T, 2008, IEEE INT VEH SYM, P795
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Komarek P., 2005, 5 IEEE INT C DATA MI, P4
   Mu Y., 2008, IEEE C COMPUTER VISI, P1
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Shimizu H, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P596
   Smith K, 2008, IEEE T PATTERN ANAL, V30, P1212, DOI 10.1109/TPAMI.2007.70773
   Tao JL, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P230, DOI 10.1109/ICCVW.2013.38
   Tosato D, 2013, IEEE T PATTERN ANAL, V35, P1972, DOI 10.1109/TPAMI.2012.263
   Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 26
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23589
EP 23605
DI 10.1007/s11042-016-4129-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700021
DA 2024-07-18
ER

PT J
AU Wang, R
   Zheng, LH
   Xiong, CQ
   Qiu, CF
   Li, HT
   Hou, XH
   Sheng, B
   Li, P
   Wu, Q
AF Wang, Rui
   Zheng, Linghan
   Xiong, Chaoqun
   Qiu, Chunfang
   Li, Huating
   Hou, Xuhong
   Sheng, Bin
   Li, Ping
   Wu, Qiang
TI Retinal optic disc localization using convergence tracking of blood
   vessels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optic disc; Retinal image; Vessel convergence; Diabetic retinopathy
ID AUTOMATIC LOCALIZATION; IMAGES; SEGMENTATION
AB Optic disc localization is of great diagnostic value related to retinal diseases, such as glaucoma and diabetic retinopathy. However, the detection process is quite challenging because positions of optic discs vary from image to image, and moreover, pathological changes, like hard exudates or neovascularization, may alter optic disc appearance. In this paper, we propose a robust approach to accurately detect the optic disc region and locate the optic disc center in color retinal images. The proposed technique employs a kernelized least-squares classifier to decide the area that contains optic disc. Then connected-component labeling and lumination information are used together to find the convergence of blood vessels, which is thought to be optic disc center. The proposed method has been evaluated over two datasets: the Digital Retinal Images for Vessel Extraction (DRIVE), and the Non-fluorescein Images for Vessel Extraction (NIVE) datasets. Experimental results have shown that our method outperforms existing methods, achieving a competitive accuracy (97.52 %) and efficiency (1.1577s).
C1 [Wang, Rui; Zheng, Linghan; Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Xiong, Chaoqun; Qiu, Chunfang] Shanghai Acad Spaceflight Technol, Shanghai, Peoples R China.
   [Li, Huating; Hou, Xuhong] Shanghai Jiao Tong Univ, Dept Endocrinol & Metab, Affiliated Peoples Hosp 6,Shanghai Key Clin Ctr M, Shanghai Clin Ctr Diabet,Shanghai Diabet Inst,Sha, Shanghai, Peoples R China.
   [Hou, Xuhong; Wu, Qiang] Shanghai Jiao Tong Univ, Dept Ophthalmol, Affiliated Peoples Hosp 6, Shanghai, Peoples R China.
   [Li, Ping] Hong Kong Univ Educ, Dept Math & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai
   Jiao Tong University
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM shengbin@sjtu.edu.cn
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240
FU National Natural Science Foundation of China [61572316, 61133009];
   National High-tech R&D Program of China (863 Program) [2015AA015904];
   Science and Technology Commission of Shanghai Municipality Program
   [13511505000, 16DZ050110]; Shanghai Jiao Tong University [14JCY10];
   Research Grants Council of Hong Kong [28200215]; Education University of
   Hong Kong [FLASS/DRF/ECR-7]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The corresponding authors of this
   paper are Bin Sheng (email: shengbin@cs.sjtu.edu.cn) and Qiang Wu
   (email: wyansh@163.com). The work is supported by the National Natural
   Science Foundation of China (Nos. 61572316, 61133009), National
   High-tech R&D Program of China (863 Program) (Grant No. 2015AA015904),
   the Science and Technology Commission of Shanghai Municipality Program
   (Nos. 13511505000, 16DZ050110), the Interdisciplinary Program of
   Shanghai Jiao Tong University (No. 14JCY10), a grant from the Research
   Grants Council of Hong Kong (Project No.: 28200215), a grant from The
   Education University of Hong Kong (Project No: FLASS/DRF/ECR-7).
CR AKITA K, 1982, PATTERN RECOGN, V15, P431, DOI 10.1016/0031-3203(82)90022-X
   Chaichana T, 2008, 2008 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, P672
   Engelgau MM, 2004, ANN INTERN MED, V140, P945, DOI 10.7326/0003-4819-140-11-200406010-00035
   Foracchia M, 2004, IEEE T MED IMAGING, V23, P1189, DOI 10.1109/TMI.2004.829331
   Gagnon L, 2001, PROC SPIE, V4322, P1218, DOI 10.1117/12.430999
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hoover A, 2003, IEEE T MED IMAGING, V22, P951, DOI 10.1109/TMI.2003.815900
   Lu SJ, 2011, IEEE T BIO-MED ENG, V58, P88, DOI 10.1109/TBME.2010.2086455
   Lupascu CA, 2008, COMP MED SY, P17, DOI 10.1109/CBMS.2008.15
   Mendels F., 1999, P IRISH MACHINE VISI, P103
   Mendonça AM, 2013, COMPUT MED IMAG GRAP, V37, P409, DOI 10.1016/j.compmedimag.2013.04.004
   Park M., 2006, INT C COMPUTER GRAPH, P141
   Salazar-Gonzalez AG, 2011, P INT WORKSH COMP IN, P1
   Sattar F, 2014, LECT NOTES COMPUT SC, V8815, P277, DOI 10.1007/978-3-319-11755-3_13
   Sekhar S, 2008, I S BIOMED IMAGING, P1577, DOI 10.1109/ISBI.2008.4541312
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Ying HJ, 2007, P ANN INT IEEE EMBS, P4139, DOI 10.1109/IEMBS.2007.4353247
   Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326
NR 19
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23309
EP 23331
DI 10.1007/s11042-016-4146-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700009
DA 2024-07-18
ER

PT J
AU Chen, XJ
   Ke, J
   Zhan, YZ
   Chen, XB
   Zhang, QQ
   Jiang, XM
   Song, XP
   Chen, BD
   Xu, H
   Zhang, JG
AF Chen, Xiao-jun
   Ke, Jia
   Zhan, Yong-zhao
   Chen, Xiao-bo
   Zhang, Qian-qian
   Jiang, Xiao-ming
   Song, Xin-ping
   Chen, Bao-ding
   Xu, Hui
   Zhang, Jian-guo
TI Improved combined invariant moment for moving targets classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Combined invariant moments; Magnitude of invariant moments; Moving
   targets; Moving object classification; Support vector regression
ID IMAGE-ANALYSIS; RECOGNITION
AB Invariant moment is a highly concentrated and distortion invariant image features. The goal of multi-moving object characterization and classification methods is to find a suitable description of different kinds of moving objects in the scene and match the similarity between unknown moving objects with invariant moment. This paper presents evolution and development of invariant moments family history, and designs a classification model to classify multi-moving objects. Experimental results show that this method can effectively improve the recognition rate of the moving object.
C1 [Chen, Xiao-jun; Chen, Bao-ding; Xu, Hui; Zhang, Jian-guo] Jiangsu Univ, Affiliated Hosp, Informat Dept, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.
   [Chen, Xiao-jun; Ke, Jia; Zhan, Yong-zhao; Zhang, Qian-qian; Jiang, Xiao-ming] JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Ke, Jia; Song, Xin-ping] Jiangsu Univ, Sch Management, Zhenjiang, Jiangsu, Peoples R China.
   [Chen, Xiao-bo; Jiang, Xiao-ming] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University; Jiangsu University; Jiangsu
   University
RP Chen, XJ (corresponding author), Jiangsu Univ, Affiliated Hosp, Informat Dept, Jiefang Rd 438, Zhenjiang 212001, Jiangsu, Peoples R China.; Chen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM cxj@ujs.edu.cn
RI Xu, Hui/ADN-0578-2022; zhang, jian/HPD-1712-2023; Jiang,
   Xiaoming/W-8098-2019
OI Xu, Hui/0000-0002-2823-5915; 
FU Department of Transportation Informatization [2013-364-836-900];
   National Natural Science Foundation of China [71573107, 71471077,
   41374129, 41474095, 60673190, 61502206, 61502208, 61203244]; Science
   Foundation of Jiangsu Province [BK20150522, BK20150523]; College Natural
   Science Research of Jiangsu Province [14KJB520008]; Senior Technical
   Personnel of Scientific Research Fund of Jiangsu University [13JDG126];
   Nature Science Foundation of Jiangsu Province [SBK2015040772]; Research
   Innovation Program for College Graduates of Jiangsu Province
   [KYLX15_1078]
FX This research has partially been supported by the project funded of the
   Department of Transportation Informatization under Grant No.
   2013-364-836-900, National Natural Science Foundation of China under
   Grant No. 71573107, 71471077, 41374129, 41474095, 60673190, 61502206,
   61502208 and 61203244, Science Foundation of Jiangsu Province under
   Grant No. BK20150522 and BK20150523, College Natural Science Research of
   Jiangsu Province under Grant No. 14KJB520008, Senior Technical Personnel
   of Scientific Research Fund of Jiangsu University under Grant No.
   13JDG126, Nature Science Foundation of Jiangsu Province under Grant No.
   SBK2015040772, Research Innovation Program for College Graduates of
   Jiangsu Province under Grant No. KYLX15_1078.
CR Amu G, 2004, APPL OPTICS, V43, P2093, DOI 10.1364/AO.43.002093
   [Anonymous], INFRARED
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], INT J COMPUT VIS
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen GY, 1999, PATTERN RECOGN, V32, P1083, DOI 10.1016/S0031-3203(98)00148-4
   Chen XB, 2012, NEUROCOMPUTING, V97, P63, DOI 10.1016/j.neucom.2012.05.004
   Chen XB, 2012, NEURAL COMPUT APPL, V21, P505, DOI 10.1007/s00521-010-0454-9
   Cheng HD, 1998, INT J PATTERN RECOGN, V12, P921, DOI 10.1142/S0218001498000506
   Fan LN, 2005, Proceedings of 2005 Chinese Control and Decision Conference, Vols 1 and 2, P579
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Gu HZ, 2013, MULTIMED TOOLS APPL, V65, P387, DOI 10.1007/s11042-012-0996-1
   GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X
   Hahn WE, 2015, MULTIMED TOOLS APPL, P1
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ke J, 2009, 2009 INT C INT COMP
   LENZ R, 1994, PATTERN RECOGN, V27, P1523, DOI 10.1016/0031-3203(94)90130-9
   Li Xueyong, 2007, OPTOELECTRONICS LASE, V18, P1244
   Li Z-m, 2005, MOMENTS ITS APPL GEN
   Liao SX, 2002, P 16 INT C PATT REC, V3, P11
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Ping ZL, 2007, PATTERN RECOGN, V40, P1245, DOI 10.1016/j.patcog.2006.07.016
   Ping ZL, 2002, J OPT SOC AM A, V19, P1748, DOI 10.1364/JOSAA.19.001748
   PIZLO Z, 1992, CVGIP-IMAG UNDERSTAN, V56, P330, DOI 10.1016/1049-9660(92)90046-6
   Qjidaa H., 2006, P 2 INT S COMM CONTR, P1
   REDDI SS, 1981, IEEE T PATTERN ANAL, V3, P240, DOI 10.1109/TPAMI.1981.4767087
   SHENG Y, 1987, J OPT SOC AM A, V4, P1176, DOI 10.1364/JOSAA.4.001176
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Shenga YH, 2014, J INTELL FUZZY SYST, V26, P1263, DOI 10.3233/IFS-130812
   Suk T, 2004, IEEE T PATTERN ANAL, V26, P1364, DOI 10.1109/TPAMI.2004.89
   Suk T, 2011, PATTERN RECOGN, V44, P2047, DOI 10.1016/j.patcog.2010.05.015
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Tsai CW, 2013, MULTIMED TOOLS APPL, V67, P137, DOI 10.1007/s11042-011-0957-0
   [吴晓光 Wu Xiaoguang], 2004, [计算机工程, Computer Engineering], V30, P124
   Wu YF, 2005, EURASIP J APPL SIG P, V2005, P588, DOI 10.1155/ASP.2005.588
   Yap PT, 2004, TENCON IEEE REGION, pA594
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zeng Wanmei, 2009, Electronics Optics & Control, V16, P21
   Zhu HQ, 2007, PATTERN RECOGN LETT, V28, P1688, DOI 10.1016/j.patrec.2007.04.013
NR 41
TC 0
Z9 1
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19959
EP 19982
DI 10.1007/s11042-016-4014-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500038
DA 2024-07-18
ER

PT J
AU Hao, M
   Hua, Z
   Li, ZX
   Chen, BQ
AF Hao, Ming
   Hua, Zhang
   Li, Zhenxuan
   Chen, Bingqian
TI Unsupervised change detection using a novel fuzzy c-means clustering
   simultaneously incorporating local and global information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Change detection; Fuzzy c-means algorithm; Local
   information; Spatial attraction; Global information
ID IMAGE; MODEL
AB This paper presents a novel fuzzy c-means (FCM) clustering simultaneously incorporating local and global information (FLGICM) method to unsupervised change detection (CD) from remotely sensed images. A new factor including three local, global and edge parameters is added into the conventional FCM to enhance the insensitivity to noise and preserve detailed features. The spatial attraction between the central pixel and its neighborhood pixels is incorporated as a local parameter to utilize spatial information. A global parameter designed based on the estimated mean values of changed and unchanged pixels is introduced into the new factor to enhance its robustness and ability of separating changed from unchanged pixels. In addition, an edge parameter is also added to remain accurate edges and change details. Two experiments were carried out on Landsat images to test the performance of FLGICM. Experimental results indicate that FLGICM always achieves high accuracy and overperforms some state-of-the-art CD methods. Therefore, the proposed FLGIC provides an effective unsupervised CD method.
C1 [Hao, Ming; Hua, Zhang; Li, Zhenxuan] China Univ Mining & Technol, Sch Environm Sci & Spatial Informat, Daxue Rd 1, Xuzhou 221116, Peoples R China.
   [Chen, Bingqian] Jiangsu Normal Univ, Sch Geog Geomat & Urban Rural Planning, Xuzhou, Peoples R China.
C3 China University of Mining & Technology; Jiangsu Normal University
RP Hua, Z (corresponding author), China Univ Mining & Technol, Sch Environm Sci & Spatial Informat, Daxue Rd 1, Xuzhou 221116, Peoples R China.
EM cumthaoming@163.com; zhhua_79@163.com
RI Hao, Ming/GXI-0243-2022; Li, Zhe-xuan/E-9182-2017; hua,
   zhang/G-5474-2012
OI Li, Zhenxuan/0000-0002-0528-8328; Chen, Bingqian/0000-0003-2246-7667
FU Natural Science Foundation of Jiangsu Province [BK20160248]; China
   Postdoctoral Science Foundation; Fundamental Research Funds for the
   Central Universities [2015XKQY09]; Priority Academic Program Development
   of Jiangsu Higher Education Institutions
FX The work presented in this paper is supported by the Natural Science
   Foundation of Jiangsu Province under Grant BK20160248, the China
   Postdoctoral Science Foundation funded project, Fundamental Research
   Funds for the Central Universities under Grant 2015XKQY09, and the
   Project Funded by the Priority Academic Program Development of Jiangsu
   Higher Education Institutions.
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, BMVC
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2002, IEEE T GEOSCI REMOTE, V40, P1984, DOI 10.1109/TGRS.2002.803794
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Desclée B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Im JH, 2008, REMOTE SENS ENVIRON, V112, P2761, DOI 10.1016/j.rse.2008.01.007
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li H, 2015, IEEE GEOSCI REMOTE S, V12, P582, DOI 10.1109/LGRS.2014.2352264
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Mishra NS, 2012, APPL SOFT COMPUT, V12, P2683, DOI 10.1016/j.asoc.2012.03.060
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang QM, 2015, IEEE J-STARS, V8, P1339, DOI 10.1109/JSTARS.2014.2355832
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Ye YX, 2014, ISPRS J PHOTOGRAMM, V90, P83, DOI 10.1016/j.isprsjprs.2014.01.009
NR 30
TC 13
Z9 15
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20081
EP 20098
DI 10.1007/s11042-017-4354-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500044
DA 2024-07-18
ER

PT J
AU Wang, JL
   Li, GH
   Pan, P
   Zhao, XS
AF Wang, Jiale
   Li, Guohui
   Pan, Peng
   Zhao, Xiaosong
TI Semi-supervised semantic factorization hashing for fast cross-modal
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal hashing; Semi-supervised learning; Semantic factorization
AB Cross-modal hashing can effectively solve the large-scale cross-modal retrieval by integrating the advantages of traditional cross-modal analysis and hashing techniques. In cross-modal hashing, preserving semantic correlation is important and challenging. However, current hashing methods cannot well preserve the semantic correlation in hash codes. Supervised hashing requires labeled data which is difficult to obtain, and unsupervised hashing cannot effectively learn semantic correlation from multi-modal data. In order to effectively learn semantic correlation to improve hashing performance, we propose a novel approach: Semi-Supervised Semantic Factorization Hashing (S3FH), for large-scale cross-modal retrieval. The main purpose of S3FH is to improve semantic labels and factorize it into hash codes. It optimizes a joint framework which consists of three interactive parts, including semantic factorization, multi-graph learning and multi-modal correlation. Then, an efficient alternating algorithm is derived for optimizing S3FH. Extensive experiments on two real world multi-modal datasets demonstrate the effectiveness of S3FH.
C1 [Wang, Jiale; Li, Guohui; Pan, Peng; Zhao, Xiaosong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Zhao, XS (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
EM wangjiale@hust.edu.cn; guohuili@hust.edu.cn; panpeng@mail.hust.edu.cn;
   hustkent@sina.com
RI Pan, Feng/IXN-2297-2023; wang, jiale/GPX-1361-2022
OI wang, jiale/0000-0001-6530-7060
CR [Anonymous], 2013, Book Linear cross-modal hashing for efficient multimedia search, DOI DOI 10.1145/2502081.2502107
   [Anonymous], 2012, P 2012 ACM SIGMOD IN
   [Anonymous], 2012, NIPS
   [Anonymous], 2012, Book A probabilistic model for multimodal hash function learning, DOI DOI 10.1145/2339530.2339678
   [Anonymous], 2014, ACM MM, DOI DOI 10.1145/2647868.2655035
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cheng J, 2014, COMPUT VIS IMAGE UND, V124, P12, DOI 10.1016/j.cviu.2014.04.001
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Ding GG, 2014, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2014.267
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   Kan MN, 2014, IEEE T CIRC SYST VID, V24, P704, DOI 10.1109/TCSVT.2013.2276713
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Luo Y, 2013, IEEE T IMAGE PROCESS, V22, P523, DOI 10.1109/TIP.2012.2218825
   Murty K. G, 1988, Linear Complementarity, Linear and Nonlinear Programming
   Pan YW, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P53, DOI 10.1145/2766462.2767725
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xie L, 2016, SIGNAL PROCESS, V124, P81, DOI 10.1016/j.sigpro.2015.10.010
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zhai X., 2013, AAAI
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu X., 2005, PhD thesis
NR 34
TC 15
Z9 15
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20197
EP 20215
DI 10.1007/s11042-017-4567-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500050
DA 2024-07-18
ER

PT J
AU Shrivastav, S
   Kumar, S
   Kumar, K
AF Shrivastav, Shikhar
   Kumar, Sandeep
   Kumar, Kuldeep
TI Towards an ontology based framework for searching multimedia contents on
   the web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Search; Retrieval; Ontology; RDF
ID CLASSIFICATION; EIGENFACES
AB We live in a world where there are huge number of consumers and producers of multimedia content. In this sea of information, finding the right content is like finding a needle in a haystack. Rich annotation of multimedia content during its initial upload on the Web, and further various methodologies for framing search query can be helpful to the user in this regard. In addition to annotation of multimedia content based on the user-provided description, various approaches for annotation and indexing of multimedia files based upon the embedded contents have been presented in the literature. However, annotating multimedia files by using multiple possible sources simultaneously to generate better annotation needs further exploration. We have proposed a framework utilizing these multiple sources of information like text, audio, image, etc. This framework generates annotation based on the contents of user entered description, embedded audio, image analysis, optical character recognition and finally by gathering more information from the Web. This framework provides multiple options to search for content like search by image, audio, video, face and also provides an improved textual search. A system has been implemented based on the proposed framework and the work has also been evaluated.
C1 [Shrivastav, Shikhar] Flipkart Bangalore, Bangalore, Karnataka, India.
   [Kumar, Sandeep] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttarakhand, India.
   [Kumar, Kuldeep] Birla Inst Technol & Sci Pilani, Comp Sci & Informat Syst, Pilani, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Birla Institute of Technology & Science
   Pilani (BITS Pilani)
RP Kumar, S (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttarakhand, India.
EM shikhar2005@gmail.com; sandeepkumargarg@gmail.com;
   kuldeepgargkkr@gmail.com
RI Kumar, Dr Sandeep/AAW-6313-2020; Kumar, Sandeep/IWU-7273-2023; Kummar,
   Kuldeep/AFO-1487-2022; Kumar, Sandeep/AAW-6570-2020; Kumar,
   Kuldeep/Y-4439-2019; Kummar, Kuldeep/AAW-8834-2021; KUMAR,
   SANDEEP/GZA-7182-2022
OI Kumar, Dr Sandeep/0000-0003-0747-6776; Kumar,
   Sandeep/0000-0002-7008-4735; Kumar, Sandeep/0000-0002-3250-4866; Kumar,
   Kuldeep/0000-0003-1160-9092; KUMAR, SANDEEP/0000-0001-7142-0852; Kumar,
   Sandeep/0000-0001-9633-407X
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Apvrille L, 2004, IEEE T SOFTWARE ENG, V30, P473, DOI 10.1109/TSE.2004.34
   Banerjee R, 2013, LAND USE POLICY, V34, P193, DOI 10.1016/j.landusepol.2013.03.005
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Celino I, 2006, P 1 INT C SEM ENH MU, V228, P40
   Chang S. F., 1999, ADV MULTIMEDIA SYSTE
   Clausen M, 2003, SIGIR MULT INF RETR, P1
   CMU Sphinx, 2016, CMU SPHINX OP SOURC
   Deilamani M. J., 2011, 2011 International Symposium on Artificial Intelligence and Signal Processing (AISP), P48, DOI 10.1109/AISP.2011.5960981
   Faloutsos C., 1996, SEARCHING MULTIMEDIA
   FileInfo, 2016, VID FIL TYP
   Frankel C., 1996, TECHNICAL REPORT
   Giró X, 2005, MULTIMEDIA CONTENT AND THE SEMANTIC WEB: METHODS, STANDARDS AND TOOLS, P203, DOI 10.1002/0470012617.ch7
   Hausenblas M, 2011, BUILDING SCALEABLE S
   Hunter J, 2005, MULTIMEDIA CONTENT AND THE SEMANTIC WEB: METHODS, STANDARDS AND TOOLS, P75, DOI 10.1002/0470012617.ch3
   Kim D, 2014, MULTIMED TOOLS APPL, V73, P857, DOI 10.1007/s11042-013-1547-0
   Kroupi E, 2016, MULTIMED TOOLS APPL, V75, P12409, DOI 10.1007/s11042-015-2980-z
   Lalinsky L, 2016, CHROMAPRINT
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu Chang, 2010, Tsinghua Science and Technology, V15, P613, DOI 10.1016/S1007-0214(10)70108-5
   Maggiori E, 2016, INT GEOSCI REMOTE SE, P5071, DOI 10.1109/IGARSS.2016.7730322
   MakeUseOf, 2016, AUD FIL FORM EXPL SI
   Martinez JM, 2016, MPEG 7 OVERVIEW
   Matthews R, 2016, DIGITAL IMAGE FILE T
   Müllerová J, 2013, INT J APPL EARTH OBS, V25, P55, DOI 10.1016/j.jag.2013.03.004
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Opencv Dev Team, 2016, FAC REC OPENCV
   Oracle, 2016, URI JAV PLATF SE 6
   Pan JZ, 2007, IEEE T KNOWL DATA EN, V19, P192, DOI 10.1109/TKDE.2007.37
   Porter A, 2012, THESIS MCGILL U
   Sexton JO, 2013, REMOTE SENS ENVIRON, V128, P246, DOI 10.1016/j.rse.2012.10.010
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Steiner T, 2010, 9 INT SEM WEB C ISWC, P97
   Swain MJ, 1999, P 1999 INT C CHALL I, P1
   Tehrany MS, 2013, J INDIAN SOC REMOTE, V41, P981, DOI 10.1007/s12524-013-0289-9
   Tjondronegoro D, 2008, INFORM PROCESS MANAG, V44, P340, DOI 10.1016/j.ipm.2007.03.004
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vachier C, 2005, J MATH IMAGING VIS, V22, P251, DOI 10.1007/s10851-005-4893-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   W3C, 2016, HTML
   W3C, 2014, RDF Schema 1.1
   Walker W, 2004, TECHNICAL REPORT
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wen Zhen-kun, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P709, DOI 10.1109/ICGEC.2010.180
   World Wide Web Consortium (W3C), 2016, EXT MARK LANG XML
   Zauner C., 2010, IMPLEMENTATION BENCH
NR 47
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18657
EP 18686
DI 10.1007/s11042-017-4350-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800025
DA 2024-07-18
ER

PT J
AU Zhu, LC
   Xu, JJ
   Yan, LM
AF Zhu Longchao
   Xu Jianjun
   Yan Limei
TI Research on congestion elimination method of circuit overload and
   transmission congestion in the internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transmission Congestion; The Internet of things; OPF; Branch Circuit
   Overload Capacity; Interrupt amount
AB Power system is facing new challenges and opportunities in the environment of the internet of things. Under the circumstance of Internet of things, the transmission congestion management of interruptible load is the important measure to improve system reliability and operating economy. Considering the condition of target selected under different circumstances, this paper proposes a new multi-objective model of transmission congestion management with interruptible load based on brand circuit overload match with interrupt capacity. The multi-object model puts forward three goals, brand circuit overload match with interruptible load, the minimum number of interruptible load nodes and the minimum total interruption of interruptible load. Against other optimization methods can not prioritize to multiple targets and it can easily lead to convergence in the process of solving problems, the paper presents construct evaluation function based on the linear weighted sum to optimize multi-objective linear problem. This method can be sorted prior to multi-objective optimization model. And it has better convergence than other optimization methods in the solution process. Finally, it tests and verifies the correctness of method through the IEEE 30 bus power system. And it successfully applied to grid congestion management in oil.
C1 [Zhu Longchao; Xu Jianjun; Yan Limei] Northeast Petr Univ, Coll Elect Informat & Engn, Daqing 163318, Peoples R China.
C3 Northeast Petroleum University
RP Yan, LM (corresponding author), Northeast Petr Univ, Coll Elect Informat & Engn, Daqing 163318, Peoples R China.
EM 123939274@qq.com
RI Zhu, Longchao/GZM-4400-2022
FU Natural Science Foundation of Heilongjiang Provincial [E201260]
FX This work was supported by Natural Science Foundation of Heilongjiang
   Provincial (E201260), the corresponding author is Prof. YAN LIMEI.
CR Baran ME, 2000, IEEE T POWER SYST, V15, P579, DOI 10.1109/59.867144
   Chao Hung-po, 2000, The Electricity Journal, V13, P38
   Jin K., 2012, AUTOMATION ELECT POW, V26, P20
   Limei Y, 2014, ELECT MACHINES CONTR, V18, P78
   Lixuan G., 2006, ZHANGZHOU TECHNICAL, V8, P12
   Wang Jian-xue, 2005, Proceedings of the CSEE, V25, P11
   Wang Xiuli, 2002, Automation of Electric Power Systems, V26, P10
   Wei C., 2009, TRANSMISSION CONGEST
   Xiangqing K., 2012, INTERRUPTIBLE LOAD P
   Xiangwei C, 2010, POWER SYST PROTECTIO, V38, P82
   Xu JJ, 2013, INT J ONLINE ENG, V9, P24, DOI 10.3991/ijoe.v9iS7.3189
   [徐建军 XU Jianjun], 2011, [电力系统保护与控制, Power System Protection and Control], V39, P107
   [闫丽梅 Yan Limei], 2014, [电工技术学报, Transactions of China Electrotechnical Society], V29, P260
   Yan Limei, 2013, Journal of Xi'an Jiaotong University, V47, P117, DOI 10.7652/xjtuxb201306020
   Yao W, 2005, ZHEJIANG ELECT POWER, V5, P4
   Yi X, 2011, OPTIMIZATION THEORY, P36
   Zhang NB, 2011, J LUMIN, V131, P2021, DOI 10.1016/j.jlumin.2011.04.035
NR 17
TC 13
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18047
EP 18066
DI 10.1007/s11042-016-3686-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800026
OA hybrid
DA 2024-07-18
ER

PT J
AU Kanso, A
   Ghebleh, M
AF Kanso, Ali
   Ghebleh, Mohammad
TI An efficient (<i>t</i>,<i>n</i>)-threshold secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Steganography; Permutation; Chaos; Tent Map
ID COLOR IMAGES; STEGANOGRAPHY
AB We propose a novel (t,n)-threshold secret image sharing scheme based on Shamir's polynomial interpolation paradigm. The proposed scheme is a derivative of Thien and Lin's (Computers & Graphics 26(5):765-770, [13]) and some of its variants by ensuring less intrusive changes in the secret image. This is achieved by cyclically shifting the bits of the secret image, thus allowing a modification in the least significant bit to have a large effect on the values used in computation of shadow images. Statistical tests and simulations are presented to show the efficiency and robustness of the proposed scheme, in particular good randomness of shadow images, little correlation between adjacent pixels, and high entropy. Competence of the proposed scheme is further demonstrated by means of comparison with existing schemes.
C1 [Kanso, Ali; Ghebleh, Mohammad] Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
C3 Kuwait University
RP Kanso, A (corresponding author), Kuwait Univ, Dept Math, POB 5969, Safat 13060, Kuwait.
EM akanso@sci.kuniv.edu.kw; mamad@sci.kuniv.edu.kw
RI Kanso, Ali/GVT-1076-2022; Ghebleh, Mohammad/I-1040-2014
OI Kanso, Ali/0000-0002-4366-841X; Ghebleh, Mohammad/0000-0003-2291-0892
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen Y, 2015, CHEM ENG SCI, V132, P1, DOI 10.1016/j.ces.2015.04.006
   Ghebleh M, 2014, COMMUN NONLINEAR SCI, V19, P1898, DOI 10.1016/j.cnsns.2013.10.014
   Guo C, 2014, MULTIMED TOOLS APPL, V72, P2195, DOI 10.1007/s11042-013-1510-0
   Kanso A, 2011, COMMUN NONLINEAR SCI, V16, P822, DOI 10.1016/j.cnsns.2010.04.039
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu L., 2015, J. Inf. Hiding Multimed. Signal Process., V6, P246
   Ott E, 2002, CHAOS DYNAMICAL SYST
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Tsai CS, 2002, J SYST SOFTWARE, V64, P163, DOI 10.1016/S0164-1212(02)00034-1
   Tsai DS, 2009, INFORM SCIENCES, V179, P3247, DOI 10.1016/j.ins.2009.05.020
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu KS, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-49
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 20
TC 42
Z9 43
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16369
EP 16388
DI 10.1007/s11042-016-3917-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100014
DA 2024-07-18
ER

PT J
AU Wang, MH
   Gao, X
AF Wang Minhui
   Gao Xia
TI The game map design based on A* algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game Map; A* algorithm; Search path
AB A* algorithm is widely used in the game for diameter, is currently one of the more popular heuristic search algorithm, but the algorithm has the problem of searching time and path. In this paper, a bidirectional search A* algorithm is proposed to improve the search efficiency and ensure the accuracy of the search, and effectively solve the problem of path twists and turns. Then, the algorithm is implemented by experiment simulation, which improves the effectiveness and feasibility of the algorithm in the large map.
C1 [Wang Minhui; Gao Xia] Shanghai Jianqiao Univ, Informat Technol Coll, Shanghai, Peoples R China.
RP Gao, X (corresponding author), Shanghai Jianqiao Univ, Informat Technol Coll, Shanghai, Peoples R China.
EM Wmh_gench@126.com
CR Cheah KY, 2015, IMPROVING TOWER DEFE
   Choi H, 2014, MULTIMED TOOLS APPL, V68, P375, DOI 10.1007/s11042-012-1310-y
   Dinges P, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P425, DOI 10.1145/2635868.2635889
   Du XP, 2014, SIGNAL PROCESS, V100, P1, DOI 10.1016/j.sigpro.2014.01.002
   Fridenfalk M, 2014, GAMES MEDIA ENTERTAI, P282
   Gang X, 2006, GEN FRAMEWORK CHESS, V27
   Guan QZ, 2016, ACHIEVEMENT PATH PLA
   Guruji AK, 2016, PROC TECH, V23, P144, DOI 10.1016/j.protcy.2016.03.010
   Hansen E A, 2015, 29 AAAI C ART INT
   Hernandez-Sabate A, 2015, INT J SERIOUS GAME
   Li Y., 2014, TELKOMNIKA INDONESIA, V12, P5537
   Persson SM, 2014, INT J ROBOT RES, V33, P1683, DOI 10.1177/0278364914547786
   Ping LI, 2014, COMPUT ENG
   Qiu S-M, 2013, MODERN COMPUT, V6
   Rui K, 2014, J SHANGHAI I TECHNOL, V631, P160
   Sánchez K, 2015, COMPUT COLOMB CONF, P150
   Tan T. G., 2013, PROC INT MULTICONF A, P135
   Zarraonandia T, 2015, MULTIMED TOOLS APPL, V74, P4535, DOI 10.1007/s11042-013-1821-1
   Zhang P, 2014, INF COMPUT CONCEPTIO
   Zhang T, 2015, B SCI TECHNOL
   Zhao ZG, 2015, INT C EL COMP ENG EL
NR 21
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17231
EP 17253
DI 10.1007/s11042-016-3982-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500020
DA 2024-07-18
ER

PT J
AU Wuttidittachotti, P
   Daengsi, T
AF Wuttidittachotti, Pongpisit
   Daengsi, Therdpong
TI Subjective MOS model and simplified E-model enhancement for Skype
   associated with packet loss effects: <i>a case using conversation-like
   tests with Thai users</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; Skype; SILK; MOS; Simplified E-model; Packet loss
ID LANGUAGE; QUALITY
AB This paper proposes two mathematical models that can be used to estimate VoIP quality from Skype, which is one of the most popular VoIP applications. The first model is simple, it has been developed using data from the informal interview tests called Conversation-like tests, referring to packet loss of 0 %, 5 %, 10 %, ..., and 30 %. The tests have been conducted with Skype using a non ITU-T's codec called SILK via the Internet with over 180 native Thai participants, while packet loss effects were generated using a network emulation tool. The second model is called the Enhanced Simplified E-model, this has been developed by adding the Thai Bias factor into a generic Simplified E-model, which calculates by subtracting the subjective results from the computed results using the Simplified E-model formula. After obtaining the models, they were evaluated with the Test set from 36 native Thai participants (different from the other group of participants) using Mean Absolute Percentage Error technique (MAPE). It has been found that VoIP quality measurement performance of both models are classified as excellent and provide higher reliability and accuracy than the Simplified E-model. Subjective MOS model and Enhanced Simplified E-model error reduction compared to the simplified one was at about 21.9 % and 21.2 % respectively, which is the major contribution of this work.
C1 [Wuttidittachotti, Pongpisit] King Mongkuts Univ Technol North Bangkok, Fac Informat Technol, Dept Data Commun & Networking, Bangkok, Thailand.
   [Daengsi, Therdpong] JADS Comm Ltd, Dept Enterprise Serv, Bangkok, Thailand.
C3 King Mongkuts University of Technology North Bangkok
RP Wuttidittachotti, P (corresponding author), King Mongkuts Univ Technol North Bangkok, Fac Informat Technol, Dept Data Commun & Networking, Bangkok, Thailand.
EM pongpisitw@kmutnb.ac.th; therdpong1@yahoo.com
RI Daengsi, Therdpong/AAH-9231-2019
OI Daengsi, Therdpong/0000-0002-7569-8197
CR [Anonymous], SONGKLANAKARIN J SCI
   Arafat Muhammad Yeasir, 2014, Journal of Networks, V9, P3415, DOI 10.4304/jnw.9.12.3415-3426
   Assem H., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P927, DOI 10.1109/ICCNC.2013.6504214
   Assem H., 2013, THESIS
   Assem H, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1276
   Bin Baharudin MA, 2015, ARAB J SCI ENG, V40, P1623, DOI 10.1007/s13369-015-1638-5
   Chu HC, 2013, ELECTRON COMMER RES, V13, P399, DOI 10.1007/s10660-013-9116-1
   Chunlei Jiang, 2011, Proceedings of the 2011 International Conference on Internet Computing and Information Services (ICICIS 2011), P499, DOI 10.1109/ICICIS.2011.130
   Cole RG, 2001, ACM SIGCOMM COMP COM, V31, P9, DOI 10.1145/505666.505669
   Daengsi T., 2012, THESIS
   Daengsi T, 2016, MULTIMEDIA SYST, V22, P575, DOI 10.1007/s00530-015-0468-3
   Daengsi T, 2015, INT CONF UBIQ FUTUR, P386, DOI 10.1109/ICUFN.2015.7182571
   De Pessemier T, 2015, MULTIMED TOOLS APPL, V74, P5873, DOI 10.1007/s11042-014-1895-4
   De Rango F, 2006, INT J COMPUT SCI NET, V6, P140
   Ding LJ, 2003, GLOB TELECOMM CONF, P3974, DOI 10.1109/GLOCOM.2003.1258975
   Gandour J, 1998, NEUROREPORT, V9, P2115, DOI 10.1097/00001756-199806220-00038
   Goudarzi Mohammad, 2011, 2011 5th International Conference on Next Generation Mobile Applications, Services and Technologies, P42, DOI 10.1109/NGMAST.2011.18
   Goudarzi M, 2008, THESIS
   Hamidia M, 2015, P IPAC 2015 BATN, DOI [10.1145/2816839.2816923, DOI 10.1145/2816839.2816923]
   Huang TY, 2010, IEEE NETWORK, V24, P42, DOI 10.1109/MNET.2010.5430143
   Huang YT, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/478202
   Ickin S, 2015, MULTIMED TOOLS APPL, V74, P381, DOI 10.1007/s11042-014-1919-0
   Jana S., 2013, P ICCCN 2013 NASS, P1
   Jana S, 2016, MULTIMED TOOLS APPL, V75, P7957, DOI 10.1007/s11042-015-2711-5
   Jiang W., 2002, P INT WORKSHOP NETWO, P73
   Jiuchun Ren, 2010, 2010 3rd International Conference on Information Sciences and Interaction Sciences (ICIS), P256, DOI 10.1109/ICICIS.2010.5534748
   Johannesson NO, 1997, IEEE COMMUN MAG, V35, P70, DOI 10.1109/35.568213
   Karapantazis S, 2009, COMPUT NETW, V53, P2050, DOI 10.1016/j.comnet.2009.03.010
   Lindeberg M, 2011, MULTIMEDIA SYST, V17, P51, DOI 10.1007/s00530-010-0187-8
   Liu L, 2013, PERFORMANCE ANAL VOI
   Markopoulou A, 2004, IEEE INFOCOM SER, P2307
   Mazurczyk W, 2016, MULTIMED TOOLS APPL, V75, P13521, DOI 10.1007/s11042-015-2740-0
   Michels BJ, 2011, TECHTRENDS, V55, P23
   Moosikaphan K, 2014, THESIS
   Narbutt M, 2005, P MESAQIN 2005 PRAG
   Okamoto M, 2014, P ICALIP 2014 MANCH, P497
   Psytechnics, 2003, COMP SUBJ LIST QUAL
   Ribadeneira A. F., 2007, THESIS
   Rungruangthum M., 2015, P APCC 2015 LAT RES, P503
   Sathapornvajana S, 2013, WIRELESS PERS COMMUN, V69, P1067, DOI 10.1007/s11277-013-1066-3
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Sun LF, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1478
   Triyason T, 2015, ELEKTRON ELEKTROTECH, V21, P82, DOI 10.5755/j01.eee.21.1.7612
   Valin J-M, 2013, HIGH QUALITY LOW DEL
   Vos K, 2009, P IETF 75 STOCKH
   Vos K., 2010, SILK SPEECH CODEC
   Voznak M., 2011, INT J MATH MOD MET S, V6, P1301
   Weiwei Zhang, 2014, Journal of Networks, V9, P515, DOI 10.4304/jnw.9.2.515-522
   Wuttidittachotti Pongpisit, 2015, International Journal of Computer Network and Information Security, V7, P28, DOI 10.5815/ijcnis.2015.12.04
   Wuttidittachotti Pongpisit, 2014, 2014 IEEE Symposium on Computer Applications and Industrial Electronics (ISCAIE), P29, DOI 10.1109/ISCAIE.2014.7010204
   Wuttidittachotti P, 2017, MULTIMED TOOLS APPL, V76, P8329, DOI 10.1007/s11042-016-3389-z
   Wuttidittachotti P, 2015, INT CONF UBIQ FUTUR, P456, DOI 10.1109/ICUFN.2015.7182585
   Xiaomin L, 2011, THESIS
   Zhang HB, 2005, SIXTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERNG, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING AND FIRST AICS INTERNATIONAL WORKSHOP ON SELF-ASSEMBLING WIRELESS NETWORKS, PROCEEDINGS, P214
   Zhang XG, 2012, IEEE INFOCOM SER, P621, DOI 10.1109/INFCOM.2012.6195805
   Zhou L, 2014, IEEE T CIRC SYST VID, V24, P889, DOI 10.1109/TCSVT.2013.2291311
   Zhou L, 2013, IEEE T WIREL COMMUN, V12, P3733, DOI 10.1109/TWC.2013.051413.120597
   Zhou X, 2006, P IPS MOME 2006 SALZ
NR 58
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16163
EP 16187
DI 10.1007/s11042-016-3901-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100006
DA 2024-07-18
ER

PT J
AU Zhang, HY
   Zhang, LY
   Sun, YS
   Zhang, JY
AF Zhang, Haiyan
   Zhang, Liyi
   Sun, Yunshan
   Zhang, Jingyu
TI Low dose CT image statistical reconstruction algorithms based on
   discrete shearlet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT image reconstruction; Low-dose CT; Sparse representation; Discrete
   shearlet
ID SPARSE; REDUCTION; REGULARIZATION; QUALITY; NOISE
AB Reducing number of projection angles and lowering current intensity of X-ray tube are two common ways for reducing CT dose. Though reduced radiation dose of CT scan can lower damage to human bodies, Few number of projection angles will result in incomplete projection data while lowering tube current intensity a declined signal to noise ratio of projection data. In this paper, two statistical methods based on sparsity constraint in shearlet domain for low-dose CT image were proposed to solve the above problems. For the limited angle scanned reconstruction, sparse representation of intermediate images in shearlet domain is added into the objective function as a regularization item by means of Augmented Lagrangian method so as to narrow down solution space. For the low X-ray tube scanned reconstruction, a penalized weighted least-squares (PWLS) approach based on discrete shearlet was introduced to improve the performance of resisting noise in sinogram. And then reconstruct CT images by Filtered Back-Projection method. According to experimental data, both of the two approaches can get high-quality images when projection data is far from meeting conditions of completeness or the signal to noise ratio of projection data declines sharply. The proposed algorithms can be used for attaining reconstructed images that clearly keep structural details when the radiation dose is decreased to 10% or even lower degrees.
C1 [Zhang, Haiyan; Zhang, Liyi; Zhang, Jingyu] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Zhang, Liyi; Sun, Yunshan] Tianjin Univ Commerce, Coll Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University of Commerce
RP Sun, YS (corresponding author), Tianjin Univ Commerce, Coll Informat Engn, Tianjin, Peoples R China.
EM sunyunshan@tjcu.edu.cn
RI liu, peiyao/KFT-1810-2024; sun, jiamin/JPY-2155-2023; yang,
   qing/JBR-8440-2023; Zhang, Haiyan/GMW-7284-2022; Zhang,
   Jing/GWZ-7332-2022
FU National Natural Science Foundation of China [61340034]; China
   Postdoctoral Science Foundation [2013 M530873]; Natural Science
   Foundation of Tianjin of China [16JCYBJC28800]; Tianjin Research Program
   of Application Foundation and Advanced Technology [13JCYBJC15600]
FX This work was supported by National Natural Science Foundation of China
   (No.61340034), China Postdoctoral Science Foundation (No.2013 M530873),
   Natural Science Foundation of Tianjin of China (No.16JCYBJC28800) and
   Tianjin Research Program of Application Foundation and Advanced
   Technology (No.13JCYBJC15600).
CR Brenner DJ, 2001, AM J ROENTGENOL, V176, P289, DOI 10.2214/ajr.176.2.1760289
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chang M, 2013, J X-RAY SCI TECHNOL, V21, P161, DOI 10.3233/XST-130370
   Dong B, 2013, J SCI COMPUT, V54, P333, DOI 10.1007/s10915-012-9579-6
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Frikel J, 2013, APPL COMPUT HARMON A, V34, P117, DOI 10.1016/j.acha.2012.03.005
   Garduño E, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/5/055006
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Hämäläinen K, 2013, SIAM J SCI COMPUT, V35, pB644, DOI 10.1137/120876277
   Hara AK, 2009, AM J ROENTGENOL, V193, P764, DOI 10.2214/AJR.09.2397
   Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673
   Leipsic J, 2010, AM J ROENTGENOL, V195, P649, DOI 10.2214/AJR.10.4285
   Li TF, 2004, IEEE T NUCL SCI, V51, P2505, DOI 10.1109/TNS.2004.834824
   Liao HY, 2008, IEEE INT S BIOM IM N
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Mastora I, 2004, RADIOLOGY, V230, P116, DOI 10.1148/radiol.2301021408
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Niu SZ, 2014, PHYS MED BIOL, V59, P2997, DOI 10.1088/0031-9155/59/12/2997
   Patel VM, 2009, IEEE T IMAGE PROCESS, V18, P2673, DOI 10.1109/TIP.2009.2029594
   Prakash P, 2010, INVEST RADIOL, V45, P202, DOI 10.1097/RLI.ob013e3181dzfeec
   Ramani S, 2012, IEEE T MED IMAGING, V31, P677, DOI 10.1109/TMI.2011.2175233
   Silva AC, 2010, AM J ROENTGENOL, V194, P191, DOI 10.2214/AJR.09.2953
   Singh S, 2011, RADIOLOGY, V259, P565, DOI 10.1148/radiol.11101450
   Sodickson A, 2009, RADIOLOGY, V251, P175, DOI 10.1148/radiol.2511081296
   Wang J, 2008, IEEE T BIO-MED ENG, V55, P1022, DOI 10.1109/TBME.2007.909531
   Wang J, 2006, IEEE T MED IMAGING, V25, P1272, DOI 10.1109/TMI.2006.882141
   Wang J, 2009, MED PHYS, V36, P252, DOI 10.1118/1.3036112
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu Q, 2012, IEEE T MED IMAGING, V31, P1682, DOI 10.1109/TMI.2012.2195669
   Zhang HY, 2015, J X-RAY SCI TECHNOL, V23, P567, DOI 10.3233/XST-150509
   Zhang YK, 2010, IEEE T NUCL SCI, V57, P2587, DOI 10.1109/TNS.2010.2060356
   Zhao J, 2010, APPL MECH MATER, V29-32, P2251, DOI 10.4028/www.scientific.net/AMM.29-32.2251
   Zhu L, 2014, J X-RAY SCI TECHNOL, V22, P227, DOI 10.3233/XST-140421
   Zhu ZG, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/185750
NR 35
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15049
EP 15064
DI 10.1007/s11042-017-4471-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400028
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Qi, R
   Zeng, YN
AF Zhang, Yujie
   Qi, Rui
   Zeng, Yanni
TI Backtracking-based matching pursuit method for distributed compressed
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed compressed sensing; Greedy algorithm; Sparse signal
   reconstruction; Iterative algorithm; Orthogonal matching pursuit
ID SPARSE; ALGORITHM; ROBUST
AB In this paper, we study a distributed compressed sensing (DCS) problem in which we need to recover a set of jointly sparse vectors from the measurements. A Backtracking-based Adaptive Orthogonal Matching Pursuit (BAOMP) method to approximately sparse solutions for DCS is proposed. It is an iterative approach where each iteration consists of consecutive forward selection to adaptively choose several atoms and backward removal stages to detect the previous chosen atoms' reliability and then delete the unreliable atoms at each iteration. Also, unlike its several predecessors, the proposed method does not require the sparsity level to be known as a prior which makes it a potential candidate for many practical applications, when the sparsity of signals is not available. We demonstrate the reconstruction ability of the proposed algorithm on both synthetically generated data and image using Normal and Binary sparse signals, and the real-life electrocardiography (ECG) data, where the proposed method yields less reconstruction error and higher exact recovery rate than other existing DCS algorithms.
C1 [Zhang, Yujie; Qi, Rui; Zeng, Yanni] China Univ Geosci, Sch Math & Phys, Wuhan, Peoples R China.
   [Zhang, Yujie] Univ Windsor, Sch Comp Sci, Windsor, ON, Canada.
   [Qi, Rui] Naval Univ Engn, Sch Sci, Wuhan, Peoples R China.
   [Zeng, Yanni] Hubei Univ Econ, Fac Stat, Wuhan, Peoples R China.
C3 China University of Geosciences; University of Windsor; Wuhan Naval
   University of Engineering; Hubei University of Economics
RP Zhang, YJ (corresponding author), China Univ Geosci, Sch Math & Phys, Wuhan, Peoples R China.; Zhang, YJ (corresponding author), Univ Windsor, Sch Comp Sci, Windsor, ON, Canada.
EM jiansuoba@qq.com
RI zhang, yujie/JAA-9367-2023
FU Natural Science Foundation of China [61302138]; Youth Foundation of
   Naval University of Engineering [HGDQNJJ13005]
FX This work is supported by Natural Science Foundation of China (No.
   61302138) and Youth Foundation of Naval University of Engineering (No.
   HGDQNJJ13005).
CR [Anonymous], 2005, SIGNALS SYSTEMS COMP, DOI DOI 10.1109/ACSSC.2005.1600024
   [Anonymous], IEEE T INFORM THEORY
   Attar A, 2016, MULTIMED TOOLS APPL, V75, P7407, DOI 10.1007/s11042-015-2663-9
   Berger CR, 2010, IEEE T SIGNAL PROCES, V58, P1708, DOI 10.1109/TSP.2009.2038424
   Blanchard JD, 2014, IEEE T SIGNAL PROCES, V62, P1694, DOI 10.1109/TSP.2014.2301980
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fayed S, 2016, MULTIMED TOOLS APPL, V75, P6347, DOI 10.1007/s11042-015-2575-8
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Huang HL, 2011, IEEE SIGNAL PROC LET, V18, P391, DOI 10.1109/LSP.2011.2147313
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D, 2010, IEEE J-STSP, V4, P310, DOI 10.1109/JSTSP.2010.2042412
   Qureshi MA, 2016, MULTIMED TOOLS APPL, V75, P6737, DOI 10.1007/s11042-015-2590-9
   Sundman D, 2011, EUR SIGNAL PR CONF, P368
   Tropp JA, 2005, INT CONF ACOUST SPEE, P721
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Wakin M.B., 2005, P WORKSHOP NEURAL IN, P1435
   Wang Q, 2011, COMPUT ELECTR ENG, V37, P916, DOI 10.1016/j.compeleceng.2011.09.008
   Zhao GH, 2012, SIGNAL PROCESS, V92, P120, DOI 10.1016/j.sigpro.2011.06.011
NR 22
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14691
EP 14710
DI 10.1007/s11042-016-3933-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400009
DA 2024-07-18
ER

PT J
AU Asghar, MN
   Fleury, M
   Makki, S
AF Asghar, Mamoona Naveed
   Fleury, Martin
   Makki, Sohail
TI Interoperable conditional access with video selective encryption for
   portable devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conditional access; Pay-TV; Selective encryption; Video streaming
ID PROTECTION; IMAGE
AB The pay-TV industry seeks to extend its reach to portable display devices. At the same time, it seeks to ensure a horizontal market by making interoperable the Conditional Access Systems (CASs) employed to protect content. To achieve interoperability for such devices, this paper proposes a form of selective encryption for video that allows simultaneous distribution of a small percentage of video data on a per-CAS basis, allowing sharing of the unencrypted video between the CASs. The bitrate overhead for each additional CAS enabled is found to be on average 7.41 %, whereas the computational overhead amounts to no more than 40 ms for the benchmark sequences tested. Adaptation of CAS to transparent encryption of scalable video is also demonstrated in this paper.
C1 [Asghar, Mamoona Naveed; Makki, Sohail] Islamia Univ Bahawalpur, Dept Comp Sci & IT, Bahawalpur, Pakistan.
   [Fleury, Martin] Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Islamia University of Bahawalpur
RP Fleury, M (corresponding author), Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
EM fleury.martin55@gmail.com
OI Asghar, Mamoona/0000-0001-7460-266X
CR [Anonymous], 1992, COND ACC BROADC SYST
   ARRIS, 2015, JOINT STAT DSTAC REP
   Asghar M.N., 2012, RECENT PAT TELECOMMU, V1, P41
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Asghar MN, 2012, J KING SAUD UNIV-COM, V24, P107, DOI 10.1016/j.jksuci.2011.12.002
   Asghar MN, 2014, MULTIMEDIA TOOLS APP
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   Boyadjis B, 2014, IEEE IMAGE PROC, P3432, DOI 10.1109/ICIP.2014.7025697
   Brown R, 2015, DOWNLOADABLE SECURIT
   Chow S, 2003, LECT NOTES COMPUT SC, V2595, P250
   Clayson PL, 1997, IEE CONF PUBL, P470, DOI 10.1049/cp:19971314
   COUTROT F, 1989, IEEE T CONSUM ELECTR, V35, P464, DOI 10.1109/30.44305
   Deng RH, 2014, MULTIMEDIA SYST, V20, P165, DOI 10.1007/s00530-013-0326-0
   Downloadable Security Technology Advisory Committee, 2015, DSTAC SUMM REP
   Hong D, 2012, IEEE INT SYMP CIRC S, P890, DOI 10.1109/ISCAS.2012.6272185
   Jakobsson M., 2002, Security and Privacy in Digital Rights Management. ACM CCS-8 Workshop DRM 2001. Revised Papers (Lecture Notes in Computer Science Vol.2320), P1
   Kanjanarin W, 2001, NINTH IEEE INTERNATIONAL CONFERENCE ON NETWORKS, PROCEEDINGS, P140, DOI 10.1109/ICON.2001.962331
   Kaufman C., 2002, NETWORK SECURITY PRI
   Koo HS, 2015, 2015 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC), P722, DOI 10.1109/ICTC.2015.7354647
   Li S., 2007, IEEE T CIRCUITS SYST, V17, P1
   Lookabaugh T, 2004, IEEE COMMUN MAG, V42, P124, DOI 10.1109/MCOM.2004.1299355
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mikityuk A, 2014, IEEE INT CONF COMMUN, P193, DOI 10.1109/ICCChina.2014.7008270
   Moon J, 2008, Third 2008 International Conference on Convergence and Hybrid Information Technology, Vol 2, Proceedings, P380, DOI 10.1109/ICCIT.2008.222
   Pedlow Jr LM, 2007, US patent, Patent No. [7,263,187 B2, 7263187]
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Rosenblatt B, 2011, CISC VIS NETW IND GL
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Shamir A, 1999, LECT NOTES COMPUT SC, V1648, P118
   Shirazi H, 2010, IEEE T BROADCAST, V56, P44, DOI 10.1109/TBC.2009.2036956
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun HM, 2009, IEEE T MULTIMEDIA, V11, P947, DOI 10.1109/TMM.2009.2021790
   Tews E, 2011, P W EUR WORKSH RES C, P96
   Tian C, 2013, INT CONF NETW DISTR, P89, DOI 10.1109/ICNDC.2013.33
   van Rijnsoever BJ, 2003, J VLSI SIG PROC SYST, V34, P167, DOI 10.1023/A:1022878024170
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Wan ZG, 2013, IEEE T MULTIMEDIA, V15, P1353, DOI 10.1109/TMM.2013.2250493
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weinmann, 2004, P 9 IFIP TC 6 TC 11, P195
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zimmermann P., 2011, 6189 IETF RFC
NR 46
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13139
EP 13152
DI 10.1007/s11042-016-3725-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900009
DA 2024-07-18
ER

PT J
AU Tong, XJ
   Chen, PH
   Zhang, M
AF Tong, Xiao-Jun
   Chen, Penghui
   Zhang, Miao
TI A joint image lossless compression and encryption method based on
   chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression joint encryption; Lossless compression; Chaotic image
   encryption; SPIHT; Integer wavelet transform
AB Nowadays poor security, low transmission and storage efficiency of images have become serious concerns. In order to improve the situation, this paper put forward a new image lossless compression joint encryption algorithm based on chaotic map with all original information intact. The lossless compression uses SPIHT(Set Partitioning in Hierarchical Trees) encoding method based on integer wavelet transform, and encrypt multiple rounds in the process of wavelet coefficients and SPIHT coding applying many kinds of chaotic maps. Experimental results show that the compressed file size is about 50 % of the original file size, which achieves relatively good lossless compression ratio. Besides, the encryption method passes many security tests, such as sensitivity test, entropy test, autocorrelation test, NIST SP800-22 test. There is a high application value in the medical field and the national security department whose image files require a relatively high quality.
C1 [Tong, Xiao-Jun; Chen, Penghui; Zhang, Miao] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China.
C3 Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Shandong, Peoples R China.
EM tong_xiaojun@163.com; cph9109@163.com; zhangmiaozm209@126.com
RI chen, peng/HMD-1278-2023
FU National Natural Science Foundation of China [60973162]; Natural Science
   Foundation of Shandong Province of China [ZR2014FM026, ZR2009GM037];
   Science and Technology of Shandong Province, China [2013GGX10129,
   2010GGX10132, 2012GGX10110]; National Cryptology Development Foundation
   of China [MMJJ201301006]; Foundation of Science and Technology on
   Information Assurance Laboratory [KJ-14-005]; Engineering Technology and
   Research Center of Weihai Information Security
FX This work was supported by the National Natural Science Foundation of
   China (60973162), the Natural Science Foundation of Shandong Province of
   China (ZR2014FM026, ZR2009GM037), the Science and Technology of Shandong
   Province, China (2013GGX10129, 2010GGX10132, 2012GGX10110), the National
   Cryptology Development Foundation of China (No. MMJJ201301006),
   Foundation of Science and Technology on Information Assurance Laboratory
   (No. KJ-14-005) and the Engineering Technology and Research Center of
   Weihai Information Security.
CR [Anonymous], 2013, ELECT J DIFFER EQU
   [Anonymous], 2008, PROC INT C COMMUN NE
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Chen SL, 2010, IEEE T CIRCUITS-II, V57, P996, DOI 10.1109/TCSII.2010.2083170
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Deng Jia-xian, 2013, Acta Photonica Sinica, V42, P121, DOI 10.3788/gzxb20134201.0121
   Hadjem T, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, DECISION AND INFORMATION TECHNOLOGIES (CODIT), P706, DOI 10.1109/CoDIT.2014.6996983
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Li XB, 1997, PATTERN RECOGN LETT, V18, P1253, DOI 10.1016/S0167-8655(97)00099-8
   Lian SG, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2195, DOI 10.1109/ICME.2004.1394705
   Liao X, 2009, CHAOTIC CRYPTOFIGURE, P43
   Liu F, 2007, ACTA PHYS SIN-CH ED, V56, P5629, DOI 10.7498/aps.56.5629
   Luo Rui, 2001, THESIS, P93
   Persohn KJ, 2012, CHAOS SOLITON FRACT, V45, P238, DOI 10.1016/j.chaos.2011.12.006
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sun Y, 2012, WAVELET TRANSFORM IM, P1
   Wang B, 2014, OPTIK, V125, P6117, DOI 10.1016/j.ijleo.2014.06.107
   Wang D, 2014, OPT PRECIS ENG, V22, P2529
   Weina D, 2002, J CIRCUIT SYST, V7, P73
   Wu Y., 2013, The Age and Ore-forming Process of MVT Deposits in the Boundary Area of Sichuan-Yunnan-Guizhou Provinces, Southwest China, P1
   Xie Y, 2013, ACTA PHYS SINICA, V62
   [谢耀华 XIE Yao-hua], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P236
   Yang H, 2012, ACTA PHYS SINICA, V61
   Zhang L, 2003, J SOFTW, V14, P1432
   Zhang XP, 2014, MULTIMED TOOLS APPL, V72, P489, DOI 10.1007/s11042-013-1392-1
   沈昌祥, 2007, [中国科学. E辑, 技术科学, Science in China. E], V37, P129
NR 29
TC 30
Z9 31
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13995
EP 14020
DI 10.1007/s11042-016-3775-6
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800015
DA 2024-07-18
ER

PT J
AU Acar, E
   Hopfgartner, F
   Albayrak, S
AF Acar, Esra
   Hopfgartner, Frank
   Albayrak, Sahin
TI A comprehensive study on mid-level representation and ensemble learning
   for emotional analysis of video material
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video affective content analysis; Ensemble learning; Deep learning;
   MFCC; Color; Dense trajectories; SentiBank
AB In today's society where audio-visual content such as professionally edited and user-generated videos is ubiquitous, automatic analysis of this content is a decisive functionality. Within this context, there is an extensive ongoing research about understanding the semantics (i.e., facts) such as objects or events in videos. However, little research has been devoted to understanding the emotional content of the videos. In this paper, we address this issue and introduce a system that performs emotional content analysis of professionally edited and user-generated videos. We concentrate both on the representation and modeling aspects. Videos are represented using mid-level audio-visual features. More specifically, audio and static visual representations are automatically learned from raw data using convolutional neural networks (CNNs). In addition, dense trajectory based motion and SentiBank domain-specific features are incorporated. By means of ensemble learning and fusion mechanisms, videos are classified into one of predefined emotion categories. Results obtained on the VideoEmotion dataset and a subset of the DEAP dataset show that (1) higher level representations perform better than low-level features, (2) among audio features, mid-level learned representations perform better than mid-level handcrafted ones, (3) incorporating motion and domain-specific information leads to a notable performance gain, and (4) ensemble learning is superior to multi-class support vector machines (SVMs) for video affective content analysis.
C1 [Acar, Esra; Albayrak, Sahin] Tech Univ Berlin, DAI Lab, Ernst Reuter Pl 7,TEL 14, D-10587 Berlin, Germany.
   [Hopfgartner, Frank] Univ Glasgow, Humanities Adv Technol & Informat Inst, Glasgow, Lanark, Scotland.
C3 Technical University of Berlin; University of Glasgow
RP Acar, E (corresponding author), Tech Univ Berlin, DAI Lab, Ernst Reuter Pl 7,TEL 14, D-10587 Berlin, Germany.
EM esraacar@gmail.com
RI Hopfgartner, Frank/H-4598-2014
OI Hopfgartner, Frank/0000-0003-0380-6088; Albayrak,
   Sahin/0000-0001-5092-4584
FU European Community [261743]
FX The research leading to these results has received funding from the
   European Community FP7 under grant agreement number 261743 (NoE
   VideoSense).
CR Acar Esra, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P303, DOI 10.1007/978-3-319-04114-8_26
   Acar E, 2015, INT WORK CONTENT MUL
   [Anonymous], ABS151104798
   [Anonymous], 1 INT WORKSH AFF AND
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2014, MM
   [Anonymous], CONT BAS MULT IND CB
   [Anonymous], 1986, EMOTION THEORY RES E
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2011, P 1 INT ACM WORKSHOP, DOI DOI 10.1145/2072529.2072532
   [Anonymous], ABS14108586
   [Anonymous], AAAI C ART INT AAAI
   [Anonymous], INT MULT ENG COMP SC
   [Anonymous], NEUROCOMPUT IN PRESS
   [Anonymous], 2012, P INT S COMP MUS MOD
   [Anonymous], ABS14115731
   [Anonymous], INT C AFF COMP INT I
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Baveye Y, 2015, INT CONF AFFECT, P77, DOI 10.1109/ACII.2015.7344554
   Baveye Y, 2015, IEEE T AFFECT COMPUT, V6, P43, DOI 10.1109/TAFFC.2015.2396531
   Baveye Y, 2013, INT CONF AFFECT, P13, DOI 10.1109/ACII.2013.9
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Borth D., 2013, P 21 ACM INT C MULT, P459
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Da Vitoria Mosteiro S.Bento, 2012, PROC ISMIR, P325
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Eggink J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P140, DOI 10.1109/ICME.2012.68
   Ellis JG, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P287, DOI 10.1109/ISM.2014.69
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Irie G, 2009, IEEE INT CON MULTI, P522, DOI 10.1109/ICME.2009.5202548
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Pang L, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P619, DOI 10.1145/2671188.2749400
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Wimmer M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P145
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   YANG XW, 1992, IEEE T INFORM THEORY, V38, P824, DOI 10.1109/18.119739
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, P414
NR 46
TC 21
Z9 23
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11809
EP 11837
DI 10.1007/s11042-016-3618-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000038
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Stojanovic, B
   Neskovic, A
   Marques, O
AF Stojanovic, Branka
   Neskovic, Aleksandar
   Marques, Oge
TI A novel neural network based approach to latent overlapped fingerprints
   separation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Overlapped fingerprints; Fingerprint separation; Fingerprint
   verification; Neural networks; Orientation field enhancement
AB Overlapped fingerprints are often found in latent fingerprints lifted from crime scenes and in live-scan fingerprint images when the surface of fingerprint sensors contains residues of fingerprints of previous users. Such overlapped fingerprints usually cannot be processed accurately by contemporary commercial fingerprint matchers, which has led many researchers to propose methods designed to separate the overlapped fingerprints. In this paper, we propose a novel latent overlapped fingerprints separation algorithm based on neural networks. Our algorithm works in a block-based fashion. After producing an initial estimation of the orientation fields present in the overlapped fingerprint image, it uses a neural network to separate the mixed orientation fields, which are then post-processed to correct remaining errors and enhanced using the global orientation field enhancement model. Experimental results show that the proposed algorithm outperforms the state-of-the-art algorithm in terms of accuracy on the Tsinghua Overlapped Latent Fingerprint Database (containing real-world overlapped fingerprints obtained by forensic methods), while also showing encouraging results (second only to state-of-the-art) on the Tsinghua Simulated Overlapped Fingerprint Database (containing artificially overlapped fingerprints of a good quality).
C1 [Stojanovic, Branka; Neskovic, Aleksandar] Univ Belgrade, Sch Elect Engn, 73 Kralja Aleksandra Blvd, Belgrade 11120, Serbia.
   [Stojanovic, Branka] Vlatacom Inst LTD Belgrade, 5 Milutina Milankovica Blvd, Belgrade 11070, Serbia.
   [Marques, Oge] Florida Atlantic Univ, Boca Raton, FL 33431 USA.
C3 University of Belgrade; State University System of Florida; Florida
   Atlantic University
RP Marques, O (corresponding author), Florida Atlantic Univ, Boca Raton, FL 33431 USA.
EM branka.stojanovic@vlatacom.com; neshko@etf.rs; omarques@fau.edu
RI Neskovic, Aleksandar M/KSM-9517-2024
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [1464537] Funding Source: National Science Foundation
CR [Anonymous], 2011, P INT JOINT C BIOM
   [Anonymous], 2010, SPIE DEFENSE SECURIT
   [Anonymous], IEEE 6 INT C BIOM TH
   [Anonymous], FVC2002 2 INT FINGER
   [Anonymous], 3 WORLD C NAT BIOL I
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Chen FL, 2011, IEEE T INF FOREN SEC, V6, P346, DOI 10.1109/TIFS.2011.2114345
   Chetty G., 2006, BIOMETRICS S SPECIAL, P1
   Feng JJ, 2013, IEEE T PATTERN ANAL, V35, P925, DOI 10.1109/TPAMI.2012.155
   Feng JJ, 2012, IEEE T INF FOREN SEC, V7, P1498, DOI 10.1109/TIFS.2012.2204254
   Gorodnichy D.O., 2011, IEEE Workshop on Computational Intelligence in Biometrics and Identity Management (CIBIM), P44
   Hassoun MH., 1995, FUNDAMENTALS ARTIFIC
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Msiza IS, 2011, INT J INNOV COMPUT I, V7, P5313
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   Tamura S, 1997, IEEE T NEURAL NETWOR, V8, P251, DOI 10.1109/72.557662
   Zhang N, 2014, INT C PATT RECOG, P678, DOI 10.1109/ICPR.2014.127
   Zhang N, 2014, IEEE T INF FOREN SEC, V9, P1547, DOI 10.1109/TIFS.2014.2340573
   Zhao QJ, 2012, IEEE T INF FOREN SEC, V7, P904, DOI 10.1109/TIFS.2012.2187281
NR 21
TC 12
Z9 12
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12775
EP 12799
DI 10.1007/s11042-016-3696-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200027
DA 2024-07-18
ER

PT J
AU Zhao, X
   Ding, GG
AF Zhao, Xin
   Ding, Guiguang
TI Query expansion for object retrieval with active learning using BoW and
   CNN feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active learning; Query expansion; Convolutional neural network; Image
   retrieval
ID SCALE
AB Most effective particular object and image retrieval approaches are based on the bag-of-words (BoW) model, and all state-of-the-art performance mainly involves a query expansion procedure, which is able to significantly improve retrieval results. Nowadays, Convolutional Neural Network(CNN) is widely applied in computer vision field, including image classification, caption, recognition and retrieval, etc. We introduce an extension to query expansion: an automatic method to select good candidate samples for interactive annotation which is used in query expansion using both BoW method and CNN feature. In this work, we address the query expansion framework using active learning, where the main focus is on the sample selection step in the process of query expansion. More specifically, we propose an active sample selection algorithm based on binary relevance classification, based on the assumption that most confusing samples of the classifiers have high probability to contain helpful true positives for query expansion, which significantly improves the retrieval performance. It takes full use of the multimodal information of the shortlist obtained from the basic retrieval to train a binary relevance classifier, which is used to pick up the most confusing samples for human annotation, with top list as unlabeled data and bottom list as fake negatives. And it can achieve a faster and better retrieval than naive top sample selection method. We also fuse BoW vector and CNN prediction in the retrieval system for a better performance. To evaluate the performance of our proposed method, experiments are conducted on Standard Oxford (5K and 105K) and Paris (6K) datasets, and experimental results and comparison with the state-of-the-art methods demonstrate the effectiveness of the proposed method.
C1 [Zhao, Xin; Ding, Guiguang] Tsinghua Univ, Beijing Haidian Disctrict, Beijing Shi, Peoples R China.
C3 Tsinghua University
RP Ding, GG (corresponding author), Tsinghua Univ, Beijing Haidian Disctrict, Beijing Shi, Peoples R China.
EM zhaoxin19@gmail.com; dinggg@tsinghua.edu.cn
RI Xin, Zhao/AFZ-5025-2022; Ding, Guiguang/KIL-3528-2024
FU National Natural Science Foundation of China [61571269]
FX This research was supported by the National Natural Science Foundation
   of China (Grant No. 61571269). The authors would like to thank the
   anonymous reviewers for their valuable comments.
CR [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2008, IEEE C COMP VIS PATT
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Blanchard G, 2010, J MACH LEARN RES, V11, P2973
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   du Plessis MC, 2014, ADV NEUR IN, V27
   du Plessis MC, 2015, PR MACH LEARN RES, V37, P1386
   Jegou H., 2007, IEEE C COMP VIS PATT
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nister David, 2006, CVPR
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Zhu CZ, 2013, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2013.214
NR 28
TC 6
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12133
EP 12147
DI 10.1007/s11042-016-4142-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000055
DA 2024-07-18
ER

PT J
AU Lu, YG
   Wei, Y
   Liu, L
   Zhong, J
   Sun, LT
   Liu, Y
AF Lu, Yonggang
   Wei, Ye
   Liu, Li
   Zhong, Jun
   Sun, Letian
   Liu, Ye
TI Towards unsupervised physical activity recognition using smartphone
   accelerometers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Physical activity recognition; Unsupervised method; Accelerometer;
   Smartphone
ID FRAMEWORK; HEALTH
AB The development of smartphones equipped with accelerometers gives a promising way for researchers to accurately recognize an individual's physical activity in order to better understand the relationship between physical activity and health. However, a huge challenge for such sensor-based activity recognition task is the collection of annotated or labelled training data. In this work, we employ an unsupervised method for recognizing physical activities using smartphone accelerometers. Features are extracted from the raw acceleration data collected by smartphones, then an unsupervised classification method called MCODE is used for activity recognition. We evaluate the effectiveness of our method on three real-world datasets, i.e., a public dataset of daily living activities and two datasets of sports activities of race walking and basketball playing collected by ourselves, and we find our method outperforms other existing methods. The results show that our method is viable to recognize physical activities using smartphone accelerometers.
C1 [Lu, Yonggang; Wei, Ye; Zhong, Jun; Sun, Letian] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
   [Liu, Li] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Liu, Li; Liu, Ye] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 Lanzhou University; Chongqing University; National University of
   Singapore
RP Liu, L (corresponding author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.; Liu, L (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
EM ylu@lzu.edu.cn; weiy13@lzu.edu.cn; dcsliuli@cqu.edu.cn;
   zhongj13@lzu.edu.cn; sunyt_13@lzu.edu.cn; ye.liu@nus.edu.sg
RI Liu, Ye/D-9148-2018
OI Liu, Ye/0000-0002-1969-2639
FU National Science Foundation of China [61272213, 61370219]; Cuiying Grant
   of China Telecom, Gansu Branch [lzudxcy-2013-3]; Science and Technology
   Planning Project of Chengguan District, Lanzhou [2013-3-1]; Scientific
   Research Foundation for the Returned Overseas Chinese Scholars, State
   Education Ministry [44th]
FX This work is supported by the National Science Foundation of China
   (Grants No. 61272213, 61370219), Cuiying Grant of China Telecom, Gansu
   Branch(grant no. lzudxcy-2013-3), Science and Technology Planning
   Project of Chengguan District, Lanzhou grant no. 2013-3-1), and
   Scientific Research Foundation for the Returned Overseas Chinese
   Scholars, State Education Ministry (grant no. 44th). The authors want to
   thank the volunteers for their time and effort to help us collecting
   data.
CR Alshurafa N, 2014, IEEE J BIOMED HEALTH, V18, P1636, DOI 10.1109/JBHI.2013.2287504
   [Anonymous], 1987, CLUSTERING MEANS MED
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], 2014, P INT ACM SIGIR WORK
   Ashton D, 1993, MONDIALE SANT BUREAU
   Bader GD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-2
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Bulling A, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2134203.2134205
   Casale P, 2012, PERS UBIQUIT COMPUT, V16, P563, DOI 10.1007/s00779-011-0415-z
   de Vries SI, 2011, MED SCI SPORT EXER, V43, P101, DOI 10.1249/MSS.0b013e3181e5797d
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ermes M, 2008, IEEE T INF TECHNOL B, V12, P20, DOI 10.1109/TITB.2007.899496
   FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117
   Hong YJ, 2010, SIMUL MODEL PRACT TH, V18, P446, DOI 10.1016/j.simpat.2009.09.002
   Hospedales TM, 2011, IEEE T PATTERN ANAL, V33, P2451, DOI 10.1109/TPAMI.2011.81
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Khan AM, 2010, IEEE T INF TECHNOL B, V14, P1166, DOI 10.1109/TITB.2010.2051955
   Kirkup JA, 2014, PROCEDIA ENGINEER, V72, P108, DOI 10.1016/j.proeng.2014.06.021
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lee JB, 2013, SENSORS-BASEL, V13, P16065, DOI 10.3390/s131216065
   Lester J, 2006, LECT NOTES COMPUT SC, V3968, P1
   Liu L, 2015, KNOWL-BASED SYST, V90, P138, DOI 10.1016/j.knosys.2015.09.024
   Liu Y, 2015, INT J GENOMICS, V2015, DOI [10.1155/2015/429469, 10.1155/2015/761063]
   Mysore P., 2005, AAAI, V5, P1541
   Nie L., 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286406
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Patterson DJ, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P44, DOI 10.1109/ISWC.2005.22
   REVELLE W, 1979, MULTIVAR BEHAV RES, V14, P57, DOI 10.1207/s15327906mbr1401_4
   Sun LT, 2014, LECT NOTES COMPUT SC, V8549, P150, DOI 10.1007/978-3-319-08416-9_16
   Taniguchi A, 2012, 2012 PROCEEDINGS OF SICE ANNUAL CONFERENCE (SICE), P361
   Vail DouglasL., 2007, Proceedings of the 6th international joint con- ference on Autonomous agents and multiagent systems, P235, DOI DOI 10.1145/1329125.1329409
   Van Kasteren T, 2007, BAYESIAN ACTIVITY RE
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wei Y, 2015, LECT NOTES ARTIF INT, V9403, P691, DOI 10.1007/978-3-319-25159-2_63
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang M, 2013, IEEE J BIOMED HEALTH, V17, P553, DOI 10.1109/JBHI.2013.2253613
   Zheng Yonglei, 2013, IAAI
   Zhong J, 2014, 2014 IEEE 11TH INTL CONF ON UBIQUITOUS INTELLIGENCE AND COMPUTING AND 2014 IEEE 11TH INTL CONF ON AUTONOMIC AND TRUSTED COMPUTING AND 2014 IEEE 14TH INTL CONF ON SCALABLE COMPUTING AND COMMUNICATIONS AND ITS ASSOCIATED WORKSHOPS, P850, DOI 10.1109/UIC-ATC-ScalCom.2014.49
NR 49
TC 128
Z9 128
U1 0
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10701
EP 10719
DI 10.1007/s11042-015-3188-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400022
DA 2024-07-18
ER

PT J
AU Tabejamaat, M
   Mousavi, A
AF Tabejamaat, Mohsen
   Mousavi, Abdolmajid
TI Concavity-orientation coding for palmprint recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concavity-orientation coding; Banana filter; Palmprint recognition;
   Biometrics
ID IDENTIFICATION; VERIFICATION
AB Efficient feature extraction strategies play an important role in palmprint recognition systems. Among various feature extraction methods, orientation methods such as Competitive Code and Half Orientation Code are the baseline ones. They encode responses of a bank of orientational filters into a binary representation and can match a test palmprint sample in real-time with a relatively good accuracy. However, they use the orientation information based upon this idea that palmprints encompass only straight lines with different orientations, whereas in reality, the majority of palm's lines are curved. This observation naturally brings the idea that the concavity and orientation features as different aspects of palmprints curves might provide more reliable and discriminative representations in palmprint recognition. Motivated by this idea, in this work we investigate the use of the concavity feature in different orientations for palmprint recognition. The experimental results, which are applied on PolyU II, 2D/3D PolyU, and blue and near infrared range images from Multispectral PolyU palmprint databases prove the efficiency of this idea compared to other coding-based methods.
C1 [Tabejamaat, Mohsen; Mousavi, Abdolmajid] Lorestan Univ, Dept Elect Engn, Fac Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mousavi, A (corresponding author), Lorestan Univ, Dept Elect Engn, Fac Engn, Khorramabad, Iran.
EM mousavi.m@lu.ac.ir
CR Altun AA, 2013, NEURAL COMPUT APPL, V22, pS27, DOI 10.1007/s00521-011-0800-6
   [Anonymous], 2003, DMKD, DOI DOI 10.1145/882082.882086
   Badrinath GS, 2011, APPL SOFT COMPUT, V11, P4267, DOI 10.1016/j.asoc.2010.05.031
   Chen GY, 2007, IMAGE VISION COMPUT, V25, P960, DOI 10.1016/j.imavis.2006.07.009
   Ding B, 2006, ICSP 2006
   Du F, 2011, COMM COM INF SC, V159, P230
   Fei LK, 2016, PATTERN RECOGN LETT, V69, P35, DOI 10.1016/j.patrec.2015.10.003
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Jaafar H, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/360217
   Jang W, 2006, LECT NOTES COMPUT SC, V3832, P258
   Jazzar MM, 2013, ARAB J SCI ENG, V38, P849, DOI 10.1007/s13369-012-0524-7
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Kipsang Choge H., 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P4993
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   [李文新 Li Wenxin], 2004, [计算机研究与发展, Journal of Computer Research and Development], V41, P996
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Morales A, 2011, IET COMPUT VIS, V5, P407, DOI 10.1049/iet-cvi.2010.0191
   Ni JY, 2015, J SENSORS, V2015, DOI 10.1155/2015/252086
   Pan X, 2008, NEUROCOMPUTING, V71, P3032, DOI 10.1016/j.neucom.2007.12.030
   Pan X, 2009, NEUROCOMPUTING, V72, P2040, DOI 10.1016/j.neucom.2008.11.019
   Peters G, 1997, P 1 STIPR, P113
   Poon C, 2004, INT C PATT RECOG, P533, DOI 10.1109/ICPR.2004.1333827
   Ribaric S, 2005, IEEE T PATTERN ANAL, V27, P1698, DOI 10.1109/TPAMI.2005.209
   Sang H, 2009, LECT NOTES COMPUTER, P831
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tamrakar D, 2015, SIGNAL IMAGE VIDEO P, V9, P535, DOI 10.1007/s11760-013-0475-9
   Wang X, 2013, KNOWL-BASED SYST, V42, P68, DOI 10.1016/j.knosys.2013.01.013
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Wu XQ, 2006, IEEE
   Yu P, 2010, J GUANGDONG U TECHNO, V1
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang YQ, 2012, NEURAL COMPUT APPL, V21, P1835, DOI 10.1007/s00521-011-0521-x
NR 40
TC 21
Z9 21
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9387
EP 9403
DI 10.1007/s11042-016-3544-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300012
DA 2024-07-18
ER

PT J
AU Wang, WC
   Chang, FL
   Liu, YL
   Wu, XJ
AF Wang, Wencheng
   Chang, Faliang
   Liu, Yunlong
   Wu, Xiaojin
TI Expression recognition method based on evidence theory and local texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Evidence theory; Local binary pattern; Texture
   feature
ID BINARY PATTERNS; CLASSIFICATION
AB To the question of feature selection and multi-feature fusion in facial expression recognition, a novel fusion model is proposed in this paper based on evidence theory and local feature operator. First, the facial image is divided into several regions with significant recognition features, and the Local Binary Pattern (LBP) textural features of the regions are extracted. Then, the LBP histograms in the local regions are connected into a single histogram list, and Chi-square distance is used as the similarity measure to establish the guidelines for evidence synthesis. Finally, the Dempster-Shafer evidence inference theory (D.S evidence theory) is adopted to accomplish the feature vector fusion of all components and the class judgment of facial expression is performed. Experiment shows that the method is simple and effective, which has a high recognition rate and can improve the performance of the facial expression recognition system to some extent.
C1 [Wang, Wencheng; Liu, Yunlong; Wu, Xiaojin] Weifang Univ, Dept Informat & Control Engn, Weifang 261061, Peoples R China.
   [Wang, Wencheng; Chang, Faliang] Shandong Univ, Coll Control Sci & Engn, Jinan 250061, Peoples R China.
C3 Weifang University; Shandong University
RP Wang, WC (corresponding author), Weifang Univ, Dept Informat & Control Engn, Weifang 261061, Peoples R China.
EM wwcwfu@126.com
RI Liu, Yunlong/GZN-1795-2022; Wang, Wencheng/A-6146-2018
OI Liu, Yunlong/0000-0002-3662-3512; Wang, Wencheng/0000-0002-0888-9225
FU National Nature Science Foundation of China [61403283, 61273277];
   Shandong Provincial Natural Science Foundation, China [ZR2013FQ036,
   ZR2015PE025]; Technology Development Plan of Weifang City [201301015]
FX This work is supported by National Nature Science Foundation of China
   (No. 61403283, 61273277), Shandong Provincial Natural Science
   Foundation, China (No. ZR2013FQ036, ZR2015PE025), and Technology
   Development Plan of Weifang City(No. 201301015).
CR [Anonymous], 2012, EURASIP J ADV SIG PR, DOI DOI 10.1186/1687-6180-2012-1
   [Anonymous], 2014, INT J SOFTWARE ENG A
   Chowdhury MIH, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P210, DOI 10.1109/ICCITechn.2014.7073131
   DEMPSTER AP, 1967, ANN MATH STAT, V38, P325, DOI 10.1214/aoms/1177698950
   Dosodia P, 2015, INT CONF COMM SYST, P546, DOI 10.1109/CSNT.2015.162
   ESSA IA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P360, DOI 10.1109/ICCV.1995.466916
   [付晓峰 FU Xiao-Feng], 2009, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V22, P123
   Gueorguieva N., 2003, Proceedings of the International Conference on Artificial Intelligence IC-AI'03, P285
   Guo G, 2003, IEEE T SYST MAN CYB, V35, P477
   He J, 2015, CHIN CONT DECIS CONF, P4200, DOI 10.1109/CCDC.2015.7162668
   Jin Hui, 2003, Journal of Software, V14, P2098
   Jun Ou, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P215, DOI 10.1109/ICCMS.2010.45
   Kim DH, 2008, PATTERN RECOGN LETT, V29, P1621, DOI 10.1016/j.patrec.2008.04.006
   Kwak N, 2008, PATTERN RECOGN, V41, P1701, DOI 10.1016/j.patcog.2007.10.012
   Lee CS, 2005, LECT NOTES COMPUT SC, V3723, P17
   Dang LT, 2014, IEEE INT FUZZY SYST, P1297, DOI 10.1109/FUZZ-IEEE.2014.6891864
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Suk M, 2015, IEEE WINT CONF APPL, P1054, DOI 10.1109/WACV.2015.145
   Sun N, 2007, J IMAGE GRAPH, V12, P848
   Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   [杨善林 YANG Shan-Lin], 2009, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V22, P169
   [应自炉 YING Zilu], 2008, [电子学报, Acta Electronica Sinica], V36, P725
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
   Zheng N, 2015, LECT NOTES ARTIF INT, V8869, P26, DOI 10.1007/978-3-319-14899-1_3
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   [周晓彦 ZHOU Xiao-yan], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1615
   [朱明旱 ZHU Ming-Han], 2009, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V22, P60
NR 31
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7365
EP 7379
DI 10.1007/s11042-016-3419-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400056
DA 2024-07-18
ER

PT J
AU Amini, M
   Ahmad, MO
   Swamy, MNS
AF Amini, Marzieh
   Ahmad, M. Omair
   Swamy, M. N. S.
TI Digital watermark extraction in wavelet domain using hidden Markov model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decoder; Watermarking; Statistical modeling; Hidden Markov model
ID IMAGE WATERMARKING; MULTIPLE WATERMARKING; ROBUST; DCT; ALGORITHM;
   MODULATION
AB A watermark decoder aims at extracting the hidden watermark bits from the digital data. Statistical modeling of wavelet subband coefficients has been used in watermark extraction schemes. It is known that the effectiveness of such schemes depends on how accurately the wavelet coefficients are modeled. The vector-based hidden Markov model (HMM) is a very powerful statistical model for describing the distribution of the wavelet coefficients, since it is capable of capturing the subband marginal distribution as well as the inter-scale and cross orientation dependencies of the wavelet coefficients. It is shown that the vector-basedHMM gives a better fit for the empirical data compared to the previously-used distributions. In view of this, we propose a watermark decoder using the vector-based HMM in the wavelet domain. The watermark decoder is designed based on the maximum likelihood criterion. Closed-form theoretical expression for the watermark decoder is derived. The performance of the proposed decoder is assessed using a number of test images. It is shown that the proposed decoder is superior to other decoders in terms of providing a lower bit error rate. The proposed decoder is shown to be highly robust against various kinds of attacks.
C1 [Amini, Marzieh; Ahmad, M. Omair; Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Ctr Signal Proc & Commun, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Ctr Signal Proc & Commun, Montreal, PQ H3G 1M8, Canada.
EM ma_amini@encs.concordia.ca; omair@ece.concordia.ca;
   swamy@ece.concordia.ca
RI Amini, Marzieh/JRZ-1889-2023; Amini, Marzieh/U-1420-2019
OI Amini, Marzieh/0000-0002-5217-2969
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Regroupement Strategique en Microelectronique du Quebec (ReSMiQ)
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and in part by the Regroupement
   Strategique en Microelectronique du Quebec (ReSMiQ).
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P822, DOI 10.1109/TMM.2009.2012922
   Amin MR, 2016, AEBMR ADV ECON, V19, P1
   Amini M, 2015, IEEE INT SYMP CIRC S, P445, DOI 10.1109/ISCAS.2015.7168666
   Amini M, 2014, IEEE INT NEW CIRC, P29, DOI 10.1109/NEWCAS.2014.6933977
   Amini M, 2014, IEEE INT SYMP CIRC S, P2285, DOI 10.1109/ISCAS.2014.6865627
   [Anonymous], P INT WORKSH DIG WAT
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P INT WORKSH DIG WAT
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE T INF FORENSICS
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Briassouli A, 2004, IEEE T IMAGE PROCESS, V13, P1604, DOI 10.1109/TIP.2004.837516
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cheng Q, 2001, IEEE T MULTIMEDIA, V3, P273, DOI 10.1109/6046.944472
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Fan GL, 2001, IEEE T SIGNAL PROCES, V49, P115, DOI 10.1109/78.890351
   Hamghalam M, 2015, MULTIMED TOOLS APPL, V74, P3077, DOI 10.1007/s11042-013-1769-1
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P474, DOI 10.1109/TIP.2010.2064327
   McLachlan G., 2007, EM ALGORITHM EXTENSI
   Nezhadarya E, 2011, IEEE T INF FOREN SEC, V6, P1200, DOI 10.1109/TIFS.2011.2163627
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Pereira S., 2001, INFORM HIDING, P340, DOI [10.1007/3-540-45496-925, DOI 10.1007/3-540-45496-925]
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Singh A., 2016, Microscale Technologies for Cell Engineering, DOI [10.1007/978-3-319-20726-1, DOI 10.1007/978-3-319-20726-1, DOI 10.1007/S11042015-27547]
   Singh AK, 2016, MULTIMED TOOLS APPL, P1
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P406, DOI 10.1166/jmihi.2015.1407
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh AK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P497, DOI 10.1109/PDGC.2012.6449871
   Sun JX, 2004, PATTERN RECOGN, V37, P1315, DOI 10.1016/j.patcog.2003.11.006
   Wang C., 2014, Science China Earth Sciences, P1
   Wang CT, 2012, IEEE T INF FOREN SEC, V7, P853, DOI 10.1109/TIFS.2012.2188797
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang Rong-Yue, 2005, Acta Automatica Sinica, V31, P705
   Zhu XS, 2014, IEEE T MULTIMEDIA, V16, P1888, DOI 10.1109/TMM.2014.2340695
NR 53
TC 25
Z9 26
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3731
EP 3749
DI 10.1007/s11042-016-3975-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200027
DA 2024-07-18
ER

PT J
AU Núñez, JC
   Cabido, R
   Montemayor, AS
   Pantrigo, JJ
AF Nunez, Juan C.
   Cabido, Raul
   Montemayor, Antonio S.
   Pantrigo, Juan J.
TI Real-time human body tracking based on data fusion from multiple RGB-D
   sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human body tracking; Sensor fusion; RGBD sensors
AB In this work we present a human pose estimation method based on the skeleton fusion and tracking using multiple RGB-D sensors. The proposed method considers the skeletons provided by each RGB-D device and constructs an improved skeleton, taking into account the quality measures provided by the sensors at two different levels: the whole skeleton and each joint individually. Then, each joint is tracked by a Kalman filter, resulting in a smooth tracking performance. We have also developed a new dataset consisting of six subjects performing seven different gestures, recorded with four Kinect devices simultaneously. Experimental results performed on this dataset show that the system obtains better smoothness results than the most representative methods found in the literature. The proposed system operates at a processing rate of 25 frames per second (including the whole algorithm loop, i.e., data acquisition and processing) without the explicit use of the multithreading capabilities of the system.
C1 [Nunez, Juan C.; Cabido, Raul; Montemayor, Antonio S.; Pantrigo, Juan J.] Univ Rey Juan Carlos, C Tulipan S-N, Mostoles 28933, Spain.
C3 Universidad Rey Juan Carlos
RP Núñez, JC (corresponding author), Univ Rey Juan Carlos, C Tulipan S-N, Mostoles 28933, Spain.
EM jc.nunezm@alumnos.urjc.es; raul.cabido@urjc.es; antonio.sanz@urjc.es;
   juanjose.pantrigo@urjc.es
RI Pantrigo, Juan José/AAA-2290-2019; Montemayor, Antonio S./Y-5409-2019
OI Pantrigo, Juan José/0000-0002-7175-3371; Montemayor, Antonio
   S./0000-0002-8980-8799; Cabido, Raul/0000-0002-9178-9224
FU Spanish Government [MINECO/FEDER TIN2015-69542-C2-1]; Banco de
   Santander; Universidad Rey Juan Carlos Funding Program for Excellence
   Research Groups ref. "Computer Vision and Image Processing (CVIP)"
FX This research has been partially supported by the Spanish Government
   research funding ref. MINECO/FEDER TIN2015-69542-C2-1 and the Banco de
   Santander and Universidad Rey Juan Carlos Funding Program for Excellence
   Research Groups ref. "Computer Vision and Image Processing (CVIP)".
CR [Anonymous], P INT C INT ROB SYST
   [Anonymous], THESIS
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   [Anonymous], IEEE T CIRCUITS SYST
   Behun K, 2014, P 30 SPRING C COMP G, P55
   Berger K, 2013, COMPUT RES REPOSIT, P4321
   Berger K., 2014, Computer Vision and Machine Learning with RGB-D Sensors, P27
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Destelle F, 2014, EUR SIGNAL PR CONF, P371
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Lacabex B, 2016, INTEGRATED IN PRESS
   MacCormick J., 2002, DISTINGUISHED DISSER
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Morato C, 2014, J COMPUT INF SCI ENG, V14, DOI 10.1115/1.4025810
   Papadopoulos Georgios Th, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P473, DOI 10.1007/978-3-319-04114-8_40
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Souvenir R, 2012, COMPUTER VISION PATT, P1
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Willianson B, 2012, INT IND TRAIN SIM ED
   Yeung KY, 2013, J COMPUT INF SCI ENG, V13, DOI 10.1115/1.4025404
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Yu H, 2016, PROC CVPR IEEE, P952, DOI 10.1109/CVPR.2016.109
   Zhang BC, 2016, INT J COMPUT VISION, V118, P364, DOI 10.1007/s11263-016-0880-y
   Zhu G, 2016, LOCAL SEARCH TRACKIN
NR 27
TC 16
Z9 16
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4249
EP 4271
DI 10.1007/s11042-016-3759-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200053
DA 2024-07-18
ER

PT J
AU Pittarello, F
   Pellegrini, T
AF Pittarello, Fabio
   Pellegrini, Tommaso
TI HCI and education: a blended design experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design thinking; Eco-feedback; Education; Environmental awareness; HCI
   teaching; Interfaces for children; Prototyping tools; Remote learning
AB Teaching HCI in an undergraduate course for computer scientists is often a challenging experience, because the skills that characterize HCI are different from scientific and computational thinking that are the focus of most subjects of the curriculum. Often HCI teaching is organized as a set of lectures that are useful to learn concepts, but don't increase the design skills of the students. This work reports the results of an educational experience where both learners and teachers were actively involved in a process of knowledge construction and design. This process usually happens in other domains, such as architecture or industrial design, but is not part of most computer science curricula. We chose as project a challenging theme: the design of eco-feedback interfaces that inform people about the consequences of their actions for the environment and help to take decisions for lowering energy consumption. Eco-feedback interfaces are also representative of the gap between the products available on the market and the results of scientific studies, evidenced also by a recent workshop about HCI education. The workshop evidenced a number of pitfalls in HCI education that in our educational experience we tried to overcome with appropriate methodologies. An additional challenging task was the attempt to organize all the design activities taking advantage of a platform for remote learning, stressing its limits. The paper will discuss all these issues, evidencing where the applied methodologies gave good results and where they need further improvements, with the final goal of giving useful advices for HCI educational experiences to come.
C1 [Pittarello, Fabio; Pellegrini, Tommaso] Univ Ca Foscari Venezia, Via Torino 155, I-30172 Venice, Italy.
C3 Universita Ca Foscari Venezia
RP Pittarello, F; Pellegrini, T (corresponding author), Univ Ca Foscari Venezia, Via Torino 155, I-30172 Venice, Italy.
EM pitt@unive.it; 805968@stud.unive.it
OI Pittarello, Fabio/0000-0003-2825-9754
CR Amin SM, 2011, EUR J CONTROL, V17, P547, DOI 10.3166/EJC.17.547-567
   Anderson T, 2011, INT REV RES OPEN DIS, V12, P80, DOI 10.19173/irrodl.v12i3.890
   [Anonymous], 2010, 2010 INTERNET THINGS
   [Anonymous], 2011, 8 ACM C, DOI DOI 10.1145/2069618.2069706
   [Anonymous], 2005, CHI 05 EXTENDED ABST
   [Anonymous], 1993, Usability Engineering
   [Anonymous], 2015, Interaction design: Beyond human-computer interaction
   Ardito C, 2015, P 11 BIANN C IT SIGC, P188
   Buxton B., 2007, SKETCHING USER EXPER
   Clow D., 2013, P 3 INT C LEARN AN K, P185, DOI 10.1145/2460296.2460332
   Darby S, 2001, ENERGY EFFICIENCY IN HOUSEHOLD APPLIANCES AND LIGHTING, P685
   Ertmer P.A., 1993, Performance Improvement Quarterly, V6, P50, DOI [10.1002/piq.21143, DOI 10.1002/PIQ.21143, DOI 10.1111/J.1937-8327.1993.TB00605.X]
   Froehlich J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1999
   Greenberg S., 2011, Sketching User Experiences: The Workbook, V1st
   Hargreaves T, 2010, ENERG POLICY, V38, P6111, DOI 10.1016/j.enpol.2010.05.068
   Heller Florian, 2012, Interactions, V19, P14, DOI 10.1145/2065327.2065332
   Holmes T, 2007, CC2007-CREATIVITY AND COGNITION 2007 SEEDING CREATIVITY: TOOLS, MEDIA, AND ENVIRONMENTS, P153
   Ju W., 2015, The Design of Implicit Interactions
   Kalbach J, RESOURCES REMOTE DES
   Landes M, REMOTE DESIGN LOOKS
   Lawson B., 2006, DESIGNERS THINK DESI
   McCalley LT, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P344, DOI 10.1109/APCHI.1998.704455
   Moere AV, 2011, LECT NOTES COMPUT SC, V6946, P470, DOI 10.1007/978-3-642-23774-4_39
   Myers B.A., 1998, ACM INTERACTIONS, V5, P44, DOI DOI 10.1145/274430.274436
   Neenan B., 2009, 1019319 EL POW RES I
   Nisi V., 2013, P BIANN C IT CHAPT S, DOI [10.1145/2499149.2499151, DOI 10.1145/2499149.2499151]
   Pierce J., 2008, P 20 AUSTRALASIAN C, P1
   Short M., 2014, P 14 INT C CONSTR AP
   Snyder C, 2004, PAPER PROTOTYPING
   Spagnolli A, 2011, COMPUTER, V44, P38, DOI 10.1109/MC.2011.125
   United Nations Environmental, UNEP CARB CALC APPL
NR 31
TC 4
Z9 5
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4895
EP 4923
DI 10.1007/s11042-016-3782-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500012
DA 2024-07-18
ER

PT J
AU Dayrit, FL
   Nakashima, Y
   Sato, T
   Yokoya, N
AF Dayrit, Fabian Lorenzo
   Nakashima, Yuta
   Sato, Tomokazu
   Yokoya, Naokazu
TI Increasing pose comprehension through augmented reality reenactment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Mobile; Novel view synthesis; Reenactment
ID FREE-VIEWPOINT VIDEO; TIME
AB Standard video does not capture the 3D aspect of human motion, which is important for comprehension of motion that may be ambiguous. In this paper, we apply augmented reality (AR) techniques to give viewers insight into 3D motion by allowing them to manipulate the viewpoint of a motion sequence of a human actor using a handheld mobile device. The motion sequence is captured using a single RGB-D sensor, which is easier for a general user, but presents the unique challenge of synthesizing novel views using images captured from a single viewpoint. To address this challenge, our proposed system reconstructs a 3D model of the actor, then uses a combination of the actor's pose and viewpoint similarity to find appropriate images to texture it. The system then renders the 3D model on the mobile device using visual SLAM to create a map in order to use it to estimate the mobile device's camera pose relative to the original capturing environment. We call this novel view of a moving human actor a reenactment, and evaluate its usefulness and quality with an experiment and a survey.
C1 [Dayrit, Fabian Lorenzo; Nakashima, Yuta; Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Dayrit, FL (corresponding author), Nara Inst Sci & Technol, 8916-5 Takayama, Nara 6300192, Japan.
EM fabian-d@is.naist.jp; n-yuta@is.naist.jp; tomoka-s@is.naist.jp;
   yokoya@is.naist.jp
RI Nakashima, Yuta/Y-6218-2019
OI Nakashima, Yuta/0000-0001-8000-3567
FU JSPS [23240024, 25540086]; Grants-in-Aid for Scientific Research
   [23240024, 25540086] Funding Source: KAKEN
FX This work was partially supported by JSPS Grant-in-Aid for Scientific
   Research Nos. 23240024 and 25540086.
CR Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [DOI 10.1145/2501988.2502045, 10.1145/2501988.2502045]
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Bingbin D., 2013, P 12 ACM SIGGRAPH IN, P243
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577
   Dayrit FL, 2014, P IEEE INT C MULT EX
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Hauswiesner S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P169, DOI 10.1109/ISMAR.2011.6092383
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Hilsmann A, 2013, COMPUT GRAPH FORUM, V32, P265, DOI 10.1111/cgf.12046
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Klein G., 2007, P IEEE ACM INT S MIX
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Malleson C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P307, DOI 10.1109/ICCVW.2013.48
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   Mousavi Hondori Hossein, 2013, Stud Health Technol Inform, V184, P279
   Pagés R, 2013, SIGNAL PROCESS-IMAGE, V28, P1089, DOI 10.1016/j.image.2013.07.001
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Velloso Eduardo., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1309
   Wang ZB, 2013, INT J ADV MANUF TECH, V69, P1311, DOI 10.1007/s00170-013-5091-x
   Waschbüsch M, 2005, VISUAL COMPUT, V21, P629, DOI 10.1007/s00371-005-0346-7
   Würmlin S, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P325, DOI 10.1109/PCCGA.2002.1167876
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Ye GZ, 2013, IEEE T CYBERNETICS, V43, P1370, DOI 10.1109/TCYB.2013.2272321
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou Z, 2012, P ACM SIGGRAPH AS
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 32
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1291
EP 1312
DI 10.1007/s11042-015-3116-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000056
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Okura, F
   Akaguma, T
   Sato, T
   Yokoya, N
AF Okura, Fumio
   Akaguma, Takayuki
   Sato, Tomokazu
   Yokoya, Naokazu
TI Addressing temporal inconsistency in indirect augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indirect augmented reality; Temporal inconsistency; Spatial
   inconsistency; Cultural heritage
AB Indirect augmented reality (IAR) employs a unique approach to achieve high-quality synthesis of the real world and the virtual world, unlike traditional augmented reality (AR), which superimposes virtual objects in real time. IAR uses pre-captured omnidirectional images and offline superimposition of virtual objects for achieving jitter- and drift-free geometric registration as well as high-quality photometric registration. However, one drawback of IAR is the inconsistency between the real world and the pre-captured image. In this paper, we present a new classification of IAR inconsistencies and analyze the effect of these inconsistencies on the IAR experience. Accordingly, we propose a novel IAR system that reflects real-world illumination changes by selecting an appropriate image from among multiple pre-captured images obtained under various illumination conditions. The results of experiments conducted at an actual historical site show that the consideration of real-world illumination changes improves the realism of the IAR experience.
C1 [Okura, Fumio] Osaka Univ, ISIR, Dept Intelligent Media, Mihogaoka 8-1, Osaka, Ibaraki, Japan.
   [Akaguma, Takayuki; Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol, Vis & Media Comp Lab, Takayama 8916-5, Nara, Japan.
C3 Osaka University; Nara Institute of Science & Technology
RP Okura, F (corresponding author), Osaka Univ, ISIR, Dept Intelligent Media, Mihogaoka 8-1, Osaka, Ibaraki, Japan.
EM okura@am.sanken.osaka-u.ac.jp
RI Okura, Fumio/AFT-2018-2022
OI Okura, Fumio/0000-0001-7595-1300
FU JSPS KAKENHI [23240024, 26330193, 15H06362, 25-7448]; NAIST Advanced
   Research Partnership Project; Grants-in-Aid for Scientific Research
   [23240024, 26330193, 15H06362] Funding Source: KAKEN
FX This research was partially supported by JSPS KAKENHI 23240024,
   26330193, 15H06362, 25-7448, and by the NAIST Advanced Research
   Partnership Project.
CR Akaguma T, 2013, P ACM SIGGRAPH AS 13
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   Arai I, 2010, ADV INTEL SOFT COMPU, V79, P173
   Aydin TO, 2015, IEEE T VIS COMPUT GR, V21, P31, DOI 10.1109/TVCG.2014.2325047
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Cote S, 2013, P 13 INT C CONSTR AP, P262
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   GROSCH T, 2005, MIRAGE 2005 COMPUTER, P25
   Gruber L., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P227, DOI 10.1109/ISMAR.2010.5643580
   Gruber L, 2012, INT SYM MIX AUGMENT, P119, DOI 10.1109/ISMAR.2012.6402548
   Hollerer T., 1999, Digest of Papers. Third International Symposium on Wearable Computers, P79, DOI 10.1109/ISWC.1999.806664
   Kán P, 2012, INT SYM MIX AUGMENT, P99, DOI 10.1109/ISMAR.2012.6402546
   Kanbara M, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P279, DOI 10.1109/ISMAR.2002.1115112
   Kawai N, 2009, LECT NOTES COMPUT SC, V5414, P271, DOI 10.1007/978-3-540-92957-4_24
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Laffont PY, 2013, IEEE T VIS COMPUT GR, V19, P210, DOI 10.1109/TVCG.2012.112
   Langlotz T, 2011, COMPUT GRAPH-UK, V35, P831, DOI 10.1016/j.cag.2011.04.004
   Lensing P, 2012, INT SYM MIX AUGMENT, P109, DOI 10.1109/ISMAR.2012.6402547
   Liestol G, 2013, INT SYM MIX AUGMENT, P23, DOI 10.1109/ISMAR-AMH.2013.6671263
   Madsen JB, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P83, DOI 10.1109/3DUI.2014.6798847
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Okura F, 2015, ACM J COMPUT CULT HE, V8, DOI 10.1145/2700428
   Okura F, 2014, INT SYM MIX AUGMENT, P287, DOI 10.1109/ISMAR.2014.6948453
   Schöps T, 2014, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2014.6948420
   Tenmoku R, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P110, DOI 10.1109/ISWC.2003.1241400
   Uyttendaele M, 2004, IEEE COMPUT GRAPH, V24, P52, DOI 10.1109/MCG.2004.1297011
   Ventura J, 2012, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2012.6402531
   Waegel K, 2014, P IEEE INT S MIX AUG, P379
   Wither J, 2011, COMPUT GRAPH-UK, V35, P810, DOI 10.1016/j.cag.2011.04.010
   Yamamoto Goshiro, 2014, Distributed, Ambient, and Pervasive Interactions. Second International Conference (DAPI 2014) Held as Part of HCI International 2014. Proceedings: LNCS 8530, P392, DOI 10.1007/978-3-319-07788-8_37
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zoelliner M, 2009, 2009 15TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA PROCEEDINGS (VSMM 2009), P193, DOI 10.1109/VSMM.2009.35
NR 34
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2671
EP 2695
DI 10.1007/s11042-015-3222-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA VI3PJ
UT WOS:000474729700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vrochidis, S
   Patras, I
   Kompatsiaris, I
AF Vrochidis, Stefanos
   Patras, Ioannis
   Kompatsiaris, Ioannis
TI Gaze movement-driven random forests for query clustering in automatic
   video annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Implicit feedback; Eye-tracking; Interactive video retrieval;
   Clustering; Random forests
AB In the recent years, the rapid increase of the volume of multimedia content has led to the development of several automatic annotation approaches. In parallel, the high availability of large amounts of user interaction data, revealed the need for developing automatic annotation techniques that exploit the implicit user feedback during interactive multimedia retrieval tasks. In this context, this paper proposes a method for automatic video annotation by exploiting implicit user feedback during interactive video retrieval, as this is expressed with gaze movements, mouse clicks and queries submitted to a content-based video search engine. We exploit this interaction data to represent video shots with feature vectors based on aggregated gaze movements. This information is used to train a classifier that can identify shots of interest for new users. Subsequently, we propose a framework that during testing: a) identifies topics (expressed by query clusters), for which new users are searching for, based on a novel clustering algorithm and b) associates multimedia data (i.e., video shots) to the identified topics using supervised classification. The novel clustering algorithm is based on random forests and is driven by two factors: first, by the distance measures between different sets of queries and second by the homogeneity of the shots viewed during each query cluster defined by the clustering procedure; this homogeneity is inferred from the performance of the gaze-based classifier on these shots. The evaluation shows that the use of aggregated gaze data can be exploited for video annotation purposes.
C1 [Vrochidis, Stefanos; Kompatsiaris, Ioannis] Inst Informat Technol, Ctr Res & Technol Hellas, Thessaloniki, Greece.
   [Patras, Ioannis] Queen Mary Univ London, London, England.
C3 Centre for Research & Technology Hellas; University of London; Queen
   Mary University London
RP Vrochidis, S (corresponding author), Inst Informat Technol, Ctr Res & Technol Hellas, Thessaloniki, Greece.
EM stefanos@iti.gr; I.Patras@eecs.qmul.ac.uk; ikom@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Vrochidis,
   Stefanos/0000-0002-2505-9178; Patras, Ioannis/0000-0003-3913-4738
FU project MULTISENSOR [FP7-610411]; project HOMER [FP7-312388]; project
   PetaMedia [FP7-216444]
FX This work was partially supported by the projects MULTISENSOR
   (FP7-610411), HOMER (FP7-312388) and PetaMedia (FP7-216444).
CR [Anonymous], P ACM MULT 2007 AUGS
   [Anonymous], P 11 INT C ART INT S
   [Anonymous], P EUR C INF RETR ECI
   [Anonymous], P 1 ACM INT C MULT R
   [Anonymous], 9902 BERK U CAL
   [Anonymous], P INT C INT MULT COM
   [Anonymous], ACM T INF SYST
   [Anonymous], J INFORM HIDING MULT
   [Anonymous], J INFORM HIDING MULT
   [Anonymous], 2009, ICMI MLMI
   [Anonymous], 2010, P 2010 S EYE TRACKIN
   [Anonymous], P AFF BRAIN COMP INT
   [Anonymous], P 2008 ACM MULT VANC
   [Anonymous], 2010, P 2010 S EYE TRACK R
   [Anonymous], ICML WORKS REINFORCE
   [Anonymous], 2007, P 6 ACM INT C IM VID
   [Anonymous], P 13 INT WORKSH IM A
   [Anonymous], IEEE T MULTIMED
   [Anonymous], P 28 ANN INT ACM SIG
   [Anonymous], P INT C INNOV COMPUT
   [Anonymous], P 9 ACM SIGMM INT WO
   [Anonymous], P TRECVID 2014 WORKS
   [Anonymous], 2005, P 11 ACM SIGKDD INT
   Breiman L., 2001, Mach. Learn., V45, P5
   Burkard R., 2009, Assignment Problems
   Chang C.C., LIBSVM: a library for support vector machines
   Granka L. A., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P478, DOI 10.1145/1008992.1009079
   Hughes A, 2003, LECT NOTES COMPUT SC, V2728, P271
   Iosifidis A, 2013, SIGNAL PROCESS, V93, P1445, DOI 10.1016/j.sigpro.2012.08.015
   Jaccard P., 1908, B SOCIETE VAUDOISE S, V44, P223, DOI DOI 10.5169/SEALS-268384
   Klami A., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P134, DOI DOI 10.1145/1460096.1460120
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lai PS, 2005, LECT NOTES ARTIF INT, V3682, P1238
   Liu WF, 2015, SIGNAL PROCESS, V110, P101, DOI 10.1016/j.sigpro.2014.08.002
   Liu WF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108474
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Sarafis I, 2015, INT J MULTIMED INF R, V4, P129, DOI 10.1007/s13735-015-0080-5
   Vinh N. X., 2009, P 26 ANN INT C MACH, P1073
   Vrochidis S, 2011, ADV MULTIMED, V2011, DOI 10.1155/2011/310762
   Wen JR, 2002, ACM T INFORM SYST, V20, P59, DOI 10.1145/503104.503108
   Zhang Y, 2010, PROCEEDINGS OF CHINA-CANADA WORKSHOP ON FINANCIAL ENGINEERING AND ENTERPRISE RISK MANAGEMENT 2010, P37, DOI 10.1145/1743666.1743674
NR 44
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2861
EP 2889
DI 10.1007/s11042-015-3221-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000056
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zhao, HL
   You, LH
   Tu, RL
   Wu, XY
   Jin, XG
AF Yang, Yue
   Zhao, Hanli
   You, Lihua
   Tu, Renlong
   Wu, Xueyi
   Jin, Xiaogang
TI Semantic portrait color transfer with internet images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color transfer; Portrait; Image matting; Semantic information
AB We present a novel color transfer method for portraits by exploring their high-level semantic information. First, a database is set up which consists of a collection of portrait images download from the Internet, and each of them is manually segmented using image matting as a preprocessing step. Second, we search the database using Face++ to find the images with similar poses to a given source portrait image, and choose one satisfactory image from the results as the target. Third, we extract portrait foregrounds from both source and target images. Then, the system extracts the semantic information, such as faces, eyes, eyebrows, lips, teeth, etc., from the extracted foreground of the source using image matting algorithms. After that, we perform color transfer between corresponding parts with the same semantic information. We get the final transferred result by seamlessly compositing different parts together using alpha blending. Experimental results show that our semantics-driven approach can generate better color transfer results for portraits than previous methods and provide users a new means to retouch their portraits.
C1 [Yang, Yue; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Zhao, Hanli] Wenzhou Univ, Intelligent Informat Syst Inst, Wenzhou, Peoples R China.
   [You, Lihua] Bournemouth Univ, Poole BH12 5BB, Dorset, England.
   [Tu, Renlong] Fudan Univ, Shanghai, Peoples R China.
   [Wu, Xueyi] Xian Univ Technol, Xian, Peoples R China.
C3 Zhejiang University; Wenzhou University; Bournemouth University; Fudan
   University; Xi'an University of Technology
RP Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM jin@cad.zju.edu.cn
FU National Natural Science Foundation of China [61472351]; Zhejiang
   Provincial Natural Science Foundation of China [LY15F020019]
FX We would like to thank the anonymous reviewers for their constructive
   comments. Xiaogang Jin was supported by the National Natural Science
   Foundation of China (61472351). Hanli Zhao was supported by Zhejiang
   Provincial Natural Science Foundation of China (LY15F020019).
CR An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   [Anonymous], 2011, ACM T GRAPHIC, DOI DOI 10.1145/2010324.1964965
   [Anonymous], 2011, P ACM SIGGRAPHEUROGR
   [Anonymous], 2005, Computational Aesthetics in Graphics, Visualization and Imaging, DOI [DOI 10.2312/COMPAESTH/COMPAESTH05/111-122, 10.2312/COMPAESTH/COMPAESTH05/111-122]
   Chang Y., 2005, ACM Trans. Appl. Perception, V2, P322
   Chang Y, 2007, IEEE T IMAGE PROCESS, V16, P329, DOI 10.1109/TIP.2006.888347
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dong W., 2010, ACM SIGGRAPH ASIA 20
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x
   Huang H., 2014, J NANOMATER, V2014, P1, DOI DOI 10.1371/J0URNAL.P0NE.0091570
   Li X, 2015, SHOCK VIB, V2015, DOI 10.1155/2015/431476
   Liu SG, 2012, J VIS COMMUN IMAGE R, V23, P173, DOI 10.1016/j.jvcir.2011.09.006
   Luan Q, 2007, COLOR TRANSFER BRUSH, P465
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Pouli T, 2011, COMPUT GRAPH-UK, V35, P67, DOI 10.1016/j.cag.2010.11.003
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Tai YW, 2005, PROC CVPR IEEE, P747
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Wen CL, 2008, COMPUT GRAPH FORUM, V27, P1765, DOI 10.1111/j.1467-8659.2008.01321.x
   Wu FZ, 2013, COMPUT GRAPH FORUM, V32, P190, DOI 10.1111/cgf.12008
   Xiao XZ, 2009, COMPUT GRAPH FORUM, V28, P1879, DOI 10.1111/j.1467-8659.2009.01566.x
   Xue S, 2008, IMAGE BASED MAT WEAT
   Yang CK, 2008, IEEE COMPUT GRAPH, V28, P52, DOI 10.1109/MCG.2008.24
   Zhao YD, 2015, IEEE T VIS COMPUT GR, V21, P229, DOI 10.1109/TVCG.2014.2355221
NR 27
TC 29
Z9 31
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 523
EP 541
DI 10.1007/s11042-015-3063-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000023
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Pan, ZQ
   Zhou, Y
   Zhu, LW
AF Zhang, Yun
   Pan, Zhaoqing
   Zhou, Yang
   Zhu, Linwei
TI Allowable depth distortion based fast mode decision and reference frame
   selection for 3D depth coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; H.264/AVC; Depth video coding; Allowable depth distortion;
   Mode decision
ID 3-D VIDEO SYSTEMS; VIEW SYNTHESIS; BIT ALLOCATION; OPTIMIZATION
AB To improve the coding efficiency and meanwhile reduce the complexity of the depth video encoder in 3D system, we present an efficient depth coding scheme based on the allowable depth distortion (ADD) in view synthesis. Firstly, we analyze the depth distortion in view synthesis and present a new ADD-based Rate Distortion (RD) optimization cost function to improve the mode/reference decision criteria. Then, we present an early mode and reference frame selection algorithm, which skips the unnecessary and complex mode and reference frame when the depth distortion is within the ADD interval. Meanwhile, the coding efficiency is improved by RD optimized mode decision and reference frame selection. The experimental results show that the proposed overall algorithm, which integrates the fast mode decision, reference frame selection and RD optimization, can reduce the depth coding complexity from 32.47 to 72.59, and 55.95 % on average over different test sequences. Meanwhile, the proposed algorithm achieves 1.34 and 1.58 dB average Bjontegaard Delta peak signal-to-noise ratio gain in terms of the view synthesis quality at low and high bit rate, respectively. In terms of the bit rate reduction, it reduces 54.66 and 49.60 % Bjontegaard Delta bit rate on average at low and high bit rate, respectively, while maintaining the same view synthesis image quality.
C1 [Zhang, Yun; Zhu, Linwei] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Pan, Zhaoqing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Zhou, Yang] Hangzhou Dianzi Univ, Dept Telecommucat, Hangzhou, Zhejiang, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Nanjing University of Information Science & Technology; Hangzhou
   Dianzi University
RP Zhang, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
EM zhangyun_8851@163.com
RI Zhang, Yun/V-7261-2019
OI Zhang, Yun/0000-0001-9457-7801
FU Natural Science Foundation of China (NSFC) [61471348, 61102088,
   61401132, 61501246]; Shenzhen Overseas High-Caliber Personnel Innovation
   and Entrepreneurship Project [KQCX20140520154115027]; Guangdong Special
   Support Program for Youth Science and Technology Innovation Talents
   [2014TQ01X345]
FX This work was partly supported by Natural Science Foundation of China
   (NSFC) (Grant Nos. 61471348 61102088 61401132 and 61501246), in part by
   Shenzhen Overseas High-Caliber Personnel Innovation and Entrepreneurship
   Project under Grant KQCX20140520154115027, and in part by Guangdong
   Special Support Program for Youth Science and Technology Innovation
   Talents under Grant 2014TQ01X345.
CR [Anonymous], 2014, APSIPA TRANS SIGNAL
   Bjontegaard G., 2001, Document VCEG-M33
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Hannuksela MM, 2013, IEEE T IMAGE PROCESS, V22, P3449, DOI 10.1109/TIP.2013.2269274
   Hu SD, 2013, IEEE T IMAGE PROCESS, V22, P585, DOI 10.1109/TIP.2012.2219549
   Kang MK, 2012, IEEE T MULTIMEDIA, V14, P121, DOI 10.1109/TMM.2011.2169238
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Liu Q, 2012, IEEE SIGNAL PROC LET, V19, P295, DOI 10.1109/LSP.2012.2190060
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Oh BT, 2014, IEEE T CIRC SYST VID, V24, P1006, DOI 10.1109/TCSVT.2013.2290577
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Pan ZQ, 2016, J REAL-TIME IMAGE PR, V11, P27, DOI 10.1007/s11554-013-0328-3
   Peng ZJ, 2010, CHIN OPT LETT, V8, P151, DOI 10.3788/COL20100802.0151
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P1, DOI 10.1109/PCS.2012.6213271
   Tanimoto M, 2009, JTC1SC29WG11 ISO IEC
   Wang X, 2015, SIGNAL PROCESS, V112, P189, DOI 10.1016/j.sigpro.2014.06.025
   Yang Y, 2015, SIGNAL PROCESS, V112, P199, DOI 10.1016/j.sigpro.2014.07.020
   Yang YX, 2015, NEUROCOMPUTING, V149, P1396, DOI 10.1016/j.neucom.2014.08.056
   Yang YX, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023019
   Yoon DH, 2011, P PSIVT 11, V2, P25
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zamarin M, 2014, SIGNAL PROCESS-IMAGE, V29, P711, DOI 10.1016/j.image.2014.05.006
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4879, DOI 10.1109/TIP.2014.2355715
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
   Zhang Y, 2013, IEEE T BROADCAST, V59, P390, DOI 10.1109/TBC.2013.2253033
   Zhang Y, 2011, IEEE T BROADCAST, V57, P15, DOI 10.1109/TBC.2010.2082670
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
   Zhu LW, 2015, MULTIMED TOOLS APPL, V74, P5935, DOI 10.1007/s11042-014-1898-1
NR 30
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1101
EP 1120
DI 10.1007/s11042-015-3109-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000048
DA 2024-07-18
ER

PT J
AU Jeong, YS
   Kim, HW
   Park, J
AF Jeong, Young-Sik
   Kim, Hyun-Woo
   Park, Jong Hyuk
TI An effective locking scheme of smart multimedia devices with convenience
   and enhanced security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart multimedia device; Smart phone; Touch screen; Locking system;
   Security; Secure smart multimedia device
AB The touch screen, the fruit of recent IT development, is incorporated into many applications through a variety of touch screen smart multimedia devices (e.g., digital cameras, TVs, door-lock systems, smart phones, tablet PCs and so on). For smart multimedia devices, it provides convenient use of time and space for many people by replacing many desktop PC functions. Although this convenience has gained popularity among the public, the security is usually neglected. In addition, the miniaturization of smart devices provides easy portability, but it also leads to more chances of being lost or stolen. Inherent features are generalized, but the features also increase risk of exposing personal information. As a result, smart multimedia devices provide a variety of locking features to protect personal information. The features include simple hiding of the screen, password buttons, and pattern locks. Although password and pattern lock features exhibit some degree of security, they are vulnerable to shoulder surfing or smudging. In this paper, vulnerable security points of smart multimedia devices are complemented and the locking system for enhanced security (LSES), in which intuitive user interface provides convenience, is proposed. LSES reduces exposure risk factors with various input methods for the lock pattern.
C1 [Jeong, Young-Sik; Kim, Hyun-Woo] Dongguk Univ, Dept Multimedia Engn, Seoul, South Korea.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Dongguk University; Seoul National University of Science & Technology
RP Park, J (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
EM ysjeong@dongguk.edu; z4538@nate.com; parkjonghyuk1@hotmail.com
FU MSIP (Ministry of Science, ICT and Future Planning), Republic of Korea,
   under the ITRC (Information Technology Research Center) support program
   [NIPA-2014-H0301-14-1021]
FX This research is supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Republic of Korea, under the ITRC (Information
   Technology Research Center) support program (NIPA-2014-H0301-14-1021)
   supervised by the NIPA (National IT Industry Promotion Agency).
CR Alberts CJ, 2002, MANAGING INFORM SECU, P1
   [Anonymous], THESIS
   Aviv AJ, 2010, 4 USENIX WORKSHOP OF, V10, P1
   Chin E., 2012, Proceedings of the Eighth Symposium on Usable Privacy and Security, P1, DOI [DOI 10.1145/2335356.2335358, 10.1145/2335356.2335358.]
   Gong YI, 2010, KOREA INF SOC DEV I, V22
   Hyeong-Il K, 2013, J CONVERG, V4
   ITU-T, 2010, SEC ASP MOB PHON T06
   Junho A, 2012, HUMAN CENTRIC COMPUT, V2
   김창순, 2010, [Journal of The Korea Institute of Information Security and Cryptology, 정보보호학회논문지], V20, P93
   Mulliner C, 2006, LECT NOTES COMPUT SC, V4064, P91
   Peng K, 2013, J INF PROCESS SYST, V9, P247, DOI 10.3745/JIPS.2013.9.2.247
   Wang GJ, 2013, J SUPERCOMPUT, V64, P661, DOI 10.1007/s11227-013-0953-4
NR 12
TC 1
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15171
EP 15183
DI 10.1007/s11042-014-2208-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700003
DA 2024-07-18
ER

PT J
AU Lu, HM
   Li, YJ
   Nakashima, S
   Serikawa, S
AF Lu, Huimin
   Li, Yujie
   Nakashima, Shota
   Serikawa, Seiichi
TI Single image dehazing through improved atmospheric light estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Image restoration; Image enhancement; Atmospheric light
   estimation
ID VISIBILITY
AB Image contrast enhancement for outdoor vision is important for smart car auxiliary transport systems. The video frames captured in poor weather conditions are often characterized by poor visibility. Most image dehazing algorithms consider to use a hard threshold assumptions or user input to estimate atmospheric light. However, the brightest pixels sometimes are objects such as car lights or streetlights, especially for smart car auxiliary transport systems. Simply using a hard threshold may cause a wrong estimation. In this paper, we propose a single optimized image dehazing method that estimates atmospheric light efficiently and removes haze through the estimation of a semi-globally adaptive filter. The enhanced images are characterized with little noise and good exposure in dark regions. The textures and edges of the processed images are also enhanced significantly.
C1 [Lu, Huimin; Li, Yujie; Serikawa, Seiichi] Kyushu Inst Technol, Kitakyushu, Fukuoka, Japan.
   [Lu, Huimin] Chinese Acad Sci, Qingdao, Peoples R China.
   [Lu, Huimin] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Nakashima, Shota] Yamaguchi Univ, Yamaguchi, Japan.
C3 Kyushu Institute of Technology; Chinese Academy of Sciences; Shanghai
   Jiao Tong University; Yamaguchi University
RP Lu, HM (corresponding author), Kyushu Inst Technol, Kitakyushu, Fukuoka, Japan.
EM luhuimin@ieee.org; yzyjli@126.com; s-naka@yamaguchi-u.ac.jp;
   serikawa@elcs.kyutech.ac.jp
RI Li, YuJie/JAC-4451-2023; Li, Yujie/AAH-3298-2019; Li,
   YuJie/HGT-8657-2022
OI Li, Yujie/0000-0002-0275-2797; 
FU Japan Society for the Promotion of Science [15F15077, 13 J10713]; Open
   Fund of the Key Laboratory of Marine Geology and Environment in Chinese
   Academy of Sciences [MGE2015KG02]; Research Fund of State Key Laboratory
   of Marine Geology in Tongji University [MGK1407]; Research Fund of State
   Key Laboratory of Ocean Engineering in Shanghai Jiaotong University
   [OEK1315]; Grants-in-Aid for Scientific Research [15F15077, 15K21197]
   Funding Source: KAKEN
FX All of the authors have the same contribution to this paper. This work
   was supported by Grant in Aid for Foreigner Research Fellows of Japan
   Society for the Promotion of Science (No. 15F15077), Open Fund of the
   Key Laboratory of Marine Geology and Environment in Chinese Academy of
   Sciences (No. MGE2015KG02), Research Fund of State Key Laboratory of
   Marine Geology in Tongji University (MGK1407), Research Fund of State
   Key Laboratory of Ocean Engineering in Shanghai Jiaotong University
   (OEK1315), and Grant in Aid for Research Fellows of Japan Society for
   the Promotion of Science (No. 13 J10713).
CR Ahlen J., 2007, Pattern Recognition and Image Analysis, V17, P170, DOI 10.1134/S105466180701021X
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], P CVPR
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Koschmieder H, 1925, THEORIE HORIZONTALEN, V2, P1
   Liang J, 2014, J APPL PHYS, V116, DOI 10.1063/1.4901244
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao S., 2005, IEEE International Conference on Image Processing 2005, DOI [10.1109/ICIP.2005.1529771, DOI 10.1109/ICIP.2005.1529771]
NR 22
TC 60
Z9 62
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17081
EP 17096
DI 10.1007/s11042-015-2977-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600017
DA 2024-07-18
ER

PT J
AU Pecev, P
   Rackovic, M
   Ivkovic, M
AF Pecev, Predrag
   Rackovic, Milos
   Ivkovic, Miodrag
TI A system for deductive prediction and analysis of movement of basketball
   referees
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple dependent time series; MLP neural networks; LTR - MDTS model;
   Field of vision simulation; Basketball referee movement
ID NEURAL-NETWORK ENSEMBLES; TIME-SERIES PREDICTION
AB This paper presents us with an automatic prediction and analysis of basketball referees movement which is useful for educational software. Such software would be very beneficial in training the young basketball referees. The paper proposes that the movement prediction of basketball referees can be achieved with a multilayered perceptron neural network. Network will reason on the basis of a ball movement during a play action. Proposed neural network will be trained with a modified Back Propagation algorithm which essentially presents a special algorithm for a multiple dependent Time Series prediction. In this paper, we will also describe initial designs of a neural network structure that, we believe, would better suit the nature of a multiple dependent Time Series prediction problems. The aforementioned educational software is capable of determining whether a referee was moving properly in a certain situation or not. Determination is possible on the basis of numerical values that are calculated by simulating the human visual field. The referee's horizontal field of view simulation is based on the standard set by the American Optometric Association. It is implemented through a modified Sweep and Prune algorithm which is also discussed in this paper.
C1 [Pecev, Predrag; Ivkovic, Miodrag] Univ Novi Sad, Tech Fac Mihajlo Pupin, Djure Djakovica BB, Zrenjanin 23000, Serbia.
   [Rackovic, Milos] Univ Novi Sad, Dept Math & Informat, Fac Sci, Trg Dositeja Obradovica 4, Novi Sad 21000, Serbia.
C3 University of Novi Sad; University of Novi Sad
RP Pecev, P (corresponding author), Univ Novi Sad, Tech Fac Mihajlo Pupin, Djure Djakovica BB, Zrenjanin 23000, Serbia.
EM pecev@tfzr.uns.ac.rs; rackovic@dmi.uns.ac.rs; mivkovic@tfzr.uns.ac.rs
RI Pecev, Predrag/JYP-5754-2024; Racković, Miloš/IQT-3885-2023
OI Racković, Miloš/0000-0002-0111-5059
FU Ministry of Science and Technological Development of Republic of Serbia
   [171039, III47003]
FX Research was partially supported by the Ministry of Science and
   Technological Development of Republic of Serbia by Grant 171039 and
   through project no. III47003 "Infrastructure for technology enhanced
   learning in Serbia".
CR Abuadlla Y, 2014, COMPUT SCI INF SYST, V11, P601, DOI 10.2298/CSIS130415035A
   Alahi Alexandre., 2009, Third ACM/IEEE International Conference on Distributed Smart Cameras, P1, DOI DOI 10.1109/ICDSC.2009.5289406
   [Anonymous], IMA C MATH SURF
   [Anonymous], P ACM INT C MULT
   Betancourt D, 2006, PR IEEE SEN ARRAY, P93
   Doulamis N, 2012, LECT NOTES COMPUT SC, V7585, P345, DOI 10.1007/978-3-642-33885-4_35
   Fauerby K, 2003, IMPROVED COLLISION D
   Giles CL, 2001, MACH LEARN, V44, P161, DOI 10.1023/A:1010884214864
   Ivankovic Z, 2014, MULTIMED TOOLS APPL, V72, P2741, DOI 10.1007/s11042-013-1580-z
   Ivankovic Z, 2010, ACTA POLYTECH HUNG, V7, P167
   Khashei M, 2010, EXPERT SYST APPL, V37, P479, DOI 10.1016/j.eswa.2009.05.044
   Lai KK, 2006, JOINT C INF SCI JCIS, DOI [10.2991/JCIS.2006.172, DOI 10.2991/JCIS.2006.172]
   Marcos S, 1999, VISION RES, V39, P2039, DOI 10.1016/S0042-6989(98)00317-4
   Markoski B, 2011, ACTA POLYTECH HUNG, V8, P111
   McBride D, 2010, MODERN MIRACLE MED M
   Moore M, 1998, P SIGGRAPH 88 COMP G, V22, P289
   Najim SA, 2008, COMPUT SCI INF SYST, V5, P127, DOI 10.2298/CSIS0801127N
   Nam J, 2009, MATH STUDIES H UNPUB
   Official, 2014, FIBA RUL
   Oliver D, 2004, BASKETBALL PAPER RUL, P392
   Ons B. R, 2003, OPTIMIZING MULTILAYE
   Patra Moujhuri, 2012, Speech, Sound and Music Processing: Embracing Research in India. 8th International Symposium, CMMR 2011 20th International Symposium, FRSM 2011. Revised Selected Papers, P26, DOI 10.1007/978-3-642-31980-8_2
   Perse M, 2009, COMPUT VIS IMAGE UND, V113, P612, DOI 10.1016/j.cviu.2008.03.001
   Protopapadakis E., 2012, INFOCOMP 2012 2 INT, P155
   Ratgeber L, 2013, ACTA POLYTECH HUNG, V10, P151
   Ruta D., 2007, Proceedings of International Joint Conference on Neural Networks,Orlando,Florida,USA,August 12-17,2007, P1235, DOI DOI 10.1145/1569901.1570067
   Ruta D, 2007, IEEE IJCNN, P1204, DOI 10.1109/IJCNN.2007.4371129
   Santos JMS, 2011, 13 IASE 3 ES C SPORT
   Schumaker RP, 2010, INTEGR SER INFORM SY, V26, P1, DOI 10.1007/978-1-4419-6730-5
   Teo KK, 2001, LECT NOTES COMPUT SC, V2074, P310
   Therón R, 2010, LECT NOTES COMPUT SC, V6133, P196, DOI 10.1007/978-3-642-13544-6_19
   Tracy DJ, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P191, DOI 10.1109/VR.2009.4811022
   Vintan L., 2004, 1 WORKSH MOD RETR CO
   Young ME, 2008, PSYCHOL SPORT EXERC, V9, P760, DOI 10.1016/j.psychsport.2007.12.004
   Zhang GP, 2001, J OPER RES SOC, V52, P652, DOI 10.1057/palgrave.jors.2601133
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
NR 36
TC 9
Z9 11
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16389
EP 16416
DI 10.1007/s11042-015-2938-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700067
DA 2024-07-18
ER

PT J
AU Agirre, A
   Parra, J
   Armentia, A
   Ghoneim, A
   Estévez, E
   Marcos, M
AF Agirre, Aitor
   Parra, Jorge
   Armentia, Aintzane
   Ghoneim, Ahmed
   Estevez, Elisabet
   Marcos, Marga
TI QoS management for dependable sensory environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of service; Service component architecture; Data distribution
   service; Fault tolerance; Safety
ID MIDDLEWARE; STATE
AB Sensory environments for healthcare are commonplace nowadays. A patient monitoring system in such an environment deals with sensor data capture, transmission and processing in order to provide on-the-spot support for monitoring the vulnerable and critical patients. A fault in such a system can be hazardous on the health of the patient. Therefore, such a system must be dependable and ensure reliability, fault-tolerance, safety and other critical aspects, in order to deploy it in real scenario. Also, the management of the infrastructure resources must be efficient and the eventual system reconfiguration must be reliably performed. This paper encounters some of these issues and proposes a component platform with specific support for several QoS aspects, namely fault tolerance, safe inter-component communication and resource management. The platform adopts the Service Component Architecture (SCA) model and defines a Data Distribution Service (DDS) binding, which provides the fault tolerance and the required safety-ensuring techniques and measures, as defined in the IEC 61784-3-3 standard. As a proof of concept, a distributed home care application that improves the medical assistance in case of fire detection is presented.
C1 [Agirre, Aitor; Parra, Jorge] IK4 Ikerlan, Embedded Syst, Arrasate Mondragon, Spain.
   [Estevez, Elisabet] Univ Jaen, Dept Elect & Automat Engn, Jaen, Spain.
   [Armentia, Aintzane; Marcos, Marga] Univ Basque Country UPV EHU, Dept Automat Control & Syst Engn, Leioa, Spain.
   [Ghoneim, Ahmed] King Saud Univ, Coll Comp Sci & Informat Sci, Riyadh, Saudi Arabia.
   [Ghoneim, Ahmed] Menoufia Univ, Coll Sci, Dept Comp Sci, Shibin Al Kawm, Egypt.
C3 Universidad de Jaen; University of Basque Country; King Saud University;
   Egyptian Knowledge Bank (EKB); Menofia University
RP Parra, J (corresponding author), IK4 Ikerlan, Embedded Syst, Arrasate Mondragon, Spain.
EM aagirre@ikerlan.es; jparra@ikerlan.es; aintzane.armentia@ehu.es;
   ghoneim@ksu.edu.sa; eestevez@ujaen.es; marga.marcos@ehu.es
RI Armentia, Aintzane/AAX-7320-2021; Marcos, Marga/J-5984-2019; ghoneim,
   ahmed/L-3019-2013
OI Armentia, Aintzane/0000-0002-6612-241X; Marcos,
   Marga/0000-0001-5570-1072; Ghoneim, Ahmed/0000-0003-2076-8925; Agirre,
   Aitor/0000-0003-4377-8835; Parra, Jorge/0000-0001-6688-891X; Estevez,
   Elisabet/0000-0002-1721-3059
FU University of the Basque Country (UPV/EHU) [UFI 11/28]; Regional
   Government of the Basque Country [IT719-13]; MCYTFEDER [DPI
   2012-37806-C02-01]; Deanship of Scientific Research at King Saud
   University [IRG14-28]
FX This work was financed in part by the University of the Basque Country
   (UPV/EHU) under project UFI 11/28, by the Regional Government of the
   Basque Country under Project IT719-13, and by the MCYT&FEDER under
   project DPI 2012-37806-C02-01. Also, the authors would like to extend
   their sincere appreciation to the Deanship of Scientific Research at
   King Saud University for its funding of this International Research
   Group (IRG14-28).
CR Agirre A., 2011, P MIDDL WORKSH POST
   Agirre A., 2012, 1 IFAC C EMB SYST CO, P218
   Agirre A, 2014, ETFA 2014
   Agirre A., 2013, EM TECHN FACT AUT ET, P1
   Agirre A., 2012, EM TECHN FACT AUT ET, P1
   Agirre A., 2014, MULT EXP WORKSH ICME, P1
   Almeida L, 2007, P 7 ACM IEEE INT C E
   [Anonymous], 2014, OMG VERS 1 4
   [Anonymous], 2004, 61499 IEC
   [Anonymous], 2007, 6178433 IEC
   AUDSLEY N, 1993, SOFTWARE ENG J, V8, P284, DOI 10.1049/sej.1993.0034
   Bruyninckx H, 2003, IEEE INT CONF ROBOT, P2766, DOI 10.1109/ROBOT.2003.1242011
   Buttazzo GC, 2002, IEEE T COMPUT, V51, P289, DOI 10.1109/12.990127
   Chan M, 2008, COMPUT METH PROG BIO, V91, P55, DOI 10.1016/j.cmpb.2008.02.001
   Consortium TO, 2004, FRACT COMP MOD SPEC
   Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001
   Crnkovic I, 2011, IEEE T SOFTWARE ENG, V37, P593, DOI 10.1109/TSE.2010.83
   D'Mello DA, 2010, ENTERP INF SYST-UK, V4, P23, DOI 10.1080/17517570903159467
   De Silva LC, 2012, ENG APPL ARTIF INTEL, V25, P1313, DOI 10.1016/j.engappai.2012.05.002
   Holborn PG, 2003, FIRE SAFETY J, V38, P1, DOI 10.1016/S0379-7112(02)00049-8
   Ing-Yi Chen, 2005, Journal of Medical and Biological Engineering, V25, P73
   JOSEPH M, 1986, COMPUT J, V29, P390, DOI 10.1093/comjnl/29.5.390
   Kim JE, 2009, PROC INT CONF SOFTW, P28, DOI 10.1109/ICSE-COMPANION.2009.5070961
   Laws S, 2011, TUSCANY SCA ACTION
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   Luck H, 1997, FIRE SAFETY J, V29, P77, DOI 10.1016/S0379-7112(96)00030-6
   Malohlava M, 2013, ELECTRON NOTES THEOR, V295, P101, DOI 10.1016/j.entcs.2013.04.009
   Marcos M, 2011, 18 IFAC WORLD C MIL
   Mohagheghi P., 2004, The Impact of Software Reuse and Incremental Development on the Quality of Large Systems
   Mori M, 2011, LECT NOTES COMPUT SC, V7041, P286, DOI 10.1007/978-3-642-24690-6_20
   Nehmer J, 2006, 28 INT C SOFTW ENG S
   OASIS, 2011, SCA POL FRAM VERS 1
   OASIS, 2011, SERV COMP ARCH ASS M
   OASIS, 2007, SERV COMP ARCH
   Pedreiras P., 2003, P 17 INT S PAR DISTR
   Pedreiras P, 2005, IEEE T IND INFORM, V1, P162, DOI 10.1109/TII.2005.852068
   Plsek A, 2008, P 9 ACM IFIP USENIX
   Pop T., 2013, KNOWL INF SYST, P1
   Poza JL, 2009, ADV SOFT COMP, V50, P587
   Rekik R, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT 2009), P766, DOI 10.1109/ICADIWT.2009.5273919
   RICHTER S, 2011, 13 REAL TIM LIN WORK
   Roldan JMD, 1999, PRINCIPIOS URGENCIAS, P1570
   Seinturier L, 2011, COMPONENT BASED MIDD
   Seinturier L, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING, P268, DOI 10.1109/SCC.2009.27
   Shirazi B., 2004, SYST SCI 2004 P 37 A
   Strasser T, 2008, IEEE INTL CONF IND I, P258
   Strunk A., 2010, Proceedings 2010 8th IEEE European Conference on Web Services (ECOWS 2010), P67, DOI 10.1109/ECOWS.2010.16
   Wegdam M, 2003, DYNAMIC RECONFIGURAT
   Yang H, 2009, LECT NOTES COMPUT SC, V5900, P331, DOI 10.1007/978-3-642-10383-4_22
NR 49
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13397
EP 13419
DI 10.1007/s11042-015-2781-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800023
DA 2024-07-18
ER

PT J
AU Choi, HH
   Lim, SA
   Kim, JH
AF Choi, Hak-Hyun
   Lim, Seung-Ae
   Kim, Jung-Hee
TI An efficient expression technique for promotional video production based
   on IoT(the internet of things) in cultural art institutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE The Internet of things; Machine to machine; Cultural arts; Promotion
   video; Big data; Information and Communications technology
AB This paper describes expressive promotional techniques, and proposes editing techniques for public relations videos through a study of the recent technology, The Internet of Things(IoT). IoT is an intelligent information technology that enables the connection among things via the Internet, and the interaction service between human beings and all sorts of objects, of objects themselves. IoT creates an expanded computing environment, and may be an efficient manner of the public-relations video rising its discrimination and competitiveness considering the interaction between the future networks and Big Data. In addition, through a connection between Information and Communications Technology(ICT) and art and culture, we will expand the manner in which it is used to develop stories. Considering the increase in the connection between ICT and art and culture, more studies are necessary in the area of public-relations videos. Therefore, by conducting an experiment on its materialization and proposing a snew plan for its improvement, we connect the features and concepts of IoT to the above field by analyzing existing public-relations videos based on related theoretical studies. The experimental materialization described in this study is the creation of an experimental video using representation techniques in Adobe After Effects, and proposing a new model of these techniques.
C1 [Choi, Hak-Hyun; Lim, Seung-Ae] Seoul Womens Univ, Dept Contents Design, 621 Hwarang Ro, Seoul 139774, South Korea.
   [Kim, Jung-Hee] Sungkyunkwan Univ, Dept Culture Contents, 25-2 Sungkyunkwan Ro, Seoul 110745, South Korea.
C3 Seoul Women's University; Sungkyunkwan University (SKKU)
RP Choi, HH (corresponding author), Seoul Womens Univ, Dept Contents Design, 621 Hwarang Ro, Seoul 139774, South Korea.
EM choiidea@naver.com; lsaictdesigner@gmail.com; creatorkjh@gmail.com
FU Seoul Women's University
FX This work was supported by a special research grant from Seoul Women's
   University(2014).
CR Booysen MJ, 2012, MACHINE TO MACHINE C
   Effland, 2006, ART ED CTR EXPLORE W
   Freedman, 2003, IMPORTANCE STUDENT A
   Gu W., 2010, INT C POW SYST TECHN
   Gubbi J., 2012, Internet of Things (IoT): A vision, architectural elements, and future directions
   Holler J, 2013, M2M IOT MARKET INSIG
   Hong S, 2007, ART MEETS SCI BACHEL
   Mihaly C., 2004, FLOW PSYCHOL OPTIMAL
   Min K. S., 2013, INTERNET OF THINGS
   Parkjihyeon, 2011, USING ICT CHINESE CU
   Vermesan O, 2013, RIVER PUBL SER COMM, P7
   Weiss RJ, 2002, UBIQUITOUS COMPUTING
   Yicheongi, 2002, ICT UTILIZING DESIGN
NR 13
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14111
EP 14124
DI 10.1007/s11042-014-2263-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500007
DA 2024-07-18
ER

PT J
AU Liu, C
   Xu, WS
   Wu, QD
   Yang, GL
AF Liu, Cong
   Xu, Weisheng
   Wu, Qidi
   Yang, Gelan
TI Learning motion and content-dependent features with convolutions for
   action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatiotemporal; Convolutional neural networks; Multiplicative
   interactions; Deep learning; Action recognition
AB A variety of recognizing architectures based on deep convolutional neural networks have been devised for labeling videos containing human motion with action labels. However, so far, most works cannot properly deal with the temporal dynamics encoded in multiple contiguous frames, which distinguishes action recognition from other recognition tasks. This paper develops a temporal extension of convolutional neural networks to exploit motion-dependent features for recognizing human action in video. Our approach differs from other recent attempts in that it uses multiplicative interactions between convolutional outputs to describe motion information across contiguous frames. Interestingly, the representation of image content arises when we are at work on extracting motion pattern, which makes our model effectively incorporate both of them to analysis video. Additional theoretical analysis proves that motion and content-dependent features arise simultaneously from the developed architecture, whereas previous works mostly deal with the two separately. Our architecture is trained and evaluated on the standard video actions benchmarks of KTH and UCF101, where it matches the state of the art and has distinct advantages over previous attempts to use deep convolutional architectures for action recognition.
C1 [Liu, Cong; Xu, Weisheng; Wu, Qidi] Tongji Univ, Sch Elect & Informat Engn, Shanghai 201804, Peoples R China.
   [Yang, Gelan] Hunan City Univ, Sch Informat Sci & Engn, Yiyang 413000, Peoples R China.
C3 Tongji University; Hunan City University
RP Liu, C (corresponding author), Tongji Univ, Sch Elect & Informat Engn, Shanghai 201804, Peoples R China.
EM 1210482congliu@tongji.edu.cn; glyang@mail.ustc.edu.cn
OI Yang, Gelan/0000-0002-2472-3436
FU Science Research Foundation of Hunan Provincial Education Department
   [12B023]
FX The research work described in this paper is supported by Science
   Research Foundation of Hunan Provincial Education Department under grant
   number 12B023.
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2014, CVPR
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], 2014, ARXIV14062199CS
   [Anonymous], IM PROC ICIP 2003 P
   [Anonymous], ARXIVCORR13063162
   [Anonymous], APPL COMP VIS WACV 2
   [Anonymous], J CONVERG
   [Anonymous], COMP VIS ICCV 2011 I
   [Anonymous], AM J PSYCHOL
   [Anonymous], 2012, CoRR
   [Anonymous], 2009, P 26 ANN INT C MACH
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bouagar S, 2016, MULTIMED TOOLS APPL, V75, P2989, DOI 10.1007/s11042-014-2417-0
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Guo J, 2011, J INF PROCESS SYST, V7, P103, DOI 10.3745/JIPS.2011.7.1.103
   Hyvärinen A, 2009, COMPUT IMAGING VIS, V39, P1
   Johnson, 2012, MATRIX ANAL
   Kim H, 2014, THERANOSTICS, V4, P1, DOI 10.7150/thno.7101
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lui S., 2017, Multimedia Tools and Applications, V76, P5787, DOI DOI 10.1007/S11042-014-2408-1
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Memisevic R, 2013, IEEE T PATTERN ANAL, V35, P1829, DOI 10.1109/TPAMI.2013.53
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Szegedy C., 2014, P IEEE CVF C COMP VI, DOI 10.1109/CVPR.2015.7298594
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P2315, DOI 10.1098/rspb.1998.0577
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang H., 2009, BMVC 2009 BRIT MACH
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
NR 40
TC 9
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13023
EP 13039
DI 10.1007/s11042-015-2550-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800003
DA 2024-07-18
ER

PT J
AU Makantasis, K
   Protopapadakis, E
   Doulamis, A
   Doulamis, N
   Matsatsinis, N
AF Makantasis, Konstantinos
   Protopapadakis, Eftychios
   Doulamis, Anastasios
   Doulamis, Nikolaos
   Matsatsinis, Nikolaos
TI 3D measures exploitation for a monocular semi-supervised fall detection
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image motion analysis; Semi-supervised learning; Camera self
   calibration; Fall detection
ID REAL-TIME; VIDEO
AB Falls have been reported as the leading cause of injury-related visits to emergency departments and the primary etiology of accidental deaths in elderly. Thus, the development of robust home surveillance systems is of great importance. In this article, such a system is presented, which tries to address the fall detection problem through visual cues. The proposed methodology utilizes a fast, real-time background subtraction algorithm, based on motion information in the scene and pixels intensity, capable to operate properly in dynamically changing visual conditions, in order to detect the foreground object. At the same time, it exploits 3D space's measures, through automatic camera calibration, to increase the robustness of fall detection algorithm which is based on semi-supervised learning approach. The above system uses a single monocular camera and is characterized by minimal computational cost and memory requirements that make it suitable for real-time large scale implementations.
C1 [Makantasis, Konstantinos; Protopapadakis, Eftychios] Tech Univ Crete, Khania, Greece.
   [Matsatsinis, Nikolaos] Tech Univ Crete, Sch Prod Engn & Management, Informat & Decis Support Syst, Khania, Greece.
   [Doulamis, Anastasios; Doulamis, Nikolaos] Natl Tech Univ Athens, Athens, Greece.
   [Doulamis, Nikolaos] Natl Tech Univ Athens, Image Video & Multimedia Lab, Athens, Greece.
C3 Technical University of Crete; Technical University of Crete; National
   Technical University of Athens; National Technical University of Athens
RP Protopapadakis, E (corresponding author), Tech Univ Crete, Khania, Greece.
EM konst.makantasis@gmail.com; eprotopapadakis@isc.tuc.gr;
   adoulam@cs.ntua.gr; ndoulam@cs.ntua.gr; nikos@ergasya.tuc.gr
RI Matsatsinis, Nikolaos F/Q-8291-2016; Protopapadakis,
   Eftychios/AAP-1371-2021; Makantasis, Konstantinos/Q-4475-2018; Doulamis,
   Anastasios/AAL-5972-2021
OI Protopapadakis, Eftychios/0000-0003-3876-0024; Makantasis,
   Konstantinos/0000-0002-0889-2766; 
FU European Union; Greece and Cyprus under the project POSEIDON:
   Development of an Intelligent System for Coast Monitoring using Camera
   Arrays and Sensor Networks in the context of the inter-regional
   programme INTERREG (Greece-Cyprus cooperation) [K1 3 1017/6/2011]
FX The research leading to these results has been supported by European
   Union funds and national funds from Greece and Cyprus under the project
   POSEIDON: Development of an Intelligent System for Coast Monitoring
   using Camera Arrays and Sensor Networks in the context of the
   inter-regional programme INTERREG (Greece-Cyprus cooperation) - contract
   agreement K1 3 1017/6/2011. The work has, also, been supported by IKY
   Fellowships of excellence for post graduate studies in Greece-Siemens
   Program.
CR Anderson D, 2009, COMPUT VIS IMAGE UND, V113, P80, DOI 10.1016/j.cviu.2008.07.006
   [Anonymous], ACCELEROMETER BASED
   [Anonymous], ROBUST VIDEO SURVEIL
   [Anonymous], METHOD AUTOMATIC FAL
   [Anonymous], 1999, IEEE COMP SOC C COMP
   [Anonymous], WEAR MIN FALL DET SY
   [Anonymous], MED ALERT ALARM PERS
   [Anonymous], P 2005 INT C NEUR
   [Anonymous], PETRA 10
   [Anonymous], FALL DETECTION MULTI
   [Anonymous], 2012 13 INT WORKSH I
   [Anonymous], THE COST OF INJURY
   [Anonymous], WEARABLE SYSTEM PREI
   [Anonymous], INFOCOMP 2012 2 INT
   [Anonymous], 2 P H A C GOV CAN PU
   [Anonymous], BAROMETRIC PRESSURE
   Bevilacqua A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P126, DOI 10.1109/ICVGIP.2008.10
   Broszio Hellward, 2003, Mirage, P105
   Chatzis S, 2009, IEEE T FUZZY SYST, V17, P505, DOI 10.1109/TFUZZ.2008.924317
   Cyganek B., 2007, INTRO 3D COMPUTER VI
   Debard Glen, 2012, Outdoor and Large-Scale Real-World Scene Analysis. 15th International Workshop on Theoretical Foundations of Computer Vision. Revised Selected Papers, P356, DOI 10.1007/978-3-642-34091-8_16
   Diraco G, 2010, DES AUT TEST EUROPE, P1536
   Doulamis A, 2011, EUR SIGNAL PR CONF, P779
   Dubey R, 2012, LECT NOTES COMPUT SC, V7325, P106, DOI 10.1007/978-3-642-31298-4_13
   Foroughi Homa, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P219, DOI 10.1109/ICCITECHN.2008.4803020
   Foroughi H, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P413, DOI 10.1109/ICVGIP.2008.49
   Fu ZM, 2008, IEEE INT SYMP CIRC S, P424, DOI 10.1109/ISCAS.2008.4541445
   Grammatikopoulos L, 2007, ISPRS J PHOTOGRAMM, V62, P64, DOI 10.1016/j.isprsjprs.2007.02.002
   Grassi M, 2010, IEEE SENSOR, P1016, DOI 10.1109/ICSENS.2010.5690746
   Hazelhoff L, 2008, LECT NOTES COMPUT SC, V5259, P298, DOI 10.1007/978-3-540-88458-3_27
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Liu YZ, 2007, J VIS COMMUN IMAGE R, V18, P253, DOI 10.1016/j.jvcir.2007.01.003
   Mastorakis G., 2012, J REALTIME IMAGE PRO, P1
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Qian HM, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1567, DOI 10.1109/ICARCV.2008.4795758
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Rougier C, 2011, LECT NOTES COMPUT SC, V6719, P121, DOI 10.1007/978-3-642-21535-3_16
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shrestha L.B., 2011, The changing demographic profile of the United States
   Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   Thome N, 2008, IEEE T CIRC SYST VID, V18, P1522, DOI 10.1109/TCSVT.2008.2005606
   Whitley D., 1999, Journal of Computing and Information Technology - CIT, V7, P33
NR 43
TC 13
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 15017
EP 15049
DI 10.1007/s11042-015-2513-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500059
DA 2024-07-18
ER

PT J
AU Muhammad, K
   Sajjad, M
   Mehmood, I
   Rho, S
   Baik, SW
AF Muhammad, Khan
   Sajjad, Muhammad
   Mehmood, Irfan
   Rho, Seungmin
   Baik, Sung Wook
TI A novel magic LSB substitution method (M-LSB-SM) using multi-level
   encryption and achromatic component of an image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Information security; LSB; Multi-level encryption;
   Steganography; Secret key
ID STEGANOGRAPHIC METHOD; SCHEME; SUPERRESOLUTION; CAPACITY
AB Image Steganography is a thriving research area of information security where secret data is embedded in images to hide its existence while getting the minimum possible statistical detectability. This paper proposes a novel magic least significant bit substitution method (M-LSB-SM) for RGB images. The proposed method is based on the achromatic component (I-plane) of the hue-saturation-intensity (HSI) color model and multi-level encryption (MLE) in the spatial domain. The input image is transposed and converted into an HSI color space. The I-plane is divided into four sub-images of equal size, rotating each sub-image with a different angle using a secret key. The secret information is divided into four blocks, which are then encrypted using an MLE algorithm (MLEA). Each sub-block of the message is embedded into one of the rotated sub-images based on a specific pattern using magic LSB substitution. Experimental results validate that the proposed method not only enhances the visual quality of stego images but also provides good imperceptibility and multiple security levels as compared to several existing prominent methods.
C1 [Muhammad, Khan; Mehmood, Irfan; Baik, Sung Wook] Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
   [Sajjad, Muhammad] Islamia Coll Peshawar, Dept Comp Sci, Peshawar, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Dept Multimedia, Anyang, South Korea.
C3 Sejong University; University of Peshawar; Sungkyul University
RP Baik, SW (corresponding author), Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
EM khan.muhammad.icp@gmail.com; muhammad.sajjad@icp.edu.pk;
   irfanmehmood@sju.ac.kr; smrho@sungkyul.ac.kr; sbaik@sejong.ac.kr
RI Rho, Seungmin/HTP-6683-2023; Sajjad, Muhammad/GZL-4962-2022; Sajjad,
   Muhammad/L-5269-2016; Baik, Sung Wook/AAR-8236-2020; Muhammad,
   Khan/L-9059-2016; Khan, Muhammad/IXN-8470-2023
OI Sajjad, Muhammad/0000-0003-0006-1156; Sajjad,
   Muhammad/0000-0001-5646-0338; Muhammad, Khan/0000-0003-4055-7412;
   Mehmood, Irfan/0000-0001-7864-957X; Baik, Sung Wook/0000-0002-6678-7788;
   Muhammad, Khan/0000-0002-5302-1150
CR Amirtharajan R, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P1064
   Anees A, 2014, NONLINEAR DYNAM, V75, P807, DOI 10.1007/s11071-013-1105-3
   [Anonymous], 2015, ARXIV150207041
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 2014, TECHNICAL J U ENG TE
   [Anonymous], INT J COMPUT INFORM
   [Anonymous], RES J INF TECHNOL
   [Anonymous], ARXIV10104007
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chen WY, 2008, APPL MATH COMPUT, V196, P40, DOI 10.1016/j.amc.2007.05.063
   Cheng WC, 2004, IEEE T CONSUM ELECTR, V50, P320, DOI 10.1109/TCE.2004.1277880
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Ghasemi E., 2012, Intelligent Control and Innovative Computing, P395
   Grover N, 2013, 2013 SECOND INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING, NETWORKING AND SECURITY (ADCONS 2013), P238, DOI 10.1109/ADCONS.2013.45
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Ioannidou A, 2012, EXPERT SYST APPL, V39, P11517, DOI 10.1016/j.eswa.2012.02.106
   Jan Z, 2012, J CHIN INST ENG, V35, P85, DOI 10.1080/02533839.2012.625146
   Jassim Firas A, 2013, ARXIV13070642
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Laaksonen J, 2000, PATTERN RECOGN LETT, V21, P1199, DOI 10.1016/S0167-8655(00)00082-9
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lou DC, 2002, COMPUT SECUR, V21, P449, DOI 10.1016/S0167-4048(02)00515-1
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Masud Karim S. M., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P286, DOI 10.1109/ICCITechn.2011.6164800
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   MUHAMMAD K, 2014, MIDDLE-EAST J SCI RE, V22, P647, DOI DOI 10.5829/idosi.mejsr.2014.22.05.21946
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Raja KB, 2007, LECT NOTES COMPUT SC, V4812, P51
   Roy R, 2013, PROC TECH, V10, P138, DOI 10.1016/j.protcy.2013.12.346
   Sajjad M, 2012, MULTIMEDIA TOOLS APP, P1
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Sajjad M, 2014, SENSORS-BASEL, V14, P3652, DOI 10.3390/s140203652
   Swain G., 2012, Int Arab J Technol, V2, P181
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
NR 60
TC 111
Z9 113
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14867
EP 14893
DI 10.1007/s11042-015-2671-9
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500051
DA 2024-07-18
ER

PT J
AU Song, B
   Hassan, MM
   Tian, Y
   Hossain, MS
   Alamri, A
AF Song, Biao
   Hassan, Mohammad Mehedi
   Tian, Yuan
   Hossain, M. Shamim
   Alamri, Atif
TI Remote display solution for video surveillance in multimedia cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote display; Video encoding; Multimedia cloud; Real-time system
AB Cloud computing offers sufficient computing and storage resources that can be used to provide multimedia services. Migrating the existing multimedia service to cloud brings a new challenging issue, i.e., remote display of video contents. To reduce the bandwidth consumption especially for mobile users, it is desired to encode video before sending to client. Existing encoding methods have unique advantages and disadvantages, differing their performance under varying situations. Thus, we propose to use multi-encoder method to solve the real-time remote display problem for remote multimedia cloud. To select the most appropriate encoder, factors including cost, application requirement, network, client device and codec implementation are considered. In this paper, we form a non-linear programming model, and provide an example to illustrate how to apply the proposed model for getting desired optimization.
C1 [Song, Biao; Hassan, Mohammad Mehedi; Tian, Yuan; Hossain, M. Shamim; Alamri, Atif] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University
RP Song, B (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM bsong@ksu.edu.sa; mmhassan@ksu.edu.sa; ytian@ksu.edu.sa;
   mshossain@ksu.edu.sa; atif@ksu.edu.sa
RI Guizani, Mohsen/AAX-4534-2021; Hossain, M. Shamim/K-1362-2014; Tian,
   Yuan/IAP-8394-2023; Hassan, Mohammad/KDM-9524-2024; Hassan,
   Mohammad/GZA-7507-2022; Hassan, Mohammad Mehedi/D-4946-2016; Alamri,
   Atif/KFQ-0028-2024
OI Guizani, Mohsen/0000-0002-8972-8094; Hossain, M.
   Shamim/0000-0001-5906-9422; Tian, Yuan/0000-0002-8043-1139; Hassan,
   Mohammad/0000-0002-1712-0004; Alamri, Atif/0000-0002-1887-5193
FU National Plan for Science, Technology and Innovation (MAARIFAH), King
   Abdulaziz City for Science and Technology, Kingdom of Saudi Arabia
   [12-INF2613-02]
FX This project was funded by the National Plan for Science, Technology and
   Innovation (MAARIFAH), King Abdulaziz City for Science and Technology,
   Kingdom of Saudi Arabia, Award Number (12-INF2613-02).
CR Anjan Kumar Paul., 2013, 2013 International Conference on Informatics, Electronics and Vision, P1, DOI DOI 10.1109/ICIEV.2013.6572719
   [Anonymous], WIREL COMMUN MOB COM
   [Anonymous], 2014, NVIDIA VIDEO CODEC S
   Chen Y-L, 2013, IEEE 27 INT C ADV IN
   Chien MC, 2012, IEEE T BROADCAST, V58, P200, DOI 10.1109/TBC.2011.2182550
   De Winter D, 2006, 16 ANN INT WORKSH NE
   Furukawa R., 2002, EurographicsWorkshop on Rendering, P257
   Huang Chun-Ying, 2013, P 4 ACM MULT SYST C, P36, DOI DOI 10.1145/2483977.2483981
   Kumar S, 2006, J VIS COMMUN IMAGE R, V17, P425, DOI 10.1016/j.jvcir.2005.04.006
   Lin CF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P655, DOI 10.1109/UIC-ATC.2012.72
   Mell Peter., 2011, NIST Special Publication, V145, P1, DOI DOI 10.6028/NIST.SP.500-325
   Nieh J, 2003, ACM T COMPUT SYST, V21, P87, DOI 10.1145/592637.592640
   Ren SL, 2013, IEEE T MULTIMEDIA, V15, P723, DOI 10.1109/TMM.2013.2240673
   Shashua A, 2001, PROC CVPR IEEE, P42
   Simoens P, 2011, COMPUTER, V44, P46, DOI 10.1109/MC.2011.70
   Simoens P, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P391, DOI 10.1109/ATNAC.2008.4783356
   Song B, 2013, J SUPERCOMPUT, V66, P1729, DOI 10.1007/s11227-013-0972-1
   Tian YL, 2008, MACH VISION APPL, V19, P315, DOI 10.1007/s00138-008-0153-z
   Yi S., 2012, Advances in Computer Science and Information Engineering, P105
   Zhou BY, 2013, IEEE T CIRC SYST VID, V23, P291, DOI 10.1109/TCSVT.2012.2203736
NR 20
TC 7
Z9 7
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13375
EP 13396
DI 10.1007/s11042-015-2816-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800022
DA 2024-07-18
ER

PT J
AU Kieu, TD
   Rudder, A
AF The Duc Kieu
   Rudder, Andrew
TI A reversible steganographic scheme for VQ indices based on joint
   neighboring and predictive coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Steganography; Watermarking; Reversible data
   embedding; Vector quantization; Joint Neighboring Coding (JNC)
ID DATA HIDING SCHEME; EXPANSION; ALGORITHM; IMAGES
AB In this paper, we propose a novel reversible steganographic technique to embed secret data into digital images compressed using vector quantization (VQ). The proposed method is based on joint neighboring and predictive coding. The proposed technique can embed n secret bits into one VQ index, where n=1, 2, 3, and 4. Our method uses left and upper neighboring VQ indexes and the difference between the current VQ index and the predicted value produced by the median edge detector predictor to achieve a low bit rate. The experimental results show that the proposed approach obtains embedding rates of 1, 2, 3, and 4 bits per index (bpi) with respective average bit rates of 0.409, 0.471, 0.534, and 0.596 bit per pixel (bpp) for a 256 sized codebook. This confirms that the proposed scheme outperforms three similar reversible data hiding schemes in VQ-compressed domain.
C1 [The Duc Kieu; Rudder, Andrew] Univ West Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
C3 University West Indies Mona Jamaica; University West Indies Saint
   Augustine
RP Kieu, TD (corresponding author), Univ West Indies, Fac Sci & Technol, Dept Comp & Informat Technol, St Augustine, Trinidad Tobago.
EM ktduc0323@yahoo.com.au; andrew.rudder@gmail.com
RI Rudder, Andrew/AEX-8439-2022
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang YT, 2015, MULTIMED TOOLS APPL, V74, P1645, DOI 10.1007/s11042-014-2019-x
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Cox IJ., 2007, DIGITAL WATERMARKING
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YC, 2013, SIGNAL PROCESS, V93, P2432, DOI 10.1016/j.sigpro.2013.03.034
   Kieu TD, 2015, EXPERT SYST APPL, V42, P713, DOI 10.1016/j.eswa.2014.09.001
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shie SC, 2012, SIGNAL PROCESS, V92, P2332, DOI 10.1016/j.sigpro.2012.02.023
   Kieu TD, 2014, J VIS COMMUN IMAGE R, V25, P1378, DOI 10.1016/j.jvcir.2014.06.001
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
NR 31
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13705
EP 13731
DI 10.1007/s11042-015-2828-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800037
DA 2024-07-18
ER

PT J
AU Dong, YC
   Zhang, Y
   Yue, JG
   Hu, ZC
AF Dong, Yanchao
   Zhang, Yan
   Yue, Jiguang
   Hu, Zhencheng
TI Comparison of random forest, random ferns and support vector machine for
   eye state classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye state estimation; Random forest; Random ferns; Support vector
   machine
ID BLINK DETECTION; TRACKING; HISTOGRAMS
AB Eye state estimation has a wide range of potential applications, such as human-computer interaction, driver fatigue monitoring system and facial expression recognition. The commonly used feature-based methods and motion-based methods are easy to be influenced by head pose variation or occlusion. Recently the appearance-based methods are arising. In this paper, we present a framework for eye state estimation with various feature sets using random forest, random ferns and support vector machine (SVM), and conduct experiments in three different datasets in order to find the most efficient one. The comparison of different classifiers indicates that random forest\ferns outperform the SVM in terms of time consumption. In addition, the results show that histogram of oriented gradient (HOG) feature is robust to noise influence for classification purpose. The average correctly recognition rate is above 93 % in controlled situation with high reliability. These results suggest that random forest with HOG feature is a promising pattern recognition method for eye state recognition.
C1 [Dong, Yanchao] Tongji Univ, Shanghai, Peoples R China.
   [Zhang, Yan] Tongji Univ, Control Theory & Control Engn, Shanghai, Peoples R China.
   [Yue, Jiguang] Tongji Univ, Dept Control Theory & Control Engn, Shanghai, Peoples R China.
   [Hu, Zhencheng] Kumamoto Univ, Dept Comp Sci, Kumamoto, Japan.
C3 Tongji University; Tongji University; Tongji University; Kumamoto
   University
RP Dong, YC (corresponding author), Tongji Univ, Shanghai, Peoples R China.
EM dongyanchao@tongji.edu.cn; 12yanzhang@tongji.edu.cn;
   yuejiguang@tongji.edu.cn; hu@cs.kumamoto-u.ac.jp
FU National Natural Science Foundation of China [61305023]; Specialized
   Research Fund for the Doctoral Program of Higher Education (New
   Teachers) [20130072120066]
FX The work was supported by the National Natural Science Foundation of
   China under Grant No. 61305023 and Specialized Research Fund for the
   Doctoral Program of Higher Education (New Teachers) under Grant No.
   20130072120066.
CR [Anonymous], 2012, INT C POW EN NERIST
   [Anonymous], P IEEE INT C VIRT EN
   Ayudhya CDN, 2009, 6 INT JOINT C COMP S
   Bacivarov I, 2008, IEEE T CONSUM ELECTR, V54, P1312, DOI 10.1109/TCE.2008.4637622
   Bhaskar TN, 2003, TENCON IEEE REGION, P821, DOI 10.1109/TENCON.2003.1273293
   Bosch Anna., 2007, Image classification using random forests and ferns
   Caruana R., 2006, ACM INT C P SER, P161, DOI DOI 10.1145/1143844.1143865
   Choi I., 2011, P 20 INT C COMP COMM, P1
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Divjak M., 2009, MVA, P350
   González-Ortega D, 2009, INT CONF INTELL SYST, P1301, DOI 10.1109/ISDA.2009.226
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Grauman Kristen, 2003, Universal Access in the Information Society, V2, P359, DOI [10.1007/s10209-003-0062-x, DOI 10.1007/s10209-003-0062-x]
   Han Seongwon, 2012, P 12 WORKSH MOB COMP, P1
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   He ZY, 2008, INT C PATT RECOG, P1401
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang G.B., 2007, E.: Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Ji Q, 2004, IEEE T VEH TECHNOL, V53, P1052, DOI 10.1109/TVT.2004.830974
   Jiangwei C, 2004, INT VEH S JUN, P357
   Kawato S, 2004, IMAGE VISION COMPUT, V22, P1031, DOI 10.1016/j.imavis.2004.03.013
   Kim KW, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.3.033103
   Królak A, 2012, UNIVERSAL ACCESS INF, V11, P409, DOI 10.1007/s10209-011-0256-6
   Lalonde M, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P481, DOI 10.1109/CRV.2007.54
   Mayumi Oshiro Thais, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P154, DOI 10.1007/978-3-642-31537-4_13
   Mikhail M, 2009, IEEE IMAGE PROC, P3557, DOI 10.1109/ICIP.2009.5414341
   Minkov K, 2012, 2012 5 INT S COMM CO, P1, DOI [10.1109/ISCCSP.2012.6217806, DOI 10.1109/ISCCSP.2012.6217806]
   Miyakawa T, 2004, SICE 2004 ANNUAL CONFERENCE, VOLS 1-3, P1626
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Pan G, 2011, TELECOMMUN SYST, V47, P215, DOI 10.1007/s11235-010-9313-3
   Polikovsky S., 2009, CRIM DET PREV ICDP 2
   Radlak K, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P145, DOI 10.1109/ICTEA.2012.6462854
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Song FY, 2014, PATTERN RECOGN, V47, P2825, DOI 10.1016/j.patcog.2014.03.024
   Tan HC, 2006, PATTERN RECOGN LETT, V27, P667, DOI 10.1016/j.patrec.2005.10.005
   Tian YL, 2000, LECT NOTES COMPUT SC, V1948, P143
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang P, 2005, PROC CVPR IEEE, P373
   Wu Y., 2010, P 2 INT C E BUS INF 2010 2 INT C E BUS I, P1
   Ying-li Tian, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P110, DOI 10.1109/AFGR.2000.840620
NR 42
TC 24
Z9 26
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11763
EP 11783
DI 10.1007/s11042-015-2635-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200010
DA 2024-07-18
ER

PT J
AU Hu, L
   Li, Y
   Li, TF
   Li, HT
   Chu, JF
AF Hu, Liang
   Li, Yan
   Li, Tengfei
   Li, Hongtu
   Chu, Jianfeng
TI The efficiency improved scheme for secure access control of digital
   video distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access Control; Set-top boxes; Cryptography; RC6; Video codec; VP9
AB The application of digital video distribution is reaching a wider spectrum of customers, in which secure access control of video content during rendering and transmission has become more and more necessary and urgent. Considering the limited computing power and the real-time requirement of set-top boxes, the efficiency of the decryption process is particularly significant. In this paper, we try to search for a scheme to improve the efficiency of the exist schemes for access control of digital video in set-top boxes mainly from three approaches. Firstly, with the specific comparison between AES and RC6, we conclude that RC6 provides sufficient security for set-top boxes, and the decryption process of RC6 is more efficient. Secondly, we improve the efficiency of the codecs process by adopting a latest more efficient video codec VP9, which is an open and royalty free video codec and is proved to be more efficient than H.264. Finally, we could only selective encrypt and decrypt some essential parts of the entire video stream during the codecs process to further improve the efficiency. In a conclusion, we propose a more efficient idea to provide access control of digital video in set-top boxes. This scheme is proved to be more efficient and more practical.
C1 [Li, Yan; Li, Tengfei] Jilin Univ, Coll Software, Changchun 130012, Jilin, Peoples R China.
   [Hu, Liang; Li, Hongtu; Chu, Jianfeng] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Li, HT (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM lihongtu@jlu.edu.cn
RI Li, Tengfei/G-1165-2018
FU Deep exploration instrumentation and equipment development
   [SinoProbe-09-01-03, 201011078]; Key Technologies and Applications of
   Network of Things, which is a major scientific and technological project
   of Jilin Province [3002304]
FX This work was supported by the Deep exploration instrumentation and
   equipment development (SinoProbe-09-01-03) under Grant No. 201011078,
   Key Technologies and Applications of Network of Things, which is a major
   scientific and technological project of Jilin Province under Grant No.
   3002304.
CR Advanced Encryption Standard (AES), 2001, ADV ENCR STAND AES P, V197
   Ahmed HAM, 2007, INZ MINER, P1
   [Anonymous], EBU TECHNICAL RE JAN
   [Anonymous], 13 VID COD EXP GROUP
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2011.5995499
   Asghar Mamoona, 2012, THESIS
   Bankoski J, 2013, PROC SPIE, V8666, DOI 10.1117/12.2009777
   Chen TC, 2006, IEEE T CIRCUITS-II, V53, P832, DOI 10.1109/TCSII.2006.880014
   Contini S., 1998, The Security of the RC6 Block Cipher
   Daemen J, 1998, AES PROPOSAL RIJNDAE, P1
   Dargahi F, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2014), P1, DOI 10.1109/SCC.2014.10
   Furht B, 2005, INTERNET COMMUN SER, P95
   Furht B., 1998, HDB INTERNET MULTIME
   Lian S, 2009, MULTIMEDIA CONTENT E, P89
   [廉士国 Lian Shiguo], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P483
   Lian Shiguo, 2009, MODEM COMPUTER, P192
   [刘完芳 Liu Wanfang], 2006, [中南林学院学报, Journal of Central South Forestry University], V26, P119
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Milind M., 2013, P NAT C NEW HOR IT, P143
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Nechvatal J, 2001, J RES NATL INST STAN, V106, P511, DOI 10.6028/jres.106.023
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Pande A, 2013, EMBEDDED MULTIMEDIA, P11, DOI [10.1007/978-1-4471-4459-5_2, DOI 10.1007/978-1-4471-4459-5_2]
   Rivest R.L., 1998, 1 ADV ENCR STAND AES
   Rivest RL, 2001, RC6 AS THE AES
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Verma H.K., 2012, International Journal of Computer Applications, V42, P1
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yang Y, 2013, PATTERN RECOGN, V46, P1358, DOI 10.1016/j.patcog.2012.10.026
   Yang Y, 2011, WORLD WIDE WEB, V14, P133, DOI 10.1007/s11280-010-0099-8
   Zhang LF, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0099946, 10.1371/journal.pone.0084950]
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P40, DOI 10.1109/TMM.2014.2370257
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang Y, 2014, P ACM INT C MULT, V14, P861, DOI [10.1145/2647868.2655027, DOI 10.1145/2647868.2655027]
NR 40
TC 4
Z9 4
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12645
EP 12662
DI 10.1007/s11042-015-2450-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700020
DA 2024-07-18
ER

PT J
AU Noh, J
   Lee, S
AF Noh, Joonho
   Lee, Soowon
TI Extracting and evaluating topics by region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic extraction; Text mining; Clustering validity index
ID TEXT CATEGORIZATION
AB Analyzing streaming data that contains regional information can derive the interest trends of a region and the differences from those of other regions. The results of analyzing regional differences can be used for making important decisions in areas such as regional marketing and national policy establishment. In this paper, we propose a method to extract topics that represent regional interests from news articles collected by region. The proposed method consists of a novel word-weighting step to extract regional keywords and a word-clustering step to extract regional topics based on the associations between the extracted keywords. The validity of the extracted regional topics is evaluated through a comparison with a ground-truth topic set. Since each topic is represented by a set of words, and a regional topic set is represented by a family of sets, we propose a new clustering validity index for families of sets for a given set of regions. Using the proposed clustering validity index, the optimal parameters for the collected data are presented through experiments.
C1 [Noh, Joonho; Lee, Soowon] Soongsil Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Soongsil University
RP Lee, S (corresponding author), Soongsil Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM nojh890@gmail.com; swlee@ssu.ac.kr
FU National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [2013R1A2A2A04016948]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning(No. 2013R1A2A2A04016948).
CR [Anonymous], 2011, Proceedings of the 20th International Conference on World Wide Web-WWW'11, DOI [DOI 10.1145/1963405.1963443, 10.1145/1963405.1963443]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Ghazisaeidi A., 2013, P E COMM DEV COUNTR, P1
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Ishikawa S, 2012, P ARCS WORKSH FEBR, P165
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Largeron C., 2011, P 2011 ACM S APPL CO, P924
   Wang DQ, 2013, J INF SCI ENG, V29, P209
   Yang H., 2011, Proceedings of the 1st International Workshop on Mobile Location-Based Service, P89
NR 9
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12765
EP 12777
DI 10.1007/s11042-016-3528-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700027
DA 2024-07-18
ER

PT J
AU Emam, M
   Han, Q
   Niu, XM
AF Emam, Mahmoud
   Han, Qi
   Niu, Xiamu
TI PCET based copy-move forgery detection in images under geometric
   transforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move; Region duplication; Locality sensitive hashing; Polar complex
   exponential transform
AB With the advent of the powerful editing software and sophisticated digital cameras, it is now possible to manipulate images. Copy-move is one of the most common methods for image manipulation. Several methods have been proposed to detect and locate the tampered regions, while many methods failed when the copied region undergone some geometric transformations before being pasted, because of the de-synchronization in the searching procedure. This paper presents an efficient technique for detecting the copy-move forgery under geometric transforms. Firstly, the forged image is divided into overlapping circular blocks, and Polar Complex Exponential Transform (PCET) is employed to each block to extract the invariant features, thus, the PCET kernels represent each block. Secondly, the Approximate Nearest Neighbor (ANN) Searching Problem is used for identifying the potential similar blocks by means of locality sensitive hashing (LSH). In order to make the algorithm more robust, morphological operations are applied to remove the wrong similar blocks. Experimental results show that our proposed technique is robust to geometric transformations with low computational complexity.
C1 [Emam, Mahmoud; Han, Qi; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
   [Emam, Mahmoud] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm 32511, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150080, Peoples R China.
EM ma7moud_emam@yahoo.com; qi.han@hit.edu.cn; xiamu.niu@hit.edu.cn
RI Emam, Mahmoud/AAF-3826-2021; Emam, Mahmoud/GSM-7707-2022
OI Emam, Mahmoud/0000-0002-1290-4272; Emam, Mahmoud/0000-0002-1290-4272
FU National Natural Science Foundation of China [61471141, 61301099,
   61361166006]; Fundamental Research Funds for the Central Universities
   [HIT. KISTP. 201416, HIT. KISTP. 201414]; Higher Education Commission of
   Egypt
FX The authors would like to thank Dr. Liyang Yu, Dr.Xianyan Wu and all
   anonymous reviewers for their valuable advices and insightful comments
   to improve the quality of this work. Additionally, This work is
   supported by the National Natural Science Foundation of China (Grant
   Number: 61471141, 61301099, 61361166006), the Fundamental Research Funds
   for the Central Universities (Grant Number: HIT. KISTP. 201416, HIT.
   KISTP. 201414) and Higher Education Commission of Egypt.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2010, SICHERHEIT
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Christlein V, 2012, EVALUATION POPULAR S
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Diane WNN, 2014, SCI WORLD J, DOI 10.1155/2014/975456
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jaberi M, 2014, MACH VISION APPL, V25, P451, DOI 10.1007/s00138-013-0522-0
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Mahalakshmi SD, 2012, DIGIT INVEST, V8, P215, DOI 10.1016/j.diin.2011.06.004
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yu L, 2014, MULTIMED TOOLS APPL, P1
NR 22
TC 69
Z9 71
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11513
EP 11527
DI 10.1007/s11042-015-2872-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900032
DA 2024-07-18
ER

PT J
AU Slusarczyk, P
   Baran, R
AF Slusarczyk, Przemyslaw
   Baran, Remigiusz
TI Piecewise-linear subband coding scheme for fast image decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subband image coding; Piecewise-linear approximation; Linear transforms;
   Image compression
ID WAVELET; COMPRESSION
AB Transform coding methods play a very important role in the development of diverse multimedia technologies. The discrete cosine and wavelet transforms are frequently used in the field of image processing and set up a basis for contemporary image compression standards (JPEG, MPEG). In this paper a novel two-channel piecewise-linear subband coding scheme (PL-SBC) is introduced. Its most important advantage are exceptionally fast and easy for implementation computational algorithms combined with good reconstruction quality. The proposed PLSBC system is based on the dual filter bank consisting of a single filter at the decomposition stage and a single one at the reconstruction stage. For the presented PL-SBC scheme, the conditions of perfect reconstruction and the piecewise-linear approximation filter bank have been defined. The compression properties of a new subband coding scheme have been analysed for different categories of images and in comparison with well-known signal transforms, such as cosine, piecewise-linear, piecewise-constant and wavelet transforms. The research includes a comparison of the reconstruction error both in objective as well as subjective approach.
C1 [Slusarczyk, Przemyslaw] Jan Kochanowski Univ, Inst Phys, Dept Comp Sci, Swietokrzyska 15, PL-25406 Kielce, Poland.
   [Baran, Remigiusz] Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
C3 Jan Kochanowski University; Kielce University of Technology
RP Slusarczyk, P (corresponding author), Jan Kochanowski Univ, Inst Phys, Dept Comp Sci, Swietokrzyska 15, PL-25406 Kielce, Poland.
EM pslusarczyk@ujk.edu.pl; r.baran@tu.kielce.pl
RI Baran, Remigiusz/E-5457-2014
OI Baran, Remigiusz/0000-0002-3643-5642; Slusarczyk,
   Przemyslaw/0000-0002-5809-7701
FU EU Operational Programme Innovative Economy
   [POIG.02.02.00-26-023/09-00]; EU Operational Programme Development of
   Eastern Poland [POPW.01.03.00-26-016/09-00]; European Union from the
   European regional Development Fund, as a part of the Innovative Economy
   Operational Programme INSIGMA [POIG.01.01.02-00-062/09]
FX The numerical experiments reported in this paper have been performed
   using computational equipment purchased in the framework of the EU
   Operational Programme Innovative Economy (POIG.02.02.00-26-023/09-00)
   and the EU Operational Programme Development of Eastern Poland
   (POPW.01.03.00-26-016/09-00).; The work was co-financed by the European
   Union from the European regional Development Fund, as a part of the
   Innovative Economy Operational Programme INSIGMA no.
   POIG.01.01.02-00-062/09.
CR Akansu AN, 1999, MULTIRESOLUTION SIGN
   Andrews H.C., 1968, Proc. Hawaii Int.Conf. System Sciences, P677
   [Anonymous], 1994, Multirate Digital Signal Processing: Multirate Systems, Filter Banks, Wavelets
   [Anonymous], 2004, 154441 ISOIEC
   [Anonymous], 1994, 109181 ISOIEC
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Baran R, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P218, DOI 10.1109/MMET.2000.888560
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   Dziech A, 2004, J INTELL ROBOT SYST, V39, P447, DOI 10.1023/B:JINT.0000026082.76722.ee
   Dziech A, 2002, 14 INT C DIG SIGN PR, DOI [10.1109/ICDSP.2002.1028340, DOI 10.1109/ICDSP.2002.1028340]
   Dziech A, 1985, SIGNALS THEIR TRANSF
   Dziech A, 1996, P CESA 96 IMACS IEEE, P157
   Dziech A, 2000, P IEEE SCI WORKSH SI, P31
   Dziech W, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P224, DOI 10.1109/MMET.2000.888563
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   *ISO IEC, 2000, 138182 ISOIEC
   *ISO IEC, 1993, 111722 ISOIEC
   Mallat S., 1998, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   PAUL CR, 1974, IEEE T ACOUST SPEECH, VAS22, P263, DOI 10.1109/TASSP.1974.1162585
   Slusarczyk P., 2003, Proceedings of the IASTED International Conference on Signal, Processing, Pattern Recognition, and Applications, P53
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Unser M, 2003, IEEE T IMAGE PROCESS, V12, P1080, DOI 10.1109/TIP.2003.812329
   Vetterli M, 2001, IEEE SIGNAL PROC MAG, V18, P61
   Vetterli Martin, 1995, Wavelets and Subband Coding
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   Woods J., 1991, Subband image coding
   WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962
NR 29
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10649
EP 10666
DI 10.1007/s11042-014-2173-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800027
OA hybrid
DA 2024-07-18
ER

PT J
AU Szwed, P
   Skrzynski, P
   Chmiel, W
AF Szwed, Piotr
   Skrzynski, Pawel
   Chmiel, Wojciech
TI Risk assessment for a video surveillance system based on Fuzzy Cognitive
   Maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Risk assessment; Video surveillance; Fuzzy cognitive maps
ID INFORMATION
AB For various IT systems security is considered a key quality factor. In particular, it might be crucial for video surveillance systems, as their goal is to provide continuous protection of critical infrastructure and other facilities. Risk assessment is an important activity in security management; it aims at identifying assets, threats and vulnerabilities, analysis of implemented countermeasures and their effectiveness in mitigating risks. This paper discusses an application of a new risk assessment method, in which risk calculation is based on Fuzzy Cognitive Maps (FCMs) to a complex automated video surveillance system. FCMs are used to capture dependencies between assets and FCM based reasoning is applied to aggregate risks assigned to lower-level assets (e.g. cameras, hardware, software modules, communications, people) to such high level assets as services, maintained data and processes. Lessons learned indicate, that the proposed method is an efficient and low-cost approach, giving instantaneous feedback and enabling reasoning on effectiveness of security system.
C1 [Szwed, Piotr; Skrzynski, Pawel] AGH Univ Sci & Technol, Dept Appl Comp Sci, Al Mickiewicza 30, PL-30059 Krakow, Poland.
   [Chmiel, Wojciech] AGH Univ Sci & Technol, Dept Automat & Biomed Engn, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow; AGH University of Krakow
RP Szwed, P (corresponding author), AGH Univ Sci & Technol, Dept Appl Comp Sci, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM pszwed@agh.edu.pl; skrzynia@agh.edu.pl; wch@agh.edu.pl
RI Chmiel, Wojciech/K-1011-2019; Szwed, Piotr/C-8474-2013
OI Chmiel, Wojciech/0000-0002-4773-9123; Szwed, Piotr/0000-0003-1231-3867
CR Aguilar J., 2005, INT J COMPUTATIONAL, V3, P27
   Anderson S.P., 1992, DISCRETE CHOICE THEO, DOI 10.7551/mitpress/2450.001.0001
   [Anonymous], NIST SPECIAL PUBLICA
   [Anonymous], SHERWOOD APPL BUSINE
   [Anonymous], 2011 C DES ARCH SIGN
   [Anonymous], 2003, TECHNOMETRICS
   [Anonymous], RELIABILITY ENG THEO
   [Anonymous], 2011, 270052011 ISOIEC
   [Anonymous], P 2012 C DES ARCH SI
   Axelrod R., 1976, The Structure of Decision: Cognitive Maps of Political Elites
   Baudrit C, 2006, IEEE T FUZZY SYST, V14, P593, DOI 10.1109/TFUZZ.2006.876720
   Birolini A, 2013, BOSCH INTELLIGENT VI
   Bremond F, 2006, BEHAV RES METHODS, V38, P416, DOI 10.3758/BF03192795
   Chen Xiu-Zhen, 2006, Journal of Software, V17, P885, DOI 10.1360/jos170885
   Chmiel Wojciech, 2012, Image processing & Communication, V17, P231, DOI 10.2478/v10248-012-0051-x
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Craft R, 1998, OPEN FRAMEWORK RISK, P1
   Eom JH, 2007, LECT NOTES COMPUT SC, V4489, P1024
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   Furht B., 2005, MULTIMEDIA SECURITY
   Geerinck T, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P341, DOI 10.1109/ICIG.2009.140
   Granick J., 2006, WIRED NEWS
   Guttman B., 1995, Security, V800, P1
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   HAGIWARA M, 1992, IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, P795, DOI 10.1109/FUZZY.1992.258761
   Han YJ, 2004, LECT NOTES COMPUT SC, V3043, P191
   Hubbard D, 2010, IBM J RES DEV, V54, DOI 10.1147/JRD.2010.2042914
   Institute for Computer Sciences and Technology, 1979, GUID AUT DAT PROC RI
   Jetter A, 2011, FUTURES, V43, P52, DOI 10.1016/j.futures.2010.05.002
   Karimaa A, 2009, 2009 14TH IEEE INTERNATIONAL CONFERENCE ON ENGINEERING OF COMPLEX COMPUTER SYSTEMS (ICECCS), P120, DOI 10.1109/ICECCS.2009.47
   KOSKO B, 1986, INT J MAN MACH STUD, V24, P65, DOI 10.1016/S0020-7373(86)80040-2
   Kosko B., 1992, Neural Networks and Fuzzy Systems: A Dynamical Systems Approach to Machine Intelligence
   Landoll D., 2005, SECURITY RISK ASSESS
   Lazzerini B, 2011, IEEE SYST J, V5, P288, DOI 10.1109/JSYST.2011.2134730
   Lin ET, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P345, DOI 10.1109/ITCC.2001.918819
   Lin ET, 2013, MIRASYS CARBON VMS
   Modarres M., 1999, RELIABILITY ENG RISK
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Özesmi U, 2004, ECOL MODEL, V176, P43, DOI 10.1016/j.ecolmodel.2003.10.027
   Papageorgiou EI, 2012, IEEE T SYST MAN CY C, V42, P150, DOI 10.1109/TSMCC.2011.2138694
   Schneier B, 1999, DR DOBBS J, V24, P21
   Senior A., 2009, Protecting Privacy in Video Surveillance
   Soo Hoo K. J., 2000, THESIS
   Sun LL, 2006, J MANAGE INFORM SYST, V22, P109, DOI 10.2753/MIS0742-1222220405
   Supervisor EDP, 2010, EDPS VID SURV GUID
   Szpyrka M, 2013, LECT NOTES COMPUT SC, V8104, P277, DOI 10.1007/978-3-642-40925-7_26
   Szwed P., 2013, AUTOMATYKAAUTOMATICS, V17, P229
   Szwed P, 2013, FED CONF COMPUT SCI, P167
   Szwed P, 2013, COMM COM INF SC, V368, P233
   Szwed P, 2014, INT J AP MAT COM-POL, V24, P213, DOI 10.2478/amcs-2014-0016
   Tadeusiewicz R, 2011, IND ELECT HDB INTELL, P1
   Tadeusiewicz R, 2009, INT J AP MAT COM-POL, V19, P143, DOI 10.2478/v10006-009-0013-7
   Vesely W.E., 1981, Fault tree handbook
   Vu V.T., 2003, Proc. of Int'l Joint Conf. o Artificial Intelligence, P9
   Wang Yuan, 2003, Mini-Micro Systems, V24, P2082
   Xue-mei X, 2009, INT C MAN SERV SCI 2, P1
   [No title captured]
NR 57
TC 18
Z9 19
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10667
EP 10690
DI 10.1007/s11042-014-2047-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800028
OA hybrid
DA 2024-07-18
ER

PT J
AU Hsieh, CC
   Hsih, MH
   Jiang, MK
   Cheng, YM
   Liang, EH
AF Hsieh, Chen-Chiung
   Hsih, Mei-Hua
   Jiang, Meng-Kai
   Cheng, Yun-Maw
   Liang, En-Hui
TI Effective semantic features for facial expressions recognition using SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Active shape model (ASM); Facial expression recognition;
   Facial texture; Support vector machine (SVM)
ID FACE DETECTION ALGORITHM
AB Most traditional facial expression-recognition systems track facial components such as eyes, eyebrows, and mouth for feature extraction. Though some of these features can provide clues for expression recognition, other finer changes of the facial muscles can also be deployed for classifying various facial expressions. This study locates facial components by active shape model to extract seven dynamic face regions (frown, nose wrinkle, two nasolabial folds, two eyebrows, and mouth). Proposed semantic facial features could then be acquired using directional gradient operators like Gabor filters and Laplacian of Gaussian. A multi-class support vector machine (SVM) was trained to classify six facial expressions (neutral, happiness, surprise, anger, disgust, and fear). The popular Cohn-Kanade database was tested and the average recognition rate reached 94.7 %. Also, 20 persons were invited for on-line test and the recognition rate was about 93 % in a real-world environment. It demonstrated that the proposed semantic facial features could effectively represent changes between facial expressions. The time complexity could be lower than the other SVM based approaches due to the less number of deployed features.
C1 [Hsieh, Chen-Chiung; Jiang, Meng-Kai; Cheng, Yun-Maw] Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Jhongshan N Rd, Taipei 104, Taiwan.
   [Hsih, Mei-Hua] Tatung Univ, Dept Ind Design, 40,Sec 3,Jhongshan N Rd, Taipei 104, Taiwan.
   [Liang, En-Hui] Tamkang Univ, Dept Informat Management, 151 Yingzhuan Rd Tamsui Dist, New Taipei 25137, Taiwan.
C3 Tatung University; Tatung University; Tamkang University
RP Hsieh, CC (corresponding author), Tatung Univ, Dept Comp Sci & Engn, 40,Sec 3,Jhongshan N Rd, Taipei 104, Taiwan.
EM cchsieh@ttu.edu.tw
OI Hsieh, Chen-Chiung/0000-0002-7716-7306
CR Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   Amjad A, 2012, IET IMAGE PROCESS, V6, P1093, DOI 10.1049/iet-ipr.2012.0167
   [Anonymous], 2012, COMPUTER VISION PATT
   [Anonymous], 2012, FACE EXPRESSION RECO
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Castrillón M, 2011, MACH VISION APPL, V22, P481, DOI 10.1007/s00138-010-0250-7
   Cevikalp H., 2013, Face and landmark detection by using cascade of classifiers
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278
   Ekman P, 1978, FACIAL ACTION CODING
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fellenz W., 1999, Circuits, Systems, Communications and Computers, P5331
   Gonzales R.C., 1992, DIGITAL IMAGE PROCES
   Hsu C. W., 2004, TECHNICAL REPORT
   Huang CL, 1997, J VIS COMMUN IMAGE R, V8, P278, DOI 10.1006/jvci.1997.0359
   Hung-Hsu Tsai, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2697, DOI 10.1109/ICMLC.2010.5580938
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Jun Ou, 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P215, DOI 10.1109/ICCMS.2010.45
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kawulok M, 2012, IET IMAGE PROCESS, V6, P95, DOI 10.1049/iet-ipr.2010.0495
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Lanitis A., 2002, IEEE T PATTERN ANAL, P743
   LEE HC, 2013, ADV INTELLIGENT SYST, V2, P259
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Ma R, 2005, LECT NOTES COMPUT SC, V3784, P144
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Saeed A, 2014, ADV HUM-COMPUT INTER, V2014, DOI 10.1155/2014/408953
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Schmidt M, 2010, LECT NOTES ARTIF INT, V5998, P149, DOI 10.1007/978-3-642-12159-3_14
   Shin G, 2008, STUD COMPUT INTELL, V149, P27, DOI 10.1007/978-3-540-70560-4_3
   Sumathi CP., 2012, International Journal of Computer Science Engineering Survey, P47
   Surendran Nanda, 2009, International Journal of Intelligent Systems Technologies and Applications, V7, P316, DOI 10.1504/IJISTA.2009.027112
   TABBONE S, 1994, INT C PATT RECOG, P52, DOI 10.1109/ICPR.1994.576225
   Tang FQ, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P632
   Ting Wu, 2012, Advances in Brain Inspired Cognitive Systems. Proceedings 5th International Conference, BICS 2012, P392, DOI 10.1007/978-3-642-31561-9_44
   Tsao WK, 2010, PATTERN RECOGN, V43, P1039, DOI 10.1016/j.patcog.2009.09.005
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Vezzetti E, 2014, AESTHETIC PLASTIC SU
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692
   Wan C, 2011, LECT NOTES COMPUT SC, V6676, P356, DOI 10.1007/978-3-642-21090-7_42
   Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680
   Wu Tingfan., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P42
   Ying Zilu, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1440, DOI 10.1109/ICOSP.2008.4697403
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
NR 53
TC 36
Z9 39
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6663
EP 6682
DI 10.1007/s11042-015-2598-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700030
DA 2024-07-18
ER

PT J
AU Kwon, GR
   Lama, RK
   Pyun, JY
   Park, CS
AF Kwon, Goo-Rak
   Lama, Ramesh Kumar
   Pyun, Jae-Young
   Park, Chun-Su
TI Multimedia digital rights management based on selective encryption for
   flexible business model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Selective encryption; Partial encryption;
   MPEG-4; MPEG-1 layer III
ID AUDIO WATERMARKING; ROBUST
AB This paper proposes an advanced encryption of MP3 and MPEG-4 coder with a quality degradation-based security model. For the MP3 audio, the magnitude and phase information of modified discrete cosine transform (MDCT) coefficients is encrypted. DCT coefficients and motion vectors (MVs) are used for the scrambling of the MPEG-4 video. This encryption scheme has a level of security, secures in perception, keeps format compliance, and obtains better time efficiency by reducing the encrypted volumes of multimedia contents. These properties make it practical to incorporate encryption and decryption process into compression and decompression process, and thus suitable for secure A/V transmission or sharing. Experimental results indicate that the proposed technique provides levels of security for a flexible business model and achieves a simple and coding-efficient architecture with no adverse impact on error resilience.
C1 [Kwon, Goo-Rak; Lama, Ramesh Kumar; Pyun, Jae-Young] Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Gwangju 501759, South Korea.
   [Park, Chun-Su] Sejong Univ, Dept Digital Contents, Seoul, South Korea.
C3 Chosun University; Sejong University
RP Park, CS (corresponding author), Sejong Univ, Dept Digital Contents, Seoul, South Korea.
EM cspark@sejong.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2010-0008974]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No.2010-0008974). Correspondence
   should be addressed to Dr. Chun-Su Park (cspark@sejong.ac.kr)
CR Agi I., 1996, Proceedings of the Symposium on Network and Distributed System Security, P137, DOI 10.1109/NDSS.1996.492420
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Borujeni SE, 2000, ICECS 2000: 7TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS & SYSTEMS, VOLS I AND II, P290, DOI 10.1109/ICECS.2000.911539
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Farkash S., 1991, 17th Convention of Electrical and Electronics Engineers in Israel. Proceedings (Cat. No.90TH0360-8), P365, DOI 10.1109/EEIS.1991.217693
   Khan JY, 2002, 13TH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOL 1-5, PROCEEDINGS, P2189, DOI 10.1109/PIMRC.2002.1046532
   Kwon GR, 2005, LECT NOTES ARTIF INT, V3802, P1098
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Lei Tang, 1996, Proceedings ACM Multimedia 96, P219, DOI 10.1145/244130.244209
   Li W, 2004, IEEE T AERO ELEC SYS, V40, P12, DOI 10.1109/TAES.2004.1292139
   MATSUNAGA A, 1989, IEEE J SEL AREA COMM, V7, P540, DOI 10.1109/49.17718
   Neubauer C, 1998, LECT NOTES COMPUT SC, V1525, P208
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Piva A, 2002, IEEE INTERNET COMPUT, V6, P18, DOI 10.1109/MIC.2002.1003126
   Qiao L, 1998, COMPUT GRAPH, V22, P437, DOI 10.1016/S0097-8493(98)00033-8
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Spanos G. A., 1995, P 4 INT C COMP COMM
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Yeh C. H., 1999, 1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461), P456, DOI 10.1109/SIPS.1999.822351
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 23
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6697
EP 6715
DI 10.1007/s11042-015-2563-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400001
DA 2024-07-18
ER

PT J
AU Liang, YR
   Liu, GP
   Zhou, NR
   Wu, JH
AF Liang, Yaru
   Liu, Guoping
   Zhou, Nanrun
   Wu, Jianhua
TI Color image encryption combining a reality-preserving fractional DCT
   with chaotic mapping in HSI space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reality-preserving fractional DCT; HSI space; Generating sequence;
   Three-dimensional scrambling; Color image encryption
ID OPTICAL ENCRYPTION; COSINE; TRANSFORM
AB A color image encryption algorithm by combining the reality-preserving fractional DCT (RPFrDCT) with chaotic mapping in HSI space is presented, in which the generating sequence (GS) is introduced and produced by 2D chaotic mapping to ensure the uniqueness of the transform matrix and enlarge the cipher key space of the encryption system. In addition, the color image is converted from standard RGB space into HSI space and the nonlinearity of the spatial transform makes the proposed encryption algorithm more secure than linear ones. Three components, namely H, S and I, are encrypted by the RPFrDCT with fractional orders and GS as cipher keys. Three-dimensional (3D) scrambling is adopted to further enhance the security of the encryption algorithm. The nonlinearity of the spatial transform from RGB to HSI, the real-valued output and the high cipher key-sensitivity guarantee the security and the feasibility of the proposed encryption algorithm. Experimental results demonstrate that the proposed encryption algorithm is sensitive to cipher keys and, to some extent, robust to noise and occlusion attacks.
C1 [Liang, Yaru; Liu, Guoping] Nanchang Univ, Sch Mechatron Engn, Nanchang 330031, Peoples R China.
   [Zhou, Nanrun; Wu, Jianhua] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
C3 Nanchang University; Nanchang University
RP Wu, JH (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Peoples R China.
EM liangyaru@126.com; liuguoping.ncu@163.com; nrzhou@ncu.edu.cn;
   jhwu@ncu.edu.cn
RI Wu, Jianhua/AFL-8480-2022; Zhou, Nanrun/HGC-4650-2022
OI Wu, Jianhua/0000-0002-4505-0568; 
FU National Natural Science Foundation of China [61262084, 61462061];
   Natural Science Foundation of Jiangxi Province [20122BAB201029]; Science
   and Technology Program of Jiangxi Provincial Department of Education
   [GJJ14135]
FX This work was supported by the National Natural Science Foundation of
   China (61262084 and 61462061), the Natural Science Foundation of Jiangxi
   Province (20122BAB201029) and the Science and Technology Program of
   Jiangxi Provincial Department of Education (GJJ14135).
CR Cariolaro G, 2002, IEEE T SIGNAL PROCES, V50, P902, DOI 10.1109/78.992138
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Frauel Y, 2007, OPT EXPRESS, V15, P10253, DOI 10.1364/OE.15.010253
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Lang J, 2012, OPT LASER ENG, V50, P929, DOI 10.1016/j.optlaseng.2012.02.012
   Liang YR, 2015, J MOD OPTIC, V62, P251, DOI 10.1080/09500340.2014.964342
   Liu H, 2013, OPT LASER TECHNOL, V50, P1, DOI 10.1016/j.optlastec.2013.02.003
   Liu S, 2013, OPT COMMUN, V287, P73, DOI 10.1016/j.optcom.2012.09.033
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Singh N, 2010, OPT LASER TECHNOL, V42, P724, DOI 10.1016/j.optlastec.2009.11.016
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Tong X, 2010, J SYST SOFTW, V85, P850
   Tong XJ, 2009, SIGNAL PROCESS, V89, P480, DOI 10.1016/j.sigpro.2008.09.011
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Venturini I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P205
   Wu JH, 2014, OPTIK, V125, P4474, DOI 10.1016/j.ijleo.2014.02.026
   Wu JH, 2013, J MOD OPTIC, V60, P1760, DOI 10.1080/09500340.2013.858189
   Wu JH, 2010, OPT COMMUN, V283, P1720, DOI 10.1016/j.optcom.2009.12.066
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhang YS, 2013, OPT LASER TECHNOL, V54, P1, DOI 10.1016/j.optlastec.2013.04.029
   Zhou NR, 2013, OPT LASER TECHNOL, V47, P341, DOI 10.1016/j.optlastec.2012.08.033
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 28
TC 11
Z9 12
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6605
EP 6620
DI 10.1007/s11042-015-2592-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700027
DA 2024-07-18
ER

PT J
AU Yang, T
   Ma, WG
   Wang, SB
   Li, J
   Yu, JY
   Zhang, YN
AF Yang, Tao
   Ma, Wenguang
   Wang, Sibing
   Li, Jing
   Yu, Jingyi
   Zhang, Yanning
TI Kinect based real-time synthetic aperture imaging through occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE See through occlusion; Kinect; Synthetic aperture imaging; Virtual
   camera array
ID DEPTH; TRACKING
AB Real-time and high performance occluded object imaging is a big challenge to many computer vision applications. In recent years, camera array synthetic aperture theory proves to be a potential powerful way to solve this problem. However, due to the high cost of complex system hardware, the severe blur of occluded object imaging, and the slow speed of image processing, the exiting camera array synthetic aperture imaging algorithms and systems are difficult to apply in practice. In this paper, we present a novel handheld system to handle those challenges. The objective of this work is to design a convenient system for real-time high quality object imaging even under severe occlusion. The main characteristics of our work include: (1) To the best of our knowledge, this is the first real-time handheld system for seeing occluded object in synthetic imaging domain using color and depth images. (2) A novel sequential synthetic aperture imaging framework is designed to achieve seamless interaction among multiple novel modules, and this framework includes object probability generation, virtual camera array generation, and sequential synthetic aperture imaging. (3) In the virtual camera array generation module, based on the integration of color and depth information, a novel feature set iterative optimization algorithm is presented, which can improve the robustness and accuracy of camera pose estimation even in dynamic occlusion scene. Experimental results in challenging scenarios demonstrate the superiority of our system both in robustness and efficiency compared against the state-of-the-art algorithms.
C1 [Yang, Tao; Ma, Wenguang; Wang, Sibing; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian, Peoples R China.
   [Li, Jing] Xidian Univ, Sch Telecommun Engn, Xian, Peoples R China.
   [Yu, Jingyi] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA.
C3 Northwestern Polytechnical University; Xidian University; University of
   Delaware
RP Yang, T (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Peoples R China.
EM yangtaonwpu@163.com
FU National Natural Science Foundation of China [61272288, 61231016]; NPU
   [G2015KY0301, 12GH0311, 13GH014604]; NSF [IIS-CAREER-0845268,
   IIS-1218156]; Foundation of China Scholarship Council [201206965020,
   201303070083]
FX This work is supported by the National Natural Science Foundation of
   China with Grant Number 61272288 and 61231016, NPU New AoXiang Star with
   Grant Number G2015KY0301 and 12GH0311, NPU New People and Direction with
   Grant Number 13GH014604, NSF grants IIS-CAREER-0845268 and IIS-1218156,
   and Foundation of China Scholarship Council with Grant Number
   201206965020 and 201303070083.
CR [Anonymous], INT C PATT REC
   [Anonymous], EUR ROB FOR RGB D WO
   [Anonymous], SIGNAL PROCESSING
   [Anonymous], P WORKSH RGB D ADV R
   [Anonymous], ACM SPECIAL INTEREST
   [Anonymous], P ACM IEEE INT C DIS
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   Ding YY, 2011, IEEE I CONF COMP VIS, P2478, DOI 10.1109/ICCV.2011.6126533
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Joshi N, 2007, INT C COMPUTER VISIO, P1
   Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Maitre M., 2008, Proc. IEEE CVPR, P1
   Pei Z, 2013, PATTERN RECOGN, V46, P174, DOI 10.1016/j.patcog.2012.06.014
   Pei Z, 2012, PATTERN RECOGN, V45, P1637, DOI 10.1016/j.patcog.2011.10.003
   Shotton J., 2011, IEEE COMPUTER VISION
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Taguchi Yuichi, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P241, DOI 10.1109/3DTV.2008.4547853
   Vaish V, 2004, PROC CVPR IEEE, P2
   Vaish V., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.244
   Venkataraman K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508390
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Wilburn B, 2004, PROC CVPR IEEE, P294
   Yamamoto K, 2012, INT CONF ACOUST SPEE, P5453, DOI 10.1109/ICASSP.2012.6289155
   Yang T, 2013, IEEE T CIRC SYST VID, V23, P1461, DOI 10.1109/TCSVT.2013.2242553
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
NR 30
TC 18
Z9 18
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6925
EP 6943
DI 10.1007/s11042-015-2618-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400012
DA 2024-07-18
ER

PT J
AU Fan, B
   Xie, L
   Yang, S
   Wang, LJ
   Soong, FK
AF Fan, Bo
   Xie, Lei
   Yang, Shan
   Wang, Lijuan
   Soong, Frank K.
TI A deep bidirectional LSTM approach for video-realistic talking head
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Talking head; Visual speech synthesis; Recurrent neural network; Long
   short-term memory; Active appearance model
ID SPEECH SYNTHESIS; NEURAL-NETWORKS
AB This paper proposes a deep bidirectional long short-term memory approach in modeling the long contextual, nonlinear mapping between audio and visual streams for video-realistic talking head. In training stage, an audio-visual stereo database is firstly recorded as a subject talking to a camera. The audio streams are converted into acoustic feature, i.e. Mel-Frequency Cepstrum Coefficients (MFCCs), and their textual labels are also extracted. The visual streams, in particular, the lower face region, are compactly represented by active appearance model (AAM) parameters by which the shape and texture variations can be jointly modeled. Given pairs of the audio and visual parameter sequence, a DBLSTM model is trained to learn the sequence mapping from audio to visual space. For any unseen speech audio, whether it is original recorded or synthesized by text-to-speech (TTS), the trained DBLSTM model can predict a convincing AAM parameter trajectory for the lower face animation. To further improve the realism of the proposed talking head, the trajectory tiling method is adopted to use the DBLSTM predicted AAM trajectory as a guide to select a smooth real sample image sequence from the recorded database. We then stitch the selected lower face image sequence back to a background face video of the same subject, resulting in a video-realistic talking head. Experimental results show that the proposed DBLSTM approach outperforms the existing HMM-based approach in both objective and subjective evaluations.
C1 [Fan, Bo; Xie, Lei; Yang, Shan] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Wang, Lijuan; Soong, Frank K.] Microsoft Res Asia, Beijing, Peoples R China.
C3 Northwestern Polytechnical University; Microsoft Research Asia;
   Microsoft
RP Fan, B; Xie, L (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM fanbo1990@gmail.com; xielei21st@gmail.com; lijuanw@microsoft.com
RI Yang, Shan/F-5020-2012; Xie, Lei/JWO-8567-2024
OI Yang, Shan/0000-0003-4464-146X
FU National Natural Science Foundation of China [61175018, 61571363]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61175018 and 61571363).
CR [Anonymous], TMH QPSR
   [Anonymous], 2014, MOL SIMULATION OIL D
   [Anonymous], P INT
   [Anonymous], SIGGRAPH
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cosatto E, 2003, P IEEE, V91, P1406, DOI 10.1109/JPROC.2003.817141
   Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480
   Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Fan Y, 2014, P INTERSPEECH, P1964
   Graves A, 2012, STUDIES COMPUTATIONA, P385, DOI DOI 10.1007/978-3-642-24797-22
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Jia J, 2014, MULTIMED TOOLS APPL, V73, P439, DOI 10.1007/s11042-013-1604-8
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kang S, ICASSP, P8012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Li Bingfeng, 2011, Journal of Tsinghua University (Science and Technology), V51, P1180
   Liu K, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/174192
   Meng FB, 2014, MULTIMED TOOLS APPL, V73, P463, DOI 10.1007/s11042-013-1601-y
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Roweis S, 1998, ADV NEUR IN, V10, P626
   Sako S., 2000, ICSLP, P25
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Theobald BJ, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2310
   Toda T, 2007, IEICE T INF SYST, VE90D, P816, DOI 10.1093/ietisy/e90-d.5.816
   Wang L., 2011, INTERSPEECH, P3307
   Wang LJ, 2012, COMPUTER, V45, P38, DOI 10.1109/MC.2012.152
   Wang LJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P446
   Wang Q, 2006, IEEE T CIRC SYST VID, V16, P1533, DOI 10.1109/TCSVT.2006.885727
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wu ZY, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1802
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Xie L, 2006, INT C PATT RECOG, P1128
   Xie L, 2014, MULTIMED TOOLS APPL, V73, P377, DOI 10.1007/s11042-013-1633-3
   Yao Qian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3829, DOI 10.1109/ICASSP.2014.6854318
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 47
TC 31
Z9 36
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5287
EP 5309
DI 10.1007/s11042-015-2944-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700026
DA 2024-07-18
ER

PT J
AU Xu, HY
   Tian, Q
   Wang, Z
   Wu, JH
AF Xu, Haiyan
   Tian, Qian
   Wang, Zhen
   Wu, Jianhui
TI A survey on aggregating methods for action recognition with dense
   trajectories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Aggregating methods; BOW; FV; VLAD; Low-level
   representation
ID MOTION; CATEGORIES; CONTEXT
AB Action recognition has become a very important topic in computer vision with unconstrained video sequences. There are varieties of approaches to feature extraction and video sequences description, which play important roles in action recognition. In this paper, we survey the main representations along dense trajectories and aggregating methods for the videos in the last decade. We mainly discuss the aggregating methods which are bag of words (BOW), fisher vector (FV) and vector of locally aggregated descriptors (VLAD). Furthermore, the newest mean average precision (mAP) obtained from the references is used to discuss different aggregating methods on realistic datasets. And for more intuitive comparison those aggregating methods, we will evaluate them on KTH in the same conditions. Finally, we analyze and compare those papers' experimental data to summarize the trends. Based on the reviews from several approaches to action recognition, we further make an analysis and discussion on the technical trends in this field.
C1 [Xu, Haiyan; Tian, Qian; Wang, Zhen; Wu, Jianhui] Southeast Univ, Sch Elect Sci & Engn, Natl ASIC Res & Engn Ctr, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Xu, HY (corresponding author), Southeast Univ, Sch Elect Sci & Engn, Natl ASIC Res & Engn Ctr, Nanjing 210096, Jiangsu, Peoples R China.
EM 230129204@seu.edu.cn
RI xu, Haiyan/C-3512-2014
FU National Science Foundation of China [61001104]; Key Foundation of
   Jiangsu [BK2011018]; Fundamental Research Funds for the Central
   Universities; Graduate Research and Innovation Projects of Universities
   in Jiangsu Province [KYLX_0129]
FX This work was partly supported by the National Science Foundation of
   China (Grant No. 61001104), Key Foundation of Jiangsu (Grant No.
   BK2011018), the Fundamental Research Funds for the Central Universities
   and Graduate Research and Innovation Projects of Universities in Jiangsu
   Province (KYLX_0129)
CR [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], BMVC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], COMBINED ORDERED IMP
   [Anonymous], DENSE BODY PART TRAJ
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], 2013, ICCV
   [Anonymous], 2014, P 17 INT C PATTERN R
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2014, CVPR
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2014, IET COMPUT VIS
   [Anonymous], BR MACH VIS C
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BMVC
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2011, IEEE INT C COMP VIS
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], 2012, CoRR
   [Anonymous], IEEE COMPUTSOC C COM
   Atmosukarto I, 2012, INT C PATT RECOG, P3333
   Bilinski P, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P228, DOI 10.1109/AVSS.2012.29
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Chakraborty B, 2011, IEEE I CONF COMP VIS, P1776, DOI 10.1109/ICCV.2011.6126443
   Do Hang Nga, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P375, DOI 10.1007/978-3-319-04114-8_32
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fathi A, 2008, IEEE C COMPUT VIS PA, P1
   Gilbert A, 2009, IEEE I CONF COMP VIS, P925, DOI 10.1109/ICCV.2009.5459335
   Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Koniusz P, 2013, COMPUT VIS IMAGE UND, V117, P479, DOI 10.1016/j.cviu.2012.10.010
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le QV, 2011, PROC CVPR IEEE
   Liu CW, 2012, INT C PATT RECOG, P3366
   Liu J., 2008, EURASIP J ADV SIG PR, V2008, P1, DOI DOI 10.1074/JBC.M802695200
   Lu G, 2013, SCI WORLD J, DOI 10.1155/2013/424617
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Park JS, 2013, I C COMP SYST APPLIC
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shabani AH, 2013, PATTERN RECOGN LETT, V34, P1771, DOI 10.1016/j.patrec.2012.12.013
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Tianzhu Zhang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P538, DOI 10.1109/ICCVW.2009.5457654
   Wang H, 2011, PROC CVPR IEEE
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu D, 2013, IEEE T CIRC SYST VID, V23, P236, DOI 10.1109/TCSVT.2012.2203731
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Xu HY, 2014, INT CONF DIGIT SIG, P63, DOI 10.1109/ICDSP.2014.6900787
   Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang TZ, 2011, IEEE T CIRC SYST VID, V21, P853, DOI 10.1109/TCSVT.2011.2133090
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 67
TC 12
Z9 12
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5701
EP 5717
DI 10.1007/s11042-015-2536-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600017
DA 2024-07-18
ER

PT J
AU Zheng, LL
   Duffner, S
   Idrissi, K
   Garcia, C
   Baskurt, A
AF Zheng, Lilei
   Duffner, Stefan
   Idrissi, Khalid
   Garcia, Christophe
   Baskurt, Atilla
TI Siamese multi-layer perceptrons for dimensionality reduction and face
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Siamese neural networks; Multi-layer perceptrons; Metric learning; Face
   identification; Dimensionality reduction
ID NEURAL-NETWORKS; MODELS; SCALE
AB This paper presents a framework using siamese Multi-layer Perceptrons (MLP) for supervised dimensionality reduction and face identification. Compared with the classical MLP that trains on fully labeled data, the siamese MLP learns on side information only, i.e., how similar of data examples are to each other. In this study, we compare it with the classical MLP on the problem of face identification. Experimental results on the Extended Yale B database demonstrate that the siamese MLP training with side information achieves comparable classification performance with the classical MLP training on fully labeled data. Besides, while the classical MLP fixes the dimension of the output space, the siamese MLP allows flexible output dimension, hence we also apply the siamese MLP for visualization of the dimensionality reduction to the 2-d and 3-d spaces.
C1 [Zheng, Lilei; Duffner, Stefan; Idrissi, Khalid; Garcia, Christophe; Baskurt, Atilla] Univ Lyon, LIRIS CNRS, Natl Inst Appl Sci INSA, Lyon, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon
RP Zheng, LL (corresponding author), Univ Lyon, LIRIS CNRS, Natl Inst Appl Sci INSA, Lyon, France.
EM lilei.zheng@insa-lyon.fr
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 1989, Principal Components Analysis
   [Anonymous], THESIS
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], 1990, P ADV NEUR INF PROC
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Bellet A., 2013, arXiv
   Berlemont S, 2015, 11 IEEE INT C AUT FA
   BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Davis J. V., 2007, ICML, P209
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ke Y, 2004, PROC CVPR IEEE, P506
   Koehn Philipp, 2004, EMNLP
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lippmann RP, 1989, NEURAL COMPUT, V1, P1, DOI 10.1162/neco.1989.1.1.1
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Luenberger D.G, 1973, Introduction to linear and nonlinear programming, V28
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rumelhart DE, 1985, CALIFORNIA U SAN DIE, DOI DOI 10.21236/ADA164453
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zheng L., 2015, 11 IEEE INT C AUT FA
NR 29
TC 30
Z9 37
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5055
EP 5073
DI 10.1007/s11042-015-2847-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700014
DA 2024-07-18
ER

PT J
AU He, N
   Wang, JB
   Zhang, LL
   Xu, GM
   Lu, K
AF He, Ning
   Wang, Jin-Bao
   Zhang, Lu-Lu
   Xu, Guang-Mei
   Lu, Ke
TI Non-local sparse regularization model with application to image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Non-local means; Sparse coding; Regularization;
   Self-similarity
ID TRANSFORM; ALGORITHM
AB We study problems related to denoising of natural images corrupted by Gaussian white noise. Important structures in natural images such as edges and textures are jointly characterized by local variation and nonlocal invariance. Both provide valuable schemes in the regularization of image denoising. In this paper, we propose a framework to explore two sets of ideas involving on the one hand, locally learning a dictionary and estimating the sparse regularization signal descriptions for each coefficient; and on the other hand, nonlocally enforcing the invariance constraint by introducing patch self-similarities of natural images into the cost functional. The minimization of this new cost functional leads to an iterative thresholding-based image denoising algorithm; its efficient implementation is discussed. Experimental results from image denoising tasks of synthetic and real noisy images show that the proposed method outperforms the state-of-the-art, making it possible to effectively restore raw images from digital cameras at a reasonable speed and memory cost.
C1 [He, Ning; Wang, Jin-Bao; Zhang, Lu-Lu; Xu, Guang-Mei] Beijing Union Univ, Coll Informat Technol, Beijing Key Lab Informat Serv Engn, Beijing 100101, Peoples R China.
   [Lu, Ke] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Beijing Union University; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP He, N (corresponding author), Beijing Union Univ, Coll Informat Technol, Beijing Key Lab Informat Serv Engn, Beijing 100101, Peoples R China.
EM xxthening@buu.edu.cn; luk@ucas.ac.cn
FU National Natural Science Foundation of China [61370138, 61271435,
   61103130, U1301251]; National Program on Key Basic Research Projects
   (973 programs) [2010CB731804-1, 2011CB706901-4]; Project of Construction
   of Innovative Teams and Teacher Career Development for Universities and
   Colleges under Beijing Municipality [IDHT20130513, CITTCD20130513];
   Beijing Municipal Natural Science Foundation [4141003]; Beijing
   Municipal Party Committee Organization Department of Outstanding Talent
   Project [2010D005022000011]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61370138, 61271435, 61103130, U1301251), National
   Program on Key Basic Research Projects (973 programs) (Grant Nos.
   2010CB731804-1, 2011CB706901-4), Project of Construction of Innovative
   Teams and Teacher Career Development for Universities and Colleges under
   Beijing Municipality (Grant Nos. IDHT20130513, CIT&TCD20130513), Beijing
   Municipal Natural Science Foundation (Grant No. 4141003), and Beijing
   Municipal Party Committee Organization Department of Outstanding Talent
   Project (Grant No. 2010D005022000011).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], P SPARS
   [Anonymous], P IEEE INT C IM PROC
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Buades A, 2009, IEEE T IMAGE PROCESS, V18, P1192, DOI 10.1109/TIP.2009.2017171
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Dabov K., 2008, P SIGN PROC AD SPARS, P1
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Deledalle CA, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.25
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2011, IEEE IMAGE PROC, P1841, DOI 10.1109/ICIP.2011.6115824
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Foi A, 2012, PROC SPIE, V8291, DOI 10.1117/12.912217
   Jalali Ali, 2010, ADV NEURAL INFORM PR, P964
   Lu YX, 2014, INT J REMOTE SENS, V35, P1143, DOI 10.1080/01431161.2013.875635
   Mairal J., 2009, P 26 ANN INT C MACH, DOI [10.1145/1553374.1553463, DOI 10.1145/1553374.1553463]
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Negahban S., 2008, Advances in Neural Information Processing Systems, V21, P1161
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 32
TC 12
Z9 12
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2579
EP 2594
DI 10.1007/s11042-015-2471-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000011
DA 2024-07-18
ER

PT J
AU Nuutinen, M
   Virtanen, T
   Leisti, T
   Mustonen, T
   Radun, J
   Häkkinen, J
AF Nuutinen, Mikko
   Virtanen, Toni
   Leisti, Tuomas
   Mustonen, Terhi
   Radun, Jenni
   Hakkinen, Jukka
TI A new method for evaluating the subjective image quality of photographs:
   dynamic reference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality; Subjective evaluation method; Performance measure
AB The Dynamic Reference (DR) method has been developed for subjective image quality experiments in which original or undistorted images are unavailable. The DR method creates reference image series from test images. Reference images are presented to observers as a slide show prior to evaluating their quality. As the observers view the set of reference images, they determine the overall variation in quality within the set of test images. This study compared the performance of the DR method to that of the standardized absolute category rating (ACR) and paired comparison (PC) methods. We measured the performance of each method in terms of time effort and discriminability. The results showed that the DR method is faster than the PC method and more accurate than the ACR method. The DR method is especially suitable for experiments that require highly accurate results in a short time.
C1 [Nuutinen, Mikko; Virtanen, Toni; Leisti, Tuomas; Mustonen, Terhi; Radun, Jenni; Hakkinen, Jukka] Univ Helsinki, Inst Behav Sci, Helsinki, Finland.
C3 University of Helsinki
RP Nuutinen, M (corresponding author), Univ Helsinki, Inst Behav Sci, Helsinki, Finland.
EM mikko.nuutinen@helsinki.fi; toni.virtanen@helsinki.fi;
   tuomasi.leisti@helsinki.fi; terhi.mustonen@helsinki.fi;
   jenni.radun@helsinki.fi; jukka.hakkinen@helsinki.fi
RI Radun, Jenni/AAB-3943-2021; Häkkinen, Jukka/A-4122-2019; Leisti,
   Tuomas/AAF-1709-2020; Virtanen, Toni I. O./E-9181-2015
OI Radun, Jenni/0000-0003-3269-2999; Häkkinen, Jukka/0000-0003-0215-2238;
   Leisti, Tuomas/0000-0002-9234-2854; Nuutinen, Mikko/0000-0002-7429-3710;
   Mustonen, Terhi/0000-0002-8565-8164
CR [Anonymous], 2012, 20462 ISO 3
   [Anonymous], 2015, INTRO MED STAT
   Bagiella E, 2000, PSYCHOPHYSIOLOGY, V37, P13, DOI 10.1111/1469-8986.3710013
   Blin J., 2006, P 2 INT WORKSH VID P
   Engelke U, 2012, SIGNAL PROCESS-IMAGE, V27, P935, DOI 10.1016/j.image.2012.07.007
   Greenwood P. E., 1996, A guide to chi-squared testing, V280
   I3A, 2007, CPIQ IN PHAS 1 WHIT
   Jin EW, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3271133
   Kawano T, 2012, INT WORK QUAL MULTIM, P218, DOI 10.1109/QoMEX.2012.6263833
   Kuang JT, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265958
   Leisti T, 2009, P SOC PHOTO-OPT INS, p[72, 420D, 420D]
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Nikkanen J, 2008, OPT ENG, V47, DOI 10.1117/1.3013232
   Nuutinen M, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P165, DOI 10.1109/ISM.2012.40
   Nuutinen M, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-8
   Petit J, 2013, J VIS COMMUN IMAGE R, V24, P1020, DOI 10.1016/j.jvcir.2013.06.014
   Ponomarenko C. J. N., 2009, ADV MODERN RADIOELEC, V10, P30
   Radun J, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1773965.1773967
   Ramanath R, 2005, IEEE SIGNAL PROC MAG, V22, P34, DOI 10.1109/MSP.2005.1407713
   Redi J, 2010, P SOC PHOTO-OPT INS, p[752, 903, 903]
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Silverstein DA, 2001, J ELECTRON IMAGING, V10, P394, DOI 10.1117/1.1344187
   Teunissen K, 1996, SMPTE J, V105, P144, DOI 10.5594/J04650
   Ween B, 2005, RADIOGRAPHY, V11, P191, DOI 10.1016/j.radi.2005.03.002
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Winkler S, 2009, INT WORK QUAL MULTIM, P139, DOI 10.1109/QOMEX.2009.5246961
   Zhou JP, 2007, I SYMP CONSUM ELECTR, P167
NR 27
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2367
EP 2391
DI 10.1007/s11042-014-2410-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000029
DA 2024-07-18
ER

PT J
AU Yang, X
   Yang, B
   Wang, PJ
   Xu, DQ
AF Yang, Xin
   Yang, Bing
   Wang, Pengjie
   Xu, Duanqing
TI MSKD: multi-split KD-tree design on GPU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE KD-tree; Acceleration structure; Ray tracing; Graphics hardware
AB We present a novel parallel acceleration structure construction and traversal algorithm designed to efficiently exploit the massive parallel computing cores on the Graphic Processing Unit(GPU) to improve the render performance. Our associated data structure is called multi-split KD-tree or MSKD, which focuses on fast generating and efficiently traveling multiple child nodes hierarchy in parallel. At build-time, we introduce a multi-split node generation method to split along three-dimension axes into eight child nodes once, and gather quickly high-quality child nodes even at early construction phase. During traversal, we propose a progressive traversal to fast decide the visiting order for multiple child nodes. Then, we use a dynamic ray transfer to adaptively drive the traversal tasks execution on the GPU. Our experiments with this hierarchy show the construction and traversal performance improvement for ray tracing using MSKD compared to previous methods.
C1 [Yang, Xin] Dalian Univ Technol, Dalian, Peoples R China.
   [Yang, Bing] Hangzhou Danzi Univ, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Pengjie] Dalian Nationalities Univ, Dalian, Peoples R China.
   [Xu, Duanqing] Zhejiang Univ, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Dalian University of Technology; Dalian Minzu University; Zhejiang
   University
RP Yang, X (corresponding author), Dalian Univ Technol, Dalian, Peoples R China.; Wang, PJ (corresponding author), Dalian Nationalities Univ, Dalian, Peoples R China.
EM xinyang@zju.edu.cn; yb@hdu.edu.cn; pengjiewang@gmail.com; xdq@zju.edu.cn
RI Wang, Pengjie/KHE-3288-2024
CR Aila T., 2009, P C HIGH PERFORMANCE, P145, DOI [DOI 10.1145/1572769.1572792, 10.1145/1572769.1572792]
   Aila Timo, 2010, PROC ACM C HIGH PERF, P113
   Antwerpen D., 2011, P ACM SIGGRAPH S HIG, P41, DOI [10.1145/2018323.2018330, DOI 10.1145/2018323.2018330]
   Benthin C, IEEE T VIS COMPUT GR
   Bikker J, 2012, ARAUNA REALTIME RAY
   Bocchino Robert L., 2010, P HIGH PERF GRAPH, P77
   Boulos S, 2008, P 2008 IEEE EG S INT
   Cadet G, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P63, DOI 10.1109/RT.2007.4342592
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Fan Z, 2004, GPU CLUSTER HIGH PER, P47
   Garanzha K., 2011, P ACM SIGGRAPH S HIG, P59, DOI DOI 10.1145/2018323.2018333
   Garanzha K, 2010, COMPUT GRAPH FORUM, V29, P289, DOI 10.1111/j.1467-8659.2009.01598.x
   Glassner AS, 1989, INTRO TAY TRACING
   Havran  V., 2000, THESIS
   Hou QM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360618
   Karras T., 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Lauterbach C, 2009, P EUROGRAPHICS
   Pantaleoni J., 2010, P C HIGH PERFORMANCE, P87
   Reshetov A, 2005, ACM T GRAPHIC, V24, P1176, DOI 10.1145/1073204.1073329
   Shevtsov M, 2007, COMPUT GRAPH FORUM, V26, P395, DOI 10.1111/j.1467-8659.2007.01062.x
   Shih M, 2009, LECT NOTES COMPUT SC, V5574, P327, DOI 10.1007/978-3-642-03095-6_32
   Sung K., 1991, EUROGRAPHICS '91. Proceedings of the European Computer Graphics Conference and Exhibition, P73
   Wachter C., 2006, Proceedings of the Eurographics Symposium on Rendering, P139, DOI DOI 10.2312/EGWR/EGSR06/139-149
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wald I, 2006, ACM T GRAPHIC, V25, P485, DOI 10.1145/1141911.1141913
   Wald Ingo., 2001, P EUROGRAPHICS COMPU, P153
   Wald Ingo., 2007, SIMD RAY STREAM TRAC
   Wu Zhefeng, 2011, P ACM SIGGRAPH S HIG, P71, DOI DOI 10.1145/2018323.2018335
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
   Zhou K, 2011, IEEE T VIS COMPUT GR, V17, P669, DOI 10.1109/TVCG.2010.75
NR 30
TC 0
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1349
EP 1364
DI 10.1007/s11042-014-2371-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700030
DA 2024-07-18
ER

PT J
AU Furuya, T
   Ohbuchi, R
AF Furuya, Takahiko
   Ohbuchi, Ryutarou
TI Similarity metric learning for sketch-based 3D object retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape retrieval; Content-basedmultimedia retrieval; 3D geometric
   modeling; Distance metric learning; Cross-domain retrieval; Diffusion
   distance
ID MODEL RETRIEVAL; SHAPE
AB Sketch-Based 3D Object Retrieval (SB3DOR) algorithms retrieve 3D models similar to hand-drawn sketch queries. It is one of the most effective modalities to query 3D models by their shape. However, comparison of a sketch, which is a 2D image, with a 3D model is not straightforward. Most of the SB3DOR algorithms compare a sketch image with images of 3D models rendered from multiple viewpoints. However, retrieval accuracies of state-of-the-art SB3DOR algorithms are still not satisfactory, due, in part, to stylistic variation, semantic influence, abstraction, and drawing error found in sketches. To improve retrieval accuracy of SB3DOR systems, we propose a manifold-based similarity metric learning algorithm that relates two kinds of features, that are, of sketches and 3D models. Features in a high dimensional space often lie on a lower dimensional subspace, or manifold. Feature similarity may be computed more accurately on the manifold than in the original high dimensional space. Our Cross-Domain Manifold Ranking (CDMR) algorithm tries to keep the two distinct feature manifolds, one for sketch features and the other for 3D model features, intact. These two manifolds are interlinked by using inter-feature similarity to form a Cross-Domain Manifold (CDM). If available, semantic labels may also be used in forming the CDM. Relevance diffusion is used to compute similarities between a sketch and 3D models in a database. Experimental evaluation showed that the CDMR algorithm produces higher retrieval accuracy than the algorithms we compared against.
C1 [Furuya, Takahiko; Ohbuchi, Ryutarou] Univ Yamanashi, Grad Sch Med & Engn, Kofu, Yamanashi, Japan.
C3 University of Yamanashi
RP Furuya, T (corresponding author), Univ Yamanashi, Grad Sch Med & Engn, 4-3-11 Takeda, Kofu, Yamanashi, Japan.
EM g13dm003@yamanashi.ac.jp; ohbuchi@yamanashi.ac.jp
RI Ohbuchi, Ryutarou/A-5821-2013
OI Ohbuchi, Ryutarou/0000-0002-7605-9135
FU Grants-in-Aid for Scientific Research [26330133, 26120517] Funding
   Source: KAKEN
CR [Anonymous], 2013, P EUR WORKSH 3D OBJ, DOI DOI 10.2312/3DOR/3DOR13/049-056
   [Anonymous], 2012, P 3DOR
   [Anonymous], 2001, P INT M PSYCH SOC
   [Anonymous], 2009, P ACM INT C IM VID R, DOI DOI 10.1145/1646396.1646430
   [Anonymous], P 2012 SIAM INT C DA
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   ElNaghy Hanan, 2013, International Journal of Research and Reviews in Applied Sciences, V14, P412
   Furuya Takahiko, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P37, DOI 10.1007/978-3-319-04114-8_4
   Furuya T, 2013, P CYBERWORLDS 2013, V2013, P274
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Goldfeder Corey, 2008, Joint Conference on Digital Libraries (JCDL 2008), P355, DOI 10.1145/1378889.1378950
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Kanai S, 2008, INT J INTERACT DES M, V2, P87, DOI [10.1007/s12008-008-0038-4, 10.1007/s12008-008-003]
   LI B., 2012, EurographicsWorkshop on 3D Object Retrieval, P109
   Li B, 2013, EG 3DOR 2013, P1
   Li B, 2013, ADV INTEL SYS RES, V31, P1
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li B, 2013, MULTIMED TOOLS APPL, V65, P363, DOI 10.1007/s11042-012-1009-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ng CBR, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P158, DOI 10.1109/MMMC.2005.59
   Ohbuchi R, 2009, LECT NOTES COMPUT SC, V5887, P137, DOI 10.1007/978-3-642-10543-2_14
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Saavedra J.M., 2011, Proceedings of the 1st ACM International Conference on Multimedia Retrieval, P1
   Saavedra J.M., 2012, 3DOR, P47
   Shao TJ, 2011, COMPUT GRAPH FORUM, V30, P2011, DOI 10.1111/j.1467-8659.2011.02050.x
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   SHREC, 2013, LARG SCAL SKETCH BAS
   Sun L, LSCCA PACKAGE LEAST
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Wang X., 2004, ACM INT C MULTIMEDIA, P944
   YOON S.M., 2010, Proceedings of the international conference on Multimedia, P193
   Zhai XH, 2012, INT CONF ACOUST SPEE, P2337, DOI 10.1109/ICASSP.2012.6288383
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 38
TC 7
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10367
EP 10392
DI 10.1007/s11042-014-2171-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700010
DA 2024-07-18
ER

PT J
AU Pereira, MHR
   de Souza, CL
   Pádua, FLC
   Silva, GD
   de Assis, GT
   Pereira, ACM
AF Pereira, Moises H. R.
   de Souza, Celso L.
   Padua, Flavio L. C.
   Silva, Giani D.
   de Assis, Guilherme T.
   Pereira, Adriano C. M.
TI SAPTE: A multimedia information system to support the discourse analysis
   and information retrieval of television programs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video retrieval; Video indexing; Television; Discourse
   analysis
ID SEGMENTATION; ARCHIVE; TV
AB This paper presents a novel multimedia information system, called SAPTE, for supporting the discourse analysis and information retrieval of television programs from their corresponding video recordings. Unlike most common systems, SAPTE uses both content independent and dependent metadata, which are determined by the application of discourse analysis techniques as well as image and audio analysis methods. The proposed system was developed in partnership with the free-to-air Brazilian TV channel Rede Minas in an attempt to provide TV researchers with computational tools to assist their studies about this media universe. The system is based on the Matterhorn framework for managing video libraries, combining: (1) discourse analysis techniques for describing and indexing the videos, by considering aspects, such as, definitions of the subject of analysis, the nature of the speaker and the corpus of data resulting from the discourse; (2) a state of the art decoder software for large vocabulary continuous speech recognition, called Julius; (3) image and frequency domain techniques to compute visual signatures for the video recordings, containing color, shape and texture information; and (4) hashing and k-d tree methods for data indexing. The capabilities of SAPTE were successfully validated, as demonstrated by our experimental results, indicating that SAPTE is a promising computational tool for TV researchers.
C1 [Pereira, Moises H. R.; Padua, Flavio L. C.] CEFET MG, Dept Comp, Belo Horizonte, MG, Brazil.
   [de Souza, Celso L.] IFSudeste MG, Dept Comp, Sao Joao Del Rei, MG, Brazil.
   [Silva, Giani D.] CEFET MG, Dept Languages, Belo Horizonte, MG, Brazil.
   [de Assis, Guilherme T.] UFOP, Dept Comp, Belo Horizonte, MG, Brazil.
   [Pereira, Adriano C. M.] Univ Fed Minas Gerais, Dept Comp Sci, Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Ouro Preto; Universidade Federal de Minas Gerais
RP Pereira, MHR (corresponding author), CEFET MG, Dept Comp, Belo Horizonte, MG, Brazil.
EM moiseshrp@gmail.com; celso.souza@ifsudestemg.edu.br;
   cardeal@decom.cefetmg.br; gianids@deii.cefetmg.br; gtassis@iceb.ufop.br;
   adrianoc@dcc.ufmg.br
RI Pádua, Flávio L C/N-7791-2013; Pereira, Adriano Machado/AAA-3995-2019;
   Souza, Celso Luiz de/C-5823-2015
OI Pereira, Adriano Machado/0000-0003-2389-0512; Souza, Celso Luiz
   de/0000-0001-5383-6491
FU FAPEMIG-Brazil [APQ-01180-10, APQ-02269-11]; CEFET-MG [PROPESQ-088/12,
   PROPESQ-076/09]; CAPES-Brazil; CNPq-Brazil
FX The authors gratefully acknowledge the financial support of
   FAPEMIG-Brazil under Procs. APQ-01180-10 and APQ-02269-11; CEFET-MG
   under Procs. PROPESQ-088/12 and PROPESQ-076/09; CAPES-Brazil and
   CNPq-Brazil.
CR Abrahamsson H., 2012, P 2012 INT MEAS C IM, P199
   Al-Surmi M, 2012, TESOL QUART, V46, P671, DOI 10.1002/tesq.33
   Andrade AAB, 2012, P 17 BRAZ C COMM SCI, V1, P1
   Baaziz N, 2010, COMPUT RES REPOS
   BAI H, 2011, P ROB SCI SYST LOS A, P1
   Baker P., 2006, CONTINUUM
   Biber D., 2005, CORPUS LINGUIST LING, V1, P151, DOI DOI 10.1515/CLLT.2005.1.2.151
   Brown E, 2001, IBM SYST J, V40, P526
   Brown JS, 1991, ORGAN SCI, V2, P40, DOI 10.1287/orsc.2.1.40
   Cesar Pablo, 2008, Foundations and Trends in Human-Computer Interaction, V2, P279, DOI 10.1561/1100000008
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Charaudeau P., 2002, Discourse Studies, V4, P301
   Chatzigiorgaki M, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P934
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Chen H, 2010, INT CONF COMP SCI, P153, DOI 10.1109/ICCSIT.2010.5564930
   Chen LH, 2008, PATTERN RECOGN, V41, P1056, DOI 10.1016/j.patcog.2007.07.024
   Cheng F., 2012, ASIAN SOCIAL SCI, V8, P75, DOI DOI 10.5539/ASS.V8N12P75
   Chiu CY, 2007, IEEE INT SYM MULTIM, P265, DOI 10.1109/ISM.Workshops.2007.52
   Croft W. B., 2010, SEARCH ENGINES INFOR
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   De Avila S. E. F., 2009, P 22 BRAZ S COMP GRA, P10, DOI DOI 10.1109/SIBGRAPI.2008.31
   Duguid A, 2010, CORPORA, V5, P109, DOI 10.3366/cor.2010.0102
   Fontaine G., 2010, Communications and Strategies, P21
   Geetha P., 2008, Journal of Computer Sciences, V4, P474, DOI 10.3844/jcssp.2008.474.486
   Gospodnetic O., 2005, Lucene in Action: A guide to the Java search engine
   Hearst M., 1993, TECHNICAL REPORT
   Hollink L, 2009, INTERDISCIPL SCI REV, V34, P253, DOI 10.1179/174327909X441144
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huurnink B, 2012, IEEE T MULTIMEDIA, V14, P1166, DOI 10.1109/TMM.2012.2193561
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jonathan C, 2008, PRAGMATIC ANNOTATION
   Kawahara T, 2004, 8 INT C SPOK LANG PR
   Ketterl M, 2010, INTERACT TECHNOL SMA, V7, P168, DOI 10.1108/17415651011071631
   Ketterl M, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P687, DOI 10.1109/ISM.2009.69
   Khalid MS, 2006, J MULTIMEDIA, V1, P209
   Lagoze C., 2003, Library Hi Tech, V21, P118, DOI 10.1108/07378830310479776
   Lave J., 2002, Supporting lifelong learning, V1, P111
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Long F, 2003, SCI CHAP FUNDAMENTA, P476
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lux M, 2009, P 17 ACM INT C MULT
   Lv Q, 2006, P SUROSYS C
   Mann W., 1988, Text, V8, P243, DOI [10.1515/text.1.1988.8.3.243, DOI 10.1515/TEXT.1.1988.8.3.243]
   Manson G, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/153160
   Marchionini G, 2006, J AM SOC INF SCI TEC, V57, P1629, DOI 10.1002/asi.20336
   Marcu D, 2000, COMPUT LINGUIST, V26, P395, DOI 10.1162/089120100561755
   Neto N., 2011, J BRAZILIAN COMPUTER, V17, P53
   Pan Z., 1993, Political Analysis, V10, P55, DOI DOI 10.1080/10584609.1993.9962963
   Passonneau RJ, 1997, COMPUT LINGUIST, V23, P103
   Pereira MHR, 2012, SISTEMAS Y TECNOLOGIAS DE INFORMACION, VOLS 1 AND 2, P58
   Phillips L., 2002, DISCOURSE ANAL THEOR
   Quan Zheng, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P1035, DOI 10.1109/CECNET.2011.5768292
   Rey JenniferM., 2001, VARIATION ENGLISH MU, P138
   Rubin N, 2009, LIBR TRENDS, V57, P393
   Sabino JLMF, 2011, THESIS
   Sabino JLMF, 2010, PARAMETROS DISCURSIV, V1, P1
   Sadlier DA, 2002, PATTERN RECOGN, V35, P2719, DOI 10.1016/S0031-3203(01)00251-5
   Sandhu R, 2008, PROC SPIE, V6914, DOI 10.1117/12.769010
   Schiffrin D., 2008, The Handbook of Discourse Analysis
   SMEATON AF, 2004, INT J DIGIT LIB, V4, P42
   Smeaton AF, 2007, INFORM SYST, V32, P545, DOI 10.1016/j.is.2006.09.001
   Souza C.M.M.A., 2012, THESIS
   Spaniol M, 2006, P I KNOW, V6, P6
   Spyrou E, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P98, DOI 10.1109/SMAP.2007.39
   Stamou G, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.15
   Stegmaier F, 2013, IEEE MULTIMEDIA, V20, P22, DOI 10.1109/MMUL.2012.55
   Stegmeier J, 2013, SPIL, V41, P91
   Upton TA, 2009, DISCOURSE STUD, V11, P585, DOI 10.1177/1461445609341006
   Van de Wouwer G, 1999, PATTERN RECOGN, V32, P443, DOI 10.1016/S0031-3203(98)00035-1
   Van Dijk T. A., 1987, NEWS ANAL
   van Dijk Teun A., 2013, News as discourse
   Wactlar HD, 1999, COMPUTER, V32, P66, DOI 10.1109/2.745722
   Weibel S L., 2000, D-lib magazine, V6, P1082, DOI [10.1045/december2000-weibel, DOI 10.1045/DECEMBER2000-WEIBEL]
   Yuan Jing., 2012, FDN INTELLIGENT SYST, P721
   Zeadally S, 2011, IEEE SYST J, V5, P518, DOI 10.1109/JSYST.2011.2165601
NR 77
TC 13
Z9 13
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10923
EP 10963
DI 10.1007/s11042-014-2311-9
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700035
DA 2024-07-18
ER

PT J
AU Razzaghi, P
   Samavi, S
AF Razzaghi, Parvin
   Samavi, Shadrokh
TI Image retargeting using nonparametric semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retargeting; Nonparametric semantic segmentation; Seam carving
AB In this paper, a new full-automatic approach to content aware image retargeting is proposed. Most image retargeting approaches does not incorporate content information and only use local appearance information. However, there are some approaches which use high level information such as saliency regions, objects mask and depth information. Such methods do not use semantic labelling for each object. In this paper, object masks as well as their semantic class labels are used to propose a new approach to image retargeting. To do so, semantic segmentation of image is provided. Hence, a nonparametric approach to semantic segmentation is employed which is fast with no need to any learning model. This makes it simple and applicable to any dataset. To evaluate the proposed approach, besides presenting visual examples, we performed a set of subjective evaluations too. The obtained results show that our method outperforms other retargeting approaches.
C1 [Razzaghi, Parvin; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Razzaghi, P (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
EM parvin.razzaghi@gmail.com
RI Razzaghi, Parvin/AAE-2348-2022; Razzaghi, Parvin/F-3913-2019
OI Razzaghi, Parvin/0000-0002-7031-4609; 
CR Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815
   [Anonymous], 2012, APPROXIMATION ALGORI
   [Anonymous], 2008, IEEE C COMPUTER VISI
   [Anonymous], 2011, IEEE T PAMI
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048
   Gould S, 2012, LECT NOTES COMPUT SC, V7576, P439, DOI 10.1007/978-3-642-33715-4_32
   Grant M.C., 2012, CVX USERS GUIDE
   Jain A, 2010, LECT NOTES COMPUT SC, V6314, P199, DOI 10.1007/978-3-642-15561-1_15
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P2368, DOI 10.1109/TPAMI.2011.131
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manseld A, 2012, EUR C COMP VIS, P143
   Myeong H, 2013, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2013.395
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Razzaghi P, 2014, PATTERN RECOGN LETT, V42, P56, DOI 10.1016/j.patrec.2014.01.003
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Shamir Ariel, 2009, ACM SIG-GRAPH ASIA 2009 Courses, P11
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   Vaquero D., 2010, SPIE OPTICAL ENG APP
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wu L, 2012, MULTIMED TOOLS APPL, V70, P721
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YAO J, 2012, COMPUTER VISION PATT, P702
NR 27
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11517
EP 11536
DI 10.1007/s11042-014-2249-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600025
DA 2024-07-18
ER

PT J
AU Saha, S
   Basu, S
   Nasipuri, M
AF Saha, Satadal
   Basu, Subhadip
   Nasipuri, Mita
TI <i>i</i>LPR: an Indian license plate recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE License plate localization; Character segmentation; Character
   recognition; QTLR; Hough transform
ID TEXT; EXTRACTION; LOCALIZATION
AB One of the major concerns of Integrated Traffic Management System (ITMS) in India is the identification of vehicles violating the stop-line at a road crossing. A large number of Indian vehicles do not stop at the designated stop-line and pose serious threat to the pedestrians crossing the roads. The current work reports the technicalities of the LPR (Indian License Plate Recognition) system implemented at five busy road-junctions in one populous metro city in India. The designed system is capable of localizing single line and two-line license plates of various sizes and shapes, recognizing characters of standard/ non-standard fonts and performing seamlessly in varying weather conditions. The performance of the system is evaluated with a large database of images for different environmental conditions. We have published a limited database of Indian vehicle images in http://code.google.com/p/cmaterdb/ for non-commercial use by fellow researchers. Despite unparallel complexity in the Indian city-traffic scenario, we have achieved around 92 % plate localization accuracy and 92.75 % plate level recognition accuracy over the localized vehicle images.
C1 [Saha, Satadal] MCKV Inst Engn, ECE Dept, Liluah 711204, Howrah, India.
   [Basu, Subhadip; Nasipuri, Mita] Jadavpur Univ, CSE Dept, Kolkata, India.
C3 Jadavpur University
RP Saha, S (corresponding author), MCKV Inst Engn, ECE Dept, 243 GT Rd N, Liluah 711204, Howrah, India.
EM satadalsaha@ieee.org; subhadip@cse.jdvu.ac.in; mnasipuri@cse.jdvu.ac.in
OI SAHA, SATADAL/0000-0002-6994-0792
CR Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2002, METH 2002
   [Anonymous], 2010, ARXIV10024048
   [Anonymous], 2009, P NAT C COCOSYS 09 B
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], J COMPUT
   Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002
   Basu S, 2010, PATTERN RECOGN, V43, P3507, DOI 10.1016/j.patcog.2010.05.018
   Basu S, 2009, PATTERN RECOGN, V42, P1467, DOI 10.1016/j.patcog.2009.01.008
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   Chang SL, 2004, IEEE T INTELL TRANSP, V5, P42, DOI 10.1109/TITS.2004.825086
   Chowdhury S. P., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1280, DOI 10.1109/ICDAR.2009.188
   Chowdhury SP, 2009, J UNIVERS COMPUT SCI, V15, P3325
   Gazcón NF, 2012, PATTERN RECOGN LETT, V33, P1066, DOI 10.1016/j.patrec.2012.02.004
   Gopalan C, 2011, SIGNAL IMAGE VIDEO P, V5, P165, DOI 10.1007/s11760-010-0152-1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jia WJ, 2005, 2005 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC), P566
   Jung C, 2008, SIGNAL PROCESS, V88, P1907, DOI 10.1016/j.sigpro.2008.02.002
   Jung C, 2009, PATTERN RECOGN LETT, V30, P114, DOI 10.1016/j.patrec.2008.05.014
   Khandelwal A, 2009, LECT NOTES COMPUT SC, V5909, P369, DOI 10.1007/978-3-642-11164-8_60
   Mahini H, 2006, INT C PATT RECOG, P841
   Mohadeskasaei Seyed, 2010, INT J COMPUT THEOR E, V2, P264, DOI [10.7763/IJCTE.2010.V2.150, DOI 10.7763/IJCTE.2010.V2.150]
   Nilsson NJ, 1982, SYMB COMPUT, V1, P1982
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pan X, 2005, ENG APPL ARTIF INTEL, V18, P963, DOI 10.1016/j.engappai.2005.03.011
   Parasuraman Kumar, 2010, IEEE INT C COMP INT
   Retornaz T, 2007, MORPHOLOGY, V1, P177
   Saha Satadal, 2009, International Journal of Recent Trends in Engineering, V1, P284
   Saha S., 2009, P IEEE NAT C COMP CO, P206
   Saha S, 2011, INT J COMPUT SCI EME, V2, P520
   Saha S, 2012, ADV INTEL SOFT COMPU, V132, P649
   Sobel I., 2014, History and definition of the sobel operator
NR 35
TC 9
Z9 10
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10621
EP 10656
DI 10.1007/s11042-014-2196-7
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700022
DA 2024-07-18
ER

PT J
AU Shrivastava, S
   Singh, SK
   Hooda, DS
AF Shrivastava, Sourabh
   Singh, Satish Kumar
   Hooda, Dhara Singh
TI Color sensing and image processing-based automatic soybean plant foliar
   disease severity detection and estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soya-plant foliar disease; Rust; Bacterial blight; Brown spot; Sudden
   death syndrome; Frog's eye; Downy mildew; Automatic disease
   identification; Disease level classification
ID BACTERIAL-BLIGHT; BROWN SPOT; YIELD; RUST
AB Soybean is among one of the most important commercial crops, which is cultivated worldwide. The research work presented in this paper is focused on the problems associated with the cultivation and highlights the effect of various Soya plant foliar diseases on its yield. It has been presented a fully automatic disease detection and level estimation system which is based on color image sensing and processing. Various new parameters, namely Disease-Severity-Index (DSI), Infection-Per Region (IPR), and Disease-Level-Parameter (DLP) for measuring the disease severity level and level-classification have also been formulated and derived. The proposed method has been tested on a real database of Soya leaves collected between July 2012 and September 2012 and found to be at an excellent methodology for the purpose mentioned above. Experimentation has shown that the method is superior to the methods proposed by Cui et al. (Sens & Instrumen. Food Qual. 3(1),49-56, 2009) & (Biosyst Eng. 107(3), 186-193, 2010) in terms of adopted methodology and measuring parameters used.
C1 [Shrivastava, Sourabh; Hooda, Dhara Singh] Jaypee Univ Engn & Technol, Guna 473226, MP, India.
   [Singh, Satish Kumar] Indian Inst Informat Technol, Allahabad 211012, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Shrivastava, S (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, MP, India.
EM sourabh.juet@gmail.com
RI singh, satish/U-7158-2018; Singh, Dr Satish Kumar/JMP-6186-2023
OI singh, satish/0000-0002-8536-4991; Singh, Dr Satish
   Kumar/0000-0003-1991-7727
CR [Anonymous], BP 68 W DOWNY MILDEW
   [Anonymous], 1990, REP A PLANT DIS DEP
   Cui D, 2010, BIOSYST ENG, V107, P186, DOI 10.1016/j.biosystemseng.2010.06.004
   Di Cui, 2009, Sensing and Instrumentation for Food Quality and Safety, V3, P49, DOI 10.1007/s11694-009-9070-8
   Dorrance A.E., 2007, Using foliar fungicides to manage soybean rust
   Dorrance AE, 2010, AC1810 OH STAT U
   Dorrance AE, 2010, AC5310 OHIO STAT U
   Food and Agriculture Organization of the United Nations, EL DAT
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   HARTMAN GL, 1991, PLANT DIS, V75, P596, DOI 10.1094/PD-75-0596
   Jagtap G.P., 2012, SCI J MICROBIOLOGY, V1, P1, DOI DOI 10.14196/SJMI.V1I1.18
   Lee GB, 1996, PLANT DIS, V80, P408, DOI 10.1094/PD-80-0408
   Loren J, 2011, BROWN SPOT SOYBEAN
   Ma Xiao-dan, 2010, Proceedings of the 2010 International Conference of Information Science and Management Engineering. ISME 2010, P14, DOI 10.1109/ISME.2010.52
   Mian MAR, 2008, CROP SCI, V48, P14, DOI 10.2135/cropsci2007.08.0432
   Miles MR, 2003, SOYBEAN RUST IS US C
   PARK EW, 1986, PLANT DIS, V70, P214, DOI 10.1094/PD-70-214
   Roy KW, 1997, PLANT DIS, V81, P1100, DOI 10.1094/PDIS.1997.81.10.1100
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Shen Weizheng, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P491, DOI 10.1109/CSSE.2008.1649
   SOPA, REP 2010
   Sweets L.E., 2008, Integrated Pest Management: Soybean Diseases
   Thoenes P, 2007, BACKGROUND PAPER COM
   Westphal A, BP 131 W FROG EYE SP
   Westphal A, 2006, BP 58 W SUDDEN DEATH
   WILLIAMS DJ, 1980, PHYTOPATHOLOGY, V70, P900, DOI 10.1094/Phyto-70-900
NR 26
TC 28
Z9 29
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11467
EP 11484
DI 10.1007/s11042-014-2239-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600022
DA 2024-07-18
ER

PT J
AU Zhong, R
   Hu, RM
   Wang, ZY
   Wang, SZ
AF Zhong, Rui
   Hu, Ruimin
   Wang, Zhongyuan
   Wang, Shizheng
TI 3D hybrid just noticeable distortion modeling for depth image-based
   rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D just noticeable distortion (3DJND); Depth image-based rendering
   (DIBR); Human visual sensitivity (HVS); Depth saliency; Geometric
   distortion
ID VISUAL-ATTENTION; VIDEO
AB The 3D Just Noticeable Distortion (JND) threshold in essence depends on Human Visual Sensitivity (HVS). This paper carves out a Hybrid Just Noticeable Distortion (HJND) model to measure JND threshold in the framework of Depth Image-Based Rendering (DIBR) for 3D video. The critical differences between 2D and 3D visual perception, depth saliency and geometric distortion, are combined into the HJND model because their significant influence on HVS. To save bit, the HJND model is introduced into the Multi-view Video plus Depth (MVD) encoding framework as a residual filter. After the residue is filtered by HJND and the reference model named Joint Just Noticeable Distortion (JJND), bit saving is achieved up to 28.79% and 23.53%, respectively, and the 3D impaired videos filtered by HJND and JJND have the similar subjective quality. The experiments demonstrate that HJND describes HVS for 3D video more accurately than the state-of-the-art methods.
C1 [Zhong, Rui; Hu, Ruimin; Wang, Zhongyuan] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430079, Peoples R China.
   [Zhong, Rui; Hu, Ruimin; Wang, Zhongyuan] Wuhan Univ, Sch Comp, Wuhan 430079, Peoples R China.
   [Wang, Shizheng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Wuhan University; Wuhan University; Nanyang Technological University
RP Hu, RM (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430079, Peoples R China.
EM zhongrui0824@126.com; hurm1964@gmail.com; wzy_hope@163.com;
   shizhengwang@ntu.edu.sg
RI zhong, rui/HSZ-2549-2023; Wang, Zhongyuan/ABD-2189-2020
FU Major program of National Natural Science Foundation of China (NSFC)
   [61231015]; Major Science and Technology Innovation Plan of Hubei
   Province [2013AAA020]; National NSFC [61271256, 61172173, 61172174,
   61303114]
FX This work was supported by Major Program of National Natural Science
   Foundation of China (NSFC) under Grant 61231015, the National NSFC under
   Grants 61271256, 61172173, 61172174, and 61303114, and by the Major
   Science and Technology Innovation Plan of Hubei Province under Grant
   2013AAA020.
CR [Anonymous], 2011, 2011 VIS COMM IM PRO
   [Anonymous], 2002, BT.500-11,
   [Anonymous], 2006, MODERN IMAGE QUALITY
   Chen H, 2010, IEEE INT CON MULTI, P713, DOI 10.1109/ICME.2010.5583897
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   De Silva DVSX, 2010, IEEE INT CON MULTI, P1219, DOI 10.1109/ICME.2010.5582582
   Gang X, 1996, EPIPOLAR GEOMETRY ST, V6
   Gao Y, 2011, 2011 IEEE INT S CIRC
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Huynh-Thu Q, 2011, IEEE T BROADCAST, V57, P421, DOI 10.1109/TBC.2011.2128250
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   JEZZARD P, 1995, MAGNET RESON MED, V34, P65, DOI 10.1002/mrm.1910340111
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Muller K, 2008, ISOIECJTC1SC29WG11M1
   Nicolas A, 2002, ICME
   Qiaoyan Zheng, 2013, Journal of Software, V8, P2541, DOI 10.4304/jsw.8.10.2541-2548
   Sequeira V, 2001, PROC SPIE, V4309, P126
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Stankiewicz O, 2009, ISOIECJTC1SC29WG11M1
   Tanimoto M., 2008, ISOIECJTC1SC29WG11M1
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Yaqing Niu, 2011, 2011 3rd European Workshop on Visual Information Processing, P211, DOI 10.1109/EuVIP.2011.6045546
   Zhang Y, 2010, EURASIP J ADV SIG PR, V60
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
NR 29
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10457
EP 10478
DI 10.1007/s11042-014-2176-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700014
DA 2024-07-18
ER

PT J
AU Wu, ZZ
   Chng, ES
   Li, HZ
AF Wu, Zhizheng
   Chng, Eng Siong
   Li, Haizhou
TI Exemplar-based voice conversion using joint nonnegative matrix
   factorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech synthesis; Voice conversion; Exemplar; Sparse representation;
   Nonnegative matrix factorization; Joint nonnegative matrix factorization
AB Exemplar-based sparse representation is a nonparametric framework for voice conversion. In this framework, a target spectrum is generated as a weighted linear combination of a set of basis spectra, namely exemplars, extracted from the training data. This framework adopts coupled source-target dictionaries consisting of acoustically aligned source-target exemplars, and assumes they can share the same activation matrix. At runtime, a source spectrogram is factorized as a product of the source dictionary and the common activation matrix, which is applied to the target dictionary to generate the target spectrogram. In practice, either low-resolution mel-scale filter bank energies or high-resolution spectra are adopted in the source dictionary. Low-resolution features are flexible in capturing the temporal information without increasing the computational cost and the memory occupation significantly, while high-resolution spectra contain significant spectral details. In this paper, we propose a joint nonnegative matrix factorization technique to find the common activation matrix using low- and high-resolution features at the same time. In this way, the common activation matrix is able to benefit from low- and high-resolution features directly. We conducted experiments on the VOICES database to evaluate the performance of the proposed method. Both objective and subjective evaluations confirmed the effectiveness of the proposed methods.
C1 [Wu, Zhizheng; Chng, Eng Siong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Wu, Zhizheng] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Li, Haizhou] Nanyang Technol Univ, Human Language Technol Dept, Inst Infocomm Res, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University; University of Edinburgh; Nanyang
   Technological University; Agency for Science Technology & Research
   (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Wu, ZZ (corresponding author), Univ Edinburgh, Ctr Speech Technol Res, Edinburgh EH8 9YL, Midlothian, Scotland.
EM zhizheng.wu@ed.ac.uk; aseschng@ntu.edu.sg; hli@i2r.a-star.edu.sg
RI Eng-Siong, CHNG/ABH-6779-2020; Li, Haizhou/Q-6438-2019
OI Eng-Siong, CHNG/0000-0001-6257-7399; Li, Haizhou/0000-0001-9158-9401
CR Afify M, 2007, P IEEE INT C AC SPEE
   [Anonymous], P IEEE INT C AC SPEE
   Buchholz S., 2011, P INT
   Cichocki A, 2006, LECT NOTES COMPUT SC, V3889, P32
   Desai S, 2010, IEEE T AUDIO SPEECH, V18, P954, DOI 10.1109/TASL.2010.2047683
   Gemmeke JF, 2011, IEEE T AUDIO SPEECH, V19, P2067, DOI 10.1109/TASL.2011.2112350
   Helander E, 2012, IEEE T AUDIO SPEECH, V20, P806, DOI 10.1109/TASL.2011.2165944
   Helander E, 2010, IEEE T AUDIO SPEECH, V18, P912, DOI 10.1109/TASL.2010.2041699
   Kain Alexander., 2001, HIGH RESOLUTION VOIC
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Mathias Samuel R, 2014, Front Biosci (Schol Ed), V6, P92
   Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007
   Ribeiro F., 2011, P IEEE INT C AC SPEE
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472
   Takashima R, 2012, P IEEE SPOK LANG TEC
   Toda T, 2009, P IEEE INT C AC SPEE
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Tokuda K, 1994, P INT C SPOK LANG PR
   Wolters MK, 7 ISCA SPEECH SYNTH
   Wu Z, 2012, P AS PAC SIGN INF PR, P1
   Wu Z, 2014, JOINT NONNEGATIVE MA
   Wu Z, 2014, IEEE ACM T AUDIO SPE
   Wu Z., 2013, 8 ISCA SPEECH SYNTH
   Zen H, 2011, IEEE T AUDIO SPEECH, V19, P417, DOI 10.1109/TASL.2010.2049685
   [No title captured]
NR 27
TC 22
Z9 28
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9943
EP 9958
DI 10.1007/s11042-014-2180-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400007
DA 2024-07-18
ER

PT J
AU Abawajy, JH
   Fudzee, F
AF Abawajy, J. H.
   Fudzee, F.
TI Dynamic path determination policy for distributed multimedia content
   adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content adaptation; Service oriented architecture; Multi-criteria
   decisionmaking; Distributed systems; Performance analysis
ID SERVICE
AB Multimedia content adaptation allows the ever increasing variety of handheld devices such as Smartphones to access distributed rich media resources available on the Internet today. Path planning and determination is a fundamental problem in enhancing performance of distributed multimedia content adaptation systems. Most of the existing path determination mechanisms use static path determination criteria based solely on associating a path with a single behavior aggregate score. However, some criteria such as availability are best represented using different functionality rather than being accumulated into the aggregate score. Moreover, since selection criteria have different behavior towards the score, this principle need to be considered. In this paper, we propose a dynamic multi-criteria path determination policy that selects an optimal path to the content adaptation services that best meet the user preferences and QoS requirements. The performance of the proposed approach is studied in terms of score's fairness and reliability under different variations. The results indicate that the proposed policy performs substantially better than the baseline policy.
C1 [Abawajy, J. H.; Fudzee, F.] Deakin Univ, Sch Informat Technol, Parallel & Distributed Comp Lab, Melbourne, Vic, Australia.
   [Fudzee, F.] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Parit Raja, Malaysia.
C3 Deakin University; University of Tun Hussein Onn Malaysia
RP Abawajy, JH (corresponding author), Deakin Univ, Sch Informat Technol, Parallel & Distributed Comp Lab, Melbourne, Vic, Australia.
EM jemal@deakin.edu.au
OI Md Fudzee, Mohd Farhan/0000-0002-6801-2660
CR [Anonymous], 2005, APPL MULTIVARIATE RE
   [Anonymous], STUD FUZZ SOFT COMP
   Ardon S, 2003, INT J COMMUN SYST, V16, P97, DOI 10.1002/dac.582
   Azzalini A, 2003, J R STAT SOC B, V65, P367, DOI 10.1111/1467-9868.00391
   Berhe G., 2005, J DIGITAL INFORM MAN, V3, P96
   El-Khatib K, 2004, FIRST INTERNATIONAL CONFERENCE ON QUALITY OF SERVICE IN HETEROGENEOUS WIRED/WIRELESS NETWORKS, PROCEEDINGS, P308, DOI 10.1109/QSHINE.2004.7
   Fawaz Y, 2008, 3 INT C INF COMM TEC
   Fawaz Y, 2008, INT J DIGIT MULTIMED, V2008, DOI 10.1155/2008/851628
   Fudzee Mohd Farhan Md, 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P721, DOI 10.1109/CCGRID.2010.128
   Fudzee M.F. Md, 2008, 10 INT C INF INT WEB, P426
   Fudzee MFM, 2011, FUTURE GENER COMP SY, V27, P256, DOI 10.1016/j.future.2010.09.005
   He J, 2007, IEEE T KNOWL DATA EN, V19, P127, DOI 10.1109/TKDE.2007.250590
   Hsiao JL, 2008, IEEE T MULTIMEDIA, V10, P646, DOI 10.1109/TMM.2008.921852
   Irving VW, 2003, HDB PSYCHOL
   Javadi B, 2008, CONCURR COMP-PRACT E, V20, P75, DOI 10.1002/cpe.1222
   Lo A.W., 2005, J. Invest. Consult., V7, P21, DOI DOI 10.2139/SSM.728864
   Lo AW, 2004, J PORTFOLIO MANAGE, P15, DOI 10.3905/jpm.2004.442611
   Lum WY, 2003, IEEE T SOFTWARE ENG, V29, P1100, DOI 10.1109/TSE.2003.1265524
   Merat S, 2008, ERPAS 10 INT C INF I, P626
   Roses K, 2007, DISCRETE MATH ITS AP
NR 20
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8325
EP 8341
DI 10.1007/s11042-013-1735-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600006
DA 2024-07-18
ER

PT J
AU Heo, GI
   Park, YJ
   Park, WH
AF Heo, Geon Il
   Park, Yong Jun
   Park, Won Hyung
TI Vulnerability of information disclosure in data transfer section for
   constructing a safe smart work infrastructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart Work; Information disclosure; SSL/TLS; Wireshark; Cipher suite
AB As the communication infrastructure has extended and the number of a smartphone' users has been rapidly increasing, many companies want to introduce Smart Work. But this means that people have chances to produce or handle their company's data. If an administrator doesn't consider a 'security' element, the Smart Work will be terrible security threats not a chance. For constructing a safe Smart Work infrastructure, this paper selects major domestic and external web[mobile] sites which provide cloud, VoIP[mVoIP], messenger, E-mail services and examines whether data are encrypted or not in data transfer section.
C1 [Heo, Geon Il] Korea Univ, Dept Informat Secur, Seoul, South Korea.
   [Park, Yong Jun] Sungkyunkwan Univ, Dept Informat & Commun, Suwon, Gyeonggi Do, South Korea.
   [Park, Won Hyung] Far East Univ, Dept Cyber Secur, Gamgok Myeon, Chungcheongbuk, South Korea.
C3 Korea University; Sungkyunkwan University (SKKU)
RP Park, WH (corresponding author), Far East Univ, Dept Cyber Secur, Gamgok Myeon, Chungcheongbuk, South Korea.
EM aza837@naver.com; yongjun.pa@gmail.com; whpark@kdu.ac.kr
CR Convergence Security R& D Team, 2010, HDB OF CIPH
   Convergence Security R& D Team, 2009, HDB SEC SERV
   Convergence Security R& D Team, 2010, GUID CIPH ALG KEY LE
   Freier AlanO., 1996, SSL PROTOCOL VERSION
   Heo GI, 2013, COUNTERMEASURES PRIV
   Kim AC, 2013, MULTIMEDIA TOOLS APP
   Korea Internet Security Agency, 2013, INTR SEED ALG
   Park WH, 2012, MULTIMEDIA TOOLS APP
   Park WH, 2012, INF SCI APPL ICISA 2, P1
   Sherif MH, 1998, THIRD IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS, PROCEEDINGS, P353, DOI 10.1109/ISCC.1998.702546
   THOMAS S, 2000, SSL TLS ESSENTIAL
NR 11
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8831
EP 8847
DI 10.1007/s11042-013-1627-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600009
DA 2024-07-18
ER

PT J
AU Punt, M
   Bjelica, MZ
   Zdravkovic, V
   Teslic, N
AF Punt, Marija
   Bjelica, Milan Z.
   Zdravkovic, Vladan
   Teslic, Nikola
TI An integrated environment and development framework for social gaming
   using mobile devices, digital TV and Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social games; Mobile devices; Interactive TV; TV-centric gaming; Game
   development framework; Second screen
ID PHONE
AB The amount of digital multimedia devices in a modern day household capable of connecting to the Internet has increased dramatically over the last years, including mobile devices such as smart phones and tablets as well as digital TV sets and set-top boxes. Since these devices are readily available and allow customization through software they can be easily used to support and enhance traditional social activities in the living room. This paper presents an integrated environment of mobile devices and digital TVs connected to the Internet used as a platform for exploring both traditional and novel gaming concepts in either a single living room or across different homes connecting multiple living rooms. To create such an environment a framework was developed enabling the implementation of distributed social games, using the digital TV as a display showing game content public to all players and using the available personal mobile devices as controllers and displays showing private portions of the game. The framework also allows the innovative use of broadcast related information and social media during game play. Five different games were developed using the framework. The framework effectiveness was evaluated by comparing TV-centric games developed with and without the framework using size and complexity metrics, additionally application responsiveness was measured using a game developed without and with the framework and compared with a state-of-the-art game controller. The experience of playing the developed games was obtained by collecting and analyzing self-reported data using a questionnaire combined with additional observations from volunteers and researchers.
C1 [Punt, Marija] Univ Belgrade, Sch Elect Engn, Belgrade 11120, Serbia.
   [Bjelica, Milan Z.; Teslic, Nikola] Univ Novi Sad, Fac Tech Sci, Comp Engn & Comp Commun Dept, Novi Sad 21000, Serbia.
   [Zdravkovic, Vladan] Sheffield Hallam Univ, Sheffield S1 1WB, S Yorkshire, England.
C3 University of Belgrade; University of Novi Sad; Sheffield Hallam
   University
RP Punt, M (corresponding author), Univ Belgrade, Sch Elect Engn, Bulevar Kralja Aleksandra 73, Belgrade 11120, Serbia.
EM marija.punt@etf.rs
OI Bjelica, Milan/0000-0002-9111-0154; Teslic, Nikola/0000-0003-3806-5777;
   Punt, Marija/0000-0002-1944-7086
FU Ministry of Education, Science and Technological Development of the
   Republic of Serbia [32041, 44009]
FX This work was partially supported by the Ministry of Education, Science
   and Technological Development of the Republic of Serbia, project No.
   32041, and 44009.
CR [Anonymous], THESIS U NOVI SAD SE
   [Anonymous], INT C ADV VIS INT AV
   [Anonymous], 2011, P BRAZ S GAM DIG ENT
   [Anonymous], EUROITV 2007
   [Anonymous], 2011, P ITS 2011
   [Anonymous], 5 ACM SIGCOMM WORKSH
   [Anonymous], CHI 08 HUM FACT COMP
   [Anonymous], 2012, Cuckoo: A computation offloading framework for smartphones, DOI DOI 10.1007/978-3-642-29336-84
   [Anonymous], 2 EUR C INT TEL ENH
   [Anonymous], METHODS PRACT CASE S
   [Anonymous], LEARN COCOS2D 2
   Baek J, 2008, IEEE T CONSUM ELECTR, V54, P719, DOI 10.1109/TCE.2008.4560153
   Barkhuus L, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1592440.1592444
   Bjelica MZ, 2013, IEEE ICCE, P667, DOI 10.1109/ICCE.2013.6487064
   Boehm B, 2000, ANN SOFTW ENG, V10, P177, DOI 10.1023/A:1018991717352
   Claypool M, 2006, PROC SPIE, V6071, DOI 10.1117/12.648609
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Courtois C., 2012, P 10 EUROPEAN C INTE, P153, DOI DOI 10.1145/2325616.2325646
   Cruickshank L., 2007, DES J, V10, P41, DOI [DOI 10.2752/146069207789271920, 10.2752/146069207789271920]
   Fallahkhair S, 2007, J COMPUT ASSIST LEAR, V23, P312, DOI 10.1111/j.1365-2729.2007.00236.x
   Gauntlett D., 1999, TV LIVING TELEVISION
   GILL GK, 1991, IEEE T SOFTWARE ENG, V17, P1284, DOI 10.1109/32.106988
   Häsel M, 2011, COMMUN ACM, V54, P139, DOI 10.1145/1866739.1866765
   Joselli Mark, 2009, Proceedings of the VIII Brazilian Symposium on Games and Digital Entertainment (SBGAMES 2009), P141, DOI 10.1109/SBGAMES.2009.24
   Magerkurth C, 2004, PROC GRAPH INTERF, P73
   Masood S. Z., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P422, DOI 10.1109/ICCVW.2011.6130272
   McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837
   Metcalf C, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1412196.1412200
   Nathan M., 2008, P INT C DESIGNING IN, P85, DOI DOI 10.1145/1453805.1453824
   Nguyen Vu, 2007, COCOMO 2 FORUM 2007
   Römer K, 2002, PERS UBIQUIT COMPUT, V6, P371, DOI 10.1007/s007790200042
   Scheible Jurgen., 2008, P 16 ACM INT C MULTI, P957, DOI DOI 10.1145/1459359.1459532
   Schroeder J., 2013, AndEngine for Android game development cookbook
   Tullis T., 2010, Measuring the user experience: collecting, analyzing, and presenting usability metrics
   Vajk T, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/539078
   Vidakovic M, 2012, IEEE T CONSUM ELECTR, V58, P1063, DOI 10.1109/TCE.2012.6311357
   Wang SC, 2011, MULTIMED TOOLS APPL, V51, P1013, DOI 10.1007/s11042-009-0435-0
   Williams D, 2011, TELEMAT INFORM, V28, P251, DOI 10.1016/j.tele.2010.11.001
   Zechner M., 2011, Beginning Android 4 Game Development
NR 39
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 8137
EP 8169
DI 10.1007/s11042-014-2045-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200033
DA 2024-07-18
ER

PT J
AU Yilmaz, GN
AF Yilmaz, G. Nur
TI A no reference depth perception assessment metric for 3D video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; Aerial perspective; Binocular parallax; Depth perception;
   Gaussian Mixture Model (GMM); Expectation Maximization (EM); QoE;
   Lateral motion
ID QUALITY ASSESSMENT; PSNR; DISTORTION; VISION; MOTION
AB Recent technological breakthroughs in 3-Dimensional (3D) video capture, display, coding, transmission, rendering, etc. have led the advances of 3D multimedia applications into the consumer market. However, the effect of these technologies on 3D video Quality of Experience (QoE) has not been thoroughly investigated to speed up the wide-spread proliferation of the 3D video applications in this market. Quality and depth perception assessment of 3D video from the view of end users reflects the most important aspect of 3D video QoE. Therefore, evaluating quality and depth perception of 3D video should be given the utmost attention. Currently, the depth perception assessment of 3D video can only be achieved using time consuming and rigorous subjective assessments due to the lack of reliable and efficient objective metrics. Assessing the depth perception using Full-Reference (FR)/Reduced Reference (RR) objective metrics is not efficient for on the fly 3D video applications due to the requirement of original video/extracted information at the receiver side. Thus, a No Reference (NR) metric, which does not need any original video related information at the receiver side to predict the depth perception, is proposed in this paper. Three important cues (i.e., binocular parallax, lateral motion, and aerial perspective) for Human Visual System (HVS) to perceive the depth of a 3D video are utilized to develop the NR metric. Experimental results devised using the proposed metric prove the effectiveness of it to predict the depth perception.
C1 Kirikkale Univ, Elect & Elect Engn Dept, Kirikkale, Turkey.
C3 Kirikkale University
RP Yilmaz, GN (corresponding author), Kirikkale Univ, Elect & Elect Engn Dept, Kirikkale, Turkey.
EM nur.gkc@gmail.com
OI NUR YILMAZ, Gokce/0000-0002-0015-9519
CR [Anonymous], THESIS U CAMBRIDGE
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], IEEE 3 INT WORKSH QU
   [Anonymous], NEM SUMM C IST TURK
   [Anonymous], INT C IMAG PROC THES
   [Anonymous], 18 IEEE INT C IMAG P
   [Anonymous], MEAN DIRECTION MEAN
   [Anonymous], IEICE T COMMUN E
   [Anonymous], INT C CONS EL COMM N
   [Anonymous], K MEANS CLUSTERING N
   [Anonymous], IEEE INT C IMAG PROC
   [Anonymous], IEEE WORKSH QUAL MUL
   [Anonymous], 17 IEEE INT C IMAG P
   [Anonymous], 1 INT WORKSH VID PRO
   [Anonymous], IEEE INT WORKSH HOT
   [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], IEEE INT S BROADB MU
   [Anonymous], J VIS LIT
   [Anonymous], IEEE INT JOINT C ART
   [Anonymous], 17 IEEE INT C IMAG P
   [Anonymous], 15 EUR SIGN PROC C P
   [Anonymous], NEURON
   [Anonymous], INT WORKSH VID PROC
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Cheong LF, 2001, INT J COMPUT VISION, V44, P199, DOI 10.1023/A:1012224215211
   Devore JayL., 2003, PROBABILITY STAT ENG, Vsixth
   Do CB, 2008, NAT BIOTECHNOL, V26, P897, DOI 10.1038/nbt1406
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Gunawan IP, 2008, IEEE T CIRC SYST VID, V18, P71, DOI 10.1109/TCSVT.2007.913755
   HALL P, 1988, STAT PROBABIL LETT, V6, P311, DOI 10.1016/0167-7152(88)90005-3
   Hansard M, 2008, J OPT SOC AM A, V25, P2357, DOI 10.1364/JOSAA.25.002357
   Harris JM, 2008, VISION RES, V48, P695, DOI 10.1016/j.visres.2007.11.018
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Karim HA, 2008, IEEE T CONSUM ELECTR, V54, P745, DOI 10.1109/TCE.2008.4560156
   Lebreton P, 2012, IEEE J-STSP, V6, P710, DOI 10.1109/JSTSP.2012.2213236
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Martini MG, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-66
   Mittal A., 2011, IEEE DIG SIGN PROC W
   Moorthy AK, 2011, MULTIMED TOOLS APPL, V51, P675, DOI 10.1007/s11042-010-0640-x
   Naccari M, 2009, IEEE T MULTIMEDIA, V11, P932, DOI 10.1109/TMM.2009.2021785
   Nur G, 2012, IEEE T CIRC SYST VID, V22, P225, DOI 10.1109/TCSVT.2011.2160600
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Read J, 2005, PROG BIOPHYS MOL BIO, V87, P77, DOI 10.1016/j.pbiomolbio.2004.06.005
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Saxena A., 2007, P 20 INT JOINT C ART
   Staelens N, 2013, IEEE T CIRC SYST VID, V23, P1322, DOI 10.1109/TCSVT.2013.2243052
   Tagliasacchi M, 2010, MULTIMED TOOLS APPL, V48, P471, DOI 10.1007/s11042-010-0473-7
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Valenzise G., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P100, DOI 10.1109/QOMEX.2010.5517880
   Wang XB, 2009, LECT NOTES COMPUT SC, V5506, P779, DOI 10.1007/978-3-642-02490-0_95
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Zhu KF, 2013, PROC SPIE, V8755, DOI 10.1117/12.2015594
NR 55
TC 12
Z9 12
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6937
EP 6950
DI 10.1007/s11042-014-1945-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800016
DA 2024-07-18
ER

PT J
AU Kang, YM
   Lee, DH
   Cho, HG
AF Kang, Young-Min
   Lee, Do-Hoon
   Cho, Hwan-Gue
TI Multipeak aniostropic microfacet model for iridescent surfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rendering; Iridescent surface; Microfacet distribution
ID REFLECTION
AB In this paper, we propose an efficient iridescent rendering method. The iridescent colors on a surface is caused by the different reflection paths of rays with different wavelengths. In microfacet-based rendering model, the dominant reflection path of an incident light ray is statistically described by the microfacet-distribution function (MDF) of the surface. Therefore, the iridescent colors on the surface can be produced by applying different MDFs to different light wave channels. However, it is unnatural for a surface to have significantly different reflection properties in accordance with the light waves. Taking those into account, the proposed method employs identical and anisotropic microfacet distribution function(MDF) for each light wave channel, and rotates the identical anisotropic MDF of each channel with its own angle to produce iridescent reflection. The method also employs multi-peak MDF for the simulation of diffraction effects, and can be successfully applied to iridecent surface such as CD-ROM and mother-of-pearl (nacre) furniture. The experimental results demonstrate that the method enables interactive applications such as games or virtual reality softwares to plausibly express various cases of iridescent surfaces.
C1 [Kang, Young-Min] Tongmyong Univ, Dept Game Engn, Busan, South Korea.
   [Lee, Do-Hoon; Cho, Hwan-Gue] Pusan Natl Univ, Dept Comp Engn, Busan, South Korea.
C3 Tongmyong University; Pusan National University
RP Kang, YM (corresponding author), Tongmyong Univ, Dept Game Engn, Sinseonno 428, Busan, South Korea.
EM ymkang@tu.ac.kr; dohoon@pusan.ac.kr; hgcho@pusan.ac.kr
RI Kang, Young-Min/R-5960-2019
CR Agu E., 2002, P IASTED VIIP
   [Anonymous], 1993, P 4 EUR WORKSH REND
   [Anonymous], 2013, BLACK LACQ WARDR CHE
   [Anonymous], 1977, P 4 ANN C COMPUTER G, DOI DOI 10.1145/965141.563893
   Ashikhmin M., 2000, Journal of Graphics Tools, V5, P25, DOI 10.1080/10867651.2000.10487522
   Ashikhmin M, 2000, COMP GRAPH, P65, DOI 10.1145/344779.344814
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Cook R. L., 1981, Computer Graphics, V15, P307, DOI 10.1145/965161.806819
   Cuypers T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231820
   Hirayama H, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/PCCGA.2000.883853
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Moravec H. P., 1981, Computer Graphics, V15, P289, DOI 10.1145/965161.806817
   Musbach A, 2013, COMPUT GRAPH FORUM, V32, P24, DOI 10.1111/cgf.12012
   Musgrave F. K., 1989, Proceedings. Graphics Interface'89, P227
   Poulin P., 1990, Computer Graphics, V24, P273, DOI 10.1145/97880.97909
   Stam J, 1999, COMP GRAPH, P101, DOI 10.1145/311535.311546
   Sun YL, 2000, SPRING COMP SCI, P341
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
NR 19
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6229
EP 6242
DI 10.1007/s11042-014-2092-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700007
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Stevens, I
   De Marez, L
   Martens, L
   Joseph, W
AF De Pessemier, Toon
   Stevens, Isabelle
   De Marez, Lieven
   Martens, Luc
   Joseph, Wout
TI Analysis of the quality of experience of a commercial voice-over-IP
   service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VoIP; User experience; QoE; Mobile
ID SKYPE
AB Voice-over-IP (VoIP) services, enabling users to make cheap phone calls using the Internet, are becoming increasingly popular, not only on desktop computers but also on mobile devices such as smartphones that are connected through mobile networks. Users' perception of the level of quality plays a key role in making a VoIP service to succeed or to fail. This paper demonstrates the influence of technical parameters (such as the audio codec, type of data network, and handovers during the call), device characteristics (such as the platform, manufacturer, model, and operating system), and application aspects (such as the software version and configuration) on the subjective quality of a commercial VoIP service. The relative influence of all these parameters is determined and a decision tree combines these results in order to assess the subjective quality. Combining a large number of objective parameters in a decision tree to determine the user's subjective evaluation of the quality of a VoIP call is a novel and complex procedure. The subjective quality, in turn, has an influence on the duration of the call, and as a result an influence on the usage behavior of the service. The users' assessment of the service quality is not evaluated by merely taking a snapshot of the perceived quality at one moment in time but rather by analyzing the perceived quality over a longer period of time during service usage, which has not been done up to now. Analyzing the VoIP service using a regression analysis over a period of 120 days showed that the perceived quality decreases slightly when the user utilizes the service more often and gets more familiar with it.
C1 [De Pessemier, Toon; Martens, Luc; Joseph, Wout] IMinds Ghent Univ, Dept Informat Technol, WiCa, B-9050 Ghent, Belgium.
C3 IMEC; Ghent University
RP De Pessemier, T (corresponding author), IMinds Ghent Univ, Dept Informat Technol, WiCa, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; isabelle.stevens@ugent.be;
   lieven.demarez@ugent.be; luc1.martens@ugent.be; wout.joseph@ugent.be
OI De Marez, Lieven/0000-0001-7716-4079; Joseph, Wout/0000-0002-8807-0673
CR About.com, 2013, WHAT AFF VOIC QUAL V
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Cano MD, 2012, TELECOMMUN SYST, V49, P5, DOI 10.1007/s11235-010-9348-5
   CARDOSO S, 2011, ESTAGIO SUPERVISIONA, P1
   De Pessemier T, 2012, IEEE T BROADCAST, V58, P580, DOI 10.1109/TBC.2012.2199590
   De Pessemier T, 2012, MULTIMED TOOLS APPL, V57, P335, DOI 10.1007/s11042-010-0712-y
   Definition of Quality of Experience (QoE), 2007, 109 ITUT TD
   Geerts David, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P158, DOI 10.1109/QOMEX.2010.5516292
   Hossfeld T, 2008, COMPUT NETW, V52, P650, DOI 10.1016/j.comnet.2007.10.008
   Huang TY, 2010, IEEE NETWORK, V24, P42, DOI 10.1109/MNET.2010.5430143
   Imam IF., 1993, J INTELL INF SYST, V2, P279, DOI [10.1007/BF00962072, DOI 10.1007/BF00962072]
   Karapanos E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P729
   Kutner M.H., 2005, Applied linear statistical models, V5th
   Magidson J., 1994, ADV METHODS MARKETIN, P118
   Manousos M, 2005, IEEE INTERNET COMPUT, V9, P35, DOI 10.1109/MIC.2005.92
   Nováková L, 2011, J INTELL INF SYST, V37, P355, DOI 10.1007/s10844-011-0157-4
   Palmieri F, 2006, LECT NOTES COMPUT SC, V4308, P355
   Rajaraman S., 2009, Five stars dominate ratings
   Reiter U., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P513, DOI 10.1109/ISCE.2011.5973883
   Rowe LA, 2005, ACM T MULTIM COMPUT, V1, P3, DOI 10.1145/1047936.1047938
   Soldani D, 2006, QOS QOE MANAGEMENT U, pi
   Support BA, 2013, GROWING POPULARITY H
NR 22
TC 6
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5873
EP 5895
DI 10.1007/s11042-014-1895-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100025
OA Green Published
DA 2024-07-18
ER

PT J
AU Benrhouma, O
   Hermassi, H
   Belghith, S
AF Benrhouma, Oussama
   Hermassi, Houcemeddine
   Belghith, Safya
TI Security analysis and improvement of a partial encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE WSN; Partial encryption; Security; Attacks
ID ONLY MULTIMEDIA CIPHERS; QUANTITATIVE CRYPTANALYSIS; CRYPTOSYSTEMS;
   DESIGN
AB This paper proposes to cryptanalyze a partial image encryption scheme. Security weaknesses were found in the cryptosystem consisting in the generation of the keystream. We then propose a modified version of the partial encryption scheme to enhance its security together with keeping the benefit of encrypting a reduced amount of data. Our contributions can be resumed in two points : we will first show the insecurity of the cryptosystem under study then we will propose a remedy to resist the described attacks.
C1 [Benrhouma, Oussama; Hermassi, Houcemeddine; Belghith, Safya] ENIT, SysComLab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Benrhouma, O (corresponding author), ENIT, SysComLab, Tunis, Tunisia.
EM oussama.benrhoumaa@gmail.com
RI Hermassi, Houcemeddine/J-2352-2012; Benrhouma, Oussama/JCD-7434-2023;
   Benrhouma, Oussama/ABE-2730-2020; hermassi, houcemeddine/ADK-4317-2022
OI Belghith, Safya/0000-0001-7408-7848; Hermassi,
   houcemeddine/0000-0002-4681-4312; Benrhouma, Oussama/0000-0002-4540-3650
CR Ariffin MRK, 2008, PHYS LETT A, V372, P5427, DOI 10.1016/j.physleta.2008.06.077
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   BIRYUKOV A, 1998, EUROCRYPT
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Furht B., 2005, MULTIMEDIA SECURITY
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Hermassi H, 2010, COMMUNICATIONS NONLI
   Hermassi H, 2009, 6 INT MULT SYST SIGN
   Hermassi H, 2012, J SYST SOFTWARE, V85, P2133, DOI 10.1016/j.jss.2012.04.031
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2004, PHYS LETT A, V332, P368, DOI 10.1016/j.physleta.2004.09.028
   Lian SG, 2004, LECT NOTES COMPUT SC, V3332, P65
   LIAN SG, 2009, MULTIMEDIA CONTENT E
   Liu YB, 2012, COMMUN NONLINEAR SCI, V17, P3267, DOI 10.1016/j.cnsns.2011.11.040
   Nagaraj N, 2009, COMMUN NONLINEAR SCI, V14, P1013, DOI 10.1016/j.cnsns.2007.12.001
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shibutani K, 2011, LECT NOTES COMPUT SC, V6917, P342, DOI 10.1007/978-3-642-23951-9_23
   Solak E, 2008, CHAOS INTERDIS J NON, V18
   Solak E, 2010, OPT COMMUN, V283, P232, DOI 10.1016/j.optcom.2009.09.070
   Vrahatis MN, 2010, MATH COMPUT MODEL, V51, P239, DOI 10.1016/j.mcm.2009.08.011
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
NR 30
TC 7
Z9 7
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3617
EP 3634
DI 10.1007/s11042-013-1790-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800001
DA 2024-07-18
ER

PT J
AU Irshad, A
   Sher, M
   Rehman, E
   Ch, SA
   Ul Hassan, M
   Ghani, A
AF Irshad, Azeem
   Sher, Muhammad
   Rehman, Eid
   Ch, Shehzad Ashraf
   Ul Hassan, Mahmood
   Ghani, Anwar
TI A single round-trip SIP authentication scheme for Voice over Internet
   Protocol using smart card
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session initiation protocol; Authentication; Security; Voice over
   Internet Protocol; Smart card
ID SECURE AUTHENTICATION
AB The Session Initiation Protocol (SIP) has revolutionized the way of controlling Voice over Internet Protocol (VoIP) based communication sessions over an open channel. The SIP protocol is insecure for being an open text-based protocol inherently. Different solutions have been presented in the last decade to secure the protocol. Recently, Zhang et al. authentication protocol has been proposed with a sound feature that authenticates the users without any password-verifier database using smart card. However, the scheme has a few limitations and can be made more secure and optimized regarding cost of exchanged messages, with a few modifications. Our proposed key-agreement protocol makes a use of two server secrets for robustness and is also capable of authenticating the involved parties in a single round-trip of exchanged messages. The server can now authenticate the user on the request message received, rather than the response received upon sending the challenge message, saving another round-trip of exchanged messages and hence escapes a possible denial of service attack.
C1 [Irshad, Azeem; Sher, Muhammad; Rehman, Eid; Ch, Shehzad Ashraf; Ul Hassan, Mahmood; Ghani, Anwar] Int Islamic Univ, Fac Basic & Appl Sci, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
C3 International Islamic University, Pakistan
RP Irshad, A (corresponding author), Int Islamic Univ, Fac Basic & Appl Sci, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
EM irshadazeem2@gmail.com; m.sher@iiu.edu.pk; eidrehmanktk@gmail.com;
   shahzad@iiu.edu.pk; mahmood-ul-hassan@iiu.edu.pk; anwar.ghani@iiu.edu.pk
RI Chaudhry, Shehzad/Y-3430-2019; Hassan, Mahmood ul/ABF-8399-2021; Ramzan,
   Muhammad Sher/N-6832-2019; Irshad, Azeem/E-7400-2010; Ghani,
   Anwar/Q-1973-2019; Ramzan, Muhammad/ABG-2396-2020
OI Chaudhry, Shehzad/0000-0002-9321-6956; Hassan, Mahmood
   ul/0000-0002-8459-1471; Ramzan, Muhammad Sher/0000-0001-6752-0033;
   Irshad, Azeem/0000-0002-1366-2834; Ghani, Anwar/0000-0001-7474-0405;
   Rehman, Eid/0000-0002-4647-5744
CR [Anonymous], SIMPLE PASSWORD BASE
   [Anonymous], 1825 RFC
   [Anonymous], 4253 RFC
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], INT J NETW SECUR
   [Anonymous], P INC IMS IDC
   [Anonymous], SIP SECURIT IN PRESS
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   [Anonymous], CFL2001002 PRINC U D
   [Anonymous], 1998, RFC 2401
   [Anonymous], INT J COMM SYST
   [Anonymous], WEAKNESSES SIP AUTHE
   [Anonymous], INT J NETWORK SECURI
   [Anonymous], RFC3261 IETF
   [Anonymous], APPL CRYPTOGRAPHY 2
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], P JCIS 06
   [Anonymous], 3961 RFC
   [Anonymous], RFC2617 IETF
   [Anonymous], EC CRYPT VER 1 0
   Arshad R, 2013, MULTIMED TOOLS APPL, V66, P165, DOI 10.1007/s11042-011-0787-0
   Bellare M, 1807, Lecture Notes in Computer Science, P139
   Boyko Victor., 2000, Provably secure Password-Authenticated Key exchange using Diffie-Hellman
   Callegari C, 2009, INT J COMMUN SYST, V22, P1023, DOI 10.1002/dac.1018
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   He DB, 2012, SECUR COMMUN NETW, V5, P1423, DOI 10.1002/sec.506
   Hussain TH, 2014, INT J COMMUN SYST, V27, P430, DOI 10.1002/dac.2371
   Irshad A., 2008, International Journal of Advanced Science and Technology(IJAST), V1, P91
   Kilian J., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P723, DOI 10.1145/129712.129782
   Kolbitz N., 1987, MATH COMPUT, V48, P203
   Li JS, 2011, INT J COMMUN SYST, V24, P837, DOI 10.1002/dac.1191
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Rescorla Eric., 2000, SSL and TLS: Designing and Building Secure Systems
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Tang HB, 2013, MULTIMED TOOLS APPL, V65, P321, DOI 10.1007/s11042-012-1001-8
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Xie Q, 2012, INT J COMMUN SYST, V25, P47, DOI 10.1002/dac.1286
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 42
TC 53
Z9 54
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3967
EP 3984
DI 10.1007/s11042-013-1807-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800017
DA 2024-07-18
ER

PT J
AU You, SD
   Chen, WH
AF You, Shingchern D.
   Chen, Wei-Hwa
TI Comparative study of methods for reducing dimensionality of MPEG-7 audio
   signature descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-7 audio signature descriptor; Principal component analysis;
   Hadamard transform; Haar transform; CDF 9/7 wavelet
AB We study how to reduce the dimensionality of the MPEG-7 audio signature descriptors in this paper. With the aid of the dimension-reduced descriptors, the comparison time for detecting copyrighted audio can be significantly reduced. The studied methods include block average, principal component analysis (PCA), Hadamard transform, Haar transform, and CDF (Cohen-Daubechies-Feauveau) 9/7 wavelet transform. For the latter four methods, we also examine whether different partition methods would affect the accuracy. The simulation results show that different reduction methods should use different partition strategies for best accuracy. In addition, we also compare the computational complexity of these methods. The experimental results show that, except the CDF 9/7 method, the rest four methods yield comparable accuracy for undistorted and MP-3 coded audio. When also considering the computational complexity, the block average method is a better choice.
C1 [You, Shingchern D.] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Chen, Wei-Hwa] Hon Hai Precis Ind Co Ltd, New Taipei City, Taiwan.
C3 National Taipei University of Technology; Hon Hai Precision Industry
RP You, SD (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sec 3,Chung Hsiao East Rd, Taipei 106, Taiwan.
EM you@csie.ntut.edu.tw
RI You, Shingchern/AAG-6401-2020
FU National Science Council of Taiwan [NSC 94-2213-E-027-042, NSC
   101-2221-E-027-127]
FX The authors thank the National Science Council of Taiwan to provide
   grants (NSC 94-2213-E-027-042 and NSC 101-2221-E-027-127) for this
   research.
CR [Anonymous], 2003, 15938 ISOIEC
   Baluja S, 2007, INT CONF ACOUST SPEE, P213
   Bringer J, 2012, HUM-CENTRIC COMPUT I, V2, DOI 10.1186/PREACCEPT-1253053215890607
   Burges CJC, 2003, IEEE T SPEECH AUDI P, V11, P165, DOI 10.1109/TSA.2003.811538
   Crysandt H, 2003, 115 AES CONV OCT
   Doets PJO, 2006, P SOC PHOTO-OPT INS
   Dogan E, 2011, INT J INTELL SYST, V26, P952, DOI 10.1002/int.20508
   Haitsma J., 2002, P ISMIR 2002 3 INT C, P107
   Hellmuth O, 2003, 115 AES CONV OCT
   Huang Y-P, 2012, J CONVERG, V3, P1
   ISO/IEC, 2002, 159384 ISOIEC
   Lee JY, 2005, LECT NOTES COMPUT SC, V3768, P526, DOI 10.1007/11582267_46
   Lin PC, 2009, J INF SCI ENG, V25, P1221
   Nack F, 1999, IEEE MULTIMEDIA, V6, P64, DOI 10.1109/93.809235
   Nack F, 1999, IEEE MULTIMEDIA, V6, P65, DOI 10.1109/93.790612
   Satone MP, 2012, J INF PROCESS SYST, V8, P483
   Shlens J., TUTORIAL PRINCIPAL C
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Taubman D.S., 2002, JPEG 2000: Image Compression Fundamentals, Standards and Practice, DOI 10.1007/978-1-4615-0799-4
   Theodoridis S, 2003, PATTERN RECOGN, V2nd
   Wang A, 2006, COMMUN ACM, V49, P44, DOI 10.1145/1145287.1145312
   Yang HY, 2012, MULTIMED TOOLS APPL, V57, P453, DOI 10.1007/s11042-010-0644-6
   You SD, 2013, SCI WORLD J, DOI 10.1155/2013/752464
NR 23
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3579
EP 3598
DI 10.1007/s11042-013-1670-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000022
DA 2024-07-18
ER

PT J
AU Xiao, D
   Hu, SL
   Zheng, HY
AF Xiao, Di
   Hu, Shulei
   Zheng, Hongying
TI A high capacity combined reversible watermarking scheme for 2-D CAD
   engineering graphics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; 2-D CAD engineering graphics; Improved
   quantization index modulation (IQIM); Improved difference expansion
   (IDE); Embedding capacity
ID DATA-HIDING SCHEME
AB Compared with the wide research on reversible watermarking scheme for raster image, the research on its counterpart for 2-D CAD engineering graphics lags far behind. In this paper, based on improved quantization index modulation (IQIM) and improved difference expansion (IDE), a combined reversible watermarking scheme is proposed for 2-D CAD engineering graphics. The proposed scheme can solve the embedding-limitation problem existing in IQIM technique and increase the watermark embedding capacity greatly. Theoretical analysis and experimental results also show that the proposed scheme has good imperceptibility and robustness.
C1 [Xiao, Di; Hu, Shulei; Zheng, Hongying] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI zhang, jt/JVE-1333-2024
FU Natural Science Foundation Project of CQ CSTC [2011jjjq40001]
FX The work was funded by the Natural Science Foundation Project of CQ CSTC
   (Grant No. 2011jjjq40001).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Anping Zhu, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1171, DOI 10.1109/CISP.2010.5646790
   Chaumont M, 2009, P SPIE VIS COMM IM P
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Huamin Ji, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P3899, DOI 10.1109/CISP.2010.5647623
   Kwon KR, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P871, DOI 10.1109/ICME.2004.1394339
   Lee H, 2011, VISUAL COMPUT, V27, P781, DOI 10.1007/s00371-011-0586-7
   Lee SH, 2010, DIGIT SIGNAL PROCESS, V20, P1379, DOI 10.1016/j.dsp.2010.01.003
   Peng F, 2011, INT J DIGIT CRIME FO, V3, P53, DOI 10.4018/jdcf.2011010104
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Zhao H, 2011, MULTIMED TOOLS APPL, V52, P277, DOI 10.1007/s11042-009-0380-y
NR 21
TC 16
Z9 16
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2109
EP 2126
DI 10.1007/s11042-013-1744-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500019
DA 2024-07-18
ER

PT J
AU Yang, HF
   Yin, JP
AF Yang, Hengfu
   Yin, Jianping
TI A secure removable visible watermarking for BTC compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Removable visible watermark; Block truncation coding; Chaotic maps;
   Image smoothness
ID ENCRYPTION
AB A novel removable visible watermarking (RVW) algorithm by combining Block Truncation Coding (BTC) and chaotic map (RVWBCM) is presented in this paper. It embeds a visible watermark in the BTC codes of images, namely both the host image and the watermarked image are BTC compressed images. First, the original image is divided into watermarked region and non-watermarked region, and a predicted version of original image can be obtained by predicting pixel values in watermarked region. Second, adaptive embedding factors are computed according to the image features. Third, the watermark is adaptively embedded into two quantization levels of the BTC compressed image in visible manner. Meanwhile, to further prevent illegal watermark removal, original bi-level watermark is encrypted and then losslessly embedded in invisible manner by adjusting the relationship of two quantization levels. At the receiver's end, only authorized users can exactly extract original bi-level watermark according the relationship of two quantization levels of BTC codes and succeed in remove the embedded visible watermark to reconstruct the original image. The experimental results show that this scheme can achieve a good balance between perceptual transparence and the watermark strength (watermark visibility) and can resist common image processing attacks. The proposed algorithm has low complexity and simplicity of implementation due to the use of BTC. It can be applicable to copyright notification and secure access control in mobile communication.
C1 [Yang, Hengfu; Yin, Jianping] Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China.
   [Yang, Hengfu] Hunan First Normal Univ, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.
C3 National University of Defense Technology - China; Hunan First Normal
   University
RP Yang, HF (corresponding author), Hunan First Normal Univ, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.
EM hengfuyang@163.com
RI Yang, Hengfu/S-6738-2019
FU National Natural Science Foundation of China [61073191, 61170287,
   61232016]; Hunan Provincial Natural Science Foundation of China
   [10JJ6090]; Scientific Research Fund of Hunan Provincial Science and
   Technology Department of China [2011GK3140, 2010GK3049, 2011GK3139]; Key
   Program of Hunan Provincial Education Department of China [12A029];
   Research Program of Humanities and Social Sciences of Chinese Ministry
   of Education [12YJAZH065]; Science and Technology Innovative Research
   Team in Higher Educational Institutions of Hunan Province [[2010]212]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 61073191, 61170287 and 61232016,
   Hunan Provincial Natural Science Foundation of China under Grant No.
   10JJ6090, Scientific Research Fund of Hunan Provincial Science and
   Technology Department of China under Grant No. 2011GK3140, 2010GK3049
   and 2011GK3139, Key Program of Hunan Provincial Education Department of
   China under Grant no. 12A029, Research Program of Humanities and Social
   Sciences of Chinese Ministry of Education under Grant No. 12YJAZH065,
   Science and Technology Innovative Research Team in Higher Educational
   Institutions of Hunan Province under Grant No. [2010]212.
CR Chang C-C, 2010, J COMPUT, V21, P37
   Farrugia RA, 2010, IEEE MEDITERR ELECT, P212, DOI 10.1109/MELCON.2010.5476303
   FRANTI P, 1994, COMPUT J, V37, P308, DOI 10.1093/comjnl/37.4.308
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hu YJ, 2006, IEEE T CIRC SYST VID, V16, P129, DOI 10.1109/TCSVT.2005.858742
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Liu Y, 2007, MULTIMED TOOLS APPL, V34, P57, DOI 10.1007/s11042-006-0072-9
   Luo Y., 2012, T EDUTAINMENT 8, P138
   Mitchell OR, 1978, P IEEE INT C COMM TO, V1
   Mohanty SP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1029, DOI 10.1109/ICME.2000.871535
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Shie SC, 2008, IMAGING SCI J, V56, P23, DOI 10.1179/174313107X214240
   Tsai HM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2106
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   Yang Y, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2952843
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Yeh FH, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1328, DOI 10.1109/APSCC.2008.30
   Yip SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P853, DOI 10.1109/ICME.2006.262635
   Zhang XP, 2011, INTELL AUTOM SOFT CO, V17, P233, DOI 10.1080/10798587.2011.10643145
NR 23
TC 28
Z9 28
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1725
EP 1739
DI 10.1007/s11042-013-1714-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500001
DA 2024-07-18
ER

PT J
AU Chen, JY
   Zeng, HY
   Fan, N
AF Chen, Junying
   Zeng, Haoyu
   Fan, Na
TI Nonlinear distance function learning using neural network: an iterative
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metric learning; Multimodal learning; Nonlinearity; Regression models
ID REGRESSION
AB In this paper, we extend several existing methods that apply distance function learning to regression problems. We discover that these methods may be viewed as approximating a matrix consisting of desired distances among all training samples. Based on this understanding, we propose an iterative framework where outlier samples are corrected by their neighbors via asymptotically increasing the correlation coefficients between the desired distances and the distances of sample labels. Moreover, using this framework, we find that most existing methods iterate only once. As another extension, we adopt a nonlinear distance function and approximate it with neural network. For a fair comparison, we conduct an experiment on age estimation from face images as a regression problem, and the results are comparable to the state of the art.
C1 [Chen, Junying; Zeng, Haoyu] Agr Univ Hebei, Coll Sci, Baoding 071001, Hebei, Peoples R China.
   [Fan, Na] E China Normal Univ, Dept Elect Engn, Shanghai 200241, Peoples R China.
C3 Hebei Agricultural University; East China Normal University
RP Chen, JY (corresponding author), Agr Univ Hebei, Coll Sci, 289 Lingyu Temple St, Baoding 071001, Hebei, Peoples R China.
EM chenjunying@hebau.edu.cn; fanna.cn@gmail.com
RI ZENG, HAOYU/JAA-9407-2023
CR [Anonymous], 2006, TECHNICAL REPORT
   [Anonymous], 2007, P IEEE 11 INT C COMP
   Balas VE., 2007, 2006 World Automation Congress, WAC'06, P1
   Castillo E, 2006, J MACH LEARN RES, V7, P1159
   Cherkassky V, 1999, IEEE T NEURAL NETWOR, V10, P1075, DOI 10.1109/72.788648
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Davis J. V., 2007, ICML, P209
   Fan N, 2011, IEEE I CONF COMP VIS, P249, DOI 10.1109/ICCV.2011.6126249
   Geng X., 2008, Proceedings Of The 16th ACM International Conference on Multimedia, P721
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Goldberger J., 2004, P INT C NEUR INF PRO, V17, P513
   Guo GD, 2009, P CVPR, P1
   He Xiaofei., 2004, ACM MULTIMEDIA, P17
   Hillel AB, 2007, P 24 INT C MACH LEAR, P65, DOI 10.1145/1273496.1273505
   Huang Y., 2008, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Jin C, 2010, INT J COMPUT INTELL, V9, P339, DOI 10.1142/S1469026810002938
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Macskassy SA, 2003, ARTIF INTELL, V143, P51, DOI 10.1016/S0004-3702(02)00359-4
   MCCULLAGH P, 1980, J ROY STAT SOC B MET, V42, P109
   Min MartinR., 2010, INT C MACH LEARN, P791
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Pan, 2010, P EMM CVPR, P455
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Salakhutdinov R., 2007, AISTATS, V2, P412
   Shalev-Shwartz S., 2004, Proceedings of the 21st international conference on Machine learning, P743
   Shental N, 2002, LECT NOTES COMPUT SC, V2353, P776
   Smith L.I., 2002, Statistics
   Stanley KO, 2007, GENET PROGRAM EVOL M, V8, P131, DOI 10.1007/s10710-007-9028-8
   TAN X, 2006, P IEEE COMP SOC C CO, P138
   Taylor G., 2010, P NIPS
   Weinberger Kilian., 2006, NIPS, V18, P1475
   Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853
   Yan SC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P96
   Yeung DY, 2007, IEEE T NEURAL NETWOR, V18, P141, DOI 10.1109/TNN.2006.883723
NR 37
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 671
EP 688
DI 10.1007/s11042-014-1944-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400001
DA 2024-07-18
ER

PT J
AU Sperandio, RC
   Patrocínio, ZKG
   de Paula, HB
   Guimaraes, SJF
AF Sperandio, Ricardo C.
   Patrocinio, Zenilton K. G., Jr.
   de Paula, Hugo B.
   Guimaraes, Silvio J. F.
TI An efficient access method for multimodal video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video retrieval; Metric access methods; Multimodal video
   retrieval; Multimedia database
ID FEATURE INDEX STRUCTURE
AB This paper presents the Slim (2) -tree, an efficient and effective content-based video retrieval technique allowing the use of multiple modalities within a single index structure. Slim (2) -tree is capable of dealing with different distance measures for the modalities and can perform both multimodal and unimodal searches using the same tree structure. Experimental studies on a large real dataset show the video similarity search performance of the proposed technique. Additionally, we present experiments comparing our method against state-of-the-art of multimodal solutions. Comparative test results demonstrate that our technique improves the performance of video similarity queries.
C1 [Sperandio, Ricardo C.; Patrocinio, Zenilton K. G., Jr.; de Paula, Hugo B.; Guimaraes, Silvio J. F.] Pontificia Univ Catolica Minas Gerais PUC Minas, Belo Horizonte, MG, Brazil.
C3 Pontificia Universidade Catolica de Minas Gerais
RP Patrocínio, ZKG (corresponding author), Pontificia Univ Catolica Minas Gerais PUC Minas, Belo Horizonte, MG, Brazil.
EM rcarlini@gmail.com; zenilton@pucminas.br; hugo@pucminas.br;
   sjamil@pucminas.br
RI Patrocínio, Zenilton K G/E-8913-2013; GUIMARAES, Silvio/C-7881-2014
OI Patrocínio, Zenilton K G/0000-0003-0804-1790; GUIMARAES,
   Silvio/0000-0001-8522-2056; Bastos de Paula, Hugo/0000-0002-6193-3205
FU PUCMinas; CNPq; CAPES; FAPEMIG
FX The authors are grateful to PUCMinas, CNPq, CAPES and FAPEMIG for the
   financial support of this work. The authors also thank to the anonymous
   reviewers for their valuable comments and suggestions.
CR Almeida J., 2010, JIDM, V1, P375
   [Anonymous], ADV DATABASE SYSTEMS
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Bustos B, 2012, MULTIMED TOOLS APPL, V58, P467, DOI 10.1007/s11042-011-0731-3
   Chávez E, 2001, ACM COMPUT SURV, V33, P273, DOI 10.1145/502807.502808
   Ciaccia P, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P426
   Ciaccia P, 2000, 1 DELOS WORKSH ISSQD
   Döller M, 2012, LECT NOTES COMPUT SC, V7131, P323
   Douze M., 2009, Proceeding of the ACM International Conference on Image and Video Retrieval. CIVR'09, p19:1, DOI [10.1145/1646396.1646421, DOI 10.1145/1646396.1646421]
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   Ganchev T., P SPECOM, P191
   Goh ST, 2000, DATA KNOWL ENG, V33, P219, DOI 10.1016/S0169-023X(00)00002-1
   He YF, 2010, COMPUT SCI INF SYST, V7, P139, DOI 10.2298/CSIS1001139H
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shao J, 2008, PROC VLDB ENDOW, V1, P1598, DOI 10.14778/1454159.1454232
   Traina C, 2000, LECT NOTES COMPUT SC, V1777, P51
   Yan R, 2007, INFORM RETRIEVAL, V10, P445, DOI 10.1007/s10791-007-9031-y
NR 17
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1357
EP 1375
DI 10.1007/s11042-014-1917-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300011
DA 2024-07-18
ER

PT J
AU Lin, JC
   Xia, JZ
   Gao, X
   Liao, MH
   He, Y
   Gu, XF
AF Lin, Juncong
   Xia, Jiazhi
   Gao, Xing
   Liao, Minghong
   He, Ying
   Gu, Xianfeng
TI Interior structure transfer via harmonic 1-forms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Volumetric parameterization; Harmonic 1-form; Interior structure
   transfer
ID PARAMETERIZATION
AB As a natural extension of surface parameterizaiton, volumetric parameterization is becoming more and more popular and exhibiting great advantages in several applications such as medical image analysis, hexahedral meshing etc. This paper presents an efficient volume parameterization algorithm based on harmonic 1-form. Our new algorithm computes three harmonic 1-forms, which can be treated as three vector fields, such that both the divergence and circulation of them are zero. By integrating the three harmonic 1-forms over the entire volumes, we can bijectively map the volume to a cuboid domain. We demonstrate the power of the technique by introducing a new application, to transfer the interior structure during the morphing of two given shapes.
C1 [Lin, Juncong; Gao, Xing; Liao, Minghong] Xiamen Univ, Software Sch, Xiamen, Peoples R China.
   [Xia, Jiazhi] Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11790 USA.
C3 Xiamen University; Central South University; Nanyang Technological
   University; State University of New York (SUNY) System; State University
   of New York (SUNY) Stony Brook
RP Xia, JZ (corresponding author), Cent S Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
EM jclin@xmu.edu.cn; xiajiazhi@gmail.com; gaoxing@xmu.edu.cn;
   liao@xmu.edu.cn; yhe@ntu.edu.sg; gu@cs.sunysb.edu
RI He, Ying/A-3708-2011
OI He, Ying/0000-0002-6749-4485; Gu, Xianfeng David/0000-0001-8226-5851
FU Singapore NRF Interactive Digital Media RD Program
   [NRF2008IDM-IDM004-006]; National Natural Science Foundation of China
   [61202142]; China Mobile [MCM20122081]; State Key Lab of CAD&CG Zhejiang
   University [A1205]; Fundamental Research Funds for the Central
   Universities [2010121070]; Central South University [2012QNZT058];
   Ministry of Education of China [MCM20122081, 20120162120019];  [AcRF
   69/07]
FX This work was supported by AcRF 69/07, Singapore NRF Interactive Digital
   Media R&D Program under research grant NRF2008IDM-IDM004-006, the
   National Natural Science Foundation of China (No. 61202142), Joint Funds
   of the Ministry of Education of China and China Mobile(MCM20122081), the
   Open Project Program of the State Key Lab of CAD&CG Zhejiang
   University(Grant No. A1205) and the Fundamental Research Funds for the
   Central Universities(No. 2010121070). Jiazhi Xia is partially supported
   by the freedom explore Program of Central South University(NO.
   2012QNZT058) and Doctoral Fund of Ministry of Education of China(NO.
   20120162120019).
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Alliez P, 2005, ACM T GRAPHIC, V24, P617, DOI 10.1145/1073204.1073238
   [Anonymous], 2006, PROC EUROGRAPHICS S
   Chi Zhang, 2012, 2012 9th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON), P1, DOI 10.1109/SECON.2012.6275778
   Cohen-Or D, 1998, ACM T GRAPHIC, V17, P116, DOI 10.1145/274363.274366
   Dinh HQ, 2005, ACM T GRAPHIC, V24, P289, DOI 10.1145/1061347.1061353
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Gregson J, 2011, COMPUT GRAPH FORUM, V30, P1407, DOI 10.1111/j.1467-8659.2011.02015.x
   Grinspun E, 2005, ACM SIGGRAPH 05
   GU X, 2003, S GEOM PROC, P127
   Guo Yanwen, 2005, Journal of Computer Aided Design & Computer Graphics, V17, P1457
   Guo YW, 2005, COMPUT GRAPH-UK, V29, P972, DOI 10.1016/j.cag.2005.09.013
   Han SC, 2011, COMPUT AIDED DESIGN, V43, P1222, DOI 10.1016/j.cad.2011.06.023
   Han Shuchu., 2010, SPM, SPM'10, P127, DOI DOI 10.1145/1839778.1839796
   He Y, 2009, COMPUT GRAPH-UK, V33, P369, DOI 10.1016/j.cag.2009.03.024
   Jiazhi Xia, 2010, Proceedings of the Shape Modeling International (SMI 2010), P3, DOI 10.1109/SMI.2010.10
   Lai YK, 2010, IEEE T VIS COMPUT GR, V16, P95, DOI 10.1109/TVCG.2009.59
   Li X., 2007, SPM 07, P109
   Li X, 2009, IEEE T AUTOM SCI ENG, V6, P409, DOI 10.1109/TASE.2009.2014735
   Martin T, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P269
   Nieser M, 2011, COMPUT GRAPH FORUM, V30, P1397, DOI 10.1111/j.1467-8659.2011.02014.x
   Rado T., 1926, Verein, V35, P49
   Sarkar R, 2010, PROCEEDINGS OF THE 9TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P232, DOI 10.1145/1791212.1791240
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Si H., 2009, TetGen: a quality tetrahedral mesh generator and three-dimensional delaunay triangulator
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Tigges M, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P25, DOI 10.1109/CGI.1999.777896
   Turk G, 1999, COMP GRAPH, P335, DOI 10.1145/311535.311580
   Wang HY, 2008, COMPUT AIDED DESIGN, V40, P721, DOI 10.1016/j.cad.2008.01.012
   Wang Hongyu., 2007, ACM SOLID PHYS MODEL, P241
   Wang Y, 2004, P 3 INT C MACH LEARN, P26
   Xia JZ, 2010, LECT NOTES COMPUT SC, V6130, P219
   Xu DH, 2005, SOUTHEAST SYMP SYSTE, P267, DOI 10.1145/1060244.1060274
   Zeng W, 2011, COMPUT GRAPH-UK, V35, P726, DOI 10.1016/j.cag.2011.03.008
NR 35
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 139
EP 158
DI 10.1007/s11042-013-1508-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300009
DA 2024-07-18
ER

PT J
AU Caillet, M
   Roisin, C
   Carrive, J
AF Caillet, Marc
   Roisin, Cecile
   Carrive, Jean
TI Multimedia applications for playing with digitized theater performances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic annotation; Temporal segmentation; Theater performance;
   Multimedia application
ID MPEG-7; OWL
AB This article presents a multimedia production chain that specializes in semantically annotated digitized theater performances. Semantic annotations-we prefer the term descriptions-are expressed in a description language that combines object-oriented features, taxonomical inheritance and temporal aggregations. The descriptions that are produced from several types of content related to the same theater play are synchronized at several levels of granularity providing rich relationships between the narrative structure of the text of the play and the narrative structure of the digitized theater performances. Two applications for multimedia access and navigation are presented in this paper, namely Dual Players, a navigation application that allows to synchronously play acts and scenes of two recordings; and Synthesizer that produces a raw publication of a new audiovisual document on the basis of the recordings.
C1 [Caillet, Marc] Univ Grenoble Alpes, LIG INRIA INA, F-38334 Saint Ismier, France.
   [Roisin, Cecile] Univ Grenoble Alpes, LIG INRIA, INRIA Grenoble, F-38334 Saint Ismier, France.
   [Carrive, Jean] INA, F-94366 Bry Sur Marne, France.
C3 Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA);
   Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA)
RP Roisin, C (corresponding author), Univ Grenoble Alpes, LIG INRIA, INRIA Grenoble, 655 Ave Europe, F-38334 Saint Ismier, France.
EM marc-caillet@orange.fr; Cecile.Roisin@inria.fr; jcarrive@ina.fr
FU European Commission [FP-020726]
FX Part of this work has been supported by the European Commission under
   contract FP-020726, Knowledge Space of semantic inference for automatic
   annotation and retrieval of multimedia content (K-Space).
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 2006, TIME ONTOLOGY OWL
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Artale A, 1996, DATA KNOWL ENG, V20, P347, DOI 10.1016/S0169-023X(96)00013-4
   Aubert O, 2006, P WORKSH SEM WEB ANN
   AUBERT O., 2005, P 16 ACM C HYPERTEXT, P235
   Auffret G, 1999, P ACM HYP 99 DARMST
   Bailer W, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P217
   Beaudouin V., 1996, Literary & Linguistic Computing, V11, P23, DOI 10.1093/llc/11.1.23
   Bloehdorn S, 2005, LECT NOTES COMPUT SC, V3532, P592
   Caillet M, 2007, P INT WORKSH SEM AW, P31
   de Berg M., 2000, Computational Geometry, Vsecond, P212
   Garcia R, 2005, P 2 EUR WORKSH INT K
   Glass J, 2006, P INT C SPOK LANG PR
   Gravier G, 2002, P JEP 02 NANC
   Hardman L, 2008, MULTIMEDIA SYST, V14, P327, DOI 10.1007/s00530-008-0134-0
   Hauglid JO, 2008, MULTIMED TOOLS APPL, V40, P183, DOI 10.1007/s11042-008-0204-5
   Hunter J, 2001, P 1 INT SEM WEB WORK
   Jewell MO, 2005, P MULT INF RETR WORK
   Knublauch H., 2006, 9 W3C
   Koide S, 2006, LECT NOTES COMPUT SC, V4185, P263
   Liu KY, 2005, P 13 ANN ACM C MULT
   Madhwacharyula CL, 2006, ACM T MULTIM COMPUT, V2, P358, DOI 10.1145/1201730.1201736
   McGuinness D.L., 2004, W3C RECOMMENDATION, V10
   Pan F., 2005, P 18 INT FLORIDA ART, P560
   Ronfard R, 2003, P IEEE INT C MULT EX
   Troncy R, 2004, P CORIMEDIA 04 SHERB
   Troncy R, 2006, LECT NOTES COMPUT SC, V4306, P41
   Tsinaraki C, 2004, BIOMED SCI INSTRUM, V3084, P398
   Vanhaesebrouck K, 2007, IMAGE NARRATIVE
NR 30
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1777
EP 1793
DI 10.1007/s11042-013-1651-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200030
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yu, LY
   Han, Q
   Niu, XM
AF Yu, Liyang
   Han, Qi
   Niu, Xiamu
TI An improved contraction-based method for mesh skeleton extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton extraction; Geometry contraction; Centeredness; Non-closed mesh
AB Contraction-based skeleton extraction methods have the feature that during skeleton extraction process, the correspondence between skeleton and mesh regions can be obtained, which makes this class of algorithm attractive. Besides, among all mesh skeleton extraction methods, contraction-based methods possesses themerits of robustness to noise, rotation invariant and no requirement on additional boundary conditions. However, contraction-based methods still suffer some flaws such as not promising homotopy or centeredness, or not capable of processing non-closed meshes, etc. In this paper, an improved contraction-based skeleton extraction method is proposed which covers the failure of existingmethods at non-closed part of a model and increases the rationality of the centeredness correction of the skeleton: First, non-closed models are virtually closed by a preprocessing stage such that models with boundaries can be contracted in the same way as the closed ones. Second, to improve the centeredness of the skeleton, we present a simpler and more effective one-ring area sequence weighting scheme by which the displacements measuring the shift of skeleton nodes can be calculated. Experimental results show the effectiveness of our work.
C1 [Yu, Liyang; Han, Qi; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Habin, Peoples R China.
   [Yu, Liyang] Mudanjiang Normal Univ, Dept Comp Sci & Technol, Mudanjiang City, Heilongjiang Pr, Peoples R China.
C3 Harbin Institute of Technology; Mudanjiang Normal University
RP Han, Q (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Habin, Peoples R China.
EM qi.han@hit.edu.cn
FU National Natural Science Foundation of China [61100187]; Fundamental
   Research Funds for the Central Universities [HIT. NSRIF. 2010046]; China
   Postdoctoral Science Foundation [2011M500666]
FX We would like to thank all anonymous reviewers for their helpful
   comments and suggestions. This work is supported by the National Natural
   Science Foundation of China (61100187), the Fundamental Research Funds
   for the Central Universities (Grant No. HIT. NSRIF. 2010046) and the
   China Postdoctoral Science Foundation (2011M500666).
CR [Anonymous], 1997, CGAL, Computational Geometry Algorithms Library
   Arcelli C, 2011, IEEE T PATTERN ANAL, V33, P709, DOI 10.1109/TPAMI.2010.140
   Attene M, 2003, VISUAL COMPUT, V19, P127, DOI 10.1007/s00371-002-0182-y
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Cao J., 2010, SHAP MOD INT C SMI 2, P187, DOI [DOI 10.1109/SMI.2010.25, 10.1109/SMI.2010.25]
   Cornea ND, 2005, VISUAL COMPUT, V21, P945, DOI 10.1007/s00371-005-0308-0
   Cornea ND, 2007, THESIS STATE U NEW J
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Dey TK, 2006, S GEOMETRY PROCESSIN, P143
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Ma CM, 2002, IEEE T PATTERN ANAL, V24, P1594, DOI 10.1109/TPAMI.2002.1114851
   Ma WC, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P207
   Ogniewicz R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P63, DOI 10.1109/CVPR.1992.223226
   Palágyi K, 1999, GRAPH MODEL IM PROC, V61, P199, DOI 10.1006/gmip.1999.0498
   Pantuwong N, 2010, SA, DOI [10.1145/1899950.1899956, DOI 10.1145/1899950.1899956]
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Willcocks CG, 2012, VISUAL COMPUT, V28, P775, DOI 10.1007/s00371-012-0688-x
NR 19
TC 3
Z9 5
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1709
EP 1722
DI 10.1007/s11042-013-1650-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200027
DA 2024-07-18
ER

PT J
AU Zhao, J
   Cheung, SCS
AF Zhao, Jian
   Cheung, Sen-ching S.
TI Human segmentation by geometrically fusing visible-light and thermal
   imageries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor fusion; Human segmentation; Multi-camera fusion; Thermal cameras
ID REAL-TIME; VIDEO; TRACKING
AB From depth sensors to thermal cameras, the increased availability of camera sensors beyond the visible spectrum has created many exciting applications. Most of these applications require combining information from these hyperspectral cameras with a regular RGB camera. Information fusion from multiple heterogeneous cameras can be a very complex problem. They can be fused at different levels from pixel to voxel or even semantic objects, with large variations in accuracy, communication, and computation costs. In this paper, we propose a system for robust segmentation of human figures in video sequences by fusing visible-light and thermal imageries. Our system focuses on the geometric transformation between visual blobs corresponding to human figures observed at both cameras. This approach provides the most reliable fusion at the expense of high computation and communication costs. To reduce the computational complexity of the geometric fusion, an efficient calibration procedure is first applied to rectify the two camera views without the complex procedure of estimating the intrinsic parameters of the cameras. To geometrically register different blobs at the pixel level, a blob-to-blob homography in the rectified domain is then computed in real-time by estimating the disparity for each blob-pair. Precise segmentation is finally achieved using a two-tier tracking algorithm and a unified background model. Our experimental results show that our proposed system provides significant improvements over existing schemes under various conditions.
C1 [Zhao, Jian] Microsoft Corp, Windows Phone, Redmond, WA 98052 USA.
   [Cheung, Sen-ching S.] Univ Kentucky, Ctr Visualizat & Virtual Environm, Lexington, KY 40506 USA.
C3 Microsoft; University of Kentucky
RP Cheung, SCS (corresponding author), Univ Kentucky, Ctr Visualizat & Virtual Environm, 329 Rose St, Lexington, KY 40506 USA.
EM Jian.Zhao@microsoft.com; cheung@engr.uky.edu
FU National Science Foundation [1018241]; Direct For Computer & Info Scie &
   Enginr [1018241] Funding Source: National Science Foundation; Division
   of Computing and Communication Foundations [1018241] Funding Source:
   National Science Foundation
FX Part of this material is based upon work supported by the National
   Science Foundation under Grant No. 1018241. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the National
   Science Foundation.
CR [Anonymous], 1988, P 1 NAT S SENS FUS
   [Anonymous], 2006, P 2006 IEEE INT TRAN
   [Anonymous], 2002, SENSOR FUSION TIME T
   [Anonymous], 2008, LEARNING OPENCV COMP
   [Anonymous], 2004, Mathematical techniques in multisensor data fusion
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Beyan C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3602204
   BOUGUET JY, 2005, MATLAB CAMERA CALIBR
   Brown D.C., 1966, Photogramm. Eng., V32, P444
   BUNYAK F, 2007, IEEE WACV 2007 FEB, P35
   Cevher V, 2007, IEEE T MULTIMEDIA, V9, P715, DOI 10.1109/TMM.2007.893340
   Chen C, 2000, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.2000.854901
   Chen S, 2008, IEEE INT SYMP CIRC S, P1926, DOI 10.1109/ISCAS.2008.4541820
   Chen Y, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P5079, DOI 10.1109/WCICA.2008.4593753
   Conaire C. O., 2005, P INT WORKSH IM AN M
   Conaire CO, 2008, MACH VISION APPL, V19, P483, DOI 10.1007/s00138-007-0078-y
   CRAMER H, 2003, 6 INT C INF FUS, V1, P2
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Davis JamesW., 2005, CVPR 05 P 2005 IEEE, P11
   Denman S, 2010, COMPUT ELECTR ENG, V36, P643, DOI 10.1016/j.compeleceng.2008.11.011
   GOUBET E, 2006, TECHNICAL REPORT
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Jian Zhao, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1185, DOI 10.1109/ICCVW.2009.5457476
   Johnson MJ., 2008, 2008 11th International Conference on Information Fusion, P1
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kolmogorov V., 2001, TECH REP
   Kumar P, 2006, LECT NOTES COMPUT SC, V4338, P528
   Lee SK, 2009, IEEE INT CON MULTI, P1708, DOI 10.1109/ICME.2009.5202850
   Leykin A, 2010, MACH VISION APPL, V21, P587, DOI 10.1007/s00138-008-0176-5
   Llinas J., 2004, REVISITING JDL DATA
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   St Laurent L., 2007, 2007 10 INT C INF FU, P1
   St-Onge PL, 2007, LECT NOTES COMPUT SC, V4842, P1
   Steinberg A.N., 2004, NSSDF C P
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Torresan H, 2004, PROC SPIE, V5405, P506, DOI 10.1117/12.548359
   Ulusoy I, 2011, IET IMAGE PROCESS, V5, P36, DOI 10.1049/iet-ipr.2009.0374
   Venkatesh MV, 2009, IEEE INT CON MULTI, P1574, DOI 10.1109/ICME.2009.5202813
   Venkatesh MV, 2009, PATTERN RECOGN LETT, V30, P168, DOI 10.1016/j.patrec.2008.03.011
   VOLFSON L, 2006, 9 INT C INF FUS, P4
   Wolfram research I, 2010, MATH ED VERS 8 0
   WU Q, 2008, MM 08, P1025, DOI DOI 10.1145/1459359.1459562
   ZHAO J, 2011, THESIS U KENTUCKY
   Zhou HY, 2008, IEEE J-STSP, V2, P503, DOI 10.1109/JSTSP.2008.2001429
NR 45
TC 13
Z9 14
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 61
EP 89
DI 10.1007/s11042-012-1299-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700004
DA 2024-07-18
ER

PT J
AU Cunningham, S
   Grout, V
AF Cunningham, Stuart
   Grout, Vic
TI Data reduction of audio by exploiting musical repetition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio; Music; Compression; Repetition; Perceptual coding
ID FITNESS MEASURE; SIGNALS; SEARCH; COMPRESSION; EFFICIENT
AB This paper presents and evaluates a method of audio compression specifically designed to exploit the natural repetition that occurs within musical audio. Our system is entitled Audio Compression Exploiting Repetition (ACER). ACER is a perceptual technique, but one that does not consider exploiting masking, but rather attempts to apply the principles of Lempel-Ziv and run-length encoding, by substituting audio sequences for numeric or character strings. The ACER procedure applies a pseudo exhaustive search process and spectral difference grading. Since ACER exploits musical structure, the amount of data reduction achieved varies from piece-to-piece. The system is described before results on a corpus of material are presented. The analysis shows moderate amounts of data reduction take place whilst the system is operating within parameters designed to maintain high-levels of perceptual audio quality, whilst lower rates of perceptual quality yield greater data reduction. Objective quality evaluations are conducted that reveal degradation in fidelity that is relative to the compression parameters.
C1 [Cunningham, Stuart; Grout, Vic] Glyndwr Univ, Creat & Appl Res Informat Soc CARDS, Wrexham, Wales.
C3 Glyndwr University
RP Cunningham, S (corresponding author), Glyndwr Univ, Creat & Appl Res Informat Soc CARDS, Wrexham, Wales.
EM s.cunningham@glyndwr.ac.uk; v.grout@glyndwr.ac.uk
RI Cunningham, Stuart/HSH-5303-2023
OI Cunningham, Stuart/0000-0002-5348-7700; Grout, Vic/0000-0003-4330-0137
CR Artists Various, 2011, DROP, V80
   Aucouturier JJ, 2005, IEEE T MULTIMEDIA, V7, P1028, DOI 10.1109/TMM.2005.858380
   Bello JP, 2011, IEEE T AUDIO SPEECH, V19, P2013, DOI 10.1109/TASL.2011.2108287
   Bogdanov D, 2011, IEEE T MULTIMEDIA, V13, P687, DOI 10.1109/TMM.2011.2125784
   Brandenburg K, 1999, AUDIO ENG SOC C 17 I
   Cai R, 2008, IEEE T MULTIMEDIA, V10, P596, DOI 10.1109/TMM.2008.921739
   Cheng K, BEAT THIS BEAT DETEC
   Cunningham S, 2005, P IADIS INT C WWW IN
   Cunningham S, 2007, P 3 COLL RES S SEC E
   Cunningham S, 2005, P ISCA 20 INT C COMP
   Cunningham S, 2009, P 3 INT C INT TECHN
   Dubnov S, 2008, IEEE T AUDIO SPEECH, V16, P327, DOI 10.1109/TASL.2007.912378
   Foote J, P 7 ACM INT C MULT 1, P77
   Foster P, 2012, EUR SIGNAL PR CONF, P1299
   Jensen K, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/73205
   Kabal P, 2004, TSP LAB SOFTWARE
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   Kirovski D, 2005, IEEE DATA COMPR CONF, P465
   Kirovski D, 2009, U.S. Patent, Patent No. 7505897
   Kirovski D, 2007, IEEE T AUDIO SPEECH, V15, P509, DOI 10.1109/TASL.2006.881687
   Kurth F, 2008, IEEE T AUDIO SPEECH, V16, P382, DOI 10.1109/TASL.2007.911552
   Lagrange M, 2010, MULTIMED TOOLS APPL, V48, P185, DOI 10.1007/s11042-009-0382-9
   Lyons Richard, 1999, UNDERSTANDING DIGITA
   Marolt M, 2006, P 7 INT SOC MUS INF
   Moffitt J., 2001, LINUX J, V2001, P9
   Müller M, 2013, IEEE T AUDIO SPEECH, V21, P531, DOI 10.1109/TASL.2012.2227732
   Novello A, 2006, P 7 INT SOC MUS INF
   Paulus J, 2009, IEEE T AUDIO SPEECH, V17, P1159, DOI 10.1109/TASL.2009.2020533
   Pohle T, 2006, P 7 INT SOC MUS INF
   Rafailidis D, 2011, MULTIMED TOOLS APPL, V51, P881, DOI 10.1007/s11042-009-0420-7
   Rao VM, 2006, U.S. Patent, Patent No. 20060173692
   Schnitzer D, 2012, MULTIMED TOOLS APPL, V58, P23, DOI 10.1007/s11042-010-0679-8
   Sturm BL, 2011, LECT NOTES COMPUT SC, V6535, P59, DOI 10.1007/978-3-642-18449-9_6
   Tabus I., 2012, P 5 INT S COMM CONTR, P1, DOI DOI 10.1109/ISCCSP.2012.6217876
   Terrell MJ, 2012, P 13 INT SOC MUS INF
   Zapata G, 2012, P 125 AES CONV SAN F
NR 36
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2299
EP 2320
DI 10.1007/s11042-013-1504-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300012
DA 2024-07-18
ER

PT J
AU Weng, SW
   Pan, JS
AF Weng, Shaowei
   Pan, Jeng-Shyang
TI Reversible watermarking based on multiple prediction modes and adaptive
   watermark embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Multiple prediction modes; Adaptive watermark
   embedding
ID IMAGE WATERMARKING; DIFFERENCE; EXPANSION
AB A new reversible watermark scheme based on multiple prediction modes and adaptive watermark embedding is presented. Six prediction modes fully exploiting strong correlation between any pixel and its surrounding pixels, are designed in this paper. Under any prediction mode, each to-be-predicted pixel must be surrounded by several pixels (they constitute a local neighborhood, and any modification to this neighborhood is not allowed in the embedding process). This neighborhood has three main applications. The first one is that when it is exploited to interpolate some to-be-predicted pixel, the noticeable improvement in prediction accuracy is obtained. The second one is that its variance is employed to determine which classification (i.e., smooth or complex set) its surrounded pixel belongs to. For any to-be-predicted pixel, the number of embedded bits is adaptively determined according to this pixel's belonging. The last one is that we can accurately evaluate the classification of watermarked pixels by analyzing the local complexity of their corresponding neighborhoods on the decoding side. Therefore, the payload can be largely increased as each to-be-predicted pixel in the smooth set can possibly carry more than 1 bit. Meanwhile, the embedding distortion is greatly controlled by embedding more bits into pixels belonging to smooth set and fewer bits into the others in complex set. Experimental results reveal the proposed method is effective.
C1 [Weng, Shaowei] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen, Peoples R China.
C3 Guangdong University of Technology; Harbin Institute of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61272498, 61001179]
FX This work was supported in part by National NSF of China (No. 61201393,
   No. 61272498, No. 61001179).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2010, P ICIP
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
NR 22
TC 16
Z9 16
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3063
EP 3083
DI 10.1007/s11042-013-1585-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300042
DA 2024-07-18
ER

PT J
AU Irtaza, A
   Jaffar, MA
   Aleisa, E
   Choi, TS
AF Irtaza, Aun
   Jaffar, M. Arfan
   Aleisa, Eisa
   Choi, Tae-Sun
TI Embedding neural networks for semantic association in content based
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Partial supervised learning; Neural network based semantic
   association
ID RELEVANCE FEEDBACK; GENETIC ALGORITHM
AB Content based image retrieval (CBIR) systems provide potential solution of retrieving semantically similar images from large image repositories against any query image. The research community are competing for more effective ways of content based image retrieval, so they can be used in serving time critical applications in scientific and industrial domains. In this paper a Neural Network based architecture for content based image retrieval is presented. To enhance the capabilities of proposed work, an efficient feature extraction method is presented which is based on the concept of in-depth texture analysis. For this wavelet packets and Eigen values of Gabor filters are used for image representation purposes. To ensure semantically correct image retrieval, a partial supervised learning scheme is introduced which is based on K-nearest neighbors of a query image, and ensures the retrieval of images in a robust way. To elaborate the effectiveness of the presented work, the proposed method is compared with several existing CBIR systems, and it is proved that the proposed method has performed better then all of the comparative systems.
C1 [Irtaza, Aun] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
   [Jaffar, M. Arfan] Al Imam Muhammad Ibn Saud Islamic Univ, Riyadh, Saudi Arabia.
   [Aleisa, Eisa] Imam Muhammad Ibne Saud Univ, Riyadh, Saudi Arabia.
   [Choi, Tae-Sun] Gwangju Inst Sci & Technol, Kwangju, South Korea.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); Imam Mohammad Ibn
   Saud Islamic University (IMSIU); Gwangju Institute of Science &
   Technology (GIST)
RP Jaffar, MA (corresponding author), Al Imam Muhammad Ibn Saud Islamic Univ, Riyadh, Saudi Arabia.
EM aun.irtaza@gmail.com; arfan.jaffar@ccis.imamu.edu.sa;
   aleisa@ccis.imamu.edu.sa; tschoi@gist.ac.kr
RI Irtaza, Aun/HTP-2773-2023; Jaffar, Arfan/GQB-2768-2022
OI Irtaza, Aun/0000-0001-7757-5839; Choi, Tae-Sun/0000-0001-7496-2438
CR Andrysiak T, 2005, INT J AP MAT COM-POL, V15, P471
   Babu Rao M, 2011, INT J ENG SCI TECHNO, V4, P2887
   Babu Rao M, 2011, INT J COMPUTER APPL, V18
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   da Silva AT, 2011, PATTERN RECOGN, V44, P2971, DOI 10.1016/j.patcog.2011.04.026
   Dengsheng Zhang, 2004, Proceedings. Third International Conference on Image and Graphics, P172
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Kijsipongse E, 2011, 8 INT JOINT C COMP S
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lama M., 2007, SPIE MED IM C SAN DI
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Rao NG, 2009, INT J COMPUT SCI NET, V9, P206
   Seo KK, 2007, LECT NOTES COMPUT SC, V4669, P537
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Stejic Z, 2003, INFORM PROCESS MANAG, V39, P1, DOI 10.1016/S0306-4573(02)00024-9
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WEBER M, 1991, IEEE T INSTRUM MEAS, V40, P820, DOI 10.1109/19.106304
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Ze Wang J., 1997, International Journal on Digital Libraries, V1, P311, DOI 10.1007/s007990050026
   Zhang J, 2011, THESIS U WOLLONGONG
   Zhang L, 2002, P IEEE REG 10 C TENC
   Zhou XS, 2001, PATTERN RECOGN LETT, V22, P457, DOI 10.1016/S0167-8655(00)00124-0
NR 32
TC 44
Z9 45
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1911
EP 1931
DI 10.1007/s11042-013-1489-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300039
DA 2024-07-18
ER

PT J
AU Trocan, M
   Tramel, EW
   Fowler, JE
   Pesquet, B
AF Trocan, Maria
   Tramel, Eric W.
   Fowler, James E.
   Pesquet, Beatrice
TI Compressed-sensing recovery of multiview image and video sequences using
   signal prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; Multiviews; Signal prediction
ID JOINT RECONSTRUCTION
AB In the compressed sensing of multiview images and video sequences, signal prediction is incorporated into the reconstruction process in order to exploit the high degree of interview and temporal correlation common to multiview scenarios. Instead of recovering each individual frame independently, neighboring frames in both the view and temporal directions are used to calculate a prediction of a target frame, and the difference is used to drive a residual-based compressed-sensing reconstruction. The proposed approach demonstrates a significant gain in reconstruction quality relative to the straightforward compressed-sensing recovery of each frame independently of the others in the multiview set, as well as a significant performance advantage as compared to a pair of benchmark multiple-frame compressed-sensing reconstructions.
C1 [Trocan, Maria] Inst Super Elect Paris, F-75006 Paris, France.
   [Tramel, Eric W.; Fowler, James E.] Mississippi State Univ, Geosyst Res Inst, Mississippi State, MS 39762 USA.
   [Pesquet, Beatrice] Telecom ParisTech, F-75634 Paris 13, France.
C3 Mississippi State University; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris
RP Trocan, M (corresponding author), Inst Super Elect Paris, 28 Rue Notre Dame Champs, F-75006 Paris, France.
EM maria.trocan@isep.fr; ewt16@msstate.edu; fowler@ece.msstate.edu;
   beatrice.pesquet@telecom-paristech.fr
OI Tramel, Eric/0000-0003-4346-0042
CR Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan TF, 2006, HDB MATH MODELS COMP
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chen X, 2009, INT CONF ACOUST SPEE, P1005, DOI 10.1109/ICASSP.2009.4959756
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gamper U, 2008, MAGN RESON MED, V59, P365, DOI 10.1002/mrm.21477
   Gan L., 2008, P EUR SIGN PROC C LA
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Jung H, 2010, INT J IMAG SYST TECH, V20, P81, DOI 10.1002/ima.20231
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Li C., 2010, An efficient algorithm for total variation regularization with applications to the single pixel camera and compressive sensing
   Li X, 2010, ELECTRON LETT, V46, P1548, DOI 10.1049/el.2010.2325
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Lu W, 2009, IEEE IMAGE PROC, P3045, DOI 10.1109/ICIP.2009.5414208
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Park JY, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-37
   Puri R, 2006, IEEE SIGNAL PROC MAG, V23, P94, DOI 10.1109/MSP.2006.1657820
   Qiu CL, 2009, INT CONF ACOUST SPEE, P393, DOI 10.1109/ICASSP.2009.4959603
   Rauhut H., 2010, THEORETICAL FDN NUME
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Trocan M., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P111, DOI 10.1109/MMSP.2010.5662003
   Trocan M, 2010, IEEE IMAGE PROC, P3345, DOI 10.1109/ICIP.2010.5652767
   Trocan M, 2010, IEEE INT CON MULTI, P1225, DOI 10.1109/ICME.2010.5583411
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4108, DOI 10.1109/TSP.2010.2048105
   Vaswani N, 2008, IEEE IMAGE PROC, P893, DOI 10.1109/ICIP.2008.4711899
   Wakin M.B., 2009, P PICT COD S CHIC IL
   Wakin M. B., 2006, P PICT COD S
   Wakin MB, 2006, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2006.312577
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
NR 41
TC 23
Z9 23
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 95
EP 121
DI 10.1007/s11042-012-1330-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800006
DA 2024-07-18
ER

PT J
AU Gao, GY
   Ma, HD
AF Gao, Guangyu
   Ma, Huadong
TI To accelerate shot boundary detection by reducing detection region and
   scope
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Skipping interval; Mutual information; Camera
   motion; Corner distribution
ID SCENE-CHANGE DETECTION; VIDEO
AB Video Shot Boundary Detection (SBD) is the fundamental process towards video summarization and retrieval. A fast and efficient SBD algorithm is necessary for real-time video processing applications. Extensive work has focused on accurate shot boundary detection at the expense of demanding computational costs. In this paper, we propose a fast SBD approach that reduces the computation pixel-wise and frame-wise while still giving satisfactory accuracy. The proposed approach substantially speeds up the computation through reducing both detection region and scope. Color histogram and mutual information are used together to measure the difference between frames. Corner distribution of frames is utilized to exclude most of false boundaries. We conduct extensive experiments to evaluate the proposed approach, and the results show that our approach can not only speed up SBD, but also detect shot boundaries with high accuracy in both Cut (CUT) and Gradual Transition (GT) boundaries.
C1 [Gao, Guangyu; Ma, Huadong] Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ma, HD (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM mhd@bupt.edu.cn
FU National Science Foundation for Distinguished Young Scholars of China
   [60925010]; Foundation for Innovative Research Groups of the National
   Natural Science Foundation of China [61121001]; Program for Changjiang
   Scholars and Innovative Research Team in University [IRT1049]; Beijing
   Committee of Education
FX The work reported in this paper is supported by the National Science
   Foundation for Distinguished Young Scholars of China under Grant No.
   60925010, the Foundation for Innovative Research Groups of the National
   Natural Science Foundation of China under Grant No. 61121001, the
   Program for Changjiang Scholars and Innovative Research Team in
   University under Grant No. IRT1049, the Co-sponsored Project of Beijing
   Committee of Education.
CR Adjeroh D, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/859371
   CABEDO XU, 1998, P NONL MOD BAS IM AN, P121
   COTSACES C, 2005, P 2005 WORKSH AUD VI
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Danisman T., 2006, P TREC VID RETR EV T
   Danisman T, 2007, P 2007 TREC VID RETR
   Derpanis K.G., 2004, HARRIS CORNER DETECT
   Han Seung Hoon, 2000, 12 WORKSH IM P IM UN
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Heng WJ, 2001, J VIS COMMUN IMAGE R, V12, P217, DOI 10.1006/jvci.2001.0457
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang CR, 2008, IEEE T MULTIMEDIA, V10, P1097, DOI 10.1109/TMM.2008.2001374
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   Huang XD, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P276, DOI 10.1109/CISP.2008.425
   Jinhui Yuan, 2005, 13th Annual ACM International Conference on Multimedia, P539, DOI 10.1145/1101149.1101271
   Lefèvre S, 2003, REAL-TIME IMAGING, V9, P73, DOI 10.1016/S1077-2014(02)00115-8
   Li YN, 2009, IET IMAGE PROCESS, V3, P121, DOI 10.1049/iet-ipr.2007.0193
   Lienhart R, 2001, PROC SPIE, V4315, P219, DOI 10.1117/12.410931
   Ling X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P445, DOI 10.1109/CISP.2008.605
   Mas Jordi, 2003, P TREC VID RETR EV C
   Pei SC, 2002, IEEE T MULTIMEDIA, V4, P309, DOI 10.1109/TMM.2002.802841
   Pei SC, 1999, IEEE T MULTIMEDIA, V1, P321, DOI 10.1109/6046.807952
   Ren Wei, 2001, INT C INF COMM SIGN
   Shien-Tang Chiu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.135
   Su CW, 2005, IEEE T MULTIMEDIA, V7, P1106, DOI 10.1109/TMM.2005.858394
   Tapu R., 2011, Proceedings of the 1st IEEE First International Conference on Consumer Electronics - Berlin (IEEE ICCE-Berlin 2011), P156, DOI 10.1109/ICCE-Berlin.2011.6031875
   Tuanfa Qin, 2010, 2010 2nd IEEE International Conference on Network Infrastructure and Digital Content (IC-NIDC 2010), P190, DOI 10.1109/ICNIDC.2010.5657841
   Wu M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P893, DOI 10.1109/ICIP.1998.723664
   Xia DY, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P389, DOI 10.1109/ICIG.2007.11
   Xiong W, 1998, COMPUT VIS IMAGE UND, V71, P166, DOI 10.1006/cviu.1998.0711
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Zhu SH, 2009, EXPERT SYST APPL, V36, P5976, DOI 10.1016/j.eswa.2008.07.009
   Zuzana C, 2006, IEEE T CIRCUITS SYST, V16, P82
NR 33
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1749
EP 1770
DI 10.1007/s11042-012-1301-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000035
DA 2024-07-18
ER

PT J
AU Rubio, G
   Navarro, E
   Montero, F
AF Rubio, Gonzalo
   Navarro, Elena
   Montero, Francisco
TI APADYT: a multimedia application for SEN learners
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia learning activities; Edutainment; Special Educational Needs;
   Computer Assisted Learning; User-centered design techniques; User
   experience assessment and evaluation
ID REMEDIAL INSTRUCTION; COMPUTER; TECHNOLOGY; USERS; TOOL
AB Information technologies have been increasingly used in education in recent years, mainly due to their possibilities of improving the classroom experience, especially those related to multimedia facilities. The new technologies are especially useful for the Special Educational Needs (SEN) group. In this paper we introduce APADYT Professional (Aplicacin Psicopedaggica para Apoyo en Diagnstico Y Tratamiento-Psychopedagogical APplicAtion for supporting Diagnosis & Education), an application developed in collaboration with SEN teachers, children with SEN and parents. This multimedia application supports SEN treatment and it exploits multi-touch interfaces to offer SEN learners multimedia learning activities. The main advantage of APADYT Professional is that it helps teachers' work by providing them with a single application that supports multiple tasks. In this way APADYT fills the gap in the existing applications, by supporting pupil management, computer-assisted learning process, report generation, planning, communication between parents and specialists, authoring tools and others interesting facilities in an integrated way. User-centered techniques have been successfully used for the development of APADYT, as the results of the User eXperience (UX) assessment reported in this paper shows, These results also shows that the approach followed to design this multimedia application is extremely appreciated by SEN teachers and specialists.
C1 [Rubio, Gonzalo] Wolters Kluwer Espana, Support Tools Div, Las Rozas 28230, Madrid, Spain.
   [Navarro, Elena; Montero, Francisco] Univ Castilla La Mancha, Comp Syst Dept, Albacete, Spain.
C3 Universidad de Castilla-La Mancha
RP Navarro, E (corresponding author), Univ Castilla La Mancha, Comp Syst Dept, Avda Espana S-N,Campus Univ, Albacete, Spain.
EM gonzalorubio1@gmail.com; elena.navarro@uclm.es; fmontero@dsi.uclm.es
RI Navarro, Elena/I-7452-2013; montero, francisco/U-4830-2019
OI Navarro, Elena/0000-0001-9496-6890; montero,
   francisco/0000-0002-0902-9681
FU Junta de Comunidades de Castilla-La Mancha [PEII09-0054-9581]; Spanish
   Government [TIN2008-06596-C02-01]
FX We would like to thank Alicia Andres Jimenez and Julia Lara Calero of
   the Marta Valcarcel Educational Psychology Center for their contribution
   to our background knowledge of this problem. We would like also to thank
   our colleagues Juan I. Del Castillo, Luis Canamares and Arturo
   Rodriguez, who helped to make APADYT a reality and the Department of the
   Psychology of the University of Castilla-La Mancha. We are grateful to
   Microsoft Iberica for the technical support provided during the
   development of APADYT. This work has been partially supported by a grant
   (PEII09-0054-9581) from the Junta de Comunidades de Castilla-La Mancha
   and also by a grant (TIN2008-06596-C02-01) from the Spanish Government.
CR [Anonymous], JUMPSTART WORLD LEAR
   [Anonymous], 2009, ERG HUM SYST INT 210
   [Anonymous], 2011, ISO 13314
   [Anonymous], 2010, SPEC NEEDS ED COUNTR
   [Anonymous], 2008, Measuring the User Experience Collecting, Analyzing, and Presenting Usability Metrics
   [Anonymous], MAK CHANG
   [Anonymous], LEARNING DISABILITIE
   [Anonymous], DYSL INF PAG
   [Anonymous], 2009, P SIGCHI C HUMAN FAC
   [Anonymous], 2006, HUMAN TECHNOLOGY, DOI DOI 10.17011/HT/URN.20
   [Anonymous], STAND PRIV IND ID HL
   [Anonymous], QUICK HEURISTICS USE
   [Anonymous], 2000, DIAGN STAT MAN MENT, DOI DOI 10.1176/APPI.BOOKS.9780890425787
   [Anonymous], 1998, ISO 9241-11
   [Anonymous], LEARN POOYOOS
   [Anonymous], MATH COMP
   [Anonymous], LANG LEARN TECHNOL
   Asteriadis S, 2009, MULTIMED TOOLS APPL, V41, P469, DOI 10.1007/s11042-008-0240-1
   Athanaselis T, 2014, MULTIMED TOOLS APPL, V68, P681, DOI 10.1007/s11042-012-1073-5
   Bacigalupo D. A., 2010, 2010 IEEE 10th International Conference on Advanced Learning Technologies (ICALT 2010), P35, DOI 10.1109/ICALT.2010.17
   Beacham NA, 2006, COMPUT EDUC, V47, P74, DOI 10.1016/j.compedu.2004.10.006
   Beale I. L., 2005, Australasian Journal of Educational Technology, V21, P173
   Bertini M, 2013, MULTIMED TOOLS APPL, V62, P111, DOI 10.1007/s11042-011-0888-9
   BRAHAN JW, 1984, COMPUT EDUC, V8, P323, DOI 10.1016/0360-1315(84)90002-2
   Cooper A., 2007, FACE 3 ESSENTIALS IN
   Dow S., 2005, Proc. of CHI, P1339
   Durkin K, 2010, COMPUT HUM BEHAV, V26, P176, DOI 10.1016/j.chb.2009.10.007
   Ecalle J, 2009, COMPUT EDUC, V52, P554, DOI 10.1016/j.compedu.2008.10.010
   Faux F., 2005, Education, Communication Information, V5, P167, DOI 10.1080/14636310500185943
   Gilmor T., 1999, International Journal of Listening, V13, P12, DOI DOI 10.1080/10904018.1999.10499024
   Grynszpan O, 2008, INT J HUM-COMPUT ST, V66, P628, DOI 10.1016/j.ijhcs.2008.04.001
   Haenselmann T, 2012, MULTIMED TOOLS APPL, V60, P589, DOI 10.1007/s11042-011-0832-z
   Haesen M, 2013, MULTIMED TOOLS APPL, V63, P331, DOI 10.1007/s11042-011-0809-y
   Hamam A, 2013, MULTIMED TOOLS APPL, V67, P455, DOI 10.1007/s11042-012-0990-7
   Handley Z, 2005, LANG LEARN TECHNOL, V9, P99
   Hornbæk K, 2006, INT J HUM-COMPUT ST, V64, P79, DOI 10.1016/j.ijhcs.2005.06.002
   Huang C, 2005, COMPUT MED IMAG GRAP, V29, P223, DOI 10.1016/j.compmedimag.2004.09.017
   Judge S., 2009, Teacher Education and Special Education, V32, P33, DOI [10.1177/0888406408330868, DOI 10.1177/0888406408330868, 10.1177/088840640833086]
   Karime A, 2012, MULTIMED TOOLS APPL, V59, P749, DOI 10.1007/s11042-011-0768-3
   Lahm EA, 2003, REM SPEC EDUC, V24, P141, DOI 10.1177/07419325030240030301
   Lee JH, 2014, MULTIMED TOOLS APPL, V68, P305, DOI 10.1007/s11042-012-1089-x
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lo JJ, 2004, COMPUT EDUC, V42, P45, DOI 10.1016/S0360-1315(03)00064-2
   Maccini P, 2002, EXCEPT CHILDREN, V68, P325, DOI 10.1177/001440290206800303
   Magnan A, 2006, COMPUT EDUC, V46, P407, DOI 10.1016/j.compedu.2004.08.008
   Maguire M, 2001, INT J HUM-COMPUT ST, V55, P587, DOI 10.1006/ijhc.2001.0503
   Margetis G, 2013, MULTIMED TOOLS APPL, V67, P473, DOI 10.1007/s11042-011-0976-x
   Mazza R, 2007, INT J HUM-COMPUT ST, V65, P125, DOI 10.1016/j.ijhcs.2006.08.008
   MCDERMOTT PA, 1983, J SPEC EDUC, V17, P81, DOI 10.1177/002246698301700110
   Mioduser D, 2000, J COMPUT ASSIST LEAR, V16, P54, DOI 10.1046/j.1365-2729.2000.00115.x
   Mulder S., 2007, USER IS ALWAYS RIGHT
   Mustaquim MM, 2013, MULTIMED TOOLS APPL, V66, P131, DOI 10.1007/s11042-011-0918-7
   Norman D.A., 1998, PSYCHOL EVERYDAY THI
   Oh JM, 2013, MULTIMED TOOLS APPL, V63, P195, DOI 10.1007/s11042-012-1017-0
   OLSON RK, 1992, READ WRIT, V4, P107, DOI 10.1007/BF01027488
   PEARCE RAH, 1953, ARCH DIS CHILD, V28, P247, DOI 10.1136/adc.28.140.247
   Pi-Hua T., 2006, Australasian Journal of Educational Technology, V22, P375
   Pruitt J., 2006, The Persona Lifecycle, DOI [DOI 10.1016/B9780125662512/500034, 10.1016/b978-012566251-2/50003-4, DOI 10.1016/B978-012566251-2/50003-4]
   Rey-López M, 2008, MULTIMED TOOLS APPL, V40, P409, DOI 10.1007/s11042-008-0213-4
   Richards R.G., 1998, The writing dilemma: Understanding dysgraphia
   Ricketts J, 2009, Q J EXP PSYCHOL, V62, P1948, DOI 10.1080/17470210802696104
   Robins B, 2010, INT J HUM-COMPUT ST, V68, P873, DOI 10.1016/j.ijhcs.2010.08.001
   Roibas AC, 2008, SOC SCI COMPUT REV, V26, P103, DOI 10.1177/0894439307307699
   Schöning J, 2009, LECT NOTES COMPUT SC, V5727, P40, DOI 10.1007/978-3-642-03658-3_8
   Tan TS, 2008, COMPUT EDUC, V50, P725, DOI 10.1016/j.compedu.2006.08.005
   United Nations Educational Scientific and Cultural Organization (UNESCO), 2018, INT TECHN GUID SEX E
   Watson T, 2008, AUSTRALAS J EDUC TEC, V24, P258
   Xu J, 2010, COMPUT ASSIST LANG L, V23, P111, DOI 10.1080/09588221003666206
   Yang YF, 2009, COMPUT EDUC, V53, P799, DOI 10.1016/j.compedu.2009.04.016
NR 69
TC 10
Z9 12
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1771
EP 1802
DI 10.1007/s11042-012-1304-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000036
DA 2024-07-18
ER

PT J
AU Sampaio, P
   Mendonça, R
   Carreira, S
AF Sampaio, Paulo
   Mendonca, Roberto
   Carreira, Silvia
TI Learning chemistry with VirtualLabs@Uma: a customizable 3D platform for
   new experimental protocols
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual environments; Virtual laboratory; Java 3D; Moodle; XML;
   VirtualLabs@UMa
AB In general, students of laboratory courses such as chemistry or biology are not able to replicate at home an experiment of a previously studied class since they lack infrastructure and material. With the possibility of providing multimedia and virtual reality environments on the Web, different applications and virtual laboratories have been proposed. However, most of the existing tools are not flexible enough or are domain-oriented, not supporting the addition of new tailor-made experiments when needed. This paper introduces a new platform for providing a customizable Virtual Laboratory, VirtualLabs@UMa. This application was proposed at University of Madeira in order to provide students with a flexible 3D virtual laboratory and teachers with a platform that can be customized to new experimental protocols. Therefore, chemistry teachers are able to create their own experimental protocols and propose them to their students. Moreover, students can be followed accordingly having their learning needs and difficulties fulfilled. VirtualLabs@UMa is a solution for motivating students and proposing an added value for complementing laboratory courses.
C1 [Sampaio, Paulo] Salvador Univ UNIFACS, Comp & Syst Res Ctr NUPERC, Salvador, BA, Brazil.
   [Mendonca, Roberto; Carreira, Silvia] Univ Madeira UMa, Funchal, Madeira, Portugal.
C3 Universidade Salvador (UNIFACS); Universidade da Madeira
RP Sampaio, P (corresponding author), Salvador Univ UNIFACS, Comp & Syst Res Ctr NUPERC, Salvador, BA, Brazil.
EM pnms.funchal@gmail.com; robertofpmendonca@gmail.com;
   silvia_carreira@hotmail.com
CR [Anonymous], CONC EXP DES
   [Anonymous], 2010, Eclipse
   [Anonymous], 2010, BioInteractive Virtual Labs
   Autodesk, 2010, AUT 3DS MAX PROD NOV
   Banerjee K, 2010, P 6 PAN COMM FOR OP
   Bredemeyer D., 2004, CUTTER CONSORTIUM EN, V7
   Domingues L, 2010, EDUC CHEM ENG, V5, pE22, DOI 10.1016/j.ece.2010.02.001
   Fowler M, 2003, CATALOG PATTERNS ENT
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Google Code, 2010, O3D WEBGL IMPL O3D
   GuangChun L, 2003, ACM SIGSOFT SOFTWARE
   Malan R, 2009, FUNCTIONAL REQUIREME
   Mendonca RFP, 2010, THESIS U MADEIRA
   Morales-Chaparro R, 2008, MVC WEB DESIGN PATTE
   Morse SF, 2004, J COMPUT SCI COLL, V20
   Mozilla, 2010, WEB DEV EV
   Net Pedagogy Portal, 2006, EV INT PED
   O'Keeffe J., 2012, Definition of Experimental Protocol
   Oberg R, 2010, TP505 RAT SOFTW
   Paolini P, 1999, INT WORKSH WORLD WID
   Pirelli, 2010, PIR INT AW
   Rodello IA, 2002, WIE 2002 8 WORKSH IN, V1
   Sauter P, 2005, MODEL VIEW CONTROLLE
   van Someren M.W., 1994, THINK ALOUD METHOD
   virtualLaboratory.net,inc, 2009, VIRT LAB SOCR STIM
   W3C, 2010, EXT MARK LANG XML
   Web3D, 2010, X3D DEV
   Web3D Consortium, 1995, VIRT REAL MOD LANG S
   Woodfield BF, 2006, VIRTUAL CHEMLAB ORGA
   Yaron D, 2010, SCIENCE, V328, P584, DOI 10.1126/science.1182435
NR 30
TC 4
Z9 4
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1129
EP 1155
DI 10.1007/s11042-012-1260-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000008
DA 2024-07-18
ER

PT J
AU Li, B
   Lin, G
   Chen, Q
   Wang, HY
AF Li, Bo
   Lin, Ge
   Chen, Qiang
   Wang, Hongyi
TI Image denoising with patch estimation and low patch-rank regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Patch estimation; Low patch-rank; Proximal splitting method
AB In this paper, we propose an image denoising algorithm for one special class of images which have periodical textures and contaminated by poisson noise using patch estimation and low patch-rank regularization. In order to form the data fidelity term, we take the patch-based poisson likelihood, which will effectively remove the 'blurring' effect. For the sparse prior, we use the low patch-rank as the regularization, avoiding the choosing of dictionary. Putting together the data fidelity and the prior terms, the denoising problem is formulated as the minimization of a maximum likehood objective functional involving three terms: the data fidelity term; a sparsity prior term, in the form of the low patch-rank regularization ;and a non-negativity constraint (as Poisson data are positive by definition). Experimental results show that the new method performs well for this special class of images which have periodical texture, and even for images with not strictly periodical textures.
C1 [Li, Bo] Nanchang Hangkong Univ, Coll Math & Informat Sci, Nanchang 330063, Peoples R China.
   [Lin, Ge] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Chen, Qiang] Guangdong Univ Educ, Guangzhou, Guangdong, Peoples R China.
   [Wang, Hongyi] Nanchang Hangkong Univ, Coll Math & Informat Sci, Nanchang 330063, Peoples R China.
C3 Nanchang Hangkong University; Sun Yat Sen University; Nanchang Hangkong
   University
RP Lin, G (corresponding author), Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, State Prov Joint Lab Digital Home Interact Applic, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM bolimath@gmail.com; 2005.ge.lin@gmail.com; Cq_c@gdei.edu.cn
RI chen, qiang/HGU-5418-2022
FU National natural science foundation of China [61262050, 61232011];
   NSFC-Guangdong Joint Fund [U1201252, U1135003]; Foundation of Jiangxi
   Educational Committee [GJJ12441]; Natural Science Foundation of Jiangxi
   [20122BAB211003]
FX This paper is supported by the National natural science foundation of
   China (No. 61262050,61232011), NSFC-Guangdong Joint Fund (No. U1201252,
   U1135003), Foundation of Jiangxi Educational Committee (No. GJJ12441),
   Natural Science Foundation of Jiangxi (20122BAB211003).
CR [Anonymous], LOW PATCH RANK INTER
   [Anonymous], 1993, P S APPL MATH, DOI DOI 10.1090/PSAPM/047/1268002
   Besbeas P, 2004, INT STAT REV, V72, P209
   Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793
   Combettes PL, 2007, IEEE J-STSP, V1, P564, DOI 10.1109/JSTSP.2007.910264
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dupe F-X, 2011, ARXIV11032213V1
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   GREEN M, 2002, 0255 CAM UCLA
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Jonsson E., 1998, 9848 CAM UCLA
   Kervrann C, 2004, INT S BIOM IM ISBI04
   Kolaczyk ED, 1999, STAT SINICA, V9, P119
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   RUDIN LI, 1994, IEEE IMAGE PROC, P31
   Timmermann KE, 1999, IEEE T INFORM THEORY, V45, P846, DOI 10.1109/18.761328
   Wright J., 2009, P C NEUR INF PROC SY
   Wright J, 2011, J ACM, V58
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
NR 22
TC 1
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 485
EP 495
DI 10.1007/s11042-013-1535-4
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400007
DA 2024-07-18
ER

PT J
AU Lim, JD
   Kim, JN
   Jung, YG
   Yoon, YD
   Lee, CH
AF Lim, Jae-Deok
   Kim, Jeong-Nyeo
   Jung, Young-Giu
   Yoon, Young-Doo
   Lee, Cheol-Hoon
TI Improving performance of X-rated video classification with the optimized
   repeated curve-like spectrum feature and the skip-and-analysis
   processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE X-rated video classification; Obscene sound classification; Audio
   feature; Optimized repeated curve-like spectrum feature;
   Skip-and-analysis processing; Support vector machine
ID AUDIO CLASSIFICATION; SEGMENTATION; RETRIEVAL
AB This paper addresses the automatic classification of X-rated videos by analyzing its obscene sounds. In this paper, we propose the optimized repeated curve-like spectrum feature for classifying obscene sounds and the skip-and-analysis processing for classifying videos. The optimized repeated curve-like spectrum feature uses the longer frame size for stationary frequency region based on the fact that most of obscene sounds, such as sexual moans and screams, consist of mostly vowels and the variation of syllables occurs slowly compared to general speech. It also uses the customized mel-scaled bandpass filter for the valid frequency regions of obscene sounds with the frequency contents mainly under 5 kHz. The skip-and-analysis processing is based on the video playback characteristics that a harmful or normal scene continues to be played at least for certain duration of time during a playback. When the skip-and-analysis processing is applied, clips to be analyzed are selected by skip interval values and only these selected clips are used to classify videos. The processing performances of the optimized repeated curve-like spectrum feature have improvements from 21 % to 25.6 % compared to the repeated curve-like spectrum feature without degradation of classification performance in clip-level classification. Furthermore, when the skip-and-analysis processing is applied, the processing performance of classifying is improved significantly by from 82.59 % to 95.03 % maintaining the classification performance of more than 90 % at F1-score.
C1 [Lim, Jae-Deok; Kim, Jeong-Nyeo] ETRI, Cyber Secur Res Lab, Daegeon 305700, South Korea.
   [Jung, Young-Giu] YM Naeultech, Multimodal & Human Interact Lab, Inchon 402751, South Korea.
   [Yoon, Young-Doo] Kangwon Natl Univ, Dept Design, Chuncheon Si 200701, Gangwon Do, South Korea.
   [Lee, Cheol-Hoon] CNU, Coll Comp Engn, Daegeon 305764, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Kangwon National University
RP Lee, CH (corresponding author), CNU, Coll Comp Engn, 99 Daehak Ro, Daegeon 305764, South Korea.
EM jdscol92@etri.re.kr; jnkim@etri.re.kr; youngq.jung@ym-naeultech.com;
   yoon02@kangwon.ac.kr; clee@cnu.ac.kr
FU KCC (Korea Communications Commission), Korea under the ETRI R&D support
   program [KCA-11921-05001]
FX This research was supported by the KCC (Korea Communications
   Commission), Korea; under the ETRI R&D support program supervised by the
   KCA (Korea Communications Agency)." (KCA-11921-05001)
CR [Anonymous], 2006, The 3rd European Conference on Visual Media Production (CVMP 2006)-Part of the 2nd Multimedia Conference 2006, IET, DOI DOI 10.1049/CP:20061978
   [Anonymous], 2009, A practical guide to support vector classification
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2010, INT J MULTIMED APPL
   Bosson A, 2002, LECT NOTES COMPUT SC, V2383, P50
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Cho Dong Uk, 2004, [The Journal of Korean Institute of Communications and Information Sciences B, 한국통신학회논문지B], V29, P554
   Coopersmith J, 2000, IEEE TECHNOL SOC MAG, V19, P27, DOI 10.1109/44.828561
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Jansohn C, 2009, P ACM INT C MULT
   Kamde P.M., 2011, INT J MULTIMED APPL, V3, P72, DOI [https://doi.org/10.48550/arXiv.1109.1145, DOI 10.48550/ARXIV.1109.1145]
   Kim CY, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P1435
   Lee CH, 2008, IEEE T AUDIO SPEECH, V16, P1541, DOI 10.1109/TASL.2008.2005345
   Lee JS, 2007, PATTERN RECOGN, V40, P2261, DOI 10.1016/j.patcog.2006.11.016
   Lim J, 2011, 2011 INT C INFORM SC, P1, DOI [10.1109/ICISA.2011.5772400, DOI 10.1109/ICISA.2011.5772400]
   Lim J.D., 2009, P 10 INT C COMP COMM, P255
   Lim JD, 2011, INT J MULTIMED APPL, V3, P1
   Liu Z, 1998, J VLSI SIG PROC SYST, V20, P61, DOI 10.1023/A:1008066223044
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Shigeo A., 2005, SUPPORT VECTOR MACHI
   Wang JC, 2006, INT C PATT RECOG, P157
   Wang JZ, 1998, COMPUT COMMUN, V21, P1355, DOI 10.1016/S0140-3664(98)00203-5
NR 25
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 717
EP 740
DI 10.1007/s11042-013-1401-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400021
DA 2024-07-18
ER

PT J
AU Walber, T
   Scherp, A
   Staab, S
AF Walber, Tina
   Scherp, Ansgar
   Staab, Steffen
TI Benefiting from users' gaze: selection of image regions from eye
   tracking information for provided tags
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region identification; Region labeling; Gaze analysis; Eye tracking;
   Tagging
AB Providing image annotations is a tedious task. This becomes even more cumbersome when objects shall be annotated in the images. Such region-based annotations can be used in various ways like similarity search or as training set in automatic object detection. We investigate the principle idea of finding objects in images by looking at gaze paths from users, viewing images with an interest in a specific object. We have analyzed 799 gaze paths from 30 subjects viewing image-tag-pairs with the task to decide whether a tag could be found in the image or not. We have compared 13 different fixation measures analyzing the gaze paths. The best performing fixation measure is able to correctly assign a tag to a region for 63 % of the image-tag-pairs and significantly outperforms three baselines. We look into details of the image region characteristics such as the position and size for incorrect and correct assignments. The influence of aggregating multiple gaze paths from several subjects with respect to improving the precision of identifying the correct regions is also investigated. In addition, we look into the possibilities of discriminating different regions in the same image. Here, we are able to correctly identify two regions in the same image from different primings with an accuracy of 38 %.
C1 [Walber, Tina; Scherp, Ansgar; Staab, Steffen] Univ Koblenz Landau, D-56070 Koblenz, Germany.
C3 University of Koblenz & Landau
RP Walber, T (corresponding author), Univ Koblenz Landau, Univ Str 1, D-56070 Koblenz, Germany.
EM walber@uni-koblenz.de; scherp@uni-koblenz.de; staab@uni-koblenz.de
RI Scherp, Ansgar/Q-2315-2016
OI Scherp, Ansgar/0000-0002-2653-9245
FU EU project SocialSensor [FP7-287975]
FX We thank the subjects participating in our experiment. The research
   leading to this article was partially supported by the EU project
   SocialSensor (FP7-287975).
CR [Anonymous], 2009, PROC 17 ACM INT C MU
   Bruneau D, 2002, P CHI, V2
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   Castagnos Sylvain, 2010, P 4 ACM C REC SYST R, P29, DOI DOI 10.1145/1864708.1864717
   Duygulu P., 2006, COMPUTER VISIONECCV, V2002, P349
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Hajimirza S., 2010, IMAGE ANAL MULTIMEDI
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jaimes A, 2001, SPIE, DOI [10.1117/12.429507, DOI 10.1117/12.429507]
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim DH, 2008, J SYST SOFTWARE, V81, P1525, DOI 10.1016/j.jss.2007.10.006
   Klami A, 2008, MULTIMEDIA INFORM
   Klami A, 2010, WORKSH MACH LEARN SI
   Kompatsiaris I, 2001, C IM AN PROC, DOI [10.1109/ICIAP.2001.957041, DOI 10.1109/ICIAP.2001.957041]
   Kozma L., 2009, MULTIMODAL INTERFACE
   Li XR, 2009, INT CONF ACOUST SPEE, P3717, DOI 10.1109/ICASSP.2009.4960434
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   Pasupa K, 2009, IEEE 12 INT C COMP V
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Ramanathan S, 2009, MULTIMEDIA, DOI [10.1145/1631272.1631399, DOI 10.1145/1631272.1631399]
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rowe NC, 2002, IEEE T KNOWL DATA EN, V14, P202, DOI 10.1109/69.979983
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Santella A., 2006, CHI, p771{780
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Sewell W., 2010, CHI 10 EXTENDED ABST, P3739, DOI DOI 10.1145/1753846.1754048
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Tsai D, 2011, IEEE I CONF COMP VIS, P611, DOI 10.1109/ICCV.2011.6126295
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   von Ahn L., 2006, CHI
   Walber T, 2012, LECT NOTES COMPUT SC, V7131, P138
   Walber Tina., 2013, Advances in Multimedia Modeling, P36
   Yarbus A. L., 1967, Eye Movements and Vision
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 35
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 363
EP 390
DI 10.1007/s11042-013-1390-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700022
DA 2024-07-18
ER

PT J
AU Jiang, L
   Xu, ZQ
   Xu, YY
AF Jiang, Li
   Xu, Zhengquan
   Xu, Yanyan
TI Commutative encryption and watermarking based on orthogonal
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Commutative encryption and watermarking (CEW); Orthogonal decomposition;
   Security
ID IMAGES
AB Commutative Encryption and Watermarking (CEW) is a technology combined with encryption and watermarking, which is used for providing comprehensive security protection for multimedia information. This paper presents a novel CEW scheme based on orthogonal decomposition. Different from current CEW, the proposed CEW not only achieves the integration of encryption and watermarking in the final data but also has no specific restrictions in selecting encryption and watermarking algorithms. Therefore, the proposed CEW possesses higher security and applicability. Experimental results demonstrate that the proposed CEW can keep the performances of selected encryption and watermarking algorithm and show more robustness than other current CEW schemes.
C1 [Jiang, Li; Xu, Zhengquan; Xu, Yanyan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Xu, ZQ (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM yigutong@163.com; xuzq@whu.edu.cn; xuyy@whu.edu.cn
FU National Basic Research Program of China (973 Program) [2011CB302204];
   National Natural Science Foundation of China [41101416]; Research Fund
   for the Doctoral Program of Higher Education of China [20110141110056];
   Wuhan University
FX This work was supported by the National Basic Research Program of China
   (973 Program) under Grant 2011CB302204, the National Natural Science
   Foundation of China under Grant 41101416, the Research Fund for the
   Doctoral Program of Higher Education of China under Grant 20110141110056
   and the Doctoral Candidate Research Independent Fund of Wuhan
   University.
CR [Anonymous], 2005, 1 SUMM REP HYBR SYST
   Battisti F, 2008, P SPIE
   Battisti F, 2009, EURASIP J ADV SIG PR, V2009, P1
   Boato G, 2008, ELECTRON LETT, V44, P601, DOI 10.1049/el:20080492
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Cancellaro M, 2008, P SPIE, P68191
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Jiang L, 2010, P 2010 IEEE INT C MU
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   Park SW, 2008, STUD COMPUT INTELL, V142, P351
   Steinebach M, 2005, PROC SPIE, V5681, P779, DOI 10.1117/12.586875
   Sun J, 2011, MULTIMED TOOLS APPL, V53, P75, DOI 10.1007/s11042-010-0491-5
   Walsh JL, 1923, AM J MATH, V45, P5, DOI 10.2307/2387224
NR 15
TC 14
Z9 17
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1617
EP 1635
DI 10.1007/s11042-012-1181-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500011
DA 2024-07-18
ER

PT J
AU Zayen, B
   Hayar, A
   Noubir, G
AF Zayen, Bassem
   Hayar, Aawatif
   Noubir, Guevara
TI Game theory-based resource management strategy for cognitive radio
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive radio; Resource allocation; Game theory; User selection
ID ALLOCATION
AB This paper investigates the application of game theory tools in the context of cognitive radio networks (CRN). Specifically, we propose a resource management strategy with the objective to maximize a defined utility function subject to minimize the mutual interference caused by secondary users (SUs) with protection for primary users (PUs). In fact, we formulate a utility function to reflect the needs of PUs by verifying the outage probability constraint, and the per-user capacity by satisfying the signal-to-noise and interference ratio (SNIR) constraint, as well as to limit interference to PUs. Furthermore, the existence of the Nash equilibrium of the proposed game is established, as well as its uniqueness under some sufficient conditions. Theoretical and simulation results based on a realistic network setting, and a comparison with a previously published resource management method are provided in this paper. The reported results demonstrate the efficiency of the proposed technique in terms of CRN deployment while maintaining quality-of-service (QoS) for the primary system.
C1 [Zayen, Bassem] EURECOM, Mobile Commun Dept, Sophia Antipolis, France.
   [Hayar, Aawatif] GREENTIC ENSEM Univ Hassan II, Casablanca, Morocco.
   [Noubir, Guevara] Coll Comp & Informat Sci, Boston, MA USA.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Zayen, B (corresponding author), EURECOM, Mobile Commun Dept, Sophia Antipolis, France.
EM zayen@eurecom.fr; a.hayar@greentic.uh2c.ma; noubir@ccs.neu.edu
RI HAYAR, Aawatif/AAW-4931-2021
OI HAYAR, Aawatif/0000-0003-0942-3889
FU European Community [249060]; Hassan II Foundation
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme (FP7/2007-2013) under
   grant agreement SACRA (Spectrum and energy efficiency through multi-band
   cognitive radio) no249060, and was partially supported by the Hassan II
   Foundation for the Moroccans residing abroad. Parts of this paper were
   presented at ICMCS 2011 [27].
CR [Anonymous], 2008, ELSEVIER PHYCOM
   [Anonymous], 1991, Urban transmission loss models for mobile radio in the 900 and 1800 MHz bands
   [Anonymous], 2003, An Introduction to Game Theory
   [Anonymous], 1973, International Journal of Game Theory, DOI 10.1007/BF01737559
   [Anonymous], FCC CONS AN COSTS BE
   [Anonymous], 2006, GAME THEORY WIRELESS
   Fudenberg D., 1991, GAME THEORY
   Haddad M, 2008, CROWNCOM SING
   Haddad M, 2008, PIMRC CANN FRANC
   Huang J, 2006, MOBILE NETW APPL, V11, P405, DOI 10.1007/s11036-006-5192-y
   Jorswieck E, 2010, INT WORKSH COGN INF
   Jovicic A, 2009, IEEE T INFORM THEORY, V55, P3945, DOI 10.1109/TIT.2009.2025539
   KIANI SG, 2007, P IEEE WIR COMM NETW
   Meshkati F, 2009, IEEE T COMMUN, V57, P3406, DOI 10.1109/TCOMM.2009.11.050638
   Mitola J, 1999, MOB MULT COMM MOMUC
   Nie N, 2005, NEW FRONTIERS DYNAMI
   OZAROW LH, 1994, IEEE T VEH TECHNOL, V43, P359, DOI 10.1109/25.293655
   Pang JS, 2010, IEEE T SIGNAL PROCES, V58, P3251, DOI 10.1109/TSP.2010.2043138
   Peha JM, 2005, IEEE COMMUN MAG, V43, P10, DOI 10.1109/MCOM.2005.1391490
   Schmidt DA, 2009, IEEE SIGNAL PROC MAG, V26, P53, DOI [10.1109/MSRP.2009.933371, 10.1109/MSP.2009.933371]
   Wu D, 2007, 2008 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND SIGNAL PROCESSING, VOLS 1 AND 2, P522
   Xing YP, 2007, IEEE T MOBILE COMPUT, V6, P423, DOI 10.1109/TMC.2007.50
   YATES RD, 1995, IEEE J SEL AREA COMM, V13, P1341, DOI 10.1109/49.414651
   Zayen B, 2011, ICMCS 11 2 INT C MUL
   Zayen B, 2009, AS
   Zayen B., 2010, SPECTRUM SENSING RES
   Zhao B, 2008, INT CONF ACOUST SPEE, P1881
NR 27
TC 3
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2063
EP 2083
DI 10.1007/s11042-012-1211-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500030
DA 2024-07-18
ER

PT J
AU da Luz, A
   Valle, E
   Araújo, AD
AF da Luz, Antonio
   Valle, Eduardo
   Araujo, Arnaldo de A.
TI Non-collaborative content detecting on video sharing social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content filtering; Bags of visual features; Latent semantic analysis;
   Video social networks
AB In this work we are concerned with detecting non-collaborative videos in video sharing social networks. Specifically, we investigate how much visual content-based analysis can aid in detecting ballot stuffing and spam videos in threads of video responses. That is a very challenging task, because of the high-level semantic concepts involved; of the assorted nature of social networks, preventing the use of constrained a priori information; and, which is paramount, of the context-dependent nature of non-collaborative videos. Content filtering for social networks is an increasingly demanded task: due to their popularity, the number of abuses also tends to increase, annoying the user and disrupting their services. We propose two approaches, each one better adapted to a specific non-collaborative action: ballot stuffing, which tries to inflate the popularity of a given video by giving "fake" responses to it, and spamming, which tries to insert a non-related video as a response in popular videos. We endorse the use of low-level features combined into higher-level features representation, like bag-of-visual-features and latent semantic analysis. Our experiments show the feasibility of the proposed approaches.
C1 [da Luz, Antonio; Araujo, Arnaldo de A.] NPDI Lab DCC UFMG, Belo Horizonte, MG, Brazil.
   [Valle, Eduardo] RECOD Lab DCA FEEC UNICAMP, Campinas, SP, Brazil.
RP da Luz, A (corresponding author), NPDI Lab DCC UFMG, Belo Horizonte, MG, Brazil.
EM daluz@dcc.ufmg.br; dovalle@dca.fee.unicamp.br; arnaldo@dcc.ufmg.br
OI Alves do Valle Jr, Eduardo/0000-0001-5396-9868
FU CNPq; CAPES; FAPEMIG; FAPESP
FX The authors are thankful to the Brazilian agencies CNPq, CAPES, FAPEMIG
   and FAPESP, for the financial support.
CR [Anonymous], 2007, CIVR '07
   [Anonymous], 2007, MIR
   Benevenuto F, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P620, DOI 10.1145/1571941.1572047
   Blanzieri E, 2008, ARTIF INTELL REV, V29, P63, DOI 10.1007/s10462-009-9109-6
   Caicedo J.C., 2010, Multimedia Information Retrieval, P359
   Cormack Gordon V., 2006, Foundations and Trends in Information Retrieval, V1, P1, DOI 10.1561/1500000006
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Crane R, 2008, P NATL ACAD SCI USA, V105, P15649, DOI 10.1073/pnas.0803685105
   de Avila SEF, 2008, INT CONF SYST SIGNAL, P449, DOI 10.1109/IWSSIP.2008.4604463
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Heymann P, 2007, IEEE INTERNET COMPUT, V11, P36, DOI 10.1109/MIC.2007.125
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Langbehn H, 2010, J INF DATA MANAG, V1, P313
   Lee CH, 2010, LECT NOTES ENG COMP, P1467
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Valle E, 2009, 2009 TUTORIALS OF THE XXII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING (SIBGRAPI 2009), P72, DOI 10.1109/SIBGRAPI-Tutorials.2009.14
   Yanai K, 2010, INT C MULT INF RETR, P305
NR 20
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1049
EP 1067
DI 10.1007/s11042-012-1198-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900021
DA 2024-07-18
ER

PT J
AU Sun, HM
AF Sun, Huey-Min
TI Online smoothness with dropping partial data based on advanced video
   coding stream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advanced video coding (AVC); Online smoothness; ITU-T Rec. H.264;
   Scalable video coding
ID BIT-RATE VIDEO; BANDWIDTH ALLOCATION; STORED VIDEO; NETWORKS; DELIVERY;
   QUALITY; SVC; EXTENSION; STANDARD; IP
AB Most studies of smoothing video stream compute the required bit rate of video transmission to satisfy all the transmitted data. In this paper, our proposed online smoothing with tolerable data dropping algorithm can adjust the bit rate as smooth as possible. Several multimedia encoding schemes, such as advanced video coding (AVC), can support partial data dropping to adapt to available bandwidth network. The AVC stream can be adapted by smoothing algorithm to ensure video quality for a given set of constraints where these constraints may be either static after the session set up or may dynamically change over the session duration. Our algorithm is based on the online minimum variance bandwidth allocation algorithm to look ahead a window of frames, dynamically adjusting the required bit rate such that ensuring smoothness when the buffer encounters underflow or overflow for video stream. Furthermore, we add the scheme of data dropping into this algorithm to increase the possibility of smoothing bit rates. The experimental results show the peak rate, the average ratio of dropped data, and the coefficient of variation for five test sequences with different content characteristics such as the average frame size, the peak/mean ratio of frame size, and the average frame bit rate. Experimental parameters are varied by window sizes and tolerable dropping ratios. The algorithm can significantly reduce the peak rate and the coefficient of variation when the transmitted packets are allowed dropping by a user-defined dropping ratio.
C1 Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
C3 Chang Jung Christian University
RP Sun, HM (corresponding author), Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
EM prince@mail.cjcu.edu.tw
FU Chang Jung Christian University [Q1000005]
FX This work was supported by Chang Jung Christian University under
   Contract Q1000005.
CR Camarda P, 2007, P 3 INT C MOB MULT C
   CHAKARESKI J, 2005, IEEE INT C MULT EXP, P1066
   Feng WC, 1997, MULTIMEDIA SYST, V5, P297, DOI 10.1007/s005300050062
   FENG WC, 1995, COMPUT COMMUN, V18, P709, DOI 10.1016/0140-3664(95)98484-M
   Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Kuschnig R., 2010, MMSYS, P157
   Lai HL, 2005, IEEE T CIRC SYST VID, V15, P221, DOI 10.1109/TCSVT.2004.841687
   Lee MJ, 2007, IEEE T CONSUM ELECTR, V53, P454, DOI 10.1109/TCE.2007.381715
   Lin JW, 2006, IEEE T MULTIMEDIA, V8, P996, DOI 10.1109/TMM.2006.879868
   Marshall A. W., 1979, Inequalities: Theory of Majorization and its Applications
   Mushtaq M, 2008, CONSUM COMM NETWORK, P447, DOI 10.1109/ccnc08.2007.106
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Reichel J., 2007, JOINT SCALABLE VIDEO
   REXFORD J, 1997, P INT WORKSH NETW OP, P249
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Schierl T, 2007, IEEE INT SYMP CIRC S, P3455, DOI 10.1109/ISCAS.2007.378370
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sen S, 2000, IEEE T MULTIMEDIA, V2, P37, DOI 10.1109/6046.825793
   Van der Auwera G, 2008, IEEE T BROADCAST, V54, P698, DOI 10.1109/TBC.2008.2000422
   Van der Auwera G, 2009, IEEE T BROADCAST, V55, P541, DOI 10.1109/TBC.2009.2027399
   Wang ZL, 2009, IEEE T MULTIMEDIA, V11, P998, DOI 10.1109/TMM.2009.2021800
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1227, DOI 10.1109/TCSVT.2007.905519
   Wu J, 2007, IEEE SIGNAL PROC LET, V14, P715, DOI 10.1109/LSP.2007.896376
   Zhang JB, 1998, COMPUT COMMUN, V21, P375, DOI 10.1016/S0140-3664(97)00170-9
NR 25
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 1021
EP 1040
DI 10.1007/s11042-012-1141-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300020
DA 2024-07-18
ER

PT J
AU Hu, HJ
   Li, YX
   Liu, MF
   Liang, WH
AF Hu, Huijun
   Li, Yuanxiang
   Liu, Maofu
   Liang, Wenhao
TI Classification of defects in steel strip surface based on multiclass
   support vector machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steel strip; Surface defect; Support vector machine; LIBSVM; OpenCV;
   Back-propagation neural network
ID PROPAGATION NEURAL-NETWORK
AB In this paper, we use support vector machine to classify the defects in steel strip surface images. After image binarization, three types of image features, including geometric feature, grayscale feature and shape feature, are extracted by combining the defect target image and its corresponding binary image. For the classification model based on support vector machine, we utilize Gauss radial basis as the kernel function, determine model parameters by cross-validation and employ one-versus-one method for multiclass classifier. Experiment results show that support vector machine model outperforms the traditional classification model based on back-propagation neural network in average classification accuracy.
C1 [Hu, Huijun; Li, Yuanxiang] Wuhan Univ, Comp Sch, State Key Lab Software Engn, Wuhan 430072, Hubei, Peoples R China.
   [Hu, Huijun; Liu, Maofu] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Liang, Wenhao] Zhejiang Dahua Tecnol Co Ltd, Hangzhou 310053, Zhejiang, Peoples R China.
C3 Wuhan University; Wuhan University of Science & Technology
RP Hu, HJ (corresponding author), Wuhan Univ, Comp Sch, State Key Lab Software Engn, Wuhan 430072, Hubei, Peoples R China.
EM huhuijun@wust.edu.cn; yxli@whu.edu.cn; liumaofu@wust.edu.cn;
   liangwh019@163.com
RI Li, Yuan/GXV-1310-2022
FU National Natural Science Foundation of China [61070009, 61100133]; Hubei
   Provincial Natural Science Funds for Distinguished Young Scholar of
   China [2010CDA090]
FX The work in this paper was supported partially by the National Natural
   Science Foundation of China (No. 61070009, 61100133) and Hubei
   Provincial Natural Science Funds for Distinguished Young Scholar of
   China (2010CDA090).
CR [Anonymous], 2003, PRACTICAL GUIDE SUPP
   [Anonymous], METALL PLANT TECHNOL
   Cecilio A, 2003, J NEUROONCOL, V55, P57, DOI DOI 10.1016/S0925-2312(03)00435-1
   Choi C-H, 1996, P INT C IM PROC, P673, DOI [10.1109/ICIP.1996.560968, DOI 10.1109/ICIP.1996.560968]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   HSU KY, 1995, OPT LASER ENG, V23, P167, DOI 10.1016/0143-8166(95)00013-E
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063
   Kim C. H., 2006, J KOREAN SOC PRECIS, V23, P80
   Kwak C, 2000, J INTELL MANUF, V11, P485, DOI 10.1023/A:1008974314490
   Lai K, 2003, P SPIE INT SOC OPT E, V4929, P447
   Li L, 2006, IEEE INT C MECH AUT, P2235, DOI [10.1109/ICMA.2006.257659, DOI 10.1109/ICMA.2006.257659]
   Liu SY, 2008, SECOND INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING: WGEC 2008, PROCEEDINGS, P137, DOI 10.1109/WGEC.2008.47
   Pernkopf F, 2004, PATTERN ANAL APPL, V7, P333, DOI 10.1007/s10044-004-0232-3
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salavi R, 2011, ADV COMPUTING COMM 1, V125, P62, DOI [10.1007/978-3-642-18440-6_8, DOI 10.1007/978-3-642-18440-6_]
   Song S-J, 1997, J KOREAN SOC NONDEST, V17, P162
   Suralkar S., 2012, INT J COMPUTER TECHO, V3, P71
   Trieber F, 1989, J IRON STEEL ENG, V66, P26
   Vapnik V., 1999, NATURE STAT LEARNING
   Wong W-K, 2009, STITCHING DEFECT DET
   Yang B., 2011, PROC DESIGN, P1, DOI DOI 10.1109/ISIDF.2011.6024276
   Zhang W, 2007, LECT NOTES COMPUT SC, V4490, P150
NR 25
TC 42
Z9 46
U1 1
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 199
EP 216
DI 10.1007/s11042-012-1248-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200010
DA 2024-07-18
ER

PT J
AU Lagodzinski, P
   Smolka, B
AF Lagodzinski, Przemyslaw
   Smolka, Bogdan
TI Application of the Extended Distance Transformation in digital image
   colorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Colorization; Distance transform; Color blending; Computer vision
ID COLOR; ALGORITHM
AB In this paper we present a novel colorization scheme that takes advantage of the modified morphological distance transform to propagate the color, scribbled by a user on the grayscale image. First, based on the scribbled image, the topological distance values are computed for each image pixel, describing its distance to the inserted color markers. These values are then complemented with the structural information and luminance changes derived from the original grayscale image. The distances are then used along with gradient based features to reproduce original image structures while propagating the new colors obtained during the additive color blending process. Extensive experiments performed on various kinds of natural images demonstrated the effectiveness of the proposed colorization method. They also showed that the main advantage of the presented algorithm is its computational speed and ability to produce visually pleasing colorization results promptly after providing the color information.
C1 [Lagodzinski, Przemyslaw] Res & Dev Inst Comp Sci, PL-44217 Rybnik, Poland.
   [Smolka, Bogdan] Silesian Tech Univ, Inst Automat Control, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Lagodzinski, P (corresponding author), Res & Dev Inst Comp Sci, Florianska 20-5 Str, PL-44217 Rybnik, Poland.
EM Przemyslaw.Lagodzinski@ibri.eu; Bogdan.Smolka@polsl.pl
RI Smolka, Bogdan/AFK-4617-2022; Lagodzinski, Przemyslaw/S-8433-2018
OI Smolka, Bogdan/0000-0003-1883-3580; Lagodzinski,
   Przemyslaw/0000-0003-0052-3111
CR Abadpour A, 2004, PROCEEDINGS OF THE FOURTH IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P491, DOI 10.1109/ISSPIT.2004.1433825
   [Anonymous], J IMAGE VIDEO PROCES
   Chang CW, 1997, J VISUAL COMP ANIMAT, V8, P165, DOI 10.1002/(SICI)1099-1778(199707)8:3<165::AID-VIS157>3.0.CO;2-2
   Chassery J.-M., 1993, Geometric Reasoning for Perception and Action. Workshop, P163
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Horiuchi T, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P245
   Horiuchi T, 2004, IMAGE VISION COMPUT, V22, P197, DOI 10.1016/j.imavis.2003.08.004
   Horiuchi T, 2003, IEEE IMAGE PROC, P457
   Horiuchi T., 2003, P IEEE INT C PATT RE, P867
   Kawulok M, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-99
   Kawulok M, 2010, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2010.5653544
   Kim T, 2009, C P IEEE ICIP, P1661
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Lagodzinski Przemyslaw, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P813, DOI 10.1109/ISSPIT.2007.4458137
   Lagodzinski P, 2008, J 13 INT C MED INF T, P151
   Lagodzinski P, 2007, C P 20 IEEE SPIE S P
   Lagodzinski P, 2007, C P ELECT IMAGING VI, P126
   Lagodzinski P, 2007, J 12 INT C MED INF T, P47
   Lagodzinski P, 2008, LECT NOTES COMPUT SC, V5197, P626, DOI 10.1007/978-3-540-85920-8_76
   Lagodzinski P, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P1
   Lagodzinski P, 2007, ADV INTEL SOFT COMPU, V45, P108
   Lagodzinski P, 2009, REC ADV COMPUT ENG, P277
   Lagodzinski P, 2008, MONOGR COTSEN INST A, P495
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu XM, 2009, LECT NOTES COMPUT SC, V5702, P468
   Lukac R, 2007, COMPUT VIS IMAGE UND, V107, P1, DOI 10.1016/j.cviu.2007.01.001
   Madeira JS, 1996, VISUAL COMPUT, V12, P1
   Pan Z., 2004, 12th International Conference on Computer Graphics, Visualization and Computer Vision (WSCG), P515
   Plataniotis K, 2010, COLOR IMAGE PROCESSI
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   ROSENFEL.A, 1966, J ACM, V13, P471
   Skora D., 2004, P 3 INT S NONPH AN R, P121, DOI DOI 10.1145/987657.987677
   Smolka B, 2001, SIGNAL PROCESS, V81, P465, DOI 10.1016/S0165-1684(00)00226-7
   Toivanen PJ, 1996, PATTERN RECOGN LETT, V17, P437, DOI 10.1016/0167-8655(96)00010-4
   Wang PP, 2007, STUD FUZZ SOFT COMP, V215, P1, DOI 10.1007/978-3-540-71258-9
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Zhang Z., 2009, Proc. ITC, P1
NR 40
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 111
EP 137
DI 10.1007/s11042-012-1246-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200006
DA 2024-07-18
ER

PT J
AU Liu, Y
   Li, XQ
   Wang, L
   Niu, YZ
   Liu, F
AF Liu, Yang
   Li, Xueqing
   Wang, Lei
   Niu, Yuzhen
   Liu, Feng
TI Oscillation analysis for salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient objects; Local minima; Local maxima; Oscillation; Auto object
   segmentation
ID VISUAL-ATTENTION; IMAGE; EXTRACTION
AB Salient object detection from an image is important for many multimedia applications. Existing methods provide good solutions to saliency detection; however, their results often emphasize the high-contrast edges, instead of regions/objects. In this paper, we present a method for salient object detection based on oscillation analysis. Our study shows that salient objects and their backgrounds have different amplitudes of oscillation between the local minima and maxima. Based on this observation, our method analyzes the oscillation in an image by estimating its local minima and maxima and computes the saliency map according to the oscillation magnitude contrast. Our method detects the local minima and maxima and performs extreme interpolation to smoothly propagate these information to the whole image. In this way, the oscillation information is smoothly assigned to regions, retaining well-defined salient boundaries as there are large variations near the salient boundaries (edges between objects and their backgrounds). As a result, our saliency map highlights salient regions/objects instead of high-contrast boundaries. We experiment with our method on two large public data set. Our results demonstrate the effectiveness of our method. We further apply our salient object detection method to automatic salient object segmentation, which again shows the success.
C1 [Liu, Yang] Shandong Univ, Jinan 250100, Shandong, Peoples R China.
   [Li, Xueqing] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Shandong, Peoples R China.
   [Wang, Lei] Weifang Coll, Weifang, Shandong, Peoples R China.
   [Niu, Yuzhen; Liu, Feng] Portland State Univ, Portland, OR 97207 USA.
C3 Shandong University; Shandong University; Portland State University
RP Liu, Y (corresponding author), Shandong Univ, Jinan 250100, Shandong, Peoples R China.
EM lawyoung@sdu.edu.cn; xqli@sdu.edu.cn; wanglpqpq@gmail.com;
   yuzhen@cs.pdx.edu; fliu@cs.pdx.edu
FU Shandong Provincial Natural Science Foundation of China [ZR2011FM037];
   Innovation Fund for Distinguished Graduate Student of Shandong
   University [yyx10043]
FX We would like to thank the reviewers for their insightful and
   constructive comments. This research is supported by Shandong Provincial
   Natural Science Foundation of China (Grant No. ZR2011FM037) and
   Innovation Fund for Distinguished Graduate Student of Shandong
   University (Grant No. yyx10043).
CR Achanta R, 2010, INT C IM PROC
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, 2008 19 INT C PATT R
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu Y, 2005, ACM INT C MULT
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Wang Z, 2008, INT C AC SPEECH SIGN
   Yanulevskaya V, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P355
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 29
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 659
EP 679
DI 10.1007/s11042-012-1072-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000008
DA 2024-07-18
ER

PT J
AU Choi, H
   Choi, E
   Song, S
AF Choi, Hun
   Choi, Eunyoung
   Song, Seungkeun
TI The structure of affection descriptors for social network game: case
   study of CityVille on facebook
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social Network Service (SNS); Social Network Game (SNG); Facebook;
   CityVille; Affection Descriptor
AB The purpose of this study is to investigate the structure of affection descriptors in order to understand users' affection revealed in social network games (SNGs) such as City Ville, Farmville, and Cafe World based on the Facebook platform. Literature relating to the affection was studied, and affection descriptors shown in SNG were selected. Six experts reviewed whether 208 words collected from the literature related to affection and a simple psychological experiment such as a free-association test were suitable for an affection descriptor. One hundred twenty users re-tested 46 affection descriptor candidates derived from the expert review. Ultimately, 25 high-scoring affection descriptor candidates were found. The relationship and framework among affection descriptors were examined using a controlled-association test administered to the 25 high-scoring affection descriptor candidates. The result of this research revealed that 19 representative affection descriptors were derived: elegant, peculiar, novel, interest, clean, confused, excited, complex, degage, upright, prominent, functional, beauty, tiny, elementary, short, modern, useful, and simple. This study suggests directions for practical production and essential design guidelines for SNG.
C1 [Choi, Hun] Catholic Univ Pusan, Dept Management Informat Syst, Pusan, South Korea.
   [Choi, Eunyoung] Seoul Digital Univ, Dept Media Image, Seoul, South Korea.
   [Song, Seungkeun] Dongseo Univ, Div Digital Content, Pusan 617716, South Korea.
C3 Catholic University Pusan; Dongseo University
RP Song, S (corresponding author), Dongseo Univ, Div Digital Content, 901 New Millennium Hall,San 69-1,Churye 2 Dong, Pusan 617716, South Korea.
EM songsk@gdsu.dongseo.ac.kr
RI CHOI, EUNYOUNG/KQU-5508-2024
CR Aarseth E, 2003, P DIG ARTS CULT
   Andy C, 2010, ESCAPIST
   [Anonymous], IND ENG MAGAZINE
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Caillois R., 2001, Man
   선지현, 2004, [Archives of Design Research, 디자인학연구], V17, P209
   Choi S, 2009, STUDY EFFECT SNS SOC
   Foley S., 2012, INDEPENDENT
   Helliwell JF, 2004, PHILOS T R SOC B, V359, P1435, DOI 10.1098/rstb.2004.1522
   박현아, 2011, [Journal of Korea Game Society, 한국게임학회 논문지], V11, P105
   Hong Y, 2011, IND ENG MAG, V18, P33
   Hong Y, 2010, KOCCA FOCUS, V10
   Jarvinen A., 2009, P 13 INT MINDTREK C
   Jason K, 2010, TECHCRUNCH
   Jung Y, 2008, TENDENCY PROSPECT SO
   Kim J, 2012, INTRO HUMAN COMPUTER
   Kim Jongchan, 2010, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V14, P2586
   Kim Y, 2005, P KOR SOC DES SCI FA, P270
   Lee K, 1998, KOR J SCI EMOT SENSI, V1, P113
   Lee S, 1996, HUMAN SENSIBILITY ER
   Martin D.W., 2008, DOING PSYCHOL EXPT, V7th
   Park M, 1998, KOREAN J SCI EMOTION, V1, P1
   Park S, 2010, INT C GAM CULT SHANG
   Park S, 1998, KOR J SCI EMOT SENSI, V2, P77
   Ran Jeon Gyong, 2011, [Journal of Korea Game Society, 한국게임학회 논문지], V11, P13
   Wikipedia, 2012, CITYVILLE
   Wikipedia, 2012, ZYNG
   Wikipedia, 2012, STANL MILGR
   Wikipedia, 2012, SOC NETW
   Wikipedia, 2012, EEG ECG EMG
   Wohn DongheeYvette., 2011, Proceedings of the 44th Hawaii International Conference on System Sciences (HICSS 2011), P1, DOI DOI 10.1109/HICSS.2011.400
   Yoon J.S., 2000, KOREAN J SCI EMOTION, V3, P67
   송승근, 2011, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V11, P120
   변태운, 2010, [Management & Information Systems Review, 경영과 정보연구], V29, P89
   한혜원, 2010, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V10, P137
NR 35
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 375
EP 389
DI 10.1007/s11042-012-1310-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400012
DA 2024-07-18
ER

PT J
AU Hong, SG
   Shin, S
   Yi, MY
AF Hong, Soon Gill
   Shin, Sungho
   Yi, Mun Yong
TI Contextual keyword extraction by building sentences with crowdsourcing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowdsourcing; Keyword extraction; Document summary; Content extraction;
   Sentence building; Contextual term extraction
AB Automatic keyword extraction from documents has long been used and proven its usefulness in various areas. Crowdsourced tagging for multimedia resources has emerged and looks promising to a certain extent. Automatic approaches for unstructured data, automatic keyword extraction and crowdsourced tagging are efficient but they all suffer from the lack of contextual understanding. In this paper, we propose a new model of extracting key contextual terms from unstructured data, especially from documents, with crowdsourcing. The model consists of four sequential processes: (1) term selection by frequency, (2) sentence building, (3) revised term selection reflecting the newly built sentences, and (4) sentence voting. Online workers read only a fraction of a document and participated in sentence building and sentence voting processes, and key sentences were generated as a result. We compared the generated sentences to the keywords entered by the author and to the sentences generated by offline workers who read the whole document. The results support the idea that sentence building process can help selecting terms with more contextual meaning, closing the gap between keywords from automated approaches and contextual understanding required by humans.
C1 [Hong, Soon Gill; Yi, Mun Yong] Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Taejon 305701, South Korea.
   [Shin, Sungho] Korea Inst Sci & Technol Informat, Taejon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea
   Institute of Science & Technology Information (KISTI); Korea Institute
   of Science & Technology (KIST)
RP Yi, MY (corresponding author), Korea Adv Inst Sci & Technol, Dept Knowledge Serv Engn, Taejon 305701, South Korea.
EM hsoongil@kaist.ac.kr; maximus74@kisti.re.kr; munyi@kaist.ac.kr
RI Yi, Mun Yong/C-2065-2011
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2011-0029185]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2011-0029185).
CR Barker K, 2000, LECT NOTES ARTIF INT, V1822, P40
   Bernstein Michael S., 2010, P 23ND ANN ACM S USE, P313, DOI 10.1145/1866029.1866078
   Frank E, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P668
   Gligorov Riste, 2012, WWW 12 COMPANION, P139
   Howe J, 2006, WIRED, V14, P1, DOI DOI 10.1086/599595
   Hsu W, 2008, P 17 INT C WORLD WID, P665
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   Hulth A, 2001, LECT NOTES COMPUT SC, V2004, P472
   Kittur A., 2010, XRDS CROSSROADS, V17, P22, DOI DOI 10.1145/1869086.1869096
   Matsuo Y., 2004, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V13, P157, DOI 10.1142/S0218213004001466
   Shaw AD, 2011, P ACM C COMP SUPP CO
   Snow R, 2008, P 2008 C EMP METH NA, P254, DOI DOI 10.3115/1613715.1613751
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   Witten I. H., 1999, Digital 99 Libraries. Fourth ACM Conference on Digital Libraries, P254, DOI 10.1145/313238.313437
NR 15
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 401
EP 412
DI 10.1007/s11042-012-1338-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400014
DA 2024-07-18
ER

PT J
AU Kim, AC
   Kim, S
   Park, WH
   Lee, DH
AF Kim, Ae Chan
   Kim, Seongkon
   Park, Won Hyung
   Lee, Dong Hoon
TI Fraud and financial crime detection model using malware forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fraud detection; Electronic financial transaction; Malware forensics
AB Recently various electronic financial services are provided by development of electronic devices and communication technology. By diversified electronic financial services and channels, users of none face-to-face electronic financial transaction services continuously increase. At the same time, under financial security environment, leakage threats of inside information and security threats against financial transaction users steadily increase. Accordingly, in this paper, based on framework standards of financial transaction detection and response, digital forensics techniques that has been used to analyze system intrusion incidents traditionally is used to detect anomaly transactions that may occur in the user terminal environment during electronic financial transactions. Particularly, for the method to analyze user terminals, automated malware forensics techniques that is used as supporting tool for malware code detection and analysis is used, and for the method to detect anomaly prior behaviors and transaction patterns of users, moving average based on the statistical basis is applied. In addition, the risk point calculation model is proposed by scoring anomaly transaction cases in the detection step by items. This model logs calculated risk point results as well as maintains incident accountability, which can be utilized as basic data for establishing security incident response and security policies.
C1 [Kim, Ae Chan; Lee, Dong Hoon] Korea Univ, CIST, Seoul, South Korea.
   [Kim, Seongkon] Catholic Univ Pusan, Dept Comp Engn, Pusan 609757, South Korea.
   [Park, Won Hyung] Far East Univ, Dept Cyber Secur, Eumseong Gun 369700, Chungbuk, South Korea.
C3 Korea University; Catholic University Pusan
RP Park, WH (corresponding author), Far East Univ, Dept Cyber Secur, Eumseong Gun 369700, Chungbuk, South Korea.
EM holytemple@korea.ac.kr; skkim@cup.ac.kr; whpark@kdu.ac.kr;
   donghlee@korea.ac.kr
FU Korea Information Security Agency [H2101-12-1001]
FX This work is supported by the Korea Information Security Agency
   (H2101-12-1001).
CR Ahnlab, 2011, 3 4 DDOS AN REP
   [Anonymous], 2006, NIST SP
   Brezinski D, 2002, 3227 IETF RFC
   Dougan T, 2012, INT J AMBIENT COMPUT, V4, P29, DOI 10.4018/jaci.2012010103
   Gastellier-Prevost S, 2011, MOB SEC NTMS 2011 4, P1
   Jang D. H., 2007, ARP SPOOFING ATTACK
   Kenney JF, 1962, MOVING AVERAGES 14 2, V1, P221
   Lim YF, 2012, J NANOMATER, V2012, DOI 10.1155/2012/393160
   Manuel E, 2012, ACM COMPUTING SURVEY, V44
   NIST NVD, 1999, CVE19990667 NIST NVD
   박희환, 2006, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V11, P251
   Park WH, 2011, INF SCI APPL ICISA 2, P1
   SANS Institute, 2011, COMP FOR TIM AN TAP
   Team Cymru Research NFP, 2013, MALW HASH REG
   Telecommunications Technology Association (TTA), 2011, TTAKKO120178 TTA
   The American Bankers Association (ABA), 2011, SURV ONL BANK SURG M
NR 16
TC 7
Z9 8
U1 4
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 2
BP 479
EP 496
DI 10.1007/s11042-013-1410-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RI
UT WOS:000331083400019
DA 2024-07-18
ER

PT J
AU Arshad, R
   Ikram, N
AF Arshad, R.
   Ikram, N.
TI Elliptic curve cryptography based mutual authentication scheme for
   session initiation protocol
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Elliptic curve cryptosystem; Security; Session
   initiation protocol
AB The Session Initiation Protocol (SIP) is the most widely used signaling protocol for controlling communication on the internet, establishing, maintaining, and terminating the sessions. The services that are enabled by SIP are equally applicable in the world of multimedia communication. Recently, Tsai proposed an efficient nonce-based authentication scheme for SIP. In this paper, we do a cryptanalysis of Tsai's scheme and show that Tsai's scheme is vulnerable to the password guessing attack and stolen-verifier attack. Furthermore, Tsai's scheme does not provide known-key secrecy and perfect forward secrecy. We also propose a novel and secure mutual authentication scheme based on elliptic curve discrete logarithm problem for SIP which is immune to the presented attacks.
C1 [Arshad, R.; Ikram, N.] Natl Univ Sci & Technol, Rawalpindi, Pakistan.
C3 National University of Sciences & Technology - Pakistan
RP Arshad, R (corresponding author), Natl Univ Sci & Technol, Rawalpindi, Pakistan.
EM raziarshad@hotmail.com; nassar@nust.edu.pk
OI Arshad, Razi/0000-0003-3549-3418
CR [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], INT J NETW SECUR
   [Anonymous], SIP SECURIT IN PRESS
   [Anonymous], 2008, INT J NETW SECUR
   [Anonymous], SECURITY ME IN PRESS
   [Anonymous], INT J NETWORK SECURI
   [Anonymous], RFC3261 IETF
   [Anonymous], 2009, INT J NETW SECUR
   [Anonymous], RFC2617 IETF
   Damgard I., 1989, LECT NOTES COMPUTER, V435, P416, DOI DOI 10.1007/0-387-34805-039
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Durlanik A, 2005, PROC WRLD ACAD SCI E, V8, P350
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   HANDLEY M, 1999, RFC2543 IETF
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Lin CL, 2003, COMPUT SECUR, V22, P68, DOI 10.1016/S0167-4048(03)00114-7
   Salsano S, 2002, IEEE NETWORK, V16, P38, DOI 10.1109/MNET.2002.1081764
   Toorani M, 2009, IEEE SYMP COMP COMMU, P712
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yoon EJ, 2010, IETE TECH REV, V27, P203, DOI 10.4103/0256-4602.62780
   Yoon EJ, 2009, CISIS: 2009 INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, VOLS 1 AND 2, P549, DOI 10.1109/CISIS.2009.93
NR 21
TC 68
Z9 68
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 165
EP 178
DI 10.1007/s11042-011-0787-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000002
DA 2024-07-18
ER

PT J
AU Sabeti, V
   Samavi, S
   Shirani, S
AF Sabeti, Vajiheh
   Samavi, Shadrokh
   Shirani, Shahram
TI An adaptive LSB matching steganography based on octonary complexity
   measure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; Adaptive methods; LSB matching; Complexity
ID STEGANALYSIS; IMAGES
AB Adaptive steganography methods tend to increase the security against attacks. Most of adaptive methods use LSB flipping (LSB-F) for embedding part of their algorithms. LSB-F is very much vulnerable against simple steganalysis methods but it allows the adaptive algorithms to be extractable at the receiver side. Use of LSB matching (LSB-M) could increase the security but extraction of data at the receiver is difficult or, in occasions, impossible. There are numerous attacks against LSB-M. In this paper we are proposing an adaptive algorithm which, unlike most adaptive methods, uses LSB-M as its embedding method. The proposed method uses a complexity measure based on a local neighborhood analysis for determination of secure locations of an image. Comparable adaptive methods that use LSB-M suffer from possible changes in the complexity of pixels when embedding is performed. The proposed algorithm is such that when a pixel is categorized as complex at the transmitter and is embedded the receiver will identify it as complex too, and data is correctly retrieved. Better performance of the algorithm is shown by obtaining higher PSNR values for the embedded images with respect to comparable adaptive algorithms. The security of the algorithm against numerous attacks is shown to be higher than LSB-M. Also, it is compared with a recent adaptive method and is proved to be advantageous for most embedding rates.
C1 [Sabeti, Vajiheh; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, Shadrokh; Shirani, Shahram] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Samavi, S (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM samavi@mcmaster.ca
RI Sabeti, Vajiheh/AAD-1661-2022
OI Sabeti, Vajiheh/0000-0002-9985-9143
CR CANCELLI G, 2008, IEEE INT C IM PROC O
   Cancelli G, 2008, IEEE INT WORKSH MULT
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chen P, 2009, INT J APPL SCI ENG, P53
   Dumitrescu S, 2003, IEEE T SIGNAL PROCES, V51, P1995, DOI 10.1109/TSP.2003.812753
   GOLJAN M, 2006, P SPIE, V6072
   Harmsen JJ, 2003, PROC SPIE, V5020, P131, DOI 10.1117/12.476813
   Huang FJ, 2007, IEEE IMAGE PROC, P401
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Liu C, 2009, P IEEE ICIP
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Maniccam SS, 2004, PATTERN RECOGN, V37, P475, DOI 10.1016/j.patcog.2003.08.010
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Omoomi M, 2010, J MULTIMED TOOL APPL, V54, P201
   Sabeti V, 2010, PATTERN RECOGN, V43, P405, DOI 10.1016/j.patcog.2009.06.006
   Sabeti V, 2007, IEEE PACIF, P288
   Tzu-Chuen Lu, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P934, DOI 10.1109/SITIS.2007.60
   *USDA, 2002, NAT RES CONS SERV PH
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang J, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P385, DOI 10.1109/MMSP.2007.4412897
NR 22
TC 19
Z9 20
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 777
EP 793
DI 10.1007/s11042-011-0975-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600013
DA 2024-07-18
ER

PT J
AU Haque, MA
   Kim, JM
AF Haque, Mohammad A.
   Kim, Jong-Myon
TI An enhanced fuzzy c-means algorithm for audio segmentation and
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio segmentation and classification; Fuzzy c-means algorithm;
   Multimedia; Database retrieval
AB Automated audio segmentation and classification play important roles in multimedia content analysis. In this paper, we propose an enhanced approach, called the correlation intensive fuzzy c-means (CIFCM) algorithm, to audio segmentation and classification that is based on audio content analysis. While conventional methods work by considering the attributes of only the current frame or segment, the proposed CIFCM algorithm efficiently incorporates the influence of neighboring frames or segments in the audio stream. With this method, audio-cuts can be detected efficiently even when the signal contains audio effects such as fade-in, fade-out, and cross-fade. A number of audio features are analyzed in this paper to explore the differences between various types of audio data. The proposed CIFCM algorithm works by detecting the boundaries between different kinds of sounds and classifying them into clusters such as silence, speech, music, speech with music, and speech with noise. Our experimental results indicate that the proposed method outperforms the state-of-the-art FCM approach in terms of audio segmentation and classification.
C1 [Haque, Mohammad A.; Kim, Jong-Myon] Univ Ulsan, Sch Elect Engn, Ulsan 689749, South Korea.
C3 University of Ulsan
RP Kim, JM (corresponding author), Univ Ulsan, Sch Elect Engn, Ulsan 689749, South Korea.
EM jongmyon.kim@gmail.com
OI Haque, Mohammad Ahsanul/0000-0001-5613-2190
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2011-0017941]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MEST) (No. 2011-0017941)
CR Bezdek J., 2005, Fuzzy Models and Algorithms for Pattern Recognition and Image Processing
   Bezdek James C., 1981, PATTERN RECOGN
   Chen L, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P781, DOI 10.1109/ICME.2006.262954
   Fukuyama Y, 1989, 5 FUZZ SYST S, P247
   GANG C, 2005, WUHAN U J NAT SCI, V10, P833, DOI DOI 10.1007/BF02832422
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Liu Z, 1998, J VLSI SIG PROC SYST, V20, P61, DOI 10.1023/A:1008066223044
   Liu Z, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P27, DOI 10.1109/MMSP.1998.738908
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Nitanda N., 2006, Systems and Computers in Japan, V37, P23, DOI 10.1002/scj.20491
   PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225
   Park DC, 2005, LECT NOTES COMPUT SC, V3767, P698
   Park DC, 2006, LECT NOTES ARTIF INT, V4099, P1104, DOI 10.1007/978-3-540-36668-3_142
   Park DC, 2009, PATTERN RECOGN LETT, V30, P794, DOI 10.1016/j.patrec.2008.05.019
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Van Lung H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P409, DOI 10.1109/FUZZY.2009.5276878
   Wang JC, 2006, INT C PATT RECOG, P157
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 20
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 485
EP 500
DI 10.1007/s11042-011-0921-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200009
DA 2024-07-18
ER

PT J
AU Canini, L
   Benini, S
   Leonardi, R
AF Canini, Luca
   Benini, Sergio
   Leonardi, Riccardo
TI Classifying cinematographic shot types
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot type; Movie content; Feature extraction
ID SHAPE
AB In film-making, the distance from the camera to the subject greatly affects the narrative power of a shot. By the alternate use of Long shots, Medium and Close-ups the director is able to provide emphasis on key passages of the filmed scene. In this work we investigate five different inherent characteristics of single shots which contain indirect information about camera distance, without the need to recover the 3D structure of the scene. Specifically, 2D scene geometric composition, frame colour intensity properties, motion distribution, spectral amplitude and shot content are considered for classifying shots into three main categories. In the experimental phase, we demonstrate the validity of the framework and effectiveness of the proposed descriptors by classifying a significant dataset of movie shots using C4.5 Decision Trees and Support Vector Machines. After comparing the performance of the statistical classifiers using the combined descriptor set, we test the ability of each single feature in distinguishing shot types.
C1 [Canini, Luca; Benini, Sergio; Leonardi, Riccardo] Univ Brescia, Dept Informat Engn, Brescia, Italy.
   [Benini, Sergio] Univ Brescia, Telecommun Grp DII, Brescia, Italy.
C3 University of Brescia; University of Brescia
RP Canini, L (corresponding author), Univ Brescia, Dept Informat Engn, Brescia, Italy.
EM luca.canini@ing.unibs.it; sergio.benini@ing.unibs.it;
   riccardo.leonardi@ing.unibs.it
RI Leonardi, Riccardo/F-5666-2010
OI Leonardi, Riccardo/0000-0003-0755-1924
CR [Anonymous], 2009, Encyclopedia of Database Systems
   [Anonymous], 1991, Grammar of the film language
   BARROW HG, 1981, ARTIF INTELL, V17, P75, DOI 10.1016/0004-3702(81)90021-7
   Benini S, 2010, P IEEE INT C MULT EX
   Benini S, 2005, P CBMI RIG LATV
   Bordwell D., 1997, FILM ART INTRO
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Brooks M.J., 1989, Shape from shading
   Canini L, 2010, P 2010 EUR SIGN PROC
   Canini L, 2011, P 7 INT S IM SIGN PR
   Cantoni V., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P135
   Cherif I, 2007, P INT S SIGN PROC IT
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duan L.Y., 2002, Proc. ACM Multimedia, P419
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Ekin A, 2003, P ICIP 03 BARC SPAIN, P1025
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hoiem D., 2007, THESIS CARNEGIE MELL
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   KELLER JM, 1987, IEEE T PATTERN ANAL, V9, P621, DOI 10.1109/TPAMI.1987.4767956
   Kotsiantis SB, 2007, INFORMATICA, V31, P149
   KURITA T, 1992, PATTERN RECOGN, V25, P1231, DOI 10.1016/0031-3203(92)90024-D
   Matessi A, 1999, LECT NOTES COMPUT SC, V1685, P987
   MONACO J, 1981, READ FILM
   Nagai T, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P561
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Palmer S., 1999, VISION SCI PHOTONS P
   Porteous J, 2010, P ACM C MULT
   Quinlan J., 1994, The Morgan Kaufmann Series in Machine Learning, V16, P235
   Quinlan JR, 1996, J ARTIF INTELL RES, V4, P77, DOI 10.1613/jair.279
   Salt B, 2006, MOVING PICTURES MORE
   Shimshoni I, 2000, INT J COMPUT VISION, V39, P97, DOI 10.1023/A:1008118909580
   SUPER BJ, 1995, IEEE T PATTERN ANAL, V17, P333, DOI 10.1109/34.385983
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang HL, 2009, IEEE T CIRC SYST VID, V19, P1529, DOI 10.1109/TCSVT.2009.2022705
   Xie L, 2002, P ICASSP 02 ORL FLOR
   Zeng W, 2002, P ICIP ROCH US
NR 39
TC 20
Z9 21
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 51
EP 73
DI 10.1007/s11042-011-0916-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yong, SP
   Deng, JD
   Purvis, MK
AF Yong, Suet-Peng
   Deng, Jeremiah D.
   Purvis, Martin K.
TI Wildlife video key-frame extraction based on novelty detection in
   semantic context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-level features; Key-frame extraction; Co-occurrence matrix;
   Semantic context
ID MOTION; ABSTRACTION; FEATURES; COLOR
AB There is a growing evidence that visual saliency can be better modeled using top-down mechanisms that incorporate object semantics. This suggests a new direction for image and video analysis, where semantics extraction can be effectively utilized to improve video summarization, indexing and retrieval. This paper presents a framework that models semantic contexts for key-frame extraction. Semantic context of video frames is extracted and its sequential changes are monitored so that significant novelties are located using a one-class classifier. Working with wildlife video frames, the framework undergoes image segmentation, feature extraction and matching of image blocks, and then a co-occurrence matrix of semantic labels is constructed to represent the semantic context within the scene. Experiments show that our approach using high-level semantic modeling achieves better key-frame extraction as compared with its counterparts using low-level features.
C1 [Yong, Suet-Peng; Deng, Jeremiah D.; Purvis, Martin K.] Univ Otago, Dept Informat Sci, Dunedin 9054, New Zealand.
C3 University of Otago
RP Deng, JD (corresponding author), Univ Otago, Dept Informat Sci, POB 56, Dunedin 9054, New Zealand.
EM jeremiah.deng@otago.ac.nz
RI Yong, Suet-Peng/F-8067-2013; Deng, Jeremiah/A-1287-2008
OI Deng, Jeremiah/0000-0003-3727-4403
CR Benjamas N., 2005, International Symposium on Communications and Information Technologies 2005 (IEEE Cat. No.05EX1224), P441
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Du-Sik Park, 1999, Proceedings 10th International Conference on Image Analysis and Processing, P909, DOI 10.1109/ICIAP.1999.797711
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Gibson D, 2002, INT C PATT RECOG, P814, DOI 10.1109/ICPR.2002.1048427
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jing F, 2003, LECT NOTES COMPUT SC, V2728, P206
   Ju SX, 1998, IEEE T CIRC SYST VID, V8, P686, DOI 10.1109/76.718513
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Liu G., 2009, 2 S INT COMP SCI COM
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mukherjee DP, 2007, IEEE T CIRC SYST VID, V17, P612, DOI 10.1109/TCSVT.2007.895353
   Narasimha R, 2003, CONF REC ASILOMAR C, P1575
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Qing L., 2002, LECT NOTES COMPUTER, V2532, P39
   Shih HC, 2005, IEEE T BROADCAST, V51, P449, DOI 10.1109/TBC.2005.854169
   Spyrou E, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P98, DOI 10.1109/SMAP.2007.39
   Spyrou E, 2009, MULTIMED TOOLS APPL, V41, P337, DOI 10.1007/s11042-008-0237-9
   Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Yong SP, 2010, IEEE INT CON MULTI, P1254, DOI 10.1109/ICME.2010.5583899
   Zeng XL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1285, DOI 10.1109/ICME.2008.4607677
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 29
TC 27
Z9 33
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 359
EP 376
DI 10.1007/s11042-011-0902-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900004
DA 2024-07-18
ER

PT J
AU Simoens, P
   Joveski, B
   Gardenghi, L
   Marshall, IJ
   Vankeirsbilck, B
   Mitrea, M
   Prêteux, F
   De Turck, F
   Dhoedt, B
AF Simoens, Pieter
   Joveski, Bojan
   Gardenghi, Ludovico
   Marshall, Iain James
   Vankeirsbilck, Bert
   Mitrea, Miha
   Preteux, Francoise
   De Turck, Filip
   Dhoedt, Bart
TI Optimized mobile thin clients through a MPEG-4 BiFS semantic remote
   display framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thin client; Semantic remote display
ID USER EVENT; PERFORMANCE; SYSTEMS; LATENCY; WEB
AB According to the thin client computing principle, the user interface is physically separated from the application logic. In practice only a viewer component is executed on the client device, rendering the display updates received from the distant application server and capturing the user interaction. Existing remote display frameworks are not optimized to encode the complex scenes of modern applications, which are composed of objects with very diverse graphical characteristics. In order to tackle this challenge, we propose to transfer to the client, in addition to the binary encoded objects, semantic information about the characteristics of each object. Through this semantic knowledge, the client is enabled to react autonomously on user input and does not have to wait for the display update from the server. Resulting in a reduction of the interaction latency and a mitigation of the bursty remote display traffic pattern, the presented framework is of particular interest in a wireless context, where the bandwidth is limited and expensive. In this paper, we describe a generic architecture of a semantic remote display framework. Furthermore, we have developed a prototype using the MPEG-4 Binary Format for Scenes to convey the semantic information to the client. We experimentally compare the bandwidth consumption of MPEG-4 BiFS with existing, non-semantic, remote display frameworks. In a text editing scenario, we realize an average reduction of 23% of the data peaks that are observed in remote display protocol traffic.
C1 [Simoens, Pieter] HoGent, Dept INWE, B-9000 Ghent, Belgium.
   [Simoens, Pieter; Vankeirsbilck, Bert; De Turck, Filip; Dhoedt, Bart] Univ Ghent, IBBT, Dept INTEC, B-9050 Ghent, Belgium.
   [Joveski, Bojan; Gardenghi, Ludovico; Mitrea, Miha] Inst Telecom, ARTEMIS Dept, F-91000 Evry, France.
   [Marshall, Iain James] ZA Courtaboeuf, Prologue, F-91943 Les Ulis, France.
   [Preteux, Francoise] MINES ParisTech, F-75272 Paris 06, France.
C3 HOGENT University College of Applied Sciences & Arts; Ghent University;
   IMT - Institut Mines-Telecom; IMT Atlantique; Institut Polytechnique de
   Paris; Telecom SudParis; Universite PSL; MINES ParisTech
RP Simoens, P (corresponding author), HoGent, Dept INWE, Valentyn Vaerwyckweg 1, B-9000 Ghent, Belgium.
EM pieter.simoens@intec.ugent.be
RI Dhoedt, Bart AGMH/K-5851-2015
OI Dhoedt, Bart AGMH/0000-0002-7271-7479; Simoens,
   Pieter/0000-0002-9569-9373; De Turck, Filip/0000-0003-4824-1199;
   Vankeirsbilck, Bert/0000-0001-9489-8306
CR [Anonymous], 1449611 ISOIEC
   Balachandran K, 2009, BELL LABS TECH J, V13, P35, DOI 10.1002/bltj.20335
   Boukerche A, 2008, COMPUT COMMUN, V31, P2716, DOI 10.1016/j.comcom.2008.02.032
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Deboosere L., 2007, Third International Conference on Networking and Services. ICNS 2007, P230
   Descampe A, 2007, IEEE T IMAGE PROCESS, V16, P1339, DOI 10.1109/TIP.2007.894258
   Hua ZG, 2006, IEEE T MOBILE COMPUT, V5, P1650, DOI 10.1109/TMC.2006.182
   ISO/IEC, 2008, COD AUD VIS OBJ 20
   Jansen J, 2009, MULTIMED TOOLS APPL, V43, P203, DOI 10.1007/s11042-009-0270-3
   Joveski B, 2010, P 2 EUR WORKSH VIS I
   Joveski B, 2011, P MULT MOB DEV MULT
   Khin HS, 2007, LECT NOTES COMPUT SC, V4523, P818
   Kim HC, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P751
   Kohler E, 2000, ACM T COMPUT SYST, V18, P263, DOI 10.1145/354871.354874
   Koller D, 2004, ACM T GRAPHIC, V23, P695, DOI 10.1145/1015706.1015782
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Lethanhman C, 2009, P 3 INT C MOB UB COM
   *LIVE555, LIVE555 STREAM MED
   MicroSoft, REM DESKT PROT BAS C
   Mitrea M, 2009, P SPIE INT SOC OPTIC, V7444, P8
   Paravati G, 2010, IEEE T CONSUM ELECTR, V56, P190, DOI 10.1109/TCE.2010.5439144
   Pendyala VS, 2009, COMPUTER, V42, P90, DOI 10.1109/MC.2009.302
   Preda M, 2008, VISUAL COMPUT, V24, P881, DOI 10.1007/s00371-008-0284-2
   RealVNC, VIRT NETW COMP
   Richardson T, 1998, IEEE INTERNET COMPUT, V2, P33, DOI 10.1109/4236.656066
   Sandklef H, 2004, LINUX J, V117, P87
   Schlosser D, 2010, ICC 2010 2010 IEEE I
   Schlosser D, 2007, 2007 AUSTRALASIANTELECOMMUNICATION NETWORKS AND APPLICATIONS CONFERENCE, P223
   Signès J, 2000, SIGNAL PROCESS-IMAGE, V15, P321, DOI 10.1016/S0923-5965(99)00052-1
   Simoens P, 2011, INT J COMMUN SYST, V24, P666, DOI 10.1002/dac.1188
   Simoens P, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P391, DOI 10.1109/ATNAC.2008.4783356
   Sun Y, 2008, J PARALLEL DISTR COM, V68, P1463, DOI 10.1016/j.jpdc.2008.05.007
   Tan KJ, 2010, IEEE INT CON MULTI, P992, DOI 10.1109/ICME.2010.5582993
   Tolia N, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.101
   Wang F, 2008, IEEE COMMUN MAG, V46, P41, DOI 10.1109/MCOM.2008.4644118
   Wellnitz Oliver, 2010, 2010 5th International Symposium on Wireless Pervasive Computing (ISWPC), P261, DOI 10.1109/ISWPC.2010.5483719
NR 36
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 2
BP 447
EP 470
DI 10.1007/s11042-011-0849-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 985MK
UT WOS:000307270600008
DA 2024-07-18
ER

PT J
AU Li, ZR
   Wong, KH
   Gong, YB
   Chang, MMY
AF Li, Zhaorong
   Wong, Kin-Hong
   Gong, Yibo
   Chang, Michael Ming-Yuen
TI A low-cost projector-based hand-held flexible display system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flexible display; Interactive display system; Multi-view reconstruction;
   3D non-rigid surface tracking
AB In this paper, we propose a low-cost hand-held flexible display system which uses a projector to project display content onto an ordinary white paper that can be twisted freely. The ultimate goal is to develop an interactive viewing tool for displaying content on flexible surface that can be deformed by the user, i.e., when the user twists the paper, the display content on the paper deforms simultaneously. This system has a lot of potential in the entertainment and education industries. A pair of cameras is employed to track the pattern printed on the back of paper. The cameras and the projector are calibrated off-line via a simple and convenient method. A real-time algorithm is proposed to recover the 3D surface of the paper. The display content is then pre-warped according to the recovered surface and projected onto the front of the paper. Two demonstrative applications are elaborated to illustrate the potential of the proposed system. Our system is easy to set up and runs in real-time. Experimental results show that the flexible display is created with satisfactory accuracy and robustness.
C1 [Li, Zhaorong; Wong, Kin-Hong; Gong, Yibo] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Chang, Michael Ming-Yuen] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong; Chinese University of Hong Kong
RP Li, ZR (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
EM zrli@cse.cuhk.edu.hk; khwong@cse.cuhk.edu.hk; ybgong@cse.cuhk.edu.hk;
   mchang@ie.cuhk.edu.hk
CR Bouguet J.Y, Pyramidal Implementation of the Lucas Kanade Feature Tracker -Description of the Algorithm
   Bregler C, P INT C COMP VIS PAT
   Cassinelli A., 2009, SIGGRAPH ASIA 2009 E, P88, DOI 10.1145/1665137.1665207
   Ilic S, 2006, IEEE T PATTERN ANAL, V28, P328, DOI 10.1109/TPAMI.2006.37
   *INT, OPENCV
   Konieczny J, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P591
   Lee JC, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P287
   Leung MC, 2009, P INT C COMP VIS PAT
   Raskar R, 2001, SPRING EUROGRAP, P89
   Raskar R, 2005, INT S SOC INF DIS SI
   Salzmann M., 2007, P INT C COMP VIS
   Salzmann M, 2007, IEEE T PATTERN ANAL, V29, P1481, DOI 10.1109/TPAMI.2007.1080
   SUKTHANKAR R, 2001, P INT C COMP VIS
   Summet J, 2005, LECT NOTES COMPUT SC, V3468, P37
   Xiao J, 2004, P INT C COMP VIS PAT
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   LEVMAR LEVENBERG MAR
NR 17
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 129
EP 148
DI 10.1007/s11042-010-0692-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800008
DA 2024-07-18
ER

PT J
AU Jang, IY
   Cho, JH
   Lee, KH
AF Jang, In Yeop
   Cho, Ji-Ho
   Lee, Kwan H.
TI 3D human modeling from a single depth image dealing with self-occlusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image; Human modeling; Self-occlusion
ID TRACKING; VIDEO; PEOPLE
AB This paper presents a 2D to 3D conversion scheme to generate a 3D human model using a single depth image with several color images. In building a complete 3D model, no prior knowledge such as a pre-computed scene structure and photometric and geometric calibrations is required since the depth camera can directly acquire the calibrated geometric and color information in real time. The proposed method deals with a self-occlusion problem which often occurs in images captured by a monocular camera. When an image is obtained from a fixed view, it may not have data for a certain part of an object due to occlusion. The proposed method consists of following steps to resolve this problem. First, the noise in a depth image is reduced by using a series of image processing techniques. Second, a 3D mesh surface is constructed using the proposed depth image-based modeling method. Third, the occlusion problem is resolved by removing the unwanted triangles in the occlusion region and filling the corresponding hole. Finally, textures are extracted and mapped to the 3D surface of the model to provide photo-realistic appearance. Comparison results with the related work demonstrate the efficiency of our method in terms of visual quality and computation time. It can be utilized in creating 3D human models in many 3D applications.
C1 [Jang, In Yeop; Cho, Ji-Ho; Lee, Kwan H.] Gwangju Inst Sci & Technol GIST, Dept Mechatron 213, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Lee, KH (corresponding author), Gwangju Inst Sci & Technol GIST, Dept Mechatron 213, 216 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM inyeop@gist.ac.kr; khlee@gist.ac.kr
FU MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) [NIPA-2010-(C1090-1011-0003)];
   National Research Foundation of Korea (NRF); Korea government (MEST)
   [20100018897]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency) (NIPA-2010-(C1090-1011-0003)) and also by the National Research
   Foundation of Korea (NRF) grant funded by the Korea government (MEST)
   (No. 20100018897).
CR Ahad Md Atiqur Rahman, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P201, DOI 10.1109/ICCITECHN.2008.4803095
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Bhasin SS, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P488, DOI 10.1109/ICCV.2001.937556
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   D'Apuzzo N., 1999, P SPIES ELECT IMAGIN, V3641, P36
   Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340
   Domiter V., 2004, P 8 CENTR EUR SEM CO, P105
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Guan L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P413
   Hilsmann Anna, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563081
   Hilton A, 1999, COMP ANIM CONF PROC, P174, DOI 10.1109/CA.1999.781210
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   Kim SM, 2006, IEICE T INF SYST, VE89D, P37, DOI 10.1093/ietisy/e89-d.1.37
   Liepa P., 2003, Symposium on Geometry Processing, P200
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park JC, 2006, LECT NOTES COMPUT SC, V4261, P770
   Peng E, 2004, P COMP VIS GRAPH INT, P1018
   Plänkers R, 2001, COMPUT VIS IMAGE UND, V81, P285, DOI 10.1006/cviu.2000.0891
   Remondino F, 2003, P 4 INT C 3 D DIG IM, P79
   Sappa A, 2003, P IEEE INT C IM PROC
   Schmaltz C, 2008, LECT NOTES COMPUT SC, V5098, P102, DOI 10.1007/978-3-540-70517-8_11
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
NR 25
TC 6
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 267
EP 288
DI 10.1007/s11042-010-0719-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600011
DA 2024-07-18
ER

PT J
AU Ahmad, I
   Gabbouj, M
AF Ahmad, Iftikhar
   Gabbouj, Moncef
TI A generic content-based image retrieval framework for mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based; Retrieval; Mobile
AB Multimedia mobile devices have created new possibilities for developing and accessing a variety of multimedia items such as images, audio and video clips. Personal multimedia items are, nowadays, being consumed at an enormous rate. Therefore, the management of these media items has become a pressing problem. In this paper, a client-server content-based image retrieval framework for mobile platforms is developed, which provides the capability of content-based query and browsing from mobile devices. The proposed framework provides an adaptive user interface and a generic structure, which supports a wide range of mobile devices. In this framework, a client requests the server for retrieval of particular images with a particular content. The server performs a content-based retrieval of images from a selected database and streams the retrieved results back to the client in an efficient way. The query results are transmitted over a wireless network and a certain number of similar images are rendered on the mobile device screen using thumbnail sizes. The proposed framework serves as a basis of content-based image retrieval on mobile devices. It addresses several important challenges such as hardware and software limitations as well as efficient use of the available network bandwidth.
C1 [Ahmad, Iftikhar] Nokia Electr Ltd, Tampere 33720, Finland.
   [Ahmad, Iftikhar] Nokia Electr Ltd, Tampere 33721, Finland.
   [Gabbouj, Moncef] Tampere Univ Technol, Inst Signal Proc, Dept Signal Proc, FIN-33101 Tampere, Finland.
C3 Nokia Corporation; Nokia Finland; Nokia Corporation; Nokia Finland;
   Tampere University
RP Ahmad, I (corresponding author), Nokia Electr Ltd, Hermiankatu 12, Tampere 33720, Finland.
EM iftikhar.ahmad@nokia.com; moncef.gabbouj@tut.fi
RI Ahmad, Mirza Iftikhar/KHD-2053-2024; Gabbouj, Moncef/G-4293-2014; Ahmad,
   iftikhar/I-6826-2015
OI Gabbouj, Moncef/0000-0002-9788-2323; 
CR AHMAD I, 2005, MMSP 05 INT WORKSH M
   [Anonymous], Markup
   Arreymbi J, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P622, DOI 10.1109/IV.2002.1028839
   BOLL S, 2003, P 2003 ACM SIGMM WOR, P21
   CHANDRASEKHARAN P, 2002, P MOB DAT MAN C SING
   Chopra V., 2004, Professional Apache Tomcat 5
   DEITEL HM, 1999, JAVA PROGRAM
   GANDHI B, 2004, MULT EXP 2004 ICME 0, V3, P1703
   GULDOGAN O, 2005, EUR SIGN PROC C EUSI
   KEOGH J, 2003, COMPLETE REFERECE J2
   Kim CY, 2004, IEEE INTELL SYST, V19, P32
   KIRANYAZ S, 2006, P WIAMIS WORKSH 2006
   Kiranyaz S, 2007, IEEE T MULTIMEDIA, V9, P102, DOI 10.1109/TMM.2006.886362
   KURZ B, 2004, COMM NETW SERV RES C
   LI S, 1999, PROFESSIONAL JAVA SE
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MANJUNATH BS, INTRO MPEG 7 MULT CO
   Partio M., 2002, P 5 NORD SIGN PROC S
   PENTLAND A, 1994, P SPIE STOR RETR IM
   PHAM B, 2004, P 2 INT C COMP GRAPH, P123
   ROTH V, 1999, ASAMA 99 P 1 INT S A, P260
   Sarvas Risto., 2004, P 2 INT C MOBILE SYS, P36
   Sarvas Risto., 2004, P 12 ANN ACM INT C M, P724
   SMITH JR, 1996, ACM MULTIMEDIA B NOV
   SORVARI A, 2004, USABILITY ISSUES UTI
   TOLLMAR K, 2004, IDEIXIS IMAGE BASED, P781
   Wong Clinton., 2000, Http Pocket Reference
NR 27
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 423
EP 442
DI 10.1007/s11042-010-0556-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600004
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Chang, WH
   Fang, MY
   Lin, CH
AF Kuo, Chung-Ming
   Chang, Wei-Han
   Fang, Min-Yuan
   Lin, Ching-Hsuan
TI A template-based baseball video scene classification using efficient
   playfield segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene classification; Baseball video; Key-frame; Playfield segmentation
ID SOCCER VIDEO; REPRESENTATION
AB In this paper, we present an effective and efficient framework for baseball video scene classification. The results of scene classification can be able to provide the ground for baseball video abstraction and high-level event extraction. In general, most conventional approaches are shot-based, which shot change detection and key-frame extraction are necessary prerequisite procedures. On the contrary, we propose a frame-based approach. In our scene classification framework, an efficient playfield segmentation technique is proposed, and then the reduced field maps are utilized as scene templates. Because the shot change detection and the key-frame extraction are not required in proposed method, the new framework is very simple and efficient. The experimental results have demonstrated that the effectiveness of our proposed framework for baseball videos scene classification, and it can be easily extended the template-based approach to other kinds of sports videos.
C1 [Kuo, Chung-Ming; Fang, Min-Yuan; Lin, Ching-Hsuan] I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
   [Chang, Wei-Han] Fortune Inst Technol, Dept Informat Management, Daliao Township 831, Kaohsiung Cty, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
RI Lin, Ching-Hsuan/AAQ-2840-2020
FU National Science Counsel of Republic of China [NSC 98-2221-E-214-054-]
FX The authors would like to express their sincere thanks to the anonymous
   reviewers for their invaluable comments and suggestions. This work was
   supported by the National Science Counsel of Republic of China Granted
   NSC 98-2221-E-214-054-
CR Barnard M, 2004, INT C PATT RECOG, P610, DOI 10.1109/ICPR.2004.1334603
   BUZO A, 1980, IEEE T ACOUST SPEECH, V28, P562, DOI 10.1109/TASSP.1980.1163445
   Chen HT, 2008, IEEE INT SYMP CIRC S, P3522, DOI 10.1109/ISCAS.2008.4542219
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   CHU WT, 2006, MULTIMEDIA MODELLING
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Foley J.D., 1990, Computer graphics: Principles and practice
   Giakoumis I, 2006, IEEE T IMAGE PROCESS, V15, P178, DOI 10.1109/TIP.2005.860311
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Heikkilä J, 2004, IMAGE VISION COMPUT, V22, P563, DOI 10.1016/j.imavis.2003.09.010
   HUA W, 2002, MULTIMEDIA EXPO 2002, V1, P821
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   HUANG YR, 2004, P INT COMP S TAIP TA, P777
   HUNG MH, 2005, IEEE INT C SYST SIGN, P254
   JIAN JL, 2005, 18 IPPR C COMP VIS G, P115
   Kangas J A, 1990, IEEE Trans Neural Netw, V1, P93, DOI 10.1109/72.80208
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   LU H, 2003, CIRCUITS SYSTEMS, V2, P680
   Montoya MDG, 2003, J PARALLEL DISTR COM, V63, P387, DOI 10.1016/S0743-7315(03)00039-X
   PEI SC, 2003, 16 IPPR C COMP VIS G, P210
   Sze KW, 2005, IEEE T CIRC SYST VID, V15, P1148, DOI 10.1109/TCSVT.2005.852623
   WANG L, 2004, ACOUSTICS SPEECH SIG, V3, P617
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhu SH, 2009, MULTIMED TOOLS APPL, V42, P183, DOI 10.1007/s11042-008-0233-0
NR 30
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 399
EP 422
DI 10.1007/s11042-010-0555-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600003
DA 2024-07-18
ER

PT J
AU Krishnamoorthy, P
   Kumar, S
AF Krishnamoorthy, P.
   Kumar, Sarvesh
TI Hierarchical audio content classification system using an optimal
   feature selection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio classification; Audio content analysis; General genre video
ID SEGMENTATION; SPEECH
AB This paper proposes a hierarchical time-efficient method for audio classification and also presents an automatic procedure to select the best set of features for audio classification using Kolmogorov-Smirnov test (KS-test). The main motivation for our study is to propose a framework of general genre (e.g., action, comedy, drama, documentary, musical, etc...) movie video abstraction scheme for embedded devices-based only on the audio component. Accordingly simple audio features are extracted to ensure the feasibility of real-time processing. Five audio classes are considered in this paper: pure speech, pure music or songs, speech with background music, environmental noise and silence. Audio classification is processed in three stages, (i) silence or environmental noise detection, (ii) speech and non-speech classification and (iii) pure music or songs and speech with background music classification. The proposed system has been tested on various real time audio sources extracted from movies and TV programs. Our experiments in the context of real time processing have shown the algorithms produce very satisfactory results.
C1 [Krishnamoorthy, P.; Kumar, Sarvesh] Samsung India Software Ctr, R&D Ctr, Noida, India.
C3 Samsung
RP Krishnamoorthy, P (corresponding author), Samsung India Software Ctr, R&D Ctr, Noida, India.
EM krishna.m1@samsung.com; k.sarvesh@samsung.com
RI P, Krishnamoorthy/A-2289-2009
CR Alatan AA, 2001, MULTIMED TOOLS APPL, V14, P137, DOI 10.1023/A:1011395131992
   Bugatti A, 2002, EURASIP J APPL SIG P, V2002, P372, DOI 10.1155/S1110865702000720
   Burred JJ, 2004, J AUDIO ENG SOC, V52, P724
   CASAGR N, 2005, P INT COMP MUS C ICM
   Chu W, 2008, IEEE T AUDIO SPEECH, V16, P137, DOI 10.1109/TASL.2007.907569
   HUANG LS, 2000, P 2000 INT C AC SPEE, V3, P1751
   Khan MKS, 2006, MULTIMEDIA SYST, V12, P55, DOI 10.1007/s00530-006-0034-0
   Krishnapuram B, 2004, IEEE T PATTERN ANAL, V26, P1105, DOI 10.1109/TPAMI.2004.55
   Lavner Y, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/239892
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Lopes R.H.C., 2007, International Workshop on Advanced Computing and Analysis Techniques in Physics Research, P1
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Lu Lie., 2001, Proceedings of the ninth ACM international conference on Multimedia, P203
   MAHALE P, 2008, 3 INT C INF COMM TEC, P1
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Pachet F, 2007, INT WORK CONTENT MUL, P227, DOI 10.1109/CBMI.2007.385416
   Pachet F, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/153017
   Panagiotakis C, 2005, IEEE T MULTIMEDIA, V7, P155, DOI 10.1109/TMM.2004.840604
   Pikrakis A, 2008, IEEE T MULTIMEDIA, V10, P846, DOI 10.1109/TMM.2008.922870
   Ruvolo P, 2010, PATTERN RECOGN LETT, V31, P1535, DOI 10.1016/j.patrec.2009.12.036
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Song JH, 2008, IEEE SIGNAL PROC LET, V15, P103, DOI 10.1109/LSP.2007.911184
   Wang KS, 1994, IEEE T SPEECH AUDI P, V2, P421, DOI 10.1109/89.294356
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 27
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 415
EP 444
DI 10.1007/s11042-010-0546-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700011
DA 2024-07-18
ER

PT J
AU Schmidt, TC
   Hege, G
   Wählisch, M
   Cycon, HL
   Palkow, M
   Marpe, D
AF Schmidt, Thomas C.
   Hege, Gabriel
   Waehlisch, Matthias
   Cycon, Hans L.
   Palkow, Mark
   Marpe, Detlev
TI Distributed SIP conference management with autonomously authenticated
   sources and its application to an H.264 videoconferencing software for
   mobiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Conference on Advances in Mobile Computing and Multimedia
CY NOV 24-26, 2008
CL Linz, AUSTRIA
SP ACM SIGMM
DE SIP-based multimedia conferencing; Distributed conference management;
   P2P group communication; Sender authentication; Cryptographically
   generated identifiers; Mobile videoconferencing; Mobile video coding
ID SERVICES
AB The design of conferencing systems for achieving efficient and flexible communication in a fully distributed, infrastructure-independent fashion is a promising direction, both in terms of research and practical development. In the particular case of video communication, the seamless adaptation to heterogeneous mobile devices poses an additional strong challenge to those seeking for interoperable and easy-to-deploy solutions. In this paper, we make several contributions towards a generic peer-to-peer (P2P) videoconferencing solution that extends into the mobile realm. We describe the essential building blocks for conference management and media distribution that are necessary for a distributed conferencing approach. Establishing a distributed SIP conference focus, participants share the conference according to their individually given capabilities and resources in terms of bandwidth and processing power rather than in a centralized and fixed way. Overall concepts and SIP-primitives for such an autonomous organization are presented. Security issues that derive from this decentralized identity management are resolved by so-called Overlay AuthoCast, a novel use of cryptographically generated identifiers. Furthermore, this work is dedicated to the development of a software-based H.264 video codec implementation and the specific aspects resulting from tuning such a highly resource-intensive software codec to the given target platform of a standard consumer smartphone.
C1 [Schmidt, Thomas C.; Hege, Gabriel; Waehlisch, Matthias] HAW Hamburg, Dept Informat, D-20099 Hamburg, Germany.
   [Waehlisch, Matthias] Free Univ Berlin, Inst Informat, D-14195 Berlin, Germany.
   [Cycon, Hans L.] HTW Berlin, D-10315 Berlin, Germany.
   [Palkow, Mark] Daviko GmbH, D-13507 Berlin, Germany.
   [Marpe, Detlev] Heinrich Hertz Inst Nachrichtentech Berlin GmbH, Fraunhofer Inst Telecommun, D-10587 Berlin, Germany.
C3 Hochschule Angewandte Wissenschaft Hamburg; Free University of Berlin;
   Fraunhofer Gesellschaft
RP Schmidt, TC (corresponding author), HAW Hamburg, Dept Informat, Berliner Tor 7, D-20099 Hamburg, Germany.
EM t.schmidt@ieee.org; hege@fhtw-berlin.de; waehlisch@ieee.org;
   h.cycon@htw-berlin.de; palkow@daviko.com; marpe@hhi.fraunhofer.de
RI Wählisch, Matthias/HLG-5906-2023
OI Wählisch, Matthias/0000-0002-3825-2807; Schmidt, Thomas
   C./0000-0002-0956-7885
CR [Anonymous], RFC
   [Anonymous], SIP HDB SERVICES TEC
   AURA T, 2005, RFC, V3972
   Basso A, 2006, MULTIMED TOOLS APPL, V28, P173, DOI 10.1007/s11042-006-6141-2
   BAUMGART I, 2007, INTERNET DRAFT WORK
   BRYAN D, 2008, INTERNET DRAFT WORK, V2
   Cho YH, 2005, IEEE J SEL AREA COMM, V23, P1934, DOI 10.1109/JSAC.2005.854120
   Chopra D, 2009, IEEE COMMUN SURV TUT, V11, P4, DOI 10.1109/SURV.2009.090102
   CYCON HL, 2008, 9 IEEE INT S WORLD W, P1
   Durresi A, 2008, MOB INF SYST, V4, P119, DOI 10.1155/2008/135848
   Faichney J, 2001, MULTIMED TOOLS APPL, V13, P165, DOI 10.1023/A:1009689110306
   Gehlen G, 2007, MOB INF SYST, V3, P165, DOI 10.1155/2007/427831
   *ITU T, 2005, 264 ITUT
   ITUT R, 2000, 323 ITUT
   JENNINGS C, 2008, INTERNET DRAFT WORK
   JOHNSTON A, 2006, RFC, V4579
   MAHY R, 2008, INTERNET DRAFT WORK, V10
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   PALKOW M, 2009, DAVIKO HOMEPAGE
   Prasad R, 2003, IEEE NETWORK, V17, P27, DOI 10.1109/MNET.2003.1248658
   ROMANO S, 2008, INTERNET DRAFT WORK, V4
   Rosenberg J., 2002, RFC, V3261
   ROSENBERG J, 2002, RFC, V3264
   ROSENBERG J, 2006, RFC, V4575
   SCHMIDT T., 2010, Multicast Mobility in Mobile IP Version 6 (MIPv6) : Problem Statement and Brief Survey
   Schmidt TC, 2008, SECUR COMMUN NETW, V1, P495, DOI 10.1002/sec.86
   Schneier B., 1995, APPL CRYPTOGRAPHY, V2nd
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seedorf J., 2006, 3 ANN VOIP SEC WORKS
   Steinmetz R., 2005, LNCS, V3485
   *VIDEOLAN, 2009, X264 FREE H264 AVC E
   WAHLISCH M, 2009, P 28 IEEE INFOCOM IE
   WAHLISCH M, 2009, P 34 IEEE C LOC COMP, P372
   2009, SPEEX PROJECTPAGE
   2009, SKYPE HOMEPAGE
NR 35
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2011
VL 53
IS 2
BP 349
EP 370
DI 10.1007/s11042-010-0500-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 753BS
UT WOS:000289739800002
DA 2024-07-18
ER

PT J
AU Liu, HM
   Yao, XZ
   Huang, JW
AF Liu, Hongmei
   Yao, Xinzhi
   Huang, Jiwu
TI Minority codes with improved embedding efficiency for large payloads
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Embedding efficiency; Payload; Minority codes
ID COPYRIGHT PROTECTION
AB Improving embedding efficiency is important for watermarking with large payloads. In this paper, we propose a coding scheme named Minority codes by observing the relationship between the populations and positions of the binary bits in a sequence whose length is an odd number. In such a sequence, there is always a bit value, whose population is minority. We observe that the positions of the minority bit in two complement sequences are the same. By using this property, we create Minority codes whose codebook is composed of a pair of complement sequences for each entry. Minority codes can be combined with watermarking algorithms to improve embedding efficiency, because we can always identify the codeword that causes fewer embedding changes according to the host image and the watermarking method. The performance of Minority codes is analyzed theoretically and supported experimentally. The complexity of Minority codes is quite low and suitable for large payloads.
C1 [Liu, Hongmei; Huang, Jiwu] Sun Yat Sen Univ, Dept Elect & Commun, Guangzhou 510275, Guangdong, Peoples R China.
   [Yao, Xinzhi] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Sun Yat Sen University; University of Hong Kong
RP Liu, HM (corresponding author), Sun Yat Sen Univ, Dept Elect & Commun, Guangzhou 510275, Guangdong, Peoples R China.
EM isslhm@mail.sysu.edu.cn; xzyao@eee.hku.hk; isshjw@mail.sysu.edu.cn
RI huang, jw/KVY-9917-2024
FU NSFC [60633030]; GDIID [2006CB303104, GDIID 200815046]; GDSTC
   [2009B090300345]
FX This work was supported by NSFC under Grants 60633030, 973 Program under
   Grant 2006CB303104 GDIID Program under Grant GDIID 200815046 and GDSTC
   program under Grant 2009B090300345.
CR [Anonymous], IEEE INT C MULT EXP
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Galand F, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P151, DOI 10.1109/ITW.2003.1216717
   GOU H, 2007, P IEEE INT C IM PROC, P277
   Huang HC, 2009, SOFT COMPUT, V13, P383, DOI 10.1007/s00500-008-0326-8
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Johnson N.F., 2001, Information Hiding: Steganography and Watermarking-Attacks and Countermeasures: Steganography and Watermarking: Attacks and Countermeasures, V1
   Lu H., 2003, P 2003 INT S CIRC SY, V3, P806
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Van Dijk M., 2001, P 22 S INF COMM THEO, P147
   WESTFELD, 2001, LECT NOTES COMPUT SC, V2137, P289
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   YANG H, 2007, IEEE T MULTIMEDIA, V9
NR 15
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 431
EP 443
DI 10.1007/s11042-009-0431-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000011
DA 2024-07-18
ER

PT J
AU Zhao, H
   Wang, HX
   Khan, MK
AF Zhao, Hong
   Wang, Hongxia
   Khan, Muhammad Khurram
TI Statistical analysis of several reversible data hiding algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Detectability; Statistical distribution models
   of difference
ID DIFFERENCE EXPANSION; WATERMARKING
AB In this paper, the truth that the current reversible data hiding algorithms are detectable is confirmed by experimental analysis method. By analyzing the distributions of horizontal pixel difference of natural images and watermarked images using several models, we find that the horizontal difference histogram of natural image is significantly altered after being embedded secret message. Furthermore, the difference between the horizontal and the vertical difference histogram of natural image is much less than that of the watermarked image. Then the presence of hiding message can be detected according to the distance between the horizontal and the vertical difference histogram. Experimental results demonstrate that our approach is effective and efficient than the already published schemes.
C1 [Zhao, Hong; Wang, Hongxia] SW Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
C3 Southwest Jiaotong University; King Saud University
RP Zhao, H (corresponding author), SW Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
EM zh1985444@hotmail.com
RI KHAN, MUHAMMAD KHURRAM/E-4836-2014; Khan, Muhammad/IXN-8470-2023; Wang,
   Hongxia/AAE-2135-2022; Nusa, Nuhammad/JXY-5819-2024
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; 
FU National Natural Science Foundation of China (NSFC) [60702025]; Research
   Foundation for Doctoral Program of Higher Education (RFDP)
   [20070613024]; Sichuan Youth Science & Technology Foundation of China
   [07ZQ026-004]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) under grant No. 60702025, the Research Foundation for Doctoral
   Program of Higher Education (RFDP) under grant No. 20070613024, Sichuan
   Youth Science & Technology Foundation of China under grant No.
   07ZQ026-004.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   GOLJAN M, 2006, SECURITY STEGANOGR 8, V6072
   Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579
   He JH, 2006, SCI CHINA SER F, V49, P273, DOI 10.1007/s11432-006-0273-x
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
NR 17
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 277
EP 290
DI 10.1007/s11042-009-0380-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000003
DA 2024-07-18
ER

PT J
AU Bhatt, CA
   Kankanhalli, MS
AF Bhatt, Chidansh Amitkumar
   Kankanhalli, Mohan S.
TI Multimedia data mining: state of the art and challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Survey; Multimodal data mining; Probabilistic temporal multimedia data
   mining; Video mining; Audio mining; Image mining; Text mining
ID EVENT DETECTION; AUDIO CLASSIFICATION; RETRIEVAL; MODEL
AB Advances in multimedia data acquisition and storage technology have led to the growth of very large multimedia databases. Analyzing this huge amount of multimedia data to discover useful knowledge is a challenging problem. This challenge has opened the opportunity for research in Multimedia Data Mining (MDM). Multimedia data mining can be defined as the process of finding interesting patterns from media data such as audio, video, image and text that are not ordinarily accessible by basic queries and associated results. The motivation for doing MDM is to use the discovered patterns to improve decision making. MDM has therefore attracted significant research efforts in developing methods and tools to organize, manage, search and perform domain specific tasks for data from domains such as surveillance, meetings, broadcast news, sports, archives, movies, medical data, as well as personal and online media collections. This paper presents a survey on the problems and solutions in Multimedia Data Mining, approached from the following angles: feature extraction, transformation and representation techniques, data mining techniques, and current multimedia data mining systems in various application domains. We discuss main aspects of feature extraction, transformation and representation techniques. These aspects are: level of feature extraction, feature fusion, features synchronization, feature correlation discovery and accurate representation of multimedia data. Comparison of MDM techniques with state of the art video processing, audio processing and image processing techniques is also provided. Similarly, we compare MDM techniques with the state of the art data mining techniques involving clustering, classification, sequence pattern mining, association rule mining and visualization. We review current multimedia data mining systems in detail, grouping them according to problem formulations and approaches. The review includes supervised and unsupervised discovery of events and actions from one or more continuous sequences. We also do a detailed analysis to understand what has been achieved and what are the remaining gaps where future research efforts could be focussed. We then conclude this survey with a look at open research directions.
C1 [Bhatt, Chidansh Amitkumar; Kankanhalli, Mohan S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 National University of Singapore
RP Bhatt, CA (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
EM chidansh@comp.nus.edu.sg; mohan@comp.nus.edu.sg
RI chen, mingang/C-7691-2011; Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   AGRAWAL R, 1995, INT C DAT ENG
   AJMERA J, 2002, IEEE INT C AC SPEECH, P1746
   [Anonymous], INT J COMPUTER SCI I
   Aradhye H, 2009, INT CONF DAT MIN WOR, P144, DOI 10.1109/ICDMW.2009.79
   Artigan J., 1975, CLUSTERING ALGORITHM
   BAILLIE M, 2004, WORKSH EV MIN DET RE
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   BENITEZ AB, 2000, MULTIMEDIA INFORM NE
   Box GE, 1994, TIME SERIES ANAL FOR
   Briggs F, 2009, IEEE DATA MINING, P51, DOI 10.1109/ICDM.2009.65
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   CHANG E, 1999, SPIE MULTIMEDIA STOR, V6
   Chen M, 2006, IEEE SIGNAL PROC MAG, V23, P38, DOI 10.1109/MSP.2006.1621447
   Chen M., 2007, Multimedia databases and data management
   Chen SC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P265, DOI 10.1109/ICME.2004.1394176
   CHEN SC, 2001, ACM SIGKDD
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   DAI K, 2006, MULTIMEDIA MODELLING
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   DIMITRIADIS D, 2003, EUR C SPEECH COMM TE
   Duda R. O., 2001, PATTERN CLASSIFICATI
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   ELLOM BL, 1998, SPEECH COMMUN, V25, P97
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   Fersini E, 2009, LECT NOTES ARTIF INT, V5632, P594, DOI 10.1007/978-3-642-03070-3_45
   Foote JT, 1997, P SOC PHOTO-OPT INS, V3229, P138, DOI 10.1117/12.290336
   Forsati R, 2010, STUD COMPUT INTELL, V270, P51
   Frakes WB., 1992, Information retrieval: Data structures and algorithms
   FRIGUI H, 2007, SIAM INT C DAT MIN
   FU CS, 1998, IEEE T CIRCUITS SYST, V8, P602
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Gajic B, 2001, INT CONF ACOUST SPEE, P85, DOI 10.1109/ICASSP.2001.940773
   GAO J, 2009, INT C WEB INF SYST M, P116
   GAO Y, 2006, ACM MIR
   GARNER PN, 2004, ICASSP 2004, V1, P597
   GHITZA O, 1987, COMPUTER SPEECH LANG, V2, P109
   Goh KS, 2004, P SOC PHOTO-OPT INS, V5307, P292
   Gold Ben., 2000, SPEECH AUDIO SIGNAL
   GOOL LV, 2009, ACM INT C IM VID RET, P1
   GORKANI MM, 1994, IEEE C PATT REC
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   GUO Z, 2007, ACM INT C KNOWL DISC
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   HAN J, 2000, SIGKDD EXPLORATIONS, V2, P14
   Han J., 2006, DATA MINING CONCEPTS
   HARB H, 2001, INT C DISTR MULT SYS, P257
   HE R, 2010, INT C INF FUS
   HE R, 2009, AS PAC C COMP INT IN
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   HERMANSKY H, 1998, INT C SPEECH LANG PR
   HERMANSKY H, 1987, INT C AC SPEECH SIGN, P1156
   HERMANSKY H, 1991, EUR C SPEECH COMM TE, P578
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Hipp J, 2000, ACM Sigkdd Explorations Newsletter, V2, P58, DOI DOI 10.1145/360402.360421
   Hsu WM, 2002, J INTELL INF SYST, V19, P7, DOI 10.1023/A:1015508302797
   Huang J., 1998, ACM Multimedia
   HWAN OJ, 2003, PAC AS C KNWOL DISC
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jiang CT, 2010, KNOWL-BASED SYST, V23, P302, DOI 10.1016/j.knosys.2009.11.010
   Jiang T, 2009, IEEE T KNOWL DATA EN, V21, P161, DOI 10.1109/TKDE.2008.150
   Jianping Fan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P111
   Juang B., 1993, Fundamentals of Speech Recognition, Vl
   KEMP T, 2000, INT C AC SPEECH SIGN
   Kotsiantis Sotiris, 2006, GESTS International Transactions on Computer Science and Engineering, V32, P71
   Kriegel H.-P., 1996, KNOWLEDGE DISCOVERY, P226, DOI DOI 10.5555/3001460
   KRUSKAL JB, 1983, SIAM REV, V25, P201, DOI 10.1137/1025045
   KUBIN G, 1994, IEEE INT C AC SPEECH
   KURABAYASHI S, 2010, DATABASE SYSTEMS ADV
   Leavitt N, 2002, COMPUTER, V35, P23, DOI 10.1109/MC.2002.1039511
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Li N, 2010, DECIS SUPPORT SYST, V48, P354, DOI 10.1016/j.dss.2009.09.003
   Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383
   LI Y, 2005, IEEE INT C COMP VIS
   LILT D, 2004, IEEE INT C AC SPEECH
   Lin L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P859
   Lin L, 2009, IEEE INT CON MULTI, P418, DOI 10.1109/ICME.2009.5202523
   Lin L, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P137, DOI 10.1109/ICSC.2009.59
   LIN W, 2002, WORKSH INT SIT AW ME
   Lin WH, 2003, LECT NOTES ARTIF INT, V2797, P217
   LIN WH, 2002, ACM MULTIMEDIA
   LIU J, 2010, ACM S APPL COMP
   LIU Q, 2009, INT C MACH LEARN DAT, P582
   Mannila H, 1997, DATA MIN KNOWL DISC, V1, P259, DOI 10.1023/A:1009748302351
   Maragos P, 1999, J ACOUST SOC AM, V105, P1925, DOI 10.1121/1.426738
   MARAGOS P, 1991, IEEE INT C AC SPEECH
   MASE K, 2009, MULTIMODAL SENSOR BA, P1
   MATSUO Y, 2003, INT WORKSH MULT DAT, P18
   MEGALOOIKONOMOU V, 1999, ACM SIGKDD
   MEINEDO H, 2005, INTERSPEECH EUROSPEE
   MESGARANI N, 2004, INT C AC SPEECH SIGN, V1, P601
   MESSINA A, 2009, INT C WORLD WID WEB, P321
   MONTAGNUOLO M, 2010, S APPL COMP SAC, P1823
   MORENO PJ, 2000, IEEE INT C AC SPEECH
   NORVAG K, 2006, INT S METH INT SYST, P745
   NORVAG K, 2009, INT C COMP LING INT, P442
   OATES T, 1996, ICML, P346
   OH J, 2002, INT WORKSH MULT DAT, P1
   ORDONEZ C, 1999, IEEE ADV DIG LIBR C
   Pan JY, 2002, LECT NOTES COMPUT SC, V2555, P194
   PAN JY, 2004, ACM SIGKDD C KNOWL D
   Patel N., 2007, MULTIMEDIA DATA MINI
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Pfeiffer S., 1996, Proceedings ACM Multimedia 96, P21, DOI 10.1145/244130.244139
   PINQUIER J, 2002, INT C SPOK LANG PROC, V3, P2005
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   QUATIERI TF, 1990, INT C AC SPEECH SIGN
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RAMACHANDRAN C, 2009, ACM INT C MULT, P721
   Ribeiro MX, 2009, STUD COMPUT INTELL, V165, P113
   RIJSBERGEN CJV, 1986, COMPUT J, V29, P481
   ROBERTSON SE, 1977, J DOC, V33, P294, DOI 10.1108/eb026647
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Saraceno C, 1997, INT CONF ACOUST SPEE, P2597, DOI 10.1109/ICASSP.1997.595320
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   SCLAROFF S, 2001, INT WORKSH MULT DAT
   SENEFF S, 1988, J PHONETICS, V16, P55, DOI 10.1016/S0095-4470(19)30466-8
   Seneff S., 1984, ICASSP 84. Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, p36.2/1
   SHAO X, 2003, IEEE PAC RIM C MULT
   Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428
   Shirahama K, 2005, IEEE INT SYM MULTIM, P598
   SHIRAHAMA K, 2008, MULT DAT MIN
   SHIRAHAMA K, 2004, INT C MULT EXP
   Shirahama K, 2009, INT CONF DAT MIN WOR, P176, DOI 10.1109/ICDMW.2009.70
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   SMITH JR, 1996, IEEE P INT C IM P, V3, P1011
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   STEINBACH M, 2000, ACM SIGKDD WORLD TEX
   STEMBRIDGE B, 2004, INTELLECT ASSET MANA
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SWAIN MJ, INT J COMPUT VIS, V7, P11
   TADA T, 2009, INT MULT ENG COMP SC
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   TOWNSHEND B, 1990, IEEE INT C AC SPEECH
   Trippe A. J., 2003, World Patent Information, V25, P211, DOI 10.1016/S0172-2190(03)00079-6
   Vailaya A., 1998, SPIE, V3656
   Victor S.P., 2010, European Journal of Scientific Research, V40, P540
   WANG JZ, 2001, LECT NOTES COMPUTER, P232
   Wei SK, 2010, IEEE T KNOWL DATA EN, V22, P1191, DOI 10.1109/TKDE.2009.145
   Williams G., 1999, EUROSPEECH
   Xie L, 2004, IEEE IMAGE PROC, P2383
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Yang Y, 2008, WORLD PAT INF, V30, P280, DOI 10.1016/j.wpi.2008.01.007
   YEUNG M, 2001, READINGS MULTIMEDIA
   Yeung M. M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P375, DOI 10.1109/ICPR.1996.546973
   Yi Wu, 2005, 13th Annual ACM International Conference on Multimedia, P872, DOI 10.1145/1101149.1101338
   ZAIANE O, 1998, ACM SIGMOD, P581
   Zhang, 2005, IEEE INT C COMP VIS
   ZHANG C, 2009, J MULTIMEDIA, V4, P321
   ZHANG HJ, 1995, SPIE C STOR RETR IM
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   ZHU R, 2009, INT C ADV DAT MIN AP, P780
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
   ZIANG J, 2002, INT C AC SPEECH SIGN
NR 161
TC 46
Z9 54
U1 0
U2 78
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 35
EP 76
DI 10.1007/s11042-010-0645-5
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800003
DA 2024-07-18
ER

PT J
AU Yadav, T
   Aygün, RS
AF Yadav, Tarun
   Ayguen, Ramazan Savas
TI <i>I-Quest</i>: an <i>i</i>ntelligent <i>que</i>ry <i>st</i>ructuring
   based on user browsing feedback for semantic retrieval of video data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia information retrieval; Semantic retrieval; Relevance
   feedback; User browsing
ID RELEVANCE FEEDBACK; MPEG-7
AB In spite of significant improvements in video data retrieval, a system has not yet been developed that can adequately respond to a user's query. Typically, the user has to refine the query many times and view query results until eventually the expected videos are retrieved from the database. The complexity of video data and questionable query structuring by the user aggravates the retrieval process. Most previous research in this area has focused on retrieval based on low-level features. Managing imprecise queries using semantic (high-level) content is no easier than queries based on low-level features due to the absence of a proper continuous distance function. We provide a method to help users search for clips and videos of interest in video databases. The video clips are classified as interesting and uninteresting based on user browsing. The attribute values of clips are classified by commonality, presence, and frequency within each of the two groups to be used in computing the relevance of each clip to the user's query. In this paper, we provide an intelligent query structuring system, called I-Quest, to rank clips based on user browsing feedback, where a template generation from the set of interesting and uninteresting sets is impossible or yields poor results.
C1 [Yadav, Tarun; Ayguen, Ramazan Savas] Univ Alabama, Dept Comp Sci, Huntsville, AL 35899 USA.
   [Yadav, Tarun] Broadband Enterprises, New York, NY USA.
C3 University of Alabama System; University of Alabama Huntsville
RP Aygün, RS (corresponding author), Univ Alabama, Dept Comp Sci, Technol Hall N360, Huntsville, AL 35899 USA.
EM tyadav@cs.uah.edu; raygun@cs.uah.edu
RI Aygun, Ramazan/HTQ-3507-2023
OI Aygun, Ramazan/0000-0001-7244-7475
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], 2006, Fundamentals of Database Systems
   Babaguchi N, 2007, IEEE T MULTIMEDIA, V9, P1016, DOI 10.1109/TMM.2007.898890
   Chen YS, 2003, MULTIMEDIA SYST, V8, P523, DOI 10.1007/s00530-002-0074-z
   Cox I.J., 1998, IEEE C COMP VIS PATT
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   HE X, 2003, IEEE T CIRCUITS SYST, V13, P1032
   HEESCH D, 2004, P TRECVID2004
   Hoi SCH, 2008, IEEE T MULTIMEDIA, V10, P607, DOI 10.1109/TMM.2008.921735
   Jie S, 2008, IEEE T MULTIMEDIA, V10, P409, DOI 10.1109/TMM.2008.917339
   KELLY D, 2004, SIGIR 04, P377
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P83, DOI 10.1109/MMUL.2002.1022862
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   MEZARIS Y, 2004, P TRECVID2004
   MU X, 2006, SIGIR 06, P679
   Munesawang P, 2005, IEEE T CIRC SYST VID, V15, P1032, DOI 10.1109/TCSVT.2005.852412
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   Ortega-Binderberger M, 2003, HDB VIDEO DATABASES, P511
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P82, DOI 10.1109/IVL.1997.629724
   Rui Y., 1997, P 2 INT C VIS INF SY, P109
   RUI Y, 1997, CONTENT BASED IMAGE
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   Shen X., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P43, DOI 10.1145/1076034.1076045
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275
   Syeda-Mahmood T., 2001, PROC ACM MULITMEDIA, V9, P119, DOI DOI 10.1145/500141.500161
   TAYCHER L, 1997, P INT C VIS INF SAN
   Wang YF, 2001, AM LAB, V33, P38
   Wu L., 2000, P INT C VERY LARGE D, P297
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Yin PY, 2005, IEEE T PATTERN ANAL, V27, P1536, DOI 10.1109/TPAMI.2005.201
   ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1
   ZHANG Y, 2007, MIR 07, P313
   2006, MPEG7XM
NR 37
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2009
VL 43
IS 2
BP 145
EP 178
DI 10.1007/s11042-009-0262-3
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 430WI
UT WOS:000265021100003
DA 2024-07-18
ER

PT J
AU Klavans, J
   Sheffield, C
   Abels, E
   Lin, J
   Passonneau, R
   Sidhu, T
   Soergel, D
AF Klavans, Judith L.
   Sheffield, Carolyn
   Abels, Eileen
   Lin, Jimmy
   Passonneau, Rebecca
   Sidhu, Tandeep
   Soergel, Dagobert
TI Computational linguistics for metadata building (CLiMB): using text
   mining for the automatic identification, categorization, and
   disambiguation of subject terms for image metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing (NLP); Word sense disambiguation (WSD);
   Lexical disambiguation; Image access; Metadata extraction; Subject
   cataloging
ID MACHINES ANALYZE MESSAGES; RETRIEVAL; HUMANS
AB In this paper, we present a system using computational linguistic techniques to extract metadata for image access. We discuss the implementation, functionality and evaluation of an image catalogers' toolkit, developed in the Computational Linguistics for Metadata Building (CLiMB) research project. We have tested components of the system, including phrase finding for the art and architecture domain, functional semantic labeling using machine learning, and disambiguation of terms in domain-specific text vis a vis a rich thesaurus of subject terms, geographic and artist names. We present specific results on disambiguation techniques and on the nature of the ambiguity problem given the thesaurus, resources, and domain-specific text resource, with a comparison of domain-general resources and text. Our primary user group for evaluation has been the cataloger expert with specific expertise in the fields of painting, sculpture, and vernacular and landscape architecture.
C1 [Klavans, Judith L.; Sheffield, Carolyn; Lin, Jimmy; Sidhu, Tandeep; Soergel, Dagobert] Univ Maryland, iSch, College Pk, MD 20742 USA.
   [Klavans, Judith L.; Lin, Jimmy] Univ Maryland, Computat Linguist & Informat Proc Lab, College Pk, MD 20742 USA.
   [Klavans, Judith L.; Lin, Jimmy] Univ Maryland, UMIACS, College Pk, MD 20742 USA.
   [Abels, Eileen] Drexel Univ, Coll Informat Sci & Technol, Philadelphia, PA 19104 USA.
   [Passonneau, Rebecca] Columbia Univ, Ctr Computat Learning Syst, New York, NY USA.
C3 University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park;
   Drexel University; Columbia University
RP Sheffield, C (corresponding author), Univ Maryland, iSch, College Pk, MD 20742 USA.
EM csheffie@umd.edu
OI Sheffield, Carolyn/0000-0001-9704-7363
CR Anderson JD, 2001, INFORM PROCESS MANAG, V37, P231, DOI 10.1016/S0306-4573(00)00026-1
   Anderson JD, 2001, INFORM PROCESS MANAG, V37, P255, DOI 10.1016/S0306-4573(00)00046-7
   [Anonymous], P 23 ANN INT ACM SIG
   [Anonymous], 1992, the 14th International Conference on Computational Linguistics
   Baca Murtha., 2003, CATALOGING CLASSIFIC, V36, P47
   Banerjee S., 2003, P 18 INT JOINT C ART, V3, P805
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Charniak E, 1997, AI MAG, V18, P33
   Chen HL, 2001, INFORM PROCESS MANAG, V37, P701, DOI 10.1016/S0306-4573(00)00049-2
   Choi Y, 2003, J AM SOC INF SCI TEC, V54, P498, DOI 10.1002/asi.10237
   Church K. W., 1988, Second Conference on Applied Natural Language Processing, P136
   Collins K., 1998, AM ARCHIVIST, V61, P36, DOI [10.17723/aarc.61.1.b531vt5q0q620642, DOI 10.17723/AARC.61.1.B531VT5Q0Q620642]
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DEMNERFUSHMAN D, 2008, ONT 2008 2 INT LANG, P18
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984
   GRISHMAN R, 1995, 6 MESSAGE UNDERSTAND, P1
   Hatzivassiloglou V., 1999, Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora. College Park, Maryland, P203
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   Kan M.Y., 1998, P 6 INT WORKSHOP VER, P197
   Keister L.H., 1994, CHALLENGES INDEXING, P7
   KLAVANS JL, 1996, J MACHINE TRANSLATIO, V10, P185
   KLAVANS JL, 1990, DICT KNOWLEDGE BASE, P110
   KLEIN S, 1963, J ACM, V10, P334, DOI 10.1145/321172.321180
   LESK Michael, 1986, P 5 ANN INT C SYST D, V5, P24, DOI 10.1145/318723.318728
   Lew MS, 2000, COMPUTER, V33, P46, DOI 10.1109/2.881694
   MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084
   Palmer M, 2006, TEXT SPEECH LANG TEC, V33, P75, DOI 10.1007/1-4020-4809-2_4
   Panofsky E., 1962, STUDIES ICONOLOGY HU
   PASSONNEAU R, 2008, P 3 INT C COMP VIS T, P13
   Pastra K, 2003, IEEE INTELL SYST, V18, P55, DOI 10.1109/MIS.2003.1179194
   Patwardhan S, 2003, LECT NOTES COMPUT SC, V2588, P241
   Rasmussen EM, 1997, ANNU REV INFORM SCI, V32, P169
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
   Rorissa A, 2008, J AM SOC INF SCI TEC, V59, P1383, DOI 10.1002/asi.20825
   Shatford S., 1986, Cataloging Classification Quarterly, V6, P39
   Sidhu T., 2007, P WORKSH LANG TECHN, P25
   TIBBO HR, 1994, J AM SOC INFORM SCI, V45, P607, DOI 10.1002/(SICI)1097-4571(199409)45:8<607::AID-ASI16>3.0.CO;2-X
   WILKS Y, 2002, J SEMANT, V19, P167
   Yang YM, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P42, DOI 10.1145/312624.312647
   YAROWSKY D, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P88
NR 42
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 115
EP 138
DI 10.1007/s11042-008-0253-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400007
DA 2024-07-18
ER

PT J
AU Fung, YS
   Lui, JCS
AF Fung, Yeung Siu
   Lui, John C. S.
TI Hack-proof synchronization protocol for multi-player online games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cheat prevention; Multiplayer online game; Speed-hack
AB Synchronization protocols based on "dead-reckoning" are vulnerable to a popular type of cheat called speed-hack. A speed-hack helps a cheater to gain unfair advantages by essentially speeding up the actions of the avatar controlled by the cheater, so that the cheater can move, explore and gather items faster than honest players. This paper presents a novel version of a dead-reckoning protocol that is invulnerable to speed-hacks. Existing games based on dead-reckoning can easily be modified to use this hack-proof dead-reckoning protocol and how the protocol works on both client-server architecture and peer-to-peer (P2P) architecture will be demonstrated in this paper.
C1 [Fung, Yeung Siu; Lui, John C. S.] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Ma Liu Shui, Peoples R China.
RP Lui, JCS (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Ma Liu Shui, Peoples R China.
EM sfyeung@cse.cuhk.edu.hk; cslui@cse.cuhk.edu.hk
CR [Anonymous], 1992, RFC1305
   BANAVAR H, 2004, P NETGAMES 2004 PORT, P161
   Baughman NE, 2001, IEEE INFOCOM SER, P104, DOI 10.1109/INFCOM.2001.916692
   *COUNT HACK, 2007, TYP HACKS
   DeLaps M, 2004, P 3 ACM SIGCOMM WORK, P134
   DIOT C, 1999, P IEEE INFOCOM IEEE
   DIOT C, 1999, IEEE NETWORKS MA JUL
   *EV BAL, 2007, OFF PUNKBUSTER WEBS
   Feng WC, 2005, IEEE ACM T NETWORK, V13, P488, DOI 10.1109/TNET.2005.850221
   GAUTIER L, 1998, P IEEE MULT ICMCS 98
   JAMIN S, 2003, P 2 INT C APPL DEV C
   LEE FW, 2006, IEEE T VIS COMPUT GR, V12, P989
   LENKER S, 2002, INT WORKSH ENT COMP
   LO V, 2004, ACM NOSSDAV 04
   *MPC FOR, 2007, MULT CHEATS
   PANTEL L, 2002, ACM NOSSDAV 02
   SCHACHTE P, 2006, P ARES 06 VIENN 20 2, P34
   SIMPSON ZB, 2008, STREAM BASED TIME SY
   SOH S, 2007, P NOSSDAV 07 URB CHA, P34
   *WIK, 2007, CAT ANT SOFTW
   *Z PROJ, 2007, OFF HLGUARD WEBS
NR 21
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 2
BP 305
EP 331
DI 10.1007/s11042-008-0230-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387NI
UT WOS:000261958500007
DA 2024-07-18
ER

PT J
AU Kárpáti, P
   Szkaliczki, T
   Böszörményi, L
AF Karpati, Peter
   Szkaliczki, Tibor
   Boeszoermenyi, Laszlo
TI Designing and scaling distributed VoD servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Designing; Scaling; Distributed video server; Self-organization;
   Configuration recommendation
AB Planning Video-on-Demand (VoD) services based on the server architecture and the available equipment is always a challenging task. We created a formal model to support the design of distributed video servers that adapt dynamically and automatically to the changing client demands, network and host parameters. The model makes giving estimations about the available throughput possible, and defines evaluation criteria for VoD services relating to utilization and load balance, video usage, client satisfaction and costs. The dynamism of the frame model originates from the possible state transitions which have to be defined in a core model. The core model is responsible for configuration recommendation which determines how clients are served depending on the properties of their requests, system configuration and system load. Furthermore, it decides on the optimal placement of the server components in the network. The usability of the model is illustrated on examples.
C1 [Szkaliczki, Tibor] Hungarian Acad Sci, Comp & Automat Res Inst, H-1111 Budapest, Hungary.
   [Karpati, Peter] Norwegian Univ Sci & Technol NTNU, N-7491 Trondheim, Norway.
   [Boeszoermenyi, Laszlo] Klagenfurt Univ, A-9020 Klagenfurt, Austria.
C3 Hungarian Academy of Sciences; Hungarian Research Network; HUN-REN
   Institute for Computer Science & Control; Norwegian University of
   Science & Technology (NTNU); University of Klagenfurt
RP Szkaliczki, T (corresponding author), Hungarian Acad Sci, Comp & Automat Res Inst, Kende 13-17, H-1111 Budapest, Hungary.
EM kpeter@idi.ntnu.no; sztibor@sztaki.hu; laszlo@itec.uni-klu.ac.at
RI Szkaliczki, Tibor/JHT-3607-2023; Szkaliczki, Tibor/H-6155-2019
OI Szkaliczki, Tibor/0000-0002-7699-8132
FU Hungarian National Science Fund [OTKA 67651]; Mobile Innovation Center,
   Hungary
FX This work was carried out partially during the tenure of an ERCIM "Alain
   Bensoussan" Fellowship Programme. Partial support of the Hungarian
   National Science Fund (Grant No. OTKA 67651) and the Mobile Innovation
   Center, Hungary is gratefully acknowledged.
CR [Anonymous], 2001, Introduction to algorithms
   *APPL COMP INC QUI, 2002, DARW STREAM SERV MAD
   Boll S., 2003, P INT C DISTR MULT S, P12
   Böszörményi L, 2003, SIGNAL PROCESS-IMAGE, V18, P749, DOI 10.1016/S0923-5965(03)00062-6
   Böszörmenyi L, 2007, MULTIMEDIA SYST, V13, P51, DOI 10.1007/s00530-007-0077-x
   CALVERT K, 2003, P ACM SIGCOMM 2003 W
   Cherkasova L, 2005, IEEE SYMP COMP COMMU, P692, DOI 10.1109/ISCC.2005.116
   CHERKASOVA L, 2002, P ACM MULT 2002 JUAN
   Cherkasova L., 2004, P INT C DEP SYST NET
   CORNUEJOLS G, 1977, MANAGE SCI, V23, P789, DOI 10.1287/mnsc.23.8.789
   DAVID WB, 1996, IEEE MULTIMEDIA, V3, P37, DOI DOI 10.1109/93.556538
   GOLDSCHMIDT B, 2004, TECHNICAL REPORTS I, P776
   Guo M., 2002, P 12 INT WORKSH NETW, P155, DOI [10.1145/507670.507692, DOI 10.1145/507670.507692]
   *HEL COMM, 2002, HEL PLATF
   JI ZGP, 2002, P ACM NOSSDAV 2002 M
   Karpati P., 2005, Proceedings of the IASTED International Conference on Internet and Multimedia Systems and Applications, P492
   KARPATI P, 2008, DESIGNING SCALING PR
   KARPATI P, 2005, TECHNICAL REPORTS I
   Kayssi Ayman., 2004, Proceedings of the 2004 ACM symposium on Applied computing, SAC '04, P357
   Khan S., 2002, STUDIA INFORM, V2, P154
   KROPFBERGER M, 2004, VITOOKI VIDEO TOOLKI
   Li B, 1999, IEEE INFOCOM SER, P1282, DOI 10.1109/INFCOM.1999.752146
   PENAS JJS, 2003, 2 ACM SIGPLAN ERL WO
   Qiu LL, 2001, IEEE INFOCOM SER, P1587, DOI 10.1109/INFCOM.2001.916655
   *REALNETWORKS INC, 2003, HEL UN SERV ADM GUID
   SITARAM D, 2000, MULTIMEDIA SERVERS, P89
   Steen M., 1999, IEEE CONCURRENCY, V7, P70
   STEINMETZ R, 2000, MULTIMEDIA TECHNOLOG, P238
   SZKALICZKI T, 2004, KLUWER INT SERIES EN, V777, P165
   TANG W., 2003, Proceedings of the 13th international workshop on Network and operating systems support for digital audio and video, P12
   TUSCH R, 2004, COMPUTER SCI INFORMA, V1, P49
   TUSCH R, 2004, THESIS U KLAGENFURT
   YANG M, 2003, COMMUNICATIONS, V1, P557
   PUBLIC HOMEPAGE INFR
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 55
EP 91
DI 10.1007/s11042-008-0219-y
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400003
DA 2024-07-18
ER

PT J
AU Glowac, A
   Grega, M
   Romaniak, P
   Leszczuk, M
   Papir, Z
   Pardyka, I
AF Glowac, Andrzej
   Grega, Michal
   Romaniak, Piotr
   Leszczuk, Mikolaj
   Papir, Zdzislaw
   Pardyka, Ignacy
TI Compression and distribution of panoramic videos utilising MPEG-7-based
   image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless content distribution; Panoramic image; MPEG-7; Edge histogram
   descriptor; Mean opinion score; Quality evaluation
AB This paper describes an innovative compression method of panoramic images based on MPEG-7 descriptors. The proposed solution employs a detection of a series of individual video frame overlaps in order to produce concatenated panoramic images. The presented method is easy to implement even in simple devices such as low power consuming chipsets installed in remote cameras having limited power supplies. Under subjective tests it has been proved that the concatenation method allows for achieving lower transmission rates while sustaining picture quality.
C1 [Glowac, Andrzej; Grega, Michal; Romaniak, Piotr; Leszczuk, Mikolaj; Papir, Zdzislaw] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
   [Pardyka, Ignacy] Jan Kochanowski Univ Humanities & Sci, PL-25406 Kielce, Poland.
C3 AGH University of Krakow; Jan Kochanowski University
RP Glowac, A (corresponding author), AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM Glowacz@kt.agh.edu.pl; Grega@kt.agh.edu.pl; Romaniak@kt.agh.edu.pl;
   Leszczuk@kt.agh.edu.pl; Papir@kt.agh.edu.pl; Ignacy.Pardyka@pu.kielce.pl
RI Glowacz, Andrzej/H-6728-2012; Leszczuk, Mikołaj I/C-4857-2011; Romaniak,
   Piotr/C-7763-2011; Grega, Michal/C-3704-2011
OI Leszczuk, Mikołaj I/0000-0001-9123-1039; Grega,
   Michal/0000-0001-7633-8663
FU Polish State Ministry of Science and Higher Education [NN517438833,
   4T11D00525]; European Commission [FP6-0384239]
FX The work presented in this paper was supported in part by the Polish
   State Ministry of Science and Higher Education under the Grants No.
   NN517438833 and 4T11D00525, as well as by the European Commission under
   the grant no. FP6-0384239 (Network of Excellence CONTENT).
CR [Anonymous], 1996, Rec. ITU-T P.800
   [Anonymous], 2020, INT TELECOMMUNICATIO
   GLOWACZ A, 2006, P INT C SIGN EL SYST
   Halonen T., 2003, GSM, GPRS And EDGE Performance
   Holma H., 2004, WCDMA UMTS, V3rd
   Hsieh JW, 2004, IMAGE VISION COMPUT, V22, P291, DOI 10.1016/j.imavis.2003.09.018
   Hsu CT, 2004, SIGNAL PROCESS-IMAGE, V19, P81, DOI 10.1016/j.image.2003.10.001
   HUANG F, 2000, CTUCMP200007 U AUCKL
   *ISO, 2004, 1449610 ISO IS 10
   *ISO, 2004, 144962 ISO IS 2
   *ISO, 2004, 1444412004 ISO IS
   *ISO IEC, 2005, 15938 ISOIEC TR
   *ISO IEC, 2004, 15948 ISO IEC
   *ITU R, 2005, H264 ITUR
   *ITU R, 1992, T81 ITUR
   ITU-T and ISO/IEC, 2004, T800 ITUT
   Kaaranen H, 2005, UMTS NETWORKS: ARCHITECTURE, MOBILITY AND SERVICES, 2ND EDITION, P1, DOI 10.1002/047001105X
   Kamisetty C, 2003, TENCON IEEE REGION, P927
   Kim DH, 2003, PATTERN RECOGN LETT, V24, P2421, DOI 10.1016/S0167-8655(03)00071-0
   MANJUNATH BS, 2002, INTRO MPEG7 MULTIMED
   McLauchlan PF, 2002, IMAGE VISION COMPUT, V20, P751, DOI 10.1016/S0262-8856(02)00064-1
   PARDYKA I, 2006, HOMOGRAPHY BASED PAN, P293
   PARDYKA I, 2006, PANORAMIC IMAGE SEQU, P282
   Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Tian GY, 2003, PATTERN RECOGN LETT, V24, P1171, DOI 10.1016/S0167-8655(02)00287-8
   Traka M, 2003, SIGNAL PROCESS-IMAGE, V18, P465, DOI 10.1016/S0923-5965(03)00032-8
   Zhang CH, 2005, LECT NOTES COMPUT SC, V3553, P334
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 29
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2008
VL 40
IS 3
BP 321
EP 339
DI 10.1007/s11042-008-0209-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 360PD
UT WOS:000260068700001
DA 2024-07-18
ER

PT J
AU Yan, WQ
   Kankanhalli, MS
AF Yan, Wei-Qi
   Kankanhalli, Mohan S.
TI A cross-modal approach for karaoke artifacts correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE adaptive sampling; artifacts handling; karaoke
AB Karaoke singing is a popular form of entertainment in several parts of the world. Since this genre of performance attracts amateurs, the singing often has artifacts related to scale, tempo, and synchrony. We have developed an approach to correct these artifacts using cross-modal multimedia streams information. We first perform adaptive sampling on the user's rendition and then use the original singer's rendition as well as the video caption highlighting information in order to correct the pitch, tempo and the loudness. A method of analogies has been employed to perform this correction. The basic idea is to manipulate the user's rendition in a manner to make it as similar as possible to the original singing. A pre-processing step of noise removal due to feedback and huffing also helps improve the quality of the user's audio. The results are described in the paper which shows the effectiveness of this multimedia approach.
C1 [Kankanhalli, Mohan S.] Natl Univ Singapore, Singapore 117543, Singapore.
   [Yan, Wei-Qi] Univ Calif Irvine, Dept Comp Sci, Irvine, CA USA.
C3 National University of Singapore; University of California System;
   University of California Irvine
RP Kankanhalli, MS (corresponding author), Natl Univ Singapore, Singapore 117543, Singapore.
EM wyan@uci.edu; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR [Anonymous], 1998, Image processing, analysis, and machine vision
   Davis M, 2003, IEEE MULTIMEDIA, V10, P54, DOI 10.1109/MMUL.2003.1195161
   Goldberg R., 2000, A practical handbook of speech coders
   Harrington Jonathan., 1999, Techniques in Speech Acoustics
   Kankanhalli MS, 2006, IEEE T MULTIMEDIA, V8, P937, DOI 10.1109/TMM.2006.879876
   Kato H., 2000, US Patent, Patent No. [6,121,531, 6121531]
   KUMAR D, 2002, Patent No. 6692259
   MATSUMOTO S, 1998, Patent No. 5889223
   MURAKI K, 1995, Patent No. 5477003
   Tang X, 2002, IEEE T NEURAL NETWOR, V13, P961, DOI 10.1109/TNN.2002.1021896
   Tang XO, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P85, DOI 10.1109/ICME.2002.1035724
   Wang Y., 2004, Proceedings of the 12th Annual ACM International Conference on Multimedia, P212
   Yan WQ, 2005, MULTIMEDIA SYST, V11, P3, DOI 10.1007/s00530-005-0186-3
   ZHANG HJ, 1993, ACM MULTIMEDIA SYSTE, V1, P10
   ZHANG Y, 2000, P ACM MULT 2000 WORK, P201
   Zhu Y., 2003, P 11 INT ACM C MULT, P359
NR 16
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 3
BP 413
EP 439
DI 10.1007/s11042-007-0174-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 328BF
UT WOS:000257771600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tunali, ET
   Kantarci, A
   Ozbek, N
AF Tunali, ET
   Kantarci, A
   Ozbek, N
TI Robust quality adaptation for Internet video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video streaming; rate adaptation; encoding rate; frame rate; buffer
   management
ID MULTIMEDIA APPLICATIONS
AB Internet video streaming is a widely popular application however, in many cases, congestion control facilities are not well integrated into such applications. In order to be fair to other users that do not stream video, rate adaptation should be performed to respond to congestion. On the other hand, the effect of rate adaptation on the viewer should be minimized and this extra mechanism should not overload the client and the server. In this paper, we develop a heuristic approach for unicast congestion control. The primary feature of our approach is the two level adaptation algorithm that utilizes packet loss rate as well as receiver buffer data to maintain satisfactory buffer levels at the receiver. This is particularly important if receiver has limited buffer such as in mobile devices. When there is no congestion, to maintain best buffer levels, fine grain adjustments are carried out at the packet level. Depending on the level of congestion and receiver buffer level, rate shaping that involves frame discard and finally rate adaptation by switching to a different pre-encoded video stream are carried out. Additive increase multiplicative decrease policy is maintained to respond to congestion in a TCP-friendly manner. The algorithm is implemented and performance results show that it has adaptation ability that is suitable for both local area and wide area networks.
C1 Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
   Ege Univ, Dept Comp Engn, TR-35100 Izmir, Turkey.
C3 Ege University; Ege University
RP Ege Univ, Int Comp Inst, TR-35100 Izmir, Turkey.
EM tunali@ube.ege.edu.tr; kantarci@bornova.ege.edu.tr;
   nozbek@madran.ube.ege.edu.tr
CR Bansal D, 2001, IEEE INFOCOM SER, P631, DOI 10.1109/INFCOM.2001.916251
   BASSO A, 1999, IMAGE COMMUNICATION, P165
   DABBOUS W, 1992, P 4 IFIP C HIGH PERF, P283
   FEAMSTER N, 2000, THESIS MIT
   Guerri JC, 2001, MULTIMED TOOLS APPL, V13, P307, DOI 10.1023/A:1009633314583
   Hoffman D., 1998, RFC2250
   JEE JY, 1998, P ITC CSCC, P245
   Kalman M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P189, DOI 10.1109/ICIP.2002.1038937
   KALMAN M, 2002, P ISCAS2002
   KANTARCI A, 2003, IN PRESS J MULTIMEDI
   Masry M, 2001, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2001.959054
   McCanne S, 1997, IEEE J SEL AREA COMM, V15, P983, DOI 10.1109/49.611154
   Rejaie R, 2000, IEEE J SEL AREA COMM, V18, P2530, DOI 10.1109/49.898735
   SEELAM N, 2001, LECT NOTES COMPUTER, V2216, P1
   Sikora T, 1997, IEEE SIGNAL PROC MAG, V14, P82, DOI 10.1109/79.618010
   Wang X, 1999, IEICE T COMMUN, VE82B, P806
   Wu DP, 2000, IEEE T CIRC SYST VID, V10, P923, DOI 10.1109/76.867930
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 20
TC 5
Z9 5
U1 8
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 431
EP 448
DI 10.1007/s11042-005-4090-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300007
DA 2024-07-18
ER

PT J
AU Boavida, M
   Cabaço, S
   Correia, N
AF Boavida, M
   Cabaço, S
   Correia, N
TI VideoZapper:: A system for delivering personalized video content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE personalized video; editing rules; video servers; metadata
AB Given the huge amounts of audiovisual materials that are broadcasted every day there is considerable interest in applications that are able to fulfill our need for selecting information. In this paper, we propose a system, VideoZapper, which can personalize and help to select audiovisual content based on its properties (represented as metadata descriptors) and mainly on the past experience of other users with that material. The content is selected based on the user profile and the description of each of the segments to be presented. A second level of selection is based on a "virtual edition" of the content, taking into account what previous users/viewers did. The paper presents related personalization and metadata approaches, the rational and principles for continuous media personalization, our current architecture and system, and preliminary experiences.
C1 Polytech Inst Setubal, Sch Technol, Dept Syst & Informat, Setubal, Portugal.
   Univ Nova Lisboa, Fac Sci & Technol, IMG, CITI, Lisbon, Portugal.
   Univ Nova Lisboa, Fac Sci & Technol, Dept Comp Sci, Lisbon, Portugal.
C3 Instituto Politecnico de Setubal; Universidade Nova de Lisboa;
   Universidade Nova de Lisboa
RP Boavida, M (corresponding author), Polytech Inst Setubal, Sch Technol, Dept Syst & Informat, Setubal, Portugal.
RI FCTUNL, CITI/G-6714-2011; Correia, Natália T. T./D-6699-2013; Correia,
   Nuno/D-2298-2010
OI Correia, Nuno/0000-0002-8704-6698
CR AHANGER G, 1997, INT C MULT COMP SYST
   CORREIA N, 2001, INTEGRATED PERSONALI
   COSTA M, 2002, ACM MULTIMEDIA 2002
   DALE D, 2002, INT C DUBL COR MET E
   DAVENPORT G, 1995, ACM MULT 95 SAN FRAN
   ECHIGO T, 2001, PERSONALIZED DELIVER
   JAIMES A, 2002, LEARNING PERSONALIZE
   JOKELA S, 2001, THESIS HELSINKI U TE
   Manjunath B.S., 2002, INTRO MPEG 7
   MERIALDO B, 1999, ACM MULT 99 ORL FLOR
   NIIRANENL S, 2002, NORSIG 5 NORD SIGN P
   SYEDAMAHMOOD T, 2001, ACM MULT 01 OTT CAN
   ZHANG HJ, 1994, INT C MULT COMP SYST
NR 13
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 345
EP 360
DI 10.1007/s11042-005-6539-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400003
DA 2024-07-18
ER

PT J
AU Dong, YF
   Zhang, ZL
AF Dong, YF
   Zhang, ZL
TI Providing controlled quality assurance for streaming stored-videos
   across the Internet using VPNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE quality assurance; multimedia content distribution; application-aware
   flow control; proxy server; video streaming
AB Video Streaming across wide-area networks is one of the most important applications on the Internet. In this paper we focus on the quality assurance issue on best-effort networks and propose a practical technique, named staggered two-flow video streaming. We deliver a stored video through two separate flows in a staggered fashion via a VPN pipe from a central server to a proxy server. One flow containing the essential portion of the video is delivered using a novel controlled TCP (cTCP), and the other flow containing the enhanced portion of the video is transmitted using a rate-controlled RTP/UDP (rUDP). To provide video-quality assurance in such a system, we design several application-aware flow-control and adaptation approaches to control bandwidth sharing and interactions among flows by exploiting the inherent priority structure in videos, the storage space on proxy servers and the coarse-grain bandwidth assurance of VPN. Our experiments using FreeBSD and simulations on NS2 both have demonstrated the efficacy of the proposed technique in protecting essential data and significantly reducing the numbers of packets retransmitted/lost in transmission and the sizes of video prefixes required on proxy servers. In summary, our application-aware approach provides stable and predictable performance in streaming videos across wide-area best-effort networks. In addition, another salient feature of our approach is that it requires no changes on the client-receiving side and minimal changes on the server-sending side.
C1 Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA.
   Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Hawaii System; University of Minnesota System; University
   of Minnesota Twin Cities
RP Univ Hawaii, Dept Elect Engn, Honolulu, HI 96822 USA.
EM yingfei@hawaii.edu; zhzhang@cs.umn.edu
CR AGGARWAL A, 2000, P IEEE INF 00 TEL AV
   AMIR E, P ACM MULTIMEDIA 95
   DESHMUKH V, DESIGN IMPLEMENTATIO
   DONG Y, THESIS U MINNESOTA
   DUFFIELD NG, P ACM SIGCOMM 99
   FENG W, P IS T SPIE MULT COM
   FLOYD S, P SIGCOMM 00
   KATZ R, POST PC ERA ITS ALL
   LI X, P IEEE INFOCOM 98
   Mahdavi J., 1997, TCP FRIENDLY UNICAST
   Mathis M., 1997, Computer Communication Review, V27, P67, DOI 10.1145/263932.264023
   MCCANNE S, P ACM SIGCOMM 96
   McManus JM, 1996, IEEE J SEL AREA COMM, V14, P1087, DOI 10.1109/49.508280
   MERZ M, P ACM MULTIMEDIA 97
   PADHYE JD, 2000, THESIS U MASSACHUSET
   RAKSHE R, THESIS U MINNESOTA
   REJAIE R, 99709 COMP SCI DEP
   REJAIE R, 1999, P SIGCOMM 99
   ROSE O, 1995, TR101 U WURZB I COMP
   SALEHI JKJ, P ACM SIGMETRICS 96
   SEN S, 1999, P IEEE INFOCOM 99
   Zhang ZL, 2000, IEEE ACM T NETWORK, V8, P429, DOI 10.1109/90.865072
   ZHANG ZL, 2000, J REAL TIME IMAGING
NR 23
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 281
EP 304
DI 10.1007/s11042-005-5608-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000005
DA 2024-07-18
ER

PT J
AU Alferez, R
   Wang, YF
   Jiao, L
AF Alferez, R
   Wang, YF
   Jiao, L
TI An affine-invariant tool for retrieving images from homogeneous
   databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based image retrieval; affine; invariants; shape; homogeneous
   database
ID RECOGNITION; SIMILARITY; SHAPES
AB In this paper, we examine the complexities involved in retrieving images from a database comprised of objects of very similar appearance. Such an operation requires a process that can discriminate among images at a very fine level, such as distinguishing among various species of fish. Furthermore, incidental environmental factors such as change in viewpoints and slight, nonessential shape deformation must be excluded from the similarity criteria. To this end, we propose a new method for content-based image retrieval and indexing, one that is well suited for discriminating among objects within the same class in a way that is insensitive to incidental environmental changes. The scheme comprises a global alignment and a local matching process. Affine transform is used to model the different viewpoints associated with positioning the camera, while multi-dimensional indexing techniques are used to make the global alignment scheme efficient. A local matching process based on dynamic programming allows the optimal matching of local structures using cost metrics that may ignore nonessential local shape deformation. Results show the method's ability to cancel out visual distortions caused by a changing viewpoint, and its tolerance to noise, occlusion, and slight deformations of the object.
C1 Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara
RP Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
EM ronald@cs.ucsb.edu; yfwang@cs.ucsb.edu; jiaolong@cs.ucsb.edu
CR Adler SL, 1998, PATTERN RECOGN, V31, P1551, DOI 10.1016/S0031-3203(98)00011-9
   ALFEREZ R, 1999, IEEE T PATTERN A JUN
   [Anonymous], IEEE COMPUT
   [Anonymous], P IEEE INT C IM PROC
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BACHELDER IA, 1992, COMPUTER VISION PATT, P798
   BINAGHI E, 1992, VISUAL DATABASE SYST, V2, P79
   BOSE SK, 1996, ARTIF INTELL, P227
   BRUNELLI R, 2000, P ICME 2000 IEEE INT
   CALIFANO A, 1994, IEEE T PATTERN ANAL, V16, P373, DOI 10.1109/34.277591
   CHANG SK, 1988, IEEE T SOFTWARE ENG, V14, P681, DOI 10.1109/32.6147
   Crane Gregory R., 2001, PERSEUS DIGITAL LIB
   FLICKNER M, 1995, IEEE COMPUT, V9, P23
   FROESE R, 2001, FISHBASE 2000
   FRYDRYCHOWICZ S, 1991, VISUAL FORM, P267
   HASTINGS NAJ, 1975, STAT DISTRIBUTION
   Kelly PM, 1996, P SOC PHOTO-OPT INS, V2670, P42, DOI 10.1117/12.234808
   LACASCIA M, 1996, P ICASSP 96 ATL GEOR
   LAMDAN Y, 1990, IEEE T ROBOTICS AUTO, V6
   LAMIROY B, 1996, P ECCV, P59
   Larish J., 1995, ADV IMAGING, V10, P38
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Martucci M., 1995, ADV IMAGING, V10, P34
   Mokhtarian F, 2002, PATTERN RECOGN, V35, P31, DOI 10.1016/S0031-3203(01)00040-1
   Mokhtarian F., 1996, BRIT MACHINE VISION, P53
   Mundy J., 1992, GEOMETRIC INVARIANCE
   Nagasaka A., 1995, Visual Database Systems II, P113
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   PAUWELS EJ, 1995, INT J COMPUT VISION, V14, P49, DOI 10.1007/BF01421488
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Picard R. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P638, DOI 10.1109/CVPR.1993.341050
   PROCTOR S, 1997, INT C IM PROC
   RABITTI F, 1989, P IFIP WORK C VIS DA, P415
   Reiss T.H., 1993, RECOGNIZING PLANAR O
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   STARTCHIK S, 1996, 1 IAPR INT WORKSH IM, P202
   SWAIN MJ, 1993, P SOC PHOTO-OPT INS, V1908, P193
   TANABE K, 1989, PROGR IMAGE ANAL PRO, P138
   WANG J, 1999, INT C MULTIMEDIA COM, V1, P875
   WEISS I, 1993, INT J COMPUT VISION, V10, P207, DOI 10.1007/BF01539536
   [No title captured]
NR 41
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2005
VL 25
IS 1
BP 133
EP 159
DI 10.1023/B:MTAP.0000046385.62974.be
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 866VY
UT WOS:000224802700006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Haneef, AM
   Ganz, A
AF Haneef, AM
   Ganz, A
TI ANMoLe - An adaptive multimedia content delivery middleware architecture
   for heterogeneous mobile multi-device neighborhoods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE middleware for mobility; multi-device content delivery; content
   adaptation; pervasive computing; application-level proxy; content
   personalization; ubiquitous computing; web proxy
AB Despite the commercial onslaught of multipurpose portable devices such as integrated mobile phone-PDA combos, the need for multiple devices, with each device performing its own pre-defined and specialized function still exists today. The new generation of internet users has been expeditious in imbibing the new generation of divergent devices for their varying needs - cell phones for voice communication, pagers for text messaging and PDAs for notes. Content sources today assume that the end-device used to retrieve the content has certain minimum pre-defined capabilities. The architecture presented in this paper explores a new realm of content delivery where all the devices in a user's neighborhood of devices are united as a single entity for content delivery. This solution exploits the characteristic capabilities of these individual devices to render the retrieved content for the user; or in cases where the target devices are limited in capabilities, modifies the content to suite the capabilities of the device. A comprehensive description of the testbed we have built based on this architecture is also described.
C1 Univ Massachusetts, Dept Elect & Comp Engn, Multimedia Networks Lab, Amherst, MA 01003 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Haneef, AM (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, Multimedia Networks Lab, Amherst, MA 01003 USA.
EM anwar@motorola.com; ganz@ecs.umass.edu
CR Anerousis N, 1999, IEEE J SEL AREA COMM, V17, P91, DOI 10.1109/49.743699
   APPENZELLER G, 1999, CSLTR99777
   Bahl Paramvir, 2000, IEEE INFOCOM 2000 MA
   BANAVAR G, 2000, ACM IEEE INT C MOB C
   ELSON J, INTERNET CONTENT ADA
   GRIBBLE S, 2001, COMPUTER NETWORKS, V35
   HANEEF A, 2002, THESIS U MASSACHUSET
   HANEEF A, 2002, FRONTIERS ED FIE 200
   JOHANSON B, 2001, P UB 2001 SEP
   Magerkurth Carsten, 2001, SIGGROUP B, V22, P16, DOI [10.1145/500721.500725, DOI 10.1145/500721.500725]
   MARTI S, THESIS MIT
   *MOT, MOT RAD TEL SYST DRI
   MYSORE JP, 2002, INT C MOB DAT MAN MD
   PHAN T, 2001, IEEE INT C COMM ICC
   REKIMOTO J, 1998, ACM C HUM FACT COMP
   STREITZ NA, 1999, ACM C HUM FACT COMP
   *SUN MICR, FREE TTS 1 1 SPEECH
   TOMLINSON, EXTENSIBLE PROXY SER
   WANG H, 2000, COMMUNICATION
NR 19
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2004
VL 22
IS 2
BP 171
EP 186
DI 10.1023/B:MTAP.0000011933.21474.96
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 762YR
UT WOS:000188035600004
DA 2024-07-18
ER

PT J
AU Law, KCK
   Wang, Y
   Ip, HHS
AF Law, KCK
   Wang, Y
   Ip, HHS
TI A structured hypertext data model with versioning for engineering
   documents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE structured hypermedia document; version nodes; hypertext network
ID HYPERMEDIA
AB Hypertext involves linking related information blocks together to form a network. It is suitable to access information in a nonlinear fashion with a flexible structure. However, when the hypertext technique is applied to manage mass data such as engineering documents, the large number of nodes and links involved can cause problems such as data access navigation and versioning control. This paper introduces a structured hypertext data model with a version control mechanism.
   In our model, the structure node is defined and can be used to reduce the number of visible nodes during browsing through the logical structure of the hypertext network. As a result, the network structure becomes clearer, relatively easier to navigate through the network and to prevent users from disorientation during data access or browsing operations. The structure node provides a high level abstract mechanism, implies more knowledge and supports visual presentation of the hypertext network. In this model, the version node is a special kind of structure node which is used as a means to support versioning. Compared with other hypertext systems or models, the proposed model is better suited to the needs of engineering data management. A formal description of this model also is presented along with a description of the write-multiple Optical Disk based Electronic Archives Management System (ODEAMS), which was developed on the basis of this model.
C1 City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Hong Kong, Peoples R China.
   Harbin Inst Technol, Dept Comp Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 City University of Hong Kong; Harbin Institute of Technology
RP Law, KCK (corresponding author), City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
RI LI, Xiang/JBJ-8387-2023
OI Wang, Yan/0000-0002-5344-1884; IP, Ho Shing Horace/0000-0002-1509-9002
CR Akscyn R., 1988, P SIGCHI C HUMAN FAC, P115
   AKSCYN RM, 1988, COMMUN ACM, V31, P820, DOI 10.1145/48511.48513
   [Anonymous], COMPUTER
   CALTIN T, 1989, P ACM HYP 89 PITTSB, P65
   CAMPBELL B, 1988, COMMUN ACM, V31, P856, DOI 10.1145/48511.48515
   Dattolo A, 1996, INFORM SYST, V21, P127, DOI 10.1016/0306-4379(96)00008-7
   DELISLE NM, 1987, ACM T INFORM SYST, V5, P168, DOI 10.1145/27636.27639
   DeRose S. J., 1994, MAKING HYPERMEDIA WO
   HAAKE A, 1996, P ACM HYPERTEXT 96 W
   HAAN BJ, 1992, COMMUN ACM, V35, P36, DOI 10.1145/129617.129618
   HALASZ FG, 1988, COMMUN ACM, V31, P836, DOI 10.1145/48511.48514
   *ISO IEC, 1992, 10740 ISOIEC INT ORG
   Kochevar P., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P94, DOI 10.1109/VISUAL.1993.398856
   Maurer Hermann, 1996, HYPERG NOW HYPERWAVE
   NIELSEN J, 1990, HYPERTEXT HYPERMEDIA
   Nielsen Jacob., 1995, MULTIMEDIA HYPERTEXT
   Spoerri A., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P150, DOI 10.1109/VISUAL.1993.398863
   WANG Y, 1996, J HARBIN I TECHNOL E, V3, P20
   YANKELOVICH N, 1988, IEEE COMPUT, V21, P81
NR 19
TC 1
Z9 1
U1 0
U2 2
PU KLUWER ACADEMIC PUBL
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2003
VL 19
IS 3
BP 241
EP 258
DI 10.1023/A:1023225313601
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 665BD
UT WOS:000182099000002
DA 2024-07-18
ER

PT J
AU Budati, M
   Karumuri, R
AF Budati, Manikanth
   Karumuri, Rajasekhar
TI An intelligent lung nodule segmentation framework for early detection of
   lung cancer using an optimized deep neural system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CT Image; Segmentation; Deep Neural System; Nodule; Lung Cancer; Feature
   Extraction
ID PREDICTION
AB Lung cancer is the most dangerous disease in the world, leading to high mortality in daily life. So, the early detection of this disease is essential to enhance the survival rate of patients worldwide. However, the small extent of lung nodules is not easily found by eye vision, so this leads to the inaccurate diagnosis of lung cancer. Nowadays, deep neural systems technology-based machine learning has been widely used in healthcare units to diagnose various diseases. It is one of the best ways to classify subtle parts of a CT scan exactly. Therefore, proposed a Sailfish-based Yolo Segmentation Framework (SbYSF) that aimed to segment the lung nodule part accurately. Initially, the CT image datasets were collected preprocessed, and required features were extracted using the sailfish function. The nodule region is traced through the extracted features and segmented. Further, the severity is attained using the SbYSF framework. The planned model accurately detected the nodule region for the early stage of a lung cancer diagnosis. The proposed model is checked in the Python simulation environment. They reached the highest accuracy, precision, and recall of 99.75% and F-measure of 99%.
C1 [Budati, Manikanth; Karumuri, Rajasekhar] Univ Coll Engn, Dept Elect & Commun Engn, JNTUK, Kakinada 533003, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Budati, M (corresponding author), Univ Coll Engn, Dept Elect & Commun Engn, JNTUK, Kakinada 533003, Andhra Pradesh, India.
EM manikanth439@gmail.com; rajakarumuri87@jntucek.ac.in
RI BUDATI, MANIKANTH/KIA-8835-2024
OI BUDATI, MANIKANTH/0009-0002-6549-5182
CR Afshar P, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107942
   Alhlalat MA., 2023, J Comput Sci, V19, P1520, DOI [10.3844/jcssp.2023.1520.1540, DOI 10.3844/JCSSP.2023.1520.1540]
   Aswathy SU, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010014
   Balagurunathan Y, 2021, IEEE T MED IMAGING, V40, P3748, DOI 10.1109/TMI.2021.3097665
   Balci MA, 2023, CANCERS, V15, DOI 10.3390/cancers15030843
   Chetan MR, 2022, EUR RADIOL, V32, P5330, DOI 10.1007/s00330-022-08635-4
   Deputy KV, 2023, J Comput Sci, V19, P1438, DOI [10.3844/jcssp.2023.1438.1449, DOI 10.3844/JCSSP.2023.1438.1449]
   Dutande P, 2021, BIOMED SIGNAL PROCES, V67, DOI 10.1016/j.bspc.2021.102527
   Gazzawe F, 2023, J Comput Sci, V19, P1380, DOI [10.3844/jcssp.2023.1380.1386, DOI 10.3844/JCSSP.2023.1380.1386]
   Gu DD, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101886
   Heuvelmans MA, 2021, LUNG CANCER, V154, P1, DOI 10.1016/j.lungcan.2021.01.027
   Ali YH, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10020138
   Jena SR, 2021, INT J IMAG SYST TECH, V31, P2144, DOI 10.1002/ima.22584
   Kadry Seifedine, 2023, Procedia Computer Science, P2786, DOI 10.1016/j.procs.2023.01.250
   Karthika K, 2022, IMAGING SCI J, V70, P117, DOI 10.1080/13682199.2022.2163538
   Kasinathan G, 2019, EXPERT SYST APPL, V134, P112, DOI 10.1016/j.eswa.2019.05.041
   Li J, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2022.106501
   Liu KH, 2022, IEEE ACCESS, V10, P75385, DOI 10.1109/ACCESS.2022.3192034
   Liu MZ, 2021, LECT NOTES COMPUT SC, V12905, P23, DOI 10.1007/978-3-030-87240-3_3
   Majidpourkhoei R, 2021, MULTIMED TOOLS APPL, V80, P30539, DOI 10.1007/s11042-021-11066-w
   Maqsood M, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9131457
   Meraj T, 2021, NEURAL COMPUT APPL, V33, P10737, DOI 10.1007/s00521-020-04870-2
   Morgado J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073273
   Mothkur Rashmi, 2023, Procedia Computer Science, P1869, DOI 10.1016/j.procs.2023.01.164
   Pandit BR, 2023, MULTIMED TOOLS APPL, V82, P6605, DOI 10.1007/s11042-022-13566-9
   Pastorino U, 2022, ANN ONCOL, V33, P395, DOI 10.1016/j.annonc.2022.01.008
   Pedrosa J, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102027
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Ren H, 2024, INFORM SCIENCES, V654, DOI 10.1016/j.ins.2023.119854
   Said Y, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030546
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   Silva F, 2021, IEEE ACCESS, V9, P58667, DOI 10.1109/ACCESS.2021.3070701
   Soulami KB, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102481
   Sujitha R, 2021, J AMB INTEL HUM COMP, V12, P5639, DOI 10.1007/s12652-020-02071-2
   Talukder MA, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117695
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Tomassini S, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105691
   Wang L, 2022, ADV SCI, V9, DOI 10.1002/advs.202203786
   Wang WL, 2021, APPL INTELL, V51, P2471, DOI 10.1007/s10489-020-01990-z
   Zhao C, 2022, MULTIMED TOOLS APPL, V81, P24265, DOI 10.1007/s11042-022-12670-0
NR 40
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17791-8
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000008
DA 2024-07-18
ER

PT J
AU Chiang, CK
   Lin, YD
   Hwang, RH
   Lin, PC
   Chang, SY
   Li, HT
AF Chiang, Chen-Kuo
   Lin, Ying-Dar
   Hwang, Ren-Hung
   Lin, Po-Ching
   Chang, Shih-Ya
   Li, Hao-Ting
TI Imperceptible adversarial attack via spectral sensitivity of human
   visual system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Imperceptible adversarial attack; Spectral sensitivity; Human visual
   system; Deep learning
AB Adversarial attacks reveals that deep neural networks are vulnerable to adversarial examples. Intuitively, adversarial examples with more perturbations result in a strong attack, leading to a lower recognition accuracy. However, increasing perturbations also causes visually noticeable changes in the images. In order to address the problem on how to improve the attack strength while maintaining the visual perception quality, an imperceptible adversarial attack via spectral sensitivity of the human visual system is proposed. Based on the analysis of human visual system, the proposed method allows more perturbations as attack information and re-distributes perturbations into pixels where the changes are imperceptible to human eyes. Therefore, it presents better Accuracy under Attack(AuA) than existing attack methods whereas the image quality can be maintained to the similar level as other methods. Experimental results demonstrate that our method improves the attack strength of existing adversarial attack methods by adding 3% to 23% while mostly maintaining the visual quality of SSIM lower than 0.05.
C1 [Chiang, Chen-Kuo] Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, Adv Inst Mfg High Tech Innovat, Minhsiung 621301, Chiayi, Taiwan.
   [Lin, Ying-Dar] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu 300093, Taiwan.
   [Hwang, Ren-Hung] Natl Yang Ming Chiao Tung Univ, Coll Artificial Intelligence, Tainan, Taiwan.
   [Lin, Po-Ching; Chang, Shih-Ya; Li, Hao-Ting] Natl Chung Cheng Univ, Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University; National Yang Ming Chiao Tung
   University; National Yang Ming Chiao Tung University; National Chung
   Cheng University
RP Chiang, CK (corresponding author), Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, Adv Inst Mfg High Tech Innovat, Minhsiung 621301, Chiayi, Taiwan.
EM ckchiang@cs.ccu.edu.tw; ydlin@cs.nctu.edu.tw; rhhwang@nycu.edu.tw;
   pclin@cs.ccu.edu.tw; otischang.true@gmail.com; haotingli@csie.io
FU Advanced Institute of Manufacturing with High-tech Innovations (AIM-HI)
   from The Featured Areas Research Center Program within the framework of
   the Higher Education Sprout Project by the Ministry of Education (MOE)
   in Taiwan; National Science and Technology Council, Taiwan [NSTC
   111-2634-F-006-012]; NSTC [111-2634-F-194-003]
FX This work was partially supported by the Advanced Institute of
   Manufacturing with High-tech Innovations (AIM-HI) from The Featured
   Areas Research Center Program within the framework of the Higher
   Education Sprout Project by the Ministry of Education (MOE) in Taiwan
   and Center for Innovative Research on Aging Society (CIRAS). This work
   was also supported in part by the National Science and Technology
   Council, Taiwan under Grant NSTC 111-2634-F-006-012 and NSTC
   111-2634-F-194-003.
CR Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen JB, 2020, P IEEE S SECUR PRIV, P1277, DOI 10.1109/SP40000.2020.00045
   Chen Z., 2023, P AAAI C ART INT JUN, V37, P414
   Croce F, 2019, IEEE I CONF COMP VIS, P4723, DOI 10.1109/ICCV.2019.00482
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong YP, 2020, PROC CVPR IEEE, P318, DOI 10.1109/CVPR42600.2020.00040
   Flynn Jeremy R., 2013, Engineering Psychology and Cognitive Ergonomics. Understanding Human Cognition. 10th International Conference, EPCE 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8019, P23, DOI 10.1007/978-3-642-39360-0_3
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Grassmann H., 1853, Ann. Phys-Berlin, V165, P69, DOI [10.1002/andp.18531650505, DOI 10.1002/ANDP.18531650505]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia XJ, 2022, PROC CVPR IEEE, P13388, DOI 10.1109/CVPR52688.2022.01304
   Kaufmann M, 2023, Arxiv, DOI arXiv:1908.08016
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kurakin Alexey, 2017, INT C LEARN REPR
   Liu Y, 2021, IEEE T INF FOREN SEC, V16, P5154, DOI 10.1109/TIFS.2021.3124734
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Luo B, 2018, AAAI CONF ARTIF INTE, P1652
   Luo C, 2022, PROC CVPR IEEE, P15294, DOI 10.1109/CVPR52688.2022.01488
   Madry A., 2018, ARXIV
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N, 2016, Arxiv, DOI arXiv:1605.07277
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang XS, 2021, PROC CVPR IEEE, P1924, DOI 10.1109/CVPR46437.2021.00196
   Wyszecki G., 1982, COLOR SCI
   Xu SK, 2023, NEUROCOMPUTING, V525, P29, DOI 10.1016/j.neucom.2023.01.055
   Zhao ZY, 2020, PROC CVPR IEEE, P1036, DOI 10.1109/CVPR42600.2020.00112
   Zifei Zhang, 2020, Machine Learning for Cyber Security. Third International Conference, ML4CS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12487), P463, DOI 10.1007/978-3-030-62460-6_42
NR 33
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17750-3
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR5X2
UT WOS:001126994000002
DA 2024-07-18
ER

PT J
AU Pujari, SD
   Pawer, MM
   Pawar, SP
AF Pujari, Suvarna D.
   Pawer, Meenakshi M.
   Pawar, Swati P.
TI M<SUP>2</SUP>S<SUP>2</SUP>-FNet: Multi-scale, Multi-stream feature
   network with Attention mechanism for classification of breast
   histopathological image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Histopathological image; CNN; Multi scale; Multi Stream; Attention
   Mechanism
ID NEURAL-NETWORKS; DIAGNOSIS; VARIABILITY; MAMMOGRAPHY; HISTOLOGY
AB Breast cancer (BC) is the most commonly diagnosed cancer type, especially in women. Identifying the subtype of malignant (cancer) lesions can help to give proper treatment to cancer patients. The subtype of benign lesions can help to estimate the risk of developing cancer in the future. The computer-aided diagnosis (CAD) is an automated and more precise method for histopathological image classification. With the recent development in computer vision and deep learning, advanced convolution neural networks have achieved great success in image classification and widely used in medical image processing. This paper proposes a deep based multi-scale multi-stream feature network ((MS2)-S-2-FNet) with attention mechanism for classification H&E stained breast histopathological microscopy image either as benign or malignant, and then categorizing malignant and benign cases into four different subtypes each. The proposed network processes the patch of breast cancer image through each multi-scale multi-stream to extract the robust; and refined features from the attention module. The proposed (MS2)-S-2-FNet follows the knowledge of sharing strategy by sharing learned features at each stream across the network and the attention mechanism. (MS2)-S-2-FNet achieved an accuracy for different magnification factors (x 40, x 100, x 200, and x 400) but the superior accuracy i.e. 98.07% for multi-class and 99.60% for binary at x 200. Accuracy, performance measure parameters like Recall, Precision and Sensitivity etc. and weight of (MS2)-S-2-FNet model were better than existing models like VGG16, Xception, ResNet152 and BreastNet.
C1 [Pujari, Suvarna D.; Pawer, Meenakshi M.; Pawar, Swati P.] Univ PAH, SVERIs Coll Engn, Dept Elect & Telecommun Engn, Pandharpur, Solapur, India.
C3 SVERI'S College of Engineering
RP Pujari, SD (corresponding author), Univ PAH, SVERIs Coll Engn, Dept Elect & Telecommun Engn, Pandharpur, Solapur, India.
EM supujari94@gmail.com; mmpawar@coe.sveri.ac.in; sppawar@coe.sveri.ac.in
CR Ahmad N, 2022, VISUAL COMPUT, V38, P2751, DOI 10.1007/s00371-021-02153-y
   Akay MF, 2009, EXPERT SYST APPL, V36, P3240, DOI 10.1016/j.eswa.2008.01.009
   Allison KH, 2015, CANCER-AM CANCER SOC, V121, P1369, DOI 10.1002/cncr.29199
   Allison KH, 2014, HISTOPATHOLOGY, V65, P240, DOI 10.1111/his.12387
   Bai X, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108102
   Benhammou Y, 2020, NEUROCOMPUTING, V375, P9, DOI 10.1016/j.neucom.2019.09.044
   Cheng XC, 2022, J SUPERCOMPUT, V78, P17114, DOI 10.1007/s11227-022-04561-w
   Coracin F., 2019, Oral Surg Oral Med Oral Pathol Oral Radiol, V128, pe36, DOI [10.1016/j.oooo.2019.02.065, DOI 10.1016/J.OOOO.2019.02.065]
   Elmore JG, 2016, ANN INTERN MED, V164, P649, DOI 10.7326/M15-0964
   Gandomkar Z, 2018, ARTIF INTELL MED, V88, P14, DOI 10.1016/j.artmed.2018.04.005
   Gandomkar Ziba, 2016, J Pathol Inform, V7, P43, DOI 10.4103/2153-3539.192814
   Guo Y, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0435-x
   Gupta Puja, 2020, Procedia Computer Science, V171, P593, DOI 10.1016/j.procs.2020.04.064
   Guray M, 2006, ONCOLOGIST, V11, P435, DOI 10.1634/theoncologist.11-5-435
   Hamidinekoo A, 2018, MED IMAGE ANAL, V47, P45, DOI 10.1016/j.media.2018.03.006
   Kar MK, 2023, CIRC SYST SIGNAL PR, V42, P1206, DOI 10.1007/s00034-022-02190-5
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Li G., 2023, Biomed Signal Process Control, V79, P2022
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu ZQ, 2014, SCI REP-UK, V4, DOI 10.1038/srep04002
   Powers DMW, 2020, Arxiv, DOI arXiv:2010.16061
   Majumdar S, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119022
   Niwas SI, 2010, 2010 IEEE S IND EL A
   Nover AB, 2009, INT J BIOMED IMAGING, V2009, DOI 10.1155/2009/902326
   Pawer MM, 2022, Machine Learning and Deep Learning Techniques for Medical Science, P243, DOI [10.1201/9781003217497-14, DOI 10.1201/9781003217497-14]
   Screening PDQ Board PE, 2022, PDQ Cancer Information Summaries
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sung H, 2021, CA-CANCER J CLIN, V71, P209, DOI 10.3322/caac.21660
   Surwase S, 2023, EVOL INTELL, V16, P485, DOI 10.1007/s12065-021-00671-1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Togaçar M, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123592
   Wang CF, 2017, IEEE ENG MED BIO, P4050, DOI 10.1109/EMBC.2017.8037745
   Weyn B, 1998, CYTOMETRY, V33, P32, DOI 10.1002/(SICI)1097-0320(19980901)33:1<32::AID-CYTO4>3.0.CO;2-D
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang ZB, 2019, NEUROCOMPUTING, V366, P46, DOI 10.1016/j.neucom.2019.07.080
   Zainudin Zanariah, 2020, International Conference on Advanced Machine Learning Technologies and Applications (AMLTA2019). Advances in Intelligent Systems and Computing (AISC 921), P43, DOI 10.1007/978-3-030-14118-9_5
   Zou Y, 2022, INT J IMAG SYST TECH, V32, P266, DOI 10.1002/ima.22628
NR 37
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17717-4
EA DEC 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600001
DA 2024-07-18
ER

PT J
AU Bhagat, M
   Kumar, D
   Kumar, S
AF Bhagat, Monu
   Kumar, Dilip
   Kumar, Sunil
TI Optimized transfer learning approach for leaf disease classification in
   smart agriculture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Transfer learning; VGG-16; CNN; Xception
ID NEURAL-NETWORK; DEEP; IDENTIFICATION; IMAGES; LEAVES
AB In recent years, numerous deep learning architectures have used publicly available/author-generated datasets to classify plant diseases. This study suggested a four-stage process for classifying plant diseases using a comparative evaluation method based on deep learning. First, the ideal CNN was found by comparing basic CNN designs with adapted and hybrid versions of contemporary DL models. Second, we tried to train the best acquired model through Adam deep learning optimizers to increase its performance. Xception and VGG-16 architecture were compared using a number of different performance criteria. These metrics included validation accuracy/loss, F1-score, precision, recall, AuC and RoC. All of the chosen DL architectures were trained on three leaf species such as tomato, potato and bell pepper of the PlantVillage dataset, which includes information about 26 unique diseases that have been seen in 14 distinct plant species. To train deep learning architectures, we used Keras with TensorFlow as the backend. Overall, the Adam optimizer-trained VGG-16 architecture performed best in terms of training and validation accuracy of (98.42%, 100%, 99.75%) and (91.85%, 97.21% and 98.18%) for dataset-1, dataset-2 and dataset-3 respectively, demonstrating its superiority over prior methods and establishing its unique contribution to the field. This study's proposed method can, therefore, be used in other agricultural applications for detection and categorization in a more open and accurate manner.
C1 [Bhagat, Monu; Kumar, Dilip] Natl Inst Technol, Comp Sci & Engn, Jamshedpur, Jharkhand, India.
   [Bhagat, Monu] Techno India Grp, Comp Sci & Engn IoT, Kolkata, India.
   [Kumar, Sunil] Manipal Univ Jaipur, Comp & Commun Engn, Jaipur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; Manipal University Jaipur
RP Bhagat, M (corresponding author), Natl Inst Technol, Comp Sci & Engn, Jamshedpur, Jharkhand, India.; Bhagat, M (corresponding author), Techno India Grp, Comp Sci & Engn IoT, Kolkata, India.
EM 2018rscs002@nitjsr.ac.in
RI Bhagat, Dr. Monu/GLS-1071-2022; Kumar, Sunil/GYV-0347-2022
OI Bhagat, Dr. Monu/0000-0001-9074-9653; Kumar, Sunil/0000-0002-1953-6273
CR Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Bhagat Monu, 2019, 2019 Devices for Integrated Circuit (DevIC). Proceedings, P141, DOI 10.1109/DEVIC.2019.8783800
   Bhagat M, 2022, MULTIMED TOOLS APPL, V81, P33897, DOI 10.1007/s11042-022-12984-z
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030343
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Chollet F, 2015, KERAS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dechorgnat J, 2011, J EXP BOT, V62, P1349, DOI 10.1093/jxb/erq409
   Durmus Halil., 2017, 2017 6 INT C AGRO GE, P1, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2017.8047016
   Elhassouny A., 2019, INT C COMP SCI REN E, P1, DOI [DOI 10.1109/ICCSRE.2019.8807737, 10.1109/ICCSRE.2019.8807737]
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Fuentes AF, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01162
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Khanna M., 2023, Multim Tools Appl, V25, P1
   Kobayashi T, 2001, PHYTOPATHOLOGY, V91, P316, DOI 10.1094/PHYTO.2001.91.3.316
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Liu F, 2019, IEEE ACCESS, V7, P119209, DOI 10.1109/ACCESS.2019.2935222
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Oppenheim D, 2019, PHYTOPATHOLOGY, V109, P1083, DOI 10.1094/PHYTO-08-18-0288-R
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Praveen Kumar J., 2018, Information Processing in Agriculture
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Römer C, 2011, COMPUT ELECTRON AGR, V79, P180, DOI 10.1016/j.compag.2011.09.011
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sawarkar V, IOSR J Comput Eng (IOSR-JCE)
   Silberman N, 2016, Tf-slim
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   Singh LK, 2023, MULTIMED TOOLS APPL, P1
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Vilasini M, 2020, CMC-COMPUT MATER CON, V62, P1445, DOI 10.32604/cmc.2020.08857
   Wang DY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40066-y
   Xie CQ, 2017, COMPUT ELECTRON AGR, V135, P154, DOI 10.1016/j.compag.2016.12.015
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Zeng Y, 2021, IOP Conference Series: Earth and Environmental Science, V792
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
NR 54
TC 3
Z9 3
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17860-y
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200006
DA 2024-07-18
ER

PT J
AU Ravanbakhsh, E
   Liang, YQ
   Ramanujam, J
   Li, X
AF Ravanbakhsh, Elham
   Liang, Yongqing
   Ramanujam, J.
   Li, Xin
TI Deep video representation learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video representation learning; Feature modeling; Video feature
   extraction; Feature learning
ID SPATIOTEMPORAL ATTENTION; NETWORK; FUSION
AB This paper provides a review on representation learning for videos. We classify recent spatio-temporal feature learning methods for sequential visual data and compare their pros and cons for general video analysis. Building effective features for videos is a fundamental problem in computer vision tasks involving video analysis and understanding. Existing features can be generally categorized into spatial and temporal features. Their effectiveness under variations of illumination, occlusion, view and background are discussed. Finally, we discuss the remaining challenges in existing deep video representation learning studies.
C1 [Ravanbakhsh, Elham; Ramanujam, J.] Louisiana State Univ, Div Elect & Comp Engn, Baton Rouge, LA 70803 USA.
   [Ravanbakhsh, Elham; Ramanujam, J.] Louisiana State Univ, Ctr Computat & Technol, Baton Rouge, LA 70803 USA.
   [Liang, Yongqing; Li, Xin] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.
   [Li, Xin] Texas A&M Univ, Sch Performance Visualizat & Fine Arts, Sect Visual Comp & Interact Media, College Stn, TX 77843 USA.
C3 Louisiana State University System; Louisiana State University; Louisiana
   State University System; Louisiana State University; Texas A&M
   University System; Texas A&M University College Station; Texas A&M
   University System; Texas A&M University College Station
RP Li, X (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.; Li, X (corresponding author), Texas A&M Univ, Sch Performance Visualizat & Fine Arts, Sect Visual Comp & Interact Media, College Stn, TX 77843 USA.
EM ervan1@lsu.edu; lyq@tamu.edu; jxr@cct.lsu.edu; xinli@tamu.edu
OI Li, Xin/0000-0002-0144-9489
FU National Science Foundation
FX No Statement Available
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Athar A, 2022, CVPR
   Azulay A, 2022, WACV
   Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056
   Bendre N, 2022, WORLD AUT C, ppp371
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Botach A, 2022, PROC CVPR IEEE, P4975, DOI 10.1109/CVPR52688.2022.00493
   Bruce XB, 2022, PAMI
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Cai JM, 2021, IEEE WINT CONF APPL, P2734, DOI 10.1109/WACV48630.2021.00278
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen Minghao, 2022, CVPR, P13801
   Chen XJ, 2015, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2015.7299020
   Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130
   Chen Z, 2016, OPT LASER TECHNOL, V80, P1, DOI 10.1016/j.optlastec.2015.12.013
   Cheng HK, 2021, CVPR
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Cho S, 2022, WACV, ppp129
   Choi J, 2019, NIPS, V32
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Cuevas C, 2020, MULTIMED TOOLS APPL, V79, P29685, DOI 10.1007/s11042-020-09409-0
   Dai R, 2022, PROC CVPR IEEE, P20009, DOI 10.1109/CVPR52688.2022.01941
   Dai XY, 2019, IEEE WINT CONF APPL, P151, DOI 10.1109/WACV.2019.00022
   De Boissiere AM, 2020, IEEE ACCESS, V8, P168297, DOI 10.1109/ACCESS.2020.3023599
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   deSouzaReis E, 2021, Pattern Recognit
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan HD, 2022, PROC CVPR IEEE, P2959, DOI 10.1109/CVPR52688.2022.00298
   Eun H, 2020, PROC CVPR IEEE, P806, DOI 10.1109/CVPR42600.2020.00089
   Fabbri Matteo, 2018, ECCV
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gao RH, 2020, PROC CVPR IEEE, P10454, DOI 10.1109/CVPR42600.2020.01047
   Gavrilyuk K, 2018, PROC CVPR IEEE, P5958, DOI 10.1109/CVPR.2018.00624
   Girdhar R, 2017, ADV NEUR IN, V30
   Hao XK, 2021, IEEE T IMAGE PROCESS, V30, P2263, DOI 10.1109/TIP.2021.3051495
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herzig R, 2022, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR52688.2022.00315
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Hu L, 2021, PROC CVPR IEEE, P4142, DOI 10.1109/CVPR46437.2021.00413
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Huang X, 2020, CVPR
   Huang ZW, 2017, PROC CVPR IEEE, P1243, DOI 10.1109/CVPR.2017.137
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Hussein N, 2019, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2019.00034
   Iqbal U, 2017, IEEE INT CONF AUTOMA, P438, DOI 10.1109/FG.2017.61
   Ji YL, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107807
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Karbalaie A, 2022, MULTIMED TOOLS APPL, V81, P35463, DOI 10.1007/s11042-021-11864-2
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Ke L, 2021, P IEEECVF INT C COMP, P14468
   Ke L, 2021, PROC CVPR IEEE, P4018, DOI 10.1109/CVPR46437.2021.00401
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim J, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108068
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kniaz VV, 2018, ECCV WORKSHOPS, P0
   Kong Y, 2020, IEEE T PATTERN ANAL, V42, P539, DOI 10.1109/TPAMI.2018.2882805
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Korbar B, 2019, IEEE I CONF COMP VIS, P6241, DOI 10.1109/ICCV.2019.00633
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1709.05584, 10.48550/arXiv.1709.05584]
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li B, 2017, IEEE INT C COMPUT, P187, DOI 10.1109/CSE-EUC.2017.217
   Li C, 2017, IEEE INT CONF MULTI
   Li J, 2020, IEEE T MULTIMEDIA, V22, P2990, DOI 10.1109/TMM.2020.2965434
   Li Mingxing, 2022, CVPR, P1332
   Li S., 2019, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, P3595
   Li S, 2020, IEEE WINT CONF APPL, P575, DOI [10.1109/wacv45572.2020.9093618, 10.1109/WACV45572.2020.9093618]
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li X, WACV, P3683
   Li YS, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107293
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587
   Liang W, 2018, AAAI CONF ARTIF INTE, P7106
   Liang Y., 2020, Adv. Neural Inf. Proces. Syst., V33, P3430
   Lin HJ, 2019, IEEE I CONF COMP VIS, P3948, DOI 10.1109/ICCV.2019.00405
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lin S., 2022, CVPR, p10 915
   Lin Z, CVPR, P1362
   Liu D, 2021, P IEEECVF C COMPUTER, ppp9816
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu J, 2017, INT C DIG IM COMP TE, P1
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P5573, DOI 10.1109/TIP.2021.3086590
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Lu YW, 2023, PROC CVPR IEEE, P18063, DOI 10.1109/CVPR52729.2023.01732
   Luo CX, 2019, IEEE I CONF COMP VIS, P5511, DOI 10.1109/ICCV.2019.00561
   Luvizon DC, 2021, IEEE T PATTERN ANAL, V43, P2752, DOI 10.1109/TPAMI.2020.2976014
   Lv Z, 2022, Complexity problems handled by advanced computer simulation technology in smart cities 2021
   Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Neimark D, 2021, ICCV, ppp3163
   Oh SW, 2019, PROC CVPR IEEE, P5242, DOI 10.1109/CVPR.2019.00539
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Park K, 2022, CVPR, P1352
   Patrick M, 2021, P INT C NEUR INF PRO, P12493
   Peng WT, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258245
   Pexels, Pexels
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013
   Pont-Tuset J, 2018, Arxiv, DOI arXiv:1704.00675
   Qin XL, 2020, NEUROCOMPUTING, V406, P127
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Ren SC, 2021, PROC CVPR IEEE, P15450, DOI 10.1109/CVPR46437.2021.01520
   Robinson Andreas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7404, DOI 10.1109/CVPR42600.2020.00743
   Seonguk Seo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P208, DOI 10.1007/978-3-030-58555-6_13
   Seoung Wug Oh, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P9225, DOI 10.1109/ICCV.2019.00932
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sharma S, 2016, Arxiv, DOI arXiv:1511.04119
   Shi L., 2019, P IEEE CVF C COMP VI, P7912
   Shi L., 2020, P ASIAN C COMPUTER V
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi Lei, 2019, CVPR
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, Arxiv, DOI arXiv:1406.2199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Su L, 2021, Arxiv, DOI arXiv:2012.07175
   Sudhakaran S, 2020, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR42600.2020.00118
   Sun M., 2020, P IEEE CVF C COMP VI, P10791
   Thakkar K, 2018, Arxiv, DOI arXiv:1809.04983
   Truong TD, 2022, PROC CVPR IEEE, P19998, DOI 10.1109/CVPR52688.2022.01940
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   Vaswani A, 2017, ADV NEUR IN, V30
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Ventura C, 2019, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2019.00542
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang LM, 2015, Arxiv, DOI arXiv:1507.02159
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang M., 2020, PAMI
   Wang P, 2017, ICCV WORKSHOPS
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang X, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108220
   Wang ZQ, 2019, IEEE I CONF COMP VIS, P3977, DOI 10.1109/ICCV.2019.00408
   Wen YH, 2019, AAAI CONF ARTIF INTE, P8989
   Wu C, 2019, IEEE INT CONF COMP V, P1740, DOI 10.1109/ICCVW.2019.00216
   Wu D, 2022, P IEEE CVF C COMP VI, P4996
   Wu J, 2022, Proceedings of the ieee/cvf conference on computer vision and pattern recognition, P4974
   Wu Jialian, 2022, CVPR
   Wu WH, 2019, IEEE I CONF COMP VIS, P6231, DOI 10.1109/ICCV.2019.00632
   Xi Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9381, DOI 10.1109/CVPR42600.2020.00940
   Xie HZ, 2021, PROC CVPR IEEE, P1286, DOI 10.1109/CVPR46437.2021.00134
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu C, 2017, INT J COMPUT VISION, V123, P454, DOI 10.1007/s11263-017-0998-6
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu K, 2022, PROC CVPR IEEE, P1332, DOI 10.1109/CVPR52688.2022.00140
   Xu K, 2019, PROC CVPR IEEE, P1379, DOI 10.1109/CVPR.2019.00147
   Xu MZ, 2019, IEEE I CONF COMP VIS, P5531, DOI 10.1109/ICCV.2019.00563
   Xu N, 2018, Arxiv, DOI arXiv:1809.03327
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan An, 2019, CVPR
   Yan An, 2019, CVPR, P7922
   Yan LQ, 2022, Arxiv, DOI arXiv:2205.10706
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang H, 2022, IEEE T IMAGE PROCESS, V31, P164, DOI 10.1109/TIP.2021.3129117
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yang JW, 2022, PROC CVPR IEEE, P14043, DOI 10.1109/CVPR52688.2022.01367
   Yang LL, 2019, PROC CVPR IEEE, P9869, DOI 10.1109/CVPR.2019.01011
   Yu BXB, 2021, AAAI CONF ARTIF INTE, V35, P3199
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yue Meng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P86, DOI 10.1007/978-3-030-58571-6_6
   Zhang D., 2018, P ASIAN C COMPUTER V, P712
   Zhang K, 2021, P IEEE CVF INT C COM, P8781
   Zhang L, 2019, IEEE I CONF COMP VIS, P5581, DOI 10.1109/ICCV.2019.00568
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang Y., 2022, WACV, P2564
   Zhao H, 2019, IEEE I CONF COMP VIS, P7002, DOI 10.1109/ICCV.2019.00710
   Zhao L, 2021, PROC CVPR IEEE, P12788, DOI 10.1109/CVPR46437.2021.01260
   Zheng W, 2019, Arxiv, DOI [arXiv:1805.02556, DOI 10.48550/ARXIV.1805.02556]
   Zheng ZX, 2021, IEEE T NEUR NET LEAR, V32, P334, DOI 10.1109/TNNLS.2020.2978613
   Zhou CL, 2017, IEEE I CONF COMP VIS, P3506, DOI 10.1109/ICCV.2017.377
   Zhou Q., 2022, P IEEE CVF C COMP VI, P10894
   Zhou Y, 2022, CVPR
   Zhu DY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1399, DOI 10.1145/3292500.3330851
   Zhu JG, 2018, Arxiv, DOI arXiv:1812.05770
   Ziwei Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12403, DOI 10.1109/CVPR42600.2020.01242
   Zolfaghari M., 2021, P IEEECVF INT C COMP, P1450
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 209
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17815-3
EA DEC 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qian, K
   Shen, JL
   Wang, SQ
   Sun, WJ
AF Qian, Kun
   Shen, Jianlu
   Wang, Shiqing
   Sun, Wenjun
TI Recent advances in object tracking using hyperspectral videos: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyperspectral video; Target tracking; Correlation filter; Deep learning
ID VISUAL TRACKING; TARGET TRACKING; IMAGE; NETWORKS; PCA
AB Short-Term Single-Object (STSO) tracking using Hyperspectral Videos (HSVs), which has become a hotspot recently, is a challenging task. Hyperspectral Object Tracking (HOT) makes full use of spatial and spectral information during the tracking process. In HOT, multiple features, including deep network features, have been combined with correlation filter methods, which increases time-consuming efficiency and tracking accuracy. However, redundant spectral information needs to be obtained in an effective way. In addition, there is currently no detailed investigation of HOT algorithms. Therefore, this survey studies the development of HOT algorithms in recent years. Specifically, several HSVs are listed, an investigation of HOT algorithms is conducted, and components of HOT are described in detail. Furthermore, several popular HOT algorithms, including our previous work BS-SiamPRN and AD-SiamRPN, are compared quantitatively and qualitatively. Finally, the research status of HOT is summarized, and future work has been described, which lays the foundation for future HOT or STSO referring to HSVs.
C1 [Qian, Kun; Shen, Jianlu; Wang, Shiqing; Sun, Wenjun] JiangNan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Qian, K (corresponding author), JiangNan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
EM kqian@jiangnan.edu.cn
FU the Fundamental Research Funds for the Central Universities
   [JUSRP121072]; Fundamental Research Funds for the Central Universities
   [DTEC202202]; Jiangsu Engineering Research Center of Digital Twinning
   Technology for Key Equipment in Petrochemical Process [BZ2020069];
   International Science and Technology Cooperation Project of Jiangsu
   Province [21KJA520001]; Major Program of University Natural Science
   Research of Jiangsu Province
FX We are grateful to the workers who have made contributions to
   hyperspectral video tracking for providing us with novel tracking
   methods and accurate experimental results. This work is partially
   supported by the Fundamental Research Funds for the Central Universities
   (JUSRP121072), Jiangsu Engineering Research Center of Digital Twinning
   Technology for Key Equipment in Petrochemical Process (DTEC202202), the
   International Science and Technology Cooperation Project of Jiangsu
   Province (BZ2020069), and the Major Program of University Natural
   Science Research of Jiangsu Province (21KJA520001).
CR Amigo JM, 2015, ANAL CHIM ACTA, V896, P34, DOI 10.1016/j.aca.2015.09.030
   Anderson GL, 2005, INT J REMOTE SENS, V26, P2487, DOI 10.1080/01431160310001618068
   Banerjee A, 2009, 009 1 WORKSH HYP IM, P1
   Barquero G, 2021, arXiv
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Chang C.-I., 2016, Real-TIme Progressive Hyperspectral Image Processing, P75, DOI DOI 10.1007/978-1-4419-6187-7
   Chen LL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13101922
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Ghafir I, 2016, 2016 IEEE 4TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD WORKSHOPS (FICLOUDW), P77, DOI 10.1109/W-FiCloud.2016.30
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He YJ, 2015, INFRARED PHYS TECHN, V73, P103, DOI 10.1016/j.infrared.2015.09.010
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hou ZF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090802
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kittler J, 1998, PROC CVPR IEEE, P924, DOI 10.1109/CVPR.1998.698715
   Kong J, 2020, IET IMAGE PROCESS, V14, P1701, DOI 10.1049/iet-ipr.2019.0827
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   Kumar A, 2013, IEEE SENS J, V13, P1329, DOI 10.1109/JSEN.2012.2233469
   Kun Qian, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P308, DOI 10.1007/978-3-030-04375-9_26
   Lan XY, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3430257
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Lei J, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14153512
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Li W., 2023, IEEE Trans. Geosci. Remote Sens.
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Li XJ, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P114
   Li X, 2019, KNOWL-BASED SYST, V166, P71, DOI 10.1016/j.knosys.2018.12.011
   Li ZAF, 2021, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS52202.2021.9484032
   Li ZAF, 2020, IEEE IMAGE PROC, P2106, DOI 10.1109/ICIP40778.2020.9191105
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2020, IET IMAGE PROCESS, V14, P2227, DOI 10.1049/iet-ipr.2019.0881
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu YH, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15030840
   Liu ZQ, 2022, IEEE T IMAGE PROCESS, V31, P7116, DOI 10.1109/TIP.2022.3216995
   Liu ZQ, 2021, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS52202.2021.9483958
   Liu ZQ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3111183
   Lu Shan, 2011, Journal of Agricultural Meteorology, V67, P85, DOI 10.2480/agrmet.67.2.1
   Lu XH, 2019, NEUROCOMPUTING, V348, P134, DOI 10.1016/j.neucom.2018.06.090
   Luo WH, 2011, IEEE IMAGE PROC, P485, DOI 10.1109/ICIP.2011.6116557
   Marchal S, 2014, IEEE INT CONGR BIG, P56, DOI 10.1109/BigData.Congress.2014.18
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   McDonald TL, 2003, ENVIRON MONIT ASSESS, V85, P277, DOI 10.1023/A:1023954311636
   Moorthy S, 2020, NEUROCOMPUTING, V411, P78, DOI 10.1016/j.neucom.2020.06.016
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Oliveira Luis M. L., 2011, Journal of Communications, V6, P143, DOI 10.4304/jcm.6.2.143-151
   Plaza A, 2009, REMOTE SENS ENVIRON, V113, pS110, DOI 10.1016/j.rse.2007.07.028
   Qian K, 2023, IET IMAGE PROCESS, V17, P1578, DOI 10.1049/ipr2.12739
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sanders C., 2013, Applied network security monitoring: Collection, detection, and analysis
   Shen MH, 2022, IEEE T IMAGE PROCESS, V31, P6991, DOI 10.1109/TIP.2022.3217365
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su N, 2022, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS56178.2022.9955082
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tu B, 2019, INT J REMOTE SENS, V40, P9484, DOI 10.1080/01431161.2019.1633699
   Uzkent B, 2019, IEEE T GEOSCI REMOTE, V57, P449, DOI 10.1109/TGRS.2018.2856370
   Uzkent B, 2017, IEEE COMPUT SOC CONF, P233, DOI 10.1109/CVPRW.2017.35
   Uzkent B, 2016, IEEE COMPUT SOC CONF, P1443, DOI 10.1109/CVPRW.2016.181
   Uzkent B, 2015, PROCEDIA COMPUT SCI, V51, P2493, DOI 10.1016/j.procs.2015.05.358
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Van Nguyen H., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops, P44
   Vasile M, 2023, ACTA ASTRONAUT, V203, P510, DOI 10.1016/j.actaastro.2022.11.039
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N., 2013, Adv Neural Inf Process Syst, V26
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang S, 2019, Arxiv, DOI arXiv:1811.11329
   Wang SQ, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15071731
   Wang SQ, 2022, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS56178.2022.9955025
   Wang Y, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15071735
   Wang Y, 2022, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS56178.2022.9955100
   Wei BB, 2022, NEUROCOMPUTING, V471, P161, DOI 10.1016/j.neucom.2021.10.112
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiong FC, 2020, IEEE T IMAGE PROCESS, V29, P3719, DOI 10.1109/TIP.2020.2965302
   Xiu CB, 2019, IET IMAGE PROCESS, V13, P498, DOI 10.1049/iet-ipr.2018.5461
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yin Z, 2008, 2008 IEEE WORKSH APP, P1
   Yu HY, 2020, INT J COMPUT VISION, V128, P1141, DOI 10.1007/s11263-019-01266-1
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang L, 2017, PATTERN RECOGN, V69, P82, DOI 10.1016/j.patcog.2017.04.004
   Zhang T, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3216532
   Zhang YF, 2022, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS56178.2022.9955094
   Zhang Z, 2022, Remote Sens, V14
   Zhang Z, 2021, WORK HYPERSP IMAG, DOI 10.1109/WHISPERS52202.2021.9484029
   Zhao CH, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122765
   Zhao D, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14246219
   Zhao HS, 2021, IEEE T GEOSCI REMOTE, V59, P9616, DOI 10.1109/TGRS.2020.3047223
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 100
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17758-9
EA DEC 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800005
DA 2024-07-18
ER

PT J
AU Chhabra, R
   Goswami, S
   Ranjan, RK
AF Chhabra, Raunak
   Goswami, Shailza
   Ranjan, Ranjeet Kumar
TI A voting ensemble machine learning based credit card fraud detection
   using highly imbalance data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Credit card fraud detection; Machine learning; Ensemble learning; Voting
   ensemble; Class imbalance
ID CLASSIFICATION
AB Long gone is the time when people preferred using only cash. In recent years, cashless transactions have gained much popularity, be it using UPI apps or credit and debit cards. The same has even led to a significant increase in the number of credit card fraud cases. Detecting fraudulent transactions is a challenging task as the fraudsters disguise the ordinary conduct of clients in order to perform fraud. Automated intelligent credit card fraud detection can be employed for detecting fraudulent transactions. In this paper, we proposed a credit card fraud detection approach involving an arrangement of supervised machine learning algorithms called ensemble learning. One of the difficulties looked at during the time spent to distinguish fraud transactions in datasets is the imbalanced class distribution. In this work, we employed an ensemble learning model in combination with two data-level techniques for handling class imbalance problems. The proposed approach is the ensemble of three base classifiers including random forest, logistic regress and K-nearest neighbour along with two data-level algorithms namely random oversampling and random undersampling. To combine the predictions of the base classifiers, the weighted voting ensemble approach is used. The proposed approach is evaluated using a highly imbalanced credit card transaction dataset. The proposed approach is evaluated using various sets of weights in order to identify the best possible outcomes in terms of accuracy and minimise the misclassification of fraudulent transactions.
C1 [Chhabra, Raunak; Goswami, Shailza] DIT Univ, Sch Comp, Dehra Dun 248009, Uttarakhand, India.
   [Ranjan, Ranjeet Kumar] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 DIT University; Thapar Institute of Engineering & Technology
RP Ranjan, RK (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM ranjeetghitm@gmail.com
OI Ranjan, Ranjeet Kumar/0000-0002-8796-4579
CR Ahmad Hadeel, 2023, Int J Inf Technol, V15, P325, DOI 10.1007/s41870-022-00987-w
   Alejo R, 2013, PATTERN RECOGN LETT, V34, P380, DOI 10.1016/j.patrec.2012.09.003
   Alfaiz NS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11040662
   Alghofaili Y, 2020, J APPL SEC RES, V15, P498, DOI 10.1080/19361610.2020.1815491
   Ali Aida, 2013, Int. J. Adv. Soft Comput. Appl., V5
   Asha R., 2021, Glob. Transit. Proc., V2, P35
   Aswathi KB, 2021, 2021 12 INT C COMP C
   Awoyemi JO, 2017, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTING NETWORKING AND INFORMATICS (ICCNI 2017)
   Bagga S., 2020, Procedia Computer Science, V173, P104, DOI [DOI 10.1016/J.PROCS.2020.06.014, 10.1016/J.PROCS.2020.06.014]
   Benchaji Ibtissam, 2019, Smart Data and Computational Intelligence. Proceedings of the International Conference on Advanced Information Technology, Services and Systems (AIT2S-18). Lecture Notes in Networks and Systems (LNNS 66), P220, DOI 10.1007/978-3-030-11914-0_24
   Bolton RJ, 2002, STAT SCI, V17, P235
   Bora A, 2022, 2022 10 INT C REL IN, P1
   Britannica. Credit Card, 2016, Encycl. Br.
   Brownlee J., 2018, Imbalanced classification with Python: better metrics, balance skewed classes, cost-sensitive learning
   CCDataset, 2018, Mach Learn Gr-ULB, P1
   Chan PK, 1999, IEEE INTELL SYST APP, V14, P67, DOI 10.1109/5254.809570
   Chowdhury S, 2020, 2020 INT ENG TECHN C
   Dal Pozzolo A, 2018, IEEE T NEUR NET LEAR, V29, P3784, DOI 10.1109/TNNLS.2017.2736643
   Dal Pozzolo A, 2014, EXPERT SYST APPL, V41, P4915, DOI 10.1016/j.eswa.2014.02.026
   Devikar M, 2020, Int Res J Eng Technol, V7
   Dietterich TG, 1997, AI MAG, V18, P97
   Dornadula VN, 2019, PROCEDIA COMPUT SCI, V165, P631, DOI 10.1016/j.procs.2020.01.057
   El-Naby AA, 2023, MULTIMED TOOLS APPL, V82, P4139, DOI 10.1007/s11042-022-13434-6
   Esenogho E, 2022, IEEE ACCESS, V10, P16400, DOI 10.1109/ACCESS.2022.3148298
   Fanai H, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119562
   Garg A, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100370
   Gerson ES, 2023, Steps to take if you are the victim of credit card fraud
   Ghosh S., 1994, Proceedings of the Twenty-Seventh Hawaii International Conference on System Sciences. Vol.III: Information Systems: Decision Support and Knowledge-Based Systems (Cat. No.94TH0607-2), P621, DOI 10.1109/HICSS.1994.323314
   Gupta A, 2021, J DISCRET MATH SCI C, V24, P1559, DOI 10.1080/09720529.2021.1969733
   Hand DJ, 1997, J R STAT SOC A STAT, V160, P523
   Haseeb Ali, 2019, IJET, V8, P390, DOI [10.14419/ijet.v8i3.29508, DOI 10.14419/IJET.V8I3.29508]
   Hasib K M., 2020, Journal of Computer Science, V16, P1546, DOI DOI 10.3844/JCSSP.2020.1546.1557
   Jin W, 2020, J Phys Conf Ser. Institute of Physics Publishing
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Joshi C., 2021, Proceedings of the International Conference on Paradigms of Computing, Communication and Data Sciences, P717, DOI [10.1007/978-981-15-7533-4_56, DOI 10.1007/978-981-15-7533-4_56]
   Joshi C., 2021, Int J Comput Digit Syst, V11, P1391, DOI [10.12785/ijcds/1101107, DOI 10.12785/IJCDS/1101107]
   Jurgovsky J, 2018, EXPERT SYST APPL, V100, P234, DOI 10.1016/j.eswa.2018.01.037
   Kho JRD, 2017, TENCON IEEE REGION, P1880, DOI 10.1109/TENCON.2017.8228165
   Kumari N., 2014, MIDDLE EAST J SCI RE, V20, P697, DOI DOI 10.5829/idosi.mejsr.2014.20.06.11387
   Maalouf Maher, 2011, International Journal of Data Analysis Techniques and Strategies, V3, P281, DOI 10.1504/IJDATS.2011.041335
   Mienye ID, 2023, IEEE ACCESS, V11, P30628, DOI 10.1109/ACCESS.2023.3262020
   Mill E, 2023, INT J ADV COMPUT SC, V14, P1172
   Modi K, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL (I2C2)
   Mohammed R, 2020, INT CONF INFORM COMM, P243, DOI 10.1109/ICICS49469.2020.239556
   Mrinali K, 2021, Investopedia
   Najadat H, 2020, INT CONF INFORM COMM, P204, DOI 10.1109/ICICS49469.2020.239524
   Nishi NJ, 2022, 2022 4 INT C SUST TE, P1
   Odegua RO, 2019, An empirical study of ensemble techniques (Bagging, Boosting and Stacking)
   Pillai T.R., 2018, 2018 Fourth International Conference on Advances in Computing, Communication Automation (ICACCA), P1
   Plakandaras V, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2086354
   Polikar R, 2009, Ensemble-based system
   Psychoula I, 2021, COMPUTER, V54, P49, DOI 10.1109/MC.2021.3081249
   Rahmani AM, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9222970
   Rakhshaninejad M, 2022, COMPUT J, V65, P1998, DOI 10.1093/comjnl/bxab038
   Randhawa K, 2018, IEEE ACCESS, V6, P14277, DOI 10.1109/ACCESS.2018.2806420
   Sahithi Gajula Lakshmi, 2022, 2022 6th International Conference on Trends in Electronics and Informatics (ICOEI), P1237, DOI 10.1109/ICOEI53556.2022.9776955
   Salman R, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00607-1
   Sánchez D, 2009, EXPERT SYST APPL, V36, P3630, DOI 10.1016/j.eswa.2008.02.001
   Shenvi P, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI [10.1109/RAICS51191.2020.9332497, 10.1109/raics51191.2020.9332497]
   Shirgave SK, 2019, Int J Sci Technol Res, V8
   Singh A, 2022, J EXP THEOR ARTIF IN, V34, P571, DOI 10.1080/0952813X.2021.1907795
   Sohony I, 2018, PROCEEDINGS OF THE ACM INDIA JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA (CODS-COMAD'18), P289, DOI 10.1145/3152494.3156815
   Thach NH, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P132, DOI 10.1109/FSKD.2008.391
   Thennakoon A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P488, DOI [10.1109/confluence.2019.8776942, 10.1109/CONFLUENCE.2019.8776942]
   Trivedi N K., 2020, International Journal of Advanced Science and Technology, V29, P3414
   UCSD, 2019, UCSD: University of California, San Diego Data Mining Contest 2009
   Valentini G, 2002, LECT NOTES COMPUT SC, V2486, P3
   Van Belle R, 2023, DECIS SUPPORT SYST, V164, DOI 10.1016/j.dss.2022.113866
   Varun Kumar K.S., 2020, Int. J. Eng. Res. Technol, V9, DOI [10.17577/ijertv9is070649, DOI 10.17577/IJERTV9IS070649]
   Whitrow C, 2009, DATA MIN KNOWL DISC, V18, P30, DOI 10.1007/s10618-008-0116-z
   Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95
   Xie YL, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/2531210
   Yang CY, 2009, NEUROCOMPUTING, V73, P397, DOI 10.1016/j.neucom.2009.08.006
   Ying X, 2014, Ensemble learning
   Younas MZ., 2021, Universe Int J Interdiscip Res, V1, P274
   Zareapoor M, 2015, PROCEDIA COMPUT SCI, V48, P679, DOI 10.1016/j.procs.2015.04.201
   Zhu H, 2023, IEEE Trans Comput Soc Syst
NR 77
TC 0
Z9 0
U1 10
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17766-9
EA DEC 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300002
DA 2024-07-18
ER

PT J
AU Kumar, D
   Mehta, MA
   Joshi, VC
   Oza, RS
   Kotecha, K
   Lin, JCW
AF Kumar, Dheeraj
   Mehta, Mayuri A.
   Joshi, Vivek C.
   Oza, Rachana S.
   Kotecha, Ketan
   Lin, Jerry Chun-Wei
TI Empirical evaluation of filter pruning methods for acceleration of
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN acceleration; CNN model compression; CNN pruning; Filter pruning;
   Neural network pruning
AB Training and inference of deep convolutional neural networks are usually slow due to the depth of the network and the number of parameters in the network. Although high-performance processors usually accelerate the training of these networks, their use on resource-constrained devices is still limited. Several compression-based acceleration methods have been presented to optimize the performance of neural networks. However, their use and adaptation are still limited due to their adverse effects on the network structure. Therefore, different filter pruning methods have been proposed to keep the network structure intact. To better solve the above limitations, we first propose a detailed classification of model acceleration method to explain the different ways of enhancing the inference performance of the convolutional neural network. Second, we present a broad classification of filter pruning methods including the comparison of these methods. Third, we present an empirical evaluation of four filter pruning methods to understand the effects of filter pruning on model accuracy and parameter reduction. Fourth, we perform several experiments with ResNet20, a pre-trained CNN, and with the proposed custom CNN to show the effect of filter pruning on them. ResNet20 is used to address the multiclass classification using CIFAR 10 dataset and custom CNN is used to address the binary classification using Leukaemia image classification dataset that includes low-information medical images. The experimental results show that among the four filter pruning methods, the soft filter pruning method best preserves the accuracy of the original model for both ResNet20 and the custom CNN. In addition, the sampling-based filter pruning method shows the highest reduction of 99.8% in parameters on custom CNN. The overall results show a reasonable pruning ratio within five training epochs for both the pre-trained CNN and custom CNN. In addition, our results show that pruning redundant filters significantly reduces the model size, and number of floating point operations.
C1 [Kumar, Dheeraj; Joshi, Vivek C.; Oza, Rachana S.] Gujarat Technol Univ, Comp IT Engn, Ahmadabad, India.
   [Mehta, Mayuri A.] Sarvajanik Coll Engn & Technol, Dept Comp Engn, Surat, India.
   [Kotecha, Ketan] Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence, Pune, India.
   [Lin, Jerry Chun-Wei] Silesian Tech Univ, Fac Automat Control Elect & Comp Sci, Gliwice, Poland.
C3 Gujarat Technological University; Sarvajanik College of Engineering &
   Technology; Symbiosis International University; Silesian University of
   Technology
RP Kumar, D (corresponding author), Gujarat Technol Univ, Comp IT Engn, Ahmadabad, India.
EM dheeraj.singh@paruluniversity.ac.in; mayuri.mehta@scet.ac.in;
   vcjoshi@rngpit.ac.in; rachana.oza@scet.ac.in; head@scaai.siu.edu.in;
   jerrylin@ieee.org
RI Kotecha, Ketan/U-3927-2017
OI Singh, Dheeraj Kumar/0000-0001-5071-3306; Oza,
   Rachana/0000-0001-8159-4055
CR [Anonymous], 2016, CoRR
   Augasta MG, 2013, OPEN COMPUT SCI, V3, P105, DOI 10.2478/s13537-013-0109-x
   Babaiee Z, 2022, arXiv, DOI [10.48550/ARXIV.2204.07412, DOI 10.48550/ARXIV.2204.07412]
   Basha SHS, 2021, Deep model compression based on the Training History
   Berthelier A, 2021, J SIGNAL PROCESS SYS, V93, P863, DOI 10.1007/s11265-020-01596-1
   Blalock D, 2020, Arxiv, DOI [arXiv:2003.03033, DOI 10.48550/ARXIV.2003.03033]
   Ch S, 2022, NEUROCOMPUTING, V514, P101, DOI 10.1016/j.neucom.2022.09.150
   Cheng Y, 2020, Arxiv, DOI [arXiv:1710.09282, DOI 10.48550/ARXIV.1710.09282]
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Chu C, 2020, IEEE INT SYM BROADB, DOI 10.1109/BMSB49480.2020.9379712
   Ding XH, 2019, Arxiv, DOI arXiv:1905.04748
   Elhoushi M, 2019, Arxiv, DOI arXiv:1909.05675
   Erick FX, 2022, ICAART, P139, DOI 10.5220/0010786400003116
   Ghimire D, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13010316
   Gholami A., 2021, arXiv
   Guo YW, 2016, Arxiv, DOI arXiv:1608.04493
   Han S, 2015, Arxiv, DOI arXiv:1506.02626
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Jacob B, 2017, PROC CVPR IEEE
   Kahatapitiya K, 2019, Comput Vis Pattern Recognit
   Li G, 2021, IET IMAGE PROCESS, V15, P405, DOI 10.1049/ipr2.12030
   Li H., 2017, PRUNING FILTERS EFFI, DOI DOI 10.48550/ARXIV.1608.08710
   Li X, 2019, IEEE INT SYM BROADB, DOI 10.1109/bmsb47279.2019.8971889
   Liebenwein L, 2019, arXiv
   Lin SH, 2020, IEEE T NEUR NET LEAR, V31, P574, DOI 10.1109/TNNLS.2019.2906563
   Liu YJ, 2023, NEUROCOMPUTING, V526, P131, DOI 10.1016/j.neucom.2023.01.014
   Liu Z, 2019, Arxiv, DOI arXiv:1810.05270
   Louizos C., 2018, INT C LEARNING REPRE
   Luo JH, 2017, Arxiv, DOI arXiv:1706.05791
   Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232
   Marinó GC, 2023, NEUROCOMPUTING, V520, P152, DOI 10.1016/j.neucom.2022.11.072
   Mondal M, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103511
   Mourya Simmi, 2019, TCIA
   Mousa-Pasandi M, 2020, Arxiv, DOI arXiv:2002.03299
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Pietron M, 2020, Retrain or not retrain?-Efficient pruning methods of deep cnn networks
   Rychetsky M., 1998, Proceedings of NC 1998. International ICSC/IFAC Symposium on Neural Computation, P603
   Sabih M, 2022, PROCEEDINGS OF THE 2022 2ND EUROPEAN WORKSHOP ON MACHINE LEARNING AND SYSTEMS (EUROMLSYS '22), P109, DOI 10.1145/3517207.3526982
   Sándor C, 2020, FRONT ARTIF INTEL AP, V325, P1435, DOI 10.3233/FAIA200249
   Sawant SS, 2022, APPL INTELL, V52, P17557, DOI 10.1007/s10489-022-03229-5
   Shao MW, 2021, SIGNAL IMAGE VIDEO P, V15, P381, DOI 10.1007/s11760-020-01760-x
   Shi CK, 2023, NEUROCOMPUTING, V528, P113, DOI 10.1016/j.neucom.2023.01.046
   Singh A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.15751
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Swaminathan S, 2020, NEUROCOMPUTING, V398, P185, DOI 10.1016/j.neucom.2020.02.035
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tofigh S, 2022, IEEE SIGNAL PROC LET, V29, P1012, DOI 10.1109/LSP.2022.3164328
   Tyree S, 2017, Pruning convolutional neural networks for resource efficient inference
   Wang H, 2018, Arxiv, DOI arXiv:1811.08390
   Wang YL, 2020, AAAI CONF ARTIF INTE, V34, P12273
   Wang ZY, 2020, NEUROCOMPUTING, V404, P247, DOI 10.1016/j.neucom.2020.03.082
   Wu H., 2020, arXiv
   Wu ZH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12094541
   Xu S, 2020, CHIN CONTR CONF, P7458, DOI 10.23919/CCC50068.2020.9189610
   Yeom SK, 2019, arXiv, DOI [10.1016/j.patcog.2021.107899, DOI 10.1016/J.PATCOG.2021.107899]
   Zhou YF, 2019, IEEE I CONF COMP VIS, P3305, DOI 10.1109/ICCV.2019.00340
   Zhu M.H., 2017, PREPRINTS
NR 59
TC 0
Z9 0
U1 8
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 7
PY 2023
DI 10.1007/s11042-023-17656-0
EA DEC 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9MN6
UT WOS:001115250300003
DA 2024-07-18
ER

PT J
AU Bhatt, A
   Bhatt, VT
AF Bhatt, Abhishek
   Bhatt, Vandana Thakur
TI Dcrff-Lhrf: an improvised methodology for efficient land-cover
   classification on eurosat dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Land-cover classification; Remote sensing; Satellite images; ResNet-50;
   Deep Convolution Neural Network (Deep CNN); EuroSAT Dataset; Feature
   level fusion; Principal Component Analysis
AB Rise in global wide population has created lot of demand across various fields and realm. As a result, many recent research mainly focuses on LCC (Land Cover Classification) which are associated with spatial distribution. Therefore, LCC plays an important role for government organizations, policy makers and farmers in order to enhance the process of decision making. In addition to that, LCC using remote sensing has possess various applications such as urban planning, precision agriculture. A massive volume of heterogeneous geographical images over a wide range of geographical areas associated with diversified imaging conditions generally cause photographic distortions, illumination change, and the scale variation, inaccuracy, inefficient due to implementation of ineffective algorithms in the existing studies that seriously decline the classification accuracy. Therefore, proposed study implemented deep learning techniques for overcoming these issues since it minimizes the computation time, makes the network converge much faster and reduces the over-fitting, moreover ResNet50 is light weight deep learning model which are fast to train when appropriately scaled for depth, width and input data resolution can provide comparable and even higher image classification accuracies. This is especially important in remote sensing where the volume of data is very large and increases constantly. Thereby gaining positive implications and delivering exceptional performances in land cover classification in the proposed study. Hence proposed study incorporated a D-CNN (Deep CNN) and ResNet50 for extracting the appropriate features from the pre-processed dataset. Once the data are extracted, dimensionality reduction takes by employing PCA (Principal Component Analysis) to rule out more number of irrelevant features. After employing PCA, classification of images takes place by implementing logistic weight updated hyper parameter tuned random forest method which classifies the extracted features. Finally, performance of the proposed model is evaluated using different performance metrics like accuracy, precision, recall and F1-score. Then the proposed method is further evaluated by comparing the proposed method with the existing methods for assessing the efficiency and efficacy of the proposed model.
C1 [Bhatt, Abhishek] Symbiosis Skills & Profess Univ, Sch Data Sci, Pune, India.
   [Bhatt, Vandana Thakur] Technocrats Inst Technol, Dept Elect & Commun Engn, Bhopal, India.
RP Bhatt, A (corresponding author), Symbiosis Skills & Profess Univ, Sch Data Sci, Pune, India.
EM abhishek.bhat@sspu.ac.in
CR Ali L, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/6314328
   Berhane TM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040580
   Carranza-García M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   Daneshtalab S., 2019, INT ARCH PHOTOGRAMM, VXLII-4/W18, P279, DOI [10.5194/isprs-archives-XLII-4-W18-279-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W18-279-2019]
   Du PJ, 2019, IEEE J-STARS, V12, P2600, DOI 10.1109/JSTARS.2018.2878037
   Ghatkar JG, 2019, INT J REMOTE SENS, V40, P9412, DOI 10.1080/01431161.2019.1633696
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Lantzanakis G, 2021, IEEE T GEOSCI REMOTE, V59, P3805, DOI 10.1109/TGRS.2020.3017937
   Lee H, 2021, IEEE T PATTERN ANAL, V43, P1499, DOI 10.1109/TPAMI.2019.2952847
   Liu J, 2019, IEEE T PATTERN ANAL, V41, P2266, DOI 10.1109/TPAMI.2018.2858795
   Mallak A., 2020, Sci, V2, P61, DOI [10.3390/sci2040061, DOI 10.3390/SCI2040061]
   Martel E, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060864
   Obianuju NL, 2021, LECT NOTE NETW SYST, V284, P1056, DOI 10.1007/978-3-030-80126-7_74
   Rajendran GB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244135
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Rousset G, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13122257
   Sun ZH, 2019, INT J REMOTE SENS, V40, P593, DOI 10.1080/01431161.2018.1516313
   Ulmas P, 2020, Arxiv, DOI arXiv:2003.02899
   Valanarasu Jeya Maria Jose, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P363, DOI 10.1007/978-3-030-59719-1_36
   Wambugu N, 2021, INT J APPL EARTH OBS, V103, DOI 10.1016/j.jag.2021.102515
   Wang H, 2020, NEURAL PROCESS LETT, V51, P853, DOI 10.1007/s11063-019-10119-4
   Wang J, 2021, IEEE T PATTERN ANAL, V43, P420, DOI 10.1109/TPAMI.2019.2937292
   Wang XT, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3101509
   Yamashkin SA, 2020, IEEE ACCESS, V8, P179516, DOI 10.1109/ACCESS.2020.3028030
   Yang Y, 2020, IEEE T PATTERN ANAL, V42, P521, DOI 10.1109/TPAMI.2018.2883941
   Yassine H., 2021, Int Arch Photogramm, Remote Sens Spatial Info Sci, V43, pB3
   Yuan BH, 2021, NEURAL COMPUT APPL, V33, P2047, DOI [10.1007/s00521-020-05071-7, 10.1038/s41598-020-68782-w]
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111593
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhao J, 2019, IEEE T PATTERN ANAL, V41, P2380, DOI 10.1109/TPAMI.2018.2858819
NR 31
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 29
PY 2023
DI 10.1007/s11042-023-17612-y
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8A7
UT WOS:001120006300004
DA 2024-07-18
ER

PT J
AU Liu, QL
   Lv, XQ
   Yu, W
   Guo, CY
   Zhang, SP
AF Liu, Qinglin
   Lv, Xiaoqian
   Yu, Wei
   Guo, Changyong
   Zhang, Shengping
TI Dual-context aggregation for universal image matting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image matting; Neural network; Interactive matting; Automatic matting
AB Natural image matting aims to estimate the alpha matte of the foreground from a given image. Various approaches have been explored to address this problem, such as interactive matting methods that use guidance such as click or trimap, and automatic matting methods tailored to specific objects. However, existing matting methods are designed for specific objects or guidance, neglecting the common requirement of aggregating global and local contexts in image matting. As a result, these methods often encounter challenges in accurately identifying the foreground and generating precise boundaries, which limits their effectiveness in unforeseen scenarios. In this paper, we propose a simple and universal matting framework, named Dual-Context Aggregation Matting (DCAM), which enables robust image matting with arbitrary guidance or without guidance. Specifically, DCAM first adopts a semantic backbone network to extract low-level features and context features from the input image and guidance. Then, we introduce a dual-context aggregation network that incorporates global object aggregators and local appearance aggregators to iteratively refine the extracted context features. By performing both global contour segmentation and local boundary refinement, DCAM exhibits robustness to diverse types of guidance and objects. Finally, we adopt a matting decoder network to fuse the low-level features and the refined context features for alpha matte estimation. Experimental results on five matting datasets demonstrate that the proposed DCAM outperforms state-of-the-art matting methods in both automatic matting and interactive matting tasks, which highlights the strong universality and high performance of DCAM.
C1 [Liu, Qinglin] Shandong Guoxing Intelligent Technol Co Ltd, Yantai 264000, Peoples R China.
   [Liu, Qinglin; Lv, Xiaoqian; Yu, Wei; Guo, Changyong; Zhang, Shengping] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
C3 Harbin Institute of Technology
RP Liu, QL (corresponding author), Shandong Guoxing Intelligent Technol Co Ltd, Yantai 264000, Peoples R China.; Liu, QL; Lv, XQ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM qinglin.liu@outlook.com; xiaoqian.hit@gmail.com;
   20b903014@stu.hit.edu.cn; guocy@hit.edu.cn; s.zhang@hit.edu.cn
RI Chen, Rainie/ISS-6016-2023; Liu, Qinglin/HMD-1377-2023
OI Liu, Qinglin/0000-0002-2408-3344
FU National Natural Science Foundation of China [62272134]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62272134).
CR Aksoy Y, 2017, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2017.32
   [Anonymous], 2007, CVPR
   Berman A, 1998, Method for removing from an image the background surrounding a selected object
   Bo D, 2023, AAAI
   Cai H, 2022, ECCV
   Cai SF, 2019, IEEE I CONF COMP VIS, P8818, DOI 10.1109/iccv.2019.00891
   Chen Q., 2013, KNN matting. TPAMI, V35, P2175, DOI [10.1109/TPAMI.2013.18, DOI 10.1109/TPAMI.2013.18]
   Chen Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P618, DOI 10.1145/3240508.3240610
   Chen T, 2009, SIGGRAPH ASIA
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Dai Y, 2022, CVPR
   Dai YT, 2021, PROC CVPR IEEE, P6837, DOI 10.1109/CVPR46437.2021.00677
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Forte Marco, 2020, arXiv
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Gong ML, 2015, IEEE T IMAGE PROCESS, V24, P1356, DOI 10.1109/TIP.2015.2401516
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2011, PROC CVPR IEEE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Hou QQ, 2019, IEEE I CONF COMP VIS, P4129, DOI 10.1109/ICCV.2019.00423
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Ke Zhanghan, 2022, AAAI
   Kingma D. P., 2014, arXiv
   Levin A., 2008, Spectral matting. TPAMI, V30, P1699, DOI [10.1109/TPAMI.2008.168, DOI 10.1109/TPAMI.2008.168]
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li D, 2013, ICCV
   Li J, 2022, Int J Comp Vision
   Li JZZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3501, DOI 10.1145/3474085.3475512
   Li YY, 2020, AAAI CONF ARTIF INTE, V34, P11450
   Lin SC, 2021, PROC CVPR IEEE, P8758, DOI 10.1109/CVPR46437.2021.00865
   Liu Q, 2023, IEEE TCSVT
   Liu YH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7535, DOI 10.1109/ICCV48922.2021.00746
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu H, 2019, IEEE I CONF COMP VIS, P3265, DOI 10.1109/ICCV.2019.00336
   Park G, 2022, PROC CVPR IEEE, P11686, DOI 10.1109/CVPR52688.2022.01140
   Paszke A, 2019, ADV NEUR IN, V32
   Qiao Y, 2023, ACM TOMM, V19
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shahrian E, 2013, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2013.88
   Srivastava A, 2022, MULTIMED TOOLS APPL, V81, P14517, DOI 10.1007/s11042-022-12514-x
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun Y., 2021, CVPR
   Tang JW, 2019, PROC CVPR IEEE, P3050, DOI 10.1109/CVPR.2019.00317
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang R, 2022, ICME
   Wang R, 2021, arXiv
   Xu N, 2017, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2017.41
   Yu H., 2021, AAAI
   Yu Qiao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13673, DOI 10.1109/CVPR42600.2020.01369
   Yu QH, 2021, PROC CVPR IEEE, P1154, DOI 10.1109/CVPR46437.2021.00121
   Yu Zhiyang, 2021, ICCV
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang YK, 2019, PROC CVPR IEEE, P7461, DOI 10.1109/CVPR.2019.00765
   Zhu BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P297, DOI 10.1145/3123266.3123286
   Zongker DE, 1999, COMP GRAPH, P205, DOI 10.1145/311535.311558
NR 62
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 15
PY 2023
DI 10.1007/s11042-023-17517-w
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8YK4
UT WOS:001101241300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Albahli, S
AF Albahli, Saleh
TI Efficient hyperparameter tuning for predicting student performance with
   Bayesian optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Student academic prediction; Machine learning; Synthetic minority
   oversampling technique; Bayesian optimization; Hyperparameter tuning
AB Higher education is crucial as it introduces students to various fields and then guides them to the next steps. Student's academic performance is critical and could lead to failure if it is not monitored to find the strengths and weaknesses of students and the factors that affect them. That is why the student academic prediction method should be improved so teachers can predict their students' performance. A lot of research tried to improve the prediction accuracy but had problems with imbalanced data and how to tune the algorithm. For this case, we proposed two different machine learning algorithms that handle imbalanced data by applying the Synthetic Minority Oversampling Technique and employing a hyperparameter tuning algorithm to increase the prediction during the training process in the machine learning models. The machine learning models we used are Random Forest and Decision Tree. Models were further tuned using Grid Search, Random Search and Bayesian Optimization Hyperparameter Tuning. After we compared them, the results showed that Synthetic Minority Oversampling Technique and Bayesian Optimization combined with the Decision Tree algorithm outperformed models for student academic prediction.
C1 [Albahli, Saleh] Qassim Univ, Coll Comp, Dept Informat Technol, Buraydah, Saudi Arabia.
C3 Qassim University
RP Albahli, S (corresponding author), Qassim Univ, Coll Comp, Dept Informat Technol, Buraydah, Saudi Arabia.
EM salbahli@qu.edu.sa
FU Researchers would like to thank the Deanship of Scientific Research,
   Qassim University for funding publication of this project.; Deanship of
   Scientific Research, Qassim University
FX Researchers would like to thank the Deanship of Scientific Research,
   Qassim University for funding publication of this project.
CR Adebayo AO., 2019, GSJ, V7, P45
   Amrieh E.A., 2016, International Journal of Database Theory and Application, V9, P119, DOI [DOI 10.14257/IJDTA.2016.9.8.13, DOI 10.14257/ijdta.2016.9.8.13]
   [Anonymous], Decision Tree Classifier Hyperparameter'
   Asif R, 2017, COMPUT EDUC, V113, P177, DOI 10.1016/j.compedu.2017.05.007
   Avwerosuoghene A, 2020, Prediction of student performance in engineering drawing using machine learning methods and synthetic minority oversampling technique (SMOTE)', V12, P10
   Beaulac C, 2019, RES HIGH EDUC, V60, P1048, DOI 10.1007/s11162-019-09546-y
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bernard S, 2009, LECT NOTES COMPUT SC, V5519, P171, DOI 10.1007/978-3-642-02326-2_18
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866, DOI 10.1109/69.553155
   Cuesta AP, 2018, Hyperparameter Optimization for Large-scale Machine Learning, DOI [10.13140/RG.2.2.33876.65927, DOI 10.13140/RG.2.2.33876.65927]
   Devasia T, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P91, DOI 10.1109/SAPIENCE.2016.7684167
   Floridia A, 2018, INT SYM DEFEC FAU TO
   GPFE, 1999, Global Partnership for Education'
   Gray CC, 2019, COMPUT EDUC, V131, P22, DOI 10.1016/j.compedu.2018.12.006
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hasan R, 2018, 2018 4 INT C COMPUTE, P1
   Helal S, 2018, KNOWL-BASED SYST, V161, P134, DOI 10.1016/j.knosys.2018.07.042
   Hota HS, 2016, Int J Eng Sci Invention Res Dev, V5, P17
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Kabiraj Sajib, 2020, 2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT), DOI 10.1109/ICCCNT49239.2020.9225451
   Kavitha M, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1329, DOI 10.1109/ICICT50816.2021.9358597
   Kayiyarasi R., 2018, Acad Perform, V6, P128
   Kotsiantis SB, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P664, DOI 10.1109/ICALT.2005.223
   Kumar Mukesh, 2017, International Journal of Modern Education and Computer Science, V9, P25, DOI 10.5815/ijmecs.2017.08.04
   Liashchynskyi P, 2019, Arxiv, DOI [arXiv:1912.06059, 10.48550/arXiv.1912.06059]
   Livieris IE, 2019, J EDUC COMPUT RES, V57, P448, DOI 10.1177/0735633117752614
   Mantovani RG, 2019, INFORM SCIENCES, V501, P193, DOI 10.1016/j.ins.2019.06.005
   Masci C, 2018, EUR J OPER RES, V269, P1072, DOI 10.1016/j.ejor.2018.02.03l
   McNeely J.H., 1938, College student mortality
   Moon YH, 2020, I C INF COMM TECH CO, P1306, DOI 10.1109/ICTC49870.2020.9289573
   Nugroho Ari, 2020, 2020 7th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE), P96, DOI 10.1109/ICITACEE50144.2020.9239164
   Popescu E, 2018, IEEE ACCESS, V6, P72774, DOI 10.1109/ACCESS.2018.2882297
   Rojanavasu Pornthep, 2019, 2019 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT-NCON), P142, DOI 10.1109/ECTI-NCON.2019.8692274
   Romero C, 2010, IEEE T SYST MAN CY C, V40, P601, DOI 10.1109/TSMCC.2010.2053532
   Thai-nghe N, Improving academic performance prediction by dealing with class imbalance
   U. I. for S. The World Bank Data, 2020, Cumulative Drop-Out Rate To The Last Grade Of Lower Secondary General Education, Both Sexes (%)'
   Uljens M., 2007, Kasvatus, V38, P7
   wenr, Common higher education grading scale variations in Saudi Arabia'
   Yang F, 2018, COMPUT EDUC, V123, P97, DOI 10.1016/j.compedu.2018.04.006
NR 40
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 11
PY 2023
DI 10.1007/s11042-023-17525-w
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Y0ZQ9
UT WOS:001102641900010
DA 2024-07-18
ER

PT J
AU Kong, WH
   Sun, MH
   Xue, H
AF Kong, Weiheng
   Sun, Minghui
   Xue, Hao
TI FANs: fully attentional networks for image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image compression; FANs model; Channel attention; Token self-attention;
   Difference map; Channel latent map
AB We propose a fully attentional networks model and achieve excellent results on top of both large-scale datasets and small-scale datasets to use as a codec for image compression. First, we convert the image to an underlying tensor using a lightweight image encoder with a convolutional neural network model. Then, a fully attentional networks model is designed to enhance image compression in combination with attentional channel processing. Combining the fully attentional networks model with associated feature learning can improve image compression performance. In addition, we design a channel processing module to compute the attention matrix in the channel dimension for improving the quality of the reconstructed images. Since compression networks are computationally and parametrically inefficient in channel processing, we design a high-efficiency channel self-attention for the FANs model that uses averaging of channel dimensions to generate token features for optimizing the reconstructed images at low rates. We evaluate our proposed method on the Kodak and CLIC datasets and compare it with recently published deep neural network-based methods. The experimental results show that our performance is comparable to recent CNN and transformer-based methods on Kodak and CLIC image sets
C1 [Kong, Weiheng; Sun, Minghui; Xue, Hao] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Kong, Weiheng; Sun, Minghui; Xue, Hao] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Sun, MH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Sun, MH (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun, Jilin, Peoples R China.
EM kongwh22@mails.jlu.edu.cn; smh@jlu.edu.cn
FU This study has been partially supported by the National Natural Science
   Foundation of China (61872164) and Program of Science and Technology
   Development Plan of Jilin Province of China (20220201147GX) and the
   Graduate Innovation Fund of Jilin University (2 [61872164]; National
   Natural Science Foundation of China [20220201147GX]; Program of Science
   and Technology Development Plan of Jilin Province of China [2023CX206];
   Graduate Innovation Fund of Jilin University
FX This study has been partially supported by the National Natural Science
   Foundation of China (61872164) and Program of Science and Technology
   Development Plan of Jilin Province of China (20220201147GX) and the
   Graduate Innovation Fund of Jilin University (2023CX206).
CR Agustsson E, 2017, ADV NEUR IN, V30
   Bahat Y, 2021, PROC CVPR IEEE, P2907, DOI 10.1109/CVPR46437.2021.00293
   Bai YC, 2021, PROC CVPR IEEE, P11941, DOI 10.1109/CVPR46437.2021.01177
   Balle J, 2018, ICLR
   Balle J, 2017, 5 INT C LEARN REPR I
   Balle J, 2016, 4 INT C LEARNING REP
   Bhowmik N, 2022, IEEE COMPUT SOC CONF, P368, DOI 10.1109/CVPRW56347.2022.00052
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chamain LD, 2021, IEEE DATA COMPR CONF, P163, DOI 10.1109/DCC50243.2021.00024
   Chen ZH, 2022, IEEE T IMAGE PROCESS, V31, P1697, DOI 10.1109/TIP.2022.3140608
   Cui Z, 2021, PROC CVPR IEEE, P10527, DOI 10.1109/CVPR46437.2021.01039
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Deng X, 2021, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR46437.2021.00154
   Dosovitskiy Alexey, 2021, ICLR
   He DL, 2021, PROC CVPR IEEE, P14766, DOI 10.1109/CVPR46437.2021.01453
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kim JH, 2022, PROC CVPR IEEE, P5982, DOI 10.1109/CVPR52688.2022.00590
   Klopp JP, 2021, PROC CVPR IEEE, P16160, DOI 10.1109/CVPR46437.2021.01590
   Kodak E, 1993, KODAK LOSSLESS TRUE
   Le N, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1590, DOI 10.1109/ICASSP39728.2021.9414465
   Lee J.-H., 2022, P IEEECVF C COMPUTER, P16113
   Lee JY, 2019, Arxiv, DOI arXiv:1809.10452
   Lei Ba J., 2016, arXiv
   Li M, 2018, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2018.00339
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Mentzer F., 2020, PROC NEURIPS 20, V33
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Minnen D, 2020, IEEE IMAGE PROC, P3339, DOI [10.1109/icip40778.2020.9190935, 10.1109/ICIP40778.2020.9190935]
   Minnen D, 2018, ADV NEUR IN, V31
   Rippel O, 2017, PR MACH LEARN RES, V70
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Theis L, 2017, Arxiv, DOI [arXiv:1703.00395, DOI 10.48550/ARXIV.1703.00395]
   Toderici G, 2017, 2017 IEEE C COMPUTER
   Toderici G, 2020, WORKSH CHALL LEARN I
   Toderici G, 2016, Arxiv, DOI arXiv:1511.06085
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Torfason R, 2018, Towards image understanding from deep compression without decoding
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang YQ, 2021, PROC CVPR IEEE, P8737, DOI 10.1109/CVPR46437.2021.00863
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Yang F, 2021, PROC CVPR IEEE, P4996, DOI 10.1109/CVPR46437.2021.00496
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang X, 2021, PROC CVPR IEEE, P13349, DOI 10.1109/CVPR46437.2021.01315
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
   Zhou DQ, 2022, PR MACH LEARN RES
   Zhu X., 2020, INT C LEARN REPR
   Zou RJ, 2022, PROC CVPR IEEE, P17471, DOI 10.1109/CVPR52688.2022.01697
NR 51
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17633-7
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100009
DA 2024-07-18
ER

PT J
AU Jassem, R
   Damak, T
   Ben Ayed, MA
   Masmoudi, N
AF Jassem, Rana
   Damak, Taheni
   Ben Ayed, Mohamed Ali
   Masmoudi, Nouri
TI Inter prediction multiple reference frames impact on H266-VVC encoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE VVC standard; Inter prediction; Motion estimation; Multiple reference
   frame
ID HEVC
AB This paper presents Inter prediction Multiple Reference Frames Impact on H266-versitele video coding (VVC) encoder. Video compression plays a crucial role in storing and transmitting video content. Recent developments in video coding have led to the development of the H266-VVC encoder, which aims to achieve greater compression efficiency than its predecessors. One of the key features of the H266-VVC encoder is its inter prediction method, which uses previously encoded frames as reference frames. Multiple reference frames are used in this study to determine how they affect the performance of the H266-VVC encoder. The use of the multiple reference frames, increases compression efficiency by providing more information for inter-prediction. The encoder must compare more frames to find the best match when using multiple reference frames, so it also increases the encoding time. To achieve the best compression efficiency and encoding speed, a trade-off between reference frame number and encoding time must be taken into account when selecting the number of reference frames to use in the H266-VVC encoder.
C1 [Jassem, Rana; Damak, Taheni; Ben Ayed, Mohamed Ali] Sfax Univ, Nouvelles Technol & Syst Telecommun NTS Com, Sfax, Tunisia.
   [Jassem, Rana] Univ Basrah, Coll Educ Pure Sci, Dept Comp Sci, Basrah, Iraq.
   [Masmoudi, Nouri] Sfax Univ, Lab Electroniqueet Technol Informat LETI, Sfax, Tunisia.
C3 Universite de Sfax; University of Basrah; Universite de Sfax
RP Damak, T (corresponding author), Sfax Univ, Nouvelles Technol & Syst Telecommun NTS Com, Sfax, Tunisia.
EM ana.mohammed@uobasrah.edu.iq; taheni.dammak@enetcom.usf.tn;
   mohamedali.benayed@enetcom.usf.tn; nouri.masmoudi@enis.rnu.tn
CR Bjotegaard G., 2001, VCEGM33
   Boyce JM, 2021, IEEE T CIRC SYST VID, V31, P3731, DOI 10.1109/TCSVT.2021.3111712
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Chen J, 2019, P JOINT VIDEO EXPERT, P19
   Chien WJ, 2021, IEEE T CIRC SYST VID, V31, P3848, DOI 10.1109/TCSVT.2021.3101212
   DuolikunDanier CF., 2022, Enhancing VVC with Deep Learning based Multi-Frame Post-Processing
   Fan K., 2017, Improved intra boundary filters for HEVC" IEEE Visual Communications and Image Processing (VCIP)
   Hamidouche W, 2022, IEEE CONSUM ELECTR M, V11, P10, DOI 10.1109/MCE.2022.3144545
   Huang YW, 2020, IEEE T CIRC SYST VID, V30, P1311, DOI 10.1109/TCSVT.2019.2945048
   ITU-T and ISO/IEC, 2013, High efficiency video coding ITU-T Rec. H.265 and ISO/IEC 23008-2 (HEVC)
   Jeeva Raj A, 2020, Power efficient real time VVC decoder
   Jubran M., 2022, Sequence-Level Reference Frames In Video Coding, V32, P1578
   Karczewicz M, 2021, IEEE T CIRC SYST VID, V31, P3907, DOI 10.1109/TCSVT.2021.3072297
   Katayama T, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427694
   Lai WP, 2013, 7 AS MOD S HONG KONG, P23, DOI [10.1109/AMS.2013.51, DOI 10.1109/AMS.2013.51]
   Martínez-Rach MO, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020039
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Park CS, 2013, IEEE INT C CONS EL I, P11, DOI [10.1109/ICCE.2013.6486913, DOI 10.1109/ICCE.2013.6486913]
   Park W, 2021, IEEE ACCESS, V9, P72, DOI 10.1109/ACCESS.2020.3046040
   Pfaff J, 2021, IEEE T CIRC SYST VID, V31, P3834, DOI 10.1109/TCSVT.2021.3072430
   Rhee CE, 2012, IEICE ELECTRON EXPR, V9, P1695, DOI 10.1587/elex.9.1695
   Schwarz H, 2021, IEEE T CIRC SYST VID, V31, P3891, DOI 10.1109/TCSVT.2021.3072202
   Wang HC., 2018, Int J Eng Sci, V7, P24
   Wang YK, 2021, IEEE T CIRC SYST VID, V31, P3779, DOI 10.1109/TCSVT.2021.3070860
   Wei HL, 2020, IEEE ACCESS, V8, P53116, DOI 10.1109/ACCESS.2020.2981143
   Yang SH, 2015, ELECTRON LETT, V51, P2109, DOI 10.1049/el.2015.3094
NR 27
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17481-5
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500005
DA 2024-07-18
ER

PT J
AU Quasar, SR
   Sharma, R
   Mittal, A
   Sharma, M
   Agarwal, D
   Diez, ID
AF Quasar, Syeda Reeha
   Sharma, Rishika
   Mittal, Aayushi
   Sharma, Moolchand
   Agarwal, Deevyankar
   de La Torre Diez, Isabel
TI Ensemble methods for computed tomography scan images to improve lung
   cancer detection and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lung cancer; Ensemble; BEiT; DenseNet; Sequential CNN
ID HISTORY
AB Lung cancer has emerged as a leading cause of global cancer-related mortality, necessitating effective early detection and classification methods. Recent advancements in deep learning algorithms have shown promise in detecting and classifying lung cancer from CT scan images. This paper proposes an ensemble lung cancer detection and classification model that integrates diverse models like BEiT, DenseNet, and Sequential CNN, leveraging ensemble methods such as AND, OR, Weighted Box Fusion, and Boosting. This study utilizes the Chest CT-Scan Images Dataset for testing. Various studies have explored ensemble methods, deep learning techniques, and hybrid models to address the challenges of accurate lung cancer diagnosis. These studies show that ensemble methods offer a powerful strategy for enhancing accuracy by combining the strengths of multiple classifiers to mitigate individual weaknesses, leading to improved overall performance. The results demonstrate that our ensemble approach outperforms single-model techniques and other ensemble methods, achieving a prediction accuracy of 98%. The proposed method enhances accuracy and provides a practical solution using existing datasets and resources. This research highlights the potential of ensemble methods as a transformative tool in advancing lung cancer diagnosis accuracy and efficacy.
C1 [Quasar, Syeda Reeha; Sharma, Rishika; Mittal, Aayushi; Sharma, Moolchand] Maharaja Agrasen Inst Technol, Dept Comp Sci & Engn, Delhi, India.
   [Agarwal, Deevyankar] Univ Technol & Appl Sci, Muscat, Oman.
   [de La Torre Diez, Isabel] Univ Valladolid, Dept Signal Theory & Commun & Telemat Engn, Valladolid, Spain.
C3 Maharaja Agrasen Institute of Technology; Universidad de Valladolid
RP Quasar, SR (corresponding author), Maharaja Agrasen Inst Technol, Dept Comp Sci & Engn, Delhi, India.
EM syedareehaquasar@gmail.com; rishikas0001@gmail.com;
   aayushimittal088@gmail.com; moolchand@mait.ac.in;
   deevyankar.agarwal@hct.edu.om; isator@tel.uva.es
RI de la Torre, Isabel Prof./B-7064-2008; Agarwal, Deevyankar/AFI-5867-2022
OI de la Torre, Isabel Prof./0000-0003-3134-7720; Agarwal,
   Deevyankar/0000-0001-8083-7342
CR Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Bao HB, 2022, Arxiv, DOI [arXiv:2206.01127, 10.48550/arXiv.2206.01127]
   Bhuvaneswari P, 2015, PROC MAT SCI, V10, P433, DOI 10.1016/j.mspro.2015.06.077
   Binson VA, 2021, CLIN CHIM ACTA, V523, P231, DOI 10.1016/j.cca.2021.10.005
   Bushara AR, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14893-1
   Bushara AR, 2022, Electron Lett Comput Vis Image Anal, V21, P130, DOI [10.5565/rev/elcvia.1490, DOI 10.5565/REV/ELCVIA.1490]
   Chang PD, 2018, AM J NEURORADIOL, V39, P1609, DOI 10.3174/ajnr.A5742
   Coté ML, 2012, EUR J CANCER, V48, P1957, DOI 10.1016/j.ejca.2012.01.038
   Das A, 2022, MULTIMED TOOLS APPL, V81, P5407, DOI 10.1007/s11042-021-11787-y
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   DeVita VT, 2008, CANCER RES, V68, P8643, DOI 10.1158/0008-5472.CAN-07-6611
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dietterich TG, 2012, Multiple classifier systems, P185, DOI [10.1007/978-3-642-31712-0_14, DOI 10.1007/978-3-642-31712-0_14]
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Ge GRY, 2023, J APPL CLIN MED PHYS, V24, DOI 10.1002/acm2.13869
   Gedeon KK, 2024, MULTIMED TOOLS APPL, V83, P8911, DOI 10.1007/s11042-023-15966-x
   Gu DD, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101886
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SJ, 2018, CANCER GENOM PROTEOM, V15, P41, DOI 10.21873/cgp.20063
   Huang XF, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106230
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu RH, 2024, MULTIMED TOOLS APPL, V83, P6909, DOI 10.1007/s11042-023-15573-w
   Nordhausen K., 2013, INT STAT REV, V81, P470, DOI [10.1111/insr.12042_10, DOI 10.1111/INSR.12042_10]
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Radha G, 2021, TRANSL ONCOL, V14, DOI 10.1016/j.tranon.2021.101166
   RNBA, 2023, Biomed Signal Process Control, DOI [10.1016/j.bspc.2023.104930, DOI 10.1016/J.BSPC.2023.104930]
   Ruta D., 2010, IEEE Trans Knowl Data Eng, V22, P590, DOI [10.1109/TKDE.2009.62, DOI 10.1109/TKDE.2009.62]
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soreide K, 2009, J CLIN PATHOL, V62, P1051, DOI 10.1136/jcp.2009.069757
   Thakur SK, 2020, CANCER METAST REV, V39, P989, DOI 10.1007/s10555-020-09901-x
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yao Y, 2013, Ensembles in machine learning applications, P1, DOI [10.1007/978-1-4471-4882-0_1, DOI 10.1007/978-1-4471-4882-0_1]
   Zhang D, 2015, Estimating the Uncertainty of Average F1 Scores, DOI [10.1145/2808194.2809488, DOI 10.1145/2808194.2809488]
NR 38
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17616-8
EA NOV 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200012
DA 2024-07-18
ER

PT J
AU Srivastava, PK
   Singh, G
   Kumar, S
   Jain, NK
   Bali, V
AF Srivastava, Prabhat Kumar
   Singh, Ghanshyam
   Kumar, Sachin
   Jain, Neelesh Kumar
   Bali, Vikram
TI Gabor Filter and Centre Symmetric-Local Binary Pattern based technique
   for forgery detection in images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Copy-move forgery detection; CS-LBP; Gabor filter; Neural network; SURF
   algorithm
AB This paper presents a new approach for the detection of copy-move image forgery, a commonly employed technique for image manipulation. The proposed method combines a modified version of the Gabor Filter and Centre Symmetric Local Binary Pattern (CS-LBP) for feature extraction, aiming to meet the growing demand for accurate forgery detection. The process involves pre-processing the image and extracting features using the Gabor filter and CS-LBP at varying scales and orientations. Key points are matched using the Manhattan distance to identify forged regions. Classification of the forged images is achieved using Hybrid Neural Networks with Decision Tree (HNN-DT). In order to assess the performance of the presented method, diverse image datasets are used and compared to existing feature extraction techniques. The results demonstrate the effectiveness of the modified Gabor filter with CS-LBP in accurately classifying forged images. Specifically, the HNN-DT method with Gabor filter CS-LBP feature extraction surpasses HNN-DT with SURF and PCA feature extraction in terms of classification accuracy and overall performance. Evaluation on the CoMoFoD database confirms superior results compared to existing techniques, establishing the proposed method as a reliable approach for distinguishing between authentic and forged images. Consequently, it serves as a robust solution for image classification and forgery detection. The presented work focuses on detecting mainly three types of image forgery, namely retouching, splicing, and cloning. It is applicable to various image formats, including JPEG and BMP, and is designed specifically for forensic applications in image forgery detection.
C1 [Srivastava, Prabhat Kumar; Bali, Vikram] IMS Engn Coll, Dept Comp Sci & Engn, Ghaziabad 201009, India.
   [Singh, Ghanshyam] Feroze Gandhi Inst Engn & Technol, Dept Elect & Commun Engn, Raebareli 229316, India.
   [Kumar, Sachin] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
   [Jain, Neelesh Kumar] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna 473226, India.
C3 SRM Institute of Science & Technology Chennai
RP Kumar, S (corresponding author), SRM Inst Sci & Technol, Dept Elect & Commun Engn, Kattankulathur 603203, Tamil Nadu, India.
EM gupta.sachin0708@gmail.com
RI Jain, Dr Neelesh/K-7840-2013; kumar, sachin/JXY-1719-2024; Jain, Neelesh
   Kumar/AAG-4748-2021; Kumar, Sachin/W-2211-2019; Bali, Vikram/W-1336-2018
OI Jain, Dr Neelesh/0000-0001-9831-374X; Jain, Neelesh
   Kumar/0000-0001-9080-0359; Kumar, Sachin/0000-0002-6260-6353; Bali,
   Vikram/0000-0002-2809-8455
CR Abinaya D, 2021, Journal of Physics: Conference Series, V1937
   Agarwal A., 2017, J Electr Eng Autom, V1, P1
   Al-Fatlawi AA., 2019, J Telecommun Electron Comput Eng, V11, P45
   alZahir S, 2020, MULTIMED TOOLS APPL, V79, P28643, DOI 10.1007/s11042-020-09502-4
   Amiri E, 2021, Journal of Computer & Robotics, V14, P11
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Bayram S., 2015, J Electron Imaging, V24, P041101
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Cheddad A., 2010, IEEE Trans Inf Forensics Secur, V5, P1
   Chierchia G., 2014, ACM-CSUR, V47, P63
   Das D., 2019, J Vis Commun Image Represent, V59, P243
   Diwan A, 2021, IET IMAGE PROCESS, V15, P1298, DOI 10.1049/ipr2.12105
   Fini RM, 2022, MULTIMED TOOLS APPL, V81, P38375, DOI 10.1007/s11042-022-13167-6
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Ganesan C, 2014, Int J Eng Res Appl, V2014, P18
   Gardella M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070119
   Gupta A., 2017, Digit Invest, V21, P37
   Hussain M., 2018, J Ambient Intell Humaniz Comput, V9, P395
   Javed AR, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104456
   Jha K, 2020, Int Res J Eng Technol, V7, P4542
   Jingade RR, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117207
   Kashyap A, 2022, COMPUT J, V65, P983, DOI 10.1093/comjnl/bxaa137
   Kaur G, 2023, ARTIF INTELL REV, V56, P1577, DOI 10.1007/s10462-022-10211-7
   Kumar S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P649, DOI 10.1109/ICIIP.2013.6707675
   Li CR, 2022, APPL SOFT COMPUT, V116, DOI 10.1016/j.asoc.2021.108210
   Niyishaka P, 2021, MULTIMED TOOLS APPL, V80, P2161, DOI 10.1007/s11042-020-09707-7
   Roy S., 2018, Multimed Tools Appl, V77, P9861
   VinodKumar RS, 2016, Int J Sci Eng Res, V7, P321
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
NR 29
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17485-1
EA NOV 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200001
DA 2024-07-18
ER

PT J
AU Kusakunniran, W
   Imaromkul, T
   Aukkapinyo, K
   Thongkanchorn, K
   Somsong, P
AF Kusakunniran, Worapan
   Imaromkul, Thanandon
   Aukkapinyo, Kittinun
   Thongkanchorn, Kittikhun
   Somsong, Pimpinan
TI Automatic classification of mangosteens and ripe status in images using
   deep learning based approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mangosteens classification; Ripe status; Deep learning; Multi-class
   classification; Binary classification
AB After the mangosteen-harvest, it is necessary to process a grading assessment which contains a key step of classifying a ripe status. This paper aims to develop an automatic solution to replace a manual process by human experts for classifying mangosteen and their ripe status in images. The classification solutions are developed based on deep learning techniques. These classification models are constructed by attempting on four architectures (i.e. DenseNet, EfficientNet, ResNet, and VGG) of convolutional neural networks (CNN). The models are trained using well-known and new prepared datasets. Two training strategies of multi-class and binary classifications are attempted in our experiments for distinguishing mangosteen from other fruits. It is reported that the multi-class classification performs better than the binary classification, with the precision, recall, and f1-score of 100%. In addition, a gradient-weighted class activation mapping (Grad-CAM) is used to demonstrate the reliability of the trained models. The proposed solution based on EfficientNetB0 performs the best for classification of mangosteens and their ripe statuses with the average accuracies of 100% and 98% respectively. The multi-class CNN-based classification is developed for solving a real-world problem of the ripe status classification. Alternative CNN architectures are attempted for finding the best-fit solution on a publicly available dataset and a self-collected dataset from a web scraping. The computed heatmaps show that it is not necessary to perform the mangosteen segmentation, the classification task could be performed directly where background and irrelevant parts of images are not/or less used.
C1 [Kusakunniran, Worapan; Imaromkul, Thanandon; Aukkapinyo, Kittinun; Thongkanchorn, Kittikhun] Mahidol Univ, Fac Informat & Commun Technol, 999 Phuttamonthon 4 Rd Salaya, Nakhon Pathom 73170, Thailand.
   [Somsong, Pimpinan] Chulalongkorn Univ, Sch Agr Resources, 254 Phayathai Rd, Bangkok 10330, Thailand.
C3 Mahidol University; Chulalongkorn University
RP Kusakunniran, W (corresponding author), Mahidol Univ, Fac Informat & Commun Technol, 999 Phuttamonthon 4 Rd Salaya, Nakhon Pathom 73170, Thailand.; Somsong, P (corresponding author), Chulalongkorn Univ, Sch Agr Resources, 254 Phayathai Rd, Bangkok 10330, Thailand.
EM worapan.kun@mahidol.edu; kittinun.auk@gmail.com; pimpinan.s@chula.ac.th
OI Kusakunniran, Worapan/0000-0002-2896-611X
FU Mahidol University (Fundamental Fund); National Science Research and
   Innovation Fund (NSRF)
FX This research project is supported by Mahidol University (Fundamental
   Fund: fiscal year 2023 by National Science Research and Innovation Fund
   (NSRF)).
CR Africa ADM, 2020, Int J, V8
   Altaheri H, 2019, IEEE ACCESS, V7, P117115, DOI 10.1109/ACCESS.2019.2936536
   Behera SK, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01865-8
   Chithra P, 2019, Int J Comp Sci Eng, V7
   Cho WH, 2021, CMC-COMPUT MATER CON, V69, P4003, DOI 10.32604/cmc.2021.018758
   De-la-Torre M, 2019, PROCESSES, V7, DOI 10.3390/pr7120928
   Gill HS, 2022, MATER TODAY-PROC, V51, P591, DOI 10.1016/j.matpr.2021.06.016
   Gill HS, 2022, Fruit image classification using deep learning
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kausar Asia, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P404, DOI 10.1109/CSCI46756.2018.00082
   Khanna M, 2023, Multimed Tool Appl, V1, P53
   Khanna M, 2023, Multimed Tool Appl, P1
   Minut MD, 2021, INT SYMP SYMB NUMERI, P155, DOI 10.1109/SYNASC54541.2021.00035
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh LK, 2022, MULTIMED TOOLS APPL, V81, P27737, DOI 10.1007/s11042-022-12826-y
   Singh LK, 2023, Multimed Tool Appl, P1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Zeeshan M, 2020, 2020 INT C EL SUST C, P28
NR 21
TC 0
Z9 0
U1 7
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17505-0
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900012
DA 2024-07-18
ER

PT J
AU Lyu, Z
   Yu, T
   Pan, FX
   Zhang, YL
   Luo, J
   Zhang, D
   Chen, YR
   Zhang, B
   Li, GY
AF Lyu, Zonglei
   Yu, Tong
   Pan, Fuxi
   Zhang, Yilin
   Luo, Jia
   Zhang, Dan
   Chen, Yiren
   Zhang, Bo
   Li, Guangyao
TI A survey of model compression strategies for object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Deep neural networks; Object detection; Model compression
ID CONVOLUTIONAL NEURAL-NETWORKS; CLASSIFICATION; PRECISION; COMPACT
AB Deep neural networks (DNNs) have achieved great success in many object detection tasks. However, such DNNS-based large object detection models are generally computationally expensive and memory intensive. It is difficult to deploy them to devices with low memory resources or scenarios with high real-time requirements, which greatly limits their application and promotion. In recent years, many researchers have focused on compressing large object detection models without significantly degrading their performance, and have made great progress. Therefore, this paper presents a survey of object detection model compression techniques in recent years. Firstly, these compression techniques were divided into six categories: network pruning, lightweight network design, neural architecture search (NAS), low-rank decomposition, network quantization, and Knowledge distillation (KD) methods. For each category, we select some representative state-of-the-art methods and compare and analyze their performance on public datasets. After that, we discuss the application scenarios and future directions of model compression techniques. Finally, this paper is further concluded by analyzing the advantages and disadvantages of six types of model compression techniques.
C1 [Lyu, Zonglei; Yu, Tong; Pan, Fuxi; Zhang, Yilin; Luo, Jia; Zhang, Dan; Chen, Yiren; Zhang, Bo; Li, Guangyao] Civil Aviat Univ China, Coll Comp Sci & Technol, Tianjin 300300, Peoples R China.
   [Lyu, Zonglei; Yu, Tong; Pan, Fuxi; Zhang, Yilin; Luo, Jia; Zhang, Dan; Chen, Yiren; Zhang, Bo; Li, Guangyao] Civil Aviat Univ China, Key Lab Smart Airport Theory & Syst, Tianjin, Peoples R China.
C3 Civil Aviation University of China; Civil Aviation University of China
RP Lyu, Z (corresponding author), Civil Aviat Univ China, Coll Comp Sci & Technol, Tianjin 300300, Peoples R China.; Lyu, Z (corresponding author), Civil Aviat Univ China, Key Lab Smart Airport Theory & Syst, Tianjin, Peoples R China.
EM zllv@cauc.edu.cn; 2021051030@cauc.edu.cn; 2019051023@cauc.edu.cn;
   2020051019@cauc.edu.cn; 2020051011@cauc.edu.cn; 2019052031@cauc.edu.cn;
   2020052039@cauc.edu.cn; 2020051029@cauc.edu.cn; 2019053075@cauc.edu.cn
RI Lyu, Zonglei/L-6993-2019; Li, Guangyao/ISV-4497-2023
OI Lyu, Zonglei/0000-0001-9427-1423; 
FU This work was supported by the Fundamental Research Funds for Central
   Universities of the Civil Aviation University of China (Grant No.
   3122021088). [3122021088]; Fundamental Research Funds for Central
   Universities of the Civil Aviation University of China
FX This work was supported by the Fundamental Research Funds for Central
   Universities of the Civil Aviation University of China (Grant No.
   3122021088).
CR Ahmed S, 2021, P 1 INT C ADV SCI IN, DOI [10.4108/eai.16-5-2020.2304034, DOI 10.4108/EAI.16-5-2020.2304034]
   Ahn S, 2019, PROC CVPR IEEE, P9155, DOI 10.1109/CVPR.2019.00938
   Alvarez JM, 2016, ADV NEUR IN, V29
   Anil R, 2018, P INT C LEARN REPR 2, DOI [10.48550/arXiv.1804.03235, DOI 10.48550/ARXIV.1804.03235]
   [Anonymous], 1990, Adv Neural Inform Process Syst.
   Baker B., 2017, INT C LEARNING REPRE
   Barry D, 2019, INT CONF IMAG VIS, DOI 10.1109/ivcnz48456.2019.8960963
   Basha Syed Muzamil, 2022, Computational Intelligence in Data Mining: Proceedings of ICCIDM 2021. Smart Innovation, Systems and Technologies (281), P113, DOI 10.1007/978-981-16-9447-9_9
   Biswas D, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS), P156, DOI 10.1109/NAS55553.2022.9925528
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Boo Y, 2021, AAAI CONF ARTIF INTE, V35, P6794
   Bulat Adrian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P309, DOI 10.1007/978-3-030-58592-1_19
   Cai H, 2019, P INT C LEARN REPR 2, DOI [10.48550/arXiv.1908.09791, DOI 10.48550/ARXIV.1908.09791]
   Cai H, 2018, PR MACH LEARN RES, V80
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Cai Han, 2019, INT C LEARN REPR
   Cai YX, 2021, AAAI CONF ARTIF INTE, V35, P955
   Carreira-Perpiñán MA, 2018, PROC CVPR IEEE, P8532, DOI 10.1109/CVPR.2018.00890
   Chang XY, 2021, AAAI CONF ARTIF INTE, V35, P6974
   Chen BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P307, DOI 10.1109/ICCV48922.2021.00037
   Chen CA, 2018, LECT NOTES COMPUT SC, V11212, P409, DOI 10.1007/978-3-030-01237-3_25
   Chen GB, 2017, ADV NEUR IN, V30
   Chen HL, 2021, INT J COMPUT VISION, V129, P501, DOI 10.1007/s11263-020-01379-y
   Chen HT, 2021, PROC CVPR IEEE, P6424, DOI 10.1109/CVPR46437.2021.00636
   Chen HT, 2020, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR42600.2020.00154
   Chen MH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12250, DOI 10.1109/ICCV48922.2021.01205
   Chen WJ, 2019, PROC CVPR IEEE, P7234, DOI 10.1109/CVPR.2019.00741
   Cheng Y, 2020, Arxiv, DOI [arXiv:1710.09282, DOI 10.48550/ARXIV.1710.09282]
   Choi K, 2022, PROC CVPR IEEE, P8301, DOI 10.1109/CVPR52688.2022.00813
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Courbariaux Y., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Dahyun Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P575, DOI 10.1007/978-3-030-58610-2_34
   Dai XL, 2021, PROC CVPR IEEE, P16271, DOI 10.1109/CVPR46437.2021.01601
   de Aguiar SA., 2021, Int Joint Conf Neural Netw (IJCNN), V2021, P1
   Denil M., 2013, ADV NEURAL INFORM PR
   Denton E, 2014, ADV NEUR IN, V27
   Diffenderfer J, 2020, arXiv, DOI 10.48550/arXiv.2103.09377
   Ding RZ, 2019, PROC CVPR IEEE, P11400, DOI 10.1109/CVPR.2019.01167
   Ding X., 2019, Adv Neural Inf Processing Syst, V32, P8867
   Ding XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4490, DOI 10.1109/ICCV48922.2021.00447
   Ding XH, 2019, PROC CVPR IEEE, P4938, DOI 10.1109/CVPR.2019.00508
   Ding XH, 2018, AAAI CONF ARTIF INTE, P6797
   Ding Xiaohan, 2019, INT C MACHINE LEARNI, P1607
   Dong X., 2019, Advances in Neural Information Processing Systems, V32, P759
   Dong X., 2017, ADV NEURAL INFORM PR, P4857
   Elhoushi M, 2021, IEEE COMPUT SOC CONF, P2359, DOI 10.1109/CVPRW53098.2021.00268
   Elsken T, 2017, P INT C LEARN REPR 2, DOI [10.48550/arXiv.1711.04528, DOI 10.48550/ARXIV.1711.04528]
   Enderich L, 2021, IEEE WINT CONF APPL, P2595, DOI 10.1109/WACV48630.2021.00264
   Evci U., 2020, PR MACH LEARN RES, P2943
   Faraone J, 2018, PROC CVPR IEEE, P4300, DOI 10.1109/CVPR.2018.00452
   Feroz MdA., 2022, COMPUTATIONAL INTELL, V1349, P37, DOI 10.1007/978-981-16-2543-5_4
   Figurnov M., 2016, ADV NEURAL INFORM PR, V29, P947
   Frankle J., 2020, In Proceedings of International Conference on Learning Representations, V535, P6377, DOI [10.5555/3495724.3496259, DOI 10.5555/3495724.3496259]
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao HY, 2021, IEEE T PATTERN ANAL, V43, P2570, DOI 10.1109/TPAMI.2020.2975796
   Gao MY, 2020, Arxiv, DOI arXiv:2002.09168
   Gao SQ, 2021, PROC CVPR IEEE, P9266, DOI 10.1109/CVPR46437.2021.00915
   Gao SQ, 2020, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR42600.2020.00197
   Gholami A, 2018, IEEE COMPUT SOC CONF, P1719, DOI 10.1109/CVPRW.2018.00215
   Gordon A, 2018, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2018.00171
   Guo JY, 2020, AAAI CONF ARTIF INTE, V34, P10885
   Guo JY, 2020, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR42600.2020.00158
   Guo YW, 2016, ADV NEUR IN, V29
   Gupta S, 2016, PROC CVPR IEEE, P2827, DOI 10.1109/CVPR.2016.309
   Han K., 2021, Learning Versatile Convolution Filters for Efficient Visual Recognition
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Han  S., 2015, ARXIV151000149
   Han S, 2015, ADV NEUR IN, V28
   Hawkins C, 2021, PREPRINT
   Hayou S, 2021, Arxiv, DOI arXiv:2002.08797
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2020, PROC CVPR IEEE, P2006, DOI 10.1109/CVPR42600.2020.00208
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Hinton G., 2015, COMPUT SCI, V2
   Hou L, 2016, INT C LEARN REPR, DOI [10.48550/arXiv.1611.01600, DOI 10.48550/ARXIV.1611.01600]
   Hou ZJ, 2022, PROC CVPR IEEE, P12277, DOI 10.1109/CVPR52688.2022.01197
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu HY, 2016, Arxiv, DOI arXiv:1607.03250
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu P, 2021, AAAI CONF ARTIF INTE, V35, P7780
   Hu QH, 2018, AAAI CONF ARTIF INTE, P3247
   Hu YM, 2018, Arxiv, DOI [arXiv:1805.11394, 10.48550/arXiv.1805.11394]
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Huang Z, 2018, P INT C LEARN REPR 2, DOI [10.48550/arXiv.1707.01219, DOI 10.48550/ARXIV.1707.01219]
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Hubara I, 2016, ADV NEUR IN, V29
   Hubara I, 2018, J MACH LEARN RES, V18
   Idelbayev Yerlan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8046, DOI 10.1109/CVPR42600.2020.00807
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jaderberg M., 2014, CORR
   Joo D, 2021, AAAI CONF ARTIF INTE, V35, P8021
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kang M, 2020, PR MACH LEARN RES, V119
   Khakzar A, 2021, PROC CVPR IEEE, P13523, DOI 10.1109/CVPR46437.2021.01332
   Kim D, 2021, INT C COMPUTER VISIO, P5271
   Kim J, 2018, ADV NEUR IN, V31
   Kim YD, 2016, Arxiv, DOI [arXiv:1511.06530, 10.48550/arXiv.1511.06530]
   Kingma DP, 2015, ADV NEUR IN, V28
   Ko JG, 2020, I C INF COMM TECH CO, P1276, DOI [10.1109/ICTC49870.2020.9289463, 10.1109/ictc49870.2020.9289463]
   Komodakis N, 2017, ICLR
   Kossaifi J, 2019, PROC CVPR IEEE, P7814, DOI 10.1109/CVPR.2019.00801
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon SJ, 2020, PROC CVPR IEEE, P1906, DOI 10.1109/CVPR42600.2020.00198
   Le DH, 2021, Arxiv, DOI [arXiv:2105.03193, 10.48550/arXiv.2105.03193]
   Lebedev V, 2015, INT C LEARN REPR, DOI [10.48550/arXiv.1412.6553, DOI 10.48550/ARXIV.1412.6553]
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Lee J, 2020, INT C LEARN REPR, DOI [10.48550/arXiv.2010.07611, DOI 10.48550/ARXIV.2010.07611]
   Lemaire C, 2019, PROC CVPR IEEE, P9100, DOI 10.1109/CVPR.2019.00932
   Leng C, 2018, AAAI CONF ARTIF INTE, P3466
   Li FF, 2016, Arxiv, DOI arXiv:1605.04711
   Li GY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2383
   Li H., 2017, PRUNING FILTERS EFFI, DOI DOI 10.48550/ARXIV.1608.08710
   Li QQ, 2017, PROC CVPR IEEE, P7341, DOI 10.1109/CVPR.2017.776
   Li TH, 2019, PROC CVPR IEEE, P3972, DOI 10.1109/CVPR.2019.00410
   Li X, 2019, PROC CVPR IEEE, P9137, DOI 10.1109/CVPR.2019.00936
   Li YC, 2021, PROC CVPR IEEE, P6434, DOI 10.1109/CVPR46437.2021.00637
   Li YC, 2019, PROC CVPR IEEE, P2795, DOI 10.1109/CVPR.2019.00291
   Li Y, 2021, AAAI CONF ARTIF INTE, V35, P8538
   Liao SY, 2019, AAAI CONF ARTIF INTE, P4287
   Lin, 2020, ADV NEURAL INFORM PR, V33, P11711, DOI DOI 10.48550/ARXIV.2007.10319
   Lin C., 2018, ADV NEURAL INFORM PR, P10170
   Lin J., 2017, NIPS, P2178
   Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Lin XF, 2017, ADV NEUR IN, V30
   Lin Y, 2018, P INT C LEARN REPR, DOI [10.48550/arXiv.1712.01887, DOI 10.48550/ARXIV.1712.01887]
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu CL, 2019, PROC CVPR IEEE, P2686, DOI 10.1109/CVPR.2019.00280
   Liu H, 2017, arXiv, DOI DOI 10.48550/ARXIV.1711.00436
   Liu HX, 2019, Arxiv, DOI [arXiv:1806.09055, DOI 10.48550/ARXIV.1806.09055]
   Liu LY, 2021, PR MACH LEARN RES, V139
   Liu N, 2020, AAAI CONF ARTIF INTE, V34, P4876
   Liu S., 2022, arXiv
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XC, 2021, AAAI CONF ARTIF INTE, V35, P8697
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Liu Z, 2018, P INT C LEARN REPR 2
   Liu ZC, 2018, LECT NOTES COMPUT SC, V11219, P747, DOI 10.1007/978-3-030-01267-0_44
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Liu ZH, 2018, ADV NEUR IN, V31
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Louizos C., 2017, arXiv
   Louizos C, 2017, ADV NEUR IN, V30
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Luo JH, 2020, PROC CVPR IEEE, P1455, DOI 10.1109/CVPR42600.2020.00153
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma XL, 2020, AAAI CONF ARTIF INTE, V34, P5117
   Mallya A, 2018, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2018.00810
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Molchanov Dmitry, 2017, P 34 INT C MACH LEAR, P2498
   Molchanov P., 2017, INT C LEARN REPR ICL, P1, DOI DOI 10.1002/9781118786352.WBIEG1156
   Molchanov P, 2019, PROC CVPR IEEE, P11256, DOI 10.1109/CVPR.2019.01152
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Neklyudov Kirill, 2017, P 31 INT C NEUR INF, V30, P6775, DOI 10.5555/3295222.3295422
   Novikov A, 2015, ADV NEUR IN, V28
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Peng BY, 2019, IEEE I CONF COMP VIS, P5006, DOI 10.1109/ICCV.2019.00511
   Peng B, 2018, LECT NOTES COMPUT SC, V11212, P307, DOI 10.1007/978-3-030-01237-3_19
   Peng Hanyu, 2019, ICML, P5113
   Pham H, 2018, PR MACH LEARN RES, V80
   Poliakov E, 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9859994, DOI 10.1109/ICME52920.2022.9859994]
   Qin HT, 2020, PROC CVPR IEEE, P2247, DOI 10.1109/CVPR42600.2020.00232
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Qiuqiu D, 2020, Yolo-fastest: yolo universal object detection model combined with efficientnet-lite
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Real E, 2017, PR MACH LEARN RES, V70
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren A, 2020, AAAI CONF ARTIF INTE, V34, P5495
   Romero A, 2014, Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, DOI [10.48550/arXiv.1412.6550, DOI 10.48550/ARXIV.1412.6550]
   Ruan XF, 2021, AAAI CONF ARTIF INTE, V35, P2495
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2019, PROC CVPR IEEE, P4830, DOI 10.1109/CVPR.2019.00497
   Singh P, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3460
   Sun K, 2018, BRIT MACH VIS C BMVC, DOI [10.48550/arXiv.1806.00178, DOI 10.48550/ARXIV.1806.00178]
   Swaminathan S, 2020, NEUROCOMPUTING, V398, P185, DOI 10.1016/j.neucom.2020.02.035
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai C, 2016, Arxiv, DOI [arXiv:1511.06067, DOI 10.48550/ARXIV.1511.06067]
   Tan M, BRIT MACH VIS C BMVC, V33, P1, DOI [10.5244/C.33.116, DOI 10.5244/C.33.116]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang YH, 2021, PROC CVPR IEEE, P5016, DOI 10.1109/CVPR46437.2021.00498
   Tang YH, 2020, AAAI CONF ARTIF INTE, V34, P5972
   Tian Yonglong, 2020, INT C LEARN REPR ICL
   Tiwari R, 2021, Arxiv, DOI [arXiv:2102.07156, 10.48550/arXiv.2102.07156]
   Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Véniat T, 2018, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2018.00368
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang H, 2020, INT C LEARN REPR 202, DOI [10.48550/arXiv.2012.09243, DOI 10.48550/ARXIV.2012.09243]
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang K, 2019, PROC CVPR IEEE, P11899, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang PS, 2018, PROC CVPR IEEE, P4376, DOI 10.1109/CVPR.2018.00460
   Wang RJ, 2018, ADV NEUR IN, V31
   Wang T, 2019, PROC CVPR IEEE, P4928, DOI 10.1109/CVPR.2019.00507
   Wang TZ, 2020, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR42600.2020.00215
   Wang W., 2021, INT C MACHINE LEARNI, P10717
   Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Wang XD, 2021, AAAI CONF ARTIF INTE, V35, P10227
   Wang YH, 2018, 32 C NEURAL INFORM P, V31
   Wang YL, 2020, AAAI CONF ARTIF INTE, V34, P6299
   Wang YL, 2020, AAAI CONF ARTIF INTE, V34, P12273
   Wang Z, 2021, PROC CVPR IEEE, P14908, DOI 10.1109/CVPR46437.2021.01467
   Wang ZW, 2021, IEEE T PATTERN ANAL, V43, P3432, DOI 10.1109/TPAMI.2020.2988262
   Wen W, 2016, ADV NEUR IN, V29
   Wong A, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P22, DOI 10.1109/EMC2-NIPS53020.2019.00013
   Wong C., 2018, P 32 INT C NEURAL IN, V31, P8366
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Wu JR, 2018, PR MACH LEARN RES, V80
   Xie GT, 2018, PROC CVPR IEEE, P8847, DOI 10.1109/CVPR.2018.00922
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xiong YY, 2021, PROC CVPR IEEE, P3824, DOI 10.1109/CVPR46437.2021.00382
   Xu YH, 2018, AAAI CONF ARTIF INTE, P4335
   Yan B, 2021, PROC CVPR IEEE, P15175, DOI 10.1109/CVPR46437.2021.01493
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang HC, 2020, PROC CVPR IEEE, P2175, DOI 10.1109/CVPR42600.2020.00225
   Yang J, 2020, Arxiv, DOI arXiv:2003.04289
   Yang Kanglin, 2022, 2022 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA), P578, DOI 10.1109/ICAICA54878.2022.9844610
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yawei Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8015, DOI 10.1109/CVPR42600.2020.00804
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yoon J., 2017, P INT C MACHINE LEAR, P3958
   You H., 2020, Advances in Neural Information Processing Systems, V33, P2771
   You S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1285, DOI 10.1145/3097983.3098135
   You Z., 2019, ADV NEURAL INFORM PR, P2133
   Yu CQ, 2021, PROC CVPR IEEE, P10435, DOI 10.1109/CVPR46437.2021.01030
   Yu G., 2021, arXiv, DOI 10.48550/arXiv.2111.00902
   Yu J, 2018, P INT C LEARN REPR 2, DOI [10.48550/arXiv.1812.08928, DOI 10.48550/ARXIV.1812.08928]
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang Q, 2020, Arxiv, DOI [arXiv:1907.05653, 10.48550/arXiv.1907.05653]
   Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang T, 2017, Arxiv, DOI arXiv:1707.02725
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhao BR, 2022, PROC CVPR IEEE, P11943, DOI 10.1109/CVPR52688.2022.01165
   Zhao C, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00046-w
   Zhao CL, 2019, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2019.00289
   Zhong YS, 2022, PROC CVPR IEEE, P12329, DOI 10.1109/CVPR52688.2022.01202
   Zhong Z, 2018, PROC CVPR IEEE, P2423, DOI 10.1109/CVPR.2018.00257
   Zhou D., 2020, P COMP VIS ECCV 2020, P680, DOI DOI 10.1007/978-3-030-58580-8_40
   Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40
   Zhou Q, 2021, MOBILE NETW APPL, V26, P77, DOI 10.1007/s11036-020-01723-z
   Zhou S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10367, DOI 10.1109/ICCV48922.2021.01022
   Zhou Shuchang, 2016, arXiv
   Zhu CZ, 2017, Arxiv, DOI arXiv:1612.01064
   Zhu SL, 2019, PROC CVPR IEEE, P4918, DOI 10.1109/CVPR.2019.00506
   Zhuang ZW, 2018, ADV NEUR IN, V31
   Zhuo LA, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1033
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 278
TC 2
Z9 2
U1 24
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17192-x
EA NOV 2023
PG 72
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X1LQ6
UT WOS:001096134900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lee, RJ
   Sivakumar, S
   Lim, KH
AF Lee, Ru Jing
   Sivakumar, Saaveethya
   Lim, King Hann
TI Review on remote heart rate measurements using photoplethysmography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Remote photoplethysmography; Heart rate measurement; Signal processing;
   Computer vision; Deep learning
ID RATE-VARIABILITY; PULSE-RATE; NONCONTACT; SEGMENTATION
AB Remote photoplethysmography (rPPG) gains recent great interest due to its potential in contactless heart rate measurement using consumer-level cameras. This paper presents a detailed review of rPPG measurement using computer vision and deep learning techniques for heart rate estimation. Several common gaps and difficulties of rPPG development are highlighted for the feasibility study in real-world applications. Numerous computer vision and deep learning methods are reviewed to mitigate crucial issues such as motion artifact and illumination variation. In comparison, deep learning approaches are proven more accurate than conventional computer vision methods due to their adaptive pattern learning and generalization characteristics. An increasing trend of applying deep learning techniques in rPPG can improve effective heart rate estimation and artifact removal. To consider more realistic disturbances into account, additional vital signs and large training datasets are crucial to improve the accuracy of heart rate estimations. By taking the benefit of contactless and accurate estimation, the application of rPPG can be greatly adopted in real-world activities, especially in precision sports.
C1 [Lee, Ru Jing; Sivakumar, Saaveethya; Lim, King Hann] Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Miri 98009, Sarawak, Malaysia.
C3 Curtin University Malaysia
RP Lee, RJ (corresponding author), Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Miri 98009, Sarawak, Malaysia.
EM 19948665@student.curtin.edu.au; saaveethya.s@curtin.edu.my;
   glkhann@curtin.edu.my
RI Lim, Hann/AAI-9930-2020
OI Lim, Hann/0000-0002-5679-7747
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Abdul Rahman NA, 2007, Rgb-h-cbcr skin colour model for human face detection, V4
   Adelabu MA., 2022, SN Comput Sci, V3, P1, DOI [10.1007/s42979-022-01179-w, DOI 10.1007/S42979-022-01179-W]
   Annis T, 2020, J AM MED INFORM ASSN, V27, P1326, DOI 10.1093/jamia/ocaa097
   Archery W, 2012, Revealing the secrets of an archer's body for the world to see
   Ashley EA., 2004, CARDIOLOGY EXPLAINED
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bickler PE, 2005, ANESTHESIOLOGY, V102, P715, DOI 10.1097/00000542-200504000-00004
   Wu BF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3141149
   Botina-Monsalve D, 2022, IEEE COMPUT SOC CONF, P2145, DOI 10.1109/CVPRW56347.2022.00233
   Bousefsaf F, 2013, BIOMED SIGNAL PROCES, V8, P568, DOI 10.1016/j.bspc.2013.05.010
   Bricout VA, 2010, AUTON NEUROSCI-BASIC, V154, P112, DOI 10.1016/j.autneu.2009.12.001
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Calloway D, 1997, J CHEM EDUC, V74, P744, DOI 10.1021/ed074p744.3
   Cardoso JF, 1999, NEURAL COMPUT, V11, P157, DOI 10.1162/089976699300016863
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Casalino G., 2022, P IEEE INT C SYST MA, P2675
   Castaneda Denisse, 2018, Int J Biosens Bioelectron, V4, P195, DOI 10.15406/ijbsbe.2018.04.00125
   Chen ML, 2022, IEEE T INF FOREN SEC, V17, P457, DOI 10.1109/TIFS.2022.3142993
   Chen WX, 2018, LECT NOTES COMPUT SC, V11206, P356, DOI 10.1007/978-3-030-01216-8_22
   Clemente F, 2011, Study of the heart rate and accuracy performance of archers, V11, P434
   Conaire Ciaran O., 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dasari A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00462-z
   de Haan G, 2014, PHYSIOL MEAS, V35, P1913, DOI 10.1088/0967-3334/35/9/1913
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Du GL, 2022, IEEE T INTELL TRANSP, V23, P21810, DOI 10.1109/TITS.2022.3176973
   Feng LT, 2015, IEEE T CIRC SYST VID, V25, P879, DOI 10.1109/TCSVT.2014.2364415
   Fouad RM, 2019, IEEE ACCESS, V7, P76513, DOI 10.1109/ACCESS.2019.2922304
   Fuertes D, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103473
   Gonzalez E, 2018, INTELL DAT CENT SYST, P175, DOI 10.1016/B978-0-12-812130-6.00010-X
   Gudi A, 2019, IEEE INT CONF COMP V, P1570, DOI 10.1109/ICCVW.2019.00196
   Gupta AK, 2023, IEEE WINT CONF APPL, P4965, DOI 10.1109/WACV56688.2023.00495
   Hsu GS, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P352, DOI 10.1109/BTAS.2017.8272721
   Hsu Y, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854440
   Huang B, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104447
   Morgan SJ, 2017, APPL PSYCHOPHYS BIOF, V42, P235, DOI 10.1007/s10484-017-9364-2
   Johnston W, 2005, NORTHEAST BIOENGIN C, P157
   Kwon S, 2015, IEEE ENG MED BIO, P4938, DOI 10.1109/EMBC.2015.7319499
   Lam A, 2015, IEEE I CONF COMP VIS, P3640, DOI 10.1109/ICCV.2015.415
   Lee Eugene, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P392, DOI 10.1007/978-3-030-58583-9_24
   Lewandowska M., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P405
   Lewis M, 2019, Arxiv, DOI [arXiv:1910.13461, DOI 10.48550/ARXIV.1910.13461]
   Li XB, 2020, IEEE COMPUT SOC CONF, P1274, DOI 10.1109/CVPRW50498.2020.00165
   Li XB, 2014, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2014.543
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu SQ, 2020, IEEE INT CONF AUTOMA, P481, DOI 10.1109/FG47880.2020.00109
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X., 2020, ADV NEURAL INF PROCE, V33, P19400
   Liu X, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3517225
   Lokendra B, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105146
   Lu H, 2021, PROC CVPR IEEE, P12399, DOI 10.1109/CVPR46437.2021.01222
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Macwan R, 2019, BIOMED SIGNAL PROCES, V49, P24, DOI 10.1016/j.bspc.2018.10.012
   Mahmood N. H., 2011, 2011 Proceedings of IEEE 7th International Colloquium on Signal Processing & its Applications (CSPA 2011), P64, DOI 10.1109/CSPA.2011.5759843
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   McDuff D, 2018, IEEE COMPUT SOC CONF, P1448, DOI 10.1109/CVPRW.2018.00185
   McDuff D, 2014, IEEE T BIO-MED ENG, V61, P2948, DOI 10.1109/TBME.2014.2340991
   McDuff D, 2014, IEEE T BIO-MED ENG, V61, P2593, DOI 10.1109/TBME.2014.2323695
   McDuff DJ, 2017, IEEE INT CONF AUTOMA, P63, DOI 10.1109/FG.2017.17
   Niu XS, 2020, IEEE T IMAGE PROCESS, V29, P2409, DOI 10.1109/TIP.2019.2947204
   Niu XS, 2018, INT C PATT RECOG, P3580, DOI 10.1109/ICPR.2018.8546321
   Nowara EM, 2018, IEEE COMPUT SOC CONF, P1353, DOI 10.1109/CVPRW.2018.00174
   Perepelkina O, 2020, IEEE COMPUT SOC CONF, P1163, DOI 10.1109/CVPRW50498.2020.00152
   Po LM, 2018, MULTIMED TOOLS APPL, V77, P6503, DOI 10.1007/s11042-017-4563-7
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Qiu Y, 2019, IEEE T MULTIMEDIA, V21, P1778, DOI 10.1109/TMM.2018.2883866
   Tran QV, 2021, IEEE T SYST MAN CY-S, V51, P5587, DOI 10.1109/TSMC.2019.2957159
   Radford A., 2019, LANGUAGE MODELS ARE
   Rapczynski M, 2019, IEEE T BIO-MED ENG, V66, P3360, DOI 10.1109/TBME.2019.2904326
   Rohmetra H, 2023, COMPUTING, V105, P783, DOI 10.1007/s00607-021-00937-7
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sheng JC, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103702
   Song RC, 2021, IEEE J BIOMED HEALTH, V25, P1373, DOI 10.1109/JBHI.2021.3051176
   Song RC, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103535
   Spetlik R., 2018, P BRIT MACH VIS C NE, P3
   Sun ZD, 2022, IEEE SIGNAL PROC LET, V29, P1507, DOI 10.1109/LSP.2022.3185964
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang ZY, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18179037
   Tarvainen MP, 2002, IEEE T BIO-MED ENG, V49, P172, DOI 10.1109/10.979357
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Villarroel M, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0199-5
   W C, 2021, Archery debuts heart-rate graphics on broadcast of the Olympic Games
   Wang WJ, 2017, IEEE T BIO-MED ENG, V64, P1479, DOI 10.1109/TBME.2016.2609282
   Wang WJ, 2017, PHYSIOL MEAS, V38, P1023, DOI 10.1088/1361-6579/aa6d02
   Wang WJ, 2017, BIOMED OPT EXPRESS, V8, P1965, DOI 10.1364/BOE.8.001965
   Wang WJ, 2016, IEEE T BIO-MED ENG, V63, P1974, DOI 10.1109/TBME.2015.2508602
   Wang WJ, 2015, IEEE T BIO-MED ENG, V62, P415, DOI 10.1109/TBME.2014.2356291
   Watson AR, 2020, TELEMED E-HEALTH, V26, P1110, DOI 10.1089/tmj.2020.0134
   Woyczyk A, 2021, IEEE J BIOMED HEALTH, V25, P1361, DOI 10.1109/JBHI.2021.3054779
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Wu WH, 2022, DIGIT SIGNAL PROCESS, V131, DOI 10.1016/j.dsp.2022.103730
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Yang Z, 2019, MULTIMED TOOLS APPL, V78, P26747, DOI 10.1007/s11042-019-07849-x
   Yao CL, 2021, IEEE IMAGE PROC, P3872, DOI 10.1109/ICIP42928.2021.9506276
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Yu Z., 2019, ARXIV PREPRINT ARXIV, P1
   Yu ZT, 2023, INT J COMPUT VISION, V131, P1307, DOI 10.1007/s11263-023-01758-1
   Yu ZT, 2022, PROC CVPR IEEE, P4176, DOI 10.1109/CVPR52688.2022.00415
   Yu ZT, 2021, IEEE SIGNAL PROC LET, V28, P1290, DOI 10.1109/LSP.2021.3089908
   Yu ZT, 2020, IEEE SIGNAL PROC LET, V27, P1245, DOI 10.1109/LSP.2020.3007086
   Yu ZT, 2019, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2019.00024
   Yue ZJ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3109398
   Zheng K, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103609
NR 107
TC 2
Z9 2
U1 19
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-16794-9
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000003
OA hybrid
DA 2024-07-18
ER

PT J
AU Saravanan, A
   Bama, SS
   Rajaleximi, PR
   Anandhi, D
   Srividya, M
AF Saravanan, A.
   Bama, S. Sathya
   Rajaleximi, P. Ramila
   Anandhi, D.
   Srividya, M.
TI Quality enhanced hybrid youtube video recommendation based on user
   preference through sentiment analysis on comments - a study on natural
   remedy videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE YouTube videos; content reliability; content relevancy; quality
   analysis; sentiment analysis; user comments
ID INFORMATION
AB With the rapid development of technologies, the Internet has become the primary source of information. In recent years, blogs and videos on the Internet have become the primary source of health-related information. About four out of five people trust the online information posted by anonymous people and access it for their own benefit. More specifically, the simple home remedies or natural remedies for minor health issues available on YouTube gain more attention among all age groups. Numerous viewers not only watch them; they even try or use these remedies personally for magical cures. However, the quality of the information about simple treatments and home remedies available on YouTube may not be accurate, reliable, useful, or trustworthy. Moreover, it is not simple to distinguish reliable information from misleading, false information. Thus, the main objective of this research work is to provide a quality enhanced recommendation of YouTube videos based on the user's preferences. In order to achieve the objective, the proposed work computes the scores for content relevancy and content reliability. The analysis of content reliability is two-fold, with implicit evaluation using structural analysis and explicit evaluation via sentimental analysis on YouTube video comments. The experimental and result analysis performed for the proposed work shows that the predicted ratings and the order of recommendations are more useful and have improved performance on reliability of the video content.
C1 [Saravanan, A.; Anandhi, D.; Srividya, M.] Coimbatore Inst Technol, Dept Comp, Coimbatore 641014, Tamil Nadu, India.
   [Bama, S. Sathya] Lawley Rd, Coimbatore 641003, Tamil Nadu, India.
   [Rajaleximi, P. Ramila] Garden City Univ, Sch Computat Sci & IT, Dept Comp Sci, Bengaluru 560049, India.
C3 Coimbatore Institute of Technology
RP Bama, SS (corresponding author), Lawley Rd, Coimbatore 641003, Tamil Nadu, India.
EM ssathya21@gmail.com
CR Abbas Syed Manzar., 2017, Bahria University Journal of Information Communication Technologies (BUJICT), V10
   Acilar A, 2022, ICT4AWE: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES FOR AGEING WELL AND E-HEALTH, P196, DOI 10.5220/0010994800003188
   Agarwal B, 2016, PROMINENT FEATURE EX, P21, DOI DOI 10.1007/978-3-319-25343-5_3
   Anandarajan M., 2019, Advances in analytics and data science, V2, P45
   [Anonymous], 2010, LREC 10
   Asghar MZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171649
   Aufar M., 2020, 2020 International Conference on Data Science and Its Applications (ICoDSA), P1, DOI DOI 10.1109/ICODSA50139.2020.9213078
   Aydin MF, 2020, INT J MED INFORM, V137, DOI 10.1016/j.ijmedinf.2020.104107
   Ballani A., 2019, Science behind these common home remedies, the time of India
   Bama S. Sathya, 2014, Journal of Theoretical and Applied Information Technology, V60, P343
   Baquero EP., 2018, A descriptive analysis of the most viewed YouTube videos related to depression, DOI [10.7916/D86M4K9P, DOI 10.7916/D86M4K9P]
   Brian D, 2021, Backlinko
   Chawla S, 2023, PLAST SURG-CHIR PLAS, V31, P371, DOI 10.1177/22925503211064382
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Dokuz Y, 2024, MULTIMED TOOLS APPL, V83, P10779, DOI 10.1007/s11042-023-16019-z
   Dubovi I, 2020, COMPUT EDUC, V156, DOI 10.1016/j.compedu.2020.103939
   Duran MB, 2021, ANDROLOGIA, V53, DOI 10.1111/and.14118
   Farag M, 2020, EUR UROL FOCUS, V6, P445, DOI 10.1016/j.euf.2019.09.017
   Gabarron E, 2013, INTERACT J MED RES, V2, P101, DOI 10.2196/ijmr.2465
   Ganesan K, 2012, INFORM RETRIEVAL, V15, P116, DOI 10.1007/s10791-011-9174-8
   GOULD HA, 1965, HUM ORGAN, V24, P201, DOI 10.17730/humo.24.3.m85151654737t712
   Han J, 2012, MOR KAUF D, P1
   Htet H., 2018, Journal of Pharmacognosy and Phytochemistry, V7, P695
   Isik M, 2020, TURK J ELECTR ENG CO, V28, P1405, DOI 10.3906/elk-1907-46
   Kalaivani P., 2013, Indian J Comput Sci Engin, V4, P285
   Kalra Gurjyot Singh, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P74, DOI 10.1109/ICCCIS48478.2019.8974514
   Kaur A., 2014, Int Eng Comput Sci, V3, P8030
   Kaur W, 2018, IND MANAGE DATA SYST, V118, P1578, DOI 10.1108/IMDS-07-2017-0300
   Kavitha K., 2020, Procedia Comput Sci, V177, P593, DOI [10.1016/j.procs.2020.10.084, DOI 10.1016/J.PROCS.2020.10.084]
   Khatri P, 2020, TRAVEL MED INFECT DI, V35, DOI 10.1016/j.tmaid.2020.101636
   Kundi F.M., 2014, LIFE SCI J, V11, P66
   Kundi FazalMasud., 2014, J BASIC APPL SCI RES, V4, P238
   Kunze Kyle N, 2019, Arthrosc Sports Med Rehabil, V1, pe109, DOI 10.1016/j.asmr.2019.09.003
   Kwok TMY, 2017, J VASC SURG-VENOUS L, V5, P238, DOI 10.1016/j.jvsv.2016.10.078
   Ladhari R, 2020, J RETAIL CONSUM SERV, V54, DOI 10.1016/j.jretconser.2019.102027
   Cunha AAL, 2019, LECT NOTES ARTIF INT, V11508, P561, DOI 10.1007/978-3-030-20912-4_51
   Lee KN, 2021, J MED INTERNET RES, V23, DOI 10.2196/24994
   Liu Q, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2613, DOI 10.1145/3340531.3416021
   Liu S, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3020, DOI 10.1145/3308558.3313513
   Liu WH, 2023, CMES-COMP MODEL ENG, V135, P239, DOI 10.32604/cmes.2022.022827
   Medicalxpress, 2020, Home remedies boom as India pandemic cases soar
   Meldrum S, 2017, DIGIT HEALTH, V3, DOI 10.1177/2055207617698908
   Metzger MJ, 2010, J COMMUN, V60, P413, DOI 10.1111/j.1460-2466.2010.01488.x
   Muhammad Abbi Nizar, 2019, 2019 International Conference on Computer Science, Information Technology, and Electrical Engineering (ICOMITEE). Proceedings, P199, DOI 10.1109/ICOMITEE.2019.8920923
   Muhammad A, 2016, KNOWL-BASED SYST, V108, P92, DOI 10.1016/j.knosys.2016.05.032
   Nazma M, 2018, Sentiment analysis on twitter data using different algorithms
   Osman W, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03446-z
   Parisius LM, 2014, BMC FAM PRACT, V15, DOI 10.1186/1471-2296-15-116
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   Sanders N, 2013, Twitter Sentiment Analysis Dataset
   Sangeorzan I, 2019, J AFFECT DISORDERS, V246, P422, DOI 10.1016/j.jad.2018.12.119
   Sathya Bama SS., 2015, Int J Appl Eng Res, V10, P13625
   Schultes P., 2013, WIRTSCHAFTSINF, V42, P15
   Sen Saikat, 2017, J Tradit Complement Med, V7, P234, DOI 10.1016/j.jtcme.2016.05.006
   Siersdorfer S., 2010, Proceedings of the 19th International Conference on World Wide Web, WWW'10, P891, DOI DOI 10.1145/1772690.1772781
   Singh AG, 2012, J RHEUMATOL, V39, P899, DOI 10.3899/jrheum.111114
   Sri Hari S, 2022, Int J Electron Market Retail, DOI [10.1504/IJEMR.2022.10048222, DOI 10.1504/IJEMR.2022.10048222]
   Szmuda T, 2020, REV MED VIROL, V30, DOI 10.1002/rmv.2132
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Thelwall M, 2014, Cyberemotions: Understanding Complex Systems, P1, DOI [10.1007/978-3-319-43639-5_7, DOI 10.1007/978-3-319-43639-5_7]
   Virmani Deepali, 2019, Smart Innovations in Communication and Computational Sciences. Proceedings of ICSICCS 2017. Advances in Intelligent Systems and Computing (AISC 669), P13, DOI 10.1007/978-981-10-8968-8_2
   Vryniotis V, 2013, Mach learn blog software develop news
   Wilhelm M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2165, DOI 10.1145/3269206.3272018
   Wong DKK, 2019, J MED INTERNET RES, V21, DOI 10.2196/10831
   Yan M, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P19, DOI 10.1145/2671188.2749344
   Yates Andrew, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P816, DOI 10.1007/978-3-642-36973-5_92
   Zhou RJ, 2020, IEEE ACCESS, V8, P6954, DOI 10.1109/ACCESS.2019.2961392
NR 68
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17391-6
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000013
DA 2024-07-18
ER

PT J
AU Srivastava, N
   Tayal, DK
AF Srivastava, Neha
   Tayal, Devendra K.
TI Assessing gene stability and gene affinity in microarray data
   classification using an extended relieff algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gene selection; Gene affinity information; Microarray data; ReliefF
   method; SVM; MLP
ID FEATURE-SELECTION; PREDICTION; CANCER
AB Microarray data have become an integral part of the clinical and drug discovery process. Due to its voluminous and heterogeneous nature, the question arises of the interpretability and stability of the traditional gene selection method. To enhance the stability of the gene selection method, so that the results are better explicable, an ameliorated Extended ReliefF gene selection algorithm is proposed. It encodes gene affinity information using a new mathematical formula based on Bayes' theorem and Manhattan distance for calculating the nearest neighbor in a pooled sample. It works in four aspects: initializing sample gene weight, improving gene weight, maximizing sample gene weight and finally adopting mutation operation. The proposed method selects the most informative genes which are highly perceptive to the prognosis of the disease. Further, to accomplish the accuracy and stability of the algorithm, soft classification is performed on Relieved_F, STIR, VLS-RelifF, I-RelieF, conventional ReliefF and proposed extended ReliefF algorithms using three classifiers namely Support Vector Machine (SVM), Multilayer Perceptron (MLP) and Random Forest (RF) on ten microarray datasets. According to the findings, MLP training times are much longer than those of RF and SVM. From a network perspective, SVM is much faster at training, whereas MLP excels in terms of accuracy. With a rise in gene similarity among the genes selected from the multiple training sets, the approach becomes more stable. As a result, it can be seen that the recommended gene selection algorithm greatly outperforms the other feature selection methods in terms of accuracy and stability.
C1 [Srivastava, Neha; Tayal, Devendra K.] Indira Gandhi Delhi Tech Univ Women, James Church,New Church Rd,Opp St,Kashmere Gate, New Delhi 110006, Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Srivastava, N (corresponding author), Indira Gandhi Delhi Tech Univ Women, James Church,New Church Rd,Opp St,Kashmere Gate, New Delhi 110006, Delhi, India.
EM nehasrivastava012329@gmail.com; devendrakumartayal@gmail.com
RI AGARWAL, NIDHI/AIA-5341-2022
OI AGARWAL, NIDHI/0000-0002-9044-8989
FU Data Science Research of Interdisciplinary Cyber-Physical Systems (ICPS)
   Programme of the Department of Science and Technology (DST),New Delhi,
   Government of India, India [T-54]
FX This work is funded under the Data Science Research of Interdisciplinary
   Cyber-Physical Systems (ICPS) Programme of the Department of Science and
   Technology (DST) [Sanction Number T-54], New Delhi, Government of India,
   India.
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Alizadeh AA, 2000, NATURE, V403, P503, DOI 10.1038/35000501
   [Anonymous], 2016, IEEE Energy Conversion Congress and Exposition ECCE
   Chaki J, 2020, MULTIMED TOOLS APPL, V79, P11163, DOI 10.1007/s11042-019-7181-8
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Dashtban M, 2017, GENOMICS, V109, P91, DOI 10.1016/j.ygeno.2017.01.004
   Dhanalakshmi R, 2019, J SCI IND RES INDIA, V78, P158
   Drotár P, 2015, COMPUT BIOL MED, V66, P1, DOI 10.1016/j.compbiomed.2015.08.010
   Furlanello C, 2003, NEURAL NETWORKS, V16, P641, DOI 10.1016/S0893-6080(03)00103-5
   Ghosh A, 2016, GENE, V583, P112, DOI 10.1016/j.gene.2016.02.015
   Giurcaneanu CD, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P57, DOI 10.1109/ISSPA.2003.1224814
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Goncalves J, 2002, IEEE ENG MED BIOL, V21, P154, DOI 10.1109/MEMB.2002.1175154
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hinrichs A, 2019, J COMPLEXITY, V50, P25, DOI 10.1016/j.jco.2018.08.003
   K CS.K MundayoorS, 2015, ARC J Int J Res Stud Biosci (IJRSB), V3, P201
   Khan MW, 2012, GENOMICS, V100, P65, DOI 10.1016/j.ygeno.2012.05.014
   Kumar M, 2015, PROCEDIA COMPUT SCI, V54, P301, DOI 10.1016/j.procs.2015.06.035
   Kumar M, 2015, KNOWL-BASED SYST, V89, P584, DOI 10.1016/j.knosys.2015.09.005
   Kumar V., 2014, SMART COMPUTING REV, V4, P211, DOI [10.6029/smartcr.2014.03.007, DOI 10.6029/SMARTCR.2014.03.007, DOI 10.1145/2740070.2626320]
   NAKAI K, 1992, GENOMICS, V14, P897, DOI 10.1016/S0888-7543(05)80111-9
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pang H, 2012, IEEE ACM T COMPUT BI, V9, P1422, DOI 10.1109/TCBB.2012.63
   Perthame É, 2016, STAT COMPUT, V26, P783, DOI 10.1007/s11222-015-9569-2
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Ram PK, 2023, MULTIMED TOOLS APPL, V82, P13453, DOI 10.1007/s11042-022-13964-z
   Ray SS, 2016, IEEE T NEUR NET LEAR, V27, P1890, DOI 10.1109/TNNLS.2015.2460994
   Ruan JH, 2019, GENOMICS, V111, P17, DOI 10.1016/j.ygeno.2016.07.005
   Sharma A, 2012, IEEE ACM T COMPUT BI, V9, P754, DOI 10.1109/TCBB.2011.151
   Sheela CJJ, 2022, J KING SAUD UNIV-COM, V34, P557, DOI 10.1016/j.jksuci.2019.04.006
   Somol P, 2010, IEEE T PATTERN ANAL, V32, P1921, DOI 10.1109/TPAMI.2010.34
   Srivastava N, 2017, Def Life Sci, VJ2, P399, DOI [10.14429/dlsj.2.11029, DOI 10.14429/DLSJ.2.11029]
   Sucharita S, 2024, MULTIMED TOOLS APPL, V83, P21319, DOI 10.1007/s11042-023-16353-2
   Dang TH, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BME-HUST), P14, DOI 10.1109/BME-HUST.2016.7782082
   Tu K, 2004, GENOMICS, V84, P922, DOI 10.1016/j.ygeno.2004.08.005
   Yates, 1999, Modern information retrieval
   Zahiri J, 2013, GENOMICS, V102, P237, DOI 10.1016/j.ygeno.2013.05.006
NR 37
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 17
PY 2023
DI 10.1007/s11042-023-17149-0
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U5AL0
UT WOS:001084922000018
DA 2024-07-18
ER

PT J
AU Lakshmanan, B
   Anand, S
   Raja, PSV
   Selvakumar, B
AF Lakshmanan, B.
   Anand, S.
   Raja, P. S. Vivek
   Selvakumar, B.
TI Improved DeepMitosisNet framework for detection of mitosis in
   histopathology images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast cancer; Histopathology images; Deep architectures; Teaching
   learning-based optimizer; Mitosis detection
ID BREAST-CANCER; MITOTIC CELLS; OPTIMIZATION; SELECTION; NETWORK
AB Mitosis detection in the histopathology images is one of the important prognostic factors that is helpful for cancer grading. Mitosis counting from whole slide images is challenging due to shape variations and stain variations. The key to solving the issue is to find more discriminative features corresponding to object boundaries and other similar objects like lymphocytes, cells with dense nuclei, and various soft tissues with the same grey level. However, small mitotic cells are difficult to detect using traditional machine learning methods. In this paper, we present an improved deep learning combined teaching learning-based optimizer (TLBO) model called DeepMitosisNet for accurate detection of mitotic figures. The proposed model helps reduce misclassification rates and computational costs. Comprehensive experiments are performed on the MITOS-ATYPIA 14 dataset for both Aperio and Hamamatsu scanners. The proposed model achieved an F-score of 96%, precision of 93.7% and recall of 98%, showing that the proposed deep framework with TLBO shows substantial improvements over other state-of-the-art mitosis detection techniques.
C1 [Lakshmanan, B.; Selvakumar, B.] Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi 626005, Tamilnadu, India.
   [Anand, S.] Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Sivakasi 626005, Tamilnadu, India.
   [Raja, P. S. Vivek] Nexstem, Bengaluru 560029, Karnataka, India.
C3 Mepco Schlenk Engineering College; Mepco Schlenk Engineering College
RP Lakshmanan, B (corresponding author), Mepco Schlenk Engn Coll, Dept Comp Sci & Engn, Sivakasi 626005, Tamilnadu, India.
EM lakshmanan@mepcoeng.ac.in; sanand@mepcoeng.ac.in;
   selvakumar.b@mepcoeng.ac.in
RI B, Selvakumar/T-1155-2019
OI B, Selvakumar/0000-0002-4534-702X
CR Albayrak A, 2016, INT SYMP COMP INTELL, P335, DOI 10.1109/CINTI.2016.7846429
   Cruz-Roa AA, 2013, LECT NOTES COMPUT SC, V8150, P403, DOI 10.1007/978-3-642-40763-5_50
   [Anonymous], 2015, J. Comput. Inf. Syst
   Babatunde O., 2014, Int. J. Electron. Commun. Comput. Eng, V5, P889
   BARLOW PW, 1977, PROTOPLASMA, V91, P207, DOI 10.1007/BF01276735
   Beevi KS, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2694004
   Beevi KS, 2019, BIOCYBERN BIOMED ENG, V39, P214, DOI 10.1016/j.bbe.2018.10.007
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Boyle P., 2008, World Cancer Report 2008
   Ciresan D., 2012, NIPS, P2843
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Das DK, 2019, COMPUT BIOL MED, V104, P29, DOI 10.1016/j.compbiomed.2018.11.001
   Vo DM, 2019, INFORM SCIENCES, V482, P123, DOI 10.1016/j.ins.2018.12.089
   ELSTON CW, 1991, HISTOPATHOLOGY, V19, P403, DOI 10.1111/j.1365-2559.1991.tb00229.x
   Gandomkar Ziba, 2017, J Pathol Inform, V8, P34, DOI 10.4103/jpi.jpi_22_17
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   GrandChallenge MITOSATYPIA14, 2014, Mitos-atypia-14.grand-challenge.org
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Irshad H, 2014, I S BIOMED IMAGING, P1279, DOI 10.1109/ISBI.2014.6868110
   Irshad Humayun, 2013, J Pathol Inform, V4, pS12, DOI 10.4103/2153-3539.109870
   Kaushal C, 2019, IRBM, V40, P211, DOI 10.1016/j.irbm.2019.06.001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2018, MED IMAGE ANAL, V45, P121, DOI 10.1016/j.media.2017.12.002
   Loukas C, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/829461
   Mahmood T, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030749
   Maroof N, 2020, PHOTODIAGN PHOTODYN, V31, DOI 10.1016/j.pdpdt.2020.101885
   Mathew T, 2021, BIOCYBERN BIOMED ENG, V41, P64, DOI 10.1016/j.bbe.2020.11.005
   Moradi P, 2016, APPL SOFT COMPUT, V43, P117, DOI 10.1016/j.asoc.2016.01.044
   Nassif AB, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102276
   Nateghi R., 2014, Computat Biol J, V2014, P1, DOI [DOI 10.1155/2014/970898, 10.1155/2014/970898]
   Nateghi R, 2021, ARTIF INTELL MED, V114, DOI 10.1016/j.artmed.2021.102048
   Nateghi R, 2014, 2014 21TH IRANIAN CONFERENCE ON BIOMEDICAL ENGINEERING (ICBME), P1, DOI 10.1109/ICBME.2014.7043883
   Pan XP, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107038
   Paul A, 2015, IEEE T IMAGE PROCESS, V24, P4041, DOI 10.1109/TIP.2015.2460455
   Rao R., 2012, Int. J. Ind. Eng. Comput., V3, P535, DOI [10.5267/J.IJIEC.2012.03.007, DOI 10.5267/J.IJIEC.2012.03.007]
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rao SD, 2018, Arxiv, DOI arXiv:1807.01788
   Rehman MU, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103212
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Smith RD, 2019, J GLOB ONCOL, V5, DOI 10.1200/JGO.19.00048
   Sohail A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85652-1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tashk A, 2015, APPL MATH MODEL, V39, P6165, DOI 10.1016/j.apm.2015.01.051
   Tashk A, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P406, DOI 10.1109/IKT.2013.6620101
   Tashk Ashkan, 2014, J Med Signals Sens, V4, P139
   Üstüner M, 2015, SIG PROCESS COMMUN, P540, DOI 10.1109/SIU.2015.7129880
   Wahab N, 2019, MICROSCOPY-JPN, V68, P216, DOI 10.1093/jmicro/dfz002
   Wahab N, 2017, COMPUT BIOL MED, V85, P86, DOI 10.1016/j.compbiomed.2017.04.012
   Wan T, 2017, NEUROCOMPUTING, V237, P291, DOI 10.1016/j.neucom.2017.01.008
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang HB, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043902
   Wang MW, 2019, KNOWL-BASED SYST, V168, P39, DOI 10.1016/j.knosys.2018.12.031
   Yosinski J, 2014, ADV NEUR IN, V27
NR 55
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-16830-8
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400003
DA 2024-07-18
ER

PT J
AU Chen, G
   Zhu, DL
   Chen, XY
AF Chen, Gang
   Zhu, Donglin
   Chen, Xiangyu
TI Similarity detection method of science fiction painting based on
   multi-strategy improved sparrow search algorithm and Gaussian pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sparrow search algorithm; Gaussian pyramid; Multi-strategy improvements;
   Science fiction painting; Similarity detection
AB Although image detection technology is widely used in various fields, there is still a large gap in the similarity detection of science fiction painting. Therefore, a similarity detection method for science fiction painting is proposed. Firstly, a k-layer pyramid image is created for the source image to be detected and the template image. Then, multi-strategy improved sparrow algorithm (MISSA) is used to perform rough matching in the top subgraph of the source image to obtain the coordinates of the initial matching target, the location transferred from the layer above each layer is the starting point of search, and pixel by pixel matching is carried out within the set window range. Finally, pHash is used as the similarity measure to calculate the similarity of matching results. The hybrid search strategy based on step function, multi-stage dynamic control of safety threshold, and food search strategy based on Logistic model are used to improve sparrow search algorithm, thereby forming MISSA to improve the accuracy and real-time performance in the matching process. In terms of performance verification of MISSA, the rationality and effectiveness of the three improved strategies are verified by ablation experiment, and the experimental results on CEC2017 benchmark function show that the optimization performance and convergence performance of MISSA are better than that of peer algorithms. The comparison results in the similarity detection experiment of science fiction painting fully verify that the proposed detection method has strong robustness in meeting the requirements of real-time and accuracy of matching.
C1 [Chen, Gang; Chen, Xiangyu] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Peoples R China.
   [Zhu, Donglin] JiangXi Univ Sci & Technol, Sch Informat Engn, Ganzhou 341000, Peoples R China.
C3 Fuzhou University; Jiangxi University of Science & Technology
RP Chen, G (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Peoples R China.
EM 201127006@fzu.edu.cn; 6920190624@mail.jxust.edu.cn;
   20201127012@fzu.edu.cn
FU This research did not receive any specific grant from funding agencies
   in the public, commercial, or not-for-profit sectors.
FX This research did not receive any specific grant from funding agencies
   in the public, commercial, or not-for-profit sectors.
NR 0
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-15494-8
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200009
DA 2024-07-18
ER

PT J
AU Elakiya, V
   Puviarasan, N
   Aruna, P
AF Elakiya, V.
   Puviarasan, N.
   Aruna, P.
TI Detection of violence using mosaicking and DFE- WLSRF: Deep feature
   extraction with weighted least square with random forest
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mosaicking; LSTM- Long short-term memory; CNN- Convolutional neural
   network; RF-Random forest; WLS-Weighted least square; Violence detection
AB The violence-related instances had surged recently in areas including footpaths, sports stadiums, remote roads, liquor stores and elevators that are tragically discovered only after some time. In exploring this issue, the complete video analysis model's potential to determine any violent acts from the sequence of video clips is evolved. However, the recent studies that work on the violent detection approach majorly focus on traditional hand-crafted features, less performance accuracy in violence detection and do not make entire utilization of deep learning research outcomes in computer vision. The proposed system is put forth a violence detection framework based on (CNN) Convolutional neural network with (LSTM) Long short-term memory feature extraction process and fine-tuned the image frame hyperparameter from extracted features using Random forest classifier updated with weight score through (WLS) Weight least square algorithm. The Model in prior subjected to the feature extraction phase and the image frames are segmented through the mosaicking pre-processing step, with a 30:20 enlargement ratio to image mosaics, aiding to generate time-consistent outcomes and algorithm's performance improvisation through minimizing search space. The integration of CNN and LSTM framework is applied to reduce the complexity of the extraction learning process, and the LSTM network in correlating feature value with past information, and retaining memory space. The dynamic weighing scheme is proposed with the WLS method and this weighted score is assigned to the most probable class in the decision tree. Such more similar parameters as hyperparameters were tuned through a random forest classifier, and it categorizes the outcomes as non-fight or fights clips dynamically. The comparative performance evaluation of the proposed framework (DFE-WLSRF), Deep feature extraction - Weighted least square random-forest classifier delineated the outperforming high accuracy results in comparison to other traditional violence detection approaches.
C1 [Elakiya, V.; Aruna, P.] Annamalai Univ, Dept Comp Sci & Engn, Chidambaram, Tamil Nadu, India.
   [Puviarasan, N.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, Tamil Nadu, India.
C3 Annamalai University; Annamalai University
RP Elakiya, V (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Chidambaram, Tamil Nadu, India.
EM elakiya88@gmail.com; npuvi2410@yahoo.in; arunapuvi95@gmail.com
CR A Baskar, 2022, Deeply Supervised Practical Implementation of Violence Detection from Videos for Maximizing Performance
   Accattoli S, 2020, APPL ARTIF INTELL, V34, P329, DOI 10.1080/08839514.2020.1723876
   Albadi N, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0587-5
   Arifoglu D, 2019, ARTIF INTELL MED, V94, P88, DOI 10.1016/j.artmed.2019.01.005
   Baba M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071676
   Bhatia M, 2022, MULTIMED TOOLS APPL, V81, P37519, DOI 10.1007/s11042-022-13505-8
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Choudhary Rohan, 2022, Advances in Data Computing, Communication and Security: Proceedings of I3CS2021. Lecture Notes on Data Engineering and Communications Technologies (106), P51, DOI 10.1007/978-981-16-8403-6_5
   Colton D., 2019, Journal of Computer-Assisted Linguistic Research, V3, P21, DOI [10.4995/jclr.2019.11112, DOI 10.4995/JCLR.2019.11112]
   Deepak K, 2020, ICT EXPRESS, V6, P155, DOI 10.1016/j.icte.2020.04.014
   Deepak K, 2021, CIRC SYST SIGNAL PR, V40, P1333, DOI 10.1007/s00034-020-01522-7
   Fan MY, 2022, IEEE T NEUR NET LEAR, V33, P5859, DOI 10.1109/TNNLS.2021.3071603
   Febin IP, 2020, PATTERN ANAL APPL, V23, P611, DOI 10.1007/s10044-019-00821-3
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Hu X, 2022, Information Sciences
   Imah E.M., 2022, Regist: J. Ilm. Teknol. Sist. Inf, V8, P94
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jahlan H. M. B., 2022, arXiv
   Kang MS, 2021, IEEE ACCESS, V9, P76270, DOI 10.1109/ACCESS.2021.3083273
   Khan SU, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9224963
   Kumar S. Malviya, 2022, Transactions on Asian and Low-Resource Language Information Processing
   Li HC, 2020, MEAS CONTROL-UK, V53, P796, DOI 10.1177/0020294020902788
   Lohithashva BH, 2021, COMM COM INF SC, V1435, P268, DOI 10.1007/978-3-030-82269-9_21
   Mahdi M. S., 2021, Journal of Al-Qadisiyah for Computer Science and Mathematics, V13, P92
   Mensa E, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01237-4
   Moaaz M. M., 2020, VIOLENCE DETECTION S, V2, P1
   Mohammadi H, 2022, Arxiv, DOI arXiv:2202.02212
   Namasudra S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108048
   Pandey A, 2019, IMAGE VISION COMPUT, V89, P236, DOI 10.1016/j.imavis.2019.07.002
   Pang WF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2260, DOI 10.1109/ICASSP39728.2021.9413686
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Peixoto B, 2020, INT CONF ACOUST SPEE, P2957, DOI [10.1109/icassp40776.2020.9054018, 10.1109/ICASSP40776.2020.9054018]
   Perperis T, 2011, EXPERT SYST APPL, V38, P14102, DOI 10.1016/j.eswa.2011.04.219
   Qu HC, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109563
   Shafiq M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12188972
   Shafiq M, 2021, IEEE INTERNET THINGS, V8, P3242, DOI 10.1109/JIOT.2020.3002255
   Shafiq M, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101863
   Shafiq M, 2020, FUTURE GENER COMP SY, V107, P433, DOI 10.1016/j.future.2020.02.017
   Shafiq SM, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102177
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Sun Liu P., 2020, Security and communication networks 2020
   Tun L. L., MERAL Portal
   Ullah FUM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112472
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Vijeikis R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062216
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Yahaya SW, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105613
   Yousaf K, 2022, IEEE ACCESS, V10, P16283, DOI 10.1109/ACCESS.2022.3147519
NR 48
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17064-4
EA OCT 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800007
DA 2024-07-18
ER

PT J
AU Bizimana, PC
   Zhang, ZP
   Asim, M
   El-Latif, AAA
   Hammad, M
AF Bizimana, Pierre Claver
   Zhang, Zuping
   Asim, Muhammad
   El-Latif, Ahmed A. Abd
   Hammad, Mohamed
TI Learning-based techniques for heart disease prediction: a survey of
   models and performance metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Learning based techniques; Machine learning; Deep learning; Healthcare;
   Prediction model; Heart diseases
ID MACHINE; DIAGNOSIS
AB Heart disease (HD) is a major threat to human health, and the medical field generates vast amounts of data that doctors struggle to effectively interpret and use. Early prediction and classification of HD types are crucial for effective medical treatment. Researchers have found it important to use learning-based techniques from machine and deep learning, such as supervised and deep neural networks, to develop automatic models for HD. These techniques have been used to simulate HD management and extract important features from complex data sets. This survey examines various HD prediction models, classifying the learning-based techniques, datasets, and contexts used, and analyzing the performance metrics of each contribution. It also clarifies which method suits a type of HD. With the growth of data sets, researchers are increasingly utilizing these techniques to create more precise models. However, there is still much work to be done to improve the accuracy of HD predictions.
C1 [Bizimana, Pierre Claver; Zhang, Zuping] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
   [Asim, Muhammad; El-Latif, Ahmed A. Abd; Hammad, Mohamed] Prince Sultan Univ, Coll Comp & Informat Sci, EIAS Data Sci Lab, Riyadh 11586, Saudi Arabia.
   [Asim, Muhammad] Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.
   [El-Latif, Ahmed A. Abd] Menoufia Univ, Fac Sci, Dept Math & Comp Sci, Shibin Al Kawm 32511, Egypt.
   [Hammad, Mohamed] Menoufia Univ, Fac Comp & Informat, Informat Technol Dept, Shibin Al Kawm 32511, Egypt.
C3 Central South University; Prince Sultan University; Guangdong University
   of Technology; Egyptian Knowledge Bank (EKB); Menofia University;
   Egyptian Knowledge Bank (EKB); Menofia University
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.; Asim, M; Hammad, M (corresponding author), Prince Sultan Univ, Coll Comp & Informat Sci, EIAS Data Sci Lab, Riyadh 11586, Saudi Arabia.; Asim, M (corresponding author), Guangdong Univ Technol, Sch Comp Sci & Technol, Guangzhou 510006, Peoples R China.; Hammad, M (corresponding author), Menoufia Univ, Fac Comp & Informat, Informat Technol Dept, Shibin Al Kawm 32511, Egypt.
EM bizimana@csu.edu.cn; zpzhang@csu.edu.cn; masim@psu.edu.sa;
   aabdellatif@psu.edu.sa; mhammad@psu.edu.sa
RI Asim, Muhammad/IYS-8929-2023; Hammad, Mohamed/U-6169-2019
OI Asim, Muhammad/0000-0002-6423-9809; Hammad, Mohamed/0000-0002-6506-3083;
   BIZIMANA, Pierre Claver/0000-0002-4522-5444
FU The authors would like to acknowledge the support of Prince Sultan
   University. Also, this research was funded by Hunan Key Laboratory for
   Internet of Things in Electricity (Grant No. 2019TP1016) and the
   National Natural Science Foundation of China (Grant N [2019TP1016];
   Prince Sultan University - Hunan Key Laboratory for Internet of Things
   in Electricity [72061147004]; National Natural Science Foundation of
   China [2021JJ30055, 5216A6200037]; National Natural Science Foundation
   of Hunan Province
FX The authors would like to acknowledge the support of Prince Sultan
   University. Also, this research was funded by Hunan Key Laboratory for
   Internet of Things in Electricity (Grant No. 2019TP1016) and the
   National Natural Science Foundation of China (Grant No.72061147004) the
   National Natural Science Foundation of Hunan Province (Grant No.
   2021JJ30055) and the project about research on key technologies of power
   knowledge graph (Grant No. 5216A6200037).
CR Adiba FI, 2021, 2021 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN INFORMATION TECHNOLOGY (ICITIIT), DOI 10.1109/ICITIIT51526.2021.9399593
   Ahmad GN, 2022, IEEE ACCESS, V10, P80151, DOI 10.1109/ACCESS.2022.3165792
   Ahmad GN, 2022, IEEE ACCESS, V10, P23808, DOI 10.1109/ACCESS.2022.3153047
   Ahmed H, 2020, FUTURE GENER COMP SY, V111, P714, DOI 10.1016/j.future.2019.09.056
   Akter S., 2021, IEEE REG 10 HUM TECH, V2021-Septe, DOI [10.1109/R10-HTC53172.2021.9641080, DOI 10.1109/R10-HTC53172.2021.9641080]
   Alex P. Mamatha, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0848, DOI 10.1109/ICCSP.2019.8697977
   Ali Abdelmegeid Amin, 2020, 2020 12th International Conference on Electrical Engineering (ICEENG), P145, DOI 10.1109/ICEENG45378.2020.9171739
   Alim MA., 2020, 2020 3 INT C COMP MA, P1, DOI DOI 10.1109/ICOMET48670.2020.9074135
   Almustafa KM, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03626-y
   Alqahtani LA, 2020, 2020 11TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P298, DOI 10.1109/UEMCON51285.2020.9298051
   Altayeva A, 2016, INT C CONTR AUTOMAT, P1087, DOI 10.1109/ICCAS.2016.7832446
   Andreopoulos B, 2009, BRIEF BIOINFORM, V10, P297, DOI 10.1093/bib/bbn058
   [Anonymous], 2015, Int J Adv Eng Technol, V8, P194
   Arooj S, 2022, BIOMEDICINES, V10, DOI 10.3390/biomedicines10112796
   Arunaggiri Pandian K., 2021, 2021 AS C INN TECHN, P1, DOI [10.1109/ASIANCON51346.2021.9544787, DOI 10.1109/ASIANCON51346.2021.9544787]
   Asadi S, 2021, J BIOMED INFORM, V115, DOI 10.1016/j.jbi.2021.103690
   Aslam M, 2022, Nano Biomed Eng, V14, DOI [10.5101/nbe.v14i1.p81-89, DOI 10.5101/NBE.V14I1.P81-89]
   Atallah R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P335
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Banoth R, 2022, 2022 IEEE 7 INT C CO, P1, DOI [10.1109/I2CT54291.2022.9824888, DOI 10.1109/I2CT54291.2022.9824888]
   Banu NKS, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P256, DOI 10.1109/ICEECCOT.2016.7955226
   Basha N, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER TECHNOLOGIES AND OPTIMIZATION TECHNIQUES (ICEECCOT), P387, DOI [10.1109/iceeccot46775.2019.9114651, 10.1109/ICEECCOT46775.2019.9114651]
   Battula K, 2021, 2021 INT C EL COMP C, P1, DOI [10.1109/ICECCME52200.2021.9591026, DOI 10.1109/ICECCME52200.2021.9591026]
   Bharanika H, 2021, P 1 INT C CMP COMM, DOI [10.4108/eai.7-6-2021.2308784, DOI 10.4108/EAI.7-6-2021.2308784]
   Bharat A, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CIRCUITS, CONTROL, COMMUNICATION AND COMPUTING (I4C)
   Bharti R, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8387680
   Bindhika GSS, 2020, Int Res J Eng Technol, V7
   Bizimana PC, 2023, BIOMED RES INT, V2023, DOI 10.1155/2023/3531420
   Boukhatem C., 2022, 2022 ADV SCI ENG TEC, P1, DOI [10.1109/ASET53988.2022.9734880, DOI 10.1109/ASET53988.2022.9734880]
   Calderon-Vilca Hugo D., 2019, 2019 7th International Engineering, Sciences and Technology Conference (IESTEC), P562, DOI 10.1109/IESTEC46403.2019.00106
   CDC, 2022, Centers for Disease Control and Prevention, Underlying Medical Conditions Associated with Higher Risk for Severe COVID-19: Information for Healthcare Professionals
   Celebi M.E., 2016, Unsupervised Learning Algorithms, DOI 10.1007/978-3-319-24211-8
   Chakarverti Mohini, 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P1578, DOI 10.1109/ICICICT46008.2019.8993191
   Chandra H, 2017, Int J Comput Sci Inf Secur, P332
   Chauhan Utsav, 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P886, DOI 10.1109/ICICICT46008.2019.8993296
   Chauhan Y, 2020, Int J Sci Res (IJSR), DOI [10.21275/SR20501193934, DOI 10.21275/SR20501193934]
   De Backer Guy, 2004, Arch Mal Coeur Vaiss, V97, P1019
   Deo RC, 2015, CIRCULATION, V132, P1920, DOI 10.1161/CIRCULATIONAHA.115.001593
   Dhar S., 2018, 2018 4 INT C COMP CO, P1, DOI [10.1109/CCAA.2018.8777531, DOI 10.1109/CCAA.2018.8777531]
   Dileep P, 2023, NEURAL COMPUT APPL, V35, P7253, DOI 10.1007/s00521-022-07064-0
   Dinesh K.G., 2018, 2018 INT C CURRENT T, P1, DOI [10.1109/ICCTCT.2018.8550857, DOI 10.1109/ICCTCT.2018.8550857]
   El-Shafiey MG, 2021, INT J COMPUT SCI NET, V21, P135, DOI 10.22937/IJCSNS.2021.21.10.18
   Enriko I.K. A., 2016, J. Telecommun. Electron. Comput. Eng, V8, P59, DOI DOI 10.21203/RS.3.RS-3297518/V1
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Fatima M., 2017, Journal of Intelligent Learning Systems and Applications, V09, P1, DOI DOI 10.4236/JILSA.2017.91001
   Garg Apurv, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012046
   Gavande S, 2022, Int Res J Eng Technol (IRJET), V9
   Geron A., 2019, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, V2
   Gnoguem C, 2022, Intelligent vision in healthcare, P59, DOI [10.1007/978-981-16-7771-7_6, DOI 10.1007/978-981-16-7771-7_6]
   Gowri J, 2022, Int J Innovat Technol Exploring Eng (IJITEE), V11, DOI [10.35940/ijitee.H9148.0711822, DOI 10.35940/IJITEE.H9148.0711822]
   Guo SD, 2023, COMPUT METH PROG BIO, V236, DOI 10.1016/j.cmpb.2023.107547
   Gupta Akansh, 2020, Proceedings of First International Conference on Computing, Communications, and Cyber-Security (IC4S 2019). Lecture Notes in Networks and Systems (LNNS 121), P561, DOI 10.1007/978-981-15-3369-3_42
   Gupta Chiradeep, 2022, Journal of Physics: Conference Series, V2161, DOI 10.1088/1742-6596/2161/1/012013
   Gupta N, 2021, J Emerg Technol Innovative Res., DOI [10.13140/RG.2.2.16604.92800, DOI 10.13140/RG.2.2.16604.92800]
   Hakim MA, 2021, 2021 12 INT C COMP C, P1, DOI [10.1109/ICCCNT51525.2021.9580063, DOI 10.1109/ICCCNT51525.2021.9580063]
   Han J, 2012, MOR KAUF D, P1
   Harkulkar N., 2020, INT J RES APPL SCI E, V8, P875, DOI DOI 10.22214/IJRASET.2020.32671
   Hazra A., 2017, Advances in Computational Sciences and Technology, V10, P2137
   Hosmer D. W., 2013, Applied logistic regression, V398, DOI DOI 10.1002/9781118548387
   Hossain AI, 2021, 2021 INT C AUT CONTR, P1, DOI [10.1109/ACMI53878.2021.9528169, DOI 10.1109/ACMI53878.2021.9528169]
   Hussain Shadab, 2021, 2021 19th OITS International Conference on Information Technology (OCIT)., P353, DOI 10.1109/OCIT53463.2021.00076
   Islam MDS, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P167, DOI [10.1109/ICAIBD.2019.8836998, 10.1109/icaibd.2019.8836998]
   Islam R, 2021, 2ND INTERNATIONAL INFORMATICS AND SOFTWARE ENGINEERING CONFERENCE (IISEC), DOI 10.1109/IISEC54230.2021.9672415
   Jabbar MA, 2017, BIOMED RES-INDIA, V28, P4154
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jayasudha SKB, 2021, 2021 IEEE MYS SUBS I, P505, DOI [10.1109/MysuruCon52639.2021.9641581, DOI 10.1109/MYSURUCON52639.2021.9641581]
   Jayatilake SMDAC, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6679512
   Jha K.K., 2021, P 2021 IEEE INT C CO, P1, DOI [10.1109/CSITSS54238.2021.9683524, DOI 10.1109/CSITSS54238.2021.9683524]
   Jin B, 2018, IEEE ACCESS, V6, P9256, DOI 10.1109/ACCESS.2017.2789324
   Jindal Harshit, 2021, IOP Conference Series: Materials Science and Engineering, V1022, DOI 10.1088/1757-899X/1022/1/012072
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Kamalapurkar S, 2020, Online portal for prediction of heart disease using machine learning ensemble method (PrHD-ML), P1, DOI [10.1109/B-HTC50970.2020.9297918, DOI 10.1109/B-HTC50970.2020.9297918]
   Karthick D, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1182, DOI 10.1109/ICISC.2018.8398990
   Kaur PC, 2020, 2020 4 INT C COMP ME, DOI [10.1109/ICCMC48092.2020.ICCMC-00037, DOI 10.1109/ICCMC48092.2020.ICCMC-00037]
   Kayikci S, 2019, 2019 3 INT S MULT ST, P1, DOI [10.1109/ISMSIT.2019.8932952, DOI 10.1109/ISMSIT.2019.8932952]
   Kelwade JP, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P1062, DOI 10.1109/ICACDOT.2016.7877749
   Kelwade JP, 2016, INT CONF RELI INFO, P426
   Kelwade JP, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONTROL, MEASUREMENT AND INSTRUMENTATION (CMI), P454, DOI 10.1109/CMI.2016.7413789
   Khan MF, 2021, IEEE ACCESS, V9, P72661, DOI 10.1109/ACCESS.2021.3080617
   Khan UJ, 2021, 2021 5 INT C COMP ME, P1779, DOI [10.1109/ICCMC51019.2021.9418345, DOI 10.1109/ICCMC51019.2021.9418345]
   Khan Y, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P21, DOI 10.1145/3318299.3318343
   Khateeb N, 2017, INTERNATIONAL CONFERENCE ON BIG DATA AND INTERNET OF THINGS (BDIOT 2017), P21, DOI 10.1145/3175684.3175703
   Kibria HB, 2022, COMPUT BIOL CHEM, V98, DOI 10.1016/j.compbiolchem.2022.107672
   Kohli P. S., 2018, P 4 INT C COMP COMM, P1, DOI [DOI 10.1109/CCAA.2018.8777449, 10.1109/CCAA.2018.8777449]
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Krishna Prasad K, 2021, Int J Health Sci Pharm, V5, DOI [10.47992/IJHSP.2581.6411.0061, DOI 10.47992/IJHSP.2581.6411.0061]
   Krishnani D, 2019, TENCON IEEE REGION, P367, DOI [10.1109/tencon.2019.8929434, 10.1109/TENCON.2019.8929434]
   Kristensen JB, 2019, 2019 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS 2019), DOI 10.1109/ieee-iws.2019.8804072
   Kulshreshth A, 2022, 2022 2 INT C INT TEC, P1, DOI [10.1109/CONIT55038.2022.9847716, DOI 10.1109/CONIT55038.2022.9847716]
   Kumar D., 2021, P 10 INT C SYST MOD, P670, DOI [10.1109/SMART52563.2021.9676234, DOI 10.1109/SMART52563.2021.9676234]
   Kumar KL, 2021, 2021 INTERNATIONAL CONFERENCE ON COMPUTING SCIENCES (ICCS 2021), P228, DOI 10.1109/ICCS54944.2021.00052
   Kumar NK, 2020, INT CONF ADVAN COMPU, P15, DOI [10.1109/icaccs48705.2020.9074183, 10.1109/ICACCS48705.2020.9074183]
   Latha C. Beulah Christalin, 2019, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2019.100203
   Latif J, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673502
   Li HX, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000006090
   Li JP, 2020, IEEE ACCESS, V8, P107562, DOI 10.1109/ACCESS.2020.3001149
   Li WQ, 2022, METHODS, V198, P96, DOI 10.1016/j.ymeth.2021.12.009
   Liang PY, 2020, IEEE INT C BIOINFORM, P2009, DOI 10.1109/BIBM49941.2020.9313253
   Limbitote M, 2020, Int J Eng Res., V9, P450, DOI [10.17577/IJERTV9IS060298, DOI 10.17577/IJERTV9IS060298]
   Luo GN, 2018, IEEE T BIO-MED ENG, V65, P1924, DOI 10.1109/TBME.2017.2762762
   Luo GN, 2016, COMPUT CARDIOL CONF, V43, P89
   Mahaveer Puneet, 2022, 2022 IEEE DELH SECT, P1
   Malav A., 2017, INT J ENG TECHNOL, V9, P3081, DOI DOI 10.21817/IJET/2017/V9I4/170904101
   Mamun M, 2022, 2022 IEEE WORLD AI IOT CONGRESS (AIIOT), P194, DOI [10.1109/AIIOT54504.2022.9817303, 10.1109/AIIoT54504.2022.9817303]
   Manjunathan N., 2022, 2022 6th International Conference on Computing Methodologies and Communication (ICCMC), P295, DOI 10.1109/ICCMC53470.2022.9753916
   Marsland S, 2009, CH CRC MACH LEARN PA, P1
   Mehmood A, 2021, ARAB J SCI ENG, V46, P3409, DOI 10.1007/s13369-020-05105-1
   Mienye Ibomoiye Domor, 2020, Informatics in Medicine Unlocked, V18, P302, DOI 10.1016/j.imu.2020.100307
   Mienye I. D., 2020, Inf. Med. Unlocked, V20, DOI DOI 10.1016/J.IMU.2020.100402
   Mishra V, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033713
   Mohan S, 2019, IEEE ACCESS, V7, P81542, DOI 10.1109/ACCESS.2019.2923707
   Morya Rimpy, 2022, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2327/1/012071
   Mukherjee B, 2021, PROCEEDINGS OF THE 2021 FIFTH INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC 2021), P456, DOI 10.1109/I-SMAC52330.2021.9640932
   Murat F, 2020, COMPUT BIOL MED, V120, DOI 10.1016/j.compbiomed.2020.103726
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Nabeel M, 2021, 4TH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING (IC)2, P203, DOI 10.1109/ICIC53490.2021.9692977
   Nair, 2019, 2019 IEEE INT C EL C, P1, DOI DOI 10.1109/ICECCT.2019.8869001
   Nanehkaran YA, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/6913043
   Nissa N, 2021, Wesleyan J Res, V13
   Obasi T, 2019, IEEE INT CONF BIG DA, P2393, DOI 10.1109/BigData47090.2019.9005488
   Otoom AhmedFawzi., 2015, Int. J. Softw. Eng. its Appl., V9, P143, DOI [DOI 10.14257/IJSEIA.2015.9.1.12, 10.14257/ijseia.2015.9.1.12]
   Pal Madhumita, 2021, Journal of Physics: Conference Series, V1817, DOI 10.1088/1742-6596/1817/1/012009
   Patel J., 2016, J. Comput. Sci. Electron., V7, P129
   Phasinam K, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/7529472
   Prathibhamol C, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P51, DOI 10.1109/ICACCI.2017.8125815
   Princy RJP, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P570, DOI [10.1109/ICICCS48265.2020.9121169, 10.1109/iciccs48265.2020.9121169]
   Qi ZY, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01436-7
   Rahman MJU, 2018, INT CONF ELECTR ENG, P58, DOI 10.1109/CEEICT.2018.8628152
   Rai H. M., 2020, 2020 IEEE 7 UTT PRAD, DOI [10.1109/upcon50219.2020.9376450, DOI 10.1109/UPCON50219.2020.9376450]
   Rajathi S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P68, DOI 10.1109/SAPIENCE.2016.7684132
   Rajdhan A, 2020, Int J Res Technol, V9, P659
   Rajliwall Nitten S., 2018, 2018 5th Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE), P246, DOI 10.1109/APWConCSE.2018.00047
   Rajpoot C, 2021, Eng J, DOI [10.4186/ej.year.vol.issue, DOI 10.4186/EJ.YEAR.VOL.ISSUE]
   Rakshit T., 2021, Int J Eng Tech Res, V10, P886
   Ramalingam V.V., 2018, International Journal of Engineering Technology, V7, P684, DOI [10.14419/ijet.v7i2.8.10557, DOI 10.14419/IJET.V7I2.8.10557]
   Ramesh TR, 2022, MALAYS J COMPUT SCI, P132, DOI 10.22452/mjcs.sp2022no1.10
   Ramprakash P, 2020, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT-2020), P666, DOI 10.1109/icict48043.2020.9112443
   Rashme Tamanna Yesmin, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1554, DOI 10.1109/ICCES51350.2021.9489057
   Reddy GD, 2021, Int J Adv Res, Ideas Innovations Technol, V7
   Reddy KVV, 2021, 2020 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT AND ADVANCED SYSTEMS (ICIAS), DOI 10.1109/ICIAS49414.2021.9642676
   Reddy N. S. C., 2019, International Journal of Innovative Computing, V9, DOI [10.11113/ijic.v9n1.210, DOI 10.11113/IJIC.V9N1.210]
   Ripan R.C., 2021, SN Comput. Sci., P1, DOI [10.1007/s42979-021-00518-7, DOI 10.1007/S42979-021-00518-7]
   Roy Riya Elizabeth, 2022, 2022 IEEE World Conference on Applied Intelligence and Computing (AIC), P373, DOI 10.1109/AIC55036.2022.9848945
   Rubakumar N., 2022, 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), P1014, DOI 10.1109/ICACCS54159.2022.9785240
   Saboor A, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/1410169
   Safdar S, 2018, ARTIF INTELL REV, V50, P597, DOI 10.1007/s10462-017-9552-8
   Santhosh Kumar K. L., 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P693, DOI 10.1109/ICISS49785.2020.9316014
   Saraf V., 2020, ADV COMPUTING TECHNO, P293, DOI [10.1007/978-981- 15- 3242-9_ 28, DOI 10.1007/978-981-15-3242-928]
   Sarangapani J, 2021, Adv Comput, P151, DOI DOI 10.1007/978-981-16-0401-0_12
   Sarra R.R., 2022, Indones. J. Electr. Eng. Comput. Sci, V29, P375
   Sateesh C., 2022, P 2 INT C INN PRACT, V2, P583
   Satu MS, 2018, 2018 INT C COMP COMM, P1, DOI [10.1109/IC4ME2.2018.8465642, DOI 10.1109/IC4ME2.2018.8465642]
   Saw M, 2020, INT CONF COMP COMMUN, P253, DOI 10.1109/iccci48352.2020.9104210
   Shah D., 2020, SN Comput Sci, V1, P345, DOI DOI 10.1007/S42979-020-00365-Y
   Shahiduzzaman M, 2022, 2022 INT C ADV EL EL, P1, DOI [10.1109/ICAEEE54957.2022.9836418, DOI 10.1109/ICAEEE54957.2022.9836418]
   Sharma S, 2020, Int J Innovative Technol Exploring Eng (IJITEE), V9
   Sharma Vijeta, 2020, 2020 2nd International Conference on Advances in Computing, Communication Control and Networking (ICACCCN), P177, DOI 10.1109/ICACCCN51052.2020.9362842
   Shen YT, 2016, IEEE ENG MED BIO, P2419, DOI 10.1109/EMBC.2016.7591218
   Shinde RM, 2015, Int J Comput Sci Inf Technol, V6
   Shorewala V., 2021, Inform. Med., V26, DOI [10.1016/j.imu.2021.100655, DOI 10.1016/J.IMU.2021.100655]
   Sidoti A, 2017, Life Safety Secur, V5, P96, DOI DOI 10.12882/2283-7604.2017.5.12
   Singh Archana, 2020, 2020 International Conference on Electrical and Electronics Engineering (ICE3), P452, DOI 10.1109/ICE348803.2020.9122958
   Singh H, 2021, 6 INT C IM INF PROC, V6, P164, DOI [10.1109/ICIIP53038.2021.9702625, DOI 10.1109/ICIIP53038.2021.9702625]
   Singh R, 2019, Int J Comput Sci Eng., DOI [10.26438/ijcse/v7i5.861866, DOI 10.26438/IJCSE/V7I5.861866]
   Singh Y, 2017, INT C ADV COMP DAT S, DOI [10.1007/978-981-10-5427-3-63, DOI 10.1007/978-981-10-5427-3-63]
   Singhal S., 2018, American International Journal of Research in Science, Technology, Engineering
   Sivaranjani R., 2019, Journal of Physics: Conference Series, V1362, DOI 10.1088/1742-6596/1362/1/012062
   Subhadra K, 2019, Int J Innovative Technol Exploring Eng (IJITEE), V8, P1
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Suneetha J., 2022, Soft Computing and Signal Processing: Proceedings of 4th ICSCSP 2021. Advances in Intelligent Systems and Computing (1413), P11, DOI 10.1007/978-981-16-7088-6_2
   Swain D., 2022, J. Comput. Sci, V18, P993, DOI [10.3844/jcssp.2022.993.1004, DOI 10.3844/JCSSP.2022.993.1004]
   Tabassum T, 2016, INT CONF ELECTR ENG
   Thakkar HK, 2020, 2020 IEEE 17 IND COU, P1, DOI [10.1109/INDICON49873.2020.9342444, DOI 10.1109/INDICON49873.2020.9342444]
   Thangamani M., 2020, Int. J. Eng. Trends Technol., V68, P48
   Trisal A, 2022, 2022 INT C COMP INT, P583, DOI [10.1109/CISES54857.2022.9844370, DOI 10.1109/CISES54857.2022.9844370]
   Tsarapatsani Konstantina, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P1066, DOI 10.1109/EMBC48229.2022.9871121
   Tseng LM, 2020, IEEE ACCESS, V8, P221886, DOI 10.1109/ACCESS.2020.3042782
   Vayadande Kuldeep, 2022, 2022 International Conference on Computational Intelligence and Sustainable Engineering Solutions (CISES), P393, DOI 10.1109/CISES54857.2022.9844406
   Velusamy D, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105770
   Vinayaka S, 2020, Adv Comput Data Sci, P395, DOI [10.1007/978-981-15-6634-9.36, DOI 10.1007/978-981-15-6634-9.36]
   Williams Reldean, 2021, 2021 International Conference on Data Analytics for Business and Industry (ICDABI), P118, DOI 10.1109/ICDABI53623.2021.9655783
   Xie J, 2021, NEUROCOMPUTING, V452, P566, DOI 10.1016/j.neucom.2020.10.114
   Xiong ZH, 2019, IEEE T MED IMAGING, V38, P515, DOI 10.1109/TMI.2018.2866845
   Xu WX, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2020), P195, DOI [10.1109/ICAIBD49809.2020.9137483, 10.1109/icaibd49809.2020.9137483]
   Yadav DP, 2021, 2021 5 INT C INF SYS, P1, DOI [10.1109/ISCON52037.2021.9702410, DOI 10.1109/ISCON52037.2021.9702410]
   Ye Q, 2021, 2021 5 AS C ART INT, P775, DOI [10.1109/ACAIT53529.2021.9731304, DOI 10.1109/ACAIT53529.2021.9731304]
   Yekkala I, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P691, DOI 10.1109/SmartTechCon.2017.8358460
   Zhou Z.-H., 2012, ENSEMBLE METHODS FDN, DOI DOI 10.1201/B12207
NR 189
TC 0
Z9 0
U1 7
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17051-9
EA OCT 2023
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200009
DA 2024-07-18
ER

PT J
AU Milosavljevic, NS
   Ralevic, NM
AF Milosavljevic, Natasa S.
   Ralevic, Nebojsa M.
TI Fuzzy methaheuristic model for copy-move forgery detection on images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Metrics; Methaheuristic; Clustering; Forensic images
AB Many methods have been proposed to detect the originality of an image. One of the most commonly used method, the Copy - move forgery detection (CMFD), is considered here. The contribution of this paper is the application of the new fuzzy distances in clustering using metaheuristics. The family of the used fuzzy distances satisfies the axioms of the fuzzy metric. CMFD method, which includes Variable Neighborhood Search (VNS) and Bee Colony Optimization (BCO) metaheuristics, has been tested and compared with similar methods. The proposed method with the proposed new metric used in this research gave better results than the existing methods. The proposed fuzzy metrics in this paper as well as the problem of p-median clustering applied to the problem and compared with existing research in this field give better results.
C1 [Milosavljevic, Natasa S.] Univ Belgrade, Fac Agr, Dept Phys & Math, Nemanjina 11080, Belgrade, Serbia.
   [Ralevic, Nebojsa M.] Univ Novi Sad, Fac Tech Sci, Dept Gen Disciplines Technol, Novi Sad 21000, Serbia.
C3 University of Belgrade; University of Novi Sad
RP Milosavljevic, NS (corresponding author), Univ Belgrade, Fac Agr, Dept Phys & Math, Nemanjina 11080, Belgrade, Serbia.
EM natasam@agrif.bg.ac.rs; nralevic@uns.ac.rs
RI Milosavljević, Nataša/JSL-2307-2023
OI Milosavljević, Nataša/0000-0003-4056-089X
FU This work was supported by the Ministry of Education, Science and
   Technological Development of the Republic of Serbia, in the frame of
   Projects applied under No. TR 34014 and No. ON 174009. record number
   451-03-68/2020-14/200156 and No. III 44006 record nu [TR 34014,
   451-03-68/2020-14/200156, 451-03-68/2020-14/200116]; Ministry of
   Education, Science and Technological Development of the Republic of
   Serbia
FX This work was supported by the Ministry of Education, Science and
   Technological Development of the Republic of Serbia, in the frame of
   Projects applied under No. TR 34014 and No. ON 174009. record number
   451-03-68/2020-14/200156 and No. III 44006 record number
   451-03-68/2020-14/200116.
CR Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   George A, 1997, FUZZY SET SYST, V90, P365, DOI 10.1016/S0165-0114(96)00207-2
   Gregori V, 2011, FUZZY SET SYST, V170, P95, DOI 10.1016/j.fss.2010.10.019
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   KRAMOSIL I, 1975, KYBERNETIKA, V11, P336
   Kumar S, 2023, MULTIMED TOOLS APPL, V82, P1431, DOI 10.1007/s11042-022-12391-4
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Nedovic L, 2018, SOFT COMPUT, V22, P4723, DOI 10.1007/s00500-017-2657-9
   Paul S, 2023, Multimed Tools, VAppl, P1
   Pavlovic A, 2019, MULTIMED TOOLS APPL, V78, P20655, DOI 10.1007/s11042-019-7277-1
   Peralta D, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106421
   Ralevic NM, 2019, SOFT COMPUT, V23, P12049, DOI 10.1007/s00500-019-03762-5
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wu CM, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106468
   Xiaofeng Wang, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P304, DOI 10.1109/MINES.2011.98
NR 21
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
AR s11042-023-17053-7
DI 10.1007/s11042-023-17053-7
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200004
DA 2024-07-18
ER

PT J
AU Patel, B
   Sharaff, A
AF Patel, Bharati
   Sharaff, Aakanksha
TI A review on rice plant phenotyping traits estimation for disease and
   growth management using modern ML techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant phenotyping; Machine learning; Rice disease; Growth analysis;
   Performance measures
ID CONVOLUTIONAL NEURAL-NETWORKS; PRINCIPAL COMPONENT ANALYSIS;
   IMAGE-PROCESSING TECHNIQUES; AUTOMATED DETECTION; CLASSIFICATION;
   RECOGNITION; IDENTIFICATION; COLOR; DISCRIMINATION; PLANTHOPPERS
AB Over the past decades, rice crops have been crucially acknowledged as one of the most powerful energy streams for the production of resources. Plant phenotyping trait estimation includes the external feature evaluation of the plants for production growth. Phenotyping using machine learning techniques outperforms the other imaging techniques for the analysis of traits including leaf, seed, branch, panicle, flower root, shoot, etc. Rice plants, categorized by multiple traits such as growth analysis and disease management, are considered a contributing factor to the agricultural, economic, and communal losses in the upcoming development of the agricultural field. The last 15 years' diagnosis of plant disease in relation to image processing techniques has remained an area of interest among researchers. Several disease detections, identification, and quantification methods have been developed and applied to a wide variety of crops. This paper reviews the related research papers from the period between 2007 and 2023, with a focus on the development of the state of the art. The related studies are compared based on image segmentation, feature extraction, feature selection, and classification. This paper also outlines the current achievements, limitations, and suggestions for future research associated with the diagnosis of rice plant growth analysis and disease identification using machine learning techniques.
C1 [Patel, Bharati; Sharaff, Aakanksha] Natl Inst Technol, Raipur 492010, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Patel, B (corresponding author), Natl Inst Technol, Raipur 492010, India.
EM bpatel.phd2018.cs@nitrr.ac.in; asharaff.cs@nitrr.ac.in
RI Sharaff, Aakanksha/L-9995-2016
OI Sharaff, Aakanksha/0000-0001-5499-7289; Ph.D. Student, Bharati
   Patel/0000-0003-1878-2269
FU The authors would like to thank the National Institute of Technology,
   Raipur for providing a research facility and giving the lots of
   encouragement for the application based data analysis for the mankind.;
   National Institute of Technology, Raipur
FX The authors would like to thank the National Institute of Technology,
   Raipur for providing a research facility and giving the lots of
   encouragement for the application based data analysis for the mankind.
CR Aggarwal M, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13050936
   Aghayeghazvini H, 2009, INT FED INFO PROC, V295, P1019
   Ahad MT, 2023, ARTIF INTELL AGR, V9, P22, DOI 10.1016/j.aiia.2023.07.001
   AHMAD MUHAMMAD, 2021, Deep learning for hyperspectral image classification
   Ahmed I, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13136
   Akyol K, 2023, MULTIMED TOOLS APPL, V82, P19503, DOI 10.1007/s11042-022-14318-5
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Almanac R, 2013, Source book for one of the most important economic activities on earth, V4th
   [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   [Anonymous], 2013, Pattern Recogn Simul
   [Anonymous], 2014, Int. J. Comput. Appl., DOI DOI 10.5120/18973-0445
   Anthonys G, 2009, 2009 INTERNATIONAL CONFERENCE ON INDUSTRIAL AND INFORMATION SYSTEMS, P403, DOI 10.1109/ICIINFS.2009.5429828
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Asfarian A., 2014, Crop Protect., V61, P103, DOI [10.1016/j.cropro.2013.12.044, DOI 10.1016/J.CROPRO.2013.12.044]
   Asma BM, 2008, AFR J BIOTECHNOL, V7, P4269
   Athanikar G., 2016, International Journal of Computer Science and Mobile Computing, V5, P76
   Bai XB, 2017, COMPUT ELECTRON AGR, V136, P157, DOI 10.1016/j.compag.2017.03.004
   Bakar MA, 2018, J Telecommun,Electr Comput E(JTEC), V10, P1
   Barbedo JGA, 2016, BIOSYST ENG, V147, P104, DOI 10.1016/j.biosystemseng.2016.03.012
   Bashir S., 2012, IOSR J Electron Commun Eng, V2, P31, DOI [10.9790/2834-0263134, DOI 10.9790/2834-0263134]
   Bhakta I., 2018, P ANN CONV COMP SOC, P300, DOI DOI 10.1007/978-981-13-1343-1_27
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen L, 2019, LECT NOTES COMPUT SC, V11473, P263, DOI 10.1007/978-3-030-28061-1_26
   Chen LS, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113200
   Cheng Fang Cheng Fang, 2005, Rice Science, V12, P13
   Cruz AC, 2017, 2017 ASABE ANN INT M, P1, DOI DOI 10.13031/AIM.201700241
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Daniya T, 2023, J ENVIRON INFORM, V42, P25, DOI 10.3808/jei.202300492
   dela Torre DMG, 2021, GEO-SPAT INF SCI, V24, P580, DOI 10.1080/10095020.2021.1936656
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devi TG, 2019, CLUSTER COMPUT, V22, P13415, DOI 10.1007/s10586-018-1949-x
   Divyanth LG., 2023, Smart Agric Technol, V3, P100
   Donahue J, 2014, PR MACH LEARN RES, V32
   farmer, Image of Insect pest
   Ferreira AD, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104963
   Gajanan DE, 2018, IJSRST, V4, P2018
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   Goswami M, 2018, ADV INTELL SYST COMP, V709, P519, DOI 10.1007/978-981-10-8633-5_51
   Groth D, Rice Disease Identification Photo Link
   Hamuda E, 2017, COMPUT ELECTRON AGR, V133, P97, DOI 10.1016/j.compag.2016.11.021
   Huang SP, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105203
   Huang SP, 2015, COMPUT ELECTRON AGR, V118, P167, DOI 10.1016/j.compag.2015.08.031
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   IRRI, Rice science for a better world
   Islam T, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P62, DOI 10.1109/ICICCT.2018.8473322
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kawasaki Y, 2015, LECT NOTES COMPUT SC, V9475, P638, DOI 10.1007/978-3-319-27863-6_59
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Khoenkaw P, 2016, INT COMP SCI ENG C I, P1
   Kounalakis T, 2019, COMPUT ELECTRON AGR, V165, DOI [10.1016/j.compag.2019.104973, 10.1016/j.compag.201]
   Kulkarni AH., 2012, Inter J Modern Eng Res, V2, P3661
   Kurniawati NN, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P23, DOI 10.1109/ICEEI.2009.5254824
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Li-na Zhang, 2014, Advanced Materials Research, V905, P659, DOI 10.4028/www.scientific.net/AMR.905.659
   Liang WZ, 2018, COMPUT ELECTRON AGR, V150, P41, DOI 10.1016/j.compag.2018.03.021
   Liu ZY, 2010, J ZHEJIANG UNIV-SC B, V11, P71, DOI 10.1631/jzus.B0900193
   Lopes UK, 2017, COMPUT BIOL MED, V89, P135, DOI 10.1016/j.compbiomed.2017.08.001
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Lurstwut Benjamaporn, 2017, Agriculture and Natural Resources, V51, P383, DOI 10.1016/j.anres.2017.12.002
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Nagasubramanian K, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0479-8
   Nigam A, 2020, MATER TODAY-PROC, V33, P4856, DOI 10.1016/j.matpr.2020.08.397
   Nti IK, 2017, Int. J. Comput. Appl., V162, DOI 10.5120/ijca2017913260
   Orillo JW, 2014, 7 IEEE INT C HUM NAN, P1
   Papademetriou M.K., 2000, BRIDGING RICE YIELD
   Patil MA, 2023, LECT NOTE NETW SYST, V608, P481, DOI 10.1007/978-981-19-9225-4_36
   Phadikar Santanu, 2008, 2008 11th International Conference on Computer and Information Technology (ICCIT), P420, DOI 10.1109/ICCITECHN.2008.4803079
   Phadikar S., 2012, International Journal of Information and Electronics Engineering, V2, DOI DOI 10.7763/IJIEE.2012.V2.137
   Phadikar S, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN INFORMATION TECHNOLOGY (RAIT), P284, DOI 10.1109/RAIT.2016.7507917
   Phadikar S, 2013, COMPUT ELECTRON AGR, V90, P76, DOI 10.1016/j.compag.2012.11.001
   Pugoy RADL, 2011, PROC SPIE, V8009, DOI 10.1117/12.896494
   Pukkela P, 2018, L N COMPUT VIS BIOME, V26, P199, DOI 10.1007/978-3-319-65981-7_8
   Rahman SU, 2023, MULTIMED TOOLS APPL, V82, P9431, DOI 10.1007/s11042-022-13715-0
   Rauf HT, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105075
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rewar E., 2017, J Adv Res Dynam Control Syst, V9, P13, DOI 10.1186/2193-1801-2-660
   Rishi N., 2015, Int J Sci Eng Res (IJSER), V3, P114
   Sanyal P, 2007, 10 INT C INF TECHN I
   Sarangdhar AA, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 2, P449, DOI 10.1109/ICECA.2017.8212855
   Sengupta S, 2017, COMPUT ELECTRON AGR, V140, P443, DOI 10.1016/j.compag.2017.06.024
   Serre T, 2005, PROC CVPR IEEE, P994
   Sethy PK., 2017, Int J Comput Appl, V157, P24
   Sethy PK, 2018, Springer Briefs in Applied Sciences and Technology
   Sethy PK, 2020, PROCEDIA COMPUT SCI, V167, P516, DOI 10.1016/j.procs.2020.03.308
   Sethy PK, 2017, HELIX, V7, P1970
   Shah JP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ADVANCED COMPUTING (ICCTAC)
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Shi Y, 2017, COMPUT ELECTRON AGR, V141, P171, DOI 10.1016/j.compag.2017.07.019
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Sonal, 2023, Indian Phytopathology, V76, P803, DOI 10.1007/s42360-023-00660-7
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Stephen A, 2023, NEURAL COMPUT APPL, V35, P6737, DOI 10.1007/s00521-022-07793-2
   Sunil GL, 2022, 2022 IEEE REG 10 S T, P1
   Tamilselvi P, 2017, 2017 THIRD INTERNATIONAL CONFERENCE ON SCIENCE TECHNOLOGY ENGINEERING & MANAGEMENT (ICONSTEM), P106, DOI 10.1109/ICONSTEM.2017.8261265
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Tisen Huang, 2018, Information Processing in Agriculture, V5, P74, DOI 10.1016/j.inpa.2017.11.001
   Türkoglu M, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Valliammal N., 2012, INT J COMPUT SCI ISS, V9, P212
   Verma P, 2017, Rice productivity and food security in India. Centre for management in agriculture
   Vimal SR, 2019, ECOL INDIC, V105, P553, DOI 10.1016/j.ecolind.2018.05.014
   Wiatowski T, 2018, IEEE T INFORM THEORY, V64, P1845, DOI 10.1109/TIT.2017.2776228
   Xiao MH, 2018, COMPUT ELECTRON AGR, V154, P482, DOI 10.1016/j.compag.2018.08.028
   Yao Q, 2017, J INTEGR AGR, V16, P1547, DOI [10.1016/s2095-3119(16)61497-1, 10.1016/S2095-3119(16)61497-1]
   Yao Q, 2014, J INTEGR AGR, V13, P1736, DOI 10.1016/S2095-3119(14)60799-1
   Yao Q, 2009, 2009 INTERNATIONAL CONFERENCE ON ENGINEERING COMPUTATION, P79, DOI 10.1109/ICEC.2009.73
   Zeng NX, 2023, PLANTS-BASEL, V12, DOI 10.3390/plants12112225
   Zhang XJ, 2016, J COMPUT SCI TECH-CH, V31, P489, DOI 10.1007/s11390-016-1642-6
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhao W.S., 2012, RICE DIS INSECT PEST
   Zheng J, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14225712
   Zheng Shicha, 2007, Control & Measurement, P290
   Zhou ZY, 2013, MATH COMPUT MODEL, V58, P701, DOI 10.1016/j.mcm.2011.10.028
NR 118
TC 1
Z9 1
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17098-8
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100008
DA 2024-07-18
ER

PT J
AU Singh, AK
   Singh, N
   Gupta, I
AF Singh, Ashutosh Kumar
   Singh, Niharika
   Gupta, Ishu
TI Cloud-HPA: hierarchical privacy perseverance anatomy for data storage in
   cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimedia data; Cloud computing; Data privacy; Protection;
   Anonymization
ID BIG DATA; HEALTH; IDENTIFICATION; PROTECTION; ALGORITHM
AB Sharing the data in the cloud environment may generate some loopholes and backdoor entries for intruders. In concern to the attributes of storage records, generally vertical and horizontal partitioning is used that can acquire resilient privacy strength. The paper portrays privacy perseverance hierarchy-oriented collaborative architecture to store data over the cloud. To improve privacy and not let attackers break through, an algorithm has been designed, which keeps the sensitive and non-sensitive records isolated by applying different properties such as cryptography & Anonymization series. It includes generalization, l-diversity & t-closeness methods. An archetype model in the cloud environment has been implemented for identifying the validity of the proposed algorithm and optimization of architecture. For the evaluation, the unification level has been incorporated into the progressive algorithm that reduces the time and increases speed for the data restructuring which is used in privacy perseverance architecture. Further, the findings incorporate generalized statistical study to identify the behavior of the properties used and the complexity analysis of the work has been presented.
C1 [Singh, Ashutosh Kumar] Indian Inst Informat Technol, Dept Comp Sci & Engn, Bhopal, India.
   [Singh, Ashutosh Kumar] Natl Inst Technol, Dept Comp Applicat, Kurukshetra, India.
   [Singh, Niharika] Univ Helsinki, Dept Comp Sci, Helsinki, Finland.
   [Gupta, Ishu] Int Inst Informat Technol, Dept Comp Sci, Bangalore, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; University of Helsinki; International Institute
   of Information Technology Bangalore (IIIT Bangalore)
RP Gupta, I (corresponding author), Int Inst Informat Technol, Dept Comp Sci, Bangalore, Karnataka, India.
EM ashutosh@nitkkr.ac.in; niharika.singh@helsinki.fi; ishugupta23@gmail.com
RI Singh, Ashutosh Kumar/AEB-6158-2022
OI Singh, Ashutosh Kumar/0000-0003-1368-116X
FU This work was supported in part by the Science and Engineering Research
   Board (SERB) under the Department of Science and Technology (DST),
   Government of India, and in part by the National Institute of
   Technology, Kurukshetra, India.; Science and Engineering Research Board
   (SERB) under the Department of Science and Technology (DST), Government
   of India; National Institute of Technology, Kurukshetra, India
FX This work was supported in part by the Science and Engineering Research
   Board (SERB) under the Department of Science and Technology (DST),
   Government of India, and in part by the National Institute of
   Technology, Kurukshetra, India.
CR Aggarwal CC, 2008, ADV DATABASE SYST, V34, P11
   Ahson SA, 2011, CLOUD COMPUTING AND SOFTWARE SERVICES: THEORY AND TECHNIQUES, P1
   Anantwar RG., 2012, Int J Eng Sci Innovative Technol (IJESIT), V1, P39
   Bayardo RJ, 2005, PROC INT CONF DATA, P217
   Cern NH, 2015, Cloud computing joins hunt for origins of the universe
   Cheng SL, 2019, Multimed Tools Appl, P1
   Cloud Security Alliance, 2011, Technical report
   Deng TP, 2022, MULTIMED TOOLS APPL, V81, P3693, DOI 10.1007/s11042-021-11737-8
   Fatma E, 2013, Int J Comput Appl, V69
   Gupta I, 2023, IEEE SYST J, V17, P5130, DOI 10.1109/JSYST.2023.3272611
   Gupta I, 2022, IEEE ACCESS, V10, P71247, DOI 10.1109/ACCESS.2022.3188110
   Gupta I, 2021, IEEE SYST J, V15, P4248, DOI 10.1109/JSYST.2020.3035666
   Gupta I, 2019, J COMMUN SOFTW SYS, V15, P173, DOI 10.24138/jcomss.v15i2.617
   Gupta I, 2019, INFORM PROCESS LETT, V147, P69, DOI 10.1016/j.ipl.2019.03.005
   Gupta R, 2023, IEEE SYST J, V17, P2445, DOI 10.1109/JSYST.2022.3218894
   Hao Z., 2010, Technical report
   Hao Z, 2011, IEEE T KNOWL DATA EN, V23, P1432, DOI 10.1109/TKDE.2011.62
   Hu JK, 2010, COMPUT STAND INTER, V32, P274, DOI 10.1016/j.csi.2009.04.005
   Huang MY, 2016, PEER PEER NETW APPL, V9, P864, DOI 10.1007/s12083-015-0356-9
   Jin J, 2011, COMPUT SECUR, V30, P116, DOI 10.1016/j.cose.2010.09.001
   Kantarcioglu M, 2010, Technical Report
   Kumar N, 2016, PEER PEER NETW APPL, V9, P824, DOI 10.1007/s12083-015-0332-4
   Kushida CA, 2012, MED CARE, V50, pS82, DOI 10.1097/MLR.0b013e3182585355
   Li JQ, 2019, IEEE T IND INFORM, V15, P6500, DOI 10.1109/TII.2019.2931156
   Liu C, 2015, IEEE T COMPUT, V64, P2609, DOI 10.1109/TC.2014.2375190
   Liu C, 2015, FUTURE GENER COMP SY, V49, P58, DOI 10.1016/j.future.2014.08.007
   Liu ZC, 2018, J NETW COMPUT APPL, V108, P112, DOI 10.1016/j.jnca.2018.01.016
   Lloret J, 2016, PEER PEER NETW APPL, V9, P876, DOI 10.1007/s12083-015-0378-3
   Lv HZ, 2019, COMPUT SCI INF SYST, V16, P705, DOI 10.2298/CSIS180915023L
   Machanavajjhala A, 2007, ACM T KNOWL DISCOV D, V1, P1, DOI DOI 10.1145/1217299.1217302
   Morampudi MK, 2020, MULTIMED TOOLS APPL, V79, P19215, DOI 10.1007/s11042-020-08680-5
   Narayan S, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'10:), P47, DOI 10.1145/1866835.1866845
   Neubauer T, 2011, INT J MED INFORM, V80, P190, DOI 10.1016/j.ijmedinf.2010.10.016
   Quantin C, 2011, INT J MED INFORM, V80, pE6, DOI 10.1016/j.ijmedinf.2010.10.003
   Rahman SMM, 2016, PEER PEER NETW APPL, V9, P894, DOI 10.1007/s12083-015-0334-2
   Shi H, 2021, MULTIMED TOOLS APPL, V80, P24631, DOI 10.1007/s11042-021-10853-9
   Singh AK, 2020, MULTIMED TOOLS APPL, V79, P31165, DOI 10.1007/s11042-020-09470-9
   Singh Niharika, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P261, DOI 10.1007/s12652-022-03889-8
   Singh N, 2022, Advances in cyber security and intelligent analytics
   Singh N, 2019, PERTANIKA J SCI TECH, V27, P159
   Singh N, 2018, DATA SCI ENG, V3, P24, DOI 10.1007/s41019-017-0046-0
   Taneja H, 2015, PROCEDIA COMPUT SCI, V70, P448, DOI 10.1016/j.procs.2015.10.073
   Thilakanathan D, 2014, FUTURE GENER COMP SY, V35, P102, DOI 10.1016/j.future.2013.09.011
   Zhao XF, 2020, MULTIMED TOOLS APPL, V79, P16707, DOI 10.1007/s11042-019-08014-0
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16674-2
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300003
DA 2024-07-18
ER

PT J
AU Zhao, FS
   Liu, Q
   Ikenaga, T
AF Zhao, Fengshan
   Liu, Qin
   Ikenaga, Takeshi
TI Semi-supervised attention based merging network with hybrid dilated
   convolution module for few-shot HDR video reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Computational photography; High dynamic range (HDR) video
   reconstruction; Semi-supervised learning; Few-shot learning
ID DYNAMIC-RANGE; IMAGES
AB Deep learning based methods for high dynamic range (HDR) video reconstruction require collecting large-scale HDR video dataset with ground truth which is time-consuming. Recent training strategies under the few-shot learning paradigm, which aim to build an effective model upon only a few labeled samples, have shown success in image classification and image segmentation. In this paper, a semi-supervised learning based framework for few-shot HDR video reconstruction is proposed. An attention based merging network with the hybrid dilated convolution module is used to recover missing contents and remove artifacts. The hybrid dilated convolution module extracts additional features from ill-exposed regions and the attention module corrects them to suppress harmful information. In the semi-supervised framework, designed training losses for the supervised branch and the unsupervised branch are utilized to constrain the network during training under the few-shot scenario. Experimental results show that the proposed method trained with only 5 labeled samples and 45 unlabeled samples achieves a PSNR score of 41.664dB on synthetic evaluation dataset, compared with 35.201dB which is the best score among supervised methods trained in the same few-shot condition.
C1 [Zhao, Fengshan; Ikenaga, Takeshi] Waseda Univ, Grad Sch IPS, Kitakyushu, Japan.
   [Liu, Qin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Waseda University; Nanjing University
RP Zhao, FS (corresponding author), Waseda Univ, Grad Sch IPS, Kitakyushu, Japan.
EM fengshan.zhao@ruri.waseda.jp; qinliu@nju.edu.cn; ikenaga@waseda.jp
OI Zhao, Fengshan/0000-0003-3407-7666
FU This work was supported by KAKENHI(21K11816). [21K11816]; KAKENHI
FX This work was supported by KAKENHI(21K11816).
CR Anand M., 2021, P 12 IND C COMP VIS, P1
   Bogoni L, 2000, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2000.903475
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chen G, 2021, P IEEE CVF INT C COM, P2502
   Choi I, 2017, IEEE T IMAGE PROCESS, V26, P5353, DOI 10.1109/TIP.2017.2731211
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Froehlich J, 2014, PROC SPIE, V9023, DOI 10.1117/12.2040003
   Hajisharif S, 2015, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-015-0095-0
   Hasinoff SW, 2010, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2010.5540167
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu ZJ, 2021, PROC CVPR IEEE, P15094, DOI 10.1109/CVPR46437.2021.01485
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Jais IKM., 2019, KNOWL ENG DATA SCI, V2, P41, DOI [DOI 10.17977/UM018V2I12019P41-46, 10.17977/um018v2i12019p41-46]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jong-Chyi Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P645, DOI 10.1007/978-3-030-58571-6_38
   Kalantari NK, 2019, COMPUT GRAPH FORUM, V38, P193, DOI 10.1111/cgf.13630
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kalantari NK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508402
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Kronander J, 2014, SIGNAL PROCESS-IMAGE, V29, P203, DOI 10.1016/j.image.2013.08.018
   Lai WS, 2017, ADV NEUR IN, V30
   Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Li YL, 2017, IEEE T IMAGE PROCESS, V26, P1143, DOI 10.1109/TIP.2016.2642790
   Ling SS, 2020, INT CONF ACOUST SPEE, P6429, DOI [10.1109/ICASSP40776.2020.9053176, 10.1109/icassp40776.2020.9053176]
   Mangiat S, 2010, SPIE, V7798, P307
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   McGuire M, 2007, IEEE COMPUT GRAPH, V27, P32, DOI 10.1109/MCG.2007.45
   Munkhdalai T, 2018, PR MACH LEARN RES, V80
   Narwaria M, 2015, SIGNAL PROCESS-IMAGE, V35, P46, DOI 10.1016/j.image.2015.04.009
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   Niu YZ, 2021, IEEE T IMAGE PROCESS, V30, P3885, DOI 10.1109/TIP.2021.3064433
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Pece F., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P1, DOI 10.1109/CVMP.2010.8
   Pourreza-Shahri R, 2015, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2015.7350812
   Prabhakar KR, 2021, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR46437.2021.00484
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Ravi S, 2016, PROC INT C LEARN REP
   Serrano A, 2016, COMPUT GRAPH FORUM, V35, P153, DOI 10.1111/cgf.12819
   Seshadrinathan K, 2012, IEEE IMAGE PROC, P2785, DOI 10.1109/ICIP.2012.6467477
   Sousa S, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207225
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Yan QS, 2020, IEEE T IMAGE PROCESS, V29, P4308, DOI 10.1109/TIP.2020.2971346
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
NR 49
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16885-7
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300011
DA 2024-07-18
ER

PT J
AU Ahmed, K
   Gad, MA
   Aboutabl, AE
AF Ahmed, Kareem
   Gad, Mai A.
   Aboutabl, Amal Elsayed
TI Snake species classification using deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Salient Object Detection (SOD); Deep Learning; Snake species
   classification; VGG16; DenseNet121
AB Incorrect snake identification from the observable visual traits is a major reason of death resulting from snake bites. The classification of snake species has a significant role in determining the appropriate treatment without any delay, the delay may cause dangerous complications or lead to the death of the victim. The difficulty of classifying snakes by human lies in the variations of snake pattern based on geographic variation and age, the intraclass variance is high for specific classes and the interclass variance is low among others, and there may be two remarkably similar types in shape, with one being toxic and the other not. The limitation of the experts' number in the herpetology and their geographical distribution leads us to the importance of using deep learning in the snake species classification. A model to classify snake species accately is proposed in this study. It is divided into two main processes, detecting the salient object by applying Salient Object Detection (SOD) model based on VGG16 architecture is the first process, the presence of snakes in places with a complex background led to the necessity of separating the salient object, then the classification model is applied with use of image augmentations parameters which improved the results. Four CNN models were used in the classification process including VGG16, ResNet50, MobileNetV2, and DenseNet121. Different experiments on 5,10,16,20, 22, and 45 number of classes and different models were conducted, and the model achieved unprecedented results. The results indicated that the VGG16, DenseNet121, and MobileNetV2 have achieved superior results in the same order from highest to lowest accuracy. The best accuracy is achieved using VGG16 architecture with accuracy 97.09% when using 45 number of classes.
C1 [Ahmed, Kareem; Gad, Mai A.] Beni Suef Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Bani Suwayf, Egypt.
   [Aboutabl, Amal Elsayed] Helwan Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Helwan, Egypt.
C3 Egyptian Knowledge Bank (EKB); Beni Suef University; Egyptian Knowledge
   Bank (EKB); Helwan University
RP Ahmed, K (corresponding author), Beni Suef Univ, Fac Comp & Artificial Intelligence, Comp Sci Dept, Bani Suwayf, Egypt.
EM kareem_ahmed@hotmail.co.uk; maialaa@fcis.bsu.edu.eg;
   amal.aboutabl@fci.helwan.edu.eg
RI ahmed, kareem/AFE-8267-2022
OI ahmed, kareem/0000-0002-1252-8625
FU Science, Technology amp; Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & amp;
   Innovation Funding Authority (STDF) in cooperation with The Egyptian
   Knowledge Bank (EKB).
CR Abayaratne S., 2019, C 3 SLAAI INT C ART
   Abdurrazaq Isa Setiawan, 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P97, DOI 10.1109/ISRITI48646.2019.9034633
   Amir A, 2017, Advances in Intelligent Systems and Computing
   Chamidullin R., 2021, CLEF 2021 C LABS EV
   Dasanayaka C, 2022, 2022 IEEE PUN SECT I
   Desingu K., 2021, CLEF 2021 C LABS EV
   Dube SS., 2022, 2022 1 ZIMB C INF CO
   Durso AM, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.582110
   Ferariu L., 2020, 2020 INT S ELMAR ZAD
   Georgiou T, 2020, Int J Multimed Information Retrieval, V2020
   GPG, 2020, 2020 5 INT C COMM EL
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang G, 2018, ARXIV
   James A, 2017, PREPRINT
   James AP, 2014, Human-centric Comput Inform Sci
   Jiang B., 2019, 2019 IEEE 3 INF TECH
   Kalinathan L., 2021, C LABS EV FOR
   Kingma D. P., 2014, arXiv
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P2990, DOI 10.1109/TPAMI.2018.2873587
   Nwankpa C. E., 2021, 2nd InternationalConference on Computational Sciences and Technology
   Patel A, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10050806
   Picek L., 2022, CLEF 2022 C LABS EV
   Progga NI, 2021, COMM COM INF SC, V1435, P216, DOI 10.1007/978-3-030-82269-9_17
   Progga NI., 2021, Applied Intelligence and Informatics
   Rachapudi V, 2021, EVOL INTELL, V14, P1337, DOI 10.1007/s12065-020-00367-y
   Rajabizadeh MRM, 2021, Sci Rep
   Ralph R, 2019, BMJ-BRIT MED J, V364, DOI 10.1136/bmj.k5317
   Rao W-q, 2022, Gigascience
   Saini D, 2021, 2021 9 INT C REL INF
   Sandler M., 2018, arXiv
   Santhanam S., 2021, 2021 INT C COMP INT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sreedevi KL, 2022, ANNU IEEE IND CONF, DOI 10.1109/INDICON56171.2022.10039799
   Üreten K, 2020, CLIN RHEUMATOL, V39, P969, DOI 10.1007/s10067-019-04487-4
   Vasmatkar MM., 2020, IEEE BOMB SECT SIGN
   Wang Q., 2022, Annals Data Sci, V9
   Yang S., 2022, ARXIV
   Yang Z, 2021, 54 HAW INT C SYST SC
   Zhang, 2020, ARXIV
NR 39
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16773-0
EA SEP 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8ZG9
UT WOS:001073989600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kobat, MA
   Barua, PD
   Tuncer, T
   Dogan, S
   Kivrak, T
   Akin, Y
   Bairy, GM
   Tan, RS
   Acharya, UR
AF Kobat, Mehmet Ali
   Barua, Prabal Datta
   Tuncer, Turker
   Dogan, Sengul
   Kivrak, Tarik
   Akin, Yusuf
   Bairy, G. Muralidhar
   Tan, Ru-San
   Acharya, U. Rajendra
TI Automated stenosis classification on invasive coronary angiography using
   modified dual cross pattern with iterative feature selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Coronary artery detection; Residual exemplar model; Center symmetric
   dual cross pattern; Relief and iterative neighborhood component analysis
ID ARTERY-DISEASE; DIAGNOSIS
AB Coronary artery disease (CAD) is a global health concern; the need for early diagnosis cannot be overstated. Many machine learning techniques have been used electrocardiography (ECG) signal to detect CAD and they have used advanced signal processing methods. In this study, we present an automated novel approach for detecting coronary artery stenosis, by integrating the residual exemplar center symmetric dual cross pattern (ResExCSDCP), relief and iterative neighborhood component analysis (RFINCA) techniques. In this work, we collected three coronary angiography images datasets to show general classification ability of the proposed model and these images were gathered from right coronary artery (RCA), left anterior descending artery (LAD), and circumflex artery (CX). The features have been extracted from patches by deploying ResExCSDCP feature extractor. The most informative features have been selected deploying RFINCA and k-nearest neighbor (kNN) has been employed for classification. Our proposed ResExCSDCP and RFINCA-based model attained accuracies of 96.73% +/- 1.38, 97.24% +/- 1.12%, and 98.51% +/- 0.31% for the automatic detection of RCA, LAD, and CX coronary angiography images, respectively. The results demonstrate that our proposal has the potential to assist the cardiologists in making accurate diagnosis and improve the quality of cardiac health.
C1 [Kobat, Mehmet Ali; Kivrak, Tarik; Akin, Yusuf] Firat Univ, Firat Univ Hosp, Dept Cardiol, Elazig, Turkiye.
   [Barua, Prabal Datta] Univ Southern Queensland, Sch Business Informat Syst, Toowoomba, Australia.
   [Tuncer, Turker; Dogan, Sengul] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
   [Bairy, G. Muralidhar] Manipal Acad Higher Educ, Dept Biomed Engn, MIT, Manipal 576104, India.
   [Tan, Ru-San] Natl Heart Ctr Singapore, Dept Cardiol, Singapore, Singapore.
   [Tan, Ru-San] Duke NUS Med Sch, Singapore, Singapore.
   [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia.
C3 Firat University; University of Southern Queensland; Firat University;
   Manipal Academy of Higher Education (MAHE); National Heart Centre
   Singapore; National University of Singapore; University of Southern
   Queensland
RP Tuncer, T (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM mkobat@firat.edu.tr; Prabal.Barua@usq.edu.au; turkertuncer@firat.edu.tr;
   sdogan@firat.edu.tr; tarikkivrak@gmail.com; yusufkn@hotmail.com;
   muralidharbairy@gmail.com; tanrsnhc@gmail.com;
   Rajendra.Acharya@usq.edu.au
RI DOGAN, Sengul/W-4854-2018
OI DOGAN, Sengul/0000-0001-9677-5684
CR Aggarwal Ashwani Kumar, 2022, WSEAS Transactions on Signal Processing, P60, DOI 10.37394/232014.2022.18.8
   Aggarwal A.K., 2022, Int J Biol Biomed Eng, V16, P241, DOI DOI 10.46300/91011.2022.16.30
   Akbal E, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107559
   Setiawan NA, 2020, Arxiv, DOI arXiv:2007.02854
   Alizadehsani R, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12573
   Alizadehsani R, 2016, KNOWL-BASED SYST, V109, P187, DOI 10.1016/j.knosys.2016.07.004
   Alizadehsani R, 2013, COMPUT METH PROG BIO, V111, P52, DOI 10.1016/j.cmpb.2013.03.004
   Arabasadi Z, 2017, COMPUT METH PROG BIO, V141, P19, DOI 10.1016/j.cmpb.2017.01.004
   Ashwani Kumar Aggarwal P.J., 2022, Int J Biol Biomed, V7, P40
   Butun E, 2020, PHYS MEDICA, V70, P39, DOI 10.1016/j.ejmp.2020.01.007
   Danilov VV, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87174-2
   Dhyani S, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104160
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ghiasi MM, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105400
   Greulich S, 2012, J CARDIOVASC MAGN R, V14, DOI 10.1186/1532-429X-14-36
   Gruszczynska I, 2019, ADV MED SCI-POLAND, V64, P58, DOI 10.1016/j.advms.2018.08.003
   Han T, 2023, COMPUT BIOL MED, V153, DOI 10.1016/j.compbiomed.2023.106546
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jungiewicz M, 2023, EXPERT SYST APPL, V228, DOI 10.1016/j.eswa.2023.120234
   Kang D, 2015, J MED IMAGING, V2, DOI 10.1117/1.JMI.2.1.014003
   Kaur A, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115686
   Kaur A, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P142, DOI [10.1109/icct46177.2019.8969054, 10.1109/ICCT46177.2019.8969054]
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Khozeimeh F, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15374-5
   Knuuti J, 2020, EUR HEART J, V41, P407, DOI 10.1093/eurheartj/ehz425
   Koji Y, 2004, AM J CARDIOL, V94, P868, DOI 10.1016/j.amjcard.2004.06.020
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P7117, DOI 10.1007/s11042-022-13636-y
   Kumar A, 2015, PROCEDIA COMPUT SCI, V57, P1015, DOI 10.1016/j.procs.2015.07.512
   Nasarian E, 2020, PATTERN RECOGN LETT, V133, P33, DOI 10.1016/j.patrec.2020.02.010
   Neumann FJ, 2019, EUR HEART J, V40, P79, DOI 10.1093/eurheartj/ehy855
   Newman D., 1998, UCI REPOSITORY MACHI
   Philips, 2020, Philips medical systems, Nederland B.V. Veenpluis 4-6 5684 PC Best
   Qin C, 2015, NEUROCOMPUTING, V168, P609, DOI 10.1016/j.neucom.2015.05.064
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Suh YJ, 2020, EUR RADIOL, V30, P3684, DOI 10.1007/s00330-020-06707-x
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Togaçar M, 2021, MED BIOL ENG COMPUT, V59, P57, DOI 10.1007/s11517-020-02290-x
   Tuncer T, 2020, IEEE T INSTRUM MEAS, V69, P9441, DOI 10.1109/TIM.2020.3003395
   Tuncer T, 2020, IEEE ACCESS, V8, P84532, DOI 10.1109/ACCESS.2020.2992641
   Wan T, 2018, COMPUT METH PROG BIO, V157, P179, DOI 10.1016/j.cmpb.2018.01.002
   Wong ND, 2014, NAT REV CARDIOL, V11, P276, DOI 10.1038/nrcardio.2014.26
   Wu X, 2023, J MAGN RESON IMAGING, V58, P1521, DOI 10.1002/jmri.28653
   Xiao J, 2023, MEASUREMENT, V214, DOI 10.1016/j.measurement.2023.112764
   Zerwic JJ, 1997, HEART LUNG, V26, P92, DOI 10.1016/S0147-9563(97)90068-6
   Zreik M, 2019, IEEE T MED IMAGING, V38, P1588, DOI 10.1109/TMI.2018.2883807
NR 45
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16697-9
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200014
DA 2024-07-18
ER

PT J
AU Yaqoob, I
   Bajwa, IS
AF Yaqoob, Iqra
   Bajwa, Imran Sarwar
TI Performance evaluation of mobile stereonet for real time navigation in
   autonomous mobile robots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Stereo vision; Navigation; Mobile Stereonet; Disparity map; Transformer
ID VISION
AB This research focuses on the performance evaluation of mobile stereonet for real-time navigation in mobile robots. The use of mobile stereonet for depth estimation and path planning has become increasingly important in the field of robotics. The research is conducting by implementing the mobile stereonet algorithm for real time navigation on a Raspberry Pi 4 and integrating it with a stereo camera to capture live video frames. The objective of this research is to evaluate the effectiveness of mobile stereonet in navigating mobile robots in different real time environments. The study will include the development of a mobile stereonet-based depth estimation and path planning system and its evaluation through simulations and experiments. The performance of the system will be evaluated based on various metrics, such as accuracy, efficiency, and robustness. The results of this study will provide insights into the potential applications of mobile stereonet in the field of robotics and contribute to the development of better navigation system for mobile robots using stereo vision technology. Implemented real time map generation using mobile stereonet is available on Github.
C1 [Yaqoob, Iqra; Bajwa, Imran Sarwar] Islamia Univ Bahawalpur, Bahawalpur, Pakistan.
C3 Islamia University of Bahawalpur
RP Bajwa, IS (corresponding author), Islamia Univ Bahawalpur, Bahawalpur, Pakistan.
EM Iqra.yaqoob@gmail.com; Imransbajwa@gmail.com
CR Aoyk C., 2022, Bicik cyacix iopaiix exooi, V5, P11
   Bebeselea-Sterp E, 2017, INT J ADV COMPUT SC, V8, P359
   Fauadi M. H. F. M., 2018, PERIOD ENG NAT SCI, V6, P47, DOI [https://doi.org/10.21533/pen.v6i2.174, DOI 10.21533/PEN.V6I2.174]
   Gao R., 2021, Sensors, V21, P2825
   Hamzah Rostam Affendi, 2010, Proceedings Second International Conference on Computer Research and Development (ICCRD 2010), P733, DOI 10.1109/ICCRD.2010.167
   Huanshihong Deng, 2020, Proceedings of the 2020 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA), P174, DOI 10.1109/ICTA50426.2020.9332014
   Juan-RouH, 2020, 2020 27 SAINT PET IN, P1
   Konolige K, 2008, SPRINGER TRAC ADV RO, V39, P179
   Koschan A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P835, DOI 10.1109/ICPR.1996.546141
   Liu Y, 2021, IEEE Access, V9, P183968
   Luo S., 2022, Sensors, V22, P1078
   Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352
   O'Riordan A, 2018, I CONF SENS TECHNOL, P178, DOI 10.1109/ICSensT.2018.8603605
   Ramírez-Hernández LR, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881419896717
   Sanchez-Rodriguez JP, 2018, ROBOTICA, V36, P1225, DOI 10.1017/S0263574718000358
   Shamsafar F, 2022, IEEE WINT CONF APPL, P677, DOI 10.1109/WACV51458.2022.00075
   Tao TF, 2008, CONF CYBERN INTELL S, P215
   Wang Y, 2019, IEEE INT CONF ROBOT, P5893, DOI [10.1109/ICRA.2019.8794003, 10.1109/icra.2019.8794003]
   Xiang Y, 2020, IOP CONF SER-MAT SCI, V831, DOI 10.1088/1757-899X/831/1/012021
   Xie Y, 2022, P IEEE INT C MULT EX
   Yang H., 2020, Pattern Recogn Lett, V129, P214
   Zhang S., 2021, J Real-Time Image Proc, V18, P685
   Zhang X, 2021, P IEEE INT C COMP VI
NR 23
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16710-1
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA S8ZG9
UT WOS:001073989600002
DA 2024-07-18
ER

PT J
AU Ramzan, Z
   Asif, HMS
   Shahbaz, M
AF Ramzan, Zeeshan
   Asif, H. M. Shahzad
   Shahbaz, Muhammad
TI Multimodal crop cover identification using deep learning and remote
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop identification; Remote sensing; Crop cover classification;
   DenseNet; Meta-learning; Multimodality
ID LAND-COVER; CLASSIFICATION; IMAGERY
AB Remote sensing is increasingly being used in agriculture and smart farming. Crop cover identification is a major challenge that is useful in the identification of a particular crop at scale. Various studies are conducted to address this challenge using remote sensing and machine learning techniques, but there is still room for improvement in predictive performance. This study has addressed the problem by incorporating multiple modalities for classification modeling. The study has used high-resolution satellite images to perform classification using convolutional neural networks. Densenet201 provided the highest classification accuracy among five candidate architectures. NDVI is calculated from medium-resolution images to be used as a feature that is combined with weather records containing temperature, rainfall, and humidity. A classification ensemble is trained on these features to perform crop classification. Five classification models are trained to select the best classification model. The classification models are evaluated with a train/test split as the models are trained using 60% of the data whereas 20% data is used for validation and 20% for testing. A meta-learner is trained on classification probabilities of both of these classifiers and final class label is obtained. Among the four meta-learners, support vector machines provided best learning and yielded a classification accuracy of 98.83% and an f1-score of 98.78%. High classification performance of the proposed approach indicate that multimodality and meta-learners are useful choices to improve the predictive performance for crop cover identification and can be successfully used for this task.
C1 [Ramzan, Zeeshan; Asif, H. M. Shahzad] Univ Engn & Technol, Dept Comp Sci, New Campus, Lahore, Punjab, Pakistan.
   [Shahbaz, Muhammad] Univ Engn & Technol, Dept Comp Engn, Lahore, Punjab, Pakistan.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore
RP Ramzan, Z (corresponding author), Univ Engn & Technol, Dept Comp Sci, New Campus, Lahore, Punjab, Pakistan.
EM zramzan@uet.edu.pk; shehzad@uet.edu.pk; m.shahbaz@uet.edu.pk
OI Ramzan, Zeeshan/0000-0003-2643-4627
FU Higher Education Commission (HEC) Pakistan [NRPU 9201]
FX This work was funded by Higher Education Commission (HEC) Pakistan as
   National Research Program for Universities (NRPU) under research grant
   NRPU 9201.
CR Ahmad N, 2021, WIRELESS PERS COMMUN, V121, P1139, DOI 10.1007/s11277-021-09054-2
   Ahmed N., 2022, ARXIV
   Ahmed N, 2016, Science International, V28, DOI DOI 10.9790/0661-17134853
   Ahmed N, 2022, SOFT COMPUT, V26, P7601, DOI 10.1007/s00500-021-06662-9
   Ahmed Nisar, 2021, Journal of Agricultural Research (Lahore), V59, P295
   Ahmed N, 2019, 2019 13TH INTERNATIONAL CONFERENCE ON MATHEMATICS, ACTUARIAL SCIENCE, COMPUTER SCIENCE AND STATISTICS (MACS-13), DOI 10.1109/macs48846.2019.9024822
   Ahmed N, 2021, MULTIMED TOOLS APPL, V80, P15677, DOI 10.1007/s11042-020-10286-w
   Ahmed N, 2020, COMPUT INFORM, V39, P385, DOI 10.31577/cai_2020_3_385
   [Anonymous], 2014, ISPRS Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, DOI DOI 10.5194/ISPRSARCHIVES-XL-7-195-2014
   Beck PSA, 2006, REMOTE SENS ENVIRON, V100, P321, DOI 10.1016/j.rse.2005.10.021
   Bellón B, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060600
   Chamundeeswari G, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104626
   Dimov D, 2022, J APPL REMOTE SENS, V16, DOI 10.1117/1.JRS.16.024519
   Domingues T, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12091350
   Durrani AUR, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0275653
   Fathololoumi S, 2022, SCI TOTAL ENVIRON, V838, DOI 10.1016/j.scitotenv.2022.156520
   Gadiraju KK, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3234, DOI 10.1145/3394486.3403375
   Giovos R, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11050457
   Heupel K, 2018, PFG-J PHOTOGRAMM REM, V86, P53, DOI 10.1007/s41064-018-0050-7
   Ji SP, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010075
   Jonsson L, 2015, THESIS INES
   Karimi N, 2022, PADDY WATER ENVIRON, V20, P395, DOI 10.1007/s10333-022-00901-x
   Khanal S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223783
   Kordi F, 2022, REMOTE SENS APPL, V27, DOI 10.1016/j.rsase.2022.100812
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Li HP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202370
   Li XY, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14092045
   Mac Kirby, 2022, SUSTAIN SCI, V17, P2049, DOI 10.1007/s11625-022-01115-0
   Monsalve-Tellez JM, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12070955
   Maxwell AE, 2017, PHOTOGRAMM ENG REM S, V83, P737, DOI 10.14358/PERS.83.10.737
   Momm HG, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030449
   Peña-Barragán JM, 2011, REMOTE SENS ENVIRON, V115, P1301, DOI 10.1016/j.rse.2011.01.009
   Pettorelli N, 2013, NORMALIZED DIFFERENCE VEGETATION INDEX, P1, DOI 10.1093/acprof:osobl/9780199693160.001.0001
   Russwurm M, 2023, ISPRS J PHOTOGRAMM, V196, P445, DOI 10.1016/j.isprsjprs.2022.12.016
   Sakamoto T, 2005, REMOTE SENS ENVIRON, V96, P366, DOI 10.1016/j.rse.2005.03.008
   Saleem G, 2019, COMPUT ELECTRON AGR, V157, P270, DOI 10.1016/j.compag.2018.12.038
   Salimans T, 2016, ADV NEUR IN, V29
   Santos LA, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050974
   Siesto G, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13173378
   Sun CL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102401
   Victor B, 2022, ARXIV
   Viskovic L, 2019, INT CONF SOFTW, P88
   Wang LJ, 2022, CROP J, V10, P1435, DOI 10.1016/j.cj.2022.01.009
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Zhang C, 2022, AGR SYST, V201, DOI 10.1016/j.agsy.2022.103462
   Zhang HY, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105618
   Zhang L, 2022, IEEE T MULTIMEDIA, V24, P1830, DOI 10.1109/TMM.2021.3073267
   Zhou S, 2019, P 27 ACM INT C MULT
NR 49
TC 0
Z9 0
U1 15
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33141
EP 33159
DI 10.1007/s11042-023-17140-9
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001073965700007
DA 2024-07-18
ER

PT J
AU Du, KP
   Zhang, X
   Gao, C
   Zhu, R
   Nong, Q
   Yang, XY
   Yin, CL
AF Du, Kunpeng
   Zhang, Xuan
   Gao, Chen
   Zhu, Rui
   Nong, Qiong
   Yang, Xianyu
   Yin, Chunlin
TI GIMM: A graph convolutional network-based paraphrase identification
   model to detecting duplicate questions in QA communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paraphrase identification; Graph convolutional network; Graph-based
   interaction; Text matching
AB Paraphrase Identification (PI) is an important task in Natural Language Processing (NLP), which aims to detect whether two sentences expressed in various forms are semantically consistent. It can be used to solve the problem of duplicate detection in QA Communities (eg: Quora and Stack Overflow). There have many studies that applied Convolutional Neural Networks to capture rich matching information between sentence pairs layer by layer. However, only a limited number of studies have explored the more flexible Graph Convolutional Networks (GCNs) for this task. GCN operates directly on the graph, and learns the representation of the node according to the neighborhood information of nodes. Thus, the interactive information between two sentences can be effectively integrated based on the local graph structure. In this paper, a Graph-based Interaction Matching model (GIMM) for PI is proposed. GIMM takes each word as a node, the word co-occurrence relations between sentence pairs, and the phrase relations within a single sentence as the relations between nodes to build the interaction graph. Then, the GCN are applied to learn the richer word representations based on the local structure of the graph. Finally, the node representations are aligned by the Attention mechanism to obtain the matching vector, and the results of PI are obtained by the Fully Connected Layer. We conduct experiments to compare the performance of GIMM with the current baselines on the Quora and Stack Overflow datasets. Experimental results demonstrate that the proposed model achieves excellent performance on both of these datasets.
C1 [Du, Kunpeng; Zhang, Xuan; Gao, Chen; Zhu, Rui; Nong, Qiong; Yang, Xianyu] Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
   [Du, Kunpeng] Yiwu Ind & Commercial Coll, Sch Electromech & Informat Technol, Yiwu, Zhejiang, Peoples R China.
   [Zhang, Xuan; Zhu, Rui] Key Lab Software Engn Yunnan Prov, Kunming, Yunnan, Peoples R China.
   [Zhang, Xuan; Zhu, Rui] Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
   [Yin, Chunlin] Yunnan Power Grid Co Ltd, Elect Power Res Inst, Kunming, Yunnan, Peoples R China.
C3 Yunnan University; China Southern Power Grid
RP Zhang, X (corresponding author), Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.; Zhang, X (corresponding author), Key Lab Software Engn Yunnan Prov, Kunming, Yunnan, Peoples R China.; Zhang, X (corresponding author), Engn Res Ctr Cyberspace, Kunming, Yunnan, Peoples R China.
EM zhxuan@ynu.edu.cn
RI R, R/AAD-2816-2022
OI R, R/0000-0002-5445-963X
FU Science Foundation of Young and Middle-aged Academic and Technical
   Leaders of Yunnan [202205AC160040]; Science Foundation of Yunnan Jinzhi
   Expert Workstation [202205AF150006]; Major Project of Yunnan Natural
   Science Foundation [202302AE09002003]; Science and Technology Project of
   Yunnan Power Grid Co., Ltd. [YNKJXM20222254]; Postgraduate Research and
   Innovation Foundation of Yunnan University [2021Z112]; Science
   Foundation of "Knowledge-driven intelligent software engineering
   innovation team"
FX This work was supported by the Science Foundation of Young and
   Middle-aged Academic and Technical Leaders of Yunnan under Grant No.
   202205AC160040; Science Foundation of Yunnan Jinzhi Expert Workstation
   under Grant No. 202205AF150006; Major Project of Yunnan Natural Science
   Foundation under Grant No. 202302AE09002003; Science and Technology
   Project of Yunnan Power Grid Co., Ltd. under Grant No.YNKJXM20222254;
   the Postgraduate Research and Innovation Foundation of Yunnan University
   under Grant No. 2021Z112; Science Foundation of "Knowledge-driven
   intelligent software engineering innovation team".
CR Ahasanuzzaman M, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P402, DOI 10.1145/2901739.2901770
   Amiri SA, 2019, INT FED INFO PROC, DOI 10.23919/ifipnetworking.2019.8816833
   Arase Y, 2021, COMPUT SPEECH LANG, V66, DOI 10.1016/j.csl.2020.101164
   Callison-Burch C., 2006, P MAIN C HUM LANG TE, P17, DOI [10.3115/1220835.1220838, DOI 10.3115/1220835.1220838]
   Chang GH, 2023, NEURAL PROCESS LETT, V55, P4419, DOI 10.1007/s11063-022-11047-6
   Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Chen QD, 2021, NEURAL PROCESS LETT, V53, P3677, DOI 10.1007/s11063-021-10561-3
   Conneau A., 2017, P 2017 C EMPIRCAL ME, P670, DOI [DOI 10.18653/V1/D17-1070, 10.18653/v1/d17-1070]
   Das A, 2022, MULTIMED TOOLS APPL, V81, P589, DOI 10.1007/s11042-021-11228-w
   Feng MW, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P813, DOI 10.1109/ASRU.2015.7404872
   Gong Yichen, 2018, INT C LEARN REPR
   Henaff M, 2015, ARXIV
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoogeveen Doris, 2015, P 20 AUSTRALASIAN DO, P1
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Iyer S., 2017, First quora dataset release: Question pairs
   Kipf TN, 2017, INT C LEARN REPR
   Kong LL, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9757032
   Lai HY, 2020, MULTIMED TOOLS APPL, V79, P14609, DOI 10.1007/s11042-018-7063-5
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Ling W, 2015, Conference Proceedings-EMNLP 2015: Conference on Empirical Methods in Natural Language Processing, P1520
   Liu Y, 2021, P 2021 C EMP METH NA, P8892
   Lukashenko R., 2007, ACM International Conference Proceeding Series, P1, DOI DOI 10.1145/1330598.1330642
   Luo Y., 2020, P ACL 2020, P6408, DOI DOI 10.18653/V1/2020.ACLMAIN.571
   Minaee S, 2021, ACM Computing Surveys (CSUR), V54, P1, DOI DOI 10.1145/3439726
   Mohamed M, 2020, LANG RESOUR EVAL, V54, P457, DOI 10.1007/s10579-019-09466-4
   Mou LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P130
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   Nakov P, 2016, P 10 INT WORKSH SEM, P525, DOI [DOI 10.18653/V1/S16-1083, 10.18653/v1/]
   Nikolentzos G, 2020, AAAI CONF ARTIF INTE, V34, P8544
   Palivela Hemant, 2021, International Journal of Information Management Data Insights, V1
   Pang L, 2016, AAAI CONF ARTIF INTE, P2793
   Parikh AP., 2016, EMNLP
   Peng H, 2021, IEEE T KNOWL DATA EN, V33, P2505, DOI 10.1109/TKDE.2019.2959991
   Peng H, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1063, DOI 10.1145/3178876.3186005
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Qu M., 2020, PMLR, P7867
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Tekli J, 2018, DATA KNOWL ENG, V117, P133, DOI 10.1016/j.datak.2018.07.007
   Tekli J, 2016, IEEE T KNOWL DATA EN, V28, P1383, DOI 10.1109/TKDE.2016.2525768
   Viji D, 2022, MULTIMED TOOLS APPL, V81, P6131, DOI 10.1007/s11042-021-11771-6
   Wallis P, 1993, P 1 PAC ASS COMP LIN, P118
   Wang HY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P843
   Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499
   Wang Z., 2016, P COLING 2016 26 INT
   Wang ZG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144
   Wu Wenhao., 2021, P 59 ANN M ASS COMP, V1, P6052
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xiao H, 2020, NEURAL NETWORKS, V131, P172, DOI 10.1016/j.neunet.2020.07.024
   Xin Y, 2021, INT C PATT RECOG, P8892, DOI 10.1109/ICPR48806.2021.9413086
   Xu KD, 2019, IEEE T COMP PACK MAN, V9, P1103, DOI 10.1109/TCPMT.2018.2869077
   Yang RQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4699
   Yao L, 2019, AAAI CONF ARTIF INTE, P7370
   Yu CM, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102738
   Zhang YF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P334
   Zhang Y, 2015, J COMPUT SCI TECH-CH, V30, P981, DOI 10.1007/s11390-015-1576-4
NR 59
TC 1
Z9 1
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31251
EP 31278
DI 10.1007/s11042-023-16592-3
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066762000004
DA 2024-07-18
ER

PT J
AU Jayanthi, V
   Thenmalar, S
AF Jayanthi, V.
   Thenmalar, S.
TI Recognition of Tamil handwritten text from a digital writing pad using
   MWDCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten text; OCR; Deep learning; MWDCNN
AB Text recognition from the Tamil Digital handwritten alphabet is challenging for researchers. Recognition systems face numerous challenges, such as more bends, curves, and rings. More errors occur in recognition of Tamil words written in digital pen and pad due to angles and curves in the Tamil alphabet, which need to be accurately converted. This paper proposes a Multi-Resolution Wavelet Deep Convolution Network (MWDCNN) for Tamil handwritten text recognition from a digital writing pad. The MWDCNN enhances low-level and high-level character features for depth information from the images. The proposed algorithm is compared with traditional algorithms such as CDBN, CapsNet, DBN, CRNN, and CNN digital writing pad-based handwritten Tamil text recognition using the MWDCNN method has achieved an accuracy of 99.3%.
C1 [Jayanthi, V.; Thenmalar, S.] SRM Inst Sci & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Jayanthi, V (corresponding author), SRM Inst Sci & Technol, Sch Comp, Dept Networking & Commun, Kattankulathur, Tamil Nadu, India.
EM jv4352@srmist.edu.in
RI V, Jayanthi/JKI-0017-2023
OI V, Jayanthi/0000-0003-3036-6428
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Ali AAA, 2022, J KING SAUD UNIV-COM, V34, P3294, DOI 10.1016/j.jksuci.2021.01.012
   Aqab S, 2020, INT J ADV COMPUT SC, V11, P137
   Azimi H, 2022, ARXIV
   Chen Z, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107555
   Elleuch M, 2019, INT J MULTIMED DATA, V10, P26, DOI 10.4018/IJMDEM.2019100102
   Jayanthi V, 2023, INTELL AUTOM SOFT CO, V36, P3551, DOI 10.32604/iasc.2023.036599
   Jemni SK, 2022, NEURAL COMPUT APPL, V34, P2055, DOI 10.1007/s00521-021-06520-7
   Khémiri A, 2019, ARAB J SCI ENG, V44, P9301, DOI 10.1007/s13369-019-03939-y
   Lincy RB, 2021, MULTIMED TOOLS APPL, V80, P5917, DOI 10.1007/s11042-020-09771-z
   Lopez-Rodriguez P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12136707
   Moudgil A, 2023, INT J COGNITIVE COMP
   Neto AFD, 2022, PATTERN RECOGN LETT, V159, P232, DOI 10.1016/j.patrec.2022.04.009
   Nam NT, 2019, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING (ICMLSC 2019), P138, DOI 10.1145/3310986.3310998
   Ott F, 2023, ARXIV
   Shaffi N, 2021, IEEE ACCESS, V9, P101469, DOI 10.1109/ACCESS.2021.3096823
   Sharma Annapurna, 2021, Expert Systems with Applications, V164, DOI 10.1016/j.eswa.2020.114004
   ul Sehr Zia N, 2022, NEURAL COMPUT APPL, P1
   Vijay A., 2022, 2022 International Conference on Sustainable Computing and Data Communication Systems (ICSCDS), P214, DOI 10.1109/ICSCDS53736.2022.9760893
   Xiao S., 2020, SN COMPUT SCI, V1, P1, DOI DOI 10.1007/S42979-020-00133-Y
NR 20
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30261
EP 30276
DI 10.1007/s11042-023-16878-6
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000009
DA 2024-07-18
ER

PT J
AU Zhai, SL
   Wu, Y
   Liu, L
   Tang, J
AF Zhai, Sulan
   Wu, Yi
   Liu, Lei
   Tang, Jin
TI RGBT Tracking based on modality feature enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGBT tracking; Channel feature enhancement; Spatial feature enhancement;
   Re-sampling
ID NETWORK
AB Fusion tracking based on visible and thermal infrared images can boost tracking performance under adverse challenging conditions, such as low illumination and bad weather. Existing RGBT tracking methods mainly focus on estimating the reliability weights of two modalities to achieve effective multi-modal fusion. However, these algorithms fail to significantly enhance the discriminability of multimodal features, including channel-level and spatial-level discriminability, which limits their tracking performance. We propose a novel Modality Feature Enhancement Network for RGBT tracking. Specifically, we design a modality feature enhancement module, which is composed of the channel feature enhancement module and the spatial feature enhancement module. The channel feature enhancement module can adaptively adjust the importance of different channels, which helps to improve the channel discriminability of multimodal features. The spatial feature enhancement module is used to improve the spatial discriminability of multimodal features. By the collaboration of these two modules, our network can effectively tackle partial occlusion challenges. In addition, modality feature enhancement module is parameter-shared between different modalities to explore the advantages of modality-shared cues. To solve the problem of the tracking failure caused by sudden camera motion, we introduce the re-sampling strategy to improve the tracking robustness. Extensive experiments on three RGBT tracking benchmark datasets show that our method is superior to other advanced tracking algorithms.
C1 [Zhai, Sulan; Wu, Yi] Anhui Univ, Sch Math Sci, Hefei, Anhui, Peoples R China.
   [Zhai, Sulan; Wu, Yi; Liu, Lei; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei, Anhui, Peoples R China.
   [Liu, Lei; Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Hefei, Anhui, Peoples R China.
C3 Anhui University; Anhui University; Anhui University
RP Liu, L (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei, Anhui, Peoples R China.; Liu, L (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei, Anhui, Peoples R China.
EM 619103864@qq.com; 1732958100@qq.com; liulei970507@163.com;
   tangjin@ahu.edu.cn
FU Natural Science Research Project of Anhui Education Department
   [KJ2019A0005]; Open Project of School of Mathematical Sciences, Anhui
   University [KF2019A03]; National Natural Science Foundation of China
   [62076003]
FX This work is part supported by the Natural Science Research Project of
   Anhui Education Department (Grant No: KJ2019A0005), the Open Project of
   School of Mathematical Sciences, Anhui University (Grant No: KF2019A03),
   the National Natural Science Foundation of China (Grant No: 62076003)
CR Cai B, 2017, J GUANG XI NORMAL U
   Chenglong Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P222, DOI 10.1007/978-3-030-58542-6_14
   Feng MZ, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102881
   Gao Y, 2019, PROC IEEE INT C COMP
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He MJ, 2022, IEEE T IMAGE PROCESS, V31, P788, DOI 10.1109/TIP.2021.3132827
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29
   Laurense VA, 2017, P AMER CONTR CONF, P5586, DOI 10.23919/ACC.2017.7963824
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135
   Li CL, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.13202
   Li JP, 2018, COGN COMPUT, V10, P368, DOI 10.1007/s12559-017-9533-x
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lu AD., 2020, DUALITY GATED MUTUAL, DOI [10.1109/TNNLS.2022.3157594, DOI 10.1109/TNNLS.2022.3157594]
   Lu AD, 2021, IEEE T IMAGE PROCESS, V30, P5613, DOI 10.1109/TIP.2021.3087341
   Marriott RT, 2021, PROC CVPR IEEE, P13440, DOI 10.1109/CVPR46437.2021.01324
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tu ZZ, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2003.07650
   Wang CQ, 2020, PROC CVPR IEEE, P7062, DOI 10.1109/CVPR42600.2020.00709
   Wang K., 2018, COMPUT SYST APPL, V27, P149
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Y, 2022, IEEE T INTELL TRANSP, V23, P7831, DOI 10.1109/TITS.2021.3073046
   Xiao Y, 2022, AAAI CONF ARTIF INTE, P2831
   Zhai SL, 2019, NEUROCOMPUTING, V334, P172, DOI 10.1016/j.neucom.2019.01.022
   Zhang H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020393
   Zhang LC, 2019, PROC IEEE C COMPUT V
   Zhang P, 2022, IEEE T CYBERNETICS, V52, P12604, DOI 10.1109/TCYB.2021.3071746
   Zhang PY, 2021, IEEE T IMAGE PROCESS, V30, P3335, DOI 10.1109/TIP.2021.3060862
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
   Zhu YB, 2022, IEEE T CIRC SYST VID, V32, P579, DOI 10.1109/TCSVT.2021.3067997
   Zhu YB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P465, DOI 10.1145/3343031.3350928
   Zhu YH, 2020, IONICS, V26, P3307, DOI 10.1007/s11581-020-03485-w
NR 37
TC 1
Z9 1
U1 8
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29311
EP 29330
DI 10.1007/s11042-023-16418-2
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001063370800003
DA 2024-07-18
ER

PT J
AU Kotei, E
   Thirunavukarasu, R
AF Kotei, Evans
   Thirunavukarasu, Ramkumar
TI Visual attention condenser model for multiple disease detection from
   heterogeneous medical image modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention mechanism; Breast cancer; Deep learning; Medical image
   analysis; Tuberculosis; Visual attention condensers
AB The World Health Organization (WHO) has identified breast cancer and tuberculosis (TB) as major global health issues. While breast cancer is a top killer of women, TB is an infectious disease caused by a single bacterium with a high mortality rate. Since both TB and breast cancer are curable, early screening ensures treatment. Medical imaging modalities, such as chest X-ray radiography and ultrasound, are widely used for diagnosing TB and breast cancer. Artificial intelligence (AI) techniques are applied to supplement the screening process for effective and early treatment due to the global shortage of radiologists and oncologists. These techniques fast-track the screening process leading to early detection and treatment. Deep learning (DL) is the most used technique producing outstanding results. Despite the success of these DL models in the automatic detection of TB and breast cancer, the suggested models are task-specific, meaning they are disease-oriented. Again, the complexity and weight of the DL applications make it difficult to apply the models on edge devices. Motivated by this, a Multi Disease Visual Attention Condenser Network (MD-VACNet) got proposed for multiple disease identification from different medical image modalities. The network architecture got designed automatically through a machine-driven design exploration with generative synthesis. The proposed MD-VACNet is a lightweight stand-alone visual recognition deep neural network based on VAC with a self-attention mechanism to run on edge devices. In the experiment, TB was identified based on chest X-ray images and breast cancer was based on ultrasound images. The suggested model achieved a 98.99% accuracy score, a 99.85% sensitivity score, and a 98.20% specificity score on the x-ray radiographs for TB diagnosis. The model also produced a cutting-edge performance on breast cancer classification into benign and malignant, with accuracy, sensitivity and specificity scores of 98.47%, 98.42%, and 98.31%, respectively. Regarding model architectural complexity, MD-VACNet is simple and lightweight for edge device implementation.
C1 [Kotei, Evans; Thirunavukarasu, Ramkumar] Vellore Inst Technol, Sch Comp Sci Engn & Informat Syst, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Thirunavukarasu, R (corresponding author), Vellore Inst Technol, Sch Comp Sci Engn & Informat Syst, Vellore 632014, Tamil Nadu, India.
EM ramkumar.thirunavukarasu@vit.ac.in
OI KOTEI, Dr. EVANS/0000-0003-0181-5247
CR Akbar S., 2019, Int J Adv Res, V7, P689, DOI [10.21474/IJAR01/8872, DOI 10.21474/IJAR01/8872]
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Aljaddouh B, 2022, MATER TODAY-PROC, V62, P4651, DOI 10.1016/j.matpr.2022.03.120
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Ayaz M, 2021, PHYS ENG SCI MED, V44, P183, DOI 10.1007/s13246-020-00966-0
   Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Benhammou Y., 2018, proceedings of the international conference on learning and optimization algorithms: theory and applications, P1
   Bhaskaran KL, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040161
   Byra M, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102828
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Chen XM, 2021, RADIOTHER ONCOL, V160, P175, DOI 10.1016/j.radonc.2021.04.019
   Chouhan V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020559
   Dai Y, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081384
   Duong LT, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115519
   Duwairi R, 2023, EGYPT INFORM J, V24, P139, DOI 10.1016/j.eij.2023.01.002
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Guo RH, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.583427
   Heenaye-Mamode Khan M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256500
   Hooda R, 2017, IEEE I C SIGNAL IMAG, P497, DOI 10.1109/ICSIPA.2017.8120663
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang PW, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e13171
   Iqbal A, 2022, TUBERCULOSIS, V136, DOI 10.1016/j.tube.2022.102234
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Kaggle, 2018, RSNA Pneumonia detection challenge 2020
   Kaggle, 2020, Tuberculosis (TB) Chest X-ray Database
   Kotei E, 2023, INFORMATION, V14, DOI 10.3390/info14030187
   Kotei E, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10112335
   Kotei E, 2022, PROG BIOPHYS MOL BIO, V171, P4, DOI 10.1016/j.pbiomolbio.2022.03.004
   Lambert Z, 2020, INT CONF IMAG PROC
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu HX, 2022, INT J GEN MED, V15, P2271, DOI 10.2147/IJGM.S347491
   Momeny M, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105175
   Mukherjee P, 2022, Arxiv, DOI arXiv:2204.11449
   Puttagunta M.K., 2021, J PHYS C SER, V1767, DOI [10.1088/1742-6596/1767/1/012004, DOI 10.1088/1742-6596/1767/1/012004]
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Rajaraman S, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.864724
   Roslidar Roslidar, 2019, 2019 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom). Proceedings, P77, DOI 10.1109/CYBERNETICSCOM.2019.8875661
   Sahlol AT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071146
   Sahu A, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104292
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sawyer-Lee Rebecca, 2016, TCIA, V1
   Sheeba A, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104048
   Silva LF, 2014, J MED IMAG HEALTH IN, V4, P92, DOI 10.1166/jmihi.2014.1226
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Su YY, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106903
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Thirunavukarasu R, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106020
   Ul Abideen Z, 2020, IEEE ACCESS, V8, P22812, DOI 10.1109/ACCESS.2020.2970023
   Wang YM, 2022, AAAI CONF ARTIF INTE, P2567
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Wong ALXD, 2018, Arxiv, DOI [arXiv:1809.05989, DOI 10.48550/ARXIV.1809.05989]
   Wong ALXD, 2020, Arxiv, DOI arXiv:2009.14385
   Zahoor S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020557
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 55
TC 2
Z9 2
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30563
EP 30585
DI 10.1007/s11042-023-16625-x
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900008
DA 2024-07-18
ER

PT J
AU Tian, XX
   Zhang, MT
   Lu, GY
AF Tian, Xiuxia
   Zhang, Mengting
   Lu, Guanyu
TI Power line insulator defect detection using CNN with dense connectivity
   and efficient attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Insulator defect detection; Yolo algorithm; Attention mechanism; Data
   augmentation
AB Power line insulator defect detection is an extremely important technology to ensure the safety of power lines. In recent years, electric power enterprises often use UAVs to conduct safety inspections of power lines. This is a resource-limited terminal platform that cannot sustain the huge computational burden. In addition, insulator images taken by UAVs usually have complex background interference. All these require that the power line insulator defect detection algorithm must guarantee high detection accuracy while keeping the computational cost low. To this end, we designed a novel single-stage detection model that can be trained end-to-end based on Yolov3. Our improved model replaces the backbone network of Yolov3 with ResNet50 to reduce the number of model parameters. We changed the original connection structure in ResNet50 to a dense connection to improve the feature extraction capability of the backbone network. To overcome the complex background interference, we add an effective attention mechanism at the end of each layer of the backbone network to enable the model to focus effectively on the detected objects. We also use Mosaic and Random Erasing methods to enhance the dataset. Extensive experimental results show that the model achieves better prediction performance compared to other state-of-the-art methods.
C1 [Tian, Xiuxia; Zhang, Mengting; Lu, Guanyu] Shanghai Univ Elect Power, Sch Comp Sci & Technol, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Tian, XX (corresponding author), Shanghai Univ Elect Power, Sch Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM xxtian@shiep.edu.cn
OI Zhang, Mengting/0000-0001-7515-8150
FU National Natural Science Foundation of China [61772327]; State Grid
   Gansu Electric Power Company [H2019-275]; Shanghai Engineering Research
   Center on Big Data Management System [H2020-216]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61772327), State Grid Gansu Electric Power Company(No.
   H2019-275), and Shanghai Engineering Research Center on Big Data
   Management System (No.H2020-216).
CR Amin M., 2003, IEEE Security & Privacy, V1, P19, DOI 10.1109/MSECP.2003.1236231
   Cao Y, 2019, IEEE ICC
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   He HY, 2020, IEEE ACCESS, V8, P133882, DOI 10.1109/ACCESS.2020.3011170
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang WH, 2020, APPL INTELL, V50, P1908, DOI 10.1007/s10489-019-01605-2
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jin H, 2021, IEEE T SMART GRID, V12, P1821, DOI 10.1109/TSG.2020.3029444
   Kang GQ, 2019, IEEE T INSTRUM MEAS, V68, P2679, DOI 10.1109/TIM.2018.2868490
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Li H, 2020, APPL INTELL, V50, P1192, DOI 10.1007/s10489-019-01571-9
   Liao SL, 2015, IEEE GEOSCI REMOTE S, V12, P963, DOI 10.1109/LGRS.2014.2369525
   Liu CY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070771
   Ma YP, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020230
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Ohta H, 2019, INT CONF SYST THEO, P125, DOI [10.1109/ICSTCC.2019.8885695, 10.1109/icstcc.2019.8885695]
   Ouyang Y, 2020, APPL INTELL, V50, P3023, DOI 10.1007/s10489-020-01692-6
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao X, 2020, IEEE T SYST MAN CY-S, V50, P1486, DOI 10.1109/TSMC.2018.2871750
   Tian CJ, 2020, APPL INTELL, V50, P3057, DOI 10.1007/s10489-020-01698-0
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Zhang DQ, 2021, IEEE T RELIAB, V70, P887, DOI 10.1109/TR.2020.3001232
   Zhao Z, 2018, 2018 IEEE 4 INT C MU, P1
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 31
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28305
EP 28322
DI 10.1007/s11042-023-15522-7
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900010
DA 2024-07-18
ER

PT J
AU Wang, XL
   Qin, JW
AF Wang, Xiaole
   Qin, Jiwei
TI Multimodal recommendation algorithm based on Dempster-Shafer evidence
   theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation algorithm; Multimodal; Evidence theory; Fusion
ID FUSION
AB Multimodal features of items (e.g., text, audio, visual) have been proven to be effective in improving recommendations. Most of the existing personalized recommendation algorithms only use user-item interaction to recommend items for users, ignoring the rich auxiliary information implicit in the multimodal features of items. This auxiliary information can enrich the user's description of the item and enhance the mining ability of the recommendation algorithm. However, as a result of users having different preferences for each modality, the multimodal recommendation becomes a challenging task. Therefore, this paper proposes a multimodal recommendation algorithm based on the Dempster-Shafer evidence theory. First, we use the similarity measure of user history interaction items and non-interaction items in different modalities to characterize user preferences for noninteraction items. Second, we use the discrete degree of different modal features of user history interaction items to represent the degree of user preference for different modalities. Third, according to the Dempster-Shafer evidence theory, users' preferences for noninteractive items in different modalities are considered evidence. As a result, we fuse this evidence with different modal preferences to produce recommendations. Experimental results show that the proposed method is superior to the traditional personalized recommendation algorithm and the early multimodal fusion recommendation method. The proposed algorithm has good interpretability and expansibility.
C1 [Wang, Xiaole; Qin, Jiwei] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Wang, Xiaole; Qin, Jiwei] Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Qin, JW (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.; Qin, JW (corresponding author), Xinjiang Univ, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM wxlyjxbp@163.com; jwqin@xju.edu.cn
FU Science Fund for Outstanding Youth of Xinjiang Uygur Autonomous Region
   [2021D01E14]; National Science Foundation of China [61867006]; Major
   science and technology project of Xinjiang Uygur Autonomous Region
   [2020A03001]; Key Laboratory Open Project of Science and Technology
   Department of Xinjiang Uygur Autonomous Region named Research on video
   information intelligent processing technology for Xinjiang regional
   security
FX This work was supported by the Science Fund for Outstanding Youth of
   Xinjiang Uygur Autonomous Region under Grant No. 2021D01E14, the
   National Science Foundation of China under Grant No. 61867006, The Major
   science and technology project of Xinjiang Uygur Autonomous Region under
   Grant No. 2020A03001 , the Key Laboratory Open Project of Science and
   Technology Department of Xinjiang Uygur Autonomous Region named Research
   on video information intelligent processing technology for Xinjiang
   regional security.
CR Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Arora S, 2019, 5 INT C LEARN REPR I
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Cuzzocrea Alfredo, 2020, MEDES '20: Proceedings of the 12th International Conference on Management of Digital EcoSystems, P115, DOI 10.1145/3415958.3433051
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Dempster AP, 2008, STUD FUZZ SOFT COMP, V219, P57
   Denoeux T, 2019, KNOWL-BASED SYST, V176, P54, DOI 10.1016/j.knosys.2019.03.030
   Denoeux T, 2019, INT J APPROX REASON, V109, P87, DOI 10.1016/j.ijar.2019.03.009
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Huang Y., 2021, arXiv
   Jin J, 2021, IEEE T NEUR NET LEAR, V32, P4814, DOI 10.1109/TNNLS.2020.3015505
   Johnson C. C., 2014, Advances in Neural Infor-mation Processing Systems, V27, P1
   Konstan J., 2001, P 10 INT C WORLD WID, P285
   Li WM, 2019, IEEE ACCESS, V7, P45451, DOI 10.1109/ACCESS.2018.2885084
   Lika B, 2014, EXPERT SYST APPL, V41, P2065, DOI 10.1016/j.eswa.2013.09.005
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Pan R, 2008, IEEE DATA MINING, P502, DOI 10.1109/ICDM.2008.16
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Rendle S., 2012, ARXIV
   Sai Ambati L, 2020, INFLUENCE DIGITAL DI, DOI [10.48009/4_iis_2020_103-113, DOI 10.48009/4_IIS_2020_103-113]
   Shafer G., 1976, MATH THEORY EVIDENCE, DOI DOI 10.1515/9780691214696
   Singh R, 2006, IEICE ELECTRON EXPR, V3, P429, DOI 10.1587/elex.3.429
   Smets P, 2005, INT J APPROX REASON, V38, P133, DOI 10.1016/j.ijar.2004.05.003
   Su ZG, 2019, IEEE T FUZZY SYST, V27, P111, DOI 10.1109/TFUZZ.2018.2869125
   Tao Y, 2023, NEURAL COMPUT APPL, V35, P13077, DOI 10.1007/s00521-021-05723-2
   Tao ZL, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102277
   Tarus JK, 2018, ARTIF INTELL REV, V50, P21, DOI 10.1007/s10462-017-9539-5
   Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034
   Wu C., 2021, arXiv
   Yu X, 2019, PATTERN RECOGN, V94, P96, DOI 10.1016/j.patcog.2019.05.030
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zheng VW, 2010, AAAI CONF ARTIF INTE, P236
   Zhou T, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101630
NR 43
TC 1
Z9 1
U1 10
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28689
EP 28704
AR s11042-023-15262-8
DI 10.1007/s11042-023-15262-8
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900001
DA 2024-07-18
ER

PT J
AU Priya, B
   Malhotra, J
AF Priya, Bhanu
   Malhotra, Jyoteesh
TI iRSL: Intelligent RAT selection framework for beyond 5G networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE B5G; Double deep reinforcement learning; Matching game theory;
   Software-defined wireless networking; Edge computing
ID RESOURCE-ALLOCATION; USER ASSOCIATION; RADIO NETWORKS; ALGORITHM
AB Future networks are shifting towards more diversified and exemplary applications for societal benefits. To realise the functionalities of these advanced applications and services, Next-generation heterogeneous networks (HetNets) emerged as an exemplary connectivity solution, enabling each user device (UD) to associate with a radio access technology (RAT) in accordance with the demanded service. However, the design of an intelligent RAT association scheme for Beyond 5G (B5G) networks is becoming a crucial challenge due to the rapid growth of network heterogeneity in terms of RATs and personalised service requirements. Lately, considerable research endeavour has been noted in this direction but they are inadequate in maintaining Quality of Service (QoS) levels and RAT constraints simultaneously. Motivated by the gaps in the existing literature, an intelligent multi-connectivity approach has been proposed that facilitates agile differentiated service provisioning on the premise of ensuring the RAT capacity constraints. In particular, the proposed approach leverages the synergetic integration of matching game theory (MGT) and double deep reinforcement learning (DDRL) to attain a fine-grained UD-RAT association policy. Eventually, the proposed approach corroborated through the rigorous simulations demonstrated a substantial improvement in fairness, robustness and system satisfaction with the increase in network size.
C1 [Priya, Bhanu] Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara, India.
   [Malhotra, Jyoteesh] Natl Inst Technol, Dept Elect & Commun Engn, Delhi, India.
C3 Lovely Professional University; National Institute of Technology (NIT
   System); National Institute of Technology Delhi
RP Priya, B (corresponding author), Lovely Profess Univ, Sch Elect & Elect Engn, Phagwara, India.
EM bpriya812@gmail.com
RI Malhotra, Jyoteesh/AAN-9159-2020
OI Malhotra, Jyoteesh/0000-0002-7016-9982; Priya, Bhanu/0000-0002-6959-8958
FU University Grant Commission, New Delhi
FX Author would like to thank University Grant Commission, New Delhi for
   Junior Research Fellowship.
CR Alizadeh A, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013871
   Arabi S, 2019, IEEE NETWORK, V33, P116, DOI 10.1109/MNET.2019.1800513
   Arabi S, 2018, 2018 IEEE 4TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P332, DOI 10.1109/WF-IoT.2018.8355135
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bhattacharyya R, 2019, PROCEEDINGS OF THE 2019 THE TWENTIETH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '19), P251, DOI 10.1145/3323679.3326523
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Chkirbene Z, 2022, IEEE T NETW SCI ENG, V9, P258, DOI 10.1109/TNSE.2021.3058037
   Chowdhury S, 2019, ICT EXPRESS, V5, P12
   Desogus C, 2019, IEEE ACCESS, V7, P27720, DOI 10.1109/ACCESS.2019.2902190
   Ding H, 2020, AD HOC NETW, V102, DOI 10.1016/j.adhoc.2019.102069
   Faheem M, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108026
   Faheem M, 2021, J IND INF INTEGR, V24, DOI 10.1016/j.jii.2021.100236
   Faheem M, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106854
   Forecast G, 2019, CISCO VISUAL NETWORK
   Ghatak G, 2020, PHYS COMMUN-AMST, V43, DOI 10.1016/j.phycom.2020.101176
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Hössler T, 2020, IEEE T COMMUN, V68, P5228, DOI 10.1109/TCOMM.2020.2995150
   KHODAPANAH B, 2020, IEEE WIREL COMMUN, P1, DOI DOI 10.1109/WCNC45663.2020.9120498
   Kumar V, 2021, J INFORM TELECOMMUN, V5, P350, DOI 10.1080/24751839.2021.1871819
   Lee H, 2019, LECT NOTES I COMPUTE, P31, DOI [10.1007/978-3-030-25748-43, DOI 10.1007/978-3-030-25748-4_3]
   Ma MF, 2021, IEEE INTERNET THINGS, V8, P11877, DOI 10.1109/JIOT.2021.3073027
   Ma MF, 2020, IET COMMUN, V14, P320, DOI 10.1049/iet-com.2018.6290
   Malviya S., 2022, Trans. Asian Low-Resour. Lang. Inf. Process, DOI 10.1145/3539223
   Martínez R, 2004, MATH SOC SCI, V47, P187, DOI 10.1016/j.mathsocsci.2003.07.002
   Matlab, 2021, DEEP LEARN TOOLB DES
   Mollel MS, 2020, PHYS COMMUN-AMST, V42, DOI 10.1016/j.phycom.2020.101133
   Monteiro A, 2019, COMPUT COMMUN, V135, P1, DOI 10.1016/j.comcom.2018.11.006
   Namasudra S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108048
   Priya Bhanu, 2020, 2020 IEEE International Conference on Computing, Power and Communication Technologies (GUCON), P300, DOI 10.1109/GUCON48875.2020.9231264
   Priya B, 2023, J NETW SYST MANAG, V31, DOI 10.1007/s10922-023-09740-5
   Priya B, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03606-x
   Priya B, 2021, TELECOMMUN SYST, V76, P233, DOI 10.1007/s11235-020-00710-9
   Priya B, 2020, SOFT COMPUT, V24, P9507, DOI 10.1007/s00500-019-04460-y
   Roth AE, 2008, INT J GAME THEORY, V36, P537, DOI 10.1007/s00182-008-0117-6
   Sandoval RM, 2019, IEEE ACCESS, V7, P123341, DOI 10.1109/ACCESS.2019.2938084
   Sarkar S., 2015, SSRG INT J COMPUT SC, V2, P18, DOI DOI 10.14445/23488387/IJCSE-V2I8P104
   Shang FJ, 2020, NEURAL COMPUT APPL, V32, P2945, DOI 10.1007/s00521-018-3751-3
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Valiveti Hima Bindu, 2018, International Journal of Computer Aided Engineering and Technology, V10, P599
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang DL, 2019, IEEE ACCESS, V7, P62938, DOI 10.1109/ACCESS.2019.2916920
   Wang XW, 2019, IEEE ACCESS, V7, P21645, DOI 10.1109/ACCESS.2019.2898205
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Zhang QQ, 2020, IEEE T WIREL COMMUN, V19, P4535, DOI 10.1109/TWC.2020.2984758
   Zhao N, 2019, IEEE T WIREL COMMUN, V18, P5141, DOI 10.1109/TWC.2019.2933417
   Zhu AQ, 2019, IEEE INTERNET THINGS, V6, P6862, DOI 10.1109/JIOT.2019.2912155
NR 47
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28479
EP 28504
DI 10.1007/s11042-023-16668-0
EA SEP 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059652000007
DA 2024-07-18
ER

PT J
AU Rana, S
AF Rana, Shuvendu
TI 3D Video watermarking for MVD based view-synthesis and RST attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; Watermarking; Singular value decomposition (SVD); Multi-view
   video plus depth (MVD)
ID SEARCH ALGORITHM; MOTION; ROBUST
AB Security in terms of copyright measurement for digital media distribution is the most challenging task. To maintain the digital right in 3D media, a watermarking scheme is proposed for Multi-view Video plus Depth (MVD) representation to sustain against the view synthesis and RST attack. The Singular Value Decomposition (SVD) is carried out on the left and the right video sequences to find view-invariant coefficients for watermark insertion. Motion compensated Discrete Cosine Transform (DCT) based Temporal Filtering (MCDCT-TF) is used in the temporal direction to make the scheme robust against video compression attack. The 2D Discrete Wavelet Transform (2D-DWT ) is processed on the temporally filtered low-pass frames as a pre-processing to get to make the SVD coefficients more connected or say correlated in between the 3D view such that robustness can be achieved against RST and view synthesis with minimum visual degradation. A set of experiments is carried out with different 3D video sequences to justify the robustness of the proposed scheme over the RST attack.
C1 [Rana, Shuvendu] SRM Univ AP, Visual Informat Proc LAB, Dept CSE, Mangalagiri 522240, Andhra Prades, India.
C3 SRM University-AP
RP Rana, S (corresponding author), SRM Univ AP, Visual Informat Proc LAB, Dept CSE, Mangalagiri 522240, Andhra Prades, India.
EM shuvendu@ieee.org
OI Rana, Shuvendu/0000-0002-8372-5669
FU Ms Usha Kumari, PhD Scholar of SRM University AP, has given substantial
   input to improve the revised version of the manuscript. Her contribution
   towards the technical writing of this paper is commendable.
FX Ms Usha Kumari, PhD Scholar of SRM University AP, has given substantial
   input to improve the revised version of the manuscript. Her contribution
   towards the technical writing of this paper is commendable.
CR Anderson R, 2005, LECT NOTES COMPUT SC, V3656, P490, DOI 10.1007/11559573_61
   Atta R, 2006, IEEE T CIRC SYST VID, V16, P43, DOI 10.1109/TCSVT.2005.858743
   BENTLEY PM, 1994, ELECTRON COMMUN ENG, V6, P175, DOI 10.1049/ecej:19940401
   Bosse S, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P129, DOI 10.1109/PCS.2012.6213303
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Chen L, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115935
   Chen Y, 2015, TEST MODEL 11 3D HEV
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Egiazarian K., 2006, Proceedings of the second international workshop on video processing and quality metrics, P1
   Etoom W, 2022, MULTIMED TOOLS APPL, V81, P28165, DOI 10.1007/s11042-022-12553-4
   Fan SL, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P549, DOI 10.1109/CIS.2012.129
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Flierl M, 2004, SIGNAL PROCESS-IMAGE, V19, P561, DOI 10.1016/j.image.2004.05.002
   Franco-Contreras J., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2761, DOI 10.1109/ICIP.2011.6116242
   Gaj S, 2015, P 5 IEEE C COMP VIS, P1, DOI [10.1109/NCVPRIPG.2015.7490066, DOI 10.1109/NCVPRIPG.2015.7490066]
   Garcia E, 2003, IEEE T CIRC SYST VID, V13, P853, DOI 10.1109/TCSVT.2003.815963
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holmes M., 2007, WORKSH EFF MACH LEAR, V58, P249
   Hui Cao, 2021, 2021 10th Mediterranean Conference on Embedded Computing (MECO), DOI 10.1109/MECO52532.2021.9460222
   Jain Vinod, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1122, DOI 10.1109/ICAIS50930.2021.9396045
   Jaipuria Smita Jagdishprasad, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P181, DOI 10.1109/ICCSP.2014.6949824
   Jridi M., LOW COMPLEXITY DCT E, DOI [10.1117/12.2006174, DOI 10.1117/12.2006174]
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Koley S, 2022, MULTIMED TOOLS APPL, V81, P19491, DOI 10.1007/s11042-021-11861-5
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu XY, 2021, INFORM SCIENCES, V542, P263, DOI 10.1016/j.ins.2020.06.066
   Luo YF, 2021, MULTIMED TOOLS APPL, V80, P14915, DOI 10.1007/s11042-020-10375-w
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Rana S, 2014, P 9 INDIAN C COMPUTE, DOI [10.1145/2683483.2683535, DOI 10.1145/2683483.2683535]
   Rana S, 2022, IETE J RES, V68, P947, DOI 10.1080/03772063.2019.1628667
   Rana S, 2015, EUR SIGNAL PR CONF, P46, DOI 10.1109/EUSIPCO.2015.7362342
   Rana S, 2015, MULTIMED TOOLS APPL, V74, P7773, DOI 10.1007/s11042-014-2023-1
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P101, DOI 10.1109/PCS.2012.6213296
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Verdicchio F, 2004, IEEE IMAGE PROC, P2845
   Vinod P., 2006, IEE Proceedings-Information Security, V153, P61, DOI 10.1049/ip-ifs:20055088
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu-Cheng Fan, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P325
   Zahariadis T, 1996, EUR SIGN PROC C 1996, P1
NR 45
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26775
EP 26795
DI 10.1007/s11042-023-16481-9
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058250800001
DA 2024-07-18
ER

PT J
AU Bhowmik, S
AF Bhowmik, Showmik
TI Utilization of relative context for text non-text region classification
   in offline documents using multi-scale dilated convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text non-text separation; Dilated convolution; CNN; Classification;
   Offline document; Multi scale dilation; AUTNT; OCR
AB Identification of text and non-text regions in a document image is necessary before feeding it to an Optical character recognition (OCR) engine for the generation of editable version. This is because OCR engines only process text regions. Presence of non-text may constrain their performance. This makes text non-text region classification a necessary step. So far, texture based feature descriptors are widely considered for document region classification. These descriptors mostly consider the local patterns to estimate the region texture. Even the convention neural networks (CNN) also emphasise on the local connectivity. However, for better characterization of the region texture it is necessary to capture the relative context too. To address this issue, in this paper, a multi-scale dilated convolution neural network is designed to classify the document regions as text or non-text. This network can effectively capture the local patterns as well as the relative context at different scale. The proposed method is evaluated on a publicly available dataset AUTNT (Khan and Mollah, Multimed Tools Appl 78(22):32159-32186) where it outperforms the benchmark result by 1.63% by obtaining 97.91% accuracy. The proposed method also outperforms some state-of-the-art methods while evaluated on the said dataset. Additionally, the performance of the proposed network is evaluated using two standard datasets MNIST and Fashion-MNIST to observe its applicability in multi-class problem. The network obtains 99.31% accuracy in MINST dataset and 90.68% accuracy in Fashion-MNIST dataset.
C1 [Bhowmik, Showmik] Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda, India.
RP Bhowmik, S (corresponding author), Ghani Khan Choudhury Inst Engn & Technol, Dept Comp Sci & Engn, Malda, India.
EM showmik.cse@gmail.com
OI Bhowmik, Showmik/0000-0003-3971-5807
CR Bhowmik S, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P36, DOI [10.1109/aspcon49795.2020.9276688, 10.1109/ASPCON49795.2020.9276688]
   Bhowmik S, 2021, MULTIMED TOOLS APPL, V80, P8471, DOI 10.1007/s11042-020-09832-3
   Bhowmik S, 2018, INT J DOC ANAL RECOG, V21, P1, DOI 10.1007/s10032-018-0296-z
   Bhowmik S, 2017, ADV INTELL SYST, V458, P507, DOI 10.1007/978-981-10-2035-3_52
   Bhowmik S, 2021, 2020 3RD INTERNATIONAL CONFERENCE ON ENERGY, POWER AND ENVIRONMENT: TOWARDS CLEAN ENERGY TECHNOLOGIES (ICEPE 2020), DOI 10.1109/ICEPE50861.2021.9404481
   Borges Oliveira Dario Augusto, 2017, 2017 IEEE International Conference on Computer Vision Workshops (ICCVW), P1173, DOI 10.1109/ICCVW.2017.142
   Ghosh M, 2021, MULTIMED TOOLS APPL, V80, P3229, DOI 10.1007/s11042-020-09844-z
   Ghosh S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4040057
   Kar MK., 2021, SN Computer Sci, V2, P397, DOI DOI 10.1007/S42979-021-00784-5
   Khan T, 2020, PROCEDIA COMPUT SCI, V167, P1889, DOI 10.1016/j.procs.2020.03.208
   Khan T, 2019, MULTIMED TOOLS APPL, V78, P32159, DOI 10.1007/s11042-019-08028-8
   Kosaraju Sai Chandra, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1029, DOI 10.1109/ICDAR.2019.00168
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei XY, 2019, IEEE ACCESS, V7, P124087, DOI 10.1109/ACCESS.2019.2927169
   Li Deng, 2012, IEEE Signal Processing Magazine, V29, P141, DOI [10.1109/MSP.2012.2211477, DOI 10.1109/MSP.2012.2211477]
   Mondal R, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038277
   Oyedotun OK, 2016, APPL INTELL, V45, P198, DOI 10.1007/s10489-015-0753-z
   Perepu PK, 2021, NEUROCOMPUTING, V431, P1, DOI 10.1016/j.neucom.2020.12.054
   Prajna Y, 2022, J INTELL FUZZY SYST, P1, DOI DOI 10.3233/JIFS-211479
   Richter ML, 2021, LECT NOTES COMPUT SC, V12892, P133, DOI 10.1007/978-3-030-86340-1_11
   Safonov IV, 2019, DOCUMENT IMAGE PROCE, P107, DOI DOI 10.1007/978-3-030-05342-0_5
   Sah AK, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P64, DOI 10.1109/CALCON.2017.8280697
   Venugopal V, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105852
   Xiao Han, 2017, ARXIV, DOI [10.48550/arXiv. 1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yu F., 2016, 4 INT C LEARN REPR I, DOI [10.48550/arXiv.1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhao XH, 2021, J OCEAN U CHINA, V20, P1089, DOI 10.1007/s11802-021-4668-5
   Zhong ZY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106986
NR 29
TC 1
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26751
EP 26774
DI 10.1007/s11042-023-16546-9
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600006
DA 2024-07-18
ER

PT J
AU Yang, JW
   Chen, SH
   Wang, GJ
   Wang, ZJ
   Jie, ZY
   Arif, M
AF Yang, Jiawei
   Chen, Shuhong
   Wang, Guojun
   Wang, Zijia
   Jie, Zhiyong
   Arif, Muhammad
TI GFL-ALDPA: a gradient compression federated learning framework based on
   adaptive local differential privacy budget allocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Federated learning; Differential privacy; Privacy-preserving; Gradient
   compression; Privacy budget allocation
AB Federated learning(FL) is a popular distributed machine learning framework which can protect users' private data from being exposed to adversaries. However, related work shows that sensitive private information can still be compromised by analyzing parameters uploaded by clients. Applying differential privacy to federated learning has been a popular privacy-preserving way to achieve strict privacy guarantees in recent years. To reduce the impact of noise, this paper proposes to apply local differential privacy(LDP) to federated learning. We propose a gradient compression federated learning framework based on adaptive local differential privacy budget allocation(GFL-ALDPA). We propose a novel adaptive privacy budget allocation scheme based on communication rounds to reduce the loss of privacy budget and the amount of model noise. It can maximize the limited privacy budget and improve the model accuracy by assigning different privacy budgets to different communication rounds during training. Furthermore, we also propose a gradient compression mechanism based on dimension reduction, which can reduce the communication cost, overall noise size, and loss of the total privacy budget of the model simultaneously to ensure accuracy under a specific privacy-preserving guarantee. Finally, this paper presents the experimental evaluation on the MINIST dataset. Theoretical analysis and experiments demonstrate that our framework can achieve a better trade-off between privacy preservation, communication efficiency, and model accuracy.
C1 [Yang, Jiawei; Chen, Shuhong; Wang, Guojun; Wang, Zijia; Jie, Zhiyong] Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Arif, Muhammad] Super Univ, Dept Comp Sci, Lahore 54000, Pakistan.
C3 Guangzhou University
RP Chen, SH (corresponding author), Guangzhou Univ, Sch Comp Sci & Cyber Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM 2112006243@e.gzhu.edu.cn; shuhongchen@gzhu.edu.cn; csgjwang@gzhu.edu.cn;
   zijiawang@gzhu.edu.cn; 2112006120@e.gzhu.edu.cn; md.arif@superior.edu.pk
RI Wang, Zijia/AGK-7144-2022; Yang, Jiawei/GXM-3958-2022
OI Chen, Shuhong/0000-0002-6120-6358
FU Guangdong Provincial Natural Science Foundation [2022A1515011386,
   2022A1515011825]; National Key Research and Development Program of China
   [2020YFB1005804]; National Natural Science Foundation of China
   [61632009, 62106055]
FX This work was supported in part by the Guangdong Provincial Natural
   Science Foundation under Grant No. 2022A1515011386 and 2022A1515011825,
   the National Key Research and Development Program of China under Grant
   2020YFB1005804, the National Natural Science Foundation of China under
   Grant 61632009 and 62106055.
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Aono Y, 2016, CODASPY'16: PROCEEDINGS OF THE SIXTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P142, DOI 10.1145/2857705.2857731
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   Das S, 2023, IEEE T IND INFORM, V19, P821, DOI 10.1109/TII.2022.3167842
   Ding Bolin, 2017, ADV NEURAL INFORM PR, P3571
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Geiping J, ADV NEURAL INFORM PR, P16937
   Geyer RC, 2017, ARXIV
   Gupta A, 2022, AUTOMAT SOFTW ENG, V29, DOI 10.1007/s10515-022-00332-2
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Hao M, 2020, IEEE T IND INFORM, V16, P6532, DOI 10.1109/TII.2019.2945367
   Hard A., 2018, ARXIV
   Huang XX, 2020, WORLD WIDE WEB, V23, P2529, DOI 10.1007/s11280-020-00780-4
   Lee S, 2022, IEEE T IND INFORM, V18, P488, DOI 10.1109/TII.2020.3035451
   Li JC, 2022, IEEE T IND INFORM, V18, P2021, DOI 10.1109/TII.2021.3098010
   Liu RX, 2020, LECT NOTES COMPUT SC, V12112, P485, DOI 10.1007/978-3-030-59410-7_33
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Melis L, 2019, P IEEE S SECUR PRIV, P691, DOI 10.1109/SP.2019.00029
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Saputra YM, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013587
   Sarkar S., 2015, SSRG INT J COMPUT SC, V2, P18, DOI DOI 10.14445/23488387/IJCSE-V2I8P104
   Sharma P, 2019, ARXIV
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Su Z, 2022, IEEE T IND INFORM, V18, P1333, DOI 10.1109/TII.2021.3095506
   Sun DF, 2022, IEEE T IND INFORM, V18, P1165, DOI 10.1109/TII.2021.3077865
   Sun Lichao, 2021, P 30 INT JOINT C ART, P1571
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Venkataramani S, 2016, ASIA S PACIF DES AUT, P308, DOI 10.1109/ASPDAC.2016.7428029
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/infocom.2019.8737416, 10.1109/INFOCOM.2019.8737416]
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Wei K, 2020, IEEE T INF FOREN SEC, V15, P3454, DOI 10.1109/TIFS.2020.2988575
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yuan JW, 2014, IEEE T PARALL DISTR, V25, P212, DOI 10.1109/TPDS.2013.18
   Zhang YL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P19, DOI [10.1145/3132747.3132768, 10.1109/SP.2017.12]
   Zhao LC, 2020, IEEE T INF FOREN SEC, V15, P1486, DOI 10.1109/TIFS.2019.2939713
   Zhu LG, 2019, ADV NEUR IN, V32
NR 38
TC 1
Z9 1
U1 12
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26349
EP 26368
DI 10.1007/s11042-023-16543-y
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900004
DA 2024-07-18
ER

PT J
AU Tataji, KNK
   Kartheek, MN
   Prasad, MVNK
AF Kumar Tataji, Kadimi Naveen
   Kartheek, Mukku Nisanth
   Prasad, Munaga V. N. K.
TI CC-CNN: A cross connected convolutional neural network using feature
   level fusion for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyclopentane; Facial expression recognition; Feature descriptor; Feature
   level fusion; Convolutional neural network etc.
ID PATTERN; ATTENTION; FACE
AB Facial expressions are an important form of non-verbal communication as they directly reflect the internal emotions of a person. The primary task of automated Facial Expression Recognition (FER) systems lies in extracting salient features related to facial expressions. In this paper, a Cross Connected Convolutional Neural Network (CC-CNN) has been proposed for extracting the facial features. The proposed CC-CNN model contains two levels of input for extracting the features related to facial expressions. Cyclopentane Feature Descriptor (CyFD), inspired by cyclopentane's structure, has been proposed to extract significant features. The feature response map generated by the CyFD method has been given as input to the first level, and in the second level, the features have been extracted directly from the facial image. The input images from both levels are passed through a series of convolutional layers with cross connections for extracting the fused (local and global) features related to facial expressions. Finally, towards the end, the CC-CNN method works by fusing all the features extracted from both levels. To validate the efficiency of the proposed CC-CNN method, the experiments have been performed on benchmark FER datasets such as CK+, MUG, RAF, FER2013 and FERG. The comparison results from the experimental analysis revealed that the proposed model outperformed the recent FER methods.
C1 [Kumar Tataji, Kadimi Naveen] Univ Hyderabad, Sch Comp & Informat Sci, Hyderabad 500046, Telangana, India.
   [Kartheek, Mukku Nisanth] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Prasad, Munaga V. N. K.] Inst Dev & Res Banking Technol, Hyderabad 500057, Telangana, India.
C3 University of Hyderabad; Vellore Institute of Technology (VIT); VIT
   Vellore
RP Kartheek, MN (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM kadimi.naveenkumar@gmail.com; nisanthkartheek@gmail.com;
   mvnkprasad@idrbt.ac.in
OI Mukku, Nisanth Kartheek/0000-0001-5502-4884
CR Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Allaert B, 2019, IEEE T AFFECT COMPUT
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   [Anonymous], 2019, INT CONF ASIC, DOI [DOI 10.1109/asicon47005.2019.8983577, 10.1109/ASICON47005.2019.8983577]
   Barua PD, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104841
   Bisogni C, 2022, IEEE T IND INFORM
   Cai J, 2018, ARXIV
   Cotter S. F., 2020, IEEE ICCE, DOI DOI 10.1109/icce46568.2020.9042973
   Dauda A, 2014, INT J SCI ENG RES, V5
   Doulamis N, 2018, MULTIMED TOOLS APPL, V77, P9651, DOI 10.1007/s11042-017-5349-7
   Dubey SR, 2019, MULTIMED TOOLS APPL, V78, P28063, DOI 10.1007/s11042-019-07908-3
   Ekman P., 2003, UNMASKING FACE GUIDE
   Ekweariri AN, 2017, INT CONF COMPUT INTE, P43, DOI [10.1109/CICN.2017.8319353, 10.1109/CICN.2017.12]
   Fan XQ, 2022, COGN NEURODYNAMICS, V16, P847, DOI 10.1007/s11571-021-09761-3
   Fan Y., 2020, IEEE Trans. Affect. Comput.
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Gan YL, 2020, IEEE ACCESS, V8, P7383, DOI 10.1109/ACCESS.2020.2963913
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hazourli AR, 2021, MULTIMED TOOLS APPL, V80, P13639, DOI 10.1007/s11042-020-10332-7
   Huo H, 2023, MULTIMED TOOLS APPL, V82, P18635, DOI 10.1007/s11042-022-14066-6
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Hwooi SKW, 2022, IEEE ACCESS, V10, P96053, DOI 10.1109/ACCESS.2022.3205018
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jiang P, 2020, IEEE SIGNAL PROC LET, V27, P725, DOI 10.1109/LSP.2020.2989670
   Karnati M, 2022, IEEE T AFFECT COMPUT, V13, P2058, DOI 10.1109/TAFFC.2022.3208309
   Kartheek MN, 2021, INT C COMPUTER ANAL, P210
   Kartheek MN, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03384-6
   Khalid M, 2020, 2020 43RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P204, DOI [10.1109/tsp49548.2020.9163446, 10.1109/TSP49548.2020.9163446]
   Kola DGR, 2021, IET BIOMETRICS, V10, P207, DOI 10.1049/bme2.12012
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Kong YH, 2022, IET IMAGE PROCESS, V16, P1694, DOI 10.1049/ipr2.12441
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li ZY, 2019, IEEE INT CON MULTI, P1108, DOI 10.1109/ICME.2019.00194
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Makhmudkhujaev F, 2019, TURK J ELECTR ENG CO, V27, P516, DOI 10.3906/elk-1804-58
   Mandal M, 2019, IET IMAGE PROCESS, V13, P850, DOI 10.1049/iet-ipr.2018.5683
   Miao S, 2019, IEEE ACCESS, V7, P78000, DOI 10.1109/ACCESS.2019.2921220
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nan F, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107678
   Nan YH, 2022, ALEX ENG J, V61, P4435, DOI 10.1016/j.aej.2021.09.066
   Ouyang WL, 2017, IEEE T PATTERN ANAL, V39, P1320, DOI 10.1109/TPAMI.2016.2587642
   Putro MD, 2020, IEEE IND ELEC, P411, DOI [10.1109/iecon43393.2020.9254805, 10.1109/IECON43393.2020.9254805]
   Rajan S, 2020, IET IMAGE PROCESS, V14, P1373, DOI 10.1049/iet-ipr.2019.1188
   Reddy AH, 2022, SIGNAL IMAGE VIDEO P, V16, P369, DOI 10.1007/s11760-021-01941-2
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Schoneveld L, 2021, IEEE IMAGE PROC, P2339, DOI 10.1109/ICIP42928.2021.9506025
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Sen D, 2019, MULTIMED TOOLS APPL, V78, P10287, DOI 10.1007/s11042-018-6537-9
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Shengtao G, 2019, 2019 IEEE INT C SIGN, P1
   Shi CP, 2021, IEEE ACCESS, V9, P39255, DOI 10.1109/ACCESS.2021.3063493
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Soman G, 2022, ALGORITHMS, V15, DOI 10.3390/a15020055
   Songfan Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P866, DOI 10.1109/FG.2011.5771364
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Pham TTD, 2019, IEEE ACCESS, V7, P5200, DOI 10.1109/ACCESS.2018.2889852
   Tuncer T, 2020, MULTIMED TOOLS APPL, V79, P29573, DOI 10.1007/s11042-020-09439-8
   Verma M, 2022, ARXIV
   Wang FJ, 2019, PROC INT C TOOLS ART, P1675, DOI 10.1109/ICTAI.2019.00246
   Wang XZ, 2018, PLATELETS, V29, P48, DOI 10.1080/09537104.2017.1293807
   Wang YA, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901820
   Xie SY, 2019, PATTERN RECOGN, V92, P177, DOI 10.1016/j.patcog.2019.03.019
   Yang JH, 2022, IEEE ACCESS, V10, P103264, DOI 10.1109/ACCESS.2022.3210109
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zhao GZ, 2020, IEEE ACCESS, V8, P38528, DOI 10.1109/ACCESS.2020.2964752
   Zhou N, 2021, IEEE ACCESS, V9, P5573, DOI 10.1109/ACCESS.2020.3046715
NR 79
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27619
EP 27645
DI 10.1007/s11042-023-16433-3
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001060108100006
DA 2024-07-18
ER

PT J
AU Hazarika, RA
   Kandar, D
   Maji, AK
AF Hazarika, Ruhul Amin
   Kandar, Debdatta
   Maji, Arnab Kumar
TI A novel machine learning based technique for classification of
   early-stage Alzheimer's disease using brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Alzheimer's Disease (AD); Early stage-Alzheimer's Disease (EAD); Deep
   Convolutional Neural Network (DNN); VGG-16; DenseNet; Principal
   Component Analysis (PCA); Random Forest (RF); Late MCI (LMCI)
ID RANDOM FOREST; DEEP; RISK
AB Alzheimer's disease (AD) is a globally alarming neuro-degenerative abnormality for elderly people. The earliest afflicted regions in AD are the brain tissues that form memory and other cognitive functions. Mild Cognitive Impairment (MCI) is the stage of dementia between Cognitively Normal (CN) and AD. Late-MCI is the last stage of MCI, also denominated as the early-stage of AD (EAD). The classification of EAD is important for preventing or delaying the development of AD. Due to the complex molecular and physical changes in the brain, medical experts struggle to classify EAD. By extracting critical features from brain images, diseases such as EAD can be effectively classified. Deep Neural Network (DNN) is a widely used machine learning (ML) technique for feature extraction and classification. In this work, we propose a DNN model for optimal feature extraction. By taking VGG-19 as a reference model, we used the concept of a dense block to pass maximal features throughout the network. We combined min-max-pooling layers to preserve both maximum and minimum valued feature information. Moreover, we've replaced all convolution layers with Inception-block to preserve fewer but more diverse parameters. Next, we used the principal component analysis (PCA) approach to select only the best features. Finally, we used a Random Forest (RF) classifier to classify EAD, CN, and AD. It is observed that, with an average performance rate of 98.08%, the proposed technique had the highest classification performance in CN vs. EAD. The proposed method also convincingly outperforms all of the discussed state-of-the-art and other classifiers
C1 [Hazarika, Ruhul Amin; Kandar, Debdatta; Maji, Arnab Kumar] North Eastern Hill Univ, Dept Informat Technol, Shillong 793022, Meghalaya, India.
   [Hazarika, Ruhul Amin] Manipal Acad Higher Educ, Manipal Inst Technol Bengaluru, Dept Informat Technol, Manipal 576104, India.
C3 North Eastern Hill University; Manipal Academy of Higher Education
   (MAHE)
RP Maji, AK (corresponding author), North Eastern Hill Univ, Dept Informat Technol, Shillong 793022, Meghalaya, India.
EM arnab.maji@gmail.com
RI Maji, Arnab Kumar/IUP-3517-2023
OI Maji, Arnab Kumar/0000-0002-3320-9965
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Adeniyi JK., 2022, PARADIGMPLUS, V3, P1, DOI [10.55969/paradigmplus.v3n3a1, DOI 10.55969/PARADIGMPLUS.V3N3A1]
   ADNI, 2023, ALZH DIS NEUR IN ADN
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Albawi S, 2017, I C ENG TECHNOL
   Alzheimer's Assoc, 2018, ALZHEIMERS DEMENT, V14, P367, DOI 10.1016/j.jalz.2018.02.001
   Beason-held LoriL, AGING BRAIN
   Burke AD, 2019, NEUROL THER, V8, P325, DOI 10.1007/s40120-019-00148-5
   Caie PD., 2021, Artificial Intelligence and Deep Learning in Pathology, DOI DOI 10.1016/B978-0-323-67538-3.00008-7
   Chelliah I., 2021, SIMPLE EXPLANATION C
   Dara S., 2018, International Journal of Pure and Applied Mathematics, V120, P305
   De A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114338
   Effrosynidis D, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101224
   Ganesh Hari S, 2021, ESCAPE, V50, P481, DOI 10.1016/b978-0-323-88506-5.50076-0
   Gao YP, 2022, BRAIN PATHOL, V32, DOI 10.1111/bpa.13047
   Garate-Escamila Anna Karen, 2020, Informatics in Medicine Unlocked, V19, P193, DOI 10.1016/j.imu.2020.100330
   Goenka N, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103500
   Hazarika Ruhul Amin, 2020, International Conference on Innovative Computing and Communications. Proceedings of ICICC 2019. Advances in Intelligent Systems and Computing (AISC 1087), P279, DOI 10.1007/978-981-15-1286-5_24
   Hazarika RA., 2022, J INTELL FUZZY SYST, V43, P1
   Hazarika RA, 2021, PREPRINT
   Hazarika RA, 2021, J KING SAUD U COMPUT
   Hazarika RA, 2022, IEEE ACCESS, V10, P99066, DOI 10.1109/ACCESS.2022.3206389
   Hazarika RA, 2021, IEEE ACCESS, V9, P161194, DOI 10.1109/ACCESS.2021.3131741
   Hazarika RA, 2021, IEEE ACCESS, V9, P58503, DOI 10.1109/ACCESS.2021.3072559
   Hong L., 2017, EURASIP J WIRE COMMU, V1, P1
   Jessen F, 2014, ALZHEIMERS DEMENT, V10, P76, DOI 10.1016/j.jalz.2012.09.017
   Kang WJ, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104678
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Kaye JA, 1998, NEUROLOGY, V51, pS45, DOI 10.1212/WNL.51.1_Suppl_1.S45
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kim J, 2021, PSYCHIAT INVEST, V18, P69, DOI 10.30773/pi.2020.0304
   KIRA K, 1992, MACHINE LEARNING /, P249
   Korolev IO., 2014, MSRJ, V4, P24, DOI DOI 10.3402/MSRJ.V3I0.201333
   Lama RK, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/5485080
   Liangxiu Han Z, 2021, IEEE J BIOMED HEALTH
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Maksoud EAA, 2019, MACHINE LEARNING IN BIO-SIGNAL ANALYSIS AND DIAGNOSTIC IMAGING, P209, DOI 10.1016/B978-0-12-816086-2.00009-6
   Murugesan B, 2018, IEEE INT SYM MED MEA, P342
   NationalInstitute onAging(NIH), 2023, WHAT IS MILD COGN IM
   Navamani TM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P123, DOI 10.1016/B978-0-12-816718-2.00014-2
   Oh K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54548-6
   Pagel JF, 2017, MACHINE DREAMING AND CONSCIOUSNESS, P1
   Palimkar Prajyot, 2022, Advanced Computing and Intelligent Technologies: Proceedings of ICACIT 2021. Lecture Notes in Networks and Systems (218), P219, DOI 10.1007/978-981-16-2164-2_19
   Peters R, 2006, POSTGRAD MED J, V82, P84, DOI 10.1136/pgmj.2005.036665
   Raghavan VV, 2016, COGNITIVE COMPUTING
   Rao YL, 2022, 3 BIOTECH, V12, DOI 10.1007/s13205-022-03123-4
   Sahu S, 2022, NETW MODEL ANAL HLTH, V11, DOI 10.1007/s13721-021-00349-9
   Sergio G., 2021, ALZHEIMERS RES THER, V13, P1
   Shanmugam JV, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103217
   Sharma R, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108099
   Sheng JH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06444-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song M, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11040453
   Song T, 2021, COMPLEXITY, DOI [10.1155/2021/7523513, DOI 10.1155/2021/7523513]
   Suthaharan S, 2016, HANDB STAT, V35, P207, DOI 10.1016/bs.host.2016.07.006
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Varatharajah Y, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38793-3
   Wu HF, 2022, INT J MACH LEARN CYB, V13, P1997, DOI 10.1007/s13042-021-01501-7
   Xue Y, 2021, IEEE COMPUT INTELL M, V16, P67, DOI 10.1109/MCI.2021.3084435
   Yelei Z., 2022, BMC PSYCH, V22, P1
   Yu J, 2022, BIOL TRACE ELEM RES, P1
   Zhang TT, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00572
   Zhi Z, 2021, TECHNOL HEALTH CARE, V29, P363, DOI 10.3233/THC-202638
   Zhou ZY, 2022, J REAL ESTATE FINANC, DOI 10.1007/s11146-022-09889-x
NR 66
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 11
PY 2023
DI 10.1007/s11042-023-16379-6
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O9TM0
UT WOS:001047169200004
DA 2024-07-18
ER

PT J
AU Zhang, ZH
   Ma, YT
   Liu, WJ
   Shi, QH
AF Zhang, Zhenghuan
   Ma, Yantu
   Liu, Wanjun
   Shi, Qiuhong
TI Multi-level continuous encoding and decoding based on dilation
   convolution for super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Deep neural network; Multi-level continuous encoding
   and decoding module; Dilation attention module
ID IMAGE SUPERRESOLUTION
AB Deep neural networks have shown better effects for super-resolution in recent years. However, it is difficult to extract multi-level features of low-resolution (LR) images to reconstruct more clear images. Most of the existing mainstream methods use encoding and decoding frameworks, which are still difficult to extract multi-level features from low resolution images, and this process is essential for the reconstruction of more clear images. To overcome these limitations, we present a multi-level continuous encoding and decoding based on dilation convolution for super-resolution (MEDSR). Specifically, we first construct a multi-level continuous encoding and decoding module, which can obtain more easy-to-extract features, complex-to-extract features, and difficult-to-extract features of LR images. Then we construct dilated attention modules based on different dilated rates to capture multi-level regional information of different respective fields and focus on each level information of multi-level regional information to extract multi-level deep features. These dilated attention modules are designed to incorporate varying levels of contextual information by dilating the receptive field of the attention module. This allows the module to attend to a larger area of the input while maintaining a constant memory footprint. MEDSR uses multi-level deep features of LR images to reconstruct better SR images, the values of PSNR and SSIM of our method on Set5 dataset reach 32.65 dB and 0.9005 respectively when the scale factor is x4. Extensive experimental results demonstrate that our proposed MEDSR outperforms that of some state-of-the-art super-resolution methods.
C1 [Zhang, Zhenghuan; Ma, Yantu; Shi, Qiuhong] Gansu Agr Univ, Informat & Network Ctr, Lanzhou, Peoples R China.
   [Liu, Wanjun] Liaoning Tech Univ, Software Engn Inst, Fuxin, Peoples R China.
C3 Gansu Agricultural University; Liaoning Technical University
RP Zhang, ZH (corresponding author), Gansu Agr Univ, Informat & Network Ctr, Lanzhou, Peoples R China.
EM zzh@gsau.edu.cn; mayt@gsau.edu.cn; liuwanjun@lntu.edu.cn;
   shiqh@gsau.edu.cn
FU National Key Ramp;D Program [2020YFB1713600]; National Natural Science
   Foundation of China [61763029]; National Natural Science Foundation
   Youth Fund of China [41701479]; Science and Technology Program of Gansu
   Province [21YF5GA072, 21JR7RA206]; Education Industry Support Program of
   Gansu Provincial Department [2021CYZC-02]; Natural Science Foundation of
   Liaoning Province [20180550529]
FX AcknowledgmentsThis work is supported by the National Key R&D Program
   (2020YFB1713600), the National Natural Science Foundation of China
   (61763029), the National Natural Science Foundation Youth Fund of China
   (41701479), the Science and Technology Program of Gansu Province
   (21YF5GA072, 21JR7RA206), the Education Industry Support Program of
   Gansu Provincial Department (2021CYZC-02), and the Natural Science
   Foundation of Liaoning Province (20180550529).
CR Agustsson Eirikur, 2017, IEEE CVF C COMP VIS, P126, DOI DOI 10.1109/CVPRW.2017.150
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen H., 2021, arXiv
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kumar BP, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116532
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu AA, 2019, MULTIMED TOOLS APPL, V78, P677, DOI 10.1007/s11042-017-5532-x
   Liu H, 2020, IEEE T GEOSCI REMOTE, V58, P8372, DOI 10.1109/TGRS.2020.2987400
   Liu H, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106103
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shamsolmoali P, 2019, MULTIMED TOOLS APPL, V78, P23815, DOI 10.1007/s11042-018-5915-7
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song ZY, 2023, IEEE T COGN DEV SYST, V15, P234, DOI 10.1109/TCDS.2022.3153090
   Song ZY, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106193
   Song ZY, 2021, MULTIMED TOOLS APPL, V80, P9765, DOI 10.1007/s11042-020-10152-9
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang XZ, 2018, PLATELETS, V29, P48, DOI 10.1080/09537104.2017.1293807
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 38
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20149
EP 20167
DI 10.1007/s11042-023-16415-5
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900013
DA 2024-07-18
ER

PT J
AU Saeed, U
   Kumar, K
   Khuhro, MA
   Laghari, AA
   Shaikh, AA
   Rai, A
AF Saeed, Umair
   Kumar, Kamlesh
   Khuhro, Mansoor Ahmed
   Laghari, Asif Ali
   Shaikh, Aftab Ahmed
   Rai, Athaul
TI DeepLeukNet-A CNN based microscopy adaptation model for acute
   lymphoblastic leukemia classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep Learning; Convolutional Neural Network; Acute Lymphoblastic
   Leukemia; ConvNet filters
ID BONE-MARROW BIOPSY; BLOOD; SEGMENTATION; DIAGNOSIS; CHILDREN
AB Acute Lymphoblastic Leukemia is one of the fatal types of disease which causes a high mortality rate among children and adults. Traditional diagnosing of this disease is achieved through analyzing the microscopic images of white blood cells by a clinical pathologist. However, this procedure relies on manual observation and often provides inaccurate results. This research proposes an automated system for diagnosing Acute Lymphoblastic Leukemia disease using a convolutional neural network technique. For this purpose, simulation work has been performed over the Acute Lymphoblastic Leukemia-IDB 1 and Leukemia-lDB 2 datasets. However, data augmentation techniques have been employed to generate images to handle the overfitting problem in the model. Qualitative analysis has been performed by visualizing the intermediate layer activation, ConvNet filters and heatmap layers, and a comparative study has been performed with existing methods to validate the efficiency of our proposed model. However, the results showed that our proposed model attained 99.61% accuracy in Acute Lymphoblastic Leukemia diagnosis. The high accuracy reveals that it provides a more effective way to detect Acute Lymphoblastic Leukemia disease than existing works reported in the same area.
C1 [Saeed, Umair] ION Grp Co, Mixit Inc, Karachi, Pakistan.
   [Kumar, Kamlesh; Khuhro, Mansoor Ahmed; Laghari, Asif Ali; Shaikh, Aftab Ahmed; Rai, Athaul] Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi, Pakistan.
RP Laghari, AA (corresponding author), Sindh Madressatul Islam Univ, Dept Comp Sci, Karachi, Pakistan.
EM asif.laghari@smiu.edu.pk
RI Laghari, Asif Ali/AAF-5893-2020; Alpkocak, Adil/F-3388-2013; KHUHRO,
   MANSOOR/AAJ-3114-2021
OI Laghari, Asif Ali/0000-0001-5831-5943; Alpkocak,
   Adil/0000-0001-7695-196X; 
CR Abdeldaim AM, 2018, STUD COMPUT INTELL, V730, P131, DOI 10.1007/978-3-319-63754-9_7
   Abhishek A, 2023, BIOMED SIGNAL PROCES, V83, DOI 10.1016/j.bspc.2023.104722
   Abhishek A, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103341
   Ahmed N, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030104
   Al-jaboriy SS, 2019, PATTERN RECOGN LETT, V125, P85, DOI 10.1016/j.patrec.2019.03.024
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Ambati LS, 2021, P 27 ANN AMERICAS C
   Ananthu KS, 2022, INTELLIGENT SUSTAINA, P679, DOI DOI 10.1007/978
   BURKE JS, 1978, AM J CLIN PATHOL, V70, P876
   Chand S, 2022, MULTIMED TOOLS APPL, V81, P37243, DOI 10.1007/s11042-022-13543-2
   Chen K, 2021, ARXIV
   Chen YK, 2019, LECT NOTES COMPUT SC, V11764, P487, DOI 10.1007/978-3-030-32239-7_54
   Cheng Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7747, DOI 10.1109/CVPR42600.2020.00777
   Das Pradeep Kumar, 2021, Machine Learning, Deep Learning and Computational Intelligence for Wireless Communication. Proceedings of MDCWC 2020. Lecture Notes in Electrical Engineering (LNEE 749), P425, DOI 10.1007/978-981-16-0289-4_32
   Das PK, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115311
   Das S, 2023, NEUROSCI INFORM, V3
   Dhal KG, 2023, J BIONIC ENG, V20, P2916, DOI 10.1007/s42235-023-00392-4
   Dhal KG, 2020, MULTIMED TOOLS APPL, V79, P12227, DOI 10.1007/s11042-019-08417-z
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Hagos YB, 2019, LECT NOTES COMPUT SC, V11764, P667, DOI 10.1007/978-3-030-32239-7_74
   Hallböök H, 2006, CANCER-AM CANCER SOC, V107, P1551, DOI 10.1002/cncr.22189
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam N, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P130
   Jawahar M, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105894
   Jha KK, 2019, COMPUT METH PROG BIO, V179, DOI 10.1016/j.cmpb.2019.104987
   Karakheti Ashwin, 2022, Nepal Journal of Health Sciences, V2, P34, DOI 10.3126/njhs.v2i2.56791
   Karim S, 2023, CURR MED IMAGING, V19, P417, DOI 10.2174/1573405618666220519144358
   Khandekar R, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102690
   Klingebiel T, 2010, BLOOD, V115, P3437, DOI 10.1182/blood-2009-03-207001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2020, ADV DATA SCI ADAPT, V12, DOI 10.1142/S2424922X20410028
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Laghari Asif Ali, 2022, Curr Med Imaging, DOI 10.2174/1573405619666221228094228
   LIPSHUTZ MD, 1980, CANCER-AM CANCER SOC, V46, P1422, DOI 10.1002/1097-0142(19800915)46:6<1422::AID-CNCR2820460623>3.0.CO;2-B
   Liu Y, 2019, LECT N BIOENG, P113, DOI 10.1007/978-981-15-0798-4_12
   Liu YF, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12010016
   Masoudi B, 2023, MULTIMED TOOLS APPL, V82, P18967, DOI 10.1007/s11042-022-14212-0
   Mishra S, 2019, BIOMED SIGNAL PROCES, V47, P303, DOI 10.1016/j.bspc.2018.08.012
   Mishra S, 2017, ADV INTELL SYST, V459, P171, DOI 10.1007/978-981-10-2104-6_16
   Mishra S, 2017, BIOMED SIGNAL PROCES, V33, P272, DOI 10.1016/j.bspc.2016.11.021
   Muhammad G, 2022, PAKISTAN J ENG TECHN, V5, P16, DOI [10.51846/vol5iss1pp16-22, DOI 10.51846/VOL5ISS1PP16-22]
   Muntasa A, 2019, PROCEDIA COMPUT SCI, V157, P87, DOI 10.1016/j.procs.2019.08.145
   Narjim Sadia, 2020, Cyber Security and Computer Science. Second EAI International Conference, ICONCS 2020. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 325), P515, DOI 10.1007/978-3-030-52856-0_41
   Palczynski K, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21238025
   Piuri V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P103, DOI 10.1109/CIMSA.2004.1397242
   Prellberg J, 2019, LECT N BIOENG, P53, DOI 10.1007/978-981-15-0798-4_6
   Ramaneswaran S, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/2577375
   Rawat J, 2017, MULTIMED TOOLS APPL, V76, P19057, DOI 10.1007/s11042-017-4478-3
   Rehman A, 2018, MICROSC RES TECHNIQ, V81, P1310, DOI 10.1002/jemt.23139
   Rejula MA, 2023, MULTIMED TOOLS APPL, V82, P35475, DOI 10.1007/s11042-023-15113-6
   Rodrigues LF, 2022, J DIGIT IMAGING, V35, P623, DOI 10.1007/s10278-022-00600-3
   Sadafi A, 2019, LECT NOTES COMPUT SC, V11764, P685, DOI 10.1007/978-3-030-32239-7_76
   Saeed U, 2022, EAI Endorsed Trans. Pervasive Health Technol., V8, pe1
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Scotti F, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P96
   Scotti F, 2006, IEEE IMTC P, P43, DOI 10.1109/IMTC.2006.328170
   Shafique S, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818802789
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Terwilliger T, 2017, BLOOD CANCER J, V7, DOI 10.1038/bcj.2017.53
   Tuba Eva, 2019, Advances in Swarm Intelligence. 10th International Conference, ICSI 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11656), P142, DOI 10.1007/978-3-030-26354-6_14
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Wang D, 2020, PROC CVPR IEEE, P3950, DOI 10.1109/CVPR42600.2020.00401
   Wang J, 2020, PROC CVPR IEEE, P4443, DOI 10.1109/CVPR42600.2020.00450
   Wang XF, 2019, LECT NOTES COMPUT SC, V11764, P423, DOI 10.1007/978-3-030-32239-7_47
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang CC, 2019, LECT NOTES COMPUT SC, V11764, P246, DOI 10.1007/978-3-030-32239-7_28
   Yu QH, 2020, PROC CVPR IEEE, P4125, DOI 10.1109/CVPR42600.2020.00418
   Zhang YF, 2019, LECT NOTES COMPUT SC, V11764, P360, DOI 10.1007/978-3-030-32239-7_40
   Zhao SY, 2019, IEEE I CONF COMP VIS, P10599, DOI 10.1109/ICCV.2019.01070
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
NR 70
TC 5
Z9 5
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21019
EP 21043
DI 10.1007/s11042-023-16191-2
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001036798900007
DA 2024-07-18
ER

PT J
AU Al-Sayyed, R
   Alhenawi, E
   Alazzam, H
   Wrikat, A
   Suleiman, D
AF Al-Sayyed, Rizik
   Alhenawi, Esra'a
   Alazzam, Hadeel
   Wrikat, Ala'a
   Suleiman, Dima
TI Mobile money fraud detection using data analysis and visualization
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile money fraud; Fraud detection; Visualization; Electronic Crimes
AB Financial investigations in the realm of fraud detection demand rigorous data analysis to identify anomalies and inform decision-making. This paper demonstrates the importance of data visualization as a means of conducting initial assessments of testable datasets to validate their suitability and promptly detect unexpected patterns before delving deeper into investigations. Using the publicly available PAYSIM dataset as a case study, we analyzed 6,362,620 records, of which 8213 were fraudulent and the remainder were legitimate. The dataset comprised 9 features and a single target class. Our analysis reveals the powerful role of visualization in identifying early indications of incompatibility with the dataset and guiding analysts to question its fitness for the context at hand. In particular, we show how visualization can highlight key findings and provide an added emphasis to the results. Through visual and numerical analysis, we demonstrate the importance of identifying potential outliers and other anomalies before proceeding with data preprocessing and modeling. Our results suggest that visual analysis of data is an essential step in detecting fraudulent activities in mobile money transactions. This approach can help to improve the accuracy and efficiency of fraud detection systems, thereby protecting users from financial losses. We conclude that data visualization should be an integral part of any data analysis project, especially in the field of fraud detection, to ensure the validity and suitability of the data before proceeding with further investigations.
C1 [Al-Sayyed, Rizik] Univ Jordan, Dept Informat Technol, Amman, Jordan.
   [Alhenawi, Esra'a] Al Ahliyya Amman Univ, Dept Software Engn, Amman, Jordan.
   [Alazzam, Hadeel] Al Balqa Appl Univ, Dept Intelligent Syst, Salt, Jordan.
   [Wrikat, Ala'a; Suleiman, Dima] Univ Jordan, Dept Comp Sci, Amman, Jordan.
C3 University of Jordan; Al-Ahliyya Amman University; Al-Balqa Applied
   University; University of Jordan
RP Alazzam, H (corresponding author), Al Balqa Appl Univ, Dept Intelligent Syst, Salt, Jordan.
EM r.alsayyed@ju.edu.jo; e.alhenawi@ammanu.edu.jo;
   hadeel.alazzam@bau.edu.jo; alaawraikat@yahoo.com;
   dima.suleiman@ju.edu.jo
RI Alhenawi, Esra'a Mahmoud/JFK-7931-2023; Alazzam, Hadeel/GYA-4591-2022;
   Alazzam, Hadeel/GXN-1461-2022
OI Alhenawi, Esra'a Mahmoud/0009-0002-9747-4642; Alazzam,
   Hadeel/0000-0002-6768-9696
CR Al-Hashedi KG, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100402
   Al-Qudah AA, 2023, ENVIRON SCI POLLUT R, V30, P61381, DOI [10.1007/s11356-021-18224-5, 10.1007/s10660-022-09577-1]
   Alazzam H, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113249
   Albrecht C, 2019, J MONEY LAUND CONTRO, V22, P210, DOI 10.1108/JMLC-12-2017-0074
   Amin M. Mohamed, 2020, IOP Conference Series: Materials Science and Engineering, V884, DOI 10.1088/1757-899X/884/1/012059
   Aslam N, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103598
   Aslam N, 2022, MULTIMED TOOLS APPL, V81, P42457, DOI 10.1007/s11042-022-13496-6
   Besenbruch J., 2018, Research Paper Business Analytics
   Bhowmik R, 2008, J DIGIT FORENSICS SE, V3, P35
   Botchey FE, 2022, INFORMATICA, V45
   Botchey FE, 2020, INFORMATION, V11, DOI 10.3390/info11080383
   Breve B, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100240
   Carcillo F, 2018, INT J DATA SCI ANAL, V5, P285, DOI 10.1007/s41060-018-0116-z
   Caruccio L, 2021, SEBD, P5
   Chang R, 2008, INFORM VISUAL, V7, P63, DOI 10.1057/palgrave.ivs.9500172
   Chen ZY, 2018, KNOWL INF SYST, V57, P245, DOI 10.1007/s10115-017-1144-z
   Cochrane N, 2021, 2021 IEEE 11TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P283, DOI 10.1109/CCWC51732.2021.9376045
   Dilla WN, 2015, INT J ACCOUNT INF SY, V16, P1, DOI 10.1016/j.accinf.2015.01.001
   Gao SJ, 2009, EXPERT SYST APPL, V36, P1493, DOI 10.1016/j.eswa.2007.11.059
   Gardner C, 2021, IEEE SOUTHEASTCON, P783, DOI 10.1109/SOUTHEASTCON45413.2021.9401949
   Horcas Jose-Miguel, 2022, SPLC '22: Proceedings of the 26th ACM International Systems and Software Product Line Conference, P55, DOI 10.1145/3546932.3546993
   Kokina J, 2019, INT J ACCOUNT INF SY, V35, DOI 10.1016/j.accinf.2019.100431
   Leite RA, 2018, VIS INFORM, V2, P198, DOI 10.1016/j.visinf.2018.11.001
   Lopez-Rojas, 2020, FINANCIAL SYNTHETIC
   Lopez-Rojas E., 2016, P 28 EUR MOD SIM S E, P249
   Lurie NH, 2007, J MARKETING, V71, P160, DOI 10.1509/jmkg.71.1.160
   Lv LT, 2008, INT C WAVEL ANAL PAT, P209, DOI 10.1109/ICWAPR.2008.4635778
   Maurer B, 2012, J DEV STUD, V48, P589, DOI 10.1080/00220388.2011.621944
   Ngai EWT, 2011, DECIS SUPPORT SYST, V50, P559, DOI 10.1016/j.dss.2010.08.006
   North, 2009, P WORKING C ADV VISU, P128
   Novikova E, 2019, ADV COMPUT ELECTR EN, P205, DOI 10.4018/978-1-5225-5693-0.ch009
   Olszewski D, 2014, KNOWL-BASED SYST, V70, P324, DOI 10.1016/j.knosys.2014.07.008
   Pal SC, 2022, J ENVIRON MANAGE, V318, DOI 10.1016/j.jenvman.2022.115582
   Powers D.M., 2020, arXiv
   Rich ML, 2016, U PENN LAW REV, V164, P871
   Rocha-Salazar JDJ, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114470
   Rouhollahi Z, 2021, ARXIV
   Sa'adah Siti, 2020, 2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P677, DOI 10.1109/ISRITI51436.2020.9315344
   Salehi A., 2017, Int. J. Appl. Eng. Res., V12, P10084
   Sanchez-Aguayo M, 2021, COMPUTERS, V10, DOI 10.3390/computers10100121
   Sarker M, 2020, INT J SCI BUSINESS, V4, P138
   Shaikh ZA, 2022, J TIANJIN U SCI TECH, V55, P324
   Shao CL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102736
   Sharma A, 2013, ARXIV
   Shukla AK, 2018, BIOCYBERN BIOMED ENG, V38, P975, DOI 10.1016/j.bbe.2018.08.004
   Singh K, 2019, INT J ACCOUNT INF SY, V34, DOI 10.1016/j.accinf.2019.06.001
   Sun J, 2018, IEEE PAC VIS SYMP, P170, DOI 10.1109/PacificVis.2018.00029
   Yan C, 2023, ENVIRON SCI POLLUT R, V30, P61271, DOI 10.1007/s11356-021-17437-y
NR 48
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17093
EP 17108
DI 10.1007/s11042-023-16068-4
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033674800002
DA 2024-07-18
ER

PT J
AU Waqas, M
   Anjum, N
AF Waqas, Muhammad
   Anjum, Nadeem
TI Generic features selection for structure classification of diverse
   styled scholarly articles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Features Engineering; Machine Learning; Research Article; Metadata
   Extraction; Text mining
ID KNOWLEDGE; SYSTEM
AB The enormous growth in online research publications in diversified domains has attracted the research community to extract these valuable scientific resources by searching online digital libraries and publishers' websites. A precise search is desired to enlist most related articles by applying semantic queries to the document's metadata and the structural elements. The online search engines and digital libraries offer only keyword-based search on full-body text, which creates excessive results. Therefore, the research article's structural and metadata information has to be stored in machine comprehendible form by the online research publishers. The research community in recent years has adopted different approaches to extract structural information from research documents like rule-based heuristics and machine-learning-based approaches. Studies suggest that machine-learning-based techniques have produced optimum results for document structure extraction from publishers having diversified publication layouts. In this paper, we have proposed thirteen different logical layout structural (LLS) components. We have identified a two-staged innovative set of generic features that are associated with the LLS. This approach has given our technique an advantage against the state-of-the-art for structural classification of digital scientific articles with diversified publication styles. We have applied chi-square (chi(2)) for feature selection, and the final result has revealed that SVM (Kernal function) has produced an optimum result with an overall F-measure of 0.95.
C1 [Waqas, Muhammad; Anjum, Nadeem] Capital Univ Sci & Technol, Dept Comp Sci, ICT, Expressway,Kahuta Rd,Zone 5, Islamabad, Pakistan.
C3 Capital University of Science & Technology
RP Waqas, M (corresponding author), Capital Univ Sci & Technol, Dept Comp Sci, ICT, Expressway,Kahuta Rd,Zone 5, Islamabad, Pakistan.
EM dcs153002@cust.pk; nadeem.anjum@cust.edu.pk
OI Waqas, Muhammad/0000-0002-4563-8951; Anjum, Nadeem/0000-0001-6470-075X
CR Abdar M, 2019, IEEE ACCESS, V7, P167605, DOI 10.1109/ACCESS.2019.2953920
   Alam MJ, 2011, LECT NOTES ARTIF INT, V7015, P239, DOI 10.1007/978-3-642-25020-0_31
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   Azad HK, 2022, PATTERN RECOGN LETT, V158, P148, DOI 10.1016/j.patrec.2022.04.013
   Azad HK, 2022, J INTELL INF SYST, P1
   Bharti KK, 2015, EXPERT SYST APPL, V42, P3105, DOI 10.1016/j.eswa.2014.11.038
   BOWLES MICHAEL., 2015, Machine learning in python: Essential techniques for predictive analysis
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Claesen M, 2023, ARXIV
   Constantin Alexandru., 2013, Proceedings of the 2013 ACM symposium on Document engineering, P177, DOI DOI 10.1145/2494266.2494271
   Déjean H, 2006, LECT NOTES COMPUT SC, V3872, P129
   Dietze S., 2016, Revised Selected Papers, V641
   Dimou A, 2016, SEMANTIC WEB EVALUAT, P243, DOI DOI 10.1007/978-3-319-46565-4_19
   Granitzer M, 2012, P 27 ANN ACM S APPL, P962
   Guo KH, 2023, IEEE T MULTIMEDIA, V25, P3894, DOI 10.1109/TMM.2022.3168146
   Guo Kehua, 2022, IEEE/ACM Trans Comput Biol Bioinform, VPP, DOI 10.1109/TCBB.2022.3185395
   Han J, 2012, MOR KAUF D, P1
   Haryanto Ardy Wibowo, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P229, DOI 10.1109/ISEMANTIC.2018.8549748
   Hiregoudar SB., 2014, International Journal of Research in Engineering and Technology, V3, P385, DOI DOI 10.15623/IJRET.2014.0315076
   Do HHN, 2013, ACM-IEEE J CONF DIG, P219
   Jiang LX, 2009, IEEE T KNOWL DATA EN, V21, P1361, DOI 10.1109/TKDE.2008.234
   Jinha AE, 2010, LEARN PUBL, V23, P258, DOI 10.1087/20100308
   Johnson R, 2018, STM REPORT AN OVERVI
   Kiss T, 2006, COMPUT LINGUIST, V32, P485, DOI 10.1162/coli.2006.32.4.485
   Klampfl S, 2014, INT J DIGIT LIBRARIE, V14, P83, DOI 10.1007/s00799-014-0115-1
   Klink S., 2001, International Journal on Document Analysis and Recognition, V4, P18, DOI 10.1007/PL00013570
   Lai C, 2006, PATTERN RECOGN LETT, V27, P1067, DOI 10.1016/j.patrec.2005.12.018
   Mahesh B., 2020, nternational Journal of Science and Research (IJSR), V9, P381, DOI [DOI 10.21275/ART20203995, 10.21275/ART20203995]
   Mumtaz F, 2018, BIOMED PHARMACOTHER, V105, P1205, DOI 10.1016/j.biopha.2018.05.086
   Olson RS, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P485, DOI 10.1145/2908812.2908918
   Ramakrishnan C, 2012, SOURCE CODE BIOL MED, V7, DOI 10.1186/1751-0473-7-7
   Rebholz-Schuhmann D, 2012, NAT REV GENET, V13, P829, DOI 10.1038/nrg3337
   Richert Willi., 2013, Building Machine Learning Systems with Python
   Santosh KC, 2015, INT J DOC ANAL RECOG, V18, P337, DOI 10.1007/s10032-015-0253-z
   Shi P, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-375
   Su XD, 2016, INT J DOC ANAL RECOG, V19, P221, DOI 10.1007/s10032-016-0267-1
   Tkaczyk D., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P11, DOI 10.1109/DAS.2012.4
   Tsai CT, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1733, DOI 10.1145/2505515.2505613
   Tuarob S, 2020, IEEE T KNOWL DATA EN, V32, P1881, DOI 10.1109/TKDE.2019.2913376
   Tuarob S, 2013, PROC INT CONF DOC, P738, DOI 10.1109/ICDAR.2013.151
   Washio T., 2003, ACM SIGKDD EXPLORATI, V5, P59, DOI [DOI 10.1145/959242.959249, 10.1145/959242.959249]
   Wu J, 2015, AI MAG, V36, P35, DOI 10.1609/aimag.v36i3.2601
   Yan K, 2015, SENSOR ACTUAT B-CHEM, V212, P353, DOI 10.1016/j.snb.2015.02.025
   Zhu L, 2019, IEEE ACCESS, V7, P114440, DOI 10.1109/ACCESS.2019.2935833
NR 44
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16623
EP 16655
DI 10.1007/s11042-023-16128-9
EA JUL 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030882700001
DA 2024-07-18
ER

PT J
AU Shwetha, N
   Priyatham, M
   Gangadhar, N
AF Shwetha, N.
   Priyatham, Manoj
   Gangadhar, N.
TI Artificial neural network based channel equalization using battle royale
   optimization algorithm with different initialization strategies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Battle Royale optimization; Finite impulse
   response; Adaptive Channel equalization
ID PARTICLE SWARM OPTIMIZATION; GENETIC ALGORITHM; ANN
AB In digital communication, the transmitted data is affected due to channel distortion. In terms of Inter-Symbol Interference (ISI), the distortion is occurs due to the dispersive nature of channel. The channel equalization technique is used at the receiver end for their reliability and high-speed communication by reducing the effects of ISI. In this paper an effective equalizer based on Artificial Neural Network (ANN) is proposed. The weights of ANN are trained by proposed Battle Royale Optimization (BRO). The objective function of ANN-BRO based equalizer is to minimize Mean Square Error (MSE) values where the error value is estimated based on the transmitted signal and the equalizer output. The BRO is modified by different initialization methods like Random Number Generation (RNG), Opposition based learning (OBL), Quasi-Opposition based learning (QBL), Tent Map and chaotic methods. The experimental results of the proposed equalizer is evaluated and compared with various initialization and optimization approaches. The performance measures such as MSE, Mean Square of the Residual Error (MSRE), and Bit Error Rate (BER) are evaluated to show the efficiency of the proposed method.
C1 [Shwetha, N.] Dr Ambedkar Inst Technol, Dept ECE, Bengaluru, Karnataka, India.
   [Priyatham, Manoj] APS Coll Engn, Dept ECE, Bengaluru, Karnataka, India.
   [Gangadhar, N.] Dr Ambedkar Inst Technol, Dept Mech Engn, Bengaluru, Karnataka, India.
RP Shwetha, N (corresponding author), Dr Ambedkar Inst Technol, Dept ECE, Bengaluru, Karnataka, India.
EM shwethaec48@gmail.com
FU Dr.Ambedkar Institute of Technology, Bangalore; Visvesvaraya
   Technological University, Jnana Sangama, Belagavi
FX This work is supported by Dr.Ambedkar Institute of Technology,
   Bangalore-560056, and Visvesvaraya Technological University, Jnana
   Sangama, Belagavi -590018.
CR Al-Shaikhi AA, 2019, ARAB J SCI ENG, V44, P2177, DOI 10.1007/s13369-018-3387-8
   Farshi TR, 2021, NEURAL COMPUT APPL, V33, P1139, DOI 10.1007/s00521-020-05004-4
   Ghosh G, 2019, INT J ADV MANUF TECH, V100, P1223, DOI 10.1007/s00170-017-1417-4
   Golafshani EM, 2020, CONSTR BUILD MATER, V232, DOI 10.1016/j.conbuildmat.2019.117266
   Ingle KK, 2021, AEU-INT J ELECTRON C, V138, DOI 10.1016/j.aeue.2020.153371
   Ingle KK, 2020, EXPERT SYST APPL, V145, DOI 10.1016/j.eswa.2019.112970
   Jyothi GN, 2020, INT J E-COLLAB, V16, P59, DOI 10.4018/IJeC.2020100105
   Kazimipour B, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2750
   Khatir S, 2020, THEOR APPL FRACT MEC, V107, DOI 10.1016/j.tafmec.2020.102554
   Kundu D., 2017, INT J APPL ENG RES, V12, P12682
   Li Y, 2017, WIREL COMMUN MOB COM
   LUCKY RW, 1965, AT&T TECH J, V44, P547, DOI 10.1002/j.1538-7305.1965.tb01678.x
   Martinek R, 2017, WIRELESS PERS COMMUN, V95, P4001, DOI 10.1007/s11277-017-4036-3
   Mohamad ET, 2017, NEURAL COMPUT APPL, V28, pS393, DOI 10.1007/s00521-016-2359-8
   Mu'azu MA, 2023, AIN SHAMS ENG J, V14, DOI 10.1016/j.asej.2022.101980
   Muthumari M., 2020, ROLE EDGE ANAL SUSTA, P67
   Nanda SJ, 2017, APPL SOFT COMPUT, V57, P197, DOI 10.1016/j.asoc.2017.03.029
   Panda S, 2020, NEURAL PROCESS LETT, V51, P1869, DOI 10.1007/s11063-019-10172-z
   Pathan A, 2021, WIRELESS PERS COMMUN, V116, P1123, DOI 10.1007/s11277-019-06951-5
   Pergoloni S, 2017, J LIGHTWAVE TECHNOL, V35, P1811, DOI 10.1109/JLT.2017.2652070
   Pradhan M, 2018, AIN SHAMS ENG J, V9, P2015, DOI 10.1016/j.asej.2016.08.023
   Punitha S, 2023, IEEE ACCESS, V11, P12378, DOI 10.1109/ACCESS.2023.3236812
   Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200
   Rauf HT, 2020, IEEE ACCESS, V8, P110535, DOI 10.1109/ACCESS.2020.3002725
   Sahu Padma, 2017, International Journal of Computer Information Systems and Industrial Management Applications, V9, P257
   Santamaría I, 2002, IEEE T SIGNAL PROCES, V50, P1184, DOI 10.1109/78.995074
   Sarangi Archana, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P301, DOI 10.1007/978-981-10-7566-7_30
   Shah SM, 2017, NONLINEAR DYNAM, V88, P839, DOI 10.1007/s11071-016-3279-y
   Shen JL, 2020, 2020 54TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), P239, DOI 10.1109/CISS48834.2020.1570617082
   Sinha R., 2017, INT J APPL ENG RES, V12, P3988
   Sun JZ, 2019, INT T ELECTR ENERGY, V29, DOI 10.1002/etep.2660
   Tran-Ngoc H, 2019, ENG STRUCT, V199, DOI 10.1016/j.engstruct.2019.109637
   Varma D. Suneel, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0001, DOI 10.1109/ICCSP.2019.8697932
   Wu GX, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102985
   Xu FY, 2020, NEUROCOMPUTING, V416, P69, DOI 10.1016/j.neucom.2019.04.086
   Ye H, 2017, VEH TECHNOL CONFE
   Zhang X, 2020, OPT EXPRESS, V28, P5058, DOI 10.1364/OE.385370
   Zhao SL, 2013, SIGNAL PROCESS, V93, P2759, DOI 10.1016/j.sigpro.2013.02.012
   Zheng Jiali, 2019, 2019 IEEE 5th International Conference on Computer and Communications (ICCC), P753, DOI 10.1109/ICCC47050.2019.9064286
NR 39
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15565
EP 15590
DI 10.1007/s11042-023-16161-8
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028490600003
DA 2024-07-18
ER

PT J
AU Shafana, ARF
   Silpasuwanchai, C
AF Shafana, Abdul Raheem Fathima
   Silpasuwanchai, Chaklam
TI Investigating the role of gesture modalities and screen size in an AR 3D
   game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Gesture modalities; Screen size
AB In pursuit of immersive Augmented Reality (AR) Games, gesture interaction is considered a promising mode. On the other hand, despite the considerable effect of screen size on user experience and usability in game contexts, the effect is still under-explored in AR game contexts. This, in turn, sparks a specific research interest in the interaction between gesture modalities and screen sizes in AR games. This work contributes to a controlled study investigating the effect of two different gesture modalities (touch and tilt) on varying screen sizes in a custom-made AR game. Competence, engagement, fatigue, and user preference were evaluated using the combined effect of gesture modalities and screen sizes. The results revealed that gesture modalities affect game competence and fatigue while they had no significant impact on user engagement. Further analysis has revealed that touch outperforms tilt for target-selection tasks like destroying enemies while tilt outperforms touch for path-following tasks like turning a character. However, no significant effect was found on screen size, contradicting past studies that suggested that screen size has an effect on engagement, fatigue, and performance. The findings of the study could be useful for AR game designers to further develop usable and engaging AR games.
C1 [Shafana, Abdul Raheem Fathima; Silpasuwanchai, Chaklam] Asian Inst Technol, Dept Informat & Commun Technol, Pathum Thani 12120, Thailand.
   [Shafana, Abdul Raheem Fathima] South Eastern Univ Sri Lanka, Dept Informat & Commun Technol, Oluvil 32360, Sri Lanka.
C3 Asian Institute of Technology; South Eastern University of Sri Lanka
RP Silpasuwanchai, C (corresponding author), Asian Inst Technol, Dept Informat & Commun Technol, Pathum Thani 12120, Thailand.
EM arfshafana@seu.ac.lk; chaklam@ait.asia
OI Shafana, Fathima/0000-0001-6926-9196
CR Aliprantis John., 2019, VIPERC@ IRCDL, P50
   Bai Huidong., 2016, Mobile augmented reality: Free-hand gesture-based interaction
   Bhattacharyya P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300553
   Cairns P, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P371, DOI 10.1145/2556288.2557065
   Cuaresma J, 2014, 2014 IEEE GAMES, MEDIA, ENTERTAINMENT (GEM)
   Daiber F, 2012, P 11 INT C MOB UB MU, P1
   Dong Z, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.927258
   Dongwei Zhao, 2020, 2020 IEEE Power & Energy Society General Meeting (PESGM), DOI 10.1109/PESGM41954.2020.9281516
   Ferrer V., 2013, IEEE, P1
   Furió D, 2015, J COMPUT ASSIST LEAR, V31, P189, DOI 10.1111/jcal.12071
   Furió D, 2013, COMPUT EDUC, V64, P24, DOI 10.1016/j.compedu.2012.12.015
   Gardeli A, 2019, INT CONF GAMES VIRTU, P1, DOI 10.1109/vs-games.2019.8864603
   Goh ES, 2019, IEEE ACCESS, V7, P40581, DOI 10.1109/ACCESS.2019.2906394
   Guarino A, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119614
   Guarino A, 2022, NEURAL COMPUT APPL, V34, P18473, DOI 10.1007/s00521-022-07454-4
   Hinckley K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2869, DOI 10.1145/2858036.2858095
   Hou JH, 2012, COMPUT HUM BEHAV, V28, P617, DOI 10.1016/j.chb.2011.11.007
   Hu WJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208740
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   Hynninen T, 2012, THESIS
   Jain A, 2019, PATTERN RECOGN LETT, V125, P604, DOI 10.1016/j.patrec.2019.06.008
   Karambakhsh A, 2019, INT J INFORM MANAGE, V45, P328, DOI 10.1016/j.ijinfomgt.2018.03.004
   Laine TH, 2016, GAMES CULT, V11, P548, DOI 10.1177/1555412015572006
   Lee CC, 2021, J SUPERCOMPUT, V77, P4831, DOI 10.1007/s11227-020-03458-w
   Marzo A., 2014, Proc. 2nd ACM Symp. Spat. user Interact. - SUI '14, P13, DOI [10.1145/2659766.2659775, DOI 10.1145/2659766.2659775]
   Medryk S, 2013, INT C MULT HUM COMP, P117
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Oshita M., 2012, P WASA 2012 WORKSH S, V1, P27, DOI [10.1145/2425296.2425301, DOI 10.1145/2425296.2425301]
   Raptis D., 2013, Proceedings of the 15th International Conference on Human-Computer Interaction with Mobile Devices and Services, P127, DOI 10.1145/2493190.2493204
   Rigby JM, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P714, DOI 10.1145/2957265.2961843
   Rocha F, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P653, DOI 10.1145/3341215.3356302
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Soares LP, 2018, BRAZIL SYMP GAME DIG, P127, DOI 10.1109/SBGAMES.2018.00024
   Teather RJ, 2014, P 2014 C INT ENT, P1, DOI [10.1145/2677758.2677766, DOI 10.1145/2677758.2677766]
   Teather RJ, 2017, ENTERTAIN COMPUT, V21, P33, DOI 10.1016/j.entcom.2017.04.005
   Terui H, 2022, LECT NOTES COMPUT SC, V13333, P268, DOI 10.1007/978-3-031-05563-8_18
   Wang LR, 2021, COMPUT SECUR, V111, DOI 10.1016/j.cose.2021.102462
   Wibirama S, 2017, IEEE ENG MED BIO, P2454, DOI 10.1109/EMBC.2017.8037353
   Xi W, 2018, GAMIFIN, P100
   Xi WY, 2019, INT J HUM-COMPUT ST, V127, P169, DOI 10.1016/j.ijhcs.2018.09.010
   YI X, 2023, P 2023 CHI C HUM FAC, P1
   Young JC, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTING (ICIC), P355, DOI 10.1109/IAC.2016.7905744
   Yu XH, 2020, IEEE INT WORK SIGN P, DOI 10.1109/spawc48557.2020.9154337
   Zhang YX, 2020, LECT NOTES COMPUT SC, V12242, P363, DOI 10.1007/978-3-030-58465-8_27
NR 45
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18169
EP 18184
DI 10.1007/s11042-023-16052-y
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600003
DA 2024-07-18
ER

PT J
AU Kaur, P
   Harnal, S
   Gautam, V
   Singh, MP
   Singh, SP
AF Kaur, Prabhjot
   Harnal, Shilpi
   Gautam, Vinay
   Singh, Mukund Pratap
   Singh, Santar Pal
TI Performance analysis of segmentation models to detect leaf diseases in
   tomato plant
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mask R-CNN; Semantic segmentation; Tomato leaf disease; Classification
ID IMAGES
AB In agriculture around 22% of crop yield loss is due to living and non-living organisms such as biotic and abiotic stress/disease. The early-stage diagnosis of these stresses is an important issue for farmers through naked eyes. Using computer vision technologies can detect the pattern and clustering of diseases at an early stage. However, in recent times, deep learning technologies based on computer vision is helpful for the diagnosis of biotic stress (single biotic and multi biotic) in tomato plant leaves. In this work, the PlantVillage dataset is gathered for the segmentation of object detection. The labeled, enhanced and augmented data has been used for training the model. The proposed hybrid Deep Segmentation Convolutional Neural Network (Hybrid-DSCNN) model has been segmenting the diseased objects in the tomato plant. This Hybrid-DSCNN is assembled using U-Net and Seg-Net pre-trained models with instance segmentation for better detection of objects. The semantic segmented data has been recognized for the single and multiple leaf diseases for identification and classification in this work. A comparison of the predicted Hybrid-DSCNN model's output has been made with other modified U-Net, M-SegNet, and modified U-SegNet in terms of Accuracy, Precision, Recall, and Intersection over Union (IoU), and mean Intersection over Union (mIoU). The proposed model processed 1004 images in 30 ns,which is better than other compared models. The accuracy achieved using the proposed model is 98.24%, which is far better than other modified segmentation models.
C1 [Kaur, Prabhjot; Harnal, Shilpi; Gautam, Vinay] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Singh, Mukund Pratap] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
   [Singh, Santar Pal] Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
C3 Chitkara University, Punjab
RP Singh, SP (corresponding author), Rashtrakavi Ramdhari Singh Dinkar Coll Engn, Dept Comp Sci & Engn, Begusarai, India.
EM spsingh78@gmail.com
RI Kaur, Prabhjot/JXN-0073-2024; Gautam, Vinay/ABF-6124-2020; Harnal,
   Shilpi/JVM-8172-2024; Singh, Mukund Pratap/GRX-7429-2022
OI Gautam, Vinay/0000-0002-0258-5132; Singh, Mukund
   Pratap/0000-0001-5877-9510; Kaur, Prabhjot/0000-0002-3539-0622
CR Abayomi-Alli OO, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12746
   Agarwal M, 2020, SUSTAIN COMPUT-INFOR, V28, DOI 10.1016/j.suscom.2020.100407
   Annrose J, 2021, SOYBEAN PLANT DIS CL
   [Anonymous], 2011, Int J Image Process
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Chen SY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062077
   Chen X, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105730
   Cheng L, 2023, MULTIMED TOOLS APPL, V82, P3101, DOI 10.1007/s11042-022-13568-7
   Dayananda C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103363
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162
   He K., 2017, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hughes D., 2015, ABS151108060 CORR
   Jain A, 2019, BIOENGINEERED, V10, P409, DOI 10.1080/21655979.2019.1649520
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Kaur Prabhjot, 2021, Proceedings of 3rd International Conference on Computing Informatics and Networks. ICCIN 2020. Lecture Notes in Networks and Systems (LNNS 167), P597, DOI 10.1007/978-981-15-9712-1_51
   Kaur P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020575
   Kaur P, 2021, MATER TODAY-PROC, V45, P4377, DOI 10.1016/j.matpr.2020.11.198
   Khan S, 2020, J KING SAUD U COMPUT
   Kumar D, 2022, MULTIMED TOOLS APPL, V81, P10143, DOI 10.1007/s11042-022-12160-3
   Kumar N, 2022, QUAL TECHNOL QUANT M, V19, P1, DOI 10.1080/16843703.2021.1972515
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Mathulaprangsan Seksan, 2021, 2021 9 INT C OR TECH, P1, DOI [10.1109/ICOT54518.2021.9680655, DOI 10.1109/ICOT54518.2021.9680655]
   Muni A, 2022, INTELL AUTOM SOFT CO, V31, P1157, DOI 10.32604/iasc.2022.020174
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Nazari K, 2022, J SCI FOOD AGR, V102, P6907, DOI 10.1002/jsfa.12052
   Panigrahi K.P., 2020, PROGR COMPUTING ANAL, V1119, P659, DOI [DOI 10.1007/978, 10.1007/978-981-15-2414-1_66, DOI 10.1007/978-981-15-2414-1_66]
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Rehman ZU, 2021, IET IMAGE PROCESS, V15, P2157, DOI 10.1049/ipr2.12183
   Revathi P., 2014, Int. J. Eng. Sci. Technol., V3, P22
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Salih T.A., 2020, Open Access Libr. J., V7, P12, DOI [DOI 10.4236/OALIB.1106296, 10.4236/oalib.1106296]
   Sammany M, 2007, LECT NOTES ARTIF INT, V4585, P639, DOI 10.1007/978-3-540-73451-2_67
   Sasaki Y., 1999, Journal of the Japanese Society of Agricultural Machinery, V61, P119
   Sharma Parul, 2020, Information Processing in Agriculture, V7, P566, DOI 10.1016/j.inpa.2019.11.001
   Thangaraj R, 2021, J PLANT DIS PROTECT, V128, P73, DOI 10.1007/s41348-020-00403-0
   Uguz S, 2021, NEURAL COMPUT APPL, V33, P4133, DOI 10.1007/s00521-020-05235-5
   Vieira J, 2023, MULTIMED TOOLS APPL, V82, P3581, DOI 10.1007/s11042-022-12048-2
   Yadav S, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2021.101247
   Yamanakkanavar N, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104761
   Zou KL, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106242
NR 48
TC 2
Z9 2
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16019
EP 16043
DI 10.1007/s11042-023-16238-4
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200017
DA 2024-07-18
ER

PT J
AU Atiya, SU
   Ramesh, NVK
   Reddy, BNK
AF Atiya, Shaik Ummay
   Ramesh, N. V. K.
   Reddy, B. Naresh Kumar
TI Classification of non-small cell lung cancers using deep convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural networks; Dual state transfer learning;
   Non-small cell carcinomas lung cancers; Restnet50; Chest CT scan image
ID PULMONARY NODULES; CT
AB Lung cancer is a major cause of cancer-related deaths worldwide, and early detection is crucial in reducing mortality rates. To aid in this effort, researchers have been exploring various deep-learning techniques to enhance computer-aided systems that utilize computed tomography in lung cancer screening. One such technique is transfer learning, which allows for the use of pre-trained models to reduce the need for extensive training data. However, deep convolutional neural networks (DCNNs), which are commonly used in deep learning, can be challenging to train due to over-fitting, and effective training requires substantial amounts of data. To address these limitations, the authors propose a dual-state transfer learning method using a deep CNN-based approach. This method aims to develop an efficient training model that reduces variance and avoids over-fitting, while accurately classifying and detecting lung cancer types such as adenocarcinoma, squamous cell carcinoma, and small cell carcinoma, using CT-scanned chest images. In order to achieve effective results, the authors utilized pre-trained models such as the DCNN, VGG16, Inceptionv3, and RestNet50. Metrics like the f1-score, recall, precision, and accuracy were used to evaluate the performance of the proposed model. During training, the ResNet50 model achieved an accuracy of 94% using dual-state transfer learning, while during validation and testing it achieved 92.57% and 96.12% accuracy, respectively. In classification tasks, the DSTL model based on Deep CNNs also surpassed state-of-the-art models. To summarize, the precision and effectiveness of screening and detecting lung cancer can be improved by utilizing dual-state transfer learning methods and deep CNN-based approaches.
C1 [Atiya, Shaik Ummay; Ramesh, N. V. K.] KLEF, Dept Elect & Commun Engn, Guntur, India.
   [Reddy, B. Naresh Kumar] Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli, Tamil Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Reddy, BNK (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Elect & Commun Engn, Tiruchirappalli, Tamil Nadu, India.
EM Naresh.nitg@gmail.com
RI ramesh, Dr.N V K/T-3770-2018
CR Agarap A. F., 2018, ARXIV
   Akinbo SRA, 2021, ARTIF INTELL, DOI [10.5772/intechopen.100602, DOI 10.5772/INTECHOPEN.100602]
   Alam M, 2018, J AM ACAD DERMATOL, V78, P560, DOI 10.1016/j.jaad.2017.10.007
   Altaf F, 2019, IEEE ACCESS, V7, P99540, DOI 10.1109/ACCESS.2019.2929365
   [Anonymous], CHEST CT SCAN IMAGES
   Aydin N, 2021, CURR MED IMAGING, V17, P1137, DOI 10.2174/1573405617666210204210500
   Boudrioua MS, 2020, SSRN ELECT J, DOI [10.2139/ssrn.3630150, DOI 10.2139/SSRN.3630150]
   Carimatto A., 2021, Proceedings of SPIE - Progress in Biomedical Optics and Imaging, V11647, DOI 10.1117/12.2577482
   Chen GL, 2019, MED BIOL ENG COMPUT, V57, P1567, DOI 10.1007/s11517-019-01976-1
   Cheng L, 2019, LECT NOTES COMPUT SC, V11935, P273, DOI 10.1007/978-3-030-36189-1_23
   Gartenschlager M, 1998, EUR RADIOL, V8, P609, DOI 10.1007/s003300050445
   Gong J, 2020, EUR RADIOL, V30, P1847, DOI 10.1007/s00330-019-06533-w
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iaccarino JM, 2019, PREV MED, V121, P24, DOI 10.1016/j.ypmed.2019.02.016
   Kalemkerian GP, 2013, J NATL COMPR CANC NE, V11, P78, DOI 10.6004/jnccn.2013.0011
   Kanmani M, 2019, INT J BIOMED ENG TEC, V31, P278
   Karabulut N, 2002, EUR RADIOL, V12, P2764, DOI 10.1007/s00330-002-1368-4
   Katar O, 2021, AVRUPA BILIM TEKNOLO, DOI [DOI 10.31590/EJOSAT.1021030, 10.31590/ejosat.1021030]
   Kawagishi M, 2017, INT J COMPUT ASS RAD, V12, P767, DOI 10.1007/s11548-017-1554-0
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Akhil, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (90), P541, DOI 10.1007/978-981-16-6289-8_45
   Larke FJ, 2011, AM J ROENTGENOL, V197, P1165, DOI 10.2214/AJR.11.6533
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Luo ZL, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.633446
   Mao KM, 2018, COMPLEXITY, DOI 10.1155/2018/3078374
   Miller R, 2020, LUNG CANCER, V139, pS6
   Monkam P, 2019, IEEE ACCESS, V7, P78075, DOI 10.1109/ACCESS.2019.2920980
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   NIH, 2020, About us
   Nishio M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200721
   Palmer C, 2020, ENGINEERING-PRC, V6, P854, DOI 10.1016/j.eng.2020.06.010
   Pang SC, 2019, MED BIOL ENG COMPUT, V57, P107, DOI 10.1007/s11517-018-1819-y
   Phillips T, 2015, APPL IMMUNOHISTO M M, V23, P541, DOI 10.1097/PAI.0000000000000256
   Popper H, 2020, ESSENTIALS DIAGNOSTI, P95, DOI [10.1007/978-3-030-22664-0_7, DOI 10.1007/978-3-030-22664-0_7]
   Sadhwani A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95747-4
   Salem FM., 2022, Recurrent Neural Networks. From Simple to Gated Architectures, DOI [10.1007/978-3-030-89929-5, DOI 10.1007/978-3-030-89929-5]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitaula C, 2021, APPL INTELL, V51, P2850, DOI 10.1007/s10489-020-02055-x
   Smith K.A., 2000, New Directions for Teaching and Learning, V81, P25, DOI DOI 10.1002/TL.8103
   Srivatsan Sanjay, 2021, bioRxiv, DOI 10.1101/2020.04.22.056283
   Teramoto A, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4067832
   Tlemsani C, 2020, CELL REP, V33, DOI 10.1016/j.celrep.2020.108296
   Travis WD., 1999, HISTOLOGICAL TYPING, DOI [10.1007/978-3-642-60049-4, DOI 10.1007/978-3-642-60049-4]
   van der Velden BHM, 2022, MED IMAGE ANAL, V79, DOI 10.1016/j.media.2022.102470
   Velugoti S., 2022, International Journal of Computer Engineering in Research Trends, V9, P114
   Wang SD, 2019, CANCERS, V11, DOI 10.3390/cancers11111673
   Weng S, 2017, J BIOMED OPT, V22, DOI 10.1117/1.JBO.22.10.106017
   Xie H, 2022, J TRANSL MED, V20, DOI 10.1186/s12967-022-03732-w
   Xie Y, 2017, MED IMAGE COMPUTING, V10435, DOI [10.1007/978, DOI 10.1007/978]
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yang SM, 2023, IEEE T INTELL TRANSP, V24, P13011, DOI 10.1109/TITS.2022.3232231
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Yu KH, 2020, J AM MED INFORM ASSN, V27, P757, DOI 10.1093/jamia/ocz230
   Zhao DZ, 2021, ENVIRON SCI POLLUT R, V28, P56892, DOI 10.1007/s11356-021-14632-9
NR 59
TC 0
Z9 0
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13261
EP 13290
DI 10.1007/s11042-023-16119-w
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700008
DA 2024-07-18
ER

PT J
AU Gopi, PSS
   Karthikeyan, M
AF Gopi, P. S. S.
   Karthikeyan, M.
TI Red fox optimization with ensemble recurrent neural network for crop
   recommendation and yield prediction model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Precision agriculture; Crop recommendation; Yield prediction; Deep
   learning; Hyperparameter tuning; Recurrent neural network; Machine
   learning
AB Precision agriculture concentrates on monitoring (sensing technologies), management information system, variable rate technologies, and responses to inter- and intravariability in cropping systems. The advantages of precision agriculture involve improving crop productivity and crop quality with minimum environmental impact. Crop yield prediction (CYP) is one of the challenging tasks in agriculture, which mainly depends upon soil, meteorological, environmental, and crop-related variables. On the other hand, farmers usually follow conventional farming patterns to decide on crops to be cultivated in a field. An automated crop recommendation system is required to assist farmers in making informed decisions prior to crop cultivation. Deep learning (DL) and Machine learning (ML) methods provide a practical approach for enhanced crop production and yield prediction using different features. Therefore, this study focuses on the design of Red Fox Optimization with Ensemble Recurrent Neural Network for Crop Recommendation and Yield Prediction (RFOERNN-CRYP) model. The presented RFOERNN-CRYP model follows an ensemble learning process, which makes use of three different DL models (namely long short-term memory (LSTM), bidirectional LSTM (BiLSTM), and gated recurrent unit (GRU)) for accomplishing enhanced prediction performance compared to the individual classifier models. Moreover, the RFO algorithm is applied for the hyperparameter selection of the three DL models to improve the overall performance, showing the novelty of the work. The experimental validation of the RFOERNN-CRYP technique is validated on crop recommendation and yield prediction datasets from the Kaggle repository. The experimental outcomes showed that the proposed model outperforms the other recent approaches regarding several measures. The presented RFOERNN-CRYP technique assists farmers in the decision-making process using different agro parameters.
C1 [Gopi, P. S. S.; Karthikeyan, M.] Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Chidambaram, Tamilnadu, India.
C3 Annamalai University
RP Gopi, PSS (corresponding author), Annamalai Univ, Fac Sci, Dept Comp & Informat Sci, Chidambaram, Tamilnadu, India.
EM gopipss@gmail.com; karthiaucse@gmail.com
CR Abbas F, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10071046
   Agarwal Sonal, 2021, Journal of Physics: Conference Series, V1714, DOI 10.1088/1742-6596/1714/1/012012
   Aggarwal K., 2022, IRAQI J COMPUT SCI M, V3, P115, DOI [DOI 10.52866/IJCSM.2022.01.01.013, 10.52866/ijcsm.2022.01.01.013]
   Bondre D.A., 2019, IJEAST, V4, P371, DOI [10.33564/IJEAST.2019.v04i05.055, DOI 10.33564/IJEAST.2019.V04I05.055]
   Colombo-Mendoza LO, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12041940
   Dash R, 2021, RESULTS ENG, V9, DOI 10.1016/j.rineng.2021.100203
   Doshi Z, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Elavarasan D, 2021, NEURAL COMPUT APPL, V33, P13205, DOI 10.1007/s00521-021-05950-7
   Elavarasan D, 2020, AGRICULTURE-BASEL, V10, DOI 10.3390/agriculture10090400
   Elavarasan D, 2020, IEEE ACCESS, V8, P86886, DOI 10.1109/ACCESS.2020.2992480
   Fan JS, 2022, AAAI CONF ARTIF INTE, P11873
   Gopal PSM, 2019, APPL ARTIF INTELL, V33, P621, DOI 10.1080/08839514.2019.1592343
   Gopal PSM, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104968
   Khaki S, 2020, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.01750
   Khaki S, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00621
   Khorami E, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/4454507
   Khosla E, 2020, ENVIRON DEV SUSTAIN, V22, P5687, DOI 10.1007/s10668-019-00445-x
   Mythili K., 2021, Annals of the Romanian Society for Cell Biology, V25, P4783
   Nevavuori P, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104859
   Nishant P.S., 2020, 2020 INT C EM TECHN, P1, DOI [10.1109/INCET49848.2020.9154036, DOI 10.1109/INCET49848.2020.9154036]
   Palanivel K., 2019, Int. J. Computer Eng. Technol., V10, P110, DOI [DOI 10.34218/IJCET.10.3.2019.013, 10.34218/IJCET.10.3.2019.013]
   Paudel D, 2021, AGR SYST, V187, DOI 10.1016/j.agsy.2020.103016
   Shah Avnika, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P952, DOI 10.1109/ICAIS50930.2021.9395849
   Shahin AI, 2021, FRACTAL FRACT, V5, DOI 10.3390/fractalfract5040175
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shook J, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0252402
   Shuai GY, 2022, REMOTE SENS ENVIRON, V272, DOI 10.1016/j.rse.2022.112938
   Suresh G., 2021, Int. J. Modern Agric., V10, P906
   Tang YD, 2016, INT CONF ACOUST SPEE, P6125, DOI 10.1109/ICASSP.2016.7472854
   van Klompenburg T, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105709
   Wang YY, 2019, APPL SOFT COMPUT, V77, P188, DOI 10.1016/j.asoc.2019.01.015
   Zhang WT, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142749
NR 32
TC 5
Z9 5
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13159
EP 13179
DI 10.1007/s11042-023-16113-2
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700004
DA 2024-07-18
ER

PT J
AU Li, SG
   Wei, YF
   Yu, ZX
AF Li, Shugang
   Wei, Yanfang
   Yu, Zhaoxu
TI Research on the influence mechanism of key halo effect and Matthew
   effect on product online word-of-mouth: considering the moderating role
   of online store service quality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Halo effect; Matthew effect; Online word-of-mouth (OWM); Online reviews;
   Text mining
ID CUSTOMER SATISFACTION; BRAND IMAGE; COMMERCE; REVIEWS; SALES; LOYALTY;
   PRICE; COMMUNICATION; ATTRIBUTES; PREFERENCE
AB The company benefits greatly from online word-of-mouth (OWM) for its products through e-commerce platforms. However, previous research neglects the critical influence mechanism of OWM for products sold in online stores, especially the relationships between consumers' past subjective impressions and OWM. This study innovatively explores the influence mechanism of key halo effect and Matthew effect on product OWM considering the moderating role of online store PSQ namely store trust. We propose a research model and influencing factors for the halo effect and Matthew effect in the e-commerce platform scenario. Collecting about 30,000 online reviews and 160,000 historical consumer reviews from Amazon, we use a semantic similarity model to match online reviews with a standard scale for the relevant variables, combining text mining and econometric analysis. Our results show that the selected hierarchical regression model has better fit than existing common models. And the halo effect and Matthew effect are indeed beneficial to increase product OWM including the indicators of consumer satisfaction and future consumption intention. And there is a reverse effect with low perceived service quality and star rating Matthew effect on product OWM is not supported. These findings help us understand consumers' online comment behaviors, and have deep implications for e-commerce platforms and related companies.
C1 [Li, Shugang; Wei, Yanfang] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Wei, YF (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
EM luck_li@shu.edu.cn; weiyanfang@shu.edu.cn; yyzx@ecust.edu.cn
OI Wei, Yanfang/0000-0001-5900-7598; Yu, Zhaoxu/0000-0002-2375-0213
FU Chinese National Natural Science Foundation [71871135, 72271155]
FX AcknowledgmentsThe authors declare no conflict of interest and this
   research was supported by the Chinese National Natural Science
   Foundation (No. 71871135 and 72271155).
CR Ahmadinejad, 2019, SCIREA J MANAGEMENT, V3, P40
   Alfoqahaa S, 2018, J RES MARK ENTREP, V20, P170, DOI 10.1108/JRME-05-2016-0014
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Askalidis G, 2017, DECIS SUPPORT SYST, V97, P23, DOI 10.1016/j.dss.2017.03.002
   Aw ECX, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2019.101991
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Berahmand K, 2019, COMPUTING, V101, P1711, DOI 10.1007/s00607-018-0684-8
   Berahmand K, 2018, CHAOS SOLITON FRACT, V110, P41, DOI 10.1016/j.chaos.2018.03.014
   Berahmand K, 2018, INT J MOD PHYS B, V32, DOI 10.1142/S0217979218501424
   Burton S, 2015, J ACAD MARKET SCI, V43, P240, DOI 10.1007/s11747-014-0378-5
   Byun KA, 2020, J BUS RES, V116, P163, DOI 10.1016/j.jbusres.2020.05.010
   Ceyhan A., 2019, EMERGING MARKETS J, V9, P88, DOI [DOI 10.5195/EMAJ.2019.173, https://doi.org/10.5195/emaj.2019.173]
   Chalkidis I, 2019, ARTIF INTELL LAW, V27, P171, DOI 10.1007/s10506-018-9238-9
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen S, 2023, INT J LOGIST-RES APP, V26, P917, DOI [10.1080/13675567.2021.1998398, 10.1109/ICMLC54886.2021.9737258]
   Chen YF, 2008, COMPUT HUM BEHAV, V24, P1977, DOI 10.1016/j.chb.2007.08.004
   Chen YB, 2008, MANAGE SCI, V54, P477, DOI 10.1287/mnsc.1070.0810
   Cheong JW, 2020, ASIA PAC J MARKET LO, V32, P1519, DOI 10.1108/APJML-03-2019-0192
   Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345
   CORTINA JM, 1993, J MANAGE, V19, P915, DOI 10.1177/014920639301900411
   Cuesta-Valiño P, 2022, TECHNOL FORECAST SOC, V175, DOI 10.1016/j.techfore.2021.121382
   Dai HY, 2022, INT J ELECTRON COMM, V26, P311, DOI 10.1080/10864415.2022.2076196
   Dawson JF, 2006, J APPL PSYCHOL, V91, P917, DOI 10.1037/0021-9010.91.4.917
   Alonso-Almeida MD, 2014, IND MANAGE DATA SYST, V114, P387, DOI 10.1108/IMDS-06-2013-0278
   Delgado-Ballester E, 2005, J PROD BRAND MANAG, V14, P187, DOI 10.1108/10610420510601058
   Dong D, 2017, ASIAN J COMMUN, V27, P213, DOI 10.1080/01292986.2016.1257034
   Fan Feng-Lei, 2021, IEEE Trans Radiat Plasma Med Sci, V5, P741, DOI [10.1109/trpms.2021.3066428, 10.1109/TRPMS.2021.3066428]
   Guo XL, 2011, J CONSUM MARK, V28, P269, DOI 10.1108/07363761111143169
   Ha J, 2015, INFORM SCIENCES, V290, P45, DOI 10.1016/j.ins.2014.08.042
   Hafizi M., 2017, IRAN J EDUC SOCIOL, V1, P95
   Hamer L., 2006, Journal of Services Marketing, V20, P219, DOI [10.1108/08876040610674571, DOI 10.1108/08876040610674571]
   Hassenzahl M, 2008, INTERACT COMPUT, V20, P473, DOI 10.1016/j.intcom.2008.05.001
   Hsieh AT, 2008, MARK INTELL PLAN, V26, P26, DOI 10.1108/02634500810847138
   Iversen NM, 2008, EUR J MARKETING, V42, P603, DOI 10.1108/03090560810862534
   Judge TA, 2008, J APPL PSYCHOL, V93, P849, DOI 10.1037/0021-9010.93.4.849
   Kaushik K, 2018, J RETAIL CONSUM SERV, V45, P21, DOI 10.1016/j.jretconser.2018.08.002
   Kim J, 2016, COMPUT HUM BEHAV, V64, P393, DOI 10.1016/j.chb.2016.07.008
   Kocór M, 2017, BRIT J EDUC STUD, V65, P239, DOI 10.1080/00071005.2016.1265642
   Konuk FA, 2019, J RETAIL CONSUM SERV, V50, P103, DOI 10.1016/j.jretconser.2019.05.005
   Kousha K, 2016, J ASSOC INF SCI TECH, V67, P566, DOI 10.1002/asi.23404
   Kumpel AS, 2020, JOURNALISM, V21, P1083, DOI 10.1177/1464884920915374
   Kulshreshtha K, 2017, J CREAT COMMUN, V12, P205, DOI 10.1177/0973258617722422
   Lee D.H., 2020, Asia Pac. J. Mark. Logist., V32, P793
   Lee MKO, 2011, INFORM MANAGE-AMSTER, V48, P185, DOI 10.1016/j.im.2010.08.005
   Leon RD, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102237
   Li WM, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102818
   Liao CH, 2021, J INFORMETR, V15, DOI 10.1016/j.joi.2020.101108
   Lien CH, 2015, ASIA PAC MANAG REV, V20, P210, DOI 10.1016/j.apmrv.2015.03.005
   Liu Y, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221079922
   Loaiza-Ramírez JP, 2022, CLEAN LOGIST SUPPL C, V3, DOI 10.1016/j.clscn.2021.100027
   Martínez-González JA, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031425
   Meng J, 2022, TELEMAT INFORM, V70, DOI 10.1016/j.tele.2022.101807
   MERTON RK, 1968, SCIENCE, V159, P56, DOI 10.1126/science.159.3810.56
   Mishra A, 2022, INT J INFORM MANAGE, V67, DOI 10.1016/j.ijinfomgt.2021.102413
   Moro S, 2019, INT J INFORM MANAGE, V44, P88, DOI 10.1016/j.ijinfomgt.2018.09.015
   Murali S, 2016, J RETAIL CONSUM SERV, V30, P67, DOI 10.1016/j.jretconser.2016.01.001
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Nunkoo R, 2020, INT J HOSP MANAG, V91, DOI 10.1016/j.ijhm.2019.102414
   Ong BS., 2011, J PROMOTION MANAGEME, V17, P207, DOI [10.1080/10496491.2011.553789, DOI 10.1080/10496491.2011.553789]
   Park DH, 2008, ELECTRON COMMER R A, V7, P399, DOI 10.1016/j.elerap.2007.12.001
   Razak M, 2020, J ASIA BUS STUD, V14, P307, DOI 10.1108/JABS-01-2019-0030
   Rita P, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02690
   Rosario AB, 2016, J MARKETING RES, V53, P297, DOI 10.1509/jmr.14.0380
   Sahoo N, 2012, INFORM SYST RES, V23, P231, DOI 10.1287/isre.1100.0336
   Sanrey C, 2021, BRIT J EDUC PSYCHOL, V91, P658, DOI 10.1111/bjep.12385
   Saygili M, 2021, MANAG-J CONTEMP MANA, V26, P179, DOI 10.30924/mjcmi.26.2.10
   Sharma SS, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102412
   Sine WD, 2003, MANAGE SCI, V49, P478, DOI 10.1287/mnsc.49.4.478.14416
   Van Dusen B, 2019, PHYS REV PHYS EDUC R, V15, DOI 10.1103/PhysRevPhysEducRes.15.020108
   Wan Y, 2018, ELECTRON COMMER RES, V18, P291, DOI 10.1007/s10660-017-9258-7
   Wan Y, 2015, ELECTRON MARK, V25, P313, DOI 10.1007/s12525-015-0186-x
   Wang JN, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2020.103281
   Wang Y., 2003, MANAG SERV QUAL, V13, P72, DOI DOI 10.1108/09604520310456726
   Wattanacharoensil W, 2019, TOURISM MANAGE, V75, P353, DOI 10.1016/j.tourman.2019.06.006
   Wen J, 2021, J TRAVEL RES, V60, P846, DOI 10.1177/0047287520912330
   Wirtz J, 2003, INT J SERV IND MANAG, V14, P96, DOI 10.1108/09564230310466001
   WIRTZ J, 1995, INT J SERV IND MANAG, V6, P84, DOI 10.1108/09564239510091358
   Wirtz J., 2001, Managing Service Quality, V11, P99, DOI [DOI 10.1108/09604520110387239, 10.1108/09604520110387239]
   Woo H, 2019, ASIA PAC J MARKET LO, V31, P773, DOI 10.1108/APJML-05-2018-0173
   Xu HY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102862
   Yeung R. M. W., 2001, British Food Journal, V103, P170, DOI 10.1108/00070700110386728
   Yin DZ, 2014, MIS QUART, V38, P539, DOI 10.25300/MISQ/2014/38.2.10
   Yu Y, 2016, PROC CIRP, V52, P179, DOI 10.1016/j.procir.2016.08.002
   Zhang C, 2022, IEEE T INTELL TRANSP, V23, P12877, DOI [10.1109/TITS.2021.3118206, 10.1109/TDSC.2022.3208706]
   Zhou Chunting, 2015, ARXIV
   Zhou T, 2009, INFORM SYST MANAGE, V26, P327, DOI 10.1080/10580530903245663
   Zhou YS, 2022, ELECTRON COMMER R A, V52, DOI 10.1016/j.elerap.2022.101125
NR 89
TC 1
Z9 1
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13045
EP 13072
DI 10.1007/s11042-023-16124-z
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001017926800001
DA 2024-07-18
ER

PT J
AU Mandalapu, SR
   Narayanan, B
   Putheti, S
AF Mandalapu, Srinivasa Rao
   Narayanan, B.
   Putheti, Sudhakar
TI A hybrid collaborative filtering mechanism for product recommendation
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative Filtering; Customer Choice; Feature Extraction and
   Classification; Recommendation System; Toppest and Lowest Rating
ID BEETLE ANTENNAE SEARCH
AB The collaborative model is the needed framework to find a good product in both user- and budget-friendly. These collaborative filtering models have provided product recommendations based on the ratings. Recently, neural networks such as Convolution neural models, recurrent neural networks, boosting models and optimization procedures were implemented for the recommendation system to find the accurate product rating. But, due to the vast amount of data, less accuracy score was reported for finding the book ratings. Considering these issues, the collaborative filtering model has been introduced in the recommendation system. However, this collaborative filtering is only effective for small data, and large data requires additional intelligent models that have maximized the error rate. So, the current research article has aimed to design a novel chimp-based Deep Neural Collaborative Filtering (CbDNCF) for the recommendation system. Initially, the dataset was filtered in a preprocessing layer of the novel CbDNCF. Consequently, the noiseless data is trained in the classification layer. Further, the feature extraction and highest rating prediction process were performed. Incorporating the Chimp functions in the deep neural classification layer has afforded the finest forecasting outcomes. Consequently, the designed model is tested using the Python programming language with book product datasets. Its robustness is measured by measuring the key metrics with other existing models. Hence, the planned approach has earned good prediction results of 97.7% accuracy and the lowest error rate of 0.02%, which is quite better than the associated models.
C1 [Mandalapu, Srinivasa Rao; Narayanan, B.] Annamalai Univ, Dept Comp Sci & Engn, Chidambaram 608002, Tamil Nadu, India.
   [Putheti, Sudhakar] VVIT, Dept Comp Sci & Engn, Nambur 522508, Andhra Pradesh, India.
C3 Annamalai University
RP Mandalapu, SR (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Chidambaram 608002, Tamil Nadu, India.
EM sree.mandalapu.sree@gmail.com; narayanan.bk@gmail.com;
   sudhakarp0101@gmail.com
RI Mandalapu, Srinivasa Rao/AGP-1337-2022
OI Mandalapu, Srinivasa Rao/0000-0002-0846-2758
CR Afoudi Y, 2021, SIMUL MODEL PRACT TH, V113, DOI 10.1016/j.simpat.2021.102375
   Ahmadian M, 2023, KNOWL-BASED SYST, V263, DOI 10.1016/j.knosys.2023.110289
   Bedi Pradeep, 2022, Advanced Computing and Intelligent Technologies: Proceedings of ICACIT 2021. Lecture Notes in Networks and Systems (218), P279, DOI 10.1007/978-981-16-2164-2_23
   Bhalse N., 2021, MATER TODAY-PROC
   Chen YC, 2021, J SUPERCOMPUT, V77, P244, DOI 10.1007/s11227-020-03266-2
   Chinchanachokchai S, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2021.102528
   Chiu MC, 2021, COMPUT IND, V128, DOI 10.1016/j.compind.2021.103421
   Cui ZH, 2020, IEEE T SERV COMPUT, V13, P685, DOI 10.1109/TSC.2020.2964552
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Hamid RA, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100337
   Hiriyannaiah S, 2023, MULTIMED TOOLS APPL, V82, P8709, DOI 10.1007/s11042-021-11551-2
   Islam R, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3779, DOI 10.1145/3442381.3449904
   Khan AT, 2022, J COMPUT SCI-NETH, V60, DOI 10.1016/j.jocs.2022.101556
   Khan AT, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3073-5
   Khan AT, 2021, NEUROCOMPUTING, V447, P294, DOI 10.1016/j.neucom.2021.03.027
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Li SG, 2022, MULTIMED TOOLS APPL, V81, P16219, DOI 10.1007/s11042-022-12491-1
   Li TH, 2021, TRANSPORT POLICY, V100, P68, DOI 10.1016/j.tranpol.2020.10.008
   Lieto A, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107166
   Liu ZC, 2021, J MANUF SYST, V58, P348, DOI 10.1016/j.jmsy.2020.12.019
   Nair AM, 2022, IOT ANAL SENS NETW, P489, DOI [10.1007/978-981-16-2919-8_44, DOI 10.1007/978-981-16-2919-8_44]
   Nitu P, 2021, BIG DATA MIN ANAL, V4, P139, DOI 10.26599/BDMA.2020.9020026
   Papadakis H, 2022, KNOWL INF SYST, V64, P35, DOI 10.1007/s10115-021-01628-7
   Rajendran D.P. D., 2021, International Journal of Information Management Data Insights, V1, P100027, DOI [10.1016/j.jjimei.2021.100027, DOI 10.1016/J.JJIMEI.2021.100027]
   Schauerte R, 2021, J CULT ECON, V45, P263, DOI 10.1007/s10824-020-09389-x
   Sharma RS, 2021, ELECTRON MARK, V31, P243, DOI 10.1007/s12525-021-00478-z
   Srinidhi CL, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101813
   Tan QM, 2021, J COMPUT SCI TECH-CH, V36, P944, DOI 10.1007/s11390-021-0102-0
   Thakker U, 2021, MULTIMED TOOLS APPL, V80, P28647, DOI 10.1007/s11042-021-10965-2
   Wang F, 2022, IEEE T COMPUT SOC SY, V9, P986, DOI 10.1109/TCSS.2021.3064213
   Wang Y, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114074
   Yu X, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102691
   Yue WB, 2021, IEEE-CAA J AUTOMATIC, V8, P701, DOI 10.1109/JAS.2021.1003919
NR 33
TC 0
Z9 0
U1 6
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12775
EP 12798
DI 10.1007/s11042-023-16056-8
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300001
DA 2024-07-18
ER

PT J
AU Zhang, M
   Jian, MW
   Wang, GG
AF Zhang, Miao
   Jian, Muwei
   Wang, Gaige
TI YOLO-AA: an efficient object detection model via strengthening fusion
   context information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; YOLOv4; Attention mechanism; Object Detection
ID CONVOLUTIONAL NETWORKS
AB Recently, deep learning-based object detection method has achieved remarkable success. Among them, YOLOv4 has attracted increasing attention with its high accuracy and real-time performance. However, the grasp of contextual semantic information is often unsatisfactory, which is mainly caused by the internal details of the network. To address this issue, we propose an efficient model YOLO-AA (YOLO Model Based on Attention and Atrous Spatial Pyramid Pooling) that enhances the fusion of contextual information. First, we mark the object area a certain degree of attention in different nodes of network propagation, so that it will be conducive to pay more attention to instrumental information; Secondly, considering the issue of parameter and computational complexity, the neck region was optimized, so that the improved model can achieve similar or even better results than the original algorithm with fewer parameter quantities; Then, inspired by the semantic segmentation model DeepLabv3 + , we replace the pooling operation in the Spatial Pyramid Pooling (SPP) module by introducing Depth-wise Separable Convolutions with different dilation rates, with the aim of reflecting multi-scale contextual semantic relationships. Experimental results show that our model has fewer parameters (with 22.83% reduction) while producing higher accuracy (9.02% and 16.89% improvement on the two distinct datasets) compared with the original YOLOv4, which is also competitive to some other representative algorithms.
C1 [Zhang, Miao; Wang, Gaige] Ocean Univ China, Sch Comp Sci & Technol, Qingdao, Peoples R China.
   [Jian, Muwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Jian, Muwei] Linyi Univ, Sch Informat Sci & Technol, Linyi, Peoples R China.
C3 Ocean University of China; Shandong University of Finance & Economics;
   Linyi University
RP Wang, GG (corresponding author), Ocean Univ China, Sch Comp Sci & Technol, Qingdao, Peoples R China.; Jian, MW (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.; Jian, MW (corresponding author), Linyi Univ, Sch Informat Sci & Technol, Linyi, Peoples R China.
EM jianmuweihk@163.com; gaigewang@163.com
RI Jian, Muwei/Q-8319-2018
FU National Natural Science Foundation of China (NSFC) [61976123,
   61601427]; Taishan Young Scholars Program of Shandong Province; Key
   Development Program for Basic Research of Shandong Province [ZR2020ZD44]
FX AcknowledgementsThis work was supported by National Natural Science
   Foundation of China (NSFC) (61976123, 61601427); Taishan Young Scholars
   Program of Shandong Province; and Key Development Program for Basic
   Research of Shandong Province (ZR2020ZD44).
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Ge Z, 2021, PROC CVPR IEEE, P303, DOI 10.1109/CVPR46437.2021.00037
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Z., 2021, ARXIV
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li C., 2022, ARXIV
   Liang H, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14050904
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2023, INFORM FUSION, V96, P281, DOI 10.1016/j.inffus.2023.02.005
   Liu S, 2023, INFORM SCIENCES, V619, P679, DOI 10.1016/j.ins.2022.11.076
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Zhang H., 2020, P EUR C COMP VIS, P260, DOI DOI 10.1007/978-3-030-58555-6_16
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zou Z, 2019, ARXIV
NR 37
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10661
EP 10676
DI 10.1007/s11042-023-16063-9
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001014722500006
DA 2024-07-18
ER

PT J
AU Gao, H
   Zhang, XP
   Gao, TG
AF Gao, Hang
   Zhang, Xinpeng
   Gao, Tiegang
TI Hierarchical reversible data hiding in encrypted images based on
   multiple linear regressions and multiple bits prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Privacy protection; Embedding capacity; Huffman
   coding; adaptive adjustment
ID DIFFERENCE; EXPANSION; SYSTEM
AB Reversible data hiding in encrypted images (RDHEI) can be used as an effective technique to protect the image content and manage the secret data embedded in the encrypted domain, it is useful for storage and management of the image outsourced to the cloud. In this paper, a hierarchical reversible data hiding with high payload in encrypted images is proposed. The pixels in original image are divided into the multiple linear regressions (MLR) predictable and the no MLR predictable. The MLR predictable pixels are processed to generate two levels label map of pixels by adaptive adjustment of predicted data and multiple bits prediction (MBP). The no MLR predictable pixels are used to generate label map of pixels (LMP) by using simple one bit prediction technique. The additional data produced by compression of three LMPs are embedded into the encrypted images. Thanks to the high correlation between pixels in the clear domain of image, the proposed scheme obtains a high embedding rate. The obtained average payloads are 2.9885 bpp, 3.759 bpp and 3.883 bpp for UCID, BOWS-2 and BOSS dataset, respectively. Extensive experiments including comparison tests, usability tests and ablation tests on some standard test images and three datasets are conducted to testify the effectiveness and usability of the proposed RDHEI, and the experimental results demonstrate that the proposed scheme outperforms the state-of-the-art RDHEI methods in payload on most images, the comparisons of performance show that great improvements have been made in the proposed method.
C1 [Gao, Hang] Tsinghua Univ, Inst Publ Safety Res, Beijing 100084, Peoples R China.
   [Zhang, Xinpeng] Fudan Univ, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300380, Peoples R China.
C3 Tsinghua University; Fudan University; Nankai University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300380, Peoples R China.
EM gaotiegang@nankai.edu.cn
FU National Science and Technology Major Project of China [2021YFB0300104];
   Key Program of Natural Science Fund of Tianjin [21JCZDJC00130]
FX AcknowledgementsThe authors gratefully acknowledge the financial support
   provided by National Science and Technology Major Project of China
   (2021YFB0300104) and the Key Program of Natural Science Fund of Tianjin
   (21JCZDJC00130).
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2017, Image database of BOWS-2
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen CC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103060
   Chen F, 2021, IEEE T CIRC SYST VID, V31, P905, DOI 10.1109/TCSVT.2020.2992817
   Chen KM, 2019, J VIS COMMUN IMAGE R, V58, P334, DOI 10.1016/j.jvcir.2018.12.023
   Chuman T, 2019, IEEE T INF FOREN SEC, V14, P1515, DOI 10.1109/TIFS.2018.2881677
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Erkin Z., 2007, EURASIP Journal on Information Security, V7, P1
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Li FY, 2021, MULTIMED TOOLS APPL, V80, P2141, DOI 10.1007/s11042-020-09805-6
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10060664
   Liu ZL, 2018, INFORM SCIENCES, V433, P188, DOI 10.1016/j.ins.2017.12.044
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Niu XM, 2000, IEEE T CONSUM ELECTR, V46, P137, DOI 10.1109/30.826391
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Puteaux P, 2021, IEEE T INF FOREN SEC, V16, P2445, DOI 10.1109/TIFS.2021.3055630
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE INT WORKS INFOR
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Puyang Y, 2018, IEEE INT WORKS INFOR
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wang YM, 2022, IEEE T MULTIMEDIA, V24, P1288, DOI 10.1109/TMM.2021.3062699
   Wu FH, 2021, KNOWL-BASED SYST, V234, DOI 10.1016/j.knosys.2021.107583
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2021, SIGNAL PROCESS, V187, DOI 10.1016/j.sigpro.2021.108146
   Yin ZX, 2022, IEEE T DEPEND SECURE, V19, P992, DOI 10.1109/TDSC.2020.3019490
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   YU CQ, 2022, IEEE T CIRC SYST VID, V32, P451, DOI DOI 10.1109/TCSVT.2021.3062947
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 53
TC 2
Z9 2
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8757
EP 8783
DI 10.1007/s11042-023-15939-0
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000006
DA 2024-07-18
ER

PT J
AU Barin, S
   Güraksin, GE
AF Barin, Sezin
   Gueraksin, Guer Emre
TI An improved hair removal algorithm for dermoscopy images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Skin cancer; Hair removal algorithm; Deep learning
ID SQUAMOUS-CELL CARCINOMA
AB Dermoscopy is commonly used for diagnosing skin cancer in its early stages. However, hair structures in dermoscopy images can negatively affect diagnosis. A proposed algorithm based on conventional image processing methods removes hair structures from these images. Removing hair structures is crucial for constructing accurate computer-aided diagnosis systems for skin cancer. To eliminate hair structures from dermoscopy images, a hair removal algorithm based on conventional image processing methods has been proposed in this study. The proposed algorithm was compared to the existing hair removal algorithms in literature and tested on the ISIC2018 dataset using the AlexNet architecture. The effects on computer-aided systems were assessed by training on images with and without hair. Results show that the algorithm performs well in removing hairs compared to previous studies and improves classification performance. Upon comparison with other literature studies, the recommended algorithm has exhibited consistently high performance, usually ranking among the top two performers in the rank analysis. Additionally, the integration of the suggested algorithm has led to improvements in the performance metrics of the AlexNet architecture, with increases of 0.9% in accuracy, 1.4% in sensitivity, 0.6% in specificity, and 1.06 in F1 score. The performance of the suggested algorithm indicates its potential as a practical and effective tool in clinical settings.
C1 [Barin, Sezin] Afyon Kocatepe Univ, Engn Fac, Biomed Engn Dept, Afyonkarahisar, Turkiye.
   [Gueraksin, Guer Emre] Afyon Kocatepe Univ, Engn Fac, Comp Engn Dept, Afyonkarahisar, Turkiye.
C3 Afyon Kocatepe University; Afyon Kocatepe University
RP Barin, S (corresponding author), Afyon Kocatepe Univ, Engn Fac, Biomed Engn Dept, Afyonkarahisar, Turkiye.
EM sbarin@aku.edu.tr
CR Abbas Q, 2011, BIOMED SIGNAL PROCES, V6, P395, DOI 10.1016/j.bspc.2011.01.003
   [Anonymous], ?About us"
   Ariff NAM, 2023, P 2023 17 INT C UB I, DOI [10.1109/IMCOM56909.2023.10035592, DOI 10.1109/IMCOM56909.2023.10035592]
   Arora G, 2023, NEURAL COMPUT APPL, V35, P7989, DOI 10.1007/s00521-022-06922-1
   Attia M, 2019, COMPUT METH PROG BIO, V177, P17, DOI 10.1016/j.cmpb.2019.05.010
   Attia M, 2017, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2017.7950522
   Berry K, 2017, JAMA DERMATOL, V153, P421, DOI 10.1001/jamadermatol.2016.5245
   Bibiloni P, 2017, LECT NOTES ARTIF INT, V10259, P322, DOI 10.1007/978-3-319-59758-4_37
   Brantsch KD, 2008, LANCET ONCOL, V9, P713, DOI 10.1016/S1470-2045(08)70178-5
   Chadebec C, 2023, IEEE T PATTERN ANAL, V45, P2879, DOI 10.1109/TPAMI.2022.3185773
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Davidson DW, 2003, NUCL INSTRUM METH A, V509, P146, DOI 10.1016/S0168-9002(03)01563-8
   Gao JB, 2023, INT J COMPUT VISION, V131, P659, DOI 10.1007/s11263-022-01695-5
   Gaulin C, 2015, AUSTRALAS J DERMATOL, V56, P70, DOI 10.1111/ajd.12205
   Gonzalez-Hidalgo M, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2010.05013
   Hasan Md Kamrul, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2021.100819
   Hosny KM, 2022, J DIGIT IMAGING, V35, P258, DOI 10.1007/s10278-021-00552-0
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Huang A, 2013, IEEE ENG MED BIO, P3315, DOI 10.1109/EMBC.2013.6610250
   Karia PS, 2013, J AM ACAD DERMATOL, V68, P957, DOI 10.1016/j.jaad.2012.11.037
   Kassem MA, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081390
   Kiani K, 2011, COMPUT BIOL MED, V41, P139, DOI 10.1016/j.compbiomed.2011.01.003
   Koehoorn J, 2015, LECT NOTES COMPUT SC, V9082, P15, DOI 10.1007/978-3-319-18720-4_2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Leiter Ulrike, 2014, Adv Exp Med Biol, V810, P120
   Li W, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107994
   Mahbod A, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105475
   Mat ariff Noor Azwana, 2022, 2022 International Conference on Information Technology Research and Innovation (ICITRI), P24, DOI 10.1109/ICITRI56423.2022.9970238
   Mathews MR, 2021, INT J IMAG SYST TECH, V31, P2093, DOI 10.1002/ima.22574
   Model MA, 2001, CYTOMETRY, V44, P309, DOI 10.1002/1097-0320(20010801)44:4<309::AID-CYTO1122>3.0.CO;2-3
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pereira PMM, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101924
   Ramella G, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010447
   Seibert JA, 1998, P SOC PHOTO-OPT INS, V3336, P348, DOI 10.1117/12.317034
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Smith L, 2011, SKIN RES TECHNOL, V17, P257, DOI 10.1111/j.1600-0846.2011.00503.x
   Süzme NÖ, 2020, LECT NOTE DATA ENG, V43, P171, DOI 10.1007/978-3-030-36178-5_14
   Toossi MTB, 2013, SKIN RES TECHNOL, V19, P230, DOI 10.1111/srt.12015
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Xie FY, 2009, COMPUT MED IMAG GRAP, V33, P275, DOI 10.1016/j.compmedimag.2009.01.003
   Xie FY, 2015, COMPUT BIOL MED, V59, P106, DOI 10.1016/j.compbiomed.2015.01.023
   Yu Z, 2022, IEEE T MED IMAGING, V41, P633, DOI 10.1109/TMI.2021.3120091
   Zheng XT, 2022, IEEE T IMAGE PROCESS, V31, P4251, DOI 10.1109/TIP.2022.3177322
   Zhu H, 2020, IEEE T GEOSCI REMOTE, V58, P1004, DOI 10.1109/TGRS.2019.2942384
NR 45
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8931
EP 8953
DI 10.1007/s11042-023-15936-3
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000003
DA 2024-07-18
ER

PT J
AU Amma, NGB
   Rajput, V
AF Amma, N. G. Bhuvaneswari
   Rajput, Vikrant
TI Towards improving the performance of traffic sign recognition using
   support vector machine based deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural network; Maximally stable extremal region;
   Support vector machine; Traffic sign classification; Traffic sign
   detection
AB Nowadays autonomous vehicles are evolving due to the advancements in cutting edge technologies. In order to recognize the traffic signatures with high efficacy, traffic recognition system is required. Sign detection and classification are the two parts of the recognition system. The sign detection algorithm detects the size and coordinates of the sign board in an image and in sign classification, the representation of traffic signal is identified and classified into one of their traffic sign sub-classes. In order to achieve these goals, an extremely fast detection module using support vector machine is proposed to detect the traffic sign into one of the traffic classes such as, prohibitory, danger, mandatory, and non-sign. Further classification is carried out using deep convolutional neural networks to determine the sub-classes of each super-class, such as, prohibitory, danger, and mandatory. Based on publicly available benchmark traffic sign image datasets, we have demonstrated that the proposed approach has significantly improved traffic sign recognition accuracy compared with state-of-the-art systems.
C1 [Amma, N. G. Bhuvaneswari] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
   [Rajput, Vikrant] Indian Inst Informat Technol, Sch Comp, Una 177209, Himachal Prades, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Amma, NGB (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM ngbhuvaneswariamma@gmail.com
OI Amma N. G., Dr. Bhuvaneswari/0000-0003-3660-380X
CR Alghmgham D.A., 2019, Procedia Comput. Sci., V163, P266, DOI [10.1016/j.procs.2019.12.108, DOI 10.1016/J.PROCS.2019.12.108]
   [Anonymous], 2021, WHO HLTH ORG ROAD SA
   [Anonymous], 2021, Turkish Journal of Computer and Mathematics Education (TURCOMAT), V12, P4244
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Berkaya SK, 2016, EXPERT SYST APPL, V48, P67, DOI 10.1016/j.eswa.2015.11.018
   Bouti A, 2019, SOFT COMPUT, P1
   Brkic K, 2009, P ANN WORKSH AUSTR A, P1
   Chen T, 2016, IEEE T VEH TECHNOL, V65, P4006, DOI 10.1109/TVT.2015.2500275
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Fan ZQ, 2013, 2013 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT), P1, DOI 10.1109/PDCAT.2013.7
   He ZL, 2020, IET INTELL TRANSP SY, V14, P323, DOI 10.1049/iet-its.2019.0409
   Hechri A, 2020, IET IMAGE PROCESS, V14, P939, DOI 10.1049/iet-ipr.2019.0634
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Huang SC, 2017, JOINT INT CONF SOFT
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Kaixuan Xie, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P201, DOI 10.1007/978-3-319-48890-5_20
   Lahmyed R, 2022, SOFT COMPUT, V26, P1743, DOI 10.1007/s00500-021-06726-w
   Liu CS, 2014, IEEE T INTELL TRANSP, V15, P2394, DOI 10.1109/TITS.2014.2314711
   Liu HP, 2014, INFORM SCIENCES, V266, P75, DOI 10.1016/j.ins.2014.01.010
   Maldonado-Bascón S, 2007, IEEE T INTELL TRANSP, V8, P264, DOI 10.1109/TITS.2007.895311
   Malik Z, 2014, INT CONF FRONT INFO, P330, DOI 10.1109/FIT.2014.68
   Mathias Markus, 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), DOI 10.1109/IJCNN.2013.6707049
   Qian RQ, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P578, DOI 10.1109/FSKD.2016.7603237
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Santos D, 2020, IEEE LAT AM T, V18, P522, DOI 10.1109/TLA.2020.9082723
   Sanyal B, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), DOI 10.1109/aisp48273.2020.9072976
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240
   Shao FM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103192
   Song SJ, 2019, J SYST ARCHITECT, V97, P269, DOI 10.1016/j.sysarc.2019.01.012
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Tabernik D, 2020, IEEE T INTELL TRANSP, V21, P1427, DOI 10.1109/TITS.2019.2913588
   Vennelakanti A, 2019, I SYMP CONSUM ELECTR
   Wang H, 2013, PROCEEDINGS OF THE 5TH (2013) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P1, DOI 10.1109/ijcnn.2013.6706812
   Yang J, 2017, SOFT COMPUT, V21, P3101, DOI 10.1007/s00500-015-1994-9
   Yang Y, 2016, IEEE T INTELL TRANSP, V17, P2022, DOI 10.1109/TITS.2015.2482461
   Zang D, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P201, DOI 10.1109/SNPD.2016.7515901
   Zeng Y., 2015, 2015 INT C INT SCI B, V9242, P272, DOI DOI 10.1007/978-3-319-23989-7_28
   Zhang CW, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550034
   Zhu Y, 2022, MATER TECHNOL, P1
NR 40
TC 0
Z9 0
U1 16
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6579
EP 6600
DI 10.1007/s11042-023-15479-7
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900010
DA 2024-07-18
ER

PT J
AU Shah, VH
   Dash, PP
AF Shah, Vishal H.
   Dash, Prajna Parimita
TI Two stage self-adaptive cognitive neural network for mixed noise removal
   from medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed noise; Convolutional Neural Network (CNN); Cognitive neural
   network; Medical image denoising; Statistical analysis
ID VALUED IMPULSE NOISE; BILATERAL FILTER; ALGORITHM; DETECTOR
AB In the current era of technological advancements where convergence of social mobility analytics and clouds enabled the end users in capturing precise medical images on the go but also had lead incorporation of unusual noises too. One such scenario is the combination of both Additive White Gaussian Noise (AWGN) along with impulse noise that are added during acquisition and post-processing of medical images which hampers the overall medical image processing where identification of region of interest is pretty important. The noises not only affect the textures but also could plays at the pixelate level. In this work, a patch transformation technique for mixed noise removal and the bilateral filtering approach for edge preservation have been associated with the cognitive neural network model to remove the noise from medical images. The self adaptation of the network identifies the presence of mixed noise and generate the training dataset with the noisy patches along with the denoised patches. The proposed two stage self adaptive cognitive neural network model (SACNN) successfully retains the edge information along with denoising of the images. The performance of SACNN model is compared with other state-of-the-art techniques through various performance matrices. Statistical analysis such as, Signed test, Wilcoxon Signed rank test and Friedman test are also carried out to investigate the dominance of proposed approach over others.
C1 [Shah, Vishal H.; Dash, Prajna Parimita] Birla Inst Technol, Dept Elect & Commun Engn, Ranchi 835215, Jharkhand, India.
C3 Birla Institute of Technology Mesra
RP Shah, VH (corresponding author), Birla Inst Technol, Dept Elect & Commun Engn, Ranchi 835215, Jharkhand, India.
EM vishalhshah@bitmesra.ac.in; ppdash@bitmesra.ac.in
RI Dash, Prajna Parimita/AAE-9282-2021; Shah, Vishal H/JAC-1524-2023
OI Dash, Prajna Parimita/0000-0002-9767-8234; Shah, Vishal
   H/0000-0001-6282-1988
CR Al-Sbou YA., 2012, WORLD APPL SCI J, V17, P218
   Baozhong Liu, 2018, MATEC Web of Conferences, V232, DOI 10.1051/matecconf/201823203025
   Brox T, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P17, DOI 10.1007/3-540-31272-2_2
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen P, 2008, FAST GAUSSIAN PARTIC, V36, P291
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Fu Bin, 2011, 2011 IEEE/ICME International Conference on Complex Medical Engineering - CME 2011, P466, DOI 10.1109/ICCME.2011.5876785
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Goyal B., 2017, INT J COMPUT APPL, V64, P1
   Goyal B., 2018, BIOMED PHARMACOL J, V11, P1227, DOI [DOI 10.13005/bpj/1484, 10.13005/bpj/1484]
   Guo FH, 2019, MULTIMED TOOLS APPL, V78, P16601, DOI 10.1007/s11042-018-7004-3
   Hu HJ, 2016, J SCI COMPUT, V67, P103, DOI 10.1007/s10915-015-0073-9
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Javed SG, 2016, MULTIMED TOOLS APPL, V75, P5887, DOI 10.1007/s11042-015-2554-0
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P24405, DOI 10.1007/s11042-017-5592-y
   Kumar M, 2020, CURR MED IMAGING, V16, P278, DOI 10.2174/1573405614666180801113345
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Li C, 2019, MULTIMED TOOLS APPL, V78, P23117, DOI 10.1007/s11042-019-7625-1
   Li YP, 2020, MULTIMED TOOLS APPL, V79, P33043, DOI 10.1007/s11042-020-09565-3
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Liu BZ, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/2/022010
   Ma H, 2018, MATH PROBL ENG, V2018
   Mafi M, 2020, IET IMAGE PROCESS, V14, P4027, DOI 10.1049/iet-ipr.2018.6335
   Naga Srinivasu P, 2021, BIOINSPIRED NEUROCOM, V903, DOI [10.1007/978-981-15-5495-7_1, DOI 10.1007/978-981-15-5495-7_1]
   Nair MS, 2013, SIGNAL IMAGE VIDEO P, V7, P1041, DOI 10.1007/s11760-012-0310-8
   OShea K., 2015, arXiv
   Radlak K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102782
   Rahman MA, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P1, DOI 10.1109/CRV.2016.39
   Razlighi Q. R., 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7257, DOI 10.1117/12.814439
   Shi ZF, 2018, MULTIMED TOOLS APPL, V77, P6933, DOI 10.1007/s11042-017-4613-1
   Singh Chaplot D, 2018, ARXIV
   SivaSai JG, 2020, STUDIES COMPUTATIONA, P163, DOI [DOI 10.1007/978-981-15-5495-7_9, 10.1007/978-981-15-5495-7_9/COVER/]
   Turkmen I, 2016, J VIS COMMUN IMAGE R, V34, P28, DOI 10.1016/j.jvcir.2015.10.011
   Türkmen I, 2014, TURK J ELECTR ENG CO, V22, P637, DOI 10.3906/elk-1208-77
   Wang SS, 2009, PATTERN RECOGN, V42, P2194, DOI 10.1016/j.patcog.2009.01.022
   Wang Y, 2020, ARXIV
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang LP, 2003, J GLOBAL OPTIM, V25, P363, DOI 10.1023/A:1022528320719
   Zhang M, 2008, INT CONF ACOUST SPEE, P929
NR 43
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6497
EP 6519
DI 10.1007/s11042-023-15423-9
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900013
DA 2024-07-18
ER

PT J
AU Lu, X
   Li, WX
   Lu, XB
AF Lu, Xin
   Li, Weixuan
   Lu, Xiaobo
TI An objectness-aware network for wildlife detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wildlife detection; YOLO; Objectness value; Label assignment; Assistant
   sample
AB The application of object detectors contributes to the monitoring and protection of wildlife with high accuracy and fast speed. However, the variety of shapes and appearances of wildlife bring difficulties to the detection task, which requires the detection models a better objectness definition and label assignment. This study proposes an objectness-aware YOLO (OA-YOLO) to improve the effect on wildlife detection. First, we redefine the objectness values of training samples and decouple the objectness branch in the detector head. Second, we propose a Natural Breaks Label Assignment (NBLA) algorithm to divide the anchors into positive, negative, and assistant samples automatically based on their objectness values. Third, the assistant samples used to be ignored participate in the classification training in an objectness-related weighted manner to improve the detection accuracy. The experimental results indicate that OA-YOLO improves the mean average precision (mAP) by 6.9% on the challenging wildlife dataset and outperforms the existing approaches.
C1 [Lu, Xin; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Lu, Xin; Lu, Xiaobo] Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Li, Weixuan] Nanjing Enbo Technol Co Ltd, Nanjing 210007, Peoples R China.
C3 Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Lu, XB (corresponding author), Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
EM lx_zjwf1218@outlook.com; 676354385@qq.com; xblu2013@126.com
OI Lu, Xin/0009-0005-7669-1674
CR Beery S, 2021, ARXIV
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cao JK, 2019, IEEE I CONF COMP VIS, P9497, DOI 10.1109/ICCV.2019.00959
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Choi J, 2019, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2019.00059
   Feng WZ, 2019, IEEE ACCESS, V7, P161412, DOI 10.1109/ACCESS.2019.2951596
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Hengduo Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10585, DOI 10.1109/CVPR42600.2020.01060
   Hsu WY, 2021, IEEE T IMAGE PROCESS, V30, P934, DOI 10.1109/TIP.2020.3039574
   Kim K, 2020, PROBABILISTIC ANCHOR
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nguyen H, 2017, PR INT CONF DATA SC, P40, DOI 10.1109/DSAA.2017.31
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wei Ke, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10203, DOI 10.1109/CVPR42600.2020.01022
   Xiaohan Liu, 2015, 2015 IEEE/CIC International Conference on Communications in China: Workshops (CIC/ICCC), P62, DOI 10.1109/ICCChinaW.2015.7961581
   Yousif H., 2019, IEEE Transactions on Circuits and Systems for Video Technology
   Zhang GF, 2021, IEEE SIGNAL PROC LET, V28, P71, DOI 10.1109/LSP.2020.3045641
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhou X., 2019, arXiv
NR 27
TC 0
Z9 0
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7119
EP 7133
DI 10.1007/s11042-023-15246-8
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600007
DA 2024-07-18
ER

PT J
AU García-Ordás, MT
   Benítez-Andrades, JA
   Aveleira-Mata, J
   Alija-Pérez, JM
   Benavides, C
AF Garcia-Ordas, Maria Teresa
   Benitez-Andrades, Jose Alberto
   Aveleira-Mata, Jose
   Alija-Perez, Jose-Manuel
   Benavides, Carmen
TI Determining the severity of Parkinson's disease in patients using a
   multi task neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Parkinson; Deep learning; Autoencoder; Disease progress; Mixed model;
   Classification; Regression
ID PROGRESSION; PREDICTION; SYSTEM; SCALE
AB Parkinson's disease is easy to diagnose when it is advanced, but it is very difficult to diagnose in its early stages. Early diagnosis is essential to be able to treat the symptoms. It impacts on daily activities and reduces the quality of life of both the patients and their families and it is also the second most prevalent neurodegenerative disorder after Alzheimer in people over the age of 60. Most current studies on the prediction of Parkinson's severity are carried out in advanced stages of the disease. In this work, the study analyzes a set of variables that can be easily extracted from voice analysis, making it a very non-intrusive technique. In this paper, a method based on different deep learning techniques is proposed with two purposes. On the one hand, to find out if a person has severe or non-severe Parkinson's disease, and on the other hand, to determine by means of regression techniques the degree of evolution of the disease in a given patient. The UPDRS (Unified Parkinson's Disease Rating Scale) has been used by taking into account both the motor and total labels, and the best results have been obtained using a mixed multi-layer perceptron (MLP) that classifies and regresses at the same time and the most important features of the data obtained are taken as input, using an autoencoder. A success rate of 99.15% has been achieved in the problem of predicting whether a person suffers from severe Parkinson's disease or non-severe Parkinson's disease. In the degree of disease involvement prediction problem case, a MSE (Mean Squared Error) of 0.15 has been obtained. Using a full deep learning pipeline for data preprocessing and classification has proven to be very promising in the field Parkinson's outperforming the state-of-the-art proposals.
C1 [Garcia-Ordas, Maria Teresa; Aveleira-Mata, Jose; Alija-Perez, Jose-Manuel] Univ Leon, Escuela Ingn Ind & Informat, SECOMUCI Res Grp, Campus Vegazana s-n, Leon 24071, Spain.
   [Benitez-Andrades, Jose Alberto; Benavides, Carmen] Univ Leon, Dept Elect Syst & Automat Engn, SALBIS Res Grp, Campus Vegazana s-n, Leon 24071, Spain.
C3 Universidad de Leon; Universidad de Leon
RP Alija-Pérez, JM (corresponding author), Univ Leon, Escuela Ingn Ind & Informat, SECOMUCI Res Grp, Campus Vegazana s-n, Leon 24071, Spain.
EM mgaro@unileon.es; jbena@unileon.es; jose.aveleira@unileon.es;
   jmalip@unileon.es; carmen.benavides@unileon.es
RI Benítez Andrades, José Alberto/M-1195-2017
OI Benítez Andrades, José Alberto/0000-0002-4450-349X
FU CRUE-CSIC agreement; Springer Nature; Junta de Castilla y Leon
   [LE078G18]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This research was funded by the Junta de Castilla y
   Leon grant number LE078G18.
CR Almeida JS, 2019, PATTERN RECOGN LETT, V125, P55, DOI 10.1016/j.patrec.2019.04.005
   BROOKS DJ, 1990, ANN NEUROL, V28, P547, DOI 10.1002/ana.410280412
   Castelli M, 2014, EXPERT SYST APPL, V41, P4608, DOI 10.1016/j.eswa.2014.01.018
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Dashtipour K, 2022, L N INST COMP SCI SO, V420, P89, DOI 10.1007/978-3-030-95593-9_8
   Ebrahimighahnavieh MA, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105242
   El Maachi I, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113075
   Goetz CG, 2004, MOVEMENT DISORD, V19, P1020, DOI 10.1002/mds.20213
   Gottapu RD, 2018, PROCEDIA COMPUT SCI, V140, P334, DOI 10.1016/j.procs.2018.10.306
   Grissette Hanane, 2021, Pers Ubiquitous Comput, P1, DOI 10.1007/s00779-021-01595-4
   Grover Srishti, 2018, Procedia Computer Science, V132, P1788, DOI 10.1016/j.procs.2018.05.154
   Jankovic J, 2023, PARKINSONS DIS CLIN
   Lauraitis A, 2019, IEEE J BIOMED HEALTH, V23, P1865, DOI 10.1109/JBHI.2019.2891729
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Mischley LK, 2017, NPJ PARKINSONS DIS, V3, P1, DOI 10.1038/s41531-017-0021-5
   Monica K. M., 2023, Personal and Ubiquitous Computing, P793, DOI 10.1007/s00779-021-01525-4
   Nilashi M, 2019, MEASUREMENT, V136, P545, DOI 10.1016/j.measurement.2019.01.014
   Nilashi M, 2018, BIOCYBERN BIOMED ENG, V38, P1, DOI 10.1016/j.bbe.2017.09.002
   Nilashi M, 2016, SCI REP-UK, V6, DOI 10.1038/srep34181
   Pahuja G, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105610
   Poewe W, 2009, MOVEMENT DISORD, V24, pS671, DOI 10.1002/mds.22600
   Prashanth R, 2018, INT J MED INFORM, V119, P75, DOI 10.1016/j.ijmedinf.2018.09.008
   Prashanth R, 2018, NEUROCOMPUTING, V305, P78, DOI 10.1016/j.neucom.2018.04.049
   Quan CQ, 2022, BIOCYBERN BIOMED ENG, V42, P556, DOI 10.1016/j.bbe.2022.04.002
   Salmanpour MR, 2020, PHYS MEDICA, V69, P233, DOI 10.1016/j.ejmp.2019.12.022
   Shi C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155758
   Singh BK, 2019, BIOCYBERN BIOMED ENG, V39, P393, DOI 10.1016/j.bbe.2019.03.001
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000
   Van Den Eeden SK, 2003, AM J EPIDEMIOL, V157, P1015, DOI 10.1093/aje/kwg068
   Zhang RL, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103883
NR 30
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-14932-x
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TU0
UT WOS:000999310400001
OA hybrid
DA 2024-07-18
ER

PT J
AU Shan, YL
   Ma, Y
   Liao, Y
   Huang, H
   Wang, B
AF Shan, Yilin
   Ma, Yan
   Liao, Yuan
   Huang, Hui
   Wang, Bin
TI Interactive image segmentation based on multi-layer random forest
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Superpixel; Random forest; Region merging; Breadth-first
   search
ID CUTS
AB Since fully automatic image segmentation methods often fail for most complex images, researchers turn to the interactive segmentation paradigm to achieve better segmentation performance. However, many interactive image segmentation algorithms are highly dependent on user interactive information. This paper presents a novel interactive image segmentation algorithm based on multi-layer random forests. Given a small amount of user input markers, region merging is done according to the merging rule, in which both the color histogram and gradient orientation histogram of the region are included to avoid the merging error. To speed up the calculation of gradient orientation histogram, breadth-first search is used to determine the intersection of two adjacent regions. Then, we relabel the training samples with k-means algorithm and Silhouette index and further perform the first layer random forest classification. Next, we reconstruct the training samples with the adjacent superpixel pairs and use the second layer random forest classifiers to classify the superpixels whose prediction confidence is lower than the threshold after the first layer random forest classification. Experiments on real natural images are conducted to demonstrate the performance of the proposed algorithm.
C1 [Shan, Yilin; Ma, Yan; Liao, Yuan; Huang, Hui; Wang, Bin] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Normal University
RP Ma, Y (corresponding author), Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
EM syilin_310@163.com; ma-yan@shnu.edu.cn; 731705150@qq.com;
   huanghui@shnu.edu.cn; binwang@shnu.edu.cn
RI zhang, yueqi/JXM-4287-2024; Zhang, Can/JUU-9511-2023; Yang,
   Mei/JNS-2225-2023
OI , Yan/0000-0003-4626-1401
FU National Natural Science Foundation of China [61373004]
FX AcknowledgementsThis work is partially supported by the National Natural
   Science Foundation of China (Grant no. 61373004).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Acuna D, 2018, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2018.00096
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breve F, 2019, EXPERT SYST APPL, V123, P18, DOI 10.1016/j.eswa.2019.01.031
   Castrejón L, 2017, PROC CVPR IEEE, P4485, DOI 10.1109/CVPR.2017.477
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Csillik O, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030243
   Eramian M, 2020, INTERACT COMPUT, V32, P233, DOI 10.1093/iwcomp/iwaa017
   Gu Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061213
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hu ZW, 2021, INT J APPL EARTH OBS, V105, DOI 10.1016/j.jag.2021.102605
   Jian M, 2016, IEEE T IMAGE PROCESS, V25, P1301, DOI 10.1109/TIP.2016.2518480
   Jiang QC, 2019, BIG DATA COGN COMPUT, V3, DOI 10.3390/bdcc3020031
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Li MC, 2021, SIGNAL IMAGE VIDEO P, V15, P571, DOI 10.1007/s11760-020-01778-1
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li YC, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106463
   Li ZW, 2018, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2018.00067
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P3060, DOI 10.1109/TIP.2015.2432711
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Peng ZL, 2019, SIGNAL PROCESS-IMAGE, V78, P159, DOI 10.1016/j.image.2019.06.012
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pinto A, 2018, PATTERN RECOGN, V82, P105, DOI 10.1016/j.patcog.2018.05.006
   Prinke P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93682-y
   Ramadan H, 2020, COMPUT VIS MEDIA, V6, P355, DOI 10.1007/s41095-020-0177-5
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang XY, 2016, NEURAL NETWORKS, V74, P1, DOI 10.1016/j.neunet.2015.10.012
   Yu HK, 2017, IEEE IMAGE PROC, P3335, DOI 10.1109/ICIP.2017.8296900
   Zhao BW, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.4438
   Zheng Q, 2018, J VIS COMMUN IMAGE R, V55, P157, DOI 10.1016/j.jvcir.2018.06.005
NR 40
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22469
EP 22495
DI 10.1007/s11042-022-14199-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:001001127400006
DA 2024-07-18
ER

PT J
AU Singh, LK
   Khanna, M
   Thawkar, S
   Singh, R
AF Singh, Law Kumar
   Khanna, Munish
   Thawkar, Shankar
   Singh, Rekha
TI Deep-learning based system for effective and automatic blood vessel
   segmentation from Retinal fundus images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DenseNet; LadderNet; U-Net; R2U-Net; ATTU-Net; Blood Vessel Segmentation
ID NEURAL-NETWORK; MATCHED-FILTER; OPTIC DISC; MODEL
AB The segmentation of blood vessels through color fundus images is a difficult and time-consuming task that requires experienced clinicians. Recently, researchers have shown that blood vessel segmentation using methods based on deep neural networks has achieved highly satisfactory results. This motivates us to employ a fast and accurate deep learning-based method that can be used in blood vessel segmentation. Five improved deep learning-based networks (U-Net, DenseU-Net, LadderNet, R2U-Net, and ATTU-Net), along with an enhanced customized R2-ATT U-Net deep learning network, have been employed to segment the retinal blood vessel tree. Segmentation using patches extraction is executed, where we have used 10,000 patches per image, in total, 8000 for training and 2000 for testing public benchmark STARE dataset images. Initially, we performed the training, followed by testing for all six models using the patch extraction approach. All the aspects of the testing phase (test log, ROC curve, precision recall curves, and confusion matrix) and statistical performance measuring metrics (accuracy, sensitivity, specificity, F1 score, precision, and AUC values) are covered in this work and are also shown in the form of tables and graphs. An in-depth performance evaluation analysis of these six implemented improved nets has been performed to evaluate the segmentation process. We got the best result in the case of LadderNet, with an accuracy of 0.971, which is comparable to recent state-of-the-art studies. In terms of accuracy, the enhanced customized R2-ATT U-Net deep learning network is also highly satisfactory, being near the best model, LadderNet. The experiment results demonstrate that the proposed methodology achieves satisfactory performance in the retinal blood vessel extraction domain and can help ophthalmologists predict many eye-related diseases at a preliminary stage.
C1 [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura 2821406, India.
   [Khanna, Munish; Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Singh, Rekha] UP Rajarshi Tandon Open Univ, Dept Phys, Prayagraj, India.
C3 GLA University
RP Singh, LK (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura 2821406, India.
EM lawkumarcs@gmail.com; munishkhanna.official@rocketmail.com;
   shankarthawkar@gmail.com; singh.rekha70@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852; Thawkar,
   Shankar/0000-0002-0118-9605
CR Annunziata R, 2016, IEEE J BIOMED HEALTH, V20, P1129, DOI 10.1109/JBHI.2015.2440091
   Argüello F, 2018, J REAL-TIME IMAGE PR, V14, P773, DOI 10.1007/s11554-014-0469-z
   Asl ME, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.034006
   Biswal B, 2018, IET IMAGE PROCESS, V12, P389, DOI 10.1049/iet-ipr.2017.0329
   Biswas R, 2020, IJST-T ELECTR ENG, V44, P505, DOI 10.1007/s40998-019-00213-7
   Budak Ü, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109426
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Demissie B, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1
   Dong H, 2022, SIGNAL IMAGE VIDEO P, V16, P1755, DOI 10.1007/s11760-022-02132-3
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Feng ST, 2020, NEUROCOMPUTING, V392, P268, DOI 10.1016/j.neucom.2018.10.098
   Franklin SW, 2014, BIOCYBERN BIOMED ENG, V34, P117, DOI 10.1016/j.bbe.2014.01.004
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Gegundez-Arias ME, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106081
   Girard F, 2019, ARTIF INTELL MED, V94, P96, DOI 10.1016/j.artmed.2019.02.004
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Guo F, 2021, MULTIMED TOOLS APPL, V80, P14767, DOI 10.1007/s11042-021-10580-1
   Guo S, 2019, INT J MED INFORM, V126, P105, DOI 10.1016/j.ijmedinf.2019.03.015
   Guo YH, 2018, COMPUT METH PROG BIO, V167, P43, DOI 10.1016/j.cmpb.2018.10.021
   Guo YH, 2018, MEASUREMENT, V125, P586, DOI 10.1016/j.measurement.2018.05.003
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hu K, 2018, NEUROCOMPUTING, V309, P179, DOI 10.1016/j.neucom.2018.05.011
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Hussain S, 2022, COMPUT METH PROG BIO, V218, DOI 10.1016/j.cmpb.2022.106732
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Jayachandran A, 2022, J AMBIENT INTELL HUM, P1
   Jiang Y, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010024
   Jiang ZX, 2018, COMPUT MED IMAG GRAP, V68, P1, DOI 10.1016/j.compmedimag.2018.04.005
   Jin QG, 2020, NEURAL PROCESS LETT, V52, P1005, DOI 10.1007/s11063-019-10011-1
   Jin QG, 2019, KNOWL-BASED SYST, V178, P149, DOI 10.1016/j.knosys.2019.04.025
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Li QL, 2016, IEEE T MED IMAGING, V35, P109, DOI 10.1109/TMI.2015.2457891
   Li XJ, 2022, NEURAL COMPUT APPL, V34, P12001, DOI 10.1007/s00521-022-07086-8
   Lin Y, 2019, IEEE ACCESS, V7, P57717, DOI 10.1109/ACCESS.2018.2844861
   Liskowski P, 2016, IEEE T MED IMAGING, V35, P2369, DOI 10.1109/TMI.2016.2546227
   Liu Q, 2019, NEUROCOMPUTING, V359, P285, DOI 10.1016/j.neucom.2019.05.039
   Lu JW, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110607
   Lupascu CA, 2010, IEEE T INF TECHNOL B, V14, P1267, DOI 10.1109/TITB.2010.2052282
   Lv Y, 2020, IEEE ACCESS, V8, P32826, DOI 10.1109/ACCESS.2020.2974027
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Melinscak Martina, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P577
   Memari N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188939
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Ni JJ, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2019.105121
   Oliveira A, 2018, EXPERT SYST APPL, V112, P229, DOI 10.1016/j.eswa.2018.06.034
   Orlando JI, 2014, LECT NOTES COMPUT SC, V8673, P634, DOI 10.1007/978-3-319-10404-1_79
   Paul R, 2016, IEEE SYS MAN CYBERN, P2570, DOI 10.1109/SMC.2016.7844626
   Peng SH, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P305, DOI 10.1109/ICIVC.2018.8492833
   Pinz A, 1998, IEEE T MED IMAGING, V17, P606, DOI 10.1109/42.730405
   Rani P, 2016, 2016 INTERNATIONAL CONFERENCE ON SYSTEMS IN MEDICINE AND BIOLOGY (ICSMB), P62, DOI 10.1109/ICSMB.2016.7915088
   Ronneberger O., 2015, 2015 INT C MED IM CO, P234
   Roy S, 2019, MULTIMED TOOLS APPL, V78, P34839, DOI 10.1007/s11042-019-08111-0
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Sathananthavathi V, 2022, WIRELESS PERS COMMUN, V125, P3641, DOI 10.1007/s11277-022-09728-5
   Sinthanayothin C, 1999, BRIT J OPHTHALMOL, V83, P902, DOI 10.1136/bjo.83.8.902
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Song J, 2017, IEEE ENG MED BIO, P681, DOI 10.1109/EMBC.2017.8036916
   Soomro T.A., 2016, P INT C DIG IM COMP, P1
   Soomro TA, 2019, COMMUNICATIONS COMPU, P996
   Soomro TA, 2019, EXPERT SYST APPL, V134, P36, DOI 10.1016/j.eswa.2019.05.029
   Soomro TA, 2018, IEEE ACCESS, V6, P3524, DOI 10.1109/ACCESS.2018.2794463
   Sule O, 2023, J DIGIT IMAGING, V36, P414, DOI 10.1007/s10278-022-00738-0
   Tang P, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103352
   Tchinda BS., 2021, Informatics in Medicine Unlocked, V23, P100521, DOI [DOI 10.1016/J.IMU.2021.100521, 10.1016/j.imu.2021.100521]
   Thangaraj S, 2018, IET IMAGE PROCESS, V12, P669, DOI 10.1049/iet-ipr.2017.0284
   Tian C, 2020, BIOCYBERN BIOMED ENG, V40, P583, DOI 10.1016/j.bbe.2020.01.011
   Tolias YA, 1998, IEEE T MED IMAGING, V17, P263, DOI 10.1109/42.700738
   Uysal E, 2021, MULTIMED TOOLS APPL, V80, P3505, DOI 10.1007/s11042-020-09372-w
   Wang C, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020168
   Wang YF, 2013, PATTERN RECOGN, V46, P2117, DOI 10.1016/j.patcog.2012.12.014
   Wu HS, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.102025
   Wu YC, 2020, NEURAL NETWORKS, V126, P153, DOI 10.1016/j.neunet.2020.02.018
   Xia HY, 2022, MULTIMED TOOLS APPL, V81, P39829, DOI 10.1007/s11042-022-12696-4
   Yan ZQ, 2018, IEEE T BIO-MED ENG, V65, P1912, DOI 10.1109/TBME.2018.2828137
   Yang D, 2023, MULTIMED TOOLS APPL, P1
   Yang X, 2022, MULTIMED TOOLS APPL, V81, P15593, DOI 10.1007/s11042-022-12418-w
   Yao ZJ, 2016, INT SYM COMPUT INTEL, P406, DOI [10.1109/ISCID.2016.1100, 10.1109/ISCID.2016.99]
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Yue KJ, 2019, J MED IMAGING, V6, DOI [10.1117/1.JMI.6.3.034004, 10.1117/1.JMI.6.3.030004]
   Zhang J, 2016, IEEE T MED IMAGING, V35, P2631, DOI 10.1109/TMI.2016.2587062
   Zhao JL, 2018, DIGIT SIGNAL PROCESS, V81, P26, DOI 10.1016/j.dsp.2018.06.006
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhu CZ, 2017, COMPUT MED IMAG GRAP, V55, P68, DOI 10.1016/j.compmedimag.2016.05.004
   Zhuang JT, 2019, Arxiv, DOI [arXiv:1810.07810, DOI 10.48550/ARXIV.1810.07810]
NR 87
TC 4
Z9 4
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15348-3
EA JUN 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000007
DA 2024-07-18
ER

PT J
AU Sharma, D
   Dhiman, C
   Kumar, D
AF Sharma, Dhruv
   Dhiman, Chhavi
   Kumar, Dinesh
TI XGL-T transformer model for intelligent image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Activation Function; Attention; Computer Vision; Higher Order
   Interaction; Image Captioning; XGL; Transformer
AB Image captioning extracts multiple semantic features from an image and integrates them into a sentence-level description. For efficient description of the captions, it becomes necessary to learn higher order interactions between detected objects and the relationship among them. Most of the existing systems take into account the first order interactions while ignoring the higher order ones. It is challenging to extract discriminant higher order semantics visual features in images with highly populated objects for caption generation. In this paper, an efficient higher order interaction learning framework is proposed using encoder-decoder based image captioning. A scaled version of Gaussian Error Linear Unit (GELU) activation function, x-GELU is introduced that controls the vanishing gradients and enhances the feature learning. To leverage higher order interactions among multiple objects, an efficient XGL Transformer (XGL-T) model is introduced that exploits both spatial and channel-wise attention by integrating four XGL attention modules in image encoder and one in Bilinear Long Short-Term Memory guided sentence decoder. The proposed model captures rich semantic concepts from objects, attributes, and their relationships. Extensive experiments are conducted on publicly available MSCOCO Karapathy test split and the best performance of the work is observed as 81.5 BLEU@1, 67.1 BLEU@2, 51.6 BLEU@3, 39.9 BLEU@4, 134 CIDEr, 59.9 ROUGE-L, 29.8 METEOR, 23.8 SPICE using CIDEr-D Score Optimization Strategy. The scores validate the significant improvements over state-of-the-art results. An ablation study is also carried out to support the experimental observations.
C1 [Sharma, Dhruv; Dhiman, Chhavi; Kumar, Dinesh] Delhi Technol Univ, Delhi, India.
C3 Delhi Technological University
RP Dhiman, C (corresponding author), Delhi Technol Univ, Delhi, India.
EM dhruv.0906@yahoo.in; chhavi.dhiman@dtu.ac.in; dineshkumar@dtu.ac.in
RI Kumar, Dr Ashwani/GWZ-1380-2022; Kumar, Dinesh/AAA-7914-2021
OI Kumar, Dr Ashwani/0000-0001-9316-3236; Kumar,
   Dinesh/0000-0003-3485-6408; Sharma, Dhruv/0000-0001-9218-2515; Dhiman,
   Chhavi/0000-0002-3401-596X
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Anh Nguyen, 2021, 2021 International Conference on System Science and Engineering (ICSSE), P215, DOI 10.1109/ICSSE52999.2021.9538437
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZR, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115836
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gordo A, 2017, PROC CVPR IEEE, P5272, DOI 10.1109/CVPR.2017.560
   Goyal A, 2021, Arxiv, DOI [arXiv:2110.07641, DOI 10.48550/ARXIV.2110.07641, 10.48550/arXiv.2110.07641]
   He S, 2021, COMPUTER VISION ACCV
   Hendrycks D., 2016, PREPRINT
   Huang L, 2019, Arxiv, DOI arXiv:1908.06954
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Karaoglu S, 2017, IEEE T MULTIMEDIA, V19, P1063, DOI 10.1109/TMM.2016.2638622
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kim JH, 2018, ADV NEUR IN, V31
   Kingma D. P., 2014, arXiv
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li N, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2397
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556
   Shazeer N, 2020, Arxiv, DOI arXiv:2002.05202
   Song Zeliang, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428310
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang YH, 2022, IEEE T CIRC SYST VID, V32, P4417, DOI 10.1109/TCSVT.2021.3121062
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang XW, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P5398, DOI 10.1145/3503161.3548409
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
NR 51
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 24
PY 2023
DI 10.1007/s11042-023-15291-3
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CU8
UT WOS:000994104400005
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Dai, MZ
   Sun, X
   Zhou, MY
AF Wang, Zhengyu
   Dai, Mingzhi
   Sun, Xin
   Zhou, Meiyu
TI A higher satisfaction product customization method for different
   customer groups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Product customization; Clustering algorithm; Interactive genetic
   algorithm; Kansei engineering; Customers satisfaction diversity
ID INTERACTIVE GENETIC ALGORITHM; EVOLUTIONARY COMPUTATION; INTERFACE
   DESIGN; SYSTEM; PREFERENCES; MODEL; OPTIMIZATION; TECHNOLOGY;
   ATTRIBUTES; SIMULATION
AB Product customization in response to the widely varying perceptual expectations of different customers is an effective means to obtain customer satisfaction. Rapidly optimizing products to meet the personalized needs of different customers while controlling costs and improving design efficiency remains a challenge. In the present paper, a higher satisfaction product customization model was proposed with aim of efficiently reducing the number of target research customers and rapidly generating customer-oriented product design. In this model, a clustering algorithm based on emotional preference and migratory behavior (EPMC) was combined with a coupled model of interactive genetic algorithm with hesitancy-based interval individual fitness (IGA-HIIF) and Kansei Engineering (KE) method. This is the first implementation of EPMC in the customer research field, and the output content is optimized, which makes it capable of quickly dividing the multi-dimensional customer data space constructed in this study and accurately identifying different types of representative customers (RCs). And then, coupled the IGA-HIIF and KE model was adopted to establish a customer-oriented product evolution design system (PEDS). Finally, the most satisfactory products were auto-generated by PEDS with the participation of the RCs. The proposed method was applied to a case of social robot design. The result verifies that the approach could reduce the number of target research customers effectively without reducing diversity, allow direct customer involvement in the design process, and accurately extracts customers' personalized emotional implicit information and preference differences.
C1 [Wang, Zhengyu; Sun, Xin; Zhou, Meiyu] East China Univ Sci & Technol, Sch Art Design & Media, Meilong Rd, 130, Shanghai 200237, Peoples R China.
   [Dai, Mingzhi] East China Univ Sci & Technol, Sch Informat Sci & Engn, Meilong Rd, 130, Shanghai 200237, Peoples R China.
   [Sun, Xin] Qinghai Univ, Sch Mech Engn, Ningda Rd, 251, Xining 810016, Qinghai, Peoples R China.
C3 East China University of Science & Technology; East China University of
   Science & Technology; Qinghai University
RP Zhou, MY (corresponding author), East China Univ Sci & Technol, Sch Art Design & Media, Meilong Rd, 130, Shanghai 200237, Peoples R China.
EM myzhou@ecust.edu.cn
RI Dai, MingZhi/ABW-3163-2022; Dai, Mingzhi/JPL-2836-2023
OI Dai, Mingzhi/0000-0001-9380-8559
FU 2019 Shanghai Art Science Planning Project [ZD2018F01]
FX The authors would like to thank the editing and be grateful to all
   anonymous reviewers for the helpful improvement of this paper. This work
   was supported by the 2019 Shanghai Art Science Planning Project
   (ZD2018F01). Finally, Zhengyu Wang would like to thank her husband, Dr.
   Wang, for his patience, care and support during the writing and revision
   of this paper.
CR Agost MJ, 2014, APPL ERGON, V45, P1076, DOI 10.1016/j.apergo.2014.01.008
   Akase R, 2014, INT J SPACE-BASED SI, V4, P143, DOI 10.1504/IJSSC.2014.066031
   Ariannezhad M, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2867, DOI 10.1145/3459637.3482208
   Avikal S, 2020, J INTELL MANUF, V31, P271, DOI 10.1007/s10845-018-1444-5
   Berry C, 2013, J MANUF SYST, V32, P404, DOI 10.1016/j.jmsy.2013.04.012
   Bu K, 2016, J BUS RES, V69, P1656, DOI 10.1016/j.jbusres.2015.10.034
   Bush BJ, 2011, IEEE T EVOLUT COMPUT, V15, P424, DOI 10.1109/TEVC.2010.2096539
   Chen Y, 2019, NUCL ENG TECHNOL, V51, P453, DOI 10.1016/j.net.2018.10.010
   Chiu MC, 2018, ADV ENG INFORM, V38, P826, DOI 10.1016/j.aei.2018.11.002
   Cross N., 2021, ENG DESIGN METHODS S
   Cui HL, 2021, INTELL AUTOM SOFT CO, V28, P277, DOI 10.32604/iasc.2021.016408
   Darani ZS, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0119-0
   Desmet P M., 2021, Emotion Measurement, V2, P645, DOI DOI 10.1016/B978-0-12-821124-3.00020-X
   Dou RL, 2020, COMPUT IND ENG, V142, DOI 10.1016/j.cie.2020.106336
   Dou RL, 2019, J INTELL MANUF, V30, P2587, DOI 10.1007/s10845-016-1280-4
   Dou RL, 2018, COMPUT IND ENG, V125, P708, DOI 10.1016/j.cie.2018.04.056
   Dou RL, 2016, KNOWL-BASED SYST, V92, P43, DOI 10.1016/j.knosys.2015.10.013
   Dou RL, 2016, APPL SOFT COMPUT, V38, P384, DOI 10.1016/j.asoc.2015.10.018
   Fang C, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13101789
   Feng X, 2020, SOFT COMPUT, V24, P7163, DOI 10.1007/s00500-019-04333-4
   Franke N, 2010, MANAGE SCI, V56, P125, DOI 10.1287/mnsc.1090.1077
   Ho CH, 2015, KSII T INTERNET INF, V9, P2251, DOI 10.3837/tiis.2015.06.016
   Hsiao SW, 2013, INT J IND ERGONOM, V43, P264, DOI 10.1016/j.ergon.2013.04.003
   Hsiao SW, 2013, COLOR RES APPL, V38, P375, DOI 10.1002/col.21730
   Hu YJ, 2021, INT J FUZZY SYST, V23, P1755, DOI 10.1007/s40815-021-01071-4
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Hui Zhang, 2020, Journal of Physics: Conference Series, V1693, DOI 10.1088/1742-6596/1693/1/012186
   Jin J, 2022, INT J PROD RES, V60, P6708, DOI 10.1080/00207543.2021.1949641
   Ju CH, 2017, MULTIMED TOOLS APPL, V76, P17577, DOI 10.1007/s11042-017-4408-4
   Kang XH, 2021, J CLEAN PROD, V304, DOI 10.1016/j.jclepro.2021.127137
   Kang XH, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8863727
   Kim HS, 2000, ENG APPL ARTIF INTEL, V13, P635, DOI 10.1016/S0952-1976(00)00045-2
   Kim SK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050763
   Lee YC, 2009, EXPERT SYST APPL, V36, P4479, DOI 10.1016/j.eswa.2008.05.034
   Li L, 2014, COMPUT IND ENG, V77, P80, DOI 10.1016/j.cie.2014.09.009
   Li X, 2021, J ENG DESIGN, V32, P559, DOI 10.1080/09544828.2021.1928023
   Li YF, 2019, RES ENG DES, V30, P3, DOI 10.1007/s00163-018-0297-4
   Lokman A.M., 2017, ADV SCI LETT, V23, P4349, DOI DOI 10.1166/asl.2017.8329
   Ma Q, 2016, APPL ERGON, V54, P62, DOI 10.1016/j.apergo.2015.11.015
   Meeran S, 2017, EUR J OPER RES, V258, P512, DOI 10.1016/j.ejor.2016.08.047
   Micevski M, 2019, J BUS RES, V104, P622, DOI 10.1016/j.jbusres.2018.11.026
   Mikulic J, 2011, MANAG SERV QUAL, V21, P46, DOI 10.1108/09604521111100243
   Mok PY, 2013, COMPUT AIDED DESIGN, V45, P1442, DOI 10.1016/j.cad.2013.06.014
   Nagamachi M, 2002, APPL ERGON, V33, P289, DOI 10.1016/S0003-6870(02)00019-4
   Pacaux-Lemoine MP, 2017, COMPUT IND ENG, V111, P581, DOI 10.1016/j.cie.2017.05.014
   Park SW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101216
   Quan HF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122397
   Shahzadeh A, 2015, IEEE IJCNN
   Shen HC, 2016, J AMB INTEL HUM COMP, V7, P875, DOI 10.1007/s12652-016-0402-3
   Smith ER, 2020, PERS SOC PSYCHOL B, V46, P1270, DOI 10.1177/0146167219900439
   Stylianou AC, 1997, DATA BASE ADV INF SY, V28, P59
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   Tan CB, 2020, J MANUF SYST, V56, P72, DOI 10.1016/j.jmsy.2020.05.006
   Tang J, 2015, P AAAI C ART INT
   Wagner C, 2015, IEEE T FUZZY SYST, V23, P248, DOI 10.1109/TFUZZ.2014.2310734
   Wang HF, 2016, ENTERP INF SYST-UK, V10, P268, DOI 10.1080/17517575.2015.1078913
   Wang KC, 2011, EXPERT SYST APPL, V38, P8738, DOI 10.1016/j.eswa.2011.01.083
   Wang SF, 2006, IEEE C EVOL COMPUTAT, P2180
   Wang TX, 2020, INT J IND ERGONOM, V76, DOI 10.1016/j.ergon.2019.102901
   Wei DY, 2020, CASE STUD THERM ENG, V19, DOI 10.1016/j.csite.2020.100618
   Wei Z, 2021, INT J BIO-INSPIR COM, V17, P42, DOI 10.1504/IJBIC.2021.113364
   Wong TC, 2015, INT J PROD RES, V53, P4050, DOI 10.1080/00207543.2014.988886
   Wu L, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6391463
   Wu TT, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INFORMATION SYSTEMS (ICAIIS), P462, DOI [10.1109/icaiis49377.2020.9194941, 10.1109/ICAIIS49377.2020.9194941]
   Xu GX, 2020, INFORM SCIENCES, V515, P280, DOI 10.1016/j.ins.2019.12.019
   Yang X, 2021, J CLEAN PROD, V298, DOI 10.1016/j.jclepro.2021.126823
   Yannou B, 2013, MECH IND, V14, P1, DOI 10.1051/meca/2013053
   Yoo JJW, 2016, ENG OPTIMIZ, V48, P985, DOI 10.1080/0305215X.2015.1080578
   Zeng D, 2021, HUM-CENT COMPUT INFO, V11, DOI 10.22967/HCIS.2021.11.015
   Zhai LY, 2009, INT J IND ERGONOM, V39, P295, DOI 10.1016/j.ergon.2008.11.003
   Zhang C, 2020, APPL INTELL, V50, P1725, DOI 10.1007/s10489-019-01577-3
   Zhang ZY, 2021, CONSTR BUILD MATER, V298, DOI 10.1016/j.conbuildmat.2021.123847
   Zhou XK, 2015, MULTIMED TOOLS APPL, V74, P5015, DOI 10.1007/s11042-014-2230-9
NR 73
TC 0
Z9 0
U1 16
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15332-x
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400004
DA 2024-07-18
ER

PT J
AU Saurabh
   Dhanaraj, RK
AF Saurabh
   Dhanaraj, Rajesh Kumar
TI Enhance QoS with fog computing based on sigmoid NN clustering and
   entropy-based scheduling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud computing; Internet of Things; Fog computing; Sigmoid-based Neural
   Network Clustering (SNNC) as well as Entropy-based Scheduling (EBS); QoS
ID SERVICE PLACEMENT; IOT; ARCHITECTURE; REQUIREMENTS; ALGORITHM; MODEL
AB The exponential expansion in the number of smart devices in the burgeoning Internet of Things (IoT) is driving the growing demand for effective storage techniques. Cloud computing has shown to be an excellent alternative for storing and processing enormous amounts of data thus far. Cloud computing, on the other hand, is predicted to be unable to successfully handle a significant number of IoT devices in the coming years due to bandwidth constraints. Fog computing is a novel technology that is supposed to solve many of the problems associated with large-scale networks on the Internet of Things. Fog computing brings high-quality cloud services closer to mobile users. To overcome all the existing drawbacks, this study improves QoS using fog computing based on Sigmoid Neural Network Clustering (SNNC) and Entropy-Based Scheduling (EBS). The work of the IoT sensors is to collect all the data and send them to the fog computing tier. After that, fog computing performs score value calculation for each fog node based on SNNC as well as EBS. Here, the data and information collected by the edge devices are analyzed in this tier. Cloud Computing manages the various actions that are to be performed by the system. A component of the monitoring runs on the sensors which enable the sensors to collect data and send it to the fog layer also the cloud computing tier constantly supervises the system. The experimental results QoS show that our proposed strategy outperforms the traditional method.
C1 [Saurabh; Dhanaraj, Rajesh Kumar] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, UP, India.
   [Saurabh] KIET Grp Inst, Ghaziabad, UP, India.
   [Dhanaraj, Rajesh Kumar] Symbiosis Int Deemed Univ, Pune, India.
C3 Galgotias University; KIET Group of Institutions; Symbiosis
   International University
RP Saurabh (corresponding author), Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, UP, India.; Saurabh (corresponding author), KIET Grp Inst, Ghaziabad, UP, India.
EM sauravsharma1437@gmail.com
RI Dhanaraj, Rajesh Kumar/AAQ-6545-2021
OI Dhanaraj, Rajesh Kumar/0000-0002-2038-7359
CR Aazam M, 2018, IEEE COMMUN MAG, V56, P46, DOI 10.1109/MCOM.2018.1700707
   Albouq SS, 2020, IEEE ACCESS, V8, P129415, DOI 10.1109/ACCESS.2020.3009200
   Anawar MR, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/7157192
   Badawy MM, 2020, CLUSTER COMPUT, V23, P575, DOI 10.1007/s10586-019-02945-x
   Ben Hassen H, 2019, HEALTH INF SCI SYST, V7, DOI 10.1007/s13755-019-0087-z
   Brian R, 2018, INT CONF UTIL CLOUD, P252, DOI 10.1109/UCC-Companion.2018.00064
   Brogi A, 2017, IEEE INTERNET THINGS, V4, P1185, DOI 10.1109/JIOT.2017.2701408
   Byers CC, 2017, IEEE COMMUN MAG, V55, P14, DOI 10.1109/MCOM.2017.1600885
   Chen H, 2015, 2015 IEEE 40TH LOCAL COMPUTER NETWORKS CONFERENCE WORKSHOPS (LCN WORKSHOPS), P708, DOI 10.1109/LCNW.2015.7365918
   Deepa N, 2020, J AMBIENT INTELL HUM, P1
   Dutton LM, 2020, P 30 ANN INT C COMPU, P189
   Ghobaei-Arani M, 2022, EXPERT SYST APPL, V200, DOI 10.1016/j.eswa.2022.117012
   Goudarzi M, 2020, IEEE T MOBILE COMPUT
   Habibi P, 2020, IEEE ACCESS, V8, P69105, DOI 10.1109/ACCESS.2020.2983253
   Hussein MK, 2020, IEEE ACCESS, V8, P37191, DOI 10.1109/ACCESS.2020.2975741
   Jaiswal K., 2019, WIRELESS PERS COMMUN, V111, P1
   Jamil B, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5581
   Lera I, 2019, IEEE INTERNET THINGS, V6, P3641, DOI 10.1109/JIOT.2018.2889511
   Liu C, 2022, NEURAL PROCESS LETT, V54, P1823, DOI 10.1007/s11063-021-10708-2
   Luo J, 2019, FUTURE GENER COMP SY, V97, P50, DOI 10.1016/j.future.2018.12.063
   Mahmud R, 2019, J PARALLEL DISTR COM, V132, P190, DOI 10.1016/j.jpdc.2018.03.004
   Mao HZ, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P270, DOI 10.1145/3341302.3342080
   Misra S, 2019, IEEE J SEL AREA COMM, V37, P1159, DOI 10.1109/JSAC.2019.2906793
   Naha RK, 2018, IEEE ACCESS, V6, P47980, DOI 10.1109/ACCESS.2018.2866491
   Nashaat H, 2020, IEEE ACCESS, V8, P111253, DOI 10.1109/ACCESS.2020.3003249
   Nguyen H, 2020, NAT RESOUR RES, V29, P691, DOI 10.1007/s11053-019-09470-z
   Nguyen ND, 2020, IEEE ACCESS, V8, P183879, DOI 10.1109/ACCESS.2020.3029583
   Ni JB, 2018, IEEE COMMUN SURV TUT, V20, P601, DOI 10.1109/COMST.2017.2762345
   Omoniwa B, 2019, IEEE INTERNET THINGS, V6, P4118, DOI 10.1109/JIOT.2018.2875544
   Santos-Sales A, 2019, AQUICHAN, V19
   Tordera E. M., 2016, arXiv
   Verma P, 2018, IEEE INTERNET THINGS, V5, P1789, DOI 10.1109/JIOT.2018.2803201
   Vilela PH, 2019, FUTURE GENER COMP SY, V97, P379, DOI 10.1016/j.future.2019.02.055
   Wanto A., 2017, International Journal Of Information System Technology, V1, P43, DOI DOI 10.30645/IJISTECH.V1I1.6
   Yan HQ, 2019, NEUROCOMPUTING, V329, P348, DOI 10.1016/j.neucom.2018.10.067
   Yang WC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164507
   Zhang HW, 2018, APPL SOFT COMPUT, V73, P862, DOI 10.1016/j.asoc.2018.09.022
NR 37
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15685-3
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZR2
UT WOS:000988581800001
DA 2024-07-18
ER

PT J
AU Mukhopadhyay, A
   Nandi, D
   Pal, U
   Chakraborty, B
AF Mukhopadhyay, Amit
   Nandi, Debashis
   Pal, Umapada
   Chakraborty, Baisakhi
TI CCOCSA-based multi-frame sparse coding super-resolution via mutual
   information-based weighted image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Super-resolution; Multi-frame registration; Crow search Algorithm;
   Sparse-based super-resolution; MFSR reconstruction; Image fusion
ID OPTIMIZATION ALGORITHM; REPRESENTATION; RESOLUTION
AB Image super-resolution (SR) is one of the most urgent requirements in many applications in computer vision. Though many techniques have been proposed to date, they are not suitable in real-life applications because of their lack of performance when the low resolution (LR) images are noisy. In the single-frame SR mechanism, the output image can not reproduce the information which is lost due to sub-sampling at the time of image formation. Multi-frame image SR technique can solve this problem to a reasonable extent. However, most of the multi-frame image SR techniques are based on image registration which is noise sensitive. The registration errors in noisy LR images deteriorate the performance of the registration process and hence the performance of the multi-frame SR algorithms. This paper addresses this problem and proposes a novel mutual information-based multi-frame sparse coding super-resolution via Chaotic Centroid-Oppositional Crow Search Optimization Algorithm (CCOCSA)-based image registration. The proposed SR algorithm is accomplished in two steps: (1) CCOCSA-based image registration and (2) Mutual information-based weighted mean multi-frame super-resolution reconstruction through sparse representation. The proposed CCOCSA is a noise-robust optimization that provides better accuracy in estimating registration parameters. We achieve this by enhancing the exploration by dynamically varying the control parameters and introducing chaos within the algorithm. The weighted mean of the registered LR frames based on mutual information provides a good noise reduction capability. Also, it gathers the information from all the LR frames on the registered weighted mean frame, which enriches the information in the reconstructed SR image. The performance of the proposed algorithm is tested through the experiments on four benchmark datasets (Vid4, McMaster, Milanfar, and Kodak) for videos and still images. We verify the performance of the proposed technique by computing four well-known quality metrics, such as Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Measure (SSIM), Edge Keeping Index (EKI), blur-metric, and Perceptual SIMilarity (PSIM) measure. The experimental results show that the proposed SR algorithm outperforms the others quantitatively and qualitatively.
C1 [Mukhopadhyay, Amit; Nandi, Debashis; Chakraborty, Baisakhi] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur 713209, India.
   [Pal, Umapada] Indian Stat Inst, CVPR Unit, Kolkata 700009, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Indian Statistical Institute; Indian Statistical
   Institute Kolkata
RP Nandi, D (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur 713209, India.
EM amit.nit.durgapur@gmail.com; debashis@cse.nitdgp.ac.in;
   umapada@isical.ac.in; baisakhi@cse.nitdgp.ac.in
OI Chakraborty, Baisakhi/0000-0002-3907-8230
CR An T, 2022, IEEE J-STARS, V15, P1373, DOI 10.1109/JSTARS.2022.3143532
   Anter AM, 2020, SOFT COMPUT, V24, P1565, DOI 10.1007/s00500-019-03988-3
   Anter AM, 2019, EXPERT SYST APPL, V118, P340, DOI 10.1016/j.eswa.2018.10.009
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Chakraborty F, 2021, SOFT COMPUT, V25, P6973, DOI 10.1007/s00500-021-05611-w
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chaudhuri A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114288
   Chen X., 2018, MACHINE LEARNING INT, DOI [10.1007/978-3-030-00557-3_14, DOI 10.1007/978-3-030-00557-3_14]
   Cheng M, 2015, IET IMAGE PROCESS, V9, P461, DOI 10.1049/iet-ipr.2014.0313
   Trinh DH, 2014, IEEE T IMAGE PROCESS, V23, P1882, DOI 10.1109/TIP.2014.2308422
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   dos Santos Coelho Leandro, 2016, 2016 IEEE Conference on Electromagnetic Field Computation (CEFC), DOI 10.1109/CEFC.2016.7815927
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gupta D, 2020, NEURAL COMPUT APPL, V32, P10915, DOI 10.1007/s00521-018-3688-6
   Han XX, 2020, IEEE ACCESS, V8, P92363, DOI 10.1109/ACCESS.2020.2980300
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Karthikumar K, 2021, SOFT COMPUT, V25, P2575, DOI 10.1007/s00500-020-05280-1
   Kato T, 2017, NEUROCOMPUTING, V240, P115, DOI 10.1016/j.neucom.2017.02.043
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kodak E., Kodak lossless true color image suite (PhotoCD PCD0992)
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   Majhi SK, 2021, EVOL SYST-GER, V12, P463, DOI 10.1007/s12530-019-09305-5
   Mandavi S, 2018, SWARM EVOL COMPUT, V39, P1, DOI 10.1016/j.swevo.2017.09.010
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mohammadi F, 2018, APPL SOFT COMPUT, V71, P51, DOI 10.1016/j.asoc.2018.06.040
   Morales-Castañeda B, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100671
   Mousavi HS, 2017, IEEE T IMAGE PROCESS, V26, P5094, DOI 10.1109/TIP.2017.2704443
   Nandi D, 2019, IET IMAGE PROCESS, V13, P663, DOI 10.1049/iet-ipr.2018.5139
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   Ouadfel S, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113572
   Peng Wang, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P357, DOI 10.1109/CMSP.2011.79
   Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200
   Sayed GI, 2019, NEURAL COMPUT APPL, V31, P171, DOI 10.1007/s00521-017-2988-6
   Sharma M, 2021, ARCH COMPUT METHOD E, V28, P1103, DOI 10.1007/s11831-020-09412-6
   Shekhawat S, 2020, ISA T, V99, P210, DOI 10.1016/j.isatra.2019.09.004
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Vella M, 2021, IEEE T IMAGE PROCESS, V30, P7830, DOI 10.1109/TIP.2021.3108907
   Wachowiak MP, 2004, IEEE T EVOLUT COMPUT, V8, P289, DOI 10.1109/tevc.2004.826068
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang Y, 2008, IEEE IMAGE PROC, P345, DOI 10.1109/ICIP.2008.4711762
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Wronski B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323024
   Wu W, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3580750
   Xu QZ, 2014, ENG APPL ARTIF INTEL, V29, P1, DOI 10.1016/j.engappai.2013.12.004
   Xu ZG, 2020, J SYST ENG ELECTRON, V31, P266, DOI 10.23919/JSEE.2020.000004
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Zamani H, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105583
   Zhang K, 2016, IEEE SIGNAL PROC LET, V23, P102, DOI 10.1109/LSP.2015.2504121
   Zhang QP, 2020, IEEE T GEOSCI REMOTE, V58, P6534, DOI 10.1109/TGRS.2020.2977719
   Zolghadr-Asli B, 2018, STUD COMPUT INTELL, V720, P143, DOI 10.1007/978-981-10-5221-7_14
NR 57
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15647-9
EA MAY 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200009
DA 2024-07-18
ER

PT J
AU Yan, SM
   Xu, SC
   Yang, WZ
   Zhang, SY
AF Yan, Simin
   Xu, Shuchang
   Yang, Wenzhen
   Zhang, Sanyuan
TI Image recoloring based on fast and flexible palette extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recoloring; Image decomposition; Palette extraction
AB Many operations, such as color transfer, recoloring, and image decomposition, are involved in the color manipulation of image editing. This paper introduces a simple, intuitive and interactive tool that allows non-experts to recolor an image by editing a color palette. First, we introduce a network that extracts a color palette from an image. Then, we introduce a network that decomposes the image into weighted layers, each corresponding to a palette color. In addition, a method is proposed to generate a variable-size palette and corresponding weighted layers. Applications such as image recoloring can be performed based on the final palette combined with the weighted layers. Our experiments show that it is much faster than the state-of-the-art image recoloring methods while keeping a better visual effect. Our algorithm can extract the palette from a 256x256 image in 0.077 s with the smallest palette loss 0.052 and then recolor the image in 0.3 s average.
C1 [Yan, Simin; Zhang, Sanyuan] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Xu, Shuchang] Hangzhou Normal Univ, Coll Informat Sci & Technol, Hangzhou, Peoples R China.
   [Yang, Wenzhen] Zhejiang Lab, Inst Intelligent Percept Res, Hangzhou, Peoples R China.
C3 Zhejiang University; Hangzhou Normal University; Zhejiang Laboratory
RP Xu, SC (corresponding author), Hangzhou Normal Univ, Coll Informat Sci & Technol, Hangzhou, Peoples R China.
EM yansimin@zju.edu.cn; xusc@hznu.edu.cn; ywz@zhejianglab.edu.cn;
   syzhang@zju.edu.cn
RI Yan, Simin/JGD-1012-2023; Yang, Wenzhen/HHY-7607-2022
OI Yan, Simin/0000-0002-2192-0717; Yang, Wenzhen/0000-0002-0068-1497; Xu,
   Shuchang/0000-0002-4742-2759
FU Beijing Dailybread Co., Ltd.; National Key Research and Development
   Program of China [2021YFF0600203]; Major Scientific Research Project of
   the Zhejiang Laboratory [2022MG0AC04]
FX We thank Yu Zhang for her help with the experiments and Zeeshan Tahir
   for his help to correct the language. This work was supported by Beijing
   Dailybread Co., Ltd.; the National Key Research and Development Program
   of China (2021YFF0600203); and the Major Scientific Research Project of
   the Zhejiang Laboratory (2022MG0AC04).
CR Afifi M, 2021, PROC CVPR IEEE, P7937, DOI 10.1109/CVPR46437.2021.00785
   Aharoni-Mack E., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, NPAR'17, DOI DOI 10.1145/3092919.3092926
   Ahmed S.T., NEW TRENDS COMPUTATI, P1121
   Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen JW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982423
   Chen XW, 2014, PROC CVPR IEEE, pCP5, DOI 10.1109/CVPR.2014.365
   Cho J, 2017, IEEE COMPUT SOC CONF, P1058, DOI 10.1109/CVPRW.2017.143
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Ding XW, 2012, LECT NOTES COMPUT SC, V7131, P103
   Dubey SR, 2020, IEEE T NEUR NET LEAR, V31, P4500, DOI 10.1109/TNNLS.2019.2955777
   Gupta R. K., 2012, P 20 ACM INT C MULT, P369, DOI DOI 10.1145/2393347.2393402
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Kim S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459776
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li Y, 2010, COMPUT GRAPH FORUM, V29, P2049, DOI 10.1111/j.1467-8659.2010.01791.x
   Li ZQ, 2020, LECT NOTES COMPUT SC, V11961, P127, DOI 10.1007/978-3-030-37731-1_11
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Matsui Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P661, DOI 10.1145/2733373.2807997
   Morse Bryan S., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P497
   ODonovan Peter, 2011, ACM SIGGRAPH 2011 papers, P1
   Phan HQ, 2018, IEEE T VIS COMPUT GR, V24, P1942, DOI 10.1109/TVCG.2017.2697948
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Shi Yang, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555534
   Tan JC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275054
   Tan JC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2988229
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang XH, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5589711
   Wang Y, 2022, LECT NOTES COMPUT SC, V13675, P271, DOI 10.1007/978-3-031-19784-0_16
   Yang J, 2020, COLOR RES APPL, V45, P401, DOI 10.1002/col.22492
   Zhang Q, 2022, IEEE T MULTIMEDIA, V24, P1545, DOI 10.1109/TMM.2021.3067463
   Zhang Q, 2017, IEEE T IMAGE PROCESS, V26, P1952, DOI 10.1109/TIP.2017.2671779
NR 33
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47793
EP 47810
DI 10.1007/s11042-023-15114-5
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986346600005
DA 2024-07-18
ER

PT J
AU Sushir, RD
   Wakde, DG
   Bhutada, SS
AF Sushir, Rupesh D.
   Wakde, Dinkar Govindrao
   Bhutada, Sarita S.
TI Enhanced blind image forgery detection using an accurate deep learning
   based hybrid DCCAE and ADFC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital images; Blind forgery detection; Deep learning; Image forgery;
   Adaptive density based fuzzy clustering
ID COPY-MOVE; NETWORK
AB Currently, digital images are easily manipulated using different image editing tools, and they are difficult to detect. Forgery detection is a hot research topic in security and forensics applications. Several computational methods have been employed to detect blind image forgeries, but efficiency is reduced due to drawbacks such as the lack of appropriate techniques and reduced accuracy. Therefore, this work presents an optimal blind forgery detection using deep learning approaches. Initially, the input forgery images are pre-processed using wiener filtering-contrast limited enhanced histogram equalization (WE-CLAHE) approach. Effective features are extracted from the clustered data using Hybrid dual-tree complex wavelet trigonometric transform (Hybrid DTT) and VGGNet. The feature dimensionality is reduced through improved horse herd optimization (IHH). Finally, a hybrid deep convolutional capsule auto encoder (Hybrid DCCAE) framework is presented for optimal image forgery recognition. The adaptive density-based fuzzy clustering (ADFC) approach is presented to segment similar pixel regions. The accuracy of CASIA V1 dataset is 99.23%, the coverage dataset 98.75% accuracy, and the GRIP dataset is 98.07% accuracy. The deep learning based proposed approach enhances the performance of forgery detection better than the existing approaches.
C1 [Sushir, Rupesh D.] PR Pote Coll Engn & Management Amravati, Dept Elect & Telecommun, Amravati, India.
   [Wakde, Dinkar Govindrao] PR Patil Coll Engn & Technol, Kathora Rd, Amravati, India.
   [Bhutada, Sarita S.] PR Pote Coll Engn & Management Amravati, Elect & Telecommun Engn, Amravati, India.
RP Sushir, RD (corresponding author), PR Pote Coll Engn & Management Amravati, Dept Elect & Telecommun, Amravati, India.
EM rupeshsushir18@gmail.com
CR Abbas MN, 2021, 2021 IEEE 19 WORLD S
   Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   Vega EAA, 2020, IEEE ACCESS, V8, P11815, DOI 10.1109/ACCESS.2020.2964516
   Barni M, 2020, IEEE T INFORM FORENS
   Bi XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14274, DOI 10.1109/ICCV48922.2021.01403
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Chen H, 2021, MULTIMED SYST, P1
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   El Biach FZ, 2021, MULTIMED TOOLS APPL, P1
   El-Latif A, 2020, ARAB J SCI ENG, V45
   Elsharkawy ZF, 2019, MULTIMED TOOLS APPL, V78, P21585, DOI 10.1007/s11042-019-7206-3
   Farooq S, 2017, COMPUT ELECTR ENG, V62, P459, DOI 10.1016/j.compeleceng.2017.05.008
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gardella M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070119
   Gavade Jayashree D., 2021, International Journal of Information and Computer Security, V14, P300, DOI 10.1504/IJICS.2021.114707
   Habibi M, 2021, INT J ENG-IRAN, V34, P443, DOI 10.5829/ije.2021.34.02b.16
   Hebbar N.K., 2021, ICTACT J IMAGE VIDEO, V11, P2447
   Jaiprakash SP, 2020, MULTIMED TOOLS APPL, V79, P29977, DOI 10.1007/s11042-020-09415-2
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Meena KB, 2020, MULTIMED TOOLS APPL, V79, P8197, DOI 10.1007/s11042-019-08343-0
   Panda S., 2018, ADV ELECT COMMUNICAT, P281, DOI [10.1007/978-981-10-4765-7_29, DOI 10.1007/978-981-10-4765-7_29]
   Prakash CS, 2018, MULTIMED TOOLS APPL, V77, P26939, DOI 10.1007/s11042-018-5899-3
   Pun C. -M., 2015, IEEE Trans. Inf. Forensics Secur
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rao Y, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108051
   Rathore NK, 2021, NATL ACAD SCI LETT, V44, P331, DOI 10.1007/s40009-020-00998-w
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shah TJ., 2021, TURKISH J COMPU MATH, V12, P37
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Siddiqi MH, 2021, IMSAGE SPLICING BASE
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Sun Y, 2018, NONOVERLAPPING BLOCK
   Thakur R, 2020, FORENSIC SCI INT, V312, DOI 10.1016/j.forsciint.2020.110311
   Ustubioglu B., 2016, SPRINGER CHAM, V2015, P127
   Vaishnavi D, 2019, J INF SECUR APPL, V44, P23, DOI 10.1016/j.jisa.2018.11.001
   Wang X., 2021, INT J DYNAM CONTROL, V20, DOI [DOI 10.1007/s40435-021-00893-2, 10.1186/s12939-020-01374-2]
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhong JL, 2016, NONLINEAR DYNAM, V84, P189, DOI 10.1007/s11071-015-2374-9
   Zhu Y, 2020, IEEE T IND INFORM, V16, P6714, DOI 10.1109/TII.2020.2982705
NR 49
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15475-x
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600003
DA 2024-07-18
ER

PT J
AU Al Mahrouqi, K
   Mostafa, MM
AF Al Mahrouqi, Khalid
   Mostafa, Mohamed M.
TI Neural correlates of Quran recitals: a functional magnetic resonance
   imaging (fMRI) analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quran; fMRI; Religious neuroscience; Spiritual experience
ID CEREBRAL-BLOOD-FLOW; ANTERIOR CINGULATE; RELIGIOUS BELIEF;
   FRONTAL-CORTEX; BRAIN; MEDITATION; PRAYER; MINDFULNESS; EXPERIENCE;
   RESPONSES
AB Religious experience is a uniquely human phenomenon present in all modern cultures. However, although there has recently been a growing interest in determining the neuroanatomical and neuropsychological foundations of the religious experience, virtually no studies have examined the neural correlates of Quran recitals. In this study, we fill this research gap via a block design fMRI paradigm based on three randomly repeated audio experimental conditions. The whole brain GLM results show that the brain networks involved in Quran recitation include the "empathy network", which includes the ACC and the insula, the "mentalizing network", which includes the superior temporal gyrus and the MFC, and the episodic memory network which includes the parietal brain regions. Broadly, our results are in line with the view that religious experience can be described via certain neural circuits mediating emotive processing and mental imagery.
C1 [Al Mahrouqi, Khalid] Minist Hlth, Directorate Diagnost Imaging & Intervent Radiol, Muscat, Oman.
   [Mostafa, Mohamed M.] Gulf Univ Sci & Technol, Kuwait, Kuwait.
C3 Gulf University for Science & Technology (GUST)
RP Mostafa, MM (corresponding author), Gulf Univ Sci & Technol, Kuwait, Kuwait.
EM mahool40@hotmail.com; mostafa@usa.com
OI Mostafa, Mohamed/0000-0002-1145-4919
CR ALQadhi A, 2001, KUWAIT TIMES
   AlTharshi A., 1992, ASSALAAT WARRIYADHIY
   Athar S., 1996, HLTH BELIEVERS CONT
   Azari N., 2001, 31RST ANN M SOC NEUR, P382
   Azari NinaP., 2005, International Journal for the Psychology of Religion, V15, P263, DOI DOI 10.1207/S15327582IJPR1504_1
   Azari NP, 2001, EUR J NEUROSCI, V13, P1649, DOI 10.1046/j.0953-816x.2001.01527.x
   Aziz AA, 2022, MENT HEALTH RELIG CU, V25, P1, DOI 10.1080/13674676.2021.2007228
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Bai ZF, 2021, MENT HEALTH RELIG CU, V24, P151, DOI 10.1080/13674676.2020.1826915
   Beauregard M, 2006, NEUROSCI LETT, V405, P186, DOI 10.1016/j.neulet.2006.06.060
   Brefczynski-Lewis JA, 2007, P NATL ACAD SCI USA, V104, P11483, DOI 10.1073/pnas.0606552104
   Bærentsen KB, 2001, NEUROIMAGE, V13, pS297
   Buxton RB, 2004, NEUROIMAGE, V23, pS220, DOI 10.1016/j.neuroimage.2004.07.013
   Cabeza R, 2008, NAT REV NEUROSCI, V9, P613, DOI 10.1038/nrn2459
   Calarge C, 2003, AM J PSYCHIAT, V160, P1954, DOI 10.1176/appi.ajp.160.11.1954
   Cohen D, 2020, MENT HEALTH RELIG CU, V23, P375, DOI 10.1080/13674676.2020.1725454
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Creswell JD, 2007, PSYCHOSOM MED, V69, P560, DOI 10.1097/PSY.0b013e3180f6171f
   Dadfar M, 2021, MENT HEALTH RELIG CU, V24, P128, DOI 10.1080/13674676.2020.1767554
   Deeley Peter Q, 2004, Anthropol Med, V11, P245, DOI 10.1080/1364847042000296554
   Desmond JE, 2002, J NEUROSCI METH, V118, P115, DOI 10.1016/S0165-0270(02)00121-8
   Devinsky O, 2008, EPILEPSY BEHAV, V12, P636, DOI 10.1016/j.yebeh.2007.11.011
   Dong Y, 2005, NEUROSCI RES, V52, P139, DOI 10.1016/j.neures.2005.02.005
   Dossey Larry., 1996, PRAYER IS GOOD MED
   Durkheim Emile., 2001, ELEM FORMS RELIG LIF
   Elmholdt EM, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00337
   Farb NAS, 2007, SOC COGN AFFECT NEUR, V2, P313, DOI 10.1093/scan/nsm030
   Ferguson MA, 2018, SOC NEUROSCI-UK, V13, P104, DOI 10.1080/17470919.2016.1257437
   Fletcher PC, 2001, NAT NEUROSCI, V4, P1043, DOI 10.1038/nn733
   FRISTON KJ, 1995, NEUROIMAGE, V2, P166, DOI 10.1006/nimg.1995.1019
   Fuster J., 2003, Cortex and mind: Unifying cognition
   Galanter M, 2017, AM J DRUG ALCOHOL AB, V43, P44, DOI 10.3109/00952990.2016.1141912
   Geertz A., 2004, COGNITIVE APPROACHES
   Grinband J, 2006, NEURON, V49, P757, DOI 10.1016/j.neuron.2006.01.032
   Han HM, 2016, BEHAV BRAIN RES, V302, P237, DOI 10.1016/j.bbr.2016.01.001
   Han SH, 2008, SOC NEUROSCI-UK, V3, P1, DOI 10.1080/17470910701469681
   Harris S, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0007272
   Hölzel BK, 2007, NEUROSCI LETT, V421, P16, DOI 10.1016/j.neulet.2007.04.074
   Hoogeveen S, 2020, CORTEX, V129, P247, DOI 10.1016/j.cortex.2020.04.011
   Hook J., 2021, RELIG CULT, V24, P745
   Inzlicht M, 2011, RELIG BRAIN BEHAV, V1, P192, DOI 10.1080/2153599X.2011.647849
   Inzlicht M, 2010, PSYCHOL SCI, V21, P1184, DOI 10.1177/0956797610375451
   Inzlicht M, 2009, PSYCHOL SCI, V20, P385, DOI 10.1111/j.1467-9280.2009.02305.x
   Ives-Deliperi VL, 2011, SOC NEUROSCI-UK, V6, P231, DOI 10.1080/17470919.2010.513495
   James W., 1902, WILLIAM JAMES WRITIN, P1
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Jeppsen B, 2022, MENT HEALTH RELIG CU, V25, P99, DOI 10.1080/13674676.2021.2024801
   Keightley ML, 2011, SOC COGN AFFECT NEUR, V6, P24, DOI 10.1093/scan/nsq003
   Kennedy DP, 2012, TRENDS COGN SCI, V16, P559, DOI 10.1016/j.tics.2012.09.006
   Kober SE, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00271
   Lane RD, 1997, NEUROPSYCHOLOGIA, V35, P1437, DOI 10.1016/S0028-3932(97)00070-5
   Lazar SW, 2005, NEUROREPORT, V16, P1893, DOI 10.1097/01.wnr.0000186598.66243.19
   Lazar SW, 2000, NEUROREPORT, V11, P1581, DOI 10.1097/00001756-200005150-00041
   Lee A, 2010, J COGNITIVE NEUROSCI, V22
   Leszkowicz E, 2021, SOC NEUROSCI-UK, V16, P486, DOI 10.1080/17470919.2021.1953582
   Liu TT, 2004, NEUROIMAGE, V21, P387, DOI 10.1016/j.neuroimage.2003.09.030
   Manna A, 2010, BRAIN RES BULL, V82, P46, DOI 10.1016/j.brainresbull.2010.03.001
   McNamara P., 2009, The neuroscience of religious experience, DOI [https://doi.org/10.1017/CBO9780511605529, DOI 10.1017/CBO9780511605529]
   Meyer M, 2005, COGNITIVE BRAIN RES, V24, P291, DOI 10.1016/j.cogbrainres.2005.02.008
   Michelon P, 2003, NEUROIMAGE, V19, P1612, DOI 10.1016/S1053-8119(03)00111-3
   Mostafa M., 2013, J MARK COMMUN, V19, P341, DOI [10.1080/13527266.2011.653688, DOI 10.1080/13527266.2011.653688]
   Mostafa M.M., 2020, Journal of Marketing Communications, V26, P40, DOI [10.1080/13527266.2018.1497680, DOI 10.1080/13527266.2018.1497680]
   Mostafa MM, 2014, QUAL MARK RES, V17, P343, DOI 10.1108/QMR-06-2011-0003
   Mostafa MM, 2012, EXPERT SYST APPL, V39, P12114, DOI 10.1016/j.eswa.2012.04.003
   Murphy K, 2004, NEUROIMAGE, V22, P879, DOI 10.1016/j.neuroimage.2004.02.005
   Neubauer RL, 2014, RELIG BRAIN BEHAV, V4, P92, DOI 10.1080/2153599X.2013.768288
   Newberg A, 2003, PERCEPT MOTOR SKILL, V97, P625, DOI 10.2466/PMS.97.6.625-630
   Newberg A, 2001, PSYCHIAT RES-NEUROIM, V106, P113, DOI 10.1016/S0925-4927(01)00074-9
   Newberg AB, 2005, ZYGON, V40, P469, DOI 10.1111/j.1467-9744.2005.00675.x
   Newberg AB, 2011, GENERATIONS, V35, P83
   Newberg AB, 2006, PSYCHIAT RES-NEUROIM, V148, P67, DOI 10.1016/j.pscychresns.2006.07.001
   Op de Beeck HP, 2010, NEUROIMAGE, V49, P1943, DOI 10.1016/j.neuroimage.2009.02.047
   Parris BA, 2009, NEUROIMAGE, V45, P1033, DOI 10.1016/j.neuroimage.2008.12.036
   Peres JF, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0049360
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   POLOMA MM, 1991, J PSYCHOL THEOL, V19, P71, DOI 10.1177/009164719101900107
   Rahman F., 1987, Health and Medicine in the Islamic Tradition: Change and Identity
   Schjodt U, 2008, NEUROSCI LETT, V443, P165, DOI 10.1016/j.neulet.2008.07.068
   Schjoedt U, 2009, SOC COGN AFFECT NEUR, V4, P199, DOI 10.1093/scan/nsn050
   Schroeder U, 2004, HUM BRAIN MAPP, V23, P181, DOI 10.1002/hbm.20057
   Shaver KellyG., 1975, An Introduction to Attribution Process
   Tomasino B, 2014, BRAIN COGNITION, V90, P32, DOI 10.1016/j.bandc.2014.03.013
   Trimble M, 2006, EPILEPSY BEHAV, V9, P407, DOI 10.1016/j.yebeh.2006.05.006
   Underwood LG, 2002, ANN BEHAV MED, V24, P22, DOI 10.1207/S15324796ABM2401_04
   van Veen V, 2002, J COGNITIVE NEUROSCI, V14, P593, DOI 10.1162/08989290260045837
   Wang DJJ, 2011, PSYCHIAT RES-NEUROIM, V191, P60, DOI 10.1016/j.pscychresns.2010.09.011
   Whittington BL, 2010, INT J PSYCHOL RELIG, V20, P59, DOI 10.1080/10508610903146316
NR 87
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47719
EP 47732
DI 10.1007/s11042-023-15588-3
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800009
DA 2024-07-18
ER

PT J
AU Das, SK
   Dhara, BC
AF Das, Sujit Kumar
   Dhara, Bibhas Chandra
TI A new image encryption method using Bezier curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Bezier curve; Monotone curve; Parametric curve; S-Box;
   Statistical attacks; c(2) test; Plaintext attacks
ID CHAOS; SCHEME; MAP; CIPHER
AB In the present age of information, images contain sensitive and confidential information. It is essential to protect confidential images from unauthorized access and modification. Image encryption is a well-accepted solution to this problem. In this article, we have proposed a non-chaotic image encryption method. This work defines a new type of scan pattern using Bezier curves. The curves are defined over the image space to i) access the pixels, ii) define the permutations, and iii) define the S-Boxes. The present method is faster and is efficient for any grayscale image. The current method is robust against different attacks. The proposed method is as efficient as state-of-the-art methods, and this indicates that the proposed work can be used as a module in various applications.
C1 [Das, Sujit Kumar; Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Kolkata, India.
C3 Jadavpur University
RP Das, SK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata, India.
EM sujit.cse.jgec@gmail.com; bcdhara@gmail.com
RI Das, Sujit Kumar/JAN-9609-2023
OI Das, Sujit Kumar/0000-0002-8505-0044
CR Abbasi AA, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.106974
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   [Anonymous], 1999, 25 FIPS P DES, P46
   Biswas M, 2021, INT C COMP INT COMM, P42
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen W., 2016, IEEE PHOTONICS J, V8, P1
   Chen W, 2016, IEEE PHOTONICS J, V8, DOI 10.1109/JPHOT.2016.2550322
   Dagadu JC, 2019, MULTIMED TOOLS APPL, P1
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Das S, 2017, IEEE ICC
   Das SK, 2017, ADV PATTERN RECOGNIT, P1
   Das SK, 2017, INT CONF COMPUT
   Dongare AS., 2017, INT RES J ENG TECHNO, V4, P3186
   Dwivedi RK, 2021, INT J CLOUD APPL COM, V11, P1, DOI 10.4018/IJCAC.2021070101
   Essaid M, 2019, J INF SECUR APPL, V47, P173, DOI 10.1016/j.jisa.2019.05.006
   Farin G., 2002, HDB COMPUTER AIDED G
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Joshi Bineet, 2022, International Journal of Cloud Applications and Computing, DOI 10.4018/IJCAC.309936
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   LAI XJ, 1991, LECT NOTES COMPUT SC, V473, P389
   Li YH, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5182
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu HJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501632
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Mahmood AS, 2018, J INF SECUR APPL, V42, P57, DOI 10.1016/j.jisa.2018.08.001
   Maiti C, 2018, 2018 5 INT C EMERGIN, P1
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Nematzadeh H., 2020, OPTIK, V163505, P202
   Nithya R, 2022, NOVEL DOMINANT COLOR, V39
   Pub N.F., 2001, Federal inf. process. standards publication, V197, P311
   Rajagopalan S, 2019, MULTIMED TOOLS APPL, V78, P10513, DOI 10.1007/s11042-018-6574-4
   Salomon D, 2007, CURVES SURFACES COMP
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Si YY, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421501467
   sipi.usc, The USC-SIPI image database
   Sivakumar T., 2021, Journal of Physics: Conference Series, V1767, DOI 10.1088/1742-6596/1767/1/012044
   Sivakumar T, 2019, OPT LASER TECHNOL, V111, P196, DOI 10.1016/j.optlastec.2018.09.048
   Sivakumar T., 2014, IAENG International Journal of Computer Science, V41, P91
   Sokouti Massoud, 2016, Open Med Inform J, V10, P11
   Tang ZJ, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8694678
   Vidhya R, 2020, APPL INTELL, V50, P3101, DOI 10.1007/s10489-020-01697-1
   Wang R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102699
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang Y, 2016, OPT LASER ENG, V78, P8, DOI 10.1016/j.optlaseng.2015.09.008
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Yadollahi M., 2020, J INF SECUR APPL, V102505, P53
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang Y, 2020, INFORM SCIENCES, V520, P177, DOI 10.1016/j.ins.2020.02.012
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
NR 58
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46961
EP 47002
DI 10.1007/s11042-023-14919-8
EA MAY 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000007
DA 2024-07-18
ER

PT J
AU Li, RH
   Cheng, LL
   Wang, DP
   Tan, JM
AF Li, Ruihao
   Cheng, Lianglun
   Wang, Depei
   Tan, Junming
TI Siamese BERT Architecture Model with attention mechanism for Textual
   Semantic Similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Siamese network; Bert; Attention mechanism; Textual semantic similarity
ID NETWORK
AB Textual Semantic Similarity is a crucial part of text matching tasks, and it has a very wide range of applications in natural language processing (NLP) tasks such as search engines, question-answering systems, information retrieval, natural language inference. Although there are a variety of approaches about textual semantic similarity, many do not succeed in achieving the semantic representation of a sentence or text that represents it well, and ignore that different words serve different roles in expressing the meaning of the whole sentence in different degrees. Therefore, our paper proposes a Siamese Bert network model to obtain textual semantic similarity. Firstly, we utilize the Bert network model to obtain the semantic features of each word in the sentence as input and utilize the merit of the Siamese network, reducing the training parameters, sharing the same encoder and feature weight information with each other. Then we use the attention mechanism to obtain more advanced semantic features. Furthermore, the similarity between two sentences can be derived by the methods of calculating the distance or concatenating their high-level semantic representations. In this paper, we apply the network structure to three related semantic similarity datasets, which perform better than other approaches.
C1 [Li, Ruihao] Guangdong Univ Technol, Sch Phys & Optoelect Engn, Guangzhou 510006, Peoples R China.
   [Cheng, Lianglun; Tan, Junming] Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.
   [Wang, Depei] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology; Guangdong University of Technology;
   Guangdong University of Technology
RP Li, RH (corresponding author), Guangdong Univ Technol, Sch Phys & Optoelect Engn, Guangzhou 510006, Peoples R China.
EM 178907357@qq.com; LLcheng@gdut.edu.cn; depeiwang@qq.com;
   597134783@qq.com
OI Wang, Depei/0000-0001-6972-5876
FU Key-Area Research and Development Program of Guangdong Province
   [2019B010153002]; Key Program of NSFC-Guangdong Joint Funds [U1701262,
   U1801263]; National Natural Science Foundation of China [62002071];
   Guangdong Provincial Key Laboratory of Cyber-Physical System
   [2020B1212060069]
FX This research is supported by Key-Area Research and Development Program
   of Guangdong Province under Grant 2019B010153002, Key Program of
   NSFC-Guangdong Joint Funds under Grant U1701262 and U1801263, National
   Natural Science Foundation of China under Grant 62002071 and Guangdong
   Provincial Key Laboratory of Cyber-Physical System under Grant
   2020B1212060069.
CR Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   Ahmed U, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.642347
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bowman S. R., 2015, Proceedings of the 2015 conference on empirical methods in natural language processing, DOI [DOI 10.18653/V1/D15-1075, 10.18653/v1/d15-1075, 10.18653/v1/D15-1075]
   Bowman SR, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1466
   Chen Q, 2018, P 32 AAAI C ART INT
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dolan W, 2004, Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources
   Duan CQ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4033
   Geng ZQ, 2020, INFORM SCIENCES, V509, P183, DOI 10.1016/j.ins.2019.09.006
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He H., 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, P1576, DOI 10.18653/v1/D15-1181
   Huang K, 2019, ARXIV
   Im J, 2017, ARXIV
   Ji Y, 2013, DISCRIMINATIVE IMPRO
   Jiang NJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4208
   Kong LL, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9757032
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li ZG, 2020, IEEE ACCESS, V8, P84093, DOI 10.1109/ACCESS.2020.2985685
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Liu B, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1237, DOI 10.1145/3178876.3186022
   Liu ZY, 2020, IEEE ACCESS, V8, P149362, DOI 10.1109/ACCESS.2020.3016727
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Madnani N., 2012, NAACL
   Mansoor M, 2020, INF TECHNOL CONTROL, V49, P495, DOI 10.5755/j01.itc.49.4.27118
   Mou LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P130
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   Neculoiu P., 2016, P 1 WORKSH REPR LEAR, P148, DOI [DOI 10.18653/V1/W16-1617, 10.18653/v1/W16-1617]
   Peinelt N, 2020, P 58 ANN M ASS COMPU
   Pontes EL, 2018, JEPTALNRECITAL
   Quan Z, 2019, IEEE-ACM T AUDIO SPE, V27, P853, DOI 10.1109/TASLP.2019.2899494
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Rocktaschel T, 2016, ARXIV
   Sahi M, 2017, COGN COMPUT, V9, P852, DOI 10.1007/s12559-017-9502-4
   Saric F, 2012, SEMEVAL
   Shao Y., 2017, P 11 INT WORKSH SEM, P130, DOI [10.18653/v1/S17-2016, DOI 10.18653/V1/S17-2016]
   Shao YN, 2021, PATTERN RECOGN LETT, V145, P157, DOI 10.1016/j.patrec.2021.02.008
   Song Y, 2019, 2019 P 18 INT C DAT
   Viswanathan Sujith, 2019, Advances in Big Data and Cloud Computing. Proceedings of ICBDCC18. Advances in Intelligent Systems and Computing (AISC 750), P519, DOI 10.1007/978-981-13-1882-5_45
   Wang C, 2021, COMPUT GEOSCI-UK, V156, DOI 10.1016/j.cageo.2021.104912
   Wang QY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM)
   Wang Y, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012119
   Wang ZG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4144
   Wu Z, 2020, ARXIV
   Zhu WH, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193919
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu XY, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500421
NR 47
TC 2
Z9 2
U1 18
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46673
EP 46694
DI 10.1007/s11042-023-15509-4
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000006
DA 2024-07-18
ER

PT J
AU Zhang, LJ
   Zhou, GX
   Chen, AB
   Yu, WT
   Peng, N
   Chen, X
AF Zhang, Liangji
   Zhou, Guoxiong
   Chen, Aibin
   Yu, Wentao
   Peng, Ning
   Chen, Xiao
TI Rapid computer vision detection of apple diseases based on AMCFNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple disease detection; AMCFNet; Particle swarm optimization; K-means;
   GrabCut
ID NEURAL-NETWORKS; CLASSIFICATION
AB Traditional image processing technology has some difficulties in detecting apple diseases. For example, fruit trees, leaves, and branches can interfere with the detection of apple diseases; different diseases of apples are similar and difficult to distinguish. In order to solve these problems, a convolutional neural network based on adaptive multi-channel feature fusion (AMCFNet) is proposed to detect apple diseases. Firstly, we used K-means algorithm for particle swarm optimization to roughly segment the apple disease image to obtain candidate frames, and then used GrabCut to finely segment the candidate frames to remove the background interference of fruit trees, leaves, and branches. Finally, the segmented apple disease image is input to the AMCFNet for detection. Experiments show that our method has better performance than other algorithms, and can reach an accuracy of 99.25% during testing, and it takes only 2.6 s to detect 100 apples.
C1 [Zhang, Liangji; Zhou, Guoxiong; Chen, Aibin; Peng, Ning; Chen, Xiao] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha, Hunan, Peoples R China.
   [Yu, Wentao] Univ Victoria, Dept Elect & Comp Engn, Victoria, BC, Canada.
C3 Central South University of Forestry & Technology; University of
   Victoria
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha, Hunan, Peoples R China.
EM ioo0614001x@163.com; zhougx01@163.com; 5708111@qq.com;
   wentaoyu@gmail.com; 595230772@qq.com; 1017538426@qq.com
FU National Natural Science Foundation of China [61703441]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant No. 61703441).
CR Ahmad M.T., 2018, 2018 5 INT MULTITOPI, P1
   Baranwal S, 2019, DEEP LEARNING CONVOL
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Bargoti S, 2017, J FIELD ROBOT, V34, P1039, DOI 10.1002/rob.21699
   Boykov YY, 2021, PROC 8 IEEE INT C CO
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Chen X, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105730
   Dias PA, 2018, COMPUT IND, V99, P17, DOI 10.1016/j.compind.2018.03.010
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hughes D., 2015, ABS151108060 CORR
   Ji YH, 2018, CHIN CONTR CONF, P5364, DOI 10.23919/ChiCC.2018.8483825
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Li L, 2020, POSTHARVEST BIOL TEC, V168, DOI 10.1016/j.postharvbio.2020.111276
   Li QZ, 2002, COMPUT ELECTRON AGR, V36, P215, DOI 10.1016/S0168-1699(02)00093-5
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu Y, 2018, T ASABE, V61, P1831, DOI 10.13031/trans.12930
   Lu Y, 2017, T ASABE, V60, P1765, DOI 10.13031/trans.12431
   Lu YZ, 2018, COMPUT ELECTRON AGR, V152, P314, DOI 10.1016/j.compag.2018.07.025
   Mhapne Namrata Varad, 2019, 2019 International Conference on Automation, Computational and Technology Management (ICACTM). Proceedings, P304, DOI 10.1109/ICACTM.2019.8776751
   Mu YP, 2020, J PLANT DIS PROTECT, V127, P367, DOI 10.1007/s41348-020-00309-x
   Nie MY, 2019, CHIN CONT DECIS CONF, P5961, DOI [10.1109/ccdc.2019.8832996, 10.1109/CCDC.2019.8832996]
   Peng Qingxi., 2016, International Journal of u- and e- Service, Science and Technology, V9, P95, DOI DOI 10.14257/IJUNESST.2016.9.11.09
   Raju SVSR, 2022, J NANOMATER, V2022, DOI 10.1155/2022/4435591
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tan WX, 2016, MULTIMED TOOLS APPL, V75, P16741, DOI 10.1007/s11042-015-2940-7
   Tian Y, 2019, JSENS, V2019
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Xing SL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143195
   Zhang WZ, 2020, IEEE ACCESS, V8, P38833, DOI 10.1109/ACCESS.2020.2974262
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
   Zou XB, 2010, COMPUT ELECTRON AGR, V70, P129, DOI 10.1016/j.compag.2009.09.014
NR 35
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44697
EP 44717
DI 10.1007/s11042-023-15548-x
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000979963000004
DA 2024-07-18
ER

PT J
AU Ayalew, AM
   Salau, AO
   Tamyalew, Y
   Abeje, BT
   Woreta, N
AF Ayalew, Aleka Melese
   Salau, Ayodeji Olalekan
   Tamyalew, Yibeltal
   Abeje, Bekalu Tadele
   Woreta, Nigus
TI X-Ray image-based COVID-19 detection using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Chest X-ray; Deep learning; CNN; Image processing;
   Classification
AB COVID-19 is a type of respiratory infection that primarily affects the lungs. Obtaining a chest X-ray is one of the most important steps in detecting and treating COVID-19 occurrences. Our study's goal is to detect COVID-19 from chest X-ray images using a Convolutional Neural Network (CNN). This study presents an effective method for categorizing chest X-ray images as Normal or COVID-19 infected. We used CNN, activation functions dropout, batch normalization, and Keras parameters to build this model. The classification method was implemented using open source tools "Python" and "OpenCV," both of which are freely available. The acquired images are transmitted through a series of convolutional and max pooling layers activated with the Rectified Linear Unit (ReLU) activation function, and then fed into the neurons of the dense layers, and finally activated with the sigmoidal function. Thereafter, SVM was used for classification using the knowledge from the learning model to classify the images into a predefined class (COVID-19 or Normal). As the model learns, its accuracy improves while its loss decreases. The findings of the study indicate that all models produced promising results, with augmentation, image segmentation, and image cropping producing the most efficient results, with a training accuracy of 99.8% and a test accuracy of 99.1%. As a result, the findings show that deep features provided consistent and reliable features for COVID-19 detection. Therefore, the proposed method aids in faster diagnosis of COVID-19 and the screening of COVID-19 patients by radiologists.
C1 [Ayalew, Aleka Melese] Univ Gondar, Dept Informat Technol, Gondar, Ethiopia.
   [Salau, Ayodeji Olalekan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Olalekan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
   [Tamyalew, Yibeltal] Bahir Dar Univ, Dept Informat Technol, Bahir Dar, Ethiopia.
   [Abeje, Bekalu Tadele] Haramaya Univ, Dept Informat Technol, Dire Dawa, Ethiopia.
   [Woreta, Nigus] Dabark Univ, Dept Informat Technol, Debark, Ethiopia.
C3 University of Gondar; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering; Bahir Dar University; Haramaya
   University
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, India.
EM ayodejisalau98@gmail.com
RI Ayalew, Aleka Melese/ITT-3051-2023; salau, ayodeji Olalekan/C-1016-2018
OI Ayalew, Aleka Melese/0000-0001-5869-6029; salau, ayodeji
   Olalekan/0000-0002-6264-9783; Wereta, Nigus/0000-0002-5636-3981
CR Akter S, 2021, BIOLOGY-BASEL, V10, DOI 10.3390/biology10111174
   Ayalew AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103530
   Azemin MZC, 2020, INT J BIOMED IMAGING, V2020, DOI 10.1155/2020/8828855
   Basu S, 2020, ARXIV
   Das AK, AUTOMATIC COVID 19 D, P9, DOI [10.1007/s10044-021-00970-4, DOI 10.1007/S10044-021-00970-4]
   Erdem E, 2020, IN PRESS, DOI [10.21203/rs.3.rs-65954/v1, DOI 10.21203/RS.3.RS-65954/V1]
   Frimpong S.A., 2022, Math Model Eng Probl 9, V9, P1557, DOI [10.18280/mmep.090615, DOI 10.18280/MMEP.090615]
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Jeczmionek E, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13071147
   Kaur D, 2014, COMPUTER
   Khan IU, 2020, INFORMATION, V11, DOI 10.3390/info11090419
   Kingma D. P., 2014, arXiv
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Mishra A., 2021, Advances in Mechanics, V9, P216, DOI [10.21203/rs.3.rs-607179/v1, DOI 10.21203/RS.3.RS-607179/V1]
   Nath Malaya Kumar, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P752, DOI 10.1109/ICCCA49541.2020.9250907
   Nwankpa C, 2018, arXiv
   Panigrahi CR, 2021, CLIN INFECT DIS, DOI [10.1201/9781003137481, DOI 10.1201/9781003137481]
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Sachar S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114181
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salau A.O., 2021, Informatics in Medicine Unlocked, V23, P2021, DOI 10.1016/j.imu.2021.100511
   Salau AO, 2021, 2021 INTERNATIONAL CONFERENCE ON DECISION AID SCIENCES AND APPLICATION (DASA), DOI 10.1109/DASA53625.2021.9682267
   Sekeroglu B, 2020, SLAS TECHNOL, V25, P553, DOI 10.1177/2472630320958376
   Shah Shanay, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P933, DOI 10.1109/ICSSIT48917.2020.9214289
   Taresh MM, 2021, INT J BIOMED IMAGING, V2021, DOI 10.1155/2021/8828404
   Wubineh B.Z., 2023, J of Pharm Negative Results, V14, P1242
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yadessa AG., 2021, 2021 INT C INN INT I, P93
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
NR 29
TC 8
Z9 8
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44507
EP 44525
DI 10.1007/s11042-023-15389-8
EA APR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976820400005
PM 37362655
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tan, LM
   Muhamad, WZAW
   Yahya, ZR
   Junoh, AK
   Azziz, NHA
   Ramlie, F
   Harudin, N
   Abu, MY
   Tan, XJ
AF Tan, Li Mei
   Wan Muhamad, Wan Zuki Azman
   Yahya, Zainor Ridzuan
   Junoh, Ahmad Kadri
   Azziz, Nor Hizamiyani Abdul
   Ramlie, Faizir
   Harudin, Nolia
   Abu, Mohd Yazid
   Tan, Xiao Jian
TI A survey on improvement of Mahalanobis Taguchi system and its
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mahalanobis Taguchi system; Mahalanobis distance;
   Mahalanobis-Taguchi-Gram-Schdimt; Optimization; Signal-to-noise ratio;
   Orthogonal Array; Metaheuristic algorithm
ID SELECTION
AB Mahalanobis Taguchi System (MTS) is used for pattern recognition and classification, diagnosis, and prediction of a multivariate data set. Mahalanobis Distance (MD), orthogonal array (OA), and signal-to-noise ratio (SNR) are used in traditional MTS in order to identify and optimize the variables. However, the high correlation among variables shows an effect on the inverse of the correlation matrix that uses in the calculation of MD and hence affects the accuracy of the MD. Therefore, Mahalanobis-Taguchi-Gram-Schmidt (MTGS) system is proposed in order to solve the problem of multicollinearity. The value of MD can be calculated by using the Gram-Schmidt Orthogonalization Process (GSOP). Besides, the computational speed and the accuracy in optimization using OA and SNR are other issues that are concerned the authors. Hence, the combination of MTS and other methods such as Binary Particles Swarm Optimization (BPSO) and Binary Ant Colony Optimization (NBACO) is proposed to improve the computational speed and the accuracy in optimization. The purpose of this paper is to review and summarize some works that developed and used the hybrid methodology of MTS as well as its application in several fields. Moreover, a discussion about the future work that can be done related to MTS is carried out.
C1 [Tan, Li Mei; Wan Muhamad, Wan Zuki Azman; Yahya, Zainor Ridzuan; Junoh, Ahmad Kadri; Azziz, Nor Hizamiyani Abdul] Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
   [Wan Muhamad, Wan Zuki Azman; Yahya, Zainor Ridzuan] Univ Malaysia Perlis, Ctr Excellence Adv Comp ADVCOMP, Arau 02600, Perlis, Malaysia.
   [Ramlie, Faizir] Univ Teknol Malaysia, Razak Fac Technol & Informat, Dept Mech Engn, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
   [Harudin, Nolia] Univ Tenaga Nas, Kajang 43000, Selangor, Malaysia.
   [Abu, Mohd Yazid] Univ Malaysia Pahang, Fac Mfg & Mechatron Engn Technol, Pekan 26600, Malaysia.
   [Tan, Xiao Jian] Tunku Abdul Rahman Univ Management & Technol, Fac Engn & Technol, Ctr Multimodal Signal Proc, Dept Elect & Elect Engn, Jalan Genting Kelang, Kuala Lumpur 53300, Malaysia.
   [Wan Muhamad, Wan Zuki Azman; Tan, Xiao Jian] Univ Malaysia Perlis, Sports Engn Res Ctr SERC, Arau 02600, Perlis, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis; Universiti
   Teknologi Malaysia; Universiti Tenaga Nasional; Universiti Malaysia
   Pahang Al-Sultan Abdullah (UMPSA); Universiti Malaysia Perlis
RP Muhamad, WZAW (corresponding author), Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.; Muhamad, WZAW (corresponding author), Univ Malaysia Perlis, Ctr Excellence Adv Comp ADVCOMP, Arau 02600, Perlis, Malaysia.; Muhamad, WZAW (corresponding author), Univ Malaysia Perlis, Sports Engn Res Ctr SERC, Arau 02600, Perlis, Malaysia.
EM wanzuki@unimap.edu.my
RI Tan, Xiao Jian/R-5647-2016
OI Tan, Xiao Jian/0000-0003-1038-3933; abu, mohd yazid/0000-0002-6148-6193;
   Abdul Azziz, Nor Hizamiyani/0000-0001-7435-5320; Muhamad, W. Z. A.
   W./0000-0001-5697-8196
FU Ministry of Higher Education, Malaysia, under the Fundamental Research
   Grant Scheme [FRGS/1/2020/STG06/UNIMAP/02/7]
FX This study was financially supported by the Ministry of Higher
   Education, Malaysia, under the Fundamental Research Grant Scheme
   (FRGS/1/2020/STG06/UNIMAP/02/7).
CR Arora S, 2019, SOFT COMPUT, V23, P715, DOI 10.1007/s00500-018-3102-4
   Bekaryan A, 2007, IEEE VTS VEH TECHNOL, P902, DOI 10.1109/VETECF.2007.197
   Buenviaje B, 2016, IEEE J BIOMED HEALTH, V20, P1205, DOI 10.1109/JBHI.2015.2434949
   Chang ZP, 2019, MEASUREMENT, V136, P501, DOI 10.1016/j.measurement.2018.12.090
   Chang ZP, 2020, IEEE ACCESS, V8, P20428, DOI 10.1109/ACCESS.2020.2967411
   Cheng LL, 2021, MECH SYST SIGNAL PR, V146, DOI 10.1016/j.ymssp.2020.107060
   Cudney E., 2008, Journal of Industrial and Systems Engineering, V1, P281
   Cudney EA, 2010, ENG MANAG J, V22, P3, DOI 10.1080/10429247.2010.11431858
   El-Banna M, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/5874896
   Ghasemi E, 2015, INT J QUAL RELIAB MA, V32, P291, DOI 10.1108/IJQRM-02-2014-0024
   Gu YP, 2019, J INF PROCESS SYST, V15, P682, DOI 10.3745/JIPS.04.0119
   Mota-Gutiérrez CG, 2018, INT J QUAL RELIAB MA, V35, P596, DOI 10.1108/IJQRM-10-2016-0174
   Huei-Chun Wang, 2004, Journal of the Chinese Institute of Industrial Engineers, V21, P606, DOI 10.1080/10170660409509440
   Jugulum R, 2003, TECHNOMETRICS, V45, P16, DOI 10.1198/004017002188618635
   Kamil N. N. Nik Mohd, 2020, Journal of Physics: Conference Series, V1532, DOI 10.1088/1742-6596/1532/1/012004
   Kamil NNNM., 2021, INT J IND MANAGEMENT, V10, P160, DOI [10.15282/ijim.10.1.2021.5982, DOI 10.15282/IJIM.10.1.2021.5982]
   Kishore Govatati S, 2015, INT J RES ENG TECHNO, V04, P576, DOI [10.15623/ijret.2015.0404100, DOI 10.15623/IJRET.2015.0404100]
   Lehua Teng, 2021, Journal of Physics: Conference Series, V1865, DOI 10.1088/1742-6596/1865/3/032075
   Liu J., 2020, J ASSIST REPROD GEN, DOI [10.1007/s12204-020-2236-6, DOI 10.1007/S12204-020-2236-6]
   Muhamad WZAW, 2018, AIP CONF PROC, V1974, DOI 10.1063/1.5041535
   Muhamad WZAW, 2018, AIP CONF PROC, V1974, DOI 10.1063/1.5041558
   Muhamad WZAW., 2017, FAR E J MATH SCI FJM, V102, P3021, DOI [10.17654/MS102123021, DOI 10.17654/MS102123021]
   Muhamad WZAW, 2018, IEEE STUD C RES DEV, V2018, DOI [10.1109/SCORED.2017.8305390, DOI 10.1109/SCORED.2017.8305390]
   Okubo H, 2021, J INTEL MAT SYST STR, V32, P1089, DOI 10.1177/1045389X20914966
   Pal A, 2010, EXPERT SYST APPL, V37, P1286, DOI 10.1016/j.eswa.2009.06.011
   Peng CF, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9091557
   Peng X, 2019, DESTECH T COMPUT SCI, DOI [10.12783/dtcse/cscme2019/32535, DOI 10.12783/DTCSE/CSCME2019/32535]
   Ramlie F, 2020, INT J ENG RES TECHNO, V13, P117, DOI [10.37624/ijert/13.1.2020.117-136, DOI 10.37624/IJERT/13.1.2020.117-136]
   Ramlie F, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093906
   Reséndiz E, 2013, EXPERT SYST APPL, V40, P2361, DOI 10.1016/j.eswa.2012.10.049
   Reséndiz E, 2013, EXPERT SYST APPL, V40, P634, DOI 10.1016/j.eswa.2012.07.058
   Resendiz-Flores EO, 2020, SOFT COMPUT, V24, P341, DOI 10.1007/s00500-019-03911-w
   Reséndiz-Flores EO, 2018, INT J ADV MANUF TECH, V94, P2613, DOI 10.1007/s00170-017-1136-x
   Reyes-Carlos YI, 2018, INT J ADV MANUF TECH, V95, P3589, DOI 10.1007/s00170-017-1348-0
   Sakeran H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163306
   Seoung Bum Kim, 2009, International Journal of Industrial and Systems Engineering, V4, P631, DOI 10.1504/IJISE.2009.026768
   Shakya P, 2015, J SOUND VIB, V337, P342, DOI 10.1016/j.jsv.2014.10.034
   Snyder J, 2018, ASEE ANN C EXP C P J, V2018
   Taguchi G., 2002, The Mahalanobis-Taguchi Strategy
   Wang Ning, 2020, Journal of Shanghai Jiaotong University (Science), V25, P214, DOI 10.1007/s12204-019-2107-1
   Wang N, 2022, ANN OPER RES, V311, P417, DOI 10.1007/s10479-019-03220-3
   Woodall WH, 2003, TECHNOMETRICS, V45, P1, DOI 10.1198/004017002188618626
   Yazid AM, 2015, PROC CIRP, V26, P258, DOI 10.1016/j.procir.2014.07.025
   Yuan JH, 2020, J CLEAN PROD, V270, DOI 10.1016/j.jclepro.2020.122119
   Yuan JH, 2019, SCI TOTAL ENVIRON, V696, DOI 10.1016/j.scitotenv.2019.133817
   Zhou H, 2018, EVALUATING ANAL EFFE, DOI [10.1109/IEA.2018.8387067, DOI 10.1109/IEA.2018.8387067]
   Zhou ZH, 2018, ANOMALY DETECTION SL, DOI [10.1109/ICNISC.2018.00030, DOI 10.1109/ICNISC.2018.00030]
NR 47
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43865
EP 43881
DI 10.1007/s11042-023-15257-5
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976628900004
DA 2024-07-18
ER

PT J
AU Yang, WJ
   Lu, LY
   Chan, DY
AF Yang, Wei-Jong
   Lu, Li-Yu
   Chan, Din-Yuen
TI Rational 3D object placement based on deep learning based plane
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plane detection; Deep learning neural network; Semantic segmentation;
   Vanishing points; AR tool
AB Effective acquisition of 3D planar features from a 2D image for immersive AR applications is challenging without any 3D depth information. In this paper, we present a novel planar object placement (POP) system for rational insertion of 3D objects on plane surfaces and fitting their plane orientations in a given 2D image. The POP system is composed of an adaptive edge extractor (AEE), a vanishing point detector (VPD), a rational fitting transformer (RFT) and a plane normal detection network (PNDnet), which performs the estimation of planar features. With the inputs of the color image and the guided edge map retrieved by the AEE, the PNDnet based on a gating weighted U-Net, whose gating weights are controlled by global cross-level connection (GCC) blocks, can properly extract 3D information including planar pixel-wise normal map, semantic plane-segmented map and plane-wise normal vectors. Simultaneously, with plane-wise normal vectors and the VPD-estimated vanishing points, the RFT can easily induce the best placement position for projecting the AR object on a destination plane with better coherent 3D perspectives. Besides, the POP system allows the users to make the subtle tunes of 3D orientation to the inserted object for personal preferences. Experimental results show that the proposed POP system, which successfully guides the 3D-inserted objects to match up the surfaces and orientations of the planes in the target image, will become an effective AR tool for the insertion of 3D objects in target images and videos in the future.
C1 [Yang, Wei-Jong] Natl Chin Yi Univ Technol, Dept Artificial Intelligence & Comp Engn, Taichung, Taiwan.
   [Lu, Li-Yu] Chunghwa Telecom Co Ltd, Telecommun Labs, Internet Things Lab, Taoyuan, Taiwan.
   [Chan, Din-Yuen] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chin-Yi University of Technology; Chunghwa Telecom; National
   Chiayi University
RP Chan, DY (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM dychan@mail.ncyu.edu.tw
FU NSTC, Taiwan [111-2634-F-006-012, 111-2222-E-167-005]; Qualcomm, USA
   [NAT-435536, 110-222-E415-013]
FX This work was partially supported by NSTC, Taiwan, under Grant Number
   111-2634-F-006-012, ## 111-2222-E-167-005, and Qualcomm, USA, under
   Grant SOW#NAT-435536, and 110-222-E415-013.
CR Brabandere B-D, 2017, ARXIV
   Butko N, 2021, 8 WALL BLOG
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang C, 2018, P IEEE INT C ROB AUT, DOI [10.1109/ICRA.2018.8460499, DOI 10.1109/ICRA.2018.8460499]
   Chaudhury K, 2014, IEEE IMAGE PROC, P3479, DOI 10.1109/ICIP.2014.7025706
   Choe J., 2020, P 2020 INT C COMPUTA, P745, DOI [10.1109/CSCI51800.2020.00140, DOI 10.1109/CSCI51800.2020.00140]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Coughlan J-M, 2000, ADV NEUR IN
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Hart PE, 2009, IEEE SIGNAL PROC MAG, V26, P18, DOI 10.1109/MSP.2009.934181
   Huang Y, 2011, P IEEE INT C IM PROC, DOI [10.1109/ICIP.2011.6115623, DOI 10.1109/ICIP.2011.6115623]
   Kluger F, 2017, PROC GERMAN C PATTER
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lee CY, 2017, IEEE I CONF COMP VIS, P4875, DOI 10.1109/ICCV.2017.521
   Liu C, 2018, PROC CVPR IEEE, P2579, DOI 10.1109/CVPR.2018.00273
   Mangiarua N, 2019, J COMPUT SCI TECHNOL, V19, P175, DOI 10.24215/16666038.19.e16
   McNamara A, 2019, P IEEE C VIRT REAL 3, DOI [10.1109/VR.2019.8797891, DOI 10.1109/VR.2019.8797891]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi C-R, 2017, PROC IEEE INT C COMP
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rana Kanaiya, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0380, DOI 10.1109/ICCSP.2019.8697999
   Renner P, 2018, P IEEE C VIRT REAL 3, DOI [10.1109/VR.2018.8446396, DOI 10.1109/VR.2018.8446396]
   Rios-Pino LF, 2021, IBER CONF INF SYST
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Yang FT, 2018, LECT NOTES COMPUT SC, V11214, P87, DOI 10.1007/978-3-030-01249-6_6
   Yu ZH, 2019, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2019.00112
   Yunqiang Chen, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022082
   Zhai MH, 2016, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2016.610
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 34
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44555
EP 44576
DI 10.1007/s11042-023-15369-y
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976820400004
DA 2024-07-18
ER

PT J
AU Joshi, AB
   Gaffar, A
   Singh, S
AF Joshi, Anand B.
   Gaffar, Abdul
   Singh, Sonali
TI Security of medical images based on special orthogonal group and Galois
   field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image encryption; Archimedes' constant; Special orthogonal
   group; Galois field; CBC mode; PSN
ID GENETIC ALGORITHM; ENCRYPTION; CRITERION; SCHEME; SYSTEM
AB Security of medical images over an unsecured channel is a challenging task, and for this, several methods have been designed recently. The present paper is also in the same direction, and is an attempt to improve the security of the existing methods. In this paper, a cryptosystem is proposed, which performs encryption and decryption in the CBC (Cipher Block Chaining) mode of operation, and attains the confusion-diffusion properties using the PSN (Permutation-Substitution Network) of cryptography. The permutation is performed by a composite operation, consisting of rotation (via special orthogonal group), reflection, flipping, and pixel-wise shuffling, while substitution is performed by a composite operation of multiplication and multiplicative inverse over Galois field. The Archimedes' constant is utilized for constructing Initialization Vector (IV) to be used in the CBC mode of encryption (and decryption). The proposed approach is able to encrypt monochrome (8-bit, 10-bit, 12-bit, and 16-bit), palette color, and 24-bit color medical images, simultaneously into noisy-like images from the human visual as well as the statistical point of view. The designed approach is empirically assessed via several statistical and security evaluation metrics, such as key sensitivity, chi-squared test, number of pixel change rate, avalanche effect, poker test, peak signal-to-noise ratio, etc. The results of these metrics support the objectives of our proposed approach. Moreover, a thorough comparison is also made with the recent state-of-the-art existing methods.
C1 [Joshi, Anand B.; Gaffar, Abdul; Singh, Sonali] Univ Lucknow, Dept Math & Astron, Lucknow 226007, Uttar Pradesh, India.
C3 Lucknow University
RP Joshi, AB (corresponding author), Univ Lucknow, Dept Math & Astron, Lucknow 226007, Uttar Pradesh, India.
EM anandiitd.joshi@gmail.com; abdulgaffar.lu@gmail.com
RI GAFFAR, ABDUL/HNC-3266-2023
OI GAFFAR, ABDUL/0000-0002-3388-9067; Joshi, Anand
   Ballabh/0000-0003-0227-4032
FU UGC (University Grants Commission), New Delhi, India [415024]
FX This work was partially supported by UGC (University Grants Commission),
   New Delhi, India under grant No. [415024]
CR Abdel-Rehim Wael Mohamed Fawaz, 2012, Journal of Computer Science, V8, P1353, DOI 10.3844/jcssp.2012.1353.1357
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Ali TS, 2020, IEEE ACCESS, V8, P71974, DOI 10.1109/ACCESS.2020.2987615
   Alqazzaz SF., 2022, INT J COMPUT SCI NET, V14, P67, DOI DOI 10.5815/IJCNIS.2022.02.06
   [Anonymous], 2022, MIN MIAS DAT MAMM
   [Anonymous], GAL FIELD
   Arndt Jorg, 2006, Pi Unleashed
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Barik RC, 2021, MULTIMED TOOLS APPL, V80, P10723, DOI 10.1007/s11042-020-09930-2
   barre.dev, MED IM SAMPL
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Biham E., 1993, Differential cryptanalysis of the data encryption standard, DOI DOI 10.1007/978-1-4613-9314-6
   Bogart S, 1999, J RES SCI TEACH
   Castro JCH, 2005, MATH COMPUT SIMULAT, V68, P1, DOI 10.1016/j.matcom.2004.09.001
   Chandrasekaran J, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/6729896
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   COCHRAN WG, 1952, ANN MATH STAT, V23, P315, DOI 10.1214/aoms/1177729380
   commons.wikimedia.org, COMPUT TOMOGR
   CrypTool, 2017, OP SOURC WIND PROGR
   Dagadu J.C., 2019, INT J NETW SECUR, V21, P83
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   data.iplantcollaborative.org, CT TRAIN BE001 DAT
   Digital Imaging and Communications in Medicine (DICOM), DOCUMENTATION
   Dummit D. S., 2004, ABSTRACT ALGEBRA
   encyclopediaofmath.org, EUCL ALG ENC MATH
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Field, ENCY MATH
   Fisher R. A., 1946, Statistical methods for research workers.
   Gafsi M., 2020, SCI PROGRAMMING-NETH, V2020, P1
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Ibrahim S, 2020, IEEE ACCESS, V8, P160433, DOI 10.1109/ACCESS.2020.3020746
   Ismail R, 2023, MULTIMED TOOLS APPL, V82, P22213, DOI 10.1007/s11042-022-13343-8
   Jeevitha S, 2021, J AMB INTEL HUM COMP, V12, P3373, DOI 10.1007/s12652-020-02399-9
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Larobina M, 2014, J DIGIT IMAGING, V27, P200, DOI 10.1007/s10278-013-9657-9
   Li MZ, 2022, COGN COMPUT SYST, V4, P378, DOI 10.1049/ccs2.12070
   Li SS, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6624809
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   mathworld.wolfram.com, US
   medpix.nlm.nih.gov, NLMS MEDPIX DAT
   Mortajez S., 2020, Inform. Med. Unlocked, V20, DOI [10.1016/j.imu.2020.100396, DOI 10.1016/J.IMU.2020.100396]
   Mullican T, 2019, BITS BYTES
   Mullican T, 2020, GUINNESS WORLD RECOR
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   nihcc.app.box.com, NIH IM DAT
   Orthogonal group, ENCY MATH
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Pearson K., 1895, Philos. Trans. R. Soc. London, Ser. A., V186, P343, DOI [10.1098/rsta.1895.0010, DOI 10.1098/RSTA.1895.0010]
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Reyad O, 2020, J INTELL FUZZY SYST, V39, P7795, DOI 10.3233/JIFS-201146
   Shafique A, 2021, IEEE ACCESS, V9, P59108, DOI 10.1109/ACCESS.2021.3071535
   Shankar K, 2018, IEEE ACCESS, V6, P77145, DOI 10.1109/ACCESS.2018.2874026
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Smart N, 2011, ECRYPT 2 YEARLY REPO
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Wahballa Osman, 2017, International Journal of Network Security, V19, P776, DOI 10.6633/IJNS.201709.19(5).15
   Wang N, 2019, IEEE ACCESS, V7, P49945, DOI 10.1109/ACCESS.2019.2910563
   wikipedia.org, About us
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yasser I, 2022, IEEE ACCESS, V10, P244, DOI 10.1109/ACCESS.2021.3138718
   Yin S., 2019, INT J NETW SECUR, V22, P421
   Yin SL, 2021, EVOL INTELL, V14, P1817, DOI 10.1007/s12065-020-00440-6
NR 69
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44277
EP 44308
DI 10.1007/s11042-023-15033-5
EA APR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000984450300004
DA 2024-07-18
ER

PT J
AU Chen, Y
   Wang, S
   Guo, JF
AF Chen, Yu
   Wang, Sheng
   Guo, Jifeng
TI DCTNet: hybrid deep neural network-based EEG signal for detecting
   depression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depression detection; Deep learning; Hybrid deep models; EEG signals;
   DCTNet
ID NONLINEAR FEATURES
AB Depression is a mood disorder that can affect people's psychological problems. The current medical approach is to detect depression by manual analysis of EEG signals, however, manual analysis of EEG signals is cumbersome and time-consuming, requiring a lot of experience. Therefore, we propose a short time series base on convolutional neural network (CNN), called DCLNet, for depression classification. Firstly, the sample size and diversity of the dataset are enhanced by the clipping strategy. Then we superimposes different frequency domains and put them into a two-dimensional matrix according to the electrode position of the EEG, which was input to CNN to extract important features. Finally, the extracted features are put into the Long short-term memory network (LSTM) to capture the temporal information. The experimental results shows that the Accuracy of the model is 99.15%, Specificity is 99.01%, and Sensitivity is 99.30%. Compared with the current popular machine learning (ML) methods and deep learning (DL) models, DCTNet has excellent performance in the evaluation indexes of Accuracy, Specificity and Sensitivity.
C1 [Chen, Yu; Wang, Sheng] Northeast Forestry Univ, Informat & Comp Engn Colege, 26 Hexing Rd, Harbin 150040, Heilongjiang Pr, Peoples R China.
   [Guo, Jifeng] Guilin Univ Aerosp Technol, Sch Comp Sci & Engn, 2 Jinji Rd, Guilin, Guangxi, Peoples R China.
C3 Northeast Forestry University - China; Guilin University of Aerospace
   Technology
RP Guo, JF (corresponding author), Guilin Univ Aerosp Technol, Sch Comp Sci & Engn, 2 Jinji Rd, Guilin, Guangxi, Peoples R China.
EM nefu_chenyu@163.com; ws2020116091@163.com; guojifeng@nefu.edu.cn
RI wang, sheng/HZI-5131-2023
FU National Natural Science Foundation of China [61300098]; Natural Science
   Foundation of Heilongjiang Province [F201347]; Fundamental Research
   Funds for the Central Universities [2572015DY07]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China[61300098], the Natural Science Foundation of
   Heilongjiang Province[F201347], and the Fundamental Research Funds for
   the Central Universities[2572015DY07].
CR Acharya UR, 2018, COMPUT METH PROG BIO, V161, P103, DOI 10.1016/j.cmpb.2018.04.012
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anderson PS., 1974, CARTOGRAPHY, V8, P182, DOI [10.1080/00690805.1974.10437803, DOI 10.1080/00690805.1974.10437803]
   Ay B, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1345-y
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Cai HS, 2018, COMPLEXITY, DOI 10.1155/2018/5238028
   Duan LJ, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00284
   Graves A, 2012, STUD COMPUT INTELL, V385, P15
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosseinifard B, 2013, COMPUT METH PROG BIO, V109, P339, DOI 10.1016/j.cmpb.2012.10.008
   Hu B, 2011, IEEE INTELL SYST, V26, P46, DOI 10.1109/MIS.2011.58
   Kang M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226526
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JH, 2015, NEUROCOMPUTING, V165, P23, DOI 10.1016/j.neucom.2014.08.092
   Li XW, 2019, MED BIOL ENG COMPUT, V57, P1341, DOI 10.1007/s11517-019-01959-2
   Mahato S, 2019, MICROSYST TECHNOL, V25, P1065, DOI 10.1007/s00542-018-4075-z
   Mumtaz W, 2016, MDD PATIENTS HLTH CO
   Mumtaz W, 2017, PLOS ONE, P1
   Mumtaz W, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103983
   Rohani DA., 2020, IEEE T EMERG TOP COM, VXX, P1
   Saeedi A, 2021, COGN NEURODYNAMICS, V15, P239, DOI 10.1007/s11571-020-09619-0
   Sandheep P, 2019, TENCON IEEE REGION, P1339, DOI [10.1109/TENCON.2019.8929254, 10.1109/tencon.2019.8929254]
   Seal A, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3053999
   Sharma G, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2020.102393
   Thoduparambil PP, 2020, PHYS ENG SCI MED, V43, P1349, DOI 10.1007/s13246-020-00938-4
   Uyulan C, 2021, CLIN EEG NEUROSCI, V52, P38, DOI 10.1177/1550059420916634
   WHO, 2017, Other common mental disorders: global health estimates
   World Federation for Mental Health, 2012, WORLD MENTAL HLTH DA, V10, P2012
NR 32
TC 4
Z9 4
U1 9
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41307
EP 41321
DI 10.1007/s11042-023-14799-y
EA APR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000967980300008
DA 2024-07-18
ER

PT J
AU Srinivasarao, U
   Sharaff, A
AF Srinivasarao, Ulligaddala
   Sharaff, Aakanksha
TI SMS sentiment classification using an evolutionary optimization based
   fuzzy recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SMS; Spam and ham; Sentiment analysis; Fuzzy recurrent neural network;
   Harris hawk optimization; Kernel extreme learning machine
ID TEXT; EXTRACTION; MODEL
AB Sentiment analysis using the inbox message polarity is a challenging task in text mining, this analysis is used to differentiate spam and ham messages in mail. Polarity estimation is mandatory for spam and ham identification, whereas developing a perfect architecture for such classification is the hot demanding topic. To fulfill that, fuzzy based Recurrent Neural network-based Harris Hawk optimization (FRNN-HHO) is introduced, which performs post-classification over the classified messages (spam and ham). Previously the authors tried to classify the spam and ham messages from the collection of SMSs. But sometimes, the spam messages may incorrectly be classified within the ham classes. This misclassification may reduce the accuracy. The sentiment analysis process is performed over the classified messages to improve such classification accuracy. The spam and ham messages from the available data are classified using a Kernel Extreme Learning Machine (KELM) classifier. The sentiment analysis and classification based experimental evaluation is carried out using accuracy, recall, f-measure, precision, RMSE, and MAE. The performance of the proposed architecture is evaluated using threedifferent datasets: SMS, Email, and spam-assassin. The Area under the curve (AUC) of the proposed approach is found to be 0.9699 (SMS dataset), 0.958 (Email dataset), and 0.95 (spam assassin).
C1 [Srinivasarao, Ulligaddala; Sharaff, Aakanksha] Natl Inst Technol Raipur, Dept Comp Sci & Engn, Chhattisgarh 492010, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Srinivasarao, U (corresponding author), Natl Inst Technol Raipur, Dept Comp Sci & Engn, Chhattisgarh 492010, India.
EM usrinivasarao.phd2018.cs@nitrr.ac.in; asharaff.cs@nitrr.ac.in
RI Srinivasarao, ulligaddala/ABK-2243-2022; Sharaff, Aakanksha/L-9995-2016
OI Srinivasarao, ulligaddala/0000-0001-9199-2700; Sharaff,
   Aakanksha/0000-0001-5499-7289
CR Abayomi-Alli O, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6989
   Agarwal B, 2018, INFORM PROCESS MANAG, V54, P922, DOI 10.1016/j.ipm.2018.06.005
   Albalawi R, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00042
   Alsmadi I, 2019, INT J WEB INF SYST, V15, P155, DOI 10.1108/IJWIS-12-2017-0083
   Arora M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0557-y
   Bandhakavi A, 2017, PATTERN RECOGN LETT, V93, P133, DOI 10.1016/j.patrec.2016.12.009
   Barushka A, 2020, NEURAL COMPUT APPL, V32, P4239, DOI 10.1007/s00521-019-04331-5
   Chalothom T., 2015, SIMPLE APPROACHES SE
   Cherif F, 2020, NEURAL PROCESS LETT, V51, P2211, DOI 10.1007/s11063-020-10193-z
   DEEPALAKSHMI S, 2016, INDIAN J SCI TECHNOL, V9, pNIL87, DOI DOI 10.17485/ijst/2016/v9i39/90599
   Dragoni M, 2019, INFORM PROCESS MANAG, V56, P1103, DOI 10.1016/j.ipm.2018.04.010
   Ghaleb SA, 2020, INT C ADV CYB SEC, P420
   Guellil I., 2020, RECENT ADV NLP CASE
   Guo SK, 2020, NEURAL PROCESS LETT, V51, P2589, DOI 10.1007/s11063-020-10213-y
   Hung CL, 2016, KNOWL-BASED SYST, V110, P224, DOI 10.1016/j.knosys.2016.07.030
   HYUNYOUNG LEE, 2018, [Smart Media Journal, 스마트미디어저널], V7, P24, DOI 10.30693/SMJ.2018.7.4.24
   Islam MR, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00696-x
   Jain G, 2019, ANN MATH ARTIF INTEL, V85, P21, DOI 10.1007/s10472-018-9612-z
   Karakus BA, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4783
   Khiari W, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1185
   Li JJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122036
   Li YC, 2018, EXPERT SYST APPL, V96, P261, DOI 10.1016/j.eswa.2017.12.016
   Moayedi H, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107389
   Nagwani NK, 2017, J INF SCI, V43, P75, DOI 10.1177/0165551515616310
   Naresh Kumar, 2020, NEED HYBRID LEXICON, P117
   Pettersson, 2018, ANDROID MESSAGING IN
   Pong-Inwong C, 2019, INT J MACH LEARN CYB, V10, P2177, DOI 10.1007/s13042-018-0800-2
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5211949
   Sahoo D., 2017, ARXIV, P170107179
   Shaaban MA, 2022, COMPLEX INTELL SYST, V8, P4897, DOI 10.1007/s40747-022-00741-6
   Sharaff Aakanksha, 2020, 2020 First International Conference on Power, Control and Computing Technologies (ICPC2T), P316, DOI 10.1109/ICPC2T48082.2020.9071488
   Sharaff A, 2021, COMPUT NETW, V199, DOI 10.1016/j.comnet.2021.108453
   Sharaff A, 2016, J INF SCI, V42, P200, DOI 10.1177/0165551515587854
   Srinivasan S, 2021, SPAM EMAILS DETECTIO, P161, DOI DOI 10.1007/978-3-030-57024-8_7
   Srinivasarao U, 2021, INTELLIGENT COMPUTIN, P211, DOI [10.1007/978-981-16-1295-4_22, DOI 10.1007/978-981-16-1295-4_22]
   Srinivasarao U, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116475
   Srinivasarao U, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.12867
   Su YJ, 2020, J INTERNET TECHNOL, V21, P821, DOI 10.3966/160792642020052103019
   Su YJ, 2020, J SUPERCOMPUT, V76, P9127, DOI 10.1007/s11227-020-03198-x
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P222, DOI 10.1016/j.aci.2018.08.006
   Ullah F, 2020, INT J PARALLEL PROG, V48, P162, DOI 10.1007/s10766-018-0570-1
   Waheeb W, 2017, COMPUT SIST, V21, P771, DOI 10.13053/CyS-21-4-2593
   Waheed A, 2021, IEEE SEM, V9
   Wan C, 2020, IEEE ACCESS, V8, P202980, DOI 10.1109/ACCESS.2020.3036043
   Xia T, 2021, NEUROCOMPUTING, V444, P48, DOI 10.1016/j.neucom.2021.02.075
NR 46
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42207
EP 42238
DI 10.1007/s11042-023-15206-2
EA APR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300007
PM 37362691
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Golzardi, E
   Sheikhahmadi, A
   Abdollahpouri, A
AF Golzardi, Elaheh
   Sheikhahmadi, Amir
   Abdollahpouri, Alireza
TI TRTCD: trust route prediction based on trusted community detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trust; Trust route; Social network; Community
ID LINK-PREDICTION; COMPLEX NETWORKS; MISSING LINKS; ALGORITHM;
   RECOMMENDATIONS; ENHANCEMENT
AB Social networks have become increasingly popular and are used for various activities. It is essential to evaluate the trustworthiness of the path between two unknown users in social networks. However, there are usually many social routes between them. In applications of trust, confidence relations among users need to be predicted. Trust route prediction predicts a new trust relationship between two users who are not currently connected. Thus, a challenging problem is finding which social trust route is optimal to yield the most trustworthy route. As a result, this process faces many challenges, such as the sparsity of user-specified trust relations, context awareness of trust, and changes in trust values over time. A new trust route prediction framework was proposed in this paper to enhance prediction accuracy. Considering community relations and node information for community detection, the proposed trust route prediction algorithm, TRTCD, is introduced. The effect of node and community information on link prediction accuracy was empirically investigated here using seven parameters. Experiments on eleven real-world datasets showed that the proposed method performed better than the fourteen existing methods. Based on the obtained experimental results, the proposed method performs better than other methods regarding accuracy and cost. The results show that the TRTCD has, on average, 22% better on eight directed datasets. The results of the NDCG measure show that the TRTCD can reach the average value of trust very close to 1, which is outstanding and performs better than other algorithms in terms of the ATCE criterion since more trusted and integrated communities are identified. In addition, the results show that the TRTCD can be successfully used in directed social networks but needs to work better in undirected social networks.
C1 [Golzardi, Elaheh; Sheikhahmadi, Amir] Islamic Azad Univ, Dept Comp Engn, Sanandaj Branch, Sanandaj, Iran.
   [Abdollahpouri, Alireza] Univ Kurdistan, Dept Comp Engn, Sanandaj, Iran.
C3 Islamic Azad University; University of Kurdistan
RP Sheikhahmadi, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sanandaj Branch, Sanandaj, Iran.
EM asheikhahmadi@iausdj.ac.ir
RI Sheikhahmadi, Amir/AAN-8637-2021
OI Golzardi, Elaheh/0000-0002-9411-2366
CR Adali Sibel, 2010, 2010 IEEE International Conference on Intelligence and Security Informatics (ISI 2010), P150, DOI 10.1109/ISI.2010.5484757
   Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Albert R, 2002, REV MOD PHYS, V74, P47, DOI 10.1103/RevModPhys.74.47
   [Anonymous], 2018, PROC 12 INT AAAI C W
   Azadjalal MM, 2017, KNOWL-BASED SYST, V116, P130, DOI 10.1016/j.knosys.2016.10.025
   BAI S, 2018, GEOCHEM PERSPECT LET, V2018, P1
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Belkhadir I, 2019, PROCEDIA COMPUT SCI, V148, P181, DOI 10.1016/j.procs.2019.01.035
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Biswas A, 2018, IEEE T FUZZY SYST, V26, P2568, DOI 10.1109/TFUZZ.2018.2795569
   Biswas A, 2017, MULTIMED TOOLS APPL, V76, P18619, DOI 10.1007/s11042-016-4270-9
   Biswas A, 2017, INFORM SCIENCES, V396, P185, DOI 10.1016/j.ins.2017.02.050
   Biswas A, 2015, EXPERT SYST APPL, V42, P6913, DOI 10.1016/j.eswa.2015.05.009
   Boccaletti S, 2006, PHYS REP, V424, P175, DOI 10.1016/j.physrep.2005.10.009
   Cannistraci CV, 2013, SCI REP-UK, V3, DOI 10.1038/srep01613
   Chaoji V., 2012, P 21 INT C WORLD WID, P529, DOI DOI 10.1145/2187836.2187908
   Chen XH, 2018, CHAOS SOLITON FRACT, V108, P57, DOI 10.1016/j.chaos.2018.01.025
   Cheng J., 2014, PLoS ONE, V9
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830
   Dai CY, 2017, SOFT COMPUT, V21, P4197, DOI 10.1007/s00500-016-2030-4
   de Sá HR, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2281, DOI 10.1109/IJCNN.2011.6033513
   Deylami HA, 2015, P 7 C INF KNOWL TECH, P1, DOI [10.1109/IKT.2015.7288742, DOI 10.1109/IKT.2015.7288742]
   Dick K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30044-1
   Ding JY, 2015, PHYSICA A, V417, P76, DOI 10.1016/j.physa.2014.09.005
   Fei Gao, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P683, DOI 10.1145/3110025.3110143
   Feng S, 2018, IEEE ACCESS, V6, P17540, DOI 10.1109/ACCESS.2018.2814000
   Feng X, 2012, EUR PHYS J B, V85, DOI 10.1140/epjb/e2011-20207-x
   Feyessa T., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1421, DOI 10.1109/PASSAT/SocialCom.2011.244
   Fire M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P73, DOI 10.1109/PASSAT/SocialCom.2011.20
   Forouzandeh S., 2015, International Journal of Computer Applications, V124
   Forouzandeh S, 2018, INT J WEB INF SYST, V14, P158, DOI 10.1108/IJWIS-07-2017-0053
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gao M, 2018, APPL INTELL, V48, P4531, DOI 10.1007/s10489-018-1220-4
   Ghafari SM, 2019, LECT NOTES COMPUT SC, V11235, P46, DOI 10.1007/978-3-030-19143-6_4
   Ghafari SM, 2018, 19 WISE, P161
   Ghavipour M, 2018, KNOWL-BASED SYST, V143, P307, DOI 10.1016/j.knosys.2017.06.034
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Golbeck J, 2003, COOPERATIVE INFORM A, V2782, DOI [10.1007/978-3-540-45217-1_18, DOI 10.1007/978-3-540-45217-1_18]
   Golzardi E, 2019, 1 RAC INT C ENG SCI
   Golzardi E, 2019, PHYSICA A, V527, DOI 10.1016/j.physa.2019.121269
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Grover A., 2016, ARXIV
   Guanfeng Liu, 2012, Proceedings of the 2012 IEEE 19th International Conference on Web Services (ICWS), P384, DOI 10.1109/ICWS.2012.47
   Guimerà R, 2009, P NATL ACAD SCI USA, V106, P22073, DOI 10.1073/pnas.0908366106
   Guo GB, 2017, KNOWL-BASED SYST, V122, P17, DOI 10.1016/j.knosys.2017.01.027
   Hong J, 2017, 2017 IEEE 19TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), DOI 10.1109/HealthCom.2017.8210813
   Huang XY, 2021, DATA MIN KNOWL DISC, V35, P1, DOI 10.1007/s10618-020-00716-6
   Huang Z., 2010, Link prediction based on graph topology: The predictive value of generalized clustering coefficient, DOI [10.2139/ssrn.1634014, DOI 10.2139/SSRN.1634014]
   Jeh G., 2002, PROC 8 ACM SIGKDD IN, P538
   Jiang LL, 2019, J AMB INTEL HUM COMP, V10, P3023, DOI 10.1007/s12652-018-0928-7
   Katz L., 1953, Psychometrika, V18, P39, DOI [10.1007/BF02289026, DOI 10.1007/BF02289026]
   Kernighan B. W., 1970, The Bell System Technical Journal, V49, P291, DOI [10.1002/j.1538-7305.1970.tb01770.x, DOI 10.1002/J.1538-7305.1970.TB01770.X]
   Leicht EA, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.026120
   Li D, 2016, SCI REP-UK
   Li FH, 2015, KNOWL-BASED SYST, V89, P669, DOI 10.1016/j.knosys.2015.09.014
   Li FH, 2014, PROCEDIA COMPUT SCI, V29, P432, DOI 10.1016/j.procs.2014.05.039
   Li X, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13936
   Li ZH, 2017, ADV MECH ENG, V9, DOI 10.1177/1687814017693541
   Liao H, 2017, PHYS REP, V689, P1, DOI 10.1016/j.physrep.2017.05.001
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Liu SX, 2017, PHYSICA A, V479, P174, DOI 10.1016/j.physa.2017.02.078
   Liu Z, 2011, EPL-EUROPHYS LETT, V96, DOI 10.1209/0295-5075/96/48007
   Lü LY, 2012, PHYS REP, V519, P1, DOI 10.1016/j.physrep.2012.02.006
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Lü LY, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.046122
   Ma C, 2018, PHYS REV E, V97, DOI 10.1103/PhysRevE.97.022301
   Ma C, 2016, SCI REP-UK, V6, DOI 10.1038/srep30098
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   Menon AK, 2011, LECT NOTES ARTIF INT, V6912, P437, DOI 10.1007/978-3-642-23783-6_28
   Naderan M., 2019, IRAN J ELECT ELECT E, V3, P294, DOI DOI 10.22068/IJEEE.15.3.294
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Pan LM, 2016, SCI REP-UK, V6, DOI 10.1038/srep22955
   Parvin H, 2019, EXPERT SYST APPL, V118, P152, DOI 10.1016/j.eswa.2018.09.045
   Pech R, 2017, EPL-EUROPHYS LETT, V117, DOI 10.1209/0295-5075/117/38002
   Pecli A, 2017, KNOWL INF SYST
   Perozzi B, 2014, ARXIV
   Rafiee S, 2020, PHYSICA A, V539, DOI 10.1016/j.physa.2019.122950
   Ravasz E, 2002, SCIENCE, V297, P1551, DOI 10.1126/science.1073374
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Ruan YF, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/3015771
   Sacco O, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0229-x
   Saeidi S, 2020, COMPUT SOC NETW, V7
   Said A, 2018, APPL SOFT COMPUT, V63, P59, DOI 10.1016/j.asoc.2017.11.014
   Sheikhahmadi A, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0278129
   Sherchan W, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501661
   Soundarajan S, 2012, P WEB C, ppp607, DOI [DOI 10.1145/2187980.2188150, 10.1145/2187980.2188150]
   Sprinzak E, 2003, J MOL BIOL, V327, P919, DOI 10.1016/S0022-2836(03)00239-0
   Stumpf MPH, 2008, P NATL ACAD SCI USA, V105, P6959, DOI 10.1073/pnas.0708078105
   Tan F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107056
   Tang T, 2020, KNOWL-BASED SYST, V194
   Trifunovic S., 2010, INFOCOM IEEE Conference on Computer Communications Workshops, V2010, P1, DOI DOI 10.1109/INFCOMW.2010.5466696
   Valverde-Rebaza Jorge Carlos, 2012, Advances in Artificial Intelligence - SBIA 2012. Proceedings 21th Brazilian Symposium on Artificial Intelligence, P92, DOI 10.1007/978-3-642-34459-6_10
   Valverde-Rebaza J, 2012, INT CONF COMPU ASPEC, P132, DOI 10.1109/CASoN.2012.6412391
   Wang JW, 2017, IEEE SYS MAN CYBERN, P158, DOI 10.1109/SMC.2017.8122595
   Wang P., 2015, SCI CHINA INFORM SCI, V58, P1
   Wang Y, 2015, WORLD WIDE WEB, V18, P159, DOI 10.1007/s11280-013-0241-5
   Wu ZH, 2016, PHYSICA A, V452, P1, DOI 10.1016/j.physa.2016.01.038
   Yan BW, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.056112
   Yang JX, 2016, SCI REP-UK, V6, DOI 10.1038/srep38208
   Yang L, 2021, J INT TECHNOL INF MA, V30
   Yu Q, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101214
   Yu Z, 2015, INFORM SCIENCES, V309, P102, DOI 10.1016/j.ins.2015.03.012
   Zhang B, 2017, COMPUT NETW, V120, P105, DOI 10.1016/j.comnet.2017.04.016
   Zhang HF, 2019, IEEE T CIRCUITS-I, V66, P1608, DOI 10.1109/TCSI.2018.2886770
   Zhang JZ, 2017, INFORM PROCESS MANAG, V53, P42, DOI 10.1016/j.ipm.2016.06.005
   Zhang QM, 2015, SCI REP-UK, V5, DOI 10.1038/srep10350
   Zhang QM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055437
   Zhang XJ, 2018, PHYSICA A, V512, P902, DOI 10.1016/j.physa.2018.08.068
   Zhang Y, 2012, J COMPUT SCI TECH-CH, V27, P492, DOI 10.1007/s11390-012-1238-8
   Zhou T, 2009, EUR PHYS J B, V71, P623, DOI 10.1140/epjb/e2009-00335-8
   Zhu BY, 2015, SCI REP-UK, V5, DOI 10.1038/srep13707
   Zitnik M, 2018, BIOINFORMATICS, V34, P457, DOI 10.1093/bioinformatics/bty294
NR 113
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41571
EP 41607
DI 10.1007/s11042-023-15096-4
EA APR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Singh, N
   Bhandari, AK
AF Singh, Neha
   Bhandari, Ashish Kumar
TI Multiclass variance based variational decomposition system for image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational mode decomposition; Multiclass variance; Multi-level
   thresholding; Color image segmentation
ID MODE DECOMPOSITION; ENTROPY
AB Thresholding-based approaches are widely used for image segmentation due to their low computational cost and complexity and ease of implementation. We proposed a novel framework for performing multilevel image segmentation. The present paper uses the feature of variational mode decomposition (VMD) and multiclass variance function for segmentation. The histogram-based thresholding schemes suffer from high fluctuation that leads to abnormalities and sharp specifics. VMD is applied to remove the unfavorable effects of the histogram by decomposing it into corresponding sub-modes for analysis and extraction of attributes. The Otsu function is then incorporated to generate accurate and optimal threshold values for subdivisions to meet the desire image segmentation. The experimental outcomes show that the proposed technique produces improved segmented images as compared to the other state-of-the-art techniques.
C1 [Singh, Neha; Bhandari, Ashish Kumar] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Bhandari, AK (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, India.
EM nehasingh0910@gmail.com; bhandari.iiitj@gmail.com
RI Bhandari, Ashish Kumar/AAA-9991-2019; Singh, Neha/JED-4558-2023
OI Bhandari, Ashish Kumar/0000-0001-9842-8125; Singh,
   Neha/0000-0001-7214-7392
CR Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   [Anonymous], BERKELEY SEGMENTATIO
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2019, MULTIMED TOOLS APPL, V78, P35733, DOI 10.1007/s11042-019-08195-8
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chouhan SS, 2018, MULTIMED TOOLS APPL, V77, P28483, DOI 10.1007/s11042-018-6005-6
   Chouksey M, 2020, MULTIMED TOOLS APPL, V79
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Dhanachandra N, 2020, MULTIMED TOOLS APPL, V79, P18839, DOI 10.1007/s11042-020-08699-8
   Dragomiretskiy K, 2015, LECT NOTES COMPUT SC, V8932, P197, DOI 10.1007/978-3-319-14612-6_15
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Hao D, 2017, SIGNAL IMAGE VIDEO P, V11, P1411, DOI 10.1007/s11760-017-1101-z
   Kang SQ, 2019, MULTIMED TOOLS APPL, V78, P17719, DOI 10.1007/s11042-018-7129-4
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P11331, DOI 10.1007/s11042-020-10189-w
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Masud M, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3418355
   McKinley R, 2016, LECT NOTES COMPUT SC, V10154, P119, DOI 10.1007/978-3-319-55524-9_12
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sharma A, 2020, J INTERDISCIP MATH, V23, P563, DOI 10.1080/09720502.2020.1731976
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Singh N, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3096266
   Singh N, 2021, MULTIMED TOOLS APPL, V80, P19399, DOI 10.1007/s11042-021-10706-5
   Singh N, 2020, IET IMAGE PROCESS, V14, P794, DOI 10.1049/iet-ipr.2019.0921
   Singh N, 2021, CLUSTER COMPUT, V24, P851, DOI 10.1007/s10586-020-03163-6
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wu YP, 2017, MULTIMED TOOLS APPL, V76, P19781, DOI 10.1007/s11042-015-3192-2
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41609
EP 41639
DI 10.1007/s11042-023-14593-w
EA APR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900006
DA 2024-07-18
ER

PT J
AU Raghuvanshi, KK
   Kumar, S
   Kumar, S
   Kumar, S
AF Raghuvanshi, Kamlesh Kumar
   Kumar, Sunil
   Kumar, Subodh
   Kumar, Sushil
TI Investigation of piecewise linear chaotic map as a diffusion model for
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Piecewise linear chaotic map; Decryption; Confusion;
   Diffusion
ID ALGORITHM; PERMUTATION; SYSTEM
AB In this paper, Piecewise Linear Chaotic Map is investigated as a diffusion model to be used in image encryption. In the proposed model, first, the image is decomposed and mixed with a random number. Next, a shuffling engine shuffles it followed by confusion and diffusion based on Piecewise Linear Chaotic Map. Various test results i.e. key space, key sensitivity, correlation coefficient, Differential attacks and security analysis i.e. NIST randomness test, average Number of Pixels Change Rate >= 99.60% and Uniform Average Change Intensity >= 33.33% scores shows that the proposed encryption model is resistive against the known attacks like chosen and known plaintext attacks.
C1 [Raghuvanshi, Kamlesh Kumar; Kumar, Subodh] Univ Delhi, Ramanujan Coll, Dept Comp Sci, Delhi, India.
   [Kumar, Sunil] Univ Delhi, Shaheed Rajguru Coll Appl Sci Women, Dept Instrumentat, Delhi 110096, India.
   [Kumar, Sushil] Univ Delhi, Shyamlal Coll, Dept Comp Sci, Delhi, India.
C3 University of Delhi; University of Delhi; University of Delhi
RP Kumar, S (corresponding author), Univ Delhi, Shaheed Rajguru Coll Appl Sci Women, Dept Instrumentat, Delhi 110096, India.
EM raghukamlesh@gmail.com; sunilkumar104@gmail.com;
   subodhkumar588@gmail.com; kumar.sk106@gmail.com
RI Kumar, Sunil/AAS-9326-2020; Kumar, Subodh/JYP-8905-2024
OI Kumar, Sunil/0000-0002-7996-6427; KUMAR, SUNIL/0000-0003-2593-3432;
   Raghuvanshi, Dr. Kamlesh Kumar/0000-0001-9887-3392
FU Shaheed Rajguru College of Applied Sciences for Women, Ramanujan
   College; Shyamlal college, University of Delhi
FX Authors acknowledges the support provided by Shaheed Rajguru College of
   Applied Sciences for Women, Ramanujan College and Shyamlal college,
   University of Delhi in this work.
CR COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   GALIL Z, 1986, LECT NOTES COMPUT SC, V218, P128
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Jain K, 2021, PATTERN RECOGN LETT, V152, P356, DOI 10.1016/j.patrec.2021.10.033
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kumar M, 2017, J INF SECUR APPL, V32, P47, DOI 10.1016/j.jisa.2016.09.002
   Kumar S, 2018, J INF SECUR APPL, V43, P123, DOI 10.1016/j.jisa.2018.10.011
   Laarem G, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111437
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Luo YQ, 2019, MULTIMED TOOLS APPL, V78, P22023, DOI 10.1007/s11042-019-7453-3
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Matta P, 2021, MATER TODAY-PROC, V46, P11035, DOI 10.1016/j.matpr.2021.02.153
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2013, NONLINEAR DYNAM, V72, P707, DOI 10.1007/s11071-012-0747-x
   Wang XY, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110102
   Wang XY, 2020, OPT LASER TECHNOL, V122, DOI 10.1016/j.optlastec.2019.105854
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu Y, 2011, NPCR and UACI randomness tests for image encryption
   Ye GD, 2017, NEUROCOMPUTING, V251, P45, DOI 10.1016/j.neucom.2017.04.016
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 32
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 36325
EP 36342
DI 10.1007/s11042-023-15145-y
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000958668000003
DA 2024-07-18
ER

PT J
AU Qayyum, H
   Ali, F
   Nawaz, M
   Nazir, T
AF Qayyum, Huma
   Ali, Farooq
   Nawaz, Marriam
   Nazir, Tahira
TI FRD-LSTM: a novel technique for fake reviews detection using DCWR with
   the Bi-LSTM method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake reviews; Deep learning; PCA; Bi-LSTM
ID MODEL
AB The growth of the internet and the availability of online stores has increased the trend of online shopping among customers. People preferred to read the comments posted by potential buyers before purchasing a product. However, online stores are using machine learning (ML)-based approaches to generate fake comments about the product with the intention of either creating a false positive impact about their products or hitting the reputations of competitors by posting negative comments about their products. Therefore, it is crucial to classify real and fake reviews from online stores to save customers from fraud. To overcome these challenges, we have presented a deep learning-based approach namely FRD-LSTM to timely recognize fake reviews. After performing the preprocessing step, the deep contextualized word representation (DCWR) approach is applied to compute the deep features. Then, the principal component analysis (PCA) approach is applied to minimize the feature space. Finally, the Bi-LSTM classifier is trained on the computed features to classify the real and bogus reviews. Our method improves the fake reviews classification performance while decreasing both the training and testing time complexity. We have tested our approach on a challenging dataset namely the Amazon product reviews database and attained an average accuracy value of 97.21%. We have confirmed through extensive experimentation that our approach is proficient to detect bogus reviews and can assist online buyers in protecting them from fake products.
C1 [Qayyum, Huma; Nawaz, Marriam] UET Taxila, Dept Software Engn, Taxila, Pakistan.
   [Ali, Farooq] UET Taxila, Dept Comp Sci, Taxila, Pakistan.
   [Nazir, Tahira] Riphah Int Univ Gulberg Greens Campus, Fac Comp, Islamabad, Pakistan.
RP Nazir, T (corresponding author), Riphah Int Univ Gulberg Greens Campus, Fac Comp, Islamabad, Pakistan.
EM tahira.nazir@riphah.edu.pk
RI Nawaz, Marriam/JVD-9229-2023
OI Nazir, Tahira/0000-0001-8130-3721
CR Adelani David Ifeoluwa, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P1341, DOI 10.1007/978-3-030-44041-1_114
   Albahli S, 2022, COMPLEX INTELL SYST, V8, P2471, DOI 10.1007/s40747-022-00658-0
   Albahli S, 2021, ARAB J SCI ENG, V46, P8509, DOI 10.1007/s13369-021-05471-4
   Alsharif N, 2022, SOFT COMPUT, V26, P7847, DOI 10.1007/s00500-022-06806-5
   Alsubari SN, 2021, APPL BIONICS BIOMECH, V2021, DOI 10.1155/2021/5522574
   Bahad P, 2019, PROCEDIA COMPUT SCI, V165, P74, DOI 10.1016/j.procs.2020.01.072
   Baishya D., 2021, SN Comput. Sci, V2, P1, DOI [10.1007/s42979-021-00918-9, DOI 10.1007/S42979-021-00918-9]
   Elmogy AM, 2021, INT J ADV COMPUT SC, V12, P601
   Fang YL, 2020, APPL INTELL, V50, P4281, DOI 10.1007/s10489-020-01761-w
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   Gupta P, 2021, ACM INT CONF PR SER, P75, DOI 10.1145/3503162.3503169
   Gutierrez-Espinoza L, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.07912
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Haque T. U., 2018, 2018 IEEE INT C INN, P1, DOI [DOI 10.1109/ICIRD.2018.8376299, 10.1109/ICIRD.2018.8376299]
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kumar A, 2022, DECIS SUPPORT SYST, V155, DOI 10.1016/j.dss.2021.113728
   Li YJ, 2021, MOBILE NETW APPL, V26, P91, DOI 10.1007/s11036-020-01688-z
   Mishra A., 2018, Computer and cyber security, P627
   Mohawesh R, 2021, IEEE ACCESS, V9, P65771, DOI 10.1109/ACCESS.2021.3075573
   Mohawesh R, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114318
   Nawaz M, 2021, MULTIMED TOOLS APPL, V80, P28953, DOI 10.1007/s11042-021-11120-7
   Qi YJ, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P307, DOI 10.1007/978-1-4419-9326-7_11
   Ren Z, 2021, PROC SPIE, V12067, DOI 10.1117/12.2602296
   Sahoo S.R., 2022, Sustainable Management of Manufacturing Systems in Industry 4.0, P159, DOI 10.1007/978-3-030-90462-3_11
   Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771
   Sun C, 2019, IEEE ACCESS, V7, P151034, DOI 10.1109/ACCESS.2019.2948155
   Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553
   Tufail H, 2022, IEEE ACCESS, V10, P25555, DOI 10.1109/ACCESS.2022.3152806
   Vyas P., 2021, LSTM BASED APPROACH, P1
   Wang JD, 2020, IEEE ACCESS, V8, P182625, DOI 10.1109/ACCESS.2020.3028588
   Wang N, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116207
   Webb G. I., 2010, Encyclopedia of Machine Learning, P713, DOI DOI 10.1007/978-0-387-30164-8_576
   Wright R. E., 1995, Reading and Understanding Multivariate Statistics, P217
   Yao JR, 2021, IEEE ACCESS, V9, P16914, DOI 10.1109/ACCESS.2021.3051174
   Yin CY, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3450285
NR 36
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31505
EP 31519
DI 10.1007/s11042-023-15098-2
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000952027100001
DA 2024-07-18
ER

PT J
AU Rani, V
   Kumar, M
AF Rani, Veenu
   Kumar, Munish
TI Human gait recognition: A systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Gait; Model-free; Model-based; Covariates; Sensors
ID MACHINE LEARNING ALGORITHMS; FEATURE-SELECTION; NEURAL-NETWORKS;
   AUTHENTICATION; CLASSIFICATION; FEATURES
AB A biometric system is a technology that utilizes an individual's unique physiological and behavioral characteristics to identify and authenticate them. It falls under the category of pattern recognition. Gait recognition, specifically the identification of individuals based on their walking patterns, has garnered significant attention from researchers due to its potential to accurately identify individuals from a distance. Gait recognition systems involve a complex integration of technical, operational and definitional choices and have been applied in a variety of contexts such as security, medical examinations, identity management, and access control. The utilization of gait recognition methods and tools has led to the development of various useful and widely accepted applications. This article provides an overview of the various techniques and approaches employed in gait recognition, including the framework, history, and parameters utilized. The article also delves into the different classifiers, both traditional and deep learning-based, used in the field. Additionally, it examines the different types of datasets utilized in experimental research and the methodology for evaluating articles on gait recognition. With its potential in security applications, gait recognition is expected to have a wide range of future applications.
C1 [Rani, Veenu; Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018
OI Kumar, Munish/0000-0003-0115-1620
CR Açici K, 2017, COMM COM INF SC, V744, P609, DOI 10.1007/978-3-319-65172-9_51
   Ahmed K, 2023, SIGNAL IMAGE VIDEO P, V17, P925, DOI 10.1007/s11760-022-02217-z
   AlAsadi AH., 2014, J BASRAH RES, V40, P68
   Alotaibi M, 2017, SIGNAL IMAGE VIDEO P, V11, P1131, DOI 10.1007/s11760-017-1067-x
   Alsaggaf WA, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/3110416
   [Anonymous], 2017, PROC 2017 5 INT WORK, DOI DOI 10.1109/IWBF.2017.7935092
   Aqmar M. R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2190, DOI 10.1109/ICPR.2010.536
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Asif M, 2022, RESULTS ENG, V15, DOI 10.1016/j.rineng.2022.100556
   Babaee M, 2018, IEEE IMAGE PROC, P768, DOI 10.1109/ICIP.2018.8451785
   Bae J, 2011, MECHATRONICS, V21, P961, DOI 10.1016/j.mechatronics.2011.03.003
   Baker R, 2007, GAIT POSTURE, V26, P331, DOI 10.1016/j.gaitpost.2006.10.014
   Balamurugan S., 2021, TURK J COMPUT MATH E, V12, P472
   Begg R., 2006, AUSTRALASIAN PHYSICAL & ENGINEERING SCIENCES IN MEDICINE, V29, P188, DOI 10.1007/BF03178892
   Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241
   Benyacoub B., 2014, Applied Mathematical Sciences, V8, P2483
   Bertoli M, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0488-2
   Bouchrika I, 2009, LECT NOTES COMPUT SC, V5558, P990, DOI 10.1007/978-3-642-01793-3_100
   Britto AV, 2018, P IEEE INT C COMP IN, P1
   Castro FM, 2020, NEURAL COMPUT APPL, V32, P14173, DOI 10.1007/s00521-020-04811-z
   Chen CH, 2011, PATTERN RECOGN, V44, P988, DOI 10.1016/j.patcog.2010.10.021
   Chen Q, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P54, DOI 10.1109/BTAS.2017.8272682
   Choi S, 2014, INT CONF COMPUT NETW, P1091, DOI 10.1109/ICCNC.2014.6785491
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   Alcaraz JC, 2021, EURASIP J ADV SIG PR, V2021, DOI 10.1186/s13634-020-00715-1
   Derlatka M, 2015, C HUM SYST INTERACT, P88, DOI 10.1109/HSI.2015.7170648
   Elharrouss O, 2021, J SUPERCOMPUT, V77, P3653, DOI 10.1007/s11227-020-03409-5
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Gadaleta M, 2016, 2016 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP)
   Gao J, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/1648138
   Gao ZP, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.996
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Giorgi Giacomo, 2017, Computer Safety, Reliability and Security, SAFECOMP 2017: Workshops ASSURE, DECSoS, SASSUR, TELERISE and TIPS. Proceedings: LNCS 10489, P384, DOI 10.1007/978-3-319-66284-8_32
   Gou H, 2015, MATEC WEB CONF, V30, DOI 10.1051/matecconf/20153006001
   Guo Q, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60132
   Gupta A, 2015, 2015 IEEE 8TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA) PROCEEDINGS, P89, DOI 10.1109/IWCIA.2015.7449468
   Gupta SK, 2021, NEUROCOMPUTING, V454, P76, DOI 10.1016/j.neucom.2021.04.113
   Hawas AR, 2019, MULTIMED TOOLS APPL, V78, P25873, DOI 10.1007/s11042-019-7638-9
   Hnatiuc M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070852
   Horst F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38748-8
   Hu L, 2022, IEEE T FUZZY SYST, V30, P3473, DOI 10.1109/TFUZZ.2021.3117442
   Huan Z, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/6471532
   Huang HH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082866
   Huang PS, 1999, IEE P-VIS IMAGE SIGN, V146, P93, DOI 10.1049/ip-vis:19990187
   Isaac ERHP, 2019, IEEE-CAA J AUTOMATIC, V6, P209, DOI 10.1109/JAS.2019.1911345
   Islam M, 2019, 2019 INTERNATIONAL CONFERENCE ON ENERGY AND POWER ENGINEERING (ICEPE), DOI [10.1109/cepe.2019.8726565, 10.1109/eict48899.2019.9068822]
   Jarchi Delaram, 2018, IEEE Rev Biomed Eng, V11, P177, DOI 10.1109/RBME.2018.2807182
   Jayasinghe U, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176605
   Jiang XR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195466
   Junaid I, 2022, 2022 IEEE INT C SIGN, DOI [10.1109/spcom55316.2022.9840818, DOI 10.1109/SPCOM55316.2022.9840818]
   Kale A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P336, DOI 10.1109/AFGR.2002.1004176
   Kececi A, 2020, ENG SCI TECHNOL, V23, P931, DOI 10.1016/j.jestch.2020.01.005
   Kiprijanovska I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185373
   Kong W, 2014, PROC IEEE S COMPUTAT, P1
   Konz L, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22208075
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kukreja V, 2021, DEEP LEARN HUM GAIT, P9, DOI [10.1109/ICACITE51222.2021.9404611, DOI 10.1109/ICACITE51222.2021.9404611]
   Kumar MSN, 2012, P 8 IND C COMP VIS G, P1
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Lai ZH, 2014, IEEE T CIRC SYST VID, V24, P1651, DOI 10.1109/TCSVT.2014.2305495
   Lee SS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081757
   Li W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103496
   Li X, 2019, IEEE T INF FOREN SEC, V14, P3102, DOI 10.1109/TIFS.2019.2912577
   Liao R, 2022, NEUROCOMPUTING, V501, P514, DOI 10.1016/j.neucom.2022.06.048
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Lin J., 2015, PROC 5 INT C COMPUTE, V5, P73
   Linda GM, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691319410121
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Luo J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061646
   Luo X, 2021, IEEE T SYST MAN CY-S, V51, P610, DOI 10.1109/TSMC.2018.2875452
   Lv ZW, 2015, SENSORS-BASEL, V15, P932, DOI 10.3390/s150100932
   Madduri Abhishek., 2021, INT J COMPUT TRENDS, V69, P22, DOI DOI 10.14445/22312803/IJCTT-V69I6P104
   Makhdoomi NA., 2013, IOP CONF SER-MAT SCI, V53, P1
   Milovanovic I, 2012, COMPUT MATH METHOD M, V2012, DOI 10.1155/2012/649743
   Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Park G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94815-z
   Peinado-Contreras A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236900
   Provencher MT, 2000, SPINE, V25, P131, DOI 10.1097/00007632-200001010-00022
   Qi YJ, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/2674425
   Qi YB, 2014, SENSORS-BASEL, V14, P15434, DOI 10.3390/s140815434
   Qiao SB, 2021, INT J COMPUT INT SYS, V14, P482, DOI 10.2991/ijcis.d.201222.001
   Rani Veenu, 2022, Artificial Intelligence and Data Science: First International Conference, ICAIDS 2021, Revised Selected Papers. Communications in Computer and Information Science (1673), P77, DOI 10.1007/978-3-031-21385-4_7
   Ricciardi C, 2020, HEALTH INFORM J, V26, P2181, DOI 10.1177/1460458219899210
   Saleh AM, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00387-6
   San-Segundo R, 2017, PERVASIVE MOB COMPUT, V38, P140, DOI 10.1016/j.pmcj.2016.09.007
   Seifert AK, 2017, IEEE RAD CONF, P1428, DOI 10.1109/RADAR.2017.7944431
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Sepas-Moghaddam A, 2021, COMPUTER VISION PATT, P1
   Renani MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195553
   Sheth A, 2023, INT J ONLINE BIOMED, V19, P107, DOI 10.3991/ijoe.v19i01.33823
   Shirke S, 2014, INT CONF COMM SYST, P891, DOI 10.1109/CSNT.2014.252
   Si W, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8815461
   Singh JP, 2021, ARCH COMPUT METHOD E, V28, P107, DOI 10.1007/s11831-019-09375-3
   Singh JP, 2018, IEEE ACCESS, V6, P70497, DOI 10.1109/ACCESS.2018.2879896
   Sokolova A, 2019, IET BIOMETRICS, V8, P134, DOI 10.1049/iet-bmt.2018.5046
   Strukova O. V., 2019, Journal of Physics: Conference Series, V1368, DOI 10.1088/1742-6596/1368/3/032001
   Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93
   Tafazzoli F, 2014, LECT NOTES COMPUT SC, V8888, P830, DOI 10.1007/978-3-319-14364-4_80
   Talha M, 2022, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2022, P197, DOI 10.1145/3529190.3529199
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Thapar D, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA)
   Tong SB, 2019, PATTERN RECOGN LETT, V125, P212, DOI 10.1016/j.patrec.2019.04.010
   Tran L, 2021, IEEE ACCESS, V9, P23826, DOI 10.1109/ACCESS.2021.3056880
   Tupa O, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0092-7
   Ukrit M.F., 2020, EUR J MOL CLIN MED, V7, P1636
   Vasudevan P., 2023, COMPUT MAT CONTINUA, V74, P6039, DOI [10.32604/cmc.2023.032331, DOI 10.32604/CMC.2023.032331]
   Wagner J, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031218
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Wang FZ, 2019, SENSOR MATER, V31, P1335, DOI 10.18494/SAM.2019.2288
   Wang N, 2010, PROCEEDINGS OF THE 2ND (2010) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P320
   Wang YY, 2019, NEUROCOMPUTING, V339, P245, DOI 10.1016/j.neucom.2019.02.025
   Wang Y, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010193
   Wang Y, 2022, VISUAL COMPUT, V38, P1915, DOI 10.1007/s00371-021-02254-8
   Wu FY, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2982894
   Xia LM, 2019, J CENT SOUTH UNIV, V26, P2759, DOI 10.1007/s11771-019-4211-7
   Xu C, 2023, IEEE T INF FOREN SEC, V18, P1309, DOI 10.1109/TIFS.2023.3236181
   Xu ZP, 2019, J VIS COMMUN IMAGE R, V59, P159, DOI 10.1016/j.jvcir.2019.01.023
   Yazdi Hadi Sadoghi, 2012, ISRN Artificial Intelligence, DOI 10.5402/2012/289721
   Yeoh T, 2016, I S INTELL SIG PROC, P194
   Yu Guan, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P321, DOI 10.1109/IIH-MSP.2012.84
   Zeng X, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134592
   Zhang J, 2012, GAIT POSTURE, V36, P667, DOI 10.1016/j.gaitpost.2012.04.020
   Zhang YX, 2019, COMPUT BIOL MED, V106, P33, DOI 10.1016/j.compbiomed.2019.01.009
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zou Q, 2020, IEEE T INF FOREN SEC, V15, P3197, DOI 10.1109/TIFS.2020.2985628
NR 127
TC 5
Z9 5
U1 17
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 17
PY 2023
DI 10.1007/s11042-023-15079-5
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A2FH1
UT WOS:000953336200005
DA 2024-07-18
ER

PT J
AU Srivastava, R
   Kumar, P
AF Srivastava, Rajshree
   Kumar, Pardeep
TI Optimizing CNN based model for thyroid nodule classification using data
   augmentation, segmentation and boundary detection techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thyroid nodules; Deep learning; Classification; Detection;
   Ultrasonography; Boundary detection; Data augmentation; Segmentation;
   Convolutional neural network
AB Thyroid nodule is an asymptomatic disorder which mostly occurs due to high production of thyroid hormones from the thyroid gland. The diagnosis is usually made by the radiologist and endocrinologists which heavily relies on their experience and expertise. Ultrasonography is one of the principal means for the initial assessment of nodules which is mainly performed when there is suspect of formation of nodules. In this research work, an optimized convolutional neural network model is proposed for the identification of thyroid nodules using various deep learning techniques like dense neural network, Alexnet, Resnet-50 and Visual geometry group-16. A total of 295 public and 654 collected thyroid ultrasonography datasets are considered in this work. The proposed model is evaluated on 1475 public and 3270 collected thyroid ultrasonography datasets with data augmentation technique. We experimentally determined the best optimized value for learning rate and drop out factor to enhance the performance of the models. The proposed model has achieved an accuracy of 93.75%, sensitivity of 94.62%, specificity of 92.53% and f-measure of 94.09% on the public dataset in experiment-I and an accuracy of 96.89%, sensitivity of 97.80%, specificity of 94.73% and f-measure of 97.26% on the collected dataset in experiment-II. The proposed model has shown an improvement of (4.57%, 7.84%), (5.06%, 8.24%), (4.43%, 6.63%) and (4.66%, 7.83%) in terms of accuracy, sensitivity, specificity and f-measure on (dataset -1, dataset-2) against other state of the art models.
C1 [Srivastava, Rajshree; Kumar, Pardeep] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, Himachal Prades, India.
C3 Jaypee University of Information Technology
RP Kumar, P (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Waknaghat, Himachal Prades, India.
EM rajshree.srivastava27@gmail.com; pardeepkumarkhokhar@gmail.com
RI SRIVASTAVA, RAJSHREE/O-9908-2018
CR Ajilisa O. A., 2020, 2020 Advanced Computing and Communication Technologies for High Performance Applications (ACCTHPA), P237, DOI 10.1109/ACCTHPA49271.2020.9213210
   Al-Rahlawee ATH, 2021, MULTIMED TOOLS APPL, V80, P28217, DOI 10.1007/s11042-021-10860-w
   Baldini E, 2022, J PERS MED, V12, DOI 10.3390/jpm12020156
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Nguyen DT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071822
   Nguyen DT, 2019, J CLIN MED, V8, DOI 10.3390/jcm8111976
   Guo XD, 2020, I S BIOMED IMAGING, P296, DOI [10.1109/ISBI45749.2020.9098637, 10.1109/isbi45749.2020.9098637]
   Gurunathan A, 2021, INT J IMAG SYST TECH, V31, P1174, DOI 10.1002/ima.22532
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ikebe M, 2005, J ROBOT MECHATRON, V17, P372, DOI 10.20965/jrm.2005.p0372
   Ilhan U, 2017, PROCEDIA COMPUT SCI, V120, P580, DOI 10.1016/j.procs.2017.11.282
   Kaur M, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8829829
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khan IU, 2021, 2021 IEEE MADRID POWERTECH, DOI 10.1109/PowerTech46648.2021.9495000
   Khan MA, 2021, ADV CIV ENG, V2021, DOI 10.1155/2021/6618407
   Ko SY, 2019, HEAD NECK-J SCI SPEC, V41, P885, DOI 10.1002/hed.25415
   Koundal D, 2018, BIOMED SIGNAL PROCES, V40, P117, DOI 10.1016/j.bspc.2017.08.025
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03306-6
   Kumar N, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9983652
   Li C, 2016, PRINCIPLES APPL RF M
   Lu JT, 2022, IEEE J BIOMED HEALTH, V26, P1582, DOI 10.1109/JBHI.2022.3153559
   Merzban MH, 2019, EXPERT SYST APPL, V116, P299, DOI 10.1016/j.eswa.2018.09.008
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Owais M, 2019, J CLIN MED, V8, DOI 10.3390/jcm8040462
   Park K, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12010073
   Pedraza L, 2015, PROC SPIE, V9287, DOI 10.1117/12.2073532
   Quality Council of India, US
   Rai HM, 2021, MULTIMED TOOLS APPL, V80, P36111, DOI 10.1007/s11042-021-11504-9
   Richman DM, 2020, RADIOLOGY, V294, P415, DOI 10.1148/radiol.2019191326
   Rohith G, 2022, MULTIMED TOOLS APPL, P1
   Ruggeri RM, 2022, J ENDOCRINOL INVEST, V45, P2283, DOI 10.1007/s40618-022-01863-x
   Saba T, 2021, MICROSC RES TECHNIQ, V84, P1272, DOI 10.1002/jemt.23686
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Shaban WM, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106906
   Shi GH, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105611
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song WF, 2019, IEEE J BIOMED HEALTH, V23, P1215, DOI 10.1109/JBHI.2018.2852718
   Srivastava R, 2021, IN PRESS
   Tejas R, 2022, CONTOUR DETECTION ED
   Wang JX, 2018, IEEE IMAGE PROC, P3114, DOI 10.1109/ICIP.2018.8451085
   Xie J, 2020, IEEE INT CONF HEALT, V1693
   Xu ZY, 2020, OPEN MED-WARSAW, V15, P860, DOI 10.1515/med-2020-0131
   Yang WK, 2021, ENG APPL ARTIF INTEL, V98, DOI 10.1016/j.engappai.2020.104064
   Yao XQ, 2022, MATH EDUC RES J, V34, P241, DOI 10.1007/s13394-020-00343-w
   Yao XH, 2022, J MATER CHEM A, V10, P2917, DOI 10.1039/d1ta09292h
   Zhao SX, 2022, IEEE T MED IMAGING
   Zhu YC, 2021, ULTRASONICS, V110, DOI 10.1016/j.ultras.2020.106300
NR 48
TC 4
Z9 4
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41037
EP 41072
DI 10.1007/s11042-023-15068-8
EA MAR 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000953336200004
DA 2024-07-18
ER

PT J
AU Srihari, P
   Santosh, V
   Ganapathy, S
AF Srihari, P.
   Santosh, V.
   Ganapathy, Sannasi
TI An epileptic seizures diagnosis system using feature selection, fuzzy
   temporal naive Bayes and T-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE KNN; Decision tree classifier; Naive Bayes; Logistic regression;
   Stochastic gradient descent epileptic seizure
AB Today's hospitals make use of state-of-the-art methods such as magnetic resonance imaging (MRI) and electroencephalogram (EEG) signal predictions in order to predict the occurrence of seizures well in advance. However, this method only works in theory. Almost every standard seizure prediction approach fails to predict epileptic seizures. Accurately, and most doctors mainly focus only on the treatment of epilepsy rather than preventing it. Health experts say that successive epileptic seizures would be even more virulent and fatal to individuals. The motivation of this research is to effectively predict and manage epileptic seizures disease by analyzing EEG signals. This work proposes a new Epileptic Seizures Diagnosis System (ESDS) for diagnosing epileptic seizures effectively. The proposed ESDS consists of two components, namely feature selection and classification. First, a newly proposed Fuzzy Temporal Naive Bayes (FT-NB) classifier and the existing Convolutional Neural Network with Temporal Features (T-CNN) are proposed for performing effective data preprocessing and classification. Second, a GridSearchCV method is used to determine the best parameter for hyperparameter tuning to obtain the best performance in the FT-NB. In addition, the T-CNN is also applied for enhancing the prediction result further, and the different machine learning (ML) algorithms are considered for performing comparative analysis with the FT-NB in terms of disease prediction. The experiments have been conducted by using the standard dataset and proved as better than other systems in terms of Precision (87.5%), Recall (90.4%), Specificity (97.4%) and Accuracy (96.7%).
C1 [Srihari, P.; Santosh, V.; Ganapathy, Sannasi] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.
   [Ganapathy, Sannasi] Vellore Inst Technol, Ctr Cyber Phys Syst, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Ganapathy, S (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, India.; Ganapathy, S (corresponding author), Vellore Inst Technol, Ctr Cyber Phys Syst, Chennai, India.
EM srihari.p2019@vitstudent.ac.in; santosh.v2019@vitstudent.ac.in;
   sganapathy@vit.ac.in
CR Abuimara Abdellatif, 2015, 2015 IEEE 4th Portuguese Meeting on Bioengineering (ENBENG). Proceedings, P1, DOI 10.1109/ENBENG.2015.7088840
   Almustafa KM., 2020, Inf. Med. Unlocked, V2, P1, DOI DOI 10.1016/J.IMU.2020.100444
   Antoniades A, 2016, IEEE INT WORKS MACH
   Anugraha A., 2017, 2017 INT C COMPUTATI, P1, DOI [DOI 10.1109/ICCIDS.2017.8272636, 10.1109/ICCIDS.2017.8272636, 10.1109/iccids.2017.8272636]
   Bhat KG, 2019, ASIA PAC CONF POSTGR, P1, DOI [10.1109/primeasia47521.2019.8950727, 10.1109/PrimeAsia47521.2019.8950727]
   Cao YZ, 2017, INT CONF SYST INFORM, P1076, DOI 10.1109/ICSAI.2017.8248445
   Daoud H, 2019, IEEE T BIOMED CIRC S, V13, P804, DOI 10.1109/TBCAS.2019.2929053
   Ganapathy S, 2014, SADHANA-ACAD P ENG S, V39, P283, DOI 10.1007/s12046-014-0236-7
   Jiang LX, 2009, IEEE T KNOWL DATA EN, V21, P1361, DOI 10.1109/TKDE.2008.234
   Kanimozhi U, 2019, NATL ACAD SCI LETT, V42, P227, DOI 10.1007/s40009-018-0732-0
   Kumar Abhishek, 2014, 2014 International Conference on Medical Imaging, m-Health and Emerging Communication Systems (MedCom), P412, DOI 10.1109/MedCom.2014.7006043
   Lestari Fauzia P., 2020, Journal of Physics: Conference Series, V1505, DOI 10.1088/1742-6596/1505/1/012055
   Perumal SP, 2019, J SUPERCOMPUT, V75, P5145, DOI 10.1007/s11227-019-02791-z
   Pinto MF, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82828-7
   Randon NJ, 2008, IEEE T FUZZY SYST, V16, P725, DOI 10.1109/TFUZZ.2008.919278
   Rasheed K, 2021, IEEE REV BIOMED ENG, V14, P139, DOI 10.1109/RBME.2020.3008792
   Riyaz B, 2020, SOFT COMPUT, V24, P17265, DOI 10.1007/s00500-020-05017-0
   Selim Sahar, 2019, 2019 14th International Conference on Computer Engineering and Systems (ICCES). Proceedings, P239, DOI 10.1109/ICCES48960.2019.9068190
   Shirakawa M, 2015, IEEE T EMERG TOP COM, V3, P205, DOI 10.1109/TETC.2015.2418716
   Siddiqui Mohammad Khubeb, 2020, Brain Inform, V7, P5, DOI 10.1186/s40708-020-00105-1
   Singh K, 2022, COMPLEX INTELL SYST, V8, P2405, DOI 10.1007/s40747-021-00627-z
   Usman SM, 2020, IEEE ACCESS, V8, P39998, DOI 10.1109/ACCESS.2020.2976866
   Usman SM, 2019, INT J ADV APPL SCI, V6, P50, DOI 10.21833/ijaas.2019.03.008
   Usman SM, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/9074759
   Wang SH, 2020, IEEE ACCESS, V8, P225639, DOI 10.1109/ACCESS.2020.3044946
   Wu X., 2022, FRONT NEUROSCI, V16, P1
   Yu LJ, 2020, IEEE ACCESS, V8, P51377, DOI 10.1109/ACCESS.2020.2973331
NR 27
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34075
EP 34094
DI 10.1007/s11042-023-14928-7
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000949737500004
DA 2024-07-18
ER

PT J
AU Devi, TG
   Patil, N
   Rai, S
   Sarah, CP
AF Devi, Tulasi Gayatri
   Patil, Nagamma
   Rai, Sharada
   Sarah, Cheryl Philipose
TI Real-time microscopy image-based segmentation and classification models
   for cancer cell detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive threshold masking method; Cancer cell detection; Convolutional
   neural network; Max pooling; UNet; VGG16
ID OPTIMIZATION
AB Image processing techniques and algorithms are extensively used for biomedical applications. Convolution Neural Network (CNN) is gaining popularity in fields such as the analysis of complex documents and images, which qualifies the approach to be used in biomedical applications. The key drawback of the CNN application is that it can't call the previous layer output following the layer's input. To address this issue, the present research has proposed the novel Modified U-Net architecture with ELU Activation Framework (MU-EAF) to detect and classify cancerous cells in the blood smear images. The system is trained with 880 samples, of which 220 samples were utilized in the validation model, and 31 images were utilized to verify the proposed model. The identified mask output of the segmentation model in the predicted mask fits the classification model to identify the cancer cell occurrence in the collected images. In addition, the segmentation evaluation is done by matching each pixel of the ground truth mask (labels) to the predicted labels from the model. The performance metrics for evaluating the segmentation of images are pixel accuracy, dice coefficient (F1-score), and Jaccard coefficient. Moreover, the model is compared with VGG-16 and simple modified CNN models, which have four blocks, each consisting of a convolutional layer, batch normalization, and activation layer with RELU activation function that are implemented and for assessing the same images used for the proposed model. The proposed model shows higher accuracy in comparison.
C1 [Devi, Tulasi Gayatri; Patil, Nagamma] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, Karnataka, India.
   [Rai, Sharada; Sarah, Cheryl Philipose] Kasturba Med Coll & Hosp, Dept Pathol, Mangalore, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Manipal Academy of Higher Education (MAHE);
   Kasturba Medical College, Mangalore
RP Devi, TG (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, Karnataka, India.
EM 177it003tulasi@nitk.edu.in; nagammapatil@nitk.edu.in;
   sharada.rai@manipal.edu; cheryl.philipose@manipal.edu
OI Gayatri, Tulasi/0000-0002-9898-5412
CR Anilkumar KK, 2021, BIOMED ENG-APP BAS C, V33, DOI 10.4015/S1016237221500423
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Bharath B, 2017, INT CONF COMPUT POW, P43, DOI 10.1109/ICCPEIC.2017.8290336
   Carvalho V, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12030317
   Das D, 2021, J MED BIOL ENG, V41, P379, DOI 10.1007/s40846-021-00612-4
   Elakkiya R, 2022, MULTIMED TOOLS APPL, V81, P191, DOI 10.1007/s11042-021-10627-3
   Ghoneim A, 2020, FUTURE GENER COMP SY, V102, P643, DOI 10.1016/j.future.2019.09.015
   Kalinathan L, 2020, HISTOL HISTOPATHOL, V35, P1115, DOI 10.14670/HH-18-240
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Kanmani M, 2019, MULTIDIM SYST SIGN P, V30, P1911, DOI 10.1007/s11045-019-00636-9
   Krithiga R, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01122-0
   Kumar D, 2020, IEEE ACCESS, V8, P142521, DOI 10.1109/ACCESS.2020.3012292
   Kurmi Y, 2021, SIGNAL IMAGE VIDEO P, V15, P1341, DOI 10.1007/s11760-021-01865-x
   Leblebici SY, 2016, NAT ENERGY, V1, DOI [10.1038/nenergy.2016.93, 10.1038/NENERGY.2016.93]
   Madheswari K, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P2826, DOI 10.1109/TENCON.2016.7848558
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Marzahl C, 2019, LECT N BIOENG, P13, DOI 10.1007/978-981-15-0798-4_2
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Pan XP, 2018, WORLD WIDE WEB, V21, P1721, DOI 10.1007/s11280-017-0520-7
   Priyankaa J., 2021, Turkish J. Comp. Math. Edu., V12, P3050
   Ratley Astha, 2020, 2020 First International Conference on Power, Control and Computing Technologies (ICPC2T), P161, DOI 10.1109/ICPC2T48082.2020.9071471
   Ravichandran A, 2017, INT CONF COMPUT POW, P68, DOI 10.1109/ICCPEIC.2017.8290341
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahlo AT, 2019, SOFT COMPUT, V23, P6345, DOI 10.1007/s00500-018-3288-5
   Shah S, 2019, LECT N BIOENG, P23, DOI 10.1007/978-981-15-0798-4_3
   Shemona JS, 2020, IET IMAGE PROCESS, V14, P1726, DOI 10.1049/iet-ipr.2019.1067
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Xiang Y, 2020, BIOCYBERN BIOMED ENG, V40, P611, DOI 10.1016/j.bbe.2020.01.016
   Zeng ZT, 2019, IEEE ACCESS, V7, P21420, DOI 10.1109/ACCESS.2019.2896920
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
NR 30
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35969
EP 35994
DI 10.1007/s11042-023-14898-w
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000948950300011
DA 2024-07-18
ER

PT J
AU Jana, GC
   Swami, K
   Agrawal, A
AF Jana, Gopal Chandra
   Swami, Keshav
   Agrawal, Anupam
TI Capsule neural network based approach for subject specific and
   cross-subjects seizure detection from EEG signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalogram (EEG); Cross-subject seizure detection; Capsule
   neural network; Decision tree; Logistic regression; Convolutional neural
   network
ID EPILEPTIC SEIZURE; CLASSIFICATION; RECOGNITION
AB The objective of this study is to propose an approach to detect Seizure and Non-Seizure phenomenon from the highly inconsistent and non-linear EEG signals. In the view of performing cross-subject classification over the inconsistency and non-linear characteristics of EEG signals, we have proposed a fine-tuned Capsule Neural Network (CapsNet) based approach to classify the seizure and non-seizure EEG signals through subject specific and cross-subject training and testing. In this experiment, first we have normalized the input data using L2 normalization technique. In the second step, the normalized data have been given to the CapsNet and model level fine-tuning has been carried out. In addition to this, we have performed seizure and non-seizure classification performance evaluation using three more classifiers such as Decision Tree, Logistic Regression, Convolutional Neural Network to compare with the performance of the proposed approach. To estimate the effectiveness of the proposed approach, subject specific and cross-subject training and testing have been performed. In both experiments, we have used multi-channel and single channel EEG datasets. For subject specific experiment, the proposed approach achieved a mean accuracy of 93.50% over the dataset-1 (multi-channel) and an accuracy of 82.61% for dataset-2 (single channel). For cross-subject experiment, the proposed approach achieved a highest mean accuracy of 86.41% over the dataset-1(multi-channel) and a mean accuracy of 48.45% over the dataset-2 (single channel) which shows an advantage of CapsNet in a certain data scenario as described in result section. Overall performance of the proposed approach shown a comparable improvement over the existing approaches.
C1 [Jana, Gopal Chandra; Agrawal, Anupam] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Interact Technol & Multimedia Res Lab, Prayagraj 211015, UP, India.
   [Swami, Keshav] KIIT Deemed Be Univ, Sch Comp Engn, Bhubaneswar 751024, Odisha, India.
C3 Indian Institute of Information Technology Allahabad; Kalinga Institute
   of Industrial Technology (KIIT)
RP Jana, GC (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Interact Technol & Multimedia Res Lab, Prayagraj 211015, UP, India.
EM go.gopal.ch.jana@gmail.com
RI Jana, Gopal Chandra/C-9912-2018
OI Jana, Gopal Chandra/0000-0003-2793-1721
FU Department of Information Technology, Indian Institute of Information
   Technology Allahabad
FX This work was carried out at Interactive Technologies & Multimedia
   Research Lab (ITMR Lab) supported by the Department of Information
   Technology, Indian Institute of Information Technology Allahabad
   (https://www.iiita.ac.in/), UP, India. The authors are grateful for this
   support.
CR Abdelhameed A, 2021, FRONT COMPUT NEUROSC, V15, DOI 10.3389/fncom.2021.650050
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2022, EPILEPSY FACTSHEET
   Bhattacharyya A, 2017, IEEE T BIO-MED ENG, V64, P2003, DOI 10.1109/TBME.2017.2650259
   Bisong E., 2019, BUILDING MACHINE LEA, P59, DOI DOI 10.1007/978-1-4842-4470-87
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   Chen SN, 2019, IEEE ACCESS, V7, P61046, DOI 10.1109/ACCESS.2019.2915610
   Chernecky CC., 2013, LAB TESTS DIAGNOSTIC, V6th
   Chiang HS, 2019, IEEE ACCESS, V7, P103255, DOI 10.1109/ACCESS.2019.2929266
   Cole TJ., 1991, Statistics in Medicine, V10, P1162, DOI DOI 10.1002/SIM.4780100718
   Constantino TM, WHATS DIFFERENCE SEI
   Department of Epileptology University of Bonn, EEG TIM SER DOWNL PA
   EEG (Electroencephalogram)-Epilepsy Society, US
   Eldor T, CAPSULE NEURAL NET 2
   Emami A, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101684
   Engel J., 2008, Epilepsy : a comprehensive textbook, V2nd
   Gajic D, 2015, FRONT COMPUT NEUROSC, V9, DOI [10.3389/fncom.7015.00038, 10.3389/fncom.2015.00038]
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo JL, 2018, INT CONF CLOUD COMPU, P47, DOI 10.1109/CCIS.2018.8691230
   Guo Xifeng., Keras Implementation for Deep Embedding Clustering (DEC)
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Ha KW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132854
   Ha KW, 2019, INT CONF BIG DATA, P387, DOI 10.1109/bigcomp.2019.8678917
   Hussain L, 2018, COGN NEURODYNAMICS, V12, P271, DOI 10.1007/s11571-018-9477-1
   Jana GC, 2020, PROCEDIA COMPUT SCI, V167, P403, DOI 10.1016/j.procs.2020.03.248
   Li Y, 2018, IEEE J BIOMED HEALTH, V22, P386, DOI 10.1109/JBHI.2017.2654479
   Liu CL, 2019, IEEE ACCESS, V7, P170352, DOI 10.1109/ACCESS.2019.2955285
   Mei ZN, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061720
   Naturomics, TENSORFLOW IMPL CAPS
   Truong ND, 2018, IEEE J EM SEL TOP C, V8, P849, DOI 10.1109/JETCAS.2018.2842761
   Niedermeyer E., 2005, ELECTROEN CLIN NEURO, DOI DOI 10.1016/B978-0-323-04233-8.50007-X
   Ozcan AR, 2019, IEEE T NEUR SYS REH, V27, P2284, DOI 10.1109/TNSRE.2019.2943707
   physionet.org, CHB MIT SCALP EEG DA
   Polat K, 2007, APPL MATH COMPUT, V187, P1017, DOI 10.1016/j.amc.2006.09.022
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Qiu Y, 2018, IEEE T NEUR SYS REH, V26, P1717, DOI 10.1109/TNSRE.2018.2864306
   research.google.com, COL FREQ ASK QUEST
   Rokach Lior, 2014, Data mining with decision trees: theory and applications, V2, DOI 10.1142/9097
   Sabour S, 2017, ADV NEUR IN, V30
   scikit-learn.org, PREPROCESSING DATA N
   Shoaran M, 2018, IEEE J EM SEL TOP C, V8, P693, DOI 10.1109/JETCAS.2018.2844733
   Solaija MSJ, 2018, IEEE ACCESS, V6, P38683, DOI 10.1109/ACCESS.2018.2853125
   Srihari S, US
   Subasi A, 2005, EXPERT SYST APPL, V28, P701, DOI 10.1016/j.eswa.2004.12.027
   Subasi A, 2005, COMPUT METH PROG BIO, V78, P87, DOI 10.1016/j.cmpb.2004.10.009
   Tatum WO, 2013, HDB EEG INTERPRETATI, P155
   Theeranaew W, 2018, IEEE T BIO-MED ENG, V65, P371, DOI 10.1109/TBME.2017.2771468
   Toraman S, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107033
   Yan PZ, 2019, SEIZURE-EUR J EPILEP, V71, P124, DOI 10.1016/j.seizure.2019.07.009
NR 51
TC 1
Z9 1
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35221
EP 35252
DI 10.1007/s11042-023-14995-w
EA MAR 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500005
DA 2024-07-18
ER

PT J
AU Rawat, AS
   Deshmukh, M
   Singh, M
AF Rawat, Arjun Singh
   Deshmukh, Maroti
   Singh, Maheep
TI A novel multi secret image sharing scheme for different dimension
   secrets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret images; Shares; Reconstructed secrets; Same dimension secrets;
   Different dimension secrets; Attacked share
ID SEMI-TENSOR PRODUCT; ENCRYPTION ALGORITHM; THRESHOLD; SECURE; EFFICIENT;
   MATRIX; LATTICE; CHAOS; (N
AB The existing state of the art schemes deals with the same dimension secret images but less work is available in the literature for different dimension secret images. In this paper, we have proposed an efficient multi secret image sharing scheme for different dimension secret images. In the proposed scheme, Chinese Remainder Theorem (CRT), shift and XOR operations are used for shares generation and secrets reconstruction to provide more randomized shares without revealing any secret information. The proposed scheme is attack resistive as if there is an attack on any of the share(s) then the reconstructed secrets doesn't reveal the attacked portion whereas the remaining portion of the secrets gets reconstructed correctly. This confirms that an attack has been performed on the share(s) during transmission. The quantitative analysis of the proposed scheme is performed using Jaccard coefficient, correlation, RMSE, PSNR, MAE, NPCR, UACI, Information Entropy, and EQ parameters whereas the qualitative analysis has been performed using histogram analysis. The experimental results shows that the proposed scheme performs better on different dimension secret images.
C1 [Rawat, Arjun Singh; Deshmukh, Maroti; Singh, Maheep] Natl Inst Technol, Srinagar, Uttaranchal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Deshmukh, M (corresponding author), Natl Inst Technol, Srinagar, Uttaranchal, India.
EM arjunsinghrawat005@gmail.com; marotideshmukh@nituk.ac.in;
   maheepsingh@nituk.ac.in
RI Rawat, Arjun Singh/JBI-8902-2023
OI Rawat, Arjun Singh/0000-0002-5556-5071
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Agarwal Ayushi, 2021, International Journal of Information Technology, V13, P609, DOI 10.1007/s41870-020-00607-5
   Agarwal A, 2020, MULTIMED TOOLS APPL, V79, P24685, DOI 10.1007/s11042-020-09169-x
   Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Binu VP, 2017, WIRELESS PERS COMMUN, V92, P1531, DOI 10.1007/s11277-016-3619-8
   Bisht K, 2021, J SUPERCOMPUT, V77, P12157, DOI 10.1007/s11227-021-03747-y
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   del Rey AM, 2005, APPL MATH COMPUT, V170, P1356, DOI 10.1016/j.amc.2005.01.026
   Deshmukh M, 2019, KNOWL INF SYST, V60, P1377, DOI 10.1007/s10115-018-1268-9
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Deshmukh M, 2017, J VIS COMMUN IMAGE R, V49, P291, DOI 10.1016/j.jvcir.2017.09.013
   Deshmukh M, 2017, ADV INTELL SYST, V459, P149, DOI 10.1007/978-981-10-2104-6_14
   Deshmukh M, 2016, LECT NOTES COMPUT SC, V10063, P212, DOI 10.1007/978-3-319-49806-5_11
   Deshmukh M, 2016, INT CON ADV INFO NET, P690, DOI 10.1109/AINA.2016.56
   Dharani P., 2015, 2015 IEEE 9th International Conference on Intelligent Systems and Control (ISCO), P1, DOI 10.1109/ISCO.2015.7282378
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Forouzan BA., 2015, Cryptography and network security
   Gayathri J, 2018, MULTIMED TOOLS APPL, V77, P24751, DOI 10.1007/s11042-018-5675-4
   Gupta M, 2020, MULTIMED TOOLS APPL, V79, P12183, DOI 10.1007/s11042-019-08454-8
   He Q, 2019, CMC-COMPUT MATER CON, V58, P349, DOI 10.32604/cmc.2019.03703
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Khorasgani HA, 2014, INT ISC CONF INFO SE, P173, DOI 10.1109/ISCISC.2014.6994043
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu ZJ, 2008, OPT COMMUN, V281, P5322, DOI 10.1016/j.optcom.2008.07.048
   Pang LJ, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P22, DOI 10.1109/ISECS.2008.60
   Pilaram H, 2017, SCI IRAN, V24, P1448, DOI 10.24200/sci.2017.4126
   Pilaram H, 2017, IEEE T DEPEND SECURE, V14, P2, DOI 10.1109/TDSC.2015.2432800
   Rajput M, 2016, PROCEDIA COMPUT SCI, V89, P677, DOI 10.1016/j.procs.2016.06.034
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shankar K., 2017, INT J PURE APPL MATH, V116, P293
   Sheikhi-Garjan M, 2019, IET INFORM SECUR, V13, P278, DOI 10.1049/iet-ifs.2018.5174
   Teodoro AAM, 2022, WIRELESS PERS COMMUN, V127, P1085, DOI 10.1007/s11277-021-08566-1
   Ulutas M, 2011, J SYST SOFTWARE, V84, P341, DOI 10.1016/j.jss.2010.11.928
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Yan XH, 2018, DIGIT SIGNAL PROCESS, V82, P80, DOI 10.1016/j.dsp.2018.07.015
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
NR 56
TC 3
Z9 3
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35183
EP 35219
DI 10.1007/s11042-023-14609-5
EA MAR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000947594500004
DA 2024-07-18
ER

PT J
AU Ding, TH
   Feng, KL
   Yan, YJ
   Wei, YJ
   Li, TP
AF Ding, Tonghe
   Feng, Kaili
   Yan, Yejin
   Wei, Yanjun
   Li, Tianping
TI An improved anchor-free method for traffic scene object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic scene; Object detection; Anchor-free; Convolutional neural
   network
AB Due to the low detection accuracy of most anchor-free detectors and the slow detection speed of anchor-based detectors. Therefore, to balance the detection accuracy and speed of traffic scene objects, a new anchor-free detector called FABNet is proposed in this paper. The method is mainly composed of feature pyramid fusion module (FPFM), cascade attention module (CAM), and boundary feature extraction module (BFEM). Firstly, we design a feature pyramid fusion module to generate richer semantic information. The proposal of the feature pyramid fusion module not only improves the detection accuracy of objects, but also solves the problem of detection of objects of different sizes. Secondly, the cascade attention module achieves the local representation of features by exploiting hierarchical attention, spatial attention and channel attention. The proposal of cascade attention module improves the representation ability of object detection head. Finally, to obtain more foreground information under the influence of complex background, we design a boundary feature extraction module to extract the boundary features of the object effectively. We perform sufficient experiments on three public datasets, i.e., BDD100K, PASCAL VOC, and KITTI. The results show that our method achieves state-of-the-art levels in both accuracy and speed.
C1 [Ding, Tonghe; Feng, Kaili; Yan, Yejin; Wei, Yanjun; Li, Tianping] Shandong Normal Univ, Sch Phys & Elect Sci, Jinan 250399, Peoples R China.
C3 Shandong Normal University
RP Li, TP (corresponding author), Shandong Normal Univ, Sch Phys & Elect Sci, Jinan 250399, Peoples R China.
EM dth17852115378@163.com; fengkaili0210@163.com; 1070060517@qq.com;
   2367041802@qq.com; sdsdltp@sdnu.edu.cn
RI yan, yejin/GXA-1986-2022
FU NSFC [61572286, 61472220]; Zhejiang Integration of Informatization
   [U1609218]; Fostering Project of Dominant Discipline a Talent Team of
   Shandong Province Higher Education; NSFC
FX This work was supported in part by NSFC (61572286 and 61472220), NSFC
   Joint with Zhejiang Integration of Informatization and Industrializaiton
   under Key Project (U1609218), and the Fostering Project of Dominant
   Discipline a Talent Team of Shandong Province Higher Education.
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao JX, 2020, Arxiv, DOI [arXiv:2005.11475, DOI 10.48550/ARXIV.2005.11475]
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen Y, 2020, arXiv, DOI 10.48550/arXiv.2007.08508
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3149780
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Dai JF, 2016, ADV NEUR IN, V29
   Fan SQ, 2021, IEEE T VEH TECHNOL, V70, P121, DOI 10.1109/TVT.2021.3049805
   Fu C.-Y., 2017, arXiv
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han Qiu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P549, DOI 10.1007/978-3-030-58452-8_32
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Lan S, 2020, P IEEE CVF C COMP VI, P10394, DOI [10.1109/CVPR42600.2020.01041, DOI 10.1109/CVPR42600.2020.01041]
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samet Nermin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P406, DOI 10.1007/978-3-030-58595-2_25
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang XG, 2017, Arxiv, DOI [arXiv:1706.03646, DOI 10.48550/ARXIV.1706.03646]
   Wei J, 2020, IEEE T INTELL TRANSP, V21, P1572, DOI 10.1109/TITS.2019.2910643
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Yang DM, 2019, NEUROCOMPUTING, V367, P20, DOI 10.1016/j.neucom.2019.08.016
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yu FS, 2020, Arxiv, DOI arXiv:1805.04687
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhou X., 2019, Objects as Points, V1904, P07850, DOI [10.48550/arXiv.1904.07850, DOI 10.48550/ARXIV.1904.07850]
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
NR 59
TC 0
Z9 0
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34703
EP 34724
DI 10.1007/s11042-023-15077-7
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946890000001
DA 2024-07-18
ER

PT J
AU Moon, SK
AF Moon, Sunil K.
TI Forensic multi-dimensional Ary exploited modified direction data
   embedding approach to increase imperceptibility and robustness of
   secured data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data security; Audio-video steganography; Forensics authentication;
   DFDAEMD
ID STEGANOGRAPHY; EMD
AB In 2006 X. Zhang and S, Wang suggested efficient steganographic embedding by Exploiting Modification Direction (EMD) where each important secrecy bit is converted to (2n + 1) -ary notational system which produces by n pixel values where 1 pixel is increased or decreased. To date, many researchers have implemented EMD algorithms that are less secure and produce less embedding capacity and imperceptibility. So, to reduce these limitations a combination of audio-video crypto-steganography using the Digital Forensic Detection Array EMD (DFDAEMD) algorithm is used. It uses (3m(2) + 4 m + 2) ary notation to embed three pixels at a time for enhancing the embedding capacity and security of secret data. The observed and verified software results confirm that the implemented security model provides better Authentication, Imperceptibility, Robustness, Embedding Capacity (EC), Embedding Rate (ER), and very good recovery of both secret and original data as compared to any existing EMD methods.
C1 [Moon, Sunil K.] SCTRs Pune Inst Comp Technol PICT, Dept Elect & Telecommun, Pune, India.
RP Moon, SK (corresponding author), SCTRs Pune Inst Comp Technol PICT, Dept Elect & Telecommun, Pune, India.
EM msunil2k@rediffmail.com
OI moon, sunil/0000-0002-8828-6300
CR Arab F, 2016, SPRINGER J MULTIMEDI, DOI [10.1007/s11042-015-2800-5, DOI 10.1007/S11042-015-2800-5]
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P512, DOI 10.1109/IIH-MSP.2014.133
   Dalal M, 2021, MULTIMED TOOLS APPL, V80, P5723, DOI 10.1007/s11042-020-09929-9
   Hajizadeh H, 2013, IRAN CONF ELECTR ENG
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Kartik JV., 2013, INT J LATEST TRENDS, V3, P97
   Kasana G, 2017, J INF PROCESS SYST, V13, P1331, DOI 10.3745/JIPS.03.0042
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Kuo WC, 2017, MULTIMED TOOLS APPL, V76, P1901, DOI 10.1007/s11042-015-3165-5
   Kuo WC, 2012, THIRD INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND INTELLIGENT CONTROL (ISIC 2012), P286, DOI 10.1109/ISIC.2012.6449762
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Leng HS, 2019, MULTIMED TOOLS APPL, V78, P18363, DOI 10.1007/s11042-019-7228-x
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YJ, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P151, DOI 10.1145/3177404.3177452
   Liu YX, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2787803
   Moon Sunil K., 2018, International Journal of Information and Computer Security, V10, P374
   Moon SK, 2015, INT J ELECTRON SECUR, V7, P305
   Musto Ronald., 2017, INTRO NAPLES MYTH HI, P1, DOI DOI 10.1109/LISAT.2017.8001965
   Niu XJ, 2015, INT J SECUR APPL, V9, P243, DOI 10.14257/ijsia.2015.9.5.24
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Saha S, 2018, ELECTRON LETT, DOI [10.1049/el.2017.3336,2018, DOI 10.1049/EL.2017.3336,2018]
   Saha S, 2020, MULTIMED TOOLS APPL, V79, P20973, DOI 10.1007/s11042-020-08951-1
   Sairam TD, 2020, MULTIMED TOOLS APPL, V79, P17003, DOI 10.1007/s11042-019-7557-9
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Younus ZS, 2022, J KING SAUD UNIV-COM, V34, P2951, DOI 10.1016/j.jksuci.2019.04.008
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35091
EP 35120
DI 10.1007/s11042-023-14500-3
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946494700007
DA 2024-07-18
ER

PT J
AU Yang, J
   Jeong, J
   Jamzuri, ER
   Baltes, J
AF Yang, Jeehyun
   Jeong, Jaesik
   Jamzuri, Eko Rudiawan
   Baltes, Jacky
TI Humanoid robot magic show performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robot magic show; Intelligent robot; Multimedia entertainment system
AB Recent advances in humanoid robotics have opened up many new directions for humanoid robotics research. Multimedia and arts are applications with significant growth opportunities. In this paper, we introduce magic shows as a benchmark and research problem for humanoid robots and discuss our flexible and versatile system architecture. The goal is to have a humanoid robot perform as a magician in front of an audience. Note that we focus on magic performances that require complex manipulation and interaction of the robot instead of tricks where the robot is passive and used mainly as a prop. So in our tricks, the magic is critically dependent on the skills of the humanoid robot. Furthermore, a successful magic show requires that the robot interacts meaningfully and goal directed with the audience. We describe the technical details of a pen and drawing magic trick, the human-robot collaboration, hardware architecture, and software architecture of our system. One interesting aspect of our system is the inclusion of various personalities for the robot magician. Overall, the robot performed the magic tricks well in the competition and won third place at the IEEE IROS Humanoid Application Challenge(HAC) 2019 in Macau.
C1 [Yang, Jeehyun; Jeong, Jaesik; Baltes, Jacky] Natl Taiwan Normal Univ, Dept Elect Engn, Heping East Rd, Taipei 10610, Taiwan.
   [Jamzuri, Eko Rudiawan] Politekn Negeri Batam, Dept Elect Engn, Batam 29461, Indonesia.
C3 National Taiwan Normal University
RP Jeong, J (corresponding author), Natl Taiwan Normal Univ, Dept Elect Engn, Heping East Rd, Taipei 10610, Taiwan.
EM zstt.jh@gmail.com; jslvjh@gmail.com; eko.rudiawan@gmail.com;
   jacky.baltes@ntnu.edu.tw
RI Jamzuri, Eko Rudiawan/AIE-3435-2022
OI Jamzuri, Eko Rudiawan/0000-0001-5142-7205; Jeong,
   Jaesik/0000-0003-2601-9132
FU "Chinese Language and Technology Center" of National Taiwan Normal
   University (NTNU) from The Featured Areas Research Center Program within
   the framework of the Higher Education Sprout Project by the Ministry of
   Education (MOE) in Taiwan; "Chinese Language and Technology Center" of
   National Taiwan Normal University (NTNU) from The Featured Areas
   Research Center Program [MOST 111-2918-I-003-003-, MOST
   110-2923-E-003-001-MY3, MOST 110-2221-E-003-023]
FX This work was financially supported by the "Chinese Language and
   Technology Center" of National Taiwan Normal University (NTNU) from The
   Featured Areas Research Center Program within the framework of the
   Higher Education Sprout Project by the Ministry of Education (MOE) in
   Taiwan, and Ministry of Science and Technology, Taiwan, under Grants no.
   MOST 111-2918-I-003-003-, MOST 110-2923-E-003-001-MY3, and MOST
   110-2221-E-003-023. We are grateful to the National Center for
   High-performance Computing for computer time and facilities to conduct
   this research.
CR Baltes J, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P1101, DOI 10.1109/IROS.2000.893166
   Baltes J, 2014, ROBOT SOCCER WORLD C, P649
   Baltes J, 2019, IEEE IROS 2019 HUMAN
   Baltes J, 2018, IEEE ROBOT AUTOM MAG, V25, P8, DOI 10.1109/MRA.2018.2822045
   Baltes J, 2016, KNOWL ENG REV, V32, DOI 10.1017/S0269888916000114
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Causer C, 2019, IEEE POTENTIALS, V38, P10, DOI 10.1109/MPOT.2019.2919851
   Cobb-Clark DA, 2012, ECON LETT, V115, P11, DOI 10.1016/j.econlet.2011.11.015
   Gerndt R, 2015, IEEE ROBOT AUTOM MAG, V22, P147, DOI 10.1109/MRA.2015.2448811
   GOLDBERG LR, 1993, AM PSYCHOL, V48, P26, DOI 10.1037/0003-066X.48.1.26
   Huggins-Daines D, 2006, INT CONF ACOUST SPEE, P185
   Iverach-Brereton Chris, 2012, Advances in Autonomous Robotics. Joint Proceedings of the 13th Annual TAROS Conference and the 15th Annual FIRA RoboWorld Congress, P209, DOI 10.1007/978-3-642-32527-4_19
   Iverach-Brereton C, 2014, ROBOT AUTON SYST, V62, P306, DOI 10.1016/j.robot.2013.09.016
   Jeong J, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100456
   Jeong J, 2020, KNOWL ENG REV, V35, DOI 10.1017/S0269888920000211
   Juang LH, 2022, MULTIMED TOOLS APPL, V81, P1545, DOI 10.1007/s11042-021-11636-y
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kirtane L, 2004, AIBOS MAGIC LOOKING
   Koretake R, 2014, IEEE ASME INT C ADV, P1249, DOI 10.1109/AIM.2014.6878253
   Lin C.-Y., 2009, IEEE International Conference on Advanced Robotics, P1
   Moon H, 2017, IEEE ROBOT AUTOM MAG, V24, P20, DOI 10.1109/MRA.2016.2646090
   Morris KJ, 2019, APPL INTELL, V49, P3834, DOI 10.1007/s10489-019-01565-7
   Morris KJ, 2018, LECT NOTES ARTIF INT, V10868, P245, DOI 10.1007/978-3-319-92058-0_23
   Paetzel M, 2019, IEEE ROBOT AUTOM MAG, V26, P14, DOI 10.1109/MRA.2019.2945738
   Pasquali D, 2021, 2021 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI, P293, DOI 10.1145/3434073.3444682
   PYTTSX3, US
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Rosner D, 2014, COMMUN ACM, V57, P82, DOI 10.1145/2602695.2602701
   Shangari TA, 2015, ADV INTELL SYST, V345, P483, DOI 10.1007/978-3-319-16841-8_44
   Singh G, 2022, MATER TODAY-PROC, V60, P1779, DOI 10.1016/j.matpr.2021.12.426
   Suzuki S, 1997, RO-MAN '97 SENDAI: 6TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P28, DOI 10.1109/ROMAN.1997.646948
   Tebbe Jonas, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P33, DOI 10.1007/978-3-030-12939-2_3
   Tu KY, 2020, KNOWL ENG REV, V35, DOI 10.1017/S026988892000003X
   Williams H, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01283
NR 34
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34609
EP 34630
DI 10.1007/s11042-023-14690-w
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700001
DA 2024-07-18
ER

PT J
AU Chao, Z
   Xu, WT
   Liu, RG
   Cho, HYS
   Jia, FC
AF Chao, Zhen
   Xu, Wenting
   Liu, Ruiguo
   Cho, Hyosung
   Jia, Fucang
TI Surgical action detection based on path aggregation adaptive spatial
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surgical action detection; Feature pyramid; Feature fusion; Spatial
   adaptive
AB Surgeon action detection plays a crucial role in computer-assisted surgery. However, due to the problems of non-rigid instrument deformation, occlusion, and less available contextual information in the surgeon action detection, these factors lead to the problem that the average accuracy of the current detection of surgical motion is very low, which needs to be solved urgently. Therefore, inspired by the application of convolutional neural networks (CNNs) can express features through learning and success in medical image detection tasks, we developed a path aggregation adaptive spatial feature pyramid network (PAAS-FPN), which combines bottom-up path enhancement and an adaptive spatial fusion mechanism. Path enhancement can use the shallow feature information of images for upward transmission. The adaptive spatial feature fusion network adds spatial granularity between deep and shallow features. In this study, the improved method was experimentally verified on the ESAD dataset and surgeon instrument detection dataset. The proposed detection method achieved the highest detection accuracy in several experiments, thereby confirming its effectiveness in surgeon action detection.
C1 [Chao, Zhen; Xu, Wenting; Jia, Fucang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Chao, Zhen] Shandong First Med Univ & Shandong Acad Med Sci, Coll Artificial Intelligence & Big Data Med Sci, 6699 Qingdao Rd, Jinan 250117, Shandong, Peoples R China.
   [Xu, Wenting; Liu, Ruiguo] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
   [Cho, Hyosung] Yonsei Univ, Coll Hlth Sci, Dept Radiat Convergence Engn, 1 Yonseidae gil, Wonju 26493, Gangwon, South Korea.
   [Jia, Fucang] Pazhou Lab, Guangzhou 510330, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Shandong First Medical University & Shandong Academy of Medical
   Sciences; Shandong University of Science & Technology; Yonsei
   University; Pazhou Lab
RP Jia, FC (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.; Cho, HYS (corresponding author), Yonsei Univ, Coll Hlth Sci, Dept Radiat Convergence Engn, 1 Yonseidae gil, Wonju 26493, Gangwon, South Korea.; Jia, FC (corresponding author), Pazhou Lab, Guangzhou 510330, Peoples R China.
EM hscho1@yonsei.ac.kr; fc.jia@siat.ac.cn
RI Jia, Fucang/J-3056-2016
OI Jia, Fucang/0000-0003-0075-979X
FU Key-Area Research and Development Program of Guangdong Province
   [2020B010165004]; National Natural Science Foundation of China
   [82001905, 62172401, 12026602]; Guangdong Natural Science Foundation
   [2022A1515010439, 2022A0505020019]; Shenzhen Key Basic Science Program
   [JCYJ2022081801802005]; National Key RD Program [2019YFC0118100]; Zhuhai
   Science and Technology Program [ZH22017002210017PWC]; Shenzhen Key
   Laboratory Program [ZDSYS201707271637577]; Academic Promotion Project of
   Shandong First Medical University
FX This work was supported by grants from the Key-Area Research and
   Development Program of Guangdong Province (No. 2020B010165004), the
   National Natural Science Foundation of China (Nos. 82001905, 62172401,
   and 12026602), the Guangdong Natural Science Foundation (Nos.
   2022A1515010439 and 2022A0505020019), the Shenzhen Key Basic Science
   Program (No. JCYJ2022081801802005), the National Key R&D Program (No.
   2019YFC0118100), the Zhuhai Science and Technology Program (No.
   ZH22017002210017PWC), the Shenzhen Key Laboratory Program (No.
   ZDSYS201707271637577) and Academic Promotion Project of Shandong First
   Medical University.
CR Azari DP, 2019, HUM FACTORS, V61, P1326, DOI 10.1177/0018720819838901
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cuzzolin, 2020, ARXIV
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Grammatikopoulou M, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102053
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hou R, 2017, ARXIV
   Jiaqi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P403, DOI 10.1007/978-3-030-58548-8_24
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Kim K., 2020, ARXIV
   Kocev B, 2014, INT J COMPUT ASS RAD, V9, P301, DOI 10.1007/s11548-013-0928-1
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Li Y., 2016, IIEEJ T IMAGE ELECT, V4, P124
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu S, 2019, ARXIV
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Najibi M, 2016, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2016.260
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Qiao S., 2019, ARXIV
   Qiao S., 2020, ARXIV
   Radosavovic Ilija, 2020, P IEEE CVF C COMP VI, P10428
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saha S, 2017, IEEE I CONF COMP VIS, P4424, DOI 10.1109/ICCV.2017.473
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   van Amsterdam B, 2019, IEEE INT CONF ROBOT, P9565, DOI [10.1109/ICRA.2019.8793696, 10.1109/icra.2019.8793696]
   Voros S, 2008, P IEEE RAS-EMBS INT, P562, DOI 10.1109/BIOROB.2008.4762915
   Xu WT, 2021, 2021 IEEE 13TH INTERNATIONAL CONFERENCE ON COMPUTER RESEARCH AND DEVELOPMENT (ICCRD 2021), P11, DOI 10.1109/ICCRD51685.2021.9386349
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XS, 2022, IEEE T PATTERN ANAL, V44, P3096, DOI 10.1109/TPAMI.2021.3050494
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 55
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26971
EP 26986
DI 10.1007/s11042-023-14990-1
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000945792800002
DA 2024-07-18
ER

PT J
AU Yengikand, AK
   Meghdadi, M
   Ahmadian, S
AF Yengikand, Amir Khani
   Meghdadi, Majid
   Ahmadian, Sajad
TI DHSIRS: a novel deep hybrid side information-based recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Deep neural networks; Data sparsity; Dot-product;
   Side information; Latent feature representation
ID MODEL
AB Latent factor-based methods have been extensively employed in recommender systems to project users and items to the same feature space and use the dot product for predicting unknown ratings. Nevertheless, the dot product method cannot describe the various influences of latent features. Also, it only captures the linear relations between users and items leading to a negative impact on the efficiency of recommender systems. Deep learning models are known as state-of-the-art techniques to deal with the non-linear relation between user and item. In this paper, we develop a new deep hybrid recommender system called DHSIRS using multilayer perceptron neural network to combine side information and interaction matrix for item recommendation. Specifically, two feature learning components are developed to extract side information-based and interaction-based latent features. Therefore, two paralleled deep neural networks are utilized in the side information-based feature learning part to obtain the feature vector for users and items from side information. Moreover, the interaction-based feature learning part obtains the latent features from the user-item matrix. Finally, we introduce a deep learning model instead of the dot product method to predict unknown ratings by integrating the side information-based and interaction-based latent features. Unlike other methods that use the dot product, our method is able to efficiently learn the high-order non-linear relations between users and items. Extensive experiments on three publicly available datasets demonstrate that DHSIRS averagely improves the recommendation performance by around 4.18% in comparison to the second-best model over different evaluation metrics.
C1 [Yengikand, Amir Khani; Meghdadi, Majid] Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
   [Ahmadian, Sajad] Kermanshah Univ Technol, Fac Informat Technol, Kermanshah, Iran.
C3 University Zanjan; Kermanshah University of Technology
RP Meghdadi, M (corresponding author), Univ Zanjan, Dept Comp Engn, Zanjan, Iran.
EM amirkhani@znu.ac.ir; meghdadi@znu.ac.ir; s.ahmadian@kut.ac.ir
CR Ahmadian M, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116697
   Ahmadian M, 2021, IEEE SYS MAN CYBERN, P2524, DOI 10.1109/SMC52423.2021.9658926
   Ahmadian S, 2022, NEUROCOMPUTING, V488, P557, DOI 10.1016/j.neucom.2021.11.064
   Ahmadian S, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115849
   Ahmadian S, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105371
   Ahmadian S, 2019, J INF SCI, V45, P607, DOI 10.1177/0165551518808191
   Ahmadian S, 2019, MULTIMED TOOLS APPL, V78, P17763, DOI 10.1007/s11042-018-7079-x
   Ahmadian S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1139, DOI 10.1109/ASONAM.2018.8508723
   Ahmadian S, 2018, APPL INTELL, V48, P4448, DOI 10.1007/s10489-018-1219-x
   Ahmadian S, 2018, INFORM PROCESS MANAG, V54, P707, DOI 10.1016/j.ipm.2017.03.002
   Ahmadian S, 2014, 2014 6TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P98, DOI 10.1109/IKT.2014.7030341
   Ahmed A, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114757
   Batmaz Z, 2019, ARTIF INTELL REV, V52, P1, DOI 10.1007/s10462-018-9654-y
   Behera G, 2022, J KING SAUD UNIV-COM
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Chen H, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115539
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Deng ZH, 2019, AAAI CONF ARTIF INTE, P61
   Dong X, 2017, AAAI CONF ARTIF INTE, P1309
   Gomede E., 2021, Comput. Educ. Artif. Intell, V2, P100009, DOI [10.1016/j.caeai.2021.100009, DOI 10.1016/J.CAEAI.2021.100009]
   Han HR, 2018, INFORMATION, V9, DOI 10.3390/info9060143
   Han JY, 2019, INFORM SCIENCES, V503, P521, DOI 10.1016/j.ins.2019.07.024
   Hancock JT, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00305-w
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   He XN, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P549, DOI 10.1145/2911451.2911489
   Jalili M, 2018, IEEE ACCESS, V6, P74003, DOI 10.1109/ACCESS.2018.2883742
   Kim D, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P233, DOI 10.1145/2959100.2959165
   Kingma D. P., 2014, arXiv
   Kiran R, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113054
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li XP, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P305, DOI 10.1145/3097983.3098077
   Liu DH, 2021, KNOWL INF SYST, V63, P621, DOI 10.1007/s10115-020-01528-2
   Liu HT, 2020, NEUROCOMPUTING, V374, P77, DOI 10.1016/j.neucom.2019.09.052
   Liu Y, 2018, BIG DATA MIN ANAL, V1, P211, DOI 10.26599/BDMA.2018.9020019
   Moradi P, 2016, INT CONF ADV ICT, P162, DOI 10.1109/ICTER.2016.7829914
   Moradi P, 2015, EXPERT SYST APPL, V42, P7386, DOI 10.1016/j.eswa.2015.05.027
   Moradi P, 2015, PHYSICA A, V436, P462, DOI 10.1016/j.physa.2015.05.008
   Nagarajan R, 2020, ARAB J SCI ENG, V45, P2929, DOI 10.1007/s13369-019-04218-6
   Rezaeimehr F, 2018, FUTURE GENER COMP SY, V78, P419, DOI 10.1016/j.future.2017.04.003
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Strub F., 2015, NIPS WORKSH MACH LEA, P1
   Tahmasebi F, 2021, MULTIMED TOOLS APPL, V80, P2339, DOI 10.1007/s11042-020-09768-8
   Vedavathi N, 2021, SOFT COMPUT, V25, P9377, DOI 10.1007/s00500-021-05753-x
   Wang Chong, 2011, P 17 ACM SIGKDD INT, P448, DOI [DOI 10.1145/2020408.2020480, 10.1145/2020408.2020480]
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang J, 2019, LECT NOTES COMPUT SC, V11730, P172, DOI 10.1007/978-3-030-30490-4_15
   Wang SY, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107753
   Weite Feng, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12572), P328, DOI 10.1007/978-3-030-67832-6_27
   Wen XL, 2021, SOFT COMPUT, V25, P3087, DOI 10.1007/s00500-020-05364-y
   Wu L, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P679, DOI 10.1145/3397271.3401144
   Yang C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1245, DOI 10.1145/3097983.3098094
   Yengikand AK, 2021, IEEE SYS MAN CYBERN, P2485, DOI 10.1109/SMC52423.2021.9658978
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zhang LB, 2018, IEEE ACCESS, V6, P9454, DOI 10.1109/ACCESS.2018.2789866
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang Wei, 2016, IJCAI
   Zhang YF, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1449, DOI 10.1145/3132847.3132892
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 59
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34513
EP 34539
DI 10.1007/s11042-023-15021-9
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000005
DA 2024-07-18
ER

PT J
AU Mohammed, AO
   Hussein, HI
   Mstafa, RJ
   Abdulazeez, AM
AF Mohammed, Abdulhakeem O.
   Hussein, Haval I.
   Mstafa, Ramadhan J.
   Abdulazeez, Adnan M.
TI A blind and robust color image watermarking scheme based on DCT and DWT
   domains
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Discrete cosine transform (DCT); Discrete wavelet
   transform (DWT); Chaotic logistic map
ID SVD; ALGORITHM; HYBRID
AB With the emergence of the Internet of Things (IoT) and many smart gadgets that support artificial intelligence, it is easier than ever to acquire, reproduce, and disseminate a large number of digital data. However, these great technologies have made it possible for intruders to easily violate issues related to copyright protection, identity theft, and privacy leakage. To address such issues, several approaches have been developed, among which image watermarking has been proven to be an ideal solution. In this paper, a blind watermarking approach for RGB color images based on joint Discrete Cosine Transform (DCT) and Discrete Wavelet Transform (DWT) is proposed. First, a self-adaptive color selecting strategy is used to select either the blue or green channel of the host image for embedding purpose. Subsequently, the selected color is subdivided into non-overlapping square blocks of size 4 x 4, and then DCT is applied to each block. Afterward, the DC values obtained from each block are decomposed into four sub-bands using DWT, and then the LH middle frequency sub-band is further decomposed into four sub-bands using DWT. Lastly, the LH1 obtained from LH is utilized for watermark embedding. To provide security to the proposed approach, the watermark image is encrypted before embedding using a chaotic sequence originated from a logistic map method. Experimental results reveal that the proposed approach not only enhances watermark invisibility but also provide excellent watermark robustness, meeting the main requirements of image watermarking.
C1 [Mohammed, Abdulhakeem O.; Abdulazeez, Adnan M.] Duhok Polytech Univ, Tech Coll Adm, Dept Informat Technol Management, Duhok 42001, Iraq.
   [Hussein, Haval I.; Mstafa, Ramadhan J.] Univ Zakho, Fac Sci, Dept Comp Sci, Zakho 42002, Iraq.
   [Mstafa, Ramadhan J.] Nawroz Univ, Coll Sci, Dept Comp Sci, Duhok 42001, Iraq.
C3 Duhok Polytechnical University; University of Zakho; Nawroz University
RP Mstafa, RJ (corresponding author), Univ Zakho, Fac Sci, Dept Comp Sci, Zakho 42002, Iraq.; Mstafa, RJ (corresponding author), Nawroz Univ, Coll Sci, Dept Comp Sci, Duhok 42001, Iraq.
EM ramadhan.mstafa@uoz.edu.krd
RI Mstafa, Ramadhan J./G-4533-2015; Abdulazeez, Adnan Mohsin/AFP-7769-2022
OI Mstafa, Ramadhan J./0000-0002-6122-234X; Abdulazeez, Adnan
   Mohsin/0000-0002-4357-7331
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Akter M.T., 2018, International Journal of Applied Mathematics and Theoretical Physics, vol, V4, DOI DOI 10.11648/J.IJAMTP.20180403.14
   Alshoura WH, 2020, IEEE ACCESS, V8, P43391, DOI 10.1109/ACCESS.2020.2978186
   Alzaidi AA, 2018, IEEE ACCESS, V6, P55405, DOI 10.1109/ACCESS.2018.2871557
   Chopra J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P413, DOI 10.1109/SPIN.2018.8474269
   Giri KJ, 2020, MULTIMED TOOLS APPL, V79, P32881, DOI 10.1007/s11042-020-09716-6
   Guo Y, 2017, IET IMAGE PROCESS, V11, P406, DOI 10.1049/iet-ipr.2016.0515
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hsu LY, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113225
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Hussein HI, 2022, PROCEEDING OF THE 2ND 2022 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSASE 2022), P337, DOI 10.1109/CSASE51777.2022.9759643
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kishore RR., 2016, INT J COMPUT INF SCI, V10, P1264
   Koley S, 2019, J KING SAUD UNIV-COM
   Kumar S, 2021, MULTIMED TOOLS APPL, V80, P15487, DOI 10.1007/s11042-020-10322-9
   Maloo S, 2018, SMART INNOV SYST TEC, V83, P509, DOI 10.1007/978-3-319-63673-3_61
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Mstafa RJ, 2022, CMC-COMPUT MATER CON, V72, P3349, DOI 10.32604/cmc.2022.025791
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Pandey MK, 2019, MICROSYST TECHNOL, V25, P3071, DOI 10.1007/s00542-018-4162-1
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Prabha K, 2020, MULTIMED TOOLS APPL, V79, P6845, DOI 10.1007/s11042-019-08212-w
   Prabha K, 2021, SADHANA-ACAD P ENG S, P46
   Prabha K, 2020, J KING SAUD UNIV-COM
   Rajani D, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107556
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Soleymani SH, 2019, MULTIMED TOOLS APPL, V78, P19163, DOI 10.1007/s11042-019-7282-4
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Sunesh, 2020, PROCEDIA COMPUT SCI, V167, P1505, DOI 10.1016/j.procs.2020.03.361
   Thakral S, 2019, COMM COM INF SC, V955, P499, DOI 10.1007/978-981-13-3140-4_45
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zheng PJ, 2020, MULTIMED TOOLS APPL, V79, P18343, DOI 10.1007/s11042-019-08490-4
NR 47
TC 8
Z9 8
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32855
EP 32881
DI 10.1007/s11042-023-14797-0
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100017
DA 2024-07-18
ER

PT J
AU Su, H
   Wang, W
   Wang, SW
AF Su, Hang
   Wang, Wei
   Wang, Shanwen
TI A robust all-weather abandoned objects detection algorithm based on dual
   background and gradient operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Abandoned objects detection; Dual background model; Temporal median
   filtering; Temporal minimum filtering; Light interference elimination
ID MIXTURE
AB Abandoned objects detection is one of the most important tasks of intelligent visual surveillance systems. In this paper, a method, based on dual background and gradient is presented for abandoned objects detection. The temporal median filter and temporal minimum filter are used to extract foreground and static objects respectively. In order to enable our algorithm to detect precisely at night, a gradient-based image processing algorithm is proposed to eliminate the interference of vehicle lights. This method can detect abandoned objects in a short time. It is robust under various lighting conditions, and it has low computational costs compared to other widely used methods.This image processing algorithm can also be used in other tasks, such as obstacle detection in autonomous driving. We compare the algorithm with other abandoned object detection algorithms on the well-known ABODA dataset and our video dataset in highway scenes. Experimental results demonstrate that the method we proposed outperforms the widely used abandoned objects detection methods.
C1 [Su, Hang; Wang, Wei; Wang, Shanwen] Renmin Univ China, Sch Math, Beijing 100872, Peoples R China.
C3 Renmin University of China
RP Su, H (corresponding author), Renmin Univ China, Sch Math, Beijing 100872, Peoples R China.
EM hangs@ruc.edu.cn; wwei@ruc.edu.cn
OI Su, Hang/0000-0003-1135-4915
FU Tianjin Yunhong Technology Development Co., Ltd.
FX Hang Su, Wei Wang and Shanwen Wang have received funding from Tianjin
   Yunhong Technology Development Co., Ltd. We have received experimental
   data from Beijing Jianhe Bafang Technology Development Co., Ltd.
CR Bird N, 2006, IEEE INT CONF ROBOT, P3775, DOI 10.1109/ROBOT.2006.1642279
   Chiu WY, 2013, IMAGING SCI J, V61, P252, DOI 10.1179/1743131X11Y.0000000016
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   EVANGELIO HERAS., 2011, Applications of Computer Vision (WACV), 2011 IEEE Workshop on, P534, DOI DOI 10.1109/WACV.2011.5711550
   Ferariu L, 2020, INT CONF SYST THEO, P367, DOI [10.1109/ICSTCC50638.2020.9259640, 10.1109/icstcc50638.2020.9259640]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Godbehere AB, 2012, P AMER CONTR CONF, P4305
   Guo LL, 2016, IEEE COMPUT SOC CONF, P1159, DOI 10.1109/CVPRW.2016.148
   Huei-Hung Liao, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P132, DOI 10.1109/AVSS.2008.9
   Huiyuan Fu, 2011, Proceedings 2011 6th International Conference on Pervasive Computing and Applications (ICPCA 2011), P117, DOI 10.1109/ICPCA.2011.6106489
   Jiyan Pan, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3597, DOI 10.1109/ICIP.2011.6116495
   Lan JH, 2016, J INTELL TRANSPORT S, V20, P401, DOI 10.1080/15472450.2015.1082910
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lin K, 2015, IEEE T INF FOREN SEC, V10, P1359, DOI 10.1109/TIFS.2015.2408263
   Luna E, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124290
   Lv F., 2006, 9 IEEE INT WORKSHOP, P83
   Mishra P, 2020, IEEE C ID 37465 INT
   Park H, 2020, IEEE ACCESS, V8, P80010, DOI 10.1109/ACCESS.2020.2990618
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Yan JP, 2016, CHINESE J GEOPHYS-CH, V59, P4759, DOI 10.6038/cjg20161234
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 25
TC 0
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29477
EP 29499
DI 10.1007/s11042-023-14632-6
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000939565700001
DA 2024-07-18
ER

PT J
AU Zhang, XX
   Li, YY
   Pei, HN
   Ding, M
AF Zhang, Xinxin
   Li, Yueying
   Pei, Huining
   Ding, Man
TI Research on chaos of product color image system driven by brand image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE chaos; Kansei engineering; Brand image; Product color image system;
   Perceptual cognitive processes
ID PERCEPTION; KNOWLEDGE; DESIGN; EMOTION
AB Chaos means innovation in the field of design. Meanwhile, the product image system is not only a quantified 'formula' between product and psychological cognitive semantics, but also a nonlinear "system". Therefore, the chaotic study of product color image system was carried out to grasp the users' color sensibility demands in their complex and nonlinear perceptual cognitive processes accurately, which could help the developers to keep up with market trends and reduce the blindness of design. In this study, the Chaos Theory combine with the Kansei Engineering were applied to obtain the color brand image, collect the time series and analyze the chaos of product color image system. The results showed that product color image system has a chaotic characteristic. Furthermore, the chaotic phenomenon in the color image system of the available products was analyzed to show that the product color trends could be quantitatively predicted. At last, a product color image perception chaotic box was proposed to conceive based on the result of this study, which provides new ideas and theoretical support for the in-depth exploration of complex systems of color images. This is a new attempt to apply the Chaos Theory to the color image cognition process.
C1 [Zhang, Xinxin; Li, Yueying; Pei, Huining; Ding, Man] Hebei Univ Technol, Sch Architecture & Art Design, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology
RP Ding, M (corresponding author), Hebei Univ Technol, Sch Architecture & Art Design, Tianjin 300401, Peoples R China.
EM zhangxinxin@hebut.edu.cn; liyueying210@foxmail.com;
   peihuining@hebut.edu.cn; dingman@hebut.edu.cn
OI Zhang, Xinxin/0000-0002-3037-0657
FU 2020 Tianjin University Co-construction Funds [282020373]; Science and
   Technology Research Projects of Higher Education Institutions in Hebei
   Province [QN2022138]; National Natural Science Foundation of China
   [52275243]
FX This research was supported financially by the 2020 Tianjin University
   Co-construction Funds (282020373), the Science and Technology Research
   Projects of Higher Education Institutions in Hebei Province (QN2022138)
   and the National Natural Science Foundation of China (52275243).
CR Alves AL, 2022, INT J IND ERGONOM, V90, DOI 10.1016/j.ergon.2022.103314
   [Anonymous], 1952, Opticks: Or A Treatise of the Reflections, Refractions, Inflections and Colors of Light
   [Anonymous], 1991, Turbulent Motion and the Structure of Chaos
   BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201
   Bittermann MS, 2018, COLOR RES APPL, V43, P527, DOI 10.1002/col.22216
   Brockwell P.J., 1991, SPRINGER SERIES STAT, V2nd
   Cash P, 2018, DESIGN STUD, V54, P50, DOI 10.1016/j.destud.2017.10.004
   Conway BR, 2012, ANN NY ACAD SCI, V1251, P77, DOI 10.1111/j.1749-6632.2012.06470.x
   DAHLGREN K, 1985, COGNITIVE SCI, V9, P379, DOI 10.1207/s15516709cog0903_4
   Ding M, COMPUT INTEGR MANUF, P1
   Ding M, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102198
   Ding M, 2021, J ADV MECH DES SYST, V15, DOI 10.1299/jamdsm.2021jamdsm0075
   Dingbang Y., 2012, DESIGN INTRO
   Earl L, 2017, COGN TECHNOL WORK, V19, P31, DOI 10.1007/s10111-016-0395-x
   Ferrer E., 2004, LENGUAJES COLOR, P49
   Fider N, 2017, J OPT SOC AM A, V34, P1285, DOI 10.1364/JOSAA.34.001285
   Fourie I, 2012, ONLINE INFORM REV, V36, P481, DOI 10.1108/14684521211241477
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   Gan Y, 2021, INT J IND ERGONOM, V83, DOI 10.1016/j.ergon.2021.103128
   GERO JS, 1990, AI MAG, V11, P26
   Greenfield Gary., 2005, COMPUTATIONAL AESTHE
   Hanada M, 2019, COLOR RES APPL, V44, P568, DOI 10.1002/col.22382
   Hanada M, 2018, COLOR RES APPL, V43, P224, DOI 10.1002/col.22171
   Holtzschue L., 2013, UNDERSTANDING COLOR
   HSIAO SW, 1995, COLOR RES APPL, V20, P191, DOI 10.1002/col.5080200309
   Hu GS, 2014, COLOR RES APPL, V39, P70, DOI 10.1002/col.21762
   Jian-Ning S., 2016, J MACHINE DESIGN, V33, P105, DOI DOI 10.13841/J.CNKI.JXSJ.(2016)
   Jiao HQ, 2013, APPL MECH MATER, V365-366, P47, DOI 10.4028/www.scientific.net/AMM.365-366.47
   Jordan F., 2004, Physics of Life Reviews, V1, DOI 10.1016/j.plrev.2004.08.001
   Juan L., 2014, CHANEL TELLS WOMEN E
   Kandela P., 2001, LANCET, V358, P677
   Khalaj J, 2019, DESIGN STUD, V62, P36, DOI 10.1016/j.destud.2019.02.002
   KUHLTHAU CC, 1991, J AM SOC INFORM SCI, V42, P361, DOI 10.1002/(SICI)1097-4571(199106)42:5<361::AID-ASI6>3.0.CO;2-#
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Kuo LW, 2022, DISPLAYS, V71, DOI 10.1016/j.displa.2021.102108
   Lin HH, 2019, COLOR RES APPL, V44, P194, DOI 10.1002/col.22342
   Linda H, 2013, UNDERSTANDING COLOR
   Mattingly A, 2011, P 8 C CREATIVITY COG
   Mei Z., 2007, ZHUANGSHI, V41, P41
   PACKARD NH, 1980, PHYS REV LETT, V45, P712, DOI 10.1103/PhysRevLett.45.712
   Poretski L, 2019, HUM-COMPUT INTERACT, V34, P240, DOI 10.1080/07370024.2017.1359604
   Qiu K, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091398
   Razza B, 2015, PROCEDIA MANUF, V3, P6228, DOI 10.1016/j.promfg.2015.07.750
   Renbin X., 1997, CHIN HIGH TECHNOL LE, V1, P22
   ROSENSTEIN MT, 1993, PHYSICA D, V65, P117, DOI 10.1016/0167-2789(93)90009-P
   [苏建宁 Su Jianning], 2017, [机械设计, Journal of Machine Design], V34, P112
   [孙志学 Sun Zhixue], 2015, [机械设计, Journal of Machine Design], V32, P120
   Tang Lin, 2010, Journal of Wuhan University of Technology, V32, P189, DOI 10.3963/j.issn.1671-4431.2010.19.044
   Tharangie KGD, 2011, INT J BIOMETRICS, V3, P285, DOI 10.1504/IJBM.2011.042813
   Wang WM, 2018, ENG APPL ARTIF INTEL, V73, P149, DOI 10.1016/j.engappai.2018.05.005
   Watanabe M, 2019, DESIGN STUD, V62, P100, DOI 10.1016/j.destud.2018.10.004
   Weipeng S., 2018, 2018 3 INT C MECH CO, V16, P35
   Xu Jiang, 2017, China Mechanical Engineering, V28, P596, DOI 10.3969/j.issn.1004-132X.2017.05.015
   [徐江 Xu Jiang], 2016, [机械设计, Journal of Machine Design], V33, P114
   Yan Zhou, 2014, Advanced Materials Research, V971-973, P1316, DOI 10.4028/www.scientific.net/AMR.971-973.1316
   [杨贤 Yang Xian], 2017, [心理科学, Journal of Psychological Science], V40, P1248
   Yin J., 2013, J. Hun. Univ. Sci. Technol. (Soc. Sci. Ed.), V16, P161
   Yu BY, 2016, DESIGN STUD, V45, P242, DOI 10.1016/j.destud.2016.04.005
   Yu W., 2012, ART ED RES, V21, P31
   Zhang Jian, 2011, 2011 6th IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC 2011), P172, DOI 10.1109/ITAIC.2011.6030303
   [张琳 Zhang Lin], 2014, [机械设计, Journal of Machine Design], V31, P108
   Zhang X, 2021, CELL MOL IMMUNOL, V18, P1751, DOI 10.1038/s41423-020-0363-5
   Zhang XQ, 2018, COMPUT IND ENG, V115, P80, DOI 10.1016/j.cie.2017.11.005
   Zhang XX, 2019, COLOR RES APPL, V44, P651, DOI 10.1002/col.22374
   Zhao WL, 2018, NEUROCOMPUTING, V291, P195, DOI 10.1016/j.neucom.2018.02.072
   Zhiwei J., 2011, J SOC ARCHIT HIST, V6, P58
NR 66
TC 3
Z9 3
U1 14
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24425
EP 24444
DI 10.1007/s11042-023-14549-0
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939565700002
DA 2024-07-18
ER

PT J
AU Pallavi, HV
   Chandra, APJ
   Paramesha
AF Pallavi, H. V.
   Chandra, A. P. Jagadeesh
   Paramesha
TI 5G wireless communication microstrip patch antenna array design with
   MIMO
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G wireless communication; Antenna; Microstrip patch antenna; Multi
   Input Multi output feeding technique; Gain; Return loss; VSWR; Mutual
   coupling
ID SLOT ANTENNA; WAVE
AB The development of the digital environment seeks the best and more efficient communication. Recent researchers are looking forward to 5G wireless communication. But this wireless communication requires a more efficient antenna design to achieve their aspects. Therefore, the proposed work is concentrating to design a high antenna for 5G wireless communication. In this work, the circular array microstrip patch antenna (MPA) design is proposed for the 5G wireless communication and the millimeter wave is utilized for this communication system to enhance the coverage area. Here, the Multi Input Multi Output feeding technique is utilized to enhance the performance of the proposed antenna design. The resonance frequency of the proposed antenna is taken as 35 GHz and RT-Duroid 5880 material is utilized for the substrate. It has a 2.2 dielectric constant value and the thickness is 0.5 mm. The simulation analysis is obtained the gain as 8.8 dB and return loss as -41.9 dB. Also, two MPA designs such as single element MPA and 2 x 2 rectangular array MPA are designed to validate the proposed antenna design. The designed microstrip patch antennas are compared by utilizing the parameters such as Gain, Return loss, VSWR, Mutual coupling, Bandwidth, and radiation efficiency. The comparative analysis proved that the proposed circular array MPA design is preferable for the 5G wireless communication system compared to the other two designs such as single element MPA and 2 x 2 rectangular array MPA.
C1 [Pallavi, H. V.] Govt Engn Coll, Dept Elect & Commun Engn, Hassan 573202, Karnataka, India.
   [Chandra, A. P. Jagadeesh] Adichunchanagiri Inst Technol, Dept Elect & Commun Engn, Chikkamagaluru, Karnataka, India.
   [Paramesha] Cent Univ Karnataka, Dept Elect & Commun Engn, Kalburgi, India.
C3 Central University of Karnataka
RP Pallavi, HV (corresponding author), Govt Engn Coll, Dept Elect & Commun Engn, Hassan 573202, Karnataka, India.
EM hv86585@gmail.com
FU Deanship of Government Engineering College; Adichunchanagiri Institute
   of Technology; Central University of Karnataka
FX The authors would like to thank the Deanship of Government Engineering
   College, Adichunchanagiri Institute of Technology and Central University
   of Karnataka for supporting this work.
CR Abdelaziz A, 2020, INT J RF MICROW C E, V30, DOI 10.1002/mmce.22416
   Bansal Aakash, 2020, International Journal of Information Technology, V12, P149, DOI 10.1007/s41870-018-0121-4
   Darboe O., 2019, International Journal of Engineering Research and Technology, V12, P854
   Famoriji OJ, 2019, IET MICROW ANTENNA P, V13, P1671, DOI 10.1049/iet-map.2018.5973
   Guttula R, 2020, EVOL INTELL, V13, P331, DOI 10.1007/s12065-019-00292-9
   Hussain N, 2020, IEEE ACCESS, V8, P22127, DOI 10.1109/ACCESS.2020.2969964
   Kumar P, 2021, IET COMMUN, V15, P1, DOI 10.1049/cmu2.12042
   Kumar Sunil, 2022, Intelligent Network Design Driven by Big Data Analytics, IoT, AI and Cloud Computing. Computing (054), P1, DOI 10.1049/PBPC054E_ch1
   Liu MX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010034
   Lodro Z, 2019, INT C LAT TRENDS EL, P1
   Nguyen DH, 2020, IEEE T ANTENN PROPAG, V68, P7339, DOI 10.1109/TAP.2020.2995416
   Priyadharshini RA, 2021, MATER TODAY-PROC, V37, P1854, DOI 10.1016/j.matpr.2020.07.446
   Rajan SP, 2019, J ELECTR ENG TECHNOL, V14, P923, DOI 10.1007/s42835-018-00072-y
   Saad AAR, 2019, AEU-INT J ELECTRON C, V99, P59, DOI 10.1016/j.aeue.2018.11.029
   Samriya JK, 2022, ARXIV
   Sandi E, 2020, J COMMUNICATIONS, P198
   Simkó M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16183406
   Su GR, 2020, IEEE ACCESS, V8, P200823, DOI 10.1109/ACCESS.2020.3035750
   Umayah EN., 2019, INT J ELECT ELECT EN, V8, P352
   Xu XL, 2022, TSINGHUA SCI TECHNOL, V27, P270, DOI 10.26599/TST.2020.9010025
NR 20
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31129
EP 31155
DI 10.1007/s11042-023-14628-2
EA FEB 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000939106800002
DA 2024-07-18
ER

PT J
AU Sasithradevi, A
   Roomi, SMM
   Nirmala, P
AF Sasithradevi, A.
   Roomi, S. Mohamed Mansoor
   Nirmala, P.
TI Visual significance model based temporal signature for video shot
   boundary detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video transitions; Visual significance; Random vector functional link
   network; F1-score
AB Video shot boundary detection (VSBD) is the fundamental step for video processing algorithms. The goal of any VSBD algorithm is to detect the transitions (abrupt or subtle) in the given video precisely. In this paper, a visual significance model that is suitable for describing transitions in video is introduced. The proposed visual significance model is composed of parameters like color, texture, edge, motion and focus computed over the frames in the video. Once the visually significant region is identified in each frame of the video, the temporal signature is generated through the dissimilarity measure of the visual significance model. The temporal signature is further examined using standard Random Vector Functional Link (RVFL) networks for categorizing the transitions as Abrupt Transitions (AT), Subtle Transitions (ST) and No Transitions (NT). To validate the performance of the proposed visual significance model based VSBD Framework, it is evaluated on benchmarks like VIDEOSEG2004 and TRECVID2001 to detect and categorize the transitions. Comparison of F1-Score measure with prominent early methods reveals that the proposed framework is a promising model for detecting the transitions in videos even in the presence of varying illumination conditions, fast camera and object motion.
C1 [Sasithradevi, A.] Vellore Inst Technol, Ctr Adv Data Sci, Chennai, India.
   [Roomi, S. Mohamed Mansoor] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai, India.
   [Nirmala, P.] Vellore Inst Technol, Sch Elect Engn, Chennai, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Thiagarajar College
   of Engineering; Vellore Institute of Technology (VIT); VIT Chennai
RP Sasithradevi, A (corresponding author), Vellore Inst Technol, Ctr Adv Data Sci, Chennai, India.
EM sasithradevi.a@vit.ac.in; smmroomi@tce.edu; nirmalavp@gmail.com
OI Anbalagan, Sasithradevi/0000-0001-5198-6648
CR Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Benoughidene A, 2022, INT J MULTIMED INF R, V11, P653, DOI 10.1007/s13735-022-00251-8
   Bi CK, 2018, IEEE ACCESS, V6, P21397, DOI 10.1109/ACCESS.2018.2825106
   Chakraborty S, 2022, EDGE ANALYTICS SELEC, P685, DOI 10.1007/978-981-19-0019-8_51
   Cyganek B, 2017, NEW GENERAT COMPUT, V35, P311, DOI 10.1007/s00354-017-0024-0
   Gygli M, 2018, INT WORK CONTENT MUL
   Kar T, 2023, MULTIMED TOOLS APPL, V82, P8489, DOI 10.1007/s11042-022-13547-y
   Kar T, 2017, 2017 2 INT C MAN MAC, P1, DOI [10.1109/MAMI.2017.8307865, DOI 10.1109/MAMI.2017.8307865]
   Mishra R, 2021, MULTIMED TOOLS APPL, V80, P28109, DOI 10.1007/s11042-021-11052-2
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   Cirne MVM, 2018, MULTIMED TOOLS APPL, V77, P857, DOI 10.1007/s11042-016-4300-7
   Nishani E, 2017, MEDD C EMBED COMPUT, P242
   Pal G., 2015, INT J IMAGE MINING, V1, P87, DOI DOI 10.1504/IJIM.2015.070027
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Roomi SMM, 1999, J INDIAN I, VSci79, P89
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   Shou S. W., 2021, ICCV, P8075
   Soucek T, 2019, TRANSNET DEEP NETWOR
   Soucek T, 2020, ARXIV
   Santos ACSE, 2017, IEEE SYS MAN CYBERN, P1310, DOI 10.1109/SMC.2017.8122794
   SRRR AS., 2016, IJCTA, V9, P3231
   Tang ST, 2019, LECT NOTES COMPUT SC, V11361, P577, DOI 10.1007/978-3-030-20887-5_36
   Thounaojam DM, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8469428
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Tong W., 2015, 2015 IEEE INT S BROA, P1
   Wu LF, 2019, IEEE ACCESS, V7, P77268, DOI 10.1109/ACCESS.2019.2922038
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Zhang L, 2016, INFORM SCIENCES, V367, P1094, DOI 10.1016/j.ins.2015.09.025
NR 29
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23037
EP 23054
DI 10.1007/s11042-023-14882-4
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000939106800007
DA 2024-07-18
ER

PT J
AU Asgharian, L
   Ebrahimnezhad, H
AF Asgharian, Lida
   Ebrahimnezhad, Hossein
TI 3D model representation using space curves: an efficient mesh
   simplification method by exchanging triangulated mesh to space curves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh simplification; Mesh segmentation; Surface representation;
   Curve-based simplification; Feature preserving; Object modeling
ID SEGMENTATION
AB Simplification of Computer-Aided-Design models plays an important role in reducing the complex features of man-made objects produced according to engineering needs. This paper proposes an efficient feature preserving method to simplify CAD models by extracting sharp edges and decomposing the original mesh model into low varying curvature sub-regions which are representable through their boundary curves. To extract the sharp edges and important boundaries of the model, the maximum curvature value and the minimum curvature direction are taken into account. We analyze the anisotropic features of the mesh to specify robust features on the mesh. An enhanced segmentation algorithm is used to decompose the mesh into sub-sections with smooth boundary curves that are suitable for our simplification framework. Once the input mesh is segmented into new sub-sections, the common boundary space curves between two different segments are determined and decimated by down sampling the vertices on the boundary curve. The sorted list of selected sample points is the only data used to represent our simplified model. After interpolating the decimated vertices, we fit a surface to the reconstructed boundary curve. Surface fitting is completed in three steps. First, the interpolated vertices of an enclosed curve are projected onto a plane. Second, the finite element mesh generation technique is employed to triangulate inside of each segment. Finally, the surface fitting to the space boundary curves is accomplished using interpolation technique for the vertices of the triangulated planer mesh inside the segment. Experimental results demonstrate that the proposed method can efficiently simplify a CAD model with complex geometric features and complicated shapes. Several comparisons have been conducted to establish the superiority of the presented algorithm over other state-of-the-art methods.
C1 [Asgharian, Lida; Ebrahimnezhad, Hossein] Sahand Univ Technol, Fac Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Fac Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
EM L_asgharian@sut.ac.ir; ebrahimnezhad@sut.ac.ir
CR Abdelkader A, 2017, COMPUT GRAPH FORUM, V36, P189, DOI 10.1111/cgf.13256
   ALFELD P, 1989, INT S NUM M, V90, P1
   Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   Asgharian L, 2020, MULTIMED TOOLS APPL, V79, P29595, DOI 10.1007/s11042-020-09395-3
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131
   Bergamasco F, 2012, PATTERN RECOGN LETT, V33, P2057, DOI 10.1016/j.patrec.2012.03.015
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cohen J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P119, DOI 10.1145/237170.237220
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Diez H, 2017, MULTIMED TOOLS APPL, V76, P21011, DOI 10.1007/s11042-016-4047-1
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Fan LB, 2011, COMPUT GRAPH FORUM, V30, P603, DOI 10.1111/j.1467-8659.2011.01895.x
   Foucault G, 2008, COMPUT AIDED DESIGN, V40, P176, DOI 10.1016/j.cad.2007.10.009
   Garland M., 1997, P 24 ANN C COMP GRAP, V1997, P209, DOI DOI 10.1145/258734.258849
   González C, 2009, COMPUT AIDED DESIGN, V41, P1095, DOI 10.1016/j.cad.2009.09.007
   Gori G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073639
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hou Y, 2021, MULTIMED TOOLS APPL, V80, P24885, DOI 10.1007/s11042-021-10816-0
   Huang JW, 2018, COMPUT GRAPH FORUM, V37, P147, DOI 10.1111/cgf.13498
   Hurtado J, 2022, ENG COMPUT-GERMANY, V38, P781, DOI 10.1007/s00366-020-01040-9
   Kim BC, 2014, COMPUT GRAPH-UK, V38, P97, DOI 10.1016/j.cag.2013.10.031
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P15867, DOI 10.1007/s11042-016-3881-5
   Kok-Lim Low, 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P75
   Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183
   Lavoué G, 2005, PROC SPIE, V5960, P1159, DOI 10.1117/12.631641
   Lavoue G, 2005, PATTERN RECOGN, V38, P1139, DOI 10.1016/j.patcog.2005.02.002
   Lee SH, 2012, COMPUT AIDED DESIGN, V44, P457, DOI 10.1016/j.cad.2011.12.005
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   Mamou K., 2005, WSEAS Transactions on Communications, V4, P587
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Morigi S, 2014, VISUAL COMPUT, V30, P479, DOI 10.1007/s00371-013-0873-6
   Nieser M, 2010, COMPUT AIDED DESIGN, V42, P213, DOI 10.1016/j.cad.2009.11.002
   Ochotta T, 2008, COMPUT GRAPH FORUM, V27, P1647, DOI 10.1111/j.1467-8659.2008.01178.x
   Peyré G, 2006, INT J COMPUT VISION, V69, P145, DOI 10.1007/s11263-006-6859-3
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Rodrigues RSV, 2015, COMPUT GRAPH-UK, V49, P24, DOI 10.1016/j.cag.2015.04.003
   Salinas D, 2015, COMPUT GRAPH FORUM, V34, P211, DOI 10.1111/cgf.12531
   Shamir A., 2006, State-of-the-Art Report, Proceedings Eurographics, V2006, P137
   Sheen DP, 2010, COMPUT AIDED DESIGN, V42, P720, DOI 10.1016/j.cad.2010.01.003
   Sibson R., 1981, Interpreting Multivariate Data, P21
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Sun R, 2010, COMPUT GRAPH-UK, V34, P556, DOI 10.1016/j.cag.2010.06.007
   Tao SQ, 2017, MULTIMED TOOLS APPL, V76, P103, DOI 10.1007/s11042-015-3033-3
   Wang H, 2014, GRAPH MODELS, V76, P440, DOI 10.1016/j.gmod.2014.04.009
   Wang RM, 2016, VISUAL COMPUT, V32, P1179, DOI 10.1007/s00371-016-1210-7
   Wasserman P.D., 1993, ADV METHODS NEURAL C, P155
   WORDENWEBER B, 1984, COMPUT AIDED DESIGN, V16, P285, DOI 10.1016/0010-4485(84)90087-3
   Xiao D, 2011, COMPUT GRAPH-UK, V35, P685, DOI 10.1016/j.cag.2011.03.020
   Zhang JY, 2011, IEEE T VIS COMPUT GR, V17, P357, DOI 10.1109/TVCG.2010.57
   Zheng YY, 2010, COMPUT GRAPH FORUM, V29, P527, DOI 10.1111/j.1467-8659.2009.01622.x
NR 55
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30965
EP 31000
DI 10.1007/s11042-023-14777-4
EA FEB 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000936302600012
DA 2024-07-18
ER

PT J
AU Murtaza, G
   Memon, RA
   Ali, S
   Shagari, NM
   Ali, J
AF Murtaza, Ghulam
   Memon, Raheel Ahmed
   Ali, Safdar
   Shagari, Nura Modi
   Ali, Javed
TI Face forgery detection via optimum deep convolution activation feature
   selection algorithm using expert-generated images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fake face detection; Face forgery detection; Expert-generated Photoshop
   images; Deep learning; Convolutional neural network
ID NETWORKS
AB The recent face forgery detection models have shown better accuracy for in-house generated and altered face image datasets. Therefore, the results of such a model cannot be compared directly and fairly. Moreover, some of the studies used datasets of smaller size, thus models can be overfitted. To address these issues, we selected a larger public dataset, created and altered by experts in photoshop. Thus, the goal of this study is to develop a face forgery detection model for expert-generated standard images. As a preprocessing step in our proposed approach, a convexhull reduced of an aligned face is extracted from each image. A convolutional neural network-based face forgery detection model is developed and trained from scratch. The images are normalized and label smoothing is applied to train the model to get minimum validation loss. The trained model is used to extract 1024 features of each image. Afterward, a feature selection algorithm is developed to select the optimum number of features without compromising the model performance. Moreover, random parameter optimization is performed to get the best parameters to train multiple classifiers. Only 36 features out of 1024 are selected using kNN(k = 4) for 76.04% sensitivity, 71.76% AUROC. The proposed approach achieved comparable results compared to the existing state-of-the-art face forgery models.
C1 [Murtaza, Ghulam; Memon, Raheel Ahmed; Ali, Safdar; Ali, Javed] Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.
   [Murtaza, Ghulam; Shagari, Nura Modi] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
C3 Sukkur IBA University; Universiti Malaya
RP Murtaza, G (corresponding author), Sukkur IBA Univ, Dept Comp Sci, Sukkur, Pakistan.; Murtaza, G (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
EM gmurtaza@iba-suk.edu.pk; raheelmemon@iba-suk.edu.pk;
   safdarsoomro@iba-suk.edu.pk; wva170053@siswa.um.edu.my;
   javed.abbasi@iba-suk.edu.pk
RI Murtaza, Ghulam/ABD-7461-2020; Memon, Raheel Ahmed/O-7548-2017
OI Murtaza, Ghulam/0000-0003-0318-7168; Memon, Raheel
   Ahmed/0000-0003-1206-3837
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Anwar S, 2019, PERCEPTUAL JUDGMENTS
   Baek JY, 2020, IEEE ACCESS, V8, P45421, DOI 10.1109/ACCESS.2020.2968612
   Brockschmidt J, 2019, 2019 IEEE 16 INT C M
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dang LM, 2019, EXPERT SYST APPL, V129, P156, DOI 10.1016/j.eswa.2019.04.005
   Gholamiangonabadi D, 2020, IEEE ACCESS, V8, P133982, DOI 10.1109/ACCESS.2020.3010715
   Gong Jiachang, 2016, Transactions of Tianjin University, V22, P151, DOI 10.1007/s12209-016-2705-z
   Hashmi MF, 2013, INT CONF INTELL SYST, P188, DOI 10.1109/ISDA.2013.6920733
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hsu CC, 2018, INT SYMP COMP CONS, P388, DOI 10.1109/IS3C.2018.00104
   Jayan TJ, 2018, 2018 INT CET C CONTR
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kashyap A, 2015, INT C COMPUTING COMM
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760
   Liu HQ, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/9025458
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Muhammad G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1146, DOI 10.1109/ICIT.2013.6505834
   Negi A, 2021, 2021 INT C COMPUTING
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Pandey AK, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P205, DOI 10.1145/2818567.2818606
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Tan T, 2019, CHINESE C BIOMETRIC
   Tariq S, 2018, DETECTING BOTH MACHI
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Vinolin V, 2021, VISUAL COMPUT, V37, P2369, DOI 10.1007/s00371-020-01992-5
   Wang R., 2019, ARXIV
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhou HY, 2016, FORENSIC SCI INT, V266, P379, DOI 10.1016/j.forsciint.2016.06.005
NR 34
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28797
EP 28825
DI 10.1007/s11042-023-14612-w
EA FEB 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936302600011
DA 2024-07-18
ER

PT J
AU Beula, RJ
   Wesley, AB
AF Beula, R. Janefer
   Wesley, A. Boyed
TI Accurate segmentation of lung nodule with low contrast boundaries by
   least weight navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dilation; Erosion; Otsu's thresholding; Computed tomography images; Edge
   detection; Lung nodule
ID CONVOLUTIONAL NEURAL-NETWORKS; THORACIC CT; COMPUTED-TOMOGRAPHY;
   AUTOMATIC DETECTION; PULMONARY NODULES; IMAGES; MODEL
AB Accurate segmentation of lung nodules with low contrast boundaries in CT images is a challenging task since the intensity of nodules and non-nodules overlap with each other. This work proposes a lung nodule segmentation scheme based on least weight navigation (LWN) that segments the lung nodule accurately with such low contrast boundaries. The complete lung nodule segmentation is categorized intothree stages namely, (i) Lung segmentation, (ii) Coarse segmentation of nodule, and (iii) Fine segmentation of nodule. The lung segmentation aims to eliminate the background other than the lung, whereas the coarse segmentation eliminates the lung leaving the nodules. The lung segmentation and coarse segmentation can be achieved using the traditional algorithms namely, dilation, erosion, and Otsu's thresholding. The proposed work focused on fine segmentation where the boundaries are accurately detected by the LWN algorithm. The LWN algorithm estimates the edge points and then navigation is performed based on the least weight. This navigation is done till the final termination is reached, which results in accurate segmentation results. The experimental validation was done on LIDC and Cancer Imaging dataset with three different nodules such as Juxta vascular, Juxta pleura, and Solitary. The evaluation was done using the metrics such as dice similarity coefficient (DSC), sensitivity (SEN), positive prediction value (PPV). Hausdorff distance (HD) andProbability rand index(PRI). The proposed approach provides a DSC, SEN, and PPV of 84.27%, 89.92%, and 80.12% respectively. The result reveals that the proposed work outperforms the traditional lung nodule segmentation algorithms.
C1 [Beula, R. Janefer] Marthandam Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Wesley, A. Boyed] Marthandam Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Beula, RJ (corresponding author), Marthandam Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM janeferbeula@gmail.com; abwesley2003@gmail.com
CR Aresta G, 2017, PROC SPIE, V10134, DOI 10.1117/12.2252022
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Armato SG, 2004, ACAD RADIOL, V11, P1011, DOI 10.1016/j.acra.2004.06.005
   Armato SG, 2003, MED PHYS, V30, P461, DOI 10.1118/1.1544679
   Brown MS, 1997, IEEE T MED IMAGING, V16, P828, DOI 10.1109/42.650879
   Cao HC, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105934
   Charron O, 2018, COMPUT BIOL MED, V95, P43, DOI 10.1016/j.compbiomed.2018.02.004
   Chen X., 2012, IEEE T IMAGE PROCESS, V21, P20352046
   Choi WJ, 2014, COMPUT METH PROG BIO, V113, P37, DOI 10.1016/j.cmpb.2013.08.015
   Dai SF, 2015, NEUROCOMPUTING, V168, P799, DOI 10.1016/j.neucom.2015.05.044
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   El-Askary NS, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116489
   Hu SY, 2001, IEEE T MED IMAGING, V20, P490, DOI 10.1109/42.929615
   Hua P, 2011, PROC IEEE INT S BIOM
   Huang X, 2019, COMPUT MED IMAG GRAP, V74, P25, DOI 10.1016/j.compmedimag.2019.02.003
   Javaid M, 2016, COMPUT METH PROG BIO, V135, P125, DOI 10.1016/j.cmpb.2016.07.031
   Kemerink GJ, 1998, MED PHYS, V25, P2432, DOI 10.1118/1.598454
   Kitasaka T., 2003, Systems and Computers in Japan, V34, P60, DOI 10.1002/scj.1201
   Kostis WJ, 2003, IEEE T MED IMAGING, V22, P1259, DOI 10.1109/TMI.2003.817785
   Kubota T, 2011, MED IMAGE ANAL, V15, P133, DOI 10.1016/j.media.2010.08.005
   Leader JK, 2003, ACAD RADIOL, V10, P1224, DOI 10.1016/S1076-6332(03)00380-5
   Liu K, 2017, INT J IMAG SYST TECH, V27, P12, DOI 10.1002/ima.22206
   Masutani Y., 1996, LECT NOTES COMPUT SC, V1131
   Setio AAA, 2015, MED PHYS, V42, P5642, DOI 10.1118/1.4929562
   Shariaty F, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105086
   Sluimer I, 2005, IEEE T MED IMAGING, V24, P1025, DOI 10.1109/TMI.2005.851757
   Suchetha M, 2021, SOFT COMPUT, V25, P15255, DOI 10.1007/s00500-021-06098-1
   Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648, DOI 10.1164/ajrccm.160.2.9804094
   Wang JK, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/2962047
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
   Wu ZT, 2021, IEEE ACCESS, V9, P7255, DOI 10.1109/ACCESS.2021.3049379
   Ye XJ, 2009, IEEE T BIO-MED ENG, V56, P1810, DOI 10.1109/TBME.2009.2017027
   Yu, 2014, PROC IEEE WORKSHOP E, P89
   Zhang HW, 2023, VISUAL COMPUT, V39, P679, DOI 10.1007/s00371-021-02366-1
   Zhang L, 2001, PROC SPIE MED IMAG P, V4321
NR 35
TC 1
Z9 1
U1 6
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27635
EP 27657
DI 10.1007/s11042-023-14620-w
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300005
DA 2024-07-18
ER

PT J
AU Zouidi, N
   Kessentini, A
   Hamidouche, W
   Masmoudi, N
   Menard, D
AF Zouidi, Naima
   Kessentini, Amina
   Hamidouche, Wassim
   Masmoudi, Nouri
   Menard, Daniel
TI Complexity assessment of the intra prediction in Versatile Video Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile Video Coding; Complexity reduction; Intra prediction; Rate
   distortion; Intra mode decision
AB The Versatile Video Coding (VVC) was finalized in July 2020 by the Joint Video Experts Team (JVET). During the standardization process, many coding techniques were investigated in order to provide superior coding efficiency with high level of versatility over the High Efficiency Video Coding (HEVC). Indeed, VVC achieved about 40% of bitrate saving compared to its predecessor for the same objective visual quality. However, its encoding complexity has considerably increased due to the exhaustive Rate-Distortion (RD) search. In this paper, a complexity assessment of the intra mode decision of VVC is presented. Experimental results reveal that the intra coding tools and the steps of intra mode decision have various degrees of complexity. Thus, opening up several complexity reduction opportunities, that yield up to 43% of complexity reduction. Also, VVC tends usually to select the 6 Most Probable Modes (MPMs). However, this selection may depend on the used intra coding tool and video texture characteristics. These conclusions give clear openings to accelerate the intra mode decision.
C1 [Zouidi, Naima] ENI Sfax LETI, 20 Ave Buttes Coesmes, F-35708 Rennes 7, France.
   [Zouidi, Naima; Hamidouche, Wassim; Menard, Daniel] INSA Rennes IETR, 20 Ave Buttes Coesmes, F-35708 Rennes 7, France.
   [Kessentini, Amina; Masmoudi, Nouri] ENI Sfax LETI, Rd Soukra, Sfax 3038, Tunisia.
   [Kessentini, Amina] ISIM Gabes, Rd Soukra, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Zouidi, N (corresponding author), ENI Sfax LETI, 20 Ave Buttes Coesmes, F-35708 Rennes 7, France.; Zouidi, N (corresponding author), INSA Rennes IETR, 20 Ave Buttes Coesmes, F-35708 Rennes 7, France.
EM Naima.zouidi@insa-rennes.fr
FU France Campus
FX This work is supported by the France Campus, and within a co-supervised
   thesis between the Institute of Electronics and Telecommunications of
   Rennes, france (IETR), and the Laboratory of Electronics and Information
   Technology (LETI) of Sfax, Tunisia.
CR Akramullah Shahriar, 2014, Digital Video Concepts, Methods, and Metrics: Quality, Compression, Performance, and Power Trade-Off Analysis, DOI DOI 10.1007/978-1-4302-6713-3
   Belghith F., 2019, 2019 IEEE INT C DES, P1
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Cao J, 2020, LECT NOTES COMPUT SC, V11961, P739, DOI 10.1007/978-3-030-37731-1_60
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   CISCO, 2018, CISCO VISUAL NETWORK, P1
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   JVET, 2020, ITU T SG 16 WP 3 ISO
   JVET, 2019, JOINT VIDEO EXPLORAT
   JVET, 2020, 19 M TELECONFERENCE
   JVET, 2018, VVCSOFTW VTM 8 0 REF
   JVET, 2020, JVET R0003
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li JH, 2017, IEEE DATA COMPR CONF, P221, DOI 10.1109/DCC.2017.59
   Li Xea, 2016, 4 JVET M
   Mercat A, 2021, IEEE ACCESS, V9, P67813, DOI 10.1109/ACCESS.2021.3077116
   Pakdaman F, 2020, ARXIV
   Pfaff J, 2021, IEEE T CIRC SYST VID, V31, P3834, DOI 10.1109/TCSVT.2021.3072430
   Reuze K, 2016, PICT COD SYMP
   Said A, 2016, IEEE IMAGE PROC, P534, DOI 10.1109/ICIP.2016.7532414
   Saldanha M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103202
   Saldanha M, 2020, IEEE IMAGE PROC, P3119, DOI [10.1109/ICIP40778.2020.9190970, 10.1109/icip40778.2020.9190970]
   Schäfer M, 2019, IEEE IMAGE PROC, P1089, DOI [10.1109/ICIP.2019.8803724, 10.1109/icip.2019.8803724]
   Siqueira I, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401714
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tissier A, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901754
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zouidi Naima, 2020, 2020 IEEE 4th International Conference on Image Processing, Applications and Systems (IPAS), P180, DOI 10.1109/IPAS50080.2020.9334954
   Zouidi N, 2019, INT MULTICONF SYST, P18, DOI [10.1109/SSD.2019.8893231, 10.1109/ssd.2019.8893231]
NR 29
TC 1
Z9 1
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27751
EP 27770
DI 10.1007/s11042-023-14442-w
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934850300006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Qian, WJ
   Hu, CH
   Wang, HZ
   Lu, L
   Shi, ZF
AF Qian, Weijie
   Hu, Chunhua
   Wang, Hanzhao
   Lu, Li
   Shi, Zefeng
TI A novel target detection and localization method in indoor environment
   for mobile robot based on improved YOLOv5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; YOLOv5; Indoor; Localization
AB Indoor mobile robots, especially those for the elderly and the disabled, are becoming more and more important to improve their quality of life. The strong interest related to this field can be explained by that the robots can help people grasp or carry things. Accurate detection and localization of target in indoor environment is the premise of this task. Aiming to complete this work, a novel indoor target detection and localization method based on improved YOLOv5 is proposed in this paper for indoor mobile robot equipped with KinectV2 camera. First, we made an indoor scene dataset containing 2000 RGB images and 2000 depth images to enhance the robustness of the 2D detection model in the case of image blur, strong and weak illumination and target occlusion. Second, we proposed an improved YOLOv5-S network for indoor 2D target detection and verified its effectiveness from both theoretical and experimental aspects. When tested on our dataset, our improved YOLOv5-S target detection method achieves the mAP@0.5 indicator of 95.9% and the FPS indicator of 65.36. Third, we proposed an improved mean filtering method to process the depth value of the target center point, so as to solve the noise problem of depth image. Finally, we deduced and sorted out the transformation formula of the target center point from the 2D pixel coordinate system to the 3D camera coordinate system, and used the chessboard calibration method to calibrate our KinectV2 camera, so as to realize the 3D localization of the target center point. When conducting localization experiments in the range of 0.5 m-3 m, the MAE indicator of the localization results of our proposed method is only 11.59 mm, which proves the effectiveness of our proposed method.
C1 [Qian, Weijie; Hu, Chunhua; Wang, Hanzhao; Lu, Li; Shi, Zefeng] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Jiangsu, Peoples R China.
C3 Nanjing Forestry University
RP Hu, CH (corresponding author), Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Jiangsu, Peoples R China.
EM huchunhua@njfu.edu.cn
RI wang, hanzhao/HHZ-3450-2022
CR Afif M, 2020, NEURAL PROCESS LETT, V51, P2265, DOI 10.1007/s11063-020-10197-9
   Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Amad-ud-Din, 2009, IEEE ST CONF RES DEV, P246, DOI 10.1109/SCORED.2009.5443066
   Biswas K, 2021, ARXIV
   Bochkovskiy A., 2020, PREPRINT
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai YX., 2020, ARXIV PREPRINT
   Chen M, 2020, PROCEEDINGS OF 2020 IEEE 9TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS'20), P772, DOI 10.1109/DDCLS49620.2020.9275060
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding XT, 2021, INT J ADV ROBOT SYST, V18, DOI 10.1177/1729881421993323
   Feng YX, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P31, DOI 10.1109/ICCIA.2016.19
   Ge Z., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.08430
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hu T, 2018, FUTURE GENER COMP SY, V88, P540, DOI 10.1016/j.future.2018.05.083
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jung J, 2015, SENSORS-BASEL, V15, P26430, DOI 10.3390/s151026430
   Kim HS, 2008, 2008 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS, VOLS 1-4, P201
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu FX, 2020, COMPUT GRAPH FORUM, V39, P433, DOI 10.1111/cgf.14157
   Maas Andrew L, 2013, P INT C MACH LEARN A, V30, P3
   Morar A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092641
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qu SY, 2014, INT J HUM ROBOT, V11, DOI 10.1142/S0219843614500108
   Quan L, 2017, I C INTELL COMPUT TE, P369, DOI 10.1109/ICICTA.2017.88
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sabir MFS, 2022, CMC-COMPUT MATER CON, V71, P4151, DOI 10.32604/cmc.2022.017865
   Sun H, 2018, IEEE INT C INT ROBOT, P8331, DOI 10.1109/IROS.2018.8593837
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang S, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040979
   Wu XD, 2008, KNOWL INF SYST, V14, P1, DOI 10.1007/s10115-007-0114-2
   Xia JH, 2022, COMPUT-AIDED CIV INF, V37, P1243, DOI 10.1111/mice.12795
   Xie Q, 2021, INT J COMPUT VISION, V129, P1857, DOI 10.1007/s11263-021-01456-w
   Xu YF, 2019, CHIN CONTR CONF, P8488, DOI [10.23919/chicc.2019.8865732, 10.23919/ChiCC.2019.8865732]
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Zhang Y, 2014, APPL MECH MATER, V511-512, P880, DOI 10.4028/www.scientific.net/AMM.511-512.880
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou X., 2019, Objects as Points, V1904, P07850, DOI [10.48550/arXiv.1904.07850, DOI 10.48550/ARXIV.1904.07850]
NR 43
TC 1
Z9 1
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28643
EP 28668
DI 10.1007/s11042-023-14569-w
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000931739200005
DA 2024-07-18
ER

PT J
AU Sivanandan, R
   Jayakumari, J
AF Sivanandan, Revathy
   Jayakumari, J.
TI Bayesian optimized novel CNN for improved diagnosis from ultrasound
   breast tumor images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature maps; Bayesian optimization; Clustering; Convolutional neural
   networks; Ultrasound breast tumor
ID CLASSIFICATION
AB Convolutional neural networks (CNNs) have played a significant role in feature extraction and tasks thereafter for accurate and automated diagnosis from ultrasound (US) breast tumor images. However, using pre-trained architectures and transfer learning for feature extraction could cause negative transfer in medical domain. Also publicly accessible online training/ validation US breast tumor datasets are seldom available. Hence, it becomes prudent to develop alternate CNN architectures as feature extraction backbones which are trained on smaller datasets without any consequences of overfitting. In this paper, a CNN was developed for feature extraction and prediction of breast tumor as benign/ malignant, with hyper parameters (learning rate, regularization factor, momentum, section depth and number of convolution filters) optimized using bayesian optimization. To further prevent any overfitting due to limited training data, a novel neutrosophic augmentation method was also introduced. The obtained simulation results on three different test datasets show that the classification accuracy of the optimized CNN outperforms by at least 3% than many other state-of-the-art deep architectures and significantly greater than 5% for shallow architectures. For segmenting the tumor region, the convolution maps from the higher layers of the optimized CNN are clustered to provide the initial contour for segmentation using active contours. The segmentation metrics with respect to ground truth is greater for the proposed work when compared with U-Net and fully Convolutional Network based segmentation. The structural similarity and mean segmentation error for the proposed method and the latter cases are 0.98, 0.93 and 0.92, and 0.01, 0.21 and 0.28 respectively.
C1 [Sivanandan, Revathy; Jayakumari, J.] Mar Baselios Coll Engn & Technol, Dept Elect & Commun Engn, Mar Ivanios Vidyanagar, Nalanchira 695015, Kerala, India.
RP Sivanandan, R (corresponding author), Mar Baselios Coll Engn & Technol, Dept Elect & Commun Engn, Mar Ivanios Vidyanagar, Nalanchira 695015, Kerala, India.
EM revathysivan.official@gmail.com; jayakumari.j@mbcet.ac.in
OI Sivanandan, Revathy/0000-0001-5170-6976
CR Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Borgli RJ, 2019, INT SYM MED INFORM, P175, DOI 10.1109/ismict.2019.8743779
   Bose A., 2022, UK WORKSHOP COMPUTAT, P179
   Byra M, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102027
   Ceylan Z., 2020, Int J Intell Syst Appl Eng, V8, P121, DOI [10.18201/ijisae.2020363531, DOI 10.18201/IJISAE.2020363531]
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng HD, 2010, PATTERN RECOGN, V43, P299, DOI 10.1016/j.patcog.2009.05.012
   Doke P, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01087-0
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   Hijab A, 2019, I CON ADV BIOMED ENG, P64, DOI 10.1109/icabme47164.2019.8940291
   Hu YZ, 2019, MED PHYS, V46, P215, DOI 10.1002/mp.13268
   Klimonda Z, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-44376-z
   Koundal D, 2016, IET IMAGE PROCESS, V10, P167, DOI 10.1049/iet-ipr.2015.0231
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Liu SF, 2019, ENGINEERING-PRC, V5, P261, DOI 10.1016/j.eng.2018.11.020
   Masud M, 2022, NEURAL COMPUT APPL, V34, P11383, DOI 10.1007/s00521-020-05394-5
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Muduli D, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.102825
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saba T, 2022, MICROSC RES TECHNIQ, V85, P1444, DOI 10.1002/jemt.24008
   Salama AA, 2018, NEUTROSOPHIC SETS SY, V21, P13
   Sezer A, 2020, ULTRASOUND MED BIOL, V46, P735, DOI 10.1016/j.ultrasmedbio.2019.09.018
   Sivanandan Revathy, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P263, DOI 10.1109/ICCCA49541.2020.9250909
   Sivanandan R, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500490
   Smarandache F., 2014, Introduction to Neutrosophic Statistics
   Tanaka H, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab5093
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Vakanski A, 2020, ULTRASOUND MED BIOL, V46, P2819, DOI 10.1016/j.ultrasmedbio.2020.06.015
   Wu H., 2019, ARXIV
   Yoon HJ, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834674
   Zhang M., 2019, ARXIV
   Zhang ZL, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102677
   Zhuang ZM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221535
   Zuluaga-Gomez J, 2021, COMP M BIO BIO E-IV, V9, P131, DOI 10.1080/21681163.2020.1824685
NR 35
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22815
EP 22833
DI 10.1007/s11042-023-14468-0
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000931739200006
DA 2024-07-18
ER

PT J
AU Chandankhede, C
   Sachdeo, R
AF Chandankhede, Chaitali
   Sachdeo, Rajneeshkaur
TI Offline MODI script character recognition using deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; CNN; InceptionV3; Residual network; Modi script; OCR
AB Deep learning is a multilayer neural network learning algorithm which emerged in recent years. It has brought a new wave to machine learning and making artificial intelligence and human-computer interaction spread with big strides. India is a heritage country where traditions, religions and languages are quite varied. MODI script is one of the oldest written forms of media. Most of the early written knowledge on subjects like medicine, Buddhist ideology, food habits and horoscope has been written using MODI script. MODI is one of the languages that present special challenge to OCR. The main challenge in MODI script is that it is mostly cursive and few characters look similar. The deep learning methods like InceptionV3 and RestNet on Modi script seems not experimented yet as per literature review. This motivates to apply the deep learning methods to offline handwritten character recognition using Residual and InceptionV3 framework. The handwritten Modi barakhadi dataset is prepared by collecting samples from around 25 different people. The dataset of size 7721 is experimented. The individual characters are cut and pre-processed using Otsu binarization technique. The performance evaluation of pre-processed data is done using both algorithms on the real-world handwritten character database written by different people. Processed images recognized through RestNet50 gives testing accuracy of 94.552% with precision of the model 0.86. Processed images recognized through InceptionV3 gives testing accuracy of 93.923% with precision of the model 0.843.
C1 [Chandankhede, Chaitali] Dr Vishwanath Karad MIT World Peace Univ, Pune, India.
   [Chandankhede, Chaitali; Sachdeo, Rajneeshkaur] MIT ADT Univ, Pune, India.
C3 Dr. Vishwanath Karad MIT World Peace University
RP Chandankhede, C (corresponding author), Dr Vishwanath Karad MIT World Peace Univ, Pune, India.; Chandankhede, C (corresponding author), MIT ADT Univ, Pune, India.
EM chaitalipb@gmail.com; rajni.sachdeo@mituniversity.edu.in
CR Alom Z, 2017, COMPUT VIS PATTERN R, V2017, P1
   Besekar DN., 2012, INT J SYST ALGORITHM, V2, P1
   Besekar DN, 2012, INT J COMPUT APPL IJ, VMAHA, P48
   Bhatt PP., 2018, SPRINGERBRIEF MATH, V11, P55
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Brust CA, 2020, KUNSTL INTELL, V34, P165, DOI 10.1007/s13218-020-00631-4
   Chandankhede Chaitali, 2023, IEEE DataPort, DOI 10.21227/X24N-WM25
   Chandure S, 2023, IETE J RES, V69, P2584, DOI 10.1080/03772063.2021.1902867
   Gan J, 2020, PATTERN RECOGN LETT, V129, P190, DOI 10.1016/j.patrec.2019.11.028
   GeeksforGeeks, 2020, RES NETW RESNET DEEP
   Gharde Sanjay S., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P236, DOI 10.1109/ICGTSPICC.2016.7955304
   Guha R, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420520096
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Jindal U, 2020, ADV INTELL SYST, V1064, P121, DOI 10.1007/978-981-15-0339-9_11
   Joseph Solley, 2020, 2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP), P32, DOI 10.1109/ICSIP49896.2020.9339435
   Joseph S., 2021, DATA SCI SECURITY, P201, DOI [10.1007/978-981-15-5309-7_21, DOI 10.1007/978-981-15-5309-7_21]
   Joseph S, 2019, PERTANIKA J SCI TECH, V27, P1649
   Koyuncu B, 2019, HANDWRITTEN CHARACTE
   Li Z, 2020, EC REFORM INTERNATIO, V2020
   Mujtaba H., 2020, Introduction to ResNet or residual network
   Mustafa WA, 2018, J PHYS CONF SER, V1019, DOI 10.1088/1742-6596/1019/1/012023
   Raj B., 2020, SIMPLE GUIDE VERSION
   Ram S, 2018, J STAT MANAG SYST, V21, P593, DOI 10.1080/09720510.2018.1471264
   Rao ZH, 2018, KSII T INTERNET INF, V12, P413
   Ren HQ, 2019, PATTERN RECOGN LETT, V128, P400, DOI 10.1016/j.patrec.2019.10.001
   Roy S, 2017, PATTERN RECOGN LETT, V90, P15, DOI 10.1016/j.patrec.2017.03.004
   Sadanand AK, 2015, 2015 INT C COMPUTER, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Vaidya R, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P772, DOI 10.1109/ICICCT.2018.8473291
   Vijayaraghavan P, 2014, 2014 INT C INFORM CO, P1
NR 31
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21045
EP 21056
DI 10.1007/s11042-023-14476-0
EA FEB 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000929502800003
DA 2024-07-18
ER

PT J
AU Cao, LZ
   Zhang, HD
   Peng, C
   Hansberger, JT
AF Cao, Lizhou
   Zhang, Huadong
   Peng, Chao
   Hansberger, Jeffrey T.
TI Real-time multimodal interaction in virtual reality-a case study with a
   large virtual interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal interaction; Virtual reality; Virtual interface; Interaction
   design
ID GESTURE; SPEECH
AB The values of VR and multimodal interaction technologies offer creative, virtual alternatives to manipulate a large data set in a virtual environment. This work presents the design, implementation, and evaluation of a real-time multimodal interaction framework that enables users to navigate, select, and move data elements. The novel multimodal fusion method is able to recognize freehand gestures, voice commands, and head gaze pointer in real-time and fuse them to meaningful actions for interacting with the virtual environment. We worked with imagery analysts who were defense and security experts on designing and testing the interface and interaction modalities. The evaluation of the framework was conducted with a case study of photo management tasks based on a real-world scenario. Users are able to select photos in a large virtual interface and move them to the bins on the left and right sides of the main view. The evaluation focuses on performance, task completion time, and users' experience amongst several different combinations of input modalities. The evaluation result shows it is important to make multiple interaction modalities available to users, and the interaction design implications are concluded based on the evaluation.
C1 [Cao, Lizhou; Zhang, Huadong; Peng, Chao] Rochester Inst Technol, Golisano Coll Comp & Informat Sci, Sch Interact Games & Media, Lomb Mem Dr, Rochester, NY 14623 USA.
   [Hansberger, Jeffrey T.] Army Res Lab, Huntsville, AL USA.
C3 Rochester Institute of Technology; United States Department of Defense;
   United States Army; US Army Research, Development & Engineering Command
   (RDECOM); US Army Research Laboratory (ARL)
RP Cao, LZ; Zhang, HD (corresponding author), Rochester Inst Technol, Golisano Coll Comp & Informat Sci, Sch Interact Games & Media, Lomb Mem Dr, Rochester, NY 14623 USA.
EM lc1248@rit.edu; hz2208@rit.edu
OI Zhang, Huadong/0000-0002-5488-5102
FU DOD [W911NF-16-2-0016]
FX AcknowledgementsThis work was supported by DOD grant W911NF-16-2-0016.
   We thank anonymous reviewers for their comments. We thank the people who
   participated in the user study.
CR [Anonymous], 2022, META USE QUEST LINK
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Cao LZ, 2021, VIRTUAL REAL-LONDON, V25, P597, DOI 10.1007/s10055-020-00477-z
   Cao LZ, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811550
   Cao LZ, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6040044
   Chatterjee I, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P131, DOI 10.1145/2818346.2820752
   Chun LM, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P59, DOI 10.1109/ICEEI.2015.7352470
   Creed C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376196
   Ferracani A., 2014, P 2014 ACM INT WORKS, P27
   Gao J, 2020, NEURAL COMPUT, V32, P829, DOI 10.1162/neco_a_01273
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887
   Hansberger JT, 2019, LECT NOTES COMPUT SC, V11574, P59, DOI 10.1007/978-3-030-21607-8_5
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jin T, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P377
   Kang RC, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357581
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kimani S, 2009, WIMP INTERFACES, P3529, DOI [10.1007/978-0-387-39940-9_467, DOI 10.1007/978-0-387-39940-9_467]
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Mariette J, 2018, BIOINFORMATICS, V34, P1009, DOI 10.1093/bioinformatics/btx682
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Mohan P., 2019, PROC 17 INT C VIRTUA, P1
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Peng C, 2017, P IEEE VIRT REAL ANN, P331, DOI 10.1109/VR.2017.7892311
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Reuten A, 2020, DRIV SIM C EUR, V2020, P1
   Schneider A, 2016, IEEE INT CONF INF VI, P390, DOI 10.1109/IV.2016.48
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Tsandilas T, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3182168
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Vanoni D, 2013, RES EXAM
   Villarreal-Narvaez S, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P855, DOI 10.1145/3357236.3395511
   Vogiazou Y, 2016, TOUCH DESIGNING EFFE
   Wang ZM, 2021, IEEE T HUM-MACH SYST, V51, P524, DOI 10.1109/THMS.2021.3097973
   Williams Adam S., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427330
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Zimmerer Chris, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P222, DOI 10.1145/3382507.3418850
NR 43
TC 3
Z9 3
U1 6
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25427
EP 25448
DI 10.1007/s11042-023-14381-6
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000924482400004
DA 2024-07-18
ER

PT J
AU Sridhar, B
AF Sridhar, B.
TI Authentication of video based on concatenated plane slicing layers
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concatenated plane slicing; Copyright protection; Multimedia security;
   Copyright marking; Discrete wavelet transform
ID WATERMARKING ALGORITHM; DIGITAL WATERMARKING; WAVELET; OWNERSHIP; DWT
AB Protection of digital contents yields more attention towards society. The proposed approach aims to authenticate the video based on the horizontal concatenation approach. Initially, the selected video frame isolates the luminance, chrominance red, and chrominance blue layers. Further, slice each layer and concatenate them slice horizontally. Now focus on the middle region concatenated layered image and introduce the single level wavelet transform. A watermark image is divided vertically and one of the portions is concealed with vertically half of the approximation band (LL1), it merged similarly another half of the watermark image with vertically half of the medium level band (LH1). In this approach, the different scaling factor values (alpha =0.1 and beta = 0.01) are used to achieve better PSNR. Apply the Inverse Discrete Wavelet Transform to bring back the normal concatenated frames. Next, group the luminance, chrominance red, and chrominance blue layers and stack to gain the marked video frame. Since this strategy is a non-blind technique, hence the copyright image can be established by using the same procedure of watermarked and non watermarked video frames. This approach aims to minimize the bit error rate and enhances the robustness.
C1 [Sridhar, B.] MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
C3 MLR Institute of Technology
RP Sridhar, B (corresponding author), MLR Inst Technol, Dept Elect & Commun Engn, Hyderabad, India.
EM sridharbece@gmail.com
RI Balakrishnan, Sridhar/AAA-4514-2021
OI Balakrishnan, Sridhar/0000-0002-3144-7468
CR Asikuzzaman Md, 2014, IEEE Transactions on Information Forensics and Security, V9, P1502, DOI 10.1109/TIFS.2014.2338274
   Busch C, 1999, IEEE COMPUT GRAPH, V19, P25, DOI 10.1109/38.736466
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Jie sang, 2020, Journal of Electronic Science and Technology, P1, DOI 10.1016/j.jnlest.2020.100052
   Khalil OH, 2020, IMAGING SCI J, V68, P90, DOI 10.1080/13682199.2020.1740431
   Leelavathy N., 2012, INT J MULTIDISCIP SC, V3, P12
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Mostafa K. S. A., 2016, J. Inf. Secur., V7, P260, DOI [10.4236/jis.2016.74021, DOI 10.4236/JIS.2016.74021]
   Mukherjee DP, 2004, IEEE T MULTIMEDIA, V6, P1, DOI 10.1109/TMM.2003.819759
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Qiao LT, 1998, J VIS COMMUN IMAGE R, V9, P194, DOI 10.1006/jvci.1998.0391
   Rajab Lama., 2009, EUR J SCI RES, V30, P389
   Reddy AA, 2005, PATTERN RECOGN LETT, V26, P1019, DOI 10.1016/j.patrec.2004.09.047
   Shukla Dolley, 2018, Radioelectronics and Communications Systems, V61, P1, DOI 10.3103/S0735272718010016
   Sridhar B, 2021, MULTIMED TOOLS APPL, V80, P8241, DOI 10.1007/s11042-020-09909-z
   Sridhar B., 2018, Pattern Recognition and Image Analysis, V28, P537, DOI 10.1134/S1054661818030203
   Sridhar B, 2015, LAT AM APPL RES, V45, P207
   Sridhar B., 2018, J AUTOM MOB ROBOT IN, V12, P68
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Thind DK, 2015, PROCEDIA COMPUT SCI, V46, P1661, DOI 10.1016/j.procs.2015.02.104
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Ye DP, 2007, APPL MATH COMPUT, V185, P907, DOI 10.1016/j.amc.2006.07.021
NR 28
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19657
EP 19673
DI 10.1007/s11042-023-14426-w
EA JAN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000922310300004
DA 2024-07-18
ER

PT J
AU Kumar, SPP
   Peter, KJ
   Kingsly, CS
AF Kumar, S. P. Predeep
   Peter, K. John
   Kingsly, C. Sahaya
TI De-noising and Demosaicking of Bayer image using deep convolutional
   attention residual learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color Filter Array interpolation; De-noising; De-mosaicking; Deep
   convolutional neural network; Honey Badger Algorithm; Deep residual
   learning
AB Nowadays, the resolution of image sensors in digital cameras is increased by minimizing the size of pixel sensors. As the size is reduced, the pixel sensor receives low light energy and becomes sensitive to thermal noise. The Color Filter Array (CFA) has a significant effect with the presence of noise, and the missing data is required to be reconstructed from the noisy data. This paper proposed a deep convolutional neural network with Honey Badger Algorithm (DCNN-HBA) for Bayer image de-noising. The deep CNN model is easily adopted and flexible for any CFA design with spatially varying color and exposures. After de-noising, attention-based deep residual learning (A-DRL) is applied to de-mosaicking the noise-free Bayer image. The channel attention is involved in which the network considers more relevant information and features. The proposed algorithm improves the quality of the image after reconstruction. The performance of the proposed work is evaluated with the performance metrics such as Peak Signal to Noise Ratio (PSNR), Color Peak Signal to Noise Ratio (CPSNR), Structural Similarity (SSIM), and Mean Structural Similarity (MSSIM) and compared with the traditional de-mosaicking approaches. By using our proposed work, the performance of PSNR, SSIM, CPSNR and MSSIM is improved by 43.23 dB, 0.997, 43.30 dB and 0.9975, respectively.
C1 [Kumar, S. P. Predeep] Viswajyothi Coll Engn & Technol, Dept Comp Sci & Engn, Muvattupuzha, Ernakulam, India.
   [Peter, K. John; Kingsly, C. Sahaya] Mangalam Coll Engn, Dept Comp Sci & Engn, Ettumanoor, Kottayam, India.
RP Kumar, SPP (corresponding author), Viswajyothi Coll Engn & Technol, Dept Comp Sci & Engn, Muvattupuzha, Ernakulam, India.
EM sppredeep@gmail.com; kjohnpeter@gmail.com; kingsly2k7@gmail.com
RI IRINS, Mangalam/KEE-7863-2024
CR Arbuj A, DEEP JOINT DENOISING
   Buades A, 2018, IEEE IMAGE PROC, P2172, DOI 10.1109/ICIP.2018.8451853
   Dong N, RESIDUAL CONTRASTIVE
   Elgendy OA, 2021, IEEE T COMPUT IMAG, V7, P137, DOI 10.1109/TCI.2021.3052694
   Guo S, 2021, IEEE T IMAGE PROCESS, V30, P6930, DOI 10.1109/TIP.2021.3100312
   Janjusevic N., 2021, ARXIV PREPRINT ARXIV
   Jayachandran S, 2017, CONTEMP CLIN DENT, V8, P193, DOI 10.4103/ccd.ccd_535_17
   Jin Q., 2020, IEEE C COMPUT VIS PA, P514
   John Peter K., 2017, INT J PRINT PACKAG A, V5, P729
   Khadidos AO, 2021, MULTIMEDIA SYST, V27, P807, DOI 10.1007/s00530-020-00707-z
   Kiku D, 2016, IEEE T IMAGE PROCESS, V25, P1288, DOI 10.1109/TIP.2016.2518082
   Kim Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174697
   Kokkinos F, 2018, LECT NOTES COMPUT SC, V11218, P317, DOI 10.1007/978-3-030-01264-9_19
   Ma K., 2022, ACM TRANSAC GRAPH TO, V41, P1
   Mihoubi S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113688
   Morrison AO, 2015, ARCH PATHOL LAB MED, V139, P1558, DOI 10.5858/arpa.2014-0315-RA
   Ni ZK, 2020, IEEE T IMAGE PROCESS, V29, P4952, DOI 10.1109/TIP.2020.2975978
   Qiao ZL, 2023, OPT LASER ENG, V160, DOI 10.1016/j.optlaseng.2022.107233
   Rafi Nazari M, 2017, THESIS U OTTAWA
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Sung Hee Park, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P860, DOI 10.1109/ACSSC.2009.5469990
   Syu NS, 2018, ARXIV
   Tan DS, 2018, IEEE T IMAGE PROCESS, V27, P2408, DOI 10.1109/TIP.2018.2803341
   Tan H, 2022, COMPUT INTEL NEUROSC
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Wang SY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093265
   Wang Y., 2021, P 2021 3 INT AC EXCH, P596
   Wu FF, 2021, NEUROCOMPUTING, V453, P369, DOI 10.1016/j.neucom.2020.09.090
   Ye W, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2482899
   Zhang C, 2016, IEEE T IMAGE PROCESS, V25, P5173, DOI 10.1109/TIP.2016.2601266
NR 30
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20323
EP 20342
DI 10.1007/s11042-023-14334-z
EA JAN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000920820100001
DA 2024-07-18
ER

PT J
AU Chen, Y
   Su, B
   Zeng, W
   Yuan, CZ
   Ji, B
AF Chen, Yang
   Su, Bo
   Zeng, Wei
   Yuan, Chengzhi
   Ji, Bing
TI Abnormal heart sound detection from unsegmented phonocardiogram using
   deep features and shallow classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heart sound; Phonocardiogram (PCG); Deep features; Deep neural network
   (DNN); Principal component analysis (PCA); Shallow classifiers
ID EMPIRICAL MODE DECOMPOSITION; WAVELET TRANSFORM; EEG SIGNALS;
   CLASSIFICATION; SYSTEM; RECOGNITION; PHYSIONET
AB Phonocardiogram (PCG) is commonly used as a diagnostic tool in ambulatory monitoring in order to evaluate cardiac abnormalities and detect cardiovascular diseases. Although cardiac auscultation is widely used for evaluation of cardiac function, the analysis of heart sound signals mostly depends on the clinician's experience and skills. There is growing demand for automatic and objective heart sound interpretation techniques. The objective of this study is to develop an automatic classification method for anomaly (binary and multi-class) detection of PCG recordings without any segmentation. A deep neural network (DNN) model is used on the raw data during the extraction of the features of the PCG inputs. Deep feature maps obtained from hierarchically placed layers in DNN are fed to various shallow classifiers for the anomaly detection, including support vector classifier (SVC), k-nearest neighbors (KNN), random forest (RF), gradient boosting (GB) classifier, decision tree (DT) classifier, quadratic discriminant analysis (QDA), and multi-layer perception (MLP). Principal component analysis (PCA) technique is used to reduce the high dimensions of feature maps.Finally, two famous heart sound databases, namely PhysioNet/Computing in Cardiology (CinC) Challenge heart sound database and heart valve disease (HVD) database, are used for evaluation. The databases are significantly different in terms of the tools used for data acquisition, clinical protocols, digital storages and signal qualities, making it challenging to process and analyze. By using the 10-fold cross-validation style, experimental results demonstrate that the proposed deep features with shallow classifiers yield highest performance with accuracy of 99.61% and 99.44% for binary and multi-class classification on the two databases, respectively. The results indicate that our method is effective for the detection of abnormal heart sound signals and outperforms other state-of-the-art methods.
C1 [Chen, Yang; Su, Bo; Zeng, Wei] Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Chen, Yang; Su, Bo; Zeng, Wei] Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou 350116, Peoples R China.
   [Yuan, Chengzhi] Univ Rhode Isl, Dept Mech, Ind & Syst Engn, Kingston, RI 02881 USA.
   [Ji, Bing] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
C3 Longyan University; Fuzhou University; University of Rhode Island;
   Shandong University
RP Zeng, W (corresponding author), Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.; Zeng, W (corresponding author), Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou 350116, Peoples R China.
EM zw0597@126.com
RI Zeng, Wei/AFO-2103-2022; Su, Bo/ABC-2881-2021
OI Su, Bo/0000-0002-1184-0828; JI, Bing/0000-0003-1326-4120
FU Natural Science Foundation of Fujian Province [2022J011146]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Fujian Province (Grant no. 2022J011146).
CR Al-Naami B, 2020, IEEE ACCESS, V8, P224852, DOI 10.1109/ACCESS.2020.3043290
   Alkhodari M, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2021.105940
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Castro A, 2013, IEEE ENG MED BIO, P3909, DOI 10.1109/EMBC.2013.6610399
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cheema A, 2019, APPL SOFT COMPUT, V77, P24, DOI 10.1016/j.asoc.2019.01.006
   Chen P, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101684
   Comert Z, 2020, MODELLING ANAL ACTIV, V1
   Deng MQ, 2020, NEURAL NETWORKS, V130, P22, DOI 10.1016/j.neunet.2020.06.015
   Deng SW, 2016, FUTURE GENER COMP SY, V60, P13, DOI 10.1016/j.future.2016.01.010
   Dominguez-Morales JP, 2018, IEEE T BIOMED CIRC S, V12, P24, DOI 10.1109/TBCAS.2017.2751545
   Er MB, 2021, APPL ACOUST, V180, DOI 10.1016/j.apacoust.2021.108152
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Feng W, 2019, IEEE J-STARS, V12, P2159, DOI 10.1109/JSTARS.2019.2922297
   Gavrovska A, 2017, COMPLEXITY, DOI 10.1155/2017/1580414
   Gavrovska A, 2016, PHYSIOL MEAS, V37, P1556, DOI 10.1088/0967-3334/37/9/1556
   Ghosh SK, 2020, COMPUT BIOL MED, V118, DOI 10.1016/j.compbiomed.2020.103632
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hassan AR, 2016, COMPUT METH PROG BIO, V137, P247, DOI 10.1016/j.cmpb.2016.09.008
   Huang BQ, 2013, J COMPUT APPL MATH, V240, P174, DOI 10.1016/j.cam.2012.07.012
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Humayun AI, 2020, IEEE J BIOMED HEALTH, V24, P2189, DOI 10.1109/JBHI.2020.2970252
   Khan KN, 2021, PHYSIOL MEAS, V42, DOI 10.1088/1361-6579/ac1d59
   Kobat MA, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108040
   Kramer O., 2013, Dimensionality Reduction with Unsupervised Nearest Neighbors, P13, DOI DOI 10.1007/978-3-642-38652-72
   Krishnan PT, 2020, PHYS ENG SCI MED, V43, P505, DOI 10.1007/s13246-020-00851-w
   Lau KW, 2003, PATTERN RECOGN, V36, P1913, DOI 10.1016/S0031-3203(03)00038-4
   Li JH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050472
   Liang QZ, 2015, J MED BIOL ENG, V35, P209, DOI 10.1007/s40846-015-0022-y
   Liu CY, 2016, PHYSIOL MEAS, V37, P2181, DOI 10.1088/0967-3334/37/12/2181
   Liu LH, 2010, INT CONF COMP SCI, P378, DOI 10.1109/ICCSIT.2010.5563893
   Messner E, 2018, IEEE T BIO-MED ENG, V65, P1964, DOI 10.1109/TBME.2018.2843258
   Murat F, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107473
   Murtagh F., 1991, NEUROCOMPUTING, V2, P183, DOI [10.1016/0925-2312(91)90023-5, DOI 10.1016/0925, DOI 10.1016/0925-2312(91)90023-5]
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Nishad A., 2018, J Ambient Intell Human Comput, DOI [10.1007/s12652-018-0867-3, DOI 10.1007/S12652-018-0867-3]
   Noman F, 2020, IEEE J BIOMED HEALTH, V24, P705, DOI 10.1109/JBHI.2019.2925036
   Oh SL, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105604
   Oliveira J, 2019, IEEE J-STSP, V13, P323, DOI 10.1109/JSTSP.2019.2908723
   Park C, 2011, NEUROCOMPUTING, V74, P867, DOI 10.1016/j.neucom.2010.07.030
   Patidar S, 2017, APPL SOFT COMPUT, V50, P71, DOI 10.1016/j.asoc.2016.11.002
   Renna F, 2019, IEEE J BIOMED HEALTH, V23, P2435, DOI 10.1109/JBHI.2019.2894222
   Rivera WA, 2016, EXPERT SYST APPL, V66, P124, DOI 10.1016/j.eswa.2016.09.010
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Salman A.H., 2016, Int. J. Electr. Comput. Eng, V6, P1, DOI 10.11591/ijece.v6i5.11344
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Soares E, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106449
   Springer DB, 2016, IEEE T BIO-MED ENG, V63, P822, DOI 10.1109/TBME.2015.2475278
   Srivastava S, 2007, J MACH LEARN RES, V8, P1277
   Talo M, 2019, ARTIF INTELL MED, V101, DOI 10.1016/j.artmed.2019.101743
   Tang H, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7070690
   Thiyagaraja SR, 2018, BIOMED SIGNAL PROCES, V45, P313, DOI 10.1016/j.bspc.2018.05.008
   Tuncer T, 2021, INFORM SCIENCES, V565, P91, DOI 10.1016/j.ins.2021.01.088
   Varghees VN, 2017, IEEE SENS J, V17, P3861, DOI 10.1109/JSEN.2017.2694970
   Wang QF, 2019, IEEE ACCESS, V7, P18450, DOI 10.1109/ACCESS.2019.2896409
   Xiao B, 2020, NEUROCOMPUTING, V392, P153
   Yaseen, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122344
   Ye J, 2004, ADV NEURAL INFORM PR, P1569
   Zabihi M, 2016, COMPUT CARDIOL CONF, V43, P613, DOI 10.22489/cinc.2016.180-213
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zeng W, 2021, ARTIF INTELL REV, V54, P6063, DOI 10.1007/s10462-021-09969-z
   Zeng W, 2021, ARTIF INTELL REV, V54, P1613, DOI 10.1007/s10462-020-09875-w
   Zhang D, 2011, INT J CARDIOL, V151, P126, DOI 10.1016/j.ijcard.2011.06.033
   Zhang WJ, 2019, BIOMED SIGNAL PROCES, V53, DOI 10.1016/j.bspc.2019.101560
   Zhao L, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18120430
NR 70
TC 3
Z9 3
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26859
EP 26883
DI 10.1007/s11042-022-14315-8
EA JAN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000913142700001
DA 2024-07-18
ER

PT J
AU Jadda, A
   Prabha, IS
AF Jadda, Amarendra
   Prabha, Inty Santi
TI Adaptive Weiner filtering with AR-GWO based optimized fuzzy wavelet
   neural network for enhanced speech enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE STFT-based noise estimation; NMF-based spectrum estimation; EMD; Weiner
   filter; FW-NN
ID LOW-RANK; ALGORITHM; MODEL; DECOMPOSITION; FRAMEWORK; MASKING; SPARSE
AB Speech signal enhancement is a subject of study in which a large number of researchers are working to improve the quality and perceptibility of speech signals. In the existing Kalman Filter method, the short-time magnitude or power spectrum due to random variations of noise was a serious problem and the signal-to-noise ratio was very low. This issue severely reduced the perceived qualityand intelligibility of enhanced speech. Thus, this paper intent to develop an improved speech enhancement model and it includes "training phase and testing phase ". In the training phase, the input noise corrupted signal is initially fed as input to both STFT-based noise estimation and NMF-based spectrum estimation forestimating the noise spectrum and signal spectrum, respectively. The obtained noise spectrum and the signal spectrum are fed as input to the Wiener filter and these filtered signals are subjected to Empirical Mean Decomposition (EMD).Since, tuning factor eta plays a key role in Wiener filter, it has to be determined for each signal and from the denoised signal the bark frequency is evaluated. The computed bark frequency is fed as input to the learning algorithm referred as Fuzzy Wavelet Neural Network (FW-NN)for detecting the suited tuning factor eta for the entire input signal in Wiener filter.An Adaptive Randomized Grey Wolf Optimization (AR-GWO) is proposed for proper tuning of the tuning factor eta referred as tuned tuning factor (eta(tuned)). The proposed AR-GWO is the improved version of standard Grey wolf optimization (GWO). In the testing phase, the training is accomplished initially and from which the tuning factor is gathered for each of the relevant input signal. Then, the properly tuned tuning factor (eta(tuned)) from FW-NN is fed as input to EMD via adaptive wiener filter for decomposing the spectral signal and the output of EMD is denoised enhanced speech signal. At last, the performance of the adopted approach is evaluated to the existing approaches in terms of various metrics. In particular, the computation time of the adopted AR-GWO model is 34.07%, 43.57%, 28.86%, 38.88%, and 16.03% better than the existing GA, ABC, PSO, FF, and GWO approaches respectively.
C1 [Jadda, Amarendra; Prabha, Inty Santi] Jawaharlal Nehru Technol Univ, Dept Elect & Commun Engn, Kakinada 533003, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Jadda, A (corresponding author), Jawaharlal Nehru Technol Univ, Dept Elect & Commun Engn, Kakinada 533003, Andhra Pradesh, India.
EM amarendrajadda0@gmail.com
CR Abel J, 2018, IEEE-ACM T AUDIO SPE, V26, P71, DOI 10.1109/TASLP.2017.2761236
   Arcos CD, 2018, ELECTRON LETT, V54, P317, DOI 10.1049/el.2017.2935
   Bai HC, 2018, CHINA COMMUN, V15, P235, DOI 10.1109/CC.2018.8456465
   Bando Y, 2018, IEEE-ACM T AUDIO SPE, V26, P215, DOI 10.1109/TASLP.2017.2772340
   Bao F, 2019, IEEE-ACM T AUDIO SPE, V27, P7, DOI 10.1109/TASLP.2018.2868407
   Chazan SE, 2016, IEEE-ACM T AUDIO SPE, V24, P2516, DOI 10.1109/TASLP.2016.2618007
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Fahad M, 2018, COMPUT ELECTR ENG, V70, P853, DOI 10.1016/j.compeleceng.2018.01.002
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Gannot S, 1998, IEEE T SPEECH AUDI P, V6, P373, DOI 10.1109/89.701367
   Garg A, 2020, PATTERN ANAL APPL, V23, P179, DOI 10.1007/s10044-018-00768-x
   GRIMBLE MJ, 1984, IEEE T AUTOMAT CONTR, V29, P552, DOI 10.1109/TAC.1984.1103581
   Grispino AS, 2013, IEEE LAT AM T, V11, P81, DOI 10.1109/TLA.2013.6502782
   Guido RC, 2007, NEUROCOMPUTING, V71, P174, DOI 10.1016/j.neucom.2007.08.010
   Guido RC, 2017, IEEE SIGNAL PROC MAG, V34, P89, DOI 10.1109/MSP.2017.2672759
   Guido RC, 2011, APPL MATH LETT, V24, P1257, DOI 10.1016/j.aml.2011.02.018
   Hamza D, 2021, INDONESIAN J ELECT E, V23, P821
   He Q, 2017, IEEE-ACM T AUDIO SPE, V25, P457, DOI 10.1109/TASLP.2016.2636445
   Hou JC, 2018, IEEE TETCI, V2, P117, DOI 10.1109/TETCI.2017.2784878
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Krawczyk M, 2014, IEEE-ACM T AUDIO SPE, V22, P1931, DOI 10.1109/TASLP.2014.2354236
   Krawczyk-Becker M, 2018, IEEE-ACM T AUDIO SPE, V26, P1140, DOI 10.1109/TASLP.2018.2816241
   Kuqi B, 2023, J SUSTAIN FINANC INV, V13, P92, DOI 10.1080/20430795.2021.1883986
   LeBlanc R, 2019, 2019 IEEE FIRST INTERNATIONAL CONFERENCE ON COGNITIVE MACHINE INTELLIGENCE (COGMI 2019), P16, DOI 10.1109/CogMI48466.2019.00012
   Lee J, 2018, IEEE SIGNAL PROC LET, V25, P1276, DOI 10.1109/LSP.2018.2849578
   Martín-Doñas JM, 2018, IEEE SIGNAL PROC LET, V25, P1680, DOI 10.1109/LSP.2018.2871419
   Ming J, 2017, IEEE-ACM T AUDIO SPE, V25, P531, DOI 10.1109/TASLP.2017.2651406
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369
   Ou SF, 2018, CHINESE J ELECTRON, V27, P827, DOI 10.1049/cje.2018.05.015
   Parente G, 2021, CHILDREN-BASEL, V8, DOI 10.3390/children8080620
   PRASANALAKSHMI B, 2019, INDIAN J SCI TECHNOL, V12, pNIL91, DOI DOI 10.17485/ijst/2019/v12i14/142792
   Rehr R, 2018, IEEE-ACM T AUDIO SPE, V26, P357, DOI 10.1109/TASLP.2017.2778151
   Samui S, 2019, APPL SOFT COMPUT, V74, P583, DOI 10.1016/j.asoc.2018.10.031
   Shao Y, 2011, IEEE T SYST MAN CY A, V41, P284, DOI 10.1109/TSMCA.2010.2069094
   Stahl J, 2018, IEEE-ACM T AUDIO SPE, V26, P436, DOI 10.1109/TASLP.2017.2779405
   Sun M, 2015, IEEE-ACM T AUDIO SPE, V23, P1233, DOI 10.1109/TASLP.2015.2427520
   Tan K, 2019, IEEE-ACM T AUDIO SPE, V27, P189, DOI 10.1109/TASLP.2018.2876171
   Tantibundhit C, 2010, IEEE T AUDIO SPEECH, V18, P1417, DOI 10.1109/TASL.2009.2035037
   utdallas, About us
   Wang J, 2018, CHINA COMMUN, V15, P141, DOI 10.1109/CC.2018.8357692
   Wang Y, 2018, IEEE-ACM T AUDIO SPE, V26, P580, DOI 10.1109/TASLP.2017.2786863
   Yilmaz S, 2010, IEEE T NEURAL NETWOR, V21, P1599, DOI 10.1109/TNN.2010.2066285
   Zheng NJ, 2019, IEEE-ACM T AUDIO SPE, V27, P63, DOI 10.1109/TASLP.2018.2870742
NR 48
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24101
EP 24125
DI 10.1007/s11042-022-14180-5
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000921144700001
PM 36532599
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Liu, FJ
   Hua, Z
   Li, JJ
   Fan, LW
AF Liu, Fangjin
   Hua, Zhen
   Li, Jinjiang
   Fan, Linwei
TI Dual UNet low-light image enhancement network based on attention
   mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low light enhancement; LBP algorithm; Double UNet; Attention model;
   Recursive calculation
ID QUALITY ASSESSMENT; SCALE
AB Low-light image enhancement has been an important research direction in the field of image processing. Recently, U-Net networks have shown better promise in low-light image enhancement. However, because of the semantic gap and the lack of connection between global contextual information in the U-shaped network, it leads to problems such as inaccurate color information in the enhanced images. To address the above problems, this paper proposes a Dual UNet low-light image enhancement network (DUAMNet) based on an attention mechanism. Firstly, the local texture features of the original image are extracted using the Local Binary Pattern(LBP) operator, and the illumination invariance of the LBP operator better maintains the texture information of the original image. Next, use the Brightness Enhancement Module(BEM). In the BEM module, the outer U-Net network captures feature information at different levels and luminance information of different regions, and the inner densely connected U-Net++ network enhances the correlation of feature information at different levels, mines more hidden feature information extracted by the encoder, and reduces the feature semantic gap between the encoder and decoder. The attention module Convolutional Block Attention Module(CBAM) is introduced in the decoder of U-Net++ network. CBAM further enhances the ability to model the global contextual information linkage and effectively improves the network's attention to the weak light region. The network adopts a progressive recursive structure. The entire network includes four recursive units, and the output of the previous recursive unit is used as the input of the next recursive unit. Comparative experiments are conducted on seven public datasets, and the results are analyzed quantitatively and qualitatively. The results show that despite the simple structure of the network in this paper, the network in this paper outperforms other methods in image quality compared to other methods.
C1 [Liu, Fangjin; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
   [Fan, Linwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University; Shandong University of Finance & Economics
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM huazhen@sdtbu.edu.cn; lijinjiang@gmail.com; fanlinwei@sdufe.edu.cn
RI Hua, Zhen/AGN-6068-2022; Fan, Linwei/ABG-8736-2021
OI Fan, Linwei/0000-0001-9986-2396
FU National Natural Science Foundation of China; Shandong Natural Science
   Foundation of China; Yantai science and technology innovation
   development plan;  [61772319];  [62002200];  [62176140];  [12001327]; 
   [ZR2021QF134];  [ZR2021MF068];  [2022JCYJ031]
FX AcknowledgmentsThe authors acknowledge the National Natural Science
   Foundation of China (61772319, 62002200, 62176140 and 12001327),
   Shandong Natural Science Foundation of China (ZR2021QF134 and
   ZR2021MF068), and Yantai science and technology innovation development
   plan (2022JCYJ031).
CR Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen X, 2021, MULTIMED TOOLS APPL, V80, P11313, DOI 10.1007/s11042-020-10406-6
   Chenxi Zhang, 2020, 2020 Second International Conference on Transdisciplinary AI (TransAI), P1, DOI 10.1109/TransAI49837.2020.00007
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li JJ, 2020, COMPUT VIS MEDIA, V6, P169, DOI 10.1007/s41095-020-0172-x
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lv FF, 2021, INT J COMPUT VISION, V129, P2175, DOI 10.1007/s11263-021-01466-8
   Ma JX, 2017, INT J MOD PHYS B, V31, DOI 10.1142/S0217979217440775
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ren XT, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351427
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   van den Heuvel TLA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200412
   Vaswani A, 2017, ADV NEUR IN, V30
   Vonikakis V, 2018, MULTIMED TOOLS APPL, V77, P9211, DOI 10.1007/s11042-017-4783-x
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang XW, 2018, SIGNAL IMAGE VIDEO P, V12, P685, DOI 10.1007/s11760-017-1208-2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, ARXIV
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Ying Z, 2017, ARXIV
   Zamir SW, 2021, NEUROCOMPUTING, V452, P37, DOI 10.1016/j.neucom.2021.04.076
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang TL, 2022, COMPUT VIS MEDIA, V8, P495, DOI 10.1007/s41095-021-0246-4
   Zhang YF, 2020, MULTIMED TOOLS APPL, V79, P9543, DOI 10.1007/s11042-019-08035-9
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhou SP, 2021, AAAI CONF ARTIF INTE, V35, P6039
   Zhou SP, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1322, DOI 10.1145/3343031.3351059
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhuang LY, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6029892
   Zibo Meng, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P327, DOI 10.1007/978-3-030-67070-2_20
NR 51
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24707
EP 24742
DI 10.1007/s11042-022-14210-2
EA DEC 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000893056800006
DA 2024-07-18
ER

PT J
AU Huo, H
   Yu, YL
   Liu, ZH
AF Huo, Hua
   Yu, YaLi
   Liu, ZhongHua
TI Facial expression recognition based on improved depthwise separable
   convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Expression recognition; Canny edge detection; Depthwise separable
   convolution; Inverted residual module
ID FACE
AB A single network model can't extract more complex and rich effective features. Meanwhile, the network structure is usually huge, and there are many parameters and consume more space resources, etc. Therefore, the combination of multiple network models to extract complementary features has attracted extensive attention. In order to solve the problems existing in the prior art that the network model can't extract high spatial depth features, redundant network structure parameters, and weak generalization ability, this paper adopts two models of Xception module and inverted residual structure to build the neural network. Based on this, a face expression recognition method based on improved depthwise separable convolutional network is proposed in the paper. Firstly, Gaussian filtering is performed by Canny operator to remove noise, and combined with two original pixel feature maps to form a three-channel image. Secondly, the inverted residual structure of MobileNetV2 model is introduced into the network structure. Finally, the extracted features are classified by Softmax classifier, and the entire network model uses ReLU6 as the nonlinear activation function. The experimental results show that the recognition rate is 70.76% in Fer2013 dataset (facial expression recognition 2013) and 97.92% in CK+ dataset (extended Cohn Kanade). It can be seen that this method not only effectively mines the deeper and more abstract features of the image, but also prevents network over-fitting and improves the generalization ability.
C1 [Huo, Hua; Yu, YaLi] Henan Univ Sci & Technol, Engn Technol Res Ctr Big Data & Computat Intellig, Kaiyuan Ave, Luoyang 471003, Henan, Peoples R China.
   [Liu, ZhongHua] Henan Univ Sci & Technol, Informat Engn Coll, Kaiyuan Ave, Luoyang 471003, Henan, Peoples R China.
C3 Henan University of Science & Technology; Henan University of Science &
   Technology
RP Huo, H (corresponding author), Henan Univ Sci & Technol, Engn Technol Res Ctr Big Data & Computat Intellig, Kaiyuan Ave, Luoyang 471003, Henan, Peoples R China.
EM pacific_huo@126.com; 2832438323@qq.com; lzhua_217@163.com
RI Wu, Wenli/IYJ-1598-2023; qi, li/JFE-7167-2023; Liu, Shao/JFK-0166-2023;
   zhang, wb/JGM-5316-2023; liu, lin/JFK-3401-2023; JIN,
   LIYING/JFB-1980-2023; Yan, Jing/JFA-6705-2023; Yang, Jing/JFK-4046-2023;
   li, jing/JEF-8436-2023; Liu, DY/JPL-4171-2023; .., What/IXW-6776-2023;
   Ma, Xiaodong/JAN-7473-2023; lu, qian/IUN-7445-2023; yan,
   xiao/JVP-0766-2024; Zhou, heng/JCN-6493-2023; Wang, He/JCO-3900-2023;
   li, wl/JJC-0768-2023; Liu, Ying/ISU-1216-2023; LI, QI/IUM-8577-2023; lu,
   yang/IWE-3635-2023; li, jincheng/GQP-6856-2022; Yang,
   Lili/JTT-5215-2023; liu, bing/JJD-5566-2023; Zhang,
   Jinfan/JPK-7588-2023; Zhang, Zhentao/JQV-7389-2023
OI Yang, Jing/0009-0004-8274-9863; Yang, Lili/0009-0008-2926-484X; Huo,
   Hua/0000-0001-9545-5443
FU National Natural Science Foundation of China [61672210]; National Key
   Research and Development Program of China [2017YFB 0306403]; Research
   Program of Foundation and Advanced Technology of Henan in China
   [162300410183]
FX This research is supported by the National Natural Science Foundation of
   China (61672210), the National Key Research and Development Program of
   China (2017YFB 0306403), and the Research Program of Foundation and
   Advanced Technology of Henan in China (162300410183).
CR Abasi S, 2020, COLOR RES APPL, V45, P632, DOI 10.1002/col.22494
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Darwin C., 1872, P374
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Gao J., 2021, Comput. Appl. Res, V38, P2213
   Ge HL, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2022.106621
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Han SF, 2021, NEUROPSYCHOLOGIA, V150, DOI 10.1016/j.neuropsychologia.2020.107700
   Hassan AK, 2020, DEF TECHNOL, V16, P1062, DOI 10.1016/j.dt.2019.12.006
   He J., 2018, COMPUT APPL RES, V35, P282
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Karthick S, 2021, MATER TODAY-PROC, V2, DOI [10.1016/j.matpr.2021.01.517, DOI 10.1016/J.MATPR.2021.01.517]
   Li HD, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106172
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Linhui Chen, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1220, DOI 10.1109/ICDAR.2019.00197
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   McIlhagga W, 2011, INT J COMPUT VISION, V91, P251, DOI 10.1007/s11263-010-0392-0
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Meng Q, 2020, SCI TOTAL ENVIRON, V710, DOI 10.1016/j.scitotenv.2019.135484
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Navabifar F., 2013, ADV SCI LETT, V19, P3520, DOI [10.1166/asl.2013.5231, DOI 10.1166/ASL.2013.5231]
   Niu X, 2014, J HUAZHONG NORMAL U, P335
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Opschoor JAA, 2020, ANAL APPL, V18, P715, DOI 10.1142/S0219530519410136
   Petersen P, 2018, NEURAL NETWORKS, V108, P296, DOI 10.1016/j.neunet.2018.08.019
   Ramírez-Revilla S, 2023, MRS COMMUN, V13, P55, DOI 10.1557/s43579-022-00311-4
   Rizzo L, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105433
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Saurav S, 2022, VISUAL COMPUT, V38, P1083, DOI 10.1007/s00371-021-02069-7
   Sharifara A, 2014, 2014 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P73, DOI 10.1109/ISBAST.2014.7013097
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Wang X, 2021, MIN METALL ENG, P126
   [王跃跃 Wang Yueyue], 2019, [测绘通报, Bulletin of Surveying and Mapping], P22
   Wei JS, 2022, MULTIMED TOOLS APPL, V81, P20643, DOI 10.1007/s11042-022-12360-x
   Xiao LW, 2022, MULTIMED TOOLS APPL, V81, P19051, DOI 10.1007/s11042-020-10107-0
   Xu LY, 2021, INT J AUTOM COMPUT, V18, P915, DOI 10.1007/s11633-021-1309-9
   Zhang T, 2019, J PHYS CONF SER, V1335, DOI 10.1088/1742-6596/1335/1/012018
NR 44
TC 7
Z9 7
U1 3
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18635
EP 18652
DI 10.1007/s11042-022-14066-6
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887890400001
PM 36467439
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Sabeti, V
   Aghabagheri, A
AF Sabeti, Vajiheh
   Aghabagheri, Adeleh
TI Developing an adaptive DCT-based steganography method using a genetic
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; JPEG images; Discrete cosine transform;
   Genetic algorithm
ID IMAGE STEGANOGRAPHY; SECRET INFORMATION; SPATIAL DOMAIN; JPEG IMAGES;
   OPTIMIZATION; FREQUENCY; CAPACITY; SCHEME
AB Steganography is an appropriate approach to establish a secure connection between the sender and the receiver. Data embedding in Discrete Cosine Transform (DCT) coefficients for JPEG images is one of the most practical approaches nowadays. In this paper, a new method called GA-Shield is proposed, in which, instead of using fixed embedding capacity, embedding a different number of bits in the quantized DCT coefficients according to the magnitude of the coefficient is used to spread bits of secret message in the most suitable coefficients. In addition, this method uses a genetic algorithm to minimize the distortion due to embedding. This minimization is performed by deciding on the best formula to calculate coefficient value after embedding. In this phase, PSNR is used as the metric to measure the amount of distortion in the cover image to produce the stego image. As these changes decrease, the value of PSNR would be optimized, and the stego image would have better quality. The proposed method can embed 300 to 20,000 bits of data (on average) in the cover image and produce the stego image with a PSNR value in the range of 65 to 40 and a SSIM value of more than 0.985. The consequences of comparisons with the state-of-the-art show that despite the fact that the proposed technique has less embedding capacity than some of the current ones, the superiority of stego image quality and security of the proposed technique, mainly at low embedding levels, is significant.
C1 [Sabeti, Vajiheh; Aghabagheri, Adeleh] Alzahra Univ, Fac Engineerning, Dept Comp Engn, Tehran 1993893973, Iran.
C3 Alzahra University
RP Sabeti, V (corresponding author), Alzahra Univ, Fac Engineerning, Dept Comp Engn, Tehran 1993893973, Iran.
EM v.sabeti@alzahra.ac.ir; adeleh.aghabagheri@gmail.com
OI sabeti, vajiheh/0000-0002-9985-9143
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Ansari Arshiya Sajid, 2017, International Journal of Image, Graphics and Signal Processing, V9, P14, DOI 10.5815/ijigsp.2017.06.02
   Attaby AA, 2018, AIN SHAMS ENG J, V9, P1965, DOI 10.1016/j.asej.2017.02.003
   Banharnsakun A, 2018, MULTIMED TOOLS APPL, V77, P27491, DOI 10.1007/s11042-018-5933-5
   Bansal D., 2014, International Journal of Computer Applications, V102, P46
   Baziyad M, 2021, MULTIMED TOOLS APPL, V80, P8611, DOI 10.1007/s11042-020-10008-2
   Bhattacharyya S, 2014, INT J COMPUT INF NET, V3, P40, DOI DOI 10.1023/B:VISI.0000029664.99615.94
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Eggers JJ, 2002, PROC SPIE, V4675, P26, DOI 10.1117/12.465284
   Evsutin O, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107811
   Evsutin O, 2018, MULTIMED TOOLS APPL, V77, P28567, DOI 10.1007/s11042-018-6055-9
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jiang CL, 2014, CIRC SYST SIGNAL PR, V33, P1611, DOI 10.1007/s00034-013-9703-3
   Kadhim IJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107481
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kaur A, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P990, DOI 10.1109/NGCT.2015.7375269
   Khamrui A., 2017, COMMUN COMPUT INFO S, V776, p577 584, DOI [10.1007/978-981-10-6430-2_45, DOI 10.1007/978-981-10-6430-2_45]
   Khan S., 2018, Int J Electric Comput Eng (IJECE), V8, P379, DOI [10.11591/ijece.v8i1.pp379-389, DOI 10.11591/IJECE.V8I1.PP379-389]
   Khan S, 2019, CMES-COMP MODEL ENG, V118, P529, DOI 10.31614/cmes.2019.06179
   Kumar KS, 2010, INT J ENG SCI TECHNO, V2, P3561
   Lima R., 2017, INT J COMPUT APPL, V164, P1, DOI 10.5120/ijca2017913686
   McAteer I, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020034
   Melman A, 2020, ARXIV
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   MK S., 2018, INT J ENG TECHNOLOGY, V7, P474, DOI [10.14419/ijet.v7i2.24.12139, DOI 10.14419/IJET.V7I2.24.12139]
   Nipanikar SI, 2018, ALEX ENG J, V57, P2343, DOI 10.1016/j.aej.2017.09.005
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Patel H., 2012, International Journal of Engineering Research and Applications, V2, P713
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pramanik S, 2020, MULTIMED TOOLS APPL, V79, P17463, DOI 10.1007/s11042-020-08676-1
   Roy R, 2015, PROCEDIA COMPUT SCI, V60, P468, DOI 10.1016/j.procs.2015.08.168
   Sabeti V., 2020, J SOFT COMPUT INFORM, V9, P55
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Shah PD, 2018, ADV INTELL SYST, V632, P119, DOI 10.1007/978-981-10-5520-1_12
   Tang WX, 2022, IEEE T CIRC SYST VID, V32, P4081, DOI 10.1109/TCSVT.2021.3115600
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wazirali R, 2019, IEEE ACCESS, V7, P133496, DOI 10.1109/ACCESS.2019.2941440
   Wedaj FT, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0206-1
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Xie JQ, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P934, DOI 10.1109/ISECS.2008.130
   Yu LF, 2009, SOFT COMPUT, V13, P393, DOI 10.1007/s00500-008-0327-7
NR 47
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19323
EP 19346
DI 10.1007/s11042-022-14166-3
EA NOV 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000884953400004
DA 2024-07-18
ER

PT J
AU Senalp, FM
   Orhan, B
   Ceylan, M
AF Senalp, Fatih Mehmet
   Orhan, Batuhan
   Ceylan, Murat
TI Cloud environment-based super resolution application for thermal images
   using the new approach TSRGAN plus model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud environment; Thermal imaging; Super resolution; Deep learning; New
   datasets
ID SUPERRESOLUTION
AB Thermal cameras can be used safely on living things because thermal camera systems provide harmless and contactless imaging. However, thermal cameras are high-cost systems, which limits their widespread usage. Therefore, low-cost thermal cameras facilitate the use of thermal imaging in different areas. Also, these thermal cameras can create blurry thermal images with low detail information. The purpose of this work is to provide an alternative to the high-cost problem and to create a system that can be easily accessed via the internet. Here, it is important to use super resolution techniques on these low quality images. In this study, a new dataset was created using two different thermal cameras. This dataset was obtained in different way from the datasets used in traditional image enhancement implementations. Here, the low-resolution thermal face images are obtained by means of the Flir One Pro (c) thermal camera, which can be easily integrated into the smartphone. The high-resolution (ground truth) thermal face images are obtained with the Variocam HD (c) thermal camera, which is an HD (high definition) thermal imaging system. In addition, the TSRGAN+ deep network model is proposed as a new approach for super resolution application on the new dataset. The obtained results were compared with state-of-the-art models using peak signal to noise ratio (PSNR) and structural similarity index measure (SSIM) image quality metrics. When the results were evaluated, it was observed that the success performance of the proposed model was superior to other models. Here, considering the PSNR and SSIM values, it was seen that the proposed model achieved approximately 0.5 dB and 6% more successful results than other models, respectively. After these studies, the proposed super resolution model was run in the cloud environment and the system can be easily accessed from anywhere through the developed Android interface software.
C1 [Senalp, Fatih Mehmet; Orhan, Batuhan; Ceylan, Murat] Konya Tech Univ, Dept Elect Elect Engn, Konya, Turkey.
C3 Konya Technical University
RP Senalp, FM (corresponding author), Konya Tech Univ, Dept Elect Elect Engn, Konya, Turkey.
EM fatih.senalp@gmail.com; bthnothan00@gmail.com; mceylan@ktunedu.tr
OI Senalp, Fatih Mehmet/0000-0001-7831-6724
FU Scientific Research Project Fund of Konya Technical University
   [201102001]; Scientific and Technological Research Council of Turkey
   (TUBITAK) [215E019]
FX This work is supported by the Scientific Research Project Fund of Konya
   Technical University under the project number 201102001.; This work is
   supported by the Scientific and Technological Research Council of Turkey
   (TUBITAK) under the project number 215E019.
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Anwar S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3390462
   Choi Y, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P223, DOI 10.1109/IROS.2016.7759059
   Chudasama V, 2020, IEEE COMPUT SOC CONF, P388, DOI 10.1109/CVPRW50498.2020.00051
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2016, IEEE T IMAGE PROCESS, V25, P2337, DOI 10.1109/TIP.2016.2542360
   Dosovitskiy A., 2016, Advances in Neural Information Processing Systems, P658
   Du WX, 2020, IEEE T INSTRUM MEAS, V69, P3566, DOI 10.1109/TIM.2019.2932175
   Fan ZL, 2018, NEUROCOMPUTING, V272, P396, DOI 10.1016/j.neucom.2017.07.017
   Fraiwan L, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0408-x
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu YC, 2020, MULTIMED TOOLS APPL, V79, P21815, DOI 10.1007/s11042-020-08980-w
   Guei AC, 2018, APPL OPTICS, V57, pD98, DOI 10.1364/AO.57.000D98
   Javaid H., 2013, THESIS BLEKINGE I TE
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Nguyen K, 2013, COMPUT VIS IMAGE UND, V117, P1526, DOI 10.1016/j.cviu.2013.06.010
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu SW, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2019), P1004, DOI [10.1109/SIPROCESS.2019.8868566, 10.1109/siprocess.2019.8868566]
   Mandanici E, 2019, APPL GEOMAT, V11, P215, DOI 10.1007/s12518-019-00253-y
   Ornek AH, 2019, INFRARED PHYS TECHN, V103, DOI 10.1016/j.infrared.2019.103044
   Radford A., 2015, ARXIV
   Rivadeneira RE, 2019, LECT NOTES COMPUT SC, V11663, P417, DOI 10.1007/978-3-030-27272-2_37
   Senalp FM, 2021, TRAIT SIGNAL, V38, P1361, DOI 10.18280/ts.380511
   Senalp FM, 2022, MULTIMED TOOLS APPL, V81, P9313, DOI 10.1007/s11042-021-11436-4
   Senalp FM., 2020, EUR J SCI TECHNOL, P131, DOI [10.31590/ejosat.802174, DOI 10.31590/EJOSAT.802174]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh K, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043015
   Sun L, 2022, LECT NOTES COMPUT SC, V13678, P412, DOI 10.1007/978-3-031-19797-0_24
   Toyran M., 2008, THESIS I SCI ISTANBU
   Voronin V, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P153, DOI 10.1109/SmartCloud.2018.00033
   Wang MX, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01073-6
   Yan R, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE-ROBIO 2021), P1129, DOI 10.1109/ROBIO54168.2021.9739390
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang XD, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082587
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18483
EP 18500
DI 10.1007/s11042-022-14169-0
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000884953400002
DA 2024-07-18
ER

PT J
AU Wang, WN
   Lin, K
AF Wang, Weina
   Lin, Kai
TI Information granule-based multi-view point sets registration using fuzzy
   c-means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view registration; Point set simplification; Information
   granulation; Fuzzy c-means clustering
ID AUTOMATIC REGISTRATION; EFFICIENT
AB This paper addresses the registration problem for multi-view point sets. Motivated by the formation of information granule and casting registration as a clustering task, an information granule-based multi-view point sets registration using fuzzy c-means clustering is proposed. Information granules are formed following the principle of justifiable granularity, and the data points covered by information granules can be obtained to represent the structural crux of the point set. The preprocessing step using information granule can achieve point set simplification and enhance the robustness of subsequent registration. Then, the aligned point sets involved in multi-view registration are clustered, and fuzzy clustering is used to solve the clustering problem and multi-view registration problem simultaneously. Membership function is introduced into the clustering-based registration, which improves the registration performance in comparison with other clustering-based methods with hard partition. Finally, the clustering and transformation estimation are alternately and iteratively applied to all point sets until the final clustering and registration results are obtained. Experiments using publicly benchmark datasets demonstrate that the proposed approach achieves better performance than the comparison approaches in terms of the accuracy and robustness for multi-view registration.
C1 [Wang, Weina; Lin, Kai] Jilin Inst Chem Technol, Coll Informat & Control Engn, Jilin 13022, Jilin, Peoples R China.
   [Lin, Kai] Suzhou Maxwell Technol Co Ltd, Laser Business Div, Suzhou 215200, Jiangsu, Peoples R China.
C3 Jilin Institute of Chemical Technology
RP Wang, WN (corresponding author), Jilin Inst Chem Technol, Coll Informat & Control Engn, Jilin 13022, Jilin, Peoples R China.
EM wangweina@jlict.edu.cn; 18222396001@163.com
RI lin, kai/KJL-3762-2024; Wang, Weina/ISR-9229-2023; Zhao,
   Chunxia/KBB-4190-2024
OI Wang, Weina/0000-0001-6773-7777; 
FU Natural Science Foundation of China [62266046]; Natural Science
   Foundation of Jilin Province, China [YDZJ202201ZYTS603]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 62266046 and the Natural Science Foundation of Jilin
   Province, China, under Grant YDZJ202201ZYTS603.
CR Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Arrigoni F, 2016, LECT NOTES COMPUT SC, V9908, P489, DOI 10.1007/978-3-319-46493-0_30
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574
   Cao HL, 2022, KNOWL-BASED SYST, V241, DOI 10.1016/j.knosys.2022.108182
   Castellani U, 2002, COMPUT VIS IMAGE UND, V87, P78, DOI 10.1006/cviu.2002.0984
   Chen H, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108431
   Chen H, 2020, IEEE T INSTRUM MEAS, V69, P9449, DOI 10.1109/TIM.2020.3003360
   Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997
   Evangelidis GD, 2018, IEEE T PATTERN ANAL, V40, P1397, DOI 10.1109/TPAMI.2017.2717829
   Ferrari V, 2022, IEEE T VIS COMPUT GR, V28, P1608, DOI 10.1109/TVCG.2020.3021534
   Fu KX, 2021, IEEE T MED ROBOT BIO, V3, P115, DOI 10.1109/TMRB.2021.3055020
   Govindu VM, 2014, IEEE T IMAGE PROCESS, V23, P1289, DOI 10.1109/TIP.2013.2246517
   Govindu VM, 2001, PROC CVPR IEEE, P218
   Guo R, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107321
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Hirose O, 2021, IEEE T PATTERN ANAL, V43, P2269, DOI 10.1109/TPAMI.2020.2971687
   Horaud R, 2011, IEEE T PATTERN ANAL, V33, P587, DOI 10.1109/TPAMI.2010.94
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   Levoy M, 2005, The stanford 3d scanning repository
   Li L, 2020, IEEE T CYBERNETICS, V50, P2097, DOI 10.1109/TCYB.2018.2845745
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Li ZY, 2020, NEUROCOMPUTING, V413, P230, DOI 10.1016/j.neucom.2020.06.102
   Liao QF, 2021, IEEE T PATTERN ANAL, V43, P3229, DOI 10.1109/TPAMI.2020.2978477
   Ma XK, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107345
   MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024
   Min Z, 2020, IEEE T AUTOM SCI ENG, V17, P334, DOI 10.1109/TASE.2019.2906391
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nüchter A, 2010, COMPUT VIS IMAGE UND, V114, P963, DOI 10.1016/j.cviu.2010.03.007
   Pan J, 2021, IEEE SENS J, V21, P11946, DOI 10.1109/JSEN.2020.3042665
   Pedrycz W, 2015, KNOWL-BASED SYST, V80, P98, DOI 10.1016/j.knosys.2014.12.030
   Pedrycz W, 2013, APPL SOFT COMPUT, V13, P4209, DOI 10.1016/j.asoc.2013.06.017
   Peng WX, 2022, IEEE T IND ELECTRON, V69, P1682, DOI 10.1109/TIE.2021.3059538
   Rusinkiewicz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323037
   Segal A., 2009, Robotics: Sci. Syst., V2, P161
   Sun L, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3145474
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Yong PA., 2021, INFORM SCIENTIST, V585, P209
   Zhang JY, 2022, IEEE T PATTERN ANAL, V44, P3450, DOI 10.1109/TPAMI.2021.3054619
   Zhu JH, 2020, IEEE T IMAGE PROCESS, V29, P9176, DOI 10.1109/TIP.2020.3024096
   Zhu JH, 2019, INFORM SCIENCES, V488, P205, DOI 10.1016/j.ins.2019.03.024
   Zhu JH, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.10.102104
NR 47
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17283
EP 17300
DI 10.1007/s11042-022-14250-8
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000884646000003
DA 2024-07-18
ER

PT J
AU Nezhad, NM
   Mirtaheri, SL
   Shahbazian, R
AF Nezhad, Narges Mohammadi
   Mirtaheri, Seyedeh Leili
   Shahbazian, Reza
TI Popular image generation based on popularity measures by generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image popularity; Generative adversarial network (GAN); Artificial
   intelligence; Deep learning; Image translation; Synthetic
ID GAN
AB We study image-to-image translation and synthetic image generation. There is still no developed model to create popular synthetic images based on the user's opinion in the fashion industry. This paper uses a combination of generative adversarial networks (GAN), deep learning, and user's opinions to create popular images. Our proposed model consists of two modules; one is a popularity module that estimates the intrinsic popularity of images without considering the effects of non-visual factors. The second one is a translation module that converts unpopular images into popular ones. Our model also performs multi-dimensional translation and multi-domain translation. We use the ResNet50 neural network as the default deep neural network in which the last layer is replaced with a fully connected layer. We use a new dataset collected from Instagram to train our network. We evaluate the performance of the proposed method by FID, LPIPS scores, and popularity index in different scenarios. The results show that our proposed method shows at least 60% and 25% improvement in terms of FID and LPIPS in color-to-color image translation. These improvements confirm the proposed method's generated images' quality and diversity. The evaluations on the popularity score also confirms that the content-based translation is more effective than style-based translation in terms of popularity.
C1 [Nezhad, Narges Mohammadi] Kharazmi Univ, Fac Math & Comp Sci, Dept Comp Sci, Tehran, Iran.
   [Mirtaheri, Seyedeh Leili] Kharazmi Univ, Elect, Comp Engn, Fac Engn, Tehran, Iran.
   [Shahbazian, Reza] Stand Res Inst, Elect Engn Res Grp, Fac Technol & Engn, Res Ctr, Alborz, Iran.
C3 Kharazmi University; Kharazmi University
RP Mirtaheri, SL (corresponding author), Kharazmi Univ, Elect, Comp Engn, Fac Engn, Tehran, Iran.
EM Mirtaheri@khu.ac.ir
RI Shahbazian, Reza/AEK-4782-2022; Shahbazian, Reza/GQG-9479-2022;
   Mirtaheri, Seyedeh Leili/HLV-9720-2023
OI Shahbazian, Reza/0000-0002-2313-6002; Shahbazian,
   Reza/0000-0002-2313-6002; 
CR Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Alec R, 2015, ARXIV
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2016, ARXIV
   Antreas A, 2017, ARXIV
   Bai J, 2020, VISUAL COMPUT, V36, P2145, DOI 10.1007/s00371-020-01943-0
   Chai CL, 2018, MULTIMED TOOLS APPL, V77, P22339, DOI 10.1007/s11042-018-5968-7
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ding KY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1979, DOI 10.1145/3343031.3351007
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gothwal R, 2014, 2014 3RD INTERNATIONAL CONFERENCE ON RELIABILITY, INFOCOM TECHNOLOGIES AND OPTIMIZATION (ICRITO) (TRENDS AND FUTURE DIRECTIONS)
   Hajarian M, 2017, COMPUT HUM BEHAV, V77, P282, DOI 10.1016/j.chb.2017.08.046
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hessel J, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P927, DOI 10.1145/3038912.3052684
   Hsu C.-C., 2017, arXiv
   Huang XW, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P172, DOI 10.1109/CICTA.2018.8706048
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jun-Yan Zhu, 2017, ARXIV
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma D. P., 2014, arXiv
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li N, 2018, IEEE ACCESS, V6, P54241, DOI 10.1109/ACCESS.2018.2870854
   Lin K, 2017, ARXIV
   Liu M, 2020, ARXIV
   Liu M. M., 2017, ARXIV
   Liu ZB, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P486, DOI 10.1109/MIPR.2019.00098
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Qian XL, 2021, IEEE SIGNAL PROC LET, V28, P180, DOI 10.1109/LSP.2021.3049997
   Rezende Danilo Jimenez, 2014, INT C MACH LEARN, V2, P2
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Salimans Tim, 2016, ARXIV
   Sohn K, 2015, ADV NEUR IN, V28
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian Y, 2018, ARXIV
   Wang CY, 2018, IEEE T IMAGE PROCESS, V27, P4066, DOI 10.1109/TIP.2018.2836316
   Wang W., 2021, ARXIV
   Xiaoming Y, 2019, ARXIV
   Yu XM, 2019, LECT NOTES COMPUT SC, V11365, P341, DOI 10.1007/978-3-030-20873-8_22
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng Z, 2020, MULTIMED TOOLS APPL, P1
NR 49
TC 0
Z9 0
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 20873
EP 20897
DI 10.1007/s11042-022-14090-6
EA NOV 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000879728900003
DA 2024-07-18
ER

PT J
AU Krobba, A
   Debyeche, M
   Selouani, SA
AF Krobba, Ahmed
   Debyeche, Mohamed
   Selouani, Sid Ahmed
TI A novel hybrid feature method based on Caelen auditory model and
   gammatone filterbank for robust speaker recognition under noisy
   environment and speech coding distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Caelen auditory model; Gammtone filter; Speech
   coding; Noise environment; GMM-UBM; I-vetcor G-PLDA
ID LINEAR PREDICTION; ADDITIVE NOISE; VERIFICATION; COEFFICIENTS;
   COMBINATION; PERFORMANCE
AB Currently, the majority of the state-of-the-art speaker recognition systems predominantly use short-term cepstral feature extraction approaches to parameterize the speech signals. In this paper, we propose new auditory features based Caelen auditory model that simulate the external, middle and inner parts of the ear and Gammtone filter for speaker recognition system, called Caelen Auditory Model Gammatone Cepstral Coefficients (CAMGTCC). The performances evaluations of the proposed feature are carried by the TIMIT and NIST 2008 corpus. The speech coding represent by Adaptive Multi-Rate wideband (AMR-WB) and noisy conditions using various noises SNR levels which are extracted from NOISEX-92. Speaker recognition system using GMM-UBM and i-vector-GPLDA modelling. The experimental results demonstrate that the proposed feature extraction method performs better compared to the Gammatone Cepstral Coefficients (GTCC) and Mel Frequency Cepstral Coefficients (MFCC) features. For speech coding distortion, the features extraction proposed improve the robustness of codec-degraded speech at different bit rates. In addition, when the test speech signals are corrupted with noise at SNRs ranging from (0 dB to 15 dB), we observe that CAMGTCC achieves overall equal error rate (EER) reduction of 10.88% to 6.8% relative, compared to baselines.
C1 [Krobba, Ahmed; Debyeche, Mohamed] Univ USTHB, Fac Elect Engn, Speech Commun & Signal Proc Lab, Algiers, Algeria.
   [Selouani, Sid Ahmed] Univ Moncton, LARIHS Lab, Campus Shappaing, Moncton, NB, Canada.
C3 University Science & Technology Houari Boumediene; University of Moncton
RP Krobba, A (corresponding author), Univ USTHB, Fac Elect Engn, Speech Commun & Signal Proc Lab, Algiers, Algeria.
EM hkrobba@gmail.com; mdebyeche@usthb.dz; selouani@umcs.ca
CR Abd El-Moneim S, 2020, MULTIMED TOOLS APPL, V79, P24013, DOI 10.1007/s11042-019-08293-7
   Al-Ali AKH, 2017, IEEE ACCESS, V5, P15400, DOI 10.1109/ACCESS.2017.2728801
   [Anonymous], 2010, PROC 5 INT C DESIGN
   Bellot O, 2000, 6 INT C SPOKEN LANGU
   CAELEN J, 1985, SPEECH COMMUN, V4, P163, DOI 10.1016/0167-6393(85)90044-5
   Chandra M, 2015, ADV INTELL SYST, V328, P529, DOI 10.1007/978-3-319-12012-6_58
   Chaouch H, 2019, SPEECH COMMUN, V108, P33, DOI 10.1016/j.specom.2019.02.002
   Chu Wai., 2003, Speech Coding Algorithms: Foundation and Evolution of Standardized Codecs, DOI DOI 10.1002/0471668850
   Dunn RB, 2001, CONF REC ASILOMAR C, P1562, DOI 10.1109/ACSSC.2001.987749
   Fedila M, 2018, MULTIMED TOOLS APPL, V77, P16721, DOI 10.1007/s11042-017-5237-1
   Fedila M., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1034, DOI 10.1109/ISSPA.2012.6310441
   Fernandez Gallardo L., 2016, HUMAN AUTOMATIC SPEA
   Ghitza O, 1994, IEEE T SPEECH AUDI P, V2, P115, DOI 10.1109/89.260357
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   Grassi S., 2000, Signal Processing X Theories and Applications. Proceedings of EUSIPCO 2000. Tenth European Signal Processing Conference, P437
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Johannesma P., 1972, The pre-response stimulus ensemble of neurons in the cochlear nucleusJ, P58
   Kadi KL, 2016, BIOCYBERN BIOMED ENG, V36, P233, DOI 10.1016/j.bbe.2015.11.004
   Kinnunen T, 2013, INTERSPEECH, P3121
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Krobba A, 2019, INT J SPEECH TECHNOL, V22, P1115, DOI 10.1007/s10772-019-09642-5
   Krobba A, 2019, MULTIMED TOOLS APPL, V78, P19525, DOI 10.1007/s11042-019-7154-y
   Li Q, 2011, IEEE T AUDIO SPEECH, V19, P1791, DOI 10.1109/TASL.2010.2101594
   Li ZQ, 2016, MULTIMED TOOLS APPL, V75, P7391, DOI 10.1007/s11042-015-2660-z
   Linguistic Data Consortium, 1990, DARPA TIMIT AC PHON
   Lyon R. F., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1282
   McCree A, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P941
   McLaren M, 2013, INTERSPEECH, P3665
   Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278
   NIST Year, 2008, SPEAK REC EV PLAN TE
   Peinado A., 2006, SPEECH RECOGNITION D
   Pohjalainen J, 2014, IEEE SIGNAL PROC LET, V21, P1516, DOI 10.1109/LSP.2014.2339632
   Rahman MH, 2018, COMPUT SPEECH LANG, V47, P240, DOI 10.1016/j.csl.2017.08.001
   Recommendation G, 2003, WID COD SPEECH 16 KB
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   Sadjadi S. O., 2013, Speech Lang. Process. Techn. Comm. Newsl, V1, P1
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Selouani SA, 2015, COMPUT SPEECH LANG, V31, P28, DOI 10.1016/j.csl.2014.11.003
   Selouani S. A., 2007, International Journal of Computers & Applications, V29, P143, DOI 10.2316/Journal.202.2007.2.202-1885
   Selouani SA., 2011, SPEECH PROCESSING SO, DOI [10.1007/978-1-4419-9685-5, DOI 10.1007/978-1-4419-9685-5]
   SENEFF S, 1988, J PHONETICS, V16, P55, DOI 10.1016/S0095-4470(19)30466-8
   Shabtai NR, 2011, APPL ACOUST, V72, P124, DOI 10.1016/j.apacoust.2010.09.009
   Sreenivasa RK, 2014, SPEECH PROCESSING MO
   Tan ZH, 2008, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84800-143-5
   Tan ZL, 2018, IEEE-ACM T AUDIO SPE, V26, P820, DOI 10.1109/TASLP.2018.2796843
   Valero X, 2012, IEEE T MULTIMEDIA, V14, P1684, DOI 10.1109/TMM.2012.2199972
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Vuppala AK, 2013, INT J SIGNAL IMAGING, V6, P130, DOI 10.1504/IJSISE.2013.054789
   Yu D, 2008, INT CONF ACOUST SPEE, P4041
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
NR 50
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16195
EP 16212
DI 10.1007/s11042-022-14068-4
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000874426100003
DA 2024-07-18
ER

PT J
AU Sharma, U
   Om, H
   Mishra, AN
AF Sharma, Usha
   Om, Hari
   Mishra, A. N.
TI HindiSpeech-Net: a deep learning based robust automatic speech
   recognition system for Hindi language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 1D-CNN; Convolutional neural network; Hindi language; Deep learning;
   Speech recognition
ID FEATURE-EXTRACTION
AB Automatic Speech Recognition (ASR) has become one of the major research areas over the past decade and gained a lot of interest. Their system implementation, adaptation to different languages and robustness in the performance are still some of the major challenges. Hindi is one of the most widely spoken languages in the world but it is a complex and resource-constraint language. Thus, speech recognition and classification systems need to be developed for Hindi language to spread the technology and to explore more communication means. But due to its language complexity than other languages and lack of standard databases, it is quite challenging to develop such systems. Deep learning is extensively used in different research fields and has proven its prominence to a broader extent. In this paper, a seven-layer 1D-convolutional neural network HindiSpeech-Net has been proposed to recognise different speech samples of the Hindi language in the respective category. A large dataset of 2400 speech samples in the Hindi language is collected in ten different classes in real-world conditions which is further accompanied by signal filtering and augmentation to enhance the dataset for making a robust model and avoid overfitting. The collected dataset is divided into training, validation and test set which were evaluated in different performance parameters. The trained HindiSpeech-Net model achieved an accuracy of 92.92% on the test set. The proposed framework is computationally less expensive, works in real-time and is suitable for implementation in embedded systems.
C1 [Sharma, Usha; Om, Hari] Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
   [Mishra, A. N.] Krishna Engn Coll, Ghaziabad 201001, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Sharma, U (corresponding author), Indian Inst Technol ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM ushasharma1529@gmail.com
RI Mishra, Achyuta Nand/AAC-7591-2021
CR Adiwijaya Aulia MN, 2017, 2017 5 INT C INFORM, DOI [10.1109/ICoICT.2017.8074689, DOI 10.1109/ICOICT.2017.8074689]
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006
   Bhatt S., 2018, 6 INT WORKSH SPOK LA, V1, P196, DOI DOI 10.21437/SLTU.2018-41
   Bhatt S, 2020, J INFORM OPTIM SCI, V41, P1333, DOI 10.1080/02522667.2020.1809091
   Dey A, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P891, DOI 10.1109/ICALIP.2014.7009923
   Dong XF, 2020, IEEE ACCESS, V8, P125714, DOI 10.1109/ACCESS.2020.3007906
   Dua M, 2019, NEURAL COMPUT APPL, V31, P6747, DOI 10.1007/s00521-018-3499-9
   Dua M, 2018, ENG SCI TECHNOL, V21, P389, DOI 10.1016/j.jestch.2018.04.005
   Farooq O, 2010, INT J WAVELETS MULTI, V8, P847, DOI 10.1142/S0219691310003845
   Ganapathiraju A, 2004, IEEE T SIGNAL PROCES, V52, P2348, DOI 10.1109/TSP.2004.831018
   Gaudani H, 2022, COMP STUDY ROBUST FE, P763
   Han W, 2020, INTERSPEECH, P3610, DOI 10.21437/Interspeech.2020-2059
   Ishizuka K, 2006, SPEECH COMMUN, V48, P1447, DOI 10.1016/j.specom.2006.06.008
   Kong QQ, 2019, IEEE-ACM T AUDIO SPE, V27, P1791, DOI 10.1109/TASLP.2019.2930913
   Kumar Ashok, 2021, International Journal of Information Technology, V13, P483, DOI 10.1007/s41870-020-00586-7
   Kumar A, 2021, J INTELL SYST, V30, P165, DOI 10.1515/jisys-2018-0417
   Kumar A, 2022, INT J SPEECH TECHNOL, V25, P67, DOI 10.1007/s10772-020-09757-0
   Kumar A, 2022, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09948-3
   KUMAR P, 2022, INDIAN J SCI TECHNOL, V15, P333, DOI DOI 10.17485/IJST/v15i8.2322
   Lee J, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8010150
   Li F, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0651-3
   Liu Z, 1998, J VLSI SIG PROC SYST, V20, P61, DOI 10.1023/A:1008066223044
   Mustafa MK, 2019, NEURAL COMPUT APPL, V31, P891, DOI 10.1007/s00521-017-3028-2
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Muzammel M, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100005
   Nanni L, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-00175-3
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Oh D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010428
   Onea D, 2019, INTERSPEECH, P2998, DOI 10.21437/Interspeech.2019-1390
   Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700
   Samudravijaya K, 2012, INDIAN LANGUAGE SPEE
   Sertolli B, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2021.101204
   Sharma Aditya, 2008, International Journal of Information and Communication Technology, V1, P373, DOI 10.1504/IJICT.2008.024008
   Sharmila Mishra AN, 2020, INT J ADV SCI TECHNO
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zahid S, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/209814
NR 39
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16173
EP 16193
DI 10.1007/s11042-022-14019-z
EA OCT 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000871515900002
DA 2024-07-18
ER

PT J
AU Sharma, N
   Singh, BM
   Singh, K
AF Sharma, Neelam
   Singh, B. M.
   Singh, Karan
TI Analysis of packet transmission protocols for multimedia applications of
   WBANs in cognitive behavioral therapy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forwarding function; Body area networks; Dissipated energy; Throughput;
   Gamification; Cognitive behavior therapy; Multimedia application
ID EFFICIENT ROUTING PROTOCOL; BODY SENSOR NETWORKS
AB Wireless body sensor networks may be defined as an aggregate of smart sensor nodes that are deployed in the human body primarily for remote health monitoring purposes. These characterize systems that monitor the daily routine activities of the host without having any adverse effect on the health of or hinder the activities of the individual. Such networks are quite efficient in the detection of health complications that may arise due to sustained comorbidities such as diabetes, asthma, heart attacks, etc. This makes them a highly desirable field of research: optimum models may serve well to bridge the demand gap in the medical healthcare field and ensure that patients can get quality healthcare in critical time frames. One of the medical subdomains that has the highest discrepancy of doctor to patient ratio is the psychotherapy discipline. The present work aims to suggest a packet transmission protocol that can be employed specifically in this field. Wireless body area networks, in the field of psychology, can be used in the discipline of cognitive-behavioral therapy. These sensor networks can manifest themselves as multimedia tools that can be used in elevated gameplay. This in turn can help with the emotional regulation of afflicted individuals. Since gamification of cognitive-behavioral therapy would produce optimum results when the model is fed appropriate real-time data, the establishment of a highly efficient, low-latency sensor network is required to make this multimedia application a success. The present article thus focuses on the enhancement of energy characteristics of the transmission protocol employed. To enhance system performance, a new packet transmission model has been proposed and presented. This is a keystone disadvantage in many of the existing methodologies for WBAN data transfer as well. A systematic comparison of the output characteristics of the multiple forwarding functions proposed therein has also been performed. The results produced as a consequence of these exercises indicate superior model performance in terms of both energy consumption and packet volume when compared to baselines such as the SIMPLE, ATTEMPT, iM-SIMPLE, etc.
C1 [Sharma, Neelam] Uttarakhand Tech Univ UTU, Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
   [Singh, B. M.] UTU, Coll Engn Roorkee COER, Dehra Dun, Uttarakhand, India.
   [Singh, Karan] Jawaharlal Nehru Univ JNU, Sch Comp & Syst Sci, Delhi, India.
C3 Uttarakhand Technical University; Uttarakhand Technical University;
   Jawaharlal Nehru University, New Delhi
RP Sharma, N (corresponding author), Uttarakhand Tech Univ UTU, Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
EM sharmaneelam2@gmail.com
CR Adibi S., 2015, MOBILE HLTH TECHNOLO
   Alam MM, 2014, SENSORS-BASEL, V14, P9153, DOI 10.3390/s140509153
   [Anonymous], 2002, WSNA '02
   Ghamari M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060831
   Guo C, 2010, CONSUM COMM NETWORK, P397
   Javaid N, 2013, PROCEDIA COMPUT SCI, V19, P224, DOI 10.1016/j.procs.2013.06.033
   Javaid N., 2014, RES J APPL SCI ENG T, V7, P603, DOI [10.19026/rjaset.7.296, DOI 10.19026/RJASET.7.296]
   Javaid N., 2013, RES J APPL SCI ENG T, V7, P123, DOI [10.19026/rjaset.7.229, DOI 10.19026/RJASET.7.229]
   Javaid N, 2015, COMPUT HUM BEHAV, V51, P1003, DOI 10.1016/j.chb.2014.10.005
   Latre Benoit., 2007, LOW DELAY PROTOCOL M, P1, DOI DOI 10.1109/MOBIQ.2007.4451060
   Manzoor B, 2013, PROCEDIA COMPUT SCI, V19, P926, DOI 10.1016/j.procs.2013.06.127
   Nabi M, 2010, P 5 INT C BOD AR NET, P77
   Nadeem Q, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON BROADBAND, WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2013), P221, DOI 10.1109/BWCCA.2013.42
   Quwaider M, 2009, ACM INT SYM MOB MAN, P149
   Quwaider M, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & COMMUNICATIONS (NETCOM 2009), P171, DOI 10.1109/NetCoM.2009.54
   Quwaider M, 2010, AD HOC NETW, V8, P824, DOI 10.1016/j.adhoc.2010.03.002
   Salehi SA, 2016, ASIA-PAC CONF COMMUN, P523, DOI 10.1109/APCC.2016.7581523
   Sapio Adrian, 2010, 2010 International Conference on Body Sensor Networks (BSN), P167, DOI 10.1109/BSN.2010.18
   Seo S-H, 2010, P 3 IEEE INT C BROAD, P1235
   Sharma N, 2021, CMC-COMPUT MATER CON, V69, P2459, DOI 10.32604/cmc.2021.014305
   Sharma N, 2018, J ENG SCI TECHNOL, V13, P196
   Tsouri GR, 2011, IEEE T BIOMED CIRC S, V5, P307, DOI 10.1109/TBCAS.2011.2160060
   Verma G., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1998/1/012019
   Watteyne T, 2007, P ICST 2 INT C BOD A
NR 24
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39765
EP 39781
DI 10.1007/s11042-022-13512-9
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000870110000002
DA 2024-07-18
ER

PT J
AU Li, HY
   Zhang, YS
   Bayramli, B
   Lu, HT
AF Li, Haiyan
   Zhang, Yangsong
   Bayramli, Bayram
   Lu, Hongtao
TI Arbitrary shape scene text detector with accurate text instance
   generation based on instance-relevant contexts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arbitrary shape text; Complete shape text instance formation; Text
   instance-relevant contextual representation; Text instance segmentation;
   Scene text detection
ID SEGMENTATION
AB Scene text detection methods based on deep segmentation techniques have achieved promising performances over the past years. However, there are still some challenges for accurately detecting arbitrary shape text instances, especially for those of pattern diversity. In this paper, we propose an arbitrary shape text detector that learns and combines instance-relevant contexts to generate accurate text instances of different patterns in scene images. Besides the instance-aware context, which is learned to distinguish adjacent text instances, the instance-relevant contexts also contain the instance shape-aware context learned by the shared segmentation-based subnet to indicate the distribution of text instances. The proposed instance formation algorithm then leverages the connectivity and the similarity of a text instance to segment the corresponding instance polygon, where the instance-relevant contexts guide the process to effectively separate dense text instances and robustly reconstruct complete arbitrary shape instances. Moreover, the formed instance polygons are refined with the local geometric features of text strokes predicted by a trainable regression-based subnet, which can help alleviate the effect of imprecise text pixel-level annotations for accurate boundary generation. Extensive experiments on four challenging datasets demonstrate the proposed method effectively improves the text detector's detection accuracy and robustness ability.
C1 [Li, Haiyan; Zhang, Yangsong; Bayramli, Bayram; Lu, Hongtao] Shanghai Jiao Tong Univ, MOE Key Lab Artificial Intelligence, AI Inst, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Li, Haiyan] Kashi Univ, Dept Comp Sci & Technol, Kashgar 844000, Peoples R China.
C3 Shanghai Jiao Tong University; Kashi University
RP Li, HY (corresponding author), Shanghai Jiao Tong Univ, MOE Key Lab Artificial Intelligence, AI Inst, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Li, HY (corresponding author), Kashi Univ, Dept Comp Sci & Technol, Kashgar 844000, Peoples R China.
EM lihaiyan_2016@sjtu.edu.cn; yangsong.zhang.zys@gmail.com;
   bayram_bai@sjtu.edu.cn; htlu@sjtu.edu.cn
FU Natural Science Foundation of Xinjiang Uygur Autonomous Region
   [2022D01A17]; NSFC [62176155]; Shanghai Municipal Science and Technology
   Major Project, China [2021SHZDZX0102]
FX This paper is supported by Natural Science Foundation of Xinjiang Uygur
   Autonomous Region(No.2022D01A17), NSFC(No.62176155), Shanghai Municipal
   Science and Technology Major Project, China, under grant no.
   2021SHZDZX0102. The authors would like to thank all editors and
   reviewers for their helpful suggestions and constructive comments.
CR Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Dai PW, 2021, PROC CVPR IEEE, P7389, DOI 10.1109/CVPR46437.2021.00731
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Deng GY, 2021, NEUROCOMPUTING, V453, P465, DOI 10.1016/j.neucom.2020.10.099
   Feng W, 2019, IEEE I CONF COMP VIS, P9075, DOI 10.1109/ICCV.2019.00917
   Guo XB, 2019, IEEE INT CON MULTI, P206, DOI 10.1109/ICME.2019.00044
   He DF, 2017, PROC CVPR IEEE, P474, DOI 10.1109/CVPR.2017.58
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Keserwani P, 2021, IEEE ACCESS, V9, P36802, DOI 10.1109/ACCESS.2021.3063030
   Li JC, 2021, IEEE COMPUT SOC CONF, P2349, DOI 10.1109/CVPRW53098.2021.00267
   Li JM, 2019, LECT NOTES COMPUT SC, V11364, P501, DOI 10.1007/978-3-030-20870-7_31
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YL, 2020, IEEE T IMAGE PROCESS, V29, P2918, DOI 10.1109/TIP.2019.2954218
   Liu YL, 2019, PATTERN RECOGN, V90, P337, DOI 10.1016/j.patcog.2019.02.002
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Lyu PY, 2018, LECT NOTES COMPUT SC, V11218, P71, DOI 10.1007/978-3-030-01264-9_5
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Moga AN, 1998, J PARALLEL DISTR COM, V51, P27, DOI 10.1006/jpdc.1998.1448
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Slimane F, 2013, PROC INT CONF DOC, P1433, DOI 10.1109/ICDAR.2013.289
   Song XG, 2020, LECT NOTES COMPUT SC, V11962, P201, DOI 10.1007/978-3-030-37734-2_17
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Tian ZT, 2019, PROC CVPR IEEE, P4229, DOI 10.1109/CVPR.2019.00436
   Wang H, 2020, AAAI CONF ARTIF INTE, V34, P12160
   Wang PF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1277, DOI 10.1145/3343031.3350988
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Xue CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P989
   Ye J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P516
   Yuliang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9806, DOI 10.1109/CVPR42600.2020.00983
   Zhang L, 2020, INT CONF ACOUST SPEE, P4272, DOI [10.1109/ICASSP40776.2020.9054213, 10.1109/icassp40776.2020.9054213]
   Zhang Shi-Xue, 2020, IEEE C COMPUTER VISI, P9699
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107336
NR 51
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17827
EP 17852
DI 10.1007/s11042-022-13897-7
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000870109900001
DA 2024-07-18
ER

PT J
AU Shyla, NSJ
   Emmanuel, WRS
AF Shyla, N. S. Jeya
   Emmanuel, W. R. Sam
TI Glaucoma detection and classification using modified level set
   segmentation and pattern classification neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Glaucoma classification; Machine learning (ML);
   Artificial intelligence (AI); Cup-to-disc ratio (Cdr); AlexNet;
   Sensitivity analysis
AB Glaucoma is a condition that causes lifelong visual loss, although it can be avoided if caught early. Computer vision-based techniques can effectively be applied to classify glaucoma stages with Machine Learning (ML) and Artificial Intelligence (AI) techniques. One of the most important elements in glaucoma diagnosis is the ratio of the optic disc to the cup. However, proper disc and cup segmentation remain a difficulty. In this work, new optic disc segmentation and classification techniques are proposed using deep learning and pattern classification neural networks. To perform optical disc segmentation, level set segmentation is used in the first stage in the resized input image. Further, AlexNet is used to perform classification for normal and glaucoma classes. Glaucoma images are further fed to a pattern recognition neural network to classify initial, moderate, or severe classes. Various statistical features and Cup-to-Disc Ratio (CDR) are used to train the neural network. This work is executed with DRISHTI-GS, LAG, and RIM-ONE databases. To validate the performance, sensitivity analysis is performed with different testing and training ratios. Metrics such as Accuracy, Sensitivity, Specificity, Precision, F1 score, and Kappa values are calculated. This work produced Accuracy, Sensitivity, and Specificity of 98.42, 97.6, and 97.5 respectively.
C1 [Shyla, N. S. Jeya; Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
   [Shyla, N. S. Jeya; Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Res Ctr, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Shyla, NSJ (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.; Shyla, NSJ (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Res Ctr, Tirunelveli 627012, Tamil Nadu, India.
EM shylagodwin@nmcc.ac.in; sam_emmanuel@nmcc.ac.in
RI EMMANUEL, W R SAM/E-5526-2018
CR Aamir M, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080602
   Abbas Q, 2017, INT J ADV COMPUT SC, V8, P41
   Afolabi OJ, 2021, IEEE ACCESS, V9, P47411, DOI 10.1109/ACCESS.2021.3068204
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Bokhari STF, 2018, CURR MED IMAGING REV, V14, P77, DOI 10.2174/1573405613666170405145913
   Cai WW, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102106
   Cai WW, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102076
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Dey A., 2016, J ADV MED MED RES, V11, P1, DOI DOI 10.9734/BJMMR/2016/19617
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   George Y, 2020, IEEE J BIOMED HEALTH, V24, P3421, DOI 10.1109/JBHI.2020.3001019
   Gothwal R, 2014, 2014 3RD INTERNATIONAL CONFERENCE ON RELIABILITY, INFOCOM TECHNOLOGIES AND OPTIMIZATION (ICRITO) (TRENDS AND FUTURE DIRECTIONS)
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   Kirar BS, 2017, 2017 INTERNATIONAL CONFERENCE ON RECENT INNOVATIONS IN SIGNAL PROCESSING AND EMBEDDED SYSTEMS (RISE), P315, DOI 10.1109/RISE.2017.8378173
   Krishnamoorthi N, 2019, MULTIMED TOOLS APPL, V78, P34247, DOI 10.1007/s11042-019-08249-x
   Li AN, 2016, IEEE ENG MED BIO, P1328, DOI 10.1109/EMBC.2016.7590952
   Li L, 2020, IEEE T MED IMAGING, V39, P413, DOI 10.1109/TMI.2019.2927226
   Parashar D, 2020, IEEE SENS J, V20, P12885, DOI 10.1109/JSEN.2020.3001972
   Routray S, 2018, OPTIK, V157, P503, DOI 10.1016/j.ijleo.2017.11.116
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Serener A, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P74, DOI 10.1109/tiptekno.2019.8894965
   Sharma AK, 2022, IEEE ACCESS, V10, P17920, DOI 10.1109/ACCESS.2022.3149824
   Thakoor KA, 2019, IEEE ENG MED BIO, P2036, DOI [10.1109/EMBC.2019.8856899, 10.1109/embc.2019.8856899]
   Verma SS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103272
   Vijapur NA, 2017, J MED BIOL ENG, V37, P365, DOI 10.1007/s40846-017-0234-4
NR 25
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15797
EP 15815
DI 10.1007/s11042-022-13892-y
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000865713700002
DA 2024-07-18
ER

PT J
AU Das, A
   Choudhuri, A
   Basu, A
   Sarkar, R
AF Das, Anubhab
   Choudhuri, Arka
   Basu, Arpan
   Sarkar, Ram
TI Generation of a synthetic handwritten Bangla compound character dataset
   using a modified conditional GAN architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Optical character recognition; Synthetic
   dataset generation; Bangla language; Compound characters; Handwritten
   text
ID IMAGE; RECOGNITION
AB Developing an Optical Character Recognition (OCR) system for handwtexts is a challenging research problem. Handwritten text can be largely different even for the same piece of text since the writing style differs from person to person. On the other hand, for many regional languages, unavailability of datasets having a large quantity of varied images is a hindrance for the research advancements. This is especially true for Bangla, which is the most widely spoken language of Bangladesh and the second most widely spoken language of India. Only a few works have been proposed for the generation of handwritten Bangla basic characters and almost none related to the generation of handwritten Bangla compound characters. To this end, in this work, a method for the generation of synthetic handwritten Bangla compound characters is proposed to alleviate this data scarcity. A generative adversarial network (GAN) based model is developed for this purpose taking inspiration from the recent Auxiliary Classifier GAN (AC-GAN) model. A novel dataset partitioning scheme is also developed for handwritten character related tasks to improve the performance of the model. The quality of generated samples is evaluated in terms of the Frechet Inception Distance (FID) metric. It is observed that the present model performs better in comparison to the basic AC-GAN architecture and also in comparison with some present GAN architectures. The sample dataset generated as a part of this work is publicly available at https://github.com/hachiro-2001/Bengah_Compound_Characters.
C1 [Das, Anubhab; Choudhuri, Arka; Basu, Arpan; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 Jadavpur University
RP Basu, A (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
EM anubhabdas33@yahoo.com; arkachoudhuri@live.com; arpan0123@gmail.com;
   ram.sarkar@jadavpuruniversity.in
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; Choudhuri, Arka/0000-0002-5719-2694
CR [Anonymous], 2016, ARXIV
   Basu A, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.6.063019
   Basu S, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P427
   Chang B, 2018, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2018.00028
   Chaudhuri BB, 1997, PROC INT CONF DOC, P1011, DOI 10.1109/ICDAR.1997.620662
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Davis B, 2020, ARXIV
   De R, 2020, IEEE SIGNAL PROC LET, V27, P1090, DOI 10.1109/LSP.2020.3003828
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guan MY, 2020, INT CONF FRONT HAND, P151, DOI 10.1109/ICFHR2020.2020.00037
   Hensel M, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Junyang Cai, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P178, DOI 10.1109/ICDAR.2019.00037
   Khan MM, 2022, J KING SAUD UNIV-COM, V34, P3356, DOI 10.1016/j.jksuci.2021.01.021
   Kingma D. P., 2014, arXiv
   Kingma DP, 2013, ARXIV
   Kundu S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112916
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Mondal R, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038277
   Odena A, 2017, PR MACH LEARN RES, V70
   Pal U, 2004, PATTERN RECOGN, V37, P1887, DOI 10.1016/j.patcog.2004.02.003
   Qian Z, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107453
   Radford A., 2015, ARXIV
   Roy S, 2017, PATTERN RECOGN LETT, V90, P15, DOI 10.1016/j.patrec.2017.03.004
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun D, 2017, ARXIV
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 31
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14775
EP 14797
DI 10.1007/s11042-022-13891-z
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864589600005
DA 2024-07-18
ER

PT J
AU Akhtar, MM
   Shatat, RSA
   Shatat, ASA
   Hameed, SA
   Alnajdawi, SI
AF Akhtar, Md Mobin
   Shatat, Raid Saleh Ali
   Shatat, Abdallah Saleh Ali
   Hameed, Shabi Alam
   Alnajdawi, Sakher (MA) Ibrahim
TI IoMT-based smart healthcare monitoring system using adaptive wavelet
   entropy deep feature fusion and improved RNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of medical things; Smart healthcare monitoring system; Adaptive
   wavelet entropy deep feature fusion; Convolutional neural network;
   Modified vulture satiation-based African vultures optimization
   algorithm; Recurrent neural network
ID INTERNET; INTELLIGENT; FRAMEWORK; THINGS; DEVICE; CLASSIFICATION
AB With the help of pervasive computing. human living has changed into a smarter way using the developments in IoMT, telecommunication technologies, and wearable sensors for ensuring improved healthcare services. IoMT is comprised of certain potentiality for the revolution in the healthcare industry. IoMT is associated with caregivers, healthcare providers, patients, and wearable sensors with software and ICT. The healthcare industry is also a well-known expanding market that has huge demands. It ensures the potential services towards the patients and also provides its contributions to the profits of the health sector. According to the technical advancements, a healthcare system must be developed based on decision-making capacity. Numerous researchers have also focused on involving cognitive behavior in IoT technology. Thus, in this paper, a new smart healthcare system with the help of loT devices is suggested. Initially, the data is collected from IoMT devices, which are fed to further processing. Secondly, the data pre-processing is carried out to remove the corrupted data and for removing the noise from the data. Thirdly, the features are collected from the pre-processed data through wavelet entropy computation, and deep features are gathered using CNN. Fourthly, both extracted wavelet entropy features and deep features have undergone an adaptive fusion process using an improved meta-heuristic algorithm, thus termed adaptive wavelet entropy deep feature fusion. Finally, the classification is performed through I-RNN to get the disease-related outcomes, where the weight of RNN is optimized using a new MVS-AVOA. Through the evaluation, the performance analysis of the proposed MVS-AVOA-RNN has 41.5% better than Naive Bayes, 26.8% better than SRU, 18.3% superior to LSTM, and 5.4% enriched than RNN. Thus, the obtained result reveals that the proposed optimized RNN with an advanced feature set supersedes the aforementioned techniques.
C1 [Akhtar, Md Mobin; Shatat, Raid Saleh Ali] Riyadh Elm Univ REU, Dept Basic Sci, Riyadh, Saudi Arabia.
   [Shatat, Abdallah Saleh Ali] Appl Sci Univ, Coll Adm Sci, Al Eker, Bahrain.
   [Hameed, Shabi Alam] Imam Muhammad IBN Saud Islamic Univ Riyadh, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Alnajdawi, Sakher (MA) Ibrahim] Appl Sci Univ, Business Management, Al Eker, Bahrain.
RP Akhtar, MM (corresponding author), Riyadh Elm Univ REU, Dept Basic Sci, Riyadh, Saudi Arabia.
EM mohammed.akhtar@riyadh.edu.sa
OI Alam, Shabi/0000-0002-7126-1561; Alnajdawi,
   Dr.Sakher/0000-0002-0152-7694; AKHTAR, MD. MOBIN/0000-0003-4654-5666;
   Shatat, Abdallah/0000-0002-2605-6358
CR Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   AlZubi AA, 2020, MEASUREMENT, V161, DOI 10.1016/j.measurement.2020.107887
   Balakrishnan N, 2021, OPT MEMORY NEURAL, V30, P80, DOI 10.3103/S1060992X21010094
   Cecil J., 2018, Informatics in Medicine Unlocked, V12, P128, DOI 10.1016/j.imu.2018.05.002
   Chen G, 2019, PERS UBIQUIT COMPUT
   Dwivedi Ruby, 2022, J Oral Biol Craniofac Res, V12, P302, DOI 10.1016/j.jobcr.2021.11.010
   Goswami P, 2023, NEURAL COMPUT APPL, V35, P22771, DOI 10.1007/s00521-021-06040-4
   Hajiheydari N, 2021, TECHNOL FORECAST SOC, V169, DOI 10.1016/j.techfore.2021.120807
   Hou GY, 2021, KSCE J CIV ENG, V25, P2779, DOI 10.1007/s12205-021-0565-0
   Huang XW, 2019, IEEE ACCESS, V7, P75276, DOI 10.1109/ACCESS.2019.2922059
   Jagadeeshwar TL, 2022, STRUCT HEALTH MONIT, V21, P2719, DOI 10.1177/14759217211073335
   Jain DK, 2021, IEEE SENS J, V21, P25517, DOI 10.1109/JSEN.2021.3091626
   Jain S, 2021, BIOSENS BIOELECTRON, V179, DOI 10.1016/j.bios.2021.113074
   Khan IA, 2022, FUTURE GENER COMP SY, V127, P181, DOI 10.1016/j.future.2021.09.010
   Khan SU, 2019, FUTURE GENER COMP SY, V98, P286, DOI 10.1016/j.future.2019.01.033
   Khan SR, 2020, FUTURE GENER COMP SY, V109, P360, DOI 10.1016/j.future.2020.03.054
   Khowaja SA, 2023, NEURAL COMPUT APPL, V35, P16175, DOI 10.1007/s00521-021-06434-4
   Kumar A, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107525
   Lu Y, 2019, FUTURE GENER COMP SY, V101, P1130, DOI 10.1016/j.future.2019.07.052
   Magacho EG, 2023, EVOL INTELL, V16, P247, DOI 10.1007/s12065-021-00652-4
   Manogaran G, 2021, IEEE J BIOMED HEALTH, V25, P3691, DOI 10.1109/JBHI.2021.3051288
   Meng WZ, 2021, IEEE INTERNET THINGS, V8, P16014, DOI 10.1109/JIOT.2021.3079461
   Nandy S, 2022, FUTURE GENER COMP SY, V130, P241, DOI 10.1016/j.future.2021.12.019
   Rachakonda L, 2020, IEEE T CONSUM ELECTR, V66, P115, DOI 10.1109/TCE.2020.2976006
   Rachakonda L, 2019, IEEE T CONSUM ELECTR, V65, P474, DOI 10.1109/TCE.2019.2940472
   Rajasekaran M, 2019, FUTURE GENER COMP SY, V98, P565, DOI 10.1016/j.future.2019.01.021
   Reddy Bojja G., 2021, AMCIS 2021 PROCEE, V31, P1761
   Sekhar A, 2022, IEEE J BIOMED HEALTH, V26, P983, DOI 10.1109/JBHI.2021.3100758
   Sharma DK, 2022, P 2 INT C MECH ENERG, V5, P331
   Soni M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5497120
   Subash TD, 2021, MATER TODAY-PROC, V43, P3549, DOI 10.1016/j.matpr.2020.09.816
   Syed L, 2019, FUTURE GENER COMP SY, V101, P136, DOI 10.1016/j.future.2019.06.004
   Tabjula JL, 2021, STRUCT CONTROL HLTH, V28, DOI 10.1002/stc.2690
   Tarikere S, 2021, BUS HORIZONS, V64, P799, DOI 10.1016/j.bushor.2021.07.015
   Tyagi SKS, 2022, IEEE T IND INFORM, V18, P5458, DOI 10.1109/TII.2021.3110963
   Yang F, 2021, IEEE INTERNET THINGS, V8, P15892, DOI 10.1109/JIOT.2021.3067905
   Yang SH, 2022, IEEE T ANTENN PROPAG, V70, P197, DOI 10.1109/TAP.2021.3098589
   Zhao K, 2020, IEEE T BIOMED CIRC S, V14, P985, DOI 10.1109/TBCAS.2020.3018711
NR 38
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17353
EP 17390
DI 10.1007/s11042-022-13934-5
EA SEP 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000863187900001
DA 2024-07-18
ER

PT J
AU Hwang, PS
   Ri, JH
   Yun, YH
AF Hwang, Pyong-Su
   Ri, Ju-Hyok
   Yun, Yong-Hun
TI Method for speeding up spatial error concealment using prediction mode
   of the neighboring blocks on H.264 video communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video communication; Error concealment(EC); Multi-directional
   interpolation(MDI)
ID ALGORITHM; INTERPOLATION
AB Error concealment can recover the video frame which has been corrupted by packet loss over error-prone channel, however, speeding up of error concealment is very important for various real-time applications such as video conferencing, video chatting, etc. A fast spatial error concealment method using prediction mode of the neighboring blocks is presented in this paper. First, the weighting values of edge prediction direction for sixteen 4 x 4 neighboring blocks are calculated considering prediction mode of the opposite neighboring blocks. Second, the significant edges within a corrupted macroblock(MB) are estimated using the sixteen weighting values of edge prediction direction. Finally, the approximations for each corrupted pixel are calculated along each significant edge, then a weighted average of multiple approximations is computed considering prediction mode of the neighboring blocks. Experimental results show that the proposed algorithm speeds up multi-directional interpolation up to 1.17 times while sacrificing image quality for about 0.01 dB on avaerage compared with the previous method.
C1 [Hwang, Pyong-Su; Ri, Ju-Hyok; Yun, Yong-Hun] Kim Il Sung Univ, Hightech Res & Dev Ctr, Inst Informat Technol, Pyongyang, North Korea.
RP Hwang, PS (corresponding author), Kim Il Sung Univ, Hightech Res & Dev Ctr, Inst Informat Technol, Pyongyang, North Korea.
EM ps.hwang0525@ryongnamsan.edu.kp
CR Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   Asheri H, 2012, IEEE T CONSUM ELECTR, V58, P880, DOI 10.1109/TCE.2012.6311331
   Byongsu H, 2019, MULTIMED TOOLS APPL, V78, P2587, DOI 10.1007/s11042-018-6362-1
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   Lee YH, 2017, J SIGNAL PROCESS SYS, V88, P13, DOI 10.1007/s11265-016-1112-y
   Li CX, 2016, COMM COM INF SC, V634, P35, DOI 10.1007/978-981-10-2260-9_5
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Nemethova O, 2005, 2005 International Conference on Wireless Networks, Communications and Mobile Computing, Vols 1 and 2, P1255
   Suh JW, 1997, IEEE T CONSUM ELECTR, V43, P295, DOI 10.1109/30.628616
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wu GL, 2010, IEEE T CIRC SYST VID, V20, P1409, DOI 10.1109/TCSVT.2010.2077471
   Xu YL, 2004, IEEE T CONSUM ELECTR, V50, P1135, DOI 10.1109/TCE.2004.1362510
   Ye SM, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P368
NR 13
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13733
EP 13743
DI 10.1007/s11042-022-13950-5
EA SEP 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190700001
DA 2024-07-18
ER

PT J
AU Izquierdo-Domenech, J
   Linares-Pellicer, J
   Orta-Lopez, J
AF Izquierdo-Domenech, Juan
   Linares-Pellicer, Jordi
   Orta-Lopez, Jorge
TI Towards achieving a high degree of situational awareness and multimodal
   interaction with AR and semantic AI in industrial applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Semantics; Deep learning; Industry; CNN;
   Transformers; Multimodal interaction
ID AUGMENTED REALITY; MAINTENANCE; SYSTEMS
AB With its various available frameworks and possible devices, augmented reality is a proven useful tool in various industrial processes such as maintenance, repairing, training, reconfiguration, and even monitoring tasks of production lines in large factories. Despite its advantages, augmented reality still does not usually give meaning to the elements it complements, staying in a physical or geometric layer of its environment and without providing information that may be of great interest to industrial operators in carrying out their work. An expert's remote human assistance is becoming an exciting complement in these environments, but this is expensive or even impossible in many cases. This paper shows how a machine learning semantic layer can complement augmented reality solutions in the industry by providing an intelligent layer, sometimes even beyond some expert's skills. This layer, using state-of-the-art models, can provide visual validation and new inputs, natural language interaction, and automatic anomaly detection. All this new level of semantic context can be integrated into almost any current augmented reality system, improving the operator's job with additional contextual information, new multimodal interaction and validation, increasing their work comfort, operational times, and security.
C1 [Izquierdo-Domenech, Juan; Linares-Pellicer, Jordi; Orta-Lopez, Jorge] Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Cami Vera S-N, E-46022 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Izquierdo-Domenech, J (corresponding author), Univ Politecn Valencia, Valencian Res Inst Artificial Intelligence VRAIN, Cami Vera S-N, E-46022 Valencia, Spain.
EM juaizdom@upv.es; jlinares@dsic.upv.es; jororlo2@upv.es
RI Orta-Lopez, Jorge/F-7649-2019; Linares-Pellicer, Jordi/G-2999-2015;
   Izquierdo-Domenech, Juan/AAC-5680-2019
OI Linares-Pellicer, Jordi/0000-0002-3315-1716; Izquierdo-Domenech,
   Juan/0000-0003-0076-7001
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Alexeev A, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8071104
   Baldauf Matthias., 2018, Proceedings of the 20th International Conference on human-computer interaction with mobile devices and services adjunct, P119
   Barakonyi I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P141, DOI 10.1109/ISMAR.2004.11
   Benbelkacem S, 2013, RENEW ENERG, V55, P428, DOI 10.1016/j.renene.2012.12.043
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Brooke J., 1996, USABILITY EVALUATION, P6
   Caudell T. P., 1992, P HAW INT C SYST SCI, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Chalapathy Raghavendra, 2019, ARXIV190103407
   Coli E, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.06517
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Drath R, 2014, IEEE IND ELECTRON M, V8, P56, DOI 10.1109/MIE.2014.2312079
   Garza LE, 2013, PROCEDIA COMPUT SCI, V25, P154, DOI 10.1016/j.procs.2013.11.019
   Elia V, 2016, EXPERT SYST APPL, V63, P187, DOI 10.1016/j.eswa.2016.07.006
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   González ANV, 2019, INT SYM MIX AUGMENT, P339, DOI 10.1109/ISMAR.2019.00032
   Gorecky D, 2014, IEEE INTL CONF IND I, P289, DOI 10.1109/INDIN.2014.6945523
   Guerreiro BV, 2018, LECT N MECH ENG, P161, DOI 10.1007/978-3-319-68619-6_16
   Hall, 1965, AD699616 NTIS STAND
   Jinyu L., 2019, VIRTUAL REAL INTELL, V1, P386, DOI DOI 10.1016/J.VRIH.2019.07.002
   Kagermann H., 2013, Final report of the Industrie 4.0 Working Group
   Kamat Pooja, 2020, E3S Web of Conferences, V170, DOI 10.1051/e3sconf/202017002007
   Lai ZH, 2020, J MANUF SYST, V55, P69, DOI 10.1016/j.jmsy.2020.02.010
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692
   Makris S, 2016, CIRP ANN-MANUF TECHN, V65, P61, DOI 10.1016/j.cirp.2016.04.038
   Mourtzis D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051855
   Ong SK, 2009, CIRP ANN-MANUF TECHN, V58, P139, DOI 10.1016/j.cirp.2009.03.020
   Pianta E, 2002, 1 INT C GLOB WORDNET, P293
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Raffel C, 2019, EXPLORING LIMITS TRA, DOI DOI 10.48550/ARXIV.1910.10683HTTPS://DOI.ORG/10.48550/ARXIV.1910.10683
   Rajpurkar P, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1606.05250
   Sanh V., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.01108
   Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Yu WH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P92
   Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935
   Zafrir O, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2111.05754
   Zonta T, 2020, COMPUT IND ENG, V150, DOI 10.1016/j.cie.2020.106889
NR 42
TC 5
Z9 5
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15875
EP 15901
DI 10.1007/s11042-022-13803-1
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000861190700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Kuznetsov, A
   Kononchenko, A
   Kryvinska, N
AF Kuznetsov, Alexandr
   Kononchenko, Anna
   Kryvinska, Natalia
TI Hiding data in vector images: software implementation and experimental
   research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Steganography; Vector graphic; Bezier curves; Javascript;
   Backend
ID WATERMARKING; SCHEME
AB In recent years, new steganographic methods have emerged to hide information in various multimedia files, such as images, videos, audio, text, and more. Such cover files, which are also called media or containers, are freely transmitted via the Internet, so they do not arouse any suspicion. An authorized person who has a secret steganographic key can restore the hidden message. This article discusses techniques for hiding data in vector images. Individual elements of vector graphics are represented through special mathematical objects (points, lines, curves, nodes, tangents, control points, etc.). These objects are used to hide information. But there is a problem, which lays in the fact, that affine vector image transformations can destroy a hidden message. In addition, hiding algorithms usually increase the size of vector image files, which is a certain unmasking feature. The main purpose of our study is to examine these problems. To do this, it is programmatically implemented data hiding and conducted a series of experiments. In particular, it is investigated various concealment techniques (bit method and pattern-based method). For different initial conditions, it is evaluated the resistance of hidden data to affine transformations, resizing of vector graphics files, performance, and so on. Based on the results of numerical experiments, it is substantiated the advantages and conditions of using the studied algorithms. To conduct the research, we have developed a cross-platform software implementation (JavaScript programming language), i.e. our scripts can be run on different types of platforms and browsers. Thus, the developed implementation can be used as a framework for individual web client applications, as well as for writing a backend of complex and professional tasks.
C1 [Kuznetsov, Alexandr; Kononchenko, Anna] Univ Macerata, Via Crescimbeni 30-32, I-62100 Macerata, Italy.
   [Kuznetsov, Alexandr] Kharkov Natl Univ, Svobody Sq 6, UA-61022 Kharkiv, Ukraine.
   [Kuznetsov, Alexandr] JSC Inst Informat Technol, Bakulin St 12, UA-61166 Kharkiv, Ukraine.
   [Kryvinska, Natalia] Comenius Univ, Bratislava 82005 25, Slovakia.
C3 University of Macerata; Ministry of Education & Science of Ukraine; VN
   Karazin Kharkiv National University; Comenius University Bratislava
RP Kryvinska, N (corresponding author), Comenius Univ, Bratislava 82005 25, Slovakia.
EM natalia.kryvinska@uniba.sk
RI Kuznetsov, Oleksandr/M-9769-2016; Kryvinska, Natalia/J-9160-2014
OI Kuznetsov, Oleksandr/0000-0003-2331-6326; Kryvinska,
   Natalia/0000-0003-3678-9229
FU National Research Foundation of Ukraine [2020.01/0351]
FX This work was supported in part by the National Research Foundation of
   Ukraine under Grant 2020.01/0351.
CR [Anonymous], 2018, MATH SOFTWARE ENG
   [Anonymous], 2021, Programming Languages by Age
   brilliant, AFF TRANSF BRILL MAT
   Cao LJ, 2015, SIGNAL IMAGE VIDEO P, V9, P1387, DOI 10.1007/s11760-013-0606-3
   Chattopadhyay S, 2023, MULTIMED TOOLS APPL, V82, P9693, DOI 10.1007/s11042-021-11839-3
   Chattopadhyay S, 2022, INT J INTELL SYST, V37, P3777, DOI 10.1002/int.22703
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   dev, 2019, TOP 5 REAS CHOOS JAV
   Dey S, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104585
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Farin G., 2000, The Essentials of CAGD
   Jang BJ, 2017, MULTIMED TOOLS APPL, V76, P16011, DOI 10.1007/s11042-016-3893-1
   Khan AH, 2022, EXP TECHNIQUES, V46, P335, DOI 10.1007/s40799-021-00470-4
   Kinzeryavyy Oleksiy, 2019, Advances in Computer Science for Engineering and Education. Advances in Intelligent Systems and Computing (AISC 754), P478, DOI 10.1007/978-3-319-91008-6_48
   Kinzeryavyy O, 2015, THESIS
   Kononchenko A, 2021, DIPLOMA PROJECT IMPL
   Kuznetsov Alexandr, 2021, 2021 IEEE 3rd Ukraine Conference on Electrical and Computer Engineering (UKRCON), P572, DOI 10.1109/UKRCON53503.2021.9575240
   Kuznetsov A, 2021, 2021 IEEE 16 INT C C, P171
   Liangbin Zheng, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P699, DOI 10.1109/IASP.2010.5476177
   Peng F, 2019, IEEE T INF FOREN SEC, V14, P2400, DOI 10.1109/TIFS.2019.2899520
   pomax, 2013, PRIMER BEZIER CURVES
   Qin JH, 2019, IEEE ACCESS, V7, P171372, DOI 10.1109/ACCESS.2019.2955452
   Schöttle P, 2016, IEEE T INF FOREN SEC, V11, P760, DOI 10.1109/TIFS.2015.2509941
   sciencedirect, BEZ CURV OV SCIENCED
   w3, BAS SHAP SVG 1 1
   w3, SCALABLE VECTOR GRAP
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   WebStorm, JETBRAINS
   Weisstein E. W.., AFFINE TRANSFORMATIO
   Wu D, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 3, P385, DOI 10.1109/CMC.2009.86
NR 30
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14581
EP 14607
DI 10.1007/s11042-022-13829-5
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863188000005
DA 2024-07-18
ER

PT J
AU Hanif, M
   Tonazzini, A
   Hussain, SF
   Habib, U
   Salerno, E
   Savino, P
   Halim, Z
AF Hanif, Muhammad
   Tonazzini, Anna
   Hussain, Syed Fawad
   Habib, Usman
   Salerno, Emanuele
   Savino, Pasquale
   Halim, Zahid
TI Blind bleed-through removal in color ancient manuscripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bleed-through; Segmentation; Gaussian mixture model; Color space
ID IMAGE SEGMENTATION; SPACES; CLASSIFICATION; SEPARATION; ALGORITHM; MODEL
AB Archaic manuscripts are an important part of ancient civilization. Unfortunately, such documents are often affected by various age related degradations, which impinge their legibility and information contents, and destroy their original look. In general, these documents are composed of three layers of information: foreground text, background, and unwanted degradation in the form of patterns interfering with the main text. In this work, we are presenting a color space based image segmentation technique to separate and remove the bleed-through degradation in digital ancient manuscripts. The main theme is to improve their readability and restore their original aesthetic look. For each pixel, a feature vector is created using color spectral and spatial location information. A pixel based segmentation method using Gaussian Mixture Model (GMM) is employed, assuming that each feature vector corresponds to a Gaussian distribution. Based on this assumption, each pixel is supposed to be drawn from a mixture of Gaussian distribution, with unknown parameters. The Expectation-Maximization (EM) approach is then used to estimate the unknown GMM parameters. The appropriate class label for each pixel is then estimated using posterior probability and GMM parameters. Unlike other binarization based document restoration method where the focus is on text extraction, we are more interested in restoring the aesthetically pleasing look of the ancient documents.The experimental results validate the usefulness of proposed method in terms of successful bleed-through identification and removal, while preserving foreground-text and background information.
C1 [Hanif, Muhammad; Tonazzini, Anna; Salerno, Emanuele; Savino, Pasquale] CNR, Ist Sci & Tecnol Informaz, Via G Moruzzi 1, I-56124 Pisa, Italy.
   [Hanif, Muhammad; Hussain, Syed Fawad; Habib, Usman; Halim, Zahid] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi 23640, Pakistan.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); GIK
   Institute Engineering Science & Technology
RP Hanif, M (corresponding author), CNR, Ist Sci & Tecnol Informaz, Via G Moruzzi 1, I-56124 Pisa, Italy.; Hanif, M (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi 23640, Pakistan.
EM muhammad.hanif@giki.edu.pk; anna.tonazzini@isti.cnr.it;
   fawadsyed@gmail.com; Usmanhabib@giki.edu.pk;
   Emanuele.Salerno@isti.cnr.it; Pasquale.Savino@isti.cnr.it;
   zahid.halim@giki.edu.pk
RI Salerno, Emanuele/A-2137-2010
OI Salerno, Emanuele/0000-0002-3433-3634; Hanif,
   Muhammad/0000-0002-9236-5263; Hussain, Syed Fawad/0000-0001-9122-6029
CR Alata O, 2009, COMPUT VIS IMAGE UND, V113, P867, DOI 10.1016/j.cviu.2009.03.001
   [Anonymous], 2018, PATTERN RECOGN, V81, P224
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Busin L, 2008, ADV IMAG ELECT PHYS, V151, P65, DOI 10.1016/S1076-5670(07)00402-8
   Cai XH, 2017, J SCI COMPUT, V72, P1313, DOI 10.1007/s10915-017-0402-2
   Cappé O, 2009, J ROY STAT SOC B, V71, P593, DOI 10.1111/j.1467-9868.2009.00698.x
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Fadoua D, 2006, LECT NOTES COMPUT SC, V3872, P38
   Galerne B, 2017, SIAM J IMAGING SCI, V10, P1446, DOI 10.1137/16M1109047
   Hanif M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050068
   Huang Y, 2010, IEEE T IMAGE PROCESS, V19, P2646, DOI 10.1109/TIP.2010.2048971
   Jurio A, 2010, COMM COM INF SC, V81, P532
   Leedham G, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P244, DOI 10.1109/IWFHR.2002.1030917
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Moghaddam RF, 2010, IEEE T PATTERN ANAL, V32, P1347, DOI 10.1109/TPAMI.2009.141
   Moghaddam RF, 2009, INT J DOC ANAL RECOG, V11, P183, DOI 10.1007/s10032-008-0076-2
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Park SH, 1998, PATTERN RECOGN, V31, P1061, DOI 10.1016/S0031-3203(97)00116-7
   Pastor-Pellicer J, 2015, LECT NOTES COMPUT SC, V9095, P115, DOI [10.1007/978-3-319-19222-2_10, 10.1007/978-3-319-19222_10]
   Peng X., 2019, P 2019 INT C DOC AN, P45
   Rani NS, 2022, AUTOMATIKA-UK, V63, P378, DOI 10.1080/00051144.2022.2042462
   Rotaru C, 2008, J REAL-TIME IMAGE PR, V3, P311, DOI 10.1007/s11554-008-0078-9
   Rowley-Brooke Roisin, 2012, Theory and Practice of Digital Libraries. Second International Conference, TPDL 2012. Proceedings: LNCS 7489, P185, DOI 10.1007/978-3-642-33290-6_21
   Rowley-Brooke R, 2013, PROC CVPR IEEE, P2954, DOI 10.1109/CVPR.2013.380
   Ruiz-Ruiz G, 2009, COMPUT ELECTRON AGR, V68, P88, DOI 10.1016/j.compag.2009.04.009
   Shi ZX, 2004, INT C PATT RECOG, P473, DOI 10.1109/ICPR.2004.1334167
   Sun B, 2016, IEEE T IMAGE PROCESS, V26, P5702, DOI 10.1109/TIP.2016.2614133
   Tensmeyer C, 2020, SN comput. sci, V1, P173
   Tonazzini A, 2006, IEEE T IMAGE PROCESS, V15, P473, DOI 10.1109/TIP.2005.860323
   Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V7, P17, DOI 10.1007/s10032-004-0121-8
   Tonazzini A, 2007, INT J DOC ANAL RECOG, V10, P17, DOI 10.1007/s10032-006-0015-z
   Tonazzini A, 2010, IEEE T IMAGE PROCESS, V19, P912, DOI 10.1109/TIP.2009.2038814
   Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0
   Wolf C, 2010, IEEE T PATTERN ANAL, V32, P431, DOI 10.1109/TPAMI.2009.33
   Zhang XT, 2020, APPL MATH MODEL, V81, P844, DOI 10.1016/j.apm.2020.01.020
   Zhao JY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106968
NR 37
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12321
EP 12335
DI 10.1007/s11042-022-13755-6
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000860416900002
DA 2024-07-18
ER

PT J
AU Tepe, T
   Tüzün, H
AF Tepe, Tansel
   Tuzun, Hakan
TI Investigating the effects of low-cost head-mounted display based virtual
   reality environments on learning and presence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Head-mounted display; Learning in virtual reality
   environments; Presence; User experience
ID DESK-TOP; EDUCATION; HMD; SIMULATIONS; IMPACTS; GAME; VR
AB In this study, it is aimed to reduce the cost of using virtual reality (VR) in education by using low-cost wireless VR devices. In this direction, the effect of low-cost VR environments developed for head-mounted displays (HMD) on learning and to what extent the presence is created in virtual environments within the scope of the "Fire and Emergency Situations" course was examined. In addition, student experiences in VR environments were investigated. Multimedia design principles were used while developing the VR environments. Adopted embedded experimental research design was used in the study. The study was carried out with 2 experimental groups and a comparison group, a total of 96 students, 32 in each. Experimental group 1 participated in both of teacher-centered direct instruction and VR implementations, experimental group 2 participated only in VR implementations, and comparison group only participated in teacher-centered direct instruction. A fire knowledge test was applied to all students before and after the implementations. The "Presence Questionnaire in Virtual Environments" and "Three-Dimensional Virtual Learning Environments Evaluation Scale" were applied to the experimental groups after the implementations. Moreover, students' opinions about VR implementations were obtained through semi-structured interviews. After the implementations, the achievement of the experimental groups and comparison group increased statistically. VR implementations have created a high level of presence for all students in the experimental groups. The participants expressed positive opinions about implementations. VR implementations reduce the risk factors that can be encountered in authentic life and can be useful in the acquisition of kinesthetic skills.
C1 [Tepe, Tansel] Turkish Airlines, Directorate Flight Operat, Istanbul, Turkey.
   [Tuzun, Hakan] Hacettepe Univ, Dept Comp Educ & Instruct Technol, Ankara, Turkey.
C3 Turkish Airlines; Hacettepe University
RP Tepe, T (corresponding author), Turkish Airlines, Directorate Flight Operat, Istanbul, Turkey.
EM tepetansel@gmail.com; htuzun@hacettepe.edu.fr
RI Tuzun, Hakan/A-9833-2008
OI Tuzun, Hakan/0000-0003-1153-5556; TEPE, TANSEL/0000-0003-3576-6172
CR Ahmad A, 2015, P INTCESSI5 2 INT C, P421
   Alexander B., 2004, EDUCAUSE, P29
   Antonietti A, 2001, J COMPUT ASSIST LEAR, V17, P142, DOI 10.1046/j.0266-4909.2001.00167.x
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2134
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Chen YL, 2016, ASIA-PAC EDUC RES, V25, P637, DOI 10.1007/s40299-016-0293-2
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Concannon BJ, 2019, FRONT EDUC, V4, DOI 10.3389/feduc.2019.00080
   Creswell J. W., 2007, DESIGNING CONDUCTING
   De Lucia A, 2009, COMPUT EDUC, V52, P220, DOI 10.1016/j.compedu.2008.08.001
   Fraenkel J.R., 2012, How to design and evaluate research in education, V8th
   Freina L, 2015, PROC EUR CONF GAME, P195
   Gamberini L, 2003, ERGONOMICS, V46, P842, DOI 10.1080/0014013031000111266
   Gil OLF, 2016, LECT NOTES COMPUT SC, V9753, P137, DOI 10.1007/978-3-319-39483-1_13
   Grassini S, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030007
   Grechkin TY, 2014, IEEE T VIS COMPUT GR, V20, P596, DOI 10.1109/TVCG.2014.18
   Hsu KS, 2016, EURASIA J MATH SCI T, V12, P1477
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Huang W, 2022, INTERACT LEARN ENVIR, V30, P100, DOI 10.1080/10494820.2019.1641525
   Huang W, 2021, COMPUT APPL ENG EDUC, V29, P1420, DOI 10.1002/cae.22393
   Hwang WY, 2013, COMPUT EDUC, V62, P308, DOI 10.1016/j.compedu.2012.10.005
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Kartiko I, 2010, COMPUT EDUC, V55, P881, DOI 10.1016/j.compedu.2010.03.019
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Kong XTR, 2017, COMPUT EDUC, V111, P144, DOI 10.1016/j.compedu.2017.04.009
   LANIER J, 1992, J COMMUN, V42, P150, DOI 10.1111/j.1460-2466.1992.tb00816.x
   Lee DY, 2013, COMPUT EDUC, V61, P193, DOI 10.1016/j.compedu.2012.10.001
   Liaw SS, 2010, COMPUT EDUC, V54, P446, DOI 10.1016/j.compedu.2009.08.029
   Lim T, 2017, INT J GAME-BASED LEA, V7, P57, DOI 10.4018/IJGBL.2017010104
   Lincoln, 1985, NATURALISTIC INQUIRY, P289, DOI DOI 10.1016/0147-1767(85)90062-8
   Mayer R.E., 2005, The Cambridge Handbook of Multimedia Learning, DOI [DOI 10.1017/CBO9780511816819.016, 10.1017/CBO9781139547369.017, DOI 10.1017/CBO9781139547369]
   McGonigle D., 1998, TECHTRENDS, V43, P23, DOI [10.1007/BF02824051, DOI 10.1007/BF02824051]
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Merriam S. B., 2001, Revised and expanded from case study research in education
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Ong SK, 2004, COMPUT EDUC, V43, P361, DOI 10.1016/j.compedu.2003.12.001
   Pachler N, 2010, INT J MOB BLENDED LE, V2, P1, DOI 10.4018/jmbl.2010010101
   Radianti Jaziar, 2020, Computers & Education, V147, P18, DOI 10.1016/j.compedu.2019.103778
   Ramachandiran CR, 2015, ELECTRON J E-LEARN, V13, P357
   Rangelova S, 2018, PRESENCE-TELEOP VIRT, V27, P15, DOI 10.1162/PRES_a_00318
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Rüppel U, 2011, ADV ENG INFORM, V25, P600, DOI 10.1016/j.aei.2011.08.001
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Serif T, 2005, PERS UBIQUIT COMPUT, V9, P238, DOI 10.1007/S00779-004-0325-4
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Shin DH, 2013, BEHAV INFORM TECHNOL, V32, P203, DOI 10.1080/0144929X.2011.606334
   Shu Y, 2019, VIRTUAL REAL-LONDON, V23, P437, DOI 10.1007/s10055-018-0376-x
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Sousa Santos B, 2009, MULTIMED TOOLS APPL, V41, P161, DOI 10.1007/s11042-008-0223-2
   Sun KT, 2010, INT J SCI MATH EDUC, V8, P689, DOI 10.1007/s10763-009-9181-z
   Tan YH, 2020, IEEE SYST MAN CYBERN, V6, P46, DOI 10.1109/MSMC.2019.2948654
   Tepe T., 2018, WORLD J ED TECHNOL C, V10, P241, DOI [10.18844/wjet.v10i4.4085, DOI 10.18844/WJET.V10I4.4085]
   Tüzün H, 2016, COMPUT EDUC, V94, P228, DOI 10.1016/j.compedu.2015.12.005
   Valentine A, 2021, AUSTRALAS J EDUC TEC, V37, P119, DOI 10.14742/ajet.5487
   Veneziano L, 1997, AM J HEALTH BEHAV, V21, P67
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu B, 2020, BRIT J EDUC TECHNOL, V51, P1991, DOI 10.1111/bjet.13023
   Xu XH, 2016, AM J DISTANCE EDUC, V30, P27, DOI 10.1080/08923647.2016.1119621
   Yang JC, 2010, COMPUT EDUC, V55, P1346, DOI 10.1016/j.compedu.2010.06.005
   Zhang YX, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P631, DOI [10.1109/VRW50115.2020.0-109, 10.1109/VRW50115.2020.00166]
   Zydney JM, 2016, COMPUT EDUC, V94, P1, DOI 10.1016/j.compedu.2015.11.001
NR 66
TC 2
Z9 2
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14307
EP 14327
DI 10.1007/s11042-022-13794-z
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000855612200024
DA 2024-07-18
ER

PT J
AU Aouraghe, I
   Khaissidi, G
   Mrabti, M
AF Aouraghe, Ibtissame
   Khaissidi, Ghizlane
   Mrabti, Mostafa
TI A literature review of online handwriting analysis to detect Parkinson's
   disease at an early stage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Parkinson's disease assessment; On-line handwriting analysis; Graphic
   tablet; Dysgraphia; Kinematics; Fine motor control; Survey
ID MILD COGNITIVE IMPAIRMENT; DISTORTED VISUAL FEEDBACK; NEUROPSYCHIATRIC
   SYMPTOMS; ALZHEIMERS-DISEASE; KINEMATIC ANALYSIS; DRAWING MOVEMENTS;
   STROKE SIZE; CLASSIFICATION; DIAGNOSIS; REPRESENTATION
AB Parkinson's disease (PD) affects millions of people worldwide, it dramatically affects the brain areas' structure and functions. Therefore, it causes a progressive decline of cognitive, functional and behavioral abilities. These changes in the brain result in the degradation of motor skills' performances. Handwriting is a daily task combining cognitive, kinesthetic and perceptual-motor abilities. Thus, any change in the brain areas affects directly on the aspects of handwriting. For this purpose, many researchers have studied the possibility of using the handwriting alterations caused by PD as diagnostic signs, in order to develop an autonomic and reliable Diagnosis Aid System which could strongly detect this pathology at an early stage. This intelligent system could help in assessing and controlling the evolution of PD, and consequently, in the improvement of the patients' quality of life. This paper aims at presenting a literature review of the most relevant studies conducted in the area of the on line handwriting analysis, in order to support PD. Starting by the typical followed procedure which consists of handwriting data acquisition, used materiel, proposed tasks, feature extraction, and finally data analysis. Indeed, according to all the investigated studies, dynamic handwriting analysis is a powerful, noninvasive, and low-cost tool to effectively diagnosis PD. In conclusion of the paper, future directions and open issues are highlighted.
C1 [Aouraghe, Ibtissame; Khaissidi, Ghizlane; Mrabti, Mostafa] USMBA Fez, Lab LIPI ENS, Fes, Morocco.
   [Aouraghe, Ibtissame] EMSI, SMARTiLab, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Aouraghe, I (corresponding author), USMBA Fez, Lab LIPI ENS, Fes, Morocco.; Aouraghe, I (corresponding author), EMSI, SMARTiLab, Rabat, Morocco.
EM aouraghe.ibtissame@gmail.com; ghizlane.derkaouil@hotmail.com;
   mostafa.mrabti@yahoo.fr
RI KHAISSIDI, Ghizlane/HDM-7213-2022
OI KHAISSIDI, Ghizlane/0000-0002-7380-147X; Aouraghe,
   Ibtissame/0000-0002-2371-1011
CR Aarsland D, 2009, J NEUROL NEUROSUR PS, V80, P928, DOI 10.1136/jnnp.2008.166959
   Afonso LCS, 2019, FUTURE GENER COMP SY, V94, P282, DOI 10.1016/j.future.2018.11.054
   Ammour A, 2020, COMPUT METH PROG BIO, V183, DOI 10.1016/j.cmpb.2019.07.007
   Angelillo MT, 2019, IEEE SYS MAN CYBERN, P835, DOI 10.1109/SMC.2019.8914157
   [Anonymous], 2017, IGS2017
   Aouraghe I, 2019, P NEW CHALLENGES DAT, P1
   Aouraghe I, 2020, J NEUROSCI METH, V339, DOI 10.1016/j.jneumeth.2020.108727
   Aouraghe I, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1923-0
   Arnulf I, 2012, MOVEMENT DISORD, V27, P677, DOI 10.1002/mds.24957
   Ayenu-Prah A, 2010, ADV DATA SCI ADAPT, V2, P1, DOI 10.1142/S1793536910000367
   Barone P, 2009, MOVEMENT DISORD, V24, P1641, DOI 10.1002/mds.22643
   Bashir M, 2012, J SIGNAL PROCESS SYS, V68, P75, DOI 10.1007/s11265-011-0576-z
   Bhidayasiri R., 2012, MOVEMENT DISORDERS V, P4, DOI DOI 10.1007/978-1-60327-426-5_2
   Bidet-Ildei C, 2011, HUM MOVEMENT SCI, V30, P783, DOI 10.1016/j.humov.2010.08.008
   Borson S, 2000, INT J GERIATR PSYCH, V15, P1021, DOI 10.1002/1099-1166(200011)15:11<1021::AID-GPS234>3.0.CO;2-6
   Broderick MP, 2009, EXP BRAIN RES, V197, P223, DOI 10.1007/s00221-009-1925-z
   Broeder S, 2014, NEUROSCIENCE, V263, P193, DOI 10.1016/j.neuroscience.2014.01.019
   Caligiuri MP, 2006, HUM MOVEMENT SCI, V25, P510, DOI 10.1016/j.humov.2006.02.004
   Chen HL, 2015, TRANSL NEURODEGENER, V4, DOI 10.1186/2047-9158-4-1
   Cobbah WGK., 2000, C PROCEED EUROMICRO, V2, P414
   Contreras-Vidal JL, 1998, ARTIF INTELL MED, V13, P57, DOI 10.1016/S0933-3657(98)00004-9
   Cookson MR, 2017, DISEASE-MODIFYING TARGETS IN NEURODEGENERATIVE DISORDERS: PAVING THE WAY FOR DISEASE-MODIFYING THERAPIES, P157
   de Boer JF, 2003, OPT LETT, V28, P2067, DOI 10.1364/OL.28.002067
   De Stefano C, 2019, PATTERN RECOGN LETT, V121, P37, DOI 10.1016/j.patrec.2018.05.013
   Diaz M, 2019, PATTERN RECOGN LETT, V128, P204, DOI 10.1016/j.patrec.2019.08.018
   Dorsey ER, 2018, JAMA NEUROL, V75, P9, DOI 10.1001/jamaneurol.2017.3299
   Drotár P, 2016, ARTIF INTELL MED, V67, P39, DOI 10.1016/j.artmed.2016.01.004
   Drotar P, 2015, IEEE INT SYM MED MEA, P344, DOI 10.1109/MeMeA.2015.7145225
   Drotár P, 2015, IEEE T NEUR SYS REH, V23, P508, DOI 10.1109/TNSRE.2014.2359997
   Drotár P, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707378
   Drotár P, 2014, COMPUT METH PROG BIO, V117, P405, DOI 10.1016/j.cmpb.2014.08.007
   Drotár P, 2013, IEEE INT C BIOINF BI, DOI 10.1109/BIBE.2013.6701692
   Eichhorn TE, 1996, MOVEMENT DISORD, V11, P289, DOI 10.1002/mds.870110313
   Elgh E, 2009, EUR J NEUROL, V16, P1278, DOI 10.1111/j.1468-1331.2009.02707.x
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   Fucetola R, 1997, ACTA PSYCHOL, V95, P255, DOI 10.1016/S0001-6918(96)00043-1
   Golshani L, 2009, INFORM SCIENCES, V179, P2426, DOI 10.1016/j.ins.2009.03.002
   Gupta U, 2020, COMPUT METH PROG BIO, V189, DOI 10.1016/j.cmpb.2019.105305
   Haas BR, 2012, TRANSL NEURODEGENER, V1, DOI 10.1186/2047-9158-1-11
   Hopfner F, 2019, DGN K 2019, P320
   HUGHES AJ, 1992, J NEUROL NEUROSUR PS, V55, P181, DOI 10.1136/jnnp.55.3.181
   Ibtissame A, 2017, INTERNET OBJETS, V17, P1
   Ibtissame A, 2017, AUTOMATIC ANAL ON LI
   Impedovo D, 2014, LECT N BIOINFORMAT, V8452, P137, DOI 10.1007/978-3-319-09042-9_10
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Impedovo D, 2019, IEEE SIGNAL PROC LET, V26, P632, DOI 10.1109/LSP.2019.2902936
   Impedovo D, 2019, IEEE REV BIOMED ENG, V12, P209, DOI 10.1109/RBME.2018.2840679
   Isenkul Muhammed, 2014, 2 INT C E HLTH TELEM, V5, P171, DOI DOI 10.13140/RG.2.1.1898.6005
   Jackson W, 2015, DIGITAL PAINTING TEC, P53
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jankovic J., 2003, Neurological Disease and Therapy, V59, P71
   Jenkinson C, 1997, AGE AGEING, V26, P353, DOI 10.1093/ageing/26.5.353
   Jerkovic VM, 2019, BIOMED ENG-BIOMED TE, V64, P187, DOI 10.1515/bmt-2017-0148
   Kibleur A, 2016, THESIS U GRENOBLE AL
   Kotsavasiloglou C, 2017, BIOMED SIGNAL PROCES, V31, P174, DOI 10.1016/j.bspc.2016.08.003
   Kulisevsky J, 2008, MOVEMENT DISORD, V23, P1889, DOI 10.1002/mds.22246
   Lebouvier T, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0012728
   LEES AJ, 1992, MOVEMENT DISORD, V7, P110, DOI 10.1002/mds.870070203
   Letanneux A, 2014, MOVEMENT DISORD, V29, P1467, DOI 10.1002/mds.25990
   Likforman-Sulem L, 2017, IEEE T HUM-MACH SYST, V47, P273, DOI 10.1109/THMS.2016.2635441
   Loconsole C, 2019, PATTERN RECOGN LETT, V121, P28, DOI 10.1016/j.patrec.2018.04.006
   de Ipiña KL, 2015, 2015 4TH INTERNATIONAL WORK CONFERENCE ON BIOINSPIRED INTELLIGENCE (IWOBI), P157, DOI 10.1109/IWOBI.2015.7160160
   Luciano MS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162799
   Man JHK, 2018, J CONTROL RELEASE, V286, P114, DOI 10.1016/j.jconrel.2018.07.017
   Martinez-Martin P, 2006, VALUE HEALTH, V9, P386, DOI 10.1111/j.1524-4733.2006.00131.x
   Martínez-Martín P, 2015, PARKINSONISM RELAT D, V21, P50, DOI 10.1016/j.parkreldis.2014.10.026
   Müller T, 2020, J NEURAL TRANSM, V127, P1369, DOI 10.1007/s00702-020-02246-3
   O'Reilly C, 2009, PATTERN RECOGN, V42, P3324, DOI 10.1016/j.patcog.2008.10.017
   Oliveira RM, 1997, J NEUROL NEUROSUR PS, V63, P429, DOI 10.1136/jnnp.63.4.429
   Pereira CR, 2018, ARTIF INTELL MED, V87, P67, DOI 10.1016/j.artmed.2018.04.001
   Pereira CR, 2016, SIBGRAPI, P340, DOI [10.1109/SIBGRAPI.2016.054, 10.1109/SIBGRAPI.2016.51]
   Pereira CR, 2015, COMP MED SY, P171, DOI 10.1109/CBMS.2015.34
   Petersen RC, 1999, ARCH NEUROL-CHICAGO, V56, P303, DOI 10.1001/archneur.56.3.303
   PHILLIPS JG, 1991, HUM MOVEMENT SCI, V10, P301, DOI 10.1016/0167-9457(91)90009-M
   Pieri V, 2000, J NEUROL SCI, V172, P7, DOI 10.1016/S0022-510X(99)00204-X
   Plamondon R, 1994, P 4 INT WORKSH FRONT, V1
   Poluha PC, 1998, ACTA PSYCHOL, V100, P71, DOI 10.1016/S0001-6918(98)00026-2
   Ponsen MM, 2008, PARKINSONISM RELAT D, V14, P199, DOI 10.1016/j.parkreldis.2007.07.019
   Porter D, 2020, SOC HIST MEDIC, P286
   Postuma RB, 2012, BRAIN, V135, P1860, DOI 10.1093/brain/aws093
   Postuma RB, 2016, SLEEP MED, V19, P148, DOI 10.1016/j.sleep.2015.08.019
   Pullman SL, 1998, MOVEMENT DISORD, V13, P85
   Randazzo V, 2021, SMART INNOVATION SYS, V184, P243
   Ribeiro LCF, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103477
   Rios-Urrego CD, 2019, COMPUT METH PROG BIO, V173, P43, DOI 10.1016/j.cmpb.2019.03.005
   Robert C., 2014, Machine Learning, a Probabilistic Perspective
   Roberts GHL, 2020, PIGM CELL MELANOMA R, V33, P8, DOI 10.1111/pcmr.12848
   Rosenblum S, 2013, J NEUROL, V260, P2357, DOI 10.1007/s00415-013-6996-x
   Schröter A, 2003, DEMENT GERIATR COGN, V15, P132, DOI 10.1159/000068484
   Shaban M, 2020, I S BIOMED IMAGING
   Sharma S, 2013, NEUROCHEM INT, V63, P201, DOI 10.1016/j.neuint.2013.06.005
   (sic)(sic) undefined, 2011, PRINC PRACT GERIATR, V1, P1
   Slavin MJ, 1999, J INT NEUROPSYCH SOC, V5, P20, DOI 10.1017/S135561779951103X
   Smits EJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0097614
   Stebbins GT, 1998, MOVEMENT DISORD, V13, P633, DOI 10.1002/mds.870130404
   Taleb C, 2023, EVOL INTELL, V16, P1813, DOI 10.1007/s12065-020-00470-0
   TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669
   Teulings HL, 1997, EXP NEUROL, V146, P159, DOI 10.1006/exnr.1997.6507
   Teulings HL, 2002, J NEUROL NEUROSUR PS, V72, P315, DOI 10.1136/jnnp.72.3.315
   TEULINGS HL, 1991, HUM MOVEMENT SCI, V10, P315, DOI 10.1016/0167-9457(91)90010-U
   Thomas B, 2007, HUM MOL GENET, V16, pR183, DOI 10.1093/hmg/ddm159
   Tucha O, 2006, J NEURAL TRANSM, V113, P609, DOI 10.1007/s00702-005-0346-9
   Ünlü A, 2006, LECT NOTES COMPUT SC, V4345, P441
   Van Gemmert AWA, 1999, NEUROPSYCHOLOGIA, V37, P685
   Van Gemmert AWA, 2003, J NEUROL NEUROSUR PS, V74, P1502, DOI 10.1136/jnnp.74.11.1502
   Van Gemmert AWA, 2001, BRAIN COGNITION, V47, P504, DOI 10.1006/brcg.2001.1328
   van Gemmert AWA, 1998, ACTA PSYCHOL, V100, P161, DOI 10.1016/S0001-6918(98)00032-8
   Vessio G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214666
   Vorasoot N, 2020, J CLIN NEUROSCI, V72, P298, DOI 10.1016/j.jocn.2019.08.119
   Werner P, 2006, J GERONTOL B-PSYCHOL, V61, pP228, DOI 10.1093/geronb/61.4.P228
   Witjas T, 2007, REV NEUROL-FRANCE, V163, P846, DOI 10.1016/S0035-3787(07)91470-8
   Zham P, 2018, IEEE J BIOMED HEALTH, V22, P1648, DOI 10.1109/JBHI.2017.2762008
   Zhang HB, 2021, IEEE REV BIOMED ENG, V14, P71, DOI 10.1109/RBME.2020.2991813
   Zhi NQ, 2017, IEEE J BIOMED HEALTH, V21, P488, DOI 10.1109/JBHI.2016.2518858
   Ziliotto A, 2015, ANN REHABIL MED-ARM, V39, P586, DOI 10.5535/arm.2015.39.4.586
NR 115
TC 7
Z9 7
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11923
EP 11948
DI 10.1007/s11042-022-13759-2
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854682700007
DA 2024-07-18
ER

PT J
AU Zhu, XK
   Zheng, MH
   Chen, XP
   Zhang, XY
   Yuan, CH
   Zhang, F
AF Zhu, Xiaoke
   Zheng, Minghao
   Chen, Xiaopan
   Zhang, Xinyu
   Yuan, Caihong
   Zhang, Fan
TI Information disentanglement based cross-modal representation learning
   for visible-infrared person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cross-modal feature learning; Information disentanglement; Shared and
   specific feature learning; Visible-infrared person re-identification
AB Visible-infrared person re-identification (VI-ReID) is an important but very challenging task in the automated video surveillance and forensics. Although existing VI-ReID methods have achieved very encouraging results, how to make full use of the useful information contained in cross-modality visible and infrared images has not been well studied. In this paper, we propose an Information Disentanglement based Cross-modal Representation Learning (IDCRL) approach for VI-ReID. Specifically, IDCRL first extracts the shared and specific features from data of each modality by using the shared feature learning module and the specific feature learning module, respectively. To ensure that the shared and specific information can be well disentangled, we impose an orthogonality constraint on the shared and specific features of each modality. To make the shared features extracted from the visible and infrared images of the same person own high similarity, IDCRL designs a shared feature consistency constraint. Furthermore, IDCRL uses a modality-aware loss to ensure that the useful modality-specific features can be extracted from each modality effectively. Then, the obtained shared and specific features are concatenated as the representation of each image. Finally, identity loss function and cross-modal discriminant loss function are employed to enhance the discriminability of the obtained image representation. We conducted comprehensive experiments on the benchmark visible-infrared pedestrian datasets (SYSU-MM01 and RegDB) to evaluate the efficacy of our IDCRL approach. Experimental results demonstrate that IDCRL outperforms the compared state-of-the-art methods. On the SYSU-MM01 dataset, the rank-1 matching rate of our approach reaches 62.35% and 71.64% in the all-search and in-door modes, respectively. On the RegDB dataset, the rank-1 result of our approach reaches 76.32% and 75.49% in the visible to thermal and thermal to visible modes, respectively.
C1 [Zhu, Xiaoke; Zheng, Minghao; Yuan, Caihong; Zhang, Fan] Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
   [Chen, Xiaopan] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng, Peoples R China.
   [Zhang, Xinyu] Wuhan Univ, Sch Comp, Wuhan, Peoples R China.
   [Zhang, Fan] Henan Univ, Henan Engn Res Ctr Intelligent Technol & Applicat, Kaifeng, Peoples R China.
C3 Henan University; Henan University; Wuhan University; Henan University
RP Chen, XP (corresponding author), Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng, Peoples R China.
EM whuzxk@whu.edu.cn; henuzmh@henu.edu.cn; xpchen@henu.edu.cn;
   zhangxinyu@whu.edu.cn; yuanch@henu.edu.cn; zhangfan@henu.edu.cn
OI Zhu, Xiaoke/0000-0002-0664-1832
FU NSFC Project [62176069]; Young Scientists Fund of the National Natural
   Science Foundation of China [62006070]; Natural Science Foundation of
   Henan Province [202300410092, 202300410093]; Key Scientific and
   Technological Project of Henan Province of China [222102210204,
   222102210197]; Excellent Youth Scientific Research Project of Hunan
   Education Department [21B0582]
FX This work was supported by the NSFC Project (No. 62176069), Young
   Scientists Fund of the National Natural Science Foundation of China (No.
   62006070), Natural Science Foundation of Henan Province (Nos.
   202300410092 and 202300410093), Key Scientific and Technological Project
   of Henan Province of China (Nos. 222102210204 and 222102210197), and the
   Excellent Youth Scientific Research Project of Hunan Education
   Department (No. 21B0582).
CR Basaran E, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115933
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen WB, 2022, MULTIMED TOOLS APPL, V81, P4649, DOI 10.1007/s11042-020-10494-4
   Chen YHS, 2021, PROC CVPR IEEE, P587, DOI 10.1109/CVPR46437.2021.00065
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Hao X., 2021, IEEE C ICCV, P16383, DOI 10.1109/ICCV48922.2021.01609
   Hao Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P57, DOI 10.1145/3343031.3351006
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang P, 2022, MULTIMED TOOLS APPL, V81, P4455, DOI 10.1007/s11042-021-11739-6
   Jia MX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1026
   Jia XD, 2021, IEEE T PATTERN ANAL, V43, P2496, DOI 10.1109/TPAMI.2020.2973634
   Jiang JG, 2020, NEUROCOMPUTING, V406, P59, DOI 10.1016/j.neucom.2020.03.109
   Kniaz VV, 2019, LECT NOTES COMPUT SC, V11134, P606, DOI 10.1007/978-3-030-11024-6_46
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li W, 2020, INT J COMPUT VISION, V128, P1635, DOI 10.1007/s11263-019-01274-1
   Liang WQ, 2021, IEEE T IMAGE PROCESS, V30, P6392, DOI 10.1109/TIP.2021.3092578
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HJ, 2020, NEUROCOMPUTING, V398, P11, DOI 10.1016/j.neucom.2020.01.089
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Meng JK, 2019, PROC CVPR IEEE, P760, DOI 10.1109/CVPR.2019.00085
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Park H, 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, P12046
   Qi MB, 2021, MULTIMED TOOLS APPL, V80, P17645, DOI 10.1007/s11042-020-10431-5
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tian XD, 2021, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR46437.2021.00157
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GA, 2020, NEURAL NETWORKS, V128, P294, DOI 10.1016/j.neunet.2020.05.008
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wu AC, 2019, PROC CVPR IEEE, P1187, DOI 10.1109/CVPR.2019.00128
   Wu AC, 2020, INT J COMPUT VISION, V128, P1765, DOI 10.1007/s11263-019-01290-1
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu DM, 2022, IEEE T INF FOREN SEC, V17, P115, DOI 10.1109/TIFS.2021.3075894
   Wu F, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107335
   Wu Q, 2021, PROC CVPR IEEE, P4328, DOI 10.1109/CVPR46437.2021.00431
   Wu WY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107424
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Xie ZW, 2020, PATTERN RECOGN LETT, V133, P70, DOI 10.1016/j.patrec.2019.03.003
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Ye M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13547, DOI 10.1109/ICCV48922.2021.01331
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P347, DOI 10.1145/3343031.3351043
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Yin J, 2020, INT J COMPUT VISION, V128, P1654, DOI 10.1007/s11263-019-01259-0
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zhang P, 2020, IEEE T CIRC SYST VID, V30, P4554, DOI 10.1109/TCSVT.2019.2939564
   Zhang S, 2019, ARXIV
   Zhang W, 2020, IEEE T IMAGE PROCESS, V29, P3365, DOI 10.1109/TIP.2019.2959653
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zhu XK, 2019, PATTERN RECOGN, V95, P211, DOI 10.1016/j.patcog.2019.06.007
NR 65
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 SEP 2
PY 2022
DI 10.1007/s11042-022-13669-3
EA SEP 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4G6IW
UT WOS:000849298600001
DA 2024-07-18
ER

PT J
AU Su, YH
AF Su, Yanhui
TI Data-driven method development and evaluation for indie mobile game
   publishing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Business intelligence; Game analytics; Metrics; Data-driven; Indie game
   developer; Online analysis tool
AB With the emergence of mobile distribution channels, the traditional game value chain has produced new changes, leading to the emergence of the mobile value chain. Independent (Indie) game developers can upload their games directly through third-party app stores and publish them themselves. However, many indie game developers have issues with game publishing, especially updating the new version, promoting the market, and forecasting revenue for their games. This paper aims to provide a method to guide indie mobile game developers with mobile publishing. This new method mainly focuses on addressing the main challenges from the indie game developer's side. The method includes a new concept of mobile game publishing logic and an online analysis tool along with the guidelines. It shows how to collect and analyze data and guide new version updates, marketing promotion, and revenue forecasts. In practice, the method was provided to six indie game companies and guided their mobile game publishing, and related data were collected and analyzed for evaluation. Based on the survey and interview results, the usefulness, usability, and confidence in the method were positive, and the method improved the indie game developers' mobile game publishing and benefited their game business.
C1 [Su, Yanhui] Univ Skovde, Sch Informat, Skovde, Sweden.
C3 University of Skovde
RP Su, YH (corresponding author), Univ Skovde, Sch Informat, Skovde, Sweden.
EM yanhui.su@his.se
FU University of Skovde, Sweden Game Arena; Game Hub Scandinavia 2.0
   project under the EU regional development fund Interreg
   oresund-Kattegat-Skagerrak [NYPS 20201849]
FX This research was supported by the University of Skovde, Sweden Game
   Arena, and the Game Hub Scandinavia 2.0 (NYPS 20201849) project under
   the EU regional development fund Interreg oresund-Kattegat-Skagerrak.
CR Aaron H, 2011, TOP 7 SOCIAL GAME ME
   Agrawal D, 2009, LECT NOTES BUS INF, V27, P75
   [Anonymous], 2016, GLOBAL GAMES PRODUCT
   [Anonymous], 2011, SEQUENTIAL KAISER ME
   [Anonymous], 2016, GAME STUDIES
   [Anonymous], 2015, DESIGN SCI RES METHO
   Attilio C., 2017, POSTMORTEM MY 1 INDI
   Bevan N., 2016, Lecture Notes in Computer Science, DOI [DOI 10.1007/978-3-319, 10.1007/978-3-319-39510-4_25, DOI 10.1007/978-3-319-39510-4_25]
   Boone HN., 2012, J EXT, V50, P1
   Broekhuizen TLJ, 2013, RES POLICY, V42, P954, DOI 10.1016/j.respol.2012.12.007
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Chatfield C., 1978, Journal of the Royal Statistical Society: Series C (Applied Statistics), V27, P264, DOI 10.2307/2347162
   Davenport T. H., 2007, Competing on analytics: The new science of winning
   Drachen A, 2018, GAMES USER RES
   Drachen A, 2016, IEEE CONF COMPU INTE
   Edwards R., 2013, What is qualitative interviewing?, P43
   El-Nasr M., 2013, Game Analytics-Maximizing the Value of Player Data
   European Games Developer Federation, 2011, GAME DEV DIGITAL GRO
   Fields Tim., 2014, Mobile Social Game Design:MonetizationMethods andMechanics
   Gnade M, 2013, INDIE GAME MAGAZINE
   Goncharova E., 2017, MONETIZATION STRATEG
   Guevara-Villalobos V, 2011, P 2011 DIGITAL GAMES
   Heimo OI, 2018, J BUS ETHICS, V153, P95, DOI 10.1007/s10551-016-3408-z
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hullett K, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P940, DOI 10.1145/1985793.1985952
   Karlsen F, 2022, GAMES CULT, V17, P639, DOI 10.1177/15554120211049579
   Kim JH, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P443
   Koskenvoima A, 2015, LECT NOTES COMPUT SC, V9373, P326, DOI 10.1007/978-3-319-25013-7_26
   Limpach O, 2020, PUBLISHING CHALLENGE, V1st, DOI [10.1201/9780367815639, DOI 10.1201/9780367815639]
   Mantymaki M, 2020, INFORM SYST FRONT, V22, P1163, DOI 10.1007/s10796-019-09913-1
   Mazzarol T, 2017, SMALL BUSINESS MANAG
   Mendez J, 2017, SHOULD YOU SELF PUBL
   Moore Tyler, 2012, The Oxford handbook of the digital economy, P572, DOI [10.1093/oxfordhb/9780195397840.001.0001, DOI 10.1093/OXFORDHB/9780195397840.001.0001]
   Moreira A., 2014, SBC Journal on Interactive Systems, V5, P2
   Moura Dinara, 2011, P 2011 ACM SIGGRAPH, P1, DOI DOI 10.1145/2018556.2018559
   Negash S., 2004, COMMUN ASSOC INF SYS, V13, P177, DOI [DOI 10.17705/1CAIS.01315, 10.1007/978-3-540-48716-69, DOI 10.1007/978-3-540-48716-69]
   Newzoo, 2021, Global mobile market report
   ODonnell C, 2014, INSIDE TECHNOL, P3
   Patton M.Q., 2014, Qualitative Research and Evaluation Methods, V4th
   Picciano A.G., 2006, DATA DRIVEN DECISION
   Rubin J., 2008, Handbook of Usability Testing: how to Plan, Design, and Conduct Effective Tests, V2nd ed.
   Su Y, 2022, P DIGRA THE DIGITAL
   Su YH, 2022, SERV ORIENTED COMPUT, V16, P67, DOI 10.1007/s11761-021-00332-2
   Su YH, 2021, SERV ORIENTED COMPUT, V15, P141, DOI 10.1007/s11761-020-00303-z
   Su YH, 2020, INT J COMPUT GAMES T, V2020, DOI 10.1155/2020/5395187
   Su YJ, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207571
   Su Y, 2022, INT J OCCUP SAF ERGO, V28, P1533, DOI 10.1080/10803548.2021.1904652
   Tankard Colin, 2016, Network Security, V2016, P5, DOI 10.1016/S1353-4858(16)30056-3
   Tsakonas G, 2004, DELOS WP7 WORKSH EV, P45
   Tsakonas G, 2006, J INF SCI, V32, P400, DOI 10.1177/0165551506065934
   Vaske JJ, 2017, LEISURE SCI, V39, P163, DOI 10.1080/01490400.2016.1127189
   Venable John, 2012, Design Science Research in Information Systems. Advances in Theory and Practice. Proceedings 7th International Conference, DESRIST 2012, P423, DOI 10.1007/978-3-642-29863-9_31
NR 52
TC 0
Z9 0
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11047
EP 11078
DI 10.1007/s11042-022-13688-0
EA AUG 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844934900006
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Snoussi, M
   Tamim, A
   El Fellah, S
   El Ansari, M
AF Snoussi, Mohamed
   Tamim, Ayoub
   El Fellah, Salma
   El Ansari, Mohamed
TI Deep residual U-Net for automatic detection of Moroccan coastal
   upwelling using SST images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Upwelling; Sea surface temperature; Segmentation; Deep learning; Fully
   convolutional neural networks; U-net framework; Residual learning
ID DELIMITATION; NETWORK; SYSTEM
AB Upwelling phenomenon is one of the most important dynamic process in the ocean, which brings nutrients from the depths of the ocean into the surface layer, leading to an enhancement of the primary production and playing a considerable role in the coastal ecosystem. Deep learning (DL) based segmentation methods have been providing state-of-the-art performance in the last few years. These methods have been successfully applied to oceanic remote sensing image segmentation, classification, and detection tasks. In particular, U-Net, has become one of the most popular for these applications. This paper proposes UpwellRes-Net, a deep fully convolutional neural network architecture, for automatic upwelling detection and pixel-segmentation on sea surface temperature (SST) images. The proposed model is based on U-Net structure and residual learning, thus, combining the strengths of both approaches. The main objective of this study is to investigate the performance of deep learning in the extraction of upwelling area. Hence, UpwellRes-Net is trained and optimized on satellite-derived SST database provided by the Moderate Resolution Imaging Spectroradiometer (MODIS). Experiments on the southern Atlantic Moroccan coast show the superiority of the proposed model to a transfer learning based model developed for the same. Deep learning based upwelling detection system can be a cost effective, accurate and convenient way for objective analysis of upwelling phenomenon.
C1 [Snoussi, Mohamed; Tamim, Ayoub; El Fellah, Salma; El Ansari, Mohamed] Ibn Zohr Univ, Fac Sci, LABSIV Comp Sci, Agadir, Morocco.
   [Tamim, Ayoub] Higher Inst Marine Fisheries ISPM, Dept Marine Fisheries, Agadir, Morocco.
   [Tamim, Ayoub; El Fellah, Salma] Mohammed V Univ, Rabat IT Ctr, Associated Unit CNRST URAC 29, LRIT,Fac Sci, Rabat, Morocco.
   [El Ansari, Mohamed] My Ismail Univ, Informat & Applicat Lab, Dept Comp Sci, Fac Sci, Meknes, Morocco.
C3 Ibn Zohr University of Agadir; Centre National de la Recherche
   Scientifique & Technologique (CNRST); Mohammed V University in Rabat;
   Moulay Ismail University of Meknes
RP Snoussi, M (corresponding author), Ibn Zohr Univ, Fac Sci, LABSIV Comp Sci, Agadir, Morocco.
EM mohamed.snoussi@edu.uiz.ac.ma
RI El Ansari, Mohamed/L-9738-2016
OI El Ansari, Mohamed/0000-0001-5394-9066; Mohamed,
   Snoussi/0000-0002-2590-2188
CR [Anonymous], 2015, Conference Track Proceedings
   Atillah A., 2005, GEO OBSERVATEUR, V14, P49
   Bezdek JC., 1992, FUZZY MODELS PATTERN
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Chaudhari S., 2008, P IGARSS 2008 2008 I, pIV, DOI [10.1109/igarss.2008.4779875, DOI 10.1109/IGARSS.2008.4779875]
   Defence Science & Technology Laboratory, DSTL SAT IM FEAT DET
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, P228, DOI 10.1109/CVPRW.2018.00042
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Lguensat R, 2018, INT GEOSCI REMOTE SE, P1764, DOI 10.1109/IGARSS.2018.8518411
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li XF, 2020, NATL SCI REV, V7, P1584, DOI 10.1093/nsr/nwaa047
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2386, DOI 10.1109/TPAMI.2020.3041332
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Mann K, 2013, DYNAMICS MARINE ECOS, DOI DOI 10.1007/BF00042919
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nascimento S, 2012, COMPUT GEOSCI-UK, V43, P207, DOI 10.1016/j.cageo.2011.10.025
   Nieto K, 2012, REMOTE SENS ENVIRON, V123, P339, DOI 10.1016/j.rse.2012.03.028
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rapantzikos K, 2003, MED IMAGE ANAL, V7, P95, DOI 10.1016/S1361-8415(02)00093-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamim A., 2013, Signal Processing Conference (EUSIPCO), 2013 Proceedings of the 21st European, P1
   Tamim A, 2019, INT J REMOTE SENS, V40, P2648, DOI 10.1080/01431161.2018.1528513
   Tamim A, 2015, IEEE GEOSCI REMOTE S, V12, P875, DOI 10.1109/LGRS.2014.2365558
   Vargas CA, 2004, AQUAT MICROB ECOL, V34, P151, DOI 10.3354/ame034151
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, DOI 10.1016/j.rse.2020.111716
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 39
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7491
EP 7507
DI 10.1007/s11042-022-13692-4
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000844473700003
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Lin, YP
   Yang, JF
AF Zhang, Yi
   Lin, Yaping
   Yang, Junfeng
TI ELGONBP: A grouped neighboring intensity difference encoding for texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture descriptors; Local binary pattern (LBP); Neighboring intensity
   difference; Different image domains; Noise robustness
ID LOCAL BINARY PATTERNS; COOCCURRENCE; DESCRIPTORS
AB Local binary pattern (LBP) plays a crucial part in texture classification. Although plenty of LBP-based methods for texture extraction have achieved good classification results, most LBP variants focus on the relationships between the neighboring pixels and its central pixel in an image patch whereas ignoring the information among neighboring pixels, making the extracted texture descriptors not robust enough to external changes (illumination, rotation, noise, etc.). In this paper, a new texture descriptor, the extended local grouped order and non-local binary pattern (ELGONBP) is introduced. Firstly, we propose a first-order difference coding scheme which is based on the sign difference to encode grouped neighborhood difference information. In this way, we can obtain a more complete representation among neighboring sampling points. To further promote the robustness of texture descriptor, we perform cross-image domain information fusion, which combines the texture information in the original image domain and the gradient domain since image gradients contain rich structural information. Comprehensive experiments are implemented on four public representative texture databases and the noise robustness of different descriptors is evaluated. The experimental results prove that the presented ELGONBP descriptor has better classification performance and noise robustness compared with other state-of-the-art LBP descriptors.
C1 [Zhang, Yi; Lin, Yaping] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Yang, Junfeng] Hunan Univ Technol & Business, Changsha, Peoples R China.
C3 Hunan University; Hunan University of Technology & Business
RP Zhang, Y (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
EM hellozy@hnu.edu.cn; yplin@hnu.edu.cn; b12100031@hnu.edu.cn
FU National Natural Science Foundation of China [61872131]; Natural Science
   Foundation of Hunan Province [2019JJ50288]; Research Foundation of the
   Education Bureau of Hunan Province [19B309]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 61872131), the Natural Science Foundation
   of Hunan Province (Grant No.2019JJ50288) and the Research Foundation of
   the Education Bureau of Hunan Province (Grant No.19B309).
CR Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   El Merabet Y, 2019, ENG APPL ARTIF INTEL, V78, P158, DOI 10.1016/j.engappai.2018.11.011
   Fawad, 2019, IEEE ACCESS, V7, P66668, DOI 10.1109/ACCESS.2019.2918004
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hanbay K, 2016, NEUROCOMPUTING, V199, P77, DOI 10.1016/j.neucom.2016.03.032
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Jia S, 2017, IEEE T GEOSCI REMOTE, V55, P2399, DOI 10.1109/TGRS.2016.2642951
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Maani R, 2013, IEEE T IMAGE PROCESS, V22, P2409, DOI 10.1109/TIP.2013.2249081
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2020, MULTIMED TOOLS APPL, V79, P5477, DOI 10.1007/s11042-019-08205-9
   Pan ZB, 2018, MULTIMED TOOLS APPL, V77, P26469, DOI 10.1007/s11042-018-5871-2
   Pan ZB, 2017, IEEE SIGNAL PROC LET, V24, P828, DOI 10.1109/LSP.2017.2694460
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Qi X, 2015, ARXIV
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Rassem TH, 2014, SCI WORLD J, DOI 10.1155/2014/373254
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Roy SK, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105910
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   Saeed A, 2019, IEEE ACCESS, V7, P110116, DOI 10.1109/ACCESS.2019.2932687
   Shang J, 2016, IET IMAGE PROCESS, V10, P662, DOI 10.1049/iet-ipr.2016.0058
   Song T, 2020, IEEE T CIRC SYST VID
   Song TC, 2019, IEEE IMAGE PROC, P4405, DOI [10.1109/ICIP.2019.8803518, 10.1109/icip.2019.8803518]
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Tabatabaei SM, 2020, VISUAL COMPUT, V36, P967, DOI 10.1007/s00371-019-01704-8
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang HB, 2022, MULTIMED TOOLS APPL, V81, P14081, DOI 10.1007/s11042-022-12449-3
   Wang K, 2013, IEEE SIGNAL PROC LET, V20, P853, DOI 10.1109/LSP.2013.2270405
   Wang TY, 2018, IEEE ACCESS, V6, P64416, DOI 10.1109/ACCESS.2018.2877729
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Xu XC, 2020, COGN COMPUT, V12, P224, DOI 10.1007/s12559-019-09673-9
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Yuan FN, 2018, INFORM SCIENCES, V460, P202, DOI 10.1016/j.ins.2018.05.033
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhou LF, 2018, PATTERN RECOGN, V78, P43, DOI 10.1016/j.patcog.2018.01.003
NR 57
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10311
EP 10336
DI 10.1007/s11042-022-13634-0
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844473700004
DA 2024-07-18
ER

PT J
AU Khan, H
   Jamal, SS
   Hazzazi, MM
   Khan, M
   Hussain, I
AF Khan, Hamza
   Jamal, Sajjad Shaukat
   Hazzazi, Mohammad Mazyad
   Khan, Majid
   Hussain, Iqtadar
TI New image encryption scheme based on Arnold map and cuckoo search
   optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cuckoo search; S-boxes; Chirikov map; Arnold map; Nonlinearity
ID PARTICLE SWARM OPTIMIZATION; SUBSTITUTION BOX; LEVY FLIGHT; S-BOXES;
   SELECTION
AB Nonlinear confusion component is one of the most important part of any modern cipher. The strength and robustness of modern cryptosystem are subjected to the cryptographic properties of this nonlineaer confusion component namely S-boxes. The principle aim of this article is twofold. Firstly, we have anticipated an innovative approach of producing S-boxes by employing the Cuckoo search algorithm (CSA) an alternative to algebraic and chaotic generation of S-boxes. Secondly, we have also proposed a new encryption technique for information confidentiality of digital color images. The suggested image encryption technique is based on generated S-boxes and Arnold map. The projected information privacy mechanism is verified against a variety of cryptographic characteristics.
C1 [Khan, Hamza; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Jamal, Sajjad Shaukat; Hazzazi, Mohammad Mazyad] King Khalid Univ, Coll Sci, Dept Math, Abha 61413, Saudi Arabia.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Stat Consulting Unit, Doha, Qatar.
C3 King Khalid University; Qatar University; Qatar University
RP Khan, H (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM hamza.khan78@gmail.com
RI Jamal, Sajjad/AHE-6498-2022; Hazzazi, Mohammad Mazyad/ABB-4202-2021
OI Hazzazi, Mohammad Mazyad/0000-0002-7945-9994
FU Deanship of Scientific Research at King Khalid University [R. G. P.
   2/109/43]
FX One of the authors (Dr. Sajjad Shaukat Jamal) extends his gratitude to
   the Deanship of Scientific Research at King Khalid University for
   funding this work through research groups program under grant number R.
   G. P. 2/109/43.
CR Açikkapi MS, 2019, IEEE ACCESS, V7, P79030, DOI 10.1109/ACCESS.2019.2921708
   Ahmad M., 2016, Perspectives in Science, V8, P465
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P572, DOI 10.1016/j.procs.2015.07.394
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   [Anonymous], 1984, REGULAR STOCHASTIC M
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Buchmann JA, 2004, INTRO CRYOTOGRAPHY
   Faiz ul Islam GL, 2017, SPRINGER 3D RES
   Farah T, 2017, NONLINEAR DYNAM, V88, P1059, DOI 10.1007/s11071-016-3295-y
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Gupta Priyanka, 2014, INT J ADV RES COMPUT, P807
   Hakli H, 2014, APPL SOFT COMPUT, V23, P333, DOI 10.1016/j.asoc.2014.06.034
   Haley, 2018, EAGLE SCHOLAR, V24
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Liu LY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122650
   Loaiyan ARA, 2020, NOVEL GROUP THEORETI, P26
   Lu B, 2019, CMC-COMPUT MATER CON, V61, P687, DOI 10.32604/cmc.2019.05633
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Mehra I, 2015, OPT COMMUN, V354, P344, DOI 10.1016/j.optcom.2015.06.015
   Musheer Ahmad DBH., 2015, NOVEL ANT COLONY OPT
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Ozkaynak F, 2019, CHAOTIC MODELING SIM
   Ozkaynak F., 2017, ACM INT C BIAM ENG B
   Pan HL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0386-3
   Pathak Y, 2019, MULTIMED TOOLS APPL, V78, P1473, DOI 10.1007/s11042-018-6155-6
   Payne R.B., 2005, CUCKOOS
   Poomagal C., 2020, COMPUT SYST SCI ENG, V35
   RANNOU F, 1974, ASTRON ASTROPHYS, V31, P289
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shashikant Burnwal, 2013, SCHEDULING OPTIMIZAT, V64, P951
   Shrija Somaraj, 2015, INDIAN J SCI TECHNOL, V8, P1, DOI [10.17485/ijst/2015/v8i35/73141, DOI 10.17485/IJST/2015/V8I35/73141]
   Swathypriyadharsini P, 2020, COMPUT SYST SCI ENG, V35, P39
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Vijayalakshmi K, 2020, INTELL AUTOM SOFT CO, V26, P303, DOI 10.31209/2020.100000165
   Webster S. E. T. A. F., 1986, ADV CRYPTOLOGY CRYPT
   Yi F, 2014, J OPTICAL SOC AM, V8
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zengin A., 2016, NOVEL APPROACH STRON, P14
NR 45
TC 5
Z9 5
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7419
EP 7441
DI 10.1007/s11042-022-13600-w
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843430100002
DA 2024-07-18
ER

PT J
AU Alaeddine, H
   Jihene, M
AF Alaeddine, Hmidi
   Jihene, Malek
TI Wide deep residual networks in networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep network in network; Convolution neural network; CIFAR-10
AB The Deep Residual Network in Network (DrNIN) model [18] is an important extension of the convolutional neural network (CNN). They have proven capable of scaling up to dozens of layers. This model exploits a nonlinear function, to replace linear filter, for the convolution represented in the layers of multilayer perceptron (MLP) [23]. Increasing the depth of DrNIN can contribute to improved classification and detection accuracy. However, training the deep model becomes more difficult, the training time slows down, and a problem of decreasing feature reuse arises. To address these issues, in this paper, we conduct a detailed experimental study on the architecture of DrMLPconv blocks, based on which we present a new model that represents a wider model of DrNIN. In this model, we increase the width of the DrNINs and decrease the depth. We call the result module (WDrNIN). On the CIFAR-10 dataset, we will provide an experimental study showing that WDrNIN models can gain accuracy through increased width. Moreover, we demonstrate that even a single WDrNIN outperforms all network-based models in MLPconv network models in accuracy and efficiency with an accuracy equivalent to 93.553% for WDrNIN-4-2.
C1 [Alaeddine, Hmidi; Jihene, Malek] Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
   [Jihene, Malek] Sousse Univ, Higher Inst Appl Sci & Technol Sousse, Sousse 4000, Tunisia.
C3 Universite de Monastir; Universite de Sousse
RP Alaeddine, H (corresponding author), Monastir Univ, Fac Sci Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
EM alaeddine.hmidi@fsm.mu.tn; jihenemalek14@gmail.com
OI Alaeddine, Hmidi/0000-0002-2417-3972
FU Electronics and Microelectronics Laboratory
FX This work was supported by the Electronics and Microelectronics
   Laboratory.
CR Alaeddine H, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/6659083
   Alaeddine H, 2021, NEURAL COMPUT APPL, V33, P1453, DOI 10.1007/s00521-020-05008-0
   Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   [Anonymous], 2014, Arxiv
   Chan T., 2014, ARXIV
   Chang J-R, 2015, ARXIV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T., 2016, ARXIV
   Ciresan D, 2012, ARXIV
   Clevert D.-A., 2016, PREPRINT
   Gao SH, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012034
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Goodfellow I.J., 2013, arXiv
   He K., 2014, ARXIV
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lee C, 2015, ARXIV
   Lee C. -Y., 2014, ARXIV
   Liao Z, 2016, IEEE WINT CONF APPL
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Murray N, 2014, PROC CVPR IEEE, P2473, DOI 10.1109/CVPR.2014.317
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Raiko T., 2012, Artificial intelligence and statistics, P924
   Romero A., 2014, ARXIV14126550
   SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P234, DOI 10.1162/neco.1992.4.2.234
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Yoo D, 2015, IEEE COMPUT SOC CONF
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 40
TC 3
Z9 3
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7889
EP 7899
DI 10.1007/s11042-022-13696-0
EA AUG 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843355500002
DA 2024-07-18
ER

PT J
AU Sharma, C
   Sharma, S
   Sakshi
AF Sharma, Chetan
   Sharma, Shamneesh
   Sakshi
TI Latent DIRICHLET allocation (LDA) based information modelling on
   BLOCKCHAIN technology: a review of trends and research patterns used in
   integration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Blockchain; Security; Ledger; LDA; Cryptocurrency; Topic modelling
ID SECURITY; BUSINESS; INTERNET; CHALLENGES; MANAGEMENT; THINGS; WILL
AB The past decade is known as the era of integrations where multiple technologies had integrated, and new research trends were seen. The security of data and information in the digital world has been a challenge to everyone; Blockchain technology has attracted many researchers in these scenarios. This paper focuses on finding the current trends in Blockchain technology to help the researchers select an area to carry future research. The data related to Blockchain Technologies have been collected from IEEE, Springer, ACM, and other digital databases. Then, the formulated corpus is used for topic modelling, and Latent Dirichlet Allocation is deployed. The outcomes of the Latent Dirichlet Allocation model are then analyzed based on various extracted key terms and key documents found for each topic. All the topic solution has been identified from the bag of words. The extracted topics are thereafter semantically mapped. Thus, based on the analysis of more than 900 papers, the most recent research trends have been discussed in this paper, ultimately focusing on the areas that need more attention from the research community. Also, the meta data analysis has been accomplished, evaluating the year wise and publication source wise research growth. More than 15 research directions are elaborated in this paper, which can direct and guide the researchers to pursuit the research in specific trends and also, find the research gaps in various technologies associated with Blockchain Technology.
C1 [Sharma, Chetan] Chitkara Univ, Solan, Himachal Prades, India.
   [Sharma, Shamneesh] Poornima Univ, Sch Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Sakshi] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Sharma, C (corresponding author), Chitkara Univ, Solan, Himachal Prades, India.
EM chcianshckhu@gmail.com; shanuteesh.sharma@email.com;
   sakshi@chitkara.edu.in
RI sharma, chetan/IWU-9248-2023; Sharma, Shamneesh/D-1300-2013
OI sharma, chetan/0000-0001-5401-8503; Sharma,
   Shamneesh/0000-0003-3102-0808
CR Ahl A, 2019, RENEW SUST ENERG REV, V107, P200, DOI 10.1016/j.rser.2019.03.002
   Aich S, 2019, INT CONF ADV COMMUN, P138, DOI [10.23919/ICACT.2019.8701910, 10.23919/icact.2019.8701910]
   Ali MS, 2019, IEEE COMMUN SURV TUT, V21, P1676, DOI 10.1109/COMST.2018.2886932
   Alketbi A, 2018, 2018 15TH LEARNING AND TECHNOLOGY CONFERENCE (L&T), P112, DOI 10.1109/LT.2018.8368494
   Alvi Syada Tasmia, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P228, DOI 10.1109/ICSSIT48917.2020.9214250
   AlzForum.org, 2019, BITC SV RAIS ITS BLO
   Andoni M, 2019, RENEW SUST ENERG REV, V100, P143, DOI 10.1016/j.rser.2018.10.014
   Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   Angelis J, 2019, BUS HORIZONS, V62, P307, DOI 10.1016/j.bushor.2018.12.001
   [Anonymous], 2013, P 2013 ECRIME RES SU, DOI DOI 10.1109/ECRS.2013.6805780
   [Anonymous], 2019, EV TOP MOD UND COH V
   Arun R, 2010, LECT NOTES ARTIF INT, V6118, P391
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Ballandies MC, 2018, PREPRINT
   Banafa A., 2017, IEEE INTERNET THINGS
   Bansal S, 2020, INT J WIREL INF NETW, V27, P340, DOI 10.1007/s10776-020-00483-7
   Beck R, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P5390
   Bell L., 2018, Blockchain in Healthcare Today, DOI DOI 10.30953/BHTY.V1.8
   Bhadoria RS., 2020, ADV APPL BLOCKCHAIN, DOI 10.1007/978-981-13-8775-3_13
   Biswas K, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1392, DOI [10.1109/HPCC-SmartCity-DSS.2016.178, 10.1109/HPCC-SmartCity-DSS.2016.0198]
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosona T, 2013, FOOD CONTROL, V33, P32, DOI 10.1016/j.foodcont.2013.02.004
   Bozic N, 2016, 2016 3RD SMART CLOUD NETWORKS & SYSTEMS (SCNS)
   Bradford RogerB., 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08, P153, DOI DOI 10.1145/1458082.1458105
   Brandon D., 2016, INT J ACAD BUS WORLD, V10, P33, DOI DOI 10.1364/BOE.6.003898
   Cao J, 2009, NEUROCOMPUTING, V72, P1775, DOI 10.1016/j.neucom.2008.06.011
   Carlozo Lou., 2017, Journal of Accountancy, V224, P29
   Cermeno J. S., 2016, BBVA RES PAPER, V16, P20
   Chamola V, 2020, IEEE ACCESS, V8, P90225, DOI 10.1109/ACCESS.2020.2992341
   Chang SE, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12010188
   Chen YL, 2017, IEEE INT CONF BIG DA, P2652, DOI 10.1109/BigData.2017.8258226
   Cole R, 2019, SUPPLY CHAIN MANAG, V24, P469, DOI 10.1108/SCM-09-2018-0309
   Crosby M, 2016, APPL INNOV REV, V2, P6, DOI DOI 10.21626/innova/2016.1/01
   De Filippi P., 2017, Harvard Business Review, V15, P1
   Dobrovnik M, 2018, LOGISTICS-BASEL, V2, DOI 10.3390/logistics2030018
   Dorri Ali, 2017, 2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI), P173, DOI 10.1145/3054977.3055003
   Dorri A., 2016, PREPRINT
   Du MX, 2017, IEEE SYS MAN CYBERN, P2567, DOI 10.1109/SMC.2017.8123011
   Duan J, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17051784
   Dubovitskaya Alevtina, 2017, AMIA Annu Symp Proc, V2017, P650
   Dwivedi AD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020326
   Ekblaw A., 2016, A Case Study for Blockchain in Healthcare:"MedRec" prototype for electronic health records and medical research data, DOI DOI 10.1109/OBD.2016.11
   Eyal I, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P45
   Faria C, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P439, DOI 10.1109/Blockchain.2019.00067
   Felin T, 2018, MIT SLOAN MANAGE REV, V60, P32
   Fernández-Caramés TM, 2018, IEEE ACCESS, V6, P32979, DOI 10.1109/ACCESS.2018.2842685
   Ferrag MA, 2019, IEEE INTERNET THINGS, V6, P2188, DOI 10.1109/JIOT.2018.2882794
   Francisco K, 2018, LOGISTICS-BASEL, V2, DOI 10.3390/logistics2010002
   Ge L., 2017, Blockchain for agriculture and food: Findings from the pilot study
   Ghag KV, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND CONTROL (IC4)
   Golosova J, 2018, 2018 IEEE 6TH WORKSHOP ON ADVANCES IN INFORMATION, ELECTRONIC AND ELECTRICAL ENGINEERING (AIEEE)
   Guang Chen, 2018, Smart Learning Environments, V5, DOI 10.1186/s40561-017-0050-x
   HABER S, 1991, LECT NOTES COMPUT SC, V537, P437
   Hafid A, 2019, IEEE ACCESS, V7, P185447, DOI 10.1109/ACCESS.2019.2961065
   Halaburda H., 2018, Commun. ACM, V61, P27, DOI 10.1145/3225619
   Halpin H, 2017, 2017 2ND IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW), P1, DOI 10.1109/EuroSPW.2017.43
   Helebrandt P, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P1221, DOI 10.1109/IEMCON.2018.8614960
   Hertz J., 2019, BIG YEAR SMALL INDEP
   Joung J, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4048960
   Kamble SS, 2018, PROCESS SAF ENVIRON, V117, P408, DOI 10.1016/j.psep.2018.05.009
   Karamchandani A, 2020, INT J INFORM MANAGE, V52, DOI 10.1016/j.ijinfomgt.2019.10.004
   Karame G, 2018, IEEE SECUR PRIV, V16, P11, DOI 10.1109/MSP.2018.3111241
   Khatoon A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010094
   Kiayias A, 2017, LECT NOTES COMPUT SC, V10401, P357, DOI 10.1007/978-3-319-63688-7_12
   Kiyomoto S, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P85, DOI 10.1109/SERA.2017.7965711
   Kraft D, 2016, PEER PEER NETW APPL, V9, P397, DOI 10.1007/s12083-015-0347-x
   Lee L., 2016, Ssrn electronic journal p, V12, P81, DOI DOI 10.2139/SSRN.2656501
   Li HF, 2020, ARTIF INTELL AGR, V4, P253, DOI 10.1016/j.aiia.2020.10.004
   Liang XP, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292361
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Lo SK, 2017, IEEE INT C ENG COMP, P158, DOI 10.1109/ICECCS.2017.26
   Madaan A., 2018, BIG DATA ANAL, P47, DOI [10.1007/978-981-10-6620-7_6, DOI 10.1007/978-981-10-6620-7_6]
   Maesa DD, 2020, J PARALLEL DISTR COM, V138, P99, DOI 10.1016/j.jpdc.2019.12.019
   Manski S, 2017, STRATEG CHANG, V26, P511, DOI 10.1002/jsc.2151
   Marbouh Dounia, 2020, Arab J Sci Eng, V45, P9895, DOI 10.1007/s13369-020-04950-4
   Mattila J., 2016, ETLA Working Papers
   Mavridis T, 2014, ENG APPL ARTIF INTEL, V35, P114, DOI 10.1016/j.engappai.2014.06.008
   McGhin T, 2019, J NETW COMPUT APPL, V135, P62, DOI 10.1016/j.jnca.2019.02.027
   Mearian L., 2021, computer world
   Meshkov D, 2017, LECT NOTES COMPUT SC, V10436, P429, DOI 10.1007/978-3-319-67816-0_25
   Michelman P, 2017, MIT SLOAN MANAGE REV, V58, P17
   Mohanta BK, 2018, INT CONF COMPUT
   Mohanta BK, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100227
   Monrat AA, 2019, IEEE ACCESS, V7, P117134, DOI 10.1109/ACCESS.2019.2936094
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Notheisen B., 2017, P 25 EUROPEAN C INFO, P1062
   Nowinski W, 2017, ENTREPR BUS ECON REV, V5, P173, DOI 10.15678/EBER.2017.050309
   Pass R, 2017, LECT NOTES COMPUT SC, V10211, P643, DOI 10.1007/978-3-319-56614-6_22
   Pedrosa AlejandroRanchal., 2018, P 1 WORKSHOP CRYPTOC, P87
   Pilkington M, 2016, RESEARCH HANDBOOK ON DIGITAL TRANSFORMATIONS, P225
   Pisa M., 2017, BLOCKCHAIN EC DEV HY
   Pixelplex, WORK
   Plisson Jol., 2004, Proceedings of IS, Vvolume 3, P83
   Pop C., 2020, PREPRINT
   Popper N., 2014, NYTIMES
   Porter MF, 2001, Snowball: a language for stemming algorithms
   Puthal D, 2018, IEEE CONSUM ELECTR M, V7, P18, DOI 10.1109/MCE.2017.2776459
   Qiu JL, 2018, IEEE INT SM C CONF
   Nguyen QK, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON GREEN TECHNOLOGY AND SUSTAINABLE DEVELOPMENT (GTSD), P51, DOI 10.1109/GTSD.2016.22
   Saberi S, 2019, INT J PROD RES, V57, P2117, DOI 10.1080/00207543.2018.1533261
   Saghafi F, 2019, ADV INTELL SYST, V800, P499, DOI 10.1007/978-3-030-14070-0_70
   Salimitari M., 2018, PREPRINT
   Samaniego M, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P433, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2016.102
   Scott B, 2017, STRATEG CHANG, V26, P423, DOI 10.1002/jsc.2142
   Sehra SK, 2017, INFORM SOFTWARE TECH, V91, P1, DOI 10.1016/j.infsof.2017.06.002
   Shah Dharambhai, 2020, 2020 4th International Conference on Electronics, Communication and Aerospace Technology (ICECA), P1258, DOI 10.1109/ICECA49313.2020.9297494
   Shahnaz A, 2019, IEEE ACCESS, V7, P147782, DOI 10.1109/ACCESS.2019.2946373
   Sharma S., 2017, AGU Int J Eng Technol, V4, P442
   Sharma S., 2017, 2 INT C INN RES ENG, P7
   Shi SY, 2020, COMPUT SECUR, V97, DOI 10.1016/j.cose.2020.101966
   Sims A., 2019, Blockchain and decentralised autonomous organisations (DAOs): the evolution of companies?
   Slattery T., 2014, Brooklyn Journal Of International Law, V39, P829
   Su CW, 2020, TECHNOL FORECAST SOC, V158, DOI 10.1016/j.techfore.2020.120178
   Subramanian H, 2018, COMMUN ACM, V61, P78, DOI 10.1145/3158333
   Sun Junruo, 2020, 2020 7th International Conference on Dependable Systems and Their Applications (DSA), P478, DOI 10.1109/DSA51864.2020.00081
   Swan M, 2017, TECHNOL INNOV MANAG, V7, P6, DOI 10.22215/timreview/1109
   Tapscott A., 2017, HARVARD BUS REV, V1, P2
   Tapscott D, 2017, MIT SLOAN MANAGE REV, V58, P10
   Tasca P, 2017, ARXIV
   Tikhomirov S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P9, DOI 10.1145/3194113.3194115
   Trautman L.J., 2016, The Consumer Finance Law Quarterly Report, V69, P232
   Ulieru M, 2016, NEW ECON WINDOWS, P297, DOI 10.1007/978-3-319-42448-4_15
   Valenta M., 2017, Comparison of ethereum, hyperledger fabric and corda, V8
   Wang HQ, 2016, FINANC INNOV, V2, DOI 10.1186/s40854-016-0031-z
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   Wang YB, 2018, DECIS SUPPORT SYST, V105, P87, DOI 10.1016/j.dss.2017.11.001
   Webster J.J., 1992, COLING 1992 VOLUME 4, V4
   White GRT, 2017, STRATEG CHANG, V26, P439, DOI 10.1002/jsc.2144
   Wu J, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093067
   Xia Q, 2017, IEEE ACCESS, V5, P14757, DOI 10.1109/ACCESS.2017.2730843
   Xia Q, 2017, INFORMATION, V8, DOI 10.3390/info8020044
   Xu X., 2019, Architecture for Blockchain Applications
   Xu XW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2017), P243, DOI 10.1109/ICSA.2017.33
   Yang LZ, 2019, SMART CITIES CYBERSECURITY AND PRIVACY, P89, DOI 10.1016/B978-0-12-815032-0.00007-X
   Yang WL, 2018, LECT NOTES ARTIF INT, V11016, P201, DOI 10.1007/978-3-319-97289-3_15
   Yun J, 2020, COMPUT IND ENG, V147, DOI 10.1016/j.cie.2020.106636
   Zamani M, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P931, DOI 10.1145/3243734.3243853
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
   Zhu S, 2020, RESOUR POLICY, V66, DOI 10.1016/j.resourpol.2020.101595
NR 139
TC 14
Z9 14
U1 9
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36805
EP 36831
DI 10.1007/s11042-022-13500-z
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000843355500003
PM 36035323
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kumar, A
AF Kumar, Adesh
TI Study and analysis of different segmentation methods for brain tumor MRI
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Magnetic resonance imaging (MRI);
   Image segmentation; Discrete Wavelet Transform (DWT); MATLAB image
   processing
ID AUTOMATIC SEGMENTATION; UNITED-STATES; IMAGES; DWT; STATISTICS;
   ALGORITHM
AB Medical Resonance Imaging (MRI) is one of the preferred imaging methods for brain tumor diagnosis and getting detailed information on tumor type, location, size, identification, and detection. Segmentation divides an image into multiple segments and describes the separation of the suspicious region from pre-processed MRI images to make the simpler image that is more meaningful and easier to examine. There are many segmentation methods, embedded with detection devices, and the response of each method is different. The study article focuses on comparing the performance of several image segmentation algorithms for brain tumor diagnosis, such as Otsu's, watershed, level set, K-means, HAAR Discrete Wavelet Transform (DWT), and Convolutional Neural Network (CNN). All of the techniques are simulated in MATLAB using online images from the Brain Tumor Image Segmentation Benchmark (BRATS) dataset-2018. The performance of these methods is analyzed based on response time and measures such as recall, precision, F-measures, and accuracy. The measured accuracy of Otsu's, watershed, level set, K-means, DWT, and CNN methods is 71.42%, 78.26%, 80.45%, 84.34%, 86.95%, and 91.39 respectively. The response time of CNN is 2.519 s in the MATLAB simulation environment for the designed algorithm. The novelty of the work is that CNN has been proven the best algorithm in comparison to all other methods for brain tumor image segmentation. The simulated and estimated parameters provide the direction to researchers to choose the specific algorithm for embedded hardware solutions and develop the optimal machine-learning models, as the industries are looking for the optimal solutions of CNN and deep learning-based hardware models for the brain tumor.
C1 [Kumar, Adesh] Univ Petr & Energy Studies, Sch Engn, Dept Elect & Elect Engn, Dehra Dun, Uttarakhand, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Kumar, A (corresponding author), Univ Petr & Energy Studies, Sch Engn, Dept Elect & Elect Engn, Dehra Dun, Uttarakhand, India.
EM adeshmanav@gmail.com
RI KUMAR, ADESH/AAP-1581-2020
OI KUMAR, ADESH/0000-0002-0209-9206
CR Abd-Ellah MK, 2019, MAGN RESON IMAGING, V61, P300, DOI 10.1016/j.mri.2019.05.028
   Abiwinanda N, 2019, IFMBE PROC, V68, P183, DOI 10.1007/978-981-10-9035-6_33
   Al-Galal SAY, 2021, HEALTH TECHNOL-GER, V11, P267, DOI 10.1007/s12553-020-00514-6
   Al-Okaili RN, 2007, RADIOLOGY, V243, P539, DOI 10.1148/radiol.2432060493
   Alsabti K., 1997, An efficient k-means clustering algorithm
   Alshayeji M, 2021, MULTIMED TOOLS APPL, V80, P28897, DOI 10.1007/s11042-021-10927-8
   Amin J, 2020, PATTERN RECOGN LETT, V129, P115, DOI 10.1016/j.patrec.2019.11.016
   Anila S, 2017, NATL ACAD SCI LETT, V40, P39, DOI 10.1007/s40009-016-0498-1
   [Anonymous], 2009, ICGST GVIP J
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bisht A, 2019, INT J RECENT TECHNOL, V8, P1
   Chahal PK, 2020, MULTIMED TOOLS APPL, V79, P21771, DOI 10.1007/s11042-020-08898-3
   Chaudhary Atish, 2020, International Journal of Information Technology, V12, P141, DOI 10.1007/s41870-018-0255-4
   Chen PY, 2015, J TRANSL MED, V13, DOI 10.1186/s12967-015-0451-y
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Davis FG, 2008, CANCER EPIDEM BIOMAR, V17, P484, DOI 10.1158/1055-9965.EPI-07-0725
   Di Giacomo AM, 2019, J EXP CLIN CANC RES, V38, DOI 10.1186/s13046-019-1426-2
   Gholipour A, 2007, IEEE T MED IMAGING, V26, P427, DOI 10.1109/TMI.2007.892508
   Ghosh KK, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114485
   Glover GH, 1999, MAGNET RESON MED, V42, P412, DOI 10.1002/(SICI)1522-2594(199908)42:2<412::AID-MRM25>3.0.CO;2-U
   Goel A., 2016, INT J COMPUT SCI INF, V14, P228
   Gupta N, 2021, MULTIMED TOOLS APPL, V80, P22301, DOI 10.1007/s11042-021-10820-4
   Gupta N, 2017, SIGNAL PROCESS-IMAGE, V59, P18, DOI 10.1016/j.image.2017.05.013
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hasan S M Kamrul, 2018, Brain Inform, V5, P8, DOI 10.1186/s40708-018-0086-x
   Hooda A, 2022, MOL CRYST LIQ CRYST, V726, P90, DOI 10.1080/15421406.2021.1935162
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Hussain S, 2018, NEUROCOMPUTING, V282, P248, DOI 10.1016/j.neucom.2017.12.032
   Iqbal S, 2018, MICROSC RES TECHNIQ, V81, P419, DOI 10.1002/jemt.22994
   Isin A, 2016, PROCEDIA COMPUT SCI, V102, P317, DOI 10.1016/j.procs.2016.09.407
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jayaraman S., 2009, DIGITAL IMAGE PROCES
   Jose A., 2014, INT J INNOV RES COMP, V2
   Joseph RohiniPaul., 2014, INT J RES ENG TECHNO, V3, P1, DOI DOI 10.15623/IJRET.2014.0301001
   Junyao Wang, 2020, Procedia Computer Science, V174, P443, DOI 10.1016/j.procs.2020.06.112
   Kaur P, 2019, MULTIMED TOOLS APPL, V78, P19905, DOI 10.1007/s11042-019-7327-8
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   Khode K. M. R., 2017, INT J ENG RES APPL, V7, P55
   Kumar Adesh, 2021, International Journal of Organizational and Collective Intelligence, V11, P1, DOI 10.4018/IJOCI.2021070105
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Kumar A, 2015, PROCEDIA COMPUT SCI, V57, P1015, DOI 10.1016/j.procs.2015.07.512
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar Munish, 2020, ACM Digital Government: Research and Practice, V1, DOI 10.1145/3411760
   Kumaria A, 2021, J KOREAN NEUROSURG S, V64, P469, DOI 10.3340/jkns.2020.0188
   Li BN, 2012, EXPERT SYST APPL, V39, P9661, DOI 10.1016/j.eswa.2012.02.095
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Moeskops P, 2016, IEEE T MED IMAGING, V35, P1252, DOI 10.1109/TMI.2016.2548501
   Moeskops P, 2015, NEUROIMAGE, V118, P628, DOI 10.1016/j.neuroimage.2015.06.007
   Mustaqeem Anam, 2012, International Journal of Image, Graphics and Signal Processing, V4, P34, DOI 10.5815/ijigsp.2012.10.05
   Nanda SJ, 2019, APPL ARTIF INTELL, V33, P152, DOI 10.1080/08839514.2018.1530869
   Nazir M, 2021, COMPUT MED IMAG GRAP, V91, DOI 10.1016/j.compmedimag.2021.101940
   Olszewska JI, 2020, J INTELL ROBOT SYST, V98, P119, DOI 10.1007/s10846-019-01107-w
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Ostrom Quinn T, 2019, Neuro Oncol, V21, pv1, DOI 10.1093/neuonc/noz150
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pardakhti N, 2020, MULTIMED TOOLS APPL, V79, P25051, DOI 10.1007/s11042-020-09121-z
   Patil R. C., 2012, Int J Electron Commun Soft Comput Sci Eng, P1
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Porter KR, 2010, NEURO-ONCOLOGY, V12, P520, DOI 10.1093/neuonc/nop066
   Remya R, 2022, IETE J RES, V68, P1532, DOI 10.1080/03772063.2019.1656555
   Roy S, 2012, International Journal of Information and Communication Technology Research, V2, P477
   Sain PK., 2015, INT RES J ENG TECHNO, V2, P191
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Thapaliya K, 2013, COMPUT MED IMAG GRAP, V37, P522, DOI 10.1016/j.compmedimag.2013.05.003
   Tivaskar SP, 2021, INDIAN J FORENSIC ME, V15
   Varuna Shree N, 2018, BRAIN INFORM, V5, P23, DOI DOI 10.1007/S40708-017-0075-5
   Virupakshappa, 2020, MULTIMED TOOLS APPL, V79, P3571, DOI 10.1007/s11042-018-6176-1
   Vrji K. S. Angel, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P145, DOI 10.1109/ICSCCN.2011.6024532
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Weathers SP, 2015, J NEURO-ONCOL, V123, P331, DOI 10.1007/s11060-015-1716-2
   Zhang C, 2019, INT J BIOMED IMAGING, V2019, DOI 10.1155/2019/7305832
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
NR 81
TC 20
Z9 20
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7117
EP 7139
DI 10.1007/s11042-022-13636-y
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000841079300004
PM 35991584
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Wang, QP
   Luo, L
   Xie, HR
   Rao, YH
   Lau, RYK
   Zhang, DT
AF Wang, Qiping
   Luo, Ling
   Xie, Haoran
   Rao, Yanghui
   Lau, Raymond Y. K.
   Zhang, Detian
TI A deep data augmentation framework based on generative adversarial
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data augmentation; Convolutional neural networks; Generative adversarial
   networks
ID RECOGNITION
AB In the process of training convolutional neural networks, the training data is often insufficient to obtain ideal performance and encounters the overfitting problem. To address this issue, traditional data augmentation (DA) techniques, which are designed manually based on empirical results, are often adopted in supervised learning. Essentially, traditional DA techniques are in the implicit form of feature engineering. The augmentation strategies should be designed carefully, for example, the distribution of augmented samples should be close to the original data distribution. Otherwise, it will reduce the performance on the test set. Instead of designing augmentation strategies manually, we propose to learn the data distribution directly. New samples can then be generated from the estimated data distribution. Specifically, a deep DA framework is proposed which consists of two neural networks. One is a generative adversarial network, which is used to learn the data distribution, and the other one is a convolutional neural network classifier. We evaluate the proposed model on a handwritten Chinese character dataset and a digit dataset, and the experimental results show it outperforms baseline methods including one manually well-designed DA method and two state-of-the-art DA methods.
C1 [Wang, Qiping] East China Normal Univ, Shanghai, Peoples R China.
   [Luo, Ling; Rao, Yanghui] Sun Yat Sen Univ, Guangzhou, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Hong Kong, Peoples R China.
   [Lau, Raymond Y. K.] City Univ Hong Kong, Kowloon, Hong Kong, Peoples R China.
   [Zhang, Detian] Soochow Univ, Suzhou, Peoples R China.
C3 East China Normal University; Sun Yat Sen University; Lingnan
   University; City University of Hong Kong; Soochow University - China
RP Xie, HR (corresponding author), Lingnan Univ, Hong Kong, Peoples R China.
EM qpwang@fem.ecnu.edu.cn; luol26@mail2.sysu.edu.cn; hrxie2@gmail.com;
   raoyangh@mail.sysu.edu.cn; raylau@cityu.edu.hk; detian.cs@gmail.com
RI Xie, Haoran/AAW-8845-2020; Xie, Haoran/AFS-3515-2022
OI Xie, Haoran/0000-0003-0965-3617
FU Education University of Hong Kong [FLASS/DRF/IDS-3, MIT/DCRF-R2/18-19];
   Fundamental Research Funds for the Central Universities, China
   [2022ECNU-HLYT001]; Lingnan University, Hong Kong [DR22A2]
FX The research of this work has been supported by the Dean's Research Fund
   2018-19 (FLASS/DRF/IDS-3), Departmental Collaborative Research Fund 2019
   (MIT/DCRF-R2/18-19) of The Education University of Hong Kong, a grant
   from the Fundamental Research Funds for the Central Universities, China
   (Projects: 2022ECNU-HLYT001) and the Direct Grant (DR22A2) of Lingnan
   University, Hong Kong.
CR Abadi Martin, 2016, arXiv
   [Anonymous], 2017, ARXIV
   Antoniou A, 2018, LECT NOTES COMPUT SC, V11141, P594, DOI 10.1007/978-3-030-01424-7_58
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Brock A., 2018, PREPRINT
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Denton E, 2015, ADV NEUR IN, V28
   Dixit M, 2017, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2017.355
   Fawzi A, 2016, IEEE IMAGE PROC, P3688, DOI 10.1109/ICIP.2016.7533048
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hauberg S, 2016, JMLR WORKSH CONF PRO, V51, P342
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jaderberg M., 2014, ARXIV
   Jha G, 2020, MULTIMED TOOLS APPL, V79, P35055, DOI 10.1007/s11042-020-08883-w
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li W, 2019, IEEE GEOSCI REMOTE S, V16, P593, DOI 10.1109/LGRS.2018.2878773
   Li Z, 2020, MULTIMED TOOLS APPL, V79, P4931, DOI 10.1007/s11042-018-7071-5
   Liu CL, 2011, PROC INT CONF DOC, P1464, DOI 10.1109/ICDAR.2011.291
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mao XJ, 2016, ADV NEUR IN, V29
   Mariani G., 2018, ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Miyato T., 2018, ARXIV
   Nowozin S., 2016, ARXIV
   Odena A, 2016, ARXIV
   Paulin M, 2014, PROC CVPR IEEE, P3646, DOI 10.1109/CVPR.2014.466
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Radford A., 2015, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salimans T, 2016, ADV NEUR IN, V29
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg J. T., 2015, ARXIV PREPRINT ARXIV
   Wang G., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508369
   Wang J., 2017, arXiv
   Wang SH, 2018, J REAL-TIME IMAGE PR, V15, P631, DOI 10.1007/s11554-017-0717-0
   Xiaodong Cui, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5582, DOI 10.1109/ICASSP.2014.6854671
   Yin X., 2018, ARXIV
   Yu Q, 2019, AAAI CONF ARTIF INTE, P411
   Zeng SN, 2020, MULTIMED TOOLS APPL, V79, P20617, DOI 10.1007/s11042-020-08918-2
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhu X, 2017, ARXIV
NR 52
TC 1
Z9 1
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42871
EP 42887
DI 10.1007/s11042-022-13476-w
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840291300003
DA 2024-07-18
ER

PT J
AU Banerjee, A
   Maji, D
   Datta, R
   Barman, S
   Samanta, D
   Chattopadhyay, S
AF Banerjee, Ayan
   Maji, Dibyendu
   Datta, Rajdeep
   Barman, Subhas
   Samanta, Debasis
   Chattopadhyay, Samiran
TI SHUBHCHINTAK An efficient remote health monitoring approach for elderly
   people
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote health monitoring; Wireless sensors; Health anomaly for elderly
   people; Cloud-based application; Artificial intelligence approach to
   health data classification
ID SYSTEM; RECOGNITION; DESIGN; MODEL
AB With the proliferation of IoT technology, it is anticipated that healthcare services, particularly for the elderly persons, will become a major thrust area of research in the coming days. Aim of this work is to design a fit-band containing multiple sensors to provide remote healthcare services for the elderly persons. An application has been designed to capture health data from the fit-band, pre-process the data and then send them to cloud for further analysis. A wireless Bluetooth enabled connection is proposed to establish communications between sensors and the application for data transmission. In the proposed application, there are three different front-end interfaces for three different users: system administrator, patient and doctor. The data collected from the patient's fit-band are sent to a cloud data storage, where the data will be analyzed to detect anomaly (e.g., heart attack, sleep apnea, etc.). A Convolution Neural Network (CNN) model is proposed for anomaly detection. For the classification of anomaly, a Long Short Term Memory (LSTM) model is proposed. In the presence of anomaly, the system immediately connects a doctor through a phone call. A prototype system termed as Shubhchintak has been developed in Android/IOS environment and tested with a number of users. The fit-band provides data tracking with an overall accuracy of 99%; the system provides a response with 3000 requests in less than 100 ms. Also, Shubhchintak provides a real-time feedback with an accuracy of 97%. Shubhchintak is also tested by patients and doctors of a nearby hospital. Shubhchintak is shown to be a simple to use, cost effective, comfortable, and efficient system compared to the existing state of the art solutions.
C1 [Banerjee, Ayan; Maji, Dibyendu; Datta, Rajdeep; Barman, Subhas] Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri 735102, India.
   [Samanta, Debasis] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Chattopadhyay, Samiran] TCG CREST, Inst Adv Intelligence, Kolkata 700091, India.
   [Chattopadhyay, Samiran] Jadavpur Univ, Dept Informat Technol, Kolkata 700106, India.
C3 Jalpaiguri Government Engineering College; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Kharagpur; Jadavpur University
RP Barman, S (corresponding author), Jalpaiguri Govt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri 735102, India.
EM ab2141@cse.jgec.ac.in; dibyendumaji415@gmail.com; rajdeep2898@gmail.com;
   subhas.barman@gmail.com; debasis.samanta.iitkgp@gmail.com;
   samirancju@gmail.com
RI Barman, Subhas/AAH-5244-2019; Chattopadhyay, Samiran/AAW-3145-2021
OI Barman, Subhas/0000-0002-3206-1110; Chattopadhyay,
   Samiran/0000-0002-8929-9605; Banerjee, Ayan/0000-0002-0269-2202
CR Agrawal S, 2015, PROCEDIA COMPUT SCI, V60, P708, DOI 10.1016/j.procs.2015.08.220
   Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   Andres J, 2018, J MANAG CARE SPEC PH, V24, P23, DOI 10.18553/jmcp.2018.24.1.23
   [Anonymous], ?About us"
   Apple, 2020, APPL WATCH SER 5
   Apple Inc, 2016, INTRO HEALTHKIT
   Apple Inc, 2016, HEALTHKIT API REF
   Atoui H, 2010, IEEE T INF TECHNOL B, V14, P883, DOI 10.1109/TITB.2010.2047754
   Baig MM, 2015, AUSTRALAS PHYS ENG S, V38, P23, DOI 10.1007/s13246-014-0315-4
   Bansal A, 2015, IET SYST BIOL, V9, P309, DOI 10.1049/iet-syb.2015.0012
   Bansal D, 2009, COMPUT BIOL MED, V39, P361, DOI 10.1016/j.compbiomed.2009.01.013
   Bansal M, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P205, DOI 10.1109/ICICT50816.2021.9358677
   Barnwell JD, 2012, INT J CARDIOVAS IMAG, V28, P587, DOI 10.1007/s10554-011-9865-7
   Bergmann JHM, 2011, ANN BIOMED ENG, V39, P2299, DOI 10.1007/s10439-011-0339-9
   Bouchard B, 2007, APPL ARTIF INTELL, V21, P623, DOI 10.1080/08839510701492579
   Catarinucci L, 2015, IEEE INTERNET THINGS, V2, P515, DOI 10.1109/JIOT.2015.2417684
   Cefalu WT, 2019, DIABETES CARE, V42, pS34, DOI 10.2337/dc19-S004
   Cisco Visual Networking Index, 2019, FOR TRENDS 2017 2022
   Clark M., 2015, SENSORS TRANSDUCERS, V184, P77
   Durán-Vega LA, 2019, GERIATRICS-BASEL, V4, DOI 10.3390/geriatrics4020034
   Fitbit Inc, FITB SDK
   Garbhapu VV, 2017, PROCEDIA COMPUT SCI, V113, P408, DOI 10.1016/j.procs.2017.08.357
   Ghosh AM, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P921, DOI 10.1109/ICIEV.2016.7760135
   Ghosh A, 2020, INTERNET THINGS-NETH, V9, DOI 10.1016/j.iot.2020.100166
   Google Inc, 2016, FIT SDK OV
   Google Inc, FIT APIS
   Hossain MZ, 2020, J EVAL CLIN PRACT, V26, P1629, DOI [10.1115/1.4047563, 10.1111/jep.13361, 10.1007/s12652-020-02579-7]
   Huawei Consumer Business Group, HONOR BAND
   Juyal S, 2021, MATER TODAY-PROC, V46, P10539, DOI 10.1016/j.matpr.2021.01.074
   Kassambara A., 2021, PACKAGE DTWSATR TOPI, P1
   Keong HC, 2008, IEEE ENG MED BIO, P3413, DOI 10.1109/IEMBS.2008.4649939
   Khoi NM, 2015, 2015 17TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATION & SERVICES (HEALTHCOM), P563, DOI 10.1109/HealthCom.2015.7454565
   Kole A, 2019, CIRCULATION, V140
   Kong DG, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P530, DOI 10.1145/2810103.2813689
   Maiolo C, 2003, J TELEMED TELECARE, V9, P67, DOI 10.1258/135763303321327902
   Majumder S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010130
   Nienhold D, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P473, DOI 10.1109/ICHI.2016.87
   Paganelli AI, 2022, INTERNET THINGS-NETH, V18, DOI 10.1016/j.iot.2021.100399
   Pandya Sharnil, 2021, Proceedings of Second International Conference on Computing, Communications, and Cyber-Security. IC4S 2020. Lecture Notes in Networks and Systems (LNNS 203), P3, DOI 10.1007/978-981-16-0733-2_1
   Pardeshi V, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P134, DOI 10.1109/ICIMIA.2017.7975587
   Prabha D., 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P453, DOI 10.1109/ICOEI51242.2021.9452911
   Ramesh Saha, 2021, SN Comput Sci, V2, P33, DOI 10.1007/s42979-020-00434-2
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saha J, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P602, DOI 10.1109/CCWC.2018.8301659
   Scalvini S, 2004, J TELEMED TELECARE, V10, P113, DOI 10.1258/135763304773391576
   Srinivasulu A, 2016, INDIAN J MEDNODENT A, P126
   Taleb N, 2016, DIABETES TECHNOL THE, V18, P561, DOI 10.1089/dia.2015.0394
   Valliappan S., 2017, 2017 International Conference on IoT and Application (ICIOT), P1, DOI DOI 10.1109/ICIOTA.2017.8073612
   Vedaei SS, 2020, IEEE ACCESS, V8, P188538, DOI 10.1109/ACCESS.2020.3030194
   Verma P, 2018, IEEE INTERNET THINGS, V5, P1789, DOI 10.1109/JIOT.2018.2803201
   Vitacca M, 2006, J TELEMED TELECARE, V12, P337, DOI 10.1258/135763306778682404
   Wang HF, 2020, COMPUT COMMUN, V160, P588, DOI 10.1016/j.comcom.2020.04.025
   Wani R.T., 2019, BMJ Innov, V5, P135, DOI [10.1136/bmjinnov-2019-000345, DOI 10.1136/BMJINNOV-2019-000345]
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wu TY, 2020, IEEE INTERNET THINGS, V7, P6932, DOI 10.1109/JIOT.2020.2977164
   Xiaomi Inc, MI BAND
   Yao Jianchu, 2005, J Clin Monit Comput, V19, P427, DOI 10.1007/s10877-005-2033-7
   Yeri Vani, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P980, DOI 10.1109/ICIRCA48905.2020.9183194
   Zhong CL, 2020, MEASUREMENT, V159, DOI 10.1016/j.measurement.2020.107774
   US
NR 60
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37137
EP 37163
DI 10.1007/s11042-022-13539-y
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840140800007
PM 35968413
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Shakoor, MH
   Boostani, R
   Sabeti, M
   Mohammadi, M
AF Shakoor, Mohammad Hossein
   Boostani, Reza
   Sabeti, Malihe
   Mohammadi, Mokhtar
TI Feature selection and mapping of local binary pattern for texture
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Features mapping; Local binary patterns; Features selection; Texture
   classification
ID FACE RECOGNITION; GRAY-SCALE; ROTATION; DESCRIPTOR
AB Local binary pattern is one of the most known descriptors, which is used for texture classification. Although completed local binary pattern is seemingly the most precise variant of this type of descriptor and provides high classification accuracy by joining three histograms of features. Merging these histograms increases the features number significantly. To reduce the size of features, in this paper, some mapping methods are proposed for feature reduction and mapping of these features into a histogram. All of the proposed mapping methods are rotation and illumination invariant. Furthermore, a constraint feature selection method is proposed that selects discriminative features. Applying the introduced methods to the known benchmarks like Outex (TC3, TC10, TC13, TC12(t) and TC12(h)), UIUC, CUReT and Defect Fabric datasets indicates that even by adopting lower number of features, the classification rate is enhanced from 1% to 9% while the features number are decreased around 10% to 99%. Comparison results on the same datasets imply the superiority of the proposed schemes to the conventional methods.
C1 [Shakoor, Mohammad Hossein] Arak Univ, Fac Engn, Dept Comp Engn, Arak 3815688349, Iran.
   [Boostani, Reza; Mohammadi, Mokhtar] Shiraz Univ, Sch Elect & Comp Engn, Comp Engn Dept, Shiraz, Iran.
   [Sabeti, Malihe] Azad Univ, Dept Comp Engn, North Tehran Branch, Tehran, Iran.
C3 Arak University; Shiraz University; Islamic Azad University
RP Shakoor, MH (corresponding author), Arak Univ, Fac Engn, Dept Comp Engn, Arak 3815688349, Iran.
EM mh-shakoor@araku.ac.ir; boostani@shirazu.ac.ir; sabeti@shirazu.ac.ir;
   Mukhtar@lfu.edu.iq
RI Boostani, Reza/ABC-5999-2021
OI mohammadi, mokhtar/0000-0002-1393-5062
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 1997, NONPARAMETRIC TEXTUR
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688
   Bianconi F, 2011, J MATH IMAGING VIS, V40, P259, DOI 10.1007/s10851-011-0261-7
   Campisi P, 2004, IEEE T IMAGE PROCESS, V13, P782, DOI 10.1109/TIP.2003.822607
   Chakraborty S, 2017, COMPUT ELECTR ENG, V62, P92, DOI 10.1016/j.compeleceng.2017.06.013
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dash M., 1997, Intelligent Data Analysis, V1
   Du SL, 2016, OPTIK, V127, P6583, DOI 10.1016/j.ijleo.2016.04.002
   Ebenuwa SH, 2019, IEEE ACCESS, V7, P24649, DOI 10.1109/ACCESS.2019.2899578
   EICHMANN G, 1988, COMPUT VISION GRAPH, V41, P267, DOI 10.1016/0734-189X(88)90102-8
   El Merabet Y, 2018, PATTERN RECOGN, V76, P303, DOI 10.1016/j.patcog.2017.11.005
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Gu Q., 2011, Graphics Interface 2011, P266, DOI DOI 10.5555/1992917.1992919
   Guo ZH, 2012, NEURAL COMPUT APPL, V21, P1893, DOI 10.1007/s00521-011-0586-6
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hadizadeh H, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P30, DOI 10.1109/AISP.2015.7123521
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Hu Y, 2016, PALGR MAC STUD FAM, P25, DOI 10.1007/978-3-319-29281-6_2
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   Huang Y., 2006, BMVC, P879
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Kalakech M, 2015, INT CONF IMAG PROC, P242, DOI 10.1109/IPTA.2015.7367138
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   Kim ND, 2000, IEEE T SYST MAN CY A, V30, P847, DOI 10.1109/3468.895915
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   Kou QQ, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.162999
   Lam WK, 1997, IEE P-VIS IMAGE SIGN, V144, P171, DOI 10.1049/ip-vis:19971198
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu L, 2016, LECT NOTES COMPUT SC, V9907, P69, DOI 10.1007/978-3-319-46487-9_5
   Liu MX, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500098
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MIR AH, 1995, IEEE ENG MED BIOL, V14, P781, DOI 10.1109/51.473275
   Moujahid A., 2016, ELECT IMAG, V28, P1
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nanni L, 2012, PATTERN RECOGN, V45, P3844, DOI 10.1016/j.patcog.2012.04.007
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Porebski A, 2013, IEEE IMAGE PROC, P3239, DOI 10.1109/ICIP.2013.6738667
   Porebski A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.011010
   Priya RMS, 2020, COMPUT COMMUN, V160, P139, DOI 10.1016/j.comcom.2020.05.048
   Qi XB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.40
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Shakoor MH, 2017, SCI IRAN, V24, P1419, DOI 10.24200/sci.2017.4124
   Shakoor MH, 2021, J MACH VIS IMAGE PRO
   Shakoor MH, 2021, MULTIMED TOOLS APPL, V80, P8639, DOI 10.1007/s11042-020-10084-4
   Shakoor MH, 2019, IET IMAGE PROCESS, V13, P877, DOI 10.1049/iet-ipr.2018.5070
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P21481, DOI 10.1007/s11042-017-5440-0
   Shakoor MH, 2017, MULTIMED TOOLS APPL, V76, P8031, DOI 10.1007/s11042-016-3455-6
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shakoor MH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500197
   Shrivastava N, 2016, MULTIMED TOOLS APPL, V75, P10887, DOI 10.1007/s11042-015-2811-2
   Song TC, 2018, IEEE SIGNAL PROC LET, V25, P625, DOI 10.1109/LSP.2018.2809607
   Song TC, 2014, IEEE SIGNAL PROC LET, V21, P93, DOI 10.1109/LSP.2013.2293335
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Talab ARR, 2018, INT C INT SYST COMP, P1
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tian G, 2008, P 5 INT C INF TECHN, P5153
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Hoang VT, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P476, DOI 10.5220/0006128204760483
   Wang S, 2015, IEEE T CIRC SYST VID, V25, P1495, DOI 10.1109/TCSVT.2015.2406198
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DQ, 2008, PATTERN RECOGN, V41, P1440, DOI 10.1016/j.patcog.2007.10.009
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151, DOI DOI 10.1145/1273496.1273641
NR 92
TC 10
Z9 10
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7639
EP 7676
DI 10.1007/s11042-022-13470-2
EA AUG 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000836366300006
DA 2024-07-18
ER

PT J
AU Rastgoo, R
   Kiani, K
   Escalera, S
AF Rastgoo, Razieh
   Kiani, Kourosh
   Escalera, Sergio
TI A deep co-attentive hand-based video question answering framework using
   multi-view skeleton
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video question answering (video-QA); Dynamic hand gesture recognition;
   BERT; Co-attention; RGB video
ID NETWORKS
AB In this paper, we present a novel hand -based Video Question Answering framework, entitled Multi-View Video Question Answering (MV-VQA), employing the Single Shot Detector (SSD), Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Bidirectional Encoder Representations from Transformers (BERT), and Co-Attention mechanism with RGB videos as the inputs. Our model includes three main blocks: vision, language, and attention. In the vision block, we employ a novel representation to obtain some efficient multiview features from the hand object using the combination of five 3DCNNs and one LSTM network. To obtain the question embedding, we use the BERT model in language block. Finally, we employ a co-attention mechanism on vision and language features to recognize the final answer. For the first time, we propose such a hand-based Video-QA framework including the multi-view hand skeleton features combined with the question embedding and co-attention mechanism. Our framework is capable of processing the arbitrary numbers of questions in the dataset annotations. There are different application domains for this framework. Here, as an application domain, we applied our framework to dynamic hand gesture recognition for the first time. Since the main object in dynamic hand gesture recognition is the human hand, we performed a step-by-step analysis of the hand detection and multi-view hand skeleton impact on the model performance. Evaluation results on five datasets, including two datasets in VideoQA, two datasets in dynamic hand gesture, and one dataset in hand action recognition show that MV-VQA outperforms state-of-the-art alternatives.
C1 [Rastgoo, Razieh; Kiani, Kourosh] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
   [Escalera, Sergio] Univ Barcelona, Barcelona, Spain.
   [Escalera, Sergio] Comp Vis Ctr, Barcelona, Spain.
C3 Semnan University; University of Barcelona; Centre de Visio per
   Computador (CVC)
RP Kiani, K (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM rrastgoo@semnan.ac.ir; Kourosh.kiani@semnan.ac.ir; sergio@maia.ub.es
RI Rastgoo, Razieh/AFO-9957-2022; Kiani, Kourosh/T-7468-2019; Escalera,
   Sergio/L-2998-2015
OI Rastgoo, Razieh/0000-0001-7963-9461; Kiani, Kourosh/0000-0001-6582-8691;
   Escalera, Sergio/0000-0003-0617-8873
FU ICREA [PID2019-105093GB-I00]; High Intelligent Solution (HIS) company in
   Iran
FX This work has been partially supported by the Spanish project
   PID2019-105093GB-I00, ICREA under the ICREA Academia programme, and High
   Intelligent Solution (HIS) company in Iran.
CR Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277
   Cerda P, 2018, MACH LEARN, V107, P1477, DOI 10.1007/s10994-018-5724-2
   Chai JY, 2019, INT CONF MACH LEARN, P535, DOI 10.1109/icmlc48188.2019.8949185
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   DSouza, 2020, MEDIUM
   Duan J, 2016, ARXIV
   El Adlouni Y, 2019, EXPERT SYST APPL, V137, P432, DOI 10.1016/j.eswa.2019.07.024
   Fan CY, 2019, PROC CVPR IEEE, P1999, DOI 10.1109/CVPR.2019.00210
   Gao JY, 2018, PROC CVPR IEEE, P6576, DOI 10.1109/CVPR.2018.00688
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hosseinabad SH, 2021, VISUAL COMPUT, V37, P119, DOI 10.1007/s00371-019-01786-4
   Hu GY, 2020, IEEE T MULTIMEDIA, V22, P2207, DOI 10.1109/TMM.2019.2953325
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Li LJ, 2019, IEEE WINT CONF APPL, P339, DOI 10.1109/WACV.2019.00042
   Li W, 2018, PATTERN RECOGN LETT, V105, P23, DOI 10.1016/j.patrec.2017.10.012
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Lu JS, 2016, ADV NEUR IN, V29
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Nabati M, 2020, COMPUT VIS IMAGE UND, V190, DOI 10.1016/j.cviu.2019.102840
   Narayana P, 2018, PROC CVPR IEEE, P5235, DOI 10.1109/CVPR.2018.00549
   Neves G, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112870
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Peris A, 2016, LECT NOTES COMPUT SC, V9887, P3, DOI 10.1007/978-3-319-44781-0_1
   Rastgoo R, 2022, ARXIV
   Rastgoo R, 2021, ARXIV
   Rastgoo R, 2021, IEEE COMPUT SOC CONF, P3446, DOI 10.1109/CVPRW53098.2021.00384
   Rastgoo R, 2022, J AMB INTEL HUM COMP, V13, P591, DOI 10.1007/s12652-021-02920-8
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   Rastgoo R, 2021, MULTIMED TOOLS APPL, V80, P127, DOI 10.1007/s11042-020-09700-0
   Rastgoo R, 2020, MULTIMED TOOLS APPL, V79, P22965, DOI 10.1007/s11042-020-09048-5
   Rastgoo R, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113336
   Rastgoo R, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110809
   Ren FJ, 2020, INT J INF TECH DECIS, V19, P5, DOI 10.1142/S0219622019300052
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang HG, 2017, IEEE INT CONF COMP V, P3129, DOI 10.1109/ICCVW.2017.370
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wang WN, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107248
   Wu CF, 2019, AAAI CONF ARTIF INTE, P8997
   Xu DJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1645, DOI 10.1145/3123266.3123427
   Xu JL, 2016, PROC CVPR IEEE, P5356, DOI 10.1109/CVPR.2016.578
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yi KX, 2018, ADV NEUR IN, V31
   Yu HN, 2016, PROC CVPR IEEE, P4584, DOI 10.1109/CVPR.2016.496
   Zeng KH, 2017, AAAI CONF ARTIF INTE, P4334
   Zha ZJ, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3320061
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhao Z, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3690
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
NR 56
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1401
EP 1429
DI 10.1007/s11042-022-13573-w
EA AUG 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000834736500009
DA 2024-07-18
ER

PT J
AU Arshaghi, A
   Ashourian, M
   Ghabeli, L
AF Arshaghi, Ali
   Ashourian, Mohsen
   Ghabeli, Leila
TI Potato diseases detection and classification using deep learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Deep learning; Defect detection; Potato
   diseases; Potato classification
ID FRUIT
AB Using machine vision and image processing methods has an important role in the identification of defects of agricultural products, especially potatoes. The applications of image processing and artificial intelligence in agriculture in identifying and classifying pests and diseases of plants and fruits have increased and research in this field is ongoing. In this paper, we use the convolution neural network (CNN) methods, also, we examined 5 classes of potato diseases with the names: Healthy, Black Scurf, Common Scab, Black Leg, Pink Rot. We used a database of 5000 potato images. We compared the results of potato defect classification our methods with other methods such as Alexnet, Googlenet, VGG, R-CNN, Transfer Learning. The results show that the accuracy of the deep learning proposed method is higher than other existing works. We get 100% and 99% accuracy in some of the classes, respectively.
C1 [Arshaghi, Ali; Ghabeli, Leila] Islamic Azad Univ, Dept Elect Engn, Cent Tehran Branch, Tehran, Iran.
   [Ashourian, Mohsen] Islamic Azad Univ, Dept Elect Engn, Majlesi Branch, Esfahan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Arshaghi, A (corresponding author), Islamic Azad Univ, Dept Elect Engn, Cent Tehran Branch, Tehran, Iran.
EM ali.arshagleng@iauctb.ac.ir
RI Arshaghi, Ali/GLR-5601-2022; arshaghi, ali/AGY-7877-2022
OI Arshaghi, Ali/0000-0002-3281-1938; 
CR Al Riza DF, 2017, POSTHARVEST BIOL TEC, V133, P12, DOI 10.1016/j.postharvbio.2017.07.006
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   [Anonymous], 2017, 2017 EFITA WCCA C MO
   [Anonymous], 2015, WORKING NOTES CLEF 2
   [Anonymous], 2016, NEUROCOMPUTING, DOI [DOI 10.1016/J.NEUC0M.2015.09.116, DOI 10.1016/J.NEUCOM.2015.09.116, 10. 1016/j.neucom.2015.09.116]
   Arivazhagan S., 2013, Agricultural Engineering International: CIGR Journal, V15, P211
   Arshaghi A, 2020, MULTIMED TOOLS APPL, V79, P26623, DOI 10.1007/s11042-020-09236-3
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Blasco J, 2017, ADV BIOCHEM ENG BIOT, V161, P71, DOI 10.1007/10_2016_51
   Brar E. S., 2016, INDIAN J SCI TECHNO, V9
   Canziani A., 2016, An Analysis of Deep Neural Network Models for Practical Applications
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dasgupta Soumik Ranjan, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P675, DOI 10.1007/978-981-13-9042-5_58
   Dorado JICLC, 2016, LPU LAGUNA J ENG COM, V3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao YW, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101734
   Gené-Mola J, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105165
   Hanwen Kang CC, 2020, FRUIT DETECTION SEGM, V171
   Jia S, 2021, NEUROCOMPUTING, V448, P179, DOI 10.1016/j.neucom.2021.03.035
   Korot E, 2021, NAT MACH INTELL, V3, P288, DOI 10.1038/s42256-021-00305-2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee Hyeon-Seung, 2020, Journal of Biosystems Engineering, V45, P233
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Li JB, 2016, COMPUT ELECTRON AGR, V127, P582, DOI 10.1016/j.compag.2016.07.016
   Loddo A, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106269
   Lu H, 2017, J MT SCI-ENGL, V14, P731, DOI 10.1007/s11629-016-3950-2
   Moallem Payman, 2017, Information Processing in Agriculture, V4, P33, DOI 10.1016/j.inpa.2016.10.003
   Moallem P, 2014, IRAN J FUZZY SYST, V11, P47
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nicolai Hani PR, 2019, COMP STUDY FRUIT DET
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pin Wang EF, 2020, PATTERN RECOGN LETT
   Qinghua Su NK, 2020, POTATO QUALITY GRADI, V2020
   Razmjooy RDN, 2011, MAJLESI C ELECT ENG
   Ronald MEM, 2016, IND J COMPUT SCI ENG, V7
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Saberkari, 2016, INT J AGR MANAGE DEV, V6, P181
   Sahu D., 2017, INT J SCI RES COMPUT, V2, P203
   Schielen R, 2016, BIORXIV
   Sengupta S., 2014, International Journal of Computer Science and Information Technologies, V5, P4638
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XD, 2016, J ARID LAND, V8, P734, DOI 10.1007/s40333-016-0049-0
   Steen KA, 2016, J IMAGING, V2, DOI 10.3390/jimaging2010006
   Sudhir DSKM, 2017, INT RES J ENG TECHNO, V4
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thyagharajan KK, 2019, ARCH COMPUT METHOD E, V26, P933, DOI 10.1007/s11831-018-9266-3
   Thyagharajan KR, 2021, CMC-COMPUT MATER CON
   Tiwari D, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P461, DOI [10.1109/iciccs48265.2020.9121067, 10.1109/ICICCS48265.2020.9121067]
   Van de Vijver R, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105106
   Wang XS, 2015, ASIAPAC SIGN INFO PR, P408
   Yang Liu ZZ, 2021, PERFORMANCE EVALUATI, V171
   Yogesh, 2016, INT CONF RELI INFO, P590, DOI 10.1109/ICRITO.2016.7785023
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang LP, 2016, J SENSORS, V2016, DOI 10.1155/2016/7954154
   Zhang WW, 2019, FOOD ANAL METHOD, V12, P2920, DOI 10.1007/s12161-019-01654-w
NR 62
TC 14
Z9 14
U1 16
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5725
EP 5742
DI 10.1007/s11042-022-13390-1
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000833514100005
DA 2024-07-18
ER

PT J
AU Boccignone, G
   Gadia, D
   Maggiorini, D
   Ripamonti, LA
   Tosto, V
AF Boccignone, Giuseppe
   Gadia, Davide
   Maggiorini, Dario
   Ripamonti, Laura A.
   Tosto, Valentina
TI Wuthering heights: gauging fear at altitude in virtual reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Skills assessment; Affective computing; Unsupervised
   learning
ID HEART-RATE-VARIABILITY; EMOTION; CATEGORIES; ANXIETY; AROUSAL
AB In this study we propose an approach to assess the fear of heights through a 3D virtual reality environment. We show that an immersive scenario provides a suitable infrastructure to such purpose, when supported by related behavioural and physiological measurements. Our approach is grounded in the principled framework of constructed emotions. This allows to shape fear detection as a case of categorical perception, which is amenable to be formalised as an unsupervised learning problem. Meanwhile, it paves the way for addressing meaningful physiological parameters for the assessment. Gauging fear of heights in individuals, beyond its theoretical relevance, is cogent for the early discernment of workers who are unsuited for operating at altitude and who may require to undergo specific training or, eventually, to be recruited for different positions.
C1 [Boccignone, Giuseppe; Gadia, Davide; Maggiorini, Dario; Ripamonti, Laura A.; Tosto, Valentina] Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
C3 University of Milan
RP Maggiorini, D (corresponding author), Univ Milan, Dept Comp Sci, Via Celoria 18, I-20133 Milan, Italy.
EM dario@di.unimi.it
RI Ripamonti, Laura Anna/GQH-8599-2022; Gadia, Davide/P-6309-2016;
   Boccignone, Giuseppe/G-7542-2012
OI Gadia, Davide/0000-0003-4491-9150; Maggiorini, Dario/0000-0002-7460-2966
FU Universita degli Studi di Milano
FX Open access funding provided by Universit`a degli Studi di Milano within
   the CRUI-CARE Agreement. This project has not been funded by any
   institution, public or private.
CR Acharya UR, 2006, MED BIOL ENG COMPUT, V44, P1031, DOI 10.1007/s11517-006-0119-0
   Andersen MM, 2020, PSYCHOL SCI, V31, P1497, DOI 10.1177/0956797620972116
   ANDERSON JR, 1991, PSYCHOL REV, V98, P409, DOI 10.1037/0033-295X.98.3.409
   [Anonymous], 1962, Affect imagery consciousness: Volume I: The positive affects
   Azari B, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77117-8
   Bach DR, 2010, INT J PSYCHOPHYSIOL, V76, P52, DOI 10.1016/j.ijpsycho.2010.01.011
   Baker C, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74421-1
   Banos R., 2004, P PRES, P156
   Barlow D. H., 2002, ANXIETY ITS DISORDER
   Barrett L.F., 2015, PSYCHOL CONSTRUCTION
   Barrett LF, 2019, NEUROSCI LETT, V693, P9, DOI 10.1016/j.neulet.2017.07.045
   Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154
   Barrett LF, 2016, EMOTION MEASUREMENT, P31, DOI 10.1016/B978-0-08-100508-8.00002-3
   Barrett LF, 2017, PSYCHOL INQ, V28, P20, DOI 10.1080/1047840X.2017.1261581
   Barrett LF, 2009, ADV EXP SOC PSYCHOL, V41, P167, DOI 10.1016/S0065-2601(08)00404-8
   Berntson GG, 1997, PSYCHOPHYSIOLOGY, V34, P623, DOI 10.1111/j.1469-8986.1997.tb02140.x
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bloom P, 2021, TRENDS COGN SCI, V25, P93, DOI 10.1016/j.tics.2020.12.001
   Boccignone Giuseppe, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P103, DOI 10.1145/3462203.3475882
   Boccignone G., 2017, P 19 ACM INT C MULTI, P438
   Boccignone G, 2018, IEEE T COGN DEV SYST, V10, P865, DOI 10.1109/TCDS.2017.2788820
   Buhmann MD, 2001, ACT NUMERIC, V9, P1, DOI 10.1017/S0962492900000015
   CACIOPPO JT, 1990, AM PSYCHOL, V45, P16, DOI 10.1037/0003-066X.45.1.16
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Chamilothori K, 2018, PERC INT HEART RAT R
   Critchley HD, 2013, NEURON, V77, P624, DOI 10.1016/j.neuron.2013.02.008
   D'Mello S, 2018, EMOT REV, V10, P174, DOI 10.1177/1754073917696583
   D'Mello SK, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682899
   Diemer J, 2016, J ANXIETY DISORD, V37, P30, DOI 10.1016/j.janxdis.2015.10.007
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Diemer J, 2014, WORLD J BIOL PSYCHIA, V15, P427, DOI 10.3109/15622975.2014.892632
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   EuroSafe, 2016, INJ EUR UN SUMM INJ
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Gat-Viks I, 2003, BIOINFORMATICS, V19, P2381, DOI 10.1093/bioinformatics/btg330
   Greco A., 2016, Advances in Electrodermal Activity Processing with Applications for Mental Health, P19
   Gross CT, 2012, NAT REV NEUROSCI, V13, P651, DOI 10.1038/nrn3301
   IZARD CE, 1993, PSYCHOL REV, V100, P68
   Jönsson P, 2010, PSYCHONEUROENDOCRINO, V35, P1397, DOI 10.1016/j.psyneuen.2010.04.003
   Kaufman L.-RousseeuwP.J.:., 2009, FINDING GROUPS DATA, V334
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Krupic D, 2021, PERS INDIV DIFFER, V169, DOI 10.1016/j.paid.2019.109720
   Lebois LAM, 2016, ACTA PSYCHOL, V169, P119, DOI 10.1016/j.actpsy.2016.05.012
   LeDoux JE, 2014, P NATL ACAD SCI USA, V111, P2871, DOI 10.1073/pnas.1400335111
   Liao D, 2019, 2019 IEEE MTT-S INTERNATIONAL MICROWAVE BIOMEDICAL CONFERENCE (IMBIOC 2019), DOI 10.1109/imbioc.2019.8777844
   Lindquist KA, 2008, PSYCHOL SCI, V19, P898, DOI 10.1111/j.1467-9280.2008.02174.x
   Ma H, 2022, IEEE T SYST MAN CY-S, V52, P2591, DOI 10.1109/TSMC.2021.3050993
   MacKay D., 2003, INFORM THEORY INFERE
   Martens MAG, 2019, J PSYCHOPHARMACOL, V33, P1264, DOI 10.1177/0269881119860156
   Norman GJ, 2014, EMOT REV, V6, P113, DOI 10.1177/1754073913512006
   Panksepp J., 2004, Affective Neuroscience: The Foundations of Human and Animal Emotions
   Posada-Quintero HF, 2016, ANN BIOMED ENG, V44, P3124, DOI 10.1007/s10439-016-1606-6
   Quadrio G, 2019, PROCEEDINGS OF THE 5TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS 2019), P128, DOI 10.1145/3342428.3342676
   Quigley KS, 2014, HANDBOOK OF RESEARCH METHODS IN SOCIAL AND PERSONALITY PSYCHOLOGY, SECOND EDITION, P220
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schulkin J, 2019, TRENDS NEUROSCI, V42, P740, DOI 10.1016/j.tins.2019.07.010
   Schuller BW, 2021, IEEE SIGNAL PROC MAG, V38, P9, DOI 10.1109/MSP.2021.3096415
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Shukla J, 2021, IEEE T AFFECT COMPUT, V12, P857, DOI 10.1109/TAFFC.2019.2901673
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Valenza G, 2012, IEEE T AFFECT COMPUT, V3, P237, DOI 10.1109/T-AFFC.2011.30
   Wang ZX, 2020, MULTIMED TOOLS APPL, V79, P35553, DOI 10.1007/s11042-019-08328-z
NR 65
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5207
EP 5228
DI 10.1007/s11042-022-13366-1
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000820564000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
   Niranjan, A
AF Bhardwaj, Rupali
   Niranjan, Ashish
TI An improved dual image separable reversible data hiding algorithm for
   encrypted HAMBTC compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Privacy protection; Separable reversible data hiding; Hierarchical
   absolute moment block truncation coding; Symmetric cryptosystem
ID STEGANOGRAPHY; DIFFERENCE
AB With the aim to ensure privacy and security of secret message, a block based dual image separable reversible data hiding algorithm in compressed as well as encrypted domain is proposed here. In the proposed algorithm, hierarchical absolute moment block truncation coding (HAMBTC) transformed every block b(i) into a quintuplet [(l(1))(i), (l(2))(i), (h(1))(i), (h(2))(i), bmp(i)] which are further accumulated into five tables; low mean tables (LT1, LT2), high mean tables (HT1, HT2) and a single bitmap sequence table BM. Firstly, low mean tables and high mean tables are encrypted using symmetric cryptosystem and then secret message is embedded into the quintuplet without occurrence of underflow and overflow problem. Experimental study revealed that for all type of test images, proposed methodology altogether beated all the compared methodologies in its ability to embed secret information and precisely recover it with maintaining the visual nature of stego images too. High payload and separable reversibility feature makes the proposed algorithm a perfect possibility for a secure framework.
C1 [Bhardwaj, Rupali; Niranjan, Ashish] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
CR Abdulla AA, 2019, THESIS U BUCKINGHAM
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alrehily Ashwag, 2018, International Journal of Computer Network and Information Security, V10, P28, DOI 10.5815/ijcnis.2018.05.04
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Carpentieri B, 2018, PROCEEDINGS OF THE 2018 CONFERENCE ON RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS (RACS 2018), P136, DOI 10.1145/3264746.3264752
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Girdhar A, 2019, J AMB INTEL HUM COMP, V10, P4947, DOI 10.1007/s12652-019-01179-4
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Prabha KR, 2021, J AMB INTEL HUM COMP, V12, P5179, DOI 10.1007/s12652-020-01978-0
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tai WL, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010023
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang YL, 2018, IEEE ACCESS, V6, P8882, DOI 10.1109/ACCESS.2018.2810058
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao B, 2010, IEEE ICC
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 43
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3335
EP 3362
DI 10.1007/s11042-022-13209-z
EA JUL 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000819704400003
DA 2024-07-18
ER

PT J
AU Sun, H
   Wang, P
   Ni, C
   Li, JM
AF Sun, Hao
   Wang, Peng
   Ni, Cui
   Li, Jin Ming
TI Loop closure detection based on image semantic feature and bag-of-words
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bag-of-words; Semantic feature; YOLOv4; Loop closure detection
ID SLAM
AB Loop closure detection is a key component of visual SLAM(Simultaneous Localization and Mapping). However, the existing loop closure detection algorithms are easily affected by the illumination change and object change of the scene. Since semantic features of images can improve the accuracy of object location recognition, a loop closure detection algorithm based on image semantic features and bag-of-words model is proposed in this paper. Because of the evenly distributed image features can better reflect the content of the image. So firstly, the ORB feature extraction algorithm is improved to make the extracted feature points more evenly distributed in the image, and then the extracted feature points are used to build the bag-of-words model. Then the L2 norm is adopted to calculate the similarity between images, and according to which the loop closure candidate images are determined quickly. In order to reduce the adverse effects of illumination changes and object changes on loop closure detection, YOLOv4 is used to extract semantic features of images in this paper, and real loop closure will be screened from the candidate images according to cosine values of included angles between similar objects in different images, so as to complete the loop closure detection. Experiments on TUM dataset and actual images show that the proposed algorithm can effectively reduce the adverse effects of illumination changes and object changes on loop closure detection, and effectively improve the accuracy and adaptability of loop closure detection.
C1 [Sun, Hao; Wang, Peng; Ni, Cui; Li, Jin Ming] Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Peoples R China.
C3 Shandong Jiaotong University
RP Wang, P (corresponding author), Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Peoples R China.
EM 1255498179@qq.com; knightwp@126.com; emilync@126.com; 799785044@qq.com
FU National Natural Science Funds of China [61502277]; Shandong Provincial
   Transportation Science and Technology Project [2021B120]
FX This work was partially supported by the National Natural Science Funds
   of China (Grant No. 61502277)and Shandong Provincial Transportation
   Science and Technology Project (Grant No. 2021B120).
CR An P., 2021, J BEIJING U AERONAUT, V1, P24
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   [丁文东 Ding Wendong], 2018, [自动化学报, Acta Automatica Sinica], V44, P385
   Dong RF, 2019, IEEE ACCESS, V7, P111245, DOI 10.1109/ACCESS.2019.2934521
   Esteves RM, 2013, INT CONF CLOUD COMP, P17, DOI 10.1109/CloudCom.2013.89
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Gao L, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND MECHATRONICS (ICARM), P1, DOI 10.1109/ICARM.2017.8273125
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843
   Guclu O, 2019, J INTELL ROBOT SYST, V93, P495, DOI 10.1007/s10846-017-0718-z
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Ke LH, 2019, J, V1, P12
   Khodatars M, DEEP LEARNING NEUROI
   Li T., 2017, INF COMMUN TECHNOL L, V10, P20
   [李小倩 Li Xiaoqian], 2021, [工程科学学报, Chinese Journal of Engineering], V43, P754
   [梁志伟 Liang ZhiWei], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P561
   [刘国忠 Liu Guozhong], 2017, [机器人, Robot], V39, P36
   [刘强 Liu Qiang], 2019, [机器人, Robot], V41, P112
   Liu W., 2018, CONTROL I CHEM IND, V45, P714
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538
   Mu BP, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4602, DOI 10.1109/IROS.2016.7759677
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Peng ZD, 2018, COMPUT TECHNOL DEV, V28, P102
   Qin C, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103072
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Shoeibi A., AUTOMATED DETECTION
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Bruno HMS, 2021, NEUROCOMPUTING, V455, P97, DOI 10.1016/j.neucom.2021.05.027
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tsintotas KA, 2021, ROBOT AUTON SYST, V141, DOI 10.1016/j.robot.2021.103782
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983
   Wang K, 2019, IEEE INT CONF ROBOT, P5224, DOI [10.1109/ICRA.2019.8793499, 10.1109/icra.2019.8793499]
   Xia LL, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881420919185
   [于金山 Yu Jinshan], 2016, [机器人, Robot], V38, P410
   Zhang G, 2019, IEEE ACCESS, V7, P124217, DOI 10.1109/ACCESS.2019.2937967
   [张括嘉 Zhang Kuojia], 2019, [机器人, Robot], V41, P649
   Zhang LQ., 2019, B SURVEYING MAPP, V3, P16
   Zhi SF, 2019, PROC CVPR IEEE, P11768, DOI 10.1109/CVPR.2019.01205
NR 43
TC 1
Z9 1
U1 7
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 22
PY 2022
DI 10.1007/s11042-022-13353-6
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2H1FK
UT WOS:000814042800002
DA 2024-07-18
ER

PT J
AU Mishra, S
   Khetarpaul, S
AF Mishra, Saurabh
   Khetarpaul, Sonia
TI uR-tree: a spatial index structure for handling multiple point selection
   queries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial indexing; Spatial queries; Point of interest; Utility score;
   Scheduling
ID SEARCH
AB People often query various Points of Interest (POIs) to plan their city tour itineraries using location-based services that provide reviews and ratings of various attributes of a POI. Most traditional location-based recommendation systems focus on various attributes like rating, cost, and social similarities of either POIs, users, or both but do not focus on efficient retrieval of POIs. This paper proposes a spatial index structure uR-tree (utility-based R-tree) for efficiently processing a location-based query implied in a location-aware recommender system to select multiple POIs which a user can visit in a tour. The uR-tree is constructed considering a change in static attributes like availability of parking, basic amenities, etc., and dynamic attributes like ticket price, congestion, etc., of each POI with the aim to maximize a user's experience. At first, the utility of each POI is calculated at different points of time based on its static and dynamic attributes. A uR-tree is constructed for the systematic indexing of the utility of each POI, and an algorithm is applied for the retrieval of top-k maximum utility POI in different time-intervals. Then, we propose two Utility-based trip scheduling algorithms for distance-based travel recommendations. The experiments were conducted on real-world location-based social network data sets and show that the proposed scheme has a lower response time, Disk I/Os, and a higher query success rate as compared to state-of-the-art, R-tree index structure.
C1 [Mishra, Saurabh; Khetarpaul, Sonia] Shiv Nadar Univ, Delhi NCR, Greater Noida, India.
C3 Shiv Nadar University
RP Khetarpaul, S (corresponding author), Shiv Nadar Univ, Delhi NCR, Greater Noida, India.
EM sonia.khetarpaul@snu.edu.in
RI Mishra, Saurabh/AAV-6576-2021; KHETARPAUL, SONIA/AAC-8721-2021
OI KHETARPAUL, SONIA/0000-0001-6058-7235
CR [Anonymous], 2013, Proceedings of the 16th International Conference on Database Theory, DOI DOI 10.1145/2448496.2448524
   [Anonymous], 2013, P 16 INT C EXT DAT T
   Bast H, 2006, VLDB J
   Benetis R, 2002, IDEAS 2002: INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P44, DOI 10.1109/IDEAS.2002.1029655
   Cao X., 2011, SIGMOD, P373
   Chakraborty C., 2011, FUZZY SYST, V3, P77
   Chakraborty C, 2009, 2009 ANN IEEE INDIA, P1
   Chakraborty C, 2010, ICCNT 2009: PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTER AND NETWORK TECHNOLOGY, P55
   Cheng P, 2019, PROC INT CONF DATA, P1626, DOI 10.1109/ICDE.2019.00158
   Cho HJ, 2015, KNOWL INF SYST, V42, P599, DOI 10.1007/s10115-013-0696-9
   Cong G, 2009, PROC VLDB ENDOW, V2
   Dawei Gao, 2016, Web-Age Information Management. 17th International Conference, WAIM 2016. Proceedings: LNCS 9658, P191, DOI 10.1007/978-3-319-39937-9_15
   De Felipe I, 2008, PROC INT CONF DATA, P656, DOI 10.1109/ICDE.2008.4497474
   Gan W, 2019, ARXIV 190209582
   Gao HH, 2022, IEEE TETCI, V6, P66, DOI 10.1109/TETCI.2020.3023155
   Gao HH, 2021, IEEE T INTELL TRANSP, V22, P3533, DOI 10.1109/TITS.2020.2983835
   Gao HH, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3391198
   Gavrila, 1994, R TREE INDEX OPTIMIZ
   Gunturi VMV, 2017, SPRING GEOGR, P127, DOI 10.1007/978-3-319-40902-3_8
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Hu HQ, 2016, PROC INT CONF DATA, P61, DOI 10.1109/ICDE.2016.7498229
   Kolpakov, 2010, UPPER LOWER BOUNDS C
   Kwon HY, 2013, WORLD WIDE WEB, V16, P111, DOI 10.1007/s11280-012-0159-3
   Li FF, 2011, IEEE T KNOWL DATA EN, V23, P1526, DOI 10.1109/TKDE.2010.181
   Li M, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P559, DOI 10.1145/2983323.2983757
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Likhyani A, 2020, ARXIV 200607580
   Liu W, 2018, LECT NOTES COMPUT SC, V10827, P67, DOI 10.1007/978-3-319-91452-7_5
   McConnell C.R., 2009, EC PRINCIPLES PROBLE, V19th
   Mitra S, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P27, DOI 10.1145/3297001.3297005
   Nguyen-Dinh L-V, 2010, SPATIO TEMPORAL AC 2
   Pande S, 2017, PROC VLDB ENDOW, V10, P1382, DOI 10.14778/3137628.3137647
   Papadias D, 2004, PROC INT CONF DATA, P301, DOI 10.1109/ICDE.2004.1320006
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Rocha JB, 2010, PROC VLDB ENDOW, V4, P93, DOI 10.14778/1921071.1921076
   Roy SB, 2015, VLDB J, V24, P467, DOI 10.1007/s00778-015-0385-2
   Saxena AS, 2019, ARXIV 191201861
   She JY, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1629, DOI 10.1145/2723372.2749446
   Wang W, 2020, IEEE INTERNET THINGS, V7, P4361, DOI 10.1109/JIOT.2019.2950418
   Yang JY, 2019, LECT NOTES COMPUT SC, V11447, P591, DOI 10.1007/978-3-030-18579-4_35
   Yang XX, 2020, MOBILE NETW APPL, V25, P376, DOI 10.1007/s11036-019-01246-2
   Yelp Inc, 2019, YELP DAT CHALL
   Yiu ML, 2007, PROC INT CONF DATA, P1051
   Yu DJ, 2019, LECT NOTES COMPUT SC, V11447, P609, DOI 10.1007/978-3-030-18579-4_36
   Zhang CY, 2016, IEEE T KNOWL DATA EN, V28, P1706, DOI 10.1109/TKDE.2016.2530060
   Zhang Z, 2019, LECT NOTES COMPUT SC, V11447, P642, DOI 10.1007/978-3-030-18579-4_38
NR 46
TC 0
Z9 1
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8093
EP 8111
DI 10.1007/s11042-022-13357-2
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000812445100002
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, SK
   Udmale, SS
AF Singh, Durgesh
   Singh, Sanjay K.
   Udmale, Sandeep Sambhaji
TI An efficient self-embedding fragile watermarking scheme for image
   authentication with two chances for recovery capability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Self-embedding; Fragile watermarking; Discrete
   cosine transformation; Image authentication; Tamper localization; Image
   restoration
ID DIGITAL SIGNATURE; TAMPER DETECTION; ROBUST; SECURE
AB A self-embedding block-wise fragile image watermarking scheme is proposed in this paper for authentication, localization, and recovery with enhanced accuracy. In this introduced scheme, the cover image is split into non-overlapping blocks with a size of 2 x 2, and each block, ten restoration bits and two authentication bits are calculated from the five MSBs planes. In the watermarked image, each block contains restoration bits of the other two partner blocks and authentication bits itself. These ways two copies of restoration bits for each block are embedded into the host image. Therefore, we will get the second opportunity for block restoration in the situation one copy is not able to extract. The proposed scheme is also beneficial because three-level hierarchical tampered detection methods verify the authenticity of each block. So the authentication of each block can be confirmed with a significant possibility. The experimental outcomes prove that the intended scheme is capable of performing a high- quality restoration. The recovery is feasible with high Peak Signal to Noise Ratio and Normalized Correlation Coefficient up to 50% tampering rate. The proposed scheme also eliminates the blocking artefacts and enhances the precision of tampered localization because of the minimal size non-overlapping blocks.
C1 [Singh, Durgesh] PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
   [Singh, Sanjay K.] Indian Inst Technol BHU, Dept Comp Sci, Engn, Varanasi 221005, Uttar Pradesh, India.
   [Udmale, Sandeep Sambhaji] Veermata Jijabai Technol Inst VJTI, Dept Comp Engn & Informat Technol, Mumbai, Maharashtra, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Technology System (IIT System); Indian
   Institute of Technology BHU Varanasi (IIT BHU Varanasi); Veermata
   Jijabai Technological Institute (VJTI)
RP Singh, D (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
EM durgeshcse@gmail.com
RI Singh, Sanjay Prithviraj/IQV-1492-2023; Udmale, Sandeep/ABE-9537-2021;
   Singh, Durgesh/AAZ-2801-2020; Singh, Sanjay Kumar/AAC-2031-2022
OI Singh, Sanjay Prithviraj/0000-0001-5043-8762; Udmale,
   Sandeep/0000-0001-9498-1230; Singh, Durgesh/0000-0002-6078-1502; Singh,
   Sanjay Kumar/0000-0002-9061-6313
CR Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2015, MULTIMED TOOLS APPL, V74, P10581, DOI 10.1007/s11042-014-2188-7
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Singh D, 2013, INTELLIGENT INTERACT
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Stallings W., 2007, NETWORK SECURITY ESS, V3rd
   Sun QB, 2005, IEEE T MULTIMEDIA, V7, P480, DOI 10.1109/TMM.2005.846776
   Wang JW, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2954129
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhang XP, 2015, MULTIMED TOOLS APPL, V74, P5767, DOI 10.1007/s11042-014-1882-9
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 25
TC 7
Z9 7
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1045
EP 1066
DI 10.1007/s11042-022-13270-8
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700004
DA 2024-07-18
ER

PT J
AU Wang, CZ
   Wang, ZN
   Li, K
   Gao, R
   Yan, LY
AF Wang, Chunzhi
   Wang, Zaoning
   Li, Ke
   Gao, Rong
   Yan, Lingyu
TI Lightweight object detection model fused with feature pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Object detection; Lightweight model; Feature pyramid
AB The research field of object detection has been a hotspot in computer vision. However, most of the one-stage lightweight object detection models based on the deep convolutional neural network have the problems of many parameters. To address this problem, this paper proposes a new model named Fusion Shuffle Light Detector (FSLDet). First, based on the FSSD mode, we apply the improved lightweight Shufflenet V2 network to the FSSD model for feature extraction, where the improvement about ShuffleNet v2 is an adjustment for the network structure. Meanwhile, we adopt the bidirectional feature pyramid model to improve the feature fusion operation, which makes the fused features have more semantic information. Experiments were carried out on PASCAL VOC 2007 + 2012 dataset and helmet detection dataset. The experiment shows that the FSLDet model is superior to the state-of-the-art model in multiple evaluation criteria.
C1 [Wang, Chunzhi; Wang, Zaoning; Li, Ke; Gao, Rong; Yan, Lingyu] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
C3 Hubei University of Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM chunzhiwang@163.com; zaoning@hbut.edu.cn; like@hbut.edu.cn;
   gaorong_hbut@126.com; yanlingyu@hbut.edu.cn
RI Yuan, Yi/KGL-5178-2024; Yang, YiChen/KEI-0140-2024
FU National Natural Science Foundation of China [61772180]; Key R&D plan of
   Hubei Province [2020BHB004,2020BAB012]; Natural Science Foundation of
   Hubei Province [2020CFB798]
FX This work is funded by the National Natural Science Foundation of China
   under Grant No.61772180, the Key R&D plan of Hubei Province
   (2020BHB004,2020BAB012) and Natural Science Foundation of Hubei Province
   No.2020CFB798.
CR Chen PH, 2016, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2016.7532457
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu C, 2019, ANN IEEE SYM FIELD P, P319, DOI 10.1109/FCCM.2019.00060
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shiman Wang, 2019, 2019 IEEE International Conference on Smart Internet of Things (SmartIoT). Proceedings, P422, DOI 10.1109/SmartIoT.2019.00075
   Sinha D, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P280, DOI 10.1109/uemcon47517.2019.8993089
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Won JH, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P418, DOI 10.1109/itc-cscc.2019.8793382
   Yan L, 2021, MOL CELL, P1
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Zhai MH, 2019, LECT NOTES ARTIF INT, V11744, P450, DOI 10.1007/978-3-030-27541-9_37
   Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1109/mascots50786.2020.9285955
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 29
TC 4
Z9 4
U1 6
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 601
EP 618
DI 10.1007/s11042-022-12127-4
EA JUN 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000807318200002
DA 2024-07-18
ER

PT J
AU Cai, YG
   Gao, XS
   Chen, WQ
   Wang, RG
AF Cai, Yangang
   Gao, Xuesong
   Chen, Weiqiang
   Wang, Ronggang
TI Towards 6DoF live video streaming system for immersive media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View synthesis; GPU acceleration; 6DoF; DIBR
AB Based on the three rotational degrees (video in three dimensions, on the X, Y and Z axes) of freedom provided by VR, the viewer is free to control the viewing point and has six degrees of freedom (6DoF). When watching a sports game, the audience is no longer limited by the position of the camera, and can freely choose the viewing angle and position just like watching in the real world, which can greatly improve the immersion of viewing. However, the major barrier that prevents 6DoF video live from being industrialized lies in the extremely high computational complexity, of which multi-view depth estimation and Depth Image Based Rendering (DIBR) is difficult to realize. And existing devices do not have hardware interfaces that support multi-views coding technology. Therefore, we need new technologies for depth estimation and virtual view synthesis, and we need to use existing hardware coding/decoding interfaces to reduce power consumption. In this paper, we provide a 6DoF live video system, which includes multi-view depth estimation technique based on unsupervised learning, virtual viewpoint real-time rendering technology and 6DoF video coding. Experimental results demonstrate that our proposed acceleration method can speed up the original depth estimation algorithm by more than 34x, and can speed up the original DIBR algorithm by more than 168x. With our 6DoF video coding method, experimental results show that the bit rate achieves an average of 70%, 64%, 33%, 60% and 66% bitrate saving for AVC, HEVC, AV1, AVS3, VVC codec standard respectively.
C1 [Cai, Yangang; Gao, Xuesong; Chen, Weiqiang; Wang, Ronggang] Peking Univ, Shenzhen Grad Sch, Shenzhen, Guangdong, Peoples R China.
C3 Peking University
RP Cai, YG (corresponding author), Peking Univ, Shenzhen Grad Sch, Shenzhen, Guangdong, Peoples R China.
EM caiyangang@pku.edu.cn; gaoxuesong@hisense.com; chenweiqiang@hisense.com;
   rgwang@pkusz.edu.cn
FU National Natural Science Foundation of China [61672063, 61902008];
   Shenzhen Research Projects [JCYJ20180503182128089, 201806080921419290];
   project PCL Future Greater-Bay Area Network Facilities for Large-scale
   Experiments and Applications [LZC0019]
FX This work is supported by National Natural Science Foundation of China
   61672063, 61902008, Shenzhen Research Projects of JCYJ20180503182128089
   and 201806080921419290. And this work is partially supported by the
   project PCL Future Greater-Bay Area Network Facilities for Large-scale
   Experiments and Applications (LZC0019). Thanks to Hisense for providing
   the experimental platform and data evaluation.
CR [Anonymous], 2013, UNSUPERVISED LEARNIN
   Cai YG, 2013, IEEE IMAGE PROC, P3172, DOI 10.1109/ICIP.2013.6738653
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   developer.nvidia, NVID VID COD SDK
   Duan YZ, 2014, IEEE T MULTIMEDIA, V16, P1915, DOI 10.1109/TMM.2014.2337834
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   hevc.hhi.fraunhofer, JCT VC SUBV REP HEVC
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jianbin Fang, 2011, 2011 International Conference on Parallel Processing, P216, DOI 10.1109/ICPP.2011.45
   Joint Video Experts Team (JVET), 2019, ALG DESCR VERS VID C
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Ligon J, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P731, DOI 10.1109/CCWC.2018.8301688
   Lin S, 2013, IEEE INT SYMP CIRC S, P2864, DOI 10.1109/ISCAS.2013.6572476
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Liu Z, 2018, IEEE T MULTIMEDIA, V20, P1321, DOI 10.1109/TMM.2017.2767781
   Long S., 2018, International Journal of Computer Vision
   Momcilovic S, 2014, IEEE T MULTIMEDIA, V16, P108, DOI 10.1109/TMM.2013.2284892
   Morvan Y, 2007, THESIS TU EINDHOVEN
   Mueller M, 2010, 3DTV CONF
   Opitz M, 2016, LECT NOTES COMPUT SC, V9907, P386, DOI 10.1007/978-3-319-46487-9_24
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tanimoto M, 2014, 3DTV CONF
   Tech G, 2013, 3 M
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Wang B, 2018, SIGNAL PROCESS-IMAGE, V62, P93, DOI 10.1016/j.image.2017.12.009
   Wang RG, 2017, IEEE T MULTIMEDIA, V19, P1392, DOI 10.1109/TMM.2017.2654120
   Wang S, 2019, INT CONF ACOUST SPEE, P2297, DOI 10.1109/ICASSP.2019.8683037
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Würmlin S, 2004, COMPUT GRAPH-UK, V28, P3, DOI 10.1016/j.cag.2003.10.015
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
NR 39
TC 3
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35875
EP 35898
DI 10.1007/s11042-021-11589-2
EA JUN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000804560500002
DA 2024-07-18
ER

PT J
AU Nath, S
   Mala, C
AF Nath, Sayantan
   Mala, C.
TI Visualization enhancement of autonomous controlling vehicles system by
   thermal image processing technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal imaging; Fuzzy model; CNN; Recognition; IoU; Inter-connectivity
ID NEURAL-NETWORKS
AB The visual camera in the autonomous vehicles is inadequate to capture a prominent image of objects, especially in the night. The headlights of the car also have limited perceptibility up to few meters. So, it is utterly essential to implement such a technique so that visibility in the night would also be cleared as crystal. In this paper, a thermal imaging camera is proposed to be felicitated in autonomous vehicles for better identification of objects especially in the night when visibility is very less. This technique is framed to use as a data acquisition tool to recognize the objects. Due to the huge variation in grayscales and pseudo coloring values in the thermal image, a fuzzy-based CNN model is proposed to be applied to identify the boundaries of the objects. In this technique, the correlation between the thermal images of the moving object and its types is proposed to be trained with the novel FCNN model. The acquired data from different scenarios would also be compared with driving safety experts. By inter-connecting these practices, a novel and unique real-time thermographic image processing would be framed for the autonomous vehicle system. The proposed technique is implemented in a grayscaled thermal image to verify the process and its analysis indicates the robustness of the proposed method.
C1 [Nath, Sayantan; Mala, C.] NIT Trichy, Dept CSE, Trichy, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Nath, S (corresponding author), NIT Trichy, Dept CSE, Trichy, India.
EM sayantan@nitt.edu; mala@nitt.edu
RI NATH, SAYANTAN/GNP-0031-2022
OI NATH, SAYANTAN/0000-0002-9393-6072
CR Alam MS, 2000, IEEE T INSTRUM MEAS, V49, P915, DOI 10.1109/19.872908
   Alexa P, 2018, J BUILD PHYS, V41, P533, DOI 10.1177/1744259117731344
   Algarni AD, 2020, MULTIMED TOOLS APPL, V79, P13403, DOI 10.1007/s11042-020-08616-z
   Azari MN, 2016, AUTOMATIKA, V57, P862, DOI 10.7305/automatika.2017.05.1579
   Bittencourt TDG, 2012, PROC SPIE, V8541, DOI 10.1117/12.970455
   Browne M, 2008, STUD COMPUT INTELL, V83, P327, DOI 10.1007/978-3-540-75398-8_15
   Burigana L, 2017, SCI TECHNOL ARCHAEOL, V3, P490, DOI 10.1080/20548923.2018.1426273
   Caillas C, 1990, EEE INT WORKSHOP INT
   Chacn M, 2006, ADV FUZZY LOGIC TECH
   De Ridder D, 2003, ADV IMAG ELECT PHYS, V126, P351, DOI 10.1016/S1076-5670(03)80019-8
   Giacomin J, 2010, THERMAL SEEING WORLD
   Iakymchuk T, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0059-4
   Lawrence M, 2007, P SOC PHOTO-OPT INS, V6542, P54215, DOI 10.1117/12.718912
   LeBeau T, 2019, PROC SPIE, V11002, DOI 10.1117/12.2521842
   Li T, 2001, IMAGE EXTRACTION SEG, V4550
   Liu CM, 2020, ROBOTICS, V9, DOI 10.3390/robotics9010019
   Liu G, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0283-9
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Muhadi NA, 2020, WATER-SUI, V12, DOI 10.3390/w12061825
   Nam YY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0245-2
   Nath, 2015, EAI ENDORSED T CREAT, V5, P2
   Peterson BJ, 2000, REV SCI INSTRUM, V71, P3696, DOI 10.1063/1.1290044
   Rossignoli I, 2015, SPINAL CORD, V53, P243, DOI 10.1038/sc.2014.212
   Song E, 2018, IEEE ACCESS, V6, P12156, DOI 10.1109/ACCESS.2018.2810951
   Tan ST, 2008, ANALYST, V133, P1395, DOI 10.1039/b718458a
   Thakur R., 2017, RECENT DEV OPTOELECT
   Tsukamoto T, 2013, J PHYS CONF SER, V476, DOI 10.1088/1742-6596/476/1/012073
   wikipedia, FUNCT
   wikipedia, CATEGORY THEORY
   wikipedia, BLACK BOD RAD
   wikipedia, ACT FUNCT
   wikipedia, PROP MATH
   WINTER J, 1973, COMPUT BIOMED RES, V6, P522, DOI 10.1016/0010-4809(73)90027-X
   Zhang JD, 2015, J INTELL FUZZY SYST, V29, P2779, DOI 10.3233/IFS-151982
NR 34
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41035
EP 41058
DI 10.1007/s11042-022-13077-7
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000796808300001
DA 2024-07-18
ER

PT J
AU Baziyad, M
   Shahin, I
   Rabie, T
   Nassif, AB
AF Baziyad, Mohammed
   Shahin, Ismail
   Rabie, Tamer
   Nassif, Ali Bou
TI 64-bit quantization: taking payload capacity of speech steganography to
   the limits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; DCT; Segment-growing; Speech; Steganography
ID TRANSFORM
AB A fundamental problem in steganography is the trade-off between the hiding capacity and the quality of the stego signal. Researchers have found in the Discrete Cosine Transform (DCT) a potential solution to this trade-off challenge due to its strong compaction property. The DCT has the ability to represent a time-domain signal within a few numbers of DCT coefficients leaving a substantial amount of insignificant DCT coefficients that can host the secret data. Moreover, it has been found that the compaction property becomes stronger with highly-correlated signals. Therefore, this paper suggests to fully exploit the strong compaction property of the DCT by segmenting the cover speech signal into correlated segments. Hiding is performed in the insignificant DCT coefficients in each segment which are determined by a new quantization method suitable for speech signals. Experimental results have proven that the proposed steganography technique has outperformed competing speech hiding schemes, in terms of the payload capacity which reached up to 14.94 bps, at similar or higher stego quality.
C1 [Baziyad, Mohammed] Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
   [Shahin, Ismail] Univ Sharjah, Dept Elect Engn, Sharjah, U Arab Emirates.
   [Rabie, Tamer; Nassif, Ali Bou] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
C3 University of Sharjah; University of Sharjah; University of Sharjah
RP Baziyad, M (corresponding author), Univ Sharjah, Res Inst Sci & Engn, Sharjah, U Arab Emirates.
EM mbaziyad@sharjah.ac.ae; ismail@sharjah.ac.ae; trabie@sharjah.ac.ae;
   anassif@sharjah.ac.ae
OI Shahin, Ismail/0000-0001-7856-9342; Baziyad,
   Mohammed/0000-0003-0272-2659
CR Ahmed Mohamed A., 2010, Journal of Applied Sciences, V10, P59, DOI 10.3923/jas.2010.59.64
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2013, IJCSA
   [Anonymous], 2009, 2009 INT C WIR COMM
   Anushiadevi R, 2021, MULTIMED TOOLS APPL, V80, P19695, DOI 10.1007/s11042-021-10729-y
   Ballesteros DM, 2012, EXPERT SYST APPL, V39, P9141, DOI 10.1016/j.eswa.2012.02.066
   Baziyad Mohammed, 2020, 2020 14th International Conference on Innovations in Information Technology (IIT), P40, DOI 10.1109/IIT50501.2020.9299010
   Baziyad Mohammed, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P791, DOI 10.1109/ICCCA49541.2020.9250849
   Baziyad Mohammed, 2020, Trends and Innovations in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 1160), P251, DOI 10.1007/978-3-030-45691-7_24
   Baziyad M., 2020, MULTIMED TOOLS APPL, V80, P1
   Baziyad M, 2018, IEEE INT CONF INNOV, P1, DOI 10.1109/INNOVATIONS.2018.8606008
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Ghasemzadeh H, 2017, IET SIGNAL PROCESS, V11, P916, DOI 10.1049/iet-spr.2016.0690
   Kathum, 2016, SPEECH STEGANOGRAPHY, V19
   Katz J, 2015, INT J INCLUSIVE EDUC, V19, P1, DOI 10.1080/13603116.2014.881569
   KITAWAKI N, 1984, IEEE COMMUN MAG, V22, P26, DOI 10.1109/MCOM.1984.1091825
   Lakshmi C, 2021, MULTIMED TOOLS APPL, V80, P8581, DOI 10.1007/s11042-020-09978-0
   Lee, 2018, J INF HIDING MULTIME, V9, P4
   Liu H., 2018, J INFO HIDING MULTIM, V9, P1222
   Liu J, 2012, IEEE ICC
   Muoz A, 2015, STEGSECRET SIMPLE ST
   Nassif AB, 2019, IEEE ACCESS, V7, P19143, DOI 10.1109/ACCESS.2019.2896880
   Nassrullah HA., 2020, J INFORM HIDING MULT, V11, P126
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Rabie, 2015, INT J COMPUT APPL T, V116
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P8295, DOI 10.1007/s11042-017-4727-5
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Rachael O, 2020, LECT NOTES ELECTR EN, V605, P1100, DOI 10.1007/978-3-030-30577-2_97
   Saiz-Alía M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50773-1
   Saracevic M, 2019, FUTURE GENER COMP SY, V100, P186, DOI 10.1016/j.future.2019.05.010
   Shahin IMA, 2013, INT J SPEECH TECHNOL, V16, P341, DOI 10.1007/s10772-013-9188-2
   Shirali-Shahreza S, 2008, 2008 IEEE INT C ACOU
   Shrestha Suchitra, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P280, DOI 10.1109/ISSPA.2010.5605474
   Sridevi R., 2009, J THEORETICAL APPL I, V5, P6
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   White R., 2017, Computer Networking Problems and Solutions: An innovative approach to building resilient, modern networks
   Xu TT, 2009, 2009 4TH INTERNATIONAL CONFERENCE ON SYSTEMS AND NETWORKS COMMUNICATIONS (ICSNC 2009), P201, DOI 10.1109/ICSNC.2009.71
NR 38
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40561
EP 40579
DI 10.1007/s11042-022-13138-x
EA MAY 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793651500003
DA 2024-07-18
ER

PT J
AU Hu, M
   Hu, RM
   Wang, ZY
   Xiong, ZX
   Zhong, R
AF Hu, Min
   Hu, Ruimin
   Wang, Zhongyuan
   Xiong, Zixiang
   Zhong, Rui
TI Spatiotemporal two-stream LSTM network for unsupervised video
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Visual attention; Spatiotemporal deep neural
   network
ID EMPIRICAL MODE DECOMPOSITION
AB Within user-created videos, the constantly changing content among neighboring images brings more challenge for the prior video summarization methods. Assuming the images' critical features are refined, one can obtain promising accuracy of keyframes' selection which is key in video summarization. In our work, we innovatively proposed a Spatiotemporal two-stream LSTM network-based (ST-LSTM) model to enhance the images' critical features with the combination of spatial saliency and temporal semantic dependencies which is referred to as the two-stream method. Motivated by the fact that sizable and moving objects attract more visual attention, we newly design a Saliency-area-based attention network to filter irrelative non-attractive information. We use the latest attention-based Bi-LSTM network to extract the temporal dependency on the semantic features. Furthermore, a multi-feature-based reward function is presented to reinforce the ST-LSTM model by integrating diversity, representativeness, and storyness. Last, the Deep Deterministic Policy Gradient (DDPG) algorithm is adopted to do the unsupervised training for the proposed method. Extensive experiments on the public datasets demonstrate that our method outperforms the state-of-the-art.
C1 [Hu, Min; Hu, Ruimin; Wang, Zhongyuan] Wuhan Univ, Wuhan, Hubei, Peoples R China.
   [Xiong, Zixiang] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.
   [Zhong, Rui] Cent China Normal Univ, Wuhan, Peoples R China.
C3 Wuhan University; Texas A&M University System; Texas A&M University
   College Station; Central China Normal University
RP Hu, M (corresponding author), Wuhan Univ, Wuhan, Hubei, Peoples R China.
EM humin0328@163.com; hrm@whu.edu.cn; wzy_hope@163.com; zx@ece.tamu.edu;
   zhongr@mail.ccnu.edu.cn
RI zhong, rui/HSZ-2549-2023
CR [Anonymous], 2015, P IEEE INT C COMPUTE
   Avila SEFD, 2011, PATTERN RECOGN LETT, V32, P5668
   Brown P. F., 1992, Computational Linguistics, V18, P467
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   ELGHOROURY HN, 1972, IEEE T COMPUT, VC 21, P1119, DOI 10.1109/T-C.1972.223460
   Elhamifar E, 2012, CVPR
   Elhamifar E, 2012, PREPARATION, V4, P8
   Fan GF, 2020, J FORECASTING, V39, P737, DOI 10.1002/for.2655
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Fei M., 2017, MULTIMED TOOLS APPL, P1
   Gong BQ, 2014, ADV NEUR IN, V27
   Gygli M, 2015, P IEEE C COMPUTER VI
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Han JW, 2014, INFORM SCIENCES, V281, P781, DOI 10.1016/j.ins.2013.12.039
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Ji Z, 2019, IEEE T CIRC SYST VID
   Ji Z, 2021, IEEE T NEUR NET LEAR, V32, P1765, DOI 10.1109/TNNLS.2020.2991083
   Jin J., 2015, Aligning where to see and what to tell: image caption with region-based attention and scene factorization
   Jung Y, 2019, AAAI CONF ARTIF INTE, P8537
   Kannan R, 2019, INT J MULTIMED DATA, V10, P1, DOI 10.4018/IJMDEM.2019070101
   Khosla A, 2013, P IEEE C COMPUTER VI, p2698 2705
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Lillicrap, 2015, ARXIV150902971, P1
   Lipton Z. C., 2015, ARXIV
   Mahasseni B, 2017, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2017.224
   Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002
   Qu S, 2017, 2017 29 CHINESE CONT
   Salehin MM, 2016, INT C DIG IM COMP TE
   Shih HC, 2013, IEEE T BROADCAST, V59, P556, DOI 10.1109/TBC.2013.2265782
   Song Y, 2015, P IEEE C COMPUTER VI
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Venugopalan S, 2015, P IEEE INT C COMPUTE, p4534 4542
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Yi P, 2020, IEEE T CIRC SYST VID, V30, P2503, DOI 10.1109/TCSVT.2019.2925844
   Yuan L, 2020, IEEE T MULTIMEDIA, V22, P2711, DOI 10.1109/TMM.2019.2959451
   Yuan Y, 2019, IEEE ACCESS, V7, P64676, DOI 10.1109/ACCESS.2019.2916989
   Zhang K, 2016, P IEEE C COMPUTER VI
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
   Zhang Z, 2019, NONLINEAR DYNAM, V98
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhao B, 2014, P IEEE C COMPUTER VI
   Zhou K, 2018, 32 AAAI C ARTIFICIAL
NR 46
TC 0
Z9 0
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40489
EP 40510
DI 10.1007/s11042-022-12901-4
EA MAY 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793007000001
DA 2024-07-18
ER

PT J
AU Lin, H
   Li, XL
   Gao, HY
   Li, J
   Wang, YS
AF Lin, Hao
   Li, Xiaolei
   Gao, Haoyu
   Li, Jie
   Wang, Yongsheng
TI ISC-MTI: An IPFS and smart contract-based framework for machine learning
   model training and invocation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning security; InterPlanetary file system; Smart contract;
   EOS; Model training; Model invocation
AB Due to centralized storage, centralization problems are common in machine learning model training and invocation, which makes train data and trained models extremely vulnerable to tampering and stealing. A safe framework for training and invoking models called ISC-MTI (IPFS (InterPlanetary File System) and Smart Contract-Based Method for Storage and Invocation of Machine Learning Mobel) is proposed in this paper. The framework uses IPFS as the storage solution, EOS (Enterprise Operation System) blockchain as the smart contract platform, RSA and AES as the implementation of encrypted communication. The Action responsible for invoking the training data and trained models in the smart contract and the model training, uploading, and invoking methods are designed. The experimental results demonstrate that ISC-MTI can improve the safety of model training and invocation with losing a little efficiency. Simultaneously, ISC-MTI can provide anti-theft model capabilities, traceability, tamper resistance, reliability, and privacy for the process.
C1 [Lin, Hao] Tianjin Univ Technol, Sch Comp Sci & Engn, Tianjin, Peoples R China.
   [Lin, Hao; Li, Xiaolei; Gao, Haoyu; Li, Jie; Wang, Yongsheng] Inner Mongolia Univ Technol, Coll Data Sci & Applicat, Hohhot, Inner Mongolia, Peoples R China.
   [Lin, Hao; Li, Xiaolei; Gao, Haoyu; Li, Jie; Wang, Yongsheng] Inner Mongolia Autonomous Reg Engn & Technol Res, Hohhot, Inner Mongolia, Peoples R China.
C3 Tianjin University of Technology; Inner Mongolia University of
   Technology
RP Li, XL (corresponding author), Inner Mongolia Univ Technol, Coll Data Sci & Applicat, Hohhot, Inner Mongolia, Peoples R China.; Li, XL (corresponding author), Inner Mongolia Autonomous Reg Engn & Technol Res, Hohhot, Inner Mongolia, Peoples R China.
EM suzukaze_aoba@foxmail.com; llxhappy@126.com; 1095055672@qq.com;
   uestc007@qq.com; 517602864@qq.com
OI Lin, Hao/0000-0001-9304-0279
FU Inner Mongolia Key Technological Development Program [2019ZD015,
   2019ZD016]; Technological Research Program of InnerMongolia Autonomous
   Region [2019GG273, 2020GG0094]; Inner Mongolia Autonomous Region Special
   Program for Engineering Application of Scientific and Technical Payoffs
   [2020CG0073]
FX This work was supported in part by the Inner Mongolia Key Technological
   Development Program under Grant (2019ZD015, 2019ZD016), in part by the
   Key Scientific, Technological Research Program of InnerMongolia
   Autonomous Region under Grant (2019GG273, 2020GG0094), and in part by
   the Inner Mongolia Autonomous Region Special Program for Engineering
   Application of Scientific and Technical Payoffs under Grant 2020CG0073.
   The authors thank Prof. Chundong Wang from Tianjin University of
   Technology for his comments and revision on the manuscript.
CR Ab Rahman NH, 2015, COMPUT SECUR, V49, P45, DOI 10.1016/j.cose.2014.11.006
   [Anonymous], 2015, P 22 ACM SIGSAC C CO, DOI DOI 10.1145/2810103.2813677
   Chatterjee I., 2021, Int. J. Mod. Res, V1, P15
   ELomari A, 2016, PROCEEDINGS OF 2016 THIRD INTERNATIONAL CONFERENCE ON SYSTEMS OF COLLABORATION (SYSCO), pP107
   Gao Haoyu, 2021, Journal of Computer Applications, P745, DOI 10.11772/j.issn.1001-9081.2020060912
   [贺海武 He Haiwu], 2018, [计算机研究与发展, Journal of Computer Research and Development], V55, P2452
   Jiang W, 2020, J CIRCUIT SYST COMP, V29, DOI 10.1142/S0218126620502527
   Jinyin C, 2020, ACTA AUTOMATICA SINI
   Khoda ME, 2020, IEEE T IND APPL, V56, P4415, DOI 10.1109/TIA.2019.2958530
   Li LX, 2020, IEEE ACCESS, V8, P227113, DOI 10.1109/ACCESS.2020.3043582
   Liu Jian, 2018, Journal of Software, V29, P42, DOI 10.13328/j.cnki.jos.005320
   Liu XY, 2020, IEEE INTERNET THINGS, V7, P6955, DOI 10.1109/JIOT.2020.2981379
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   [孟小峰 Meng Xiaofeng], 2021, [计算机研究与发展, Journal of Computer Research and Development], V58, P237
   Rahman MU, 2020, 2020 IEEE GLOBAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INTERNET OF THINGS (GCAIOT), P1, DOI 10.1109/GCAIOT51063.2020.9345874
   Ribeiro M, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P896, DOI 10.1109/ICMLA.2015.152
   Ruchika, 2022, MULTIMED TOOLS APPL, V81, P5259, DOI 10.1007/s11042-021-11781-4
   Sharma A, 2019, INT CONF MANAGE DATA, P105, DOI 10.1145/3299869.3319883
   Shrivastava V, 2019, P INT C MACH LEARN B
   Suliman A, 2019, IET NETW, V8, P32, DOI 10.1049/iet-net.2018.5026
   Sun J, 2020, IEEE ACCESS, V8, P59389, DOI 10.1109/ACCESS.2020.2982964
   [孙隆隆 Sun Longlong], 2020, [密码学报, Journal of Cryptologic Research], V7, P525
   Sun zhi-xin, 2021, Journal of Software, P1, DOI 10.13328/j.cnki.jos.006111
   [谭作文 Tan Zuowen], 2020, [软件学报, Journal of Software], V31, P2127
   Tavallali P, 2019, MULTIMED TOOLS APPL, V78, P2599, DOI 10.1007/s11042-018-6385-7
   ul Haque A, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P170, DOI [10.1109/icoin48656.2020.9016456, 10.1109/ICOIN48656.2020.9016456]
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Wei Z., 2019, CHINA SAFETY SCI J, V29, P32, DOI [10.16265/j.cnki.issn1003-3033.2019.S1.007, DOI 10.16265/J.CNKI.ISSN1003-3033.2019.S1.007]
   Xu GW, 2020, IEEE T INF FOREN SEC, V15, P911, DOI 10.1109/TIFS.2019.2929409
   [徐嘉辉 Xu Jiahui], 2020, [电力自动化设备, Electric Power Automation Equipment], V40, P17
   Xu J, 2020, J ELECTRON INF TECHN, V42, P2319, DOI 10.11999/JEIT200058
   [许心炜 Xu Xinwei], 2020, [密码学报, Journal of Cryptologic Research], V7, P179
   [于颖超 Yu Yingchao], 2018, [信息网络安全, Netinfo Security], P10
   Zhang YY, 2019, IEEE INTERNET THINGS, V6, P1594, DOI 10.1109/JIOT.2018.2847705
   [朱昱锦 Zhu Yujin], 2020, [软件学报, Journal of Software], V31, P1
NR 35
TC 1
Z9 1
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40343
EP 40359
DI 10.1007/s11042-022-13163-w
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791885300004
PM 35572386
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Ramis, S
   Buades, JM
   Perales, FJ
   Manresa-Yee, C
AF Ramis, Silvia
   Buades, Jose M.
   Perales, Francisco J.
   Manresa-Yee, Cristina
TI A Novel Approach to Cross dataset studies in Facial Expression
   Recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Facial expression recognition;
   Cross-datasets; Facial expression labelling
ID DEEP NEURAL-NETWORKS
AB Recognizing facial expressions is a challenging task both for computers and humans. Although recent deep learning-based approaches are achieving high accuracy results in this task, research in this area is mainly focused on improving results using a single dataset for training and testing. This approach lacks generality when applied to new images or when using it in in-the-wild contexts due to diversity in humans (e.g., age, ethnicity) and differences in capture conditions (e.g., lighting or background). The cross-datasets approach can overcome these limitations. In this work we present a method to combine multiple datasets and we conduct an exhaustive evaluation of a proposed system based on a CNN analyzing and comparing performance using single and cross-dataset approaches with other architectures. Results using the proposed system ranged from 31.56% to 61.78% when used in a single-dataset approach with different well-known datasets and improved up to 73.05% when using a cross-dataset approach. Finally, to study the system and humans' performance in facial expressions classification, we compare the results of 253 participants with the system. Results show an 83.53% accuracy for humans and a correlation exists between the results obtained by the participants and the CNN.
C1 [Ramis, Silvia; Buades, Jose M.; Perales, Francisco J.; Manresa-Yee, Cristina] Univ Illes Balears, Dept Matemat & Informat, Palma De Mallorca 07122, Spain.
C3 Universitat de les Illes Balears
RP Ramis, S (corresponding author), Univ Illes Balears, Dept Matemat & Informat, Palma De Mallorca 07122, Spain.
EM silvia.ramis@uib.es; josemaria.buades@uib.es; francisco.perales@uib.es;
   cristina.manresa@uib.es
RI Perales, Francisco Jose/G-3084-2015; Manresa-Yee, Cristina/G-3049-2015;
   Buades Rubio, Jose Maria/G-4232-2015
OI Manresa-Yee, Cristina/0000-0002-8482-7552; Buades Rubio, Jose
   Maria/0000-0002-6137-9558
FU CRUE-CSIC; Springer Nature; MINECO/AEI/ERDF, EU
   [PID2019-104829RA-I00/MCIN/AEI, RTI2018-096986-B-C31]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has been supported by the project
   PID2019-104829RA-I00/MCIN/AEI/https://doi.org/10.13039/501100011033,
   EXPLainable Artificial INtelligence systems for health and well-beING
   (EXPLAINING), and the project RTI2018-096986-B-C31 (MINECO/AEI/ERDF,
   EU), Design of pervasive gaming experiences for intergenerational social
   and emotional well-being (PERGAMEX).
CR Abdullah SMSA., 2021, Journal of Applied Science and Technology Trends, V2, P52
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Barreto A. M., 2017, Emotional Expression: the Brain and the Face, P163
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Berrar D., 2018, Encyclopedia of Bioinformatics and Computational Biology: ABC of Bioinformatics, V1, P403, DOI [DOI 10.1016/B978-0-12-809633-8.20473-1, 10.1016/b978-0-12-809633-8.20473-1]
   BURKERT P, 2015, DEXPRESSION DEEP CON
   Chen ZJ, 2019, IEEE INTEL TRANSP SY, V11, P41, DOI 10.1109/MITS.2019.2903525
   Ekman P., 1977, Nonverbal communication and behavior, P97
   Eskil MT, 2014, COMPUT VIS IMAGE UND, V119, P1, DOI 10.1016/j.cviu.2013.11.002
   Fischer A, 2015, EMOT REV, V7, P22, DOI 10.1177/1754073914544406
   Gilyazev RA, 2018, PROGRAM COMPUT SOFT+, V44, P476, DOI 10.1134/S0361768818060142
   Giryes R, 2016, IEEE T SIGNAL PROCES, V64, P3444, DOI 10.1109/TSP.2016.2546221
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Grabowski K, 2019, PSYCHIAT CLIN NEUROS, V73, P50, DOI 10.1111/pcn.12799
   Han B, 2020, IEEE ACCESS, V8, P159172, DOI 10.1109/ACCESS.2020.3018738
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jain N, 2018, PATTERN RECOGN LETT, V115, P101, DOI 10.1016/j.patrec.2018.04.010
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Küntzler T, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.627561
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li Y, 2018, NEUROCOMPUTING, V301, P11, DOI 10.1016/j.neucom.2018.01.084
   Lisani JL, 2017, SIAM J IMAGING SCI, V10, P2091, DOI 10.1137/17M1118774
   Liu SR, 2020, 2020 IEEE 3RD INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND SIGNAL PROCESSING (ICICSP 2020), P236, DOI [10.1109/icicsp50920.2020.9232063, 10.1109/ICICSP50920.2020.9232063]
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M., 2017, Japanese female facial expression (JAFFE) database
   MALATESTA CZ, 1987, PSYCHOL AGING, V2, P193, DOI 10.1037/0882-7974.2.2.193
   Medjden S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235908
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Najah G, 2017, EMOTION ESTIMATION F
   Olszanowski Michal, 2014, Front Psychol, V5, P1516, DOI 10.3389/fpsyg.2014.01516
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Poursaberi A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-17
   Ramis S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236716
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sajjanhar A, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P583
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Shamshirband S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103627
   Siddiqi MH, 2014, IETE TECH REV, V31, P277, DOI 10.1080/02564602.2014.944588
   Song I, 2014, I SYMP CONSUM ELECTR, P566
   Susskind JM, 2007, NEUROPSYCHOLOGIA, V45, P152, DOI 10.1016/j.neuropsychologia.2006.05.001
   Trujillo L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P14
   Valstar M., 2010, Proceedings of 3rd intern. workshop on EMOTION (satellite of LREC): Corpora for research on emotion and affect, P65
   Valstar MF, 2015, 2015 11 IEEE INT C W
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zhang ZC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107297
NR 55
TC 8
Z9 8
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39507
EP 39544
DI 10.1007/s11042-022-13117-2
EA APR 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788980000009
OA hybrid
DA 2024-07-18
ER

PT J
AU Sandula, P
   Okade, M
AF Sandula, Pavan
   Okade, Manish
TI Robust spatio-temporal saliency estimation method for H.264 compressed
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video saliency; Local derivative patterns; Discrete wavelet transform;
   Dempster-Shafer rule; Compressed domain
ID DOMAIN; MODEL
AB This paper presents a robust spatio-temporal saliency estimation method based on modeling motion vectors and transform residuals extracted from the H.264/AVC compressed bitstream. Spatial saliency is estimated by analyzing the detailed sub-band coefficients obtained by the wavelet decomposition of the luminance component of the macro-blocks, while temporal saliency is estimated by modeling the block motion vector orientation information using local derivative patterns. Dempster Shafer fusion rule is used to fuse the spatial saliency map and the motion saliency map to obtain the final saliency for a video frame. Extensive experimental validation along with comparative analysis with state-of-the-art methods is carried out to establish the proposed saliency method.
C1 [Sandula, Pavan; Okade, Manish] Natl Inst Technol NIT, Dept Elect & Commun Engn, Rourkela 769008, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Okade, M (corresponding author), Natl Inst Technol NIT, Dept Elect & Commun Engn, Rourkela 769008, India.
EM okadem@nitrkl.ac.in
FU SERB, Government of India [ECR/2016/000112]
FX This research work is supported by SERB, Government of India under grant
   No ECR/2016/000112.
CR Agarwal G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P133
   Bellitto G, 2020, ARXIV 201001220
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Khatoonabadi SH, 2017, MULTIMED TOOLS APPL, V76, P26297, DOI 10.1007/s11042-016-4124-5
   Khatoonabadi SH, 2015, MULTIMED TOOLS APPL, V74, P10057, DOI 10.1007/s11042-015-2802-3
   Khatoonabadi SH, 2015, IEEE C COMPUTER VISI
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li Y, 2020, ARXIV 200809103
   Li Y, 2018, ADV OPTICAL IMAGING, V10816
   Li YJ, 2017, MULTIMED TOOLS APPL, V76, P26273, DOI 10.1007/s11042-016-4118-3
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu W, 2021, IEEE T IND INFORM
   Liu Y, 2020, IEEE T IMAGE PROCESS, V29, P360, DOI 10.1109/TIP.2019.2930906
   Ma YF, 2001, INT C IMAGE PROCESSI, V3
   Ma YL, 2021, IEEE INTERNET THINGS, V8, P5822, DOI 10.1109/JIOT.2020.3034221
   Ouerhani N, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, PROCEEDINGS, P309, DOI 10.1109/CIRA.2005.1554295
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Shafer Glenn, 1976, MATH THEORY EVIDENCE, P2
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sinha A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P161
   Sun MJ, 2019, IEEE T CYBERNETICS, V49, P2900, DOI 10.1109/TCYB.2018.2832053
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang Q, 2020, IEEE T IMAGE PROCESS, V29, P3321, DOI 10.1109/TIP.2019.2959253
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39021
EP 39039
DI 10.1007/s11042-022-13148-9
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000795344600001
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Shaikh, SH
   Chakrabarti, A
   Ghosh, R
AF Chakraborty, Sanjay
   Shaikh, Soharab Hossain
   Chakrabarti, Amlan
   Ghosh, Ranjan
TI Quantum image edge extraction based on classical robinson operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quantum computing; Quantum image edge extraction; Robinson operator;
   Quantum circuits; Quantum image processing
AB In this paper, a quantum image edge extraction technique is developed with the help of the classical Robinson operator. A novel enhanced quantum representation (NEQR) technique is used to represent the quantum image. A quantum methodology is proposed to implement the Robinson masks of eight directions and perform convolution operations with the quantum shifted image sets. In this paper, a quantum parallel computation is used for evaluating gradients of the image intensity of all pixels, and a threshold-based quantum black box is designed to classify the points as edge points. The computational complexity of the proposed scheme for an image of size 2(n) x 2(n) is O(n(2) + 2(q+ 3)). However, we also carry out the design and simulation analysis of our proposed algorithm and finally compare our results with some state-of-art image edge extraction algorithms in terms of PSNR (peak signal to noise ratio), MSE (mean square error) and execution time.
C1 [Chakraborty, Sanjay] JIS Univ, Comp Sci & Engn, Kolkata, India.
   [Shaikh, Soharab Hossain] BML Munjal Univ, Comp Sci & Engn, Kapriwas, India.
   [Chakrabarti, Amlan; Ghosh, Ranjan] Univ Calcutta, K Choudhury Sch IT, Kolkata, India.
C3 BML Munjal University; University of Calcutta
RP Chakraborty, S (corresponding author), JIS Univ, Comp Sci & Engn, Kolkata, India.
EM schakraborty770@gmail.com
RI Chakraborty, Sanjay/ACM-8531-2022; Chakrabarti, Amlan/U-7020-2019;
   Hossain Shaikh, Soharab/AAF-6303-2019
OI Chakrabarti, Amlan/0000-0003-4380-3172; Hossain Shaikh,
   Soharab/0000-0003-3409-8467
CR [Anonymous], 1977, Computer Graphics and Image Processing, DOI 10.1016/s0146-664x(77)80024-5
   [Anonymous], 2003, P 16 IPPR C COMP VIS
   [Anonymous], 2016, COMMUN APPL ELECT, DOI DOI 10.5120/CAE2016652230
   Cai YQ, 2018, CHINESE J ELECTRON, V27, P718, DOI 10.1049/cje.2018.02.012
   Chakraborty S, 2020, INT J THEOR PHYS, V59, P3348, DOI 10.1007/s10773-020-04590-2
   Chakraborty S, 2020, APPL INTELL, V50, P1775, DOI 10.1007/s10489-019-01604-3
   Chakraborty S, 2019, INT J QUANTUM INF, V17, DOI 10.1142/S0219749919500163
   Chakraborty S, 2018, INTELL DECIS TECHNOL, V12, P251, DOI 10.3233/IDT-180331
   Chakraborty S, 2020, INT J PAVEMENT ENG, V21, P215, DOI 10.1080/10298436.2018.1453068
   Chetia R, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-020-02944-7
   El Amraoui A, 2016, I C COMP SYST APPLIC
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2129-x
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2131-3
   Fu X, 2009, MIPPR 2009 MED IM PA, V7497
   Islam M. S., 2009, Information Technology Journal, V8, P208, DOI 10.3923/itj.2009.208.213
   Jamal AT, 2021, TUMOR EDGE DETECTION
   Le Phuc Q., 2010, IAENG International Journal of Applied Mathematics, V40, P113
   Le PQ, 2011, INT J APPL MATH, V40, P113
   Li PC, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-019-2559-0
   Lu ZY, 2019, MULTIMED TOOLS APPL, V78, P24067, DOI 10.1007/s11042-019-7173-8
   McMahon D, 2008, QUANTUM COMPUTING EXPLAINED, P1
   Simangsong PBN., 2020, INFOKUM, V8, P31
   Thapliyal H., 2011, 2011 IEEE 11th International Conference on Nanotechnology (IEEE-NANO), P1430, DOI 10.1109/NANO.2011.6144350
   Xiaowei Fu, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7497, DOI 10.1117/12.832499
   Xu PG, 2020, OPT EXPRESS, V28, P12508, DOI 10.1364/OE.386283
   Yan F., 2020, Quantum Image Processing, P19
   Yan F, 2016, QUANTUM INF PROCESS, V15, P1, DOI 10.1007/s11128-015-1195-6
   Yao XW, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031041
   Zhang Y, 2015, QUANTUM INF PROCESS, V14, P1573, DOI 10.1007/s11128-014-0842-7
   Zhang Y, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5158-9
   Zhou RG, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2376-5
   Zhou RG, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-017-1640-9
NR 32
TC 3
Z9 3
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33459
EP 33481
DI 10.1007/s11042-022-12627-3
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122500002
DA 2024-07-18
ER

PT J
AU Jagriti
   Lobiyal, DK
AF Jagriti
   Lobiyal, D. K.
TI An efficient self-organized traffic maintenance scheme employing
   positive selection algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VANET; VTL; AIS; PSA; ALPSA
AB Virtual Traffic Lights (VTLs) come under the umbrella of Vehicular Adhoc Networks (VANETs) and are self-organized systems to implement traffic light control systems at a road intersection. During a VTL lifetime, VTLs may fail to maintain the uninterrupted working of the traffic light system. The vehicles arriving after a stable cluster formation and ongoing operation of VTL may go unattended which can weaken its application effect. If a new vehicle approaches the intersection, it either needs to get re-clustered with the current VTL cluster or has to form a new cluster with other arriving vehicles. In this paper, we aim to incorporate the Positive Selection Algorithm (PSA) scheme which is flourished with Artificial Immune System (AIS) behaviour to detect and control this anomalous clustering condition of the VTL traffic management systems. We propose the Adaptive Layer Positive Selection Algorithm (ALPSA) for monitoring the participating and non-participating vehicles; which are detected by appropriate detectors, generated through the algorithm. The algorithm works in layers and has two phases. Prior to the algorithm, we present a mobility model to generate the metrics for appropriate clustering. We extensively evaluate the ALPSA where results validate the management with reduced 'similarity detection time' and better 'similarity detection rate'. The similarity detection time is the response time given to the vehicles to decide whether to join the VTL cluster or not. Therefore, reduction in this time has shown better working for VTLs.
C1 [Jagriti; Lobiyal, D. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Jagriti (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi 110067, India.
EM jagrit37_scs@jnu.ac.in; dkl@mail.jnu.ac.in
CR Akcelik R, 1998, ARRB TRANSP RES LTD
   Alizadeh E, 2017, IEEE T CYBERNETICS, V47, P3799, DOI 10.1109/TCYB.2016.2582384
   [Anonymous], 2012, P 9 ACM INT WORKSH V
   [Anonymous], 2016, IEEE Standard 802.11-2020
   [Anonymous], 1959, CLONAL SELECTION THE, DOI DOI 10.5962/BHL.TITLE.8281
   Bazzi A, 2016, AD HOC NETW, V49, P42, DOI 10.1016/j.adhoc.2016.06.006
   Behdad M, 2012, IEEE T SYST MAN CY C, V42, P1273, DOI 10.1109/TSMCC.2012.2215851
   Behrisch M., 2011, P SIMUL 2011 3 INT C, P1
   BLUMER A, 1987, INFORM PROCESS LETT, V24, P377, DOI 10.1016/0020-0190(87)90114-1
   Camazine S., 2003, SELF ORG BIOL SYSTEM
   Coello CAC, 2002, IEEE C EVOL COMPUTAT, P819, DOI 10.1109/CEC.2002.1007031
   Dasgupta D, 2004, LECT NOTES COMPUT SC, V3239, P1
   de Castro LeandroN., 2002, ARTIFICIAL IMMUNE SY
   de Castro LN, 2003, SOFT COMPUT, V7, P526, DOI [10.1007/S00500-002-0237-Z, 10.1007/S00500-002-0237-z]
   De Castro LN, 1999, 2101 U EST CAMP
   Fathollahnejad N, 2017, IEEE PAC RIM INT SYM, P311, DOI 10.1109/PRDC.2017.56
   Ferreira Michel., 2010, PROC ACM INT WORKSHO, P85
   Forrest S., 1994, Proceedings of 1994 IEEE Computer Society Symposium on Research in Security and Privacy (Cat. No.94CH3444-7), P202, DOI 10.1109/RISP.1994.296580
   González F, 2003, LECT NOTES COMPUT SC, V2787, P261
   Hagenauer Florian, 2014, ZTE Communications, V12, P11, DOI 10.3969/j.issn.1673-5188.2014.01.002
   Hong L, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P340, DOI 10.1109/KAMW.2008.4810493
   Ji Z, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P111
   Ji Z, 2009, INFORM SCIENCES, V179, P1390, DOI 10.1016/j.ins.2008.12.015
   Kenney JB, 2011, P IEEE, V99, P1162, DOI 10.1109/JPROC.2011.2132790
   Liang XY, 2018, IEEE INTERNET THINGS, V5, P1924, DOI 10.1109/JIOT.2018.2817459
   Nakamurakare Manuel, 2013, 2013 IEEE International Conference on Sensing, Communications and Networking (SECON), P236, DOI 10.1109/SAHCN.2013.6644984
   ROBERTSON DI, 1991, IEEE T VEH TECHNOL, V40, P11, DOI 10.1109/25.69966
   Sitbor T, 2005, P 7 ANN C GEN EV COM
   Somayaji A., 1998, New Security Paradigms Workshop. Proceedings, P75
   Sommer C, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P230, DOI 10.1109/WF-IoT.2014.6803164
   Tonguz OK, 2020, IEEE T INTELL TRANSP, V21, P509, DOI 10.1109/TITS.2019.2901285
   Tonguz OK, 2011, IEEE COMMUN MAG, V49, P106, DOI 10.1109/MCOM.2011.6069717
   Van T.N., 2015, VNU Journal of Science: Computer Science and Communication Engineering, V31, P1
   Viriyasitavat W, 2012, 2012 IEEE VEH TECHN
   Zhang R, 2020, 2020 IEEE 91 VEH TEC
   Zhang RY, 2018, PR MACH LEARN RES, V80
NR 36
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33107
EP 33125
DI 10.1007/s11042-022-13174-7
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800001
DA 2024-07-18
ER

EF