FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Yan, YH
   Zhou, MQ
   Zhang, D
   Geng, SL
AF Yan, Yuhuan
   Zhou, Mingquan
   Zhang, Dan
   Geng, Shengling
TI Average increment scale-invariant heat kernel signature for 3D non-rigid
   shape analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laplace-Beltrami operator; Scale-invariant heat kernel signature; Heat
   kernel average increment; 3D non-rigid shape retrieval
ID GEODESIC DISTANCE
AB In recent years, spectral shape descriptors have attracted much attention because the Laplace-Beltrami operator(LBO) has good characteristics for non-rigid deformation shapes. The scale-invariant heat kernel signature(SIHKS) can describe the local or global information of the shape with the change of time parameters, and has scaling invariance compared with heat kernel signature(HKS). However, since the SIHKS descriptor is a feature sequence, it is impossible to balance the shape description accuracy and computational complexity when measuring shape similarity. If all feature sequences are selected for high precision description that will produce high computational complexity. Conversely, if only features under partial time parameters are selected, the accuracy will be affected and some shape features will be lost. To solve this problem, we define a more compact and efficient spectral shape descriptor, the average increment scale-invariant heat kernel signature(AISIHKS), which can effectively extract geometric and topological information by calculating the average increment of the heat kernel under all time parameters, and all the attributes of the shape can be effectively retained while reducing the feature dimension, which greatly reduces the complexity of the similarity measure. At the same time, the shape features obtained based on the increment are more discriminative than SIHKS, and can finely describe the local details of the shape. The experimental results on benchmarks show that the AISIHKS decreiptor is invariant to isometric and scale transformation, robust to topology, sampling and noise transformations, and can more accurately and robustly describe the local differences between shapes than other spectral shape descriptors, which have good performance in 3D non-rigid shape distance calculation and shape retrieval, and the more encouraging results are achieved compared with several representative approaches.
C1 [Yan, Yuhuan; Zhou, Mingquan; Zhang, Dan; Geng, Shengling] State Key Lab Tibetan Intelligent Informat Proc &, Xining 810000, Peoples R China.
   [Yan, Yuhuan; Zhou, Mingquan; Zhang, Dan; Geng, Shengling] Qinghai Normal Univ, Sch Comp Sci, Xining 810000, Peoples R China.
   [Zhou, Mingquan; Zhang, Dan; Geng, Shengling] Acad Plateau Sci & Sustainabil Dev, Xining 810000, Peoples R China.
C3 Qinghai Normal University
RP Zhou, MQ (corresponding author), State Key Lab Tibetan Intelligent Informat Proc &, Xining 810000, Peoples R China.; Zhou, MQ (corresponding author), Qinghai Normal Univ, Sch Comp Sci, Xining 810000, Peoples R China.; Zhou, MQ (corresponding author), Acad Plateau Sci & Sustainabil Dev, Xining 810000, Peoples R China.
EM 2314305749@qq.com; mqzhou@bnu.edu.cn; danz@mail.bnu.edu.cn;
   370898534@qq.com
RI ZHOU, MING/JVP-2920-2024
FU National Key RD plan [2020YFC1523305]; National Nature Science Fundation
   of China [62102213]; Key R&D and transformation plan of Qinghai Province
   [2020-SF-142]; State Key lab of Tibetan Intelligent Information
   Processing and Application [2022-SKL-014]; Young and middle-aged
   scientific research fund of Qinghai Normal University [KJQN2021004]
FX The authors would like to thank the reviewers for their thoughtful and
   constructive comments, which led to many improvements of the paper. This
   work was partially supported by the National Key R&D
   plan(No.2020YFC1523305); National Nature Science Fundation of
   China(No.62102213); Key R&D and transformation plan of Qinghai
   Province(No.2020-SF-142); Independent project fund of State Key lab of
   Tibetan Intelligent Information Processing and
   Application(Co-established by province and ministry)(Grant
   Nos.2022-SKL-014); Young and middle-aged scientific research fund of
   Qinghai Normal University(No.KJQN2021004).
CR Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bouttier J, 2003, NUCL PHYS B, V663, P535, DOI 10.1016/S0550-3213(03)00355-9
   Bronstein A, 2010, P EUROGRAPHICS WORKS, P93
   Bronstein A., 2010, Comput. Rev, V51, P222
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Choukroun Y, 2020, IEEE T VIS COMPUT GR, V26, P1320, DOI 10.1109/TVCG.2018.2867513
   Choulli M, 2017, SEMIGROUP FORUM, V94, P71, DOI 10.1007/s00233-015-9757-6
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   Du GG, 2016, I C VIRTUAL REALITY, P144, DOI 10.1109/ICVRV.2016.31
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Havens TC, 2008, INT C PATT RECOG, P2304, DOI 10.1109/ICPR.2008.4761772
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hua J, 2008, IEEE T VIS COMPUT GR, V14, P1643, DOI 10.1109/TVCG.2008.134
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Jouili S, 2012, PATTERN RECOGN, V45, P4054, DOI 10.1016/j.patcog.2012.04.016
   Li CY, 2013, INT J MULTIMED INF R, V2, P261, DOI 10.1007/s13735-013-0041-9
   Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3
   Li HS, 2018, INT CONF BIG DATA, P448, DOI 10.1109/BigComp.2018.00072
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Lian Z, 2015, P EUR WORKSH 3D OBJ
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Martinek M, 2012, VISION MODELING VISU, P219
   Masoumi M, 2016, PATTERN RECOGN LETT, V83, P339, DOI 10.1016/j.patrec.2016.04.009
   Montuori A, 2006, IEEE IJCNN, P3561
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Patané G, 2016, COMPUT GRAPH FORUM, V35, P599, DOI 10.1111/cgf.12866
   Pickup D., 2015, SHREC 15 TRACK CANON, DOI [DOI 10.2312/3DOR.20151063, 10.2312/3dor.20151063]
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   Raviv D., 2010, ACM WORKSHOP 3D OBJE, P39
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rostami R, 2019, COMPUT GRAPH FORUM, V38, P356, DOI 10.1111/cgf.13536
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Shilane P., 2004, P INT C SHAPE MODELI, DOI DOI 10.1109/SMI.2004.1314504
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   ThiruvadandamPorethi V, 2010, P EUR WORKSH 3D OBJ
   Toony Z, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0074-3
   Wang YQ, 2019, PROC CVPR IEEE, P6224, DOI 10.1109/CVPR.2019.00639
   Wu HY, 2011, IEEE I CONF COMP VIS, P587, DOI 10.1109/ICCV.2011.6126292
   Xu XG, 2020, J INTELL FUZZY SYST, V39, P3241, DOI 10.3233/JIFS-191649
   Yang JB, 2011, IEEE T NEURAL NETWOR, V22, P954, DOI 10.1109/TNN.2011.2128342
   Yu RX, 2020, IEEE T IMAGE PROCESS, V29, P4530, DOI 10.1109/TIP.2020.2967579
   Zeng W, 2012, GRAPH MODELS, V74, P121, DOI 10.1016/j.gmod.2012.03.009
   Zhang D, 2021, LECT NOTES COMPUT SC, V12890, P44, DOI 10.1007/978-3-030-87361-5_4
   Zhang D, 2021, MULTIMED TOOLS APPL, V80, P615, DOI 10.1007/s11042-020-09420-5
NR 51
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8077
EP 8115
DI 10.1007/s11042-023-15346-5
EA JUN 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009907400006
DA 2024-07-18
ER

PT J
AU Kemper, G
   Sanchez, A
   Serpa, S
AF Kemper, Guillermo
   Sanchez, Alonso
   Serpa, Sergio
TI MPEG-1 psychoacoustic model emulation using multiscale convolutional
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE audio coding; MPEG; neural networks; perceptual coding; psychoacoustic
   model
AB The Moving Picture Experts Group - 1 (MPEG-1) perceptual audio compression scheme is a successful family of audio codecs described in standard ISO/IEC 11172-3. Currently, there is no general framework to emulate nor MPEG-1 neither any other psychoacoustic model, which is a core piece of many perceptual codecs. This work presents a successful implementation of a convolutional neural network which emulates psychoacoustic model 1 from the MPEG-1 standard, termed "MCNN-PM" (Multiscale Convolutional Neural Network - Psychoacoustic Model). It is then implemented as part of the MPEG-1, Layer I codec. Using the objective difference grade (ODG) to evaluate audio quality, the MCNN-PM MPEG-1, Layer I codec outperforms the original MPEG-1, Layer I codec by up to 17% at 96 kbps, 14% at 128 kbps and performs almost equally at 192 kbps. This work shows that convolutional neural networks are a viable alternative to standard psychoacoustic models and can be used as part of perceptual audio codecs successfully.
C1 [Kemper, Guillermo; Sanchez, Alonso; Serpa, Sergio] Univ Peruana Ciencias Aplicadas, Fac Engn, Sch Elect Engn, Lima, Peru.
C3 Universidad Peruana de Ciencias Aplicadas (UPC)
RP Kemper, G (corresponding author), Univ Peruana Ciencias Aplicadas, Fac Engn, Sch Elect Engn, Lima, Peru.
EM guillermo.kemper@upc.pe
OI Sanchez Huapaya, Alonso/0000-0002-4449-786X
CR Agustsson E, 2017, ARXIV
   Ananthabhotla I, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1518, DOI 10.1145/3343031.3351148
   [Anonymous], 1998, Recommendation ITU-R
   Bourtsoulatze E, 2019, IEEE T COGN COMMUN, V5, P567, DOI 10.1109/TCCN.2019.2919300
   Cui Z., 2016, arXiv preprint arXiv:1603.06995
   Gârbacea C, 2019, INT CONF ACOUST SPEE, P735, DOI 10.1109/ICASSP.2019.8683277
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   ISO/IEC, 1993, 111723 ISOIEC
   ISO/IEC, 2006, 138181 ISOIEC
   Kankanahalli S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2521, DOI 10.1109/ICASSP.2018.8461487
   Kingma D. P., 2014, arXiv
   Leon LFA, 2011, CONATEL 2011, P1
   Lim W, 2022, ASIAPAC SIGN INFO PR, P860, DOI 10.23919/APSIPAASC55919.2022.9980064
   Min G, 2019, IEEE INT CONF MULTI, P372, DOI 10.1109/ICMEW.2019.00070
   Zhen K, 2020, IEEE SIGNAL PROC LET, V27, P2159, DOI 10.1109/LSP.2020.3039765
   Zhen K, 2020, INT CONF ACOUST SPEE, P361, DOI [10.1109/ICASSP40776.2020.9054347, 10.1109/icassp40776.2020.9054347]
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6963
EP 6974
DI 10.1007/s11042-023-15949-y
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700001
DA 2024-07-18
ER

PT J
AU Zhao, YM
   Liu, Z
   Liu, TT
   Wang, YY
   Chai, YJ
AF Zhao, YuMeng
   Liu, Zhen
   Liu, TingTing
   Wang, YuanYi
   Chai, YanJie
TI Affective-pose gait: perceiving emotions from gaits with body pose and
   human affective prior knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotion perception; Gait; Fine-grained affective features; Prior
   knowledge; Affective-pose gait
AB As a non-verbal biometric method that can be perceived emotion at a distance, gait has broad applications in affective computing. To perceive emotions from gaits, existing methods usually use velocity, acceleration and area to describe human affective features, which often fail to learn the features of body pose and lose representativeness comprehensively. In this paper, we design the fine-grained affective features based on prior knowledge and present a novel perspective to treat the fine-grained affective features of the gait as the fusion of spatial-temporal features. Following this perspective, we use the ST-GCN to build the pose features and utilize the CNN to learn the affective features. By integrating, we proposed the Affective-Pose Gait network, which fusion the pose and affective feature to analyze the emotions in gaits. The experimental results on the Emotion-Gait dataset prove that Affective-Pose Gait achieves 85.2% in terms of accuracy and outperforms state-of-the-art methods.
C1 [Zhao, YuMeng; Liu, Zhen; Chai, YanJie] Ningbo Univ, Fac Elect Engn & Comp Sci, FengHua St, Ningbo 315211, Zhejiang, Peoples R China.
   [Liu, TingTing; Wang, YuanYi] Ningbo Univ, Coll Sci & Technol, BaiSha St, Ningbo 315300, Zhejiang, Peoples R China.
C3 Ningbo University; Ningbo University
RP Liu, Z (corresponding author), Ningbo Univ, Fac Elect Engn & Comp Sci, FengHua St, Ningbo 315211, Zhejiang, Peoples R China.
EM yumeng9605@foxmail.com; liuzhen@nbu.edu.cn; liutingting@nbu.edu.cn;
   wangyuanyi@nbu.edu.cn; chaiyanjie@nbu.edu.cn
RI chen, chen/JGD-3057-2023; chen, yue/JXW-9556-2024; Liu,
   Shaobo/JUU-5767-2023; zhang, jiayue/JUF-0129-2023; lin,
   yuan/JXL-9592-2024; yang, liu/JXX-5043-2024; Zhang,
   Wenkai/JWO-2030-2024; he, xi/JXN-3817-2024; zhang, xu/JXX-7692-2024; Li,
   Ren/JVZ-9153-2024; Zhang, Xiaoyu/JXR-6386-2024; Liu, qi/JZT-5038-2024;
   zhang, ling/JXW-6931-2024; zhao, weiwei/JUU-6585-2023; Jing,
   Jing/JSK-6237-2023; zhang, yan/JGL-8022-2023; Li, Huizhen/JPX-2563-2023;
   Wang, zhenhua/KFA-8731-2024; wang, jiaqi/JSL-7112-2023; Chen,
   Jin/KBQ-0163-2024; li, lan/KCJ-5061-2024; zhang, wen/JXN-0191-2024;
   wang, KiKi/JFZ-3334-2023; yang, yy/KBR-1536-2024; FENG, X/JPL-4188-2023;
   Wang, Xingyu/JNE-0602-2023; Li, Wenjuan/KDN-8450-2024; Zhang,
   yuxuan/JXM-9935-2024
OI Li, Ren/0000-0002-2579-2580; Chen, Jin/0009-0005-5844-635X; 
FU Ningbo Science Technology Plan projects [2021S091, 2022Z077, 2020Z082];
   Ningbo University scientific Research Innovation Fund Project
   [IF2022122, IF2022116, IF2022132, IF2022133]
FX This work was partially sponsored by Ningbo Science Technology Plan
   projects (Grant No. 2021S091, 2022Z077, 2020Z082) and Ningbo University
   scientific Research Innovation Fund Project Grant No. IF2022122, No.
   IF2022116, No. IF2022132, No. IF2022133.
CR Ahmed F, 2019, LECT NOTES COMPUT SC, V11542, P53, DOI 10.1007/978-3-030-22514-8_5
   Antoniadis P, 2021, IEEE INT CONF COMP V, P3638, DOI 10.1109/ICCVW54120.2021.00407
   Bailly F, 2021, IEEE INT CONF ROBOT, P4912, DOI 10.1109/ICRA48506.2021.9561993
   Bhattacharya U., 2020, P EUR C COMP VIS CHA, P145
   Bhattacharya U, 2020, INT SYM MIX AUGMENT, P24, DOI [10.1109/1SMA1R50242.2020.00020, 10.1109/ISMAR50242.2020.00020]
   Bhattacharya U, 2020, AAAI CONF ARTIF INTE, V34, P1342
   Bigi Wolmer, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2472, DOI 10.1145/3394171.3413530
   Bliss-Moreau E, 2021, NEUROSCI BIOBEHAV R, V120, P574, DOI 10.1016/j.neubiorev.2020.06.024
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chao HQ, 2022, IEEE T PATTERN ANAL, V44, P3467, DOI 10.1109/TPAMI.2021.3057879
   Crenn A., 2016, 2016 INT C 3D IMAGIN, P1, DOI [10.1109/IC3D.2016.7823448, DOI 10.1109/IC3D.2016.7823448]
   Crenn A., 2017, P 19 ACM INT C MULT, P15
   Dabral R, 2018, LECT NOTES COMPUT SC, V11213, P679, DOI 10.1007/978-3-030-01240-3_41
   Daoudi M, 2017, LECT NOTES COMPUT SC, V10484, P550, DOI 10.1007/978-3-319-68560-1_49
   Dewaele JM, 2020, INT J MULTILING, V17, P499, DOI 10.1080/14790718.2019.1612902
   Elhamdadi H, 2022, IEEE T VIS COMPUT GR, V28, P769, DOI 10.1109/TVCG.2021.3114784
   Fang Z, 2022, VISUAL COMPUT, V38, P1151, DOI 10.1007/s00371-021-02074-w
   Gao S, 2022, IET COMPUT VIS, V16, P111, DOI 10.1049/cvi2.12070
   Gedik E, 2021, IEEE T AFFECT COMPUT, V12, P269, DOI 10.1109/TAFFC.2018.2875987
   Hall PT, 2020, J BIOMECH, V103, DOI 10.1016/j.jbiomech.2020.109685
   Hashmi MA, 2020, IEEE SENS J, V20, P13511, DOI 10.1109/JSEN.2020.3004399
   Hassan T, 2021, IEEE T PATTERN ANAL, V43, P1815, DOI 10.1109/TPAMI.2019.2958341
   Huang YB, 2021, IEEE INT CONF COMP V, P3602, DOI 10.1109/ICCVW54120.2021.00403
   Rivas JJ, 2020, IEEE T AFFECT COMPUT, V11, P470, DOI 10.1109/TAFFC.2018.2808295
   Karg M, 2010, IEEE T SYST MAN CY B, V40, P1050, DOI 10.1109/TSMCB.2010.2044040
   Li BB, 2018, IEEE T AFFECT COMPUT, V9, P585, DOI 10.1109/TAFFC.2016.2637343
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li HJ, 2018, 2018 IEEE INT C ROB
   Li M, 2021, IEEE T NEUR SYS REH, V29, P985, DOI 10.1109/TNSRE.2021.3081706
   Liu W., 2022, IEEE T PATTERN ANAL, V3, P173
   Lv F, 2021, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR46437.2021.00258
   Martin M, 2019, IEEE I CONF COMP VIS, P2801, DOI 10.1109/ICCV.2019.00289
   Miller L, 2018, VISION RES, V142, P58, DOI 10.1016/j.visres.2017.08.004
   Mittal Trisha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14222, DOI 10.1109/CVPR42600.2020.01424
   Mittal T, 2021, IEEE MULTIMEDIA, V28, P67, DOI 10.1109/MMUL.2021.3068387
   Narayanan V, 2020, IEEE INT C INT ROBOT, P8200, DOI 10.1109/IROS45743.2020.9340710
   Noroozi Fatemeh, 2021, IEEE Transactions on Affective Computing, V12, P505, DOI 10.1109/TAFFC.2018.2874986
   O'Brien K, 2020, J AM GERIATR SOC, V68, P176, DOI 10.1111/jgs.16217
   Peter P., 2021, GAIT POSTURE, V91, P126
   Pitcher D, 2021, TRENDS COGN SCI, V25, P100, DOI 10.1016/j.tics.2020.11.006
   Randhavane T, 2020, Arxiv, DOI [arXiv:1906.11884, DOI 10.48550/ARXIV.1906.11884]
   Randhavane T, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P395, DOI 10.1109/ISMAR-Adjunct.2019.000-2
   Randhavane T, 2021, IEEE T VIS COMPUT GR, V27, P2967, DOI 10.1109/TVCG.2019.2953063
   Romeo L, 2022, IEEE T AFFECT COMPUT, V13, P389, DOI 10.1109/TAFFC.2019.2954118
   Rosanna E., 2020, J EXP PSYCHOL HUMAN, V46, P657, DOI [10.1037/xhp0000737, DOI 10.1037/XHP0000737]
   Santhoshkumar R., 2019, Procedia Computer Science, V152, P158, DOI 10.1016/j.procs.2019.05.038
   Sarah KD., 2020, PERSONAL INDIVID DIF, V160, P0191
   Sheng WJ, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107868
   Shi J., 2021, SENSORS BASEL SWITZE, V21, P1
   Shiyi Yu, 2021, 2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI), P190, DOI 10.1109/CISAI54367.2021.00043
   Shun L, 2016, PEERJ, V4
   Song P, 2020, IEEE T AFFECT COMPUT, V11, P373, DOI 10.1109/TAFFC.2018.2800046
   Song YF, 2021, IEEE T CIRC SYST VID, V31, P1915, DOI 10.1109/TCSVT.2020.3015051
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Srinivasan R, 2021, IEEE T AFFECT COMPUT, V12, P707, DOI 10.1109/TAFFC.2018.2887267
   Sun X, 2021, IEEE T SYST MAN CY-S, V51, P6111, DOI 10.1109/TSMC.2019.2958094
   Talbot B, 2021, IEEE T COGN DEV SYST, V13, P791, DOI 10.1109/TCDS.2020.2993855
   Thomas T, 2021, ARXIV
   Uttaran B, 2021, P 29 ACM INT C MULTI
   Venture G, 2014, INT J SOC ROBOT, V6, P621, DOI 10.1007/s12369-014-0243-1
   Wei jS, 2021, 2021 4 ART INT CLOUD, P41
   Woojin K, 2021, P 2021 CHI C HUM FAC
   Xu N, 2022, IEEE T INTELL TRANSP, V23, P3565, DOI 10.1109/TITS.2020.3038155
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yuan Zhuang, 2021, Computer Vision - ACCV 2020 Workshops. 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12628), P46, DOI 10.1007/978-3-030-69756-3_4
   Zhang K, 2022, IEEE T CIRC SYST VID, V32, P1034, DOI 10.1109/TCSVT.2021.3072412
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang XG, 2021, NEUROCOMPUTING, V445, P194, DOI 10.1016/j.neucom.2021.02.047
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 70
TC 2
Z9 2
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 1
PY 2023
DI 10.1007/s11042-023-15162-x
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0CF9
UT WOS:000999534000008
DA 2024-07-18
ER

PT J
AU Mohamed, B
   Yassine, B
AF Mohamed, Bouyahi
   Yassine, Ben Ayed
TI Shot boundary detection using multimodal Siamese network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multimodal; Siamese; Shot boundary; Cnn; Gru; Similarity
ID SEGMENTATION; IMAGE
AB Shot Boundary Detection (SBD) is one of the most interesting pre-processing tasks involving all intelligent video analysis applications. An efficient method for SBD is a very important task in this challenge. A wide variety of methods was proposed in the literature to achieve this task. However, only a few of them adopted the multimodal approach to help solve the problem. In this work, we introduced a new multimodal technique for shot boundary detection by learning the distance measure between audiovisual features using the Siamese network. The proposed system consists of two models: Convolutional Neural Network-Gated Recurrent Unit(CNN-GRU) based model for the audio modality and the pre-trained model EfficientNet for the visual modality. The proposed network learns the similarity score from the image embedding features and the Power Spectrum Density (PSD) as audio features. The obtained similarity scores from the proposed network were then used to build a signal which represents the audio-visual change. After that, we used a global threshold for transition detection, and an adaptive threshold to differentiate between the detected transition types (Abrupt or Gradual). The experimental study, applied on standard datasets (TRECvid 2001 and TRECvid 2007) revealed that the introduction of the audio features achieved an interesting improvement, in terms of F1 score (91.36%) and gradual transition (89.06%) compared to the state-of-the-art models. The proposed approach can be incorporated into different multimedia applications to reduce their complexity.
C1 [Mohamed, Bouyahi; Yassine, Ben Ayed] Sfax Univ, MIRACL Lab Multimedia InfoRmat Syst & Adv Comp, Sfax, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax
RP Mohamed, B (corresponding author), Sfax Univ, MIRACL Lab Multimedia InfoRmat Syst & Adv Comp, Sfax, Tunisia.
EM bouyahi_206@hotmail.com; yassine.benayed@isims.usf.tn
CR Abdulhussain SH, 2019, MULTIMED TOOLS APPL, V78, P20361, DOI 10.1007/s11042-019-7364-3
   Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Amirian S, 2020, IEEE ACCESS, V8, P218386, DOI 10.1109/ACCESS.2020.3042484
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bouyahi Mohamed, 2020, Procedia Computer Science, V176, P10, DOI 10.1016/j.procs.2020.08.002
   Bouyahi M., 2021, INT C MACHINE VISION, V11605, P661
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P3071, DOI 10.1007/s11042-020-09683-y
   Chakraborty S, 2019, APPL INTELL, V49, P3207, DOI 10.1007/s10489-019-01444-1
   Chavate Shrikant, 2021, 2021 10th International Conference on System Modeling & Advancement in Research Trends (SMART), P1, DOI 10.1109/SMART52563.2021.9676246
   Choi JA, 2020, ICT EXPRESS, V6, P175, DOI 10.1016/j.icte.2020.04.012
   Das Chakladar D, 2021, INFORM FUSION, V71, P17, DOI 10.1016/j.inffus.2021.01.004
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Georgiou T, 2020, INT J MULTIMED INF R, V9, P135, DOI 10.1007/s13735-019-00183-w
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He L, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040374
   Hou L., 2019, P 2019 12 INT C IMAG, DOI [DOI 10.1109/CISP-BMEI48845.2019.8966048, DOI 10.1109/CISPBMEI48845.2019.8966048]
   Ichida AY, 2018, IEEE IJCNN
   Iwan LH, 2017, MULTIMED TOOLS APPL, V76, P1379, DOI 10.1007/s11042-015-3130-3
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Langford Z, 2019, PROCEEDINGS OF THE 2019 ACM WORKSHOP ON WIRELESS SECURITY AND MACHINE LEARNING (WISEML '19), P1, DOI 10.1145/3324921.3328781
   Mocanu Bogdan, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P506, DOI 10.1007/978-3-030-64559-5_40
   Priya GGL, 2014, ECOL INFORM, V23, P107, DOI 10.1016/j.ecoinf.2013.09.003
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Rastgoo MN, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.010
   Sajjad M, 2020, IEEE ACCESS, V8, P143759, DOI 10.1109/ACCESS.2020.3009537
   Sasithradevi A., 2020, J VIS COMMUN IMAGE R, V102754, P67
   Sharma V, 2021, IEEE ACCESS, V9, P139489, DOI 10.1109/ACCESS.2021.3118541
   Shen L, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8229-7
   Shoeibi A, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113788
   Spolaôr N, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103557
   Sun JD, 2021, NEUROCOMPUTING, V423, P34, DOI 10.1016/j.neucom.2020.10.031
   Supriya S, 2020, HEALTH INF SCI SYST, V8, DOI 10.1007/s13755-020-00129-1
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanberk S, 2021, 6 INT C COMPUTER SCI, P506, DOI 10.1109/UBMK52708.2021.9558954
   Thounaojam DM, 2017, INT J MULTIMED INF R, V6, P167, DOI 10.1007/s13735-017-0123-1
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Zhu QQ, 2022, ISPRS J PHOTOGRAMM, V184, P63, DOI 10.1016/j.isprsjprs.2021.12.005
NR 40
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15428-4
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700010
DA 2024-07-18
ER

PT J
AU Duma, RA
   Niu, ZD
   Nyamawe, A
   Tchaye-Kondi, J
   Chambua, J
   Yusuf, AA
AF Duma, Ramadhani Ally
   Niu, Zhendong
   Nyamawe, Ally
   Tchaye-Kondi, Jude
   Chambua, James
   Yusuf, Abdulganiyu Abdu
TI DHMFRD - TER: a deep hybrid model for fake review detection
   incorporating review texts, emotions, and ratings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Fake reviews; Ratings; Emotions; Convolution neural network; Long
   short-term memory; Bidirectional Encoder Representations from
   Transformers
ID SENTIMENT; SPAM
AB Recently, there has been an increasing reward to manipulate product/ service reviews, mostly profit-driven, since positive reviews infer high business returns and vice versa. To combat this issue, experts in industry and researchers recently attempted integrating multi-aspect (reviewer- and review-centric) data features. However, the emotions hidden in the review, the semantic meaning of the review, and data heterogeneity still deserve more study as they are essential indicators of fake content. This study proposed a Deep Hybrid Model for Fake Review Detection incorporating review Texts, Emotions, and Ratings (DHMFRD - TER). Initially, it computes contextualized review text vectors and extraction of emotion indicators representations. Then, the model learns the representation to extract higher-level review features. Finally, contextualized word vectors, ratings, and emotions are concatenated; such a multidimensional feature representation is used to classify reviews. Extensive experiments on three publicly available datasets demonstrate that DHMFRD-TER significantly outperforms state-of-the-art baseline approaches, achieving an accuracy of 0.988, 0.987, and 0.994 in Amazon, Yelp CHI, and OSF datasets, respectively.
C1 [Duma, Ramadhani Ally; Niu, Zhendong; Tchaye-Kondi, Jude; Yusuf, Abdulganiyu Abdu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Duma, Ramadhani Ally; Nyamawe, Ally] Univ Dodoma, Coll Informat & Virtual Educ, Dodoma, Tanzania.
   [Chambua, James] Univ Dar Es Salaam, Comp Sci & Engn Dept, Dar Es Salaam, Tanzania.
C3 Beijing Institute of Technology; University of Dar es Salaam
RP Niu, ZD (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
EM radsiffi@gmail.com; zniu@bit.edu.cn; ally.nyamawe@udom.ac.tz;
   tchaye59@gmail.com; jchambua@gmail.com; abdulg720@gmail.com
RI niu, zhendong/KIJ-1559-2024; Yusuf, Abdulganiyu/ABC-1247-2021; Chambua,
   James/AAS-8936-2021
OI Nyamawe, Ally/0000-0002-5210-259X
FU National Natural Science Foundation of China [62272048]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62272048.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Asghar MZ, 2020, SOFT COMPUT, V24, P3475, DOI 10.1007/s00500-019-04107-y
   Barbado R, 2019, INFORM PROCESS MANAG, V56, P1234, DOI 10.1016/j.ipm.2019.03.002
   Barushka A, 2020, NEURAL COMPUT APPL, V32, P4239, DOI 10.1007/s00521-019-04331-5
   Bhuvaneshwari P, 2021, MULTIMED TOOLS APPL, V80, P18107, DOI 10.1007/s11042-021-10602-y
   Bravo-Marquez F, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P536, DOI [10.1109/WI.2016.0091, 10.1109/WI.2016.90]
   Bravo-Marquez F, 2014, KNOWL-BASED SYST, V69, P86, DOI 10.1016/j.knosys.2014.05.016
   Budhi GS, 2021, MULTIMED TOOLS APPL, V80, P13079, DOI 10.1007/s11042-020-10299-5
   Chollet F., 2015, Keras: Deep learning library for theano and tensorflow
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Denecke Kerstin, 2008, 2008 IEEE 24th International Conference on Data Engineering Workshop (ICDE Workshop), P507, DOI 10.1109/ICDEW.2008.4498370
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong LY, 2018, EXPERT SYST APPL, V114, P210, DOI 10.1016/j.eswa.2018.07.005
   Duma RA, 2023, SOFT COMPUT, V27, P6281, DOI 10.1007/s00500-023-07897-4
   Ellson A, 2021, TIMES
   Fei Geli., 2013, ICWSM
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Ghai R, 2019, ADV INTELL SYST, V670, P189, DOI 10.1007/978-981-10-8971-8_18
   Gretzel U, 2009, INF COMMUN TECHNOL T, DOI [10.1007/978-3-211-93971-0, DOI 10.1007/978-3-211-93971-0]
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Harris C.G., 2012, Workshops at AAAI on Artificial Intelligence, VWS-12-08, P87
   Heydari A, 2015, EXPERT SYST APPL, V42, P3634, DOI 10.1016/j.eswa.2014.12.029
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Jacob MS, 2021, FUZZY ARTIFICIAL BEE, P1, DOI [10.1002/cpe.6539, DOI 10.1002/CPE.6539]
   Jiaming Li, 2020, Cognitive Computing - ICCC 2020. 4th International Conference Held as Part of the Services Conference Federation, SCF 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12408), P39, DOI 10.1007/978-3-030-59585-2_4
   Jindal N., 2008, Proceedings of the 2008 International Conference on Web Search and Data Mining: ACM, DOI DOI 10.1145/1341531.1341560
   Jindal N., 2007, P 16 INT WORLD WID W, P1189, DOI DOI 10.1145/1242572.1242759
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Khan ZY, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114528
   Khan ZY, 2020, NEUROCOMPUTING, V402, P256, DOI 10.1016/j.neucom.2020.03.075
   Kokate S, 2015, FAKE REV BRAND SPAM, V6, P3523
   Lauriola I, 2022, NEUROCOMPUTING, V470, P443, DOI 10.1016/j.neucom.2021.05.103
   Li Fangtao., 2011, P 22 INT JOINT C ART
   Li HY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1063, DOI 10.1145/3038912.3052582
   Li JD, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114585
   Li JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1566
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Li YJ, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P317, DOI 10.1109/ICISCE.2016.77
   Lim E.P., 2010, P ACM INT C INFORM K, P939, DOI DOI 10.1145/1871437.1871557
   Liu YX, 2022, INFORM SYST, V103, DOI 10.1016/j.is.2021.101865
   LUCA M, 2016, 12016 HARV BUS SCH N
   Luo N, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P475, DOI 10.1109/ICISCE.2017.106
   Malik MSI, 2017, COMPUT HUM BEHAV, V73, P290, DOI 10.1016/j.chb.2017.03.053
   Manaskasemsak B, 2023, NEURAL COMPUT APPL, V35, P1169, DOI 10.1007/s00521-021-05948-1
   Melleng A., 2019, INT C REC ADV NAT LA, P750, DOI [10.26615/978-954-452-056-4_087, DOI 10.26615/978-954-452-056-4_087]
   Mewada A, 2022, J KING SAUD UNIV-COM, V34, P7530, DOI 10.1016/j.jksuci.2021.07.021
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P632
   Noekhah S., 2014, P 8 IEEE INT C E COM, V33
   Ott M., 2013, P 2013 C N AM CHAPT, P497
   Ott M, 2011, Arxiv, DOI [arXiv:1107.4557, DOI 10.48550/ARXIV.1107.4557]
   Palani B., 2021, CB FAKE MULTIMODAL D
   Qingxi Peng, 2014, Journal of Software, V9, P2065, DOI 10.4304/jsw.9.8.2065-2072
   Rajamohana SP, 2018, COMPUT ELECTR ENG, V67, P497, DOI 10.1016/j.compeleceng.2018.02.015
   Rayana S, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P985, DOI 10.1145/2783258.2783370
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Ren J, 2018, J ASSOC INF SCI TECH, V69, P449, DOI 10.1002/asi.23967
   Ren YF, 2017, INFORM SCIENCES, V385, P213, DOI 10.1016/j.ins.2017.01.015
   Sagnika S, 2021, NEURAL COMPUT APPL, V33, P17425, DOI 10.1007/s00521-021-06328-5
   Saini M., 2017, Int J Hybrid Inf Technol, V10, P447, DOI DOI 10.14257/IJHIT.2017.10.1.36
   Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771
   Vidanagama DU, 2020, ARTIF INTELL REV, V53, P1323, DOI 10.1007/s10462-019-09697-5
   Wallace B., 2015, ARXIV
   Wang XP, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P366, DOI 10.18653/v1/P17-1034
   Zhang W, 2018, INFORM PROCESS MANAG, V54, P576, DOI 10.1016/j.ipm.2018.03.007
   Zhao SY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2410206
NR 66
TC 2
Z9 2
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15193-4
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400001
DA 2024-07-18
ER

PT J
AU Shi, YH
   Wang, YS
   Wang, J
   Ding, WP
   Yin, BC
AF Shi, Yunhui
   Wang, Yuansong
   Wang, Jin
   Ding, Wenpeng
   Yin, Baocai
TI Optimal sequence reordering for low delay screen content coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE High Efficiency Video Coding (HEVC); Screen Content Coding (SCC); Hash;
   Picture reordering; Reference picture
ID EFFICIENCY; STANDARD
AB Screen content denotes images generated by computers, which consists of texts, graphics and synthetic images. Conventional encoding strategies developed for natural content, which are premised on the strong temporal relevance, may not work well for screen content. This is because the irregular motion of objects results in the weak temporal relevance in screen content, which also makes the selection of reference pictures not optimal. This paper proposes an optimal picture reordering scheme for screen content coding to enhance the temporal relevance of screen content. In our scheme, a concept of inter-picture correlation is introduced to help formulate the temporal relevance problem, and a model of permutation is proposed to produce the new order of the pictures. To further improve the coding efficiency, a reference picture selecting algorithm is also proposed. Better compression performance can then be achieved. Compared with SCC extension of HEVC, on average, 2.82% bit rate saving can be achieved by reordering the pictures and 4.40% bit saving is achieved by further utilizing the reference pictures selection algorithm.
C1 [Shi, Yunhui; Wang, Yuansong; Wang, Jin; Ding, Wenpeng; Yin, Baocai] Beijing Univ Technol, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Wang, J (corresponding author), Beijing Univ Technol, Beijing Inst Artificial Intelligence, Fac Informat Technol, Beijing 100124, Peoples R China.
EM ijinwang@bjut.edu.cn
OI Wang, Jin/0000-0001-5437-3150
FU National Key R&D Program of China [2021ZD0111902]; National Natural
   Science Foundation of China [61976011, 62272016, U21B2038, U1937207];
   Common Program of Beijing Municipal Commission of Education
   [KM202010005013]; Opening Project of Beijing Key Laboratory of Internet
   Culture and Digital Dissemination Research; BJUT [NTUT-BJUT-111-02];
   NTUT [NTUT-BJUT-111-02]
FX This work was supported by the National Key R&D Program of China (No.
   2021ZD0111902), National Natural Science Foundation of China(61976011,
   62272016, U21B2038, U1937207), the Common Program of Beijing Municipal
   Commission of Education under Grant KM202010005013, the Opening Project
   of Beijing Key Laboratory of Internet Culture and Digital Dissemination
   Research, and by the Special Academic Collaborative Research Projects
   between BJUT and NTUT(NTUT-BJUT-111-02).
CR [Anonymous], 2011, 2011 IEEE 13 INT WOR
   [Anonymous], 2012, HEVC TEST MOD HM
   [Anonymous], 2012, JCTVCK1003
   [Anonymous], 2016, JCTVCW0078
   [Anonymous], 2014, JCTVCQ0245
   Bjontegaard G., 2008, VCEGAI11
   Charikar M., 2002, P THIRY 4 ANN ACM S, P380
   Chen C, 2016, IEEE IMAGE PROC, P2365, DOI 10.1109/ICIP.2016.7532782
   Flynn D, 2016, IEEE T CIRC SYST VID, V26, P4, DOI 10.1109/TCSVT.2015.2478707
   Li B, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P530, DOI 10.1109/VCIP.2014.7051623
   Manju VN, 2019, MULTIMED TOOLS APPL, V78, P14897, DOI 10.1007/s11042-018-6652-7
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P1169, DOI 10.1109/TCSVT.2016.2643701
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P499, DOI 10.1109/TCSVT.2016.2612684
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Zhang H, 2016, INT CONF ACOUST SPEE, P1377, DOI 10.1109/ICASSP.2016.7471902
   Zhu W, 2012, 2012 VISUAL COMMUNIC, P1
   Zhu WJ, 2015, IEEE T MULTIMEDIA, V17, P935, DOI 10.1109/TMM.2015.2428171
   Zhu WJ, 2014, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2014.11
NR 22
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15345-6
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400016
DA 2024-07-18
ER

PT J
AU Fang, LL
   Liang, XY
   Xu, C
   Wang, Q
AF Fang, Lingling
   Liang, Xiyue
   Xu, Chang
   Wang, Qian
TI Image segmentation using a novel dual active contour model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Dual active contour model; Region-based information;
   Edge-based information; Energy functional
AB For some complex images, low contrast, intensity inhomogeneity, and blurred edges are common phenomena, which inevitably cause difficulties in image segmentation. As a popular image segmentation method, the active contour model (ACM) is often used to solve the above problems. However, the ACM is highly dependent on the initial evolving curves, which makes the model unstable and complex in the actual image segmentation. In this paper, a novel dual active contour model (DACM) is proposed to segment images, which integrates region and edge information to obtain accurate segmentation. Thereinto, the two contours are initialized and evolved simultaneously. The proposed DACM can use region-based and edge-based information, which can handle images with complex structures. For region-based DACM, uniformity among the object pixels and background difference is interlinked to provide an evolving force. Here, uniformity among the object pixels is constructed based on the color reward strategy. For edge-based DACM, the adjustable weighting parameter is set based on image gradient information of two evolving curves. The edge-based DACM can make the evolving curves move inward or outward adaptively. The proposed method is evaluated on various synthetic and real images and accurate segmentation results are obtained. Besides, the state-of-the-art methods are compared with the proposed DACM and an in-depth study of this novel method is given, which denotes that the proposed model can be applied to different types of complex image segmentation.
C1 [Fang, Lingling; Liang, Xiyue; Xu, Chang] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian City, Liaoning Provin, Peoples R China.
   [Wang, Qian] Liaoning Normal Univ, Dept Math, Dalian City, Liaoning Provin, Peoples R China.
C3 Liaoning Normal University; Liaoning Normal University
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian City, Liaoning Provin, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU Natural Science Foundation of Liaoning Province [2021-MS-272]; Education
   Department of Liaoning Province [LJKQZ2021088]
FX AcknowledgementThis work was supported by Natural Science Foundation of
   Liaoning Province under Grant 2021-MS-272; Education Department of
   Liaoning Province under Grant LJKQZ2021088.
CR Biswas S, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang HH, 2009, NEUROIMAGE, V47, P122, DOI 10.1016/j.neuroimage.2009.03.068
   Dym C.L., 2013, Solid Mechanics: A Variational Approach
   Fang LL, 2022, SIGNAL IMAGE VIDEO P, V16, P193, DOI 10.1007/s11760-021-01979-2
   Fang LL, 2018, COMPUT MATH APPL, V75, P4286, DOI 10.1016/j.camwa.2018.03.029
   Gao Y, 2018, IEICE T FUND ELECTR, VE101A, P658, DOI 10.1587/transfun.E101.A.658
   Ghosh A, 2018, APPL SOFT COMPUT, V66, P413, DOI 10.1016/j.asoc.2018.02.034
   GUNN SR, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P305
   Hafri M, 2016, IEEE IMAGE PROC, P4334, DOI 10.1109/ICIP.2016.7533178
   Huang XC, 2014, C IND ELECT APPL, P1091, DOI 10.1109/ICIEA.2014.6931327
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Li CM, 2007, PROC CVPR IEEE, P339
   Li Z., 2022, IEEE T PATTERN ANAL, V44, P9904, DOI DOI 10.1109/TPAMI.2021.3132068
   Meng FM, 2013, IEEE T CYBERNETICS, V43, P725, DOI 10.1109/TSMCB.2012.2215316
   Molinari F, 2012, J ULTRAS MED, V31, P1123
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Sun YP, 2021, Arxiv, DOI arXiv:2111.03392
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Wang Y, 2017, MED IMAGE ANAL, V40, P1, DOI 10.1016/j.media.2017.05.005
   Weng GR, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104299
   Woo J, 2013, COMPUT VIS IMAGE UND, V117, P1084, DOI 10.1016/j.cviu.2012.11.012
   Xu XY, 2012, COMPUT MED IMAG GRAP, V36, P248, DOI 10.1016/j.compmedimag.2011.06.007
   Yang XJ, 2020, INT J AMBIENT COMPUT, V11, P87, DOI 10.4018/IJACI.2020010105
   Zhang ZW, 2017, J MED IMAG HEALTH IN, V7, P607, DOI 10.1166/jmihi.2017.2056
   Zhu GP, 2006, OPT ENG, V45, DOI 10.1117/1.2333566
NR 27
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15472-0
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY3
UT WOS:000990967600002
DA 2024-07-18
ER

PT J
AU Becattini, F
   De Divitiis, L
   Baecchi, C
   Bimbo, AD
AF Becattini, Federico
   De Divitiis, Lavinia
   Baecchi, Claudio
   Bimbo, Alberto Del
TI Fashion recommendation based on style and social events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Style; Social events; Garment recommendation; Fashion
AB Fashion recommendation is often declined as the task of finding complementary items given a query garment or retrieving outfits that are suitable for a given user. In this work we address the problem by adding an additional semantic layer based on the style of the proposed dressing. We model style according to two important aspects: the mood and the emotion concealed behind color combination patterns and the appropriateness of the retrieved garments for a given type of social event. To address the former we rely on Shigenobu Kobayashi's color image scale, which associated emotional patterns and moods to color triples. The latter instead is analyzed by extracting garments from images of social events. Overall, we integrate in a state of the art garment recommendation framework a style classifier and an event classifier in order to condition recommendation on a given query.
C1 [Becattini, Federico; De Divitiis, Lavinia; Baecchi, Claudio; Bimbo, Alberto Del] Univ Florence, Media Integrat & Commun Ctr MICC, Viale Morgagni 65, Florence, Italy.
C3 University of Florence
RP Becattini, F (corresponding author), Univ Florence, Media Integrat & Commun Ctr MICC, Viale Morgagni 65, Florence, Italy.
EM federico.becattini@unifi.it; lavinia.dedivitiis@unifi.it;
   claudio.baecchi@unifi.it; alberto.delbimbo@unifi.it
RI Becattini, Federico/AAE-8554-2021
OI Becattini, Federico/0000-0003-2537-2700
FU Italian MIUR within PRIN [20172BH297]; Italian MIUR within PRIN 2017
   [20172BH297]
FX This work was partially supported by the Italian MIUR within PRIN 2017,
   Project Grant 20172BH297: I-MALL - improving the customer experience in
   stores by intelligent computer vision.
CR Ahmad K, 2016, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON MULTIMEDIA SYSTEMS (MMSYS'16), P380, DOI 10.1145/2910017.2910624
   Becattini F., 2021, ACM MULTIMEDIA ASIA, P1
   Bertini Marco, 2021, ACM MULT AS
   Bigi Wolmer, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P2472, DOI 10.1145/3394171.3413530
   Cucurull G, 2019, PROC CVPR IEEE, P12609, DOI 10.1109/CVPR.2019.01290
   Cuffaro G, 2016, LECT NOTES COMPUT SC, V9915, P25, DOI 10.1007/978-3-319-49409-8_4
   Cui ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P307, DOI 10.1145/3308558.3313444
   De Divitiis Lavinia, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P282, DOI 10.1007/978-3-030-68790-8_23
   De Divitiis L, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3531017
   De Divitiis L, 2021, INT WORK CONTENT MUL, P1, DOI 10.1109/CBMI50038.2021.9461912
   Feng ZL, 2018, Arxiv, DOI arXiv:1806.04845
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Graves A, 2014, Arxiv, DOI arXiv:1410.5401
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12127, DOI 10.1109/ICCV48922.2021.01193
   Kobayashi S., 2009, Color image scale
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JH, 2019, NEUROCOMPUTING, V359, P249, DOI 10.1016/j.neucom.2019.05.081
   Marchetti Francesco, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13805), P543, DOI 10.1007/978-3-031-25072-9_37
   Marchetti F., 2020, IEEE T PATTERN ANAL
   Marchetti F, 2024, Arxiv, DOI arXiv:2203.12446
   Marchetti F, 2020, PROC CVPR IEEE, P7141, DOI 10.1109/CVPR42600.2020.00717
   Sá J, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2405, DOI 10.1145/3477495.3531866
   Sagar D, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P221, DOI 10.1109/BigMM50055.2020.00039
   Sarkar R, 2022, IEEE COMPUT SOC CONF, P2262, DOI 10.1109/CVPRW56347.2022.00249
   Song XM, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P320, DOI 10.1145/3343031.3350956
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Vasileva MI, 2018, LECT NOTES COMPUT SC, V11220, P405, DOI 10.1007/978-3-030-01270-0_24
   Wang J.Z., 2006, P 8 ACM INT WORKSHOP, P5, DOI DOI 10.1145/1178677
   Wang X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P329, DOI 10.1145/3343031.3350909
   Weston J, 2015, Arxiv, DOI arXiv:1410.3916
   Yang X, 2020, AAAI CONF ARTIF INTE, V34, P287
NR 34
TC 1
Z9 1
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 17
PY 2023
DI 10.1007/s11042-023-15290-4
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7EQ1
UT WOS:000990751100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Quan, Z
   Pu, LX
AF Quan, Zhi
   Pu, Luoxi
TI For better and quicker understanding of how users feel: an optimized
   sentiment classification model for long comments on social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE bidirectional long short term memory (Bi LSTM); Word2vec; support vector
   machine (SVM); sentiment classification; sentiment analysis
AB It seems beneficial to systematically and massively analyze postings on social networks to capture people's feelings, opinions and attitudes. Sentiment analysis, thus, is of increasing academic and applied values. This research aims to develop and evaluate an optimized sentiment classification model to investigate long comments on social networks for distance education. To achieve the goal, this research mainly utilizes the deep learning model of Bi LSTM for model building, combined with proven techniques of Word2vec and support vector machine (SVM). More than 20,000 online comments were collected to constitute a corpus and several data sets for a comparison experiment. The experimental results show that, the constructed model in this research can achieve a little higher accuracy and better effect of classification in a shorter time, as compared to two other recent classification methods. This effort may inspire better integration of established techniques for sentiment classification and future incorporation of multimodal elements for better and quicker understanding of how online users feel.
C1 [Quan, Zhi] Southwestern Univ Finance & Econ, 555 Liutai Ave, Chengdu, Peoples R China.
   [Pu, Luoxi] Lincoln Univ, Christchurch, New Zealand.
C3 Southwestern University of Finance & Economics - China
RP Quan, Z (corresponding author), Southwestern Univ Finance & Econ, 555 Liutai Ave, Chengdu, Peoples R China.
EM quanzhi@swufe.edu.cn
RI PU, Luoxi/JUV-3407-2023
CR Ahmad K., 2011, AFFECTIVE COMPUTING, P7, DOI [10.1007/978-94-007-1757-2, DOI 10.1007/978-94-007-1757-2]
   Beale R, 2008, LECT NOTES COMPUT SC, V4868, P1, DOI 10.1007/978-3-540-85099-1_1
   Bian C, 2020, ENERGY, V191, DOI 10.1016/j.energy.2019.116538
   Cambria E, 2017, SOCIO AFFECT COMPUT, V5, P1, DOI 10.1007/978-3-319-55394-8_1
   Chen Peng, 2017, P 2017 C EMP METH NA, P452, DOI [10.18653/v1/D17-1047, DOI 10.18653/V1/D17-1047]
   Di Gennaro G, 2021, J SUPERCOMPUT, V77, P12320, DOI 10.1007/s11227-021-03743-2
   Fang J., 2011, P WORKSHOP SENTIMENT, P94
   Giatsoglou M, 2017, EXPERT SYST APPL, V69, P214, DOI 10.1016/j.eswa.2016.10.043
   Govindarajan M., 2022, Data Mining Approaches for Big Data and Sentiment Analysis in Social Media, P1
   Guggilla C., 2016, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, P2740
   Iglesias C. A., 2020, Sentiment Analysis for Social Media
   Kang X, 2020, IEEE T AFFECT COMPUT, V11
   Lei L, 2021, Conducting sentiment analysis, DOI DOI 10.1017/9781108909679
   Liu B, 2020, Studies in Natural L, P1, DOI 10.1017/9781108639286
   Liu B., 2012, Sentiment Analysis and Opinion Mining (Synthesis Lectures on Human Language Technologies), V1st, P9, DOI DOI 10.1007/978-3-031-02145-9
   Liu B, 2020, J AMB INTEL HUM COMP, V11, P451, DOI 10.1007/s12652-018-1095-6
   Liu B, 2017, SOCIO AFFECT COMPUT, V5, P11, DOI 10.1007/978-3-319-55394-8_2
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Murty MN, 2016, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-3-319-41063-0
   Onan A, 2021, COMPUT APPL ENG EDUC, V29, P572, DOI 10.1002/cae.22253
   Paiva A., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P1
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Picard R., 2000, AFFECTIVE INTERACTIO, P219
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Poria S., 2018, MULTIMODAL SENTIMENT
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Pozzi FA, 2017, SENTIMENT ANALYSIS IN SOCIAL NETWORKS, P1, DOI 10.1016/B978-0-12-804412-4.00001-2
   Rong X, 2016, Arxiv, DOI arXiv:1411.2738
   Stoean C., 2014, SUPPORT VECTOR MACHI, DOI DOI 10.1007/978-3-319-06941-8
   Sun W, 2020, ENERGY, V207, DOI 10.1016/j.energy.2020.118294
   Takahashi K, 2021, J SUPERCOMPUT, V77, P9848, DOI 10.1007/s11227-020-03584-5
   Tan Y, 2020, INT J CONTIN ENG EDU, V30, P120
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thamm RobertA., 2006, Handbook of the Sociology of Emotions, Handbooks of Sociology and Social Research, P11
   Tsai MF, 2021, J SUPERCOMPUT, V77, P6676, DOI 10.1007/s11227-020-03525-2
   Tseng CW, 2018, IEEE ACCESS, V6, P72870, DOI 10.1109/ACCESS.2018.2878478
   Verstege S, 2019, COMPUT HUM BEHAV, V100, P325, DOI 10.1016/j.chb.2019.02.020
   Vieira V, 2020, IET SIGNAL PROCESS, V14, P522, DOI 10.1049/iet-spr.2019.0383
   Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058
   Wang ZY, 2020, COMPUT GEOSCI-UK, V138, DOI 10.1016/j.cageo.2020.104455
   Yang M, 2017, AAAI CONF ARTIF INTE, P5013
   Zarrinkalam F, 2019, INFORM RETRIEVAL J, V22, P93, DOI 10.1007/s10791-018-9337-y
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
NR 43
TC 0
Z9 0
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15752-9
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100004
DA 2024-07-18
ER

PT J
AU Alam, S
   Mohammad, OKJ
   Alfurhood, BS
   Saxena, KK
   Anand, M
   Mahaveerakannan, R
   Savitha, V
AF Alam, Shadab
   Mohammad, Omer K. Jasim
   Alfurhood, Badria Sulaiman
   Saxena, Kuldeep K.
   Anand, M.
   Mahaveerakannan, R.
   Savitha, V.
TI Effective sound detection system in commercial car vehicles using Msp430
   launchpad development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Acoustic Source Localization; Launchpad Development; Sound Detection;
   Sound Prototyping; Sound Transducer
ID LOCALIZATION
AB In vehicular networks, several automation protocols are invented in artificial intelligence-based systematic processes. But best of our knowledge, none of the methods discussed effective sound detection systems and sound transducers based on real-time scenarios. In this research, an effective sound detection system and sound transducer for an intelligent sound adjustment system in commercial car vehicles using proposed sound prototyping development are developed to create an impact of a sound detection system. This Intelligent sound adjustment system enables six models for vehicle wearable sensor systems with Value Line MSP430 LaunchPad (TM) Development Kit. This model reduces and maintains a balanced sound system inside the car based on unique circumstances such as Acoustic source localization, Microphone with Super cardioid, and Mass comparison. This Proposed Analysis of an Intelligent sound adjustment system in commercial car vehicles works based on Value Line MSP430 LaunchPad (TM) Development Kit connected with "Acoustic source localization," "Microphone with Super cardioid" for creating a vehicle wearable sensor system. This system can find a nearby vehicle, especially an ambulance, and the siren sound of an ambulance. However, sensors are car wearable devices for accessing ambulance sound and predicting exclusive sound patterns of an ambulance by comparing and predicting sound from a real-time sound to a sound database. Proposed connected development kit to sound system used to control sound. According to experimental findings, an effective sound detection system in commercial car vehicles using proposed sound prototyping achieves a recognition accuracy equivalent to that of edge Value Line MSP430 LaunchPad (TM) Development systems already in use while significantly decreasing data traffic by 93.5 and computational delay by 92%. Findings indicate that Intelligent sound adjustment system fault detection accuracy ranges from 99.82 percent on average to 97.92 percent at its peak. Compared to traditional federated learning, a microphone with super-cardioid considerably reduces energy usage by 68.5 with a minimum accuracy loss of up to 97.3%. Acoustic source localization is built and utilized to find sound faults at the end. This technique offers a fresh concept for arc sound detection systems and performs well.
C1 [Alam, Shadab] Jazan Univ, Coll Comp Sci & IT, Jazan, Saudi Arabia.
   [Mohammad, Omer K. Jasim] Univ Fallujah, Al Fallujah, Iraq.
   [Alfurhood, Badria Sulaiman] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, POB 84428, Riyadh 11671, Saudi Arabia.
   [Saxena, Kuldeep K.] Lovely Profess Univ, Div Res & Dev, Phagwara, Punjab, India.
   [Anand, M.] SRM Inst Sci & Technol, Sch Comp, Dept Data Sci & Business Syst, Chennai, India.
   [Mahaveerakannan, R.] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Savitha, V.] SNS Coll Technol, Dept CSE, Coimbatore 641035, India.
C3 Jazan University; Princess Nourah bint Abdulrahman University; Lovely
   Professional University; SRM Institute of Science & Technology Chennai;
   Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; SNS College of Technology
RP Alam, S (corresponding author), Jazan Univ, Coll Comp Sci & IT, Jazan, Saudi Arabia.
EM snafis@jazanu.edu.sa; omerk.jasim@uofallujah.edu.iq;
   bsalfurhood@pnu.edu.sa; saxena0081@gmail.com; anandmenscall@gmail.com;
   mahaveerakannanr.sse@saveetha.com; savicse@gmail.com
RI Renganathan, Mahaveerakannan/M-8941-2013; M, Anand/AAE-5629-2020; Alam,
   Shadab/AAK-7827-2021; SAXENA, KULDEEP K/ABF-2558-2020; Velaayutham,
   Savitha/ABA-8893-2020; Alfurhood, Badria Sulaiman/IQU-6895-2023
OI Renganathan, Mahaveerakannan/0000-0003-4458-0783; M,
   Anand/0000-0001-5801-3654; Alam, Shadab/0000-0003-0504-4515; SAXENA,
   KULDEEP K/0000-0003-4064-5113; Velaayutham, Savitha/0000-0002-8063-2459;
   Alfurhood, Badria Sulaiman/0000-0002-7626-5262
FU Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia
   [PNURSP2023R359]
FX Badria Alfurhood would like to thank Princess Nourah bint Abdulrahman
   University Researchers Supporting Project number (PNURSP2023R359),
   Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia.
CR Aller M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31549-0
   Anbuhl KL, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30455-9
   Armoundas AA., 2021, STATE ART WEARABLE I, P353
   BARY BM, 1962, NATURE, V194, P36, DOI 10.1038/194036a0
   Buergers S, 2022, NAT HUM BEHAV, V6, P732, DOI 10.1038/s41562-022-01294-x
   Calapai A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29185-9
   Chen FY, 2011, NAT NEUROSCI, V14, P770, DOI 10.1038/nn.2827
   Darwish A, 2011, SENSORS-BASEL, V11, P5561, DOI 10.3390/s110605561
   Dean I, 2005, NAT NEUROSCI, V8, P1684, DOI 10.1038/nn1541
   Favre-Bulle IA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19982-5
   Franken TP, 2015, NAT NEUROSCI, V18, P444, DOI 10.1038/nn.3948
   Gao B, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29712-8
   Griffiths TD, 1996, NATURE, V383, P425, DOI 10.1038/383425a0
   Han WB, 2021, ACS APPL ELECTRON MA, V3, P485, DOI 10.1021/acsaelm.0c00724
   Hassan Mohammed K., 2019, BIG DATA CHALLENGES, P3
   Hassan M, 2022, ADV MATER TECHNOL-US, V7, DOI 10.1002/admt.202100773
   Hofman PM, 1998, NAT NEUROSCI, V1, P417, DOI 10.1038/1633
   Homma Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14006-2
   Hu CQ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-17235-7
   Inui K., 2009, NAT PREC, DOI [10.1038/npre.2009.3652.1, DOI 10.1038/NPRE.2009.3652.1]
   Kaggle.com, 2022, EM VEH SIR SOUNDS
   Kar A, 2022, BIOMATERIALS, V283, DOI 10.1016/j.biomaterials.2022.121435
   Kim JS, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11478-1
   Lakshmi PV., 2021, INT J SENS WIREL COM, V11, P976
   Lang CH, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11108
   Larsen LB, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16456-0
   Lin RZ, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29859-4
   Ma C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-08221-7
   McWalter R, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12893-0
   Moore S, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19152-7
   Moro F, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31157-y
   Nuttall AL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06725-w
   Olenik S, 2021, NAT REV MATER, V6, P286, DOI 10.1038/s41578-021-00299-8
   Pokorny F. B., 2022, SCI REP-UK, V12, P1, DOI 10.1038/s41598-022-17203-1
   Rachim VP, 2021, ESSAYS BIOCHEM, V65, P491, DOI 10.1042/EBC20200131
   Rufo J, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31014-y
   Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526
   Stylogiannis A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32175-6
   Sunwoo SH, 2021, ANNU REV CHEM BIOMOL, V12, P359, DOI 10.1146/annurev-chembioeng-101420-024336
   Syafrudin M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092946
   Talling PJ, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31689-3
   Tran T, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-13237-7
   Vijayan V, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165589
   Wang HY, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abi6751
   Will C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29984-5
   Yan W, 2022, NATURE, V603, P616, DOI 10.1038/s41586-022-04476-9
   Yang HL, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32020-w
   Yang LX, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12060666
   Zahorik P, 2001, NAT NEUROSCI, V4, P78, DOI 10.1038/82931
   Zhang J, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23991-3
   Zhao SJ, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12048-1
   Zhu B, 2021, ELECTROANAL
NR 52
TC 2
Z9 2
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15373-2
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800007
DA 2024-07-18
ER

PT J
AU Wang, MX
   Wang, XY
   Wang, CP
   Xia, ZQ
   Zhou, S
AF Wang, Mingxu
   Wang, Xingyuan
   Wang, Chunpeng
   Xia, Zhiqiu
   Zhou, Shuang
TI Novel image compression-then-encryption scheme based on 2D cross coupled
   map lattice and compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image compression-then-encryption; Cross coupled map lattice;
   Compressive sensing; Hash function
ID SPATIOTEMPORAL CHAOS; ALGORITHM; ENTROPY
AB A 2D cross coupled map lattice (2D-CCML) model with large key spaces is constructed for image compression and encryption, and this model exhibits better cryptographic features in dynamics than the traditional cross coupled map lattice (CCML) system. Furthermore, by combining the 2D-CCML model and compressive sensing (CS), we present an image compression-then-encryption scheme, the core of which includes image compression by CS and image encryption based on the 2D-CCML. In addition, the proposed 2D-CCML model is utilized to generate a measurement matrix for use in CS. Furthermore, the key stream used in our algorithm and the 2D-CCML model is based on the hash values calculated with the SHA-512 hash function and plain images. We experimentally demonstrate reasonable chaotic behaviors of the 2D-CCML model in terms of its image encryption effect, compression capability, and high security.
C1 [Wang, Mingxu; Wang, Xingyuan; Xia, Zhiqiu] Dalian Maritime Univ, Dalian, Peoples R China.
   [Wang, Chunpeng] Qilu Univ Technol, Qilu, Peoples R China.
   [Zhou, Shuang] Chongqing Normal Univ, Chongqing, Peoples R China.
C3 Dalian Maritime University; Qilu University of Technology; Chongqing
   Normal University
RP Wang, MX; Xia, ZQ (corresponding author), Dalian Maritime Univ, Dalian, Peoples R China.
EM mxwang9033@163.com; xzqjsdtc@163.com
OI Wang, Mingxu/0000-0002-9392-9809
CR Ansari MS, 2018, IEEE J EM SEL TOP C, V8, P404, DOI 10.1109/JETCAS.2018.2832204
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chao Zhao, 2013, 2013 38th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz 2013), DOI 10.1109/IRMMW-THz.2013.6665668
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Frunzete M, 2011, SPA 2011: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P11
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Kang XJ, 2019, IEEE T CIRC SYST VID, V29, P1919, DOI 10.1109/TCSVT.2018.2859253
   Lei Yu, 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P229
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Ma LH, 2018, OPT COMMUN, V407, P51, DOI 10.1016/j.optcom.2017.08.047
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Ponnaian D, 2017, OPTIK, V147, P263, DOI 10.1016/j.ijleo.2017.07.063
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Shibata H, 2001, PHYSICA A, V292, P182, DOI 10.1016/S0378-4371(00)00591-4
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Teng L, 2022, INFORM SCIENCES, V605, P71, DOI 10.1016/j.ins.2022.05.032
   Teng L, 2021, NONLINEAR DYNAM, V105, P1859, DOI 10.1007/s11071-021-06663-1
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang MX, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110028
   Wang MX, 2021, INFORM SCIENCES, V544, P1, DOI 10.1016/j.ins.2020.07.051
   Wang XQ, 2021, INT J BIFURCAT CHAOS, V31, DOI 10.1142/S0218127421500218
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiao D, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/6/060505
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yan XP, 2021, MULTIMED TOOLS APPL, V80, P10949, DOI 10.1007/s11042-020-10218-8
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yin Hong-peng, 2013, Control and Decision, V28, P1441
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhang YQ, 2013, NONLINEAR ANAL-MODEL, V18, P526, DOI 10.15388/NA.18.4.13977
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou S, 2022, CHAOS SOLITON FRACT, V161, DOI 10.1016/j.chaos.2022.112380
   Zhou S, 2022, MULTIMEDIA SYST, V28, P95, DOI 10.1007/s00530-021-00803-8
   Zhou S, 2019, CHAOS, V29, DOI 10.1063/1.5087512
NR 47
TC 2
Z9 2
U1 13
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15286-0
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZR5
UT WOS:000988582100001
DA 2024-07-18
ER

PT J
AU Pati, SK
   Gupta, MK
   Banerjee, A
   Shai, R
   Shivakumara, P
AF Pati, Soumen Kumar
   Gupta, Manan Kumar
   Banerjee, Ayan
   Shai, Rinita
   Shivakumara, Palaiahnakote
TI Drug discovery through Covid-19 genome sequencing with siamese graph
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE COVID-19; Next Gene Sequencing; Siamese Network; Graph Neural Network;
   DNA Sequencing; D3Similarity; Multi-view Learning; Drug Repurposing
AB After several waves of COVID-19 led to a massive loss of human life worldwide due to the changes in its variants and the vast explosion. Several researchers proposed neural network-based drug discovery techniques to fight against the pandemic; utilizing neural networks has limitations (Exponential time complexity, Non-Convergence, Mode Collapse, and Diminished Gradient). To overcome those difficulties, this paper proposed a hybrid architecture that will help to repurpose the most appropriate medicines for the treatment of COVID-19. A brief investigation of the sequences has been made to discover the gene density and noncoding proportion through the next gene sequencing. The paper tracks the exceptional locales in the virus DNA sequence as a Drug Target Region (DTR). Then the variable DNA neighborhood search is applied to this DTR to obtain the DNA interaction network to show how the genes are correlated. A drug database has been obtained based on the ontological property of the genomes with advanced D3Similarity so that all the chemical components of the drug database have been identified. Other methods obtained hydroxychloroquine as an effective drug which was rejected by WHO. However, The experimental results show that Remdesivir and Dexamethasone are the most effective drugs, with 97.41 and 97.93%, respectively.
C1 [Pati, Soumen Kumar; Gupta, Manan Kumar] Maulana Abul Kalam Azad Univ Technol, Dept Bioinformat, Haringhata 741249, W Bengal, India.
   [Banerjee, Ayan] Jalpaiguri Governmemt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri 735102, W Bengal, India.
   [Shai, Rinita] Calcutta Univ, Behala Coll, Dept Math, Kolkata 700060, W Bengal, India.
   [Shivakumara, Palaiahnakote] Univ Malaya, Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
C3 Maulana Abul Kalam Azad University of Technology; University of
   Calcutta; Universiti Malaya
RP Pati, SK (corresponding author), Maulana Abul Kalam Azad Univ Technol, Dept Bioinformat, Haringhata 741249, W Bengal, India.; Banerjee, A (corresponding author), Jalpaiguri Governmemt Engn Coll, Dept Comp Sci & Engn, Jalpaiguri 735102, W Bengal, India.
EM soumenkrpati@gmail.com; mownon89@gmail.com; ab2141@cse.jgec.ac.in;
   rinitashai15@gmail.com; shiva@um.edu.my
CR Abdel-Basset M, 2020, IEEE ACCESS, V8, P170433, DOI 10.1109/ACCESS.2020.3024238
   Abdulrahman SA., 2020, EFFICIENT DEEP BELIE
   Acharya A, 2020, J CHEM INF MODEL, V60, P5832, DOI 10.1021/acs.jcim.0c01010
   Alakus TB, 2021, INTERDISCIP SCI, V13, P44, DOI 10.1007/s12539-020-00405-4
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Amin SA, 2022, MOL DIVERS, V26, P215, DOI 10.1007/s11030-021-10198-3
   Amin SA, 2021, J BIOMOL STRUCT DYN, V39, P4764, DOI 10.1080/07391102.2020.1780946
   Aslan MF, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106912
   Bahri S, 2021, IEEE INT CONF INDUST, P901, DOI 10.1109/ICIT46573.2021.9453534
   Banerjee A., 2022, UNDERSTANDING COVID, DOI [10.1007/978-3-030-74761-9_11, DOI 10.1007/978-3-030-74761-9_11]
   Banerjee A., 2022, SN Computer Science, V3, P208
   Banerjee A, 2022, MULTIMED TOOLS APPL, V81, P37137, DOI 10.1007/s11042-022-13539-y
   Barnes SJ, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114360
   Bhati AP, 2021, ARXIV
   Chenthamarakshan V, 2020, NeurIPS
   Cheung M, 2020, IEEE INT CONF BIG DA, P5646, DOI 10.1109/BigData50022.2020.9378164
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Cuccarese M. F., 2020, BIORXIV
   DARYA SR, 2020, POLYPHARMDB DEEP LEA
   de Moura J, 2022, APPL SOFT COMPUT, V115, DOI 10.1016/j.asoc.2021.108190
   Delijewski Marcin, 2021, Med Drug Discov, V9, P100077, DOI 10.1016/j.medidd.2020.100077
   Du B, 2022, INFORM SCIENCES, V582, P287, DOI 10.1016/j.ins.2021.09.025
   Dutta Shawni, 2020, MEDRXIV
   Galindez G, 2021, NAT COMPUT SCI, V1, P33, DOI 10.1038/s43588-020-00007-6
   Gan R, 2020, MED HYPOTHESES, V144, DOI 10.1016/j.mehy.2020.110024
   Gaudelet T., 2020, arXiv, DOI DOI 10.48550/ARXIV.2012.05716
   Hasan N, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100228
   Hooshmand SA, 2021, MOL DIVERS, V25, P1717, DOI 10.1007/s11030-020-10144-9
   Ionov NS., 2020, BIOMED CHEM RES METH, V3
   Jacobs AS, 2020, INT J HIGH PERFORM C, V2020
   Jamshidi M.B., Emerging Technologies During the Era of COVID-19 Pandemic, V2021, P9, DOI 10.1007/978-3-030-67716-9_2
   Kumari M, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104317
   Lazarus JV, 2021, NAT MED, V27, P225, DOI 10.1038/s41591-020-1124-9
   Li DQ, 2021, APPL INTELL, V51, P2805, DOI 10.1007/s10489-020-02002-w
   Liang CY, 2020, EUR J MED CHEM, V201, DOI 10.1016/j.ejmech.2020.112527
   Majumdar S, 2021, COGN COMPUT, DOI 10.1007/s12559-021-09840-x
   Martinez MA, 2022, DRUG DISCOV TODAY, V27, P1954, DOI 10.1016/j.drudis.2022.02.012
   Meng Y, 2021, APPL INTELL, V51, P3202, DOI 10.1007/s10489-020-01992-x
   Ioannidis VN, 2020, Arxiv, DOI arXiv:2007.10261
   Nag S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-02724-x
   Nguyen DD, 2020, CHEM SCI, V11, P12036, DOI 10.1039/d0sc04641h
   Oktay T, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115755
   Paul R, 2021, PROC IEEE ACM INT C, P244, DOI 10.1109/ICSE-Companion52605.2021.00113
   Peng L, 2024, IEEE T NEUR NET LEAR, V35, P4530, DOI 10.1109/TNNLS.2022.3161030
   Pham TH, 2021, NAT MACH INTELL, V3, DOI 10.1038/s42256-020-00285-9
   Potdar V, 2020, MAXIMUM CONTAINMENT
   Ray S, 2020, ARXIV
   Sainz-Pardo JL, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115710
   Savioli N, 2020, Arxiv, DOI arXiv:2004.02136
   Shahid F, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110212
   Smith TRF, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16505-0
   Song Y., 2021, PMLR, P9801
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Wang B, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105241
   Wang Q., 2020, arXiv
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wu F, 2020, NATURE, V579, P265, DOI 10.1038/s41586-020-2008-3
   Xia DW, 2021, PHYSICA A, V578, DOI 10.1016/j.physa.2021.126056
   Yadav PD, 2020, MAXIMUM CONTAINMENT
   Yang RC, 2020, PHARMACOL RES, V157, DOI 10.1016/j.phrs.2020.104820
   Yu X, 2021, NEUROCOMPUTING, V452, P592, DOI 10.1016/j.neucom.2020.07.144
   Zhang R, 2021, J BIOMED INFORM, V115, DOI 10.1016/j.jbi.2021.103696
NR 64
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15270-8
EA MAY 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600002
PM 37362739
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Hao, ZH
   Liu, GX
   Zhang, HY
   Wang, F
AF Hao, Zhaohui
   Liu, Guixi
   Zhang, Haoyang
   Wang, Fei
TI Robust cascaded-parallel visual tracking using collaborative color and
   correlation filter models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Correlation filter; Cascaded-parallel tracking; Target likelihood
   probability; Reliable expert selection analysis
ID OBJECT TRACKING
AB In recent years, the multi-expert collaborative tracking strategy has been introduced into visual tracking tasks and achieves impressive performance. Different from most existing multi-expert trackers that linearly fuse multiple tracking models, we propose a novel cascaded-parallel tracking algorithm (CPT) via adaptively selecting the suitable expert among multiple tracking models. And the CPT consists of cascaded and parallel tracking components. In the cascaded tracking component, we hierarchically implement two effective correlation filter models to coarse-to-fine locate the target. And in the parallel tracking component, a color tracking model is applied to locate the target to compensate for the demerit of the correlation filter models. With the proposed adaptive expert selection mechanism, the most reliable expert (i.e. tracking model) is selected for tracking in each frame. Extensive experimental results on OTB2013, OTB2015 and TempleColor128 datasets demonstrate that our proposed algorithm performs favorably against some state-of-the-art algorithms.
C1 [Hao, Zhaohui; Liu, Guixi; Zhang, Haoyang; Wang, Fei] Xidian Univ, Sch Mechano Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Hao, Zhaohui] Henan Inst Sci & Technol, Sch Informat Engn, Xinxiang 453003, Henan, Peoples R China.
C3 Xidian University; Henan Institute of Science & Technology
RP Liu, GX (corresponding author), Xidian Univ, Sch Mechano Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM gxliu@xidian.edu.cn
RI Zhang, Yuyao/KEH-7175-2024; Zhang, Yansong/KHW-4097-2024
FU National Natural Science Foundation of China [61972307]
FX This work is supported by the National Natural Science Foundation of
   China [grant number 61972307].
CR Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, BRIT MACH VIS C
   Dekel T, 2015, PROC CVPR IEEE, P2021, DOI 10.1109/CVPR.2015.7298813
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fang S, 2021, MULTIMED TOOLS APPL, V80, P23963, DOI 10.1007/s11042-021-10804-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Qi YK, 2019, IEEE T PATTERN ANAL, V41, P1116, DOI 10.1109/TPAMI.2018.2828817
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan JR, 2021, MULTIMED TOOLS APPL, V80, P2355, DOI 10.1007/s11042-020-09644-5
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhao DW, 2019, INFORM SCIENCES, V470, P78, DOI 10.1016/j.ins.2018.08.053
NR 39
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 8
PY 2023
DI 10.1007/s11042-023-15614-4
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7FF6
UT WOS:000983956900005
DA 2024-07-18
ER

PT J
AU Gull, S
   Parah, SA
AF Gull, Solihah
   Parah, Shabir A.
TI Advances in medical image watermarking: a state of the art review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Electronic Patient Record; Watermarking; Medical Images; Authentication;
   Security
ID DATA HIDING METHOD; REVERSIBLE WATERMARKING; FRAGILE WATERMARKING;
   TAMPER LOCALIZATION; AUTHENTICATION; SCHEME; CRYPTOGRAPHY; INTEGRITY;
   ROBUST
AB Watermarking has been considered to be a potent and persuasive gizmo for its application in healthcare setups that work online, especially in the current COVID-19 scenario. The security and protection of medical image data from various manipulations that take place over the internet is a topic of concern that needs to be addressed. A detailed review of security and privacy protection using watermarking has been presented in this paper. Watermarking of medical images helps in the protection of image content, authentication of Electronic Patient Record (EPR), and integrity verification. At first, we discuss the various prerequisites of medical image watermarking systems, followed by the classification of Medical Image Watermarking Techniques (MIWT) that include state-of-the-art. We have classified MIWT's into four broader classes for providing better understanding of medical image watermarking. The existing schemes have been presented along with their cons so that the reader may be able to grasp the shortcomings of the technique in order to develop novel techniques proving the inevitability of the presented review. Further, various evaluation parameters along with potential challenges pertaining to medical image watermarking systems have been discussed to provide a deep insight into this research area.
C1 [Gull, Solihah; Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
CR Abdullatif M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P235, DOI 10.1109/CSPA.2013.6530048
   Aherrahrou N, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0101-x
   Allaf A. Hassani, 2019, Innovations in Smart Cities Applications Edition 2. Proceedings of the Third International Conference on Smart City Applications. Lecture Notes in Intelligent Transportation and Infrastructure (LNITI), P472, DOI 10.1007/978-3-030-11196-0_40
   Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Aparna P, 2020, J INTELL SYST, V29, P1558, DOI 10.1515/jisys-2018-0370
   Aparna P, 2018, J INTELL SYST, V27, P115, DOI 10.1515/jisys-2017-0266
   Arya P., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P129
   Ashima A., 2020, COMPUT COMMUN, V15, P272
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Bagheri MH, 2017, UROL ONCOL-SEMIN ORI, V35, P473, DOI 10.1016/j.urolonc.2017.04.014
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Chaitanya K., 2016, IJARCCE, V5, P184, DOI 10.17148/IJARCCE.2016.5834
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P12647, DOI 10.1007/s11042-017-5348-8
   Das S, 2013, COMPUT METHODS PROG, V111
   Dixit Anuja, 2017, International Journal of Image, Graphics and Signal Processing, V9, P56, DOI 10.5815/ijigsp.2017.04.07
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Fan TY, 2019, SIGNAL PROCESS-IMAGE, V70, P174, DOI 10.1016/j.image.2018.09.015
   Gadhiya TD, 2017, IEEE REGION 10 SYMP
   Ghazali N.F., 2015, Int. J. Appl. Eng. Res, V10, P4991
   Govind PVS, 2021, COMPUT ELECTR ENG, V89, DOI 10.1016/j.compeleceng.2020.106933
   Gull S, 2021, MULTIMED TOOLS APPL, V80, P29939, DOI 10.1007/s11042-021-11170-x
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Heylen K, 2008, P SOC PHOTO-OPT INS, V7075, DOI 10.1117/12.793308
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Hussan M, 2021, ARAB J SCI ENG, V46, P3465, DOI 10.1007/s13369-020-05135-9
   Jabade V.S., 2011, International Journal of Computer Applications, V31, P28
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Jana M, 2022, J KING SAUD UNIV-COM, V34, P9822, DOI 10.1016/j.jksuci.2021.12.011
   Jero SE, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0132-z
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   Kishore PVV., 2016, LANCET, V11, P2882
   Kumar L., 2020, EUR J MOL CLIN MED, V7, P2250
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Lin CC, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12020415
   Liu XY, 2019, IEEE ACCESS, V7, P76580, DOI 10.1109/ACCESS.2019.2921894
   Loan NA, 2017, J BIOMED INFORM, V73, P125, DOI 10.1016/j.jbi.2017.08.002
   Memon NA, 2020, IEEE ACCESS, V8, P75448, DOI 10.1109/ACCESS.2020.2989175
   Memon NA, 2011, INT J COMPUT MATH, V88, P265, DOI 10.1080/00207161003596690
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Moad MS, 2022, MICROPROCESS MICROSY, V90, DOI 10.1016/j.micpro.2022.104490
   Mothi R, 2019, MEASUREMENT, V136, P67, DOI 10.1016/j.measurement.2018.12.030
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Naseem MT., 2013, J BASIC APPL SCI RES, V3, P488
   Nasir M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183311
   Nunez-Ramirez D, 2022, J KING SAUD UNIV-COM, V34, P5468, DOI 10.1016/j.jksuci.2021.05.007
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Pandey R, 2016, MULTIMED TOOLS APPL, V75, P14381, DOI 10.1007/s11042-016-3536-6
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Priya R., 2014, Journal of Theoretical and Applied Information Technology, V65, P103
   Priya S., 2014, J APPL SCI, V14, P1638, DOI [10.3923/jas.2014.1638.1642, DOI 10.3923/jas.2014.1638.1642]
   Qasim AF, 2019, MULTIMED TOOLS APPL, V78, P16433, DOI 10.1007/s11042-018-7029-7
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Ranjani JJ, 2018, J INTELL SYST, V27, P19, DOI 10.1515/jisys-2017-0019
   Rao KG., 2018, INT J ENG TECHNOL, V7, P2137, DOI [10.14419/ijet.v7i4.128554, DOI 10.14419/IJET.V7I4.12855]
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P1355, DOI 10.1007/s11517-021-02374-2
   Rayachoti E, 2014, Arxiv, DOI arXiv:1412.6143
   Razbonyali C., 2016, INT RES J ENG TECHNO, V3, P2556
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Sahu AK, 2022, J KING SAUD UNIV-COM, V34, P1395, DOI 10.1016/j.jksuci.2019.07.004
   Saju G, 2019, INT J INF SYST COMPU, V8, P152, DOI 10.30534/ijiscs/2019/36822019
   Showkat S, 2021, MULTIMED TOOLS APPL, V80, P2009, DOI 10.1007/s11042-020-09732-6
   Singh AK, 2017, MULTIMED SYST APPL, P13, DOI 10.1007/978-3-319-57699-2_2
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Singh P, 2022, IEEE ACCESS, V10, P8974, DOI 10.1109/ACCESS.2022.3143801
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Sinha Samman, 2018, Procedia Computer Science, V132, P557, DOI 10.1016/j.procs.2018.05.009
   Sinhal R, 2022, MULTIMED TOOLS APPL, V81, P14045, DOI 10.1007/s11042-022-12082-0
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Song LP, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108883
   Soualmi A, 2021, MULTIMED TOOLS APPL, V80, P2279, DOI 10.1007/s11042-020-09614-x
   Sunesh, 2020, PROCEDIA COMPUT SCI, V167, P1505, DOI 10.1016/j.procs.2020.03.361
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Swaraja K, 2018, MULTIMED TOOLS APPL, V77, P28249, DOI 10.1007/s11042-018-6020-7
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Thabit R., 2019, INT J SCI ENG INVEST, V8, P110
   Thabit R, 2021, MULTIMED TOOLS APPL, V80, P13439, DOI 10.1007/s11042-020-10421-7
   Thabit R, 2017, MULTIMED TOOLS APPL, V76, P309, DOI 10.1007/s11042-015-3055-x
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Tripathi SP, 2013, REV MED IMAGE WATERM, V2, P1
   Verma U., 2019, Int J Innov Technol Explor Eng, V9, P351, DOI [DOI 10.35940/IJITEE.A4126.119119, 10.35940/ijitee.A4126.119119]
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Ye CH, 2015, INT J SECUR APPL, V9, P409, DOI 10.14257/ijsia.2015.9.1.39
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Yu XY, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9040056
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
NR 96
TC 3
Z9 3
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 5
PY 2023
DI 10.1007/s11042-023-15396-9
EA MAY 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5VE6
UT WOS:000983013200004
PM 37362709
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yadav, H
   Maini, S
AF Yadav, Hitesh
   Maini, Surita
TI Electroencephalogram based brain-computer interface: Applications,
   challenges, and opportunities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer interface (BCI); BCI advancements; EEG feature
   extraction; BCI future; BCI challenges; BCI tools
ID PERIPHERAL NERVOUS-SYSTEM; FATIGUE DETECTION SYSTEM; EEG-BASED BCI;
   OF-THE-ART; VIRTUAL-REALITY; MOTOR IMAGERY; EMOTION RECOGNITION;
   MINDFULNESS MEDITATION; FMRI NEUROFEEDBACK; FEATURE-EXTRACTION
AB Brain-Computer Interfaces (BCI) is an exciting and emerging research area for researchers and scientists. It is a suitable combination of software and hardware to operate any device mentally. This review emphasizes the significant stages in the BCI domain, current problems, and state-of-the-art findings. This article also covers how current results can contribute to new knowledge about BCI, an overview of BCI from its early developments to recent advancements, BCI applications, challenges, and future directions. The authors pointed to unresolved issues and expressed how BCI is valuable for analyzing the human brain. Humans' dependence on machines has led humankind into a new future where BCI can play an essential role in improving this modern world.
C1 [Yadav, Hitesh; Maini, Surita] St Longowal Inst Engn & Technol, Dept Elect & Instrumentat Engn, Longowal, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET)
RP Yadav, H (corresponding author), St Longowal Inst Engn & Technol, Dept Elect & Instrumentat Engn, Longowal, Punjab, India.
EM hitesh.yadav125@gmail.com
CR Abdulkader SN, 2015, EGYPT INFORM J, V16, P213, DOI 10.1016/j.eij.2015.06.002
   Abiri R, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf12e
   Afiatdoust F, 2015, AIN SHAMS ENG J, V6, P639, DOI 10.1016/j.asej.2014.10.019
   Ahn JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091991
   Ahn M, 2015, J NEUROSCI METH, V243, P103, DOI 10.1016/j.jneumeth.2015.01.033
   Akbari H., 2020, Signal Process, Renew. Energy, V4, P23
   Akcakaya Murat, 2014, IEEE Rev Biomed Eng, V7, P31, DOI 10.1109/RBME.2013.2295097
   Akin M, 2002, J Med Syst, V26, P241, DOI 10.1023/A:1015075101937
   Al-Nafjan A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7121239
   Alariki AA., 2018, J COMPUT SCI-NETH, V14, P173, DOI [10.3844/jcssp.2018.173.181, DOI 10.3844/JCSSP.2018.173.181]
   Alcaide-Aguirre RE, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa7fc4
   Amin HU, 2015, AUSTRALAS PHYS ENG S, V38, P139, DOI 10.1007/s13246-015-0333-x
   Amiri S, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/187024
   Andujar M, 2015, BRAIN-COMPUT INTERFA, V2, P60, DOI 10.1080/2326263X.2015.1104613
   [Anonymous], PHYSIOL MEAS, V39
   [Anonymous], USABILITY ENG SCENAR
   Urigüen JA, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/031001
   Apicella A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84447-8
   Appriou A, 2020, IEEE SYST MAN CYBERN, V6, P29, DOI 10.1109/MSMC.2020.2968638
   Aricò P, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aad57e
   Arpaia P, 2020, IEEE T INSTRUM MEAS, V69, P6362, DOI 10.1109/TIM.2020.2970846
   Arsalan A, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104377
   Artoni F, 2018, NEUROIMAGE, V175, P176, DOI 10.1016/j.neuroimage.2018.03.016
   Ashok Sharmila, 2017, Journal of Medical Engineering & Technology, V41, P46, DOI 10.1080/03091902.2016.1210685
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Attia A, 2021, EVOL SYST-GER, V12, P827, DOI 10.1007/s12530-019-09319-z
   Bagherzadeh Y, 2020, NEURON, V105, P577, DOI 10.1016/j.neuron.2019.11.001
   Bai LM, 2019, FRONT CHEM, V7, DOI 10.3389/fchem.2019.00313
   Baik SY, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01290
   Bamdad M, 2015, DISABIL REHABIL-ASSI, V10, P355, DOI 10.3109/17483107.2014.961569
   Banville H, 2016, BRAIN-COMPUT INTERFA, V3, P9, DOI 10.1080/2326263X.2015.1134958
   Baykara E, 2016, CLIN NEUROPHYSIOL, V127, P379, DOI 10.1016/j.clinph.2015.04.054
   Belwafi K, 2017, J SIGNAL PROCESS SYS, V89, P263, DOI 10.1007/s11265-016-1192-8
   Bennett JD, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abd51f
   Bi LZ, 2013, IEEE T HUM-MACH SYST, V43, P161, DOI 10.1109/TSMCC.2012.2219046
   Biasiucci A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04673-z
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Bin Nasir Tafhim, 2021, Proceedings of 2021 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD), P445, DOI 10.1109/ICICT4SD50815.2021.9396982
   Birbaumer N, 2007, J PHYSIOL-LONDON, V579, P621, DOI 10.1113/jphysiol.2006.125633
   Birbaumer N, 2006, PSYCHOPHYSIOLOGY, V43, P517, DOI 10.1111/j.1469-8986.2006.00456.x
   Birbaumer N, 2008, CURR OPIN NEUROL, V21, P634, DOI 10.1097/WCO.0b013e328315ee2d
   Bismuth J, 2020, NEUROPHYSIOL CLIN, V50, P5, DOI 10.1016/j.neucli.2019.12.002
   Borghini G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00633-7
   Bostrom N, 2009, SCI ENG ETHICS, V15, P311, DOI 10.1007/s11948-009-9142-5
   Brown RE, 2003, NAT REV NEUROSCI, V4, P1013, DOI 10.1038/nrn1257
   Bubrick EJ, 2014, SEIZURE-EUR J EPILEP, V23, P699, DOI 10.1016/j.seizure.2014.05.007
   Burwell S, 2017, BMC MED ETHICS, V18, DOI 10.1186/s12910-017-0220-y
   Calabrò RS, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0268-4
   Carabalona R, 2012, ERGONOMICS, V55, P552, DOI 10.1080/00140139.2012.661083
   Casson AJ, 2019, BIOMED ENG LETT, V9, P53, DOI 10.1007/s13534-018-00093-6
   Catrambone V, 2019, IEEE T NEUR SYS REH, V27, P411, DOI 10.1109/TNSRE.2019.2898469
   Cattan G, 2018, COMPUTERS, V7, DOI 10.3390/computers7020034
   Cauvery N.K., 2012, INT J ADV ENG TECHNO, V3, P739, DOI DOI 10.1109/ic3i.2014.7019589
   Chai XK, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101687
   Chang EF, 2015, NEURON, V86, P68, DOI 10.1016/j.neuron.2015.03.037
   Chang WW, 2021, NEUROPSYCHOLOGIA, V151, DOI 10.1016/j.neuropsychologia.2020.107695
   Chaudhary U, 2016, NAT REV NEUROL, V12, P513, DOI 10.1038/nrneurol.2016.113
   Chen CC, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178822
   Chen XG, 2015, P NATL ACAD SCI USA, V112, pE6058, DOI 10.1073/pnas.1508080112
   Cheron G, 2012, NEURAL PLAST, V2012, DOI 10.1155/2012/375148
   Chikara RK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173791
   Cho H, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/6/066009
   Choi I, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176674
   Chung T, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/5/056018
   Cincotti F, 2008, BRAIN RES BULL, V75, P796, DOI 10.1016/j.brainresbull.2008.01.007
   Clark E., 2019, INT C HUM COMP INT, P243
   Clausen J, 2011, CURR OPIN PSYCHIATR, V24, P495, DOI 10.1097/YCO.0b013e32834bb8ca
   Coco-Martin MB, 2020, J OPHTHALMOL, V2020, DOI 10.1155/2020/7067846
   Cohen MX, 2019, NEUROIMAGE, V199, P81, DOI 10.1016/j.neuroimage.2019.05.048
   Coin A, 2020, PHILOSOPHIES, V5, DOI 10.3390/philosophies5040031
   Combaz A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121481
   Corsi MC, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065718500144
   de Munck JC, 2009, NEUROIMAGE, V47, P69, DOI 10.1016/j.neuroimage.2009.04.029
   Debie E, 2019, IEEE T CYBERNETICS, V51, P1542
   DeFranco J, 2020, HEALTH SECUR, V18, P267, DOI 10.1089/hs.2020.0009
   Dehais F, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00268
   Del Pozo-Banos M, 2014, EXPERT SYST APPL, V41, P6537, DOI 10.1016/j.eswa.2014.05.013
   Delaloye S, 2022, DIALOGUES CLIN NEURO
   Delbeke J., 2020, NEURAL INTERFACE ENG, P123, DOI DOI 10.1007/978-3-030-41854-0_6
   Delegates GNS, 2018, NEURON, V100, P19, DOI 10.1016/j.neuron.2018.09.021
   Deng XY, 2020, IEEE T NEUR SYS REH, V28, P328, DOI 10.1109/TNSRE.2019.2958076
   Denning T, 2009, NEUROSURG FOCUS, V27, DOI 10.3171/2009.4.FOCUS0985
   Dhiman R, 2014, APPL SOFT COMPUT, V19, P8, DOI 10.1016/j.asoc.2014.01.029
   Di Flumeri G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061365
   Djamal E. C., 2019, Telkomnika (Telecommunication Computing Electronics and Control), V17, P1149, DOI [10.12928/telkomnika.v17i3.11776, DOI 10.12928/TELKOMNIKA.V17I3.11776]
   Dobkin BH, 2007, J PHYSIOL-LONDON, V579, P637, DOI 10.1113/jphysiol.2006.123067
   Donoghue JP, 2002, NAT NEUROSCI, V5, P1085, DOI 10.1038/nn947
   Dressler O, 2004, BRIT J ANAESTH, V93, P806, DOI 10.1093/bja/aeh270
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Elsayed N., 2017, International Journal of Computer Applications, V169, P12, DOI DOI 10.5120/IJCA2017914621
   Fan ML, 2019, IEEE T BIO-MED ENG, V66, P601, DOI 10.1109/TBME.2018.2850959
   FARWELL LA, 1988, ELECTROEN CLIN NEURO, V70, P510, DOI 10.1016/0013-4694(88)90149-6
   Fazel-Rezai Reza, 2012, Front Neuroeng, V5, P14, DOI 10.3389/fneng.2012.00014
   Fazli S, 2012, NEUROIMAGE, V59, P519, DOI 10.1016/j.neuroimage.2011.07.084
   Fekete Z, 2017, SENSOR ACTUAT B-CHEM, V243, P1214, DOI 10.1016/j.snb.2016.12.096
   Feng ZQ, 2020, MULTIMED TOOLS APPL, V79, P10327, DOI 10.1007/s11042-019-7607-3
   Fernández-Rodríguez A, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/6/061001
   Nicolas-Alonso LF, 2012, SENSORS-BASEL, V12, P1211, DOI 10.3390/s120201211
   Finnigan S, 2013, CLIN NEUROPHYSIOL, V124, P10, DOI 10.1016/j.clinph.2012.07.003
   Foong R, 2020, IEEE T BIO-MED ENG, V67, P786, DOI 10.1109/TBME.2019.2921198
   Friedrich J, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005423
   Frömer R, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21315-z
   Fu YL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133651
   Fujiwara K, 2019, IEEE T BIO-MED ENG, V66, P1769, DOI 10.1109/TBME.2018.2879346
   Galán F, 2008, CLIN NEUROPHYSIOL, V119, P2159, DOI 10.1016/j.clinph.2008.06.001
   Gao X, 2014, INT J PSYCHOPHYSIOL, V94, P399, DOI 10.1016/j.ijpsycho.2014.10.010
   Gao ZK, 2019, IEEE T NEUR NET LEAR, V30, P2755, DOI 10.1109/TNNLS.2018.2886414
   Correa AG, 2014, MED ENG PHYS, V36, P244, DOI 10.1016/j.medengphy.2013.07.011
   Gassert R, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0383-x
   Ghayab Hadi Ratham Al, 2016, Brain Inform, V3, P85, DOI 10.1007/s40708-016-0039-1
   GIAQUINTO S, 1994, STROKE, V25, P2204, DOI 10.1161/01.STR.25.11.2204
   Gomez-Pilar J, 2014, IEEE ENG MED BIO, P3630, DOI 10.1109/EMBC.2014.6944409
   Goodday SM, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0151-8
   Grau C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0105225
   Grienberger C, 2012, NEURON, V73, P862, DOI 10.1016/j.neuron.2012.02.011
   Grieshaber D, 2008, SENSORS-BASEL, V8, P1400, DOI 10.3390/s8031400
   Grillner S, 2016, NAT NEUROSCI, V19, P1118, DOI 10.1038/nn.4371
   Grosse-Wentrup M, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025004
   Grozea C, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/2/025008
   Gu XT, 2021, IEEE ACM T COMPUT BI, V18, P1645, DOI 10.1109/TCBB.2021.3052811
   Gulati T, 2014, NAT NEUROSCI, V17, P1107, DOI 10.1038/nn.3759
   Gupta A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33618-1
   Guyon A, 2020, J INTERDISCIP METHOD
   Haas L F, 2003, J Neurol Neurosurg Psychiatry, V74, P9, DOI 10.1136/jnnp.74.1.9
   Haselager P, 2009, NEURAL NETWORKS, V22, P1352, DOI 10.1016/j.neunet.2009.06.046
   Hassanien AE., 2015, INTEL SYST REF LIBR, P74, DOI DOI 10.1007/978-3-319-10978-7
   He F, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101387
   Hinrichs H, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62154-0
   Hinterberger T, 2004, IEEE T BIO-MED ENG, V51, P1011, DOI 10.1109/TBME.2004.827067
   Hobson EV, 2017, AMYOTROPH LAT SCL FR, V18, P378, DOI 10.1080/21678421.2017.1288253
   Hoffmann U, 2008, J NEUROSCI METH, V167, P115, DOI 10.1016/j.jneumeth.2007.03.005
   Holz EM, 2013, ARTIF INTELL MED, V59, P111, DOI 10.1016/j.artmed.2013.08.001
   Hong KS, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00246
   Hong X, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08928-5
   Hramov AE, 2021, PHYS REP, V918, P1, DOI 10.1016/j.physrep.2021.03.002
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1109/TAFFC.2019.2901456, 10.1145/3290605.3300851]
   Huang HY, 2014, CELL TRANSPLANT, V23, pS5, DOI 10.3727/096368914X684952
   Huang KC, 2016, INT J NEURAL SYST, V26, DOI 10.1142/S0129065716500180
   Hwang HJ, 2013, INT J HUM-COMPUT INT, V29, P814, DOI 10.1080/10447318.2013.780869
   Hwang HJ, 2009, J NEUROSCI METH, V179, P150, DOI 10.1016/j.jneumeth.2009.01.015
   Ienca M, 2016, ETHICS INF TECHNOL, V18, P117, DOI 10.1007/s10676-016-9398-9
   Ignacio Serrano J., 2017, BRAIN-COMPUT INTERFA, P99, DOI [10.1007/978-3-319-57132-4_8, DOI 10.1007/978-3-319-57132-4_8]
   Im HJ, 2018, NUCL MED MOLEC IMAG, V52, P5, DOI 10.1007/s13139-017-0493-6
   Islam MK, 2021, J NEUROSCI METH, V360, DOI 10.1016/j.jneumeth.2021.109249
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Jafarifarmand A, 2019, IEEE T NEUR SYS REH, V27, P1200, DOI 10.1109/TNSRE.2019.2915801
   Jas M, 2017, NEUROIMAGE, V159, P417, DOI 10.1016/j.neuroimage.2017.06.030
   Jebari K, 2013, NEUROETHICS-NETH, V6, P617, DOI 10.1007/s12152-012-9176-2
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Jiang LX, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41895-7
   Jiang X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19050987
   Johnson NN, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aa8ce3
   Jotterand F, 2011, INT REV PSYCHIATR, V23, P476, DOI [10.3109/09540261.2011.616189, 10.3109/09540261.2011.616189.2011.616189]
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Käthner I, 2014, BIOL PSYCHOL, V102, P118, DOI 10.1016/j.biopsycho.2014.07.014
   Käthner I, 2013, CLIN NEUROPHYSIOL, V124, P327, DOI 10.1016/j.clinph.2012.08.006
   Kalaganis FP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31425-2
   Kalantari S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89297-y
   Kasahara K, 2015, NEUROIMAGE, V110, P95, DOI 10.1016/j.neuroimage.2015.01.055
   Kaufmann T, 2012, INT J PSYCHOPHYSIOL, V83, P336, DOI 10.1016/j.ijpsycho.2011.11.018
   Keefer EW, 2008, NAT NANOTECHNOL, V3, P434, DOI 10.1038/nnano.2008.174
   Kennedy PR, 1998, NEUROREPORT, V9, P1707, DOI 10.1097/00001756-199806010-00007
   Kerous B, 2018, VIRTUAL REAL-LONDON, V22, P119, DOI 10.1007/s10055-017-0328-x
   Khodagholy D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2573
   Khosla A, 2020, BIOCYBERN BIOMED ENG, V40, P649, DOI 10.1016/j.bbe.2020.02.002
   Kim K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79423-7
   Kim Min H, 2016, Sensors (Basel), V16, DOI 10.3390/s16111894
   Klados MA, 2011, BIOMED SIGNAL PROCES, V6, P291, DOI 10.1016/j.bspc.2011.02.001
   Ko LW, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80171-x
   Kozai TDY, 2016, J NEUROSCI METH, V258, P46, DOI 10.1016/j.jneumeth.2015.10.007
   Kropotov J.D., 2010, Quantitative EEG, event-related potentials and neurotherapy
   Kruskal PB, 2015, NEURON, V86, P21, DOI 10.1016/j.neuron.2015.01.004
   Lai YF, 2018, GRANULAR COMPUT, V3, P169, DOI 10.1007/s41066-017-0064-3
   Laszlo S, 2014, J NEUROSCI METH, V235, P298, DOI 10.1016/j.jneumeth.2014.05.012
   Leamy DJ, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-9
   Lécuyer A, 2008, COMPUTER, V41, P66, DOI 10.1109/MC.2008.410
   Li F, 2015, SCI REP-UK, V5, DOI 10.1038/srep11821
   Li G, 2015, IEEE SENS J, V15, P7169, DOI 10.1109/JSEN.2015.2473679
   Li GL, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/abbd50
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Lim S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071669
   Liyanage SR, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/3/036007
   Lopes AC, 2013, ROBOT AUTON SYST, V61, P245, DOI 10.1016/j.robot.2012.11.002
   Lopez-Gordo MA, 2014, SENSORS-BASEL, V14, P12847, DOI 10.3390/s140712847
   Loriette C, 2021, REV NEUROL-FRANCE, V177, P1133, DOI 10.1016/j.neurol.2021.08.004
   Lotte F, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aab2f2
   Lotte F., 2016, Brain-Computer Interfaces, V1, P127
   Lu W., 2021, Nanosensors for Smart Manufacturing, P115, DOI [10.1016/B978-0-12-823358-0.00006-X, DOI 10.1016/B978-0-12-823358-0.00006-X]
   Luck SJ, 2000, TRENDS COGN SCI, V4, P432, DOI 10.1016/S1364-6613(00)01545-X
   Lystad Reidar P, 2009, J Can Chiropr Assoc, V53, P59
   Ma YL, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4721863
   Maksimenko VA, 2018, COMPLEXITY, DOI 10.1155/2018/9385947
   Mannan MMN, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030891
   Marini F, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab21f2
   Marshall D, 2013, IEEE T COMP INTEL AI, V5, P82, DOI 10.1109/TCIAIG.2013.2263555
   Martis RJ, 2015, J MECH MED BIOL, V15, DOI 10.1142/S0219519415500402
   Mashat MEM, 2019, IEEE T NEUR SYS REH, V27, P2178, DOI 10.1109/TNSRE.2019.2936987
   Mathewson KE, 2017, PSYCHOPHYSIOLOGY, V54, P74, DOI 10.1111/psyp.12536
   McCane LM, 2015, CLIN NEUROPHYSIOL, V126, P2124, DOI 10.1016/j.clinph.2015.01.013
   McCullagh P, 2014, NEUROETHICS-NETH, V7, P109, DOI 10.1007/s12152-013-9188-6
   Mellinger J, 2007, NEUROIMAGE, V36, P581, DOI 10.1016/j.neuroimage.2007.03.019
   Meng JJ, 2014, IEEE J BIOMED HEALTH, V18, P1461, DOI 10.1109/JBHI.2013.2285232
   Meziane N, 2013, PHYSIOL MEAS, V34, pR47, DOI 10.1088/0967-3334/34/9/R47
   Miller A, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0202-7
   Min BK, 2010, TRENDS BIOTECHNOL, V28, P552, DOI 10.1016/j.tibtech.2010.08.002
   Min JL, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188756
   Ming YR, 2021, IEEE TETCI, V5, P583, DOI 10.1109/TETCI.2020.2997031
   Minguillon J, 2017, BIOMED SIGNAL PROCES, V31, P407, DOI 10.1016/j.bspc.2016.09.005
   Mondéjar T, 2016, J BIOMED INFORM, V63, P131, DOI 10.1016/j.jbi.2016.08.006
   Mota AR, 2013, SENSOR ACTUAT A-PHYS, V199, P310, DOI 10.1016/j.sna.2013.06.013
   Müller-Putz GR, 2006, IEEE T NEUR SYS REH, V14, P30, DOI 10.1109/TNSRE.2005.863842
   Nakazawa E., 2016, AJOB Neurosci., V7, P110, DOI DOI 10.1080/21507740.2016.1172134
   Naranjo-Hernández D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020365
   Nicolelis MAL, 2009, NAT REV NEUROSCI, V10, P530, DOI 10.1038/nrn2653
   Nolan H, 2010, J NEUROSCI METH, V192, P152, DOI 10.1016/j.jneumeth.2010.07.015
   Norton JJS, 2015, P NATL ACAD SCI USA, V112, P3920, DOI 10.1073/pnas.1424875112
   O'Doherty JE, 2011, NATURE, V479, P228, DOI 10.1038/nature10489
   Ofner P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43594-9
   Öncel Ç, 2010, COPD, V7, P11, DOI 10.3109/15412550903499480
   Ordikhani-Seyedlar M, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00352
   Orsborn AL, 2014, NEURON, V82, P1380, DOI 10.1016/j.neuron.2014.04.048
   Ortiz-Rosario A, 2013, REV NEUROSCIENCE, V24, P537, DOI 10.1515/revneuro-2013-0032
   Oxley TJ, 2016, NAT BIOTECHNOL, V34, P320, DOI 10.1038/nbt.3428
   Pais-Vieira M, 2013, SCI REP-UK, V3, DOI 10.1038/srep01319
   Papanastasiou G, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04250
   Park W, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0120-2
   Pathak RS, 2016, INTEGR TRANSF SPEC F, V27, P468, DOI 10.1080/10652469.2016.1155569
   Pei SC, 2000, IEEE T SIGNAL PROCES, V48, P1338, DOI 10.1109/78.839981
   Peining P, 2017, P IRC C SCI ENG TECH
   Perdikis S, 2017, IEEE SPECTRUM, V54, P44, DOI 10.1109/MSPEC.2017.8012239
   Pfurtscheller G, 2000, NEUROSCI LETT, V292, P211, DOI 10.1016/S0304-3940(00)01471-3
   Pfurtscheller G, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnpro.2010.00003
   Picard RW., 2000, AFFECTIVE COMPUTING, DOI [10.7551/mitpress/1140.001.0001, DOI 10.7551/MITPRESS/1140.001.0001]
   Pires G, 2011, J NEUROSCI METH, V195, P270, DOI 10.1016/j.jneumeth.2010.11.016
   Putze F., 2019, BRAIN ART, P433, DOI DOI 10.1007/978-3-030-14323-7_16
   Putze F, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00144
   Qu HQ, 2019, ALGORITHMS, V12, DOI 10.3390/a12070145
   Rabbani Q, 2019, NEUROTHERAPEUTICS, V16, P144, DOI 10.1007/s13311-018-00692-2
   Rahimi M, 2019, BIOMED SIGNAL PROCES, V51, P393, DOI 10.1016/j.bspc.2019.02.002
   Rainey Stephen, 2020, AJOB Neurosci, V11, P46, DOI 10.1080/21507740.2019.1704918
   Ramadan RA, 2017, NEUROCOMPUTING, V223, P26, DOI 10.1016/j.neucom.2016.10.024
   Ramos-Murguialday A, 2013, ANN NEUROL, V74, P100, DOI 10.1002/ana.23879
   Rao RPN, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111332
   Rashid M, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00025
   Reiser JE, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49503-4
   Remsik A, 2016, EXPERT REV MED DEVIC, V13, P445, DOI 10.1080/17434440.2016.1174572
   Rezeika A, 2018, BRAIN SCI, V8, DOI 10.3390/brainsci8040057
   Riener R, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0157-2
   Robineau F, 2014, NEUROIMAGE, V100, P1, DOI 10.1016/j.neuroimage.2014.05.072
   Robinson N, 2021, CURR OPIN BIOMED ENG, V20, DOI 10.1016/j.cobme.2021.100354
   Rodriguez JAP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59885-5
   Rohani DA, 2015, EPJ NONLINEAR BIOMED, V3, DOI 10.1140/epjnbp/s40366-015-0027-z
   Romero-Laiseca MA, 2020, IEEE T NEUR SYS REH, V28, P988, DOI 10.1109/TNSRE.2020.2974056
   Saha S, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.578875
   Sai CY, 2018, IEEE J BIOMED HEALTH, V22, P664, DOI 10.1109/JBHI.2017.2723420
   Sakkalis V, 2011, COMPUT BIOL MED, V41, P1110, DOI 10.1016/j.compbiomed.2011.06.020
   Santhanam G, 2006, NATURE, V442, P195, DOI 10.1038/nature04968
   Sazgar M., 2019, ABSOLUTE EPILEPSY EE, DOI [10.1007/978-3-030-03511-2, DOI 10.1007/978-3-030-03511-2]
   Scherer R, 2013, SOFT COMPUT, V17, P317, DOI 10.1007/s00500-012-0895-4
   Sekhavat YA, 2020, MULTIMED TOOLS APPL, V79, P3449, DOI 10.1007/s11042-019-07963-w
   Seo D, 2016, NEURON, V91, P529, DOI 10.1016/j.neuron.2016.06.034
   Sereshkeh AR, 2019, BRAIN-COMPUT INTERFA, V6, P128, DOI 10.1080/2326263X.2019.1698928
   Serrhini M, 2017, ADV INTELL SYST, V520, P135, DOI 10.1007/978-3-319-46568-5_14
   Shahriari Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab22ea
   Shibata K, 2011, SCIENCE, V334, P1413, DOI 10.1126/science.1212003
   Shih JJ, 2012, MAYO CLIN PROC, V87, P268, DOI 10.1016/j.mayocp.2011.12.008
   Shon D, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15112461
   Sitaram Ranganatha, 2007, Comput Intell Neurosci, P25487, DOI 10.1155/2007/25487
   Skola F, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00329
   Slobounov SM, 2015, INT J PSYCHOPHYSIOL, V95, P254, DOI 10.1016/j.ijpsycho.2014.11.003
   Song XM, 2015, COMPUT BIOL MED, V61, P150, DOI 10.1016/j.compbiomed.2015.03.023
   Spataro R, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00068
   Steinert S, 2020, SCI ENG ETHICS, V26, P351, DOI 10.1007/s11948-019-00087-2
   Svetlov AS, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01351
   Szocik K, 2020, FUTURES, V115, DOI 10.1016/j.futures.2019.102489
   Takeuchi N, 2013, STROKE RES TREAT, V2013, DOI 10.1155/2013/128641
   Tan LF, 2014, CONSCIOUS COGN, V23, P12, DOI 10.1016/j.concog.2013.10.010
   Tariq M, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00312
   Tarrant J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01280
   Thakor NV., 2013, NEURAL ENG, P259, DOI [10.1007/978-1-4614-5227-0_5, DOI 10.1007/978-1-4614-5227-0_5]
   Nguyen T, 2017, SCI REP-UK, V7, DOI 10.1038/srep43933
   Tidoni E, 2017, IEEE T NEUR SYS REH, V25, P1622, DOI 10.1109/TNSRE.2016.2626391
   Tidoni E, 2017, IEEE T NEUR SYS REH, V25, P772, DOI 10.1109/TNSRE.2016.2597863
   Tonin L, 2020, IEEE T ROBOT, V36, P78, DOI 10.1109/TRO.2019.2943072
   Torkamani-Azar M, 2020, IEEE J BIOMED HEALTH, V24, P2550, DOI 10.1109/JBHI.2020.2980056
   Luu TP, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/3/036006
   Valderrama AT, 2010, J NEUROSCI METH, V187, P270, DOI 10.1016/j.jneumeth.2010.01.019
   van Dokkum LEH, 2015, ANN PHYS REHABIL MED, V58, P3, DOI 10.1016/j.rehab.2014.09.016
   van Erp JBF, 2012, COMPUTER, V45, P26, DOI 10.1109/MC.2012.107
   Van Essen DC, 2012, NEUROIMAGE, V62, P2222, DOI 10.1016/j.neuroimage.2012.02.018
   van Vliet M., 2012, 2012 ISSNIP BIOSIGNA, P1, DOI DOI 10.1109/BRC.2012.6222186
   Vaseghi S. V., 2008, Advanced Digital Signal Processing and Noise Reduction
   Vecsei Z, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36353-9
   VIDAL JJ, 1973, ANNU REV BIOPHYS BIO, V2, P157, DOI 10.1146/annurev.bb.02.060173.001105
   Vidaurre C, 2011, IEEE T BIO-MED ENG, V58, P587, DOI 10.1109/TBME.2010.2093133
   VOURVOPOULOS A, 2019, FRONT HUMAN NEUROSCI, V210
   Vyas Saurabh, 2018, Neuron, V97, P1177, DOI 10.1016/j.neuron.2018.01.040
   Waelde LC, 2017, CHILDREN-BASEL, V4, DOI 10.3390/children4050032
   Waldert S, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00295
   Wang H, 2016, EXPERT SYST APPL, V53, P117, DOI 10.1016/j.eswa.2016.01.024
   Wang HT, 2018, COGN NEURODYNAMICS, V12, P365, DOI 10.1007/s11571-018-9481-5
   Wang J, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-020-00711-1
   Wang Wei, 2010, Phys Med Rehabil Clin N Am, V21, P157, DOI 10.1016/j.pmr.2009.07.003
   Wang YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107626
   Wei CS, 2018, NEUROIMAGE, V174, P407, DOI 10.1016/j.neuroimage.2018.03.032
   Werner T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00474
   Widge AS, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09557-4
   Widodo A, 2007, MECH SYST SIGNAL PR, V21, P2560, DOI 10.1016/j.ymssp.2006.12.007
   Winkler I, 2011, BEHAV BRAIN FUNCT, V7, DOI 10.1186/1744-9081-7-30
   Wolpaw J., 2012, BRAIN COMPUTER INTER, DOI [10.1093/acprof:oso/9780195388855.003.0001, DOI 10.1093/ACPROF:OSO/9780195388855.001.0001]
   Wolpaw JR, 2000, IEEE T REHABIL ENG, V8, P164, DOI 10.1109/TRE.2000.847807
   Xu BG, 2011, INT J ADV ROBOT SYST, V8, P88, DOI 10.5772/45703
   Xu B, 2018, IEEE ACCESS, V6, P48088, DOI 10.1109/ACCESS.2018.2867719
   Yadav D, 2020, J NEUROSCI METH, V346, DOI 10.1016/j.jneumeth.2020.108918
   Yang YJ, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P121, DOI 10.1109/ICCWAMTIP.2015.7493959
   Ye Jieping., 2005, Advances in Neural Information Processing Systems, P1
   Yin EW, 2015, IEEE T NEUR SYS REH, V23, P693, DOI 10.1109/TNSRE.2015.2403270
   Yin M, 2014, NEURON, V84, P1170, DOI 10.1016/j.neuron.2014.11.010
   Yu X, 2014, OPTIK, V125, P1498, DOI 10.1016/j.ijleo.2013.09.013
   Yuan H, 2014, IEEE T BIO-MED ENG, V61, P1425, DOI 10.1109/TBME.2014.2312397
   Yuan P, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/2/026014
   Yuan W, 2019, IEEE T COGN DEV SYST, V11, P527, DOI 10.1109/TCDS.2018.2869903
   Zabielska-Mendyk E, 2018, NEUROSCIENCE, V384, P101, DOI 10.1016/j.neuroscience.2018.05.028
   Zeng H, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9110326
   Zhang HY, 2020, IEEE T NEUR SYS REH, V28, P1771, DOI 10.1109/TNSRE.2020.3005771
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216321
   Zhang X, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/abc902
   Zhang XL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030486
   Zhang Y, 2017, NEURAL COMPUT APPL, V28, P3153, DOI 10.1007/s00521-016-2230-y
   Zhang Y, 2017, NEURAL PROCESS LETT, V45, P365, DOI 10.1007/s11063-016-9530-1
   Zhao XG, 2016, IEEE T SYST MAN CY-S, V46, P947, DOI 10.1109/TSMC.2016.2523762
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zhu MH, 2020, J EXPO SCI ENV EPID, V30, P285, DOI 10.1038/s41370-019-0154-1
   Zhuang MM, 2020, J NEURORESTORATOLOGY, V8, P12, DOI 10.26599/JNR.2020.9040001
   Zoega Ramsoy Thomas, 2020, Augmented Cognition. Theoretical and Technological Approaches. 14th International Conference, AC 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12196), P209, DOI 10.1007/978-3-030-50353-6_15
NR 337
TC 3
Z9 3
U1 30
U2 100
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47003
EP 47047
DI 10.1007/s11042-023-15653-x
EA MAY 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000981387900008
PM 37362726
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Hosseinzadeh, M
   Abbasi, S
   Rahmani, AM
AF Hosseinzadeh, Mehdi
   Abbasi, Shirin
   Rahmani, Amir Masoud
TI Resource Management approaches to Internet of Vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Resource management; Internet of Vehicles; Task offloading; Task
   scheduling; Load balancing
ID VEHICULAR NETWORKS; EDGE; ALLOCATION; COMMUNICATION; ALGORITHM
AB The Internet of Vehicles (IoV) has become a significant issue in designing smart cities. Many applications and services are provided in IoV for various purposes. They need the resources for the computation and data collection. One of the open issues in IoV is resource management because of resource limitation, resource heterogeneity, and dynamic networks. To our knowledge, no systematic and thorough research in resource management methodologies was conducted in IoV, despite the critical nature of resource management challenges. This paper analyzes the recently published studies on resource management in IoV. Our analysis shows that resource allocation has the most utilization rate of resource management approaches at 30%. The most critical parameter in resource allocation is cost, which includes energy, time, price, and processing capacity. The analytical reports show those cost parameters have the most evaluation in the approaches by 19%. Furthermore, we propose a taxonomy for resource management in IoV and extract challenges and open issues in this field. It can be a start point to suggest new methods for resource management in IoV.
C1 [Hosseinzadeh, Mehdi] Gachon Univ, Pattern Recognit & Machine Learning Lab, 1342 Seongnamdaero, Seongnam 13120, South Korea.
   [Abbasi, Shirin] Islamic Azad Univ, Comp Engn Dept, Sci & Res Branch, Tehran, Iran.
   [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
C3 Gachon University; Islamic Azad University; National Yunlin University
   Science & Technology
RP Rahmani, AM (corresponding author), Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
EM rahmania@yuntech.edu.tw
RI Rahmani, Amir Masoud/K-2702-2013; Abbasi, Shirin/AAO-8889-2021
OI Rahmani, Amir Masoud/0000-0001-8641-6119; Abbasi,
   Shirin/0000-0002-8106-1942
CR Aazam M, 2018, IEEE T IND INFORM, V14, P4674, DOI 10.1109/TII.2018.2855198
   Abbas A, 2021, SOFT COMPUT, V25, P11899, DOI 10.1007/s00500-020-05542-y
   Abbasi S, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4793
   Al-Surmi I, 2021, WIRELESS PERS COMMUN, V120, P1341, DOI 10.1007/s11277-021-08517-w
   Alioua A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3787
   Ameen HA, 2019, IEEE ACCESS, V7, P158349, DOI 10.1109/ACCESS.2019.2949130
   Chen X, 2019, IEEE ACCESS, V7, P117088, DOI 10.1109/ACCESS.2019.2934890
   Cheng J, 2021, EURASIP J WIREL COMM, V2021, DOI 10.1186/s13638-021-01984-6
   Fourati H, 2021, INT J MACH LEARN CYB, V12, P385, DOI 10.1007/s13042-020-01178-4
   Ghobaei-Arani M, 2020, J GRID COMPUT, V18, P1, DOI 10.1007/s10723-019-09491-1
   Gu XH, 2021, COMPUT COMMUN, V166, P244, DOI 10.1016/j.comcom.2020.12.010
   Gu XY, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1194-2
   He XM, 2021, IEEE T INTELL TRANSP, V22, P2252, DOI 10.1109/TITS.2020.3016002
   Hong CH, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3326066
   Hou XW, 2020, IEEE INTERNET THINGS, V7, P7097, DOI 10.1109/JIOT.2020.2982292
   Hu FY, 2021, IET COLL INTEL MANUF, V3, P334, DOI 10.1049/cim2.12023
   Huang XG, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-1652-5
   Ji HJ, 2020, IEEE ACCESS, V8, P61020, DOI 10.1109/ACCESS.2020.2983609
   Kadhim AJ, 2019, IEEE COMMUN LETT, V23, P140, DOI 10.1109/LCOMM.2018.2878710
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P12701, DOI 10.1007/s11042-017-4911-7
   Kaviarasan R, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4642
   Khadir AA, 2021, PEER PEER NETW APPL, V14, P1261, DOI 10.1007/s12083-020-01066-2
   Kim T, 2020, FUTURE GENER COMP SY, V108, P82, DOI 10.1016/j.future.2020.02.007
   Lee SS, 2020, IEEE INTERNET THINGS, V7, P10450, DOI 10.1109/JIOT.2020.2996213
   Lee Y, 2020, IEEE ACCESS, V8, P147313, DOI 10.1109/ACCESS.2020.3015550
   Li HT, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3818
   Li LH, 2020, J SIGNAL PROCESS SYS, V92, P1421, DOI 10.1007/s11265-020-01572-9
   Li MS, 2020, IEEE T COGN COMMUN, V6, P1122, DOI 10.1109/TCCN.2020.3003036
   Li ZG, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4844
   Lin C., 2017, J COMMUNICATIONS INF, V2, P126, DOI [10.1007/s41650-017-0027-5, DOI 10.1007/S41650]
   Lin K, 2019, FUTURE GENER COMP SY, V94, P610, DOI 10.1016/j.future.2018.12.045
   Liu CH, 2020, IEEE INTERNET THINGS, V7, P7999, DOI 10.1109/JIOT.2020.2997720
   Liu M, 2019, IEEE T VEH TECHNOL, V68, P641, DOI 10.1109/TVT.2018.2883669
   Liu ZX, 2021, PEER PEER NETW APPL, V14, P164, DOI 10.1007/s12083-020-00970-x
   LiWang M, 2020, IEEE INTERNET THINGS, V7, P311, DOI 10.1109/JIOT.2019.2949602
   Lv ZH, 2021, IEEE T INTELL TRANSP, V22, P2048, DOI 10.1109/TITS.2020.3019756
   Madan N, 2020, VEH COMMUN, V25, DOI 10.1016/j.vehcom.2020.100252
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Mahapatra SN, 2020, ARAB J SCI ENG, V45, P6211, DOI 10.1007/s13369-020-04461-2
   Makhdoom I, 2019, IEEE COMMUN SURV TUT, V21, P1636, DOI 10.1109/COMST.2018.2874978
   Mamadou AM, 2020, MOBILE NETW APPL, V25, P1749, DOI 10.1007/s11036-020-01564-w
   Martinez I, 2021, IEEE INTERNET THINGS, V8, P2494, DOI 10.1109/JIOT.2020.3022699
   Midya S, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107126
   Qi Q, 2019, IEEE T VEH TECHNOL, V68, P4192, DOI 10.1109/TVT.2019.2894437
   Qiao GH, 2020, IEEE INTERNET THINGS, V7, P247, DOI 10.1109/JIOT.2019.2945640
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Singh PK, 2019, VEH COMMUN, V18, DOI 10.1016/j.vehcom.2019.100164
   Sonmez C, 2021, IEEE T INTELL TRANSP, V22, P2239, DOI 10.1109/TITS.2020.3024233
   Sorkhoh I, 2019, IEEE T VEH TECHNOL, V68, P8472, DOI 10.1109/TVT.2019.2927634
   Sun A, 2021, MOB NETW APPL, V2021, P1
   Tan HZ, 2020, J ENG-JOE, V2020, P1080, DOI 10.1049/joe.2020.0134
   Thirugnanam T, 2020, PEER PEER NETW APPL, V13, P2112, DOI 10.1007/s12083-019-00829-w
   Venkatramana DKN, 2017, IET NETW, V6, P102, DOI 10.1049/iet-net.2016.0117
   Wang G, 2020, IEEE ACCESS, V8, P7173, DOI 10.1109/ACCESS.2020.2964018
   Xu XL, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3401979
   Xu XL, 2020, WIREL NETW, V26, P1611, DOI 10.1007/s11276-019-02127-y
   Xu XL, 2019, FUTURE GENER COMP SY, V96, P89, DOI 10.1016/j.future.2019.01.012
   Xue JB, 2021, IEEE ACCESS, V9, P16152, DOI 10.1109/ACCESS.2021.3049883
   Yang HL, 2019, IEEE T VEH TECHNOL, V68, P4157, DOI 10.1109/TVT.2018.2890686
   Yang S, 2020, IEEE ACCESS, V8, P53261, DOI 10.1109/ACCESS.2020.2980567
   Yao W, 2019, IEEE ACCESS, V7, P160889, DOI 10.1109/ACCESS.2019.2945610
   Zahoor S, 2021, J KING SAUD UNIV-COM, V33, P921, DOI 10.1016/j.jksuci.2018.08.014
   Zhang M, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00182-x
   Zhang PY, 2020, IEEE T VEH TECHNOL, V69, P15774, DOI 10.1109/TVT.2020.3035341
   Zhao JH, 2020, IEEE ACCESS, V8, P3319, DOI 10.1109/ACCESS.2019.2963051
   Zheng Q, 2016, IEEE T VEH TECHNOL, V65, P7857, DOI 10.1109/TVT.2016.2538461
NR 66
TC 1
Z9 1
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46811
EP 46844
DI 10.1007/s11042-023-15590-9
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:001033146000001
DA 2024-07-18
ER

PT J
AU Sharma, S
   Kumar, D
AF Sharma, Sarika
   Kumar, Deepak
TI Product backlog optimization technique in agile software development
   using clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software engineering; Agile methodology; Clustering; Algorithm;
   Parameters
AB ContextThe recent research trend has highlighted that multiple stakeholders are involved during requirement gathering in agile software development. Hence, leading to an increased number of duplicate user stories in agile product backlog during requirement gathering.ObjectiveThe objective of this paper is to evaluate the existing techniques employed in identifying and eliminating the duplicate user stories from agile product backlog and to overcome the existing gaps with the help of a newly proposed clustering algorithm.MethodAn agile user story is expressed as a function of input and output parameters. That said multiple user stories having similar set of input parameters are most likely to be duplicate causing a redundancy. The newly proposed algorithm is used for clustering user stories having similar set of input parameters through various iterations and then removing the identified duplicate user stories from agile product backlog. This paper also introduces the concept of mass clustering which means clustering a number of user stories in single run.ResultsExperimental results prove the proposed model is capable of handling small and large releases ranging between 100 to 1000 user stories with similar efficiency. The proposed clustering algorithm outperformed the clustering algorithms and resulted in 37% decrease in agile product backlog by eliminating duplicate user stories causing redundancy. The experimental results are obtained from the logs of the MATLAB tool. However, the provided algorithm is generic in nature and can be implemented using R, Python or SAS programming tools. The provided algorithms employs proven matrix operations.ConclusionThe proposed clustering algorithm overcomes the limitation of existing user story management methods and clearly out performs when compared with other clustering algorithms. Finally, this paper gives recommendations about the usage of the provided clustering algorithm during agile release planning for eliminating duplicate user stories from agile product backlog.
C1 [Sharma, Sarika; Kumar, Deepak] Amity Univ, Amity Inst Informat Technol, Sect 125, Noida, Uttar Pradesh, India.
C3 Amity University Noida
RP Sharma, S (corresponding author), Amity Univ, Amity Inst Informat Technol, Sect 125, Noida, Uttar Pradesh, India.
EM sarika.s17@gmail.com
RI Kumar, Deepak/AAA-9696-2021
OI Kumar, Deepak/0000-0003-2409-9706
CR Abrahamsson P, 2003, PROC INT CONF SOFTW, P244, DOI 10.1109/ICSE.2003.1201204
   Ahmad MO, 2018, J SYST SOFTWARE, V137, P96, DOI 10.1016/j.jss.2017.11.045
   Alsalemi AM, 2015, 2015 9TH MALAYSIAN SOFTWARE ENGINEERING CONFERENCE (MYSEC2015), P189, DOI 10.1109/MySEC.2015.7475219
   Barbosa R, 2016, I C DEPENDABLE SYST, P2, DOI [10.1109/DSN-W.2016.7, 10.1109/DSN-W.2016.27]
   Berger H, 2009, INFORM SYST J, V19, P549, DOI 10.1111/j.1365-2575.2009.00329.x
   Blankenship J, 2011, PROAGILE NET DEV SCR, DOI [10.1007/978-1-4302-3534-7_4, DOI 10.1007/978-1-4302-3534-7]
   Boerman MP, 2015, INT WORKS EMERG TREN, P54, DOI 10.1109/WETSoM.2015.15
   Bolloju N, 2017, AMCIS 2017 PROCEEDINGS
   Charikar M, 2002, J COMPUT SYST SCI, V65, P129, DOI 10.1006/jcss.2002.1882
   Cohen-Addad V, 2022, ACM S THEORY COMPUT, P1038, DOI 10.1145/3519935.3519946
   Czumaj A, 2017, ENCY MACHINE LEARNIN, P1205, DOI [10.1007/978-1-4899-7687-1_798, DOI 10.1007/978-1-4899-7687-1_798]
   Duraisamy G, 2013, J THEOR APPL INF TEC
   Frahling G., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P135, DOI 10.1145/1137856.1137879
   Ghosh S, 2013, INT J ADV COMPUT SC, V4, P35
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Holmes CC, 2002, J ROY STAT SOC B, V64, P295, DOI 10.1111/1467-9868.00338
   Kayes I, 2016, INNOV SYST SOFTW ENG, V12, P303, DOI 10.1007/s11334-016-0271-0
   Kosub S, 2019, PATTERN RECOGN LETT, V120, P36, DOI 10.1016/j.patrec.2018.12.007
   Kupiainen E, 2015, INFORM SOFTWARE TECH, V62, P143, DOI 10.1016/j.infsof.2015.02.005
   Li J., 2016, OCEANS 2016, Shanghai, P1, DOI DOI 10.1155/2016/4321928
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Masulli F, 2015, LECT NOTES COMPUT SC, V7627, P1, DOI 10.1007/978-3-662-48577-4_1
   Maurer F, 2002, IEEE INTERNET COMPUT, V6, P86, DOI 10.1109/4236.989006
   Noll J, 2017, LECT NOTES COMPUT SC, V10611, P307, DOI 10.1007/978-3-319-69926-4_22
   Paasivaara M., 2012, 2012 7th IEEE International Conference on Global Software Engineering (ICGSE 2012), P174, DOI 10.1109/ICGSE.2012.41
   Panigrahy R, 2008, LECT NOTES COMPUT SC, V4957, P387, DOI 10.1007/978-3-540-78773-0_34
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Radigan D, 2018, PRODUCT BACKLOG YOUR
   Rawat, 2021, QUAL QUANTITY, V55, P1371, DOI DOI 10.1007/S11135-020-01061-Y
   Samworth RJ, 2012, ANN STAT, V40, P2733, DOI 10.1214/12-AOS1049
   Sedano T, 2019, PROC INT CONF SOFTW, P200, DOI 10.1109/ICSE.2019.00036
   Sharma Sarika, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P223, DOI 10.1007/978-981-13-5934-7_20
   Sharma S, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P934, DOI [10.1109/aicai.2019.8701252, 10.1109/AICAI.2019.8701252]
   Song G, 2016, IEEE T KNOWL DATA EN, V28, P2376, DOI 10.1109/TKDE.2016.2562627
   Tirumala SS., 2016, INT J COMPUT APPL, V156, P1, DOI [10.5120/ijca2016912443, DOI 10.5120/IJCA2016912443]
   Wang C, 2021, IEEE-CAA J AUTOMATIC, V8, P876, DOI 10.1109/JAS.2020.1003420
   WONG MA, 1983, J ROY STAT SOC B MET, V45, P362
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Xu R., 2008, Clustering, DOI DOI 10.1002/9780470382776
   Yakowitz S., 1987, J TIME SER ANAL, V8, P235, DOI DOI 10.1111/J.1467-9892.1987.TB00435.X
NR 40
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 46695
EP 46715
DI 10.1007/s11042-023-15406-w
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000982739000013
DA 2024-07-18
ER

PT J
AU Li, HJ
   Shen, XL
   Sun, XH
   Wang, YL
   Li, CB
   Chen, JJ
AF Li, Hongjun
   Shen, Xulin
   Sun, Xiaohu
   Wang, Yunlong
   Li, Chaobo
   Chen, Junjie
TI Video anomaly detection based on scene classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video anomaly detection; Scene classification; Generative adversarial
   network
AB As a significant research hotspot in the field of computer vision, video anomaly detection plays an essential role in ensuring public safety. Anomaly detection remains a challenging task given the complex situation in public areas and the large random distribution of crowds. The density of people in the same scene varies greatly due to the instability of the pedestrian volume. Specifically, the characteristics of crowd distribution mainly include low density, small aggregation and dispersion, or large aggregation and severe occlusion. Considering the large difference between high-density and low-density crowd characteristics, we propose an anomaly detection algorithm based on scene classification in order to obtain better anomaly detection result. Firstly, we propose a novel scene classification method, which uses pre-trained YoloV4 model to detect the number of people in the video frames and generate heatmaps, and extracts pixel features through the Double-Canny algorithm to represent the occlusion degree of the crowd. Furthermore, K-Means clustering is used to adaptively divide the scene into sparse and dense. Secondly, the Generative Adversarial Network (GAN) based on prediction and reconstruction is introduced to detect anomalies respectively, and the final accuracy is achieved by combining the detection accuracy of both networks. Finally, experiments on three benchmark datasets demonstrate the competitive performance of our method with the state-of-the-art methods.
C1 [Li, Hongjun; Shen, Xulin; Sun, Xiaohu; Wang, Yunlong; Li, Chaobo; Chen, Junjie] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University
RP Li, HJ (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun@ntu.edu.cn; 2010310003@stmail.ntu.edu.cn;
   2010310052@stmail.ntu.edu.cn; 2110310014@stmail.ntu.edu.cn;
   1811310007@yjs.ntu.edu.cn; cjjcy@ntu.edu.cn
OI Wang, Yunlong/0000-0002-3774-6338; Li, Chaobo/0000-0003-3772-3344; Chen,
   Junjie/0000-0003-4219-6171; sun, xiao hu/0000-0002-5501-5424; li,
   hongjun/0000-0001-7500-4979
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Jiangsu Industry University Research Cooperation Project
   [BY2021349]; Nantong Science and Technology Program [JC2021131];
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province [KYCX21_3084, KYCX22_3340]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61871241, Grant 61971245 and Grant 61976120, in part
   by Jiangsu Industry University Research Cooperation Project BY2021349,
   in part by Nantong Science and Technology Program JC2021131 and in part
   by Postgraduate Research and Practice Innovation Program of Jiangsu
   Province KYCX21_3084 and KYCX22_3340.
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Alafif T, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03323-5
   Alanazi AA, 2019, ARXIV
   Bhuiyan MR, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.895
   Bhuiyan R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145102
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen DY, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107969
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Gong S, 2019, DIGITAL IMAGE SIGNAL
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hussain N, 2011, SAFETY SCI, V49, P824, DOI 10.1016/j.ssci.2011.01.005
   Huynh VS, 2019, IEEE SYS MAN CYBERN, P3019, DOI 10.1109/SMC.2019.8914497
   Jia DY, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01167-9
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Lamba S, 2019, MULTIMED TOOLS APPL, V78, P5645, DOI 10.1007/s11042-017-5554-4
   Lamba S, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS), P296, DOI 10.1109/SITIS.2017.57
   Lazaridis L, 2018, EUR SIGNAL PR CONF, P2060, DOI 10.23919/EUSIPCO.2018.8553620
   Lee S, 2020, IEEE T IMAGE PROCESS, V29, P2395, DOI 10.1109/TIP.2019.2948286
   Lei Z, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P1, DOI 10.1145/3317640.3317644
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Marsden Mark, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078482
   Naeem H, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622503029
   Ravanbakhsh M, 2019, IEEE WINT CONF APPL, P1896, DOI 10.1109/WACV.2019.00206
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Samriya JK, 2022, SUSTAIN COMPUT-INFOR, V35, DOI 10.1016/j.suscom.2022.100746
   Song H, 2020, IEEE T MULTIMEDIA, V22, P2138, DOI 10.1109/TMM.2019.2950530
   Wang P, 2021, PATTERN RECOGN LETT, V142, P20, DOI 10.1016/j.patrec.2020.11.018
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Xu ML, 2019, PATTERN RECOGN LETT, V125, P563, DOI 10.1016/j.patrec.2019.02.026
   Zhu LP, 2020, NEURAL COMPUT APPL, V32, P5105, DOI 10.1007/s00521-018-3954-7
NR 31
TC 0
Z9 0
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45345
EP 45365
DI 10.1007/s11042-023-15328-7
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000978477000006
DA 2024-07-18
ER

PT J
AU Swain, D
   Parmar, B
   Shah, HS
   Gandhi, A
   Acharya, B
   Hu, YC
AF Swain, Debabrata
   Parmar, Badal
   Shah, Hansal
   Gandhi, Aditya
   Acharya, Biswaranjan
   Hu, Yu-Chen
TI Enhanced handwritten digit recognition using optimally selected
   optimizer for an ANN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwritten digit recognition; Artificial neural networks; Optimizers;
   MNIST dataset; Hyper-parameters; Deep learning; Adagrad; Adam; RMSprop;
   Gradient descent; Stochastic gradient descent; Mini-batch gradient
   descent
ID CNN-SVM CLASSIFIER
AB Handwritten digit recognition is a complex problem that has stumped even the brilliant minds of this century. Getting precise results from different handwritten samples has been a challenge that needs to be addressed due to the occurrence of this issue in several sectors like document verification, post mail, deciphering, etc. Hence, we introduce our paper as a response to the requirement of an accurate model that can acutely recognize and then predict the handwriting of a variety of individuals with ease. Our model aims to do number recognition through the implementation of neural networks. We tested out different models with each optimizer to verify which model provided the best performance and with which optimizer. Optimizers are an inherent part of Deep learning, and they are used to upgrade the weights, so the model can learn accordingly and get a more accurate system. Instead of just comparing the performance of various optimizers with only one model, we compared different model performances, while trying to select the optimizer that would best suit that learning model. Rigorous training and experimentalizing have resulted in an accuracy of 98.55% for an ANN model employed with an Adagrad optimizer.
C1 [Swain, Debabrata; Parmar, Badal; Shah, Hansal; Gandhi, Aditya] Pandit Deendayal Energy Univ, Comp Sci Engn, Gandhinagar, Gujarat, India.
   [Acharya, Biswaranjan] Marwadi Univ, Dept Comp Engn AI & BDA, Rajkot, Gujarat, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
   [Hu, Yu-Chen] TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
C3 Pandit Deendayal Energy University; Marwadi University; Providence
   University - Taiwan; Tunghai University
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.; Hu, YC (corresponding author), TungHai Univ, Dept Comp Sci, Taichung, Taiwan.
EM debabrata.swain7@yahoo.com; badal.pce18@sot.pdpu.ac.in;
   hansal.sce19@sot.pdpu.ac.in; aditya.gce19@pdpu.ac.in;
   acharya.biswa85@gmail.com; ychu@pu.edu.tw
RI Acharya, Biswaranjan/AAL-1977-2020
OI Acharya, Biswaranjan/0000-0002-6506-9207; Hu,
   Yu-Chen/0000-0002-5055-3645; Parmar, Badal/0000-0001-6279-7113
CR AgrawalVK Ayush Kumar, 2021, INT J ADV RES SCI CO, P30
   Ahlawat S, 2020, PROCEDIA COMPUT SCI, V167, P2554, DOI 10.1016/j.procs.2020.03.309
   Albahli S, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175988
   Ali S, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1161-5
   Almodfer R, 2017, PROC INT C TOOLS ART, P663, DOI 10.1109/ICTAI.2017.00106
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Alyahya H., 2020, TIPCV, V6, P68, DOI 10.19101/TIPCV.2020.618051
   An S., 2020, arXiv
   Beskopylny Alexey, 2020, E3S Web of Conferences, V224, DOI 10.1051/e3sconf/202022401025
   Chen F, 2018, ARXIV
   Chowdhury RR, 2019, 2019 JOINT 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR) WITH INTERNATIONAL CONFERENCE ON ACTIVITY AND BEHAVIOR COMPUTING (ABC), P318, DOI [10.1109/iciev.2019.8858545, 10.1109/ICIEV.2019.8858545]
   Diaz GI, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2709578
   Fan Jerome, 2006, CJEM, V8, P19
   Fathma Siddique SS., 2019, PREPRINT, DOI [10.20944/preprints201903, DOI 10.20944/PREPRINTS201903]
   Garg A, 2019, 2019 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P602, DOI [10.1109/spin.2019.8711703, 10.1109/SPIN.2019.8711703]
   Hamel L., 2009, Encyclopedia of Data Warehousing and Mining, V2nd, P1316, DOI DOI 10.4018/978-1-60566-010-3.CH204
   Hossain A., 2019, ADV INTELL SYST, DOI [10.17406/GJCST, DOI 10.17406/GJCST]
   James A., 2018, INDONESIAN J ELECT E, V6, P393, DOI DOI 10.11591/IJEEI.V6I1.518
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Katarzyna Janocha WM, 2017, ARXIV
   Ketkar N., 2017, Deep Learning With Python, P113, DOI DOI 10.1007/978-1-4842-2766-4_8
   Kumar A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290607.3312928, 10.1109/imarc45935.2019.9118731]
   Lee SG, 2018, J INF PROCESS SYST, V14, P205, DOI 10.3745/JIPS.04.0061
   Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172
   Lydia A., 2019, INT J INFORM COMPUTI, V6, P566
   Munsarif M, IMPROVED CONVOLUTION
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Postalcioglu S, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420510039
   Ruder S., 2016, ARXIV
   Sharma P., 2021, GRAPH VIS COMPUT, V5, P200032, DOI [10.1016/j.gvc.2021.200032, DOI 10.1016/J.GVC.2021.200032]
   Shima Y., 2018, P INT C MULT SYST SI, P36
   Soham De AM, 2018, ARXIV
   Tabik S, 2017, INT J COMPUT INT SYS, V10, P555, DOI 10.2991/ijcis.2017.10.1.38
   Trivedi A, 2018, PROCEDIA COMPUT SCI, V125, P525, DOI 10.1016/j.procs.2017.12.068
   Vani S, 2019, 2019 3 INT C TRENDS, P331
   Zhan HJ, 2018, INT C PATT RECOG, P3729, DOI 10.1109/ICPR.2018.8546100
NR 36
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44021
EP 44036
DI 10.1007/s11042-023-15402-0
EA APR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979936300004
DA 2024-07-18
ER

PT J
AU Alsenani, TR
   Ayon, SI
   Yousuf, SM
   Anik, FB
   Chowdhury, MES
AF Alsenani, Theyab R. R.
   Ayon, Safial Islam
   Yousuf, Sayeda Mayesha
   Anik, Fahad Bin Kamal
   Chowdhury, Mohammad Ehsan Shahmi
TI Intelligent feature selection model based on particle swarm optimization
   to detect phishing websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Detect Phishing Websites; Feature Selection; Machine Learning Technique;
   Particle Swarm Optimization; Swarm Intelligence
ID ALGORITHM; PRIORITIZATION; NETWORKS
AB In the past ten years, due to the rapid growth of the Internet, a huge number of cyber-crimes have been committed on the Internet. One of the crucial obstacles' user's encounters is the phishing website's threat, especially for login credentials and credit card information. According to the statistics, most attackers utilized PayPal (22%), Microsoft (19%), Facebook (15%), eBay (6%), and Amazon (3%) for phishing. Some phishing attempts are designed to get login credentials or infect specific people's computers. Since the stakes are so high, attackers invest a lot of effort into fooling the chosen victims. The feature selection-based Particle Swarm Optimization (PSO) method is applied in this study to detect phishing websites. Feature engineering is critical in phishing website detection systems, and detection accuracy is heavily dependent on prior knowledge of characteristics. PSO iteratively attempts to optimize a problem by improving the proposed model. Many computational methods are applied in this model to evaluate the results. The experimental findings show that the proposed PSO-based feature selection model substantially improved classification accuracy, sensitivity, specificity, f1-score, and Matthew's correlation coefficient in machine learning models. Testing the model on two prominent datasets containing phishing and legitimate website, the accuracy reaches 97.81% and 90.39% for the two datasets using the artificial neural network in both cases. Experimental findings demonstrate that the detection efficiency may be enhanced by selecting the features appropriately.
C1 [Alsenani, Theyab R. R.] Prince Sattam Bin Abdulaziz Univ, Coll Engn Al Kharj, Dept Elect Engn, Al Kharj 11942, Saudi Arabia.
   [Ayon, Safial Islam] Univ Potsdam, Dept Comp Sci, Potsdam, Germany.
   [Yousuf, Sayeda Mayesha; Anik, Fahad Bin Kamal; Chowdhury, Mohammad Ehsan Shahmi] Green Univ Bangladesh, Dept Comp Sci & Engn, Dhaka 1207, Bangladesh.
C3 Prince Sattam Bin Abdulaziz University; University of Potsdam
RP Ayon, SI (corresponding author), Univ Potsdam, Dept Comp Sci, Potsdam, Germany.
EM safialislam302@gmail.com
RI Chowdhury, Muhammad E.H./J-6916-2019; R. Alsenani, Theyab/AAI-7281-2021
OI Chowdhury, Muhammad E.H./0000-0003-0744-8206; R. Alsenani,
   Theyab/0000-0002-1358-8806; Ayon, Safial Islam/0000-0002-0970-0455
FU Prince Sattam bin Abdulaziz University [PSAU/2023/R/1444]
FX This study is supported via funding from Prince Sattam bin Abdulaziz
   University project number (PSAU/2023/R/1444).
CR Abd Manaf S., 2018, INT J INTELL ENG SYS, V11, P62, DOI DOI 10.22266/IJIES2018.0228.07
   Abdelhamid Neda, 2015, Applied Computing and Informatics, V11, P29, DOI 10.1016/j.aci.2014.07.002
   Abdelhamid N, 2014, EXPERT SYST APPL, V41, P5948, DOI 10.1016/j.eswa.2014.03.019
   Abraham A., 2006, STUD COMP INTELL, V26, P3
   Aburrous Maher, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P176, DOI 10.1109/ITNG.2010.117
   Aburrous M, 2010, EXPERT SYST APPL, V37, P7913, DOI 10.1016/j.eswa.2010.04.044
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Ahmed H., 2012, Swarm Intelligence: Concepts, Models, and Applications
   Ahn S, 2017, INTEGR COMPUT-AID E, V24, P187, DOI 10.3233/ICA-170539
   Akhand MAH, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105887
   Akinyelu AA, 2014, J APPL MATH, DOI 10.1155/2014/425731
   Al-Najjar HAH, 2019, PROC SPIE, V11156, DOI 10.1117/12.2532687
   Aleroud A, 2017, COMPUT SECUR, V68, P160, DOI 10.1016/j.cose.2017.04.006
   Alexandridis A, 2017, INTEGR COMPUT-AID E, V24, P143, DOI 10.3233/ICA-160536
   Ali W, 2019, IET INFORM SECUR, V13, P659, DOI 10.1049/iet-ifs.2019.0006
   Ali W, 2017, INT J ADV COMPUT SC, V8, P72
   Alinizzi M, 2018, COMPUT-AIDED CIV INF, V33, P905, DOI 10.1111/mice.12380
   Alsariera YA, 2020, IEEE ACCESS, V8, P142532, DOI 10.1109/ACCESS.2020.3013699
   Alsariera YA, 2020, ARAB J SCI ENG, V45, P10459, DOI 10.1007/s13369-020-04802-1
   Altaher A, 2017, Int J Adv Comput Sci Appl, V8, DOI [10.14569/IJACSA.2017.080611, DOI 10.14569/IJACSA.2017.080611]
   [Anonymous], SPAM ASSASSIN HOMEPA
   [Anonymous], PHISHINGCORPUS
   [Anonymous], PHISHING WEBSITES DA
   [Anonymous], TIMELY ACCURATE RELE
   [Anonymous], GINI INDEX DECISION
   [Anonymous], WEBSITE PHISHING DAT
   [Anonymous], BLACKPHISH
   Anti-phishing working group, PHISH ACT TRENDS REP
   Arade MS., 2011, INT J COMPUTER SCI T, V2, P282
   Aydin M, 2015, IEEE CONF COMM NETW, P769, DOI 10.1109/CNS.2015.7346927
   Ayon SI, 2019, 2019 INT C ELECT COM, P1
   Babagoli M, 2019, SOFT COMPUT, V23, P4315, DOI 10.1007/s00500-018-3084-2
   Bagloee SA, 2018, COMPUT-AIDED CIV INF, V33, P833, DOI 10.1111/mice.12370
   Balamuralikrishna T., 2012, INT J SCI ENG RES, V3, P1
   Balogun AO, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07437
   Basnet Ram B., 2012, Advanced Research in Applied Artificial Intelligence. Proceedings 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2012, P252, DOI 10.1007/978-3-642-31087-4_27
   Blum Christian, 2008, P43, DOI 10.1007/978-3-540-74089-6_2
   Bonyadi MR, 2017, EVOL COMPUT, V25, P1, DOI 10.1162/EVCO_r_00180
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brewka Gerd., 1996, KNOWL ENG REV, V11, P78, DOI DOI 10.1017/S0269888900007724
   Buber E, 2017, 2017 INTERNATIONAL ARTIFICIAL INTELLIGENCE AND DATA PROCESSING SYMPOSIUM (IDAP)
   Chang EH, 2013, INT CONF IT CONVERGE
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Chiew KL, 2019, INFORM SCIENCES, V484, P153, DOI 10.1016/j.ins.2019.01.064
   Chiew KL, 2018, EXPERT SYST APPL, V106, P1, DOI 10.1016/j.eswa.2018.03.050
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dhamija R, 2005, P 2005 S US PRIV SEC, P77, DOI DOI 10.1145/1073001.1073009
   Dong ZZ, 2015, 2015 IEEE 2ND INTERNATIONAL FUTURE ENERGY ELECTRONICS CONFERENCE (IFEEC)
   Fette I., 2007, P 16 INT C WORLD WID, P649, DOI DOI 10.1145/1242572.1242660
   Fu AY, 2006, IEEE T DEPEND SECURE, V3, P301, DOI 10.1109/TDSC.2006.50
   Fu WL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040404
   Gao Y, 2015, SCI REP-UK, V5, DOI 10.1038/srep09295
   García-Nieves JD, 2018, COMPUT-AIDED CIV INF, V33, P655, DOI 10.1111/mice.12356
   Garera S, 2007, WORM'07: PROCEEDINGS OF THE 2007 ACM WORKSHOP ON RECURRING MALCODE, P1
   google, Google Safe browsing
   Guo HX, 2016, ENG APPL ARTIF INTEL, V49, P176, DOI 10.1016/j.engappai.2015.09.011
   Hadi W, 2016, APPL SOFT COMPUT, V48, P729, DOI 10.1016/j.asoc.2016.08.005
   Harinahalli Lokesh Gururaj, 2021, Journal of Cyber Security Technology, V5, P1, DOI 10.1080/23742917.2020.1813396
   Hastie T., 2009, The Elements of Statistical Learning
   He MX, 2011, EXPERT SYST APPL, V38, P12018, DOI 10.1016/j.eswa.2011.01.046
   Nguyen HH, 2016, LECT NOTES ELECTR EN, V371, P123, DOI 10.1007/978-3-319-27247-4_11
   Jain AK, 2018, TELECOMMUN SYST, V68, P687, DOI 10.1007/s11235-017-0414-0
   Kawamura A, 2017, INT CONF AWARE SCI, P564, DOI 10.1109/ICAwST.2017.8256521
   Khonji M., 2011, 2011 6th International Conference for Internet Technology and Secured Transactions (ICITST), P422
   Li XN, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P3685, DOI 10.1109/BigData.2016.7841036
   Liao TY, 2017, COMPUT-AIDED CIV INF, V32, P1047, DOI 10.1111/mice.12308
   Liu DJ, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102421
   Ma J., 2009, P 26 ANN INT C MACH, P681, DOI DOI 10.1145/1553374.1553462
   Maimon Oded Z, 2014, Data mining with decision trees: theory and applications, V81
   Malkauthekar M. D., 2013, P 3 INT C COMP INT I, P503
   Marchal S, 2014, IEEE T NETW SERV MAN, V11, P458, DOI 10.1109/TNSM.2014.2377295
   Merigó JM, 2011, INT J COMPUT INT SYS, V4, P123
   Mohammad RM, 2015, COMPUT SCI REV, V17, P1, DOI 10.1016/j.cosrev.2015.04.001
   Mohammad RM, 2014, NEURAL COMPUT APPL, V25, P443, DOI 10.1007/s00521-013-1490-z
   Mohammad RM, 2012, INT CONF INTERNET, P492
   Muharemi F, 2019, J INFORM TELECOMMUN, V3, P294, DOI 10.1080/24751839.2019.1565653
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pasupuleti S, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P67
   Pham C, 2018, IEEE T NETW SERV MAN, V15, P1076, DOI 10.1109/TNSM.2018.2831197
   Phishtank, VER PHISH URL
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Priya A, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1468, DOI 10.1109/RTEICT.2017.8256841
   Probst P, 2019, J MACH LEARN RES, V20
   Qabajeh I, 2014, INT CONF ADV COMPUT, P125, DOI 10.1109/ACSAT.2014.29
   Rao RS, 2021, NEURAL COMPUT APPL, V33, P5733, DOI 10.1007/s00521-020-05354-z
   Rao RS, 2020, J AMB INTEL HUM COMP, V11, P3853, DOI 10.1007/s12652-019-01637-z
   Rao RS, 2019, NEURAL COMPUT APPL, V31, P3851, DOI 10.1007/s00521-017-3305-0
   Roussopoulos N., 1995, SIGMOD Record, V24, P71, DOI 10.1145/568271.223794
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Sahingoz OK, 2019, EXPERT SYST APPL, V117, P345, DOI 10.1016/j.eswa.2018.09.029
   Sarkar S, 2013, INT J COMPUT APPL, V65
   Sattiraju R, 2019, MOB COMMUN INT, P1
   Schratz P, 2019, ECOL MODEL, V406, P109, DOI 10.1016/j.ecolmodel.2019.06.002
   Shabudin S, 2020, INT J ADV COMPUT SC, V11, P587
   Shahriar H, 2012, FUTURE GENER COMP SY, V28, P1258, DOI 10.1016/j.future.2011.02.001
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Sharma S, 2017, Towards Data Sci, V6, P310, DOI [DOI 10.33564/IJEAST.2020.V04I12.054, 10.33564/IJEAST.2020.v04i12.054]
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Shrestha N, 2015, IEEE WORLD CONGR SER, P206, DOI 10.1109/SERVICES.2015.38
   Sopto DS, 2018, 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND TECHNOLOGY (ICIET)
   SUBASI A, 2017, INT C EL COMP TECHN, P1, DOI DOI 10.1109/ICECTA.2017.8252051
   Suganya V., 2016, International Journal of Computer Applications, V139, P20, DOI [DOI 10.5120/IJCA2016909084, 10.5120/ijca2016909084]
   Sun B, 2016, KNOWL-BASED SYST, V102, P87, DOI 10.1016/j.knosys.2016.03.024
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tahir MAU, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P1126, DOI [10.1109/CSCI.2016.213, 10.1109/CSCI.2016.0214]
   Vaitkevicius P, 2020, INFORMATICA-LITHUAN, V31, P143, DOI [10.0000/15388/20-INFOR404, 10.15388/20-INFOR404]
   Vrbancic G, 2019, INT J ARTIF INTELL T, V28, DOI 10.1142/S021821301960008X
   Wang WP, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2595794
   Weerts H. J., 2020, ARXIV
   Wu SX, 2010, APPL SOFT COMPUT, V10, P1, DOI 10.1016/j.asoc.2009.06.019
   Xie SY, 2018, COMPUT-AIDED CIV INF, V33, P815, DOI 10.1111/mice.12368
   Yerima S. Y., 2020, ICCAIS 2020 3 INT C, P1, DOI DOI 10.1109/ICCAIS48893.2020.9096869
   Yi P, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/4678746
   Zamir A, 2020, ELECTRON LIBR, V38, P65, DOI 10.1108/EL-05-2019-0118
   Zhu EZ, 2019, IEEE ACCESS, V7, P73271, DOI 10.1109/ACCESS.2019.2920655
   Zhu X, 2014, COMPUTATIONAL INTELL, P3
   Zverovich V, 2017, COMPUT-AIDED CIV INF, V32, P727, DOI 10.1111/mice.12260
NR 117
TC 2
Z9 2
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 44943
EP 44975
DI 10.1007/s11042-023-15399-6
EA APR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000977223400005
DA 2024-07-18
ER

PT J
AU Murugesan, VP
AF Murugesan, Vijaya Prabhagar
TI Impact of new seed and performance criteria in proposed rough k-means
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Rough k-means; Zeta values; S; T index; RMSSTD
ID FUZZY
AB Rough k-means algorithm is one of the widely used soft clustering methods for clustering. However, the rough k-means clustering algorithm has certain issues like it is very sensitive to random initial cluster centroid and subjectivity involved in fixing the constant value of zeta parameter to decide the fuzzy elements. Also, there are no appropriate performance measures for the rough k-means algorithm. This study proposes a new initialization algorithm to address the issue of random allocation of data elements to improve the performance of the clustering. A new method to determine the best zeta values for the rough k-means algorithm is evolved. Also, new performance criteria are introduced, such as distance between the centroid and the farthest element in the cluster, number of elements in the intersection area and distance between the centroid of clusters. The seven experiments were carried out by using several benchmark datasets such as Microarray, Synthetic and Forest cover datasets. The performance criteria were compared across the Proposed algorithms, Peters (k-means++), Peters PI, Ioannis' algorithm, Vijay algorithm Mano algorithm, and Peters (random) initialization methods. The Root mean square standard deviation (RMSSTD) and S/T index were used to validate the performance of the rough k-means clustering algorithm. Also, the frequency table was constructed to gauge the degree of fuzziness in each algorithm. The program completion time of each initialization algorithm was used to measure the variability among the proposed and existing rough k-means clustering algorithms. It was found that the initialization algorithms excelled in all criteria and performed better than the existing rough k-means clustering algorithms.
C1 [Murugesan, Vijaya Prabhagar] Old Univ Campus, Indian Inst Management Jammu, IT Syst & Analyt, Canal Rd, Jammu 180016, India.
C3 Indian Institute of Management (IIM System); Indian Institute of
   Management Jammu
RP Murugesan, VP (corresponding author), Old Univ Campus, Indian Inst Management Jammu, IT Syst & Analyt, Canal Rd, Jammu 180016, India.
EM vijaya@iimj.ac.in
CR Acharjya DP, 2021, MULTIMED TOOLS APPL, V80, P35387, DOI 10.1007/s11042-020-10167-2
   Anderberg M., 1973, Cluster Analysis for Applications
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Berahmand K, 2022, CLUSTER COMPUT, V25, P869, DOI 10.1007/s10586-021-03430-0
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Berahmand K, 2022, J KING SAUD UNIV-COM, V34, P1869, DOI 10.1016/j.jksuci.2020.08.013
   Bhargava R, 2013, COMP 2013 6 ACM IND
   Bubeck S, 2009, INITIALIZATION AFFEC, V16, P436, DOI [10.1051/ps/2012013, DOI 10.1051/PS/2012013]
   Cheng CH, 2020, MULTIMED TOOLS APPL, V79, P29845, DOI 10.1007/s11042-020-09517-x
   Cui Y, 2015, JPN J APPL PHYS, V54, DOI 10.7567/JJAP.54.061701
   Darken C., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P233, DOI 10.1109/IJCNN.1990.137720
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Flynn PJ, 2000, DATA CLUSTERING REV, V31, DOI [10.1145/331499.331504, DOI 10.1145/331499.331504]
   Frank A., 2010, UCI MACHINE LEARNING
   GONZALEZ F, 1985, CLUSTERING MINIMIZE, V38, P293
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Kumar DM, 2021, MULTIMED TOOLS APPL, V80, P6939, DOI 10.1007/s11042-020-09635-6
   Lingras P, 2004, J INTELL INF SYST, V23, P5, DOI 10.1023/B:JIIS.0000029668.88665.1a
   Lingras P, 2011, WIRES DATA MIN KNOWL, V1, P64, DOI 10.1002/widm.16
   Maji P, 2007, IEEE T SYST MAN CY B, V37, P1529, DOI 10.1109/TSMCB.2007.906578
   Manochandar S, 2020, COMPUT IND ENG, V141, DOI 10.1016/j.cie.2020.106290
   MILLIGAN GW, 1985, J MARKETING RES, V22, P224, DOI 10.2307/3151374
   Mitra S, 2007, LECT NOTES COMPUT SC, V4400, P151
   Moore W, 2001, STAT DATA MINING TUT, P1
   Munusamy S, 2020, APPL INTELL, V50, P1922, DOI 10.1007/s10489-019-01626-x
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Murugesan VP, 2020, SOFT COMPUT, V24, P11605, DOI 10.1007/s00500-019-04625-9
   Nambura A, 2017, APPL SOFT COMPUT, V54, P456, DOI 10.1016/j.asoc.2016.08.020
   Nazari Z, 2015, INT CONF INTEL INFOR, P148, DOI 10.1109/ICIIBMS.2015.7439517
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   PAWLAK Z, 2007, ROUGH SETS SOME EXTE, V177, P28, DOI DOI 10.1016/J.INS.2006.06.006
   PETERS G, 2005, OUTLIERS ROUGH K MEA, P702
   Peters G, 2006, PATTERN RECOGN, V39, P1481, DOI 10.1016/j.patcog.2006.02.002
   Peters G, 2015, PATTERN RECOGN LETT, V53, P31, DOI 10.1016/j.patrec.2014.11.003
   Peters G, 2014, INFORM SCIENCES, V277, P358, DOI 10.1016/j.ins.2014.02.073
   Peters G, 2013, INT J APPROX REASON, V54, P307, DOI 10.1016/j.ijar.2012.10.003
   Peters G, 2008, LECT NOTES COMPUT SC, V5084, P289, DOI 10.1007/978-3-540-85064-9_13
   Prabhagar MV, 2020, NEURAL COMPUT APPL, V32, P2589, DOI 10.1007/s00521-019-04297-4
   Sarle W.S., 1990, TECHNOMETRICS, V32, P227, DOI DOI 10.2307/1268876
   Sivaguru M, 2021, SOFT COMPUT, V25, P1595, DOI 10.1007/s00500-020-05247-2
   Su T, 2007, INTELL DATA ANAL, V11, P319, DOI 10.3233/IDA-2007-11402
   Ubukata S, 2021, INFORM SCIENCES, V548, P479, DOI 10.1016/j.ins.2020.10.037
   Zafar M.H., 2015, INT J DATABASE THEOR, V8, P11, DOI [DOI 10.14257/IJDTA.2015.8.1.02, 10.14257/ijdta.2015.8.1.02]
NR 44
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43671
EP 43700
DI 10.1007/s11042-023-14414-0
EA APR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000972822600001
DA 2024-07-18
ER

PT J
AU Sun, HB
   Fan, YG
AF Sun, HaiBin
   Fan, YueGuang
TI Fault diagnosis of rolling bearings based on CNN and LSTM networks under
   mixed load and noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rolling bearing; Machine learning; Feature fusion; Generalization
   capability; Noise immunity
ID MODEL; SPECTRUM; FEATURES; ENTROPY; SYSTEM
AB In recent years, the method of building models based on machine learning has achieved good results in the field of bearing fault diagnosis. However, due to the complexity and variability of the actual working environment, the collected rolling bearing vibration data not only comes from different loads, but also contains noise data. The existing models are unable to adapt to all operating environments and their fault diagnosis capabilities are significantly reduced especially when the collected data is noisy. In order to achieve higher fault diagnosis accuracy and robustness under different work conditions, a new fault diagnosis model 1LWCNNLSTM (One-layer wide convolutional and long-short term memory network) is proposed, which is a hybrid model based on convolutional neural network (CNN) and long-short term memory network (LSTM). Firstly, the model extracts features from the raw data using a wide convolutional kernel to attenuate the effect of noise, then fuses the features extracted from different convolutional kernels to generate a new sequence, and finally uses LSTM to learn the features in the new sequence. The impact of the model parameters is analyzed through extensive experiments and the proposed model has higher diagnostic accuracy under mixed load and noise when compared with existing models. Further analyses of model classification details through visualization techniques and confusion matrices demonstrate the high usability of the model. The experimental results show that the model proposed has better load generalization capability and noise immunity for the vibration data coming from the complex working environments.
C1 [Sun, HaiBin; Fan, YueGuang] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Fan, YG (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM 15020179172@163.com
OI Fan, YueGuang/0000-0001-6189-6427
CR Aker E, 2020, ENERGIES, V13, DOI 10.3390/en13010243
   Bayrakdar S, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4424
   Chen ZQ, 2017, MICROELECTRON RELIAB, V75, P327, DOI 10.1016/j.microrel.2017.03.006
   Cheng YW, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106796
   Deng W, 2018, IEEE ACCESS, V6, P35042, DOI 10.1109/ACCESS.2018.2834540
   Gao ZW, 2015, IEEE T IND ELECTRON, V62, P3768, DOI [10.1109/TIE.2015.2419013, 10.1109/TIE.2015.2417501]
   Harmouche J, 2015, IEEE T ENERGY CONVER, V30, P376, DOI 10.1109/TEC.2014.2341620
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jalayer M, 2021, COMPUT IND, V125, DOI 10.1016/j.compind.2020.103378
   Janssens O, 2016, J SOUND VIB, V377, P331, DOI 10.1016/j.jsv.2016.05.027
   Khorram A, 2021, APPL INTELL, V51, P736, DOI 10.1007/s10489-020-01859-1
   Koizumi Y, 2019, IEEE-ACM T AUDIO SPE, V27, P212, DOI 10.1109/TASLP.2018.2877258
   Li JM, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107419
   Li Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108509
   Mbo'o CP, 2016, IEEE T IND APPL, V52, P3861, DOI 10.1109/TIA.2016.2581139
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Minhas AS, 2021, KNOWL-BASED SYST, V218, DOI 10.1016/j.knosys.2021.106883
   Nguyen V, 2021, MACHINES, V9, DOI 10.3390/machines9120345
   Pan WJ, 2019, APPL MATH MODEL, V68, P113, DOI 10.1016/j.apm.2018.10.022
   Qiao MY, 2020, IEEE ACCESS, V8, P66257, DOI 10.1109/ACCESS.2020.2985617
   Stief A, 2019, IEEE T IND ELECTRON, V66, P9510, DOI 10.1109/TIE.2019.2891453
   Sun HB, 2021, SHOCK VIB, V2021, DOI 10.1155/2021/1221462
   Tian J, 2016, IEEE T IND ELECTRON, V63, P1793, DOI 10.1109/TIE.2015.2509913
   Wang YS, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103765
   Wang ZY, 2020, MEASUREMENT, V156, DOI 10.1016/j.measurement.2020.107574
   Wu ZH, 2020, MEASUREMENT, V151, DOI 10.1016/j.measurement.2019.107227
   Xu F, 2018, APPL SOFT COMPUT, V73, P898, DOI 10.1016/j.asoc.2018.09.037
   Yoo Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071102
   Yu L, 2019, SHOCK VIB, V2019, DOI 10.1155/2019/2756284
   Zhang W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020425
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao B, 2020, KNOWL-BASED SYST, V199, DOI 10.1016/j.knosys.2020.105971
   Zhao K, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106974
NR 33
TC 5
Z9 5
U1 9
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43543
EP 43567
DI 10.1007/s11042-023-15325-w
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000971011000001
DA 2024-07-18
ER

PT J
AU Ferreira , PE Jr
   Mello, VM
   Giraldi, GA
AF Ferreira Jr, Perfilino Eugenio
   Mello, Vinicius Moreira
   Giraldi, Gilson Antonio
TI Image thresholding through nonextensive entropies and long-range
   correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image thresholding; Infrared images; Long-range correlation;
   Non-destructive testing images
ID GRAY-LEVEL; SEGMENTATION; TSALLIS; ALGORITHM; SELECTION; RENYI
AB In recent years, many image thresholding techniques have emerged involving entropy measures with the related long-range and short-range correlation properties. However, despite the segmentation capabilities demonstrated by those methods, we have noticed limitations in dealing with images with local long-range correlation in the foreground and background. In order to address this issue, in this paper, we propose a combination of two approaches, the first one that applies the Tsallis and Shannon entropies while the second one uses the Masi entropy as the information measure. Such a combination leads to a thresholding criterion based on Tsallis and Masi entropies, providing an improved long-range correlation image thresholding method. Besides, differently from the others, the novel technique works with two entropic parameters instead of just one, which improves the technique's capabilities to fit the specific requirements of the applications. In the computational experiments, the quantitative evaluation of the segmentation is performed using infrared, Non-Destructive Testing images, the public Berkeley Segmentation Dataset (BSDS500), together with four error metrics computed through the ground-truth segmentation and the obtained results. The proposed method outperforms the competing approaches for infrared and non-destructive images. In the case of BSDS500, we get the second best results. For benchmark images without ground-truth segmentation, the visual analysis shows that the proposal is competitive concerning counterpart techniques.
C1 [Ferreira Jr, Perfilino Eugenio; Mello, Vinicius Moreira] Univ Fed Bahia, Dept Math, Salvador, BA, Brazil.
   [Giraldi, Gilson Antonio] Natl Lab Sci Comp, Coordinat Math & Computat Methods, Petropolis, RJ, Brazil.
C3 Universidade Federal da Bahia; Laboratorio Nacional de Computacao
   Cientifica (LNCC)
RP Giraldi, GA (corresponding author), Natl Lab Sci Comp, Coordinat Math & Computat Methods, Petropolis, RJ, Brazil.
EM perfeuge@ufba.br; vinicius.moreira.mello@gmail.com; gilson@lncc.br
OI Ferreira Junior, Perfilino/0000-0002-7629-6325; Mello,
   Vinicius/0000-0001-6330-9847
CR Abdollahi B., 2020, Data Augmentation in Training Deep Learning Models for Medical Image Analysis, P167, DOI DOI 10.1007/978-3-030-42750-4_6
   Aiying Lin, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1460, DOI 10.1109/CISP.2010.5648295
   Alcântara R, 2017, LECT NOTES COMPUT SC, V10125, P451, DOI 10.1007/978-3-319-52277-7_55
   [Anonymous], 1975, On measures of information and their characterizations
   [Anonymous], 2017, Eur. J. Eng. Technol. Res, DOI DOI 10.24018/EJERS.2017.2.1.237
   Babu AA, 2020, COMPUT INTELL-US, V36, P1242, DOI 10.1111/coin.12339
   Ben Ishak A, 2017, APPL SOFT COMPUT, V52, P306, DOI 10.1016/j.asoc.2016.10.034
   Ben Ishak A, 2017, PHYSICA A, V466, P521, DOI 10.1016/j.physa.2016.09.053
   Borjigin S, 2019, PATTERN RECOGN, V92, P107, DOI 10.1016/j.patcog.2019.03.011
   BRINK AD, 1992, PATTERN RECOGN, V25, P803, DOI 10.1016/0031-3203(92)90034-G
   Cáceres MO, 1999, BRAZ J PHYS, V29, P125, DOI 10.1590/S0103-97331999000100011
   CHENG SC, 1993, IEEE T COMPUT, V42, P501, DOI 10.1109/12.214696
   Cowger W, 2020, APPL SPECTROSC, V74, P989, DOI 10.1177/0003702820929064
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Deng Q, 2022, ENTROPY-SWITZ, V24
   Dhal KG, 2020, ARCH COMPUT METHOD E, V27, P855, DOI 10.1007/s11831-019-09334-y
   Díaz-Cortés MA, 2018, INFRARED PHYS TECHN, V93, P346, DOI 10.1016/j.infrared.2018.08.007
   El Jurdi R, 2020, IEEE J-STSP, V14, P1189, DOI 10.1109/JSTSP.2020.3001502
   Elaraby A, 2017, SCI IRAN, V24, P3247, DOI 10.24200/sci.2017.4359
   Fabbri R, 2012, PHYSICA A, V391, P4487, DOI 10.1016/j.physa.2012.05.001
   Feng YC, 2017, DIGIT SIGNAL PROCESS, V60, P186, DOI 10.1016/j.dsp.2016.08.003
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57
   He Y., 2021, arXiv
   HERTZ L, 1988, COMPUT VISION GRAPH, V44, P279, DOI 10.1016/0734-189X(88)90125-9
   Hu QM, 2006, IEEE T IMAGE PROCESS, V15, P228, DOI 10.1109/TIP.2005.860348
   Hu Y., 2018, ARXIV
   Jasim WN, 2021, J ELECTR COMPUT ENG
   Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Khashman A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1-6, P280
   KIRBY RL, 1979, IEEE T SYST MAN CYB, V9, P860
   Kumar D, 2020, SOFT COMPUT, V24, P4003, DOI 10.1007/s00500-019-04169-y
   Kumar N, 2018, MULTIMED TOOLS APPL, V77, P19139, DOI 10.1007/s11042-017-5329-y
   Lang CB, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030318
   Larabi-Marie-Sainte S, 2021, ELECTRONICS
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lei B, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106588
   Lei B, 2020, SOFT COMPUT, V24, P7305, DOI 10.1007/s00500-019-04351-2
   Leung CK, 1997, IEE P-VIS IMAGE SIGN, V144, P161, DOI 10.1049/ip-vis:19971181
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Li ZY, 2011, PATTERN ANAL APPL, V14, P109, DOI 10.1007/s10044-010-0184-8
   Lin QQ, 2012, SIGNAL PROCESS, V92, P2931, DOI 10.1016/j.sigpro.2012.05.025
   Liu D, 2006, PATTERN RECOGN LETT, V27, P1968, DOI 10.1016/j.patrec.2006.05.006
   Liu Q, 2019, PTB TIR THERMAL INFR
   Mahmoudi L, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTATIONAL TOOLS FOR ENGINEERING APPLICATIONS (ACTEA), P204, DOI 10.1109/ICTEA.2012.6462867
   Manda MP, 2021, TRAIT SIGNAL, V38, P1713, DOI 10.18280/ts.380614
   Manda MP, 2020, ALGORITHMS, V13, DOI 10.3390/a13090207
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Miezianko R, 2020, IEEE OTCBVS WS SERIE
   Mohanalin J, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING, P3, DOI 10.1109/ICSAP.2009.17
   Moreira Mello V, 2022, ENTROPY THRESHOLDING
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pare S, 2020, IJST-T ELECTR ENG, V44, P1, DOI 10.1007/s40998-019-00251-1
   Prasad M., 2013, J COMPUT APPL MATH, V70, P48
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Farshi TR, 2021, MULTIMEDIA SYST, V27, P125, DOI 10.1007/s00530-020-00716-y
   Rodrigues PS, 2017, PATTERN ANAL APPL, V20, P1, DOI 10.1007/s10044-015-0450-x
   Rodrigues PS, 2009, SIBGRAPI, P232, DOI 10.1109/SIBGRAPI.2009.23
   Rodrigues PS, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040430
   Sahoo P, 1997, PATTERN RECOGN, V30, P71, DOI 10.1016/S0031-3203(96)00065-9
   Salah Jrad Mael, 2016, 2016 2nd International Conference on Advanced Technologies for Signal and Image Processing (ATSIP), P319, DOI 10.1109/ATSIP.2016.7523099
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shokri M, 2003, CCECE 2003: CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, VOLS 1-3, PROCEEDINGS, P1231
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Sipos E, 2022, IEEE INT CONF AUTO, P119, DOI 10.1109/AQTR55203.2022.9802021
   Sparavigna A. C., 2015, International Journal of Sciences, V4, P40, DOI 10.18483/ijSci.613
   Thilagaraj M, 2019, CLUSTER COMPUT, V22, P15213, DOI 10.1007/s10586-018-2549-5
   Tizhoosh HR, 2005, PATTERN RECOGN, V38, P2363, DOI 10.1016/j.patcog.2005.02.014
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Tsallis C, 1999, BRAZ J PHYS, V29, P1, DOI 10.1590/S0103-97331999000100002
   Wachs-Lopes GA, 2020, COMMUN NONLINEAR SCI, V88, DOI 10.1016/j.cnsns.2020.105256
   WHATMOUGH RJ, 1991, CVGIP-GRAPH MODEL IM, V53, P592, DOI 10.1016/1049-9652(91)90009-9
   Wunnava A, 2020, ENG APPL ARTIF INTEL, V94, DOI 10.1016/j.engappai.2020.103836
   Xu Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232772
   Yao XQ, 2022, MATH EDUC RES J, V34, P241, DOI 10.1007/s13394-020-00343-w
   Yin SB, 2017, PATTERN RECOGN, V68, P245, DOI 10.1016/j.patcog.2017.03.012
   Zhang XL, 2015, ISPRS J PHOTOGRAMM, V102, P73, DOI 10.1016/j.isprsjprs.2015.01.009
NR 83
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43029
EP 43073
DI 10.1007/s11042-023-14978-x
EA APR 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000984450300007
DA 2024-07-18
ER

PT J
AU Heller, S
   Spiess, F
   Schuldt, H
AF Heller, Silvan
   Spiess, Florian
   Schuldt, Heiko
TI A tale of two interfaces: vitrivr at the lifelog search challenge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Lifelog retrieval; Lifelog search challenge; Interactive retrieval
   system evaluation; Virtual reality
AB The past decades have seen an exponential growth in the amount of data which is produced by individuals. Smartphones which capture images, videos and sensor data have become commonplace, and wearables for fitness and health are growing in popularity. Lifelog retrieval systems aim to aid users in finding and exploring their personal history. We present two systems for lifelog retrieval: vitrivr and vitrivr-VR, which share a common retrieval model and backend for multi-modal multimedia retrieval. They differ in the user interface component, where vitrivr relies on a traditional desktop-based user interface and vitrivr-VR has a Virtual Reality user interface. Their effectiveness is evaluated at the Lifelog Search Challenge 2021, which offers an opportunity for interactive retrieval systems to compete with a focus on textual descriptions of past events. Our results show that the conventional user interface outperformed the VR user interface. However, the format of the evaluation campaign does not provide enough data for a thorough assessment and thus to make robust statements about the difference between the systems. Thus, we conclude by making suggestions for future interactive evaluation campaigns which would enable further insights.
C1 [Heller, Silvan; Spiess, Florian; Schuldt, Heiko] Univ Basel, Dept Math & Comp Sci, Basel, Switzerland.
C3 University of Basel
RP Heller, S (corresponding author), Univ Basel, Dept Math & Comp Sci, Basel, Switzerland.
EM silvan.heller@unibas.ch; florian.spiess@unibas.ch;
   heiko.schuldt@unibas.ch
OI Schuldt, Heiko/0000-0001-9865-6371; Spiess, Florian/0000-0002-3396-1516
FU University of Basel
FX Open access funding provided by University of Basel
CR Ang WH, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P47, DOI 10.1145/3463948.3469070
   Barnes C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778826
   Cer D, 2018, Arxiv, DOI [arXiv:1803.11175, DOI 10.48550/ARXIV.1803.11175]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gasser R, 2019, Arxiv, DOI arXiv:1902.03878
   Gasser R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4465, DOI 10.1145/3394171.3414538
   Gasser R, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P391, DOI 10.1145/3323873.3326921
   Giangreco I, 2018, THESIS U BASEL, DOI [10.5451/unibas-006827345, DOI 10.5451/UNIBAS-006827345]
   Gurrin C., 2018, P 2018 ACM WORKSHOP, DOI [10.1145/3210539, DOI 10.1145/3210539]
   Gurrin C, 2019, ITE TRANS MEDIA TECH, V7, P46, DOI 10.3169/mta.7.46
   Heller Silvan, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P435, DOI 10.1007/978-3-030-67835-7_41
   Heller Silvan, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P1, DOI 10.1145/3379172.3391715
   Heller S, 2021, WORKSH LIF SEARCH CH
   Heller S, 2022, LECT NOTES COMPUT SC, V13142, P493, DOI 10.1007/978-3-030-98355-0_44
   Heller S, 2022, INT J MULTIMED INF R, V11, P1, DOI 10.1007/s13735-021-00225-2
   Heller S, 2020, IEEE INT CONF MULTI
   Hu R., 2020, COMPUTER VISION ECCV, P742
   Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lokoc J, 2022, MULTIMEDIA MODELING
   Lokoc J, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3445031
   Peterhans S, 2022, LECT NOTES COMPUT SC, V13541, P282, DOI 10.1007/978-3-031-16802-4_23
   Radford A, 2021, PR MACH LEARN RES, V139
   Rettig L, 2021, LECT NOTES COMPUT SC, V12706, P521, DOI 10.1007/978-3-030-74296-6_43
   Rossetto Luca, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P385, DOI 10.1007/978-3-030-67835-7_33
   Rossetto Luca, 2020, LSC '20: Proceedings of the Third Annual Workshop on Lifelog Search Challenge, P13, DOI 10.1145/3379172.3391717
   Rossetto L, 2016, LNCS, V9517, P336, DOI 10.1007/978-3-319-27674-8_30
   Rossetto L., 2018, THESIS U BASEL, DOI [10.5451/unibas-006859522, DOI 10.5451/UNIBAS-006859522]
   Rossetto L, 2021, IEEE MULTIMEDIA, V28, P18, DOI 10.1109/MMUL.2021.3066779
   Rossetto L, 2021, LSC '21: PROCEEDINGS OF THE 4TH ANNUAL LIFELOG SEARCH CHALLENGE, P7, DOI 10.1145/3463948.3469068
   Rossetto L, 2019, LSC '19 - PROCEEDINGS OF THE ACM WORKSHOP ON LIFELONG SEARCH CHALLENGE, P27, DOI 10.1145/3326460.3329160
   Rossetto L, 2019, LECT NOTES COMPUT SC, V11296, P616, DOI 10.1007/978-3-030-05716-9_55
   Rossetto L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1183, DOI 10.1145/2964284.2973797
   Rossetto L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P18, DOI 10.1109/ISM.2014.38
   Sauter Loris, 2022, IMuR '22: Proceedings of the 2nd International Workshop on Interactive Multimedia Retrieval, P33, DOI 10.1145/3552467.3554797
   Sauter L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P187, DOI 10.1109/AIVR.2018.00041
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Spiess F, 2021, WORKSH LIF SEARCH CH
   Spiess F, 2022, LECT NOTES COMPUT SC, V13142, P499, DOI 10.1007/978-3-030-98355-0_45
   Spolaôr N, 2021, MULTIMED TOOLS APPL, V80, P33971, DOI 10.1007/s11042-021-11401-1
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Theus A, 2022, LECT NOTES COMPUT SC, V13142, P182, DOI 10.1007/978-3-030-98355-0_16
   Wang X, 2019, IEEE I CONF COMP VIS, P4580, DOI 10.1109/ICCV.2019.00468
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 46
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 APR 6
PY 2023
DI 10.1007/s11042-023-15082-w
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C9IT9
UT WOS:000964979100003
PM 37799145
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Lazzez, O
   Qahtani, AM
   Alsufyani, A
   Almutiry, O
   Dhahri, H
   Piuri, V
   Alimi, AM
AF Lazzez, Onsa
   Qahtani, Abdulrahman M.
   Alsufyani, Abdulmajeed
   Almutiry, Omar
   Dhahri, Habib
   Piuri, Vincenzo
   Alimi, Adel M.
TI DeepVisInterests : deep data analysis for topics of interest prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep data analysis; Convolutional neural networks; Online social
   networks; Deep learning; Ontology; Users' interest
ID USERS
AB Deep data analysis for latent information prediction has become an increasingly important area of research. In order to predict users' interests and other latent attributes, most of the existing solutions (works, studies) have used textual data and have obtained accurate results. However, little attention has been paid to visual data that have become increasingly popular in recent years. This paper addresses the problem of discovering the attributed interests and analyzing the performance of the automatic prediction by a comparison with the self-assessed topics of interests (topics of interests provided by the user in a proposed questionnaire) based on data analysis techniques applied to users' visual data. We analyze the content of individual images and aggregate the image-level information to predict user-level interest distribution. Thus, we employ a Convolutional Neural Network architecture pre-trained on ImageNet dataset for feature extraction. The suggested system is based on the construction of users' interests ontology in order to learn the semantic representation for the popular Topics of interests defined by social networks (e.g., Facebook). Our experiments show that the analysis enhances the overall prediction performance. We set forth a novel evaluation database to improve our framework's robustness and enhance its ability to generalize to new user profiles. Our proposed framework has shown promising results. Our method yields a competitive accuracy of 0.80 compared with the state of the art techniques.
C1 [Lazzez, Onsa; Alimi, Adel M.] Univ Sfax, REGIM Lab Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
   [Qahtani, Abdulrahman M.; Alsufyani, Abdulmajeed] Taif Univ, Coll Comp & Informat Technolgy, Dept Comp Sci, POB 11099, Taif 21944, Saudi Arabia.
   [Almutiry, Omar; Dhahri, Habib] King Saud Univ, Coll Appl Comp Sci, Almuzahmiyah Campus, Riyadh, Saudi Arabia.
   [Piuri, Vincenzo] Univ Milan, Dept Informat, I-20133 Milan, Italy.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Taif University; King Saud University; University of
   Milan; University of Johannesburg
RP Lazzez, O (corresponding author), Univ Sfax, REGIM Lab Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM onsa.lazzez@enis.tn; amqahtani@tu.edu.sa; a.s.alsufyani@tu.edu.sa;
   oalmutiry@ksu.edu.sa; habib.dhahri@ieee.org; vincenzo.piuri@unimi.it;
   adel.alimi@enis.tn
RI Alimi, Adel M./A-5697-2012; Dhahri, Habib/L-7833-2018; Alsufyani,
   abdulmajeed/AGG-9038-2022
OI Alimi, Adel M./0000-0002-0642-3384; Alsufyani,
   abdulmajeed/0000-0001-6110-3642
FU Taif University [LR11ES48]; Taif University Researchers Supporting
   Project, Taif University, Taif, Saudi Arabia; Ministry of Higher
   Education and Scientific Research of Tunisia [TURSP-2020/115]
FX We deeply acknowledge Taif University for Supporting this study through
   Taif University Researchers Supporting Project number (TURSP-2020/115),
   Taif University, Taif, Saudi Arabia. The research leading to these
   results has received fund-ing from the Ministry of Higher Education and
   Scientific Research of Tunisia under the grant agreement number
   LR11ES48.
CR Alam F, 2021, SOCIAL MEDIA IMAGES
   Alpaydin E., 2020, INTRO MACHINE LEARNI, DOI DOI 10.7551/MITPRESS/13811.001.0001
   Chen CT, 2017, KNOWL-BASED SYST, V126, P1, DOI 10.1016/j.knosys.2017.04.006
   Chung TL, 2021, COMPUT HUM BEHAV, V115, DOI 10.1016/j.chb.2020.106623
   DAgostino G, 2016, PHYSICA A, P443
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dinh XT, 2020, P 4 INT C MACH LEARN, P14
   Faralli S, 2017, J WEB SEMANT, V45, P23, DOI 10.1016/j.websem.2017.05.004
   Gharibshah Z, 2020, DATA SCI ENG J
   Hohenecker Patrick, 2017, ARXIV
   Hong T, 2020, CONCURR COMP-PRACT E, P4163
   Huang CJ, 2019, COMPUT HUM BEHAV, V97, P280, DOI 10.1016/j.chb.2019.03.009
   Jia Y, 2023, CAFFE CONVOLUTIONAL
   Kaur K, 2016, 2016 INT C COMP TECH, P10
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazzez O, 2017, ADV INTELL SYST, V552, P527, DOI 10.1007/978-3-319-52941-7_52
   LeCun Y, 2000, P COMP VIS PATT REC
   Lewenberg Y., 2015, 2015 IEEE INT C DATA, P1
   Li JX, 2018, NEUROCOMPUTING, V278, P87, DOI 10.1016/j.neucom.2017.04.078
   Li L-J, 2017, P INT C COMPUTER VIS
   Li L-J, 2010, IEEE INT C COMPUTER
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Liu Z, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511342
   Lourdusamy R, 2020, 2018 2 INT C INV SYS
   Lovato P, 2013, IEEE IMAGE PROC, P2892, DOI 10.1109/ICIP.2013.6738595
   Malviya N, 2012, INT J SCI ENG RES, V2
   McDaniel M, 2018, 2007 ASIA PACIFIC C
   Musto C, 2018, MULTICRITERIA RECOMM
   Ouarda W, 2016, J INF ASSUR SECUR, V11, P201
   Rich J, 2016, DH'16: PROCEEDINGS OF THE 2016 DIGITAL HEALTH CONFERENCE, P111, DOI 10.1145/2896338.2897734
   Segalin C, 2014, DATA KNOWL ENG
   Shen HY, 2017, IEEE T SYST MAN CY-S, V47, P3363, DOI 10.1109/TSMC.2016.2580606
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wu B., 2010, INFOCOM IEEE Conference on Computer Communications Workshops , 2010, P1
   Yang C, 2019, 2019 IEEE INT C AC S, P10
   Yang C, 2013, P 21 ACM INT C MULT, P5
   Yang C, 2016, NEUROCOMPUTING, V210, P185, DOI 10.1016/j.neucom.2015.12.136
   Yang L, 2017, CLASSIFICATION LATEN
   You Q, 2018, PICTURE TELLS 1000 W
   Zareie A, 2019, INFORM SCIENCES, V493, P217, DOI 10.1016/j.ins.2019.04.033
   Zarrinkalam F, 2019, INFORM RETRIEVAL J, V22, P93, DOI 10.1007/s10791-018-9337-y
   Zarrinkalam F, 2018, INFORM PROCESS MANAG, V54, P339, DOI 10.1016/j.ipm.2017.12.003
   Zhou GR, 2019, AAAI CONF ARTIF INTE, P5941
   Zhu H, 2017, TSINGHUA SCI TECHNOL, V22, P254
NR 45
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40913
EP 40936
DI 10.1007/s11042-023-14806-2
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rahman, WU
   Huh, EN
AF ur Rahman, Waqas
   Huh, Eui-Nam
TI Content-aware QoE optimization in MEC-assisted Mobile video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; HTTP-based video streaming; Adaptive streaming;
   Quality of experience; Streaming media
ID RATE ADAPTATION; QUALITY
AB The traditional client-based HTTP adaptation strategies do not explicitly coordinate between the clients, servers, and cellular networks. A lack of coordination leads to suboptimal user experience. In addition to optimizing Quality of Experience (QoE), other challenges in adapting HTTP adaptive streaming (HAS) to the cellular environment are overcoming unfair allocation of the video rate and inefficient utilization of the bandwidth under the high-dynamics cellular links. Furthermore, the majority of the adaptive strategies ignore important video content characteristics and HAS client information, such as segment duration, buffer size, and video duration, in the video quality selection process. In this paper, we present a content-aware hybrid multi-access edge computing (MEC)-assisted quality adaptation algorithm by taking advantage of the capabilities of edge cloud computing. The proposed algorithm exploits video content characteristics, HAS client settings, and application-layer information to jointly adapt the bitrates of multiple clients. We design separate strategies to optimize the performance of short and long duration videos. We then demonstrate the efficiency of our algorithm against client-based solutions as well as MEC-assisted algorithms. The proposed algorithm guarantees high QoE, equitably selects video rates for clients, and efficiently utilizes the bandwidth for both short and long duration videos. The results from our extensive experiments reveal that the proposed long video adaptation algorithm outperforms state-of-the-art algorithms, with improvements in average video rate, QoE, fairness, and bandwidth utilization of 0.4%-12.3%, 8%-65%, 3.3%-5.7%, and 60%-130%, respectively. Furthermore, when high bandwidth is available to competing clients, the proposed short video adaptation algorithm improves QoE by 11.1% compared to the long video adaptation algorithm.
C1 [ur Rahman, Waqas] Birmingham City Univ, Sch Comp & Digital Technol, Digital Media Technol Lab, Birmingham, England.
   [Huh, Eui-Nam] Kyung Hee Univ, Dept Comp Sci & Engn, Elect & Informat Bldg,Room 331,1732 Deogyeong Daer, Yongin 17104, Gyeonggi Do, South Korea.
C3 Birmingham City University; Kyung Hee University
RP Huh, EN (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Elect & Informat Bldg,Room 331,1732 Deogyeong Daer, Yongin 17104, Gyeonggi Do, South Korea.
EM johnhuh@khu.ac.kr
RI Rahman, Waqas ur/X-4387-2019
OI Rahman, Waqas ur/0000-0002-3849-6596
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) - Korea government (MSIT) [2202-0-00047]
FX This work was partly supported by Institute of Information &
   communications Technology Planning & Evaluation (IITP) grant funded by
   the Korea government (MSIT)(No.2202-0-00047, Development of
   Microservices Development/Operation Platform Technology that Supports
   Application Service Operation Intelligence).Data availability statement
   The datasets generated during and/or analysed during the current study
   are available from the corresponding author on reasonable request.
CR Aggarwal V, 2011, WRKS LOC METRO AREA
   Aguilar-Armijo Jesus, 2021, 2021 IEEE 46th Conference on Local Computer Networks (LCN), P487, DOI 10.1109/LCN52139.2021.9524883
   [Anonymous], 2013, 26247 3GPP TS
   [Anonymous], CONF HTTP DYN STREAM
   [Anonymous], 2017, LONG IS AVERAGE MOVI
   [Anonymous], 2019, IS SHORTER VIDEO LEN
   Azumi M, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417622
   Che XH, 2015, IEEE MULTIMEDIA, V22, P56, DOI 10.1109/MMUL.2015.34
   Chen J., 2013, Proceedings of the 19th Annual International Conference on Mobile Computing Networking, P389
   cisco, CISC VIS NETW IND GL
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   dash mse test appspot, MPEG DASH MEDIA SOU
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Egger Sebastian., 2014, Proceedings of the 2014 Workshop on Design, Quality and Deployment of Adaptive Video Streaming, P31
   Farahani R, 2021, PROCEEDINGS OF THE 31ST ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV '21), P51, DOI 10.1145/3458306.3460997
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Joseph V, 2014, IEEE INFOCOM SER, P82, DOI 10.1109/INFOCOM.2014.6847927
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Kim M., 2020, IEEE ACCESS, V25, P2142
   Le HT, 2018, SIGNAL PROCESS-IMAGE, V65, P154, DOI 10.1016/j.image.2018.03.014
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Li ZR, 2013, 2013 5TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY (IC-BNMT), P1, DOI 10.1109/ICBNMT.2013.6823903
   Mehrabi A, 2019, IEEE T MOBILE COMPUT, V18, P787, DOI 10.1109/TMC.2018.2850026
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Muller C., 2012, 4th ACM Workshop on Mobile Video (MoVID), P37, DOI DOI 10.1145/2151677.2151686
   Ni P., 2011, P 19 ACM INT C MULT, P463, DOI DOI 10.1145/2072298.2072359
   Petrangeli S, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818361
   Physical layer aspect for evolved Universal Terrestrial Radio Access (UTRA), 2008, WG1R1081483 3GPP TSG
   Rahman WU, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103415
   Rahman WU, 2019, IEEE ACCESS, V7, P129082, DOI 10.1109/ACCESS.2019.2940292
   Rahman WU, 2018, MULTIMEDIA SYST, V24, P509, DOI 10.1007/s00530-018-0588-7
   Rahman WU, 2017, J VIS COMMUN IMAGE R, V49, P433, DOI 10.1016/j.jvcir.2017.10.007
   Rajendra J., 1984, QUANTITATIVE MEASURE
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shen Y, 2015, IEICE T COMMUN, VE98B, P62, DOI 10.1587/transcom.E98.B.62
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   statistics, ε-ELSTAT
   Sun Y, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P272, DOI 10.1145/2934872.2934898
   Tran TX, 2017, 2017 13TH ANNUAL CONFERENCE ON WIRELESS ON-DEMAND NETWORK SYSTEMS AND SERVICES (WONS), P165, DOI 10.1109/WONS.2017.7888772
   Yang SR, 2019, IEEE T VEH TECHNOL, V68, P1888, DOI 10.1109/TVT.2018.2889196
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Yu J, 2022, IEEE WIRELESS COMMUN
   yumyumvideos, SHORT VS LONG VIDEO
   Zambelli Alex., 2009, IIS Smooth Streaming Technical Overview
   Zhao MC, 2015, IEEE T CIRC SYST VID, V25, P451, DOI 10.1109/TCSVT.2014.2357094
NR 48
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42053
EP 42085
DI 10.1007/s11042-023-15163-w
EA APR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000983404900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Jabberi, M
   Wali, A
   Chaudhuri, BB
   Alimi, AM
AF Jabberi, Marwa
   Wali, Ali
   Chaudhuri, Bidyut Baran
   Alimi, Adel M.
TI 68 landmarks are efficient for 3D face alignment: what about more? 3D
   face alignment method applied to face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; 3D face alignment; Deep learning; DCNNs; Feature
   extraction; 3D mesh reconstruction; 3D mesh preprocessing
ID ALGORITHM; SYSTEM
AB This paper proposes a 3D face alignment of 2D face images in the wild with noisy landmarks. The objective is to recognize individuals from their single profile image. We first proceed by extracting more than 68 landmarks using a bag of features. This allows us to obtain a bag of visible and invisible facial keypoints. Then, we reconstruct a 3D face model and get a triangular mesh by meshing the obtained keypoints. For each face, the number of keypoints is not the same, which makes this step very challenging. Later, we process the 3D face using butterfly and BPA algorithms to make correlation and regularity between 3D face regions. Indeed, 2D-to-3D annotations give much higher quality to the 3D reconstructed face model without the need for any additional 3D Morphable models. Finally, we carry out alignment and pose correction steps to get frontal pose by fitting the rendered 3D reconstructed face to 2D face and performing pose normalization to achieve good rates in face recognition. The recognition step is based on deep learning and it is performed using DCNNs, which are very powerful and modern, for feature learning and face identification. To verify the proposed method, three popular benchmarks, YTF, LFW, and BIWI databases, are tested. Compared to the best recognition results reported on these benchmarks, our proposed method achieves comparable or even better recognition performances.
C1 [Jabberi, Marwa] Univ Sousse, ISITCom, Sousse 4011, Tunisia.
   [Jabberi, Marwa; Wali, Ali; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax ENIS, Res Grp Intelligent Machines REGIM Lab, 1173, Sfax 3038, Tunisia.
   [Chaudhuri, Bidyut Baran] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata 700108, India.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sousse; Universite de Sfax; Ecole Nationale dIngenieurs de
   Sfax (ENIS); Indian Statistical Institute; Indian Statistical Institute
   Kolkata; University of Johannesburg
RP Jabberi, M (corresponding author), Univ Sousse, ISITCom, Sousse 4011, Tunisia.; Jabberi, M (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, Res Grp Intelligent Machines REGIM Lab, 1173, Sfax 3038, Tunisia.
EM marwa.jabberi@regim.usf.tn; ali.wali@isims.usf.tn; bbc@isical.ac.in;
   adel.alimi@regim.usf.tn
RI Wali, Ali/J-7961-2012; Alimi, Adel M./A-5697-2012
OI Wali, Ali/0000-0002-8423-7923; Alimi, Adel M./0000-0002-0642-3384;
   Jabberi, Marwa/0000-0001-5930-2597
FU Ministry of Higher Education and Scientific Research of Tunisia
   [LR11ES48]
FX AcknowledgementsThe research leading to these results has received
   funding from the Ministry of Higher Education and Scientific Research of
   Tunisia under the grant agreement number LR11ES48.
CR Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   An ZF, 2019, IEEE ACCESS, V7, P14653, DOI 10.1109/ACCESS.2019.2894162
   Anwarul S, 2020, LECT NOTES ELECTR EN, V597, P495, DOI 10.1007/978-3-030-29407-6_36
   Arigbabu OA, 2017, ARXIV
   Barra P, 2020, IEEE T IMAGE PROCESS, V29, P5457, DOI 10.1109/TIP.2020.2984373
   Beksi WJ, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1079, DOI 10.1109/IROS.2016.7759183
   Benmohamed A, 2015, MULTIMED TOOLS APPL, V74, P9297, DOI 10.1007/s11042-014-2082-3
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P35973, DOI 10.1007/s11042-020-10160-9
   Bisogni Carmen, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P173, DOI 10.1109/TBIOM.2021.3122307
   Boissonnat JD, 2018, FOUND COMPUT MATH, V18, P399, DOI 10.1007/s10208-017-9344-1
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Browatzki B, 2020, PROC CVPR IEEE, P6109, DOI 10.1109/CVPR42600.2020.00615
   Bruckstein AM, 1999, INT J COMPUT VISION, V35, P223, DOI 10.1023/A:1008156210387
   Cao J, 2018, ADV NEUR IN, V31
   Chandrakala M, 2021, INT C SOFT COMP SIGN
   Chou KP, 2021, MULTIMED TOOLS APPL, V80, P16635, DOI 10.1007/s11042-020-09216-7
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cui JY, 2018, INT CONF BIOMETR, P140, DOI 10.1109/ICB2018.2018.00031
   Dapogny A, 2019, IEEE I CONF COMP VIS, P6892, DOI 10.1109/ICCV.2019.00699
   Deeba F, 2019, INT J ADV COMPUT SC, V10, P274
   Ding L, 2012, IEEE SIGNAL PROC LET, V19, P721, DOI 10.1109/LSP.2012.2215586
   Dkhil MB, 2018, ARXIV
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fard AP, 2021, IEEE COMPUT SOC CONF, P1521, DOI 10.1109/CVPRW53098.2021.00168
   Fdhila R, 2016, J INF ASSUR SECUR, V11, P385
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gao F, 2021, NEURAL COMPUT APPL, V33, P3035, DOI 10.1007/s00521-020-05167-0
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hocine Elaggoune, 2021, 2021 1 INT C CYB MAN
   Huang G.B., 2014, LABELED FACES WILD U
   Huang YS, 2015, IEEE IMAGE PROC, P3106, DOI 10.1109/ICIP.2015.7351375
   Huber P, 2016, INT C COMP VIS THEOR, V5
   Islem J, 2017, PROC SPIE, V10341
   Jabberi M, 2023, Inter Con Info Netwo, P242, DOI 10.1109/ICOIN56518.2023.10049052
   Jarraya I, 2021, BIOMETRIC SYSTEM
   Jeni LA, 2016, LECT NOTES COMPUT SC, V9914, P511, DOI 10.1007/978-3-319-48881-3_35
   Jiang LS, 2019, IEEE ICC
   Jing XY, 2006, PATTERN RECOGN, V39, P707, DOI 10.1016/j.patcog.2005.10.020
   Kang J, 2021, IEEE T SYST MAN CY-S
   Kapoutsis CA, 1999, IEEE T IMAGE PROCESS, V8, P1644, DOI 10.1109/83.799892
   Kar A, 2020, APPL INTELL, V50, P698, DOI 10.1007/s10489-019-01545-x
   Karakas S, 2022, MINIM INVASIV THER, V31, P803, DOI 10.1080/13645706.2021.2025111
   Kas M, 2020, MULTIMED TOOLS APPL, V79, P375, DOI 10.1007/s11042-019-08049-3
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Khan Maliha, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P116, DOI 10.1109/ICCCIS48478.2019.8974493
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Abhinav, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8233, DOI 10.1109/CVPR42600.2020.00826
   Li D, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P477, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.76
   Li Y, 2021, J PHYS C SERIES, V1757
   Ling HF, 2020, MULTIMED TOOLS APPL, V79, P5595, DOI 10.1007/s11042-019-08422-2
   Liu F, 2020, IEEE T PATTERN ANAL, V42, P664, DOI 10.1109/TPAMI.2018.2885995
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu YX, 2003, COMPUT VIS IMAGE UND, V91, P138, DOI 10.1016/S1077-3142(03)00078-X
   Mandal C, 2000, IEEE T VIS COMPUT GR, V6, P265, DOI 10.1109/2945.879787
   Moujahid A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114334
   Muqeet Mohd Abdul, 2019, Applied Computing and Informatics, V15, P163, DOI 10.1016/j.aci.2017.11.002
   Mutneja V, 2019, J REAL-TIME IMAGE PR, V16, P1573, DOI 10.1007/s11554-017-0667-6
   Napoléon T, 2014, PROC SPIE, V9094, DOI 10.1117/12.2051267
   Ning X, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.6147
   Oloyede MO, 2020, MULTIMED TOOLS APPL, V79, P27891, DOI 10.1007/s11042-020-09261-2
   Pandaya J.M., 2013, International Journal of Engineering Research and Applications, P632
   Rao KS., 2005, EURASIP J ADV SIG PR, V2005, P1
   Rao YM, 2017, IEEE I CONF COMP VIS, P3801, DOI 10.1109/ICCV.2017.408
   Ruan ZY, 2021, IEEE T IMAGE PROCESS, V30, P5793, DOI 10.1109/TIP.2021.3087397
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Shah JH, 2013, INT ARAB J INF TECHN, V10, P536
   Shan Shiguang, 2002, 2002 IEEE INT S CIRC, V2
   Sharif M, 2017, J ENG SCI TECHNOL RE, V10
   Sharkas M, 2008, INT CONF SIGN PROCES, P914, DOI 10.1109/ICOSP.2008.4697276
   Shi L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040759
   Sluzek A, 2016, LECT NOTES COMPUT SC, V9915, P759, DOI 10.1007/978-3-319-49409-8_63
   Soltanpour S, 2017, PATTERN RECOGN, V72, P391, DOI 10.1016/j.patcog.2017.08.003
   Sun B, 2019, ARXIV
   Sun HL, 2017, PROC CVPR IEEE, P6240, DOI 10.1109/CVPR.2017.661
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang FG, 2020, OPTIK, V205, DOI 10.1016/j.ijleo.2020.164238
   Tang WJ, 2017, MULTIMED TOOLS APPL, V76, P22725, DOI 10.1007/s11042-017-4343-4
   Tarini M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925898
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thomas Heseltine, 2004, INT C IM AN REC
   Tu X, 2019, NAT COMMUN, V1
   Turk M, 2005, FACE PROCESS ADV MOD, P55
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Vinay A, 2015, PROCEDIA COMPUT SCI, V70, P185, DOI 10.1016/j.procs.2015.10.070
   Vit P., 2016, International Journal of Signal Processing, Image Processing and Pattern Recognition, V9, P143
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang YQ, 2014, IMAGE PROCESS ON LIN, V4, P128, DOI 10.5201/ipol.2014.104
   Wang YX, 2021, MULTIMED TOOLS APPL, V80, P25271, DOI 10.1007/s11042-021-10872-6
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zhao K, 2019, PROC CVPR IEEE, P1136, DOI 10.1109/CVPR.2019.00123
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
   Zou GF, 2020, MULTIMED TOOLS APPL, V79, P23571, DOI 10.1007/s11042-020-09076-1
NR 101
TC 2
Z9 2
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41435
EP 41469
DI 10.1007/s11042-023-14770-x
EA APR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000961747500006
PM 37362713
OA Green Published, Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Mashhadi, S
   Saeedi, Z
AF Mashhadi, Samaneh
   Saeedi, Zahra
TI A (<i>t</i>,<i>n</i>)- Secret image sharing with steganography based on
   Rook polynomial and LWE problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Rook polynomial; Lattice-based cryptography;
   Learning with errors; Steganography
ID SCHEME; AUTHENTICATION
AB In a meaningful secret image sharing scheme with authentication, an image is distributed among the participants without raising adversaries suspicion. Additionally the cheats of the dealer and participants in the reconstruction of the image are discoverable, which means that the integration of the shares is verifiable. In this paper, we propose a novel meaningful secret image sharing with authentication property based on learning with errors problem and rook polynomial. Compared with the previous schemes, it has a higher embedding rate and a better visual quality.
C1 [Mashhadi, Samaneh; Saeedi, Zahra] Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
C3 Iran University Science & Technology
RP Mashhadi, S (corresponding author), Iran Univ Sci & Technol, Sch Math, Cryptog & Data Secur Lab, Tehran 1684613114, Iran.
EM smashhadi@iust.ac.ir
RI mashhadi, samaneh/ISV-0962-2023
OI mashhadi, samaneh/0000-0001-9191-1376; saeidi, zahra/0000-0002-5236-2068
CR Ahmadian AM, 2019, SIGNAL PROCESS-IMAGE, V74, P78, DOI 10.1016/j.image.2019.01.006
   Chang Ch-Ch., 2014, J INF HIDING MULTIME, V5, P342
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133802
   Charoghchi S, 2021, INFORM SCIENCES, V552, P220, DOI 10.1016/j.ins.2020.11.034
   Chen Ch-Ch., 2016, J INF HIDING MULTIME, V7, P135
   Chen SS, 2021, IEEE ACCESS, V9, P116427, DOI 10.1109/ACCESS.2021.3105590
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Gao K, 2021, IEEE ACCESS, V9, P50112, DOI 10.1109/ACCESS.2021.3069008
   Guo YZ, 2019, IEEE ACCESS, V7, P73782, DOI 10.1109/ACCESS.2019.2919294
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Kanso A, 2017, MULTIMED TOOLS APPL, V76, P16369, DOI 10.1007/s11042-016-3917-x
   Knospe H, 2019, A course in cryptography
   Lee CW, 2013, SIGNAL PROCESS, V93, P2010, DOI 10.1016/j.sigpro.2013.01.009
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1, DOI 10.1007/s11042-015-3011-9
   Li XX, 2019, INT J PHOTOENERGY, V2019, DOI 10.1155/2019/3725364
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101236
   Liu Q, 2022, IEEE T CIRC SYST VID, V32, P4038, DOI 10.1109/TCSVT.2021.3108772
   Liu Y-X, 2018, IRONMAK STEELMAK
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Maan VK., 2013, Int J Eng Res Technol, V2, P421
   Meng KJ, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116221
   Riordan J., 1980, Introduction to Combinatorial Analysis, DOI DOI 10.1515/9781400854332
   Sardar M.K., 2020, J. Vis. Commun. Image Represent, V68, DOI [10.1016/j.jvcir.2020.102768, DOI 10.1016/J.JVCIR.2020.102768]
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shiu PF, 2019, SIGNAL PROCESS-IMAGE, V74, P64, DOI 10.1016/j.image.2019.01.003
   Singh P, 2018, INFORM SCIENCES, V422, P77, DOI 10.1016/j.ins.2017.08.077
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Strang G., 2016, INTRO LINEAR ALGEBRA
   Teng Guo, 2013, Information and Communications Security. 15th International Conference, ICICS 2013. Proceedings: LNCS 8233, P404, DOI 10.1007/978-3-319-02726-5_29
   Wang Z-H., 2014, PLOS ONE, V5, P47
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Xiong LZ, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108064
   Xiong LZ, 2021, IEEE T INF FOREN SEC, V16, P2912, DOI 10.1109/TIFS.2021.3065794
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yan XH, 2021, INFORM SCIENCES, V562, P475, DOI 10.1016/j.ins.2021.03.029
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, IEEE SIGNAL PROC LET, V19, P789, DOI 10.1109/LSP.2012.2220348
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
   Zhou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070249
   Zhu LY, 2022, IEEE T CIRC SYST VID, V32, P4052, DOI 10.1109/TCSVT.2021.3107342
NR 48
TC 4
Z9 4
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39077
EP 39097
DI 10.1007/s11042-023-15016-6
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000983783100011
DA 2024-07-18
ER

PT J
AU Islam, MA
   Hassan, MR
   Uddin, M
   Shajalal, M
AF Islam, Mohammad Aminul
   Hassan, Md. Rakib
   Uddin, Machbah
   Shajalal, Md
TI Germinative paddy seed identification using deep convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Germinative seed; Paddy identification; Image processing; Image
   normalization; CNN; Deep learning
ID CLASSIFICATION
AB Paddy has been the staple food of millions of people and due to its rising demand, it is imperative to increase paddy crop yield within the limited availability of land. Paddy yield depends on many factors and one of the significant factors is the quality of germinative seed. However, the traditional methods for selecting quality germinative seeds are expensive and time-consuming. Therefore, automatic detection of germinative seeds using non-destructive techniques is unavoidable. Few methods exist for the identification of germinative paddy seeds. However, these methods suffered from low-accuracy and precision rates because the methods only depends on hand-crafted and classical features. In this research, we propose a novel framework to identify germinative seeds applying deep convolutional neural network (CNN). We collected paddy seeds' images using a smartphone in open environment. However, acquiring images in open environment can lead to illumination, orientation, and scale-related challenges, which might hinder model performance. Therefore, we addressed the illumination problem by converting the images into HSV format and applying the image normalization technique to handle scale and orientation challenges. We also address the overfitting problem by deriving an optimal set of parameters by tuning the hyperparameters of the model. The experimental results on a dataset consisting of three paddy varieties: BRRI 36, BRRI 49, and BRRI 52 demonstrated that our proposed framework achieved high accuracy (99.50%) in identifying germinative paddy seeds. We also compare the performance of our model applying different pre-trained transfer learning techniques (googlenet, alexnet, resnet50, and resnet101) and an existing traditional feature-based technique, RSGES. Our proposed model significantly outperforms the transfer learning techniques and RSGES for all the datasets in terms of all evaluation metrics. Hence, this model can be integrated in the industry and farmer level as a non-destructive method for identifying germinative paddy seeds.
C1 [Islam, Mohammad Aminul; Hassan, Md. Rakib; Uddin, Machbah] Bangladesh Agr Univ, Dept Comp Sci & Math, Mymensingh 2202, Bangladesh.
   [Islam, Mohammad Aminul] Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld, Australia.
   [Shajalal, Md] Hajee Mohammad Danesh Sci & Technol Univ, Dept Comp Sci & Engn, Dinajpur 5200, Bangladesh.
   [Shajalal, Md] Fraunhofer Inst Adv Informat Technol FIT, D-53757 St Augustin, Germany.
C3 Bangladesh Agricultural University (BAU); Griffith University
RP Islam, MA (corresponding author), Bangladesh Agr Univ, Dept Comp Sci & Math, Mymensingh 2202, Bangladesh.; Islam, MA (corresponding author), Griffith Univ, Sch Informat & Commun Technol, Brisbane, Qld, Australia.
EM amin@bau.edu.bd; rakib@bau.edu.bd; machbah.csm@bau.edu.bd;
   shajalal@hstu.ac.bd
RI Shajalal, Md/AAK-7103-2020; Uddin, Machbah/ADI-4535-2022; Islam,
   Mohammad Aminul/KCY-5804-2024
OI Shajalal, Md/0000-0002-9011-708X; UDDIN, MACHBAH/0000-0002-1572-8606;
   Islam, Mohammad Aminul/0000-0002-5809-552X
CR Aakif A, 2015, BIOSYST ENG, V139, P66, DOI 10.1016/j.biosystemseng.2015.08.003
   Akhter R, 2022, J KING SAUD UNIV-COM, V34, P5602, DOI 10.1016/j.jksuci.2021.05.013
   Akinbile C. O., 2012, Trends in Applied Sciences Research, V7, P331, DOI 10.3923/tasr.2012.331.349
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   Anami Basavaraj S., 2019, Information Processing in Agriculture, V6, P47, DOI 10.1016/j.inpa.2018.09.001
   Ansari N, 2021, J AGR FOOD RES, V3, DOI 10.1016/j.jafr.2021.100109
   Bernardes RC, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12111801
   Chandio AA, 2021, TECHNOL SOC, V66, DOI 10.1016/j.techsoc.2021.101607
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Cheng MH, 2022, AGR WATER MANAGE, V264, DOI 10.1016/j.agwat.2022.107530
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Cordeiro M, 2022, FUTURE GENER COMP SY, V129, P115, DOI 10.1016/j.future.2021.11.013
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Durando Stefano, 2022, 2022 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI 10.1109/NSS/MIC44845.2022.10398961
   Farooq M, 2009, SUSTAIN AGR REV, V1, P137, DOI 10.1007/978-1-4020-9654-9_9
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Duong HT, 2019, PROCEEDINGS OF THE 2019 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (INCIT), P199, DOI [10.1109/incit.2019.8912121, 10.1109/INCIT.2019.8912121]
   Jaithavil D., 2022, 2022 INT ELECT ENG C, P1
   Kabir M., 2016, Bangladesh Rice Journal, V19, P1, DOI DOI 10.3329/BRJ.V19I2.28160
   Kalaivani S, 2020, MULTIMED TOOLS APPL, V79, P9145, DOI 10.1007/s11042-018-7126-7
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P25763, DOI 10.1007/s11042-020-09244-3
   Khan MA, 2020, MULTIMED TOOLS APPL, V79, P18627, DOI 10.1007/s11042-020-08726-8
   Khazaei J, 2016, INT J FOOD PROP, V19, P1227, DOI 10.1080/10942912.2015.1071839
   Khoenkaw Paween., 2017, P 2016 INT COMP SCI, P2, DOI 10. 1109/ICSEC.2016.7859890
   Kobata T, 2010, PLANT PROD SCI, V13, P289, DOI 10.1626/pps.13.289
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lurstwut B., 2016, INT J COMPUT APPL TE, V5, P176
   Lurstwut Benjamaporn, 2017, Agriculture and Natural Resources, V51, P383, DOI 10.1016/j.anres.2017.12.002
   Moussafir M, 2022, PLANT SOIL, V479, P251, DOI 10.1007/s11104-022-05513-2
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Nguyen-Quoc H., 2020, TELKOMNIKA, V18, P1897
   Oikonomidis A, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2031823
   Onmankhong J, 2022, INFRARED PHYS TECHN, V123, DOI 10.1016/j.infrared.2022.104100
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Hong PTT, 2015, 2015 SEVENTH INTERNATIONAL CONFERENCE ON KNOWLEDGE AND SYSTEMS ENGINEERING (KSE), P377, DOI 10.1109/KSE.2015.46
   Subramanian M, 2022, NEURAL COMPUT APPL, V34, P13951, DOI 10.1007/s00521-022-07246-w
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Truong Hoang V., 2020, ECTI Transactions on Computer and Information Technology (ECTI-CIT), V14, P1, DOI 10.37936/ecti-cit.2020141.204170
   Uddin M.K., 2022, IEEE T SERV COMPUT, P1, DOI [10.1080/15226514.2022.2086214, DOI 10.1109/TSC.2022.3187962]
   Uddin M, 2022, COMPLEX INTELL SYST, V8, P657, DOI 10.1007/s40747-021-00545-0
   Vaishnnave M., 2022, Artificial Intelligent Techniques for Wireless Communication and Networking, P47, DOI DOI 10.1002/9781119821809.CH4
   Wang L, 2022, COMPUT ELECTRON AGR, V192, DOI 10.1016/j.compag.2021.106623
   Yu HL, 2022, COMPUT ELECTRON AGR, V195, DOI 10.1016/j.compag.2022.106805
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 45
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39481
EP 39501
DI 10.1007/s11042-023-14914-z
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600013
DA 2024-07-18
ER

PT J
AU Cizotto, AAJ
   de Souza, RCT
   Mariani, VC
   Coelho, LD
AF Cizotto, Andre Armstrong Janino
   de Souza, Rodrigo Clemente Thom
   Mariani, Viviana Cocco
   Coelho, Leandro dos Santos
TI Web pages from mockup design based on convolutional neural network and
   class activation mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web-design; Convolutional neural networks; Object detection; Semantic
   segmentation; User eXperience
ID USER
AB The objective of this study is to validate the use of Deep Neural Networks (DNNs) to segment and classify web elements. To achieve this, a dataset of 2200 images was created through screenshots of real web pages, with 10 distinct classes to represent the most common web elements. The contributions of this study encompass the validation of classification-only Convolutional Neural Networks (CNNs) with the support of Class Activation Mapping (CAM), a weakly-supervised semantic segmentation technique that requires no in-image annotation, significantly simplifying the dataset creation process when compared to traditional segmentation models. Multiple networks with distinct hyper-parameter combinations were cross-validated with 10 folds, with a final accuracy rating of 95.71% on the best-performing model. Although the final CNN showed promising results, further improvements on the dataset and architecture are still required for it to be employed as the centerpiece of a real-time dynamic web page building solution, with clear improvements needed on the clarity of the segmentation heatmap.
C1 [Cizotto, Andre Armstrong Janino; Coelho, Leandro dos Santos] Pontifical Catholic Univ Parana PUCPR, Ind & Syst Engn Grad Program PPGEPS, Curitiba, Brazil.
   [Cizotto, Andre Armstrong Janino] Facebook, London, England.
   [de Souza, Rodrigo Clemente Thom] Fed Univ Parana UFPR, Adv Campus Jandaia Do Sul, Jandaia Do Sul, Brazil.
   [de Souza, Rodrigo Clemente Thom] State Univ Maringa UEM, Comp Sci Grad Program PCC, Maringa, Brazil.
   [de Souza, Rodrigo Clemente Thom] State Univ Maringa UEM, Prod Engn Grad Program PGP, Maringa, Brazil.
   [Mariani, Viviana Cocco; Coelho, Leandro dos Santos] Fed Univ Parana UFPR, Dept Elect Engn, Curitiba, PR, Brazil.
   [Mariani, Viviana Cocco] Pontifical Catholic Univ Parana PUCPR, Dept Mech Engn, Curitiba, Brazil.
C3 Pontificia Universidade Catolica do Parana; Facebook Inc; Universidade
   Federal do Parana; Universidade Estadual de Maringa; Universidade
   Estadual de Maringa; Universidade Federal do Parana; Pontificia
   Universidade Catolica do Parana
RP Mariani, VC (corresponding author), Fed Univ Parana UFPR, Dept Elect Engn, Curitiba, PR, Brazil.; Mariani, VC (corresponding author), Pontifical Catholic Univ Parana PUCPR, Dept Mech Engn, Curitiba, Brazil.
EM andre.janino@gmail.com; thom@ufpr.br; viviana.mariani@pucpr.br;
   leandro.coelho@pucpr.br
RI Mariani, Viviana Cocco/N-5634-2016; Coelho, Leandro dos
   Santos/G-8213-2014
OI Mariani, Viviana Cocco/0000-0003-2490-4568; Coelho, Leandro dos
   Santos/0000-0001-5728-943X
FU National Council of Scientific and Technologic Development of
   Brazil-CNPq [307958/2019-1-PQ, 307966/2019-4-PQ, 404659/2016-0-Univ,
   405101/2016-3-Univ]; PRONEX 'Fundacao Araucaria' [042/2018]
FX The authors would like to thank the National Council of Scientific and
   Technologic Development of Brazil-CNPq (Grants number: 307958/2019-1-PQ,
   307966/2019-4-PQ, 404659/2016-0-Univ, 405101/2016-3-Univ), and PRONEX
   'Fundacao Araucaria' 042/2018.
CR Balog Matej, 2016, DeepCoder: Learning to Write Programs
   Bansemir B, 2014, DESIGN USER EXPERIEN, P3
   Baule D, 2021, ARXIV
   Beltramelli T, 2018, PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS (EICS'18), DOI 10.1145/3220134.3220135
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Brigato L, 2020, ARXIV
   Bunian S, 2021, ARXIV
   Cai JZ, 2019, PATTERN RECOGN, V86, P368, DOI 10.1016/j.patcog.2018.08.012
   Chen WY., 2021, CODE GENERATION GRAP
   Deming DJ., 2018, 145791216 NAT BUR EC
   Dingsoyr T, 2019, IEEE SOFTWARE, V36, P30, DOI 10.1109/MS.2018.2884884
   Fu K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050544
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z
   Halbe A, 2015, PROCEDIA COMPUT SCI, V45, P197, DOI 10.1016/j.procs.2015.03.122
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hehn J, 2018, INT REQUIR ENG CONF, P400, DOI 10.1109/RE.2018.00-18
   Heitkötter H, 2013, LECT NOTES BUS INF P, V140, P120
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jamshidi P, 2013, IEEE T CLOUD COMPUT, V1, P142, DOI 10.1109/TCC.2013.10
   Kashfi P, 2016, ARXIV
   Le THM, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3383458
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   López-Sánchez D, 2019, NEUROCOMPUTING, V338, P418, DOI 10.1016/j.neucom.2018.08.086
   Luo C., 2020, ARXIV
   Mattina Matthew, 2019, P 2 SYSML C
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Muhammad MB, 2020, ARXIV
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ries E, 2011, The Lean Startup
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wojdziak J, 2016, COMM COM INF SC, V617, P167, DOI 10.1007/978-3-319-40548-3_28
   Xie S., 2017, ARXIV
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yuille AL, 2019, ARXIV
   Zhao T, 2021, ARXIV
   Zhou B., 2014, CORR, V1412, P6856
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu LP, 2020, NEURAL COMPUT APPL, V32, P5105, DOI 10.1007/s00521-018-3954-7
NR 43
TC 2
Z9 2
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38771
EP 38797
DI 10.1007/s11042-023-15108-3
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956328600005
DA 2024-07-18
ER

PT J
AU Qi, Q
AF Qi, Qing
TI A multi-path attention network for non-uniform blind image deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Non-uniform; Blind image deblurring; Generative adversarial network;
   Multi-path attention block
AB In the field of computer vision, image deblurring is a crucial and difficult task. By learning features from receptive fields, existing image deblurring algorithms have progressed. However, non-local feature representations, which depict the global data distribution of blurry images are not taken into account. As a result, in the local receptive field, combining the reliance of global space and the interaction of neighborhood space. For non-uniform deblurring, we develop a multi-path attention block (MPAB). To fuse several multi-path attention blocks, we offer an improved one-shot aggregation (IOSA). In addition, multiple loss functions are proposed to enhance network training and encourage convergence. Subjective and objective comparison experiments on various datasets are done to illustrate the efficiency of the suggested strategy. On synthetic datasets and real photos, our technique outperforms state-of-the-art (SOTA) methods.
C1 [Qi, Qing] Qinghai Nationalities Univ, Sch Phys & Elect Informat Engn, Bayi Middle Rd 3, Xining 810007, Peoples R China.
C3 Qinghai Nationalities University
RP Qi, Q (corresponding author), Qinghai Nationalities Univ, Sch Phys & Elect Informat Engn, Bayi Middle Rd 3, Xining 810007, Peoples R China.
EM qiqing@tju.edu.cn
CR Berahmand K, 2019, COMPUTING, V101, P1711, DOI 10.1007/s00607-018-0684-8
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani I, 2017, Arxiv, DOI arXiv:1704.00028
   HRADI M, 2015, BRIT MACH VIS C
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin MG, 2018, IEEE COMPUT SOC CONF, P858, DOI 10.1109/CVPRW.2018.00118
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348
   Kingma D. P., 2014, arXiv
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Lee YW, 2019, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2019.00103
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2019, Arxiv, DOI arXiv:1906.08462
   Li CY, 2019, Arxiv, DOI arXiv:1901.05495
   Li CY, 2020, IEEE T MULTIMEDIA, V22, P704, DOI 10.1109/TMM.2019.2933334
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li YW, 2021, INT C PATT RECOG, P5333, DOI 10.1109/ICPR48806.2021.9413148
   Maas AL, 2013, PROC INT C MACH LEAR
   Madam NT, 2018, LECT NOTES COMPUT SC, V11214, P358, DOI 10.1007/978-3-030-01249-6_22
   Mao XJ, 2016, ADV NEUR IN, V29
   Mustaniemi J, 2018, Arxiv, DOI arXiv:1810.00986
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Qi Q, 2020, IEEE ACCESS, V8, P100044, DOI 10.1109/ACCESS.2020.2997408
   Qing Q., 2021, ARTIF INTELL COMMUN, V101, p1C13
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Sun L., 2013, IEEE INT C COMPUTATI, P1, DOI [10.1109/ICCPhot.2013.6528301, DOI 10.1109/ICCPHOT.2013.6528301]
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang Q, 2022, IEEE T NEUR NET LEAR, V33, P1066, DOI 10.1109/TNNLS.2020.3039675
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yuan Y, 2019, IEEE T IMAGE PROCESS, V28, P3423, DOI 10.1109/TIP.2019.2896952
   [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1
   Zhang Z, 2021, INT J ADV MANUF TECH
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 23
PY 2023
DI 10.1007/s11042-023-14470-6
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A5CE8
UT WOS:000955293100001
DA 2024-07-18
ER

PT J
AU Kanungo, A
   Choubey, C
   Gupta, V
   Kumar, P
   Kumar, N
AF Kanungo, Abhas
   Choubey, Chandan
   Gupta, Varun
   Kumar, Pankaj
   Kumar, Neeraj
TI Design of an intelligent wavelet-based fuzzy adaptive PID control for
   brushless motor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brushless direct current motor; Proportional-integral-derivative; Gain
   scheduling; Hybrid optimization
ID IMPLEMENTATION; OPTIMIZATION
AB Nowadays, high speed and high power density Brushless Direct Current (BLDC) motors have been widely utilized in the industrial area. Moreover, the design of motor simulation strategies is used in the drive system, which controls the complicated problems in the BLDC motors. However, speed regulation is a vital challenge since it affects the controller performance; the Proportional-Integral-Derivative (PID) controller is used in mechanical concerns. Therefore, this study introduces the novel Wavelet-based Fuzzy Adaptive Hybrid Bat-Vulture PID (WFA-HBVPID) controller to control the BLDC motor acceleration. Also, the developed WFA-HBVPID controller organizes the loads in the BLDC motor while verifying the gain scheduling conditions. Furthermore, this proposed PID controller is implemented using MATLAB/Simulink. Here, the performance of the motor is assessed in two ways, i.e., with hybrid optimization and without hybrid optimization. In addition, the efficiency of the developed controller has been checked over the time domain specifications like settling time, rise time, peak overshoot, and gain. To calculate the presented controller efficiency, the performances of the controller were compared with existing techniques. From the comparison of the outcomes, it is found that the proposed controller has less computation time and error rate.
C1 [Kanungo, Abhas] KIET Grp Inst, Dept Elect & Commun Engn, Ghaziabad 201206, Uttar Pradesh, India.
   [Choubey, Chandan] IMS Engn Coll, Dept Elect & Commun Engn, Ghaziabad 201015, Uttar Pradesh, India.
   [Gupta, Varun] KIET Grp Inst, Dept Elect & Elect Engn, Ghaziabad 201206, Uttar Pradesh, India.
   [Kumar, Pankaj] Chaudhary Charan Singh Univ Campus, Dept Elect & Commun Engn, SCRIET, Meerut 250003, Uttar Pradesh, India.
   [Kumar, Neeraj] Greater Noida Inst Technol, Dept Elect & Commun Engn, Greater Noida 201310, Uttar Pradesh, India.
C3 KIET Group of Institutions; KIET Group of Institutions; Chaudhary Charan
   Singh University; Greater Noida Institute of Technology
RP Kanungo, A (corresponding author), KIET Grp Inst, Dept Elect & Commun Engn, Ghaziabad 201206, Uttar Pradesh, India.
EM abhas.kanungo@kiet.edu; er.choubey.chandan@gmail.com;
   varun.gupta@kiet.edu; nadarpankaj.miet@gmail.com; iet_neeraj@yahoo.com
OI GUPTA, VARUN/0000-0002-0390-9266; Choubey, Chandan/0000-0002-2034-2054
CR Balamurugan K., 2021, Advances in Smart System Technologies. Select Proceedings of ICFSST 2019. Advances in Intelligent Systems and Computing (AISC 1163), P51, DOI 10.1007/978-981-15-5029-4_5
   Cao Y, 2021, APPL THERM ENG, V196, DOI 10.1016/j.applthermaleng.2021.117339
   Chen CJ, 2021, MICROSYST TECHNOL, V27, P1217, DOI 10.1007/s00542-018-4171-0
   El-Hoseny HM, 2019, MULTIMED TOOLS APPL, V78, P26373, DOI 10.1007/s11042-019-7552-1
   Huynh TT, 2022, APPL INTELL, V52, P2720, DOI 10.1007/s10489-021-02482-4
   Kanungo A, 2020, J INTERDISCIP MATH, V23, P145, DOI 10.1080/09720502.2020.1721708
   Karuppannan A, 2021, NEURAL COMPUT APPL, V33, P13481, DOI 10.1007/s00521-021-05971-2
   Khwarahm NR, 2021, IRAN J SCI TECHNOL A, V45, P1519, DOI 10.1007/s40995-021-01150-z
   Kumar Ambreesh, 2018, International Journal of Intelligent Systems and Applications, V10, P23, DOI 10.5815/ijisa.2018.05.03
   Liu CQ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093179
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Lu PW, 2021, PROCEEDINGS OF 2021 7TH INTERNATIONAL CONFERENCE ON CONDITION MONITORING OF MACHINERY IN NON-STATIONARY OPERATIONS (CMMNO), P130, DOI 10.1109/CMMNO53328.2021.9467649
   Ma RJ, 2022, IEEE T MULTIMEDIA, V24, P2366, DOI 10.1109/TMM.2021.3079697
   Manap HH, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102300
   Eltoum MAM, 2021, ARAB J SCI ENG, V46, P9423, DOI 10.1007/s13369-020-05262-3
   Mohanty D, 2021, J CONTROL AUTOM ELEC, V32, P416, DOI 10.1007/s40313-020-00683-9
   Najariyan M, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114182
   Narayanan KL, 2022, MULTIMED TOOLS APPL, V81, P3297, DOI 10.1007/s11042-021-11264-6
   Sain D, 2021, ISA T, V110, P319, DOI 10.1016/j.isatra.2020.10.048
   Shi Q, 2020, NEUROCOMPUTING, V402, P183, DOI 10.1016/j.neucom.2020.03.063
   Singh R, 2021, INT J FUZZY SYST, V23, P27, DOI 10.1007/s40815-020-00994-8
   Swethamarai P, 2022, IETE J RES, V68, P3487, DOI 10.1080/03772063.2020.1768906
   Mai TA, 2021, J BRAZ SOC MECH SCI, V43, DOI 10.1007/s40430-020-02767-8
   Vanchinathan K, 2021, RESULTS CONTROL OPTI, V4, DOI 10.1016/j.rico.2021.100032
   Wang MS, 2018, MICROSYST TECHNOL, V24, P33, DOI 10.1007/s00542-016-3148-0
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/353910
   Xu QZ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/659809
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2018, PHYSICA A, V494, P484, DOI 10.1016/j.physa.2017.11.155
   Yang SM, 2017, NEURAL NETWORKS, V94, P220, DOI 10.1016/j.neunet.2017.07.012
   Zeng WJ, 2021, PROG NUCL ENERG, V132, DOI 10.1016/j.pnucene.2020.103564
   Zhang YJ, 2023, MULTIMED TOOLS APPL, V82, P27081, DOI 10.1007/s11042-019-7280-6
NR 37
TC 1
Z9 1
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33203
EP 33223
DI 10.1007/s11042-023-14872-6
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000948950300008
DA 2024-07-18
ER

PT J
AU Gao, WQ
   Cheng, N
   Xin, GJ
   Khantong, S
   Ding, CS
AF Gao, Wanqing
   Cheng, Ning
   Xin, Guojiang
   Khantong, Sommai
   Ding, Changsong
TI TCM2Vec: a detached feature extraction deep learning approach of
   traditional Chinese medicine for formula efficacy prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traditional Chinese medicine; Feature extraction; Formula predicting;
   Deep learning model; TCM representation
AB In current era, the intelligent development of traditional Chinese medicine (TCM) has attracted more and more attention. As the main carrier of clinical medication, formulas use synergies of active substances to enhance efficacy and reduce side effects. Related studies show that there is a nonlinear relationship between the efficacy of formulas and herbs. Deep learning is an effective technique for fitting nonlinear relationships. However, it is not good for using deep learning model directly due to ignoring the characteristics of formulas. In this paper, we propose a detached feature extraction approach (TCM2Vec) based on deep learning for better feature extraction and efficacy prediction. We build two detached encoders, one of it uses cross-feature-based unsupervised pre-training model (FMh2v) to extract the relationship features of herbal medicines for initializing, while the other one simulates multi-dimensional characteristics of medicines by normal distribution. Then we integrate relationships and medicinal characteristics for deep feature extraction. We processed 31,114 unlabeled formulas for pre-training and two classification tasks in-domain for predicting and fine-tuning. One of tasks is multi-classed with 1036 formulas, other one is multi-labelled with 1,723 formulas. For labelled formulas, different feature extraction models based on detached encoder are trained to predict efficacy. Compared with the no pre-training, CBOW and BERT baseline models, FMh2v leads to performance gains. Moreover, the detached encoder offers large positive effects in different models which for efficacy prediction, where ACC increased by 5.80% on average and F1 increased by 12.06% on average. Overall, the proposed feature extraction is an effective method for obtaining characteristic representation of TCM formulas, and provides reference for the adaptability of artificial intelligence technology in the domain of TCM.
C1 [Gao, Wanqing; Cheng, Ning; Xin, Guojiang; Ding, Changsong] Hunan Univ Chinese Med, Sch Informat, Changsha, Peoples R China.
   [Khantong, Sommai] Mahasarakham Univ, Mahasarakham Business Sch, Digital Business & Informat Syst Dept, Maha Sarakham, Thailand.
   [Ding, Changsong] Hunan Univ Chinese Med, Big Data Anal Lab Tradit Chinese Med, Changsha, Peoples R China.
C3 Hunan University of Chinese Medicine; Mahasarakham University; Hunan
   University of Chinese Medicine
RP Ding, CS (corresponding author), Hunan Univ Chinese Med, Sch Informat, Changsha, Peoples R China.; Ding, CS (corresponding author), Hunan Univ Chinese Med, Big Data Anal Lab Tradit Chinese Med, Changsha, Peoples R China.
EM wq_gao@163.com; 759440689@163.com; lovesin_guojiang@126.com;
   sommai.k@acc.msu.ac.th; dingcs1975@hnucm.edu.cn
RI gao, wanqing/HTM-8625-2023; Khantong, Sommai/HOH-9411-2023
OI Khantong, Sommai/0000-0001-7874-4980
FU Key Project of TCM Scientific Research Program in Hunan Province;
   Natural Science Foundation of Hunan Province [2020002, 2018JJ2301]
FX AcknowledgementsThis work is funded by The Key Project of TCM Scientific
   Research Program in Hunan Province
   (http://tcm.hunan.gov.cn/tcm/index.html) and Natural Science Foundation
   of Hunan Province (http://kjt.hunan.gov.cn/zxgz/zkjj/). The project
   Numbers are 2020002 and 2018JJ2301. The main researcher of this project
   has received a total of RMB 130,000 of funding.
CR Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P13489, DOI 10.1007/s11042-021-11495-7
   [Anonymous], 2017, ARXIV
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Clevert D., 2016, ARXIV151107289
   [邓乐 Deng Le], 2020, [中草药, Chinese Traditional and Herbal Drugs], V51, P4277
   Devlin J., 2018, BERT PRE TRAINING DE
   Gangavarapu T, 2020, ARTIF INTELL REV, V53, P5019, DOI 10.1007/s10462-020-09814-9
   Gao KY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371
   Gururangan S., 2020, ARXIV
   Han X, 2018, 2018 SIXTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION, NETWORKING, AND WIRELESS COMMUNICATIONS (DINWC), P53, DOI 10.1109/DINWC.2018.8356995
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hu W., 2019, 2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC), P284
   Hu Y., 2016, J TRADIT CHIN MED SC, V3, P110
   Hu Y, 2021, IEEE T CYBERNETICS, V51, P708, DOI 10.1109/TCYB.2019.2909925
   Hu ZN, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1857, DOI 10.1145/3394486.3403237
   Huang FY, 2018, SIGNAL PROCESS, V149, P179, DOI 10.1016/j.sigpro.2018.03.013
   Johnson R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P562, DOI 10.18653/v1/P17-1052
   Ker J, 2018, IEEE ACCESS, V6, P9375, DOI 10.1109/ACCESS.2017.2788044
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kwak SG, 2017, KOREAN J ANESTHESIOL, V70, P144, DOI 10.4097/kjae.2017.70.2.144
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lee J, 2021, CMC-COMPUT MATER CON, V69, P647, DOI 10.32604/cmc.2021.016712
   Li SZ, 2021, ARCH TOXICOL, V95, P1683, DOI 10.1007/s00204-021-03023-1
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Ozawa K, 2019, MIDWEST SYMP CIRCUIT, P323, DOI [10.1109/mwscas.2019.8885057, 10.1109/MWSCAS.2019.8885057]
   Parkes EJ, 1996, COMPUT PHYS COMMUN, V98, P288, DOI 10.1016/0010-4655(96)00104-X
   Pathirage CSN, 2019, STRUCT HEALTH MONIT, V18, P103, DOI 10.1177/1475921718800363
   Ramos J, 2003, P 1 INSTRUCTIONAL C, V242, P29
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Rodríguez P, 2018, IMAGE VISION COMPUT, V75, P21, DOI 10.1016/j.imavis.2018.04.004
   Shah SMA, 2021, COMPUT SYST SCI ENG, V36, P369, DOI 10.32604/csse.2021.014234
   Shahrajabian MH, 2019, ACTA AGR SCAND B-S P, V69, P546, DOI 10.1080/09064710.2019.1606930
   Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050
   Song ZH, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1383, DOI [10.1109/ITAIC.2019.8785612, 10.1109/itaic.2019.8785612]
   Tachibana K, 2018, 2018 57TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1029, DOI 10.23919/SICE.2018.8492660
   Tong T, 2020, CHIN MED-UK, V15, DOI 10.1186/s13020-020-00326-w
   Wang CL, 2021, CMC-COMPUT MATER CON, V69, P1375, DOI 10.32604/cmc.2021.017950
   Wang J, 2022, COMPUT SYST SCI ENG, V41, P1207, DOI 10.32604/csse.2022.022365
   Wang YJ, 2022, J PLANT GROWTH REGUL, V41, P1099, DOI 10.1007/s00344-021-10366-7
   Xu B., 2015, arXiv
   Yue SJ, 2017, SCI REP-UK, V7, DOI 10.1038/srep40318
   Zhang QC, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5252
   Zhou WA, 2021, PHARMACOL RES, V173, DOI 10.1016/j.phrs.2021.105752
   Zhu XL, 2020, MULTIMED TOOLS APPL, V79, P10519, DOI 10.1007/s11042-019-7226-z
NR 47
TC 1
Z9 1
U1 13
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26987
EP 27004
DI 10.1007/s11042-023-14701-w
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700014
OA hybrid
DA 2024-07-18
ER

PT J
AU Salman, H
   Taherinia, AH
   Zabihzadeh, D
AF Salman, Hasan
   Taherinia, Amir Hossein
   Zabihzadeh, Davood
TI Fast and accurate image retrieval using knowledge distillation from
   multiple deep pre-trained networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Knowledge distillation; Model quantization;
   Semantic hash coding; Attention mechanism
ID SCALE; ROTATION; PATTERN
AB The content retrieval systems aim to retrieve images similar to a query image from a large data set. A feature extractor and similarity measure play a key role in these systems. Hand-crafted feature descriptors like SURF, SIFT, and GIST find a suitable pattern for measuring the similarity between images. Recently deep learning in this field has been given much attention, which performs feature extraction and similarity learning simultaneously. Various research shows that the feature vector extracted from pre-trained networks contains richer information than class labels in classifying or retrieving information. This paper presents an effective method, Deep Muti-teacher Transfer Hash (DMTH), which uses knowledge from several complex models to teach a simple one. Due to the variety of available pre-trained models and the diversity among their extracted features, we utilize an attention mechanism to obtain richer features from them to teach a simple model via an appropriate knowledge distillation loss. We test our method on widely used datasets Cifar10 & Cifar100 and compare our method with other state-of-the-art methods. The experimental results show that DMTH can improve the image retrieval performance by learning better features obtained through an attention mechanism from multiple teachers without increasing evaluation time. Specifically, the proposed multi-teacher model surpasses the best individual teacher by 2% in terms of accuracy on Cifar10. Meanwhile, it boosts the performance of the student model by more than 4% using our knowledge transfer mechanism.
C1 [Salman, Hasan; Taherinia, Amir Hossein] Ferdowsi Univ Mashhad, Fac Engn, Comp Engn Dept, Mashhad, Iran.
   [Zabihzadeh, Davood] Hakim Sabzevari Univ, Dept Comp Engn, Sabzevar, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Fac Engn, Comp Engn Dept, Mashhad, Iran.
EM taherinia@um.ac.ir
RI Taherinia, Amir Hossein/AAC-9575-2020; Taherinia, Amir
   Hossein/HTP-1792-2023
OI Taherinia, Amir Hossein/0000-0002-5103-4812; , Hassan
   Salman/0009-0009-9384-1768
CR Al-Kaabi K, 2021, ARXIV
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Berthelot D, 2022, Arxiv, DOI arXiv:2106.04732
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z
   Gu G, 2021, P AAAI C ARTIFICIAL
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hsu KJ, 2015, PROC CVPR IEEE, P1921, DOI 10.1109/CVPR.2015.7298802
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Kim S, 2020, PROC CVPR IEEE, P3235, DOI 10.1109/CVPR42600.2020.00330
   Krizhevsky A., 2011, P 19 EUR S ART NEUR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li JY, 2020, INT J MACH LEARN CYB, V11, P883, DOI 10.1007/s13042-019-01026-0
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng ZM, 2019, IEEE I CONF COMP VIS, P441, DOI 10.1109/ICCV.2019.00053
   Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Wu DY, 2019, PROC CVPR IEEE, P9061, DOI 10.1109/CVPR.2019.00928
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yang Z., 2016, P 2016 C N AM CHAPTE
   Yao T., 2016, IJCAI
   Zhai H, 2020, IEEE T CIRC SYST VID
   Zhu CZ, 2017, Arxiv, DOI arXiv:1612.01064
NR 44
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33937
EP 33959
DI 10.1007/s11042-023-14761-y
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700012
DA 2024-07-18
ER

PT J
AU Soni, B
   Thakuria, D
   Nath, N
   Das, N
   Boro, B
AF Soni, Badal
   Thakuria, Debangan
   Nath, Nilutpal
   Das, Navarun
   Boro, Bhaskarananda
TI RikoNet: A Novel Anime Recommendation Engine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anime; Autoencoder; Recommendation system; Spectral clustering
ID SYSTEM
AB Anime is quite well-received today, especially among the younger generations. As anime has recently garnered mainstream attention, we have insufficient information regarding users' penchant and watching habits. Therefore, it is an uphill task to build a recommendation engine for this relatively obscure entertainment medium. In this attempt, we have built a novel hybrid recommendation system that could act both as a recommendation system and as a means of exploring new anime genres and titles. We have analyzed the general trends in this field and the users' watching habits for coming up with our efficacious solution. Our solution employs deep autoencoders for the tasks of predicting ratings and generating embeddings. Following this, we formed clusters using the embeddings of the anime titles. These clusters form the search space for anime with similarities and are used to find anime similar to the ones liked and disliked by the user. This method, combined with the predicted ratings, forms the novel hybrid filter. In this article, we have demonstrated this idea and compared the performance of our implemented model with the existing state-of-the-art techniques.
C1 [Soni, Badal] Natl Inst Technol Silchar, Dept Comp Engn, Silchar, India.
   [Thakuria, Debangan; Nath, Nilutpal; Das, Navarun; Boro, Bhaskarananda] Natl Inst Technol Silchar, Comp Sci & Engn, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Soni, B (corresponding author), Natl Inst Technol Silchar, Dept Comp Engn, Silchar, India.
EM badal@cse.nits.ac.in; debanganthakuria44@gmail.com;
   nilutpalnath555@gmail.com; dasnavarun06@gmail.com;
   boro123bhaskar@gmail.com
CR Al-Badarenah A, 2016, INT J ADV COMPUT SC, V7, P166
   Azfar T., 2020, PALARCHS J ARCHAEOLO, V17, P890
   Barkan Oren, 2016, IEEE INT WORKSHOP MA
   Behera RN., 2017, INT J CONTROL THEORY, V10, P41
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Clevert D. A., 2015, FAST ACCURATE DEEP N
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Geetha G, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012101
   Girsang A. S., 2020, Journal of Physics: Conference Series, V1566, DOI 10.1088/1742-6596/1566/1/012057
   Hande R, 2016, MARMARA PHARM J
   Hornung T, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P57, DOI 10.1109/WI-IAT.2013.9
   Kim HT, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.102
   Kiran R, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113054
   Klambauer Gunter, 2017, arXiv
   Kuchaiev O, 2017, ARXIV
   Kumar M, 2015, INT J COMPUT APPL, V124
   Nápoles G, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106372
   Ota Syoichiro, 2017, Entertainment Computing - ICEC 2017. 16th IFIP TC 14 International Conference. Proceedings: LNCS 10507, P400, DOI 10.1007/978-3-319-66715-7_49
   Putri DCG, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020185
   Ramashini M, 2018, PERSONALIZED RECOMME
   Su Z, 2021, IEEE ACCESS, V9, P30739, DOI 10.1109/ACCESS.2021.3060016
   Vie JJ, 2017, PROC INT CONF DOC, P21, DOI 10.1109/ICDAR.2017.287
   Virk HK, 2015, ANAL DESIGN HYBRID O
   Yuan XF, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102384
   Zhang HR, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/145636
NR 25
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32329
EP 32348
DI 10.1007/s11042-023-14710-9
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943163700010
DA 2024-07-18
ER

PT J
AU Sharma, BP
   Purwar, RK
AF Sharma, Bhanu Prakash
   Purwar, Ravindra Kumar
TI An augmented mammogram image dataset and its performance analysis for
   various classification models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Mammogram; Image augmentation; Texture feature;
   Histogram; ULBP; HOG; Underfitting; Convolutional neural network
ID BREAST-CANCER
AB For a pattern classification problem, dataset size plays a vital role in the training and testing of the used classifier. With a smaller dataset, the model suffers from a common problem of data underfitting in which the model remains unable to cover the underlying trend of scenarios, as well as its learning rules remain simple and flexible. As a result, the classification model performs wrong predictions and its performance remains low. In this direction, the proposed work augments a mammographic image analysis society (MIAS) dataset of mammogram images that are used for the classification of breast cancer. In this process, the suspected cancerous region of interest (ROI) has been extracted from all 323 (64 benign, 52 malignant, and 207 normal) mammogram images to form a non-augmented dataset. The images of this non-augmented dataset are augmented using simple image transformation (rotations and flip) techniques to form its augmented dataset. It consists of 23,256 (4608 benign, 3744 malignant, and 14,904 normal) ROI images. The images of both datasets are normalized to 128 X 128 pixels. A total of five feature vectors from these images are generated using individual features such as histogram, uniform local binary pattern (ULBP) and histogram-oriented gradient (HOG) as well as some of their combinations like (ULBP + HOG) and (histogram + ULBP + HOG). Using these feature vectors, the performance of 24 popular classification models have been analyzed in terms of accuracy, classification time per image, sensitivity, specificity, precision and f1-score for both datasets using k-fold (k = 5) cross-validation. Along with a significant improvement in all parameters, an improvement of average accuracy of 8.26% has been obtained for the augmented dataset over the non-augmented one. Specifically, this average accuracy improvement for the above five feature vectors is 22.16%, 2.87%, 5.25%, 2.8%, and 8.22% in that order of their listing which pleads for the finding that histogram features are more suitable for mammogram image classification. It shows that the augmented dataset not only improves the performance of various classifiers but it can be useful for further research based on mammogram images.
C1 [Sharma, Bhanu Prakash; Purwar, Ravindra Kumar] USIC&T GGSIPU, Delhi, India.
RP Sharma, BP (corresponding author), USIC&T GGSIPU, Delhi, India.
EM bhanu.12016492317@ipu.ac.in; ravindra@ipu.ac.in
RI Sharma, Bhanu/HMP-1466-2023
OI Sharma, Bhanu Prakash/0000-0002-7141-7132
FU Visveswaraya Fellowship scheme of the Government of India (GOI)
FX This work has been carried out under the Visveswaraya Fellowship scheme
   of the Government of India (GOI) for research and authors are thankful
   for the valuable comments and suggestions of anonymous reviewers in
   improving the quality of this paper.
CR Abdel-Nasser M, 2016, J EXP THEOR ARTIF IN, V28, P385, DOI 10.1080/0952813X.2015.1024496
   Albalawi U, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5803
   American Cancer Society, 2021, CANC FACTS FIGURES 2, DOI DOI 10.1080/15398285.2012.701177
   Arar M, 2021, IEEE INT CONF COMP V, P1698, DOI 10.1109/ICCVW54120.2021.00195
   Bakalo R, 2021, NEUROCOMPUTING, V421, P15
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deshmukh J, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P134, DOI 10.1109/WiSPNET.2017.8299734
   Dibden A, 2020, CANCERS, V12, DOI 10.3390/cancers12040976
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gong XN, 2019, MULTIMED TOOLS APPL, V78, P31185, DOI 10.1007/s11042-019-07917-2
   Guan S, 2017, IEEE APP IMG PAT
   Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Jotwani AC, 2009, MOL DIAGN THER, V13, P349, DOI 10.2165/11318220-000000000-00000
   Khan HN, 2019, IEEE ACCESS, V7, P165724, DOI 10.1109/ACCESS.2019.2953318
   Li H, 2019, BIOMED SIGNAL PROCES, V51, P347, DOI 10.1016/j.bspc.2019.02.017
   Mazumder B, 2020, 2020 2 INT C SUSTAIN, P1
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omonigho EL, 2020, 2020 INT C MATH COMP, P1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paramkusham S, 2018, INT J SIGNAL IMAGING, V11, P136
   Rabidas R, 2020, MULTIMED TOOLS APPL, V79, P21967, DOI 10.1007/s11042-020-08959-7
   Ragab DA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104245
   Samma H, 2020, IRBM, V41, P195, DOI 10.1016/j.irbm.2020.01.005
   Schapire RE, 1998, ANN STAT, V26, P1651
   Scholkopf B., 2002, Learning with Kernels
   Seber G.A.F., 1984, Multivariate Observations, DOI [10.1002/9780470316641, DOI 10.1002/9780470316641]
   Seiffert C, 2008, INT C PATT RECOG, P3650
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Song RY, 2020, IEEE ACCESS, V8, P75011, DOI 10.1109/ACCESS.2020.2986546
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Takahashi R., 2018, ASIAN C MACHINE LEAR, P786
   Takahashi R, 2020, IEEE T CIRC SYST VID, V30, P2917, DOI 10.1109/TCSVT.2019.2935128
   Trevor H., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Zhang XF, 2018, IEEE T NANOBIOSCI, V17, P237, DOI 10.1109/TNB.2018.2845103
NR 42
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32011
EP 32055
DI 10.1007/s11042-023-14566-z
EA MAR 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941926100004
DA 2024-07-18
ER

PT J
AU Patra, DK
   Si, TP
   Mondal, S
   Mukherjee, P
AF Patra, Dipak Kumar
   Si, Tapas
   Mondal, Sukumar
   Mukherjee, Prakash
TI Breast lesion detection from MRI images using quasi-oppositional slime
   mould algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast DCE-MRI; Segmentation; Entropy; Multi-level thresholding; Slime
   mould algorithm; Opposition-based learning
ID OPTIMIZATION ALGORITHM; TEXTURE FEATURES; DIAGNOSIS; CANCER;
   CLASSIFICATION; SEGMENTATION; SELECTION
AB In recent years cancer on breast in women has increased rapidly worldwide. Therefore, the automatic segmentation of breast Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) has been exhaustively investigated since the proper use of methods permits the diagnosis and identification of diseases. Radiologists accept that breast fat-suppressed DCE-MRI evaluation for lesion detection and segmentation, which optimization algorithm via multi-level thresholding, is essential to differentiate breast lesions from other tissue types in DCE-MRI. This article proposes a breast DCE-MRI segmentation method using a multilevel thresholding technique based on enhanced Slime Mould Algorithm (SMA). The anisotropic diffusion filter is used to denoise MR images first. The preprocessing step then corrects intensity inhomogeneities. The suggested SMAQOBL algorithm is used to segment preprocessed MR images. Next, we developed the enhanced SMA by incorporating the Quasi Opposition-based Learning (QOBL) mechanism in it. This algorithm is used to find optimal threshold values through the maximization of Shannon entropy. Throughout this article, the proposed algorithm has been termed SMAQOBL. Finally, the segmented lesions are accurately localized in MR images. The proposed method is evaluated using 200 sagittal T2-weighted fat-suppressed DCE-MRI images of 40 patients. The SMAQOBL is compared with SMA, Dragonfly Optimization (DA), Grasshopper Optimization Algorithm (GOA), Particle Swarm Optimizer (PSO), Multi-Verse Optimization (MVO), Conventional Markov Random Field (CMRF), Hidden Markov Random Field (HMRF), and Improved Markov Random Field (IMRF). The best-achieved results of the proposed method in terms of accuracy is 99.94%, sensitivity is 99.86% and Dice Similarity Coefficient (DSC) is 98.41%. Evaluating the proposed method achieves an mean accuracy of 99.36%, a mean sensitivity of 95.83%, and mean DSC of 92.19%. We have analyzed the results using a one-way ANOVA test with posthoc Tukey-HSD test and Wilcoxon Signed Rank Test with Bonferroni correction. Furthermore, we have also analyzed the overall performance using Multi-Criteria Decision Making based on sensitivity, accuracy, specificity, Geometric-Mean, F-measure, DSC, and False Positive Rate (FPR). The proposed methods outperform other compared methods, according to both quantitative and qualitative outcomes.
C1 [Patra, Dipak Kumar] Raja Narendra Lal Khan Womens Coll Autonomous, Dept Comp Sci, Midnapore 721102, West Bengal, India.
   [Si, Tapas] Univ Engn & Management, Dept Comp Sci & Engn, GURUKUL, Sikar Rd NH-11,Udaipuria Mod, Jaipur 303807, Rajasthan, India.
   [Mondal, Sukumar] Raja Narendra Lal Khan Womens Coll Autonomous, Dept Math, Midnapore 721102, West Bengal, India.
   [Mukherjee, Prakash] Hijli Coll, Dept Math, Midnapore 721306, West Bengal, India.
RP Patra, DK (corresponding author), Raja Narendra Lal Khan Womens Coll Autonomous, Dept Comp Sci, Midnapore 721102, West Bengal, India.
EM dpatra11@gmail.com; sukumarmondal@rnlkwc.ac.in;
   prakashmukherjee25@gmail.com
OI Patra, Dipak Kumar/0000-0002-7835-2255
CR Agliozzo S, 2012, MED PHYS, V39, P1704, DOI 10.1118/1.3691178
   Agner SC, 2011, PROC SPIE, V7963, P280
   AlQoud A, 2016, INT J COMPUT SCI NET, V16, P16
   [Anonymous], 2000, APPL OPTIMIZAT
   [Anonymous], 2019, CANC IMAGING ARCH TC
   [Anonymous], 1949, MATH MODEL COMMUNICA
   [Anonymous], 2011, INT J COMPUT TECHNOL
   ANSCOMBE FJ, 1948, J ROY STAT SOC A, V111, P181, DOI 10.2307/2984159
   Arbach L, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P253
   Arjmand A, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P305, DOI [10.1109/ICCKE48569.2019.8964794, 10.1109/iccke48569.2019.8964794]
   Azmi Reza, 2011, J Med Signals Sens, V1, P156
   Balafar MA, 2010, ARTIF INTELL REV, V34, P195, DOI 10.1007/s10462-010-9169-7
   Behrens S, 2007, COMPUT MED IMAG GRAP, V31, P236, DOI 10.1016/j.compmedimag.2007.02.007
   Benjelloun M, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGIES AND APPLICATIONS (CLOUDTECH)
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bohare MD., 2011, INF COMMUN ENG, V4, P1
   Boukerroui D, 1998, Eur J Ultrasound, V8, P135, DOI 10.1016/S0929-8266(98)00062-7
   Bray F, 2013, INT J CANCER, V132, P1133, DOI 10.1002/ijc.27711
   Brown S.D., 2020, Comprehensive chemometrics-chemical and biochemical data analysis
   Chatzis SP, 2010, IEEE T NEURAL NETWOR, V21, P1004, DOI 10.1109/TNN.2010.2046910
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Clerc M., 1999, P C EV COMP, P1951, DOI DOI 10.1109/CEC.1999.785513
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   Dhane DM, 2015, PROCEDIA COMPUT SCI, V58, P438, DOI 10.1016/j.procs.2015.08.059
   Eltoukhy MM, 2010, COMPUT MED IMAG GRAP, V34, P269, DOI 10.1016/j.compmedimag.2009.11.002
   Engelbrecht A. P., 2005, FUNDAMENTALS COMPUTA
   Eskandari P., 2021, MJECE, V3, P28
   Ferlay, 2013, GLOBOCAN 2012 V10 CA
   Ha WT, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5396327
   Hauth EAM, 2006, CLIN IMAG, V30, P160, DOI 10.1016/j.clinimag.2005.11.005
   HOMMEL G, 1988, BIOMETRIKA, V75, P383, DOI 10.2307/2336190
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Kadry S., 2021, 2021 7 INT C BIOS I, DOI [10.1109/ICBSII51839.2021.9445152, DOI 10.1109/ICBSII51839.2021.9445152]
   Karthiga R., 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P274, DOI 10.1109/ICECA.2018.8474739
   Kashyap KL, 2015, IEEE CONF IMAGING SY, P131
   Keyvanfard F, 2013, NEURAL COMPUT APPL, V22, pS35, DOI 10.1007/s00521-012-0937-y
   Krishnaveni A., 2021, VERSATILE DUCK TRAVE, DOI [10.2139/ssrn.3803814, DOI 10.2139/SSRN.3803814]
   Levman J, 2008, IEEE T MED IMAGING, V27, P688, DOI 10.1109/TMI.2008.916959
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Lingle W, 2007, FILIPPINI J RADIOLOG
   Mann RM, 2008, EUR RADIOL, V18, P1307, DOI 10.1007/s00330-008-0863-7
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili SZ, 2018, APPL INTELL, V48, P805, DOI 10.1007/s10489-017-1019-8
   Mohan G, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P53, DOI 10.1016/B978-0-12-816718-2.00011-7
   Mohan J, 2014, BIOMED SIGNAL PROCES, V9, P56, DOI 10.1016/j.bspc.2013.10.007
   Mustra M, 2013, SIGNAL PROCESS, V93, P2817, DOI 10.1016/j.sigpro.2012.07.026
   Naidu M. S. R., 2018, Alexandria Engineering Journal, V57, P1643, DOI 10.1016/j.aej.2017.05.024
   Nie K, 2008, MED PHYS, V35, P5253, DOI 10.1118/1.3002306
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Patra D. K., 2021, INT J INNOV TECHNOL, V10, P170, DOI [10.35940/ijitee.G9054.0510721, DOI 10.35940/IJITEE.G9054.0510721]
   Patra DK, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102925
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Piantadosi G, 2019, COMP MED SY, P628, DOI 10.1109/CBMS.2019.00130
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Rahnamayan S, 2007, IEEE C EVOL COMPUTAT, P2229, DOI 10.1109/CEC.2007.4424748
   Samantaray Leena, 2020, Revue d'Intelligence Artificielle, V34, P541, DOI 10.18280/ria.340503
   Shi JZ, 2008, MED PHYS, V35, P280, DOI 10.1118/1.2820630
   Si TP, 2021, ARTIF INTELL REV, V54, P4097, DOI 10.1007/s10462-020-09949-9
   Si T, 2019, INT J INF TECH DECIS, V18, P1717, DOI 10.1142/S0219622019500329
   Si T, 2015, INT J WAVELETS MULTI, V13, DOI 10.1142/S0219691315500393
   Snekha T, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190348
   Suradi SH, 2021, P INT C MEDICAL BIOL, V84, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]
   Tharwat A, 2021, APPL COMPUT INFORM, V17, P168, DOI 10.1016/j.aci.2018.08.003
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Tunçay AH, 2015, IEEE T BIO-MED ENG, V62, P688, DOI 10.1109/TBME.2014.2364015
   Wajid SK, 2018, EXPERT SYST APPL, V112, P388, DOI 10.1016/j.eswa.2017.11.057
   Wang H, 2018, P BRIT MACHINE VISIO
   World Health Organization, 2021, BREAST CANCER-TOKYO
   Wu Q, 2006, PROC SPIE, V6144, DOI 10.1117/12.654308
   Xu XW, 2018, IEEE ENG MED BIO, P750, DOI 10.1109/EMBC.2018.8512422
   Yao JH, 2009, IEEE J-STSP, V3, P94, DOI 10.1109/JSTSP.2008.2011110
   Zhang H., 2004, INDUCTION MUCOSAL SY, P1
NR 76
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30599
EP 30641
DI 10.1007/s11042-023-14329-w
EA FEB 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940065100004
DA 2024-07-18
ER

PT J
AU Xie, HY
   Zhong, YQ
AF Xie, Haoyang
   Zhong, Yueqi
TI Consistent 3D human body segmentation based on combinatorial descriptor
   in spectral domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human mesh segmentation; Combinatorial descriptor; Laplacian operator;
   Mesh segmentation
ID MESH SEGMENTATION; CAD MODELS; DRIVEN
AB Consistent 3D human body segmentation plays a vital role in many human-oriented applications. Recently research used supervised methods to achieve state-of-the-art performance. However, requiring massive labelled data and tedious training is a costly process. Unsupervised methods do not need labelling and training but struggle to achieve consistent segmentation for a non-rigid deformable mesh. Moreover, the segmentation style is also fixed. In the paper, we aim to achieve high-performance, consistent 3D human mesh segmentation avoiding fully-labelled data and time-consuming training. Specifically, this paper designs a Laplacian operator by incorporating mesh saliency, in which a face-level filter is proposed to improve the detection of concave vertices. Accordingly, we construct a combinatorial descriptor by explicitly employing the global and local attributes derived from the spectrum of the proposed saliency Laplacian operator to achieve consistent segmentation in the spectral domain. An automatic determination mechanism is adopted to determine the number of segments. Extensive experimental results demonstrate that the presented method is effective and efficient for many 3D meshes, especially for the human body shape. The segmentation results are comparable to other state-of-the-art performances without requiring time-consuming labelling and training on large-scale datasets.
C1 [Xie, Haoyang] North China Univ Water Resources & Elect Power, Coll Informat Engn, Zhengzhou 450046, Peoples R China.
   [Zhong, Yueqi] Donghua Univ, Coll Text, Shanghai 201620, Peoples R China.
   [Zhong, Yueqi] Donghua Univ, Key Lab Text Sci & Technol Minist Educ, Shanghai 201620, Peoples R China.
C3 North China University of Water Resources & Electric Power; Donghua
   University; Donghua University
RP Xie, HY (corresponding author), North China Univ Water Resources & Elect Power, Coll Informat Engn, Zhengzhou 450046, Peoples R China.
EM xiehaoyang@ncwu.edu.cn
RI Xie, Haoyang/HNR-0985-2023
FU Key Science and Technology Program of Henan Province, China
   [222102210124]; National Natural Science Foundation of China [61572124];
   Key Programof Higher Education Teaching Reform Research and Practice,
   Henan, China [2021SJGLX167]
FX This work is supported by the Key Science and Technology Program of
   Henan Province, China[Grant No. 222102210124], National Natural Science
   Foundation of China [Grant No. 61572124], Key Programof Higher Education
   Teaching Reform Research and Practice, Henan, China [Grant No.
   2021SJGLX167].
CR [Anonymous], 2010, ACM SIGGRAPH 2010 papers
   Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Benjamin W, 2011, COMPUT GRAPH FORUM, V30, P2097, DOI 10.1111/j.1467-8659.2011.02060.x
   Benzian Mohamed Yaghmorasan, 2020, 2020 1st International Conference on Communications, Control Systems and Signal Processing (CCSSP), P271, DOI 10.1109/CCSSP49278.2020.9151831
   Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296
   Chang A. X., 2015, ARXIV
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Gauthier S., 2017, ELECT IMAGING, V2017, P33, DOI [10.2352/ISSN.2470-1173.2017.20.3DIPM-005, DOI 10.2352/ISSN.2470-1173.2017.20.3DIPM-005]
   George D, 2018, GRAPH MODELS, V96, P1, DOI 10.1016/j.gmod.2018.01.001
   Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   He C, 2018, WIRELESS PERS COMMUN, V102, P3835, DOI 10.1007/s11277-018-5414-1
   He Y., 2021, arXiv
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Hou Y, 2021, MULTIMED TOOLS APPL, V80, P24885, DOI 10.1007/s11042-021-10816-0
   Huang JD, 2019, COMPUT AIDED DESIGN, V108, P19, DOI 10.1016/j.cad.2018.10.004
   Ji ZP, 2006, COMPUT GRAPH FORUM, V25, P283, DOI 10.1111/j.1467-8659.2006.00947.x
   Jiao X, 2017, J COMPUT APPL MATH
   Jung JY, 2021, FASH TEXT, V8, DOI 10.1186/s40691-021-00255-8
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lee Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P279
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Lv JJ, 2012, COMPUT GRAPH FORUM, V31, P2241, DOI 10.1111/j.1467-8659.2012.03217.x
   Mejia D, 2017, INT J INTERACT DES M, V11, P503, DOI 10.1007/s12008-016-0300-0
   Pal P, 2012, INT J ADV MANUF TECH, V63, P1205, DOI 10.1007/s00170-012-3986-6
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Shu ZY, 2022, COMPUT AIDED DESIGN, V145, DOI 10.1016/j.cad.2021.103181
   Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tao SQ, 2013, COMPUT AIDED DESIGN, V45, P1239, DOI 10.1016/j.cad.2013.05.008
   Theologou P, 2017, IEEE T PATTERN ANAL, V39, P397, DOI 10.1109/TPAMI.2016.2544311
   Tong WH, 2020, IEEE T VIS COMPUT GR, V26, P1807, DOI 10.1109/TVCG.2018.2882212
   Vasilakis AA, 2014, COMPUT GRAPH FORUM, V33, P293, DOI 10.1111/cgf.12327
   Wang H, 2014, GRAPH MODELS, V76, P440, DOI 10.1016/j.gmod.2014.04.009
   Wang PY, 2018, COMPUT GRAPH-UK, V70, P128, DOI 10.1016/j.cag.2017.07.030
   Yamauchi H, 2005, VISUAL COMPUT, V21, P659, DOI 10.1007/s00371-005-0319-x
   Yang S, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/1394231
   Yi B, 2014, COMPUT AIDED DESIGN, V55, P13, DOI 10.1016/j.cad.2014.04.008
   Yi Fang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2145, DOI 10.1109/CVPR.2011.5995695
   Yu Hou, 2021, Journal of Physics: Conference Series, V1802, DOI 10.1088/1742-6596/1802/3/032045
   Zhang L, 2022, IEEE T VIS COMPUT GR, V28, P2879, DOI 10.1109/TVCG.2020.3045450
   Zhong YQ, 2018, INT J CLOTH SCI TECH, V30, P380, DOI 10.1108/IJCST-06-2017-0086
   Zhou YN, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P187
NR 47
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27927
EP 27947
DI 10.1007/s11042-023-14729-y
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000940065100009
DA 2024-07-18
ER

PT J
AU Xu, ZY
   Tian, SR
   Abhadiomhen, SE
   Shen, XJ
AF Xu, Zhiyong
   Tian, Sirui
   Abhadiomhen, Stanley Ebhohimhen
   Shen, Xiang-Jun
TI Robust multiview spectral clustering via cooperative manifold and low
   rank representation induced
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiview clustering; Low-rank representation; Cooperative manifold;
   Spectral clustering
ID SPARSE; ALGORITHM
AB This paper proposes a novel multiview low-rank clustering method to learn robust multiview clustering from two different data structures, unlike existing methods' one data structure learning technique. Specifically, by inducing the multiview data's manifold through dual data structures to obtain each view's low-rank representation and a similarity matrix, respectively, the proposed method can avoid the uncertainty of one-way manifold learning and obtain optimal clustering performance. To facilitate our approach, each view's low-rank representation is constrained to be a linear mixture of consensus and view-specific parts. In this way, the consensus part and the similarity matrix are then allowed to guide each other to find the more optimal solution adaptively. Besides, we avoid the extra computational time involved in a similarity matrix's spectral post-processing such that our clustering structure is revealed directly through the obtained similarity matrix with the help of a rank constraint. Several experiments were conducted on WebKB, ORL, UCI digits, 3sources, and F-MNIST benchmark datasets to evaluate the effectiveness of the proposed method. Experimental results obtained on all five datasets with respect to six standard evaluation metrics: accuracy, normalized mutual information, adjusted rand index, F-score, precision, and recall reveal that the proposed method has the superior advantage over compared state-of-the-art methods with more than 2% improvements in most experiments. The results also show more than 0.5% improvements over compared deep learning techniques.
C1 [Xu, Zhiyong; Tian, Sirui] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Dept Elect Engn, Nanjing, Peoples R China.
   [Abhadiomhen, Stanley Ebhohimhen; Shen, Xiang-Jun] JiangSu Univ, Sch Comp Sci & Commun Engn, Jiangsu 212013, Peoples R China.
   [Abhadiomhen, Stanley Ebhohimhen] Univ Nigeria, Dept Comp Sci, Nsukka, Nigeria.
C3 Nanjing University of Science & Technology; Jiangsu University;
   University of Nigeria
RP Shen, XJ (corresponding author), JiangSu Univ, Sch Comp Sci & Commun Engn, Jiangsu 212013, Peoples R China.
EM xjshen@ujs.edu.cn
RI Abhadiomhen, Stanley Ebhohimhen/AAH-5788-2021
OI Abhadiomhen, Stanley Ebhohimhen/0000-0002-9509-1915; Tian,
   SIrui/0000-0003-3601-6189
FU Key Program of National Natural Science Foundations of China [41930110]
FX AcknowledgementsThis research was funded in part by the Key Program of
   National Natural Science Foundations of China under Grant No. 41930110.
CR Abhadiomhen SE, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3465056
   Abhadiomhen SE, 2022, APPL INTELL, V52, P530, DOI 10.1007/s10489-021-02409-z
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Brbic M, 2018, PATTERN RECOGN, V73, P247, DOI 10.1016/j.patcog.2017.08.024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai X., 2013, 23 INT JOINT C ART I, P2598
   Chaudhuri K., 2009, P 26 ANN INT C MACH, P129
   Chen J, 2021, KNOWL-BASED SYST
   Deng TQ, 2020, INFORM SCIENCES, V508, P1, DOI 10.1016/j.ins.2019.08.060
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   FAN K, 1950, P NATL ACAD SCI USA, V36, P31, DOI 10.1073/pnas.36.1.31
   Gao W, 2021, SCI PROGRAMMING-NETH, P1
   Guo J., 2021, IEEE T NEUR NET LEAR
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Jing XY, 2021, IEEE T PATTERN ANAL, V43, P139, DOI 10.1109/TPAMI.2019.2929166
   Kumar A., 2011, P 28 INT C MACHINE L, P393
   Kumar P., 2011, Adv. Neural Inf. Process. Syst., P1413, DOI DOI 10.5555/2986459.2986617
   Li RH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2916
   Li Z, 2020, NEUROCOMPUTING
   Liang YW, 2019, IEEE DATA MINING, P1204, DOI 10.1109/ICDM.2019.00148
   Liang YC, 2020, NEUROCOMPUTING, V385, P220, DOI 10.1016/j.neucom.2019.11.058
   Lin, 2010, ARXIV10095055
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu JY, 2022, IEEE T NEUR NET LEAR, V33, P5177, DOI 10.1109/TNNLS.2021.3069424
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170
   Lucinska M, 2012, LECT NOTES COMPUT SC, V7564, P254
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Sun YS, 2021, IEEE ACM T COMPUT BI
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wang QQ, 2021, IEEE T MULTIMEDIA, V23, P3483, DOI 10.1109/TMM.2020.3025666
   Wang SQ, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106745
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang ZY, 2021, IEEE INFOCOM SER, DOI 10.1109/INFOCOM42981.2021.9488756
   Wu F, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107632
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xu J, 2021, IEEE T CYBERNETICS, V51, P1493, DOI 10.1109/TCYB.2019.2943691
   Xu J, 2019, PATTERN RECOGN, V88, P679, DOI 10.1016/j.patcog.2018.12.023
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Xu J, 2015, COMPUT VIS IMAGE UND, V138, P25, DOI 10.1016/j.cviu.2015.04.003
   Xue XQ, 2020, INFORM SCIENCES, V513, P190, DOI 10.1016/j.ins.2019.10.058
   Yang X., 2021, IEEE Transactions on Neural Networks and Learning Systems
   Yin M, 2018, IEEE T IMAGE PROCESS, V27, P3716, DOI 10.1109/TIP.2018.2825647
   Zhai H, 2019, IEEE T GEOSCI REMOTE, V57, P1723, DOI 10.1109/TGRS.2018.2868796
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhou T, 2020, IEEE T CYBERNETICS, V50, P3517, DOI 10.1109/TCYB.2019.2918495
NR 51
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24445
EP 24464
DI 10.1007/s11042-023-14557-0
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000940065100015
DA 2024-07-18
ER

PT J
AU Kaur, K
   Singh, P
AF Kaur, Kamaldeep
   Singh, Parminder
TI Trends in speech emotion recognition: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech; Emotions; Database; Features; Classifiers
ID DEEP LEARNING ARCHITECTURES; FEATURE-SELECTION; NEURAL-NETWORKS;
   FEATURE-EXTRACTION; GOLDEN RATIO; FEATURES; CLASSIFICATION; CLASSIFIERS;
   ALGORITHMS; RECURRENT
AB Among the other modes of communication, such as text, body language, facial expressions, and so on, human beings employ speech as the most common. It contains a great deal of information, including the speaker's feelings. Detecting the speaker's emotions from his or her speech has shown to be quite useful in a variety of real-world applications. The dataset development, feature extraction, feature selection/dimensionality reduction, and classification are the four primary processes in the Speech Emotion Recognition process. In this context, more than 70 studies are thoroughly examined in terms of their databases, emotions, features extracted, and classifiers employed. The databases, characteristics, extraction and classification methods, as well as the results, are all thoroughly examined. The study also includes a comparative analysis of these research papers.
C1 [Kaur, Kamaldeep] IKG Punjab Tech Univ, Kapurthala, Punjab, India.
   [Kaur, Kamaldeep; Singh, Parminder] Guru Nanak Dev Engn Coll, Dept Comp Sci & Engn, Ludhiana, Punjab, India.
C3 I. K. Gujral Punjab Technical University; Guru Nanak Dev Engineering
   College Ludhiana
RP Kaur, K (corresponding author), IKG Punjab Tech Univ, Kapurthala, Punjab, India.; Kaur, K (corresponding author), Guru Nanak Dev Engn Coll, Dept Comp Sci & Engn, Ludhiana, Punjab, India.
EM kamal.gndec@gmail.com
CR Abdel-Hamid L, 2020, SPEECH COMMUN, V122, P19, DOI 10.1016/j.specom.2020.04.005
   Abdelwahab M, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925524, 10.1109/ACII.2019.8925524]
   Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Agrawal S. S., 2011, 2011 Oriental COCOSDA 2011 - International Conference on Speech Database and Assessments, P7, DOI 10.1109/ICSDA.2011.6085972
   Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Albornoz EM, 2017, IEEE T AFFECT COMPUT, V8, P43, DOI 10.1109/TAFFC.2015.2503757
   Albornoz EM, 2011, COMPUT SPEECH LANG, V25, P556, DOI 10.1016/j.csl.2010.10.001
   Anagnostopoulos CN, 2015, ARTIF INTELL REV, V43, P155, DOI 10.1007/s10462-012-9368-5
   [Anonymous], 1997, 5 EUR C SPEECH COMM
   [Anonymous], 1997, The handbook of phonetic sciences
   [Anonymous], 2002, Emotional prosody speech and transcripts'
   [Anonymous], 2009, Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech
   Balakrishnama S., 1998, Institute for Signal and Information Processing, V1998, P1, DOI DOI 10.1073/PNAS.1715593115
   Bansal S, 2013, P INT C OR COCOSDA H, P1, DOI [10.1109/ICSDA.2013.6709867, DOI 10.1109/ICSDA.2013.6709867]
   Bansal S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1865
   BEAUFAYS F, 1995, IEEE T SIGNAL PROCES, V43, P422, DOI 10.1109/78.348125
   Bin Abdul Qayyum Alif, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P122, DOI 10.1109/SPICSCON48833.2019.9065172
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Bou-Ghazale SE, 2000, IEEE T SPEECH AUDI P, V8, P429, DOI 10.1109/89.848224
   Brookes M., 1997, VOICEBOX SPEECH PROC
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2011, INT CONF ACOUST SPEE, P5692
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   C. academic of science Institute of automation, 2005, CASIA CHIN EM SPEECH
   Cao HW, 2015, COMPUT SPEECH LANG, V29, P186, DOI 10.1016/j.csl.2014.01.003
   Chakroborty S, 2010, SPEECH COMMUN, V52, P693, DOI 10.1016/j.specom.2010.04.002
   Chandrasekar P, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P341, DOI 10.1109/CSCITA.2014.6839284
   Chen B, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P180, DOI 10.1109/CIS.2014.148
   Chen C, 2006, LECT NOTES COMPUT SC, V3991, P449
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Chen X.-W., 2007, 6 INT C MACH LEARN A, P429, DOI [10.1109/ICMLA.2007.44, DOI 10.1109/ICMLA.2007.35]
   Chen Yanxiang, 2012, Journal of Electronics (China), V29, P339, DOI 10.1007/s11767-012-0871-2
   Chen Z, 2018, INT CONF BIG DATA, P251, DOI 10.1109/BigComp.2018.00044
   Chiu S, 2008, INTRO DATA MINING, P137, DOI [10.1016/b978-0-7506-8234-3.00007-1, DOI 10.1016/B978-0-7506-8234-3.00007-1]
   Choudhury AR, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P257, DOI 10.1109/ASPCON.2018.8748626
   Clavel C, 2008, SPEECH COMMUN, V50, P487, DOI 10.1016/j.specom.2008.03.012
   Darekar RV, 2018, BIOL INSPIR COGN ARC, V23, P35, DOI 10.1016/j.bica.2018.01.002
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Devillers Laurence, 2007, Speaker Classification II. Selected Projects. (Lecture Notes in Artificial Intelligence Vol.4441), P34
   Dey A, 2020, IEEE ACCESS, V8, P200953, DOI 10.1109/ACCESS.2020.3035531
   Dhall Abhinav., 2011, Acted facial expressions in the wild database
   Duda PEHRO., 1973, PATTERN CLASSIFICATI, V19, P462
   Dupuis Kate, 2011, Canadian Acoustics, V39, P182
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Engberg I., 1996, DOCUMENTATION DANISH
   Er MB, 2020, IEEE ACCESS, V8, P221640, DOI 10.1109/ACCESS.2020.3043201
   essentia.upf, ESSENTIA TOOLKIT
   Eyben F., 2009, 3 INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349350
   Eyben F., 2015, ACM SIGMULTIMEDIA RE, V6, P4, DOI [10.1145/2729095.2729097, DOI 10.1145/2729095.2729097]
   Eyben F, 8 EMOTIONAL SPEECH D
   Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Ezz-Eldin M, 2021, IEEE ACCESS, V9, P19999, DOI 10.1109/ACCESS.2021.3054345
   Fahad MS, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102951
   Faramarzi A, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105190
   Farhoudi Z, 2017, INT J SPEECH TECHNOL, V20, P553, DOI 10.1007/s10772-017-9426-0
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Ferdib-Al-Islam, 2021, 2021 2nd International Conference on Robotics, Electrical and Signal Processing Techniques (ICREST), P445, DOI 10.1109/ICREST51555.2021.9331108
   Fernandez R, 2003, SPEECH COMMUN, V40, P145, DOI 10.1016/S0167-6393(02)00080-8
   Fischer A, 2014, PATTERN RECOGN, V47, P25, DOI 10.1016/j.patcog.2013.05.025
   Fonti V, 2017, VU AMSTERDAM RES PAP, V30, P1, DOI DOI 10.1109/ACCESS.2017.2696365
   FUKUNAGA K, 1983, IEEE T PATTERN ANAL, V5, P671, DOI 10.1109/TPAMI.1983.4767461
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Giannakopoulos T, 2009, INT CONF ACOUST SPEE, P65, DOI 10.1109/ICASSP.2009.4959521
   Gomes J, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P476, DOI 10.1109/CSCI.2015.17
   Grimm M, 2007, INT CONF ACOUST SPEE, P1085
   Hansen J. H., 1997, GETTING STARTED SUSA
   Haque M, 2018, LECT NOTES ELECTR EN, V475, P297, DOI 10.1007/978-981-10-8240-5_33
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Hifny Y, 2019, INT CONF ACOUST SPEE, P6710, DOI 10.1109/ICASSP.2019.8683632
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong Wei, 2010, Proceedings of the 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P445, DOI 10.1109/ICMTMA.2010.604
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hozjan V, 2002, INTERFACE DATABASES
   Huang CC, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/749604
   Huang RQ, 2006, INT C PATT RECOG, P1204
   Islam M., 2020, DIAGNOSIS COVID 19 X
   Islam M. M., 2020, Social Netw. Comput. Sci., V1, P1, DOI [10.1007/s42979-020-00223-x, DOI 10.1007/S42979-020-00223-X]
   Islam MR, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104757
   Islam MR, 2021, IEEE ACCESS, V9, P94601, DOI 10.1109/ACCESS.2021.3091487
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jackson Philip, 2011, Surrey audio-visual expressed emotion (SAVEE) database.
   Jaiswal JK, 2017, 2017 2ND WORLD CONGRESS ON COMPUTING AND COMMUNICATION TECHNOLOGIES (WCCCT), P65, DOI 10.1109/WCCCT.2016.25
   Jaratrotkamjorn Apichart, 2019, 2019 23rd International Computer Science and Engineering Conference (ICSEC), P103, DOI 10.1109/ICSEC47112.2019.8974707
   Jiang PX, 2019, IEEE ACCESS, V7, P90368, DOI 10.1109/ACCESS.2019.2927384
   Jing SL, 2018, DIGIT SIGNAL PROCESS, V72, P216, DOI 10.1016/j.dsp.2017.10.016
   Kamble Vaibhav V., 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1984, DOI 10.1109/ICCSP.2014.6950191
   Kandali AB, 2008, TENCON IEEE REGION, P1543
   Kate Dupuis MKP-F, 2010, TORONTO EMOTIONAL SP
   Kattubadi IB, 2019, INT CONF ADVAN COMPU, P285, DOI [10.1109/icaccs.2019.8728519, 10.1109/ICACCS.2019.8728519]
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Khan A, 2016, P INTRO DEEP NEURAL, DOI [10.13140/RG.2.2.17217.15200, DOI 10.13140/RG.2.2.17217.15200]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Koolagudi SG, 2011, 2011 international conference on devices and communications (ICDeCom), P1
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Koolagudi SG, 2018, INT J SPEECH TECHNOL, V21, P167, DOI 10.1007/s10772-018-9495-8
   Koolagudi SG, 2009, COMM COM INF SC, V40, P485, DOI 10.1007/978-3-642-03547-0_46
   Krothapalli SR, 2013, INT J SPEECH TECHNOL, V16, P181, DOI 10.1007/s10772-012-9175-z
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   Kuchibhotla S, 2014, INT J SPEECH TECHNOL, V17, P401, DOI 10.1007/s10772-014-9239-3
   Kwon O.-W., 2003, Interspeech, P125
   Lalitha S, 2019, INT J SPEECH TECHNOL, V22, P497, DOI 10.1007/s10772-018-09572-8
   Lalitha S, 2015, 2015 IEEE INT C COMP, DOI [10.1109/ICCIC.2015.7435630, DOI 10.1109/ICCIC.2015.7435630]
   Langley P, 1998, P 10 NATL C ARTIFICI, V90
   Lee CY, 2018, APPL SOFT COMPUT, V68, P961, DOI 10.1016/j.asoc.2017.04.055
   Lee CM, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P737, DOI 10.1109/ICME.2002.1035887
   Lee KH, 2019, I C INF COMM TECH CO, P1162, DOI 10.1109/ictc46691.2019.8939830
   Li DD, 2021, EXPERT SYST APPL, V173, DOI 10.1016/j.eswa.2021.114683
   Li JM, 2018, CHIN AUTOM CONGR, P2705, DOI 10.1109/CAC.2018.8623055
   Li X, 2007, SPEECH FEAT TOOLB SP
   Liam, 2017, PERFORMANCE MEASURES
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Litman D., 2004, PROC ANN M ASS COMPU, P351, DOI DOI 10.3115/1218955.1219000
   Liu B, 2018, NEUROCOMPUTING, V277, P101, DOI 10.1016/j.neucom.2017.05.097
   Liu YG, 2014, INT J MOB COMPUT MUL, V6, P20, DOI 10.4018/IJMCMC.2014100102
   Liu ZT, 2018, NEUROCOMPUTING, V309, P145, DOI 10.1016/j.neucom.2018.05.005
   Liu ZT, 2018, NEUROCOMPUTING, V273, P271, DOI 10.1016/j.neucom.2017.07.050
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Loizou PC, 1998, COLEA MATLAB SOFTWAR
   Lotfian R, 2019, IEEE T AFFECT COMPUT, V10, P471, DOI 10.1109/TAFFC.2017.2736999
   Luengo I, 2010, IEEE T MULTIMEDIA, V12, P490, DOI 10.1109/TMM.2010.2051872
   Majkowski A, 2016, SIG P ALGO ARCH ARR, P276, DOI 10.1109/SPA.2016.7763627
   Manjunath R., 2013, INT J IMAGE PROCESSI, V1, P16
   Mannepalli K, 2016, INT J SPEECH TECHNOL, V19, P779, DOI 10.1007/s10772-016-9368-y
   Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P629, DOI 10.1109/TSMCB.2002.804363
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mao X, 2010, IEICE T INF SYST, VE93D, P2324, DOI 10.1587/transinf.E93.D.2324
   MARILL T, 1963, IEEE T INFORM THEORY, V9, P11, DOI 10.1109/TIT.1963.1057810
   Martin O, 2006, 22 INT C DAT ENG WOR, DOI [10.1109/ICDEW.2006.145, DOI 10.1109/ICDEW.2006.145]
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Meftah A, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Meftah A, 2016, 2016 INTERNATIONAL CONFERENCE ON BIO-ENGINEERING FOR SMART TECHNOLOGIES (BIOSMART)
   Milton A, 2014, COMPUT SPEECH LANG, V28, P727, DOI 10.1016/j.csl.2013.08.004
   Mohammed T, 2017, SPR PROC BUS ECON, P1, DOI 10.1007/978-3-319-48454-9_1
   Mohanta A, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2812
   Montenegro CS, 2015, 8 INT C HUMANOID NAN, DOI [10.1109/HNICEM.2015.7393229, DOI 10.1109/HNICEM.2015.7393229]
   Morin D, 2004, ENCYCLOPEDIC DICT GE, P1, DOI [10.1002/0471684228.egp01270, DOI 10.1002/0471684228.EGP01270]
   Mustafa MB, 2018, INT J SPEECH TECHNOL, V21, P137, DOI 10.1007/s10772-018-9493-x
   Nanavare VV, 2015, PROCEDIA COMPUT SCI, V49, P24, DOI 10.1016/j.procs.2015.04.223
   Nematollahi AF, 2020, SOFT COMPUT, V24, P1117, DOI 10.1007/s00500-019-03949-w
   Nicholson J, 2000, NEURAL COMPUT APPL, V9, P290, DOI 10.1007/s005210070006
   Ortony A., 1988, The Cognitive Structure of Emotions, DOI DOI 10.1017/CBO9780511571299
   OShea K, 2015, INTRO CONVOLUTIONAL, DOI [10.48550/arXiv.1511.08458, DOI 10.48550/ARXIV.1511.08458]
   Özseven T, 2018, APPL ACOUST, V136, P1, DOI 10.1016/j.apacoust.2018.02.009
   Palo HK, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P127, DOI 10.1109/ICDSBA.2018.00030
   Palo HK, 2016, INT J SPEECH TECHNOL, V19, P135, DOI 10.1007/s10772-016-9333-9
   Panda Swagat Kumar, 2019, 2019 IEEE International Conference on System, Computation, Automation and Networking (ICSCAN). Proceedings, DOI 10.1109/ICSCAN.2019.8878775
   Partila P, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P416
   Pathak BV, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P201, DOI [10.1109/ICCS45141.2019.9065620, 10.1109/iccs45141.2019.9065620]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petrushin V., 1999, Proc. Artif. Neural Netw. Eng., V710, P22
   Picard R. W., 1997, AFFECTIVE COMPUTING
   Pratiwi ON, 2015, COMM COM INF SC, V516, P205, DOI 10.1007/978-3-662-46742-8_19
   Prinz J., 2004, Which emotions are basic, P69, DOI DOI 10.1093/ACPROF:OSO/9780198528975.003.0004
   Pudil S, 1991, KYBERNETIKA, V1
   Pyrczak F, 2019, INTRO T TEST, DOI [10.4324/9781315179803-28, DOI 10.4324/9781315179803-28]
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rajisha TM, 2016, PROC TECH, V24, P1097, DOI 10.1016/j.protcy.2016.05.242
   Rajoo R, 2016, 2016 IEEE SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P35, DOI 10.1109/ISCAIE.2016.7575033
   Ram ES, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P19, DOI 10.1109/ICICICT.2014.6781245
   Rao KS, 2013, INT J SPEECH TECHNOL, V16, P143, DOI 10.1007/s10772-012-9172-2
   Ren MJ, 2019, VIS INFORM, V3, P150, DOI 10.1016/j.visinf.2019.10.003
   Revathi A, 2019, INT J SPEECH TECHNOL, V22, P473, DOI 10.1007/s10772-018-9533-6
   Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Roubos H, 2000, P DEV SOFT COMPUTING, V150, P108, DOI [10.1007/978-3-7908-1829-1_13, DOI 10.1007/978-3-7908-1829-1_13]
   Ryerson, 2017, MULTIMEDIA RES LAB R
   Sadeghyan S, 2018, ARXIV, DOI [10.48550/arXiv.1804.05092, DOI 10.48550/ARXIV.1804.05092]
   Sari H, 1996, SIGNAL PROCESSING TE, P374
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Savargiv M, 2015, 2015 7TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT)
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schubiger M., 1958, ENGLISH INTONATIONIT
   Schuller B, 2013, INTERSPEECH, P148
   Schuller B, 2011, SPEECH COMMUN, V53, P1062, DOI 10.1016/j.specom.2011.01.011
   Shahin I, 2019, IEEE ACCESS, V7, P26777, DOI 10.1109/ACCESS.2019.2901352
   Sheikhan M, 2013, NEURAL COMPUT APPL, V23, P215, DOI 10.1007/s00521-012-0814-8
   Song P, 2015, ELECTRON LETT, V51, P112, DOI 10.1049/el.2014.3339
   Spolaôr N, 2013, 2013 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P6, DOI 10.1109/BRACIS.2013.10
   Suganya S, 2019, INT CONF ADV ICT, DOI 10.1109/icter48817.2019.9023737
   Sun LH, 2019, SPEECH COMMUN, V115, P29, DOI 10.1016/j.specom.2019.10.004
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Swain M, 2018, INT J SPEECH TECHNOL, V21, P93, DOI 10.1007/s10772-018-9491-z
   Swain M, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1644, DOI 10.1109/TENCON.2016.7848296
   Tacconi D, 2008, 2008 2ND INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING TECHNOLOGIES FOR HEALTHCARE, P93
   Taha T.M., 2018, Int. J. Comput. Appl, V179, P1
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Uhrin D, 2014, 2014 22ND TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P529, DOI 10.1109/TELFOR.2014.7034463
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI 10.1145/2661806.2661807
   Van Lierde K, 1996, Acta Otorhinolaryngol Belg, V50, P309
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Vihari S, 2016, PROCEDIA COMPUT SCI, V89, P666, DOI 10.1016/j.procs.2016.06.032
   Vlasenko B., 2007, DAGA, V1, P1
   Vrebcevic N, 2019, 2019 42ND INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1007, DOI [10.23919/MIPRO.2019.8756867, 10.23919/mipro.2019.8756867]
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wang XC, 2003, PATTERN RECOGN, V36, P2429, DOI 10.1016/S0031-3203(03)00044-X
   WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410
   Williams CE, 1981, SPEECH EVAL PSYCHIAT
   Wu G, 2021, APPL NUMER MATH, V164, P101, DOI 10.1016/j.apnum.2020.09.013
   Wu J., 2017, Nat. Key Lab Novel Softw. Technol. Nanjing Univ. China, V5, P495, DOI DOI 10.1007/978-3-642-28661-2-5
   Yao ZW, 2020, SPEECH COMMUN, V120, P11, DOI 10.1016/j.specom.2020.03.005
   Ye CX, 2008, LECT NOTES COMPUT SC, V5353, P61
   Yegnanarayana B., 2009, ARTIFICIAL NEURAL NE
   Yildirim S, 2011, COMPUT SPEECH LANG, V25, P29, DOI 10.1016/j.csl.2009.12.004
   Yu C, 2004, ARXIV, DOI [10.48550/arXiv.cs/0410027, DOI 10.48550/ARXIV.CS/0410027]
   Yulan Li, 2019, 2019 23rd International Computer Science and Engineering Conference (ICSEC), P351, DOI 10.1109/ICSEC47112.2019.8974716
   Zang Q, 2013, 2013 INT S SIGNAL PR
   Zeynep Inanoglu RC, 2005, EMOTIVE ALERT HMM BA
   ZHALEHPOUR S, 2016, IEEE T AFFECT COMPUT, P1
   Zhang C, 2019 IEEECVF C COMPU, P2577
   Zhang HY, 2021, IEEE ACCESS, V9, P5332, DOI 10.1109/ACCESS.2020.3047395
   Zhang SQ, 2020, IEEE ACCESS, V8, P23496, DOI 10.1109/ACCESS.2020.2969032
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang X, 2018, 2018 1 ASIAN C AFFEC, P1, DOI [10.1109/ACIIAsia.2018, DOI 10.1109/ACIIASIA.2018]
   Zhang ZX, 2015, IEEE-ACM T AUDIO SPE, V23, P115, DOI 10.1109/TASLP.2014.2375558
   Zhao JF, 2018, IET SIGNAL PROCESS, V12, P713, DOI 10.1049/iet-spr.2017.0320
   Zhao ZP, 2019, IEEE ACCESS, V7, P97515, DOI 10.1109/ACCESS.2019.2928625
   Zhen Li, 2019, 2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS). Proceedings, P186
NR 227
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29307
EP 29351
DI 10.1007/s11042-023-14656-y
EA FEB 2023
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936302600010
DA 2024-07-18
ER

PT J
AU Lee, JS
   Chen, YC
   Hsieh, YH
   Chang, SH
   Huynh, NT
AF Lee, Jung-San
   Chen, Yin-Chin
   Hsieh, Yun-Hao
   Chang, Shih-Hao
   Huynh, Ngoc-Tu
TI Preserving friendly stacking and weighted shadows in selective scalable
   secret image sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Friendly stacking; Secret image sharing; Scalability; Selectivity;
   Weighted shadow
ID STEGANOGRAPHY; SCHEME
AB With advancement of technology, the technique of selective scalable secret image sharing (SSSIS) was first proposed in 2017 as a new alternative of secret image sharing. The region of interest (ROI) in the protected secret could be revealed progressively once the number of collected shadows has reached a predefined threshold. Accordingly, the ROIs of the secret image increase based on the number of collected shadows. Nonetheless, players without sufficient shadows may be able to learn the location and contour of hidden secret to perform advanced guessing attacks. Thus, we aim to introduce friendly stacking to yield a genuine outcome of mitigating this risk during the recovery process. Furthermore, the weighting concept is brought into constructing the meaningful shadow so that the priority of a specific participant can be emphasized to approach real applications.
C1 [Lee, Jung-San; Chen, Yin-Chin; Hsieh, Yun-Hao] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Shih-Hao] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Huynh, Ngoc-Tu] Ton Duc Thang Univ, Dept Informat Technol, Ho Chi Minh City, Vietnam.
C3 Feng Chia University; National Taipei University of Technology; Ton Duc
   Thang University
RP Huynh, NT (corresponding author), Ton Duc Thang Univ, Dept Informat Technol, Ho Chi Minh City, Vietnam.
EM leejs@fcu.edu.tw
OI Lee, Jung-San/0000-0001-7030-2985
CR Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen CC, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3268362
   Chen YC, 2018, MULTIMED TOOLS APPL, V77, P27107, DOI 10.1007/s11042-018-5908-6
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Kamble PR, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1090, DOI 10.1109/ICISC.2018.8398972
   Lee JS, 2017, MULTIMED TOOLS APPL, V76, P1, DOI 10.1007/s11042-015-3011-9
   Lee JS, 2016, IEEE T CIRC SYST VID, V26, P1004, DOI 10.1109/TCSVT.2015.2430591
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2009, OPT ENG, V48, DOI 10.1117/1.3168644
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2009, LECT NOTES COMPUT SC, V5414, P988, DOI 10.1007/978-3-540-92957-4_86
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu XT, 2019, DIGIT SIGNAL PROCESS, V93, P22, DOI 10.1016/j.dsp.2019.06.016
   Xie XZ, 2019, IET IMAGE PROCESS, V13, P1411, DOI 10.1049/iet-ipr.2018.5333
   Xiong LZ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107571
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2019, IEEE T CIRC SYST VID, V29, P252, DOI 10.1109/TCSVT.2017.2771255
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29283
EP 29305
DI 10.1007/s11042-023-14712-7
EA FEB 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000936302600009
DA 2024-07-18
ER

PT J
AU Devi, PRS
   Baskaran, R
AF Devi, Suganya P. R.
   Baskaran, R.
TI A two-phase approach for expression invariant 3D face recognition using
   fine-tuned VGG-16 and 3D-SIFT descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face recognition; Face expression; Kernel principal component
   analysis; 3D-SIFT; VGG-16
ID 3-D FACE; SPARSE REPRESENTATION; MULTISCALE; FEATURES
AB Expression invariant 3D face recognition systems have many computer vision applications such as human-computer interaction. Most 3D face recognition systems rely on rigid region features and a substantial amount of training data to achieve better accuracy. However, the computational cost of these systems is very high. In order to address the problem of compromising computational efficiency for accuracy, this paper presents a computationally efficient two-phase expression invariant 3D face recognition approach using fine-tuned VGG-16 and 3D-SIFT descriptors. In the first phase, the pre-trained VGG-16 is fine-tuned with the Texas database and the CASIA-3D database. The candidates are recognized using the fused features from the fine-tuned VGG-16 and landmarks-based angles. In the second phase, the 3D-SIFT descriptors are computed on the rigid component of the probe and candidate 3D faces. Then, the final identity is obtained based on the best 3D-SIFT keypoints' match score. Reporting competitive results in comparison to the state-of-the-art, the proposed method achieves 100% and 97.69% recognition rates respectively for the neutral-neutral and neutral-non neutral scenarios on the Bosphorus Database. Further, it requires only 1.27 seconds to identify a probe from a gallery with 105 faces.
C1 [Devi, Suganya P. R.; Baskaran, R.] Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai, India.
C3 Anna University; Anna University Chennai
RP Devi, PRS (corresponding author), Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai, India.
EM suganya.rvks5@gmail.com
CR Abbad A, 2018, COMPUT ELECTR ENG, V70, P525, DOI 10.1016/j.compeleceng.2017.08.017
   Adjabi I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081188
   Al-Osaimi FR, 2020, J IMAGING, V6, DOI 10.3390/jimaging6110112
   Alyüz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081
   Amberg B, 2008, IEEE INT CONF AUTOMA, P667
   Amor BB, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, P150
   [Anonymous], 2010, 2010 2 INT C SIGNAL
   [Anonymous], 2011, 2011 INT JOINT C BIO, DOI DOI 10.1109/IJCB.2011.6117521
   [Anonymous], 2005, CVPR WORKSH
   [Anonymous], 2004, CASIA 3DFACEV1
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P35973, DOI 10.1007/s11042-020-10160-9
   Cai Y, 2019, NEUROCOMPUTING, V363, P375, DOI 10.1016/j.neucom.2019.07.047
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Cignoni P., 2008, P EUR IT CHAPT C, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/129-136]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devi PRS, 2021, APPL INTELL, V51, P2253, DOI 10.1007/s10489-020-02000-y
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Feng S, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P156, DOI 10.1109/SSP.2007.4301238
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279
   Guo YL, 2016, PATTERN RECOGN LETT, V83, P403, DOI 10.1016/j.patrec.2016.04.003
   Gupta SD, 2010, METHODS MOL BIOL, V589, P97, DOI [10.1007/978-1-60327-114-1_10, 10.1109/SSIAI.2010.5483908]
   Huang D., 2010, Consumer Communications and Networking Conference (CCNC), P1
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang D, 2011, LECT NOTES COMPUT SC, V6523, P206
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018
   Li Y, 2018, NEUROCOMPUTING, V275, P1295, DOI 10.1016/j.neucom.2017.09.070
   Liu PJ, 2013, IEEE T IMAGE PROCESS, V22, P914, DOI 10.1109/TIP.2012.2222897
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XG, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P156
   Lu XG, 2008, IEEE T PATTERN ANAL, V30, P1346, DOI 10.1109/TPAMI.2007.70784
   Medioni G, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P232
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Miao S, 2010, INT CONF ACOUST SPEE, P1134, DOI 10.1109/ICASSP.2010.5495363
   Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107
   Morales A, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100400
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Mpiperis I, 2007, IEEE T INF FOREN SEC, V2, P537, DOI 10.1109/TIFS.2007.902326
   Nassih B, 2021, COMP GEOM-THEOR APPL, V97, DOI 10.1016/j.comgeo.2021.101758
   Quan W, 2016, PATTERN ANAL APPL, V19, P765, DOI 10.1007/s10044-014-0439-x
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Rajagopal SD, 2022, COMPUT INTELL-US, V38, P345, DOI 10.1111/coin.12498
   Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeets D., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1172, DOI 10.1109/ICPR.2010.293
   Smeets D, 2013, COMPUT VIS IMAGE UND, V117, P158, DOI 10.1016/j.cviu.2012.10.002
   Soltanpour S, 2019, IEEE T IMAGE PROCESS, V28, P3020, DOI 10.1109/TIP.2019.2893524
   Soltanpour S, 2017, IET BIOMETRICS, V6, P27, DOI 10.1049/iet-bmt.2015.0120
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tang HL, 2013, SIGNAL PROCESS, V93, P2190, DOI 10.1016/j.sigpro.2012.04.002
   Wang Yuan, 2022, IPMV 2022: 2022 4th International Conference on Image Processing and Machine Vision (IPMV), P13, DOI [10.1109/CCISP55629.2022.9974287, 10.1145/3529446.3529449]
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Zhou S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0157-2
NR 63
TC 1
Z9 1
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23873
EP 23890
DI 10.1007/s11042-023-14407-z
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000936195100006
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Chang, TY
   Lai, CC
AF Kuo, Lungwen
   Chang, Tsuiyueh
   Lai, Chih-Chun
TI Color aesthetics with regard to product design and multimedia web pages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design; Web pages; Color; Product; Multimedia
ID VISUAL-SEARCH; PREFERENCE; USABILITY; EMOTIONS
AB The present study combined product design and web page color aesthetics, and various affective adjectives were applied to create a design mode that supports designers in developing multimedia web page colors. These approaches help designers understand the importance of colors and imagery in multimedia web pages and visual design. This study adopted the semantic differential to extract user-centered emotional dimensions and obtain crucial design factors for home page appearance. The most preferred visual design was determined through analyses of products affective features as perceived by users. A data assessment was then conducted using the semantic differential to examine the quantitative relationship between web page designs and emotional dimensions. Finally, a Likert-type scale was used to identify the most appropriate web page color. This study contributes to web page design that satisfies user emotions and can also serve as a reference for multimedia web page color research. The findings of Experiment 1 on web page design-related emotional adjectives revealed that "convenient," "technology," "vintage," and "distinctive" were the most appropriate emotional adjectives for the web page visual design experiment. With regard to Experiment 2 on the visual design of multimedia web pages, the most appropriate composition was the one that presented the product in the center of a rectangle with dynamic effects. Experiment 3 on multimedia web page color fit indicated that the most appropriate colors were royal blue, slate blue, and black. Experiment 4 on the two-color fit of multimedia web pages revealed that the most appropriate two-color pairs were royal blue/cyan and royal blue/black. Through investigations of design management mode and emotional factors, this study can provide a platform containing design methods for designers, allowing them to rapidly grasping consumer preferences and to incorporate correlations of product-related terms in styling, colors, and elements in multimedia webpages. Therefore, these researchers can achieve the goal of innovative design and research.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA 95131 USA.
   [Lai, Chih-Chun] Tatung Univ, Dept Ind Design, Taipei, Taiwan.
C3 Sanming University; Tatung University
RP Chang, TY (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA 95131 USA.
EM yueh5031162@yahoo.com.tw
RI Kuo, Lungwen/AAV-1958-2021; lai, chih chun/AAE-6772-2021
OI Kuo, Lungwen/0000-0001-9894-2706; Lai, Chih-Chun/0000-0003-4261-6228
CR Akça E, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102031
   Barry C., 2001, IEEE Multimedia, V8, P52, DOI 10.1109/93.917971
   Bonnardel N, 2011, DISPLAYS, V32, P69, DOI 10.1016/j.displa.2010.12.002
   Brown Alex, 2016, Proceedings of the Association for Information Science and Technology, V53, P1, DOI [DOI 10.1002/PRA2.2016.14505301040, 10.1002/pra2.2016.14505301040,arXiv:https://asistdl.onlinelibrary.wiley.com/doi/pdf/10.1002/pra2, DOI 10.1002/PRA2.2016.14505301040,ARXIV:HTTPS://ASISTDL.ONLINELIBRARY.WILEY.COM/DOI/PDF/10.1002/PRA2]
   Bulterman DCA, 2007, MULTIMEDIA SYST, V12, P423, DOI 10.1007/s00530-006-0065-6
   Celentano A, 2006, MULTIMED TOOLS APPL, V29, P7, DOI 10.1007/s11042-006-7811-9
   Celentano A, 2017, MULTIMED TOOLS APPL, V76, P5511, DOI 10.1007/s11042-016-3790-7
   Cheng C, 2017, HEALTH PROMOT J AUST, V28, P15, DOI 10.1071/HE15127
   Cyr D, 2010, INT J HUM-COMPUT ST, V68, P1, DOI 10.1016/j.ijhcs.2009.08.005
   Gaggi O, 2005, MULTIMED TOOLS APPL, V27, P53, DOI 10.1007/s11042-005-2714-8
   Guo F, 2016, HUM FACTOR ERGON MAN, V26, P110, DOI 10.1002/hfm.20617
   Hagtvedt H, 2020, PSYCHOL MARKET, V37, P864, DOI 10.1002/mar.21268
   Hsu CC, 2012, DISPLAYS, V33, P119, DOI 10.1016/j.displa.2012.04.001
   Hsu CC, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2011.01.009
   Jalali NY, 2016, QME-QUANT MARK ECON, V14, P353, DOI 10.1007/s11129-016-9178-1
   Lee S, 2010, COMPUT IND, V61, P329, DOI 10.1016/j.compind.2009.12.004
   Li H, 2013, ETRI J, V35, P900, DOI 10.4218/etrij.13.0112.0834
   Lin HY, 2014, DISPLAYS, V35, P202, DOI 10.1016/j.displa.2014.05.009
   Ling J, 2007, DISPLAYS, V28, P60, DOI 10.1016/j.displa.2007.04.003
   Liu WL, 2016, DISPLAYS, V42, P25, DOI 10.1016/j.displa.2016.02.004
   Liu X, 2021, FUTURE GENER COMP SY, V117, P433, DOI 10.1016/j.future.2020.12.014
   Michalski R, 2014, DISPLAYS, V35, P176, DOI 10.1016/j.displa.2014.05.007
   Miller C., 2012, Journal of Information Literacy, V6, P35
   Moretti G, 2013, COLOR RES APPL, V38, P203, DOI 10.1002/col.20736
   Motoki K, 2022, J BUS RES, V150, P365, DOI 10.1016/j.jbusres.2022.06.013
   Nemcsics A, 2009, COLOR RES APPL, V34, P210, DOI 10.1002/col.20489
   Ou LC, 2006, COLOR RES APPL, V31, P191, DOI 10.1002/col.20208
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Park SE, 2004, INTERACT COMPUT, V16, P351, DOI 10.1016/j.intcom.2003.07.001
   Salmerón L, 2020, J COMPUT ASSIST LEAR, V36, P1038, DOI 10.1111/jcal.12458
   Schloss KB, 2011, ATTEN PERCEPT PSYCHO, V73, P551, DOI 10.3758/s13414-010-0027-0
   Schmidt KE, 2009, ERGONOMICS, V52, P631, DOI 10.1080/00140130802558995
   Thorlacius L, 2007, NORD REV, V28, P63, DOI 10.1515/nor-2017-0201
   Wan HY, 2021, INFORM SCIENCES, V576, P589, DOI 10.1016/j.ins.2021.06.071
   Wang C, 2018, J ASSOC INF SCI TECH, V69, P1007, DOI 10.1002/asi.24025
   Wu O, 2018, MULTIMED TOOLS APPL, V77, P6671, DOI 10.1007/s11042-017-4582-4
   Xiao XZ, 2009, COMPUT GRAPH FORUM, V28, P1879, DOI 10.1111/j.1467-8659.2009.01566.x
   Xie XF, 2011, RISK ANAL, V31, P450, DOI 10.1111/j.1539-6924.2010.01530.x
   Yang CK, 2008, IEEE COMPUT GRAPH, V28, P52, DOI 10.1109/MCG.2008.24
   Yang Y, 2017, MULTIMED TOOLS APPL, V76, P523, DOI 10.1007/s11042-015-3063-x
NR 40
TC 1
Z9 1
U1 7
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22905
EP 22923
DI 10.1007/s11042-023-14580-1
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000934222700001
DA 2024-07-18
ER

PT J
AU Mukhopadhyay, R
   Gupta, P
   Satti, P
   Garg, B
AF Mukhopadhyay, Ritwik
   Gupta, Prakhar
   Satti, Piyush
   Garg, Bharat
TI Adaptive Radii selection based Inpainting method for impulse noise
   removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Inpainting; Mean filters; Salt and pepper noise; Image restoration
   and denoising
ID SWITCHING MEDIAN FILTER; HIGH-DENSITY SALT
AB Digital images acquired via electronic products are prone to corruption by various noises among which Salt & Pepper noise is one such variant. In cases of corruption by said noise, it is important to apply image restoration techniques that regenerate corrupted pixel values. In this document, an Adaptive Radii Selection based Inpainting Method is proposed, which makes use of the Telea Inpainting algorithm by dynamically choosing the optimal radii with which the best denoised pixel can be obtained. The radii selection is based on observed noise density in a particular window around the noisy pixels. Further, a recombination logic is applied to the inpainted images to obtaining the restored image. Qualitative and Quantitative analysis have been performed on standard images as well as the Kodak image dataset. This work serves as an extension to the Telea Inpainting algorithm for denoising efforts showing an improvement in quality metrics such as PSNR by 0.31dB and 8-12% in IEF.
C1 [Mukhopadhyay, Ritwik; Gupta, Prakhar; Satti, Piyush; Garg, Bharat] Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Garg, B (corresponding author), Thapar Inst Engn & Technol, ECED, Patiala, Punjab, India.
EM rmukhopadhyay_be17@thapar.edu; pgupta8_be17@thapar.edu;
   psatti_be17@thapar.edu; bharat.garg@thapar.edu
RI Garg, Bharat/P-2979-2018
OI Garg, Bharat/0000-0002-2904-3720
FU Thapar Institute of Engineering Technology (TIET), Patiala, India
FX This work is supported by Thapar Institute of Engineering Technology
   (TIET), Patiala, India.
CR Appiah O, 2022, J KING SAUD UNIV-COM, V34, P782, DOI 10.1016/j.jksuci.2020.04.005
   Balasubramanian G, 2016, IMAGING SCI J, V64, P241, DOI 10.1080/13682199.2016.1168144
   Chen JN, 2019, IET IMAGE PROCESS, V13, P2604, DOI 10.1049/iet-ipr.2019.0096
   Thanh DNH, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2019.163677
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Erkan U, 2020, IET IMAGE PROCESS, V14, P1291, DOI 10.1049/iet-ipr.2019.0398
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Garg B, 2020, MULTIMED TOOLS APPL, V79, P32305, DOI 10.1007/s11042-020-09557-3
   Garg B, 2020, SIGNAL IMAGE VIDEO P, V14, P1555, DOI 10.1007/s11760-020-01695-3
   Gupta M, 2023, MULTIMED TOOLS APPL, V82, P5091, DOI 10.1007/s11042-022-12169-8
   Kalita DJ, 2022, SOFT COMPUT, V26, P2277, DOI 10.1007/s00500-021-06498-3
   Nair MS, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P426, DOI 10.1109/CISP.2008.21
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Patel P., 2012, INT J IMAGE GRAPH, V4, P5
   Pitas I., 1990, Nonlinear Digital Filters, DOI [10.1007/978-1-4757-6017-0, DOI 10.1007/978-1-4757-6017-0]
   Satti P., 2022, J LOW FREQ NOISE V A, V5, P1
   Satti P, 2020, IEEE SIGNAL PROC LET, V27, P1475, DOI 10.1109/LSP.2020.3016868
   Sohi P. J. S., 2020, INNOVATIONS COMPUTAT, P150
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Thanh DN, 2020, OPTIK
   Veerakumar T, 2014, SIGNAL IMAGE VIDEO P, V8, P159, DOI 10.1007/s11760-013-0517-3
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
   Vijaykumar V. R., 2008, IAENG International Journal of Computer Science, V35, P259
   Vinay Kumar S.B., 2018, Journal of King Saud University - Computer and Information Sciences
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
NR 27
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27615
EP 27634
DI 10.1007/s11042-023-14466-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000934222700007
DA 2024-07-18
ER

PT J
AU Yun, HI
   Park, JS
AF Yun, Hong-In
   Park, Jeong-Sik
TI End-to-end emotional speech recognition using acoustic model adaptation
   based on knowledge distillation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotional speech recognition; Deep neural network; Model adaptation;
   Model compression; Knowledge distillation
ID NEURAL-NETWORKS
AB The end-to-end approach provides better performance in speech recognition compared to the traditional hidden Markov model-deep neural network (HMM-DNN)-based approach, but still shows poor performance in abnormal speech, especially emotional speech. The optimal solution is to build an acoustic model suitable for emotional speech recognition using only emotional speech data for each emotion, but it is impossible because it is difficult to collect sufficient amount of emotional speech data for each emotion. In this study, we propose a method to improve the emotional speech recognition performance by using the knowledge distillation technique that was originally introduced to decrease computational intensity of deep learning-based approaches by reducing the number of model parameters. In addition to its use as model compression, we employ this technique for model adaptation to emotional speech. The proposed method builds a basic model (referred to as a teacher model) with a number of model parameters using an amount of normal speech data, and then constructs a target model (referred to as a student model) with fewer model parameters using a small amount of emotional speech data (i.e., adaptation data). Since the student model is built with emotional speech data, it is expected to reflect the emotional characteristics of each emotion well. In the emotional speech recognition experiment, the student model maintained recognition performance regardless of the number of model parameters, whereas the teacher model degraded performance significantly as the number of parameters decreased, showing performance degradation of about 10% in word error rate. This result demonstrates that the student model serves as an acoustic model suitable for emotional speech recognition even though it does not require much emotional speech data.
C1 [Yun, Hong-In] Hankuk Univ Foreign Studies, Dept English Linguist, Seoul, South Korea.
   [Park, Jeong-Sik] Hankuk Univ Foreign Studies, Dept English Linguist & Language Technol, Seoul, South Korea.
C3 Hankuk University Foreign Studies; Hankuk University Foreign Studies
RP Park, JS (corresponding author), Hankuk Univ Foreign Studies, Dept English Linguist & Language Technol, Seoul, South Korea.
EM gnlenfn@gmail.com; parkjs@hufs.ac.kr
OI Park, Jeong-Sik/0000-0002-4213-8775
FU Hankuk University of Foreign Studies Research Fund; National Research
   Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2020R1A2C1013162]
FX AcknowledgementsThis research was supported by Hankuk University of
   Foreign Studies Research Fund and the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIT) (No.
   NRF-2020R1A2C1013162).
CR Aida-zade K, 2016, I C APPL INF COMM TE, P108
   Alkhulaifi A, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.474
   Amodei D, 2016, PR MACH LEARN RES, V48
   Athanaselis T, 2005, NEURAL NETWORKS, V18, P437, DOI 10.1016/j.neunet.2005.03.008
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chebotar Y, 2016, INTERSPEECH, P3439, DOI 10.21437/Interspeech.2016-1190
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dean J., 2015, NIPS DEEP LEARNING R
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gharavian D., 2010, Majlesi Journal of Electrical Engineering, V4, P19
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kim JB, 2016, ENG APPL ARTIF INTEL, V52, P126, DOI 10.1016/j.engappai.2016.02.018
   Kosaka T, 2018, ASIAPAC SIGN INFO PR, P1747, DOI 10.23919/APSIPA.2018.8659756
   Kurata G, 2018, IEEE W SP LANG TECH, P411, DOI 10.1109/SLT.2018.8639629
   Li YC, 2019, INTERSPEECH, P2803, DOI 10.21437/Interspeech.2019-2594
   Liu J, 2006, LECT NOTES COMPUT SC, V4274, P87
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Na HJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188412
   Najkar N, 2010, MATH COMPUT MODEL, V52, P1910, DOI 10.1016/j.mcm.2010.03.041
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Park JS, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196876
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Senior A, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P604, DOI 10.1109/ASRU.2015.7404851
   Sheikhan M, 2012, NEURAL COMPUT APPL, V21, P1765, DOI 10.1007/s00521-011-0620-8
   Singh YB, 2021, MULTIMED TOOLS APPL, V80, P14001, DOI 10.1007/s11042-020-10399-2
   Siriwardhana S, 2020, ARXIV
   Takashima R, 2019, INT CONF ACOUST SPEE, P6156, DOI 10.1109/ICASSP.2019.8682671
   Takashima R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5809, DOI 10.1109/ICASSP.2018.8461995
   Thiruvengatanadhan R., 2018, International Research Journal of Engineering and Technology (IRJET), V05, P918
   Van LT, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041414
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Xihao S., 2013, INT S SIGNALS CIRCUI, P1
   Yoon JW, 2021, IEEE-ACM T AUDIO SPE, V29, P1626, DOI 10.1109/TASLP.2021.3071662
NR 37
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22759
EP 22776
DI 10.1007/s11042-023-14680-y
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000929853100005
PM 36817556
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bartlett, KA
   Camba, JD
AF Bartlett, Kristin A. A.
   Camba, Jorge D. D.
TI An RGB-D sensor-based instrument for sitting balance assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sitting balance; Postural assessment; RGB-D sensor; Depth camera
ID MICROSOFT KINECT; VALIDITY; RELIABILITY; INDIVIDUALS; SYSTEM;
   REHABILITATION; MOVEMENT; ABILITY; PEOPLE; V2
AB Sitting balance is an important aspect of overall motor control, particularly for individuals who are not able to stand. Typical clinical assessment methods for sitting balance rely on human observation, making them subjective, imprecise, and sometimes time-consuming. The primary objective of this study is to develop an improved system for assessing sitting balance in clinical settings. We designed a software tool that takes input from an RGB-D camera system to track human movement during sitting balance assessment. We validated the system by tracking subject's movements during two seated balance exercises. To assess the accuracy of our system's measurements, we compared them with measurements taken using a ruler and measurements captured from still images from a video recording. The agreement of body angle measurement was an average of 2.19 +/- 2.29 degrees, and agreement of forward reach distance was an average of 0.1 +/- 0.25 in.. The results show that our approach can track a person's body movements with clinically relevant accuracy, suggesting that this RGB-D camera-based system could offer advantages over existing observational methods of sitting balance assessment.
C1 [Bartlett, Kristin A. A.; Camba, Jorge D. D.] Purdue Univ, Sch Engn Technol, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Camba, JD (corresponding author), Purdue Univ, Sch Engn Technol, W Lafayette, IN 47907 USA.
EM bartletk@purdue.edu; jdorribo@purdue.edu
OI Bartlett, Kristin/0000-0003-3577-8034
CR Abou L, 2018, TOP SPINAL CORD INJ, V24, P177, DOI 10.1310/sci17-00027
   Abreu J, 2017, ADV INTELL SYST, V570
   [Anonymous], 2017, P 11 EAI INT C PERVA
   [Anonymous], 2017, 2017 IEEE INT S SYST, DOI DOI 10.1109/SYSENG.2017.8088272
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Diego-Mas JA, 2014, APPL ERGON, V45, P976, DOI 10.1016/j.apergo.2013.12.001
   Arora T, 2020, J SPINAL CORD MED, V43, P10, DOI 10.1080/10790268.2018.1481692
   Asaeda M, 2018, GAIT POSTURE, V62, P458, DOI 10.1016/j.gaitpost.2018.04.010
   Ayed I, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/7574860
   Bakhti KKA, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0451-2
   Bartlett KA, 2019, J BIOMECH, V90, P138, DOI 10.1016/j.jbiomech.2019.04.039
   Beaulieu-Boire L., 2015, J Nov Physiother., V5, P261, DOI [10.4172/2165-7025.1000261, DOI 10.4172/2165-7025.1000261]
   BERG K, 1989, Physiotherapy Canada, V41, P304
   Birnbaum M, 2018, DISABIL REHABIL, V40, P616, DOI 10.1080/09638288.2016.1261947
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Botner EM, 2005, DISABIL REHABIL, V27, P156, DOI 10.1080/09638280400008982
   Cai LS, 2019, APPL BIONICS BIOMECH, V2019, DOI 10.1155/2019/7175240
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Chen CL, 2003, ARCH PHYS MED REHAB, V84, P1276, DOI 10.1016/S0003-9993(03)00200-4
   Clark RA, 2015, GAIT POSTURE, V42, P210, DOI 10.1016/j.gaitpost.2015.03.005
   Clark RA, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0006-8
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Dehbandi B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0170890
   Duffy P, 2013, MEASURING EFFECTIVEN, P3
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Eltoukhy M, 2017, GAIT POSTURE, V58, P421, DOI 10.1016/j.gaitpost.2017.09.010
   Ferreira RN, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030984
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Ganz DA, 2005, J AM GERIATR SOC, V53, P2190, DOI 10.1111/j.1532-5415.2005.00509.x
   Grooten WJA, 2018, BMC MUSCULOSKEL DIS, V19, DOI 10.1186/s12891-017-1927-0
   Hsiao MY, 2018, CLIN REHABIL, V32, P473, DOI 10.1177/0269215517730117
   Johnson L, 2019, J BIOMECH, V93, P6, DOI 10.1016/j.jbiomech.2019.06.001
   Jung S, 2021, DEV NEUROREHABIL, V24, P159, DOI 10.1080/17518423.2020.1819458
   Kitsunezaki N, 2013, IEEE INT SYM MED MEA, P294, DOI 10.1109/MeMeA.2013.6549755
   Kloos AD, 2010, MOVEMENT DISORD, V25, P2838, DOI 10.1002/mds.23421
   Bó APL, 2011, IEEE ENG MED BIO, P3479, DOI 10.1109/IEMBS.2011.6090940
   Latorre J, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0568-y
   Lim D, 2015, CLIN INTERV AGING, V10, P1077, DOI 10.2147/CIA.S85299
   Lloréns R, 2015, CLIN REHABIL, V29, P261, DOI 10.1177/0269215514543333
   Ma MX, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202338
   Manghisi VM, 2017, APPL ERGON, V65, P481, DOI 10.1016/j.apergo.2017.02.015
   Martin CJ, 2012, CAMB STUD COMPAR, P50, DOI 10.1109/SIEDS.2012.6215130
   Maudsley-Barton S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227485
   Medley Ann, 2011, Physiotherapy Theory and Practice, V27, P471, DOI 10.3109/09593985.2010.531077
   Mentiplay BF, 2018, J SPORT SCI, V36, P2202, DOI 10.1080/02640414.2018.1445439
   Mousavi Hondori Hossein, 2014, J Med Eng, V2014, P846514, DOI 10.1155/2014/846514
   Phommahavong S., 2015, CURRENT DIRECTIONS B, V1, P184, DOI DOI 10.1515/CDBME-2015-0046
   Plantard P, 2017, APPL ERGON, V65, P562, DOI 10.1016/j.apergo.2016.10.015
   Reither LR, 2018, DISABIL REHABIL-ASSI, V13, P54, DOI 10.1080/17483107.2016.1278473
   Sápi M, 2019, GAMES HEALTH J, V8, P41, DOI 10.1089/g4h.2018.0027
   Sheehy L, 2020, PM&R, V12, P754, DOI 10.1002/pmrj.12331
   Simonsen D, 2017, BIOSYST BIOROBOT, V15, P1299, DOI 10.1007/978-3-319-46669-9_212
   Springer Barbara A, 2007, J Geriatr Phys Ther, V30, P8
   Tao G., 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P164, DOI 10.1109/ICVR.2013.6662084
   Usmani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155134
   van Diest M, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-101
   Vernadakis N, 2014, PHYS THER SPORT, V15, P148, DOI 10.1016/j.ptsp.2013.08.004
   Wadhwa G, 2016, SPINAL CORD, V54, P319, DOI 10.1038/sc.2015.148
   Watson PF, 2010, THERIOGENOLOGY, V73, P1167, DOI 10.1016/j.theriogenology.2010.01.003
   Webster D, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-108
   Wochatz M, 2019, GAIT POSTURE, V70, P330, DOI 10.1016/j.gaitpost.2019.03.020
   Xu X, 2015, APPL ERGON, V49, P47, DOI 10.1016/j.apergo.2015.01.005
   YANG CM, 2020, MEDICINE, V99, DOI DOI 10.1097/MD.0000000000021228
   Yang Y, 2014, IEEE SENS J, V14, P1633, DOI 10.1109/JSEN.2013.2296509
   Yeung LF, 2014, GAIT POSTURE, V40, P532, DOI 10.1016/j.gaitpost.2014.06.012
   Zaki R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037908
NR 66
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27245
EP 27268
DI 10.1007/s11042-023-14518-7
EA FEB 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000931751400006
DA 2024-07-18
ER

PT J
AU Thangavel, P
   Lourdusamy, R
AF Thangavel, Prabakaran
   Lourdusamy, Ravi
TI A lexicon-based approach for sentiment analysis of multimodal content in
   tweets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal; Sentiment analysis (SA); Multimedia content; Text
   pre-processing; Lexicon-based
ID TWITTER
AB Sentiment analysis (SA) is widely used in various applications such as online opinion gathering for policy directives in government, monitoring of customers and staff satisfaction in corporate bodies in politics and security structures for public tension monitoring. Recently, the field met new challenges where new algorithms must contend with highly unstructured sources for sentiment expressions emanating from online social media fora. This study proposes a lexicon-based procedure to implement tweets sentiment analysis with improved algorithms. To deal with sources devoid of syntactic and grammatical structure, the approach incorporates lexicon-based text pre-processing using lexicon features such as tokenisation, parts-of-speech (POS), stop word removal, stemming, normalisation, word frequency and count for context analysis. However, since data in social network sites that primarily express sentiments are in multimodal forms, an analysis of multimedia content is required (i.e. retrieving text from audio, image and video). Hence a novel lexicon-based methodology and framework for multimodal sentiment analysis of text congregated from audio, images, and videos have been proposed. The lexicon-based approach classified the contents as positive, negative or neutral. The experiment results from STS-Gold datasets (recall = 93.2%, precision = 81.9%, F1-score = 87.2%, Accuracy = 92.29%) show the efficacy of the proposed approach as compared with those of other state-of-the-art research studies.
C1 [Thangavel, Prabakaran; Lourdusamy, Ravi] Thiruvalluvar Univ, Sacred Heart Coll Autonomous, Dept Comp Sci, Tirupattur, Tamilnadu, India.
C3 Thiruvalluvar University
RP Thangavel, P (corresponding author), Thiruvalluvar Univ, Sacred Heart Coll Autonomous, Dept Comp Sci, Tirupattur, Tamilnadu, India.
EM prabakaran2607@gmail.com
RI Lourdusamy, Ravi/IAL-9321-2023
CR Abdulla NA, 2014, INT J INF TECHNOL WE, V9, P55, DOI 10.4018/ijitwe.2014070104
   Abirami AM, 2017, INT CONF ADV COMPU, P72, DOI 10.1109/ICoAC.2017.7951748
   Agarwal Amit, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P189, DOI 10.1109/ICACCE.2018.8441696
   Ahmad M., 2017, INT J MULTIDISCIP SC, V8, P29
   Akter S, 2016, INT CONF ELECTR ENG
   Aung KZ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P149
   Bhoir P., 2015, 2015 IEEE INT C COMP, P1
   Bird S., 2009, NATURAL LANGUAGE PRO
   Boutet A, 2013, SOC NETW ANAL MIN, V3, P1379, DOI 10.1007/s13278-013-0120-1
   Cheng LC, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P1001, DOI 10.1145/3341161.3344821
   D'Andrea A., 2015, INT J COMPUT APPL, V125, DOI [DOI 10.5120/IJCA2015905866, 10.5120/ijca2015905866]
   Devika MD, 2016, PROCEDIA COMPUT SCI, V87, P44, DOI 10.1016/j.procs.2016.05.124
   Dhaoui C, 2017, J CONSUM MARK, V34, P480, DOI 10.1108/JCM-03-2017-2141
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Jurek Anna., 2015, Security Informatics, V4, P9, DOI DOI 10.1186/S13388-015-0024-X
   Kaur R., 2022, Research Anthology on Implementing Sentiment Analysis Across Multiple Disciplines, V10, P1846, DOI DOI 10.4018/IJSSMET.2019040103
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P24103, DOI 10.1007/s11042-019-7390-1
   Loper E., 2002, ARXIV
   Maynard D, 2013, BCS SGAI WORKSH SOC
   Mudinas A., 2012, Proceedings of the First International Workshop on Issues of Sentiment Discovery and Opinion Mining, P5
   Nigam N., 2018, Revised Selected Papers, P154, DOI 10.1007/978-981-13-1810-8_16
   Palanisamy P., 2013, 2 JOINT C LEX COMP S
   Pamungkas EW, 2016, 2016 6TH INTERNATIONAL ANNUAL ENGINEERING SEMINAR (INAES), P28, DOI 10.1109/INAES.2016.7821901
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Sahmed S, 2016, 10 INT AAAI C WEB SO
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Taj S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTING, MATHEMATICS AND ENGINEERING TECHNOLOGIES (ICOMET), DOI 10.1109/icomet.2019.8673428
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Vijayarani S., 2015, International Journal of Computer Science Communication Networks, V5, P7
   Vu L, 2017, P INT C INFORM KNOWL
   Zhang L., 2011, COMBINING LEXICON BA
NR 31
TC 3
Z9 3
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24203
EP 24226
DI 10.1007/s11042-023-14411-3
EA JAN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000922310300002
DA 2024-07-18
ER

PT J
AU Rajput, SS
   Mondal, B
   Warsi, FQ
AF Rajput, Shyam Singh
   Mondal, Bhaskar
   Warsi, Farheen Qamar
TI A robust watermarking scheme via optimization-based image reconstruction
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Robust watermarking; Attacks; Image reconstruction;
   Copyright problem
ID SVD
AB A robust watermarking scheme using an optimization-based image reconstruction technique is presented in this paper. In the proposed scheme, the cover image (CI) and watermark image (WI) are decomposed using Hessenberg decomposition (HD) and singular value decomposition (SVD) with discrete wavelet transformation (DWT). Following the use of SVD, each singular value of the watermark is immediately incorporated into the singular component of the CI using the best scaling factor. Considering the scenario of different attacks on the WI, the optimization-based robust image reconstruction technique is developed and applied to the attacked WI to reproduce its attack-free good quality version. The proposed technique splits the low-quality attacked WI into several small patches processed in raster scan order. Moreover, it also employs some database images of the same domain for computing the reconstruction coefficients and producing the high-quality counterpart of the extracted attacked watermark. Simulation results calculated in terms of different performance metrics, namely Normalized Cross-Correlation (NC), Bit Error Rate (BER), Normalized Absolute Error (NAE), Peak Signal to Noise Ratio (PSNR), and Structure Similarity Index (SSIM) suggest that the proposed watermarking scheme is more robust to different attacks as compared to several existing competent techniques.
C1 [Rajput, Shyam Singh; Mondal, Bhaskar; Warsi, Farheen Qamar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Mondal, B (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM bhaskar.cs@nitp.ac.in
RI Rajput, Shyam Singh/AAU-4448-2020; Mondal, Dr. Bhaskar/Q-6376-2018
OI Mondal, Dr. Bhaskar/0000-0001-6863-9183
CR [Anonymous], 2015, INT J SOFTW WEB SCI
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Ahmadi SBB, 2021, VISUAL COMPUT, V37, P385, DOI 10.1007/s00371-020-01808-6
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Chopra J, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P413, DOI 10.1109/SPIN.2018.8474269
   Devi KJ, 2022, APPL SOFT COMPUT, V131, DOI 10.1016/j.asoc.2022.109781
   Ebrahimnejad J, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104831
   Elad M, 1999, IEEE T PATTERN ANAL, V21, P817, DOI 10.1109/34.790425
   Gakkhar Dhruv, 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P23, DOI 10.1109/ICSIP.2010.5697435
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Hu RW, 2021, SIGNAL PROCESS, V179, DOI 10.1016/j.sigpro.2020.107833
   Hu RW, 2021, IEEE T IMAGE PROCESS, V30, P318, DOI 10.1109/TIP.2020.3036727
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Jiang JJ, 2020, IEEE T CYBERNETICS, V50, P324, DOI 10.1109/TCYB.2018.2868891
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Liang XY, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116462
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu L., 2017, IEEE T CYBERNETICS, P1, DOI [10.1109/ICSPCC.2017.8242518, DOI 10.1007/S11581-017-1972-6]
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mohammed AA, 2020, MULTIMED TOOLS APPL, V79, P32095, DOI 10.1007/s11042-020-09694-9
   Mondal B, 2019, INT J ADV INTELL PAR, V13, P67, DOI [DOI 10.1504/IJAIP.2019.099944, 10.1504/IJAIP.2019.099944]
   Mondal B., 2018, RECENT PATENTS ENG, V12, P5, DOI [10.2174/1872212111666170223165916, DOI 10.2174/1872212111666170223165916]
   Mondal B, 2022, MULTIMED TOOLS APPL, V81, P34547, DOI 10.1007/s11042-021-11657-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P2653, DOI 10.1007/s11042-013-1577-7
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Prabha K, 2022, J KING SAUD UNIV-COM, V34, P2982, DOI 10.1016/j.jksuci.2020.04.003
   Qi WF, 2022, IEEE T IMAGE PROCESS, V31, P691, DOI 10.1109/TIP.2021.3134466
   Rai D, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2022.3223141
   Rajput Shyam Singh, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P252, DOI 10.1109/TBIOM.2019.2939808
   Rajput SS, 2018, INFORM SCIENCES, V463, P227, DOI 10.1016/j.ins.2018.06.050
   Rajput SS, 2018, SIGNAL PROCESS, V147, P233, DOI 10.1016/j.sigpro.2018.01.030
   Sakthivel SM, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106649
   Salehnia T, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115058
   Sheppard DG, 2000, IEEE T IMAGE PROCESS, V9, P295, DOI 10.1109/83.821746
   Singh SK, 2009, UKSIM EURO SYMP COMP, P241, DOI 10.1109/EMS.2009.114
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Wang XY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103123
   Zermi N, 2021, MICROPROCESS MICROSY, V84, DOI 10.1016/j.micpro.2021.104134
   Zhang LN, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102805
   Zhang LN, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107421
NR 42
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25039
EP 25060
DI 10.1007/s11042-023-14363-8
EA JAN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000915813000002
DA 2024-07-18
ER

PT J
AU Chanu, TR
   Singh, TR
   Singh, KM
AF Chanu, Thiyam Romita
   Singh, Th. Rupachandra
   Singh, Kh. Manglem
TI A new algorithm for removing salt and pepper noise from color medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Impulse noise; Color medical image; Vector median; Salt and pepper noise
ID VECTOR MEDIAN FILTER; IMPULSE NOISE; QUATERNION
AB A new method for eliminating salt and pepper noise from color medical images is formulated in this work. The presence of noise in the medical images degrades image quality, affecting disease analysis, detection, and diagnosis by the doctors. Therefore, removal of noise from the medical image is crucial. For color image, vector median filter is preferred for decreasing presence of salt and pepper noise as it preserves the correlation between the channels. However, applying filter on the image without detecting the noise not only reduces noise, but also produces blurring effect in the homogeneous regions and removes the important features such as textures, edges, thin lines, curves, corners etc. presence in the images. This paper proposes a switching vector median filter that detects the salt and pepper noise in the images prior to the filtering operation to avoid such undesirable effects. The vector median filter is applied in the filtering kernel if the central vector pixel does not lie in the set of healthy vector pixels and the minimum average sums of the distances of the vector pixels that forms the edges in the four directions is more than a predetermined threshold. In comparison to existing common filters, the simulation results demonstrate the proposed filter's superior performance for color medical image in decreasing salt and pepper noise and maintaining details.
C1 [Chanu, Thiyam Romita; Singh, Th. Rupachandra] Manipur Univ, Dept Comp Sci, Imphal, Manipur, India.
   [Singh, Kh. Manglem] NIT Manipur, Dept Comp Sci & Engn, Imphal, Manipur, India.
C3 Manipur University; National Institute of Technology (NIT System);
   National Institute of Technology Manipur
RP Chanu, TR (corresponding author), Manipur Univ, Dept Comp Sci, Imphal, Manipur, India.
EM thromita@manipuruniv.ac.in
FU University Grants Commission (UGC) [F.159(JULY 2018)/2018(NET)]
FX This study was funded by University Grants Commission (UGC) (No.
   F.15-9(JULY 2018)/2018(NET))
CR Aksac A, 2019, BMC RES NOTES, V12, DOI 10.1186/s13104-019-4121-7
   Aldhyani THH, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12102505
   Arora S, 2020, PATTERN RECOGN LETT, V139, P1, DOI 10.1016/j.patrec.2018.06.002
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Cao YQ, 2022, IEEE SIGNAL PROC LET, V29, P369, DOI 10.1109/LSP.2021.3135803
   Celebi M.E., 2013, COLOR MED IMAGE ANAL
   Chanu PR, 2019, MULTIMED TOOLS APPL, V78, P15375, DOI 10.1007/s11042-018-6925-1
   Chanu PR, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1057-8
   Chen P, 2022, IEEE ACCESS, V10, P94007, DOI 10.1109/ACCESS.2022.3204280
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Gao J, 2018, SIGNAL IMAGE VIDEO P, V12, P1523, DOI 10.1007/s11760-018-1308-7
   HosseinKhani Z, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1074-7
   Jin LH, 2020, J MATH IMAGING VIS, V62, P505, DOI 10.1007/s10851-019-00942-8
   Jin LH, 2008, FRONT MECH ENG-PRC, V3, P205, DOI 10.1007/s11465-008-0025-2
   Karvelis PS, 2007, ICCS 2007, P49, DOI 10.1007/978-1-84628-992-7_7
   Kashyap R, 2023, J DIGIT IMAGING, V36, P562, DOI 10.1007/s10278-022-00739-z
   Li C, 2021, SIGNAL IMAGE VIDEO P, V15, P1145, DOI 10.1007/s11760-020-01842-w
   Liu Z, 2022, IEEE T MED IMAGING, V1
   Lukac R., 2003, International Journal of Applied Mathematics and Computer Science, V13, P369
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Lukac R, 2006, ADV IMAG ELECT PHYS, V140, P187, DOI 10.1016/S1076-5670(05)40004-X
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Meng XX, 2021, IET IMAGE PROCESS, V15, P228, DOI 10.1049/ipr2.12023
   OISTAMO K, 1992, IEEE INTERNATIONAL CONFERENCE ON SYSTEMS ENGINEERING, P16, DOI 10.1109/ICSYSE.1992.236953
   Radlak K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102782
   Radlak K, 2019, PROC SPIE, V10996, DOI 10.1117/12.2519483
   Rastegar H, 2023, MULTIMED TOOLS APPL, V82, P18907, DOI 10.1007/s11042-022-14181-4
   Roy A, 2020, MULTIMED TOOLS APPL, V79, P34851, DOI 10.1007/s11042-020-09107-x
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Sadrizadeh S, 2022, SIGNAL PROCESS, V192, DOI 10.1016/j.sigpro.2021.108378
   Sheela CJJ, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101657
   Singh I, 2021, MULTIMED TOOLS APPL, V80, P18279, DOI 10.1007/s11042-021-10643-3
   Singh KM, 2014, IMAGING SCI J, V62, P313, DOI 10.1179/1743131X14Y.0000000072
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2015, J REAL-TIME IMAGE PR, V10, P289, DOI 10.1007/s11554-012-0307-0
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Wang GH, 2010, SIGNAL PROCESS, V90, P3213, DOI 10.1016/j.sigpro.2010.05.026
   Weber Allan G, 2006, The USC-SIPI Image Database
   Yoo Y, 2007, PROC SPIE, V6502, DOI 10.1117/12.702758
   Zhang WH, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105558
   Zhou H, 2008, DIGIT SIGNAL PROCESS, V18, P406, DOI 10.1016/j.dsp.2007.04.013
   Zhou TF, 2021, LECT NOTES COMPUT SC, V12902, P560, DOI 10.1007/978-3-030-87196-3_52
NR 42
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24991
EP 25013
DI 10.1007/s11042-023-14378-1
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000988280300001
DA 2024-07-18
ER

PT J
AU Jandaghian, M
   Setayeshi, S
   Razzazi, F
   Sharifi, A
AF Jandaghian, Maryam
   Setayeshi, Saeed
   Razzazi, Farbod
   Sharifi, Arash
TI Music emotion recognition based on a modified brain emotional learning
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music emotion recognition; Brain emotional learning; Feature extraction;
   Thayer model; Fuzzy system; Symbolic analysis
ID FEATURE-EXTRACTION; FEATURES; MIXTURE
AB Listening to music can evoke different emotions in humans. Music emotion recognition (MER) can predict a person's emotions before listening to a song. However, there are three problems with MER studies. First, the brain is the seat of music perception, but the simulation of MER based on the brain's limbic system has not been examined so far. Secondly, although the effect of individual differences is recognized on the perception and induction of music emotion in the literature, less attention has been paid to the personalization of the model. Finally, most previous studies have emphasized the classification of music pieces into emotional groups, while often a piece of music creates several emotions with different values. The purpose of the present study is to introduce an optimized model of brain emotional learning (BEL) which is combined with Thayer's psychological model to predict the quantitative value of all emotions that hat would reach a specific person by listening to a new piece of music. The proposed model consists of 12 emotional parts that work in parallel where each part is responsible for evaluating one Thayer's specific emotion. Four neural areas of the emotional brain are simulated for each part. The input signal is adjusted using Thayer's dimensions and a fuzzy system. The average of the results obtained with the proposed model were: R2 = 0.69 for arousal, R2 = 0.36 for valence, and MSE = 0.051, which was better and faster than the multilayer network models and even the original BEL model for all emotions.
C1 [Jandaghian, Maryam; Sharifi, Arash] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Setayeshi, Saeed] Amirkabir Univ Technol, Dept Energy Engn & Phys, Tehran, Iran.
   [Razzazi, Farbod] Islamic Azad Univ, Dept Elect Engn, Sci & Res Branch, Tehran, Iran.
C3 Islamic Azad University; Amirkabir University of Technology; Islamic
   Azad University
RP Setayeshi, S (corresponding author), Amirkabir Univ Technol, Dept Energy Engn & Phys, Tehran, Iran.
EM setayesh@aut.ac.ir
RI Setayeshi, Saeed/JPY-2228-2023
OI Setayeshi, Saeed/0000-0002-1415-222X
CR Abbasi Layegh M., 2014, GAZI UNIJ SCI PART E, V1, P57
   Adolphs R, 2017, SOC COGN AFFECT NEUR, V12, P24, DOI 10.1093/scan/nsw153
   Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   Balasubramanian G, 2018, BIOMED SIGNAL PROCES, V42, P115, DOI 10.1016/j.bspc.2018.01.015
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bogdanov D., 2013, P 14 INT SOC MUS INF, P493, DOI DOI 10.1145/2502081.2502229
   Campobello G, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106488
   Chen YA, 2017, IEEE-ACM T AUDIO SPE, V25, P1409, DOI 10.1109/TASLP.2017.2693565
   Cortes DS, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82135-1
   Davies Stephen., 1994, MUSICAL MEANING EXPR
   de Benito-Gorron D, 2019, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-019-0152-1
   Er MB, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107840
   Farhoudi Z, 2021, SPEECH COMMUN, V127, P92, DOI 10.1016/j.specom.2020.12.001
   Ferreira Lucas, 2019, Proceedings of the 20th International Society for Music Information Retrieval Conference (Delft, The Netherlands), P384, DOI [DOI 10.5281/ZENODO.3527824, 10 . 5281 / zenodo.3527824]
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P5137, DOI 10.1007/s11042-021-11650-0
   Gaut B., 2013, ROUTLEDGE COMPANION, DOI [10.4324/9780203813034, DOI 10.4324/9780203813034]
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Graben PB, 2019, J MATH PSYCHOL, V91, P38, DOI 10.1016/j.jmp.2019.03.002
   Grekow J, 2021, J INTELL INF SYST, V57, P531, DOI 10.1007/s10844-021-00658-5
   Grekow J, 2018, J INFORM TELECOMMUN, V2, P322, DOI 10.1080/24751839.2018.1463749
   Hasanzadeh F, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107028
   Hausmann M, 2016, BRAIN COGNITION, V104, P58, DOI 10.1016/j.bandc.2016.03.001
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Hyung Z, 2017, INFORM PROCESS MANAG, V53, P1185, DOI 10.1016/j.ipm.2017.04.006
   Jafari NZ, 2016, J LIT ART STUD, V6, P74, DOI [10.17265/2159-5836/2016.01.010, DOI 10.17265/2159-5836/2016.01.010]
   Kim D., 2017, Int. J. Electr. Comput. Eng, V7, P1246, DOI [10.11591/ijece.v7i3.pp1246-1254, DOI 10.11591/IJECE.V7I3.PP1246-1254]
   Koelsch S, 2018, NEURON, V98, P1075, DOI 10.1016/j.neuron.2018.04.029
   Krumhansl CL, 1997, CAN J EXP PSYCHOL, V51, P336, DOI 10.1037/1196-1961.51.4.336
   LABERGE D, 1974, COGNITIVE PSYCHOL, V6, P293, DOI 10.1016/0010-0285(74)90015-2
   Lindquist KA, 2012, BEHAV BRAIN SCI, V35, P121, DOI 10.1017/S0140525X11000446
   Liu T, 2018, AIP CONF PROC, V1967, DOI 10.1063/1.5039095
   Malheiro R, 2018, IEEE T AFFECT COMPUT, V9, P240, DOI 10.1109/TAFFC.2016.2598569
   Meyer L.B., 1956, Emotion and meaning in music
   Mo SS, 2019, IEEE T AFFECT COMPUT, V10, P313, DOI 10.1109/TAFFC.2017.2724515
   Morén J, 2000, FROM ANIM ANIMAT, P383
   Motamed S, 2017, BIOL INSPIR COGN ARC, V19, P32, DOI 10.1016/j.bica.2016.12.002
   Orjesek R, 2022, MULTIMED TOOLS APPL, V81, P5017, DOI 10.1007/s11042-021-11584-7
   Panda R, 2023, IEEE T AFFECT COMPUT, V14, P68, DOI 10.1109/TAFFC.2020.3032373
   Rachman F.H., 2018, INT J ELECT COMPUT E, V8, P1720, DOI [10.11591/ijece.v8i3.pp1720-1730, DOI 10.11591/IJECE.V8I3.PP1720-1730]
   Rajesh S, 2020, PROCEDIA COMPUT SCI, V167, P16, DOI 10.1016/j.procs.2020.03.178
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Russo M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102270
   Sahabi, 2022, J DRAM ARTS MUSIC, V12, P35
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Sen A., 1990, REGRESSION ANAL THEO, DOI DOI 10.1007/978-1-4612-4470-7
   Sharafbayani, 2017, J DRAM ARTS MUSIC, V7, P131, DOI [10.30480/dam.2017.336, DOI 10.30480/DAM.2017.336]
   Singer N, 2016, NEUROIMAGE, V141, P517, DOI 10.1016/j.neuroimage.2016.07.002
   Soleymani M., 2013, P 2 ACM INT WORKSH C, P1, DOI DOI 10.1145/2506364.2506365
   Tala'i Dariush., 2000, Traditional Persian A rt Music: The Radif of Mirza AbdoIIah, DOI DOI 10.4000/ABSTRACTAIRANICA.35712
   Tang XB, 2018, COGN SYST RES, V52, P359, DOI 10.1016/j.cogsys.2018.07.016
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Turchet L, 2022, IEEE-ACM T AUDIO SPE, V30, P305, DOI 10.1109/TASLP.2021.3138709
   Tzanetakis G., 2000, Organised Sound, V4, P169, DOI DOI 10.1017/S1355771800003071
   Vempala NN, 2018, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02239
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
   Zonis, 1973, CLASSICAL PERSIAN MU, DOI [10.1017/S0020743800024399, DOI 10.1017/S0020743800024399]
NR 60
TC 1
Z9 1
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26037
EP 26061
DI 10.1007/s11042-023-14345-w
EA JAN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000913487000001
DA 2024-07-18
ER

PT J
AU Reddy, SD
   Murugan, R
   Nandi, A
   Goel, T
AF Reddy, S. Dhanunjay
   Murugan, R.
   Nandi, Arnab
   Goel, Tripti
TI Classification of arrhythmia disease through electrocardiogram signals
   using sampling vector random forest classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram; Arrhythmia; Two-stage median filter; Dynamic
   features; sampling vector random forest
AB An electrocardiogram (ECG) is an electrical signal produced by ECG sensors to examine and visualize the heart's functionality, quick identification of arrhythmia aids in proper care and reduction of the risk factor. This paper uses machine learning algorithms to detect and identify arrhythmia types by extracting simple dynamic features from the ECG signals. The workflow will undergo three stages: pre-processing, feature extraction, and classification. A Low Pass Filter (LPF) and a two-stage median filter are proposed to eliminate all the signaling artifacts for successful feature extraction. The pre-processed signal is then fed into extracts of dynamic ECG features. With the aid of extracted features, the proposed Sampling Vector Random Forest Classifier (SVRF) predicts the form of arrhythmia. The novelty of the proposed SVRF is the ensemble-based approach for multi-class classification has overcome the noise resistance and gained inaccuracy when compared to another state-of-the-art classifier. The proposed method was tested with all the possible eleven types of arrhythmia from the MIT-BIH arrhythmia database, as stated in the association for the advancement of medical instrumentations recommendations. With the help of the proposed (SVRF), 98.22% of accuracy is achieved, which is better than other existing techniques. These aid medical professionals in the early detection of arrhythmia stages. The performance and comparative analysis are presented in this paper to prove the efficiency of the proposed method with the performance metrics of the confusion matrix and receiver operating characteristics.
C1 [Reddy, S. Dhanunjay; Murugan, R.; Nandi, Arnab; Goel, Tripti] Natl Inst Technol Silchar, Biomed Imaging Lab BIOMIL, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Murugan, R (corresponding author), Natl Inst Technol Silchar, Biomed Imaging Lab BIOMIL, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM murugan.rmn@ece.nits.ac.in
OI Srikireddy, Dhanunjay Reddy/0009-0007-0226-9133; R,
   MURUGAN/0000-0002-9341-3810
CR Al-Saadany D, 2022, LECT NOTES COMPUT SC, P546, DOI 10.1007/978-3-031-08754-7_60
   [Anonymous], 2017, Intelligent Systems Technologies and Applications, DOI DOI 10.1007/978-3-319-68385-0_18
   [Anonymous], AHA DATABASE CAN BE
   Baygin M, 2021, INFORM SCIENCES, V575, P323, DOI 10.1016/j.ins.2021.06.022
   Behar JA, 2019, PRENATAL DIAG, V39, P178, DOI 10.1002/pd.5412
   Boriani G, 2021, J CLIN MED, V10, DOI 10.3390/jcm10040729
   Chen ZJ, 2018, IEEE T CIRCUITS-II, V65, P948, DOI 10.1109/TCSII.2017.2747596
   Cheng P, 2017, IEEE ACCESS, V5, P14195, DOI 10.1109/ACCESS.2017.2723258
   Faust O, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081446
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Hurtado JE, 1998, ARCH COMPUT METHOD E, V5, P3, DOI 10.1007/BF02736747
   Leite JPRR, 2018, IET SIGNAL PROCESS, V12, P431, DOI 10.1049/iet-spr.2017.0296
   Lin C, 2014, INTERVALS MORPHOLOGI, V2014
   Lin YJ, 2019, BIOMED CIRC SYST C, DOI [10.1109/biocas.2019.8919138, 10.1109/BIOCAS.2019.8919138, 10.1109/biocas.2019.8919141]
   Marinho LB, 2019, FUTURE GENER COMP SY, V97, P564, DOI 10.1016/j.future.2019.03.025
   MARK RG, 1982, IEEE T BIO-MED ENG, V29, P600
   Mathunjwa BM, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102262
   Murugan R, 2021, J AMB INTEL HUM COMP, V12, P8887, DOI 10.1007/s12652-020-02688-3
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Park J, 2015, IEEE ENG MED BIO, P5191, DOI 10.1109/EMBC.2015.7319561
   Phinyomark A., 2009, An optimal wavelet function based on wavelet denoising for multifunction myoelectric control, P1098, DOI [10.1109/ecticon.2009.5137236, DOI 10.1109/ECTICON.2009.5137236]
   Raj S, 2017, IEEE T INSTRUM MEAS, V66, P470, DOI 10.1109/TIM.2016.2642758
   Rakshit M, 2018, BIOMED SIGNAL PROCES, V40, P140, DOI 10.1016/j.bspc.2017.09.020
   Ramkumar M., 2021, Journal of Physics: Conference Series, V1831, DOI 10.1088/1742-6596/1831/1/012015
   Sannino G, 2018, FUTURE GENER COMP SY, V86, P446, DOI 10.1016/j.future.2018.03.057
   Teijeiro, US
   Tuncer T, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104923
   Ullah A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030951
   Venkatesan C, 2018, IEEE ACCESS, V6, P9767, DOI 10.1109/ACCESS.2018.2794346
   Wang ST, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105941
   Xia YF, 2018, IEEE ACCESS, V6, P16529, DOI 10.1109/ACCESS.2018.2807700
   Yang H, 2020, IEEE ACCESS, V8, P47103, DOI 10.1109/ACCESS.2020.2979256
   Yang WY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143214
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Zhai XL, 2018, IEEE ACCESS, V6, P27465, DOI 10.1109/ACCESS.2018.2833841
   Zhang ZC, 2014, COMPUT BIOL MED, V46, P79, DOI 10.1016/j.compbiomed.2013.11.019
   Zheng JW, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0440-8
NR 37
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26797
EP 26827
DI 10.1007/s11042-022-14304-x
EA DEC 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000904017400004
DA 2024-07-18
ER

PT J
AU Wang, R
   Zhang, YH
   Zhang, J
AF Wang, Rong
   Zhang, Yonghui
   Zhang, Jian
TI An efficient swin transformer-based method for underwater image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater imaging; Image enhancement; Swin transformer; Deep learning
AB Due to the complex imaging environment of the ocean, the underwater images obtained by optical vision systems are usually severely degraded. Recently, methods for enhancing underwater images are mostly based on deep learning. However, the intrinsic locality of convolution operation makes it difficult to model long-range dependency efficiently, which may lead to the limited performance of these methods. This paper proposes an efficient method for underwater image enhancement by utilizing Swin Transformer for local feature learning and long-range dependency modeling. The network structure of this method is mainly composed of encoder, decoder and skip connections, in which the encoder and decoder take the Swin Transformer block as the basic unit. Specifically, the encoder is used to learn multi-scale feature representations, and the decoder is utilized to upsample the extracted contextual features progressively. Skip connections are used to fuse multi-scale features from the encoder and decoder. Experimental results demonstrate that the proposed method outperforms state-of-the-art methods on different datasets by up to 1.09 similar to 1.64dB (PSNR) and 1.9%similar to 2.3% (SSIM) in objective metrics, and achieves the best visual effect in subjective comparisons, especially in terms of color cast removal and sharpness enhancement.
C1 [Wang, Rong; Zhang, Yonghui; Zhang, Jian] Hainan Univ, Sch Informat & Commun Engn, 58 Renmin Ave, Haikou 570228, Hainan, Peoples R China.
C3 Hainan University
RP Zhang, YH (corresponding author), Hainan Univ, Sch Informat & Commun Engn, 58 Renmin Ave, Haikou 570228, Hainan, Peoples R China.
EM wrong@hainanu.edu.cn; yhzhang@hainanu.edu.cn; whealther@hainanu.edu.cn
RI Yang, Mei/JNS-2225-2023; Zhang, Yonghui/AGY-5688-2022; Wang,
   Rong/HJH-1689-2023
OI Wang, Rong/0000-0003-2275-8202
FU Key Research and Development Project of Hainan Province [ZDYF2019024]
FX This work was supported by the Key Research and Development Project of
   Hainan Province (No. ZDYF2019024).
CR Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3059703
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Cao J, 2021, arXiv
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen DJ, 2021, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR46437.2021.01207
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen L, 2021, IEEE T CIRC SYST VID, V31, P3078, DOI 10.1109/TCSVT.2020.3035108
   Dai ZG, 2021, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR46437.2021.00165
   Dosovitskiy Alexey, 2020, INT C LEARN REPRESEN
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Gao SB, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919947
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hu JK, 2021, IEEE SIGNAL PROC LET, V28, P2152, DOI 10.1109/LSP.2021.3099746
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Korhonen J, 2012, INT WORK QUAL MULTIM, P37, DOI 10.1109/QoMEX.2012.6263880
   Lanchantin J, 2021, PROC CVPR IEEE, P16473, DOI 10.1109/CVPR46437.2021.01621
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li HY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116248
   Li Y, 2021, IET IMAGE PROCESS, V15, P774, DOI 10.1049/ipr2.12061
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu P, 2019, IEEE ACCESS, V7, P94614, DOI 10.1109/ACCESS.2019.2928976
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu XD, 2020, IEEE GEOSCI REMOTE S, V17, P1488, DOI 10.1109/LGRS.2019.2950056
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mao JG, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3144, DOI 10.1109/ICCV48922.2021.00315
   Misra Ishan, 2021, Proceedings of the IEEE/CVF International Conference on Computer Vision, P2906
   Moghimi MK, 2021, J REAL-TIME IMAGE PR, V18, P1509, DOI 10.1007/s11554-020-01052-0
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng L., 2021, ARXIV, VPart II, P290
   Sajid U, 2021, IEEE INT CONF COMP V, P2249, DOI 10.1109/ICCVW54120.2021.00254
   Singhai J, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P507, DOI 10.1109/ICCIMA.2007.359
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2020, IEEE ACCESS, V8, P130719, DOI 10.1109/ACCESS.2020.3003351
   Wang YQ, 2021, PROC CVPR IEEE, P8737, DOI 10.1109/CVPR46437.2021.00863
   Yan K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115420
   Yang M, 2019, IEEE ACCESS, V7, P123638, DOI 10.1109/ACCESS.2019.2932611
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yu HF, 2020, MULTIMED TOOLS APPL, V79, P20373, DOI 10.1007/s11042-020-08701-3
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
   Zhang ZX, 2021, IEEE INT CONF COMP V, P2799, DOI 10.1109/ICCVW54120.2021.00314
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhuang PX, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104171
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 58
TC 3
Z9 3
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18691
EP 18708
DI 10.1007/s11042-022-14228-6
EA NOV 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000887890500003
DA 2024-07-18
ER

PT J
AU Masoudi, B
AF Masoudi, Babak
TI VKCS: a pre-trained deep network with attention mechanism to diagnose
   acute lymphoblastic leukemia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acute lymphoblastic leukemia; Attention mechanism; Classification; Deep
   learning; Transfer learning
ID CLASSIFICATION
AB Leukemia is a prominent hematologic malignancy that causes mortality and complications at different ages. In this paper, to provide a more accurate diagnosis of Acute Lymphoblastic Leukemia (ALL), a three-stage model based on transfer learning called variable-kernel channel-spatial attention (VKCS) is proposed. First, a deep pre-trained network extracts high-level features from the blood smear images. In the second stage, two attention mechanisms of variable-kernel spatial attention and variable-kernel channel attention consider spatial and channel information in parallel to improve model performance. The last step is the classification module. The experiments are repeated for different pre-trained networks, as well as for images in RGB, HSV, L*a*b*, and YCbCr color spaces, and by applying morphological operators (erosion and dilation) to images in different color spaces. The best model efficiency accuracy was achieved for images in HSV color space and the use of EfficientNet-V2M for feature extraction. The VKCS model accuracy is 100% for the ALL-IDB1 dataset and 99.6% for the ALL-IDB2 dataset, which are promising results.
C1 [Masoudi, Babak] Payamenoor Univ PNU, Dept Informat Technol, POB 19395-3697, Tehran, Iran.
RP Masoudi, B (corresponding author), Payamenoor Univ PNU, Dept Informat Technol, POB 19395-3697, Tehran, Iran.
EM B.masoudi@pnu.ac.ir
OI masoudi, babak/0000-0002-3975-5078
CR Abou El-Seoud S, 2020, INT J ONLINE BIOMED, V16, P94, DOI 10.3991/ijoe.v16i15.15481
   Ahmed N, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030104
   Alagu S, 2021, APPL ARTIF INTELL, V35, P1952, DOI 10.1080/08839514.2021.1995974
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Anilkumar KK, 2022, IRBM, V43, P405, DOI 10.1016/j.irbm.2021.05.005
   Anilkumar KK, 2021, MED ENG PHYS, V98, P8, DOI 10.1016/j.medengphy.2021.10.006
   Bodzas A, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.01005
   Boumaraf S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102192
   Cha SM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031242
   Das PK, 2022, MEASUREMENT, V191, DOI 10.1016/j.measurement.2022.110762
   Das PK, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115311
   El Houby E. M., 2021, Appl Comput Inform, V1, P1, DOI [10.1108/ACI-07-2021-0191, DOI 10.1108/ACI-07-2021-0191]
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jha KK, 2019, COMPUT METH PROG BIO, V179, DOI 10.1016/j.cmpb.2019.104987
   Karthik R, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103406
   Kumar A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12894
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Mishra S, 2019, BIOMED SIGNAL PROCES, V47, P303, DOI 10.1016/j.bspc.2018.08.012
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Pandiyan V, 2022, J MATER PROCESS TECH, V303, DOI 10.1016/j.jmatprotec.2022.117531
   Qin FW, 2018, COMPUT METH PROG BIO, V162, P243, DOI 10.1016/j.cmpb.2018.05.024
   Rastogi P, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2022.105236
   Rawat J, 2022, EVOL INTELL, V15, P99, DOI 10.1007/s12065-020-00491-9
   Rodrigues LF, 2022, J DIGIT IMAGING, V35, P623, DOI 10.1007/s10278-022-00600-3
   Rosales-Perez A., 2022, Biosignal Processing and Classification Using Computational Learning and Intelligence, P429, DOI DOI 10.1016/B978-0-12-8201251.00033-6
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shafique S, 2018, TECHNOL CANCER RES T, V17, DOI 10.1177/1533033818802789
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan Mingxing, 2021, PMLR 10096-10106, P10096
   Wang AL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041151
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang ZY, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0261848
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu CB, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102730
NR 41
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18967
EP 18983
DI 10.1007/s11042-022-14212-0
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886864400002
DA 2024-07-18
ER

PT J
AU Jiao, L
   Kang, CR
   Dong, SF
   Chen, P
   Li, GQ
   Wang, RJ
AF Jiao, Lin
   Kang, Chenrui
   Dong, Shifeng
   Chen, Peng
   Li, Gaoqiang
   Wang, Rujing
TI An attention-based feature pyramid network for single-stage small object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Feature pyramid network; Feature fusion; Single-stage;
   Small object
AB Recently, single-stage detection methods have made great progress, achieving comparable accuracy to two-stage detection methods. However, they have poor performance over small object detection. In this work, we improve the performance of the single-stage detector for detecting objects of small sizes. The proposed method makes two major novel contributions. The first is to devise an attention-based feature pyramid network (aFPN) by introducing a learnable fusion factor for controlling feature information that deep layers deliver to shallow layers. The design of a learnable fusion factor could adapt a feature pyramid network to small object detection. The second contribution is to propose a soft-weighted loss function, which reduces the false attention during network training. To be specify, we reweight the contribution of training samples to the network loss according to their distances with the boundaries of the ground-truth box, leading to fewer false-positive detections. To verify the performance of the proposed method, we conduct extensive experiments on different datasets by comparing including RetinaNet, ATSS, FCOS, FreeAnchor, et al. Experimental results show that our method can achieve 44.2% AP on MS COCO dataset, 23.0% AP on VisDrone dataset, which significantly gains improvements with nearly no computation overhead.
C1 [Jiao, Lin; Chen, Peng; Li, Gaoqiang] Anhui Univ, Sch Internet, Hefei 230039, Peoples R China.
   [Jiao, Lin; Dong, Shifeng; Wang, Rujing] Chinese Acad Sci, Inst Intelligent Machines, Hefei Inst Phys Sci, Hefei 230031, Peoples R China.
   [Kang, Chenrui] Southwest Univ Sci & Technol, Mianyang 621010, Sichuan, Peoples R China.
   [Dong, Shifeng; Wang, Rujing] Univ Sci & Technol China, Hefei 230031, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; Hefei Institutes of
   Physical Science, CAS; Southwest University of Science & Technology -
   China; Chinese Academy of Sciences; University of Science & Technology
   of China, CAS
RP Jiao, L (corresponding author), Anhui Univ, Sch Internet, Hefei 230039, Peoples R China.; Jiao, L (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei Inst Phys Sci, Hefei 230031, Peoples R China.
EM ljiao@ahu.edu.cn
RI Li, Gaoqiang/C-9192-2015
CR Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Dai PW, 2021, PROC CVPR IEEE, P7389, DOI 10.1109/CVPR46437.2021.00731
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Gao ZL, 2019, PROC CVPR IEEE, P3019, DOI 10.1109/CVPR.2019.00314
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gong Y, 2020, EFFECTIVE FUSION FAC
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee S, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107256
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717
   Togaçar M, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106810
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang B, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106897
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang RJ, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106290
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XS, 2022, IEEE T PATTERN ANAL, V44, P3096, DOI 10.1109/TPAMI.2021.3050494
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu P, 2018, ARXIV
   Zhu YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107336
NR 45
TC 4
Z9 4
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18529
EP 18544
DI 10.1007/s11042-022-14159-2
EA NOV 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000885231500004
DA 2024-07-18
ER

PT J
AU de Francisco, MS
   Díaz, P
   Onorati, T
   Aedo, I
AF Sanchez de Francisco, Monica
   Diaz, Paloma
   Onorati, Teresa
   Aedo, Ignacio
TI Connecting citizens with urban environments through an augmented reality
   pervasive game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AR pervasive games; Playable cities; User engagement; User interest;
   Situated motivational affordances
ID USER ENGAGEMENT; RELIABILITY; FRAMEWORK
AB The concept of Playable City situates games in public spaces to create connections between the citizens and the urban environment. To this end, Augmented Reality (AR) and pervasive technologies can provide additional information about urban objects or places and support innovative and engaging experiences to increase the user interest in the surrounding area. Understanding how these experiences affect the user interest is crucial for reaching a well-established connection between the people and the spaces around them. Our contribution is a preliminary framework to evaluate how being engaged in a playful activity improves interest and awareness in a specific urban area. The framework is based on the situated motivational affordances to establish a correlation among the users' motivations, the situation, and the employed technological artifact. We use an AR pervasive game to evaluate a playful historical experience as a technology probe. The results suggest that while playing the game, the citizens started to show a growing interest in the historical facts around them. At the same time, they began to raise concerns about other issues like sustainability, socio-environmental, and socioeconomic development.
C1 [Sanchez de Francisco, Monica; Diaz, Paloma; Onorati, Teresa; Aedo, Ignacio] Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Onorati, T (corresponding author), Univ Carlos III Madrid, Dept Comp Sci, Madrid, Spain.
EM mosanche@inf.uc3m.es; pdp@inf.uc3m.es; tonorati@inf.uc3m.es;
   aedo@ia.uc3m.es
RI ; Aedo, Ignacio/F-3222-2014
OI SANCHEZ DE FRANCISCO, Monica/0000-0002-6760-0401; Aedo,
   Ignacio/0000-0001-5819-0511; ONORATI, TERESA/0000-0002-3154-249X; DIAZ
   PEREZ, MARIA PALOMA/0000-0002-9493-7739
FU project sense2MakeSense - Spanish State Agency of Research
   [PID2019-109388GB-I00]; Madrid Government (Comunidad de Madrid - Spain)
   [EPUC3M17]
FX This work is supported by the project sense2MakeSense grant funded by
   the Spanish State Agency of Research (PID2019-109388GB-I00) and the
   Madrid Government (Comunidad de Madrid - Spain) under the Multiannual
   Agreement with UC3M in the line of Excellence of University Professors
   (Grant Number: EPUC3M17) context of the V PRICIT (Regional Programme of
   Research and Technological Innovation).
CR [Anonymous], 2014, PROC EXTENDED ABSTR
   Attfield S., 2011, WSDM WORKSHOP USER M, P9
   Baerentsen K.B., 2002, PROC NORDICHI 2002, P51, DOI DOI 10.1145/572020.572028
   Calafiore A, 2016, WORKSHOP FICTIONAL G, P1
   Chang M, 2005, CHI EXTENDED ABSTRAC, P2109, DOI 10.1145/1056808.1057110
   Claypool M, 2001, IEEE INTERNET COMPUT, V5, P32, DOI 10.1109/4236.968829
   Corbin J, 2008, Techniques and procedures for developing grounded theory, V3rd
   De Lange Michiel., 2015, The playful city: using play and games to foster citizen participation
   Deterding S, 2021, FIGHTING POSTTRUTH S
   Deterding S., 2011, GAMIFICATION USING G, P3
   Dodge Y., 2003, OXFORD DICT STAT TER
   Fabiano F, 2018, P 20 INT C HUMAN COM, P197, DOI [10.1145/3236112.3236140, DOI 10.1145/3236112.3236140]
   Ferreira V, 2017, GAMING MEDIA SOC EFF, P211, DOI 10.1007/978-981-10-1962-3_10
   Fischer PT, 2017, GAMING MEDIA SOC EFF, P163, DOI 10.1007/978-981-10-1962-3_8
   Hair JF, 2010, Multivariate data analysis
   Hamari J, 2019, INT J HUM-COMPUT INT, V35, P804, DOI 10.1080/10447318.2018.1497115
   Hutchinson H., 2003, P ACM C HUMAN FACTOR, P17, DOI DOI 10.1145/642611.642616
   Innocent T, 2018, PROCEEDINGS OF THE 4TH MEDIA ARCHITECTURE BIENNALE CONFERENCE 2018 (MAB18), P137, DOI 10.1145/3284389.3284493
   Kasapakis Vlasios., 2013, Proceedings of the 17th panhellenic conference on informatics, P152
   Koivisto J, 2019, INT J INFORM MANAGE, V45, P191, DOI 10.1016/j.ijinfomgt.2018.10.013
   Laato S., 2019, P 11 INT C COMPUTER, P616, DOI DOI 10.5220/0007801206160627
   Leorke Dale, 2020, Making Smart Cities More Playable: Exploring Playable Cities, P51, DOI [10.1007/978-981-13-9765-3_3, DOI 10.1007/978-981-13-9765-3_3]
   Liao T, 2015, NEW MEDIA SOC, V17, P1418, DOI 10.1177/1461444814527734
   Miyahara S, 2007, INT J HUM-COMPUT INT, V23, P131, DOI 10.1080/10447310701363072
   Nijholt A, 2017, GAMING MEDIA SOC EFF, P1, DOI 10.1007/978-981-10-1962-3_1
   Nunnally JC, 1978, PSYCHOMETRIC THEORY, V2nd
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Prandi C, 2017, MULTIMED TOOLS APPL, V76, P4951, DOI 10.1007/s11042-016-3780-9
   Qiu F., 2006, Proceedings of the 15th International Conference on World Wide Web, P727, DOI DOI 10.1145/1135777.1135883
   Rauschnabel PA, 2017, COMPUT HUM BEHAV, V76, P276, DOI 10.1016/j.chb.2017.07.030
   Razafimahazo M, 2014, ERCIM NEWS, P45
   Sánchez-Francisco M, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206586
   Santos V, 2018, L N INST COMP SCI SO, V229, P74, DOI 10.1007/978-3-319-76908-0_8
   Schmidt K., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P285, DOI 10.1023/A:1021272909573
   Schrepp M, 2020, J USABILITY STUD, V15, P247
   Spearman's Rank-Order Correlation, SPEARM RANK ORD CORR
   STAPP WB, 1969, ENVIRON EDUC-WASH, V1, P30, DOI 10.1080/00139254.1969.10801479
   Sun SJ, 2021, FRONT ARCHIT RES, V10, P229, DOI 10.1016/j.foar.2020.08.001
   Sutcliffe A., 2010, Synthesis Lectures on Human-Centered Informatics (SLHCI), V2, P1, DOI [DOI 10.2200/S00210ED1V01Y200910HCI005, 10.2200/S00210ED1V01Y200910HCI005]
   Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2
   Ursachi G, 2015, PROC ECON FINANC, V20, P679, DOI 10.1016/S2212-5671(15)00123-9
   Weiser P, 2015, ACSR ADV COMPUT, V22, P271
   White RW, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P363, DOI 10.1145/1571941.1572005
   Yan Xu, 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P19, DOI 10.1109/ISMAR-AMH.2011.6093652
   Zach FJ., 2017, INFORM COMMUNICATION, P217, DOI DOI 10.1007/978-3-319-51168-916
NR 46
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 12939
EP 12955
DI 10.1007/s11042-022-14055-9
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000876660800002
DA 2024-07-18
ER

PT J
AU Alhothali, A
   Balabid, A
   Alharthi, R
   Alzahrani, B
   Alotaibi, R
   Barnawi, A
AF Alhothali, Areej
   Balabid, Amal
   Alharthi, Reem
   Alzahrani, Bander
   Alotaibi, Reem
   Barnawi, Ahmed
TI Anomalous event detection and localization in dense crowd scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd anomaly detection; Hajj Scene; Magnitude of optical flow;
   Spatial-temporal features
ID BEHAVIOR DETECTION
AB Recognizing and localizing anomalous events in crowd scenes is a challenging problem that has attracted the attention of researchers in computer vision. Surveillance cameras record scenes that require an automated examination to identify anomalous events. Existing approaches in the field have utilized different feature descriptors, modeling methods, and recognition strategies to accurately and efficiently detect anomalies in the scene. Existing techniques in the field have focused mainly on performing global frame-level identification of abnormal events. Only a small number of studies have considered locating abnormal action in the frame. Proposed methods are also often evaluated on scenes that contain a sparse number of individuals performing abnormal and normal staged acts. This research aims to detect and locate anomalies in a structured and unstructured dense crowd scene. The proposed model first detects moving objects and individuals in the scene using a deep convolutional neural network and tracks objects and individuals using spatial and temporal features. Then, spatial-temporal features are extracted from consecutive frames of interest points. The extracted features include the histogram of optical flow, velocity and direction of moving objects, and other features that can indicate sudden motion change. A support vector machine model is then used to classify abnormal events into one of seven classes. The proposed methodology is evaluated on Hajj2 dataset that has 18 videos and 7 different types of abnormal events.
C1 [Alhothali, Areej; Balabid, Amal; Alharthi, Reem; Alzahrani, Bander; Alotaibi, Reem; Barnawi, Ahmed] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
C3 King Abdulaziz University
RP Alhothali, A; Alzahrani, B (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
EM aalhothali@kau.edu.sa; baalzahrani@kau.edu.sa
RI ALZAHRANI, BANDER/C-6585-2018; Alotaibi, Reem/ABG-5116-2020; Barnawi,
   Ahmed/AGZ-1217-2022
OI Alotaibi, Reem/0000-0001-9354-0046; Barnawi, Ahmed/0000-0003-0516-8331;
   Alhothali, Areej/0000-0001-9727-0178
FU Deputyship for Research and Innovation, Ministry of Education in Saudi
   Arabia [227]
FX The authors extend their appreciation to the Deputyship for Research and
   Innovation, Ministry of Education in Saudi Arabia for funding this
   research work through the project number (227).
CR Al-shargie F, 2018, MED BIOL ENG COMPUT, V56, P125, DOI 10.1007/s11517-017-1733-8
   Alafif T, 2022, ARXIV, DOI [10.48550/ARXIV.2207.11931https://doi.org/10.48550/ARXIV.2207.11931, DOI 10.48550/ARXIV.2207.11931HTTPS://DOI.ORG/10.48550/ARXIV.2207.11931]
   Alafif T, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03323-5
   Almazroey Alaa Atallah, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P258, DOI 10.1007/978-3-030-44289-7_25
   Aqeel M., 2020, PROC IEEE 23 INT MUL, P1
   Bansod S. D., 2019, Revised Selected Papers, Part II, V4, P117
   Bansod SD, 2020, VISUAL COMPUT, V36, P609, DOI 10.1007/s00371-019-01647-0
   Bera A, 2016, IEEE COMPUT GRAPH, V36, P37, DOI 10.1109/MCG.2016.113
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Biswas S, 2017, NEUROCOMPUTING, V242, P63, DOI 10.1016/j.neucom.2017.02.058
   Chen CY, 2015, IEEE SENS J, V15, P2431, DOI 10.1109/JSEN.2014.2381260
   Chen YJ, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P760, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.131
   Chibloun A, 2018, 9TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC 2018), P197, DOI 10.1109/ISIVC.2018.8709192
   Das D, 2018, INT CONF IND INF SYS, P40
   Deng LY, 2022, IEEE T NEUR NET LEAR, V33, P2416, DOI 10.1109/TNNLS.2021.3136171
   Direkoglu C, 2020, IEEE ACCESS, V8, P80408, DOI 10.1109/ACCESS.2020.2990355
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Gnouma Mariem, 2020, International Joint Conference: 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019). Proceedings. Advances in Intelligent Systems and Computing (AISC 951), P87, DOI 10.1007/978-3-030-20005-3_9
   Gnouma M, 2018, MULTIMED TOOLS APPL, V77, P24843, DOI 10.1007/s11042-018-5701-6
   Guo CS, 2019, INT J HUM ROBOT, V16, DOI 10.1142/S0219843619410056
   Guo SQ, 2019, IEEE ACCESS, V7, P169577, DOI 10.1109/ACCESS.2019.2954544
   Han QL, 2020, J REAL-TIME IMAGE PR, V17, P2153, DOI 10.1007/s11554-020-01029-z
   He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1, DOI 10.1002/9781118646106
   Hu L, 2017, INT SYM COMPUT INTEL, P421, DOI 10.1109/ISCID.2017.130
   Hu X, 2022, VIDEO ANOMALY DETECT, P1
   Hu X, 2020, NEUROCOMPUTING, V383, P270, DOI 10.1016/j.neucom.2019.11.087
   Hu ZP, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102765
   Ilyas Z, 2021, MULTIMED TOOLS APPL, V80, P24053, DOI 10.1007/s11042-021-10785-4
   Ji QG, 2018, IET IMAGE PROCESS, V12, P133, DOI 10.1049/iet-ipr.2016.0044
   Jiaxing Pan, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P642, DOI 10.1007/978-3-319-69923-3_69
   Jocher G., 2022, ULTRALYTICSYOLOV5 V6, DOI [10.5281/zenodo.6222936, DOI 10.5281/ZENODO.6222936]
   Joshi KV, 2021, INT J NEXT GEN COMPU, V12
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Lamba S, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P435, DOI 10.1109/SITIS.2018.00073
   Li A, 2016, GLOBAL ANOMALY DETEC
   Li A, 2017, MULTIMED TOOLS APPL, V76, P26249, DOI 10.1007/s11042-016-4115-6
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li NN, 2022, NEUROCOMPUTING, V481, P154, DOI 10.1016/j.neucom.2022.01.026
   Li XD, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1907, DOI 10.1109/ICASSP.2018.8461422
   Li X, 2021, MAR GEORESOUR GEOTEC, V39, P163, DOI 10.1080/1064119X.2019.1681039
   Lin HH, 2015, IEEE IMAGE PROC, P2434, DOI 10.1109/ICIP.2015.7351239
   Lin SH, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909882
   Lin SH, 2021, INT C PATT RECOG, P6742, DOI 10.1109/ICPR48806.2021.9412673
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu SY, 2018, IEEE ACCESS, V6, P22184, DOI 10.1109/ACCESS.2018.2800530
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Luo ZH, 2017, INT CONF COMP SCI ED, P183, DOI 10.1109/ICCSE.2017.8085486
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Marsden M, 2016, IEEE IMAGE PROC, P918, DOI 10.1109/ICIP.2016.7532491
   Mehmood A, 2021, IEEE ACCESS, V9, P138283, DOI 10.1109/ACCESS.2021.3118009
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mishra Soumya Ranjan, 2020, Smart Intelligent Computing and Applications. Proceedings of the Third International Conference on Smart Computing and Informatics. Smart Innovation, Systems and Technologies (SIST 159), P561, DOI 10.1007/978-981-13-9282-5_53
   Mondal R, 2018, P 11 INDIAN C COMPUT, V2018, P1
   Moustafa AN, 2020, MULTIMED TOOLS APPL, V79, P20689, DOI 10.1007/s11042-020-08840-7
   Patil N, 2016, 2016 SIXTH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2016), P217, DOI 10.1109/ISED.2016.7977085
   Qasim T, 2019, MATH COMPUT SIMULAT, V166, P245, DOI 10.1016/j.matcom.2019.05.014
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Ramos J, 2018, MULTIMED TOOLS APPL, V77, P17755, DOI 10.1007/s11042-017-5382-6
   Sabih M, 2022, VISUAL COMPUT, V38, P1719, DOI 10.1007/s00371-021-02100-x
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Samat A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161953
   Shao S., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1805.00123
   statista, 2022, SAUD AR HAJJ POP ANN
   Tian Yu, 2021, Proceedings of the IEEE/CVF international conference on computer vision, P4975
   Tome A, 2017, 2017 INT CARNAHAN C, P1, DOI [10.1109/CCST.2017.8167830, DOI 10.1109/CCST.2017.8167830]
   Turaga P, 2010, ADV COMPUT, V80, P237, DOI 10.1016/S0065-2458(10)80007-5
   Vaquero L, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108205
   Wang DL, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.2.023009
   Wang L, 2022, IEEE ACCESS, V10, P44278, DOI 10.1109/ACCESS.2022.3165977
   Wang Q, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550077
   Wang SQ, 2016, INT C PATT RECOG, P3398, DOI 10.1109/ICPR.2016.7900159
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wojke N, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1703.07402
   Xiao Li, 2021, Advances in Intelligent Networking and Collaborative Systems. 12th International Conference on Intelligent Networking and Collaborative Systems (INCoS-2020). Advances in Intelligent Systems and Computing (AISC 1263), P361, DOI 10.1007/978-3-030-57796-4_35
   Xu M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163337
   Xu YP, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0201-3
   Yang B, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/2087574
   Yang M, 2018, IEEE COMPUT SOC CONF, P328, DOI 10.1109/CVPRW.2018.00059
   Zhang SJ, 2022, IEEE T CIRC SYST VID, V32, P5427, DOI 10.1109/TCSVT.2022.3148392
   Zhang XG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020423
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhao K, 2018, 2018 DIGITAL IMAGE C, P1, DOI DOI 10.1109/ICMEW.2018.8551517
   Zhou SF, 2015, INT CONF ACOUST SPEE, P1300, DOI 10.1109/ICASSP.2015.7178180
NR 86
TC 5
Z9 5
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15673
EP 15694
DI 10.1007/s11042-022-13967-w
EA OCT 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000874060500003
DA 2024-07-18
ER

PT J
AU Wang, HF
   Zhang, Y
AF Wang, Haifeng
   Zhang, Yi
TI Histogram image enhancement using a limited wavelet integer coefficient
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information entropy; Limited histogram; Wavelet transform; Image
   enhancement; Narrow dynamic range
ID EQUALIZATION; BRIGHTNESS
AB Histogram equalization plays an important role in digital image preprocessing. However, traditional histogram equalization tends to have technical defects such as over-enhancement and artifacts. This can lead to a loss of detail and make the target image look unnatural. To resolve this issue, this paper presents an approach to image enhancement that uses a limited wavelet integer coefficient histogram to maintain high information entropy. First, a single-layer wavelet transform is performed on the input image to obtain a low-frequency sub-image and three high-frequency sub-images. Then, the low-frequency sub-image is subjected to a histogram-limitation technique to acquire the wavelet integer coefficients. After this, the processed low-frequency and three high-frequency sub-images are reconstructed to output a single high-information enhanced image. An experiment was conducted that shows that the proposed method performs very well in terms of the amount of detailed information captured when compared to an existing improved method based on histogram equalization. In addition, the method can handle the enhancement of images across different dynamic ranges, especially images with narrow a dynamic range, thus improving the amount of detailed information in the output image and maximizing the visual effect for human observers.
C1 [Wang, Haifeng; Zhang, Yi] Jiangsu Univ Technol, Informat Ctr, Changzhou, Peoples R China.
C3 Jiangsu University of Technology
RP Wang, HF (corresponding author), Jiangsu Univ Technol, Informat Ctr, Changzhou, Peoples R China.
EM cjswhf@163.com
FU Natural Science Fund Project of Colleges in Jiangsu Province
   [18KJB520012]
FX The authors would like to express their gratitude to EditSprings
   (https://www.editsprings.com/) for the expert linguistic services
   provided. This project is supported by the Natural Science Fund Project
   of Colleges in Jiangsu Province(grant number 18KJB520012).
CR Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Chen Bo-yangp, 2017, Optics and Precision Engineering, V25, P502, DOI 10.3788/OPE.20172402.0502
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Cheng Lei, 2011, Proceedings of the 2011 International Conference on Transportation and Mechanical & Electrical Engineering (TMEE), P1705, DOI 10.1109/TMEE.2011.6199540
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   [姜柏军 Jiang Bojun], 2014, [激光与红外, Laser and Infrared], V44, P702
   Kanmani M, 2018, MULTIMED TOOLS APPL, V77, P23371, DOI 10.1007/s11042-018-5650-0
   Khanzadi M.R., 2012, P IEEE INT C POW EL, P1, DOI [DOI 10.1109/FCS.2012.6243677, DOI 10.1109/PEDES.2012.648447.8]
   Kia SH, 2018, ELECTR POW COMPO SYS, V46, P2021, DOI 10.1080/15325008.2018.1562647
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li Geng-fei, 2018, Optics and Precision Engineering, V26, P1191, DOI 10.3788/OPE.20182605.1191
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Lu CH, 2009, I W IMAG SYST TECHNI, P402
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Santhi K, 2015, OPTIK, V126, P1809, DOI 10.1016/j.ijleo.2015.05.023
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Tang JR, 2017, APPL SOFT COMPUT, V55, P31, DOI 10.1016/j.asoc.2017.01.053
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Vali MH, 2018, EXPERT SYST APPL, V114, P296, DOI 10.1016/j.eswa.2018.07.004
   Wang XW, 2017, SIGNAL PROCESS-IMAGE, V58, P187, DOI 10.1016/j.image.2017.07.009
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Y, 2017, INFRARED PHYS TECHN, V86, P59, DOI 10.1016/j.infrared.2017.08.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao B, 2018, NEUROCOMPUTING, V275, P2798, DOI 10.1016/j.neucom.2017.11.057
   Xie Xiao-fu, 2010, Journal of Computer Applications, V30, P921, DOI 10.3724/SP.J.1087.2010.00921
NR 29
TC 0
Z9 0
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14879
EP 14896
DI 10.1007/s11042-022-14060-y
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000866314300002
DA 2024-07-18
ER

PT J
AU Shi, H
   Chen, MH
   Yan, KX
AF Shi Hui
   Chen Meihan
   Yan Kexun
TI Separable dual data hiding scheme for secured data in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual data hiding; TSRM; PAS; Entropy rate superpixel segmentation; QWT;
   Security and robustness
ID TRANSFORM
AB Robust as well as secure data hiding is capable of providing a promising solution in many copyright protection applications. In this paper, a separable dual data hiding scheme for secured data is developed. Security of carrier image is enhanced by the new proposed TSRM (Tent-Sort-Reshape-Modulation). And security of secret message is ensured by the new proposed PAS (Padova-Arnold- Scrambling). The robustness is increased by dual data hiding, one is zero data hiding, and the other is robust data hiding, in which QWT, SVD, Schur decompositin and entropy rate superpixel segmentation are used. Under different attacks, even if one secret message fails, the other one can still be used for authentication. A large number of experimental results and thorough evaluations confirm that our scheme can obtain higher security, better imperceptibility and stronger robustness under different types of attacks, and achieve better performance than the current state-of-the-art data hiding algorithms.
C1 [Shi Hui; Chen Meihan; Yan Kexun] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Shi, H (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com
RI Kexun, Yan/AIF-4542-2022
FU Liaoning Provincial Education Department [WQ2020014]; Key Research
   Project of Dalian academy of social sciences [2020dlsky042,
   2021dlsky027]; Liaoning Planning Office of Philosophy and Social Science
   (CN) [L19BTQ001]; National Youth Science Foundation of China [61601214]
FX This work was supported by the Scientific Research Program Funded by
   Liaoning Provincial Education Department (Grant No. WQ2020014), the Key
   Research Project of Dalian academy of social sciences (Grant No.
   2020dlsky042, 2021dlsky027), Liaoning Planning Office of Philosophy and
   Social Science (CN) (Grant L19BTQ001), the National Youth Science
   Foundation of China(61601214).
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   [Anonymous], 2016, Kodak lossless true color image suite
   [Anonymous], 2016, UCID UNCOMPRESSED CO
   [Anonymous], 2016, USC-SIPI image database
   Bayat M., 2016, J ASIAN SCI RES, V6, P24, DOI [10.18488/journal.2/2016.6.2/2.2.24.33, DOI 10.18488/JOURNAL.2/2016.6.2/2.2.24.33]
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Chang TJ, 2019, MULTIMED TOOLS APPL, V78, P9169, DOI 10.1007/s11042-018-6505-4
   Chen SY, 2022, VISUAL COMPUT, V38, P2189, DOI 10.1007/s00371-021-02277-1
   Chen YY, 2019, MULTIMEDIA SYST, V25, P551, DOI 10.1007/s00530-017-0560-y
   Fletcher P, 2017, SIGNAL PROCESS, V136, P2, DOI 10.1016/j.sigpro.2016.12.025
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Jiang XY, 2018, ARXIV
   Ke LF, 2021, MULTIMED TOOLS APPL, V80, P3997, DOI 10.1007/s11042-020-09807-4
   Li CR, 2013, IEEE SIGNAL PROC LET, V20, P799, DOI 10.1109/LSP.2013.2247596
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Kumar PM, 2021, SOFT COMPUT, V25, P12159, DOI 10.1007/s00500-021-05866-3
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890
   Ndayikengurukiye Aristide, 2022, Advances on Smart and Soft Computing: Proceedings of ICACIn 2021. Advances in Intelligent Systems and Computing (1399), P409, DOI 10.1007/978-981-16-5559-3_33
   Niu PP, 2020, MULTIDIM SYST SIGN P, V31, P1509, DOI 10.1007/s11045-020-00718-z
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Sable S, 2020, INT J GRID DISTRIB, V13, P220
   Shynu PG, 2020, J CLOUD COMPUT-ADV S, V9, DOI 10.1186/s13677-020-00214-6
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Soleymani SH, 2019, MULTIMED TOOLS APPL, V78, P19163, DOI 10.1007/s11042-019-7282-4
   Tong DY, 2019, MULTIMED TOOLS APPL, V78, P16053, DOI 10.1007/s11042-018-7014-1
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
NR 27
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19117
EP 19154
DI 10.1007/s11042-022-14039-9
EA OCT 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000866314400001
DA 2024-07-18
ER

PT J
AU Lian, J
   Yu, FN
   Li, LH
   Zhou, YF
AF Lian, Jing
   Yu, Fengning
   Li, Linhui
   Zhou, Yafu
TI Early intention prediction of pedestrians using contextual
   attention-based LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous vehicles; Pedestrian; Intention prediction; Intelligence
ID TRAJECTORY PREDICTION
AB In a realistic traffic scenario involving intelligent vehicles, the interaction between autonomous vehicles and pedestrians is important. It is crucial to safe autonomous driving and advanced driver assistance systems to accurately predict the intentions of pedestrians. Specifically, when an autonomous vehicle is driving in complex environments, such as urban intersection, it will reduce the likelihood of a collision and increase the driving comfort if it can accurately and promptly distinguish the pedestrian's intention. This paper proposes a competitive framework for predicting pedestrian crossing intentions using only video sequences obtained from the RGB camera mounted on the vehicle in natural traffic scenes. In the proposed framework, it firstly detects the pedestrian and tracks them, then predicts whether they will cross or not by the attention-based LSTM (CA-LSTM) with some contextual and dynamical features. This proposed model achieves an accuracy score of 89.68% which is competitive compared to many other related works. Extensive experiments on the JAAD datasets demonstrate that the performance of our model is superior to that of related works, with an accuracy score of 89.68%.
C1 [Lian, Jing; Yu, Fengning; Li, Linhui; Zhou, Yafu] Dalian Univ Technol, Sch Automot Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Li, LH (corresponding author), Dalian Univ Technol, Sch Automot Engn, Dalian 116024, Peoples R China.
FU National Natural Science Foundation of China [51775082,61976039]; China
   Fundamental Research Funds for the Central Universities [DUT19LAB36,
   DUT20GJ207]; Science and Technology Innovation Fund of Dalian
   [2018J12GX061]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos.51775082,61976039) and the China Fundamental Research
   Funds for the Central Universities (Grant Nos. DUT19LAB36, DUT20GJ207),
   and Science and Technology Innovation Fund of Dalian (2018J12GX061).
CR Aboah A, 2021, IEEE COMPUT SOC CONF, P4202, DOI 10.1109/CVPRW53098.2021.00475
   Bandyopadhyay T., 2013, INT S EXPT ROBOTICS, P963, DOI DOI 10.1007/978-3-319-00065-764
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chaabane M, 2020, IEEE WINT CONF APPL, P2286, DOI [10.1109/WACV45572.2020.9093426, 10.1109/wacv45572.2020.9093426]
   Chen T., 2021, P IEEECVF INT C COMP, P3103
   Dong B., 2021, arXiv
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fang ZJ, 2018, IEEE INT VEH SYM, P1271, DOI 10.1109/IVS.2018.8500413
   Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168, DOI 10.1007/BFb0053999
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Keller CG, 2014, IEEE T INTELL TRANSP, V15, P494, DOI 10.1109/TITS.2013.2280766
   Kingma D. P., 2014, arXiv
   Kooij JFP, 2014, LECT NOTES COMPUT SC, V8694, P618, DOI 10.1007/978-3-319-10599-4_40
   Liu BB, 2020, IEEE ROBOT AUTOM LET, V5, P3485, DOI 10.1109/LRA.2020.2976305
   Morency L.P., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383299
   Neogi S, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI)
   Oh SM, 2008, INT J COMPUT VISION, V77, P103, DOI 10.1007/s11263-007-0062-z
   Quan RJ, 2021, IEEE T IMAGE PROCESS, V30, P3229, DOI 10.1109/TIP.2021.3058599
   Rasouli A., 2020, ARXIV
   Rasouli A, 2017, IEEE INT CONF COMP V, P206, DOI 10.1109/ICCVW.2017.33
   Saleh K, 2018, IEEE T INTELL VEHICL, V3, P414, DOI 10.1109/TIV.2018.2873901
   Sun JH, 2020, PROC CVPR IEEE, P657, DOI 10.1109/CVPR42600.2020.00074
   Vaswani A, 2017, ADV NEUR IN, V30
   Wagner M, 2015, LECT N MOBIL, P163, DOI 10.1007/978-3-319-19078-5_14
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xue H, 2021, IEEE T NEUR NET LEAR, V32, P77, DOI 10.1109/TNNLS.2020.2975837
   Yang DF, 2022, IEEE T INTELL VEHICL, V7, P221, DOI 10.1109/TIV.2022.3162719
   Yao Y, 2021, IEEE ROBOT AUTOM LET, V6, P1463, DOI 10.1109/LRA.2021.3056339
   Zeng WL, 2020, IEEE ACCESS, V8, P151250, DOI 10.1109/ACCESS.2020.3016289
NR 30
TC 3
Z9 3
U1 6
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14713
EP 14729
DI 10.1007/s11042-022-13814-y
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000864310100003
DA 2024-07-18
ER

PT J
AU Gattoju, S
   Nagalakshmi, V
AF Gattoju, Saritha
   Nagalakshmi, V.
TI Design of ChaApache framework for securing Hadoop application in big
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hadoop; Big data; Secure data; Unauthorized access; Data encryption;
   Data cleaning; Data compute; Data transmit
AB Hadoop is one of the biggest software structures for distributing the data to compute and handle big data. Big data is a group of composite and enormous datasets that contains a massive amount of data such as real-time data, social media, capabilities of data management, money laundering, and so on. Also, big data is measured as regards terabytes and petabytes. The main issue of the Hadoop application is unauthorized access. There are several existing techniques introduced to secure the data, but they have data errors, malicious attacks, and take a long time to compute. So the author proposed a novel ChaApache framework to secure the Hadoop application from an unauthorized person also to save processing time of data, and reduce the error rate. The main aim of the developed replica is securing data from an unauthorized person or unauthorized access. Moreover, the developed ChaApache framework is implemented in python, and the Hadoop application contains 512 bits of data, and the data are encrypted by four 32 bits. Furthermore, the proposed model is compared with other existing replicas in terms of computation time, resource usage, data sharing rate, encryption speed, and so on.
C1 [Gattoju, Saritha; Nagalakshmi, V.] GITAM Inst Sci Univ, Dept Comp Sci, Visakhapatnam 530045, Andhra Pradesh, India.
RP Gattoju, S (corresponding author), GITAM Inst Sci Univ, Dept Comp Sci, Visakhapatnam 530045, Andhra Pradesh, India.
EM saritha760@gmail.com; nagalakshmi.vadlamani@gmail.com
CR Ali F, 2021, FUTURE GENER COMP SY, V114, P23, DOI 10.1016/j.future.2020.07.047
   Awaysheh FM, 2022, IEEE T ENG MANAGE, V69, P3676, DOI 10.1109/TEM.2020.3045661
   Awaysheh FM, 2020, FUTURE GENER COMP SY, V108, P726, DOI 10.1016/j.future.2020.02.052
   Bao K, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02080-1
   Begum G, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00356-z
   Bide P, 2020, INT CONF ADVAN COMPU, P1, DOI [10.1109/ICACCS48705.2020.9074202, 10.1109/icaccs48705.2020.9074202]
   Cattaneo G, 2019, MULTIMED TOOLS APPL, V78, P32999, DOI 10.1007/s11042-019-7561-0
   Chhabra GS, 2020, MULTIMED TOOLS APPL, V79, P15881, DOI 10.1007/s11042-018-6338-1
   Demirbaga U, 2022, IEEE T COMPUT, V71, P1035, DOI 10.1109/TC.2021.3070639
   Tran DT, 2022, J SUPERCOMPUT, V78, P11051, DOI 10.1007/s11227-021-04275-5
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Gudditti V, 2021, MATER TODAY-PROC, DOI [10.1016/j.matpr.2021.01.190, DOI 10.1016/J.MATPR.2021.01.190]
   Gupta C, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P1336, DOI 10.1109/BigData.2015.7363892
   Gupta D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165491
   Gupta M, 2018, PROCEEDINGS OF THE THIRD ACM WORKSHOP ON ATTRIBUTE-BASED ACCESS CONTROL (ABAC'18), P13, DOI 10.1145/3180457.3180463
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ngu HCV, 2019, CLUSTER COMPUT, V22, P1011, DOI 10.1007/s10586-017-1183-y
   Kapil G, 2020, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.259
   Mahdi MS, 2021, SN APPL SCI, V3, DOI 10.1007/s42452-021-04425-7
   Narayanan U, 2022, J KING SAUD UNIV-COM, V34, P3121, DOI 10.1016/j.jksuci.2020.05.005
   Nellutla R, 2020, ADV INTELL SYST COMP, V1054, P247, DOI 10.1007/978-981-15-0135-7_24
   Panarello A, 2020, MULTIMED TOOLS APPL, V79, P9037, DOI 10.1007/s11042-019-07786-9
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Panwar A, 2020, APPL MACHINE LEARNIN, P365
   Parmar RR, 2017, IEEE ACCESS, V5, P7156, DOI 10.1109/ACCESS.2017.2700228
   Pradeep D, 2020, FUTURE GENER COMP SY, V108, P849, DOI 10.1016/j.future.2020.03.010
   Priyanka E.B., 2021, Deep Learning and Big Data for Intelligent Transportation: Enabling Technologies and Future Trends, P3
   Rahul M. K., 2022, FUNDAMENTALS METHODS, P379, DOI DOI 10.1002/9781119821908.CH16
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Rathore MM, 2018, MULTIMED TOOLS APPL, V77, P4959, DOI 10.1007/s11042-017-4393-7
   Saritha G, 2021, INT J ADV RES ENG TE, V11, P326
   Seethalakshmi V, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00321-w
   Sharma A, 2020, LECT NOTES ELECTR EN, V597, P125, DOI 10.1007/978-3-030-29407-6_11
   Shetty MM, 2019, ADV INTELL SYST, V839, P167, DOI 10.1007/978-981-13-1274-8_13
   Trung L., 2021, EMERGING TECHNOLOGIE, P571, DOI DOI 10.1007/978-981-33-4367-2_54
   Wang SX, 2020, MULTIMED TOOLS APPL, V79, P35369, DOI 10.1007/s11042-019-07765-0
   Yinwei Li, 2020, 2020 International Conference on Advance in Ambient Computing and Intelligence (ICAACI), P47, DOI 10.1109/ICAACI50733.2020.00014
   Yu X, 2014, P 2014 S BOOTCAMP SC, DOI [10.1145/2600176.2600202, DOI 10.1145/2600176.2600202]
   Zagan E, 2020, 2020 15TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P189, DOI [10.1109/das49615.2020.9108912, 10.1109/DAS49615.2020.9108912]
NR 40
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15247
EP 15269
DI 10.1007/s11042-022-13944-3
EA OCT 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000862543700002
DA 2024-07-18
ER

PT J
AU Javed, I
   Butt, MA
   Khalid, S
   Shehryar, T
   Amin, R
   Syed, AM
   Sadiq, M
AF Javed, Iram
   Butt, Muhammad Atif
   Khalid, Samina
   Shehryar, Tehmina
   Amin, Rashid
   Syed, Adeel Muzaffar
   Sadiq, Marium
TI Face mask detection and social distance monitoring system for COVID-19
   pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face mask detection; Social distance measurement; Single and multi-stage
   detectors; Coronavirus
ID FASTER
AB Coronavirus triggers several respirational infections such as sneezing, coughing, and pneumonia, which transmit humans to humans through airborne droplets. According to the guidelines of the World Health Organization, the spread of COVID-19 can be mitigated by avoiding public interactions in proximity and following standard operating procedures (SOPs) including wearing a face mask and maintaining social distancing in schools, shopping malls, and crowded areas. However, enforcing the adaptation of these SOPs on a larger scale is still a challenging task. With the emergence of deep learning-based visual object detection networks, numerous methods have been proposed to perform face mask detection on public spots. However, these methods require a huge amount of data to ensure robustness in real-time applications. Also, to the best of our knowledge, there is no standard outdoor surveillance-based dataset available to ensure the efficacy of face mask detection and social distancing methods in public spots. To this end, we present a large-scale dataset comprising of 10,000 outdoor images categorized into a binary class labeling i.e., face mask, and non-face masked people to accelerate the development of automated face mask detection and social distance measurement on public spots. Alongside, we also present an end-to-end pipeline to perform real-time face mask detection and social distance measurement in an outdoor environment. Initially, existing state-of-the-art single and multi-stage object detection networks are fine-tuned on the proposed dataset to evaluate their performance in terms of accuracy and inference time. Based on better performance, YOLO-v3 architecture is further optimized by tuning its feature extraction and region proposal generation layers to improve the performance in real-time applications. Our results indicate that the presented pipeline performed better than the baseline version, showing an improvement of 5.3% in terms of accuracy.
C1 [Javed, Iram; Khalid, Samina; Sadiq, Marium] Mirpur Univ Sci & Technol, Dept Comp Sci & Informat Technol, Azad Jammu and Kashmir, Pakistan.
   [Butt, Muhammad Atif] Informat Technol Univ, Lahore, Punjab, Pakistan.
   [Shehryar, Tehmina] Mirpur Univ Sci & Technol, Dept Software Engn, Azad Jammu and Kashmir, Pakistan.
   [Amin, Rashid] Univ Chakwal, Dept Comp Sci, Chakwal 48800, Pakistan.
   [Syed, Adeel Muzaffar] Bahria Univ, Dept Software Engn, Islamabad, Pakistan.
RP Khalid, S (corresponding author), Mirpur Univ Sci & Technol, Dept Comp Sci & Informat Technol, Azad Jammu and Kashmir, Pakistan.
EM samina.csit@must.edu.pk
RI amin, Rashid/H-2389-2017
OI amin, Rashid/0000-0002-3143-689X
CR [Anonymous], 2022, MASK DATASET MAKEML
   Atangana A, 2020, CHAOS SOLITON FRACT, V136, DOI 10.1016/j.chaos.2020.109860
   Berahmand K, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104933
   Bhuiyan M.M., 2020, 2020 11 INT C COMPUT, P1, DOI DOI 10.1109/ICCCNT49239.2020.9225384
   Butt MA, 2021, SIMUL-T SOC MOD SIM, V97, P601, DOI 10.1177/00375497211004721
   Butt MA, 2022, LECT NOTES COMPUT SC, V13237, P741, DOI 10.1007/978-3-031-06555-2_50
   Butt MA, 2022, SIGNAL PROCESS-IMAGE, V104, DOI 10.1016/j.image.2022.116667
   Butt MA, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6644861
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Christa GH, 2021, INT CO SIG PROC COMM, P115, DOI 10.1109/ICSPC51351.2021.9451688
   Degadwala Sheshang, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P209, DOI 10.1109/ICAIS50930.2021.9395857
   Edmond V, 2022, APPL INNOVATIVE TECH, V12, P5129
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Ge XY, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102413
   Ghodgaonkar I, 2020, ARXIV
   Goldberg MH, 2020, FRONT COMMUN, V5, DOI 10.3389/fcomm.2020.00044
   Hussain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083495
   Iftikhar A, 2021, SINTEZA 2021 INT SCI, P120
   Intelligence W, 2021, FACE MASK DETECTION
   Jagadeeswari C., 2020, INT J ADV SCI TECHNO, V29, P3074
   Jiang N, 2010, 2010 INT S INT SIGN, P1
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Katz R, 2019, PUBLIC HEALTH REP, V134, P150, DOI 10.1177/0033354918819755
   Khandelwal P, 2020, ARXIV
   Kodali R.K., 2021, 2021 INT C COMP COMM, P1
   Lee C, 2016, INT C CONTR AUTOMAT, P107, DOI 10.1109/ICCAS.2016.7832305
   Levchev P, 2014, INT C INDOOR POSIT, P442, DOI 10.1109/IPIN.2014.7275515
   Liang JZ, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING FOR GEOSPATIAL RESEARCH AND APPLICATION (COM.GEO), P70, DOI 10.1109/COMGEO.2013.11
   Liu B, 2017, CHIN AUTOM CONGR, P6233, DOI 10.1109/CAC.2017.8243900
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Magoo R, 2021, NEURAL COMPUT APPL, V33, P15807, DOI 10.1007/s00521-021-06201-5
   Mai XC, 2020, IEEE T AUTOM SCI ENG, V17, P1555, DOI 10.1109/TASE.2020.2964289
   Mehrpooya A, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab410
   Middleton J, 2020, INT J PUBLIC HEALTH, V65, P237, DOI 10.1007/s00038-020-01362-x
   MILITANTE SV, 2020, 2020 3 INT C VOCATIO
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Naudé W, 2020, AI SOC, V35, P761, DOI 10.1007/s00146-020-00978-0
   Niu YR, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175908
   Onyema EM, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5196000
   Prather KA, 2020, SCIENCE, V368, P1422, DOI 10.1126/science.abc6197
   Prem K, 2020, LANCET PUBLIC HEALTH, V5, pE261, DOI 10.1016/S2468-2667(20)30073-6
   Punn N. S., 2020, ARXIV
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Rahmani MKI, 2022, COMPUT SYST SCI ENG, V42, P1181, DOI 10.32604/csse.2022.022014
   Rasib M, 2021, IEEE ACCESS, V9, P167855, DOI 10.1109/ACCESS.2021.3134889
   Rasib M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6639169
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rostami M, 2022, ARTIF INTELL MED, V123, DOI 10.1016/j.artmed.2021.102228
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saberi-Movahed F, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105426
   Sethi S, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103848
   Snyder SE, 2021, IEEE SOUTHEASTCON, P614, DOI 10.1109/SOUTHEASTCON45413.2021.9401874
   Suwarno I, 2020, USING COMBINATION PI
   Taneja Soham, 2021, Proceedings of Second International Conference on Computing, Communications, and Cyber-Security. IC4S 2020. Lecture Notes in Networks and Systems (LNNS 203), P39, DOI 10.1007/978-981-16-0733-2_3
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Yang DF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134608
   Zhang SF, 2021, IEEE T PATTERN ANAL, V43, P4008, DOI 10.1109/TPAMI.2020.2997456
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2013, OPTIK, V124, P1218, DOI 10.1016/j.ijleo.2012.03.032
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 65
TC 5
Z9 5
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14135
EP 14152
DI 10.1007/s11042-022-13913-w
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000862219700009
PM 36196269
OA Green Published, Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Jin, MX
   Li, HF
   Xia, ZQ
AF Jin, Mingxin
   Li, Huifang
   Xia, Zhaoqiang
TI Hybrid attention network and center-guided non-maximum suppression for
   occluded face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Occluded face detection; Inter-class occlusion; Intra-class occlusion;
   Hybrid attention mechanism; Center-guided non-maximum suppression
ID CONVOLUTIONAL NEURAL-NETWORK; ROBUST; NMS
AB The face detection technique has obtained significant development with the huge application of convolutional neural networks. However, various types of occlusion are widespread in face detection, inevitably destroying the visual features of faces and significantly increasing the difficulty of post-processing. These problems make the occluded face detection a challenging and crucial task. In this paper, we propose a new occlusion-aware face detector (OFDet) to deal with the problem of occluded face detection, which mainly includes a hybrid attention module (HAM) and a center-guided non-maximum suppression (cgNMS) algorithm. Specifically, the HAM consists of three types of attention blocks, i.e., spatial attention block (SAB), channel attention block (CAB), and channel-spatial attention block (CSAB), integrated in a hybrid manner. This module can help the network learn more discriminative and robust feature representation by adaptively highlighting the features of more informative visible facial regions and weakening the features of occluded facial regions, contributing to solving the inter-class occlusion issue. The cgNMS introduces the information of center point distance between detected boxes as a new suppression metric to supplement the traditional intersection over union (IoU) metric. This dual-metric design of cgNMS can ensure that it makes the correct post-processing from highly overlapped detected boxes to deal with the intra-class occlusion problem. Experimental results show that our OFDet achieves state-of-the-art results on the MAFA dataset and obtains competitive results on the WIDER FACE and FDDB datasets, which demonstrate the effectiveness of our method. In addition, HAM and cgNMS are highly efficient, and their cost basically does not affect the efficiency of the model.
C1 [Jin, Mingxin; Li, Huifang; Xia, Zhaoqiang] Northwestern Polytech Univ, Sch Elect & Informat, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Li, HF (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
EM jmx@mail.nwpu.edu.cn; LHuifang@nwpu.edu.cn; zxia@nwpu.edu.cn
RI Xia, Zhaoqiang/AAC-4021-2019; Li, Huifang/ADF-7310-2022
OI Xia, Zhaoqiang/0000-0003-0630-3339; Jin, Mingxin/0000-0002-6532-1409;
   Li, Huifang/0000-0001-7634-5839
FU Key Research and Development Program of Shaanxi, China [2021ZDLGY15-01]
FX This work is partially supported by the Key Research and Development
   Program of Shaanxi, China (Program No. 2021ZDLGY15-01).
CR Behera SK, 2021, MULTIMED TOOLS APPL, V80, P19043, DOI 10.1007/s11042-021-10704-7
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen S., 2019, ARXIV
   Chen YJ, 2018, INT CONF BIOMETR THE
   Chen YP, 2018, ADV NEUR IN, V31
   Cheng G, 2021, J REMOTE SENS-PRC, V2021, DOI 10.34133/2021/9805389
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Chenhongyi Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P530, DOI 10.1007/978-3-030-58523-5_31
   Chi C, 2019, AAAI CONF ARTIF INTE, P8231
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Fang ZY, 2020, NEUROCOMPUTING, V398, P20, DOI 10.1016/j.neucom.2020.02.060
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gahlert N., 2020, ARXIV
   Gan YL, 2020, IEEE ACCESS, V8, P7383, DOI 10.1109/ACCESS.2020.2963913
   Gao ZL, 2019, PROC CVPR IEEE, P3019, DOI 10.1109/CVPR.2019.00314
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Ghiasi G, 2015, ARXIV
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He LX, 2018, PROC CVPR IEEE, P7054, DOI 10.1109/CVPR.2018.00737
   He R, 2020, IEEE T PATTERN ANAL, V42, P1025, DOI 10.1109/TPAMI.2019.2961900
   He Zhao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7718, DOI 10.1109/CVPR42600.2020.00774
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang Lang, 2019, ARXIV
   Huang X., 2020, P IEEE CVF C COMP VI, P10747, DOI DOI 10.1109/CVPR42600.2020.01076
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Iliadis M, 2017, IEEE T IMAGE PROCESS, V26, P2203, DOI 10.1109/TIP.2017.2675206
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Kumar Abhinav, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8233, DOI 10.1109/CVPR42600.2020.00826
   Lee H, 2019, IEEE I CONF COMP VIS, P1854, DOI 10.1109/ICCV.2019.00194
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   LINSLEY D., 2019, INT C LEARNING REPRE
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu Y, 2020, IEEE C COMPUTER VISI, P13043
   Liu Y., 2020, P IEEE CVF C COMPUTE, P13568
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XQ, 2022, IEEE T CYBERNETICS, V52, P8425, DOI 10.1109/TCYB.2020.3035587
   Luo JP, 2020, PATTERN RECOGN LETT, V133, P180, DOI 10.1016/j.patrec.2020.03.002
   Mahbub U, 2019, IMAGE VISION COMPUT, V82, P1, DOI 10.1016/j.imavis.2018.12.003
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Misra D, 2021, IEEE WINT CONF APPL, P3138, DOI 10.1109/WACV48630.2021.00318
   Mnih V, 2014, ADV NEUR IN, V27
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Nian FD, 2020, NEUROCOMPUTING, V395, P119, DOI 10.1016/j.neucom.2017.12.071
   Opitz M, 2016, LECT NOTES COMPUT SC, V9907, P386, DOI 10.1007/978-3-319-46487-9_24
   Park J., 2018, BRIT MACH VIS C, P147
   Qin ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P763, DOI 10.1109/ICCV48922.2021.00082
   Roccetti M., 2010, Comput Entertain (CIE), V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Roy AG, 2019, IEEE T MED IMAGING, V38, P540, DOI 10.1109/TMI.2018.2867261
   Salscheider NO, 2021, INT C PATT RECOG, P7848, DOI 10.1109/ICPR48806.2021.9412930
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Triantafyllidou Danai, 2016, 2016 23rd International Conference on Pattern Recognition (ICPR). Proceedings, P3560, DOI 10.1109/ICPR.2016.7900186
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang J., 2017, arXiv
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xia ZQ, 2020, IEEE T IMAGE PROCESS, V29, P8590, DOI 10.1109/TIP.2020.3018222
   Yang LX, 2021, PR MACH LEARN RES, V139
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang Z., 2020, P IEEECVF C COMPUTER, P11794
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu XB, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P515, DOI 10.1109/IAEAC.2017.8054068
   Zeng D, 2021, IET BIOMETRICS, V10, P581, DOI 10.1049/bme2.12029
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang JL, 2021, IEEE T MULTIMEDIA, V23, P3085, DOI 10.1109/TMM.2020.3020691
   Zhang Kevin, 2019, ARXIV
   Zhang SF, 2019, INT J COMPUT VISION, V127, P537, DOI 10.1007/s11263-019-01159-3
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 85
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15143
EP 15170
DI 10.1007/s11042-022-13999-2
EA SEP 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000861190800002
DA 2024-07-18
ER

PT J
AU Raja, R
   Sharma, PC
   Mahmood, MR
   Saini, DK
AF Raja, Rohit
   Sharma, Prakash Chandra
   Mahmood, Md Rashid
   Saini, Dinesh Kumar
TI Analysis of anomaly detection in surveillance video: recent trends and
   future vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Video surveillance; Deep learning; Machine learning;
   Feature extraction; Real-time video detection
ID LOCALIZATION; FRAMEWORK; NETWORKS
AB Video Surveillance (VS) systems are popular. For enhancing the safety of public lives as well as assets, it is utilized in public places like marketplaces, hospitals, streets, education institutions, banks, shopping malls, city administrative offices, together with smart cities. The main purpose of security applications is the well-timed and also accurate detection of video anomalies. Anomalous activities along with anomalous entities are the video anomalies, which are stated as the irregular or abnormal patterns on the video that doesn't match the normal trained patterns. Automatic detection of Anomalous activities, say traffic rule infringements, riots, fighting, and stampede in addition to anomalous entities, say, weapons at the sensitive place together with deserted luggage ought to be done. The Anomaly Detection (AD) in VS is reviewed in the paper. This survey concentrates on the Deep Learning (DL) application in finding the exact count, involved individuals and the occurred activity on a larger crowd at every climate condition. The fundamental DL implementation technology concerned in disparate crowd Video Analysis (VA) is discussed. Moreover, it presented the available datasets as well as metrics for performance evaluation and also described the examples of prevailing VS systems utilized in the real life. Lastly, the challenges together with propitious directions for additional research are outlined. Pattern recognition has been the subject of a great deal of study during the previous half-century. There isn't a single technique that can be utilised for all kinds of applications, whether in bioinformatics or data mining or speech recognition or remote sensing or multimedia or text detection or localization or any other area. Methodologies for object recognition are the primary focus of this paper. All aspects of object recognition, including local and global feature-based algorithms, as well as various pattern-recognition approaches, are examined here. Please note that we have attempted to describe the findings of many technologies and the future extent of this paper's particular technique. We used the datasets' properties and other evaluation parameters found in an easily accessible web database. Research in pattern recognition and object recognition can greatly benefit from this study, which identifies the research gaps and limits in this subject.
C1 [Raja, Rohit] Guru Ghasidas Vishwavidyalaya, Dept Informat Technol, Bilaspur, CG, India.
   [Sharma, Prakash Chandra] Manipal Univ Jaipur, Dept Informat Technol, Jaipur, Rajasthan, India.
   [Mahmood, Md Rashid] Guru Nanak Inst, Dept Elect & Commun Engn, Tech Campus, Hyderabad, India.
   [Saini, Dinesh Kumar] Manipal Univ Jaipur, Dept Comp & Commun Engn, Jaipur, Rajasthan, India.
C3 Guru Ghasidas Vishwavidyalaya; Manipal University Jaipur; Guru Nanak
   Institutions Technical Campus; Manipal University Jaipur
RP Sharma, PC (corresponding author), Manipal Univ Jaipur, Dept Informat Technol, Jaipur, Rajasthan, India.
EM drrohitraja1982@gmail.com; prakashshanna12@gmail.com;
   er.mashid@gmail.com; dineshkumar.saini@jaipur.manipal.edu
RI Mahmood, Md Rashid/AAZ-3961-2021; Saini, Dinesh Kumar/P-8322-2015
OI Saini, Dinesh Kumar/0000-0002-5140-1731; Mahmood, Md
   Rashid/0000-0002-3546-4716
CR Al Farid F, 2022, J IMAGING, V8, DOI 10.3390/jimaging8060153
   Barz B, 2019, IEEE T PATTERN ANAL, V41, P1088, DOI 10.1109/TPAMI.2018.2823766
   Bozcan I, 2021, IEEE ROBOT AUTOM LET, V6, P1638, DOI 10.1109/LRA.2021.3057003
   Chandrakar R, 2021, INT J BIOMETRICS, V1, P1
   Chandrakar R, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116306
   Chandrakar R, 2022, MULTIMED TOOLS APPL, V81, P42149, DOI 10.1007/s11042-021-11290-4
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chen CY, 2015, IEEE SENS J, V15, P7252, DOI 10.1109/JSEN.2015.2472960
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chu W., 2017, J LATEX CLASS FILES, V14, P1
   Direkoglu C, 2020, IEEE ACCESS, V8, P80408, DOI 10.1109/ACCESS.2020.2990355
   Dong LP, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P266, DOI 10.1109/ICDSP.2016.7868559
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Fadl S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116066
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Ganokratanaa T, 2020, IEEE ACCESS, V8, P50312, DOI 10.1109/ACCESS.2020.2979869
   Gao XW, 2019, IEEE ACCESS, V7, P107550, DOI 10.1109/ACCESS.2019.2931820
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hu ZP, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102765
   Khaleghi Ali, 2018, 2018 8th Conference of AI & Robotics and 10th RoboCup Iranopen International Symposium (IRANOPEN), P73, DOI 10.1109/RIOS.2018.8406634
   Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li A, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107355
   Li B, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103249
   Li NJ, 2019, NEUROCOMPUTING, V369, P92, DOI 10.1016/j.neucom.2019.08.044
   Li Q, 2016, INT SYM COMPUT INTEL, P455, DOI [10.1109/ISCID.2016.1112, 10.1109/ISCID.2016.111]
   Li T, 2021, NEUROCOMPUTING, V439, P256, DOI 10.1016/j.neucom.2021.01.097
   Li YS, 2018, IEEE ACCESS, V6, P40281, DOI 10.1109/ACCESS.2018.2851747
   Li YY, 2019, IEEE ACCESS, V7, P172425, DOI 10.1109/ACCESS.2019.2954540
   Li ZY, 2020, IEEE ACCESS, V8, P25531, DOI 10.1109/ACCESS.2020.2970497
   Lim JY, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104094
   Liu C, 2010, IEEE IMAGE PROC, P717, DOI 10.1109/ICIP.2010.5651958
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   Luo WX, 2021, NEUROCOMPUTING, V444, P332, DOI 10.1016/j.neucom.2019.12.148
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Maqsood R, 2021, MULTIMED TOOLS APPL, V80, P18693, DOI 10.1007/s11042-021-10570-3
   Murugesan M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103303
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Ovhal KB, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P596, DOI 10.1109/ISS1.2017.8389240
   Pandey S, 2022, INT J REMOTE SENS, V43, P5848, DOI 10.1080/01431161.2021.2000062
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Pramanik A, 2021, ACCIDENT ANAL PREV, V154, DOI 10.1016/j.aap.2021.106019
   Ragedhaksha, 2023, Materials Today: Proceedings, P2911, DOI 10.1016/j.matpr.2021.07.064
   Raja R, 2022, CMC-COMPUT MATER CON, V72, P2015, DOI 10.32604/cmc.2022.022904
   Rani S, 2022, MULTIMED TOOLS APPL, V81, P17303, DOI 10.1007/s11042-022-12412-2
   Reccetti M., 2010, Comput Entertain, V8, P1, DOI [10.1145/1921141.1921148, DOI 10.1145/1921141.1921148]
   Sahu AK, 2021, COMPUT COMMUN, V176, P146, DOI 10.1016/j.comcom.2021.05.024
   SanMiguel JC, 2017, INT CARN CONF SECU
   Singh H., 2020, arXiv
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Sun JY, 2018, IEEE ACCESS, V6, P33353, DOI 10.1109/ACCESS.2018.2848210
   Thomaz LA, 2018, IEEE T CIRCUITS-I, V65, P1003, DOI 10.1109/TCSI.2017.2758379
   Tiwari L, 2021, MEASUREMENT, V172, DOI 10.1016/j.measurement.2020.108882
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang T, 2019, IEEE T INF FOREN SEC, V14, P1390, DOI 10.1109/TIFS.2018.2878538
   Wu P, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107515
   Wu P, 2020, IEEE T NEUR NET LEAR, V31, P2609, DOI 10.1109/TNNLS.2019.2933554
   Wu RZ, 2021, NEUROCOMPUTING, V462, P523, DOI 10.1016/j.neucom.2021.05.112
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xiao T, 2015, IEEE SIGNAL PROC LET, V22, P1477, DOI 10.1109/LSP.2015.2410031
   Xiaocai Zhang, 2021, Knowledge-Based Systems, V217, P60, DOI 10.1016/j.knosys.2021.106833
   Xie SC, 2019, NEURAL COMPUT APPL, V31, P175, DOI 10.1007/s00521-018-3692-x
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu K, 2020, IEEE T MULTIMEDIA, V22, P394, DOI 10.1109/TMM.2019.2929931
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1198, DOI 10.1109/TITS.2016.2601655
   Zaheer MZ, 2019, I C INF COMM TECH CO, P472, DOI 10.1109/ictc46691.2019.8939930
   Zaheer MZ, 2020, IEEE SIGNAL PROC LET, V27, P1705, DOI 10.1109/LSP.2020.3025688
   Zahid Y, 2020, IEEE ACCESS, V8, P220620, DOI 10.1109/ACCESS.2020.3042222
   Zaidi S, 2017, 2017 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN COMPUTER, ELECTRICAL, ELECTRONICS AND COMMUNICATION (CTCEEC), P544, DOI 10.1109/CTCEEC.2017.8455012
   Zang XH, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P113, DOI 10.1109/BigMM.2016.33
   Zhang XC, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108234
   Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394
   Zhou FQ, 2020, NEURAL PROCESS LETT, V52, P961, DOI 10.1007/s11063-019-10113-w
NR 76
TC 8
Z9 8
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12635
EP 12651
DI 10.1007/s11042-022-13954-1
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000860416900003
DA 2024-07-18
ER

PT J
AU Biswas, K
   Shivakumara, P
   Pal, U
   Lu, T
   Blumenstein, M
   Lladós, J
AF Biswas, Kunal
   Shivakumara, Palaiahnakote
   Pal, Umapada
   Lu, Tong
   Blumenstein, Michael
   Llados, Josep
TI Classification of aesthetic natural scene images using statistical and
   semantic features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene images; Personality traits; Person behaviour; Color features; Deep
   learning; Aesthetic images
ID QUALITY ASSESSMENT
AB Aesthetic image analysis is essential for improving the performance of multimedia image retrieval systems, especially from a repository of social media and multimedia content stored on mobile devices. This paper presents a novel method for classifying aesthetic natural scene images by studying the naturalness of image content using statistical features, and reading text in the images using semantic features. Unlike existing methods that focus only on image quality with human information, the proposed approach focuses on image features as well as text-based semantic features without human intervention to reduce the gap between subjectivity and objectivity in the classification. The aesthetic classes considered in this work are (i) Very Pleasant, (ii) Pleasant, (iii) Normal and (iv) Unpleasant. The naturalness is represented by features of focus, defocus, perceived brightness, perceived contrast, blurriness and noisiness, while semantics are represented by text recognition, description of the images and labels of images, profile pictures, and banner images. Furthermore, a deep learning model is proposed in a novel way to fuse statistical and semantic features for the classification of aesthetic natural scene images. Experiments on our own dataset and the standard datasets demonstrate that the proposed approach achieves 92.74%, 88.67% and 83.22% average classification rates on our own dataset, AVA dataset and CUHKPQ dataset, respectively. Furthermore, a comparative study of the proposed model with the existing methods shows that the proposed method is effective for the classification of aesthetic social media images.
C1 [Biswas, Kunal; Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata, India.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Lu, Tong] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Blumenstein, Michael] Univ Technol Sydney, Sydney, NSW, Australia.
   [Llados, Josep] Univ Autonoma Barcelona, Comp Vis Ctr, Barcelona, Spain.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   Universiti Malaya; Nanjing University; University of Technology Sydney;
   Autonomous University of Barcelona; Centre de Visio per Computador (CVC)
RP Shivakumara, P (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
EM biswaskunal29@gmail.com; shiva@um.edu.my; umapada@isical.ac.in;
   lutong@nju.edu.cn; michael.blumenstein@uts.edu.au; josep@cvc.uab.es
RI Palaiahnakote, Shivakumara/B-6261-2013; Pal, Umapada/AAC-4930-2022;
   Palaiahnakote, Shivakumara/ITU-6488-2023
OI Palaiahnakote, Shivakumara/0000-0001-9026-4613
FU University of Malaya, Malaysia [GPF096A-2020, GPF096B-2020,
   GPF096C-2020]; TIH; ISI
FX Palaiahnakote Shivakumara received partial support for this work from
   the Faculty Grant: GPF096A-2020, GPF096B-2020 and GPF096C-2020,
   University of Malaya, Malaysia. This work is also partly supported by
   TIH, ISI.
CR Adak C, 2017, PROC INT CONF DOC, P175, DOI 10.1109/ICDAR.2017.37
   [Anonymous], Vision AI | Derive Image Insights via ML | Cloud Vision API | Google Cloud
   BHATTACHARYA S, 2011, ACM TOMM, V78, P1
   Bum J, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102973
   Cui C., 2020, ACM T MULTIM COMPUT, V16, P1
   Dai Y, 2022, J IMAGING, V8, DOI 10.3390/jimaging8040085
   Dai Y, 2021, MULTIMED TOOLS APPL, V80, P1387, DOI 10.1007/s11042-020-09426-z
   Deng YB, 2017, IEEE SIGNAL PROC MAG, V34, P80, DOI 10.1109/MSP.2017.2696576
   Gattupalli V, 2016, INT C PATT RECOG, P2446, DOI 10.1109/ICPR.2016.7900003
   Gomez R, 2019, ARXIV
   Guntuku SC, 2017, STUDYING PERSONALITY
   Jang H, 2021, IEEE ACCESS, V9, P29850, DOI 10.1109/ACCESS.2021.3060171
   Jiang W, 2010, IEEE INT CON MULTI, P920, DOI 10.1109/ICME.2010.5582588
   Jin X, 2020, MULTIMED TOOLS APPL, V79, P14341, DOI 10.1007/s11042-018-6436-0
   Kim WH, 2020, IEEE T AFFECT COMPUT, V11, P493, DOI 10.1109/TAFFC.2018.2809752
   Krishnani D, 2021, MULTIMED TOOLS APPL, V80, P15589, DOI 10.1007/s11042-020-10404-8
   KUANG Q, 2020, IEEE T, V2000, P2623
   Kucer M, 2018, IEEE WINT CONF APPL, P1764, DOI 10.1109/WACV.2018.00196
   Li L., 2020, IEEE T IP, V29, P388
   Li X., 2009, P 1 ACM INT WORKSHOP, P33
   Lu P, 2018, INT C PATT RECOG, P2845, DOI 10.1109/ICPR.2018.8546328
   Luo, 2022, SOCIAL IMAGE AESTHET, DOI [10.1007/s00521-022-07128-1, DOI 10.1007/S00521-022-07128-1]
   MacAvaney S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0221152
   Majumdar A, 2016, INT CONF FRONT HAND, P423, DOI [10.1109/ICFHR.2016.80, 10.1109/ICFHR.2016.0085]
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   MURRAY N, 2012, PROC CVPR IEEE, P2408, DOI DOI 10.1109/CVPR.2012.6247954
   Muszynski M, 2018, ACM TOMM, V14
   Pfister J, 2021, IEEE COMPUT SOC CONF, P816, DOI 10.1109/CVPRW53098.2021.00091
   Safari RM, 2019, MULTIMED TOOLS APPL, V78, P33747, DOI 10.1007/s11042-019-08046-6
   Sankarasubramaiam Y, 2010, P ICIP, P2137
   Shen LQ, 2019, IEEE TETCI, V3, P59, DOI 10.1109/TETCI.2018.2804885
   Shu YY, 2020, NEUROCOMPUTING, V404, P304, DOI 10.1016/j.neucom.2020.04.142
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Zeng H, 2020, IEEE T IMAGE PROCESS, V29, P1548, DOI 10.1109/TIP.2019.2941778
   Zhang XD, 2021, IEEE T MULTIMEDIA, V23, P611, DOI 10.1109/TMM.2020.2985526
   Zhang XD, 2019, IEEE T MULTIMEDIA, V21, P2815, DOI 10.1109/TMM.2019.2911428
   Zhang YH, 2012, IEEE IMAGE PROC, P2753
NR 37
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13507
EP 13532
DI 10.1007/s11042-022-13924-7
EA SEP 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857279400002
DA 2024-07-18
ER

PT J
AU Wani, IM
   Arora, S
AF Wani, Insha Majeed
   Arora, Sakshi
TI Osteoporosis diagnosis in knee X-rays by transfer learning based on
   convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Osteoporosis; Knee bone; X-rays; Deep learning; Diagnosis
ID QUANTITATIVE COMPUTED-TOMOGRAPHY; EPIDEMIOLOGY; ULTRASOUND; FRACTURES;
   DENSITY
AB Osteoporosis degrades the quality of bones and is the primary cause of fractures in the elderly and women after menopause. The high diagnostic and treatment costs urge the researchers to find a cost-effective diagnostic system to diagnose osteoporosis in the early stages. X-ray imaging is the cheapest and most common imaging technique to detect bone pathologies butmanual interpretation of x-rays for osteoporosis is difficult and extraction of required features and selection of high-performance classifiers is a very challenging task. Deep learning systems have gained the popularity in image analysis field over the last few decades. This paper proposes a convolution neural network (CNN) based approach to detect osteoporosis from x-rays. In our study, we have used the transfer learning of deep learning-based CNNs namely AlexNet, VggNet-16, ResNet, and VggNet -19 to classify the x-ray images of knee joints into normal, osteopenia, and osteoporosis disease groups. The main objectives of the current study are: (i) to present a dataset of 381 knee x-rays medically validated by the T-scores obtained from the Quantitative Ultrasound System, and (ii) to propose a deep learning approach using transfer learning to classify different stages of the disease. The performance of these classifiers is compared and the best accuracy of 91.1% is achieved by pretrained Alexnet architecture on the presented dataset with an error rate of 0.09 and validation loss of 0.54 as compared to the accuracy of 79%, an error rate of 0.21, and validation loss of 0.544 when pretrained network was not used.. The results of the study suggest that a deep learning system with transfer learning can help clinicians to detect osteoporosis in its early stages hence reducing the risk of fractures.
C1 [Wani, Insha Majeed; Arora, Sakshi] Shri Mata Vaishno Devi Univ, Sch Comp Sci Engn, Katra, India.
C3 Shri Mata Vaishno Devi University
RP Wani, IM (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci Engn, Katra, India.
EM insha333@gmail.com; sakshi@smvdu.ac.in
CR Ali AM, 2002, J ORTHOP TRAUMA, V16, P323, DOI 10.1097/00005131-200205000-00006
   Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   [Anonymous], 1994, World Health Organ Tech Rep Ser, V843, P1
   [Anonymous], 2018, 2018 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2018.8489205
   Becker David J, 2010, Curr Rheumatol Rep, V12, P186, DOI 10.1007/s11926-010-0097-y
   Brett AD, 2015, J ORTHOP TRANSL, V3, P178, DOI 10.1016/j.jot.2015.08.006
   Chen Y., 2018, INT C HEALTHC SCI EN, P83
   Chen YJ, 2018, EUR RADIOL, V28, P5027, DOI 10.1007/s00330-018-5419-x
   COOPER C, 1992, TRENDS ENDOCRIN MET, V3, P224, DOI 10.1016/1043-2760(92)90032-V
   Court-Brown CM, 2006, INJURY, V37, P691, DOI 10.1016/j.injury.2006.04.130
   Deniz CM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34817-6
   Derkatch S, 2019, RADIOLOGY, V293, P405, DOI 10.1148/radiol.2019190201
   Dimai HP, 2017, BONE, V104, P39, DOI 10.1016/j.bone.2016.12.016
   Ebrahimi-Ghahnavieh A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P133, DOI [10.1109/iciaict.2019.8784845, 10.1109/ICIAICT.2019.8784845]
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Fang YJ, 2021, EUR RADIOL, V31, P1831, DOI 10.1007/s00330-020-07312-8
   Ferizi U, 2019, J MAGN RESON IMAGING, V49, P1029, DOI 10.1002/jmri.26280
   Gregg EW, 1997, OSTEOPOROSIS INT, V7, P89, DOI 10.1007/BF01623682
   Guo MH, 2019, PROC INT CONF ANTI, P324, DOI [10.1109/icasid.2019.8925267, 10.1109/ICASID.2019.8925267]
   Hans D, 2017, J CLIN DENSITOM, V20, P322, DOI 10.1016/j.jocd.2017.06.018
   Hatano K, 2017, INT C CONTR AUTOMAT, P1593, DOI 10.23919/ICCAS.2017.8204241
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He QF, 2018, BONE JOINT RES, V7, P468, DOI 10.1302/2046-3758.77.BJR-2017-0332.R1
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Jain S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1599537
   Jiang H, 2018, J CLIN DENSITOM, V21, P140, DOI 10.1016/j.jocd.2017.02.003
   Johnell O, 2006, OSTEOPOROSIS INT, V17, P1726, DOI 10.1007/s00198-006-0172-4
   Kanis J.A., 2008, WHO Sci. Gr. Assess. osteoprosis Prim. Heal. care Lev, P5
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Krishnaraj A, 2019, J AM COLL RADIOL, V16, P1473, DOI 10.1016/j.jacr.2019.02.033
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee JS, 2019, DENTOMAXILLOFAC RAD, V48, DOI 10.1259/dmfr.20170344
   Lee KS, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020392
   Lee S, 2020, SKELETAL RADIOL, V49, P613, DOI 10.1007/s00256-019-03342-6
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Liu DS, 2019, LECT NOTES COMPUT SC, V11953, P535, DOI 10.1007/978-3-030-36708-4_44
   Liu J, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1502-3
   Lu S, 2020, DETECTION ABNORMAL B, P1
   Lu SY, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e05625
   Majeed Wani I, 2021, MENDELEY DATA, VV2, DOI [10.17632/fxjm8fb6mw.2, DOI 10.17632/FXJM8FB6MW.2]
   Mallina R, 2010, KNEE, V17, P181, DOI 10.1016/j.knee.2009.10.011
   Militante S. V., 2019, 2019 IEEE 6 INT C EN, P1, DOI [DOI 10.1109/ICETAS48360.2019.9117332, 10.1109/ICETAS48360.2019.9117332]
   Mithal Ambrish, 2014, Indian J Endocrinol Metab, V18, P449, DOI 10.4103/2230-8210.137485
   Rahman T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093233
   Salau A.O., 2021, INFORM MED UNLOCKED, V23, P100511, DOI [10.1016/j.imu.2021.100511, DOI 10.1016/J.IMU.2021.100511]
   Salau AO, 2020, J GENET ENG BIOTECHN, V18, DOI 10.1186/s43141-020-00026-w
   Salih Shadman Q., 2020, Kurdistan Journal of Applied Research, V5, P119, DOI 10.24017/covid.14
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sollmann N, 2022, AUTOMATED OPPORTUNIS
   Stange R, 2020, PRINCIPLES PRACTICE
   Sukegawa S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-021-04603-y
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamilselvi R., 2019, BIOMED PHARMACOL J, V12, P267, DOI DOI 10.13005/bpj/1637
   Tang C, 2019, CNN BASED AUTOMATIC
   Tecle N, 2020, J HAND SURG-AM, V45, P175, DOI 10.1016/j.jhsa.2019.11.019
   Tomita N, 2018, COMPUT BIOL MED, V98, P8, DOI 10.1016/j.compbiomed.2018.05.011
   Torrey Lisa, 2010, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, P242
   Wang SP, 2021, BMC MUSCULOSKEL DIS, V22, DOI 10.1186/s12891-021-04090-2
   Wani IM, 2021, 2021 9 INT C RELIABI, P1
   Wani IM, 2020, MED BIOL ENG COMPUT, V58, P1873, DOI 10.1007/s11517-020-02171-3
   Wani IM, 2020, LECT NOTES ELECTR EN, V597, P65, DOI 10.1007/978-3-030-29407-6_6
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Yamamoto N, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10111534
   Yasaka K, 2020, EUR RADIOL, V30, P3549, DOI 10.1007/s00330-020-06677-0
   Yu S., 2019, J SMART HLTH
   Yu X, 2019, FUND INFORM, V168, P219, DOI 10.3233/FI-2019-1829
   Zhang B, 2020, BONE, V140, DOI 10.1016/j.bone.2020.115561
NR 71
TC 9
Z9 10
U1 5
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14193
EP 14217
DI 10.1007/s11042-022-13911-y
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857279400001
PM 36185321
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Anilkumar, B
   Srividya, K
   Sowjanya, AM
AF Anilkumar, B.
   Srividya, K.
   Sowjanya, A. Mary
TI Covid-19 classification using sigmoid based hyper-parameter modified DNN
   for CT scans and chest X-rays
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pre-processing; Sigmoid value; DNN; AGWO; Covid-19; Gaussian filter
ID DEEP; CORONAVIRUS
AB Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus. Diagnosis of Computed Tomography (CT), and Chest X-rays (CXR) contains the problem of overfitting, earlier diagnosis, and mode collapse. In this work, we predict the classification of the Corona in CT and CXR images. Initially, the images of the dataset are pre-processed using the function of an adaptive Gaussian filter for de-nosing the image. Once the image is pre-processed it goes to Sigmoid Based Hyper-Parameter Modified DNN(SHMDNN). The hyperparameter modification makes use of the optimization algorithm of adaptive grey wolf optimization (AGWO). Finally, classification takes place and classifies the CT and CXR images into 3 categories namely normal, Pneumonia, and COVID-19 images. Better accuracy of 99.9% is reached when compared to different DNN networks.
C1 [Anilkumar, B.] GMR Inst Technol, Dept ECE, Rajam, India.
   [Srividya, K.] GMR Inst Technol, Dept CSE, Rajam, India.
   [Sowjanya, A. Mary] Andhra Univ Coll Engn, Dept CS&SE, Visakhapatnam, Andhra Pradesh, India.
C3 GMR Institute of Technology; GMR Institute of Technology; Andhra
   University
RP Anilkumar, B (corresponding author), GMR Inst Technol, Dept ECE, Rajam, India.
EM anil.revanth@gmail.com
RI B, ANILKUMAR/ADY-9383-2022
OI B, ANILKUMAR/0000-0002-3468-3650
CR Abbasimehr H, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110511
   Abdelminaam DS, 2021, IEEE ACCESS, V9, P27840, DOI 10.1109/ACCESS.2021.3058066
   Afshar P, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00900-3
   Akshitha B., 2021, Journal of Physics: Conference Series, V1916, DOI 10.1088/1742-6596/1916/1/012064
   Al-Waisy AS, 2021, CMC-COMPUT MATER CON, V67, P2409, DOI 10.32604/cmc.2021.012955
   Albahli S, 2021, CURR MED IMAGING, V17, P109, DOI 10.2174/1573405616666200604163954
   Ben Ahmed K, 2021, IEEE ACCESS, V9, P72970, DOI [10.1109/ACCESS.2021.3079716, 10.1109/access.2021.3079716]
   Berrimi M., 2021, Philosophers on Philosophy: The 2020 PhilPapers Survey, P1
   Cadena L., 2017, Proceedings of the World Congress on Engineering, V1, P5
   Castiglione A, 2021, IEEE T IND INFORM, V17, P6480, DOI 10.1109/TII.2021.3057524
   Chattopadhyay S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020315
   Chest Imaging, 2020, THIS IS THREAD COVID
   Cohen JP, 2020, COVID 19 IMAGE DATA, DOI 10.59275/j.melba.2020-48g7
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Goel T, 2021, APPL INTELL, V51, P1351, DOI 10.1007/s10489-020-01904-z
   Haque AKM, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.02173
   He X. etal, 2020, medRxiv
   Huang L., 2021, 5 INT C BIOL INF BIO, P1
   Irfan M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063056
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Joloudari J.H., 2021, DNN GFE DEEP NEURAL
   Kanne Jeffrey P, 2020, Radiology, V296, pE113, DOI 10.1148/radiol.2020200527
   Khishe M, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9091002
   Lee EYP, 2020, LANCET INFECT DIS, V20, P384, DOI 10.1016/S1473-3099(20)30134-1
   Mamalakis M, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.04006
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Mukherjee H, 2021, APPL INTELL, V51, P2777, DOI 10.1007/s10489-020-01943-6
   Mulinti RB, 2021, PEER PEER NETW APPL, V14, P1044, DOI 10.1007/s12083-020-01070-6
   Musulin J, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18084287
   Nafees MT, 2021, NOVEL CONVOLUTIONAL, DOI [10.1101/2021.08.11.21261946, DOI 10.1101/2021.08.11.21261946]
   Pan F, 2020, RADIOLOGY, V295, P715, DOI 10.1148/radiol.2020200370
   Rashid Hasib-Al, 2022, 2022 IEEE Healthcare Innovations and Point of Care Technologies (HI-POCT), P37, DOI 10.1109/HI-POCT54491.2022.9744064
   Sahlol AT, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071146
   Sharifrazi D, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102622
   Singh D, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421510046
   Thakur S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102920
   Wang L., 2020, FIGURE 1 COVID 19 CH
   Yeh CF, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.12786
   Zhang JP, 2021, IEEE T MED IMAGING, V40, P879, DOI 10.1109/TMI.2020.3040950
   Zhao J., 2020, ARXIV PREPRINT ARXIV
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
   Zu ZY, 2020, RADIOLOGY, V296, pE15, DOI 10.1148/radiol.2020200490
NR 42
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12513
EP 12536
DI 10.1007/s11042-022-13783-2
EA SEP 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200008
PM 36157352
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Rafique, AA
   Gochoo, M
   Jalal, A
   Kim, K
AF Rafique, Adnan Ahmed
   Gochoo, Munkhjargal
   Jalal, Ahmad
   Kim, Kibum
TI Maximum entropy scaled super pixels segmentation for multi-object
   detection and scene recognition via deep belief network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of features; Deep belief network; Entropy-scaled segmentation;
   Super-pixels
ID OBJECT; ALGORITHM; FEATURES; MODEL
AB Recent advances in visionary technologies impacted multi-object recognition and scene understanding. Such scene-understanding tasks are a demanding part of several technologies such as augmented reality based scene integration, robotic navigation, autonomous driving and tourist guide applications. Incorporating visual information in contextually unified segments, super-pixel-based approaches significantly mitigate the clutter, which is normal in pixel wise frameworks during scene understanding. Super-pixels allow customized shapes and variable size patches of connected components to be obtained. Furthermore, the computational time for these segmentation approaches can significantly decreased due to the reduced number of super-pixel target clusters. Hence, the super pixel-based approaches are more commonly used in robotics, computer vision and other intelligent systems. In this paper, we propose a Maximum Entropy scaled Super-Pixels (MEsSP) Segmentation method that encapsulates super-pixel segmentation based on an Entropy Model and utilizes local energy terms to label the pixels. Initially, after acquisition and pre-processing, image is segmented by two different methods: Fuzzy C-Means (FCM) and MEsSP. Then, to extract the features from these segmented objects, the dynamic geometrical features, fast Fourier transform (FFT), blob extraction, Maximally Stable Extremal Regions (MSER) and KAZE features are extracted using the bag of features approach. Then, to categorize the objects, multiple kernel learning is applied. Finally, a deep belief network (DBN) assigns the relevant labels to the scenes based on the categorized objects, intersection over union scores and dice similarity coefficient. The experimental results regarding multiple objects recognition accuracy, precision, recall and F1 scores over PASCAL VOC, Caltech 101 and UIUC Sports datasets show a remarkable performance. In addition, the evaluation of proposed scene recognition method over these benchmark datasets outperforms the state of the art (SOTA) methods.
C1 [Rafique, Adnan Ahmed; Jalal, Ahmad] Air Univ, E-9, Islamabad, Pakistan.
   [Rafique, Adnan Ahmed] Univ Poonch, Poonch, Ajk, Pakistan.
   [Gochoo, Munkhjargal] United Arab Emirates Univ, Dept Comp Sci & Software Engn, Al Ain 15551, U Arab Emirates.
   [Kim, Kibum] Hanyang Univ, Dept Human Comp Interact, Seoul, South Korea.
C3 Air University Islamabad; United Arab Emirates University; Hanyang
   University
RP Kim, K (corresponding author), Hanyang Univ, Dept Human Comp Interact, Seoul, South Korea.
EM adnanrafique@upr.edu.pk; mgochoo@uaeu.ac.ae; ahmadjalal@mail.au.edu.pk;
   kibum@hanyang.ac.kr
RI Kim, Kibum/ABA-0127-2022; Ghadi, Yazeed Yasin/AAW-6774-2021
OI Kim, Kibum/0000-0003-2590-9600; Ghadi, Yazeed Yasin/0000-0002-7121-495X
FU Ministry of Culture, Sports and Tourism and Korea Creative Content
   Agency [R2021040093]
FX This research was supported by the Ministry of Culture, Sports and
   Tourism and Korea Creative Content Agency (Project Number: R2021040093).
CR Ahmed A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143871
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2016, 2016 INT S INNOVATIO
   Appiah O, 2022, J KING SAUD UNIV-COM, V34, P782, DOI 10.1016/j.jksuci.2020.04.005
   Arasu B, 2014, C PROCEEDING INT J E, P205
   Armeni Iro, 2017, arXiv
   Arnold E, 2019, IEEE T INTELL TRANSP, V20, P3782, DOI 10.1109/TITS.2019.2892405
   Asif U, 2017, IEEE T ROBOT, V33, P547, DOI 10.1109/TRO.2016.2638453
   Bakalos N, 2019, IEEE SIGNAL PROC MAG, V36, P36, DOI 10.1109/MSP.2018.2885359
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Chen L, 2019, IEEE T IMAGE PROCESS, V28, P4883, DOI 10.1109/TIP.2019.2913079
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chung PC, 2008, PATTERN RECOGN, V41, P1572, DOI 10.1016/j.patcog.2007.10.022
   Debelee TG, 2019, COMPUT VIS MEDIA, V5, P347, DOI 10.1007/s41095-019-0151-2
   Dong X, 2019, MED PHYS, V46, P2157, DOI 10.1002/mp.13458
   Doulamis N. D., 2010, P 1 ACM INT WORKSH A, P39, DOI [10.1145/1877868.1877880, DOI 10.1145/1877868.1877880]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feng JF, 2018, INFORMATION, V9, DOI 10.3390/info9040097
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Guo J., 2015, ARXIV
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hussain N, 2024, MULTIMED TOOLS APPL, V83, P14935, DOI 10.1007/s11042-020-08852-3
   Jalal A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10207122
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jalal A, 2013, INDOOR BUILT ENVIRON, V22, P271, DOI 10.1177/1420326X12469714
   Jaritz M, 2019, IEEE INT CONF COMP V, P3995, DOI 10.1109/ICCVW.2019.00494
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Jiang X, 2019, IEEE ACCESS, V7, P60584, DOI 10.1109/ACCESS.2019.2911560
   Kachouri R, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P177, DOI 10.1109/ATSIP.2016.7523091
   KAMADA S, 2019, IEEE IJCNN
   Kosmopoulos DI, 2012, COMPUT VIS IMAGE UND, V116, P422, DOI 10.1016/j.cviu.2011.09.006
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Liu Y, 2011, PATTERN RECOGN, V44, P2287, DOI 10.1016/j.patcog.2010.12.012
   Mahmood M, 2020, MULTIMED TOOLS APPL, V79, P6919, DOI 10.1007/s11042-019-08527-8
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Miao JQ, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106200
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Nair Vinod, 2020, ARXIV
   Nanni L, 2013, APPL SOFT COMPUT, V13, P2171, DOI 10.1016/j.asoc.2012.12.013
   Narain S, 2019, P IEEE S SECUR PRIV, P587, DOI 10.1109/SP.2019.00068
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Rafique Adnan Ahmed, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P225, DOI 10.1109/ICAEM.2019.8853721
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rohan A, 2019, IEEE ACCESS, V7, P69575, DOI 10.1109/ACCESS.2019.2919332
   Shetty S, 2016, ARXIV
   Song XH, 2015, PROC CVPR IEEE, P1312, DOI 10.1109/CVPR.2015.7298736
   Szuster, 2019, J TELECOMMUN INF TEC, V4, P65
   Ulhaq A, 2020, IEEE ACCESS, V8, P179437, DOI 10.1109/ACCESS.2020.3027685
   Vasan D, 2020, COMPUT NETW, V171, DOI 10.1016/j.comnet.2020.107138
   Veta M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161286
   Xia SF, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101072
   Yanzhe X, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57223-y
   Zamani F, 2017, EURASIP J IMAGE VIDE, P1, DOI 10.1186/s13640-017-0225-y
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3241, DOI 10.1109/TIP.2014.2328894
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050837
   Zheng CX, 2018, IEEE ACCESS, V6, P4416, DOI 10.1109/ACCESS.2017.2786672
   Zhu HJ, 2018, MULTIMED TOOLS APPL, V77, P28905, DOI 10.1007/s11042-018-6076-4
   Zia S, 2017, IEEE INT CONF COMP V, P887, DOI 10.1109/ICCVW.2017.109
NR 67
TC 10
Z9 10
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13401
EP 13430
DI 10.1007/s11042-022-13717-y
EA SEP 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000855612200033
DA 2024-07-18
ER

PT J
AU Mallick, MT
   Biswas, S
   Das, AK
   Saha, HN
   Chakrabarti, A
   Deb, N
AF Mallick, M. D. Tausif
   Biswas, Shrijeet
   Das, Amit Kumar
   Saha, Himadri Nath
   Chakrabarti, Amlan
   Deb, Nilanjan
TI Deep learning based automated disease detection and pest classification
   in Indian <i>mung bean</i>
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pest and disease identification; Transfer learning; Image classification
ID CLIMATE-CHANGE; PLANT-DISEASE; THREAT
AB Crop pests and diseases are major threats to food security globally. The mung bean (Vigna Radiata) is one of the leading crops in India. A large part of the population in India is completely dependent on mung bean. So, high production efficiency for the mung bean is required, which does not happen due to the excessive damage from pests and diseases. Recently, with the advancement of Deep Learning techniques, remarkable performance has been achieved in the field of image classification by employing Convolutional Neural Networks (CNNs). This brings a lot of promise in the field of pest and disease identification by effective image classification. In this paper, we have proposed a novel deep learning-based technique to identify the mung bean pest and disease. In order to handle the limitation arising due to less number of mung bean crop images for the purpose of training, we have adopted transfer learning, which is able to generate a very promising result for quick and easy pest and disease detection. The developed model has successfully recognized 6 different types of mung bean diseases and 4 types of pests out of healthy and affected leaves collected in different seasons. Based on the experiments conducted, the proposed smartphone-based deep learning model for the mung bean pest and disease detection has achieved an average accuracy of 93.65%.
C1 [Mallick, M. D. Tausif; Biswas, Shrijeet; Das, Amit Kumar; Chakrabarti, Amlan] Univ Calcutta, AKCSIT, Kolkata, India.
   [Das, Amit Kumar] Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
   [Saha, Himadri Nath] Univ Calcutta, SNEC, Dept Comp Sci, Kolkata, India.
   [Deb, Nilanjan] Univ Calcutta, Dept Agron, Kolkata, India.
C3 University of Calcutta; Institute of Engineering & Management (IEM),
   Kolkata; University of Calcutta; University of Calcutta
RP Das, AK (corresponding author), Univ Calcutta, AKCSIT, Kolkata, India.; Das, AK (corresponding author), Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
EM tausif.realmadrid@gmail.com; shrijeetbiswas.calcuniv@gmail.com;
   amitladas.kol@gmail.com; contactathimadri@gmail.com;
   acakcs@caluniv.ac.in; nilandeb@yahoo.com
RI Chakrabarti, Amlan/U-7020-2019
OI Chakrabarti, Amlan/0000-0003-4380-3172
FU Department of Science & Technology and Biotechnology, Govt. West Bengal
   [345(sanc)/ST/P/ST/1-G/2018]
FX The Department of Science & Technology and Biotechnology, Govt. of West
   Bengal, (Project Sanction Number: (memo no:
   345(sanc)/ST/P/S&T/1-G/2018)) has funded this research work.
CR Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   [Anonymous], 2015, INT J INNOV RES SCI
   [Anonymous], 2013, Smallholders, food security and the environment, P29
   [Anonymous], 2012, Int. J. Comput. Sci. Telecommun
   [Anonymous], 2015, International Journal of Computer Applications, DOI 10.5120/20071-1993
   [Anonymous], 2014, T CHINESE SOC AGRI M
   [Anonymous], 2014, 7972 NISTIR
   Arevalo J, 2015, IEEE ENG MED BIO, P797, DOI 10.1109/EMBC.2015.7318482
   Barbedo JGA, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-660
   Babu M., 2007, LEAVES RECOGNITION U
   Calicioglu O, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11010222
   Cartwright H, 2015, METHODS MOL BIOL, V1260, pV
   Chakraborty S, 2000, ENVIRON POLLUT, V108, P317, DOI 10.1016/S0269-7491(99)00210-9
   Chen JW, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040372
   Coakley SM, 1999, ANNU REV PHYTOPATHOL, V37, P399, DOI 10.1146/annurev.phyto.37.1.399
   Garrett KA, 2006, ANNU REV PHYTOPATHOL, V44, P489, DOI 10.1146/annurev.phyto.44.070505.143420
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Harvey CA, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0089
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hrabanski M., 2016, INTERGOVERNMENTAL PL
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Karar ME, 2021, ALEX ENG J, V60, P4423, DOI 10.1016/j.aej.2021.03.009
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Mahlein AK, 2013, REMOTE SENS ENVIRON, V128, P21, DOI 10.1016/j.rse.2012.09.019
   Mahlein AK, 2012, EUR J PLANT PATHOL, V133, P197, DOI 10.1007/s10658-011-9878-z
   Miller SA, 2009, ANNU REV PHYTOPATHOL, V47, P15, DOI 10.1146/annurev-phyto-080508-081743
   Patil K., 2012, Journal of Signal & Image Processing, V3, P60
   Patil SB., 2011, Int. J. Eng. Technol, V3, P297, DOI DOI 10.7763/IJET.2011.V3.241
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Prakash N., 2020, 2020 INT C COMPUTER, P1
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Revathi P., 2014, International Journal of Engineering and Technology, V5, P4637
   Riley M.B., 2002, The Plant Health Instructor, DOI [10.1094/PHI-I-2002-1021-01, DOI 10.1094/PHI-I-2002-1021-01]
   Rishiikeshwer, 2019, J COMPUT SCI-NETH
   Rohr JR, 2008, P NATL ACAD SCI USA, V105, P17436, DOI 10.1073/pnas.0806368105
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Sanchez PA, 2005, SCIENCE, V307, P357, DOI 10.1126/science.1109057
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Steinwart Ingo, 2008, SUPPORT VECTOR MACHI
   Strange RN, 2005, ANNU REV PHYTOPATHOL, V43, P83, DOI 10.1146/annurev.phyto.43.113004.133839
   Tai APK, 2014, NAT CLIM CHANGE, V4, P817, DOI [10.1038/nclimate2317, 10.1038/NCLIMATE2317]
   Tatem AJ, 2006, ADV PARASIT, V62, P293, DOI 10.1016/S0065-308X(05)62009-X
   van der Zwet T, 2006, ACTA HORTIC, P35, DOI 10.17660/ActaHortic.2006.704.1
   Zhang LP, 2016, J SENSORS, V2016, DOI 10.1155/2016/7954154
   Zhao YS, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106128
   [周驰 Zhou Chi], 2003, [计算机应用研究, Application Research of Computers], V20, P7
   Zhou YunCheng Zhou YunCheng, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P219
   Zhou Zhi-Hua, 2002, Chinese Journal of Computers, V25, P1
NR 52
TC 19
Z9 19
U1 19
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12017
EP 12041
DI 10.1007/s11042-022-13673-7
EA SEP 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854429500003
DA 2024-07-18
ER

PT J
AU Mahto, DK
   Singh, AK
AF Mahto, Dhiran Kumar
   Singh, Amit Kumar
TI Firefly optimization-based dual watermarking for colour images with
   improved capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Smart cities; Copyright protection; Security; Contourlet transform;
   Pseudo magic cubes; Firefly algorithm; Encryption
ID SVD; SCHEME; ROBUST
AB This paper discusses the improved capacity of colour image authentication in media applications and proposes an optimization-based robust watermarking algorithm. The algorithm first uses firefly optimization to compute the optimal embedding strength factor, which is useful for maintaining an effective relationship between robustness and quality. The combination of spatial and transformed domain schemes is then adopted to conceal the multiple marks on the different channels of the carrier media through the optimal strength factor. In order to make image marking safer, it is encrypted before being concealed by the media channel. Extensive experiments analyzed the impact of various results on Kodak and USI-SIPI datasets, demonstrating that the suggested algorithm has improved robustness, excellent quality, and high capacity. Superior to other existing schemes, the proposed algorithm achieves robustness of up to 11% with the improved watermark capacity.
C1 [Mahto, Dhiran Kumar; Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
EM dhiranm.phd18.cs@nitp.ac.in; amit.singh@nitp.ac.in
FU DLRL, Hyderabad, India [DLRL/21CR0003/SWCCENT/GN/LP]; NIT Patna, Bihar,
   India [NITP/1457/19]
FX This work is supported by research project entitled "Copyright
   Protection Tool for Digital Data" order no. DLRL/21CR0003/SWCC&ENT/GN/LP
   dt. 29 August, 2020, DLRL, Hyderabad, India and seed project entitled
   "Robust and Secure Copyright Protection Techniques for E-Government
   Document," order no. NITP/1457/19 dt. 13 June, 2019, NIT Patna, Bihar,
   India.
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Anand A, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P366, DOI 10.1109/BigMM50055.2020.00063
   Anand A, 2021, MULTIMED TOOLS APPL, V80, P30165, DOI 10.1007/s11042-020-08801-0
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   [Anonymous], USI SIPI DATASET
   Chen Y, 2020, IEEE ACCESS, V8, P30628, DOI 10.1109/ACCESS.2020.2973044
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Du M, 2019, IEEE ACCESS, V7, P168655, DOI 10.1109/ACCESS.2019.2953878
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Gonge SS, 2015, COMM COM INF SC, V536, P290, DOI 10.1007/978-3-319-22915-7_28
   kaggle, US
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kumar S, 2019, HDB MULTIMED INF SEC, P37
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Mahto DK, 2021, COMPUT ELECTR ENG, V93, P1
   Mohanty SP, 2017, IEEE CONSUM ELECTR M, V6, P83, DOI 10.1109/MCE.2017.2684980
   Pourhadi A, 2020, MULTIMED TOOLS APPL, V79, P21653, DOI 10.1007/s11042-020-08960-0
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Sharma N, 2021, COMPUTING, V103, P1883, DOI 10.1007/s00607-020-00881-y
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh AK, 2018, FUTURE GENER COMP SY, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh OP, 2023, COMPLEX INTELL SYST, V9, P2759, DOI 10.1007/s40747-021-00309-w
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Sinhal R, 2021, PATTERN RECOGN LETT, V145, P171, DOI 10.1016/j.patrec.2021.02.011
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Yang XS, 2014, NATURE-INSPIRED OPTIMIZATION ALGORITHMS, P111, DOI 10.1016/B978-0-12-416743-8.00008-7
   Yang Y, 2021, IEEE T CIRCUITS SYST
NR 36
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 SEP 16
PY 2022
DI 10.1007/s11042-022-13795-y
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4O0WM
UT WOS:000854429700008
DA 2024-07-18
ER

PT J
AU Santana, OJ
   Freire-Obregón, D
   Hernández-Sosa, D
   Lorenzo-Navarro, J
   Sánchez-Nielsen, E
   Castrillón-Santana, M
AF Santana, Oliverio J.
   Freire-Obregon, David
   Hernandez-Sosa, Daniel
   Lorenzo-Navarro, Javier
   Sanchez-Nielsen, Elena
   Castrillon-Santana, Modesto
TI Facial expression analysis in a wild sporting environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft biometrics; Expression recognition; In the wild
ID RECOGNITION; MOVEMENT; EMOTIONS
AB The scientific community and mass media have already reported the use of nonverbal behavior analysis in sports for athletes' performance. Their conclusions stated that certain emotional expressions are linked to athlete's performance, or even that psychological strategies serve to improve endurance performance. This paper examines the portrayal of well-known emotions and their relationship to the participants of an ultra-distance race in a high-stake environment. For this purpose, we analyzed almost 600 runners captured when they passed through a set of locations placed along the race track. We have observed a correlation between the runners' facial expressions and their performance along the track. Moreover, we have analyzed Action Unit activations and aligned our findings with the state-of-the-art psychological baseline.
C1 [Santana, Oliverio J.; Freire-Obregon, David; Hernandez-Sosa, Daniel; Lorenzo-Navarro, Javier; Castrillon-Santana, Modesto] Univ Las Palmas Gran Canaria, Las Palmas Gran Canaria, Canary Islands, Spain.
   [Sanchez-Nielsen, Elena] Univ La Laguna, San Cristobal De La Lagu, Canary Islands, Spain.
C3 Universidad de Las Palmas de Gran Canaria; Universidad de la Laguna
RP Freire-Obregón, D (corresponding author), Univ Las Palmas Gran Canaria, Las Palmas Gran Canaria, Canary Islands, Spain.
EM david.freire@ulpgc.es
RI Navarro, Javier Lorenzo/L-1972-2014; Sánchez-Nielsen,
   Elena/HTT-2627-2023; Freire-Obregon, David/L-7574-2014
OI Navarro, Javier Lorenzo/0000-0002-2834-2067; Sánchez-Nielsen,
   Elena/0000-0003-2114-4137; Santana Jaria, Oliverio
   Jesus/0000-0001-7511-5783; Freire-Obregon, David/0000-0003-2378-4277
FU CRUE-CSIC; Springer Nature; ULPGC [ULPGC2018-08]; Spanish Ministry of
   Economy and Competitiveness (MINECO) [RTI2018-093337-B-I00]; Spanish
   Ministry of Science and Innovation [PID2019-107228RB-I00,
   PID2021-122402OB-C22]; Gobierno de Canarias; FEDER funds
   [ProID2020010024, ProID2021010012]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work is partially funded by the ULPGC under
   project ULPGC2018-08, the Spanish Ministry of Economy and
   Competitiveness (MINECO) under project RTI2018-093337-B-I00, the Spanish
   Ministry of Science and Innovation under projects PID2019-107228RB-I00
   and PID2021-122402OB-C22, and by the Gobierno de Canarias and FEDER
   funds under project ProID2020010024 and ProID2021010012.
CR [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2021, COFF WORLD MARK TRAD
   [Anonymous], 2000, EMOTIONS SPORT
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Ben-Ami I, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.19
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Brand R, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02901
   Brick NE, 2018, PSYCHOL SPORT EXERC, V34, P20, DOI 10.1016/j.psychsport.2017.09.009
   Campo M, 2012, SPORT PSYCHOL, V26, P62, DOI 10.1123/tsp.26.1.62
   Cheong J.H., 2021, Py-Feat: Python Facial Expression Analysis Toolbox
   Choi Y, 2021, IEEE INT C IM PROC
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Ekman P., 1975, UNMASKING FACE
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Freire-Obregon D, 2022, INT C IMAGE ANAL PRO
   Freire-Obregón D, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415500068
   Furley P, 2023, INT REV SPORT EXER P, V16, P448, DOI 10.1080/1750984X.2021.1894594
   Goodfellow I. J., 2013, INT C NEURAL INFORM
   Hernandez-Carrascosa P, 2020, P INT C PATTERN RECO
   Hopfensitz A, 2019, J ECON PSYCHOL, V75, DOI 10.1016/j.joep.2018.04.008
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kos MK, 2017, IEEE ACCESS, V5, P6411, DOI 10.1109/ACCESS.2017.2675538
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Luan Pham, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P4513, DOI 10.1109/ICPR48806.2021.9411919
   Moeslund T. B., 2014, COMPUTER VISION SPOR
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Morales-Sánchez V, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01199
   Penate-Sanchez A, 2020, PATTERN RECOGN LETT, V138, P355, DOI 10.1016/j.patrec.2020.08.003
   Ross A, 2022, COMPUT VIS IMAGE UND, V221, DOI 10.1016/j.cviu.2022.103438
   RUSSELL JA, 1983, J PERS SOC PSYCHOL, V45, P1281, DOI 10.1037/0022-3514.45.6.1281
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Serengil SI, 2021, DEEPFACE LIGHTWEIGHT
   Thomas G, 2017, COMPUT VIS IMAGE UND, V159, P3, DOI 10.1016/j.cviu.2017.04.011
   Uchida MC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208834
   Wronska A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P84, DOI 10.1109/ICBAKE.2017.8090642
   Wundt W, 1905, GRUNDZUGE PHYSIOLOGI
   Yan Y, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107370
   Zhang Y.-F., 2021, arXiv
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang Z, 2017, FACIAL EXPRESSION RE
NR 41
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11395
EP 11415
DI 10.1007/s11042-022-13654-w
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854682600003
PM 36124096
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Taheri, F
   Rahbar, K
   Salimi, P
AF Taheri, Fatemeh
   Rahbar, Kambiz
   Salimi, Pedram
TI Effective features in content-based image retrieval from a combination
   of low-level features and deep Boltzmann machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content-based image retrieval; Low-level features; Deep Boltzmann
   machine
ID COLOR; DESCRIPTOR; WAVELET; FUSION
AB Image retrieval is a convenient way to browse and search for a set of similar images. The main challenge of Content-based Image Retrieval (CBIR) systems is to extract the appropriate feature vector for image description. In this research, a content-based image retrieval model focusing on extracting effective features is introduced. The introduced feature vector is a combination of low-level and mid-level Image Features. The extraction of low-level features of the image, including color, shape, and texture, was performed using auto-correlogram, Gabor wavelet transform, and multi-level fractal dimension analysis. The mid-level features of the image are also extracted through the use of the Deep Boltzmann Machine as well as by learning the low-level features of the image and the relationships between them. The resulting feature vector of Image retrieval based on the combination of low-level features and deep Boltzmann machine (LB-CBIR) is adjusted with the Corel 1 K dataset, and the performance of the proposed model is measured on the Corel 1 K-illumination, Corel 1 K-Scale, Corel 5 K, Corel 10 K, Oxford buildings and Caltech-256 dataset. The best-evaluated results on the mentioned datasets have been reported with the average precision criterion as 99.4% for Corel 1 K dataset, 94.2% for Corel 1 l-Scale, 82.05 for Corel 1 K-illumination, 98.2% for Corel 5 K dataset, 90.2% for Corel 10 K dataset, 64.1% for Oxford buildings, 32.12% for Caltech-256 dataset. Explainability of the feature vector and the value of the extracted features in the proposed model are also interpreted by calculating the Shapley value.
C1 [Taheri, Fatemeh; Rahbar, Kambiz; Salimi, Pedram] Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
C3 Islamic Azad University
RP Rahbar, K (corresponding author), Islamic Azad Univ, Dept Comp Engn, South Tehran Branch, Tehran, Iran.
EM k_rahbar@azad.ac.ir
RI Rahbar, Kambiz/F-6037-2012
OI Rahbar, Kambiz/0000-0003-2212-0479; Taheri, Fatemeh/0000-0002-4430-8416
CR Aamir M, 2021, ARAB J SCI ENG, V46, P9237, DOI 10.1007/s13369-021-05674-9
   Ahmed KT, 2017, APPL INTELL, V47, P526, DOI 10.1007/s10489-017-0916-1
   Amelio A, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.04.043
   Amitha I. C., 2021, ADV INTELL SYST COMP, P673
   [Anonymous], COREL DATASET
   [Anonymous], 2015, INT J COMPUT APPL
   [Anonymous], CALTECH 256 DATASET
   [Anonymous], OXFORD BUILDINGS DAT
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Bilquees S, 2021, INT J OPT, V2021, DOI 10.1155/2021/4151482
   Casagrande L, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01121-1
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Chavda S., 2020, SN Comput. Sci., V1, P305
   Chavda S, 2022, MULTIMED TOOLS APPL, V81, P4039, DOI 10.1007/s11042-021-11698-y
   Chen H, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102934
   Etemad S, 2021, ENG APPL ARTIF INTEL, V102, DOI 10.1016/j.engappai.2021.104256
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Gu YF, 2020, MULTIMED TOOLS APPL, V79, P35253, DOI 10.1007/s11042-019-7687-0
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang L, 2022, MULTIMEDIA SYST, V28, P673, DOI 10.1007/s00530-021-00866-7
   Inthiyaz S, 2018, AIN SHAMS ENG J, V9, P3277, DOI 10.1016/j.asej.2017.12.007
   Jaiswal Amit Kumar, 2021, ICTIR '21: Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval, P307, DOI 10.1145/3471158.3472253
   Jiang DY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125701
   Joseph AJ, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111301
   Kanaparthi SK, 2020, MULTIMED TOOLS APPL, V79, P34875, DOI 10.1007/s11042-019-08029-7
   Kapoor R, 2021, MULTIMED TOOLS APPL, V80, P29561, DOI 10.1007/s11042-021-11045-1
   Khan A, 2021, INT J COGN INFORM NA, V15, P1, DOI 10.4018/IJCINI.2021010101
   Khan UA, 2021, MULTIMED TOOLS APPL, V80, P26911, DOI 10.1007/s11042-021-10530-x
   Kumar TGS, 2019, PATTERN ANAL APPL, V22, P1233, DOI 10.1007/s10044-018-0724-1
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Li XQ, 2021, NEUROCOMPUTING, V452, P675, DOI 10.1016/j.neucom.2020.07.139
   Li XL, 2020, IEEE ACCESS, V8, P142229, DOI 10.1109/ACCESS.2020.3011102
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Liu HM, 2019, INT J COMPUT VISION, V127, P1217, DOI 10.1007/s11263-019-01174-4
   Liu L, 2013, OPTIK, V124, P2577, DOI 10.1016/j.ijleo.2012.07.010
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Liu YN, 2019, MULTIMED TOOLS APPL, V78, P2525, DOI 10.1007/s11042-018-6386-6
   Nair LR, 2021, J AMB INTEL HUM COMP, V12, P5917, DOI 10.1007/s12652-020-02139-z
   Nur-A-Alam, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107387
   Pinto EP, 2021, PHYSICA A, V581, DOI 10.1016/j.physa.2021.126192
   Rajendran T, 2019, CLUSTER COMPUT, V22, pS3115, DOI 10.1007/s10586-018-1975-8
   Sajwan V, 2015, SMART INNOV SYST TEC, V31, P637, DOI 10.1007/978-81-322-2205-7_59
   Soares LD, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185432
   Somasundaran BV, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115652
   Sundararajan SK, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1305-6
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   Tang SY, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87762-2
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Tyagi V., 2017, Content-Based Image Retrieval: Ideas, Influences, and Current Trends, DOI DOI 10.1007/978-981-10-6759-4
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Wei WY, 2022, MULTIMED TOOLS APPL, V81, P659, DOI 10.1007/s11042-021-11198-z
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Weng HS, 2022, SIGNAL IMAGE VIDEO P, V16, P1117, DOI 10.1007/s11760-021-02061-7
   Yang P, 2016, NEUROCOMPUTING, V197, P212, DOI 10.1016/j.neucom.2016.02.061
   Zeng MQ, 2019, J COMPUT SCI TECH-CH, V34, P287, DOI 10.1007/s11390-019-1911-2
   Zheng Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050693
NR 57
TC 8
Z9 8
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 30
PY 2022
DI 10.1007/s11042-022-13670-w
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4E1YW
UT WOS:000847629600001
DA 2024-07-18
ER

PT J
AU Guo, XY
   Gao, ML
   Zhai, WZ
   Li, QL
   Pan, JF
   Zou, GF
AF Guo, Xiangyu
   Gao, Mingliang
   Zhai, Wenzhe
   Li, Qilei
   Pan, Jinfeng
   Zou, Guofeng
TI Multiscale aggregation network via smooth inverse map for crowd counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crowd counting; Smart city; Scale variation; Density map; Convolutional
   neural network
AB Crowd counting is a practical yet essential research topic in computer vision, which has been beneficial to diverse applications in smart city environment safety. The commonly adopted paradigm in most existing methods is to regress a Gaussian density map that works as the learning objective during model training. However, given the unavoidable identity occlusion and scale variation in a crowd image, the corresponding Gaussian density map is degraded, failing to provide reliable supervision for optimization. To address this problem, we propose to replace the traditional Gaussian density map with a better alternation, namely the smooth inverse map (SIM). The proposed SIM can reflect the head location spatially and provide a smooth gradient to stabilize the model learning. Besides, we want the method to learn more discriminative features to cope with the challenge of large-scale variations. We deliver a multiscale aggregation (MA) to adaptively fuse features in different hierarchies to benefit semantic information under diverse receptive filed. The SIM and MA are meant to be complementary modules to guide the model in learning an accurate density map. Extensive experiments on benchmark datasets demonstrate the effectiveness of the proposed method compared with the state-of-the-art techniques.
C1 [Guo, Xiangyu; Gao, Mingliang; Zhai, Wenzhe; Pan, Jinfeng; Zou, Guofeng] Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255000, Peoples R China.
   [Li, Qilei] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
C3 Shandong University of Technology; University of London; Queen Mary
   University London
RP Gao, ML (corresponding author), Shandong Univ Technol, Sch Elect & Elect Engn, Zibo 255000, Peoples R China.
EM mlgao@sdut.edu.cn
RI Guo, Xiangyu/GSN-5068-2022; , 李启磊/K-7546-2019; Zhai,
   Wenzhe/KEE-6745-2024
OI Guo, Xiangyu/0000-0001-9405-3792; , 李启磊/0000-0002-9675-9016; Zhai,
   Wenzhe/0000-0003-0996-6832
FU National Natural Science Foundation of China [61601266, 61801272];
   National Natural Science Foundation of Shandong Province [ZR2021QD041,
   ZR2020MF127]
FX This work is supported in part by the National Natural Science
   Foundation of China (Nos. 61601266 and 61801272) and National Natural
   Science Foundation of Shandong Province (Nos. ZR2021QD041 and
   ZR2020MF127).
CR Amirgholipour S, 2018, IEEE IMAGE PROC, P948, DOI 10.1109/ICIP.2018.8451399
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Guo X, 2022, SPATIAL FREQUENCY AT, DOI [10.1089/big.2022.0039, DOI 10.1089/BIG.2022.0039]
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang DK, 2021, Arxiv, DOI arXiv:2102.07925
   Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Oghaz MM, 2019, Arxiv, DOI arXiv:1906.07258
   Oh MH, 2020, Arxiv, DOI [arXiv:1903.07427, 10.1609/AAAI.V34I07.6852]
   Olmschenk G, 2019, Arxiv, DOI arXiv:1902.05379
   Sajid U, 2021, INT C PATT RECOG, P5790, DOI 10.1109/ICPR48806.2021.9412406
   Sam DB, 2021, IEEE T PATTERN ANAL, V43, P2739, DOI 10.1109/TPAMI.2020.2974830
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1002, DOI 10.1109/ICCV.2019.00109
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Song QY, 2021, AAAI CONF ARTIF INTE, V35, P2576
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tian YK, 2020, IEEE T IMAGE PROCESS, V29, P2714, DOI 10.1109/TIP.2019.2952083
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Wan J, 2022, IEEE T PATTERN ANAL, V44, P1357, DOI 10.1109/TPAMI.2020.3022878
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Xu CF, 2022, INT J COMPUT VISION, V130, P405, DOI 10.1007/s11263-021-01542-z
   Zhai WZ, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.041214
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 32
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 24
PY 2022
DI 10.1007/s11042-022-13664-8
EA AUG 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8TU
UT WOS:000843996100004
DA 2024-07-18
ER

PT J
AU Rinosha, SMJ
   Augasta, MG
AF Rinosha, S. M. Jainul
   Augasta, M. Gethsiyal
TI Principal sample based learning of deep network for correlation filter
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Feature-based learning;
   Convolutional neural network (CNN); Feature pooling layer; Selection
   strategy; Object tracking
ID VISUAL TRACKING
AB Correlation filter based tracking has shown impressive and amazing results for the object tracking domain. The types of features used in this family of trackers significantly affect the performance of the tracking process. In order to achieve the significant features, deep networks can be combined with correlation trackers. In this work, the principal sample-based learning of deep networks has been proposed for correlation filter tracking. Usual training of deep networks always takes all sample frames for backpropagation, which is not ideal for large tracking video collections. To overcome these shortcomings, a novel sample selection strategy is devised while back-propagating the network loss or error, and hence the proposed method is named as Principal Sample-based Learning of Deep Network (OT-PSLDN) for correlation filter based object tracking. The proposed OT-PSLDN method is evaluated with standard performance criteria on benchmark datasets, namely Object Tracking Benchmark 2013 (OTB 2013), OTB 2015, Visual Object Tracking 2017 (VOT 2017), and VOT 2018. The experimental results show that the proposed method constantly exceeds the state-of-the-art methods in terms of qualitative and quantitative performance measures.
C1 [Rinosha, S. M. Jainul; Augasta, M. Gethsiyal] Kamaraj Coll, Res Dept Comp Sci, Thoothukudi, Tamil Nadu, India.
   [Rinosha, S. M. Jainul; Augasta, M. Gethsiyal] Manonmaniam Sundaranar Univ, Tinmelveli, India.
C3 Manonmaniam Sundaranar University
RP Augasta, MG (corresponding author), Kamaraj Coll, Res Dept Comp Sci, Thoothukudi, Tamil Nadu, India.; Augasta, MG (corresponding author), Manonmaniam Sundaranar Univ, Tinmelveli, India.
EM sm.jainulrinosha@gmail.com; augastaglady@gmail.com
RI M, Gethsiyal Augasta/AAS-2164-2020
OI M, Gethsiyal Augasta/0000-0002-1975-7623
CR Abbass MY, 2021, ARTIF INTELL REV, V54, P3349, DOI 10.1007/s10462-020-09905-7
   Abbass MY, 2021, VISUAL COMPUT, V37, P831, DOI 10.1007/s00371-020-01833-5
   Bai S, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102759
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Du F, 2020, PROC CVPR IEEE, P6835, DOI 10.1109/CVPR42600.2020.00687
   Fan NN, 2021, NEURAL NETWORKS, V140, P344, DOI 10.1016/j.neunet.2021.04.004
   Gao P, 2020, INFORM SCIENCES, V517, P52, DOI 10.1016/j.ins.2019.12.084
   Gethsiyal Augasta M, 2020, INT J FUTURE GENE CO, V13
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Huang B, 2020, IEEE T MULTIMEDIA, V22, P2820, DOI 10.1109/TMM.2020.2965482
   Huang B, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107157
   Jainul Rinosha SM, 2022, LECT NOTES COMPUT SC
   Katija K, 2021, IEEE WINT CONF APPL, P859, DOI 10.1109/WACV48630.2021.00090
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Li SJ, 2022, IEEE T CYBERNETICS, V52, P1179, DOI 10.1109/TCYB.2020.2996245
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liu QY, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107766
   Liu S, 2021, NEUROCOMPUTING, V458, P615, DOI 10.1016/j.neucom.2019.12.143
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu S, 2021, NEURAL COMPUT APPL, V33, P1055, DOI 10.1007/s00521-020-05021-3
   Quan W, 2021, MULTIMED TOOLS APPL, V80, P6493, DOI 10.1007/s11042-020-09852-z
   Rahman MM, 2020, IEEE ACCESS, V8, P100857, DOI 10.1109/ACCESS.2020.2997917
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang JS, 2021, ROBOT CIM-INT MANUF, V67, DOI 10.1016/j.rcim.2020.102010
   Wu CL, 2020, IEEE ACCESS, V8, P7473, DOI 10.1109/ACCESS.2020.2964269
   Xiao YF, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107170
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Xuesong Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10173, DOI 10.1109/CVPR42600.2020.01019
   Yang YX, 2020, IEEE ACCESS, V8, P20257, DOI 10.1109/ACCESS.2020.2968125
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yuan D, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105697
   Zhang KH, 2019, IEEE T IMAGE PROCESS, V28, P479, DOI 10.1109/TIP.2018.2868561
   Zheng LY, 2020, NEUROCOMPUTING, V401, P36, DOI 10.1016/j.neucom.2020.02.080
NR 35
TC 1
Z9 1
U1 8
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7825
EP 7840
DI 10.1007/s11042-022-13681-7
EA AUG 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843355500004
DA 2024-07-18
ER

PT J
AU Tian, Q
   Chanda, S
   Kumar, KCA
   Gray, D
AF Tian, Qing
   Chanda, Sampath
   Kumar, Amit K. C.
   Gray, Douglas
TI Improving apparel detection with category grouping and multi-grained
   branches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apparel detection; Deep neural networks; Multi-grained detection
   branches; Imbalanced data
AB Training an accurate object detector is expensive and time-consuming. One main reason lies in the laborious labeling process, i.e., annotating category and bounding box information for all instances in every image. In this paper, we examine ways to improve performance of deep object detectors without extra labeling. We first explore to group existing categories of high visual and semantic similarities together as one super category (or, a superclass). Then, we study how this knowledge of hierarchical categories can be exploited to better detect objects using multi-grained RCNN branches*. Experimental results on DeepFashion2 and OpenImagesV4-Clothing reveal that the proposed detection heads with multi-grained branches can boost the overall performance by as high as 2% with no additional time-consuming annotations. In addition, classes that have fewer training samples tend to benefit more from the proposed multi-grained heads with superclass grouping. In particular, we improve the mAP for the last 30% categories (in terms of training sample number) by 2.6% and 4.6% on DeepFashion2 and OpenImagesV4-Clothing, respectively.
C1 [Tian, Qing] Bowling Green State Univ, Dept Comp Sci, Hayes Hall, Bowling Green, OH 43403 USA.
   [Tian, Qing] McGill Univ, Dept Elect & Comp Engn, 3480 Univ St, Montreal, PQ H3A 0E9, Canada.
   [Chanda, Sampath; Kumar, Amit K. C.; Gray, Douglas] Amazoncom Inc, Visual Search & AR A9, 611 Cowper St, Palo Alto, CA 94301 USA.
C3 University System of Ohio; Bowling Green State University; McGill
   University
RP Tian, Q (corresponding author), Bowling Green State Univ, Dept Comp Sci, Hayes Hall, Bowling Green, OH 43403 USA.; Tian, Q (corresponding author), McGill Univ, Dept Elect & Comp Engn, 3480 Univ St, Montreal, PQ H3A 0E9, Canada.
EM qtian@bgsu.edu
RI tian, qing/JMQ-8820-2023; Tian, Qing/ACD-4955-2022
OI Tian, Qing/0000-0003-1808-2887
FU National Science Foundation (NSF) [2153404]; Div Of Information &
   Intelligent Systems; Direct For Computer & Info Scie & Enginr [2153404]
   Funding Source: National Science Foundation
FX This work would not have been possible without the computing resources
   provided by Amazon AWS and the Ohio Supercomputer Center. This research
   was supported in part by the National Science Foundation (NSF) under
   Award No. 2153404.
CR [Anonymous], IMPLEMENTATION YOLOV
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Gidaris S, 2016, ARXIV
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hara K, 2016, IEEE WINT CONF APPL
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jia D, 2012, PROC CVPR IEEE, P3450, DOI 10.1109/CVPR.2012.6248086
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khan SH, 2018, IEEE T NEUR NET LEAR, V29, P3573, DOI 10.1109/TNNLS.2017.2732482
   Krawczyk B, 2014, APPL SOFT COMPUT, V14, P554, DOI 10.1016/j.asoc.2013.08.014
   Kuznetsova A, 2018, ARXIV
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sermanet P., 2013, ARXIV
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Ting Kai Ming, 2000, P 17 INT C MACH LEAR
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang SJ, 2016, IEEE IJCNN, P4368, DOI 10.1109/IJCNN.2016.7727770
   Wang YX, 2017, 31 ANN C NEURAL INFO, V30
   Wu JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1570, DOI 10.1145/3394171.3413970
   Wu Y., 2019, DETECTRON2
   Xu Z., 2020, ADV NEURAL INFORM PR, P4
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Yang H, 2019, IEEE I CONF COMP VIS, P9804, DOI 10.1109/ICCV.2019.00990
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
   Zhou ZH, 2010, COMPUT INTELL-US, V26, P232, DOI 10.1111/j.1467-8640.2010.00358.x
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 43
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7383
EP 7400
DI 10.1007/s11042-022-13424-8
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000843355500006
DA 2024-07-18
ER

PT J
AU Deng, SJ
   Yang, GB
   Dong, W
   Xia, M
AF Deng, Shijie
   Yang, Gaobo
   Dong, Wen
   Xia, Ming
TI Flexible revocation in ciphertext-policy attribute-based encryption with
   verifiable ciphertext delegation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Attribute-based encryption; Verifiable ciphertext
   delegation; Flexible revocation; Access control
ID IDENTITY-BASED ENCRYPTION; DECRYPTION; SECURE
AB Attribute-based encryption (ABE) is a promising approach to enables fine-grained access control for encrypted data in cloud storage. However, to design a flexible and effective revocation mechanism has always been a tricky problem for ABE, especially for the situations where revocation occurs frequently. In this work, we propose a practical attribute-based access control scheme by introducing ciphertext-policy attribute-based encryption (CP-ABE) that allows the trusted authority (TA) to efficiently manage the credentials of data users. The problem of revocation is solved efficiently by exploiting user binary tree. To achieve flexible revocation, our scheme supports both attribute revocation and user revocation to accommodate different revocation needs. Non-revoked users can still decrypt the ciphertext as long as his/her remaining attributes satisfy the access policy associated with the ciphertext. Moreover, verifiable ciphertext delegation is presented to reduce the heavy computation cost brought by frequent revocation. The merits of the proposed scheme are proved by comparing its performance and security with the related works.
C1 [Deng, Shijie; Yang, Gaobo; Dong, Wen; Xia, Ming] Hunan Univ, Sch Informat Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Elect Engn, Changsha 410082, Peoples R China.
EM yanggaobo@hnu.edu.cn
OI Yang, Gaobo/0000-0003-2734-659X
FU National Key R&D Program of China [2018YFB1003205]; National Natural
   Science Foundation of China [61972143]
FX This work was supported in part by the National Key R&D Program of China
   (No. 2018YFB1003205) and the National Natural Science Foundation of
   China (No. 61972143).
CR Akinyele JA, 2013, J CRYPTOGR ENG, V3, P111, DOI 10.1007/s13389-013-0057-3
   [Anonymous], 2006, P 13 ACM C COMP COMM
   Attrapadung N, 2012, THEOR COMPUT SCI, V422, P15, DOI 10.1016/j.tcs.2011.12.004
   Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   Boldyreva A, 2008, CCS'08: PROCEEDINGS OF THE 15TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P417
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Chase M, 2007, LECT NOTES COMPUT SC, V4392, P515
   Cui J, 2019, INFORM SCIENCES, V489, P63, DOI 10.1016/j.ins.2019.03.043
   De SJ, 2020, IEEE T CLOUD COMPUT, V8, P124, DOI 10.1109/TCC.2017.2754255
   Hur J, 2011, IEEE T PARALL DISTR, V22, P1214, DOI 10.1109/TPDS.2010.203
   Ibraimi L, 2009, LECT NOTES COMPUT SC, V5932, P309, DOI 10.1007/978-3-642-10838-9_23
   Kumar PP, 2018, J NETW COMPUT APPL, V108, P37, DOI 10.1016/j.jnca.2018.02.009
   Lewko A, 2011, LECT NOTES COMPUT SC, V6632, P568, DOI 10.1007/978-3-642-20465-4_31
   Li JG, 2018, IEEE SYST J, V12, P1767, DOI 10.1109/JSYST.2017.2667679
   Li JG, 2017, IEEE T SERV COMPUT, V10, P715, DOI 10.1109/TSC.2016.2542813
   Li JG, 2017, IEEE T SERV COMPUT, V10, P785, DOI 10.1109/TSC.2016.2520932
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Liu ZC, 2018, J NETW COMPUT APPL, V108, P112, DOI 10.1016/j.jnca.2018.01.016
   Rimal Bhaskar Prasad, 2009, Proceedings of the 2009 Fifth International Joint Conference on INC, IMS and IDC, P44, DOI 10.1109/NCM.2009.218
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sahai A, 2012, LECT NOTES COMPUT SC, V7417, P199
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Shi YF, 2015, INFORM SCIENCES, V295, P221, DOI 10.1016/j.ins.2014.10.020
   Tysowski PK, 2013, IEEE T CLOUD COMPUT, V1, P172, DOI 10.1109/TCC.2013.11
   Vipul G, 2006, P ACM SIGSAC C COMP, P89, DOI 10.1145/1180405.1180418
   Watanabe Y, 2017, LECT NOTES COMPUT SC, V10159, P432, DOI 10.1007/978-3-319-52153-4_25
   Waters B, 2005, LECT NOTES COMPUT SC, V3494, P114
   Wei JH, 2018, IEEE T CLOUD COMPUT, V6, P1136, DOI 10.1109/TCC.2016.2545668
   Wei JH, 2018, IEEE SYST J, V12, P1731, DOI 10.1109/JSYST.2016.2633559
   Xu SM, 2019, FUTURE GENER COMP SY, V97, P284, DOI 10.1016/j.future.2019.02.051
   Xu SM, 2018, IEEE T INF FOREN SEC, V13, P2101, DOI 10.1109/TIFS.2018.2810065
   Yang K., Proceedings of the 8th ACM SIGSAC symposium on Information, computer and communications security, 2013, P523
   Yang K, 2017, IEEE INTERNET THINGS, V4, P563, DOI 10.1109/JIOT.2016.2571718
   Yin H, 2019, IEEE ACCESS, V7, P5682, DOI 10.1109/ACCESS.2018.2889754
   Yu SC, 2010, IEEE INFOCOM SER, DOI 10.1109/INFCOM.2010.5462174
   Zhou ZB, 2015, IEEE T COMPUT, V64, P126, DOI 10.1109/TC.2013.200
NR 36
TC 4
Z9 4
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22251
EP 22274
DI 10.1007/s11042-022-13537-0
EA AUG 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000842724400005
DA 2024-07-18
ER

PT J
AU Priyanka
   Babulal, KS
AF Priyanka
   Babulal, Kanojia Sindhuben
TI Hematological image analysis for segmentation and characterization of
   erythrocytes using FC-TriSDR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blood smear; Erythrocytes; Fuzzy c-means; Image segmentation; Leishman
   stain
ID NEURAL-NETWORKS; FEATURE-EXTRACTION; CLASSIFICATION; IDENTIFICATION;
   MICROSCOPY
AB In medical science, the scrutiny of blood smears for the abnormality in erythrocyte, leads to decisive determination of several ailments like Thalasemia, Liver disease, Sickle cell anaemia and so on. The conventional methodology for determining the malformation of the erythrocytes is through visual inspection of the blood smear through light or compound microscope. Since, the process of such examination is manual, it might lead to discrepancies and subjectivity. It is a well-known fact that early and affordable diagnostics can make a significant impact on curative. Hence, this research study has proposed an image analysis perspective to characterize the erythrocytes based on their morphological changes. The prime objective of this research work is to enhance the preliminary screening of erythrocytes by analyzing the morphological, textural, and color features by the proposed model FC-TriSDR (Fuzzy C-Means clustering algorithm along with three ensembled classifiers- Support vector machine, Decision Tree, and Radial Basis Functional Neural Network). Automated identification and characterization of erythrocytes is accomplished by integrating the steps of image acquisition, preprocessing, sub-imaging, image segmentation, feature extraction, significant feature selection and classification into five different domains of erythrocytes as - Normal, Stomatocyte, Poikilocyte, Spherocyte, and Schistocyte in the Leishman stained microscopic blood smear images. Total 51 eminent features of erythrocyte were extracted and the performance of FC-TriSDR gained the highest accuracy of 96.7% with computational time of 1.68 sec. when compared amongst 5 other classic neural networks.
C1 [Priyanka; Babulal, Kanojia Sindhuben] Cent Univ Jharkhand, Dept Comp Sci & Technol, Ranchi, Bihar, India.
C3 Central University of Jharkhand
RP Babulal, KS (corresponding author), Cent Univ Jharkhand, Dept Comp Sci & Technol, Ranchi, Bihar, India.
EM priya.pa105@gmail.com; sindhukanojia@gmail.com
OI , Priyanka/0000-0002-1458-9421
CR Aggarwal Ashwani Kumar, 2022, WSEAS T SIGNAL PROCE, P60, DOI DOI 10.37394/232014.2022.18.8
   Albertini MC, 2003, CYTOM PART A, V52A, P12, DOI 10.1002/cyto.a.10019
   Alpana, 2016, COMPUT IND, V75, P35, DOI 10.1016/j.compind.2015.10.003
   Amjad RA, 2020, IEEE T PATTERN ANAL, V42, P2225, DOI 10.1109/TPAMI.2019.2909031
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Balasamy K, 2023, IETE J RES, V69, P83, DOI 10.1080/03772063.2021.1893231
   Bhuyan Hemanta Kumar, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P1212, DOI 10.1109/ICSSIT46314.2019.8987780
   Bhuyan HK, 2023, IEEE T ENG MANAGE, V70, P2732, DOI 10.1109/TEM.2021.3098463
   Bhuyan HK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12776
   Bhuyan HK, 2022, ENG OPTIMIZ, V54, P1305, DOI 10.1080/0305215X.2021.1922897
   BROWN KE, 1993, SCIENCE, V262, P114, DOI 10.1126/science.8211117
   Cimen MYB, 2008, CLIN CHIM ACTA, V390, P1, DOI 10.1016/j.cca.2007.12.025
   CLEMENS MR, 1987, CHEM PHYS LIPIDS, V45, P251, DOI 10.1016/0009-3084(87)90068-5
   Das DK, 2013, J MICROSC-OXFORD, V249, P136, DOI 10.1111/jmi.12002
   Devi SS, 2018, MULTIMED TOOLS APPL, V77, P631, DOI 10.1007/s11042-016-4264-7
   dos Santos GS, 2012, EXPERT SYST APPL, V39, P4805, DOI 10.1016/j.eswa.2011.09.137
   Durant TJS, 2017, CLIN CHEM, V63, P1847, DOI 10.1373/clinchem.2017.276345
   Elhoseny M, 2019, COMPUT NETW, V159, P147, DOI 10.1016/j.comnet.2019.04.016
   FOLEY DH, 1972, IEEE T INFORM THEORY, V18, P618, DOI 10.1109/TIT.1972.1054863
   Gálvez A, 2021, J COMPUT SCI-NETH, V56, DOI 10.1016/j.jocs.2021.101481
   Go T, 2018, BIOSENS BIOELECTRON, V103, P12, DOI 10.1016/j.bios.2017.12.020
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jannah N., 2021, Proc. Comput. Sci., V194, P69, DOI [DOI 10.1016/J.PROCS.2021.10.060, 10.1016/j.procs.2021.10.060]
   Jha CK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101875
   Kihm A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006278
   Kumar P, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741490
   Kumar P, 2021, MULTIMED TOOLS APPL, V80, P16515, DOI 10.1007/s11042-019-07978-3
   Mahto D, 2022, B POL ACAD SCI-TECH, V70, DOI 10.24425/bpasts.2022.141001
   Maity M, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0691-x
   Mohapatra S, 2014, NEURAL COMPUT APPL, V24, P1887, DOI 10.1007/s00521-013-1438-3
   Monteiro A.C.B., 2021, Trends in Deep Learning Methodologies, P129
   Moreno SR, 2020, ENERG CONVERS MANAGE, V213, DOI 10.1016/j.enconman.2020.112869
   MUI JK, 1980, IEEE T PATTERN ANAL, V2, P429, DOI 10.1109/TPAMI.1980.6592364
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parvathy VS, 2020, PHYS COMMUN-AMST, V41, DOI 10.1016/j.phycom.2020.101119
   Paz-Soto Y, 2020, SIBGRAPI, P156, DOI 10.1109/SIBGRAPI51738.2020.00029
   Pillai CKS, 2009, PROG POLYM SCI, V34, P641, DOI 10.1016/j.progpolymsci.2009.04.001
   Rodríguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   ROSE HG, 1965, J LIPID RES, V6, P428
   Sanjay R., 2012, Int J Future Comput Commun, P366, DOI DOI 10.7763/IJFCC.2012.V1.97
   Shukla AK, 2021, 2021 IEEE INT C TECH, P1
   Singh D, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105524
   Sola J, 1997, IEEE T NUCL SCI, V44, P1464, DOI 10.1109/23.589532
   Thiran JP, 1996, IEEE T BIO-MED ENG, V43, P1011, DOI 10.1109/10.536902
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tyas DA, 2020, IEEE ACCESS, V8, P69849, DOI 10.1109/ACCESS.2020.2983155
   Umbaugh SE, 1997, IEEE ENG MED BIOL, V16, P62, DOI 10.1109/51.603650
   Zhao QB, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1089
   Zhou DX, 2006, ADV COMPUT MATH, V25, P323, DOI 10.1007/s10444-004-7206-2
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 51
TC 4
Z9 4
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7861
EP 7886
DI 10.1007/s11042-022-13613-5
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840056800002
DA 2024-07-18
ER

PT J
AU Hambali, MA
   Oladele, TO
   Adewole, KS
   Sangaiah, AK
   Gao, W
AF Hambali, Moshood A.
   Oladele, Tinuke O.
   Adewole, Kayode S.
   Sangaiah, Arun Kumar
   Gao, Wei
TI Feature selection and computational optimization in high-dimensional
   microarray cancer datasets via InfoGain-modified bat algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Binary bat algorithm; Information gain; Cancer
   classification; Microarray data; Random forest; Computational
   optimization
ID ANT COLONY OPTIMIZATION; PARTIAL LEAST-SQUARES; GENE SELECTION; TUMOR
   CLASSIFICATION; MARKOV BLANKET; EXPRESSION; ECHOLOCATION; PREDICTION;
   SEARCH
AB Achieving a satisfactory cancer classification accuracy with the complete set of genes remains a great challenge, due to the high dimensions, small sample size, and presence of noise in gene expression data. Feature reduction is critical and sensitive in the classification task, most importantly in heterogeneous multimedia data. One of the major drawbacks in cancer study is recognizing informative genes from thousands of available genes in microarray data. Traditional feature selection algorithms have failed to scale on large space data like microarray data. Therefore, an effective feature selection algorithm is required to explore the most significant subset of genes by removing non-predictive genes from the dataset without compromising the accuracy of the classification algorithm. The study proposed an information Gain - Modified Bat Algorithm (InfoGain-MBA) features selection model for selecting relevant and informative features from high dimensional Microarray cancer datasets and evaluate the approach with four classifiers - C4.5, Decision Tree, Random Forest and classification and regression tree (CART). The results obtained show that the proposed approach is promising for the classification of microarray cancer data. The random forest has 100% accuracy with few genes in all seven datasets used. Further investigations were also conducted to determine the optimal threshold for each of the datasets.
C1 [Hambali, Moshood A.] Fed Univ Wukari, Dept Comp Sci, Wukari, Taraba State, Nigeria.
   [Oladele, Tinuke O.; Adewole, Kayode S.] Univ Ilorin, Dept Comp Sci, Ilorin, Kwara State, Nigeria.
   [Sangaiah, Arun Kumar] Natl Yunlin Univ Sci & Technol, Touliu 633102, Yunlin, Taiwan.
   [Gao, Wei] Yunnan Normal Univ, Sch Informat Sci & Technol, Kunming, Yunnan, Peoples R China.
C3 University of Ilorin; National Yunlin University Science & Technology;
   Yunnan Normal University
RP Sangaiah, AK (corresponding author), Natl Yunlin Univ Sci & Technol, Touliu 633102, Yunlin, Taiwan.
EM hambali@fuwukari.edu.ng; oladele.to@unilorin.edu.ng;
   adewole.ks@unilorin.edu.ng; aksangaiah@iece.org; gaowei@ynnu.edu.cn
RI Hambali, Moshood Abiola/ADS-9827-2022; Adewole, Kayode
   Sakariyah/AAI-1852-2019; Sangaiah, Arun Kumar/U-6785-2019; Oladele,
   Tinuke Omolewa/ITT-6756-2023
OI Hambali, Moshood Abiola/0000-0002-2194-9376; Adewole, Kayode
   Sakariyah/0000-0002-0155-7949; Sangaiah, Arun Kumar/0000-0002-0229-2460;
   
FU Tertiary Education Trust Fund (TETFUND) [FUW/REG/T.5/VOL.1/T11];
   Ministry of Education of the People's Republic of China
FX This research has been financially supported in part by Tertiary
   Education Trust Fund (TETFUND) with Reference FUW/REG/T.5/VOL.1/T11. We
   also acknowledge the support of Ministry of Education of the People's
   Republic of China.
CR Abeer MM, 2013, INT C RECENT ADV CIR, P220
   Aitkenhead MJ, 2008, EXPERT SYST APPL, V34, P18, DOI 10.1016/j.eswa.2006.08.008
   Alomari Osama Ahmad, 2017, Journal of Theoretical and Applied Information Technology, V95, P2610
   Alshamlan HM, 2015, COMPUT BIOL CHEM, V56, P49, DOI 10.1016/j.compbiolchem.2015.03.001
   [Anonymous], 2012, INT J COMPUT SCI ENG
   [Anonymous], 2009, INT J CYBER SOC ED
   [Anonymous], 2011, INT J COMPUT APPL
   Bennet J., 2015, INT ARAB J INF TECHN, V12, P695
   Biau G, 2012, J MACH LEARN RES, V13, P1063
   Bolón-Canedo V, 2015, APPL SOFT COMPUT, V30, P136, DOI 10.1016/j.asoc.2015.01.035
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cao J, 2015, J BIOMED INFORM, V53, P381, DOI 10.1016/j.jbi.2014.12.009
   Chormunge S., 2018, J ELECT SYST INF TEC, V5, P542, DOI [DOI 10.1016/J.JESIT.2017.06.004, 10.1016/j.jesit.2017.06.004]
   Chuang LY, 2012, J COMPUT BIOL, V19, P68, DOI 10.1089/cmb.2010.0064
   Dashtban M, 2018, GENOMICS, V110, P10, DOI 10.1016/j.ygeno.2017.07.010
   De Caigny A, 2018, EUR J OPER RES, V269, P760, DOI 10.1016/j.ejor.2018.02.009
   Doddipalli Lavanya., 2012, International Journal of Information Technology Convergence and Services, V2, P17, DOI DOI 10.5121/IJITCS.2012.2103
   Doreswamy M. Umme, 2016, Int. J. Soft Comput., Artif. Intell. Appl., V5, P01, DOI [10.5121/ijscai.2016.5301, DOI 10.5121/IJSCAI.2016.5301]
   Ebrahimpour MK, 2018, COMPUT BIOL CHEM, V73, P171, DOI 10.1016/j.compbiolchem.2018.02.006
   El Akadi A, 2011, KNOWL INF SYST, V26, P487, DOI 10.1007/s10115-010-0288-x
   Forsati R, 2014, NEUROCOMPUTING, V142, P354, DOI 10.1016/j.neucom.2014.03.053
   Gandomi AH, 2013, NEURAL COMPUT APPL, V22, P1239, DOI 10.1007/s00521-012-1028-9
   Geetha R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1402-6
   Genuer R., 2008, ARXIV, DOI DOI 10.48550/ARXIV.0811.3619
   Ghorai S, 2011, IEEE ACM T COMPUT BI, V8, P659, DOI 10.1109/TCBB.2010.36
   Griffin D. R., 1960, Animal Behaviour, V8, P141, DOI 10.1016/0003-3472(60)90022-1
   Gunavathi C, 2015, INT J DATA MIN BIOIN, V13, P248, DOI 10.1504/IJDMB.2015.072092
   Hall MA, 1998, AUST COMP S, V20, P181
   Hambali A. M., 2016, J ADV COMPUT RES, V7, P109
   Hambali M., 2019, J ADV COMPUTER RES, V10, P31
   Han J, 2012, MOR KAUF D, P1
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Kabir MM, 2012, EXPERT SYST APPL, V39, P3747, DOI 10.1016/j.eswa.2011.09.073
   Lin SW, 2012, SOFT COMPUT, V16, P63, DOI 10.1007/s00500-011-0734-z
   Lin WZ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024756
   Lonning PE, 2005, NAT CLIN PRACT ONCOL, V2, P26, DOI 10.1038/ncponc0072
   Mahmoud AM., 2014, INT J ADV RES ARTIF, V3, P1
   Maldonado S, 2018, APPL SOFT COMPUT, V67, P94, DOI 10.1016/j.asoc.2018.02.051
   Martens H, 2001, CHEMOMETR INTELL LAB, V58, P85, DOI 10.1016/S0169-7439(01)00153-8
   Martín-Merino M, 2009, LECT NOTES COMPUT SC, V5772, P107, DOI 10.1007/978-3-642-03915-7_10
   Masud Rana M., 2020, P INT JOINT C COMP I, P207
   METZNER W, 1991, SCI PROG, V75, P453
   Mishra S, 2012, PROC TECH, V4, P802, DOI 10.1016/j.protcy.2012.05.131
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281
   Motieghader Habib, 2017, Informatics in Medicine Unlocked, V9, P246, DOI 10.1016/j.imu.2017.10.004
   Nakamura R. Y. M., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P291, DOI 10.1109/SIBGRAPI.2012.47
   Narayanan Ajit, 2002, Appl Bioinformatics, V1, P191
   Nguyen DV, 2002, BIOINFORMATICS, V18, P1216, DOI 10.1093/bioinformatics/18.9.1216
   Nguyen DV, 2002, BIOINFORMATICS, V18, P39, DOI 10.1093/bioinformatics/18.1.39
   Panigrahi PP, 2013, J THEOR BIOL, V334, P109, DOI 10.1016/j.jtbi.2013.06.013
   Panigrahi Ranjit, 2018, Procedia Computer Science, V132, P323, DOI 10.1016/j.procs.2018.05.186
   Pirooznia M, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-S1-S13
   Polat K, 2009, EXPERT SYST APPL, V36, P1587, DOI 10.1016/j.eswa.2007.11.051
   PRAAGMAN J, 1985, EUR J OPER RES, V19, P144, DOI 10.1016/0377-2217(85)90321-2
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rajeswari P., 2011, INT J COMPUT APPL, V34, P25
   Rodrigues D, 2014, EXPERT SYST APPL, V41, P2250, DOI 10.1016/j.eswa.2013.09.023
   Rui Tang, 2012, 2012 Seventh International Conference on Digital Information Management (ICDIM 2012), P116, DOI 10.1109/ICDIM.2012.6360145
   Saeid Mary Monir, 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P857, DOI 10.1109/ICOEI48184.2020.9142961
   Sahu B, 2012, PROCEDIA ENGINEER, V38, P27, DOI 10.1016/j.proeng.2012.06.005
   Schnitzler HU, 2001, BIOSCIENCE, V51, P557, DOI 10.1641/0006-3568(2001)051[0557:EBIEB]2.0.CO;2
   Seera M, 2014, EXPERT SYST APPL, V41, P2239, DOI 10.1016/j.eswa.2013.09.022
   Selvaraj S, 2011, BIOINFORMATION, V6, P95, DOI 10.6026/97320630006095
   Shafi ASM, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3051-2
   Sharbaf FV, 2016, GENOMICS, V107, P231, DOI 10.1016/j.ygeno.2016.05.001
   Shreem SS, 2014, INFORM SCIENCES, V258, P108, DOI 10.1016/j.ins.2013.10.012
   Sulaiman A, 2015, J ADV SCI RES ITS AP, V2, P79
   Suresh A, 2020, SOFT COMPUT, V24, P7947, DOI 10.1007/s00500-019-04066-4
   Swathi S, 2012, P INT C COMP DES ENG, V49, P100, DOI DOI 10.7763/IPCSIT.2012.V49.19
   Veerabhadrappa L.Rangarajan. s.l., 2010, International Journal of Computer Applications, V4, P33, DOI DOI 10.5120/800-1137
   Vieira SM, 2013, APPL SOFT COMPUT, V13, P3494, DOI 10.1016/j.asoc.2013.03.021
   Wang GG, 2013, J APPL MATH, DOI 10.1155/2013/696491
   Wang LP, 2007, IEEE ACM T COMPUT BI, V4, P40, DOI 10.1109/TCBB.2007.1006
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yang XS, 2011, INT J BIO-INSPIR COM, V3, P267, DOI 10.1504/IJBIC.2011.042259
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
NR 79
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36505
EP 36549
DI 10.1007/s11042-022-13532-5
EA AUG 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000839516900005
DA 2024-07-18
ER

PT J
AU Chauhan, K
   Sharma, KK
   Varma, T
AF Chauhan, Krishna
   Sharma, Kamalesh Kumar
   Varma, Tarun
TI A method for simplifying the spoken emotion recognition system using a
   shallow neural network and temporal feature stacking & pooling (TFSP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Vocal-tract length disruption; SVM
   classifier; Average pooling; Shallow neural network
ID MODELS
AB This study presents a new speech emotion recognition (SER) technique using temporal feature stacking and pooling (TFSP). First, Mel-frequency cepstral coefficients, Mel-spectrogram, and emotional silence factor (ESF) are extracted from segmented audio samples. The normalized features are fed into this neural network for training. For final feature representation, the learned features passed through the proposed TFSP framework. Subsequently, a linear support vector machine classifier is employed for emotion classification. It is evident from the confusion matrices that the suggested method can extract emotional content from speech signals efficiently with more unique emotional aspects from commonly confused emotions. According to this study, a shallow neural network can perform as good as the existing deep learning architectures like CNN, RNN, and attention networks. It may be mentioned here that the proposed method also utilises data augmentation by artificially increasing the number of speakers by disrupting the vocal tract length. Furthermore, these highly complex networks employ millions of trainable parameters, resulting in a longer convergence time. The experiments are carried out on four different language speech emotional datasets, the Berlin emotional speech dataset (EmoDB) in German language, Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) in North American English, Surrey Audio-Visual Expressed Emotion Database (SAVEE) in British English and a newly constructed MNITJ-Simulated Emotional Hindi speech Database (MNITJ-SEHSD) in the Hindi language. Experimental results on the proposed framework achieved an overall accuracy of 95.09%, 90.20%, 95.50% and 94.67%, on EmoDB, RAVDESS, SAVEE and MNITJ-SEHSD, respectively, at much lesser computational complexity. These findings are compared to the baseline of the three existing architectures on the same databases. Classification accuracy, precision, recall and F1-score are used to validate the developed method.
C1 [Chauhan, Krishna; Sharma, Kamalesh Kumar; Varma, Tarun] Malaviya Natl Inst Technol Jaipur, Elect & Commun Engn Dept, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Chauhan, K (corresponding author), Malaviya Natl Inst Technol Jaipur, Elect & Commun Engn Dept, Jaipur 302017, Rajasthan, India.
EM 2018rec9121@mnit.ac.in; kksharma.ece@mnit.ac.in; tvarma.ece@mnit.ac.in
RI Chauhan, Krishna/AFS-7346-2022
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Anvarjon T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185212
   Atila O, 2021, APPL ACOUST, V182, DOI 10.1016/j.apacoust.2021.108260
   Atmaja BT, 2021, SPEECH COMMUN, V126, P9, DOI 10.1016/j.specom.2020.11.003
   Bin Abdul Qayyum Alif, 2019, 2019 IEEE International Conference on Signal Processing, Information, Communication & Systems (SPICSCON), P122, DOI 10.1109/SPICSCON48833.2019.9065172
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chatterjee R, 2021, IEEE T CONSUM ELECTR, V67, P68, DOI 10.1109/TCE.2021.3056421
   Chatziagapi A, 2019, INTERSPEECH, P171, DOI 10.21437/Interspeech.2019-2561
   Chauhan Krishna, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1176, DOI 10.1109/ICAIS50930.2021.9395844
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dangol R, 2020, MULTIMED TOOLS APPL, V79, P32917, DOI 10.1007/s11042-020-09693-w
   Deb S, 2019, IEEE T CYBERNETICS, V49, P802, DOI 10.1109/TCYB.2017.2787717
   Deng J, 2013, INT CONF AFFECT, P511, DOI 10.1109/ACII.2013.90
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Guizzo E, 2020, INT CONF ACOUST SPEE, P6489, DOI [10.1109/icassp40776.2020.9053727, 10.1109/ICASSP40776.2020.9053727]
   Han K, 2014, INTERSPEECH, P223
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   Jaitly N., 2013, Proc. ICML Workshop Deep. Learn. Audio Speech Lang, V117
   Javaheri B., 2021, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liu ZT, 2015, CHIN CONTR CONF, P3780, DOI 10.1109/ChiCC.2015.7260224
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Ma E., 2019, NLPAUG DATA AUGMENTA
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mushtaq Z, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107389
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Nediyanchath A, 2020, INT CONF ACOUST SPEE, P7179, DOI [10.1109/icassp40776.2020.9054073, 10.1109/ICASSP40776.2020.9054073]
   Özseven T, 2018, APPL ACOUST, V142, P70, DOI 10.1016/j.apacoust.2018.08.003
   Rafael Aguiar L., 2018, INT JOINT C NEURAL N, P1, DOI DOI 10.1109/IJCNN.2018.8489166
   Sarma M, 2018, INTERSPEECH, P3097, DOI 10.21437/Interspeech.2018-1353
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Sun LH, 2019, SPEECH COMMUN, V115, P29, DOI 10.1016/j.specom.2019.10.004
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wu C, 2018, MULTIMED TOOLS APPL, V77, P24353, DOI 10.1007/s11042-018-5742-x
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Wu XX, 2019, INT CONF ACOUST SPEE, P6695, DOI 10.1109/ICASSP.2019.8683163
   Xie Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1675, DOI 10.1109/TASLP.2019.2925934
   Zhang YY, 2018, ASIAPAC SIGN INFO PR, P1771, DOI 10.23919/APSIPA.2018.8659587
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zhong SM, 2020, IEEE ACCESS, V8, P222533, DOI 10.1109/ACCESS.2020.3043894
NR 50
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11265
EP 11283
DI 10.1007/s11042-022-13463-1
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000838552300001
DA 2024-07-18
ER

PT J
AU Abdelwahed, N
   Ben Letaifa, A
   El Asmi, S
AF Abdelwahed, Nawres
   Ben Letaifa, Asma
   El Asmi, Sadok
TI Monitoring web QoE based on analysis of client-side measures and user
   behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User engagement; Web QoE; Machine learning; MOS; User profiling
ID EXPERIENCE; QUALITY; PROFILE; TOOLS
AB An increasing number of web applications in all fields for different types of use incites developers and researchers to enhance the web applications as well as the network conditions to satisfy the final user. That's why the estimation of the Quality of Experience for web applications (web QoE) remains necessary. The web QoE gives service and content providers an idea about the perceived quality by users as it helps them to determine issues for improvement. Waiting time influences user satisfaction. For this reason, we found many studies in web QoE interested in the first part of the browsing operation, such as the waiting time until the first page is completely loaded. However, these measures do not include the interactions of the user with the web application lately. We measured the interactions of the user with the web application via the user engagement metrics. This new field of research has attracted many researchers these last years due to its efficacity in determining the satisfaction level of the user. The contribution of our study is the research and use of user engagement metrics for QoE prediction. We have noticed that user engagement metrics (generally used to evaluate a user's commitment in social media) are more precise in expressing the QoE of the user. For this reason, we used user engagement metrics to predict user web QoE that is the novelty of our work. In this study, we elaborated our dataset, which contains the three types of measurements; Quality of Service (QoS), QoE, and user engagement metrics. The obtained dataset reflects the user experience from several perspectives (the network quality, the loading process, and the interaction of the user with the web application). This reflection makes our dataset an exhaustive one. After collecting the data, we visualized our different metrics. Besides, we tried to predict the Mean Opinion Score (MOS) with Machine Learning (ML) algorithms, but we obtained low accuracy due to the small number of lines in our dataset. Finally, we tried to profile the users using the K-means clustering algorithm. In this clustering, we recuperated three user information metrics (age, gender, and study level).
C1 [Abdelwahed, Nawres; El Asmi, Sadok] Univ Carthage, Supcom Tunisia, Cosim Lab, Tunis, Tunisia.
   [Ben Letaifa, Asma] Univ Carthage, Supcom Tunisia, Mediatron Lab, Tunis, Tunisia.
C3 Universite de Carthage; Universite de Carthage
RP Abdelwahed, N (corresponding author), Univ Carthage, Supcom Tunisia, Cosim Lab, Tunis, Tunisia.
EM nawres.abdelwahed@supcom.tn; asma.benletaifa@supcom.tn; elasmi@supcom.tn
RI BEN LETAIFA, Asma/AAM-7034-2020
OI , Nawres/0000-0003-2069-8525
CR Abdelwahed N, 2021, WIRELESS PERS COMMUN, V117, P2383, DOI 10.1007/s11277-020-07980-1
   Abrams Z., 2011, WEB PERF OP C
   Ahmed H, 2017, INT J ADV COMPUT SC, V8, P562
   Alaoui S, 2015, PROCEDIA COMPUT SCI, V73, P342, DOI 10.1016/j.procs.2015.12.002
   Alfian G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072183
   Allioui YE., 2012, INT J COMPUT APPL, V41, P31, DOI [10.5120/5531-7577, DOI 10.5120/5531-7577]
   Alreshoodi M, 2013, INT J DISTRIBUTED PA, P4
   Anitha V., 2016, 2016 INT C COMPUTING, P1
   [Anonymous], 2017, P INT SUMM YOUNG RES
   [Anonymous], 2011, ADV COMMUNICATION NE
   Asrese AS, 2019, LECT NOTES COMPUT SC, V11419, P18, DOI 10.1007/978-3-030-15986-3_2
   Asrese AS, 2019, IEEE T NETW SERV MAN, V16, P535, DOI 10.1109/TNSM.2019.2896710
   Attfield S., 2011, WSDM WORKSHOP USER M, P9
   Bakaev M, 2020, LECT NOTES COMPUT SC, V12128, P146, DOI 10.1007/978-3-030-50578-3_11
   Barakovic S., 2017, QUALITY USER EXPERIE, V2
   Ben Letaifa A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.4007
   Bernaschina C, 2017, LECT NOTES COMPUT SC, V10360, P98, DOI 10.1007/978-3-319-60131-1_6
   Bocchi E, 2016, ACM SIGCOMM COMP COM, V46, DOI 10.1145/2940136.2940138
   Calegari S, 2010, FUTURE INTERNET, V2, P533, DOI 10.3390/fi2040533
   Chikhaoui B, 2014, INFORM SCIENCES, V285, P204, DOI 10.1016/j.ins.2014.06.026
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Ducasse J, 2020, INT J HUM-COMPUT INT, V36, P1558, DOI 10.1080/10447318.2020.1757255
   Fang W., 2007, Library Philosophy and Practice, V2007, P1, DOI [DOI 10.7282/T3MK6B6N, 10.7282/T3MK6B6N]
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Gao QZ, 2017, PROCEEDINGS OF THE 2017 WORKSHOP ON QOE-BASED ANALYSIS AND MANAGEMENT OF DATA COMMUNICATION NETWORKS (INTERNET QOE 17), P13, DOI 10.1145/3098603.3098606
   Gauch S., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P54
   Godoy D., 2005, KNOWL ENG REV, P1
   Grover P, 2020, J RETAIL CONSUM SERV, V53, DOI 10.1016/j.jretconser.2018.12.002
   Gunter U, 2016, ANN TOURISM RES, V61, P199, DOI 10.1016/j.annals.2016.10.007
   Hameed A, 2016, IEEE T MULTIMEDIA, V18, P764, DOI 10.1109/TMM.2016.2525862
   Hossfeld T, 2020, PROCEEDINGS OF THE 2020 6TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2020): BRIDGING THE GAP BETWEEN AI AND NETWORK SOFTWARIZATION, P51, DOI 10.1109/NetSoft48620.2020.9165426
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Ijaz MF, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8081325
   Islam Mohammed J., 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P1541, DOI 10.1109/ICCIT.2007.148
   Jahromi HZ, 2020, PROCEEDINGS OF THE 2020 6TH IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2020): BRIDGING THE GAP BETWEEN AI AND NETWORK SOFTWARIZATION, P43, DOI 10.1109/NetSoft48620.2020.9165497
   Jahromi HZ, 2019, 2019 30TH IRISH SIGNALS AND SYSTEMS CONFERENCE (ISSC)
   Jahromi HZ, 2020, IEEE ACCESS, V8, P47741, DOI 10.1109/ACCESS.2020.2979385
   Kang YQ, 2013, IEEE INT CONF COMMUN, P264, DOI 10.1109/ICCChina.2013.6671126
   Kanoje S., 2014, INT J ADV FDN RES CO, V1
   Katsarakis M, 2014, IEEE COMMUN MAG, V52, P37, DOI 10.1109/MCOM.2014.6894450
   Kawazu H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2518, DOI 10.1109/BigData.2016.7840891
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Kumar A, 2019, INT J ELECTRON COMM, V23, P179, DOI 10.1080/10864415.2018.1564550
   Lashkari A., 2018, Journal of Cyber Security and Mobility, V8, P75
   Le Callet P, 2012, EUROPEAN NETWORK QUA, P3
   Le Callet P, 2006, IEEE T NEURAL NETWOR, V17, P1316, DOI 10.1109/TNN.2006.879766
   Machado VA, 2011, IEEE 3 LAT AM C COMM
   Mason L, 2000, ADV NEUR IN, V12, P512
   Menkovski Vlado, 2010, Proceedings 2010 2nd International Conference on Intelligent Networking and Collaborative Systems (INCoS 2010), P461, DOI 10.1109/INCOS.2010.86
   Mok RKP, 2019, PROCEEDINGS OF THE 2019 ACM SIGCOMM CONFERENCE POSTERS AND DEMOS (SIGCOMM '19), P60, DOI 10.1145/3342280.3342307
   Ouaftouh S, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS: THEORIES AND APPLICATIONS (SITA)
   Pal M, 2002, INT GEOSCI REMOTE SE, P503, DOI 10.1109/IGARSS.2002.1025087
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9060690
   Panigrahi R, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9070751
   Plaza B, 2011, TOURISM MANAGE, V32, P477, DOI 10.1016/j.tourman.2010.03.015
   Ramawat S., 2017, INT J COMPUT ENG TEC, V8, P12
   Robloff T, 2019, IEEE GLOB ENG EDUC C, P296, DOI [10.1109/educon.2019.8725118, 10.1109/EDUCON.2019.8725118]
   Sachse J, 2019, ASLIB J INFORM MANAG, V71, P325, DOI 10.1108/AJIM-07-2018-0182
   Sahu S., 2019, International Journal of Applied Engineering Research, V14, P2339
   Salutari F, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3194, DOI 10.1145/3308558.3313467
   Samet N, 2016, IEEE 30TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA 2016), P204, DOI 10.1109/WAINA.2016.120
   Shahid M, 2013, INT WORK QUAL MULTIM, P176, DOI 10.1109/QoMEX.2013.6603233
   Strohmeier D, 2012, IEEE GLOBE WORK, P1309, DOI 10.1109/GLOCOMW.2012.6477771
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Thushara Y, 2016, Int J Comput Appl, V149, P21, DOI [10.5120/ijca2016911610, DOI 10.5120/IJCA2016911610]
   Upadhyaya B, 2014, 2014 IEEE 21ST INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2014), P57, DOI 10.1109/ICWS.2014.21
   Wang Z, 2012, W3C RECOMMENDATION
   Wassermann S, 2020, ACM SIGCOMM 2020 POS
   Win Thanda Aung, 2009, 2009 IEEE Asia-Pacific Services Computing Conference (APSCC 2009), P372, DOI 10.1109/APSCC.2009.5394100
   Xuezhi Lei, 2018, 2018 International Conference on Engineering Simulation and Intelligent Control (ESAIC), P192, DOI 10.1109/ESAIC.2018.00052
   Yang YH, 2010, DECIS SUPPORT SYST, V49, P261, DOI 10.1016/j.dss.2010.03.001
   Zhang X, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P289, DOI 10.1145/3341302.3342089
NR 72
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6243
EP 6269
DI 10.1007/s11042-022-13427-5
EA AUG 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836084100001
DA 2024-07-18
ER

PT J
AU Pradeepa, P
   Jeyakumar, MK
AF Pradeepa, P.
   Jeyakumar, M. K.
TI Modelling of IDBN with LSNN based optimal feature selection for the
   prediction of CKD using real time data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chronic kidney disease; Novel local search with nearest neighbour
   optimization; Improved deep belief network; Hybrid atom crow
   optimization
ID CONVOLUTIONAL NEURAL-NETWORK
AB Chronic Kidney Disease (CKD) is a critical condition induced by either reduced kidney functions or kidney pathology. The early diagnosis of CKD is considered significant to prevent the patient from a serious condition. In literature, various techniques are presented to detect CKD at the initial stage, but providing a better performance is still challenging, which causes the patients may not identify their diseases at the starting stage. Some of the noticeable drawbacks of existing techniques are higher-dimensional attributes, computational issues and high execution time. In order to overcome these concerns, this proposed paper focuses on designing an improved deep learning approach with optimal feature selection for the effective detection of CKD. The first stage of the proposed method is preprocessing, which performs digitalization, normalization and data filling. Then, a novel Local Search with Nearest Neighbour (LSNN) optimization is introduced for selecting effective features. Finally, the Improved Deep Belief Network (IDBN) is built using the obtained optimal features. The proposed CKD prediction model is validated using Benchmark and Real time datasets. The performance of the model is analyzed by considering five different cases. Each case has a different combination of attributes, and the performances are compared with conventional CKD prediction techniques like Deep Belief Network (DBN), Deep Neural Network (DNN), Multi-layer Perceptron (MLP), and Support Vector Machine (SVM). Both the prediction strategies provided better performance while using the optimally selected 15 features by LSNN. The proposed IDBN provided a maximum of 98% and 97% of accuracy, 0.01 and 0.02 of error value, 99% and 98% of precision, 98% and 99% of recall for benchmark and real time datasets, respectively. Ultimately the proposed IDBM with LSNN based techniques provided better performance for the prediction of CKD.
C1 [Pradeepa, P.; Jeyakumar, M. K.] Noorul Islam Ctr Higher Educ, Dept Comp Applicat, Kumaracoil 629180, Tamil Nadu, India.
RP Pradeepa, P (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Applicat, Kumaracoil 629180, Tamil Nadu, India.
EM pradeepa20285@gmail.com
RI Jeyakumar, MK/KIA-5250-2024
OI Jeyakumar, MK/0000-0001-9703-4685
CR Arafat Faisal, 2021, 2021 IEEE 12th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON), P1010, DOI 10.1109/IEMCON53756.2021.9623101
   Ariani A., 2021, SINERGI, V25, P177, DOI [10.22441/sinergi.2021.2.009, DOI 10.22441/SINERGI.2021.2.009]
   Arulanthu P, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER TECHNOLOGIES AND OPTIMIZATION TECHNIQUES (ICEECCOT), P70, DOI [10.1109/iceeccot46775.2019.9114653, 10.1109/ICEECCOT46775.2019.9114653]
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bouktif S, 2018, ENERGIES, V11, DOI 10.3390/en11071636
   Chen GZ, 2020, IEEE ACCESS, V8, P100497, DOI 10.1109/ACCESS.2020.2995310
   Chittora P, 2021, IEEE ACCESS, V9, P17312, DOI 10.1109/ACCESS.2021.3053763
   Choi E, 2017, J AM MED INFORM ASSN, V24, P361, DOI 10.1093/jamia/ocw112
   Dhiman G, 2021, INT J MACH LEARN CYB, V12, P571, DOI 10.1007/s13042-020-01189-1
   Ilyas H, 2021, BMC NEPHROL, V22, DOI 10.1186/s12882-021-02474-z
   Jangra M., 2017, COMMUNICATION COMPUT, P177
   Lakshmanaprabu SK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105487
   Lambert Jerlin Rubini, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0119, DOI 10.1109/ICCSP48568.2020.9182206
   Lambert JR, 2022, J AMB INTEL HUM COMP, V13, P1799, DOI 10.1007/s12652-021-03477-2
   Ma FZ, 2020, FUTURE GENER COMP SY, V111, P17, DOI 10.1016/j.future.2020.04.036
   Parthiban R., 2021, Eur. J. Mol. Clin. Med, V7, P2511
   Patil S, 2021, BIO-ALGORITHMS MED-S, V17, P137, DOI 10.1515/bams-2020-0068
   Perotte A, 2015, J AM MED INFORM ASSN, V22, P872, DOI 10.1093/jamia/ocv024
   Rajarajeswari S., 2021, International Journal of Advanced Networking and Applications, V12, P4776
   Reddy SS., 2020, EAI Endorsed Trans Pervasive Health Technol, V6, DOI [10.4108/eai11112020166958, DOI 10.4108/EAI11112020166958]
   Roy S, 2018, ENCYCLOP BIOINFORM C, V463
   Rubini LJ, 2020, J MED IMAG HEALTH IN, V10, P2297, DOI 10.1166/jmihi.2020.3177
   Shamrat F.M.J.M., 2020, PROC IEEE INT C INNO, P1, DOI [10.1109/INOCON50539.2020.9298026, DOI 10.1109/INOCON50539.2020.9298026]
   Singh P, 2021, Machine learning and the internet of medical things in healthcare, P89, DOI DOI 10.1016/B978-0-12-821229-5.00003-3
   Tazin N, 2016, 2016 INTERNATIONAL CONFERENCE ON MEDICAL ENGINEERING, HEALTH INFORMATICS AND TECHNOLOGY (MEDITEC)
NR 28
TC 3
Z9 3
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6309
EP 6344
DI 10.1007/s11042-022-13561-0
EA AUG 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400008
DA 2024-07-18
ER

PT J
AU Kumar, S
   Yadav, D
   Gupta, H
   Kumar, M
   Verma, OP
AF Kumar, Saurav
   Yadav, Drishti
   Gupta, Himanshu
   Kumar, Mohit
   Verma, Om Prakash
TI Towards smart surveillance as an aftereffect of COVID-19 outbreak for
   recognition of face masked individuals using YOLOv3 algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Facemask detection; Object detection; Surveillance system;
   YOLOv3 algorithm; Convolutional neural network; Deep neural networks
AB The eruption of COVID-19 pandemic has led to the blossoming usage of face masks among individuals in the communal settings. To prevent the transmission of the virus, a mandatory mask-wearing rule in public areas has been enforced. Owing to the use of face masks in communities at different workplaces, an effective surveillance seems essential because several security analyses indicate that face masks may be used as a tool to hide the identity. Therefore, this work proposes a framework for the development of a smart surveillance system as an aftereffect of COVID-19 for recognition of individuals behind the face mask. For this purpose, transfer learning approach has been employed to train the custom dataset by YOLOv3 algorithm in the Darknet neural network framework. Moreover, to demonstrate the competence of YOLOv3 algorithm, a comparative analysis with YOLOv3-tiny has been presented. The simulated results verify the robustness of YOLOv3 algorithm in the recognition of individuals behind the face mask. Also, YOLOv3 algorithm achieves a mAP of 98.73% on custom dataset, outperforming YOLOv3-tiny by approximately 62%. Moreover, YOLOv3 algorithm provides adequate speed and accuracy on small faces.
C1 [Kumar, Saurav] Indian Inst Technol, Dept Elect Engn, Roorkee, Uttar Pradesh, India.
   [Yadav, Drishti] Tech Univ Wien, Fac Informat, A-1040 Vienna, Austria.
   [Gupta, Himanshu; Verma, Om Prakash] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
   [Kumar, Mohit] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Informat & Technol, Jalandhar 144011, Punjab, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Technische Universitat Wien; National
   Institute of Technology (NIT System); Dr B R Ambedkar National Institute
   of Technology Jalandhar; National Institute of Technology (NIT System);
   Dr B R Ambedkar National Institute of Technology Jalandhar
RP Verma, OP (corresponding author), Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept Instrumentat & Control Engn, Jalandhar 144011, Punjab, India.
EM saurav_k@ee.iitr.ac.in; drish131196@gmail.com; guptah.nitj@gmail.com;
   kumarmohit@nitj.ac.in; vermaop@nitj.ac.in
RI Verma, Om/AAD-1007-2019; Gupta, Himanshu/AAW-2278-2021; KUMAR,
   MOHIT/GNP-6004-2022; Kumar, Saurav/CAJ-5221-2022
OI Verma, Om/0000-0002-7421-295X; Gupta, Himanshu/0000-0003-4799-5693;
   KUMAR, MOHIT/0000-0003-1600-6872; YADAV, DRISHTI/0000-0002-2974-0323
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Al-masni MA, 2018, COMPUT METH PROG BIO, V157, P85, DOI 10.1016/j.cmpb.2018.01.017
   [Anonymous], 2021, Weekly epidemiological update, V46th
   Bu W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P458, DOI 10.1109/ICCIS.2017.8274819
   Rangel JC, 2018, APPL SOFT COMPUT, V65, P603, DOI 10.1016/j.asoc.2018.02.005
   Chavda A, 2021, 2021 6TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/I2CT51068.2021.9418207
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen QQ, 2018, J VIS COMMUN IMAGE R, V55, P795, DOI 10.1016/j.jvcir.2018.08.016
   Cheng YF, 2021, SCIENCE, V372, P1439, DOI 10.1126/science.abg6296
   Chowdhury AE, 2020, HFDCM LOW COST MACHI, P1348, DOI DOI 10.1109/ICICICT46008.2019.8993212
   Corovic A, 2018, 2018 26TH TELECOMMUNICATIONS FORUM (TELFOR), P731
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Fang YQ, 2020, J MED VIROL, V92, P645, DOI 10.1002/jmv.25750
   Feng S, 2020, LANCET RESP MED, V8, P434, DOI 10.1016/S2213-2600(20)30134-X
   Fischer EP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abd3083
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   GLUMOV NI, 1995, OPT LASER TECHNOL, V27, P241, DOI 10.1016/0030-3992(95)93752-D
   Gupta H, 2022, MULTIMED TOOLS APPL, V81, P19683, DOI 10.1007/s11042-021-11146-x
   Gupta H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020127
   Harikrishnan J, 2019, P INT C VISION EMERG
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Inamdar M., 2020, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3663305
   Karthik R, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105933
   Khandelwal P., 2020, Using computer vision to enhance safety of workforceinmanufacturinginapostcovidworld
   Klompas M, 2020, NEW ENGL J MED, V382, DOI 10.1056/NEJMp2006372
   Kumar S, 2022, MULTIMED TOOLS APPL, V81, P22163, DOI 10.1007/s11042-021-11280-6
   Kumar S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10010014
   Leung NHL, 2020, NAT MED, V26, P676, DOI 10.1038/s41591-020-0843-2
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P792, DOI 10.1109/TKDE.2002.1019214
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Ma QX, 2020, J MED VIROL, V92, P1567, DOI 10.1002/jmv.25805
   Mahapatra R, 2021, CMC-COMPUT MATER CON, V68, P1219, DOI 10.32604/cmc.2021.015590
   Mery D, 2019, IEEE WINT CONF APPL, P857, DOI 10.1109/WACV.2019.00096
   Militante SV, 2020, 2020 11TH IEEE CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P106, DOI [10.1109/icsgrc49013.2020.9232610, 10.1109/ICSGRC49013.2020.9232610]
   Nie X, 2019, IEEE INT C INTELL TR, P47, DOI 10.1109/ITSC.2019.8917475
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2015, IEEE INT CONF ROBOT, P1316, DOI 10.1109/ICRA.2015.7139361
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Suganthalakshmi R., 2020, International Research Journal of Engineering and Technology (IRJET), V7, P3127
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang SH, 2018, INTL CONF POWER SYST, P3871, DOI 10.1109/POWERCON.2018.8602149
   Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698
   WHO, 2021, COR DIS COVID 19 POS
   World Health Organization, 2020, ADV US MASKS CONT CO
   World Health Organization, 2020, ADV US MASKS COMM HO
   Wu HL, 2020, ECLINICALMEDICINE, V21, DOI 10.1016/j.eclinm.2020.100329
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Yadav Shashi., 2020, INT J RES APPL SCI E, V8, P1368, DOI [DOI 10.22214/IJRASET.2020.30560, 10.22214/IJRASET.2020.30560]
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 62
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8381
EP 8403
DI 10.1007/s11042-021-11560-1
EA JUL 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000832843900002
PM 35968407
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Diwakar, M
   Shankar, A
   Chakraborty, C
   Singh, P
   Arunkumar, G
AF Diwakar, Manoj
   Shankar, Achyut
   Chakraborty, Chinmay
   Singh, Prabhishek
   Arunkumar, G.
TI Multi-modal medical image fusion in NSST domain for internet of medical
   things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal medical image fusion; Multi local extrema; Fuzzy logic;
   Shearlet transform; Co-occurrence filter
ID SHEARLET TRANSFORM; ALGORITHM; FILTER
AB The Internet of Medical Things (IoMT) has included a new layer for development and smart infrastructure growth in the medical field. Besides, the medical data on IoMT systems are constantly expanding due to the rising peripherals in the health system. This paper introduces a new fusion technique in the shearlet domain to improve existing methods, which may provide medical image fusion in the IoMT system. In this paper, firstly low and high frequencies NSST coefficients are obtained of both input images. Over the low frequency component, a new Multi local extrema (MLE) based decomposition is performed to get more detail features (Coarse and detail layers). Over these MLE features saliency based weighted average is performed using co-occurrence filter to get the enhanced low frequency NSST Coefficients. These enhanced low frequency NSST Coefficients of both input images are fused using the proposed weighted function. In high frequency NSST Coefficients, local type-2 fuzzy entropy-based fusion is performed. Finally, inverse NSST is performed to get the final fused image. The experimental results are evaluated and compared with existing methods by visually and also by performance metrics. After a critical analysis, it was found that the results of the proposed method give better outcomes compared to similar and recent existing schemes.
C1 [Diwakar, Manoj] Graph Era Deemed Be Univ, CSE Dept, Dehra Dun, Uttarakhand, India.
   [Shankar, Achyut] Amity Univ Uttar Pradesh, Amity Sch Engn & Technol, Noida, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Mesra, Jharkhand, India.
   [Singh, Prabhishek] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
   [Arunkumar, G.] Vellore Inst Technol VIT, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Graphic Era University; Amity University Noida; Birla Institute of
   Technology Mesra; Vellore Institute of Technology (VIT); VIT Vellore
RP Singh, P (corresponding author), Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, India.
EM manoj.diwakar@gmail.com; ashankar2711@gmail.com;
   cchakrabarty@bitmesra.ac.in; prabhisheksingh88@gmail.com;
   arunkumargurunathan@gmail.com
RI Singh, Dr. Prabhishek/AAI-6544-2021; G, ARUNKUMAR/C-3063-2017;
   Chakraborty, Chinmay/N-3608-2017; Diwakar, Manoj/AAS-2520-2021
OI Singh, Dr. Prabhishek/0000-0002-9338-0932; G,
   ARUNKUMAR/0000-0002-7038-2783; Chakraborty, Chinmay/0000-0002-4385-0975;
   
CR Al-Azzawi N.A., 2015, International Journal of Computer Applications, V125, P1
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Dai Y, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0204-3
   Diwakar M, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102788
   Fu J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102488
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Ganasala P, 2014, BIOMED ENG LETT, V4, P414, DOI 10.1007/s13534-014-0161-z
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Jin X, 2018, SIGNAL PROCESS, V153, P379, DOI 10.1016/j.sigpro.2018.08.002
   Kaur M, 2021, J AMB INTEL HUM COMP, V12, P2483, DOI 10.1007/s12652-020-02386-0
   Khare A, 2021, MULTIMED TOOLS APPL, V80, P11491, DOI 10.1007/s11042-020-10184-1
   Kong WW, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107921
   Kong WW, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.1.017001
   Kumar P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3985
   Li LL, 2021, MULTIMED TOOLS APPL, V80, P12389, DOI 10.1007/s11042-020-10462-y
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Liu XB, 2018, BIOMED SIGNAL PROCES, V40, P343, DOI 10.1016/j.bspc.2017.10.001
   Liu XB, 2017, NEUROCOMPUTING, V235, P131, DOI 10.1016/j.neucom.2017.01.006
   Liu ZD, 2014, EXPERT SYST APPL, V41, P7425, DOI 10.1016/j.eswa.2014.05.043
   Murthy KNN, 2017, ADV INTELL SYST, V516, P69, DOI 10.1007/978-981-10-3156-4_7
   Nair RR, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165742
   Parmar K., 2012, P INT C COMM SYST NE, P124
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Ramlal SD, 2018, SIGNAL IMAGE VIDEO P, V12, P1479, DOI 10.1007/s11760-018-1303-z
   Shehanaz S, 2021, OPTIK, V231, DOI 10.1016/j.ijleo.2021.166413
   Singh R, 2012, J MED IMAG HEALTH IN, V2, P168, DOI 10.1166/jmihi.2012.1080
   Parvathy VS, 2020, INT J IMAG SYST TECH, V30, P847, DOI 10.1002/ima.22436
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   Ullah H, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101724
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Wang L, 2014, IEEE T BIO-MED ENG, V61, P197, DOI 10.1109/TBME.2013.2279301
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Yin M, 2014, OPTIK, V125, P2274, DOI 10.1016/j.ijleo.2013.10.064
   Yu KP, 2021, IEEE CONSUM ELECTR M, V10, P111, DOI 10.1109/MCE.2020.3035520
   Zhang J, 2021, CMC-COMPUT MATER CON, V66, P2087, DOI 10.32604/cmc.2020.014220
   Zhang S, 2020, ELECTRON LETT, V56, P761, DOI 10.1049/el.2020.0557
   Zhao WD, 2017, IEEE T INSTRUM MEAS, V66, P2283, DOI 10.1109/TIM.2017.2700198
   Zhen L, 2021, IEEE INTERNET THINGS, V8, P5114, DOI 10.1109/JIOT.2020.3030856
   Zhu R, 2021, MULTIMED TOOLS APPL, V80, P12991, DOI 10.1007/s11042-020-09543-9
NR 42
TC 11
Z9 13
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37477
EP 37497
DI 10.1007/s11042-022-13507-6
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000832844000014
DA 2024-07-18
ER

PT J
AU Mohammed, MA
   Abdulhasan, MJ
   Kumar, NM
   Abdulkareem, KH
   Mostafa, SA
   Maashi, MS
   Khalid, LS
   Abdulaali, HS
   Chopra, SS
AF Mohammed, Mazin Abed
   Abdulhasan, Mahmood Jamal
   Kumar, Nallapaneni Manoj
   Abdulkareem, Karrar Hameed
   Mostafa, Salama A.
   Maashi, Mashael S.
   Khalid, Layth Salman
   Abdulaali, Hayder Saadoon
   Chopra, Shauhrat S.
TI Automated waste-sorting and recycling classification using artificial
   neural network and features fusion: a digital-enabled circular economy
   vision for smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Waste management in smart cities; Waste images; Automated sorting
   approach; Trash recycling classification; AI for waste management;
   Circular economy in smart cities
ID MEDICAL WASTE; GENERATION
AB Waste generation in smart cities is a critical issue, and the interim steps towards its management were not that effective. But at present, the challenge of meeting recycling requirements due to the practical difficulty involved in waste sorting decelerates smart city CE vision. In this paper, a digital model that automatically sorts the generated waste and classifies the type of waste as per the recycling requirements based on an artificial neural network (ANN) and features fusion techniques is proposed. In the proposed model, various features extracted using image processing are combined to develop a sophisticated classifier. Based on the different features, different models are built, and each model produces a single decision. Besides, the kind of class is determined using machine learning. The model is validated by extracting relevant information from the dataset containing 2400 images of possible waste types recycled across three categories. Based on the analysis, it is observed that the proposed model achieved an accuracy of 91.7%, proving its ability to sort and classify the waste as per the recycling requirements automatically. Overall, this analysis suggests that a digital-enabled CE vision could improve the waste sorting services and recycling decisions across the value chain in smart cities.
C1 [Mohammed, Mazin Abed] Univ Anbar, Coll Comp Sci & Informat Technol, 11 Ramadi, Anbar, Iraq.
   [Abdulhasan, Mahmood Jamal] Al Ayen Univ, Sci Res Ctr, Environm Res Grp, Thi Qar, Iraq.
   [Kumar, Nallapaneni Manoj; Chopra, Shauhrat S.] City Univ Hong Kong, Sch Energy & Environm, Kowloon, Hong Kong, Peoples R China.
   [Kumar, Nallapaneni Manoj] HICCER Hariterde Int Council Circular Econ Res, Ctr Digital Circular Econ, Palakkad 678631, Kerala, India.
   [Abdulkareem, Karrar Hameed] Al Muthanna Univ, Coll Agr, Samawah 66001, Iraq.
   [Abdulkareem, Karrar Hameed] Univ Warith Al Anbiyaa, Coll Engn, Karbala, Iraq.
   [Mostafa, Salama A.] Univ Tun Hussein Onn Malaysia, Fac Comp Sci & Informat Technol, Batu Pahat 86400, Johor, Malaysia.
   [Maashi, Mashael S.] King Saud Univ, Coll Comp & Informat Sci, Software Engn Dept, Riyadh 11451, Saudi Arabia.
   [Khalid, Layth Salman] Univ Tun Hussein Onn Malaysia, Fac Civil & Environm Engn, Batu Pahat 86400, Johor, Malaysia.
   [Abdulaali, Hayder Saadoon] Univ Kebangsaan Malaysia, Fac Engn & Built Environm, Dept Architecture, Bangi, Selangor, Malaysia.
C3 University of Anbar; Al-Ayen University; City University of Hong Kong;
   Al-Muthanna University; University of Warith Alanbiyaa; University of
   Tun Hussein Onn Malaysia; King Saud University; University of Tun
   Hussein Onn Malaysia; Universiti Kebangsaan Malaysia
RP Mohammed, MA (corresponding author), Univ Anbar, Coll Comp Sci & Informat Technol, 11 Ramadi, Anbar, Iraq.
EM mazinalshujeary@uoanbar.edu.iq; mahmood9jamal@gmail.com;
   mnallapan2-c@my.cityu.edu.hk; khak9784@mu.edu.iq; salama@uthm.edu.my;
   mmaashi@ksu.edu.sa; layth.s.khalid@gmail.com;
   haydersaadoonabdulaali@gmail.com; sschopra@cityu.edu.hk
RI Aljaberi, Mahmood Jamal/GZH-2046-2022; Manoj Kumar,
   Nallapaneni/R-8605-2018; Chopra, Shauhrat S./AAS-8691-2020; Maashi,
   Mashael S./AAJ-3501-2020; Mohammed, Mazin Abed/E-3910-2018; Abdulkareem,
   Karrar Hameed/V-1741-2017; Chopra, Shauhrat S./HIK-2137-2022
OI Manoj Kumar, Nallapaneni/0000-0002-7382-7784; Chopra, Shauhrat
   S./0000-0001-9067-4321; Maashi, Mashael S./0000-0003-0446-5430;
   Mohammed, Mazin Abed/0000-0001-9030-8102; Abdulkareem, Karrar
   Hameed/0000-0001-7302-2049; 
CR Aazam M, 2016, 2016 IEEE 21ST INTERNATIONAL WORKSHOP ON COMPUTER AIDED MODELLING AND DESIGN OF COMMUNICATION LINKS AND NETWORKS (CAMAD), P188, DOI 10.1109/CAMAD.2016.7790356
   Abd Ghani MK, 2020, NEURAL COMPUT APPL, V32, P625, DOI 10.1007/s00521-018-3882-6
   Adedeji O, 2019, PROCEDIA MANUF, V35, P607, DOI 10.1016/j.promfg.2019.05.086
   Adelodun B, 2021, WASTE MANAGE, V122, P71, DOI 10.1016/j.wasman.2021.01.003
   Ahmad K, 2020, IEEE ACCESS, V8, P96495, DOI 10.1109/ACCESS.2020.2995681
   Ahmmed MS, 2020, MANAG ENVIRON QUAL, V31, P1587, DOI 10.1108/MEQ-10-2019-0214
   Ali T, 2020, ARAB J SCI ENG, V45, P10185, DOI 10.1007/s13369-020-04637-w
   Arebey M, 2011, ENVIRON MONIT ASSESS, V177, P399, DOI 10.1007/s10661-010-1642-x
   Chen XR, 2022, ENERGY REP, V8, P3127, DOI 10.1016/j.egyr.2022.01.193
   Chu YH, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/5060857
   Fayomi G. U., 2021, IOP Conference Series: Earth and Environmental Science, V655, DOI 10.1088/1755-1315/655/1/012040
   Glouche Y., 2013, 2 INT C SMART SYST D
   Hantoko D, 2021, J ENVIRON MANAGE, V286, DOI 10.1016/j.jenvman.2021.112140
   Janiesch C, 2021, ELECTRON MARK, V31, P685, DOI 10.1007/s12525-021-00475-2
   Kannangara M, 2018, WASTE MANAGE, V74, P3, DOI 10.1016/j.wasman.2017.11.057
   Kapoor NR, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/9404807
   Kashinath SA, 2021, IEEE ACCESS, V9, P51258, DOI 10.1109/ACCESS.2021.3069770
   Kirchherr J, 2017, RESOUR CONSERV RECY, V127, P221, DOI 10.1016/j.resconrec.2017.09.005
   Kumar A, 2018, WASTE MANAGE, V79, P781, DOI 10.1016/j.wasman.2018.08.045
   Kumar NM, 2021, PROCESS SAF ENVIRON, V152, P482, DOI 10.1016/j.psep.2021.06.026
   Madden B, 2021, RESOUR CONSERV RECY, V168, DOI 10.1016/j.resconrec.2021.105442
   Makhadmeh SN, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040447
   Modi MA., 2021, MACH LEARN PREDICT A, V1, P203, DOI [10.1007/978-981-15-7106-0_20, DOI 10.1007/978-981-15-7106-0_20]
   Qi CC, 2022, J CLEAN PROD, V343, DOI 10.1016/j.jclepro.2022.130958
   Ruiz V, 2019, LECT NOTES COMPUT SC, V11487, P422, DOI 10.1007/978-3-030-19651-6_41
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P160, DOI 10.1007/s42979-021-00592-x
   Sousa Joao, 2019, 2019 XV Workshop de Visao Computacional (WVC) [2019 XV Computer Vision Workshop (WVC)]. Proceedings, P43, DOI 10.1109/WVC.2019.8876924
   Togaçar M, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107459
   Xia WJ, 2022, WASTE MANAGE RES, V40, P609, DOI 10.1177/0734242X211033716
   Yang M., 2016, CS229
   Zaman A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14053061
   Zhao HL, 2021, WASTE MANAGE, V126, P388, DOI 10.1016/j.wasman.2021.03.034
NR 32
TC 21
Z9 21
U1 9
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39617
EP 39632
DI 10.1007/s11042-021-11537-0
EA JUL 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000832565900004
PM 35915808
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Perwaiz, N
   Fraz, MM
   Shahzad, M
AF Perwaiz, N.
   Fraz, M. M.
   Shahzad, M.
TI Smart surveillance with simultaneous person detection and
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart city; CCTV surveillance; Person detection; Person
   re-identification; Deep features
ID PEDESTRIAN DETECTION
AB When the faces of individuals are not clearly identifiable in surveillance videos due to variations in poses, camera viewpoints and occlusions, the appearances of people play a vital role in their identification. Appearance based person re-identification (re-id) summarizes appearances of persons to identify them across multiple non-overlapping camera views. Existing person re-id solutions work on the cropped person images to learn the salient features of a person instead of working on the raw surveillance images, hence these solutions need an independent preliminary phase of preparing cropped person datasets for the training and evaluation purposes. In contrast, the proposed solution works on the raw surveillance images instead of prerequisite of the cropped person dataset and the proposed hierarchical association building among various local parts of the images results in rich person representations for person re-id. In the proposed solution of Smart Surveillance with Simultaneous Person Detection and Re-identification (SSPDR), the complete surveillance video scenes are processed to perform simultaneous person detection and re-identification for all of the persons captured by a surveillance network. We use region proposals based localization scheme for person detection with an increased confidence strategy about the estimation of bounding boxes locations and the person re-identification module learns the hierarchical associations among local salient body parts of a person. Firstly, the proposed re-id module establishes associations among local horizontal strips of two persons, and afterwards it builds associations among local salient sub-patches of already associated pairs of horizontal strips. We address two major re-id challenges i.e. background noise and scale differences using the proposed re-id solution. In context of simultaneous person detection and re-identification, the proposed method is evaluated on publicly available re-id benchmark Person Re-identification in Wild (PRW) as well as on a local surveillance dataset, and attains state-of-the performance.
C1 [Perwaiz, N.; Fraz, M. M.; Shahzad, M.] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Shahzad, M.] Tech Univ Munich, D-80333 Munich, Germany.
   [Shahzad, M.] Natl Ctr Artificial Intelligence NCAI, Islamabad, Pakistan.
C3 National University of Sciences & Technology - Pakistan; Technical
   University of Munich
RP Perwaiz, N (corresponding author), Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
EM nazia.perwaiz@seecs.edu.pk; moazam.fraz@seecs.edu.pk;
   muhammad.shehzad@tum.de
OI Perwaiz, Nazia/0000-0002-0614-3788; Fraz, Muhammad
   Moazam/0000-0003-0495-463X
CR [Anonymous], 2017, 7 INT C IM PROC THEO
   Ansar W, 2018, PROGR PATTERN RECOGN, P654
   Batool S, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P220, DOI 10.1109/IPAS.2018.8708882
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cho HG, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P1035, DOI 10.1109/IVS.2012.6232264
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   He ZP, 2019, MULTIMED TOOLS APPL, V78, P5863, DOI 10.1007/s11042-018-6408-4
   Kwak JY, 2015, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV.2015.13
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li TZ, 2018, MULTIMED TOOLS APPL, V77, P21393, DOI 10.1007/s11042-017-5541-9
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Mubariz N, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P348, DOI 10.5220/0006613303480355
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Ou XY, 2019, MULTIMED TOOLS APPL, V78, P28257, DOI 10.1007/s11042-019-07921-6
   Perwaiz N, 2019, 2019 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION IN INDUSTRY (ICRAI), DOI 10.1109/icrai47710.2019.8967389
   Perwaiz N, 2020, 2020 23 INT MULTITOP, P1
   Perwaiz N, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.447
   Perwiaz N, 2018, IEEE ACCESS, V6, P77334, DOI 10.1109/ACCESS.2018.2882254
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang S, 2019, NEURAL COMPUT APPL, V31, P1189, DOI 10.1007/s00521-017-3152-z
   Tian YM, 2019, MULTIMED TOOLS APPL, V78, P24187, DOI 10.1007/s11042-018-6998-x
   Verma A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P555, DOI 10.1109/ICCVW.2015.78
   Wu JJ, 2019, MULTIMED TOOLS APPL, V78, P29323, DOI 10.1007/s11042-018-7119-6
   Xiao J, 2017, ARXIV 17050555
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yang DM, 2018, MULTIMED TOOLS APPL, V77, P25841, DOI 10.1007/s11042-018-5819-6
   Zhai SL, 2019, MULTIMED TOOLS APPL, V78, P31605, DOI 10.1007/s11042-019-07939-w
   Zhang N, 2015, PROC CVPR IEEE, P4804, DOI 10.1109/CVPR.2015.7299113
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhao K, 2018, MULTIMED TOOLS APPL, V77, P30891, DOI 10.1007/s11042-018-6173-4
   Zheng L, 2016, ARXIV 161002984
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zhu FQ, 2018, MULTIMED TOOLS APPL, V77, P3049, DOI 10.1007/s11042-017-5009-y
NR 47
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15461
EP 15482
DI 10.1007/s11042-022-13458-y
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000827365200003
DA 2024-07-18
ER

PT J
AU Tasnimi, M
   Ghaffari, HR
AF Tasnimi, Mahin
   Ghaffari, Hamid Reza
TI Diagnosis of anomalies based on hybrid features extraction in thyroid
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern algorithm; Histogram of oriented gradients
   algorithm; Thyroid diagnosis; Deep learning; Capsule network
ID ULTRASOUND IMAGES; CLASSIFICATION; ALGORITHM; PREDICTION; NODULES
AB Diagnosing benign and malignant glands in thyroid ultrasound images is considered a challenging issue. Recently, deep learning techniques have significantly resulted in extracting features from medical images and classifying them. Convolutional neural networks ignore the hierarchical structure of entities within images and do not pay attention to spatial information as well as the need for a large number of training samples. Capsule networks consist of different hierarchical capsules equivalent to the same layers in the convolutional neural networks. We propose a feature extraction method for ultrasound images based on the capsule network. Then, we combine those deep features with conventional features such as Histogram of Oriented Gradients and Local Binary Pattern together to form a hybrid feature space. We increase the accuracy percentage of a support vector machine (SVM) by balancing and reducing the data dimensions of samples. Since the SVM provides different training kernels according to the sample distribution method, the extracted textural features were categorized using each of these kernels to obtain the result. The parameters of classification evaluation using the researcher-made model have outperformed the other methods in this field. Experimental results showed that the combination of HOG, LBP, and CapsNet methods outperformed the others, with 83.95% accuracy in the SVM with a linear kernel.
C1 [Tasnimi, Mahin; Ghaffari, Hamid Reza] Islamic Azad Univ, Dept Comp, Fetdows Branch, Ferdows, Iran.
C3 Islamic Azad University
RP Ghaffari, HR (corresponding author), Islamic Azad Univ, Dept Comp, Fetdows Branch, Ferdows, Iran.
EM tasnimi_m@yahoo.com; hghaffari@fenlowsiau.ac.ir
OI tasnimi, mahin/0000-0002-4636-821X; Ghaffari,
   Hamidreza/0000-0002-7437-8466
CR Agarwal D, 2013, I S BIOMED IMAGING, P1368
   Ahn HS, 2014, NEW ENGL J MED, V371, P1765, DOI 10.1056/NEJMp1409841
   Ali H, 2020, ARTIF INTELL REV, V53, P2635, DOI 10.1007/s10462-019-09743-2
   [Anonymous], 2015, OPEN ACCESS THYROID
   Azizi G, 2015, ULTRASOUND MED BIOL, V41, P2855, DOI 10.1016/j.ultrasmedbio.2015.06.021
   Banu GR, 2016, COMMUN APPL ELECT CA, P4, DOI DOI 10.5120/CAE2016651990
   Buda M, 2019, RADIOLOGY, V292, P695, DOI 10.1148/radiol.2019181343
   Chatterjee I., 2021, Int. J. Mod. Res, V1, P15
   Chi JN, 2017, J DIGIT IMAGING, V30, P477, DOI 10.1007/s10278-017-9997-y
   Das M. N, 2016, INT C INVENTIVE COMP
   Deepika M, 2018, 2018 2 INT C INVENTI
   Devi GU, 2019, CLUSTER COMPUT, V22, P11537, DOI 10.1007/s10586-017-1417-z
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Douzas G, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11243040
   Erfani SM, 2016, PATTERN RECOGN, V58, P121, DOI 10.1016/j.patcog.2016.03.028
   Feng Du, 2017, International Journal of Wireless and Mobile Computing, V13, P306
   Georgoulas G, 2013, MECH SYST SIGNAL PR, V41, P510, DOI 10.1016/j.ymssp.2013.02.020
   Guan Q, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.04.34
   Hao YW, 2018, LECT NOTES COMPUT SC, V11061, P452, DOI 10.1007/978-3-319-99365-2_40
   Hu X, 2018, EURASIP J ADV SIG PR, DOI 10.1186/s13634-018-0574-4
   Ionita I, 2016, BRAIN-BROAD RES ARTI, V7, P115
   Ionita I, 2016, STUD INFORM CONTROL, V25, P385
   Jajroudi M, 2014, TECHNOL CANCER RES T, V13, P353, DOI 10.7785/tcrt.2012.500384
   Jha SK, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12343
   Jia T, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P25, DOI 10.1109/ICWS.2017.12
   Karami A, 2015, NEUROCOMPUTING, V149, P1253, DOI 10.1016/j.neucom.2014.08.070
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kavitha S, 2012, COMM COM INF SC, V270, P320
   Ko SY, 2019, HEAD NECK-J SCI SPEC, V41, P885, DOI 10.1002/hed.25415
   Kulkarni NN, 2017, IETE J RES, V63, P11, DOI 10.1080/03772063.2016.1241164
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Li GF, 2019, IEEE ACCESS, V7, P23713, DOI 10.1109/ACCESS.2018.2887223
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Li HR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24309-y
   Li XC, 2019, LANCET ONCOL, V20, P193, DOI 10.1016/S1470-2045(18)30762-9
   Lincango-Naranjo E, 2021, ENDOCRINE, V72, P644, DOI 10.1007/s12020-020-02588-8
   Liu R., 2019, MEDICINE, V98, P29
   Liu TJ, 2017, INT CONF ACOUST SPEE, P919, DOI 10.1109/ICASSP.2017.7952290
   Moussa O, 2020, INT J IMAG SYST TECH, V30, P185, DOI 10.1002/ima.22363
   Muhammed AM, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Nallamuth R, 2015, KUWAIT J SCI, V42, P189
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pande S., 2018, J Adv Res Dynam Control Syst, V10, P2765
   Pandey S., 2015, INT J ENG TECHNOL, V28, P457
   Patrick MK, 2022, J KING SAUD UNIV-COM, V34, P1295, DOI 10.1016/j.jksuci.2019.09.014
   Peng SH, 2010, COMPUT BIOL MED, V40, P931, DOI 10.1016/j.compbiomed.2010.10.005
   Qi JX, 2020, NEURAL COMPUT APPL, V32, P6343, DOI 10.1007/s00521-019-04142-8
   Qin PL, 2020, IEEE J BIOMED HEALTH, V24, P1028, DOI 10.1109/JBHI.2019.2950994
   Sabour S, 2017, ADV NEUR IN, V30
   Salimian M, 2019, 2 NAT C NEW TECHN EL
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Wang B., 2019, Dep. Radiol. Fac. Pap, V75, P53, DOI [DOI 10.37015/AUDT.2019.190811, DOI 10.37015/AUDT.2019, 10.37015/AUDT.2019.190811]
   Yin Q, 2015, DISCRETE CONT DYN-S, V8, P1415, DOI 10.3934/dcdss.2015.8.1415
   Zakeri FS, 2012, J MED SYST, V36, P1621, DOI 10.1007/s10916-010-9624-7
   Zarei M, 2021, BIOMED ENG-APP BAS C
   Zarei M, 2021, COMP M BIO BIO E-IV, V9, P574, DOI 10.1080/21681163.2021.1897884
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
NR 60
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3859
EP 3877
DI 10.1007/s11042-022-13433-7
EA JUL 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000826828100003
PM 35874325
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Khatchatoorian, AG
   Jamzad, M
AF Khatchatoorian, Artin Ghostan
   Jamzad, Mansour
TI Suggesting an Integration System for Image Annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Information retrieval; Model integration;
   Genetic algorithm; Data set unbalancedness
ID RETRIEVAL; FUSION; MODEL
AB The number of digital images uploaded in the virtual world is rapidly growing every day. Therefore, an automatic image annotation system that can retrieve information from these images seems to be in high demand. One of the challenges in this field is the imbalanced data sets and the difficulty of successfully learning tags from them. Even if a nearly balanced data set exists for image annotation, it is unlikely to find a single learner, which could learn all tags with the same accuracy. In this paper, we suggest a novel integration system that selects an elite group of models from all existing annotation models and then combines them to take the best advantage of each model's learning technique. The proposed system studies the data sets of selected models without the need for direct access to those data sets. As this algorithm is independent of the annotation models or data sets, it could be used to combine the currently available annotation models and those developed in future, along with their data sets and learning models. We believe the proposed approach has the potential of becoming an integrated ground for automatic image annotation models.
C1 [Khatchatoorian, Artin Ghostan; Jamzad, Mansour] Sharif Univ Technol, Dept Comp Engn, Tehran 1136511155, Iran.
C3 Sharif University of Technology
RP Khatchatoorian, AG (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran 1136511155, Iran.
EM khatchatoorian@ce.sharif.edu; jamzad@sharif.edu
CR Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   [Anonymous], 2010, P ICML
   Ballan Lamberto, 2014, P INT C MULT RETR IC, P73
   Bradshaw B., 2000, Proceedings ACM Multimedia 2000, P167, DOI 10.1145/354384.354456
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bugnon LA, 2020, IEEE T NEUR NET LEAR, V31, P2857, DOI 10.1109/TNNLS.2019.2914471
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P2746, DOI 10.1109/TIP.2015.2428055
   Chen A., 2013, ICML, P1274
   Cui CR, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P957
   Dai HJ, 2019, INT J MED INFORM, V129, P122, DOI 10.1016/j.ijmedinf.2019.05.017
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e
   Fakeri-Tabrizi A, 2010, LECT NOTES COMPUT SC, V6242, P291, DOI 10.1007/978-3-642-15751-6_37
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Grubinger M., 2007, THESIS VICTORIA U ME
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Ivasic-Kos M, 2015, EXPERT SYST APPL, V42, P9539, DOI 10.1016/j.eswa.2015.07.068
   Jiancheng Li, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P345, DOI 10.1007/978-3-319-48890-5_34
   Jin C, 2016, J VIS COMMUN IMAGE R, V34, P167, DOI 10.1016/j.jvcir.2015.10.017
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Ke X, 2017, PATTERN RECOGN, V71, P60, DOI 10.1016/j.patcog.2017.05.020
   Khatchatoorian AG, 2020, IET COMPUT VIS, V14, P214, DOI 10.1049/iet-cvi.2019.0500
   Khatchatoorian AG, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (ICDSP 2018), P88, DOI 10.1145/3193025.3193035
   Khatchatoorian AG, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P406
   Kuric E, 2015, COMPUT GRAPH-UK, V47, P1, DOI 10.1016/j.cag.2014.09.035
   Le HM, 2016, PROCEEDINGS OF THE SEVENTH SYMPOSIUM ON INFORMATION AND COMMUNICATION TECHNOLOGY (SOICT 2016), P323, DOI 10.1145/3011077.3011118
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Liu Y, 2018, PATTERN RECOGN, V78, P307, DOI 10.1016/j.patcog.2018.01.022
   Lu Z., 2012, P 20 ACM INT C MULT, P499, DOI DOI 10.1145/2393347.2393418
   Ma YC, 2020, NEURAL COMPUT APPL, V32, P6559, DOI 10.1007/s00521-019-04114-y
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Manning C. D., 2008, Introduction to information retrieval, DOI [DOI 10.1017/CBO9780511809071, 10.1017/CBO9780511809071]
   Moran S, 2014, INT J MULTIMED INF R, V3, P209, DOI 10.1007/s13735-014-0063-y
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Rad R, 2017, J VIS COMMUN IMAGE R, V46, P1, DOI 10.1016/j.jvcir.2017.03.005
   Rad R, 2015, IET COMPUT VIS, V9, P806, DOI 10.1049/iet-cvi.2014.0413
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su F, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P403, DOI 10.1145/2671188.2749383
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P2837, DOI 10.1109/TMM.2019.2909860
   Tariq A, 2015, PROC CVPR IEEE, P1958, DOI 10.1109/CVPR.2015.7298806
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Yang Y, 2015, J VIS COMMUN IMAGE R, V33, P368, DOI 10.1016/j.jvcir.2015.10.006
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang WF, 2018, NEURAL PROCESS LETT, V48, P1503, DOI 10.1007/s11063-017-9753-9
   Zhang XC, 2015, NEUROCOMPUTING, V149, P1658, DOI 10.1016/j.neucom.2014.08.027
   Zhou Z-H., 2009, Encyclopedia of Biometrics, P270, DOI [DOI 10.1007/978-0-387-73003-5_293, 10.1007/978-0-387-73003-5293, DOI 10.1007/978-0-387-73003-5293]
   Zhuang JX, 2019, PR MACH LEARN RES, V102, P588
NR 56
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8323
EP 8343
DI 10.1007/s11042-021-11571-y
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000825912900002
DA 2024-07-18
ER

PT J
AU Andono, PN
   Setiadi, DIM
AF Andono, Pulung Nurtantio
   Setiadi, De Rosal Ignatius Moses
TI Quantization selection based on characteristic of cover image for PVD
   Steganography to optimize imperceptibility and capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PVD Steganography; Cover selection; Imperceptibility; Image
   classification; PSNR vs SSIM
ID PIXEL; HISTOGRAM
AB Pixel Value Differencing (PVD) is one of the popular steganography methods and continues to be developed today. This method works based on differences in pixel values in the image. Each cover image has a different embedding capacity based on the difference in pixel values and their quantification range. PVD is superior in the aspects of capacity and imperceptibility based on the human visual system (HVS), which is widely measured using a structural similarity index (SSIM). By default, PVD has two quantization ranges. After further evaluation using SSIM in several types of cover images, the results do not always match due to differences in the characteristics of the cover image. PVD is mostly developed with adaptive quantization, which directly calculates the pixel value to optimize the trade-off of capacity and imperceptibility. This research proposes a different method to optimize this trade-off. The method is to learn the cover image characteristics with features extraction and machine learning (ML). This is done in the preprocessing before the embedding process to determine the ideal quantization for each cover image. The proposed method has been tested on the standard PVD method. It is proven to classify the cover image well and improve the quality of the stego image because the selected quantization range is more by the image characteristics. This method can later be developed and combined with the further PVD steganography method or other methods because the process is not integrated with the embedding process.
C1 [Andono, Pulung Nurtantio; Setiadi, De Rosal Ignatius Moses] Dian Nuswantoro Univ, Dept Informat Engn, Semarang 50131, Indonesia.
C3 Dian Nuswantoro University
RP Andono, PN (corresponding author), Dian Nuswantoro Univ, Dept Informat Engn, Semarang 50131, Indonesia.
EM pulung@dsn.dinus.ac.id; moses@dsn.dinus.ac.id
RI Andono, Pulung/GKM-7226-2022; Setiadi, De Rosal Ignatius
   Moses/V-1891-2019; Andono, Pulung Nurtantio/GPS-7808-2022
OI Setiadi, De Rosal Ignatius Moses/0000-0001-6615-4457; 
CR Alharan AF., 2019, INDONES J ELECT ENG, V14, P1433, DOI [10.11591/ijeecs.v14.i3.pp1433-1442, DOI 10.11591/IJEECS.V14.I3.PP1433-1442]
   Dias PA, 2018, IEEE ROBOT AUTOM LET, V3, P3003, DOI 10.1109/LRA.2018.2849498
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   google, IMAGES GOOGLE DRIVE
   Grover R, 2018, 3RD INTERNATIONAL CONFERENCE ON INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH-18), P125
   Hameed MA, 2019, IEEE ACCESS, V7, P185189, DOI 10.1109/ACCESS.2019.2960254
   Hameed MA, 2018, MULTIMED TOOLS APPL, V77, P14705, DOI 10.1007/s11042-017-5056-4
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Irawan Candra, 2018, 2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P33, DOI 10.1109/ISRITI.2018.8864443
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kavzoglu T, 2009, ENVIRON MODELL SOFTW, V24, P850, DOI 10.1016/j.envsoft.2008.11.012
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Lee CF, 2017, MULTIMED TOOLS APPL, V76, P9993, DOI 10.1007/s11042-016-3591-z
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Li ZT, 2018, J INF SECUR APPL, V43, P47, DOI 10.1016/j.jisa.2018.10.006
   lipsum, Lorem ipsum-all the facts-lipsum generator
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Mader KS, 2017, Finding and measuring lungs in CT data
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Mishra Abhay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P887, DOI 10.1007/978-981-15-0751-9_81
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P14495, DOI 10.1007/s11042-020-10424-4
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Rehman TU, 2019, COMPUT ELECTRON AGR, V156, P585, DOI 10.1016/j.compag.2018.12.006
   Rustad S, 2022, J KING SAUD UNIV-COM, V34, P3559, DOI 10.1016/j.jksuci.2020.12.017
   Saha S, 2020, MULTIMED TOOLS APPL, V79, P20973, DOI 10.1007/s11042-020-08951-1
   Sahu AK, 2019, WIRELESS PERS COMMUN, V108, P159, DOI 10.1007/s11277-019-06393-z
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Setiadi DIM, 2022, J KING SAUD UNIV-COM, V34, P104, DOI 10.1016/j.jksuci.2019.12.007
   Shen SY, 2015, MULTIMED TOOLS APPL, V74, P707, DOI 10.1007/s11042-014-2016-0
   Shukla AK, 2018, IEEE ACCESS, V6, P51130, DOI 10.1109/ACCESS.2018.2868192
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Younus ZS, 2022, J KING SAUD UNIV-COM, V34, P2951, DOI 10.1016/j.jksuci.2019.04.008
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 41
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3561
EP 3580
DI 10.1007/s11042-022-13393-y
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376500002
DA 2024-07-18
ER

PT J
AU Wang, XF
   Li, XN
   Tang, C
   Ding, LYW
AF Wang, Xiaofeng
   Li, Xinai
   Tang, Chao
   Ding, Liangyiwen
TI Median filtering detection using LBP encoding pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Median filtering detection; Local binary pattern; Discriminating
   algorithm; Recognition algorithm
ID STEGANALYSIS; FORENSICS; TRACES
AB In recent years, median filtering detection has a widely application in many fields such as images' processing history tracking, image editing detection, image anti-forensics analyzing and anti-steganalysis analyzing. In this paper, we propose two median filtering detection algorithms. The Algorithm I is a recognition algorithm that can identify whether a given image has undergone median filtering. The Algorithm II is a discriminating algorithm that can distinguish a median (average, Gaussian) filtered image from unfiltered images. Differing from the general framework of existing median filtering detectors, the contribution of our work is that the presented methods are not based on the statistical learning model. The proposed methods do not need any classifier, or any threshold. These methods are implemented by counting the number of specific Local Binary Pattern encoding patterns of a single image. Experimental results demonstrate that the proposed methods provide high accuracy and broad-spectrum robustness for tolerating content-preserving manipulations. Compared to state-of-the-art methods, the proposed methods exhibit high efficiency, high accuracy, and strong robustness.
C1 [Wang, Xiaofeng; Li, Xinai; Tang, Chao; Ding, Liangyiwen] Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Wang, XF (corresponding author), Xian Univ Technol, Sch Sci, Xian 710048, Shaanxi, Peoples R China.
EM xfwang@xaut.edu.cn
RI tang, chao/JTD-5578-2023
FU National Natural Science Foundation of China [61772416, 61973094]; Key
   Laboratory Project of the Education Department of Shaanxi Province
   [17JS098]; Shaanxi province technology innovation guiding fund project
   [2018XNCG-G-G-02]; Shaanxi Science Foundation of China [2022GY-087]
FX This work was supported by the National Natural Science Foundation of
   China, No.61772416 and No.61973094; the Key Laboratory Project of the
   Education Department of Shaanxi Province, No.17JS098; Shaanxi province
   technology innovation guiding fund project, No.2018XNCG-G-G-02; Shaanxi
   Science Foundation of China under Grant 2022GY-087.
CR Bas P., 2007, Break our Watermarking System, V2nd
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cancelli G, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P795, DOI 10.1109/MMSP.2008.4665182
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen YS, 2009, IEEE SIGNAL PROC LET, V16, P125, DOI 10.1109/LSP.2008.2008951
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Gao SD, 2019, J REAL-TIME IMAGE PR, V16, P741, DOI 10.1007/s11554-019-00860-3
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Ker AD, 2008, PROC SPIE, V6819, DOI 10.1117/12.766820
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P810, DOI 10.1109/TIFS.2010.2074195
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pasquini C, 2016, IEEE T INF FOREN SEC, V11, P1425, DOI 10.1109/TIFS.2016.2530636
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shen ZY, 2016, MULTIMED TOOLS APPL, V75, P2327, DOI 10.1007/s11042-014-2407-2
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   *USDA, 2002, NAT RES CONS SERV PH
   Yu X., 2008, PATTERN RECOGN, P1
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 32
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 11
PY 2022
DI 10.1007/s11042-022-12346-9
EA JUL 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2U8AD
UT WOS:000823376500003
DA 2024-07-18
ER

PT J
AU Qureshi, SG
   Shandilya, SK
AF Qureshi, Shahana Gajala
   Shandilya, Shishir Kumar
TI Nature-inspired adaptive decision support system for secured clustering
   in cyber networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Nature-inspired cyber security; Adaptive defense; Nature-inspired
   decision support system; Secure clustering; Optimization
ID WIRELESS; ALGORITHM
AB The Internet of Things (IoT) technology has proved that Wireless Sensor Networks (WSN) is important for all loT application areas. WSN combined with other advanced technologies like Artificial Intelligence (AI) brings automation via the sensing, transmitting, and monitoring steps. However, the cyber threats such as Malware, Distributed Denial of Service Attack (DDoS), and Man in the Middle (MitM), etc. limits the potential of such networks. Several security methods were introduced in last decade to protect the WSN from various cyber threats; however. due to resource-constrained sensor nodes, designing the energy-efficient security algorithm for WSN is a widely studied research problem. In the proposed work, a novel Nature-inspired Decision Support System for Secure Clustering (NIDSC) is proposed to overcome the security issues with minimum resource consumptions and computational overhead. In NIDSC, a hybrid trust model is designed to evaluate each sensor node before selecting Cluster Head (CH) by measuring various sensor node parameters, to achieve a reliable decision support system which classifies each node as either legitimate or attacker. Later, the proposed decision support system along with clustering optimization is formulated for CH selection using a natural evolution-based hybrid trust model. Due to its fast convergence over other optimization algorithms, the nature-inspired Differential Evolution (DE) algorithm is used to perform Decision Support System (DSS) for optimal and secure WSN clustering. The proposed method is a lightweight trust-based decision-making method for Quality of Service (QoS) clustering to establish secure data transmission in intra-cluster and/or inter-cluster communication. The simulation is carried out to analyze and compare the performance of the proposed method with the existing works such as Low Energy Adaptive Clustering flierarchy(LEACH), Trust Management System (TMS), and Energy-efficient Trusted Moth Flame Optimization and Genetic Algorithm based clustering algorithm(eeTMFO/GA). The comparisons were mainly focused on throughput, Packet Delivery Ratio (PDR), delay, communication overhead, and energy consumption to validate the performance of the proposed method. The experimental results found that the proposed method has got improved throughput value (similar to 3 kbps), improved PDR (similar to 4%), minimum delay (similar to 0.01 seconds), less communication overhead (similar to 0.75 ms. and less energy consumption (similar to 0.003 joules) as compared to the existing methods on various testcase scenarios.
C1 [Qureshi, Shahana Gajala; Shandilya, Shishir Kumar] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
C3 VIT Bhopal University
RP Shandilya, SK (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal, India.
EM shahana.gajala2018@vitbhopal.ac.in; shishir.sam@gmail.com
RI qureshi, shahana/JPL-4698-2023; Shandilya, Dr. Shishir Kumar/V-1584-2019
OI Shandilya, Dr. Shishir Kumar/0000-0002-3308-4445
CR [Anonymous], 2013, INT J EMERG TECHNOL
   Bagci H, 2010, IEEE INT CONF FUZZY
   Cho JH, 2011, IEEE COMMUN SURV TUT, V13, P562, DOI 10.1109/SURV.2011.092110.00088
   Dahane A, 2015, IFIP ADV INF COMM TE, V456, P429, DOI 10.1007/978-3-319-19578-0_35
   Deepa SR, 2001, IET NETW
   Elhoseny M, 2019, STUD SYST DECIS CONT, V165, P115, DOI 10.1007/978-3-319-92807-4_6
   Enami Neda, 2010, Proceedings of the 5th International Conference on Computer Sciences and Convergence Information Technology (ICCIT 2010), P40, DOI 10.1109/ICCIT.2010.5711026
   Geetha V., 2014, Wireless Sensor Network, V6, P173, DOI DOI 10.4236/WSN.2014.69017
   Gilbert EPK, 2019, INT J BIO-INSPIR COM, V14, P103
   Guo William W., 2012, Journal of Networks, V7, P1592, DOI 10.4304/jnw.7.10.1592-1599
   He T., 2004, PROC ACM INT C MOBIL, P270, DOI DOI 10.1145/990064.990096
   Heinzelman WR, 2000, P 33 ANN HAW INT C S, V2, P10
   Hoang D, 2010, 2010 IEEE INT C COMM, P1
   John J, 2019, MOBILE NETW APPL, V24, P1509, DOI 10.1007/s11036-019-01271-1
   Juliana R, 2016, WIRELESS PERS COMMUN, V89, P351, DOI 10.1007/s11277-016-3269-x
   Kuila P, 2014, APPL SOFT COMPUT, V25, P414, DOI 10.1016/j.asoc.2014.08.064
   Mahajan S., 2016, INT J ADV RES COMPUT, V7, P198
   Mallick C., 2018, INT J COMPUTER APPL, V179, P42, DOI DOI 10.5120/IJCA2018916667
   Mao Song, 2011, Journal of China Universities of Posts and Telecommunications, V18, P89, DOI 10.1016/S1005-8885(10)60126-4
   Mittal N, 2019, WIRELESS PERS COMMUN, V104, P677, DOI 10.1007/s11277-018-6043-4
   Mugheri AA., 2018, Sukkur IBA Journal of Computing and Mathematical Sciences, V2, P52, DOI DOI 10.30537/SJCMS.V2I1.69
   Nimbalkar N. B., 2015, INT J COMPUTER APPL, V112, P30
   Pavani M, 2019, IET WIREL SENS SYST, V9, P274, DOI 10.1049/iet-wss.2018.5227
   Qureshi SG, 2022, WIRELESS PERS COMMUN, V127, P577, DOI 10.1007/s11277-021-08352-z
   Qureshi SS, 2021, J MATER SCI-MATER EL, P1
   Ramesh S, 2020, MULTIMED TOOLS APPL, V79, P10157, DOI 10.1007/s11042-019-7585-5
   Rehman E, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/1630673
   Sahoo RR, 2013, PROC TECH, V10, P515, DOI 10.1016/j.protcy.2013.12.390
   Sahoo RR, 2013, INT C TREND COMPUT C, P532, DOI 10.1109/ICE-CCN.2013.6528557
   Shandilya S.K, 2019, INT C HYBR INT SYST, P268
   Sharawi M., 2016, NATURE INSPIRED COMP, P111
   Sharma R., 2019, SYSTEM PERFORMANCE M, P259, DOI [10.1007/978-981-10-7323-6_22, DOI 10.1007/978-981-10-7323-6_22]
   Sharma R, 2020, TELECOMMUN SYST, V74, P253, DOI 10.1007/s11235-020-00654-0
   Sharma R, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P365, DOI [10.1109/CONFLUENCE.2019.8776618, 10.1109/confluence.2019.8776618]
   Singh A, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100342
   Subramanian P, 2020, WIRELESS PERS COMMUN, V113, P905, DOI 10.1007/s11277-020-07259-5
   Tolba FD, 2013, IEEE SENSOR, P1731
   Umar IA, 2017, IEEE ACCESS, V5, P2550, DOI 10.1109/ACCESS.2017.2672827
   Wang TS, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3815834
   Wang WC, 2009, 2009 5TH INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND MOBILE COMPUTING, VOLS 1-8, P3330
   Yilmaz O, 2012, COMPUT MATH APPL, V63, P48, DOI 10.1016/j.camwa.2011.10.070
   Zhang WB, 2017, IEEE ACCESS, V5, P1702, DOI 10.1109/ACCESS.2017.2666818
NR 42
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUL 6
PY 2022
DI 10.1007/s11042-022-13336-7
EA JUL 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2W9MD
UT WOS:000824839400003
DA 2024-07-18
ER

PT J
AU Liu, XY
   Hao, CY
   Su, ZZ
   Qi, ZR
   Fu, SJ
   Li, YL
   Han, HB
AF Liu, Xuya
   Hao, Caiyan
   Su, Zezhao
   Qi, Zerong
   Fu, Shujun
   Li, Yuliang
   Han, Hongbin
TI Image inpainting algorithm based on tensor decomposition and weighted
   nuclear norm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Low-rank approximation; Nonlocal similarity; Tensor
   completion; Tensor ring decomposition
ID MATRIX COMPLETION
AB For a damaged image, recovering an image with missing entire rows or columns is a challenging problem arising in many real applications, such as digital image inpainting. For this kind of information missing situation, the diffusion-based inpainting methods are tend to produce blur, the exemplar-based methods are prone to error filling and the neural network-based methods are highly dependent on data. Many existing approaches formulate this problem as a general low-rank matrix approximate one which cannot handle this special structural missing very well. In this paper, we propose a novel image inpainting algorithm named nonlocal low-rank tensor completion (NLLRTC) based on the nonlocal self-similarity prior and the low-rank prior. By using the nonlocal self-similarity of image patches, we directly stack these patches into a three-dimensional similar tensor instead of pulling them into column vectors, then the similar tensor can be completed by tensor ring (TR) decomposition. By leveraging the alternating direction method under the augmented Lagrangian multiplier framework, the optimization results can be obtained. Moreover, a weighted nuclear norm is added to the tensor completion model to achieve better inpainting performance, which we call weighted nonlocal low-rank tensor completion (WNLLRTC) algorithm. Our empirical studies show encouraging results on both quantitative assessment and visual interpretation of our proposed methods in comparison to some state-of-the-art algorithms.
C1 [Liu, Xuya] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Peoples R China.
   [Hao, Caiyan] Qingdao Hiimage Technol Co Ltd, Qingdao 266000, Peoples R China.
   [Su, Zezhao] Guangdong Technion Israel Inst Technol, Shantou 515063, Peoples R China.
   [Qi, Zerong] Shandong Chengshi Elect Technol Ltd Co, Jinan 250031, Peoples R China.
   [Fu, Shujun] Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
   [Li, Yuliang] Shandong Univ, Dept Intervent Med, Hosp 2, Jinan 250100, Peoples R China.
   [Han, Hongbin] Peking Univ Third Hosp, Dept Radiol, Beijing 100089, Peoples R China.
   [Han, Hongbin] Beijing Key Lab Magnet Resonance Imaging Equipmen, Beijing 100089, Peoples R China.
C3 Shandong Jianzhu University; Guangdong Technion Israel Institute of
   Technology; Shandong University; Shandong University
RP Fu, SJ (corresponding author), Shandong Univ, Sch Math, Jinan 250100, Peoples R China.
EM shujunfu@163.com
RI LI, Yuliang/AAR-8943-2021
OI LI, Yuliang/0000-0003-2189-6849
FU National Natural Science Foundation of China [12071263, 61671276,
   11971269]; Natural Science Foundation of Shandong Province of China
   [ZR2019MF045]; National Science Fund for Distinguished Young Scholars
   [61625102]
FX The research has been supported in part by the National Natural Science
   Foundation of China (12071263, 61671276, 11971269), the Natural Science
   Foundation of Shandong Province of China (ZR2019MF045), and the National
   Science Fund for Distinguished Young Scholars (61625102).
CR Barnes Connelly, 2017, [Computational Visual Media, 计算可视媒体], V3, P3
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daisy M, 2014, IEEE IMAGE PROC, P4622, DOI 10.1109/ICIP.2014.7025937
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   He LT, 2014, IEEE T IMAGE PROCESS, V23, P5470, DOI 10.1109/TIP.2014.2362051
   Hillar CJ, 2013, J ACM, V60, DOI 10.1145/2512329
   Hu SM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508381
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Komodakis N., 2006, 2006 IEEE COMP SOC C
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li F, 2014, IEEE T IMAGE PROCESS, V23, P4242, DOI 10.1109/TIP.2014.2346030
   Li W, 2015, COMPUT GRAPH FORUM, V34, P111, DOI 10.1111/cgf.12521
   Lin, 2010, ARXIV10095055
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Luo SJ, 2015, IEEE T VIS COMPUT GR, V21, P56, DOI 10.1109/TVCG.2014.2327979
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   Steck H., 2010, TRAINING TESTING REC, P713, DOI 10.1145/1835804.1835895
   Toh KC, 2010, PAC J OPTIM, V6, P615
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wen ZW, 2012, MATH PROGRAM COMPUT, V4, P333, DOI 10.1007/s12532-012-0044-1
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yuan LH, 2019, AAAI CONF ARTIF INTE, P9151
   Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x
   Zhao Q., 2016, Tensor Ring Decomposition
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
NR 45
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3433
EP 3458
DI 10.1007/s11042-022-12635-3
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000820945600001
DA 2024-07-18
ER

PT J
AU Jarjar, M
   Hraoui, S
   Najah, S
   Zenkouar, K
AF Jarjar, Mohamed
   Hraoui, Said
   Najah, Said
   Zenkouar, Khalid
TI New technology of color image encryption based on chaos and two improved
   Vigenere steps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vigenere grid; Broadcast function; Chaotic map; Encryption function;
   S-box
ID ALGORITHM
AB This article traces the development trajectory of the new cryptographic system using two circuits provided by the profound improvement of the traditional Vigenere technology. This new method uses several dynamic permutation matrices attached to the advanced chaotic permutation function. Explain its structure and definition in detail. The first round will modify the first bootloader block by intervening the initial value calculated from the original image, and will be infected by all the chaotic maps used to overcome the problem of uniform color images, and then restore our new depth advanced Vigenere technology. The second round will recalculate new initialization values based on the obtained encrypted image and the generated chaotic map. The last round will focus on the introduction of the new replacement matrix, in which strong links will be implemented, strong propagation will be achieved, and encrypted blocks will be linked with subsequent transparent blocks to eliminate any differential attacks. Simulations performed on a large number of images of different sizes and formats showed encouraging results and confirmed that this method is not affected by known attacks.
C1 [Jarjar, Mohamed; Najah, Said; Zenkouar, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab SIA, Fes, Morocco.
   [Hraoui, Said] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, LIASSE, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Jarjar, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab SIA, Fes, Morocco.
EM jarjar.moharned@gmail.com; said.hraoui@usmba.ac.ma;
   saidnajah@usmba.ac.ma; khalid.zenkouar@yahoo.fr
RI HRAOUI, Said/ABD-3324-2021
CR Ali SMA, 2019, NOVEL ENCRYPTION ALG, V80
   [Anonymous], 2016, 2016 10 INT C TELECO
   [Anonymous], 2010, IJ NETWORK SECURITY
   Boussif M, 2020, IET IMAGE PROCESS, V14, P1209, DOI 10.1049/iet-ipr.2019.0042
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ge RJ, 2019, IEEE ACCESS, V7, P99470, DOI 10.1109/ACCESS.2019.2927415
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Hraoui S, 2013, 2013 ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS (AICCSA)
   Jarjar A, 2017, INT J STAT APPL MATH, V2
   JarJar M., 2019, P COMPUT SCI, V00, P000
   Kester Q-A., 2012, INT J ADV RES COMPUT, V1
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Patidar U, 2011, UD OPTICS COMMUNICAT, V254, P4331
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Peng J, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P492, DOI 10.1109/ICCCAS.2002.1180666
   Reddy VVK, 2018, INT J PURE APPL MATH, V118
   Saputra I, 2017, INT J ENG RES TECHNO, V6
   Shah A., 2016, INT J COMPUT APPL, V136, P0975
   Sum F., 2008, CHAOS SOLUTION FRACT, V3, P631
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 28
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24665
EP 24689
DI 10.1007/s11042-022-12750-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000820167600051
DA 2024-07-18
ER

PT J
AU Sharma, S
   Zou, JJ
   Fang, G
AF Sharma, Sunpreet
   Zou, Ju Jia
   Fang, Gu
TI A dual watermarking scheme for identity protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image authentication; Copyright protection; Cybersecurity; DWT-DCT;
   Halftone; Identity protection; Watermark
ID IMAGE WATERMARKING; SIGNIFICANT DIFFERENCE; BLIND WATERMARKING; ROBUST;
   DCT; AUTHENTICATION; DOMAIN; SVD; FRAMEWORK
AB A novel dual watermarking scheme with potential applications in identity protection, media integrity maintenance and copyright protection in both electronic and printed media is presented. The proposed watermarking scheme uses the owner's signature and fingerprint as watermarks through which the ownership and validity of the media can be proven and kept intact. To begin with, the proposed watermarking scheme is implemented on continuous-tone/greyscale images, and later extended to images achieved via multitoning, an advanced version of halftoning-based printing. The proposed watermark embedding is robust and imperceptible. Experimental simulations and evaluations of the proposed method show excellent results from both objective and subjective view-points.
C1 [Sharma, Sunpreet; Zou, Ju Jia; Fang, Gu] Western Sydney Univ, Sch Engn Design & Built Environm, Locked Bag 1797, Penrith, NSW 2751, Australia.
C3 Western Sydney University
RP Sharma, S (corresponding author), Western Sydney Univ, Sch Engn Design & Built Environm, Locked Bag 1797, Penrith, NSW 2751, Australia.
EM 18547232@student.westernsydney.edu.au
RI Fang, Gu/HGU-6004-2022
OI sharma, Sunpreet/0000-0002-3185-6149
FU Western Sydney University Postgraduate Research Award
FX This work is supported by the Western Sydney University Postgraduate
   Research Award. The authors are thankful to the anonymous reviewers for
   their helpful comments and suggestions. They would like to thanks Dr.
   Campbell Aitken and Jessica Johnston for proofreading this work.
CR Ali M, 2014, SIGNAL PROCESS, V94, P545, DOI 10.1016/j.sigpro.2013.07.024
   [Anonymous], VACCINE CERTIFICATES
   [Anonymous], NATIONS LARGEST EVER
   [Anonymous], NCC CALCULATIONS MAT
   [Anonymous], SERVICE NSW CYBER IN
   [Anonymous], AIRPORT DELAYS SUBSI
   [Anonymous], FAKE COVID 19 PASSPO
   [Anonymous], WATERLOO FRACTAL COD
   [Anonymous], CVG-UGR-Image Database
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Barr M, 2020, IET IMAGE PROCESS, V14, P697, DOI 10.1049/iet-ipr.2018.5868
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Bertini F, 2020, ARXIV 200603903
   Bhowmik D, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3357333
   Bobkowska K, 2019, IET IMAGE PROCESS, V13, P2516, DOI 10.1049/iet-ipr.2019.0072
   Chan YH, 2020, IEEE T IMAGE PROCESS, V29, P859, DOI 10.1109/TIP.2019.2936097
   Chen YY, 2018, MULTIMED TOOLS APPL, V77, P8019, DOI 10.1007/s11042-017-4697-7
   Ernawan F, 2021, IEEE ACCESS, V9, P45474, DOI 10.1109/ACCESS.2021.3067245
   Gonzalez R, 2013, DIGITAL IMAGE PROCES
   Guo J. M., 2019, ECTI T COMPUTER INFO, P1
   Guo JM, 2018, ASIAPAC SIGN INFO PR, P1113, DOI 10.23919/APSIPA.2018.8659686
   Guo JM, 2010, IEEE MULTIMEDIA, V17, P34
   Haddada LR, 2017, SIGNAL PROCESS-IMAGE, V55, P23, DOI 10.1016/j.image.2017.03.008
   Hosny KM, 2021, IEEE ACCESS, V9, P91209, DOI 10.1109/ACCESS.2021.3091614
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Hurrah NN, 2019, AD HOC NETW, V95, DOI 10.1016/j.adhoc.2019.101989
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Koley S, 2021, MULTIMED TOOLS APPL, V80, P6755, DOI 10.1007/s11042-020-09918-y
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Lee HL, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/4901609
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Liu YF, 2016, IEEE T IMAGE PROCESS, V25, P2971, DOI 10.1109/TIP.2016.2552723
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Mahto DK, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107255
   Meerwald P, 2009, IEEE T MULTIMEDIA, V11, P1037, DOI 10.1109/TMM.2009.2021793
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Sarailidis G, 2012, IEEE T IMAGE PROCESS, V21, P2693, DOI 10.1109/TIP.2012.2185936
   Shariff SM, 2020, INT CONF UBIQUIT INF, DOI [10.1109/imcom48794.2020.9001724, 10.1109/NILES50944.2020.9257978]
   Sharma S, 2020, ELECTRON LETT, V56, P923, DOI 10.1049/el.2020.1445
   Sharma S, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING RESEARCH & PRACTICE (ICEERP-2019), P48, DOI 10.1109/iceerp49088.2019.8956998
   Sharma S, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P1388, DOI 10.1109/TENCON.2016.7848242
   Sharma Y, 2020, IEEE T SUST COMPUT
   Sharma Y, 2017, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD COMPUTING (UCC' 17), P57, DOI 10.1145/3147213.3147218
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Ulichney R., 1987, DIGITAL HALFTONING
   van der Schyff K, 2020, COMPUT SECUR, V94, DOI 10.1016/j.cose.2020.101822
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Xu Y., 2019, ELECT IMAGING, V2019, P526
   Yamni M, 2022, DIGIT SIGNAL PROCESS, V120, DOI 10.1016/j.dsp.2021.103251
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 64
TC 14
Z9 14
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2207
EP 2236
DI 10.1007/s11042-022-13207-1
EA JUN 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000813560900002
PM 35755622
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chen, B
   Yin, XL
   Lu, W
   Ren, HL
AF Chen, Bing
   Yin, Xiaolin
   Lu, Wei
   Ren, Honglin
TI Reversible data hiding in encrypted domain by signal reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Signal reconstruction; Lossless recovery;
   Homomorphism
ID PUBLIC-KEY CRYPTOGRAPHY; IMAGES; DIFFERENCE
AB In this paper, a model of reversible data hiding in encrypted domain (RDH-ED) based on signal reconstruction is presented, in which homomorphic encryption is introduced to reconstruct the encrypted signal generated by non-expansible symmetric encryption (NSE). In this way, NSE guarantees the security of the original signal, homomorphic encryption with short-bit key is performed in signal reconstruction. Since the reconstructed encrypted signal is homomorphic, data hiding can be facilely achieved by using homomorphism. According to the proposed model, both homomorphic symmetric encryption and homomorphic public-key encryption can be adopted to reconstruct NSE-based signal. Meanwhile, homomorphism is not limited to additive homomorphism, and multiplicative homomorphism is also applicable. In addition, two RDH-ED methods using symmetric multiplication homomorphism and public-key addition homomorphism are devised, respectively. Experimental results are demonstrated to illustrate the superiority of the proposed methods.
C1 [Chen, Bing] Guangdong Polytech Normal Univ, Sch Cyber Secur, Guangzhou 510665, Peoples R China.
   [Chen, Bing; Yin, Xiaolin; Lu, Wei; Ren, Honglin] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Prov Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
C3 Guangdong Polytechnic Normal University; Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Prov Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
EM chenbing@gpnu.edu.cn; yinx16@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   renhlin@mail2.sysu.edu.cn
RI hu, xin/KHT-2406-2024; ren, honglin/IWD-4761-2023
OI Ren, Honglin/0000-0002-2096-1744; Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [62102101, U2001202,
   62072480]; Doctoral Scientific Research Foundation of Guangdong
   Polytechnic Normal University [2021SDKYA101]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62102101, No. U2001202, No. 62072480), the Doctoral
   Scientific Research Foundation of Guangdong Polytechnic Normal
   University (No. 2021SDKYA101).
CR [Anonymous], USC SIPI IMAGE DATAB
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen B, 2019, SIGNAL PROCESS, V164, P48, DOI 10.1016/j.sigpro.2019.05.036
   Chen B, 2018, J VIS COMMUN IMAGE R, V57, P272, DOI 10.1016/j.jvcir.2018.11.017
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Di FQ, 2018, LECT NOTE DATA ENG, V6, P138, DOI 10.1007/978-3-319-59463-7_14
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kipnis A., 2012, IACR Cryptol. ePrint Arch, V2012, P637
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang XF, 2017, MULTIMED TOOLS APPL, V76, P6127, DOI 10.1007/s11042-016-3288-3
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu HT, 2019, IEEE ACCESS, V7, P62361, DOI 10.1109/ACCESS.2019.2916355
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 26
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1203
EP 1222
DI 10.1007/s11042-022-13266-4
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800002
DA 2024-07-18
ER

PT J
AU Singh, KM
   Singh, LD
   Tuithung, T
AF Singh, Khoirom Motilal
   Singh, Laiphrakpam Dolendro
   Tuithung, Themrichon
TI Improvement of image transmission using chaotic system and elliptic
   curve cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arnold's cat map; Elliptic curve cryptosystem; Image encryption; Pixel
   grouping
ID ENCRYPTION; CRYPTANALYSIS; COMBINATION
AB Recently, an encryption scheme (Abdelfatah IEEE Access 8:3875-3890, 2020) based on chaotic and enhanced elliptic curve cryptography was proposed. The author uses a pixel grouping method as an essential stage for the entire encryption scheme. This Pixel grouping method is carried out so that the execution speed is enhanced. However, there exists a condition during the pixel grouping stage that makes the method futile while decrypting. Upon pixel grouping, if the large integer turns out to be equal or larger than the modulo prime parameter P of the elliptic curve, precise decrypted values cannot be obtained. In this paper, the flaw is avoided by using the inverse modulo operator if the large integer is greater than or equal to P. Experimental analysis to prove the conditions is shown in this paper. Moreover, a new method is added to circumvent such conditions.
C1 [Singh, Khoirom Motilal; Tuithung, Themrichon] Natl Inst Technol Nagaland, Dept Comp Sci & Engn, Dimapur, India.
   [Singh, Laiphrakpam Dolendro] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, India.
   [Singh, Khoirom Motilal] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland; National Institute of Technology (NIT System);
   National Institute of Technology Silchar; Koneru Lakshmaiah Education
   Foundation (K L Deemed to be University)
RP Singh, KM (corresponding author), Natl Inst Technol Nagaland, Dept Comp Sci & Engn, Dimapur, India.; Singh, KM (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram, AP, India.
EM khmotilal@gmail.com; ldsingh.cse@gmail.com; t_tuithung@yahoo.com
RI Laiphrakpam, Dolendro Singh/L-1072-2016; Motilal Singh,
   Khoirom/AGW-9205-2022
OI Motilal Singh, Khoirom/0000-0001-6034-9050
CR Abdelfatah RI, 2020, IEEE ACCESS, V8, P3875, DOI 10.1109/ACCESS.2019.2958336
   [Anonymous], USC SIPI IMAGE DATAB
   [Anonymous], ELLIPTIC CURVE PARAM
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li Z, 2018, NONLINEAR DYNAM, V94, P1319, DOI 10.1007/s11071-018-4426-4
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Liu LD, 2019, IEEE ACCESS, V7, P126450, DOI 10.1109/ACCESS.2019.2938181
   Liu Y, 2019, IEEE ACCESS, V7, P74070, DOI 10.1109/ACCESS.2019.2916600
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Shafique A, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12138-3
   Singh KM, 2018, OPTIK, V168, P370, DOI 10.1016/j.ijleo.2018.04.068
   Singh KM., 2020, RECENT PATENTS ENG, V14, P1, DOI [10.2174/187221211401200513085214, DOI 10.2174/187221211401200513085214]
   Tawalbeh L, 2013, IET INFORM SECUR, V7, P67, DOI 10.1049/iet-ifs.2012.0147
   Vanstone SA, 2003, COMPUT SECUR, V22, P412, DOI 10.1016/S0167-4048(03)00507-8
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Washington LC., 2008, ELLIPTIC CURVES NUMB, DOI DOI 10.1201/9781420071474
   Wolfram Library Archive, ADV ENCRYPTION STAND
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zefreh EZ, 2020, MULTIMED TOOLS APPL, V79, P24993, DOI 10.1007/s11042-020-09111-1
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P13841, DOI 10.1007/s11042-020-10437-z
   Zhang XQ, 2018, IEEE ACCESS, V6, P70025, DOI 10.1109/ACCESS.2018.2879844
NR 31
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1149
EP 1170
DI 10.1007/s11042-022-13253-9
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800007
DA 2024-07-18
ER

PT J
AU Abada, L
   Aouat, S
AF Abada, Lyes
   Aouat, Saliha
TI Improved photometric stereo based on local search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photometric stereo; 3D reconstruction; Local search; Non-Lambertian;
   General isotropic reflectance; BRDF
ID SHAPE; NETWORK
AB Photometric stereo methods seek to reconstruct 3D objects using multiple images captured under varied illumination directions. Nevertheless, shadows are still among the most significant problems faced by the photometric stereo and most of the existing formulations disregard this problem although the elimination of shadow greatly improves the results. Usually, authors define empirically a threshold to eliminate pixels that have low brightness. Accordingly, in this paper we present an improved approach to enhance the photometric stereo. Our aim consists to propose an improved formulation for solving the shadow problem and determine the optimal solution. In order to define the threshold value used to solve the shadow problem, we propose an improvement of an existing formulation. Our formulation normalizes the error rate with respect to the threshold, which makes it possible to compare the error rates of a different threshold values. A second contribution consists to find the optimal solution of the normal vectors by adapting the local search method "Tabu search meta-heuristic" to find the optimal solution in the neighborhood of the initial solution. We perform several tests on real objects of different complexity with different parameters values. In order to show the effectiveness of our proposal, a number of comparisons with recent published methods are made. Through these experiments, we show that our proposed method outperforms modern near-field photometric stereo approaches in terms of quality and application that does not require manual intervention.
C1 [Abada, Lyes; Aouat, Saliha] Univ Sci & Technol USTHB, Artifcial Intelligence Lab LRIA Comp Sci Dept, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Abada, L (corresponding author), Univ Sci & Technol USTHB, Artifcial Intelligence Lab LRIA Comp Sci Dept, Algiers, Algeria.
EM labada@usthb.dz; saouat@usthb.dz
RI abada, lyes/J-5274-2017
OI abada, lyes/0000-0001-8105-2352
FU Directorate General for Scientific Research and Technological
   Development [C0662300]
FX Directorate General for Scientific Research and Technological
   Development, Grant/Award Number: C0662300.
CR Abada Lyes, 2016, International Journal of Advanced Intelligence Paradigms, V8, P3
   Abada Lyes, 2013, 2013 Science and Information Conference (SAI), P416
   Abada L, 2014, INTELLIGENT SYSTEMS, P369
   Abada L, 2017, FRONT COMPUT SCI-CHI, V11, P320, DOI 10.1007/s11704-016-5255-6
   Abada L, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015500359
   Alldrin N, 2008, PROC CVPR IEEE, P2447
   Blinn J.F., 1977, P 4 ANN C COMP GRAPH
   Chen GY, 2019, PROC CVPR IEEE, P8731, DOI 10.1109/CVPR.2019.00894
   Chen GY, 2018, LECT NOTES COMPUT SC, V11213, P3, DOI 10.1007/978-3-030-01240-3_1
   Chen LX, 2021, IEEE T PATTERN ANAL, V43, P48, DOI 10.1109/TPAMI.2019.2927909
   Cho D, 2020, IEEE T PATTERN ANAL, V42, P232, DOI 10.1109/TPAMI.2018.2873295
   Cho D, 2016, LECT NOTES COMPUT SC, V9906, P170, DOI 10.1007/978-3-319-46475-6_11
   Cook R. L., 1982, ACM T GRAPHIC, V1, P7, DOI DOI 10.1145/357290.357293
   Goldman DB, 2010, IEEE T PATTERN ANAL, V32, P1060, DOI 10.1109/TPAMI.2009.102
   Guanying Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P745, DOI 10.1007/978-3-030-58568-6_44
   HAYAKAWA H, 1994, J OPT SOC AM A, V11, P3079, DOI 10.1364/JOSAA.11.003079
   Higo T, 2010, PROC CVPR IEEE, P1157, DOI 10.1109/CVPR.2010.5540084
   Horn B K P, 1970, Tech. Rep.
   Hui Z, 2017, IEEE T PATTERN ANAL, V39, P2060, DOI 10.1109/TPAMI.2016.2623613
   Ikehata S, 2014, PROC CVPR IEEE, P2187, DOI 10.1109/CVPR.2014.280
   Ikehata S, 2012, PROC CVPR IEEE, P318, DOI 10.1109/CVPR.2012.6247691
   Ju YK, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107162
   Ju YK, 2020, NEUROCOMPUTING, V375, P62, DOI 10.1016/j.neucom.2019.09.084
   Li M, 2020, FRONT INFORM TECH EL, V21, P1191, DOI 10.1631/FITEE.1900156
   Liang W, 2021, MULTIMED TOOLS APPL, V80, P29617, DOI 10.1007/s11042-021-11137-y
   Lu F, 2018, IEEE T PATTERN ANAL, V40, P221, DOI 10.1109/TPAMI.2017.2655525
   Matsushita Y, 2020, COMPUTER VISION REFE, P14
   Mecca R, 2016, SIAM J IMAGING SCI, V9, P1858, DOI 10.1137/16M1068177
   Miyazaki D, 2010, IEEE IMAGE PROC, P4057, DOI 10.1109/ICIP.2010.5650067
   Ouyang WB, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043031
   ROUY E, 1992, SIAM J NUMER ANAL, V29, P867, DOI 10.1137/0729053
   Santo H, 2017, IEEE INT CONF COMP V, P501, DOI 10.1109/ICCVW.2017.66
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P17303, DOI 10.1007/s11042-020-08688-x
   Shi BX, 2019, IEEE T PATTERN ANAL, V41, P271, DOI 10.1109/TPAMI.2018.2799222
   Shi BX, 2016, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2016.403
   Shi BX, 2014, IEEE T PATTERN ANAL, V36, P1078, DOI 10.1109/TPAMI.2013.196
   Shi BX, 2012, PROC CVPR IEEE, P230, DOI 10.1109/CVPR.2012.6247680
   Shin S, 2018, IEEE HAPTICS SYM, P262, DOI 10.1109/HAPTICS.2018.8357186
   Sun YJ, 2016, NEUROCOMPUTING, V207, P95, DOI 10.1016/j.neucom.2016.03.064
   Takechi K, 2017, IEEE IMAGE PROC, P2632, DOI 10.1109/ICIP.2017.8296759
   Taniai T, 2018, PR MACH LEARN RES, V80
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136
   Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55
   Xie XL, 2020, MULTIMED TOOLS APPL, V79, P9565, DOI 10.1007/s11042-019-08034-w
   Yu C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216261
   Yuan JF, 2021, MULTIMED TOOLS APPL, V80, P19491, DOI 10.1007/s11042-021-10615-7
   Zhang T, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2019.163802
   Zheng Q, 2020, Virtual Real. Intell. Hardw, V2, P213
   Zheng Q, 2019, IEEE T IMAGE PROCESS, V28, P3177, DOI 10.1109/TIP.2019.2894963
NR 50
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31181
EP 31195
DI 10.1007/s11042-022-13205-3
EA JUN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000807318300008
DA 2024-07-18
ER

PT J
AU Li, JQ
   Wang, J
   Di, XQ
AF Li, Jinqing
   Wang, Jia
   Di, Xiaoqiang
TI Image encryption algorithm based on bit-level permutation and
   "Feistel-like network" diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaotic system; Bit-level plane; Feistel-like network; Image
   encryption
ID CHAOTIC SYSTEM; SCHEME; MAP; DESIGN
AB This paper proposes a bit-level image encryption algorithm based on six-dimensional hyperchaotic system. First, the image is divided into 8 bit-level planes, and the chaotic system is used to sort each bit-level plane. Then, the sorted matrix is sorted again according to the location information set by the user. Finally, the permutation image is divided into two parts, and the image is diffused using the "Feistel-like network". Due to the plaintext correlation of chaotic systems, the algorithm can effectively resist known/selected plaintext attacks. At the same time, the cross-diffusion operation makes the algorithm has better autocorrelation, achieves a better diffusion effect, and has good encryption performance in only one round. Simulation results and performance analysis show that the encryption algorithm is safe and reliable, and is suitable for image encryption.
C1 [Li, Jinqing; Wang, Jia; Di, Xiaoqiang] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Peoples R China.
   [Li, Jinqing; Wang, Jia; Di, Xiaoqiang] Jilin Prov Key Lab Network & Informat Secur, Changchun, Peoples R China.
   [Di, Xiaoqiang] Changchun Univ Sci & Technol, Informat Ctr, Changchun, Peoples R China.
C3 Changchun University of Science & Technology; Changchun University of
   Science & Technology
RP Li, JQ (corresponding author), Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Peoples R China.; Li, JQ (corresponding author), Jilin Prov Key Lab Network & Informat Secur, Changchun, Peoples R China.
EM lijinqing@cust.edu.cn; dixiaoqiang@cust.edu.cn
FU National key Research and Development projects [2018YFB1800303]; Natural
   Science Foundation of Jilin Province [201902 01188JC]; Research on
   teaching reform of higher education in Jilin Province
   [JLLG685520190725093004]
FX This work has been supported by the National key Research and
   Development projects (2018YFB1800303), and the Natural Science
   Foundation of Jilin Province (201902 01188JC), and the Research on
   teaching reform of higher education in Jilin Province
   (JLLG685520190725093004).
CR Akhavan A, 2017, OPTICS LASER TECHNOL
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2020, COMMUN NONLINEAR SCI, P90
   [Anonymous], 2012, J COMPUT INF SYST
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Diab H, 2018, SIGNAL PROCESS, V142, P53, DOI 10.1016/j.sigpro.2017.06.028
   Djimasra F, 2021, MULTIMED TOOLS APPL, V80, P25121, DOI 10.1007/s11042-021-10734-1
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Karawia A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010057
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li TY, 2017, COMPLEXITY, DOI 10.1155/2017/9010251
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu HJ, 2017, IET IMAGE PROCESS, V11, P324, DOI 10.1049/iet-ipr.2016.0040
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500160
   Liu Y, 2016, IET INFORM SECUR, V10, P433, DOI 10.1049/iet-ifs.2015.0024
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Vedral V, 2002, REV MOD PHYS, V74, P197, DOI 10.1103/RevModPhys.74.197
   Wang XY, 2019, OPT LASER ENG, V115, P107, DOI 10.1016/j.optlaseng.2018.11.010
   Wang XY, 2018, OPT LASER ENG, V107, P370, DOI 10.1016/j.optlaseng.2017.06.015
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu Y, 2014, SIGNAL PROCESS, V102, P122, DOI 10.1016/j.sigpro.2014.03.015
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   2019, IEEE ACCESS, VPP, P1
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang X, 2018, IEEE PHOTONICS J, V10, DOI [10.1109/JPHOT.2018.2859257, 10.1109/JPHOT.2018.2818715]
   Zhang Y, 2020, INFORM SCIENCES, V526, P180, DOI 10.1016/j.ins.2020.03.054
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 53
TC 6
Z9 6
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44335
EP 44362
DI 10.1007/s11042-022-12736-z
EA JUN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805063200006
DA 2024-07-18
ER

PT J
AU Satapathy, SK
   Loganathan, D
AF Satapathy, Santosh Kumar
   Loganathan, D.
TI Automated classification of multi-class sleep stages classification
   using polysomnography signals: a nine- layer 1D-convolution neural
   network approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sleep stage classification; Polysomnography signals; Deep learning;
   1D-convolution neural network
ID DECISION-SUPPORT-SYSTEM; EEG SIGNALS; IDENTIFICATION; CHANNEL; FEATURES;
   FUSION; MODEL
AB Sleep disorder diseases have one of the major health issues across the world. To handle this issue the primary step taken by most of the sleep experts is the sleep staging classification. The whole visual inspection process is carried out manually by the sleep experts, which can be a highly time-consumed task and creates a lot of annotation errors due to more human interventions. In this study, we introduce an efficient and robust approach to improve the sleep staging accuracy. In this paper, we proposed an automated deep nine-layer one-dimensional convolution neural network for multi-class sleep staging classification (9 L-1D-CNN-SSC) using polysomnography (PSG) signals. The proposed 9 L-1D-CNN-SSC model comprises eleven layers with learnable parameters: nine convolution layers and two fully connected layers. The main objective of designing such a model is to achieve higher classification accuracy for multiclass sleep stages classifications with reduced learnable parameters. The proposed network architecture is tested on two different subgroups recordings of ISRUC-Sleep datasets namely ISRUC-Sleep subgroup1 (ISR-SG-I), and ISRUC-Sleep subgroup3 (ISR-SG-III). The proposed model is compiled with eight different individual experiments based on a single-channel electroencephalogram (EEG), electrooculogram (EOG), electromyogram (EMG), and combinations of EEG + EOG+ EMG signals. The proposed 9 L-1D-CNN-SSC model achieved the highest classification accuracy of 99.03%, 99.50%, and 99.03% for three to five sleep stages classification, respectively with single-channel of EEG signals, similarly, the model achieved 98.93% for two-state sleep stage classification with EMG signals using the ISR-SG-I dataset. The same model achieved the highest classification accuracy of 98.88%, 98.76%, and 98.67% for three-five sleep stages classification with a single-channel EMG signal, and 99.24% for two-state sleep classification with single-channel EOG using ISR-SG-III dataset. It has been observed that the obtained results from the proposed 9 L-1D-CNN-SSC model give the best classification accuracy performance on multiclass sleep stages classification incomparable to the existing literature works. The developed 9 L-1D-CNN-SSC deep learning architecture is ready for clinical usage with high PSG data.
C1 [Satapathy, Santosh Kumar; Loganathan, D.] Puducherry Technol Univ, Pondicherry, India.
   [Satapathy, Santosh Kumar] Pandit Deendayal Energy Univ, Gandhinagar, India.
C3 Pondicherry Engineering College; Pandit Deendayal Energy University
RP Satapathy, SK (corresponding author), Puducherry Technol Univ, Pondicherry, India.; Satapathy, SK (corresponding author), Pandit Deendayal Energy Univ, Gandhinagar, India.
EM Santosh.Satapathy@sot.pdpu.ac.in
RI Satapathy, Santosh/AGY-1029-2022
CR Abdollahpour M, 2020, IEEE ACCESS, V8, P180618, DOI 10.1109/ACCESS.2020.3027289
   Acharya R, 2005, COMPUT METH PROG BIO, V80, P37, DOI 10.1016/j.cmpb.2005.06.011
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Acharya R, 2010, INT J NEURAL SYST, V20, P509, DOI 10.1142/S0129065710002589
   Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   Alaa T, 2018, ADABOOST CLASSIFIER, DOI [10.13140/RG.2.2.19929.01122, DOI 10.13140/RG.2.2.19929.01122]
   Bajaj V, 2013, COMPUT METH PROG BIO, V112, P320, DOI 10.1016/j.cmpb.2013.07.006
   Banluesombatkul N, 2021, IEEE J BIOMED HEALTH, V25, P1949, DOI 10.1109/JBHI.2020.3037693
   Basha AJ, 2021, J AMB INTEL HUM COMP, V12, P6189, DOI 10.1007/s12652-020-02188-4
   Boashash B, 2016, KNOWL-BASED SYST, V106, P38, DOI 10.1016/j.knosys.2016.05.027
   Chambon S, 2018, IEEE T NEUR SYS REH, V26, P758, DOI 10.1109/TNSRE.2018.2813138
   Chen ZD, 2021, IEEE T NEUR NET LEAR, V32, P348, DOI 10.1109/TNNLS.2020.2978753
   Cooray N, 2019, CLIN NEUROPHYSIOL, V130, P505, DOI 10.1016/j.clinph.2019.01.011
   Cui ZH, 2018, COMPLEXITY, DOI 10.1155/2018/9248410
   Dimitriadis SI, 2018, CLIN NEUROPHYSIOL, V129, P815, DOI 10.1016/j.clinph.2017.12.039
   Diykh M, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105116
   Durmer JS, 2005, SEMIN NEUROL, V25, P117, DOI 10.1055/s-0029-1237117
   Faust O, 2018, COMPUT METH PROG BIO, V161, P1, DOI 10.1016/j.cmpb.2018.04.005
   Fernandez-Blanco E, 2020, SOFT COMPUT, V24, P4067, DOI 10.1007/s00500-019-04174-1
   Fernandez-Varela Isaac, 2018, Multidisciplinary Digital Publishing Institute Proceedings, V2, P1174
   Fraiwan L, 2021, BIOCYBERN BIOMED ENG, V41, P1, DOI [10.1016/j.bbe.2020.11.003, 10.1016/j.bbe.2020.11.0030208-5216/]
   Fraiwan L, 2012, COMPUT METH PROG BIO, V108, P10, DOI 10.1016/j.cmpb.2011.11.005
   Correa AG, 2014, MED ENG PHYS, V36, P244, DOI 10.1016/j.medengphy.2013.07.011
   Gevins Alan S, 1994, U.S. Pat, Patent No. [US5295491A, 5295491]
   Ghimatgar H, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108320
   Guillon A, 2020, INTENS CARE MED, V46, P1897, DOI 10.1007/s00134-020-06170-8
   Güler I, 2005, J NEUROSCI METH, V148, P113, DOI 10.1016/j.jneumeth.2005.04.013
   Güler NF, 2005, EXPERT SYST APPL, V29, P506, DOI 10.1016/j.eswa.2005.04.011
   Hassan AR, 2017, KNOWL-BASED SYST, V128, P115, DOI 10.1016/j.knosys.2017.05.005
   Hassan AR, 2017, COMPUT METH PROG BIO, V140, P201, DOI 10.1016/j.cmpb.2016.12.015
   Hassan AR, 2017, NEUROCOMPUTING, V219, P76, DOI 10.1016/j.neucom.2016.09.011
   Hassan AR, 2016, J NEUROSCI METH, V271, P107, DOI 10.1016/j.jneumeth.2016.07.012
   Hassan AR, 2016, BIOCYBERN BIOMED ENG, V36, P248, DOI 10.1016/j.bbe.2015.11.001
   Hassan AR, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2238, DOI 10.1109/ICACCI.2015.7275950
   Hirshkowitz M, 2004, MED CLIN N AM, V88, P551, DOI 10.1016/j.mcna.2004.01.001
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hori T, 2001, PSYCHIAT CLIN NEUROS, V55, P305
   Hsu YL, 2013, NEUROCOMPUTING, V104, P105, DOI 10.1016/j.neucom.2012.11.003
   Huang CS, 2013, IEEE INT CONF FUZZY, DOI 10.1109/FUZZ-IEEE.2013.6622495
   Hussein R, 2019, CLIN NEUROPHYSIOL, V130, P25, DOI 10.1016/j.clinph.2018.10.010
   Ieracitano C, 2019, NEUROCOMPUTING, V323, P96, DOI 10.1016/j.neucom.2018.09.071
   Imtiaz SA, 2015, IEEE ENG MED BIO, P378, DOI 10.1109/EMBC.2015.7318378
   Jadhav P, 2020, BIOCYBERN BIOMED ENG, V40, P494, DOI 10.1016/j.bbe.2020.01.010
   Jiao ZC, 2018, PATTERN RECOGN, V76, P582, DOI 10.1016/j.patcog.2017.12.002
   Jolliffe I., 2011, International Encyclopedia of Statistical Science, P1094, DOI [DOI 10.1007/978-3-642-04898-2_455, 10.1007/978-3-642-04898-2_455]
   Kalbkhani, 2018, SLEEP STAGES CLASSIF
   Khalighi S, 2016, COMPUT METH PROG BIO, V124, P180, DOI 10.1016/j.cmpb.2015.10.013
   Khalighi S, 2011, IEEE ENG MED BIO, P3306, DOI 10.1109/IEMBS.2011.6090897
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Korkalainen H, 2020, IEEE J BIOMED HEALTH, V24, P2073, DOI 10.1109/JBHI.2019.2951346
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lajnef T, 2015, J NEUROSCI METH, V250, P94, DOI 10.1016/j.jneumeth.2015.01.022
   Li XW, 2019, MED BIOL ENG COMPUT, V57, P1341, DOI 10.1007/s11517-019-01959-2
   Li Y, 2016, NEUROCOMPUTING, V193, P106, DOI 10.1016/j.neucom.2016.01.062
   Lovrek I, 2008, LECT NOTES COMPUT SC, DOI [10.1007/978-3-540-85565-1, DOI 10.1007/978-3-540-85565-1]
   Memar P, 2018, IEEE T NEUR SYS REH, V26, P84, DOI 10.1109/TNSRE.2017.2776149
   Michielli N, 2019, COMPUT BIOL MED, V106, P71, DOI 10.1016/j.compbiomed.2019.01.013
   Mienye Ibomoiye Domor, 2020, Informatics in Medicine Unlocked, V18, P302, DOI 10.1016/j.imu.2020.100307
   Mousavi Z, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.108312
   Nagabushanam P, 2020, SOFT COMPUT, V24, P9981, DOI 10.1007/s00500-019-04515-0
   Najdi S, 2017, IFIP ADV INF COMM TE, V499, P191, DOI 10.1007/978-3-319-56077-9_18
   Nakamura T, 2017, IEEE IJCNN, P4387, DOI 10.1109/IJCNN.2017.7966411
   Nejedly P, 2019, NEUROINFORMATICS, V17, P225, DOI 10.1007/s12021-018-9397-6
   Ogwueleka F., 2020, Int. J. Comput. Appl., V176, P40
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Parrine L, 2014, CURR OPIN PULM MED, V20, P533, DOI 10.1097/MCP.0000000000000100
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Penzel T, 2000, SLEEP MED REV, V4, P131, DOI 10.1053/smrv.1999.0087
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rahman MM, 2018, COMPUT BIOL MED, V102, P211, DOI 10.1016/j.compbiomed.2018.08.022
   Rechtschaffen A., 1968, A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects
   Reynolds CF, 2013, AM J PSYCHIAT, V170, P1099, DOI 10.1176/appi.ajp.2013.13010058
   Rosenberg RS, 2013, J CLIN SLEEP MED, V9, P81, DOI 10.5664/jcsm.2350
   Sanders TH, 2014, IEEE ENG MED BIO, P4579, DOI 10.1109/EMBC.2014.6944643
   Seifpour S, 2018, EXPERT SYST APPL, V104, P277, DOI 10.1016/j.eswa.2018.03.020
   Sen B, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0018-0
   Sharma M, 2018, COMPUT BIOL MED, V98, P58, DOI 10.1016/j.compbiomed.2018.04.025
   Shen HM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174677
   Silveiral T, 2016, SINGLE CHANNEL EEG S
   Simoes H, 2010, ICINCO 2010: PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 3, P128
   Sors A, 2018, BIOMED SIGNAL PROCES, V42, P107, DOI 10.1016/j.bspc.2017.12.001
   Sousa T, 2015, COMPUT BIOL MED, V59, P42, DOI 10.1016/j.compbiomed.2015.01.017
   Sturm I, 2016, J NEUROSCI METH, V274, P141, DOI 10.1016/j.jneumeth.2016.10.008
   Sun CL, 2019, IEEE ACCESS, V7, P109386, DOI 10.1109/ACCESS.2019.2933814
   Sun CL, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab39ca
   Supratak A, 2017, IEEE T NEUR SYS REH, V25, P1998, DOI 10.1109/TNSRE.2017.2721116
   Tagluk ME, 2010, J MED SYST, V34, P717, DOI 10.1007/s10916-009-9286-5
   Tang ZC, 2017, OPTIK, V130, P11, DOI 10.1016/j.ijleo.2016.10.117
   Tripathy RK, 2018, BIOCYBERN BIOMED ENG, V38, P890, DOI 10.1016/j.bbe.2018.05.005
   Tsinalis Orestis, 2016, arXiv
   Tzimourta KD, 2018, Biomed J, V1, DOI [DOI 10.26717/BJSTR.2018.07.001535, 10.26717/BJSTR.2018.07.001535]
   Wan H, 2019, IEEE SYS MAN CYBERN, P3298, DOI 10.1109/SMC.2019.8914215
   Wang QQ, 2019, MED BIOL ENG COMPUT, V57, P1693, DOI 10.1007/s11517-019-01978-z
   Wei LJ, 2017, PROC INT C TOOLS ART, P88, DOI 10.1109/ICTAI.2017.00025
   Xiao SY, 2015, 2015 54TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1222, DOI 10.1109/SICE.2015.7285326
   Yan R, 2019, BIOMED SIGNAL PROCES, V49, P14, DOI 10.1016/j.bspc.2018.10.001
   Yildirim O, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16040599
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang T, 2021, IEEE J BIOMED HEALTH, V25, P577, DOI 10.1109/JBHI.2020.2993644
   Zhang XQ, 2020, SLEEP BREATH, V24, P581, DOI 10.1007/s11325-019-02008-w
   Zhu GH, 2014, IEEE J BIOMED HEALTH, V18, P1813, DOI 10.1109/JBHI.2014.2303991
   Zhu TQ, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17114152
NR 104
TC 8
Z9 9
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8049
EP 8091
DI 10.1007/s11042-022-13195-2
EA MAY 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000800436500001
DA 2024-07-18
ER

PT J
AU Zhang, GK
   Huang, CX
   Jiang, JW
   Xu, WZ
   Chen, JQ
   Xu, XW
AF Zhang, Guokai
   Huang, Chenxi
   Jiang, Jingwen
   Xu, Weizhe
   Chen, Jianqing
   Xu, Xiaowen
TI Denoising of brain magnetic resonance images using a MDB network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain magnetic resonance images; Dilated network; DnCNN; Convolution
   neural network
ID MRI; SEGMENTATION; RICIAN; CNN
AB The denoising of brain magnetic resonance images could be important for the medical image analysis. Many algorithms have been proposed for this task, especially the deep learning ones which show great success compared with the classical image processing algorithms. Though satisfied results it achieve, they may fail to consider the contextual and attentive features during the feature learning process, and those ones could provide essential and complementary information for the feature encoding, and the poor learning of them could hinder the model to achieve a better performance. To address this challenge, in this paper, we propose a multi-dilated block (MDB) which aims to extract more contextual and attentive features during the feature extraction stage. The whole network is based on DnCNN, and the MDB is placed in the middle stage of the network to learn the contextual and attentive representations. Moreover, for improving the similarity between the noisy image and the denoised one from feature-level, we propose a perceptual loss which is able to further boost the performance of the MDB network. To validate the effectiveness of our proposed method, we conduct extensive experiments on the brain magnetic resonance images to compare the peak signal to noise ratio and structural similarity index, and the final experimental results demonstrate that our propose method could predict a higher resolution image compared with other ones.
C1 [Zhang, Guokai] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
   [Huang, Chenxi] Xiamen Univ, Software Sch, Xiamen, Fujian, Peoples R China.
   [Jiang, Jingwen] Shanghai Elect Grp Co Ltd, Technol Transformat Ctr, Cent Acad, Shanghai, Peoples R China.
   [Xu, Weizhe] Tongji Univ, Sch Software Engn, Shanghai, Peoples R China.
   [Chen, Jianqing] Shanghai Jiao Tong Univ, Dept Otolaryngol Head & Neck Surg, Shanghai Peoples Hosp 9, Sch Med, Shanghai, Peoples R China.
   [Xu, Xiaowen] Tongji Univ, Tongji Hosp, Dept Med Imaging, Sch Med, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology; Xiamen University;
   Shanghai Electric; Tongji University; Shanghai Jiao Tong University;
   Tongji University
RP Chen, JQ (corresponding author), Shanghai Jiao Tong Univ, Dept Otolaryngol Head & Neck Surg, Shanghai Peoples Hosp 9, Sch Med, Shanghai, Peoples R China.; Xu, XW (corresponding author), Tongji Univ, Tongji Hosp, Dept Med Imaging, Sch Med, Shanghai, Peoples R China.
EM zhangguokai_01@163.com; chen.christophe@yahoo.com; 1710451@tongji.edu.cn
RI Chen, Jianqing/K-4471-2012; Cao, Lei/KIA-4940-2024; Jiang, Jing
   wen/AAP-5996-2021; Huang, Chenxi/AAC-6316-2019
OI Wu, Xue-ting/0000-0001-9708-9491
CR Ali HM, 2018, HIGH RESOLUTION NEUR, V14
   [Anonymous], CoRR abs/1511.07122
   Ashtari M, 2005, AM J NEURORADIOL, V26, P1461
   Balafar MA, 2010, ARTIF INTELL REV, V33, P261, DOI 10.1007/s10462-010-9155-0
   Baselice F, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0319-x
   Bhujle HV, 2019, BIOMED SIGNAL PROCES, V47, P252, DOI 10.1016/j.bspc.2018.08.031
   Bhujle HV, 2013, MAGN RESON IMAGING, V31, P1599, DOI 10.1016/j.mri.2013.07.001
   Borges P, 2019, LECT NOTES COMPUT SC, V11827, P100, DOI 10.1007/978-3-030-32778-1_11
   Chang YN, 2015, BIO-MED MATER ENG, V26, pS1275, DOI 10.3233/BME-151425
   Golshan HM, 2015, IEEE ACM T COMPUT BI, V12, P861, DOI 10.1109/TCBB.2014.2344675
   GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Han X, 2007, IEEE T MED IMAGING, V26, P479, DOI 10.1109/TMI.2007.893282
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Kandhway K, 2008, TENCON IEEE REGION, P18
   Kingma D. P., 2014, arXiv
   Li SQ, 2020, MAGN RESON IMAGING, V71, P55, DOI 10.1016/j.mri.2020.04.006
   Liu C, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/232389
   Ma J, 2007, IEEE T IMAGE PROCESS, V16, P2198, DOI 10.1109/TIP.2007.902333
   Maggioni M, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI 10.1109/TIP.2012.2210725
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Manjón JV, 2015, MED IMAGE ANAL, V22, P35, DOI 10.1016/j.media.2015.01.004
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Mohan J, 2013, BIOMED SIGNAL PROCES, V8, P779, DOI 10.1016/j.bspc.2013.07.005
   Muckley MJ, 2021, MAGN RESON MED, V85, P413, DOI 10.1002/mrm.28395
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Tripathi PC, 2020, PATTERN RECOGN LETT, V135, P57, DOI 10.1016/j.patrec.2020.03.036
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   Varadarajan D, 2015, IEEE T MED IMAGING, V34, P2191, DOI 10.1109/TMI.2015.2427157
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XY, 2015, MED IMAGE ANAL, V19, P75, DOI 10.1016/j.media.2014.08.004
NR 34
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41751
EP 41763
DI 10.1007/s11042-021-11521-8
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000805509400006
DA 2024-07-18
ER

PT J
AU Kalra, A
   Sequeira, A
   Manjunath, A
   Lal, S
   Raghavendra, BS
AF Kalra, Abhi
   Sequeira, Aaron
   Manjunath, Aditya
   Lal, Shyam
   Raghavendra, B. S.
TI A new deep learning architecture for dehazing of aerial remote sensing
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aerial image; Deep learning; Dehazing
ID VISIBILITY; WEATHER
AB A major problem in most aerial remote image processing applications is the presence of haze in images. It is a phenomenon by which particles in the atmosphere disperse light, thus altering the quality of the overall image. This can be detrimental to the performance of vision-based algorithms such as those concerned with object detection. There have been numerous attempts using traditional image processing techniques as well as using deep learning approaches to eliminate this haze. In most cases, models tend to make assumptions on the nature of haze that are rarely true in reality. In this paper, we propose an end-to-end deep learning architecture that can dehaze aerial remote sensing images efficiently with minimal deviation from the ground truth. Many of the assumptions made in other models are eliminated and the relationship between hazed and dehazed images is directly computed. The proposed model is based on the observation that identifying structural and statistical portions separately from an image and using those features to reconstruct the image can give a realistic dehazed image. It also makes use of information exposed by different color spaces to achieve this using lesser computation. The experimental quantitative and qualitative results of the proposed architecture are compared with recent benchmark dehaze models on NYU hazy dataset and real-world hazy images. Experimental results yield that the proposed architecture outperforms benchmark models on test aerial remote sensing images.
C1 [Kalra, Abhi; Sequeira, Aaron; Manjunath, Aditya; Lal, Shyam; Raghavendra, B. S.] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Surathkal Mangaluru 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Lal, S (corresponding author), Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Surathkal Mangaluru 575025, Karnataka, India.
EM kalra.abhi993@gmail.com; aaron191999@gmail.com;
   aditya.manjunathsj@gmail.com; shyam.mtec@gmail.com; r.bobbi@gmail.com
OI Lal, Dr. Shyam/0000-0002-4355-6354
FU Visvesvaraya Ph.D. Scheme of Ministry of Electronics & Information
   Technology (MeitY), Government of India in the National Institute of
   Technology Karnataka, Surathkal [DIC/MUM/GA/10(37)D]
FX This publication is the outcome of R & D work undertaken in the Young
   Faculty Research Fellowship project under Visvesvaraya Ph.D. Scheme of
   Ministry of Electronics & Information Technology (MeitY), Government of
   India in the National Institute of Technology Karnataka, Surathkal being
   implemented by Digital India Corporation (Formerly Media Lab Asia), New
   Delhi, Grant No. DIC/MUM/GA/10(37)D, Dated 24-01-2019.
CR Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dudhane A, 2020, IEEE T IMAGE PROCESS, V29, P628, DOI 10.1109/TIP.2019.2934360
   Dudhane A, 2019, IEEE WINT CONF APPL, P1147, DOI 10.1109/WACV.2019.00127
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jiao LB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122001
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Katsigiannis S., 2018, Quality and User Experience, V3, P6, DOI [DOI 10.1007/S41233-018-0019-8, 10.1007/s41233-018-0019-8]
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li H, 2017, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2017.560
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nuzillard D, BLIND SEPARATION LOW
   Pal NS, 2019, ENG SCI TECHNOL, V22, P22, DOI 10.1016/j.jestch.2018.11.006
   Pal NS, 2018, IETE TECH REV, V35, P223, DOI 10.1080/02564602.2016.1276868
   Pal NS, 2018, OPTIK, V163, P99, DOI 10.1016/j.ijleo.2018.02.067
   Park J, 2020, IEEE T IMAGE PROCESS, V29, P4721, DOI 10.1109/TIP.2020.2975986
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu QB, 2020, IEEE T IMAGE PROCESS, V29, P1788, DOI 10.1109/TIP.2019.2942504
   Xiao D, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3065148
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
NR 33
TC 1
Z9 1
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43639
EP 43655
DI 10.1007/s11042-022-13122-5
EA MAY 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000802317700001
DA 2024-07-18
ER

PT J
AU Hoang, TM
AF Thang Manh Hoang
TI A novel design of multiple image encryption using perturbed chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital perturbed chaos; Perturbed chaotic map; Chaos-based image
   encryption; Multiple image encryption (MIE)
ID BLOCK CIPHER; ALGORITHM; SCHEME; STEGANOGRAPHY; PERMUTATION; TRANSFORM;
   RETRIEVAL; SECRET; DOMAIN; DCT
AB For recent decades, the increasing volume of multimedia data has been witnessed, and the data is required technical methods to assure the security for storage and transmission. Chaos-based encryption is one of promising approaches to keep large volume of data confidential. Most of chaos-based algorithms were proposed for single image encryption. Recently, several schemes were proposed for multiple image encryption, and all of them are designed to work in a single round of encryption. In addition, the dynamics of chaotic maps therein are stationary, so it does not provide advantage of uncertainty of chaotic orbits for the security. Moreover, a chaotic map being realized in digital platforms can produce a large number of bits, and so far those bits have not been used efficiently to encrypt larger volume of data. In this paper, a novel design of chaos-based multiple image encryption is proposed using the permutation-diffusion architecture for the first time. Any chaotic map can be employed for the proposed design. Chaotic dynamics are non-stationary by means of perturbation on state variables and control parameters in bit level. Amounts of perturbation are constructed from the coordinate of pixels and the content of plain images respectively in the pixel permutation and diffusion processes, so the proposed design provides the property of authentication. Values of chaotic state variables are represented in fixed-point number, and bits generated by chaotic maps are thoroughly exploited to encrypt multiple images at the same time. The specific example will demonstrate the effectiveness of the proposed design by means of the statistical and security analyses. The simulation results will show its resistance from the attacking method of differential analysis, and those are also compared with those of other existing algorithms.
C1 [Thang Manh Hoang] Hanoi Univ Sci & Technol, Sch Elect & Elect Engn, 1 Dai Co Viet, Hanoi, Vietnam.
   [Thang Manh Hoang] Hanoi Univ Sci & Technol, Vietnam Japan Int Inst Sci Technol, 1 Dai Co Viet, Hanoi, Vietnam.
C3 Hanoi University of Science & Technology (HUST); Hanoi University of
   Science & Technology (HUST)
RP Hoang, TM (corresponding author), Hanoi Univ Sci & Technol, Sch Elect & Elect Engn, 1 Dai Co Viet, Hanoi, Vietnam.; Hoang, TM (corresponding author), Hanoi Univ Sci & Technol, Vietnam Japan Int Inst Sci Technol, 1 Dai Co Viet, Hanoi, Vietnam.
EM thang.hoangmanh@hust.edu.vn
OI Manh Hoang, Thang/0000-0003-3555-5682
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.04-2018.06]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.04-2018.06.
CR Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P1241, DOI 10.1007/s11042-019-08234-4
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Alvarez G., 2011, LESSONS LEARNT CRYPT, V257
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2018, J INF HIDING MULTIME
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P15561, DOI 10.1007/s11042-016-3858-4
   Chen JX, 2013, OPT EXPRESS, V21, P27873, DOI 10.1364/OE.21.027873
   Chen S, 2011, ADV COMPUTER SCI INT
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Cheng SL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030332
   Deepak M, 2014, 2014 1 INT C NETWORK
   Dhivya R, 2018, ELECTRON LETT, V54, P1332, DOI 10.1049/el.2018.6426
   El Assad S, 2014, US Patent, Patent No. [8,781,116, 8781116]
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fridrich J, 2007, INFORM HIDING
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Haq T., 2020, J INF SECUR APPL, P54
   Hilborn R. C., 2000, CHAOS NONLINEAR DYNA
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P3287, DOI 10.1016/j.cnsns.2011.12.012
   Kar N, 2018, IMPROVED CHAOS BASED, V4
   Katz J., 2014, INTRO MODERN CRYPTOG
   Kennedy M.P., 2000, CHAOTIC ELECT TELECO
   Khalind O, 2015, COMP SCI INFO TECH, V5
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Li XY, 2017, OPT LASER ENG, V96, P7, DOI 10.1016/j.optlaseng.2017.04.005
   Liu LF, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500591
   Liu LF, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501036
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu X, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500160
   Liu YQ, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S021812741750033X
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Masuda N, 2006, IEEE T CIRCUITS-I, V53, P1341, DOI 10.1109/TCSI.2006.874182
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mondal B, 2020, MICROELECTRONICS TEL
   Mousavi M, 2021, MULTIMED TOOLS APPL, V80, P13157, DOI 10.1007/s11042-020-10440-4
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Patro KAK, 2020, MULTIMED TOOLS APPL, V79, P12959, DOI 10.1007/s11042-019-08470-8
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Peng J, 2014, 2014 IEEE 13 INT C C
   Peng J, 2009, MACHINE LEARNING CYB
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Saeed MJ, 2013, J ENG SCI TECHNOL, V8, P508
   Sahasrabuddhe A, 2021, INFORM SCIENCES, V550, P252, DOI 10.1016/j.ins.2020.10.031
   Saidi M, 2017, MULTIMED TOOLS APPL, V76, P13493, DOI 10.1007/s11042-016-3722-6
   Sang T, 1998, ELECTRON LETT, V34, P873, DOI 10.1049/el:19980680
   Sayed WS, 2018, INT C MICROELECTRON, P92, DOI 10.1109/ICM.2018.8704022
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sharif A, 2017, MULTIMED TOOLS APPL, V76, P7849, DOI 10.1007/s11042-016-3398-y
   Sheela S, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6497
   Shuai CHEN., 2007, J CHINA U MINING TEC, V17, P258, DOI [10.1016/S1006-1266(07)60084-4, DOI 10.1016/S1006-1266(07)60084-4]
   SHUBO L, 2009, CHINESE PHYS B, V18, P5219
   Situ G, 2006, J OPT A-PURE APPL OP, V8, P391, DOI 10.1088/1464-4258/8/5/005
   Som S, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON BUSINESS AND INFORMATION MANAGEMENT (ICBIM)
   Stavroulakis Peter., 2006, Chaos applications in telecommunications
   Tam FCM., 2007, DIGITAL COMMUNICATIO
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P1901, DOI 10.1016/j.chaos.2004.07.033
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Hoang TM, 2021, IEEE ICCE 2020: 2020 IEEE EIGHTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P413, DOI 10.1109/ICCE48956.2021.9352070
   Hoang TM, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050548
   Thenmozhi S, 2013, 2013 7 INT C INTELLI
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Valandar MY, 2019, MULTIMED TOOLS APPL, V78, P9971, DOI 10.1007/s11042-018-6584-2
   Valandar MY, 2017, J INF SECUR APPL, V34, P142, DOI 10.1016/j.jisa.2017.04.004
   Wang J, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20090693
   Wang L, 2019, PSEUDO RANDOM NUMBER, V21, P960
   Wang Q, 2010, 2010 IEEE 5 INT C BI
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P11655, DOI 10.1007/s11042-020-10202-2
   Wang Y, 2014, OPT COMMUN, V330, P91, DOI 10.1016/j.optcom.2014.05.032
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Weng HP, 2021, IEEE ACCESS, V9, P20481, DOI 10.1109/ACCESS.2021.3054952
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Yang FF, 2020, MULTIMED TOOLS APPL, V79, P19963, DOI 10.1007/s11042-020-08821-w
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Yao W, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0165937
   Yao W, 2015, NONLINEAR DYNAM, V81, P151, DOI 10.1007/s11071-015-1979-3
   Yavuz E, 2019, OPT LASER TECHNOL, V114, P224, DOI 10.1016/j.optlastec.2019.01.043
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Zarebnia M, 2019, OPTIK, V179, P761, DOI 10.1016/j.ijleo.2018.10.025
   Zhang J, 2019, MULTIMED TOOLS APPL, V78, P15605, DOI 10.1007/s11042-018-6973-6
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zhang SJ, 2021, MATH COMPUT SIMULAT, V190, P723, DOI 10.1016/j.matcom.2021.06.012
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110660
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhou NR, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-020-02794-3
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2104-6
   Zhu HH, 2020, MULTIMED TOOLS APPL, V79, P12329, DOI 10.1007/s11042-019-08478-0
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 104
TC 17
Z9 17
U1 11
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26535
EP 26589
DI 10.1007/s11042-022-12139-0
EA MAY 2022
PG 55
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000796326600004
DA 2024-07-18
ER

PT J
AU Deng, R
AF Deng, Rui
TI Optimized resource allocation for multipath cooperative video
   transmission over MEC-assisted 5G heterogeneous networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile Edge Computing; Cooperative transmission; Resource optimization;
   Scalable video; QoE
ID MULTICAST; QUALITY
AB With the continuously increasing demands for video application, high-quality video transmission will still be one of the major challenges for future Mobile Edge Computing (MEC) assisted 5G heterogeneous networks. It poses the pressing need for solutions that enable to optimize the resource allocation. Therefore, we design a complete and practical multipath cooperative transmission scheme for scalable video, to achieve efficient operation of cache management, resource optimization, signaling interaction and information processing. On this basis, an improved cache optimization algorithm is proposed to determine an appropriate cooperative cache strategy for all MEC severs. By considering the structural features of SVC, content-related rate-quality relationship and the delay characteristics of multipath cooperative transmission, it can effectively improve cache hit ratio while decreasing the average delay. For further improving the overall QoE of all clients, a novel transmission resource optimization problem that aims to maximize the sum of the short-time quality gain and the final quality achievement of all the clients, is formulated. To accurately predict the final quality achievement, we establish a low-complexity model for real-time analysis of the end-to-end delay, and subsequently propose an innovative quality prediction method with considering deadline constraint. Based on the formulation, a two-phase algorithm is developed to address the problem efficiently. The simulation results show that our scheme outperforms the others in the caching optimization stage in terms of both hit rate and delay, and moreover achieves the playback continuity while guaranteeing higher video quality in the transmission optimization stage.
C1 [Deng, Rui] Shaanxi Normal Univ, Sch Journalism & Commun, Xian, Peoples R China.
C3 Shaanxi Normal University
RP Deng, R (corresponding author), Shaanxi Normal Univ, Sch Journalism & Commun, Xian, Peoples R China.
EM dengrui618@snnu.edu.cn
FU National Natural Science Foundation of China [61901250]
FX This research was supported by National Natural Science Foundation of
   China(61901250)
CR Awobuluyi Olatunde, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P1657, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.250
   Bhushan N, 2014, IEEE COMMUN MAG, V52, P82, DOI 10.1109/MCOM.2014.6736747
   Bouali F, 2017, INT SYMP WIREL, P354, DOI 10.1109/WPMC.2017.8301838
   Chen C, 2014, IEEE T IMAGE PROCESS, V23, P2206, DOI 10.1109/TIP.2014.2312613
   Chen DC, 2015, IEEE T WIREL COMMUN, V14, P3194, DOI 10.1109/TWC.2015.2403321
   Chen SW, 2020, IEEE T VEH TECHNOL, V69, P10227, DOI 10.1109/TVT.2020.3004048
   Chen W-Y, 2021, IEEE T MOBILE COMPUT
   Cheng XL, 2012, IEEE GLOB COMM CONF
   Cicalò S, 2014, IEEE T MULTIMEDIA, V16, P848, DOI 10.1109/TMM.2014.2300442
   Deng R, 2020, MULTIMED TOOLS APPL, V79, P21073, DOI 10.1007/s11042-020-08808-7
   Deng R, 2018, MULTIMED TOOLS APPL, V77, P6445, DOI 10.1007/s11042-017-4551-y
   Eswara N, 2020, IEEE T BROADCAST, V66, P346, DOI 10.1109/TBC.2019.2954064
   Fattah Hossam, 2009, 2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems. MASS 2009, P929, DOI 10.1109/MOBHOC.2009.5337027
   Ge XH, 2017, IEEE T MULTIMEDIA, V19, P2345, DOI 10.1109/TMM.2017.2733461
   Ge XH, 2016, IEEE T VEH TECHNOL, V65, P7882, DOI 10.1109/TVT.2016.2539285
   Guo YS, 2017, IEEE T VEH TECHNOL, V66, P2324, DOI 10.1109/TVT.2016.2575920
   He LJ, 2014, IEEE T WIREL COMMUN, V13, P6768, DOI 10.1109/TWC.2014.2364603
   Holleczek P, 2006, IEEE INT C NETW SERV, P15
   Hu Y.C., 2015, MOBILE EDGE COMPUTIN
   Ji X, 2009, IEEE T CIRC SYST VID, V19, P1549, DOI 10.1109/TCSVT.2009.2026812
   Kela P, 2008, INT S WIRELESS PERVA
   Kompella RR, 2012, IEEE ACM T NETWORK, V20, P811, DOI 10.1109/TNET.2012.2188905
   Li F, 2009, IEEE WORKSH GLOB COM
   Luo HY, 2010, IEEE COMMUN MAG, V48, P102, DOI 10.1109/MCOM.2010.5402671
   Nightingale J, 2018, IEEE T BROADCAST, V64, P621, DOI 10.1109/TBC.2018.2816786
   Pervez F, 2017, INT S PERS IND MOB R, P1
   Piro G, 2011, IEEE T MULTIMEDIA, V13, P1052, DOI 10.1109/TMM.2011.2152381
   Poularakis K, 2016, IEEE INFOCOM SER
   Qiao J, 2015, IEEE T WIREL COMMUN, V14, P5692, DOI 10.1109/TWC.2015.2441708
   Rappaport TS, 2013, IEEE ACCESS, V1, P335, DOI 10.1109/ACCESS.2013.2260813
   Roccetti M, 2001, MULTIMED TOOLS APPL, V14, P23, DOI 10.1023/A:1011303506685
   Sangaiah AK, 2019, IEEE T IND INFORM, P11
   Sangaiah AK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020539
   Singh S, 2014, IEEE T WIREL COMMUN, V13
   Stenumgaard P, 2013, IEEE COMMUN MAG, V51, P186, DOI 10.1109/MCOM.2013.6515064
   Vo N, 2016, IEEE GLOBAL COMMUN C, P16
   Wang CX, 2014, IEEE COMMUN MAG, V52, P122, DOI 10.1109/MCOM.2014.6736752
   Yang J, 2019, INT S COMP COMM
   Ye Z, 2017, 2017 PROCEEDINGS OF THE 29TH INTERNATIONAL TELETRAFFIC CONGRESS (ITC 29), VOL 1, P205, DOI [10.1109/ITC.2017.19, 10.23919/ITC.2017.8064357]
   Yu RZ, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511029
   Zhang GZ, 2016, IEEE T COMMUN, V64, P876, DOI 10.1109/TCOMM.2016.2515596
   Zhang HH, 2010, IEEE J SELECT AREAS, V28
   Zhang WW, 2013, IEEE T MULTIMEDIA, V15, P1431, DOI 10.1109/TMM.2013.2247583
   Zhang XC, 2017, IEEE COMMUN MAG, V55, P77, DOI 10.1109/MCOM.2017.1700405
   Zhang XW, 2018, IEEE T VEH TECHNOL, V67, P9047, DOI 10.1109/TVT.2018.2849703
   Zhang Z, 2017, IEEE WIRELESS COMMUN
NR 46
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40135
EP 40157
DI 10.1007/s11042-022-12137-2
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100001
DA 2024-07-18
ER

PT J
AU Deng, WM
   Zhang, HB
   Lei, Q
   Du, JX
   Huang, M
AF Deng, Wei-Mo
   Zhang, Hong-Bo
   Lei, Qing
   Du, Ji-Xiang
   Huang, Min
TI Pose attention and object semantic representation-based human-object
   interaction detection network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-object interaction detection; Pose attention; Object semantic;
   Relation feature
AB Human-object interaction (HOI) detection is a core problem in human-centric scene understanding, which is devoted to inferring triplets < human, verb, object > between humans and objects. Previous works mainly determine the interaction of each human-object pair by performing joint inference based on multiple features. In this paper, we design more discriminative representation of the human-object pair and a more effective HOI detection model. On the one hand, we use human poses as an attention mechanism to strengthen features, which is a novel way to deal with human poses in HOI detection. On the other hand, for a more effective representation of objects, a word vector is used to encode objects, and the relation features of humans and objects are captured by a graph convolution network based on object word vectors and human appearance features. These relation features are also strengthened by a human pose attention mechanism. Our model yields favorable results compared to the state-of-the-art HOI detection algorithms on two large-scale benchmark datasets, V-COCO and HICO-DET.
C1 [Deng, Wei-Mo; Zhang, Hong-Bo] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
   [Lei, Qing] Huaqiao Univ, Xiamen Key Lab Comp Vis & Pattern Recognit, Xiamen 361000, Peoples R China.
   [Du, Ji-Xiang] Huaqiao Univ, Fujian Key Lab Big Data Intelligence & Secur, Xiamen 361000, Peoples R China.
   [Huang, Min] Xiamen Univ, Coll Humanities, Xiamen 361000, Peoples R China.
C3 Huaqiao University; Huaqiao University; Huaqiao University; Xiamen
   University
RP Zhang, HB (corresponding author), Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
EM Dengweimo@stu.hqu.edu.cn; zhanghongbo@hqu.edu.cn; leiqing@hqu.edu.cn;
   jxdu@hqu.edu.cn; huangm1059@189.cn
RI Zhang, Hong-Bo/GWC-9306-2022
FU Natural Science Foundation of China [61871196, 62001176, 61902330,
   61673186]; National Key Research and Development Program of China
   [2019YFC1604700]; Natural Science Foundation of Fujian Province of China
   [2019J01082, 2020J01085]; Promotion Program for Young and Middle-aged
   Teacher in Science and Technology Research of Huaqiao University
   [ZQN-YX601]
FX This work was supported by the Natural Science Foundation of China [No.
   61871196, 62001176, 61902330 and 61673186]; National Key Research and
   Development Program of China [NO.2019YFC1604700]; Natural Science
   Foundation of Fujian Province of China [No. 2019J01082 and 2020J01085];
   and the Promotion Program for Young and Middle-aged Teacher in Science
   and Technology Research of Huaqiao University [ZQN-YX601].
CR Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P696, DOI 10.1007/978-3-030-58610-2_41
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Colque RM, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P293, DOI 10.5220/0006615202930300
   Dong-Jin Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P718, DOI 10.1007/978-3-030-58589-1_43
   Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4
   Gao C., 2018, ARXIV
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta Saurabh, 2015, ARXIV150504474, P5
   Gupta T, 2019, IEEE I CONF COMP VIS, P9676, DOI 10.1109/ICCV.2019.00977
   Hai Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P248, DOI 10.1007/978-3-030-58520-4_15
   Hassan M., 2015, INT C COMP VIS IM AN
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JF, 2016, IEEE T CIRC SYST VID, V26, P647, DOI 10.1109/TCSVT.2015.2397200
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Liang Zhijun, 2020, ARXIV200802042
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2017, Advances in pre-training distributed word representations
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Syed MR, 2008, MEDIA FOREIGN LANGUA, V13, P222
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang TC, 2019, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2019.00206
   Xu BJ, 2020, IEEE T MULTIMEDIA, V22, P1423, DOI 10.1109/TMM.2019.2943753
   Yang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P248, DOI 10.1007/978-3-030-58568-6_15
   Zhang HB, 2020, INTENS CARE MED, V46, P586, DOI 10.1007/s00134-020-05985-9
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhou PH, 2019, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2019.00093
NR 41
TC 0
Z9 0
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39453
EP 39470
DI 10.1007/s11042-022-13146-x
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000788451300001
DA 2024-07-18
ER

PT J
AU Cai, L
   Luo, PE
   Xu, T
   Chen, ZX
AF Cai, Lei
   Luo, Peien
   Xu, Tao
   Chen, Zhenxue
TI M-PFGMNet: multi-pose feature generation mapping network for visual
   object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unmanned detection system; Visual object tracking; Distributed
   generative adversarial network; Multi-pose feature mapping
ID QUALITY
AB The occlusion and low-resolution environments lead to insufficient feature data and redundant calculations, which affects the accuracy and timeliness of the unmanned detection system in visual object tracking. To solve this issue, this paper proposes the multi-pose feature generation mapping network for visual object tracking (M-PFGMNet). Firstly, M-PFGMNet suggests a distributed generative adversarial network to increase the accuracy of target detection and reconstruct the local-to-global features of the data with insufficient target features. Secondly, M-PFGMNet proposes a multi-pose feature mapping method for real-time target detection, this method can migrate sample data with high similarity between dynamic target and unmanned system. The experimental results show that the algorithm is effective compared with other similar algorithms in the OTB-50/100 public dataset.
C1 [Cai, Lei; Xu, Tao] Henan Inst Sci Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
   [Luo, Peien] Xian Univ Technol, Sch Elect Engn, Xian 710000, Peoples R China.
   [Chen, Zhenxue] Shandong Univ, Sch Control Sci Engn, Jinan 250061, Peoples R China.
C3 Henan Institute of Science & Technology; Xi'an University of Technology;
   Shandong University
RP Cai, L (corresponding author), Henan Inst Sci Technol, Sch Artificial Intelligence, Xinxiang 453003, Henan, Peoples R China.
EM cailei2014@126.com; kjxylpe0220@163.com; xutao@hist.edu.cn;
   chenzhenxue@sdu.edu.cn
RI luo, peien/AAZ-2254-2020; Zhang, Youmin/AAT-7095-2020
OI luo, peien/0000-0003-4813-1395; Zhang, Youmin/0000-0002-9731-5943
FU National Key R&D Program of China [2019YFB1311002]
FX This work was supported by National Key R&D Program of China
   (2019YFB1311002).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Cai L, 2019, INT J DISTRIB SENS N, V15, P1, DOI 10.1177/1550147719870657
   Chang J, 2017, INT CONF ACOUST SPEE, P2746, DOI 10.1109/ICASSP.2017.7952656
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P986, DOI 10.1109/TIP.2019.2938680
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hu Q, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540260
   Huang B, 2018, PATTERN RECOGN LETT, V111, P72, DOI 10.1016/j.patrec.2018.04.028
   Karbalayghareh A, 2018, IEEE T SIGNAL PROCES, V66, P3724, DOI 10.1109/TSP.2018.2839583
   Lu H, 2017, J MT SCI-ENGL, V14, P731, DOI 10.1007/s11629-016-3950-2
   Mo KX, 2018, AAAI CONF ARTIF INTE, P5317
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qin FB, 2019, IEEE-ASME T MECH, V24, P1117, DOI 10.1109/TMECH.2019.2909081
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Saha B, 2016, KNOWL INF SYST, V46, P315, DOI 10.1007/s10115-015-0821-z
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Sun YW, 2018, J X-RAY SCI TECHNOL, V26, P523, DOI 10.3233/XST-17356
   Wu S, 2018, IEEE T IMAGE PROCESS, V27, P1418, DOI 10.1109/TIP.2017.2779271
   Yin XL, 2020, IEEE ACCESS, V8, P31057, DOI 10.1109/ACCESS.2020.2973534
   Yuan ZF, 2020, IEEE T INTELL VEHICL, V5, P314, DOI 10.1109/TIV.2019.2955907
   Zhang DY, 2017, LECT NOTES COMPUT SC, V10636, P217, DOI 10.1007/978-3-319-70090-8_23
   Zhao J, 2016, 2016 IEEE MTT-S INTERNATIONAL WIRELESS SYMPOSIUM (IWS), DOI 10.1109/ICSSSM.2016.7538614
   Zheng XH, 2018, IEEE T MED IMAGING, V37, P1498, DOI 10.1109/TMI.2018.2832007
NR 25
TC 1
Z9 1
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38803
EP 38816
DI 10.1007/s11042-022-12875-3
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500003
DA 2024-07-18
ER

PT J
AU Bhagat, M
   Kumar, D
AF Bhagat, Monu
   Kumar, Dilip
TI A comprehensive survey on leaf disease identification & classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf disease; Artificial intelligence; Classification; Feature
   selection; Deep learning; ANN; SVM; CNN; RF; DL architecture;
   Visualization
ID PLANT-DISEASE; NEURAL-NETWORK; DEEP; SEGMENTATION; OPTIMIZATION;
   RECOGNITION; INDEXES; LEAVES; NITRATE; SYSTEM
AB This paper presents survey on various techniques used to classify plants and its disease. Classification is concerned with classifying each sample into different classes. Classification is a method of separating a healthy and diseased leaf on its morphological features such as texture, color, shape, pattern and so on. Due to resemblance in the visual properties among plants, sorting and classification are complicated to carry out especially in large area. There are various methods based on image processing techniques and computer vision. Choosing the suitable classification technique is quite difficult as the result varies on different input data. Classification of leaf diseases in plants has wide applications in different fields such as agriculture and biological research. This paper provides a general idea of few existing methods, its pros and cons, state of art of different techniques used by several authors in leaf disease identification and classification such as preprocessing techniques, feature extraction and selection techniques, datasets used, classifiers and performance metrics. Apart from these some challenges and research gaps are identified and their probable solutions are pointed out.
C1 [Bhagat, Monu; Kumar, Dilip] NIT Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Bhagat, M (corresponding author), NIT Jamshedpur, Dept Comp Sci & Engn, Jamshedpur, Jharkhand, India.
EM 2018rscs002@nitjsr.ac.in
RI Bhagat, Dr. Monu/GLS-1071-2022
OI Bhagat, Dr. Monu/0000-0001-9074-9653
FU National Institute of Technology Jamshedpur, India under the MHRD
FX This research was supported by the National Institute of Technology
   Jamshedpur, India under the MHRD doctoral research fellowship.
CR Alahi MEE, 2018, IEEE INTERNET THINGS, V5, P4409, DOI 10.1109/JIOT.2018.2809669
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Amara J., 2017, DATENBANKSYSTEME BUS
   Arjunagi S, 2019, TEXTURE BASED LEAF D
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Atole RR, 2018, INT J ADV COMPUT SC, V9, P67
   Bagde S, 2015, INT J COMPUT SCI MOB
   Bajwa SG, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020127
   Bannari A, 2007, IEEE T GEOSCI REMOTE, V45, P3063, DOI 10.1109/TGRS.2007.897429
   Bierman A, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9209727
   Bock CH, 2010, CRIT REV PLANT SCI, V29, P59, DOI 10.1080/07352681003617285
   Brahimi M, 2019, ARXIV ARXIV190513523
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Chen J, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030343
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Chouhan SS, 2018, IEEE ACCESS, V6, P8852, DOI 10.1109/ACCESS.2018.2800685
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Cruz AC, 2017, 2017 ASABE ANN INT M, P1, DOI DOI 10.13031/AIM.201700241
   Cruz AC, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01741
   Cugu S, 2017, TREELOGY NOVEL TREE
   DeChant C, 2017, PHYTOPATHOLOGY, V107, P1426, DOI 10.1094/PHYTO-11-16-0417-R
   Dechorgnat J, 2011, J EXP BOT, V62, P1349, DOI 10.1093/jxb/erq409
   Dey AK, 2016, PROCEDIA COMPUT SCI, V85, P748, DOI 10.1016/j.procs.2016.05.262
   Digumarti ST, 2018, IEEE ROBOT AUTOM LET, V3, P3043, DOI 10.1109/LRA.2018.2849499
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Elhassouny A., 2019, INT C COMP SCI REN E, P1, DOI [DOI 10.1109/ICCSRE.2019.8807737, 10.1109/ICCSRE.2019.8807737]
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Fuentes AF, 2018, FRONT PLANT SCI, V9, DOI 10.3389/fpls.2018.01162
   Fujita E, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P989, DOI [10.1109/ICMLA.2016.56, 10.1109/ICMLA.2016.0178]
   Gitelson AA, 2002, REMOTE SENS ENVIRON, V80, P76, DOI 10.1016/S0034-4257(01)00289-9
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   Gui J., 2015, INT J MULTIMED UBIQU, V10, P45, DOI [10.14257/ijmue.2015.10.6.06, DOI 10.14257/IJMUE.2015.10.6.06]
   Ha JG, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042621
   Haque I., 2020, 2 INT C DAT ENG APPL, P1, DOI [DOI 10.1109/IDEA49133.2020.9170725, 10.1109/IDEA49133.2020.9170725]
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   Hlaing Chit Su, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P439, DOI 10.1109/ICIS.2018.8466483
   Hlaing Chit Su, 2017, 2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT). Proceedings, P223, DOI 10.1109/PDCAT.2017.00044
   Hu GS, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.100353
   Huang WJ, 2014, IEEE J-STARS, V7, P2516, DOI 10.1109/JSTARS.2013.2294961
   Islam M.N., 2012, P INT C ELECT COMPUT, P626
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Jin X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030395
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Kaveh Mohammad, 2018, Information Processing in Agriculture, V5, P372, DOI 10.1016/j.inpa.2018.05.003
   Kawasaki Y, 2015, LECT NOTES COMPUT SC, V9475, P638, DOI 10.1007/978-3-319-27863-6_59
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Kerkech M, 2018, COMPUT ELECTRON AGR, V155, P237, DOI 10.1016/j.compag.2018.10.006
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Kour VP, 2019, IEEE ACCESS, V7, P29374, DOI 10.1109/ACCESS.2019.2901900
   Kulkarni AH., 2012, Inter J Modern Eng Res, V2, P3661
   Kumar J. P., 2019, Information Processing in Agriculture, V6, P233, DOI 10.1016/j.inpa.2018.09.005
   Kumar S, 2020, P INT C ADV EL EL CO, DOI [10.2139/ssrn.3574648, DOI 10.2139/SSRN.3574648]
   Kumar S, 2021, EVOL INTELL, V14, P293, DOI 10.1007/s12065-018-0186-9
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Pires RDL, 2016, COMPUT ELECTRON AGR, V125, P48, DOI 10.1016/j.compag.2016.04.032
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Manojkumar P, 2017, 2017 THIRD IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P231, DOI 10.1109/ICRCICN.2017.8234512
   Meunkaewjinda A, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P513, DOI 10.1109/ECTICON.2008.4600483
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.75, 10.1109/ICTAI.2016.0078]
   Nagasubramanian K, 2018, ARXIV ARXIV180408831
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Ozguven MM, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122537
   Padol PB, 2017, P INT C GLOB TRENDS, P298, DOI [10.1109/ICGTSPICC.2016.7955315, DOI 10.1109/ICGTSPICC.2016.7955315]
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Patil SB., 2011, Int. J. Eng. Technol, V3, P297, DOI DOI 10.7763/IJET.2011.V3.241
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Prasad S., 2011, 2011 2nd International Conference on Computer and Communication Technology, P646, DOI 10.1109/ICCCT.2011.6075212
   Qin F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168274
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Ramesh S., 2020, Information Processing in Agriculture, V7, P249, DOI 10.1016/j.inpa.2019.09.002
   Rangarajan AK, 2018, PROCEDIA COMPUT SCI, V133, P1040, DOI 10.1016/j.procs.2018.07.070
   Rathod ArtiN., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3
   Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
   Sambasivam G, 2021, EGYPT INFORM J, V22, P27, DOI 10.1016/j.eij.2020.02.007
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Sawarkar V, IOSR J COMPUTER ENG
   Sibiya M, 2019, AGRIENGINEERING, V1, P119, DOI 10.3390/agriengineering1010009
   Singh A, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGICAL INNOVATIONS IN ICT FOR AGRICULTURE AND RURAL DEVELOPMENT TIAR 2015, P24, DOI 10.1109/TIAR.2015.7358526
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Sulistyo SB, 2017, IEEE T IND INFORM, V13, P103, DOI 10.1109/TII.2016.2628439
   Tetila EC, 2020, IEEE GEOSCI REMOTE S, V17, P903, DOI 10.1109/LGRS.2019.2932385
   Tetila EC, 2017, IEEE GEOSCI REMOTE S, V14, P2190, DOI 10.1109/LGRS.2017.2743715
   Tiwari VM., 2017, Int J Eng Manag Technol, V5, P11
   Toda Y, 2019, PLANT PHENOMICS, V2019, DOI 10.34133/2019/9237136
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Türkoglu M, 2019, TURK J ELECTR ENG CO, V27, P1636, DOI 10.3906/elk-1809-181
   Vetal S., 2017, Int J Adv Res Comput Commun Eng, V6, P293, DOI 10.17148/IJARCCE.2017.6651
   Vilasini M, 2020, CMC-COMPUT MATER CON, V62, P1445, DOI 10.32604/cmc.2020.08857
   Wallelign Serawork., 2018, PROC 31 INT FLORIDA, P146
   Wang DY, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40066-y
   Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
   Wang HG, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P894, DOI 10.1109/CISP.2012.6469998
   Wang X, 2015, IEEE T BIO-MED ENG, V62, P80, DOI 10.1109/TBME.2014.2339295
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Zhang KK, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/6710865
   Zhang SW, 2019, COMPUT ELECTRON AGR, V162, P422, DOI 10.1016/j.compag.2019.03.012
   Zhang SW, 2019, COGN SYST RES, V53, P31, DOI 10.1016/j.cogsys.2018.04.006
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhang X, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131554
NR 118
TC 15
Z9 15
U1 6
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33897
EP 33925
DI 10.1007/s11042-022-12984-z
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300020
DA 2024-07-18
ER

PT J
AU Zhang, H
   Li, F
   Yan, ZS
AF Zhang, Hong
   Li, Fan
   Yan, Zhisheng
TI A novel transmission approach based on video content for 360-degree
   streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content; 360-degree video; Multiple tile resolutions; Tile-based
   streaming
AB Because of the immersive experience provided, 360-degree video is developing rapidly. However, high data volume is needed to create the panoramic video for the end-user, which conflicts with the limited transmission resources. In this paper, we present a novel transmission approach based on video content to guarantee an acceptable objective video quality for end-users by reusing the transmitted video data, in which transmission resources are saved by transmitting part of video data. The approach is designed to address challenges, such as the increment of video data volume from the tile-based encoding and the inconsistency between transmitted tiles and the viewed region using a single mode of tile partition. We also employ public network traces to simulate the network condition in our work. Simulated results show that our proposed approach can save bandwidth of 5% similar to 12% only at the price of slightly eroding the perceived quality measured by SSIM value than transmitting all video data in the viewport. Moreover, the bandwidth saving varies with different video content.
C1 [Zhang, Hong; Li, Fan] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Yan, Zhisheng] George Mason Univ, Sch Comp, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
C3 Xi'an Jiaotong University; George Mason University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
EM zhanghong007@stu.xjtu.edu.cn; lifan@mail.xjtu.edu.cn
FU National Science Foundation of China [61671365, U1903213]; Key Research
   and Development Program of Shaanxi Province [2020KW-009]
FX This research work was supported in part by the National Science
   Foundation of China (61671365, U1903213), and in part by the Key
   Research and Development Program of Shaanxi Province (2020KW-009).
CR Nguyen A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1190, DOI 10.1145/3240508.3240669
   [Anonymous], 4G LTE BANDW LOGS
   [Anonymous], VIRTUAL REALITY VR H
   Anwar MS, 2018, I C VIRTUAL REALITY, P106, DOI 10.1109/ICVRV.2018.00030
   AZEVEDO RDO, 2020, IDENTIFICATION ANAL, P1
   Bentaleb A, 2019, IEEE COMMUN SURV TUT, V21, P562, DOI 10.1109/COMST.2018.2862938
   Brunnstrom K., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Concolato C, 2018, IEEE T CIRC SYST VID, V28, P1981, DOI 10.1109/TCSVT.2017.2688491
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   Covaci A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2378, DOI 10.1145/3343031.3350954
   Dasari M, 2020, INFOCOM, P1
   Dobrian F, 2011, ACM SIGCOMM COMP COM, V41, P362, DOI 10.1145/2043164.2018478
   Duanmu ZF, 2018, IEEE T BROADCAST, V64, P474, DOI 10.1109/TBC.2018.2822870
   Ghaznavi-Youvalari R, 2019, IEEE T CIRC SYST VID, V29, P3106, DOI 10.1109/TCSVT.2018.2874179
   Guan Y, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P394, DOI 10.1145/3341302.3342063
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Hu Q, 2020, MULTIMED TOOLS APPL, V79, P12205, DOI 10.1007/s11042-019-08390-7
   Lungaro P, 2018, IEEE T VIS COMPUT GR, V24, P1535, DOI 10.1109/TVCG.2018.2794119
   Nguyen DV, 2019, IEEE J EM SEL TOP C, V9, P29, DOI 10.1109/JETCAS.2019.2899488
   Ozcinar C, 2017, IEEE IMAGE PROC, P2174, DOI 10.1109/ICIP.2017.8296667
   Qian F., 2016, Proceedings of the 5th Workshop on All Things Cellular: Operations, Applications and Challenges, P1, DOI DOI 10.1145/2980055.2980056
   Qian F, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P99, DOI 10.1145/3241539.3241565
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Song JR, 2020, IEEE T MULTIMEDIA, V22, P2366, DOI 10.1109/TMM.2019.2957976
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZX, 2021, MULTIMED TOOLS APPL, V80, P2441, DOI 10.1007/s11042-020-09231-8
   Xiao MB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P708, DOI 10.1145/3123266.3123339
   Xie L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P315, DOI 10.1145/3123266.3123291
   Xie SW, 2020, IEEE T CIRC SYST VID, V30, P3029, DOI 10.1109/TCSVT.2019.2934136
   Yan ZS, 2018, IEEE T MOBILE COMPUT, V17, P2536, DOI 10.1109/TMC.2018.2812852
   Yaqoob A, 2020, IEEE COMMUN SURV TUT, V22, P2801, DOI 10.1109/COMST.2020.3006999
   Yeo H, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P645
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zhang J, 2020, C HOTICN, P1
   Zhang XY, 2020, IEEE T CIRC SYST VID, V30, P217, DOI 10.1109/TCSVT.2018.2886805
   Zhou C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3209660
   Zou W, 2021, IEEE T CIRCUITS SYST, P1
   Zou WJ, 2019, IEEE ACCESS, V7, P183405, DOI 10.1109/ACCESS.2019.2920443
NR 40
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 34067
EP 34085
DI 10.1007/s11042-022-11938-9
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784679300029
DA 2024-07-18
ER

PT J
AU Singh, AK
   Gupta, R
AF Singh, Ashutosh Kumar
   Gupta, Rishabh
TI A privacy-preserving model based on differential approach for sensitive
   data in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Cloud computing; Differential privacy; Laplace
   distribution; k-anonymity
ID SECURITY
AB A large amount of data and applications need to be shared with various parties and stakeholders in the cloud environment for storage, computation, and data utilization. Since a third party operates the cloud platform, owners cannot fully trust this environment. However, it has become a challenge to ensure privacy preservation when sharing data effectively among different parties. This paper proposes a novel model that partitions data into sensitive and non-sensitive parts, injects the noise into sensitive data, and performs classification tasks using k-anonymization, differential privacy, and machine learning approaches. It allows multiple owners to share their data in the cloud environment for various purposes. The model specifies communication protocol among involved multiple untrusted parties to process owners' data. The proposed model preserves actual data by providing a robust mechanism. The experiments are performed over Heart Disease, Arrhythmia, Hepatitis, Indian-liver-patient, and Framingham datasets for Support Vector Machine, K-Nearest Neighbor, Random Forest, Naive Bayes, and Artificial Neural Network classifiers to compute the efficiency in terms of accuracy, precision, recall, and F1-score of the proposed model. The achieved results provide high accuracy, precision, recall, and F1-score up to 93.75%, 94.11%, 100%, and 87.99% and improvement up to 16%, 29%, 12%, and 11%, respectively, compared to previous works.
C1 [Singh, Ashutosh Kumar; Gupta, Rishabh] Natl Inst Technol, Dept Comp Applicat, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Gupta, R (corresponding author), Natl Inst Technol, Dept Comp Applicat, Kurukshetra, Haryana, India.
EM ashutosh@nitkkr.ac.in; rishabhgpt66@gmail.com
RI Singh, Ashwani/GQP-2566-2022; Singh, Anil/JUU-2219-2023; Singh, Ashok
   K/HGF-2506-2022
FU University Grant Commission, New Delhi, India [3515/(NET-NOV 2017)]
FX This work is supported by University Grant Commission, New Delhi, India
   under the scheme of National Eligibility Test-Junior Research Fellowship
   (NET-JRF) with reference id-3515/(NET-NOV 2017).
CR Ali M, 2017, IEEE SYST J, V11, P395, DOI 10.1109/JSYST.2014.2379646
   Ali M, 2015, INFORM SCIENCES, V305, P357, DOI 10.1016/j.ins.2015.01.025
   Casino F, 2015, J COMPUT SYST SCI, V81, P1000, DOI 10.1016/j.jcss.2014.12.013
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Fan WB, 2020, J PARALLEL DISTR COM, V135, P70, DOI 10.1016/j.jpdc.2019.09.009
   Frank Andrew., 2010, School of information and computer science, V213, P2
   Fu ZJ, 2018, IEEE T INF FOREN SEC, V13, P2359, DOI 10.1109/TIFS.2018.2819121
   Gao CZ, 2018, INFORM SCIENCES, V444, P72, DOI 10.1016/j.ins.2018.02.058
   Gupta I, 2021, IEEE SYST J, V15, P4248, DOI 10.1109/JSYST.2020.3035666
   Hesamifard Ehsan, 2018, Proceedings on Privacy Enhancing Technologies, V2018, P123, DOI 10.1515/popets-2018-0024
   Jang SB, 2017, MULTIMED TOOLS APPL, V76, P17855, DOI 10.1007/s11042-015-3123-2
   Kumar J, 2020, SOFT COMPUT, V24, P14593, DOI 10.1007/s00500-020-04808-9
   Phong LT, 2019, IEEE T INF FOREN SEC, V14, P3003, DOI 10.1109/TIFS.2019.2911169
   Li P, 2018, FUTURE GENER COMP SY, V87, P341, DOI 10.1016/j.future.2018.04.076
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Li T, 2018, INFORM SCIENCES, V444, P89, DOI 10.1016/j.ins.2018.02.056
   Li T, 2018, J NETW COMPUT APPL, V106, P100, DOI 10.1016/j.jnca.2017.12.021
   Ma XD, 2021, IEEE T SERV COMPUT, V14, P1251, DOI 10.1109/TSC.2018.2868750
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Singh AK, 2020, MULTIMED TOOLS APPL, V79, P31165, DOI 10.1007/s11042-020-09470-9
   Stergiou C, 2017, MULTIMED TOOLS APPL, V76, P22803, DOI 10.1007/s11042-017-4590-4
   Sudhakar RV, 2020, CLUSTER COMPUT, V23, P2579, DOI 10.1007/s10586-019-03028-7
   Tanuwidjaja HC, 2020, IEEE ACCESS, V8, P167425, DOI 10.1109/ACCESS.2020.3023084
   Wei JH, 2018, IEEE T CLOUD COMPUT, V6, P1136, DOI 10.1109/TCC.2016.2545668
   Wei K, 2020, IEEE T INF FOREN SEC, V15, P3454, DOI 10.1109/TIFS.2020.2988575
   Wei LF, 2014, INFORM SCIENCES, V258, P371, DOI 10.1016/j.ins.2013.04.028
   Xu SM, 2018, IEEE T INF FOREN SEC, V13, P2101, DOI 10.1109/TIFS.2018.2810065
   Yonetani R, 2017, IEEE I CONF COMP VIS, P2059, DOI 10.1109/ICCV.2017.225
   Yuan JW, 2014, IEEE T PARALL DISTR, V25, P212, DOI 10.1109/TPDS.2013.18
   Zaghloul E, 2020, IEEE T BIG DATA, V6, P804, DOI 10.1109/TBDATA.2019.2907133
   Zhao XD, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.07.008
NR 31
TC 11
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33127
EP 33150
DI 10.1007/s11042-021-11751-w
EA APR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800008
DA 2024-07-18
ER

PT J
AU Vatsavayi, VK
   Andavarapu, N
AF Vatsavayi, Valli Kumari
   Andavarapu, Nagaraju
TI Identification and classification of wild animals from video sequences
   using hybrid deep residual convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fast averaging peer group; Gray scale conversion; DRCNN; TSOA; Video
   classification
AB In recent decades, wild animal classification from the video sequence is considered the trending research domain. Existing techniques utilize image processing for wild animal classification; however, the video-based classification is not much concentrated on any other previous research. So, in this research, we have concentrated on the wild animal classification using many videos that may contain accurate details about the wild animals. For such classification, Deep Residual Convolutional Neural Network (DRCNN) is integrated with (TSO) algorithm to perform the video processing, accurately classifying the different classes of wild animals using the Serengeti dataset. The video sequences are initially converted into video frames to initiate the wild animal classification. Then, unwanted noise from each video frame is removed using the Fast Average Peer Group (FAPG) filter in the pre-processing stage. Before the filtering process, all the images are resized into the same size. Next to the pre-processing, the threshold-based segmentation process is performed to subtract the background portion from the video frame. Then, features like colour, texture, etc., are extracted from the segmented image to perform the classification process. Finally, the extracted features are given input to the hybrid DRCNN-TSO algorithm for class label prediction. The TSO algorithm achieves the hyperparameter tuning of DRCNN. The proposed method has been executed in the Python platform. Finally, the performance of the proposed methodology is evaluated using the performance metrics (i.e. accuracy, false alarm rate, sensitivity, precision, F1 score, and false discovery rate), which are calculated using true positive (TP), false positive (FP), true negative (TN), and false-negative (FN) values. The obtained results are compared with existing techniques. Further, the Specificity, F1 score, false alarm rate and false discovery rate are compared with filtering and without filtering o show the efficiency of the proposed methodology.
C1 [Vatsavayi, Valli Kumari; Andavarapu, Nagaraju] Andhra Univ, Dept CS & SE, AUCE A, Visakhapatnam, Andhra Pradesh, India.
C3 Andhra University
RP Vatsavayi, VK (corresponding author), Andhra Univ, Dept CS & SE, AUCE A, Visakhapatnam, Andhra Pradesh, India.
EM vallikumari@gmail.com; nagraz.a@gmail.com
RI Vatsavayi, Valli Kumari/AAH-1539-2019
OI Vatsavayi, Valli Kumari/0000-0002-7252-8301
CR Abuduweili A, 2019, ARXIV PREPRINT ARXIV
   Alharbi F, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927702033
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Banupriya N., 2020, J CRIT REV, V7, P434, DOI 10.31838/jcr.07.01.85
   Bhardwaj S, 2019, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.2019.00044
   Carl C, 2020, EUR J WILDLIFE RES, V66, DOI 10.1007/s10344-020-01404-y
   Chen RL, 2019, ECOL EVOL, V9, P9453, DOI 10.1002/ece3.5410
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Conway AM, 2020, FRAME BY FRAME ANNO
   Dwibedi Debidatta, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10384, DOI 10.1109/CVPR42600.2020.01040
   El Abbadi Nidhal K., 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P72, DOI 10.1109/CSASE48920.2020.9142070
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gholap A.B., 2019, International Journal of Engineering and Advanced Technology (IJEAT), V8, P495, DOI [10.35940/ijeat.a1089.1291s319, DOI 10.35940/IJEAT.A1089.1291S319, 10.35940/ijeat.E7911.088619]
   Guo YH, 2020, IET IMAGE PROCESS, V14, P585, DOI 10.1049/iet-ipr.2019.1042
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Hou J, 2020, BIOL CONSERV, V242, DOI 10.1016/j.biocon.2020.108414
   Ibraheam Mai, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P523, DOI 10.1007/978-3-030-44041-1_47
   Islam SB, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P537, DOI [10.1109/CCWC47524.2020.9031190, 10.1109/ccwc47524.2020.9031190]
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Krishnaveni P, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01668-6
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Mathis MW, 2020, CURR OPIN NEUROBIOL, V60, P1, DOI 10.1016/j.conb.2019.10.008
   Meena D, 2020, INT J FUZZY SYST, V22, P1868, DOI 10.1007/s40815-020-00907-9
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Pucci R, 2020, ARXIV PREPRINT ARXIV
   Qiao SC, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8895875
   Rakesh TM, 2019, INT J ENG RES TECHNO, V8
   Rauf HT, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105075
   Schofield D, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aaw0736
   Singh P, 2020, IEEE SW SYMP IMAG, P66, DOI [10.1109/SSIAI49293.2020.9094613, 10.1109/ssiai49293.2020.9094613]
   Sreedevi CK., 2019, P INT C SYST EN ENV
   Suhas MV., 2019, COMPUSOFT, V8, P3069
   Verma Gyanendra K., 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P327, DOI 10.1007/978-981-10-7898-9_27
   Verma GK, 2018, INT J COMPUT INTELL, V17, DOI 10.1142/S1469026818500219
   Williams HM, 2019, BEHAV ECOL SOCIOBIOL, V74, DOI 10.1007/s00265-019-2789-2
   Yousif H, 2019, ECOL EVOL, V9, P1578, DOI 10.1002/ece3.4747
NR 38
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 33335
EP 33360
DI 10.1007/s11042-022-12852-w
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000784122800010
DA 2024-07-18
ER

PT J
AU Sharma, G
   Jindal, N
AF Sharma, Gouri
   Jindal, Neeru
TI Breast tumour detection using machine learning: review of selected
   methods from 2015 to 2021
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Breast tumour detection; Medical imaging; Machine learning;
   Segmentation; Classification
ID MASS CLASSIFICATION; MITOSIS DETECTION; CANCER; SEGMENTATION; DIAGNOSIS;
   IDENTIFICATION; MAMMOGRAMS; HISTOGRAM; FEATURES; SYSTEM
AB Breast tumour is one of the leading causes of death among women worldwide. Researchers are working hard to develop early and improved detection tools for breast tumour. Several innovations lead to the decline in the mortality rate for this lethal illness, but breast amputation and early death diagnosis contributed the most to preventing disease transmission. Early detection of a breast tumour allows for the most effective treatment. By using several different techniques, imaging of breast cancer can be done and some of these techniques are X-ray, MRI, CT, Ultrasonography, and now Molecular Imaging. This paper examines similar works that use Mammography, X-ray, Ultrasound, Biopsy and Artificial Intelligence, highlighting their benefits and limitations, as well as open issues and research challenges. In the literature, a variety of machine learning, artificial neural networks, and deep learning models were employed to process thermographic or mammographic images of breast tumour, including, Support Vector Machine, Bayes Net, decision tree, K-Nearest Neighbors (KNN), Deconvolutional Neural Networks (DNN), Convolutional Neural Networks (CNN) and CAD system. This study also discusses the different datasets used for breast tumour detection.
C1 [Sharma, Gouri; Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Sharma, G (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM gsharma1_me20@thapar.edu; neeru.jindal@thapar.edu
CR Abdel-Nasser M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010100
   Aghdam H. H., 2017, Guide to Convolutional Neural Networks: A Practical Application to Traffic-Sign Detection and Classification, DOI DOI 10.1007/978-3-319-57550-6
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-hadidi MR, 2016, I C DEV ESYST ENG, P35, DOI 10.1109/DeSE.2016.8
   Al-Sammarraie LHA, 2020, 2020 4 INT S MULT ST, DOI [10.1109/ISMSIT50672.2020.9254891, DOI 10.1109/ISMSIT50672.2020.9254891]
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Araujo T, 2017, CLASSIFICATION BREAS
   Asri H, 2016, PROCEDIA COMPUT SCI, V83, P1064, DOI 10.1016/j.procs.2016.04.224
   Bajaj V, 2019, NEURAL COMPUT APPL, V31, P3307, DOI 10.1007/s00521-017-3282-3
   Baneriee C, 2017, 2017 INT C COMPUTER, DOI [10.1109/ICCECE.2017.8526215, DOI 10.1109/ICCECE.2017.8526215]
   Beevi KS, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2694004
   Benmazou S, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP)
   Beura S, 2015, NEUROCOMPUTING, V154, P1, DOI 10.1016/j.neucom.2014.12.032
   Bhangu K. S., 2020, P 6 INT C PAR DISTR, P438, DOI [10.1109/PDGC50313.2020.9315815, DOI 10.1109/PDGC50313.2020.9315815]
   Bhardwaj H, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P2186, DOI 10.1109/SSCI.2018.8628935
   Bhide A, 2020, CASE HIST SIGNIFICAN
   Cai D, 2019, I S BIOMED IMAGING, P919, DOI [10.1109/isbi.2019.8759461, 10.1109/ISBI.2019.8759461]
   Caorsi S, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTROMAGNETICS IN ADVANCED APPLICATIONS (ICEAA), P1236, DOI 10.1109/ICEAA.2017.8065494
   Carneiro G, 2017, IEEE T MED IMAGING, V36, P2355, DOI 10.1109/TMI.2017.2751523
   Cascetta, 2021, BREAST BIOPSY
   Castro Eduardo, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P230, DOI 10.1109/BHI.2018.8333411
   Chaurasia V, 2014, IJCSMC
   Chiang TC, 2019, IEEE T MED IMAGING, V38, P240, DOI 10.1109/TMI.2018.2860257
   Dabass J, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P658, DOI 10.1109/CONFLUENCE.2019.8776937
   Darapureddy Nagadevi, 2019, 2019 4th International Conference on Recent Trends on Electronics, Information, Communication & Technology (RTEICT), P351, DOI 10.1109/RTEICT46194.2019.9016822
   Deb SD, 2020, NATL CONF COMMUN, DOI [10.1109/WIECON-ECE52138.2020.9397935, 10.1109/ncc48643.2020.9056011]
   Dempsey PJ, 2004, J ULTRAS MED, V23, P887, DOI 10.7863/jum.2004.23.7.887
   Desai Shrinivas D, 2020, 2020 12 INT C COMP I, P34, DOI [DOI 10.1109/CICN49253.2020.9242551, 10.1109/CICN49253.2020.9242551]
   DeSantis C, 2014, CA-CANCER J CLIN, V64, P52, DOI 10.3322/caac.21203
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Diaz RAN, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEM (ICORIS), P233, DOI [10.1109/ICORIS.2019.8874873, 10.1109/icoris.2019.8874873]
   Elston C W, 2002, Histopathology, V41, P154
   felman Adam, 2019, WHAT KNOW BREAST CAN
   Ghosh S, 2017, IEEE REG 10 HUMANIT, P792, DOI 10.1109/R10-HTC.2017.8289075
   Giusti A, 2014, I S BIOMED IMAGING, P1360, DOI 10.1109/ISBI.2014.6868130
   Gupta B, 2017, MULTIDIM SYST SIGN P, V28, P1549, DOI 10.1007/s11045-016-0432-1
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Helwan A, 2015, I CON ADV BIOMED ENG, P17, DOI 10.1109/ICABME.2015.7323240
   Hossam A, 2018, INT J COMPUT SCI INF
   Husan S, 2016, BREAST ULTRASOUND SC
   Iqbal HT, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8918687
   Iranmakani S, 2020, EGYPT J RADIOL NUC M, V51, DOI 10.1186/s43055-020-00175-5
   Ismail Nur Syahmi, 2019, 2019 International UNIMAS STEM 12th Engineering Conference (EnCon). Proceedings, P89, DOI 10.1109/EnCon.2019.8861256
   Jafarbiglo SK, 2018, 2018 4TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P89, DOI 10.1109/ICSPIS.2018.8700540
   Jalalian A, 2017, EXCLI J, V16, P113, DOI [10.17179/excli201-701, 10.17179/excli2016-701]
   Jebathangam J, 2016, ANAL SEGMENTATION ME
   Jiao ZC, 2018, PATTERN RECOGN, V75, P292, DOI 10.1016/j.patcog.2017.07.008
   Jiao ZC, 2016, NEUROCOMPUTING, V197, P221, DOI 10.1016/j.neucom.2016.02.060
   Jochelson M, 2017, BREAST CANC STAGING
   Jongwon Chang, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210843
   Jung NY, 2014, WORLD J SURG ONCOL, V12, DOI 10.1186/1477-7819-12-168
   Kanchana M, 2016, INT J WAVELETS MULTI, V14, DOI 10.1142/S021969131650017X
   Kavya N, 2018, BREAST CANC DETECTIO, DOI [10.1109/CIMCA.2018.8739662, DOI 10.1109/CIMCA.2018.8739662]
   Kennedy DA, 2009, INTEGR CANCER THER, V8, P9, DOI 10.1177/1534735408326171
   Kethavarapu U, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ADVANCED COMPUTING (ICCTAC)
   Khan AA, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P412, DOI 10.1109/ICSCCC.2018.8703342
   Khan MHM, 2017, 2017 3RD IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P54, DOI 10.1109/ICSPIS.2017.8311589
   Khan S, 2017, MULTIMED TOOLS APPL, V76, P33, DOI 10.1007/s11042-015-3017-3
   Khourdifi Y, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ADVANCED ELECTRICAL AND COMMUNICATION TECHNOLOGIES (ISAECT)
   Kiymet S, 2019, 2019 INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS CONFERENCE (ASYU), P52, DOI 10.1109/asyu48272.2019.8946367
   Koch H, 2016, RADIOLOGIA BRASILEIR
   Kozegar E, 2018, IEEE T MED IMAGING, V37, P918, DOI 10.1109/TMI.2017.2787685
   Kumar MN, 2019, 2019 INT C SMART SYS, DOI [10.1109/ICSSIT46314.2019.8987818, DOI 10.1109/ICSSIT46314.2019.8987818]
   Laghmati S, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS AND MOBILE COMMUNICATIONS (WINCOM), P67, DOI 10.1109/wincom47513.2019.8942575
   Lee JH, 2022, IEEE T MED IMAGING, V41, P225, DOI 10.1109/TMI.2021.3108949
   Lessa V, 2016, LECT NOTES COMPUT SC, V9972, P429, DOI 10.1007/978-3-319-46418-3_38
   Liberman L, 2002, AM J ROENTGENOL, V179, P171, DOI 10.2214/ajr.179.1.1790171
   Lin H, 2018, IEEE WINT CONF APPL, P539, DOI 10.1109/WACV.2018.00065
   Lu HC, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P9, DOI [10.1109/icaibd.2019.8837000, 10.1109/ICAIBD.2019.8837000]
   Lu Y, 2018, REV BREAST CANC DETE, DOI [10.1109/vcip.2018.8698732, 10.1109/VCIP.2018.869873, DOI 10.1109/VCIP.2018.869873]
   Ma J, 2019, VIBROENGINEERING PRO, DOI [10.21595/vp.2019.20978, DOI 10.21595/VP.2019.20978]
   Maheshwar, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P683, DOI 10.1109/ICSSIT46314.2019.8987778
   Min S, 2017, KSII T INTERNET INF, V11, P1134, DOI 10.3837/tiis.2017.02.029
   Mishra S, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P211, DOI 10.23919/indiacom49435.2020.9083722
   Mohana RM, 2019, INT J RECENT TECHNOL
   Moll J, 2021, 2021 15 EUR C ANT PR, DOI [10.23919/EuCAP51087.2021.9411493, DOI 10.23919/EUCAP51087.2021.9411493]
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Mouelhi A, 2018, COMPUT METH PROG BIO, V165, P37, DOI 10.1016/j.cmpb.2018.08.005
   Muramatsu C, 2018, PROC INT WORKSH ADV
   MurtiRawat Ram, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P534, DOI 10.1109/ICESC48915.2020.9155783
   Muthuselvan S, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Naderan M., 2020, P 2020 IEEE 2 INT C, P1, DOI [10.1109/SAIC51296.2020.9239139, DOI 10.1109/SAIC51296.2020.9239139]
   NHS, 2019, OV BREAST CANC WOM
   Parvin F, 2020, IEEE REGION 10 SYMP, P945
   Paul A, 2015, IEEE T IMAGE PROCESS, V24, P4041, DOI 10.1109/TIP.2015.2460455
   Phyu TN, 2009, LECT NOTES ENG COMP, P727
   Pramanik S, 2019, IEEE T MED IMAGING, V38, P572, DOI 10.1109/TMI.2018.2867620
   Pramanik S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P8, DOI 10.1109/ICACCI.2016.7732018
   Pramanik S, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), P205, DOI 10.1109/ISACC.2015.7377343
   Prasad SN, 2007, ROLE VARIOUS MODALIT
   Radiology info, 2019, BRE CANC SCREENING
   Raghavendra U, 2016, QUANT INFR THERM J, V13, P195, DOI 10.1080/17686733.2016.1176734
   Roslidar Roslidar, 2019, 2019 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom). Proceedings, P77, DOI 10.1109/CYBERNETICSCOM.2019.8875661
   Routray I, 2018, INT CONF COMPUT
   Roux L., 2014, Mitos atypia
   RSNA, 2020, BRE CANC SCREENING
   Sadoughi F, 2018, BREAST CANCER-TARGET, V10, P219, DOI 10.2147/BCTT.S175311
   Santana Maíra Araújo de, 2018, Res. Biomed. Eng., V34, P45, DOI 10.1590/2446-4740.05217
   Selvathi, 2017, MIDDLE-EAST J SCI RE, P25
   Shah H, 2015, INT J SCI TECHNOLOGY
   Sharma K, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2743, DOI 10.1109/ICACCI.2016.7732477
   Sharma S, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON COMPUTATIONAL TECHNIQUES, ELECTRONICS AND MECHANICAL SYSTEMS (CTEMS), P114, DOI 10.1109/CTEMS.2018.8769187
   Shi P, 2018, COMPUT BIOL MED, V96, P178, DOI 10.1016/j.compbiomed.2018.03.011
   Shravya Ch., 2019, INT J INNOVATIVE TEC, V8
   shute Nancy, 2014, 3D MAMMOGRAPHY
   Shwetha SV, 2020, IOP C SER MAT SCI EN
   Singh AK, 2016, NOVEL APPROACH BREAS
   Singh Shiksha, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P498, DOI 10.1109/SPIN48934.2020.9071218
   Solanki LS, 2016, IEEE C EVOL COMPUTAT, P1370, DOI 10.1109/CEC.2016.7743948
   Sonar P, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION (ICSPC'17), P305, DOI 10.1109/CSPC.2017.8305858
   Surendiran B, 2015, INT J MED ENG INFORM
   Tan YJ, 2017, 2017 INTERNATIONAL CONFERENCE ON ROBOTICS, AUTOMATION AND SCIENCES (ICORAS)
   Teifke A, 2002, RADIOLOGY, V224, P881, DOI 10.1148/radiol.2243010547
   Thawkar, 2017, INT J INTELLIGENT EN
   The American Cancer Society medical and editorial content team, 2021, AM CANC SOC MED ED C
   Tripathi AS, 2013, MITIOS DETECTION BRE
   Velmurugan T, 2015, INDIAN J SCI TECHNOL
   Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795
   Yadav P, 2016, INTERNATIONAL CONFERENCE ON ADVANCES IN INFORMATION COMMUNICATION TECHNOLOGY & COMPUTING, 2016, DOI 10.1145/2979779.2979866
   Yeasmin S, 2020, 2020 11 INT C COMP C, DOI [10.1109/ICCCNT49239.2020.9225448, DOI 10.1109/ICCCNT49239.2020.9225448]
NR 120
TC 2
Z9 2
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32161
EP 32189
DI 10.1007/s11042-022-12859-3
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941600006
DA 2024-07-18
ER

PT J
AU Thati, RP
   Dhadwal, AS
   Kumar, P
   Sainaba, P
AF Thati, Ravi Prasad
   Dhadwal, Abhishek Singh
   Kumar, Praveen
   Sainaba, P.
TI A novel multi-modal depression detection approach based on mobile crowd
   sensing and task-based mechanisms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depression detection; Multi-modal; Mobile crowd sensing; Emotion
   elicitation; Speech elicitation; Machine learning
ID SOCIAL MEDIA; EXPRESSION; INVENTORY; SPACE
AB Depression has become a global concern, and COVID-19 also has caused a big surge in its incidence. Broadly, there are two primary methods of detecting depression: Task-based and Mobile Crowd Sensing (MCS) based methods. These two approaches, when integrated, can complement each other. This paper proposes a novel approach for depression detection that combines real-time MCS and task-based mechanisms. We aim to design an end-to-end machine learning pipeline, which involves multimodal data collection, feature extraction, feature selection, fusion, and classification to distinguish between depressed and non-depressed subjects. For this purpose, we created a real-world dataset of depressed and non-depressed subjects. We experimented with: various features from multi-modalities, feature selection techniques, fused features, and machine learning classifiers such as Logistic Regression, Support Vector Machines (SVM), etc. for classification. Our findings suggest that combining features from multiple modalities perform better than any single data modality, and the best classification accuracy is achieved when features from all three data modalities are fused. Feature selection method based on Pearson's correlation coefficients improved the accuracy in comparison with other methods. Also, SVM yielded the best accuracy of 86%. Our proposed approach was also applied on benchmarking dataset, and results demonstrated that the multimodal approach is advantageous in performance with state-of-the-art depression recognition techniques.
C1 [Thati, Ravi Prasad; Dhadwal, Abhishek Singh; Kumar, Praveen] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, South Ambazari Rd, Nagpur 440010, Maharashtra, India.
   [Sainaba, P.] Cent Univ Tamil Nadu, Dept Appl Psychol, Neelakudy, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; Central University of Tamil Nadu
RP Thati, RP (corresponding author), Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, South Ambazari Rd, Nagpur 440010, Maharashtra, India.
EM thati.raviprasad@gmail.com
RI Kumar, Praveen/AAA-8584-2022; Thati, Ravi Prasad/Q-2614-2015
OI Kumar, Praveen/0000-0003-4820-3088; Thati, Ravi
   Prasad/0000-0002-8366-5491
CR Agarwal S, 2013, 2013 INTERNATIONAL CONFERENCE ON MACHINE INTELLIGENCE AND RESEARCH ADVANCEMENT (ICMIRA 2013), P203, DOI 10.1109/ICMIRA.2013.45
   Alghowinem S, 2018, IEEE T AFFECT COMPUT, V9, P478, DOI 10.1109/TAFFC.2016.2634527
   Alghowinem S, 2013, IEEE IMAGE PROC, P4220, DOI 10.1109/ICIP.2013.6738869
   Alghowinem S, 2013, INT CONF AFFECT, P283, DOI 10.1109/ACII.2013.53
   Asgari M, 2014, IEEE INT WORKS MACH
   Baltrusaitis Tadas, 2018, 2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018), P59, DOI 10.1109/FG.2018.00019
   Barbosa PA, 2016, ELICITATION TECHNIQU, P503
   BECK AT, 1961, ARCH GEN PSYCHIAT, V4, P561, DOI 10.1001/archpsyc.1961.01710120031004
   Ciman M, 2018, IEEE T AFFECT COMPUT, V9, P51, DOI 10.1109/TAFFC.2016.2592504
   Colom F, 2009, BRIT J PSYCHIAT, V194, P260, DOI 10.1192/bjp.bp.107.040485
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cummins N, 2015, SPEECH COMMUN, V75, P27, DOI 10.1016/j.specom.2015.09.003
   Cummins N, 2015, SPEECH COMMUN, V71, P10, DOI 10.1016/j.specom.2015.03.004
   Cummins N, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3008
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   EKMAN P, 1990, J PERS SOC PSYCHOL, V58, P342, DOI 10.1037/0022-3514.58.2.342
   Ekman P., 1997, What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS), V2, P331
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fukazawa Y., 2020, J INF PROCESS, V28, P16, DOI DOI 10.2197/IPSJJIP.28.16
   Fukazawa Y, 2019, J BIOMED INFORM, V93, DOI 10.1016/j.jbi.2019.103151
   Girard JM, 2013, IEEE INT CONF AUTOMA
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kanter Jonathan W., 2003, Prim Care Companion J Clin Psychiatry, V5, P245
   Kelly D, 2020, INFORM FUSION, V53, P43, DOI 10.1016/j.inffus.2019.06.008
   Kelly D, 2017, IEEE J BIOMED HEALTH, V21, P1750, DOI 10.1109/JBHI.2017.2649602
   Khan A, 2022, J KING SAUD UNIV-COM, V34, P2688, DOI 10.1016/j.jksuci.2020.04.004
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Kumar S, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15122907
   Latif Siddique, 2020, IEEE Trans Artif Intell, V1, P85, DOI 10.1109/TAI.2020.3020521
   Li M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/4174857
   Lin LY, 2016, DEPRESS ANXIETY, V33, P323, DOI 10.1002/da.22466
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Liu JX, 2016, ACSR ADV COMPUT, V68, P1, DOI 10.1145/3185504
   Masud MT, 2020, J BIOMED INFORM, V103, DOI 10.1016/j.jbi.2019.103371
   Morales M., 2017, CRC handbook of thermal engineering, P1, DOI DOI 10.18653/V1/W17-3101
   Moshe I, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.625247
   Narziev N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051396
   Nasir M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P43, DOI 10.1145/2988257.2988261
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Palmius N, 2017, IEEE T BIO-MED ENG, V64, P1761, DOI 10.1109/TBME.2016.2611862
   Pampouchidou A, 2018, THESIS SCH BOURGOGNE
   Pampouchidou A, 2019, IEEE T AFFECT COMPUT, V10, P445, DOI 10.1109/TAFFC.2017.2724035
   Pampouchidou A, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P27, DOI 10.1145/2988257.2988266
   Panicker SS, 2019, BIOCYBERN BIOMED ENG, V39, P444, DOI 10.1016/j.bbe.2019.01.004
   Pediaditis M, 2015, IEEE ENG MED BIO, P3711, DOI 10.1109/EMBC.2015.7319199
   Ray A, 2019, MULTILEVEL ATTENTION, P81
   Rush AJ, 2003, BIOL PSYCHIAT, V54, P573, DOI 10.1016/S0006-3223(02)01866-8
   Saeb S, 2016, PEERJ, V4, DOI 10.7717/peerj.2537
   Salari N, 2020, GLOBALIZATION HEALTH, V16, DOI 10.1186/s12992-020-00620-0
   Scherer S, 2016, IEEE T AFFECT COMPUT, V7, P59, DOI 10.1109/TAFFC.2015.2440264
   Seppälä J, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/mental.9819
   Stasak B, 2018, INVESTIGATION ACOUST
   Uhrig MK, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00180
   Wang QX, 2018, J VIS COMMUN IMAGE R, V57, P228, DOI 10.1016/j.jvcir.2018.11.003
   WHO, 2017, Other common mental disorders: global health estimates
   Williamson J.R, 2014, 2014 ACM INT WORKSH, P65
   Williamson JR, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P11, DOI 10.1145/2988257.2988263
   Xiong HY, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P415, DOI 10.1145/2971648.2971711
NR 60
TC 16
Z9 16
U1 6
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4787
EP 4820
DI 10.1007/s11042-022-12315-2
EA APR 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000781124000007
PM 35431608
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Chaki, J
AF Chaki, Jyotismita
TI Two-fold brain tumor segmentation using fuzzy image enhancement and
   DeepBrainet2.0
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; Fuzzy image enhancement; DeepBrainet2; 0;
   Augmented dataset; Deep learning
ID CONVOLUTIONAL NEURAL-NETWORK; MRI
AB Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) is a challenging and essential task for brain tumor detection. In this article, a new two-fold fuzzy and deep learning-based approach is proposed for the segmentation of three types of brain tumor. A total of eight CNN-based approaches are proposed, from the basic architecture (Brainet1.0(1)) to the final architecture DeepBrainet2.0 to find out the optimal one for brain tumor segmentation. Brainet1.0(1) is upgraded to DeepBrainet2.0 via Brainet1.0(2) to Brainet1.0(4), Brainet2.0, Brainet3.0, and Deepbrainet1.0 by changing the number of layers, neurons, and type of connection between neurons. The best result (final brain tumor mask) is achieved by using DeepBrainet2.0 which utilizes an efficient skip-connection mapping plan to lean the brain tumor features. To make DeepBrainet2.0 efficient, enhanced train and test instances are created by utilizing a fuzzy-logic-based method. Also, a second augmented dataset is created which applies five types of augmentations to the images of the first dataset to convert the system into robust from the alteration in orientation, scale, and flip. The outcome of the proposed method is tested on three datasets where the accuracy rate obtained are 94.3%, 96.7%, and 95.2% which specifies the efficacy of the proposed approach.
C1 [Chaki, Jyotismita] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Chaki, J (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM jyotismita.c@gmail.com
RI Chaki, Jyotismita/T-4882-2019
OI Chaki, Jyotismita/0000-0003-1804-8590
CR Abbasi S, 2017, NEUROCOMPUTING, V219, P526, DOI 10.1016/j.neucom.2016.09.051
   Acharya UK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165760
   Chahal PK, 2020, MULTIMED TOOLS APPL, V79, P21771, DOI 10.1007/s11042-020-08898-3
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143903
   Das TK, 2020, J BIOMIM BIOMATER BI, V45, P57, DOI 10.4028/www.scientific.net/JBBBE.45.57
   Dolz J, 2016, COMPUT MED IMAG GRAP, V52, P8, DOI 10.1016/j.compmedimag.2016.03.003
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   Hu K, 2019, IEEE ACCESS, V7, P92615, DOI 10.1109/ACCESS.2019.2927433
   Jesson A, 2018, LECT NOTES COMPUT SC, V10670, P392, DOI 10.1007/978-3-319-75238-9_34
   Kaur H, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P770, DOI 10.1109/WiSPNET.2016.7566237
   Li ZJ, 2018, LECT NOTES COMPUT SC, V10670, P123, DOI 10.1007/978-3-319-75238-9_11
   Lin FM, 2021, MULTIMED TOOLS APPL, V80, P22951, DOI 10.1007/s11042-020-08795-9
   Noori M, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2019), P269, DOI [10.1109/iccke48569.2019.8964956, 10.1109/ICCKE48569.2019.8964956]
   Pereira S, 2018, LECT NOTES COMPUT SC, V11072, P706, DOI 10.1007/978-3-030-00931-1_81
   Pereira S, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Punn NS, 2021, MULTIMED TOOLS APPL, V80, P30305, DOI 10.1007/s11042-020-09271-0
   Ranjbar S, 2020, ARXIV PREPRINT ARXIV
   Remya R, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102158
   Samuel J, 2007, P INT SOC MAG RESON, V15, P3701
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Shaikh M, 2018, LECT NOTES COMPUT SC, V10670, P309, DOI 10.1007/978-3-319-75238-9_27
   Sharif M, 2020, COGN SYST RES, V59, P273, DOI 10.1016/j.cogsys.2019.10.001
   Sun JW, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1358-6
   Sun JD, 2021, NEUROCOMPUTING, V423, P34, DOI 10.1016/j.neucom.2020.10.031
   Sun Y, 2019, IEEE IMAGE PROC, P1535, DOI [10.1109/icip.2019.8803073, 10.1109/ICIP.2019.8803073]
   Vaidhya Kiran, 2016, Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. First International Workshop, Brainles 2015, held in conjunction with MICCAI 2015. Revised Selected Papers: LNCS 9556, P181, DOI 10.1007/978-3-319-30858-6_16
   Zhao XM, 2016, LECT NOTES COMPUT SC, V10154, P75, DOI 10.1007/978-3-319-55524-9_8
   Zhou ZX, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103766
   Zhou ZX, 2020, NEUROCOMPUTING, V402, P235, DOI 10.1016/j.neucom.2020.03.097
NR 29
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30705
EP 30731
DI 10.1007/s11042-022-13014-8
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700004
DA 2024-07-18
ER

PT J
AU Kannao, R
   Guha, P
   Chaudhuri, BB
AF Kannao, Raghvendra
   Guha, Prithwijit
   Chaudhuri, Bidyut B.
TI Only overlay text: novel features for TV news broadcast video
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV News Broadcast Segmentmentation; Advertisement Detection; Story
   Segmentation; Text Detection; Text Tracking
ID MODEL
AB Segmentation of television news videos into programs and stories (after removing advertisements) is a necessary first step for news broadcast analysis. Existing methods have used manually defined presentation styles as an important feature for such segmentation. Manually defined presentation styles make algorithms channel specific and hampers scalability for large number of channels. In this work, we advocate the usebility of overlay text for automatic characterization of broadcast presentation styles. This automatic characterization will minimize the manual intervention required in developing the scalable solutions for television news broadcast segmentation. To this end, we introduce three novel features solely derived from position and content of overlay text bands. These are Bag of Bands (BoB), BoB Templates (BoBT) and Text-based Semantic Similarity (TSS). The BoB features characterize on-screen distribution of text bands and are used with classifiers for advertisement detection. The BoBT features characterize co-occurrence of text bands. Thereby modeling the presentation styles of video shots. Sequences of BoBT features are modeled using Conditional Random Fields (CRFs) for identifying program boundaries. Sequences of features derived from semantic similarity (TSS) between consecutive shots and BoBT feature are used with CRFs for story segmentation. Performances of the proposed features are validated on 360 hours of broadcast data recorded from three Indian English news channels. Benchmark on baseline methods has shown better performance of our proposal.
C1 [Kannao, Raghvendra; Guha, Prithwijit] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
   [Chaudhuri, Bidyut B.] Indian Stat Inst Kolkata, Kolkata 700108, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Statistical Institute; Indian
   Statistical Institute Kolkata
RP Kannao, R (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, North Guwahati 781039, Assam, India.
EM raghvendra@iitg.ac.in; pguha@iitg.ac.in; bidyutbaranchaudhuri@gmail.com
OI Kannao, Raghvendra/0000-0003-2083-2560
CR An E, 2019, LARGE SCALE VIDEO CL
   [Anonymous], 2015, MULTIMED TOOLS APPL
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2018, IP TELEVISION MAGAZI
   [Anonymous], 2013, INT C MULT RETR
   [Anonymous], 2003, TRECVID C GAITH WASH
   [Anonymous], 2004, Trecvid 2004-anoverview
   [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   Browne P, 2002, 11 TEXT RETR C
   Charlet D, 2015, INT CONF ACOUST SPEE, P5261, DOI 10.1109/ICASSP.2015.7178975
   Chatzis SP, 2013, IEEE T PATTERN ANAL, V35, P1523, DOI 10.1109/TPAMI.2012.208
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P2225, DOI 10.1109/TMM.2015.2481711
   Chua T.-S., 2004, PROC ACMMM, P656, DOI [10.1145/1027527.1027679, DOI 10.1145/1027527.1027679]
   Claveau V, 2015, COMPUT SPEECH LANG, V29, P63, DOI 10.1016/j.csl.2014.04.006
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Dietterich T. G., 2002, Structural, syntactic, and statistical pattern recognition, DOI [DOI 10.1007/3-540-70659-3_2, 10.1007/3-540-70659-3_2]
   Dimitrova N., 2000, Signal Processing Conference, 2000 10th European, P1
   Direkoglu C, 2018, MACH VISION APPL, V29, P891, DOI 10.1007/s00138-018-0944-9
   Duygulu P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1267, DOI 10.1109/ICME.2004.1394454
   Feng BL, 2014, MULTIMEDIA SYST, V20, P347, DOI 10.1007/s00530-013-0350-0
   Feng BL, 2012, INT CONF ACOUST SPEE, P1417, DOI 10.1109/ICASSP.2012.6288156
   Ghosh H, 2010, INT J DIGIT MULTIMED, V2010, DOI 10.1155/2010/486487
   Gunter B, 2015, COGNITIVE IMPACT OF TELEVISION NEWS: PRODUCTION ATTRIBUTES AND INFORMATION RECEPTION, P1
   Hachten WA., 2015, The World News Prism: Digital, Social and Interactive, V9th
   Hua XS, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P149
   Jiaxi Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P456, DOI 10.1007/978-3-030-58517-4_27
   Jindal A., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P458, DOI 10.1109/ISM.2011.81
   Kannan R., 2015, Adaptive sensor fusion technology for mobile and wearable applications, SENSORS, 2015 IEEE, P1
   Kannao Raghvendra, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P793, DOI 10.1007/978-3-319-27671-7_66
   Kannao R, 2016, INT C PATTERN RECOGN
   Kannao R, 2016, IND C COMP VIS GRAPH, P164
   Kannao R, 2019, MULTIMED TOOLS APPL, V78, P31925, DOI 10.1007/s11042-019-7699-9
   Kannao R, 2017, PATTERN RECOGN, V68, P38, DOI 10.1016/j.patcog.2017.02.029
   Kim JW., 2014, INT J STW ENG APPL, V8, P229
   Kim W, 2010, J SIGNAL PROCESS SYS, V61, P251, DOI 10.1007/s11265-009-0446-0
   Lafferty John, 2001, INT C MACH LEARN ICM
   Li Hongzhi., 2013, Proceedings of the 21st ACM international conference on Multimedia, P449
   Lienhart R, 2003, INT SER VIDEO COMPUT, V6, P155
   Liu N, 2011, IEEE T MULTIMEDIA, V13, P961, DOI 10.1109/TMM.2011.2160334
   Liu Z, 2018, INT C MULT EXP WORKS, P19
   Lu XM, 2013, INT CONF ACOUST SPEE, P8465, DOI 10.1109/ICASSP.2013.6639317
   Misra H, 2016, ADV MULTIMEDIA MODEL, P347
   Muhling M, 2007, TREC VIDEO RETRIEVAL
   Nakamura Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P393, DOI 10.1145/266180.266391
   Perebinossoff Philippe., 2005, PROGRAMMING TV RADIO
   Qusenot GM, 2004, TREC VIDEO RETRIEVAL
   Renoust B, 2016, IEEE T MULTIMEDIA, V18, P2184, DOI 10.1109/TMM.2016.2614224
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Smola A. J., 2003, Advances in Neural Information Processing Systems, P585
   Su XK, 2009, ISIP: 2009 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING, PROCEEDINGS, P175
   Trojahn TH, 2021, MULTIMED TOOLS APPL, V80, P17487, DOI 10.1007/s11042-020-10450-2
   Volkmer T, 2004, TREC VIDEO RETRIEVAL
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang XQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030888
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu XM, 2013, IEEE T CIRC SYST VID, V23, P1054, DOI 10.1109/TCSVT.2013.2248991
   Xiang Wang, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.70
   Xu Zhenqi, 2016, 2016 IEEE INT C MULT, P1, DOI [10.1109/ICME.2016.7552971, DOI 10.1109/ICME.2016.7552971]
   Zhang L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P587
   Zhang SY, 2018, IEEE IPCCC
NR 63
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30493
EP 30517
DI 10.1007/s11042-022-12917-w
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778931200002
DA 2024-07-18
ER

PT J
AU Naqvi, N
   Islam, MS
   Iqbal, M
   Kanwal, S
   Khan, A
   Ye, ZF
AF Naqvi, Nuzhat
   Islam, M. Shujah
   Iqbal, Mansoor
   Kanwal, Shamsa
   Khan, Asad
   Ye, ZhongFu
TI Deep neural combinational model (DNCM): digital image descriptor for
   child's independent learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Automatic image captioning; CNN; LSTM; RNN; Combinational
   model; Children independent learning
ID ATTENTION
AB This project is an endeavor to address preschool children's independent learning. Currently, technology is invading our lives, and working parents are busily overpowering their social setup. As a result, the art of preschool education to young children has become rare or vanished. Automatic image descriptors (captioning models) have recently shown their effectiveness, motivating us to utilize such models for address purposes. Unfortunately, developed image descriptors produce only complex and generic visual descriptions irrelevant to children's understanding. Therefore, it is important to have a suitable image descriptor as teaching material for young children at the initial educational stage. To fill this gap, we introduced a novel digital image descriptor and 3k-Flickr-SDD dataset using smart augmentation that originally extracted and labeled solitary dogs' images from Flickr8k and Stanford Dogs Dataset (SDD) datasets. The newly developed 3k-Flickr-SDD dataset split further into two versions, making it meet the standard experimental requirements. The proposed method accumulates Convolutional Neural Networks (CNNs) for image contents extraction, whereas; Long Short-term Memory (LSTM) language model customizes to generate understandable and attractive text from Dogs images. We performed the quantitative and qualitative analysis; the finding reveals that the proposed model outperforms in contrast to existing models.
C1 [Naqvi, Nuzhat; Islam, M. Shujah; Iqbal, Mansoor; Kanwal, Shamsa; Ye, ZhongFu] Univ Sci & Technol China USTC, Hefei, Peoples R China.
   [Khan, Asad] South China Normal Univ, Sch Comp Sci, Guangzhou, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; South China Normal University
RP Naqvi, N (corresponding author), Univ Sci & Technol China USTC, Hefei, Peoples R China.
EM nuzhatnaqvi@mail.ustc.edu.cn; mshujahislam@mail.ustc.edu.cn;
   man2017@mail.ustc.edu.cn; shamsakanwal@mail.ustc.edu.cn;
   asadustc@gmail.com; yezf@ustc.edu.cn
RI Khan, Asad/KOD-6735-2024
OI Khan, Asad/0000-0002-1261-0418; Sameem, M Shujah
   Islam/0000-0003-3768-6045
FU China's National Natural Science Foundation [61671418]; Advanced
   Research Fund of the University of Science and Technology of China
FX This work is supported by China's National Natural Science Foundation
   (No. 61671418) and the Advanced Research Fund of the University of
   Science and Technology of China. Conflicts of Interest: The authors
   declare no conflict of interest.
CR [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], IMAGE CAPTION GENERA
   BARNETT WS, 1992, J HUM RESOUR, V27, P279, DOI 10.2307/145736
   Callison-Burch C, 2006, 11 C EUR CHAPT ASS C
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   Cui Y, 2018, PROC CVPR IEEE, P5804, DOI 10.1109/CVPR.2018.00608
   Degadwala Sheshang, 2021, 2021 6th International Conference on Communication and Electronics Systems (ICCES), P1103, DOI 10.1109/ICCES51350.2021.9489111
   Denoual E, 2005, P C INCL POST DEM TU
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fu K, 2017, IEEE T PATTERN ANAL, V39, P2321, DOI 10.1109/TPAMI.2016.2642953
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Hibbin R, 2016, PASTOR CARE EDUC, V34, P218, DOI 10.1080/02643944.2016.1225315
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   HOSSAIN MD ZAKIR, 2018, ARXIV PREPRINT ARXIV
   Jent J.F., 2011, PLAY INTERPERSONAL P
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khan S. M., 2021, INT JOINT C ADV COMP, P217
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Mao J, 2014, CELL DEATH DIS, V5, DOI 10.1038/cddis.2013.515
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Naqvi N, 2020, MULTIMED TOOLS APPL, V79, P24429, DOI 10.1007/s11042-020-09128-6
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Perry BruceD., 2010, BORN LOVE WHY EMPATH
   SHAH PH, 2017, P I MECH ENG L-J MAT, P1
   Soh M., 2016, LEARNING CNN LSTM AR
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Venter E, 2017, INT J ADOLESC YOUTH, V22, P497, DOI 10.1080/02673843.2016.1267022
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang C, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115432
   Warin J., 2011, Education and Health, V29, P19
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Ye ZF, 2021, MULTIMED TOOLS APPL, V80, P25557, DOI 10.1007/s11042-021-10632-6
   Yu FY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P305, DOI 10.1109/ICME.2006.262459
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
NR 45
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 29955
EP 29975
DI 10.1007/s11042-022-12291-7
EA APR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500004
DA 2024-07-18
ER

PT J
AU Smitha, A
   Jidesh, P
AF Smitha, A.
   Jidesh, P.
TI Detection of retinal disorders from OCT images using generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ophthalmic image analysis; Optical coherence tomography; Retinal
   disorder; Retinal image segmentation and classification; Age-related
   macular degeneration; Diabetic macular edema
ID OPTICAL COHERENCE TOMOGRAPHY; SEGMENTATION; LAYERS; CLASSIFICATION
AB Retinal image analysis has opened up a new window for prompt diagnosis and detection of various retinal disorders. Optical Coherence Tomography (OCT) is one of the major diagnostic tools to identify retinal abnormalities related to macular disorders like Age-Related Macular Degeneration (AMD) and Diabetic Macular Edema (DME). The clinical findings include retinal layer analysis to spot the abnormalities on OCT images. Though various models are proposed over the years to diagnose these disorders automatically, an end-to-end system that performs automatic denoising, segmentation, and classification does not exist to the best of our knowledge. This paper proposes a Generative Adversarial Network (GAN) based approach for automated segmentation and classification of OCT-B scans to diagnose AMD and DME. The proposed method incorporates the integration of handcrafted Gabor features to enhance the retina layer segmentation and non-local denoising to remove speckle noise. The classification metrics of GAN are compared with existing methods. The accuracy of up to 92.42% and F1-score of 0.79 indicates that the GANs can perform well for segmentation and classification of OCT images.
C1 [Smitha, A.; Jidesh, P.] Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Jidesh, P (corresponding author), Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal 575025, India.
EM jidesh@nitk.edu.in
RI P, J/KCK-9262-2024; P, Jidesh/C-6030-2017
OI P, Jidesh/0000-0001-9448-1906
FU Ministry of Education, Government of India; Department of Atomic Energy,
   Govt. of India [02011/17/2020NBHM(RP)/RDII/8073]
FX A. Smitha would like to acknowledge Prof. Vasudevan Lakshminarayanan,
   University of Waterloo, Canada, and Dr. J. Jothi Balaji, Medical
   Research Foundation, India, for their valuable suggestions regarding the
   research work. Smitha express her gratitude to the Ministry of
   Education, Government of India, for providing financial support (as
   fellowship) for carrying out the research at National Institute of
   Technology Karnataka, Surathkal. She also acknowledges the contribution
   of Mr. Abhinaba Hazarika, Master student at NITK, for assisting in the
   implementation and documentation of the proposed work. Dr. P. Jidesh
   thanks the Department of Atomic Energy, Govt. of India, for providing
   financial support under the research grant no.
   02011/17/2020NBHM(RP)/R&DII/8073.
CR Alqudah AM, 2020, MED BIOL ENG COMPUT, V58, P41, DOI 10.1007/s11517-019-02066-y
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Balasuriya BK, 2017, I C SOFTWARE KNOWL I
   Bandello F., 2019, DIABETIC MACULAR EDE, P97, DOI [10.1007/978-3-319-96157-6, DOI 10.1007/978-3-319-96157-6]
   Birch DG, 2007, INT J NANOMED, V2, P65, DOI 10.2147/nano.2007.2.1.65
   Brownlee J., 2020, CALCULATE FEATURE IM
   Chiu SJ, 2010, OPT EXPRESS, V18, P19413, DOI 10.1364/OE.18.019413
   Dai Z, 2017, ARXIVABS170509783
   Das V, 2020, IEEE SENSOR LETT, V4, DOI 10.1109/LSENS.2019.2963712
   Dodo BI, 2019, IEEE ACCESS, V7, P152388, DOI 10.1109/ACCESS.2019.2947761
   Febin IP, 2018, IMAGING SCI J, V66, P479, DOI 10.1080/13682199.2018.1518760
   Froment J, 2014, IMAGE PROCESS ON LIN, V4, P300, DOI 10.5201/ipol.2014.120
   Fuglede B, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P31
   Garcia-Layana, 2017, OPTICAL COHERENCE TO
   Girish GN, 2019, IEEE J BIOMED HEALTH, V23, P296, DOI 10.1109/JBHI.2018.2810379
   Glen S., 2014, P-value in statistical hypothesis testing: What is it?
   Goldman D.R, 2018, 15 1 DIABETIC MACULA
   Grandini M., 2020, arXiv preprint arXiv:2008.05756
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang LF, 2019, IEEE SIGNAL PROC LET, V26, P1026, DOI 10.1109/LSP.2019.2917779
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jidesh P, 2018, COMPUT ELECTR ENG, V70, P631, DOI 10.1016/j.compeleceng.2017.09.013
   Li JX, 2021, BIOMED OPT EXPRESS, V12, P2204, DOI 10.1364/BOE.417212
   Li QL, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.61
   Li XC, 2019, IEEE ACCESS, V7, P33771, DOI 10.1109/ACCESS.2019.2891975
   Ma YS, 2021, J INNOV OPT HEAL SCI, V14, DOI 10.1142/S1793545821400113
   Minitab, 2020, GOODN FIT IND DISTR
   Mishra Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66355-5
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moreira Neto C A, 2018, ATLAS RETINAL OCT OP, P1
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Paul D, 2020, COMP MED SY, P526, DOI 10.1109/CBMS49503.2020.00105
   Popescu Dan P, 2011, Biophys Rev, V3, P155, DOI 10.1007/s12551-011-0054-7
   Rasti R, 2018, IEEE T MED IMAGING, V37, P1024, DOI 10.1109/TMI.2017.2780115
   Roy AG, 2017, BIOMED OPT EXPRESS, V8, P3627, DOI 10.1364/BOE.8.003627
   Salimans T, 2016, ADV NEUR IN, V29
   Schmitt JM, 1999, J BIOMED OPT, V4, P95, DOI 10.1117/1.429925
   Sedai S, 2019, LECT NOTES COMPUT SC, V11764, P282, DOI 10.1007/978-3-030-32239-7_32
   Serener A., 2019, 2019 SCIENT M EL, P1
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Sudeep PV, 2016, BIOMED SIGNAL PROCES, V28, P1, DOI 10.1016/j.bspc.2016.03.001
   Sudeep PV, 2016, COMPUT BIOL MED, V71, P97, DOI 10.1016/j.compbiomed.2016.02.003
   Sunija AP, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105877
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang DB, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2926231
   Wang XJ, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS 2021), P260, DOI [10.1109/ICoIAS53694.2021.00053, 10.1109/ICBAIE52039.2021.9390034]
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Yanagihara RT, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.11
NR 50
TC 8
Z9 9
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29609
EP 29631
DI 10.1007/s11042-022-12475-1
EA APR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000778057700005
DA 2024-07-18
ER

PT J
AU Zhang, LM
   Li, FY
   Qin, C
AF Zhang, Lianming
   Li, Fengyong
   Qin, Chuan
TI Efficient reversible data hiding in encrypted binary image with Huffman
   encoding and weight prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Encrypted binary image; Huffman encoding; Weight
   prediction
ID SCHEME
AB This paper proposes an efficient reversible data hiding (RDH) scheme in encrypted binary image by combining Huffman encoding and weighted prediction. Since the pixel redundant space in binary image is very small, existing RDH schemes for encrypted binary image is very difficult to get a balance between large embedding capacity and high visual quality of recovered binary image. To provide an efficient solution, we first divide the original binary image into three different types of non-overlapping blocks, black blocks, white blocks and mixed blocks. Subsequently, the Huffman encoding mechanism is introduced to achieve a large embedding capacity in all blocks. Due to the correct decodability of Huffman coding, both black blocks and white blocks can be recovered lossless after extracting secret data. Furthermore, a weight prediction mechanism is designed to make an accurate prediction for the mixed blocks, which can be sequentially recovered by involving a large area of pixel correlation. Our method can efficiently achieve a large embedding capacity for additional data, while keeping a high visual quality for recovered image. Extensive experiments demonstrate that our method outperforms existing encrypted binary RDH schemes with higher visual quality and larger embedding capacity.
C1 [Zhang, Lianming; Li, Fengyong] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 Shanghai University of Electric Power; University of Shanghai for
   Science & Technology
RP Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 200090, Peoples R China.
EM fyli@shiep.edu.cn
RI Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU Natural Science Foundation of Shanghai [20ZR1421600]
FX This work was supported by the Natural Science Foundation of Shanghai
   (20ZR1421600).
CR Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   Di FQ, 2019, MULTIMED TOOLS APPL, V78, P34541, DOI 10.1007/s11042-019-08109-8
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Li FY, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00522-6
   Li FY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107454
   Li FY, 2018, IEEE ACCESS, V6, P29912, DOI 10.1109/ACCESS.2018.2841415
   Li N, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107476
   Li YZ, 2019, IEEE ACCESS, V7, P73573, DOI 10.1109/ACCESS.2019.2920178
   Long M, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107703
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   [马志鹏 Ma Zhipeng], 2013, [上海大学学报. 自然科学版, Journal of Shanghai University. Natural Science], V19, P111
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Ren HL, 2019, SIGNAL PROCESS, V165, P268, DOI 10.1016/j.sigpro.2019.07.020
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Wang CC, 2014, J SYST SOFTWARE, V93, P152, DOI 10.1016/j.jss.2014.02.023
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yin XL, 2020, ADV INTELL SYST, V895, P891, DOI 10.1007/978-3-030-16946-6_73
   Yin ZX, 2022, IEEE T DEPEND SECURE, V19, P992, DOI 10.1109/TDSC.2020.3019490
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Zhang F, 2019, MULTIMED TOOLS APPL, V78, P21891, DOI 10.1007/s11042-019-7519-2
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 29
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29347
EP 29365
DI 10.1007/s11042-022-12710-9
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900001
DA 2024-07-18
ER

PT J
AU Tank, VR
   Mahajan, SP
AF Tank, Vanita Raj
   Mahajan, Shrinivas Padmakar
TI Adaptive recurrent nonnegative matrix factorization with phase
   compensation for Single-Channel speech enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single Channel speech enhancement; Optimal deep learning; Signal
   decomposition; Phase compensation; Adaptive attack power-based sail fish
   optimization; Adaptive recurrent nonnegative matrix factorization
ID NOISE; MODEL
AB The speech signals are affected by the background noise distortion that is unfavorable to both the intelligibility as well as the speech quality. Most of the speech processing algorithms function with the spectral magnitude without consideration of the spectral phase by leaving them unexplored and unstructured. The proposed single channel speech enhancement model called the Adaptive Recurrent Nonnegative Matrix Factorization (AR-NMF) is designed based on the phase compensation strategy with deep learning. The two major phases considered here are the training phase and the testing phase. During the process of training, the noisy speech signal is decomposed by the Hurst exponent-based Empirical Mode Decomposition (HEMD) and is converted into the frequency domain using Short Time Fourier Transform. Further, the new AR-NMF is used for denoising, where the tuning factor is optimally generated by the optimized RNN. Here, the hidden neurons are optimized using the proposed Adaptive Attack Power-based Sail Fish Optimization (AAP-SFO) with consideration of minimizing the Mean Absolute Error between the actual value and the predicted value. Finally, this phase compensated speech signal is given to the ISTFT that results in the final denoised clean speech signal. From the analysis, the CSED of AAP-SFO-AR-NMF for the street noise is 58.24%, 57.34%, 56.72%, and 77.37% more than RNMF, esHRNR, esTSNR, and Vuvuzela respectively. The performance of the proposed deep enhancement method is extensively evaluated and compared to diverse adverse noisy environments that describe the superiority of the proposed method.
C1 [Tank, Vanita Raj] DrVishwanath Karad MIT World Peace Univ, Elect & Commun, Pune, Maharashtra, India.
   [Mahajan, Shrinivas Padmakar] Savitribai Phule Pune Univ, Coll Engn, Elect & Telecommun, Pune, Maharashtra, India.
C3 College of Engineering Pune; Savitribai Phule Pune University
RP Tank, VR (corresponding author), DrVishwanath Karad MIT World Peace Univ, Elect & Commun, Pune, Maharashtra, India.
EM vanita.tank@mitwpu.ac.in
RI Mahajan, Shrinivas/AAX-3447-2021
CR [Anonymous], 2016, J ACOUST SOC AM
   Barysenka SY, 2018, SPEECH COMMUN, V99, P144, DOI 10.1016/j.specom.2018.03.009
   Benesty J, 2015, SINGLE CHANNEL NOISE, P31
   Chung H, 2017, SPEECH COMMUN, V87, P18, DOI 10.1016/j.specom.2016.11.003
   Dionelis N, 2018, IEEE-ACM T AUDIO SPE, V26, P937, DOI 10.1109/TASLP.2018.2800525
   Doire CSJ, 2017, IEEE-ACM T AUDIO SPE, V25, P572, DOI 10.1109/TASLP.2016.2641904
   Du J, 2016, IEEE-ACM T AUDIO SPE, V24, P1424, DOI 10.1109/TASLP.2016.2558822
   Gerkmann T, 2015, IEEE SIGNAL PROC MAG, V32, P55, DOI 10.1109/MSP.2014.2369251
   Islam MS, 2020, DIGIT SIGNAL PROCESS, V100, DOI 10.1016/j.dsp.2020.102697
   Jafari M, 2017, EUR J MECH A-SOLID, V66, P1, DOI 10.1016/j.euromechsol.2017.06.003
   Krawczyk M, 2014, IEEE-ACM T AUDIO SPE, V22, P1931, DOI 10.1109/TASLP.2014.2354236
   Kulmer J, 2015, IEEE SIGNAL PROC LET, V22, P598, DOI 10.1109/LSP.2014.2365040
   Laufer Y, 2019, IEEE-ACM T AUDIO SPE, V27, P225, DOI 10.1109/TASLP.2018.2876177
   Lavanya T, 2020, IEEE-ACM T AUDIO SPE, V28, P1315, DOI 10.1109/TASLP.2020.2986877
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Mowlaee P, 2017, SPEECH COMMUN, V86, P85, DOI 10.1016/j.specom.2016.11.008
   Mowlaee P, 2015, IEEE-ACM T AUDIO SPE, V23, P1521, DOI 10.1109/TASLP.2015.2439038
   Mowlaee P, 2015, IEEE-ACM T AUDIO SPE, V23, P1283, DOI 10.1109/TASLP.2015.2430820
   Mowlaee P, 2013, IEEE SIGNAL PROC LET, V20, P1235, DOI 10.1109/LSP.2013.2286748
   Mowlaee Pejman, 2016, Single Channel Phase-Aware Signal Processing in Speech Communication: Theory and Practice
   Murthy MYB, 2022, BIOMED ENG LETT, V12, P37, DOI 10.1007/s13534-021-00209-5
   Plapous C, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P289
   Plapous C, 2006, IEEE T AUDIO SPEECH, V14, P2098, DOI 10.1109/TASL.2006.872621
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMPUTING RESEARCH (ICCIC), P606
   Saleem N., 2020, J COMMUN TECHNOL EL+, V64, P1382
   Saleem N, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106666
   Saleem N, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107385
   Sandhya P., 2015, INT J APPL INFORM CO, V1, P26
   Shadravan S, 2019, ENG APPL ARTIF INTEL, V80, P20, DOI 10.1016/j.engappai.2019.01.001
   So S, 2011, SPEECH COMMUN, V53, P818, DOI 10.1016/j.specom.2011.02.001
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Unnisa N, 2022, WIRELESS PERS COMMUN, V122, P3019, DOI 10.1007/s11277-021-09039-1
   Wakabayashi Y, 2018, IEEE-ACM T AUDIO SPE, V26, P1559, DOI 10.1109/TASLP.2018.2831632
   Wang DS, 2018, SOFT COMPUT, V22, P387, DOI 10.1007/s00500-016-2474-6
   Wölfel M, 2009, IEEE T AUDIO SPEECH, V17, P312, DOI 10.1109/TASL.2008.2009161
NR 36
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28249
EP 28294
DI 10.1007/s11042-022-12858-4
EA MAR 2022
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200010
DA 2024-07-18
ER

PT J
AU Elkandoz, MT
   Alexan, W
AF Elkandoz, Marwa Tarek
   Alexan, Wassim
TI Image encryption based on a combination of multiple chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic functions; NIST analysis
ID DNA ENCRYPTION; SCHEME; COMPRESSION; SECURITY; SYSTEM
AB Recent years have seen a rapid evolution of digital communications and an immense use of image transmissions over unsecured links. More specifically, some domains require the exchange of images depicting sensitive information, such as fingerprints, medical records and government or military satellite images. This creates a major challenge for researchers to come up with efficient and effective image encryption schemes. On the other hand, chaotic maps have proven suitable for such applications. This is because they exhibit characteristics such as ergodicity and sensitivity to control parameters and initial conditions. In this paper, an image encryption confusion-diffusion technique is proposed. First, the image pixels are disarranged resulting in a shuffled one which is then diffused through XORing its pixels with a secret key. This key is generated from a combination of different chaotic maps. Performance of the proposed scheme is evaluated utilizing various metrics. The proposed scheme is shown to be robust against differential attacks and resistant to statistical attacks. Its running time is very small which guarantees its efficiency and suitability for real time applications.
C1 [Elkandoz, Marwa Tarek; Alexan, Wassim] Fac Informat Engn & Technol, Cairo, Egypt.
RP Alexan, W (corresponding author), Fac Informat Engn & Technol, Cairo, Egypt.
EM marwa.elkandoz@guc.edu.eg; wassim.alexan@ieee.org
RI Alexan, Wassim/J-9944-2019
OI Alexan, Wassim/0000-0001-6159-4971
CR AbdelRaouf A, 2021, MULTIMED TOOLS APPL, V80, P23393, DOI 10.1007/s11042-020-10224-w
   Al Dbsawie M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING (ICOCO), P122, DOI 10.1109/ICOCO53166.2021.9673559
   Alexan Wassim, 2021, 2021 International Conference on Microelectronics (ICM), P29, DOI 10.1109/ICM52667.2021.9664947
   Alexan Wassim, 2021, 2021 International Conference on Microelectronics (ICM), P34, DOI 10.1109/ICM52667.2021.9664961
   Alexan Wassim, 2021, 2021 3rd Novel Intelligent and Leading Emerging Sciences Conference (NILES), P359, DOI 10.1109/NILES53778.2021.9600536
   Alexan W., 2020, Int. J. Comput. Digit. Syst, V9, P545, DOI [10.12785/ijcds/090403, DOI 10.12785/IJCDS/090403]
   Alexan W, 2019, SIG P ALGO ARCH ARR, P229, DOI 10.23919/SPA.2019.8936812
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Ben Slimane N, 2018, MULTIMED TOOLS APPL, V77, P30993, DOI 10.1007/s11042-018-6145-8
   Elkandoz MT, 2019, SIG P ALGO ARCH ARR, P290, DOI [10.23919/SPA.2019.8936718, 10.23919/spa.2019.8936718]
   Farrag S, 2020, MULTIMED TOOLS APPL, V79, P29289, DOI 10.1007/s11042-020-09437-w
   Ganwani P, 2021, 2021 12 INT C COMP C, P1
   Garces H, 2006, PROC SPIE, V6210, DOI 10.1117/12.666364
   Ge B, 2021, IEEE ACCESS, V9, P137635, DOI 10.1109/ACCESS.2021.3118377
   Ghamsarian N, 2020, MULTIMED TOOLS APPL, V79, P18909, DOI 10.1007/s11042-020-08617-y
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   Hemeida F., 2019, IN 2019 NOVEL INTELL, V1, P17
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Hua ZY, 2014, IEEE SYS MAN CYBERN, P3229, DOI 10.1109/SMC.2014.6974425
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Kuznetsov A, 2021, INT WORKSH INT DATA, P414, DOI 10.1109/IDAACS53288.2021.9660879
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Mashaly M, 2019, SIG P ALGO ARCH ARR, P284, DOI [10.23919/spa.2019.8936800, 10.23919/SPA.2019.8936800]
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Melman Anna, 2021, 2021 XVII International Symposium "Problems of Redundancy in Information and Control Systems" (REDUNDANCY), P49, DOI 10.1109/REDUNDANCY52534.2021.9606459
   Moussa Yomna, 2020, 2020 2nd Novel Intelligent and Leading Emerging Sciences Conference (NILES), P224, DOI 10.1109/NILES50944.2020.9257937
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Patidar V, 2010, COMMUN NONLINEAR SCI, V15, P2755, DOI 10.1016/j.cnsns.2009.11.010
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Samir A., 2020, 2020 4 INT C ELECT C, P912
   Tang HC, 2007, EUR J OPER RES, V182, P820, DOI 10.1016/j.ejor.2006.08.055
   Vakani Hassan, 2021, 2021 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT), P201, DOI 10.1109/IAICT52856.2021.9532553
   van Harten, 2018, DYNAMICS ONE DIMENSI
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wu DC, 2022, IEEE ACCESS, V10, P8824, DOI 10.1109/ACCESS.2021.3138895
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yang FF, 2019, IEEE ACCESS, V7, P58751, DOI 10.1109/ACCESS.2019.2914722
   Yasser S, 2020, PROCEEDINGS OF 2020 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMMUNICATION AND COMPUTER ENGINEERING (ITCE), P227, DOI [10.1109/ITCE48509.2020.9047752, 10.1109/itce48509.2020.9047801]
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zhang XC, 2020, INT J OPT, V2020, DOI 10.1155/2020/6102824
   Zhang YQ, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2020.106040
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
NR 56
TC 50
Z9 50
U1 5
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25497
EP 25518
DI 10.1007/s11042-022-12595-8
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000771882200003
DA 2024-07-18
ER

PT J
AU Houtinezhad, M
   Ghaffari, HR
AF Houtinezhad, Maryam
   Ghaffari, Hamid Reza
TI Off-line signature verification system using features linear mapping in
   the candidate points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Off-line signature verification system (OS-VS); Candidate point;
   Hand-craft feature; Bag of feature
ID FEATURE-EXTRACTION; ONLINE; RECOGNITION; VECTOR; REPRESENTATION;
   INFORMATION; SELECTION; IDENTIFICATION; FORGERIES; IMAGES
AB This paper proposes BoF-CP approach which is a novel scheme feature fusion for writer-dependent offline signature verification. At the heart of the new methodology lies feature extraction in surrounded candidate points. In the proposed method, at first, several features of the type of component-oriented and pixel-oriented features are extracted at the region of candidate points. Due to the different geometric structure in different signatures, several short feature vectors are created to the number of candidate points in each image. In the proposed approach, the corresponding homogeneous feature vectors are fused based on standard deviation and variance at the candidate points to create a normalized vector. We called the proposed method Bag of Features in Candidate Point (BoF-CP). Finally, the normalized feature vector enters the classification stage to verify the query samples. To evaluate the proposed method, standard datasets MCYT, GPDS, and CEDAR have been used. According to the experimental results, the proposed approach has been able to import optimal features into the classification algorithm by which the recognition rate in the separation of the genuine and forgery samples has been enhanced. According to the obtained statistical results, the proposed method has improved in several criteria such as average error rate, accuracy, sensitivity, specify as compared to state of the art.
C1 [Houtinezhad, Maryam; Ghaffari, Hamid Reza] Islamic Azad Univ, Dept Comp Engn, Ferdows Branch, Ferdows, Iran.
C3 Islamic Azad University
RP Houtinezhad, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Ferdows Branch, Ferdows, Iran.
EM m.houtinezhad@srbiau.ac.ir; hghaffari@ferdowsiau.ac.ir
OI Ghaffari, Hamidreza/0000-0002-7437-8466
CR Ahrabian K, 2017, ARXIV171202781
   [Anonymous], 2012, ADV ELECT ELECT
   [Anonymous], 2016, ARAB J FORENSIC SCI
   [Anonymous], 2013, 21 IR C EL ENG ICEE
   AVOLA A, 2019, MULTIMED TOOLS APPL
   AVOLA A, 2017, INT C IM AN PROC
   Batista L, 2012, PATTERN RECOGN, V45, P1326, DOI 10.1016/j.patcog.2011.10.011
   Batool FE, 2024, MULTIMED TOOLS APPL, V83, P14959, DOI 10.1007/s11042-020-08851-4
   Ben XY, 2019, PATTERN RECOGN, V90, P87, DOI 10.1016/j.patcog.2019.01.017
   Bertolini D, 2010, PATTERN RECOGN, V43, P387, DOI 10.1016/j.patcog.2009.05.009
   Chandra S, 2017, MULTIMED TOOLS APPL, V76, P19139, DOI 10.1007/s11042-017-4531-2
   Chowdhury M, 2016, C IND ELECT APPL, P1311, DOI 10.1109/ICIEA.2016.7603787
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   De Marsico M, 2016, PATTERN RECOGN LETT, V82, P106, DOI 10.1016/j.patrec.2016.02.001
   Del Nostro P, 2009, BOOK NEW DIRECTIONS
   Diaz M, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3274658
   Diaz M, 2018, IEEE T CYBERNETICS, V48, P228, DOI 10.1109/TCYB.2016.2630419
   Diaz M, 2017, IEEE T PATTERN ANAL, V39, P951, DOI 10.1109/TPAMI.2016.2560810
   Ferrer MA, 2013, INT CONF BIOMETR
   Ferrer MA, 2018, IEEE T CYBERNETICS, V48, P2896, DOI 10.1109/TCYB.2017.2751740
   Fischer A, 2017, IEEE T HUM-MACH SYST, V47, P169, DOI 10.1109/THMS.2016.2634922
   Galbally J, 2015, PATTERN RECOGN, V48, P2921, DOI 10.1016/j.patcog.2015.03.019
   Ghandali S, 2008, IEEE INT SYMP SIGNAL, P315, DOI 10.1109/ISSPIT.2008.4775712
   Guerbai Y, 2015, PATTERN RECOGN, V48, P103, DOI 10.1016/j.patcog.2014.07.016
   Guido RC, 2018, INFORM FUSION, V41, P161, DOI 10.1016/j.inffus.2017.09.006
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Hafemann LG, 2016, IEEE IJCNN, P2576, DOI 10.1109/IJCNN.2016.7727521
   HERACLEOUS P, 2018, PATTERN RECOGN LETT
   Houtinezhad M., 2019, WRITER INDEPENDENT S
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Jagtap AB, 2020, MULTIMED TOOLS APPL, V79, P35109, DOI 10.1007/s11042-020-08857-y
   Jain A, 2021, NEURAL COMPUT APPL, V33, P6999, DOI 10.1007/s00521-020-05473-7
   Jain A, 2020, MULTIMED TOOLS APPL, V79, P19993, DOI 10.1007/s11042-020-08728-6
   JINDAL U, 2019, EMERGING TRENDS EXPE
   Kalera MK, 2004, INT J PATTERN RECOGN, V18, P1339, DOI 10.1142/S0218001404003630
   Kumar R, 2012, PATTERN RECOGN LETT, V33, P301, DOI 10.1016/j.patrec.2011.10.009
   Lanitis A, 2010, INT J BIOMETRICS, V2, P34, DOI 10.1504/IJBM.2010.030415
   Larkins R., 2008, ADAPTIVE FEATURE THR
   LEE S, 1992, IEEE T SYST MAN CYB, V22, P755, DOI 10.1109/21.156588
   Liwicki M, 2011, PROC INT CONF DOC, P1480, DOI 10.1109/ICDAR.2011.294
   Mamta, 2014, EXPERT SYST APPL, V41, P6494, DOI 10.1016/j.eswa.2014.03.040
   Mendenhall W, 2019, INTRO PROBABILITY ST
   Müller MK, 2013, NEURAL NETWORKS, V41, P137, DOI 10.1016/j.neunet.2012.07.006
   Okawa M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107227
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Oliveira L.S., 2017, INT CONF IMAG PROC, P1
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parodi M, 2013, IET BIOMETRICS, V2, P137, DOI 10.1049/iet-bmt.2013.0025
   Piekarczyk M, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P897, DOI 10.1109/ACPR.2013.164
   Pirlo G, 2015, IEEE T HUM-MACH SYST, V45, P805, DOI 10.1109/THMS.2015.2443050
   Pirlo G, 2013, IEEE T HUM-MACH SYST, V43, P499, DOI 10.1109/THMS.2013.2279008
   Pirlo G, 2013, IET BIOMETRICS, V2, P151, DOI 10.1049/iet-bmt.2013.0012
   Rantzsch Hannes, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P616, DOI 10.1007/978-3-319-50832-0_60
   Rivard D, 2013, INT J DOC ANAL RECOG, V16, P83, DOI 10.1007/s10032-011-0180-6
   Serdouk Y, 2018, I C COMP SYST APPLIC
   Serdouk Y, 2017, IMAGE VISION COMPUT, V66, P26, DOI 10.1016/j.imavis.2017.08.004
   Serdouk Y, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P84, DOI 10.1109/SITIS.2014.36
   Serdouk Y, 2016, EXPERT SYST APPL, V51, P186, DOI 10.1016/j.eswa.2016.01.001
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharma, 2010, C 1 INT C INT INT TE, DOI 10.1145/1963564.1963610
   Sharma A, 2018, IEEE T CYBERNETICS, V48, P611, DOI 10.1109/TCYB.2017.2647826
   Sharma A, 2016, PATTERN RECOGN LETT, V84, P22, DOI 10.1016/j.patrec.2016.07.015
   Sim HM, 2014, EXPERT SYST APPL, V41, P5390, DOI 10.1016/j.eswa.2014.02.051
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Srikantan G, 1996, PATTERN RECOGN, V29, P1147, DOI 10.1016/0031-3203(95)00146-8
   Taboga M., 2017, LECT PROBABILITY THE
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Tolosana R, 2018, IEEE ACCESS, V6, P5128, DOI 10.1109/ACCESS.2018.2793966
   Tolosana R, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176792
   Tolosana R, 2015, IEEE ACCESS, V3, P478, DOI 10.1109/ACCESS.2015.2431493
   Ulrich L, 2020, MULTIMED TOOLS APPL, V79, P29375, DOI 10.1007/s11042-020-09479-0
   Vamvakas G, 2010, PATTERN RECOGN, V43, P2807, DOI 10.1016/j.patcog.2010.02.018
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Yahyatabar ME, 2017, IET BIOMETRICS, V6, P393, DOI 10.1049/iet-bmt.2016.0103
   Yilmaz MB, 2016, INFORM FUSION, V32, P109, DOI 10.1016/j.inffus.2016.02.003
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zois EN, 2019, EXPERT SYST APPL, V125, P14, DOI 10.1016/j.eswa.2019.01.058
   Zois EN, 2018, IEEE COMPUT SOC CONF, P545, DOI 10.1109/CVPRW.2018.00084
NR 83
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24815
EP 24847
DI 10.1007/s11042-022-12499-7
EA MAR 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771882300008
DA 2024-07-18
ER

PT J
AU Li, R
   Hao, PN
   Sun, FY
   Li, YL
   You, L
AF Li, Ran
   Hao, Peinan
   Sun, Fengyuan
   Li, Yanling
   You, Lei
TI Quality improvement of motion-compensated frame interpolation by
   self-similarity based context feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion-compensated frame interpolation; Self-similarity; Context cube;
   Block matching algorithm; Bidirectional motion estimation
ID RATE UP-CONVERSION
AB Block Matching Algorithm (BMA) is the core of Motion-Compensated Frame Interpolation (MCFI), and its accuracy greatly affects the interpolation quality of MCFI. To improve BMA accuracy, this paper proposes the use of a self-similarity based context feature to improve the matching accuracy of BMA. First, we extract the patch centered at any pixel in a block, and perform the self-similarity descriptor to generate its correlation surface. Second, the correlation surface is statistically measured to represent the context feature, and the context cube of a block is produced by attaching the corresponding context feature to each pixel. Finally, we fuse the context cube into bidirectional matching criterion of BMA to get the motion vector field of the absent frame, and predict the absent frame by using motion compensation interpolation. Experimental results show that the proposed algorithm improves the BMA accuracy with a low computational complexity, and is better than the traditional MCFI algorithms in terms of both objective and subjective quality of the interpolated frames.
C1 [Li, Ran; Hao, Peinan; Li, Yanling; You, Lei] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Sun, Fengyuan] Guilin Univ Elect Technol, Guangxi Key Lab Wireless Wideband Commun & Signal, Guilin 541004, Peoples R China.
C3 Xinyang Normal University; Guilin University of Electronic Technology
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
EM liran@xynu.edu.cn
RI Li, Ran/N-3389-2013; li, yang/IQV-3559-2023; li, chunyuan/IQW-1618-2023;
   li, yan/GTI-4638-2022
OI Li, Ran/0000-0001-7475-759X; 
FU Project of Science and Technology Department of Henan Province in China
   [212102210106]; National Natural Science Foundation of China [61572417,
   31872704]; Innovation Team Support Plan of University Science and
   Technology of Henan Province in China [19IRTSTHN014]; Guangxi Key
   Laboratory of Wireless Wideband Communication and Signal Processing and
   China Ministry of Education Key Laboratory of Cognitive Radio and
   Information Processing
FX This work was funded in part by the Project of Science and Technology
   Department of Henan Province in China, under Grant no. 212102210106, in
   part by the National Natural Science Foundation of China, under Grant
   nos. 61572417, 31872704, in part by Innovation Team Support Plan of
   University Science and Technology of Henan Province in China, under
   Grant no. 19IRTSTHN014, and in part by the Guangxi Key Laboratory of
   Wireless Wideband Communication and Signal Processing and China Ministry
   of Education Key Laboratory of Cognitive Radio and Information
   Processing.
CR Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941
   Bao WB, 2018, IEEE T IMAGE PROCESS, V27, P3813, DOI 10.1109/TIP.2018.2825100
   Choi G, 2019, IEEE T CIRC SYST VID, V29, P1251, DOI 10.1109/TCSVT.2018.2840842
   Choi G, 2017, IEEE IMAGE PROC, P800, DOI 10.1109/ICIP.2017.8296391
   He JL, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3382506
   He YG, 2020, CHINA COMMUN, V17, P210, DOI 10.23919/JCC.2020.09.016
   Jacobson N, 2010, IEEE T IMAGE PROCESS, V19, P2924, DOI 10.1109/TIP.2010.2050928
   Jeong SG, 2013, IEEE T IMAGE PROCESS, V22, P4497, DOI 10.1109/TIP.2013.2274731
   Jeong SG, 2012, IEEE IMAGE PROC, P845, DOI 10.1109/ICIP.2012.6466992
   Kim D, 2013, IEEE T CIRC SYST VID, V23, P445, DOI 10.1109/TCSVT.2012.2207271
   Kokaram A, 2020, SMPTE 2020 ANN TECHN, P1, DOI [10.5594/M001927, DOI 10.5594/M001927]
   Kokaram A, 2020, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP40778.2020.9191152
   Lee H., IEEE Access
   Niklaus S, 2021, IEEE WINT CONF APPL, P1098, DOI 10.1109/WACV48630.2021.00114
   Paikin G, 2021, IEEE COMPUT SOC CONF, P1291, DOI 10.1109/CVPRW53098.2021.00142
   Romano Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2576402
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Shen W, 2020, PROC CVPR IEEE, P5113, DOI 10.1109/CVPR42600.2020.00516
   Suzuki K, 2021, INT C PATT RECOG, P1499, DOI 10.1109/ICPR48806.2021.9412470
   Nguyen TV, 2020, IEEE ACCESS, V8, P58310, DOI 10.1109/ACCESS.2020.2982039
   Tsai TH, 2012, J DISP TECHNOL, V8, P341, DOI 10.1109/JDT.2012.2186555
   Vanam R, 2020, IEEE IMAGE PROC, P558, DOI 10.1109/ICIP40778.2020.9191325
   Vranjes D, 2020, IEEE CONSUM ELECTR M, V9, P17, DOI 10.1109/MCE.2019.2956208
   Wang C, 2010, IEEE T CIRC SYST VID, V20, P886, DOI 10.1109/TCSVT.2010.2046057
   Wang H, 2020, IEEE T CIRCUITS-I, V67, P451, DOI 10.1109/TCSI.2019.2921943
   Wijma R, 2021, IEEE INT CONF COMP V, P1127, DOI 10.1109/ICCVW54120.2021.00132
   Xue F., 2021, P 2021 IEEE INT C MU, P1
   Yoon SJ, 2018, IEEE T IMAGE PROCESS, V27, P5918, DOI 10.1109/TIP.2018.2861567
   Yuan X, 2021, IEEE SIGNAL PROC MAG, V38, P65, DOI 10.1109/MSP.2020.3023869
   Yunlong Zhao, 2019, 2019 7th International Conference on Information, Communication and Networks (ICICN), P158, DOI 10.1109/ICICN.2019.8834946
   Zhang YB, 2020, IEEE T CIRC SYST VID, V30, P11, DOI 10.1109/TCSVT.2018.2885564
   Zhu QS, 2021, IEEE T PATTERN ANAL, V43, P4491, DOI 10.1109/TPAMI.2020.3001644
NR 32
TC 0
Z9 0
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24301
EP 24318
DI 10.1007/s11042-022-12814-2
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000012
DA 2024-07-18
ER

PT J
AU Liu, MJ
   Zhao, JQ
   Zhou, Y
   Zhu, HC
   Yao, R
   Chen, Y
AF Liu, Minjie
   Zhao, Jiaqi
   Zhou, Yong
   Zhu, Hancheng
   Yao, Rui
   Chen, Ying
TI Survey for person re-identification based on coarse-to-fine feature
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person Re-ID; Deep learning; Video surveillance
ID NEURAL-NETWORK; ATTENTION; HALLUCINATION; REPRESENTATION; SURVEILLANCE;
   RECOGNITION; BODY
AB Person re-identification (Re-ID), aiming to retrieve interested people through multiple non-overlapping cameras, has caused concerns in pattern recognition communities and computer vision in recent years. With the continuous promotion of deep learning, the research on person Re-ID is more and more extensive. In this paper, we conduct a comprehensive review of the advanced methods and divide them into three categories from coarse to fine: (1) global-based methods, which are based on whole images to obtain discriminative features; (2) part-based methods, which focus on image regions to extract detailed information; (3) multiple granularities-based methods, which combine advantages of the above two categories. For each category, we further classify it according to popular research tools. Then, we give the evaluation of some typical models on a set of benchmark datasets and compare them in detail. We also introduce some widely used training tricks. The methods mentioned in this paper were published in 2011-2021. By discussing their advantages and limitations, we provide a reference for future works.
C1 [Liu, Minjie; Zhao, Jiaqi; Zhou, Yong; Zhu, Hancheng; Yao, Rui; Chen, Ying] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Liu, Minjie; Zhao, Jiaqi; Zhou, Yong; Zhu, Hancheng; Yao, Rui; Chen, Ying] Minist Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Zhao, JQ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Zhao, JQ (corresponding author), Minist Educ Peoples Republ China, Mine Digitizat Engn Res Ctr, Xuzhou 221116, Jiangsu, Peoples R China.
EM liuminjie@cumt.edu.cn; jiaqizhao@cumt.edu.cn; yzhou@cumt.edu.cn;
   hanchengzhu@cumt.edu.cn; ruiyao@cumt.edu.cn; cheny@cumt.edu.cn
RI yi, cheng/KHC-5004-2024; zhang, fei/KHU-5230-2024; Wang,
   Yifan/KDO-8319-2024; chen, ying/HHS-8254-2022
FU National Natural Science Foundation of China [62172417, 61806206,
   62101555]; Natural Science Foundation of Jiangsu Province [BK20210488,
   BK20180639, BK20201346]; Six Talent Peaks Project in Jiangsu Province
   [2018-XYDXX-044, 2015-DZXX-010]
FX Author Minjie Liu, Author Jiaqi Zhao, Author Yong Zhou, Author Hancheng
   Zhu, Author Rui Yao and Author Ying Chen declare that they have no
   conflict of interest. Author Jiaqi Zhao has received research grants No.
   61806206 from the National Natural Science Foundation of China and No.
   BK20180639 from the Natural Science Foundation of Jiangsu Province.
   Author Yong Zhou has received research grants No. BK20201346 from the
   Natural Science Foundation of Jiangsu Province and No. 2015-DZXX-010
   from the Six Talent Peaks Project in Jiangsu Province. Author Hancheng
   Zhu has received research grants No. 62101555 from the National Natural
   Science Foundation of China and No. BK20210488 from the Natural Science
   Foundation of Jiangsu Province. Author Rui Yao has received research
   grants No. 62172417 from the National Natural Science Foundation of
   China and No. 2018-XYDXX-044 from the Six Talent Peaks Project in
   Jiangsu Province.
CR Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   Almasawa MO, 2019, IEEE ACCESS, V7, P175228, DOI 10.1109/ACCESS.2019.2957336
   [Anonymous], 2014, BRIT MACH VIS C
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870
   Bao LQ, 2019, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2019.00191
   Becerra-Riera F, 2019, ARTIF INTELL REV, V52, P1155, DOI 10.1007/s10462-019-09689-5
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chang YS, 2020, PATTERN RECOGN LETT, V130, P306, DOI 10.1016/j.patrec.2018.08.011
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen H, 2021, JOINT GENERATIVE CON
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng D, 2018, MULTIMED TOOLS APPL, V77, P3533, DOI 10.1007/s11042-017-5182-z
   Chung SL, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI [10.1109/avss.2019.8909890, 10.1109/CLEOE-EQEC.2019.8871467]
   Congcong Zhao, 2020, ICRSA '20: Proceedings of the 2020 3rd International Conference on Robot Systems and Applications, P30, DOI 10.1145/3402597.3402604
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Franco A, 2016, IEEE WINT CONF APPL
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Ge YX, 2018, ADV NEUR IN, V31
   Gong XW, 2019, IEEE ACCESS, V7, P131374, DOI 10.1109/ACCESS.2019.2935116
   Gou MR, 2017, IEEE INT CONF COMP V, P1294, DOI 10.1109/ICCVW.2017.154
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He S., 2021, Transreid: Transformer-based object reidentification
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang H, 2018, ARXIV181211369
   Huang JL, 2020, PATTERN RECOGN LETT, V138, P540, DOI 10.1016/j.patrec.2020.08.022
   Huang Y, 2019, INT JOINT C NEURAL N
   Huang Y, 2017, NEUROCOMPUTING, V241, P191, DOI 10.1016/j.neucom.2017.02.055
   Huang ZY, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03473-6
   Huo LJ, 2021, INT C PATT RECOG, P3652, DOI 10.1109/ICPR48806.2021.9412527
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jian, 2019, 2019 IEEE 38 INT PER, P1
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2019, INFORM SCIENCES, V488, P181, DOI 10.1016/j.ins.2019.03.026
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Jiao SS, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION ENGINEERING (ICECE 2019), P47, DOI [10.1109/icece48499.2019.9058499, 10.1109/ICECE48499.2019.9058499]
   Jie S., 2019, P UK CHIN EM TECHN G, P1
   Jin HY, 2021, NEUROCOMPUTING, V455, P111, DOI 10.1016/j.neucom.2021.05.059
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Lavi, 2020, SURVEY RELIABLE DEEP
   Lei JJ, 2019, IEEE T CIRC SYST VID, V29, P2453, DOI 10.1109/TCSVT.2018.2866260
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li C, 2021, IET IMAGE PROCESS, V15, P2399, DOI 10.1049/ipr2.12225
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   LI Y, 2021, MULTIMED TOOLS APPL
   Li YY, 2020, CHIN CONTR CONF, P7154, DOI 10.23919/CCC50068.2020.9189421
   Liang JL, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P366, DOI [10.1109/BigMM.2019.00017, 10.1109/BigMM.2019.00065]
   Lin, 2021 IEEE INT C IM P, P2299
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu X, 2020, IEEE T NEUR SYS REH, V28, P2325, DOI 10.1109/TNSRE.2020.3021410
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Ma LQ, 2017, ADV NEUR IN, V30
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Mathur Neha, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P129, DOI 10.1109/ICETCE48199.2020.9091747
   Matsukawa T, 2020, IEEE T PATTERN ANAL, V42, P2179, DOI 10.1109/TPAMI.2019.2914686
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Neves J, 2016, ARTIF INTELL REV, V46, P515, DOI 10.1007/s10462-016-9474-x
   Pala F, 2016, IEEE T CIRC SYST VID, V26, P788, DOI 10.1109/TCSVT.2015.2424056
   Patruno C, 2019, PATTERN RECOGN, V89, P77, DOI 10.1016/j.patcog.2019.01.003
   Quan HL, 2020, MULTIMED TOOLS APPL, V79, P7259, DOI 10.1007/s11042-019-08184-x
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Satta R, 2011, EXPLOITING DISSIMILA, V7005, P275
   Satta R, 2011, LECT NOTES COMPUT SC, V6979, P140, DOI 10.1007/978-3-642-24088-1_15
   Satta R, 2012, PATTERN RECOGN LETT, V33, P1838, DOI 10.1016/j.patrec.2012.03.026
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shao S., 2018, CROWDHUMAN BENCHMARK
   Sharma C, 2021, PERSON RE IDENTIFICA
   Shi Y, 2022, IEEE T BIG DATA, V8, P377, DOI 10.1109/TBDATA.2020.2964169
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Sun LC, 2019, IEEE IMAGE PROC, P2254, DOI [10.1109/icip.2019.8803292, 10.1109/ICIP.2019.8803292]
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2021, IEEE T PATTERN ANAL, V43, P902, DOI 10.1109/TPAMI.2019.2938523
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan HL, 2020, IEEE ACCESS, V8, P63632, DOI 10.1109/ACCESS.2020.2984915
   Tan HC, 2022, IEEE T CIRC SYST VID, V32, P160, DOI 10.1109/TCSVT.2021.3061412
   Tang C, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON MECHANICAL, CONTROL AND COMPUTER ENGINEERING (ICMCCE 2020), P2009, DOI 10.1109/ICMCCE51767.2020.00439
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Tu C, 2020, ESA REID ENTROPY BAS
   Vidhyalakshmi MK, 2017, ADV INTELL SYST COMP, V517, P503, DOI 10.1007/978-981-10-3174-8_42
   Wan CQ, 2020, IEEE T MULTIMEDIA, V22, P1605, DOI 10.1109/TMM.2019.2946486
   Wan FB, 2020, IEEE COMPUT SOC CONF, P3620, DOI 10.1109/CVPRW50498.2020.00423
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang LC, 2022, DIVERS DISTRIB, V28, P189, DOI 10.1111/ddi.13452
   Wang YY, 2018, IEEE ACCESS, V6, P44199, DOI 10.1109/ACCESS.2018.2864588
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu W, 2020, Pattern Recogn, Patent No. 107424
   Xiao, 2021, PATTERN RECOGN
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu Y., 2019, IEEE ICC, DOI DOI 10.1109/icc.2019.8761264
   Xuelin Qian, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12624), P71, DOI 10.1007/978-3-030-69535-4_5
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu ZX, 2022, IEEE T MULTIMEDIA, V24, P4482, DOI 10.1109/TMM.2021.3119133
   Zhang HJ, 2020, IEEE ACCESS, V8, P83685, DOI 10.1109/ACCESS.2020.2991838
   Zhang JF, 2021, IEEE T IMAGE PROCESS, V30, P603, DOI 10.1109/TIP.2020.3036762
   Zhang MH, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106154
   Zhang T, 2021, UNREALPERSON ADAPTIV
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang YL, 2019, MATEC WEB CONF, V277, DOI 10.1051/matecconf/201927702025
   Zhang Z, 2021, PERSON RE IDENTIFICA
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao YL, 2020, TSINGHUA SCI TECHNOL, V25, P415, DOI 10.26599/TST.2019.9010031
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong WL, 2020, MULTIMED TOOLS APPL, V79, P22525, DOI 10.1007/s11042-019-08395-2
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou SP, 2019, IEEE T IMAGE PROCESS, V28, P4671, DOI 10.1109/TIP.2019.2908065
   Zhu JQ, 2020, IEEE INTERNET THINGS, V7, P2053, DOI 10.1109/JIOT.2019.2960549
   Zhu K, 2021, AAFORMER AUTOALIGNED
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 151
TC 4
Z9 5
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21939
EP 21973
DI 10.1007/s11042-022-12510-1
EA MAR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770205800006
DA 2024-07-18
ER

PT J
AU Kim, J
   Kim, W
AF Kim, Jinhee
   Kim, Wonjun
TI Direction-aware feedback network for robust lane detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection; Direction-aware feedback network; Directional attention
   module; Wide-range contextual dependencies
AB Lane detection is a fundamental technique for autonomous driving systems. Various methods with deep neural networks have been actively introduced for this task, however, challenging issues, e.g., occlusion by vehicles, ambiguity by deterioration, etc., often give difficulties to accurately detect lanes in diverse road environments. To alleviate those problems, we propose the direction-aware feedback network. The key idea of the proposed method is to abundantly consider the global context of lanes by exploiting the directional attention module (DAM) in a multi-scale manner, which efficiently explores the high directionality with consideration of wide-range contextual dependencies both in horizontal and vertical directions. Moreover, such direction-aware features extracted from our DAMs are progressively refined by utilizing the feedback mechanism across different scale spaces, leading to the high-precision lane detection. Experimental results on benchmark datasets show the effectiveness of the proposed method under various road environments. The code and model are publicly available at: https://github.com/JinheeKIM94/ Direction-aware lane detection
C1 [Kim, Jinhee; Kim, Wonjun] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM tyt8131@konkuk.ac.kr; wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   [Anonymous], IEEE T CIRCUITS SYST
   Azad R, 2019, IEEE INT CONF COMP V, P406, DOI 10.1109/ICCVW.2019.00052
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Borkar A, 2011, INT CONF ACOUST SPEE, P1037
   Borkar A, 2009, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP.2009.5413980
   CHEN Q, IEEE T CIRC SYST VID
   Chin K-Y, 2015, IEEE C INTELL VEH S, P706
   Choi Hyun-Chul., 2010, The 2010 International Joint Conference on Neural Networks (IJCNN), P1
   Gao NY, 2021, IEEE T CIRC SYST VID, V31, P661, DOI 10.1109/TCSVT.2020.2985420
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Lee S, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P406, DOI 10.1109/APCCAS.2010.5775078
   Lim KH, 2009, INT C INTEL HUM MACH, P351, DOI 10.1109/IHMSC.2009.211
   Neven D, 2018, IEEE INT VEH SYM, P286
   Ozgunalp U, 2017, IEEE T INTELL TRANSP, V18, P621, DOI 10.1109/TITS.2016.2586187
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Paszke A., 2016, ARXIV160602147
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Qin Z., 2020, COMPUTER VISION ECCV, V12369, P276, DOI DOI 10.1007/978-3-030-58586-017
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Satzoda RK, 2015, IEEE T CIRC SYST VID, V25, P1870, DOI 10.1109/TCSVT.2015.2406171
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Su YN, 2018, IEEE T INTELL TRANSP, V19, P2739, DOI 10.1109/TITS.2017.2751746
   TuSimple, 2017, TUSIMPLE VEL EST CHA
   Van Gansbeke W, 2019, IEEE INT CONF COMP V, P905, DOI 10.1109/ICCVW.2019.00119
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YF, 2012, SIGNAL PROCESS, V92, P319, DOI 10.1016/j.sigpro.2011.07.019
   Wu CB, 2019, IEEE T CIRC SYST VID, V29, P582, DOI 10.1109/TCSVT.2018.2805704
   Xu CM, 2020, PR IEEE SEN ARRAY, DOI 10.1109/sam48682.2020.9104386
   Yang WJ, 2019, IEEE ACCESS, V7, P173148, DOI 10.1109/ACCESS.2019.2957053
   Yoo JH, 2017, IEEE T INTELL TRANSP, V18, P3254, DOI 10.1109/TITS.2017.2679222
   Yoo S, 2020, IEEE COMPUT SOC CONF, P4335, DOI 10.1109/CVPRW50498.2020.00511
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yuan J, 2014, CHIN CONTR CONF, P4887, DOI 10.1109/ChiCC.2014.6895768
   Zhang J, 2018, LECT NOTES COMPUT SC, V11205, P502, DOI 10.1007/978-3-030-01246-5_30
   Zhao K, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P1084, DOI 10.1109/IVS.2012.6232168
   Zhou SY, 2010, IEEE INT VEH SYM, P59, DOI 10.1109/IVS.2010.5548087
NR 41
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21697
EP 21717
DI 10.1007/s11042-022-12541-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800007
DA 2024-07-18
ER

PT J
AU Tang, YP
   Zhang, CL
   Cheng, QH
   Li, ZX
   Qian, LY
AF Tang, Yanping
   Zhang, Canlong
   Cheng, Qinghe
   Li, Zhixin
   Qian, Luyang
TI Fast semantic segmentation network with attention gate and multi-layer
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image semantic segmentation; Multi-layer fusion; Attention gated
   mechanism
AB Automatically learning to focus on salient regions while suppressing irrelevant regions is very useful in some specific image segmentation tasks like medical diagnosis and automatic driving. In this paper, a fast semantic segmentation method based on attention gate and multi-layer fusion is proposed. In our model, an attention gate module with few model parameters is designed as a bridge between downsampling layer and corresponding upsampling one, which can highlight the features of foreground, and improve feature representations in semantic segmentation. In addition, a multi-layer fusion mechanism is proposed to integrate the semantic information from different downsampling layers, which can supplement the lost pixels by utilizing the semantic complementarity among different layers. Considering the real-time of segmentation, we use the lightweight model as the backbone network to extract feature. The proposed architecture makes a right trade-off between segmentation accuracy and efficiency on CamVid, VOC and Cityscapes datasets. Specifically, for a 512x512 input, we achieve 72.9% mean IOU on the CamVid test dataset with the speed of 43 FPS.
C1 [Tang, Yanping] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin, Peoples R China.
   [Zhang, Canlong; Cheng, Qinghe; Li, Zhixin; Qian, Luyang] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China.
C3 Guangxi Normal University; Guilin University of Electronic Technology
RP Zhang, CL (corresponding author), Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin, Peoples R China.
EM zcltyp@163.com
RI Huang, Liping/KIB-4430-2024; Li, Zhixin/ABI-9264-2022; Zhao,
   YuHan/KIE-0813-2024
OI Li, Zhixin/0000-0002-5313-6134; Zhang, Canlong/0000-0003-4375-1405
FU National Natural Science Foundation of China [61866004, 61663004,
   61966004, 61962007]; Guangxi Natural Science Foundation
   [2018GXNSFDA281009, 2019GXNSFDA245018, 2018GXNSFDA294001]; Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing, Research Fund of Guangxi Key Lab of
   Multi-source Information Mining Security; Guangxi "Bagui Scholar" Teams
   for Innovation and Research Project
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61866004, 61663004, 61966004, 61962007), the Guangxi Natural
   Science Foundation (Nos. 2018GXNSFDA281009, 2019GXNSFDA245018,
   2018GXNSFDA294001), Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing,
   Research Fund of Guangxi Key Lab of Multi-source Information Mining &
   Security (No.20-A-03-01), and Guangxi "Bagui Scholar" Teams for
   Innovation and Research Project.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baek J, 2018, IEEE COMPUT SOC CONF, P1074, DOI 10.1109/CVPRW.2018.00142
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Lateef F, 2019, NEUROCOMPUTING, V338, P321, DOI 10.1016/j.neucom.2019.02.003
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu P, 2019, HUMAN COMPUTER INTER
   Liu S, 2021, IEEE T MULTIMED, V99, P1
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Min W, 2019, J COMPUT AIDED COMPU, V31, P659
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Paszke A, 2019, ENET DEEP NEURAL NET
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tao S, 2017, ARXIV170904696
   Tsutsui S, 2018, IEEE COMPUT SOC CONF, P1101, DOI 10.1109/CVPRW.2018.00145
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wenchao L, 2019, J COMPUT AIDED COMPU, V31, P447
   Wu J, 2022, IEEE T CYBERNETICS, V52, P11081, DOI 10.1109/TCYB.2021.3076420
   Wu Z, 2017, REAL TIME SEMANTIC I
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu F., 2015, ARXIV
   Yuan Y, 2018, OCNET OBJECT CONTEXT
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 42
TC 3
Z9 3
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21547
EP 21562
DI 10.1007/s11042-022-12519-6
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769297700004
DA 2024-07-18
ER

PT J
AU Bindal, N
   Garg, B
AF Bindal, Nishant
   Garg, Bharat
TI Novel three stage range sensitive filter for denoising high density salt
   & pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Processing; Salt & Pepper Noise; Mean and Median filters
ID WEIGHTED MEDIAN FILTER; MEAN FILTER; REMOVAL
AB This paper proposed a novel three stage algorithm to eliminate salt & pepper noise from the image. The three stages in the proposed algorithm are i) Pre-processing stage, ii) Main algorithm and iii) Post-processing stage. The proposed algorithm performs a number of basic standard operations (mean and median) governed by fuzzy logic. In pre-processing and Post-processing stages, low density noise is eliminated whereas, the main stage handles the high density noises and noisy pixels available on the boundary of image. Further, the proposed algorithm utilizes non-corner pixels to estimate denoinsed pixels value for corner pixels. Therefore, it effectively eliminates salt and pepper noise while efficiently preserving the edges. The performance of the proposed filter is analysed and compared over the existing filters using various benchmark images. The proposed algorithm on an averages improves the PSNR value by 2.1% and 7.73% at noise density ranges from 10% to 90% and 91% to 99%, respectively.
C1 [Bindal, Nishant; Garg, Bharat] Thapar Inst Engn Technol, ECED, Patiala 147001, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Garg, B (corresponding author), Thapar Inst Engn Technol, ECED, Patiala 147001, Punjab, India.
EM nishant.bindal1999@gmail.com; bharat.garg@thapar.edu
RI Garg, Bharat/GPP-5755-2022
OI Garg, Bharat/0000-0002-2904-3720
CR Chen FY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12121990
   Chithirala N, 2016, INT CONF ADVAN COMPU
   Erkan U., 2020, 2020 INT C ELECT COM, P1, DOI [10.1109/ICECCE49384.2020.9179351, DOI 10.1109/ICECCE49384.2020.9179351]
   Erkan U., 2019, INT J ENG RES DEV, V11, P542, DOI DOI 10.29137/UMAGD.495904
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Faragallah OS, 2016, AEU-INT J ELECTRON C, V70, P1034, DOI 10.1016/j.aeue.2016.04.018
   Garg B, 2020, INT J AD HOC UBIQ CO, V35, P84, DOI 10.1504/IJAHUC.2020.109795
   Garg B, 2020, MULTIMED TOOLS APPL, V79, P32305, DOI 10.1007/s11042-020-09557-3
   Garg B, 2020, SIGNAL IMAGE VIDEO P, V14, P1555, DOI 10.1007/s11760-020-01695-3
   Garg B, 2021, AM J OBSTET GYNECOL, V224, pS113
   Isma Irum Muhammad Sharif, 2015, J. appl. res. technol, V13, P79
   Lin PH, 2016, J DISP TECHNOL, V12, P344, DOI 10.1109/JDT.2015.2487559
   Patel Punyaban, 2012, International Journal of Image, Graphics and Signal Processing, V4, P53, DOI 10.5815/ijigsp.2012.11.08
   Roy A, 2020, MULTIMED TOOLS APPL, V79, P34851, DOI 10.1007/s11042-020-09107-x
   Santhanam T., 2014, 2014 International Conference on Science Engineering and Management Research (ICSEMR), P1, DOI [DOI 10.1109/ICSEMR.2014.7043602, 10.1109/ICSEMR.2014.7043602]
   Shinde B., 2012, INT J IMAGE GRAPHICS, V4, P51, DOI DOI 10.5815/IJIGSP.2012.02.08
   Sohi P. J. S., 2020, INNOVATIONS COMPUTAT, P150
   Thanh DNH, 2020, MULTIMED TOOLS APPL, V79, P21013, DOI 10.1007/s11042-020-08887-6
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Veerakumar T, 2014, SIGNAL IMAGE VIDEO P, V8, P159, DOI 10.1007/s11760-013-0517-3
   Vijaykumar VR, 2014, AEU-INT J ELECTRON C, V68, P1145, DOI 10.1016/j.aeue.2014.06.002
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
NR 22
TC 5
Z9 5
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21279
EP 21294
DI 10.1007/s11042-022-12574-z
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500008
DA 2024-07-18
ER

PT J
AU Natarajan, J
   Bajaj, U
   Shahi, D
   Soni, R
   Anand, T
AF Natarajan, Jayanthi
   Bajaj, Utkarsh
   Shahi, Dishant
   Soni, Rohan
   Anand, Tarun
TI Speech and gesture analysis: a new approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deception detection; Speech and gesture modality; Autism diagnosis
ID LIE DETECTION; AUTISM; CHILDREN
AB Speech and gesture are interlinked components and are critical for felicitous communication. Both these components have certain characteristics, and when convoluted together, they open up greater insights about psychological aspects of the human brain. We use the real-time courtroom truth and lie dataset (2015) comprising 153 videos of truth and lie labeled videos of a courtroom. We have used a convoluted framework and combined both linguistic and gesture approaches to generate a more robust tool for deception analysis and attain a classification accuracy between 65 and 75%. The results show this model will find a great application in interrogative environments where human interactions cannot be completely trusted for deriving results. Besides this, we also wish to introduce a novel approach with our framework to expand our research into the field of medical diagnosis, by using Autism detection as an application to our underlying framework. Through this approach, we wish to address the problem of early autism detection, which is difficult to ascertain through regular clinical practice. The results would enable early diagnosis and early treatment of the concerned problem.
C1 [Natarajan, Jayanthi; Bajaj, Utkarsh; Shahi, Dishant; Soni, Rohan; Anand, Tarun] Delhi Technol Univ, Delhi, India.
C3 Delhi Technological University
RP Natarajan, J (corresponding author), Delhi Technol Univ, Delhi, India.
EM njayanthi@dce.ac.in; utkarshbajaj2401@gmail.com; dishantshahi@yahoo.in;
   rohansoni14@gmail.com; tarunanand1996@gmail.com
OI Bajaj, Utkarsh/0000-0002-5860-7038
CR [Anonymous], 2020, SCREEN DIAGN AUT SPE
   [Anonymous], 2017, DECEPTION DETECTION
   [Anonymous], 2019, Facial action coding system (facs) - a visual guidebook
   Bhowmik MK, 2011, REVIEWS, REFINEMENTS AND NEW IDEAS IN FACE RECOGNITION, P113
   Buddharaju P, 2005, PROC CVPR IEEE, P1179
   Congleton J. J., 1997, International Journal of Speech Technology, V2, P61, DOI 10.1007/BF02539823
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Farah MJ, 2014, NAT REV NEUROSCI, V15, P123, DOI 10.1038/nrn3665
   Gage NM, 2003, NEUROREPORT, V14, P2047, DOI 10.1097/00001756-200311140-00008
   Kozel FA, 2005, BIOL PSYCHIAT, V58, P605, DOI 10.1016/j.biopsych.2005.07.040
   Kuhl PK, 2005, DEVELOPMENTAL SCI, V8, pF1, DOI 10.1111/j.1467-7687.2004.00384.x
   Langleben DD, 2013, PSYCHOL PUBLIC POL L, V19, P222, DOI 10.1037/a0028841
   Lincoln AJ, J AUTISM DEV DISORD
   Lock C, 2004, SCI NEWS, V166, P72, DOI DOI 10.2307/4015451
   Lohar V., 2020, INT J FUTURE GENERAT, V13, P426
   Lord C, 2000, J AUTISM DEV DISORD, V30, P205, DOI 10.1023/A:1005592401947
   Lu Shan., 2005, Proceedings of the Hawaii International Conference on System Sciences, p20c
   Michael N, 2010, LECT NOTES COMPUT SC, V6316, P462, DOI 10.1007/978-3-642-15567-3_34
   Pavlidis I, 2002, NATURE, V415, P35, DOI 10.1038/415035a
   Pérez-Rosas V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P59, DOI 10.1145/2818346.2820758
   Porter S, 2010, LEGAL CRIMINOL PSYCH, V15, P57, DOI 10.1348/135532509X433151
   Rubin V.L., 2010, ASIST, V47, P1, DOI 10.1002/meet.14504701124
   SEN UM, 2020, IEEE T AFFECT COMPUT, V1
   Su L, 2016, COMPUT VIS IMAGE UND, V147, P52, DOI 10.1016/j.cviu.2016.01.009
   V, 2012, DECEPTION DETECTION
NR 25
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 20763
EP 20779
DI 10.1007/s11042-022-12685-7
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000767922000004
DA 2024-07-18
ER

PT J
AU Choe, G
   Son, I
   Choe, C
   So, H
   Kim, H
   Choe, G
AF Choe, Gwangmin
   Son, Ilmyong
   Choe, Chunhwa
   So, Hyoson
   Kim, Hyokchol
   Choe, Gyongnam
TI Deep learning of spatio-temporal information for visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Spatial features; Temporal information; Augmented data;
   Particle filter
ID OBJECT TRACKING; NETWORKS; CONTEXT
AB The performance of the tracking task directly depends on target object appearance features. Therefore, a robust method for constructing appearance features is crucial for avoiding tracking failure. The tracking methods based on Convolution Neural Network (CNN) have exhibited excellent performance in the past years. However, the features from each original convolutional layer can usually represent spatial information, but not temporal information. They only use additionally the temporal information at the testing stage. To solve the lacks of prediction in the pretrained networks, we train both the spatial features and the temporal information for training at the pretraining stage. Firstly, the spatial features are trained by a domain-wise learning with the augmented data to prepare the training data to learn the temporal information. Secondly, the posterior probability maps are calculated by the particle filter and the above pretrained model. The posterior probability maps are used as the prior and the posterior respectively corresponding to the input and the output of the final network at the next stage. Thirdly, the temporal information is trained by using the augmented image sequences and the probability maps. The experimental results demonstrate that the proposed tracking method outperforms the state-of-the-art tracking methods.
C1 [Choe, Gwangmin; Son, Ilmyong; Choe, Chunhwa; So, Hyoson; Kim, Hyokchol; Choe, Gyongnam] Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
RP Choe, G (corresponding author), Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
EM gm.choi@ryongnamsan.edu.kp
CR [Anonymous], 2015, P 2015 IEEE C COMPUT
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Girshick R., 2017, rich feature hierarchies for accurate object detection and semantic segmentation tech report (v5)
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H., 2014, P BMVC
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu Q, 2017, SIGNAL IMAGE VIDEO P, V11, P881, DOI 10.1007/s11760-016-1035-x
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma X, 2018, MACH VISION APPL, V29, P749, DOI 10.1007/s00138-018-0930-2
   Moujtahid S, 2015, BRIT MACH VIS C BMCV
   Ondrúska P, 2016, AAAI CONF ARTIF INTE, P3361
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sun B, 2018, NEURAL NETWORKS, V105, P36, DOI 10.1016/j.neunet.2017.11.021
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yao AB, 2012, PATTERN RECOGN, V45, P2584, DOI 10.1016/j.patcog.2012.01.016
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhao ZJ, 2019, COMPUT ASSIST SURG, V24, P20, DOI 10.1080/24699322.2018.1560097
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 41
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17283
EP 17302
DI 10.1007/s11042-022-11967-4
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200011
DA 2024-07-18
ER

PT J
AU Yue, SQ
   Zhang, Q
   Shao, DQ
   Fan, Y
   Bai, JH
AF Yue, Shiqin
   Zhang, Qian
   Shao, Dingqin
   Fan, Yu
   Bai, Jinhua
TI Safety helmet wearing status detection based on improved boosted random
   ferns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Improved boosted random ferns; Safety helmet; Weighted
   coefficient
ID OBJECT; SCALE
AB The safety helmet wearing of workers is extremely important to their safety in construction scenarios, and it is very meaningful for computer vision, pattern recognition and artificial intelligence. This paper proposes a new Improved Boosted Random Ferns algorithm (IBRFs) for safety helmet wearing status detection. IBRFs originates from the Boosted Random Ferns algorithm (BRFs) and introduces the weighted coefficient to improve. In IBRFs, firstly, the feature is extracted by Histogram of Oriented Gradient (HOG) to form the feature domain space of the image. Secondly, the random binary test method is used to construct random ferns in the feature domain space. Then, a weak (acceptable) classifier is constructed by random ferns. Finally, an improved Real AdaBoost algorithm is used to select the most discriminative ones to construct IBRFs. Experimental evaluation on an enlarged public Safety Helmet Wearing-datasets (GZMU-SHWD) shows that the result of IBRFs outperforms those of the existing advanced detection algorithms, including SSD, YOLOv3 and Faster R-CNN, which further demonstrates the effectiveness of IBRFs for safety helmet wearing status detection.
C1 [Yue, Shiqin; Zhang, Qian; Shao, Dingqin; Fan, Yu; Bai, Jinhua] Guizhou Minzu Univ, Sch Data Sci & Informat Engn, Guiyang 550025, Peoples R China.
   [Zhang, Qian] Guizhou Minzu Univ, Acad Affairs Off, Guiyang 550025, Peoples R China.
   [Yue, Shiqin; Shao, Dingqin; Fan, Yu; Bai, Jinhua] Key Lab Pattern Recognit & Intelligent Syst Guizh, Guiyang 550025, Peoples R China.
C3 Guizhou Minzu University; Guizhou Minzu University
RP Zhang, Q (corresponding author), Guizhou Minzu Univ, Sch Data Sci & Informat Engn, Guiyang 550025, Peoples R China.; Zhang, Q (corresponding author), Guizhou Minzu Univ, Acad Affairs Off, Guiyang 550025, Peoples R China.
EM gzmuzq@gzmu.edu.cn
FU National Natural Science Foundation of China [61802082, 61762020,
   61263034]; Guizhou Provincial Department of Education [Qian Jiao He KY
   ZI [2018] 018]
FX The work is supported by National Natural Science Foundation of China
   (61802082, 61762020, 61263034), Guizhou Provincial Department of
   Education (Qian Jiao He KY ZI [2018] 018) .
CR Cai L., 2011, Mining Science and Technology (China), V21, P553, DOI [10.1016/j.mstc.2011.06.016, DOI 10.1016/J.MSTC.2011.06.016]
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cheng R, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083652
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fang Ming, 2019, Optics and Precision Engineering, V27, P1196, DOI 10.3788/OPE.20192705.1196
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Jebril Noor A., 2018, Pattern Recognition and Image Analysis, V28, P321, DOI 10.1134/S1054661818020141
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185202
   Mneymneh BE, 2017, PROCEDIA ENGINEER, V196, P895, DOI 10.1016/j.proeng.2017.08.022
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park MW, 2015, J CONSTR ENG M, V141, DOI 10.1061/(ASCE)CO.1943-7862.0000974
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Siebert FW, 2020, ACCIDENT ANAL PREV, V134, DOI 10.1016/j.aap.2019.105319
   Thakar V., 2018, IEEE INT SM C CONF, P1, DOI 10.1109/ISC2.2018.8656929
   Tingchao Shi, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2595, DOI 10.1109/ROBIO49542.2019.8961615
   Villamizar Michael, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P388, DOI 10.1109/ICPR.2010.103
   Villamizar M, 2018, IEEE T PATTERN ANAL, V40, P272, DOI 10.1109/TPAMI.2017.2676778
   Villamizar M, 2012, PATTERN RECOGN, V45, P3141, DOI 10.1016/j.patcog.2012.03.025
   Wang BY, 2014, CHIN CONT DECIS CONF, P3975, DOI 10.1109/CCDC.2014.6852876
   Wu F, 2019, IEEE INT C NETW SENS, P363, DOI [10.1109/ICNSC.2019.8743246, 10.1109/icnsc.2019.8743246]
   Yokoya N, 2015, INT GEOSCI REMOTE SE, P2852, DOI 10.1109/IGARSS.2015.7326409
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
NR 27
TC 9
Z9 9
U1 3
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16783
EP 16796
DI 10.1007/s11042-022-12014-y
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100013
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, R
AF Kumar, Sandeep
   Kumar, Rajeev
TI Intelligent model to image enrichment for strong night-vision
   surveillance cameras in future generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image; Histogram; Algorithm; Multimedia application; Dim light;
   Night images; Principal component analysis; Surveillance camera
ID IDENTIFICATION; ENHANCEMENT; FRAMEWORK
AB Images, which are captured in the night, have the poor quality in comparison to day light. In surveillance cameras, because of weather and other constraint images have low brightness, low contrast, and high noise. We need night vision in various sectors like automobile industry, LOC patrolling, Civil Security, Prevent accident, etc. In this paper, we try to improve image quality by the improving contrast enhancement algorithm along with developed luminance range. In this research, which is an extension of earlier work, we use Principal Component Analysis (PCA) technique as it contains significant information of pixels. We compare daytime images with enhanced images in various environment and variables to get a good quality image. We use Contrast enhancement for brightness and contrast, bilateral filter for de-noise and edge prevention, which work more efficiently over other methods.
C1 [Kumar, Sandeep] Right Zone Technol Private Ltd, Moradabad, India.
   [Kumar, Rajeev] Chandigarh Univ, Comp Sci & Engn APEX, Mohali, India.
C3 Chandigarh University
RP Kumar, R (corresponding author), Chandigarh Univ, Comp Sci & Engn APEX, Mohali, India.
EM Sandeepkmr.nishad@gmail.com; rajeev2009mca@gmail.com
RI Kumar, Rajeev/N-8237-2016; Kumar, Rajeev/AAJ-4134-2021
OI Kumar, Rajeev/0000-0002-4141-1282; Kumar, Rajeev/0000-0002-4141-1282
CR Agarwal A, 2019, INFORM FUSION, V45, P333, DOI 10.1016/j.inffus.2017.11.004
   [Anonymous], 2008, DIGITAL IMAGE PROCES
   [Anonymous], 2017, Electron. Imaging
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Aslam A, 2021, MULTIMED TOOLS APPL, V80, P13021, DOI 10.1007/s11042-020-10277-x
   Bernacki J, 2021, MULTIMED TOOLS APPL, V80, P29657, DOI 10.1007/s11042-021-11129-y
   Bernacki J, 2021, MULTIMED TOOLS APPL, V80, P921, DOI 10.1007/s11042-020-09133-9
   BUCHSBAUM G, 1983, PROC R SOC SER B-BIO, V220, P89, DOI 10.1098/rspb.1983.0090
   Chen YS, 2017, IEEE IMAGE PROC, P4337, DOI 10.1109/ICIP.2017.8297101
   Fales CL, 1996, PHILOS T R SOC A, V354, P2249, DOI 10.1098/rsta.1996.0099
   Freire-Obregón D, 2019, PATTERN RECOGN LETT, V126, P86, DOI 10.1016/j.patrec.2018.01.005
   Fu XY, 2013, IEEE GLOB CONF SIG, P1085, DOI 10.1109/GlobalSIP.2013.6737082
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Gupta Anish, 2020, 2020 International Conference on Intelligent Engineering and Management (ICIEM), P155, DOI 10.1109/ICIEM48762.2020.9160317
   Gupta N., 2021, SN Computer Science, V2, P1, DOI [10.1007/s41256-021-00704-z, DOI 10.1007/S41256-021-00704-Z]
   Gupta N, 2021, MULTIMED TOOLS APPL, V80, P22301, DOI 10.1007/s11042-021-10820-4
   Huang W-B, 2011, ELECTR ENG, P95
   Huck F.O., 1997, VISUAL COMMUN-US
   Jaiswal A, 2019, INT J ANAL EXPT MODA, V11, P1456
   Jaiswal A, 2020, INT J ALL RES ED SCI, V8
   JANG IS, 2011, J IMAGING SCI TECHN, V55, P1
   Jobson DJ, 1996, SYST APPL
   Maksimovic M, 2021, MULTIMED TOOLS APPL, V80, P22619, DOI 10.1007/s11042-020-09912-4
   Marra F, 2018, SIGNAL PROCESS-IMAGE, V65, P240, DOI 10.1016/j.image.2018.04.007
   Meenu S, 2019, INT J ENG ADV TECHNO, V08, P184, DOI [10.35940/ijeat.E7084.088619, DOI 10.35940/IJEAT.E7084.088619]
   Mian SM, 2020, J XIDIAN U, V14, P414
   MJA J., 2020, INT C INT ENG MAN IC, V2020, P396, DOI [10.1109/ICIEM48762.2020.9160056, DOI 10.1109/ICIEM48762.2020.9160056]
   Nowisz J, 2021, MULTIMED TOOLS APPL, V80, P14941, DOI 10.1007/s11042-020-10385-8
   Ocaña M, 2022, MULTIMED TOOLS APPL, V81, P3369, DOI 10.1007/s11042-021-11186-3
   Pérez FJ, 2021, MULTIMED TOOLS APPL, V80, P23681, DOI 10.1007/s11042-020-10206-y
   Rivera AR, 2012, IEEE T IMAGE PROCESS, V21, P3967, DOI 10.1109/TIP.2012.2198667
   Saxena V, 2017, IEEE XPLORE, P182, DOI [10.1109/SYSMART.2016.7894514, DOI 10.1109/SYSMART.2016.7894514]
   Siddiqui Mohammed Hatim Ferhan, 2020, 2020 International Conference on Intelligent Engineering and Management (ICIEM), P306, DOI 10.1109/ICIEM48762.2020.9160322
   Singh Satendra, 2019, Indian J Med Ethics, V4, P29, DOI [10.20529/IJME.2018.064, 10.1109/ICCABS.2018.8542085]
   Singh SK, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12156250
   Singh SK, 2020, SUSTAIN CITIES SOC, V60, DOI 10.1016/j.scs.2020.102252
   Singh SK, 2020, FUTURE GENER COMP SY, V110, P721, DOI 10.1016/j.future.2019.09.002
   Singh SK, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070941
   Sun L, 2022, MULTIMED TOOLS APPL, V81, P42485, DOI 10.1007/s11042-021-11212-4
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Yawalkar MPH, 2015, INT J ADV RES COMP C, V4
NR 41
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16335
EP 16351
DI 10.1007/s11042-022-12496-w
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600005
DA 2024-07-18
ER

PT J
AU Zhang, L
   Chen, XB
AF Zhang Li
   Chen XiaoBo
TI Recommendation algorithm of influence and trust relationship
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Social influence; Trust relationship; Social
   recommendation algorithm; Probability matrix factorization
ID SOCIAL NETWORKS
AB The recommendation system recommends information and services to users by collecting and analyzing user behaviors. Many current studies have shown that recommendation algorithms that integrate social network information can effectively improve recommendation performance. Most of the existing social recommendation algorithms assume that the trust relationship between users is singular and homogeneous. These social recommendation algorithms generally ignore two problems: (i) in a network of trust relationships, each user has various friends and trust relationships, which have an impact on user ratings. (ii) each user with different social status, which influences also affects the ratings between users. Propose a social network recommendation algorithm (Social Strength Trust Recommendation Algorithm, SSTRA) in this paper. Firstly, the algorithm uses the different out-degree and in-degree relationships among different users to calculate the different trust strengths of each user in social networks; secondly, it calculates the social influence of different users through the social ranking algorithm (SocailRank); thirdly, it will be based on the trust strength relationship of social networks and the social influence of users are integrated into the probability matrix factorization model. This method can achieve the purpose of optimizing recommendation results. The experimental results compared on the CiaoDVD dataset show that: Compared with the SocialMF, SoRec, RSTE, PMF, and Trust algorithms, the average MAE has increased by 1.33%, 1.69%, 4.88%, 11.17% and 220.41%, and the average RMSE has increased by 1.47%, 1.9%, 5.06%, 7.27%, 217.55%. The experimental results compared on the Ciao dataset show that: Compared with the SocialMF, SoRec, RSTE, PMF, and Trust algorithms, the average MAE is increased by 4.83%, 5.05%, 1.96%, 5.58%, 143.39%, and the average RMSE is increased by 1.76%, 2.17%, 2.1%, 2.38%, 151.1%. Experimental results show that the algorithm has obvious advantages in recommendation accuracy.
C1 [Zhang Li] Jiangsu Univ Technol, Sch Comp Engn, Changzhou 213001, Jiangsu, Peoples R China.
   [Chen XiaoBo] Peoples Bank China, Changzhou City Ctr Branch, Changzhou 213001, Jiangsu, Peoples R China.
C3 Jiangsu University of Technology; People's Bank of China
RP Zhang, L (corresponding author), Jiangsu Univ Technol, Sch Comp Engn, Changzhou 213001, Jiangsu, Peoples R China.
EM zhangli_3913@163.com
FU Jiangsu University of Technology [KYY19042]
FX This research was funded by Jiangsu University of Technology (Grant No.
   KYY19042).
CR Amato Flora, 2019, Future Generation Computer Systems, V93, P914, DOI 10.1016/j.future.2017.04.028
   Avesani P., 2005, SAC, P1589, DOI DOI 10.1145/1066677.1067036
   Chen Ting, 2017, Journal of Software, V28, P721, DOI 10.13328/j.cnki.jos.005159
   Davoudi Anahita, 2018, Online Social Networks and Media, V7, P1, DOI 10.1016/j.osnem.2018.05.001
   Eirinaki M, 2018, FUTURE GENER COMP SY, V78, P413, DOI 10.1016/j.future.2017.09.015
   Esmaeili L, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113301
   Guo GB, 2017, KNOWL-BASED SYST, V122, P17, DOI 10.1016/j.knosys.2017.01.027
   [郭弘毅 Guo Hongyi], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P1664
   Gupta S, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105756
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Li J, 2017, KNOWL-BASED SYST, V127, P58, DOI 10.1016/j.knosys.2017.02.032
   Liu Q, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3046941
   Ma H., 2011, Proceedings of the 4th ACM International Conference on Web Search and Data Mining, P287
   Ma H., 2008, CIKM '08, P931
   Ma H, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961201
   Pal B, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P437, DOI 10.1145/3240323.3240402
   [潘一腾 Pan Yiteng], 2018, [计算机学报, Chinese Journal of Computers], V41, P65
   Pradhan T, 2020, FUTURE GENER COMP SY, V110, P1139, DOI 10.1016/j.future.2019.11.017
   Rogati M., 2010, Proceedings of the 19th international conference on World wide web, P981, DOI DOI 10.1145/1772690.1772790
   Wu Bin, 2018, Journal of Software, V29, P2681, DOI 10.13328/j.cnki.jos.005274
   Wu H, 2016, KNOWL-BASED SYST, V97, P111, DOI 10.1016/j.knosys.2016.01.011
   Yang XW, 2014, COMPUT COMMUN, V41, P1, DOI 10.1016/j.comcom.2013.06.009
   Yang Xiwang., 2012, P 18 ACM SIGKDD INT, P1267, DOI [10.1145/2339530.2339728, DOI 10.1145/2339530.2339728]
   Zhang J, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100221
   Zhang Xue-Feng, 2020, Journal of Zhejiang University (Engineering Science), V54, P311, DOI 10.3785/j.issn.1008-973X.2020.02.012
NR 26
TC 2
Z9 3
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15635
EP 15652
DI 10.1007/s11042-022-12231-5
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600017
DA 2024-07-18
ER

PT J
AU Sanida, T
   Tsiktsiris, D
   Sideris, A
   Dasygenis, M
AF Sanida, Theodora
   Tsiktsiris, Dimitris
   Sideris, Argyrios
   Dasygenis, Minas
TI A heterogeneous implementation for plant disease identification using
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous system; Deep learning; Plant disease classification; Deep
   convolutional neural network; Image processing; Model optimizations
ID NEURAL-NETWORKS
AB In own global economy, the agricultural sector plays a pivotal role in every aspect of our modern life. One of the most important issues that matters in agriculture, that leads to huge economic losses, are the crop diseases. The reliable and accurate diagnosis of plant diseases, even today, remains one of the most difficult tasks. An efficient, accurate and rapid diagnosis of plant disease is active area of research. One of the solutions that has been proposed is Deep Learning (DL). DL is a vital approach in many fields, including agriculture, as it has the potential to reach a high level of accuracy and efficiency. Various authors have investigated DL techniques for agriculture, but most of them examine a very limited dataset or few models and optimizers. In constrast with existing publications, we have performed the most thoroughly examination of all the state of the art DL models resulting in discovering the best models and parameters for utilizing DL in modern agricalture. The experimental results have shown that the DenseNet201 model in combination with the Adam optimization algorithm achieves the highest testing accuracy score of 99.87% surpassing all other DL architectures.
C1 [Sanida, Theodora; Tsiktsiris, Dimitris; Sideris, Argyrios; Dasygenis, Minas] Univ Western Macedonia, Dept Elect & Comp Engn, Kozani 50131, Greece.
C3 University of Western Macedonia
RP Sanida, T (corresponding author), Univ Western Macedonia, Dept Elect & Comp Engn, Kozani 50131, Greece.
EM thsanida@uowm.gr
RI Tsiktsiris, Dimitrios/KHY-3240-2024
OI Tsiktsiris, Dimitrios/0000-0001-6475-5865; Sideris,
   Argyrios/0000-0002-6252-426X
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Amodei D, 2016, PR MACH LEARN RES, V48
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Brahimi M, 2018, HUM-COMPUT INT-SPRIN, P93, DOI 10.1007/978-3-319-90403-0_6
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Carranza-Rojas J, 2017, BMC EVOL BIOL, V17, P1, DOI 10.1186/s12862-017-1014-z
   Chao XF, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071065
   Chen JD, 2021, PLANT PATHOL, V70, P630, DOI 10.1111/ppa.13322
   Chen JD, 2020, MULTIMED TOOLS APPL, V79, P31497, DOI 10.1007/s11042-020-09669-w
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen JD, 2020, J SCI FOOD AGR, V100, P3246, DOI 10.1002/jsfa.10365
   Chetlur S., 2014, ARXIV14100759
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Ciresan D., 2012, NIPS, P2843
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dozat T., 2016, INT C LEARN REPR
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Hassan SM, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121388
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, Cited on, V14, P2
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hughes D., 2015, ABS151108060 CORR
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Maeda-Gutiérrez V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041245
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Ruder S., 2016, ARXIV
   Saleem MH, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101319
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Zeiler M. D., 2012, CoRR
   Zhang P, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105652
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 53
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15041
EP 15059
DI 10.1007/s11042-022-12461-7
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761886300002
DA 2024-07-18
ER

PT J
AU Li, DY
   Ma, ZM
AF Li, Daiyi
   Ma, Zongmin
TI Residual attention learning network and SVM for malaria parasite
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep convolutional neural networks (DCNNs); Residual learning; Support
   vector machine (SVM); Feature extraction; Class activation mapping (CAM)
ID CLASSIFICATION
AB Automated malaria parasite detection in thin-blood smear images is an important way to improve the diagnostic performance. Although deep convolutional neural networks (DCNNs) perform well in many image classification tasks, accurate classification of malaria parasite remains challenging due to the lack of training data, poor quality of smears and inter-class similarity. In this paper, we present a novel hybrid model dubbed RAL-CNN-SVM, which is composed of multiple residual attention learning convolution neural network (RAL-CNN) modules, a global average pooling (GAP) block and a classifier trained by a support vector machine (SVM). Each RAL-CNN block consists of residual learning and a new attention mechanism, which is mainly used to extract image depth activation features. The classification layer takes advantage of strong points of the SVM classification algorithm, solves the problem of nonlinear separable and improves the detection accuracy for malaria parasites. During our experiments, we evaluate the proposed RAL-CNN-SVM model on public Malaria Cell Images dataset, and the results show that the accuracy of the proposed novel hybrid model is 99.7%. We also visualized the class activation mapping (CAM) obtained by RAL-CNN50-SVM and ResNet50. The experimental results show that the RAL-CNN50-SVM (a single 50-layer model) model has strong attention ability and can highlight parasitic cells rather than background tissues in thin-blood smear images.
C1 [Li, Daiyi; Ma, Zongmin] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Li, DY (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Peoples R China.
EM lidaiyi@nuaa.edu.cn
OI Li, daiyi/0000-0002-3677-4636
FU National Natural Science Foundation of China [61370075]
FX We acknowledge the official NIH Website for the Public Malaria Cell
   Images dataset to support our research work. Meanwhile, we also
   acknowledge the National Natural Science Foundation of China
   (No.61370075) for funding our research work.
CR Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bibin D, 2017, IEEE ACCESS, V5, P9099, DOI 10.1109/ACCESS.2017.2705642
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Das DK, 2013, MICRON, V45, P97, DOI 10.1016/j.micron.2012.11.002
   Davison AC, 2003, STAT SCI, V18, P141
   Diaz M, 2019, PATTERN RECOGN LETT, V128, P204, DOI 10.1016/j.patrec.2019.08.018
   Dong YH, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P101, DOI 10.1109/BHI.2017.7897215
   Dou HK, 2020, OPT LETT, V45, P2688, DOI 10.1364/OL.389696
   Gopakumar GP, 2018, J BIOPHOTONICS, V11, DOI 10.1002/jbio.201700003
   Gutman JR, 2020, AM J TROP MED HYG, V103, P572, DOI 10.4269/ajtmh.20-0516
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hossain MS, 2019, IEEE T IND INFORM, V15, P1027, DOI 10.1109/TII.2018.2875149
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang YJ, 2021, SIGNAL IMAGE VIDEO P, V15, P1031, DOI 10.1007/s11760-020-01828-8
   Ioffe S, 2015, BATCH NORMALIZATION, V45, P204
   Jiang H, 2020, NEUROCOMPUTING, V391, P220, DOI 10.1016/j.neucom.2018.11.103
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li G, 2019, IEEE T GEOSCI REMOTE, V57, P8506, DOI 10.1109/TGRS.2019.2921342
   Liang ZH, 2016, IEEE INT C BIOINFORM, P493, DOI 10.1109/BIBM.2016.7822567
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu SJ, 2018, INT GEOSCI REMOTE SE, P7145, DOI 10.1109/IGARSS.2018.8517855
   Luo R., 2020, MULTIMED TOOLS APPL, V79, P1
   Masud M, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8895429
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Rajaraman S, 2019, PEERJ, V7, DOI 10.7717/peerj.6977
   Rajaraman S, 2018, PEERJ, V6, DOI 10.7717/peerj.4568
   Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Srivastava RK, 2015, ARXIV150500387
   Suzuki K, 2017, RADIOL PHYS TECHNOL, V10, P257, DOI 10.1007/s12194-017-0406-5
   Swami A., 2012, J MACH LEARN RES, V12
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vapnik, 2000, NATURE STAT LEARNING, DOI [DOI 10.1007/978-1-4757-3264-1, 10.1080/00401706.1996.10484565, DOI 10.1080/00401706.1996.10484565]
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Weese J, 2016, MED IMAGE ANAL, V33, P44, DOI 10.1016/j.media.2016.06.023
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu H, 2019, SOURCE INT J INTELLI, V12, P212
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Xing L., 2017, MATH BIOSCI ENG, V3
   Xiong W, 2016, IEEE DATA MINING, P519, DOI [10.1109/ICDM.2016.0063, 10.1109/ICDM.2016.66]
   Xu Y, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206891
   Yang Y., 2018, SYNETGY ALGORITHM HA
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Zhang QC, 2020, INFORM SCIENCES, V536, P91, DOI 10.1016/j.ins.2020.05.013
   Zhao R, 2019, MECH SYST SIGNAL PR, V115, P213, DOI 10.1016/j.ymssp.2018.05.050
NR 54
TC 5
Z9 5
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10935
EP 10960
DI 10.1007/s11042-022-12373-6
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400010
DA 2024-07-18
ER

PT J
AU Peng, YQ
   Li, W
   Li, YJ
   Pei, YX
   Guo, YF
AF Peng, Yuqing
   Li, Wei
   Li, Yingjun
   Pei, Yixin
   Guo, Yongfang
TI Multi-task person re-identification via attribute and part-based
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Convolutional neural network; Attribute
   feature; Multi-task learning
ID NETWORK
AB Person re-identification(re-ID) is a challenging task due to the dramatic visual appearance changes from pose, viewpoint, illumination, occlusion, low resolution, and background clutter, etc. Mid-level person attributes are robust to the above mentioned variations and are often exploited as efficient supplement information to promote the performance of person re-ID task. In this paper, we propose a multi-branch network that jointly learns discriminative appearance and complementary attribute representations from both global and local features and mid-level semantic attributes with the supervision of identification loss and verification loss in a unified deep learning model. On the one hand, we design global network, local network, and attribute network to extract global features, local features, and attribute features respectively. On the other hand, we fuse identification loss and verification loss to optimize our model by a multi-task learning strategy. Extensive experiments are conducted on Market1501 and DukeMTMC-reID with attribute annotations to verify the efficiency of our method and competitive performance compared with state-of-the-art algorithms. Specifically, our model achieves 94.45% Rank-1, 92.11% mAP on the Market-1501 dataset and 89.95% Rank-1, 86.49% mAP on the DukeMTMC-reID dataset.
C1 [Peng, Yuqing; Li, Wei; Li, Yingjun; Pei, Yixin; Guo, Yongfang] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
   [Peng, Yuqing; Li, Wei; Li, Yingjun; Pei, Yixin] Hebei Prov Key Lab Big Data Calculat, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology
RP Guo, YF (corresponding author), Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
EM guoyongfang@hebut.edu.cn
RI li, yingjun/HJB-0161-2022
FU National Key Research and Development Program of China [2018YFB1306900];
   National Natural Science Foundation of China [U1813222]
FX This paper is supported by the National Key Research and Development
   Program of China (2018YFB1306900) and National Natural Science
   Foundation of China (NO. U1813222).
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li SZ, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107016
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Lin ZJ, 2020, IEEE T IMAGE PROCESS, V29, P3750, DOI 10.1109/TIP.2020.2965987
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P737, DOI 10.1145/3240508.3240585
   Liu S, 2020, IEEE ACCESS, V8, P56469, DOI 10.1109/ACCESS.2020.2982032
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Luo JH, 2019, IEEE IMAGE PROC, P165, DOI [10.1109/ICIP.2019.8802961, 10.1109/icip.2019.8802961]
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Su C, 2018, IEEE T PATTERN ANAL, V40, P1167, DOI 10.1109/TPAMI.2017.2679002
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Tian H, 2019, NEUROCOMPUTING, V359, P93, DOI 10.1016/j.neucom.2019.05.037
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Z, 2020, IEEE T IMAGE PROCESS, V29, P2013, DOI 10.1109/TIP.2019.2946975
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xie B, ARXIV PREPRINT ARXIV
   Xie ZH, 2022, MULTIMED TOOLS APPL, V81, P19151, DOI 10.1007/s11042-021-10537-4
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yang WX, 2019, NEUROCOMPUTING, V340, P125, DOI 10.1016/j.neucom.2019.02.042
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhai Y, 2019, IEEE COMPUT SOC CONF, P1526, DOI 10.1109/CVPRW.2019.00194
   Zhang Y, 2019, IEEE ACCESS, V7, P53585, DOI 10.1109/ACCESS.2019.2912844
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu H, 2021, INFORM FUSION, V70, P72, DOI 10.1016/j.inffus.2020.12.008
NR 55
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11221
EP 11237
DI 10.1007/s11042-022-12124-7
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757200200005
DA 2024-07-18
ER

PT J
AU Wang, Z
   Li, F
   Cong, RM
   Bai, HH
   Zhao, Y
AF Wang, Zhao
   Li, Feng
   Cong, Runmin
   Bai, Huihui
   Zhao, Yao
TI Adaptive feature fusion network based on boosted attention mechanism for
   single image dehazing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dehazing; Convolutional neural network; Adaptive feature fusion
   network; Boosted attention mechanism; Residual desne attention block
ID FRAMEWORK; VISION
AB Recently convolutional neural networks based methods have achieved significant improvements in image dehazing. However, these algorithms still face the challenge of producing haze-free images while preserving credible contrast and color fidelity. In this paper, we propose an adaptive feature fusion network to remove the haze and ensure realistic details from global and local perspectives. On the global scale, we learn compact feature representations by progressive downsampling, which can provide the overall information from the encoded high-level semantic context. Besides, dilated convolution is adopted to expand the receptive fields, which can effectively capture the contextual information and alleviate the details loss of resolution reduction. Correspondingly, the proposed method employs a local branch to enrich the feature representations and further emphasize the meaningful information for image details recovery. To this end, we design the residual dense attention block (RDAB) which encourages mid-level feature aggregation and persist memory by dense connections. Within the RDAB, a boosted attention mechanism (BAM) is presented to explicitly model the feature interdependencies between channels under different scales. Then, a weighting operation is conducted to balance the information flow received from these scales. Moreover, an adaptive weighted network is developed to achieve a good trade-off between the contributions of global and local information for semantical image dehazing. To take full account of quality evaluation, we use the L1 smooth loss and perceptual loss to reconsturct the dehazed images. Extensive evaluation demonstrates the superior performance of our method is 4db PSNR values and 0.1 SSIM value more than the related work while preserving credible contrast and color fidelity.
C1 [Wang, Zhao; Li, Feng; Cong, Runmin; Bai, Huihui; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Wang, Zhao; Li, Feng; Cong, Runmin; Bai, Huihui; Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Bai, HH (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.; Bai, HH (corresponding author), Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
EM hhbai@bjtu.edu.cn
RI Li, Feng/IWE-4665-2023
OI Li, Feng/0000-0001-9862-0432; Bai, Huihui/0000-0002-3879-8957
FU National Natural Science Foundation of China [61972023]; Fundamental
   Research Funds for the Central Universities [2019YJS031, 2019JBZ102]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61972023) and Fundamental Research Funds for the Central
   Universities (2019YJS031, 2019JBZ102).
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Bahat Y, 2016, IEEE INT CONF COMPUT, P34
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai H, 2019, IEEE ICC
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dai CG, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107257
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Gupta S, 2019, MULTIMED TOOLS APPL, V78, P34157, DOI 10.1007/s11042-019-08232-6
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeong D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071936
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lei JJ, 2021, IEEE T CIRC SYST VID, V31, P2686, DOI 10.1109/TCSVT.2020.3027616
   Li B., 2017, ARXIV PREPRINT ARXIV
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li F, 2020, IEEE T IMAGE PROCESS, V29, P4474, DOI 10.1109/TIP.2020.2972118
   Li KM, 2017, IEEE INT CONF COMP V, P491, DOI 10.1109/ICCVW.2017.65
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P345, DOI 10.1109/TCSVT.2021.3057518
   Peng B, 2021, NEUROCOMPUTING, V456, P519, DOI 10.1016/j.neucom.2020.05.123
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Reda M, 2018, 2018 IEEE CSAA GUIDANCE, NAVIGATION AND CONTROL CONFERENCE (CGNCC)
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yeh CH, 2020, IEEE T IMAGE PROCESS, V29, P3153, DOI 10.1109/TIP.2019.2957929
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu L, 2017, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2017.60
NR 52
TC 6
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11325
EP 11339
DI 10.1007/s11042-022-12151-4
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400007
DA 2024-07-18
ER

PT J
AU Bakkouri, I
   Afdel, K
   Benois-Pineau, J
   Catheline, G
AF Bakkouri, Ibtissam
   Afdel, Karim
   Benois-Pineau, Jenny
   Catheline, Gwenaelle
CA Alzheimer's Dis Neuroimaging Initi
TI BG-3DM2F: Bidirectional gated 3D multi-scale feature fusion for
   Alzheimer's disease diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; 3D convolutional neural network; 3D multi-scale
   feature fusion; Hippocampal volumes of interest; Bidirectional gated
   recurrent unit
ID MILD COGNITIVE IMPAIRMENT; CONVOLUTIONAL NEURAL-NETWORK; RECOGNITION;
   LSTM; CLASSIFICATION; HIPPOCAMPUS; MODEL; CNN; 3D-CNN; PARCELLATION
AB A computer-aided diagnosis system is one of the crucial decision support tools under the medical imaging scope. It has recently emerged as a powerful way to diagnose Alzheimer's Disease (AD) from structural magnetic resonance imaging scans. However, due to the deficit of recognition memory in the Mild Cognitive Impairment (MCI) stage, semantic feature ambiguity, and high inter-class visual similarities problems, computer-aided diagnosis of AD remains challenging. To bridge these gaps, this paper proposed a hippocampus analysis method based on a novel 3D convolutional neural network fusion strategy, called Bidirectional Gated 3D Multi-scale Feature Fusion (BG-3DM2F). The suggested BG-3DM2F framework consists of two modules: 3D Multi-Scale Chained Network (3DMS-ChaineNet) and Bidirectional Gated Recurrent Fusion Unit (Bi-GRFU). The 3DMS-ChaineNet architecture is introduced to design the subtle features and capture the variations in hippocampal atrophy, while the Bi-GRFU scheme is investigated to store 3DMS-ChaineNet levels in the forward and backward fashion and retain them in the decision-making process. For validation, our solution is completely evaluated on the public Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Practically, we conducted empirical evaluations to verify the effect of BG-3DM2F components. In comparison with the current state-of-the-art methods, the experiments show that our proposed approach provides efficient results, achieving the accuracies of 98.12%, 95.26%, and 96.97% for binary classification of Normal Control (NC) versus AD, AD versus MCI, and NC versus MCI, respectively. Therefore, we can conclude that our proposed BG-3DM2F system has the potential to dramatically improve the conventional classification methods for assisting clinical decision-making.
C1 [Bakkouri, Ibtissam; Afdel, Karim] Ibn Zohr Univ, Fac Sci, Dept Comp Sci, Lab Comp Syst & Vis LabSIV, BP 8106, Agadir 80000, Morocco.
   [Benois-Pineau, Jenny] Univ Bordeaux, Bordeaux Lab Comp Sci Res LaBRI UMR 5800, CNRS, Bordeaux INP, F-33400 Talence, France.
   [Catheline, Gwenaelle] Univ Victor Segalen Bordeaux 2, Aquitaine Inst Cognit & Integrat Neurosci INCIA U, CNRS, F-33076 Bordeaux, France.
C3 Ibn Zohr University of Agadir; Universite de Bordeaux; Centre National
   de la Recherche Scientifique (CNRS); Universite de Bordeaux; Centre
   National de la Recherche Scientifique (CNRS)
RP Bakkouri, I (corresponding author), Ibn Zohr Univ, Fac Sci, Dept Comp Sci, Lab Comp Syst & Vis LabSIV, BP 8106, Agadir 80000, Morocco.
EM ibtissam.bakkouri@gmail.com
RI Benois-Pineau, Jenny/ABG-6325-2020; Karim, AFDEL/AAC-7992-2019;
   Bakkouri, Ibtissam/Z-1275-2018
OI Benois-Pineau, Jenny/0000-0003-0659-8894; Karim,
   AFDEL/0000-0002-0828-2116; Bakkouri, Ibtissam/0000-0003-4827-9007
FU PPR2-2015 project [14UIZ2015]; Al Khawarizmi project - Moroccan
   government through the CNRST funding program; Alzheimer's Disease
   Neuroimaging Initiative (ADNI) (National Institutes of Health) [U01
   AG024904]; DOD ADNI (Department of Defense) [W81XWH-12-2-0012]; National
   Institute on Aging; National Institute of Biomedical Imaging and
   Bioengineering; AbbVie; Alzheimer's Association; Alzheimer's Drug
   Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen;
   Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan
   Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F. Hoffmann-La
   Roche Ltd.; Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd.;
   Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson &
   Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck;
   Merck Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research;
   Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer
   Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company;
   Transition Therapeutics; Canadian Institutes of Health Research
FX This work is supported in part by the PPR2-2015 project with the
   donation of the NVIDIA Geforce GTX 1080 Ti GPU used for this research
   under grant no 14UIZ2015, and in part by the Al Khawarizmi project
   financed by the Moroccan government through the CNRST funding program.
   Data collection and sharing for this project was funded by the
   Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes
   of Health Grant U01 AG024904) and DOD ADNI (Department of Defense award
   numberW81XWH-12-2-0012). ADNI is funded by the National Institute on
   Aging, the National Institute of Biomedical Imaging and Bioengineering,
   and through generous contributions from the following: AbbVie,
   Alzheimer's Association; Alzheimer's Drug Discovery Foundation; Araclon
   Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company;
   CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli
   Lilly and Company; EuroImmun; F. Hoffmann-La Roche Ltd and its
   affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO
   Ltd.;Janssen Alzheimer Immunotherapy Research & Development, LLC.;
   Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity;
   Lundbeck; Merck & Co., Inc.;Meso Scale Diagnostics, LLC.; NeuroRx
   Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation;
   Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company;
   and Transition Therapeutics. The Canadian Institutes of Health Research
   is providing funds to support ADNI clinical sites in Canada. Private
   sector contributions are facilitated by the Foundation for the National
   Institutes of Health (www.fnih.org). The grantee organization is the
   Northern California Institute for Research and Education, and the study
   is coordinated by the Alzheimer's Therapeutic Research Institute at the
   University of Southern California. ADNI data are disseminated by the
   Laboratory for Neuro Imaging at the University of Southern California.
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Aderghal K, 2017, LECT NOTES COMPUT SC, V10132, P690, DOI 10.1007/978-3-319-51811-4_56
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Arifoglu D, 2019, ARTIF INTELL MED, V94, P88, DOI 10.1016/j.artmed.2019.01.005
   Asl EH, 2018, FRONT BIOSCI-LANDMRK, V23, P584, DOI 10.2741/4606
   BAKKOURI I, 2019, INT WORK CONTENT MUL
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bakkouri I, 2019, MULTIMED TOOLS APPL, V78, P12939, DOI 10.1007/s11042-018-6267-z
   Baldi P, 2014, ARTIF INTELL, V210, P78, DOI 10.1016/j.artint.2014.02.004
   Banning LCP, 2020, AM J GERIAT PSYCHIAT, V28, P735, DOI 10.1016/j.jagp.2020.01.012
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Ben Ahmed O, 2017, NEUROCOMPUTING, V220, P98, DOI 10.1016/j.neucom.2016.08.041
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Ben Miled Z, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101771
   Blennow K, 2006, LANCET, V368, P387, DOI 10.1016/S0140-6736(20)32205-4
   Budson A E., 2016, Memory Loss, Alzheimer's Disease and Dementia, VSecond, P47, DOI [10.1016/b978-0-323-28661-9.00004-4, DOI 10.1016/B978-0-323-28661-9.00004-4]
   Budson AE., 2016, Memory loss, Alzheimer's disease, and dementia: a practical guide for clinicians, V2nd, P5, DOI DOI 10.1016/B978-0-323-28661-9.00002-0
   Cahall DE, 2019, FRONT COMPUT NEUROSC, V13, DOI 10.3389/fncom.2019.00044
   Castro A, 2019, PATHOPHYSIOLOGY, DOI 10.1016/j.pathophys.2019.07.003
   Cattaud V, 2018, NEUROBIOL AGING, V72, P147, DOI 10.1016/j.neurobiolaging.2018.08.024
   Cheng D, 2017, LECT NOTES COMPUT SC, V10541, P106, DOI 10.1007/978-3-319-67389-9_13
   Cheng HJ, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1511-4
   Cogan T, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103351
   Cruz-Alonso M, 2019, TALANTA, V197, P413, DOI 10.1016/j.talanta.2019.01.056
   Cui RX, 2019, IEEE J BIOMED HEALTH, V23, P2099, DOI 10.1109/JBHI.2018.2882392
   Cui RX, 2018, PROC SPIE, V10806, DOI 10.1117/12.2503194
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Du XF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030789
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Esmaeilzadeh S, 2018, LECT NOTES COMPUT SC, V11046, P337, DOI 10.1007/978-3-030-00919-9_39
   Fawzi A, 2017, IEEE SIGNAL PROC MAG, V34, P50, DOI 10.1109/MSP.2017.2740965
   Feng CY, 2019, IEEE ACCESS, V7, P63605, DOI 10.1109/ACCESS.2019.2913847
   Feng CY, 2018, LECT NOTES COMPUT SC, V11121, P138, DOI 10.1007/978-3-030-00320-3_17
   Frisoni GB, 2005, J NEUROL NEUROSUR PS, V76, P112, DOI 10.1136/jnnp.2003.029876
   Gessert N, 2018, INT J COMPUT ASS RAD, V13, P1073, DOI 10.1007/s11548-018-1777-8
   Grajski KA, 2019, NEUROIMAGE-CLIN, V23, DOI 10.1016/j.nicl.2019.101860
   Hsiao TY, 2019, J SYST ARCHITECT, V95, P9, DOI 10.1016/j.sysarc.2019.02.008
   Hu XC, 2019, ALZHEIMERS DEMENT, V15, P185, DOI 10.1016/j.jalz.2018.09.002
   Huang SP, 2018, PATTERN RECOGN, V77, P395, DOI 10.1016/j.patcog.2017.10.018
   HUANG Y, 2019, FRONT NEUROSCI-SWITZ
   Islam J, 2018, LECT NOTES ARTIF INT, V11309, P359, DOI 10.1007/978-3-030-05587-5_34
   Islam MS, 2018, PROCEDIA COMPUT SCI, V143, P595, DOI 10.1016/j.procs.2018.10.436
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Jack CR, 2008, J MAGN RESON IMAGING, V27, P685, DOI 10.1002/jmri.21049
   Jagannatha A, 2016, P 2016 C N AM CHAPT, DOI 10.18653/v1/n16-1056
   Kam TE, 2018, LECT NOTES COMPUT SC, V11072, P293, DOI 10.1007/978-3-030-00931-1_34
   Karasawa H, 2018, LECT NOTES ARTIF INT, V10751, P287, DOI 10.1007/978-3-319-75417-8_27
   King DB, 2015, ACS SYM SER, V1214, P1
   Klambauer G, 2017, ADV NEUR IN, V30
   Kleinberg R, 2018, PR MACH LEARN RES, V80
   Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Li F, 2017, IEEE ACCESS, V5, P10979, DOI 10.1109/ACCESS.2017.2713389
   Li HM, 2019, ALZHEIMERS DEMENT, V15, P1059, DOI 10.1016/j.jalz.2019.02.007
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Liu B, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2287
   Liu FG, 2020, NEUROCOMPUTING, V371, P39, DOI 10.1016/j.neucom.2019.09.012
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Liu J, 2018, IEEE ACM T COMPUT BI, V15, P624, DOI 10.1109/TCBB.2016.2635144
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Lyu C, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1868-5
   Marteau P, 2016, ADV KNOWLEDGE DISCOV, P39, DOI [10.1007/978-3-319-45763-5setminus_3, DOI 10.1007/978-3-319-45763-5SETMINUS_3]
   McNeely-White D, 2020, COGN SYST RES, V59, P312, DOI 10.1016/j.cogsys.2019.10.004
   Mufson EJ, 2015, NEUROSCIENCE, V309, P51, DOI 10.1016/j.neuroscience.2015.03.006
   Mukkamala MC, 2017, PR MACH LEARN RES, V70
   Nalepa J, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101769
   Nam D, 2014, CLIN ORTHOP RELAT R, V472, P3665, DOI 10.1007/s11999-014-3579-9
   Nickerson P, 2016, IEEE ENG MED BIO, P2966, DOI 10.1109/EMBC.2016.7591352
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2018, IEEE T IMAGE PROCESS, V27, P2575, DOI 10.1109/TIP.2018.2806229
   Ofori E, 2019, NEUROIMAGE-CLIN, V24, DOI 10.1016/j.nicl.2019.101985
   OHZEKI M, 2018, SCI REP-UK
   Ouyang X, 2019, IEEE ACCESS, V7, P40757, DOI 10.1109/ACCESS.2019.2906654
   Pagola M, 2017, LECT NOTES COMPUT SC, V10255, P437, DOI 10.1007/978-3-319-58838-4_48
   Pirzada S, 2020, MAGN RESON IMAGING, V68, P83, DOI 10.1016/j.mri.2020.01.016
   Pluta R, 2018, PHARMACOL REP, V70, P881, DOI 10.1016/j.pharep.2018.03.004
   Rabai F, 2017, ESSENTIALS NEUROANES, P519, DOI [10.1016/b978-0-12-805299-0.00031-2, DOI 10.1016/B978-0-12-805299-0.00031-2]
   Rao CP, 2020, COMP MATER SCI, V184, DOI 10.1016/j.commatsci.2020.109850
   Rolls ET, 2020, NEUROIMAGE, V206, DOI 10.1016/j.neuroimage.2019.116189
   Rolls ET, 2015, NEUROIMAGE, V122, P1, DOI 10.1016/j.neuroimage.2015.07.075
   Selkoe D.J., 2015, Rosenberg's Molecular and Genetic Basis of Neurological and Psychiatric Disease, P753, DOI [DOI 10.1016/B978-0-12-410529-4.00067-X, 10.1016/b978-0-12-410529-4.00067-x]
   SHEN J, 2019, P 56 ANN DES AUT C 2
   Shinagawa S, 2016, NEUROSCI LETT, V629, P33, DOI 10.1016/j.neulet.2016.06.055
   Shmulev Yaroslav, 2018, Graphs in Biomedical Image Analysis and Integrating Medical Imaging and Non-Imaging Modalities. Second International Workshop, GRAIL 2018 and First International Workshop, Beyond MIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11044), P83, DOI 10.1007/978-3-030-00689-1_9
   Slot RER, 2019, ALZHEIMERS DEMENT, V15, P465, DOI 10.1016/j.jalz.2018.10.003
   Sorensen L, 2017, NEUROIMAGE-CLIN, V13, P470, DOI 10.1016/j.nicl.2016.11.025
   Tang H, 2018, COMM COM INF SC, V888, P115, DOI 10.1007/978-981-13-2122-1_9
   Thapar D, 2019, PATTERN RECOGN LETT, V125, P646, DOI 10.1016/j.patrec.2019.07.008
   Tipps ME, 2015, INT REV NEUROBIOL, V123, P239, DOI 10.1016/bs.irn.2015.05.012
   Bui TD, 2019, ARTIF INTELL MED, V97, P1, DOI 10.1016/j.artmed.2019.04.005
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Umamakeswari A, 2020, ADV INTELL SYST COMP, V1034, P531, DOI 10.1007/978-981-15-1084-7_51
   Vorugunti CS, 2020, NEUROCOMPUTING, V409, P157, DOI 10.1016/j.neucom.2020.05.072
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Wijnands JS, 2020, NEURAL COMPUT APPL, V32, P9731, DOI 10.1007/s00521-019-04506-0
   Xu JY, 2018, PR MACH LEARN RES, V80
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   XU X, 2019, NEUROCOMPUTING
   Yan Y, 2018, LECT NOTES COMPUT SC, V11121, P26, DOI 10.1007/978-3-030-00320-3_4
   Yang H, 2019, PATTERN RECOGN, V85, P1, DOI 10.1016/j.patcog.2018.07.028
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   ZHANG K, 2018, 2018 IEEE INT C BIG
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhao K, 2020, SCI BULL, V65, P1103, DOI 10.1016/j.scib.2020.04.003
   Zhi SF, 2018, COMPUT GRAPH-UK, V71, P199, DOI 10.1016/j.cag.2017.10.007
   Zhou TX, 2019, ARRAY-NY, V3-4, DOI 10.1016/j.array.2019.100004
   Zhou ZH, 2019, MULTIMED TOOLS APPL, V78, P35813, DOI 10.1007/s11042-019-08101-2
   Zhu ZJ, 2020, PATTERN RECOGN LETT, V140, P358, DOI 10.1016/j.patrec.2020.11.009
NR 111
TC 16
Z9 16
U1 8
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10743
EP 10776
DI 10.1007/s11042-022-12242-2
EA FEB 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700009
DA 2024-07-18
ER

PT J
AU Hasan, U
   Hussain, W
   Rasool, N
AF Hasan, Usama
   Hussain, Waqar
   Rasool, Nouman
TI AEPI: insights into the potential of deep representations for human
   identification through outer ear images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Ear Pinna; Ear biometrics; Deep learning; Residual network;
   Spatial encoding
ID RECOGNITION; PATTERN
AB For forensic human identification, one of the most important methods is by opting for protocols of biometrics. The outer human ear, also known as auricle or pinna, has unique characteristics, which are not even the same in identical twins. Thus, considering the uniqueness, reliability, and easy collectability of this trait, herein, a novel method is proposed for human identification namely Automated Ear Pinna Identification (AEPI). The proposed method opts for potentials of deep learning, by creating a unique blend of deep representation from a residual network and a spatial encoding block to identify human ear pinna imagery. The evaluation of the proposed method is also performed by comparing both, same and different ear pinna image pairs. Based on the evaluation, it is observed that the proposed method is 87.207% accurate for classification among classes of the dataset, 97.2% for gender-based classification and 99.0% accurate for identifying humans based on ear pinna images. These scores depict the strong potential and contribution of the proposed method in the field of ear biometrics and it is concluded that AEPI can aid the identification of humans based on ear pinna images in an accurate, effective and efficient manner. AEPI is freely available at (http://zeetu.org/AEPI.html).
C1 [Hasan, Usama] Univ Punjab, Punjab Univ Coll Informat Technol, Natl Ctr Artificial Intelligence, Lahore, Pakistan.
   [Hussain, Waqar] Univ Management & Technol, Sch Syst & Technol, Dept Comp Sci, Lahore, Pakistan.
   [Rasool, Nouman] Ctr Profess & Appl Studies, Lahore, Pakistan.
C3 University of Punjab; University of Management & Technology (UMT)
RP Rasool, N (corresponding author), Ctr Profess & Appl Studies, Lahore, Pakistan.
EM noumanrasool@gmail.com
RI Hussain, Waqar/AAC-9367-2020
OI Hussain, Waqar/0000-0001-8991-9424; Rasool, Nouman/0000-0003-0210-5845
CR Abaza A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431221
   Abdelwhab A., 2018, Machine learning and biometrics
   Priyadharshini RA, 2021, APPL INTELL, V51, P2161, DOI 10.1007/s10489-020-01995-8
   Al Rahhal MM, 2018, IEEE ACCESS, V6, P11883, DOI 10.1109/ACCESS.2018.2810339
   Al Rahhal MM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013007
   Alkababji A.M., 2021, Telkomnika (Telecommun. Comput. Electron. Control), V19, P523, DOI [10.12928/telkomnika.v19i2.18322, DOI 10.12928/TELKOMNIKA.V19I2.18322]
   Benzaoui A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053008
   Cao K, 2019, IEEE T PATTERN ANAL, V41, P788, DOI 10.1109/TPAMI.2018.2818162
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chatterjee A, 2019, OPT LASER TECHNOL, V112, P368, DOI 10.1016/j.optlastec.2018.11.043
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chowdhury DP, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0855-8
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dodge S, 2018, IET BIOMETRICS, V7, P207, DOI 10.1049/iet-bmt.2017.0208
   Doghmane H, 2019, INT J BIOMETRICS, V11, P50, DOI 10.1504/IJBM.2019.10016808
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Ghoualmi L, 2016, EXPERT SYST APPL, V57, P49, DOI 10.1016/j.eswa.2016.03.004
   Gonzalez, 2018, AMI EAR DATASET
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Hassaballah M, 2019, EXPERT SYST APPL, V118, P182, DOI 10.1016/j.eswa.2018.10.007
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hezil N, 2017, IET BIOMETRICS, V6, P351, DOI 10.1049/iet-bmt.2016.0072
   Hinton GE, 1993, ADV NEURAL INFORM PR, P3, DOI [DOI 10.1021/JP906511Z, DOI 10.5555/2987189.2987190]
   Hoang, 2019, EARVN1 0 NEW LARGE S
   Hussain W, 2020, FORENSIC SCI INT, V313, DOI 10.1016/j.forsciint.2020.110345
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008
   Larrain T, 2017, IEEE T INF FOREN SEC, V12, P1646, DOI 10.1109/TIFS.2017.2680403
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Galdámez PL, 2017, J APPL LOGIC, V24, P62, DOI 10.1016/j.jal.2016.11.014
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Paszke Adam, 2017, NIPS W
   Rasool N, 2020, FORENSIC SCI INT, V307, DOI 10.1016/j.forsciint.2020.110142
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Zhang L, 2021, IEEE T NEUR NET LEAR, DOI [10.1109/TNNLS.2021.3105143, 10.1109/TCYB.2021.3101880]
   Zhang Y, 2017, LECT NOTES COMPUT SC, V10667, P405, DOI 10.1007/978-3-319-71589-6_35
NR 51
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10427
EP 10443
DI 10.1007/s11042-022-12025-9
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700031
DA 2024-07-18
ER

PT J
AU Lakehal, A
   Alti, A
   Roose, P
AF Lakehal, Abderrahim
   Alti, Adel
   Roose, Philippe
TI Real-time ontology-based context-aware situation reasoning framework in
   pervasive computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT; Ontologies; Heterogeneous objects; Smart environments; Urgent
   composite situations
ID ACTIVITY RECOGNITION
AB Currently, the use of mobile applications for smart environments have multiplied, and they play a fundamental role in people's daily lives. While there are many applications based on a microservices architecture that can simultaneously handle various context data provided by heterogeneous connected objects, this is not the case with mobile devices for real-time composite user-centric urgent situations. In fact, it becomes necessary to rethink a new way to minimize both the ratio of missed situations and the response time by combining competitive microservices with a priority-based parallel reasoning strategy. In this paper, we introduce a novel flexible, modular and hierarchical loosely coupled framework which can be employed for parallel composite situations that rule management and reasoning. To provide such reasoning, we proposed an innovative parallel reasoning process, which involved a set of filtered and factorized user's situations rules, priority-based on the emergency of the events and situations to speed up the queued urgent situation rules, and parallel situations identification across collaborating microservices. We compared the proposed approach with existing reasoning approaches of the smart domains use cases in terms of expired event ratio, missed situation ratio, event detection throughput and latency. The experiments show that the proposed approach achieved low expired event and missed situation ratios, going up to 0.07 and 0.1 respectively. In addition, results show that the proposed approach can detect events in a high workload with an average detection latency of 2.4ms, also that the event detection throughput is improved to 82.4% thanks to a new shared lightweight thread approach in comparison with pipelining-based approach.
C1 [Lakehal, Abderrahim; Alti, Adel] Univ Ferhat Abbas SETIF 1, Dept Comp Sci, LRSD Lab, Fac Sci, POB 19000, Setif, Algeria.
   [Alti, Adel] Qassim Univ, Dept Management Informat Syst, Coll Business & Econ, POB 6633, Buraydah 51452, Saudi Arabia.
   [Roose, Philippe] Univ PAU, LIUPPA, F-64000 Anglet, France.
C3 Universite Ferhat Abbas Setif; Qassim University; Universite de Pau et
   des Pays de l'Adour
RP Alti, A (corresponding author), Univ Ferhat Abbas SETIF 1, Dept Comp Sci, LRSD Lab, Fac Sci, POB 19000, Setif, Algeria.; Alti, A (corresponding author), Qassim Univ, Dept Management Informat Syst, Coll Business & Econ, POB 6633, Buraydah 51452, Saudi Arabia.
EM abderrahim.lakehal@univ-setif.dz; alti.adel@tutivsetif.dz;
   philippe.roose@iutbayonne.univ-pau.fr
RI Adel, ALTI/AAW-2318-2021
OI Adel, ALTI/0000-0001-8348-1679
CR Al-Jawad MMH, 2017, THESIS U SALFORD
   Alirezaie M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071586
   Alti A, 2016, FUTURE INTERNET, V8, DOI 10.3390/fi8040048
   Angsuchotmetee C, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P247, DOI 10.1145/3167132.3167380
   [Anonymous], 2012, THESIS
   Asim M, 2018, J SOFTW-EVOL PROC, V30, DOI 10.1002/smr.1944
   Augusto JC, 2008, INT J COMPUT INT SYS, V1, P361
   Bermudez-Edo M, 2017, PERS UBIQUIT COMPUT, V21, P475, DOI 10.1007/s00779-017-1010-8
   Butt SA, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3684
   Cedric D, 2013, IGI GLOBAL, P225
   Cumin J, 2017, LECT NOTES COMPUT SC, V10586, P413, DOI 10.1007/978-3-319-67585-5_43
   Da K, 2014, SER SAC 14, P413
   GU T, 2004, P COMM NETW DISTR NE
   Gull Karuna, 2017, INT J RECENT INNOV T, V5, P221
   Henricksen K, 2006, PERVASIVE MOB COMPUT, V2, P37, DOI 10.1016/j.pmcj.2005.07.003
   Jimenez A.R., 2018, MULTIDISCIPLINARY DI, V2, P1264
   Kanda T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P380, DOI 10.1145/1409635.1409686
   Karchoud R, 2017, PERS UBIQUIT COMPUT, V21, P1025, DOI 10.1007/s00779-017-1077-2
   Lakehal A., 2019, International Journal of Advanced Computer Research, V9, P212, DOI [10.19101/IJACR.PID33, DOI 10.19101/IJACR.PID33]
   Mansour E, 2019, INT DATABASE ENG APP, P53, DOI 10.1145/3331076.3331102
   Meditskos G, 2017, PERVASIVE MOB COMPUT, V40, P17, DOI 10.1016/j.pmcj.2017.05.003
   Papamarkos G, 2007, EVENT CONDITION ACTI
   Patel SN, 2007, LECT NOTES COMPUT SC, V4717, P271
   Ranganathan A, 2004, IEEE PERVAS COMPUT, V3, P62, DOI 10.1109/MPRV.2004.1316821
   Riboni D, 2009, LECT NOTES COMPUT SC, V5585, P39, DOI 10.1007/978-3-642-02830-4_5
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Sioutis M., 2017, IJCAI WORKSH QUAL RE, P901
   Swapna G, 2018, ICT EXPRESS, V4, P243, DOI 10.1016/j.icte.2018.10.005
   Wojek C., 2006, 2006 IEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (IEEE Cat. No. 06TH8908), P25, DOI 10.1109/MFI.2006.265608
   Yang JB, 2006, IEEE T SYST MAN CY A, V36, P266, DOI 10.1109/TSMCA.2005.851270
   Yang JY, 2008, PATTERN RECOGN LETT, V29, P2213, DOI 10.1016/j.patrec.2008.08.002
   Ye J, 2015, PERVASIVE MOB COMPUT, V19, P47, DOI 10.1016/j.pmcj.2014.02.003
NR 32
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14913
EP 14957
DI 10.1007/s11042-022-12252-0
EA FEB 2022
PG 45
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000755422300002
DA 2024-07-18
ER

PT J
AU Dokuz, Y
   Tüfekci, Z
AF Dokuz, Yesim
   Tufekci, Zekeriya
TI Feature-based hybrid strategies for gradient descent optimization in
   end-to-end speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Deep learning; Mini-batch gradient descent; Hybrid
   sample selection strategies; LSTM
AB With the increasing popularity of deep learning, deep learning architectures are being utilized in speech recognition. Deep learning based speech recognition became the state-of-the-art method for speech recognition tasks due to their outstanding performance over other methods. Generally, deep learning architectures are trained with a variant of gradient descent optimization. Mini-batch gradient descent is a variant of gradient descent optimization which updates network parameters after traversing a number of training instances. One limitation of mini-batch gradient descent is the random selection of mini-batch samples from training set. This situation is not preferred in speech recognition which requires training features to collapse all possible variations in speech databases. In this study, to overcome this limitation, hybrid mini-batch sample selection strategies are proposed. The proposed hybrid strategies use gender and accent features of speech databases in a hybrid way to select mini-batch samples when training deep learning architectures. Experimental results justify that using hybrid of gender and accent features is more successful in terms of speech recognition performance than using only one feature. The proposed hybrid mini-batch sample selection strategies would benefit other application areas that have metadata information, including image recognition and machine vision.
C1 [Dokuz, Yesim] Nigde Omer Halisdemir Univ, Dept Comp Engn, Nigde, Turkey.
   [Tufekci, Zekeriya] Cukurova Univ, Dept Comp Engn, Adana, Turkey.
C3 Nigde Omer Halisdemir University; Cukurova University
RP Dokuz, Y (corresponding author), Nigde Omer Halisdemir Univ, Dept Comp Engn, Nigde, Turkey.
EM ytorun@ohu.edu.tr
RI Tüfekci, Zekeriya/G-4701-2018
OI Dokuz, Yesim/0000-0001-7202-2899
CR Chang H.-S., 2017, NeurIPS, P1002
   Chen MY, 2018, IEEE SIGNAL PROC LET, V25, P1440, DOI 10.1109/LSP.2018.2860246
   Dai XY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P599, DOI 10.1145/3397271.3401045
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Doetsch P, 2017, ARXIV170502414, P1
   Dokuz Y, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107573
   Garain A, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114416
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Graves A, 2012, STUD COMPUT INTELL, V385, P61
   Hourri S, 2020, INT J SPEECH TECHNOL, V23, P123, DOI 10.1007/s10772-019-09665-y
   Hussain W, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2021.107941
   Joseph KJ, 2019, ARXIV190608771, P1
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Loshchilov I., 2015, ARXIV151106343
   Maas A., 2015, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P345
   Mei MQ, 2021, IET IMAGE PROCESS, V15, P3638, DOI 10.1049/ipr2.12271
   Nicolson A, 2019, SPEECH COMMUN, V111, P44, DOI 10.1016/j.specom.2019.06.002
   Park JS, 2018, SIGNAL PROCESS-IMAGE, V67, P132, DOI 10.1016/j.image.2018.04.015
   Peng XY, 2020, IEEE T NEUR NET LEAR, V31, P4649, DOI 10.1109/TNNLS.2019.2957003
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Ruder S., 2016, ARXIV
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Souli S, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2020.107854
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Veaux C., 2016, CSTR VCTK corpus: English multi-speaker corpus for CSTR voice cloning toolkit
   Wang D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050644
   Wang ZY, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107647
   Watanabe S, 2017, IEEE J-STSP, V11, P1240, DOI 10.1109/JSTSP.2017.2763455
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Zheng LL, 2016, MULTIMED TOOLS APPL, V75, P5055, DOI 10.1007/s11042-015-2847-3
NR 36
TC 3
Z9 3
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9969
EP 9988
DI 10.1007/s11042-022-12304-5
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800020
DA 2024-07-18
ER

PT J
AU Tiple, B
   Patwardhan, M
AF Tiple, Bhavana
   Patwardhan, Manasi
TI Multi-label emotion recognition from Indian classical music using
   gradient descent SNN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Spiking neural network; Gradient descent;
   Temporal; Spectral; Short Term Fourier Transform
ID SPIKING NEURAL-NETWORK; CLASSIFICATION
AB Music enthusiasts are growing exponentially and based on this, many songs are being introduced to the market and stored in signal music libraries. Due to this development emotion recognition model from music contents has received increasing attention in today's world. Of these technologies, a novel Music Emotion Recognition (MER) system is introduced to meet the ever-increasing demand for easy and efficient access to music information. Even though this system was well-developed it lacks in maintaining accuracy of the system and finds difficulty in predicting multi-label emotion type. To address these shortcomings, in this research article, a novel MER system is developed by inter-linking the pre-processing, feature extraction and classification steps. Initially, pre-processing step is employed to convert larger audio files into smaller audio frames. Afterwards, music related temporal, spectral and energy features are extracted for those pre-processed frames which are subjected to the proposed gradient descent based Spiking Neural Network (SNN) classifier. While learning SNN, it is important to determine the optimal weight values for reducing the training error so that gradient descent optimization approach is adopted. To prove the effectiveness of proposed research, proposed model is compared with conventional classification algorithms. The proposed methodology was experimentally tested using various evaluation metrics and it achieves 94.55% accuracy. Hence the proposed methodology attains a good accuracy measure and outperforms well than other algorithms.
C1 [Tiple, Bhavana] Dr Vishwanath Karad MIT World Peace Univ, Sch SCET, Pune, Maharashtra, India.
   [Patwardhan, Manasi] TCS Innovat Labs, Pune, Maharashtra, India.
C3 Dr. Vishwanath Karad MIT World Peace University
RP Tiple, B (corresponding author), Dr Vishwanath Karad MIT World Peace Univ, Sch SCET, Pune, Maharashtra, India.
EM bhavana.tiple@mitwpu.edu.in
CR [Anonymous], 2019, INT C LEARNING REPRE
   Anyu Chen, 2010, Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P4088, DOI 10.1109/CISP.2010.5646222
   Bajaj V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0048-y
   Baniya BK, 2017, J INF PROCESS SYST, V13, P400, DOI 10.3745/JIPS.04.0032
   Barthet Mathieu, 2012, INT S COMP MUS MOD R, P228, DOI DOI 10.1007/978-3-642-41248-6_13
   Bashwiner DM, 2016, SCI REP-UK, V6, DOI 10.1038/srep20482
   Baume C, 2013, P AUD ENG SOC CONV, P134
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Buscicchio CA, 2006, LECT NOTES ARTIF INT, V4203, P38
   Capizzi G, 2020, NEURAL NETWORKS, V129, P271, DOI 10.1016/j.neunet.2020.06.001
   Charles, 2019, APPLICABILITY MIREMO
   Chingshun Lin, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P375, DOI 10.1109/ICMLC.2016.7860930
   Costa Y.M.G., 2011, 2011 18th International Conference on Systems, Signals and Image Processing, P1
   Eyben F, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0057-6
   Fürnkranz J, 2008, MACH LEARN, V73, P133, DOI 10.1007/s10994-008-5064-8
   Gyöngyössy NM, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P2201, DOI 10.1109/SSCI44817.2019.9002720
   Juslin PN., 2010, J NEW MUSIC RES, V33, P216
   Liu Y, 2015, IEEE T AFFECT COMPUT, V6, P247, DOI 10.1109/TAFFC.2015.2396151
   Lokhande PS, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P262, DOI 10.1109/ICCONS.2017.8250723
   Malheiro R, 2018, IEEE T AFFECT COMPUT, V9, P240, DOI 10.1109/TAFFC.2016.2598569
   Meftah B., 2013, ARTIF INTELL, P525, DOI DOI 10.1007/978-3-642-29694-9_20
   Misron M.M., 2014, Recent Advances on Soft Computing and Data Mining, P539
   Mo SS, 2019, IEEE T AFFECT COMPUT, V10, P313, DOI 10.1109/TAFFC.2017.2724515
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Pouyanfar S, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Querlioz D, 2013, IEEE T NANOTECHNOL, V12, P288, DOI 10.1109/TNANO.2013.2250995
   Rachman F.H., 2018, INT J ELECT COMPUT E, V8, P1720, DOI [10.11591/ijece.v8i3.pp1720-1730, DOI 10.11591/IJECE.V8I3.PP1720-1730]
   Sanden Chris., 2011, Proceedings of the International Society for Music Information Retrieval Conference, P717
   Schmidt E.M., 2010, Proceedings of the international conference on Multimedia information retrieval, P267, DOI 10.1145/1743384.1743431
   Tsoumakas G, 2011, IEEE T KNOWL DATA EN, V23, P1079, DOI 10.1109/TKDE.2010.164
   Virgilio CD, 2020, NEURAL NETWORKS, V122, P130, DOI 10.1016/j.neunet.2019.09.037
   Wieczorkowska A, 2006, ADV SOFT COMP, P307
NR 32
TC 5
Z9 5
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8853
EP 8870
DI 10.1007/s11042-022-11975-4
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000752739500001
DA 2024-07-18
ER

PT J
AU Ding, N
   Tian, SW
   Yu, L
AF Ding, Ning
   Tian, Sheng-wei
   Yu, Long
TI A multimodal fusion method for sarcasm detection based on late fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal fusion; Sarcasm detection; Dialogue emotion recognition
AB Information on social media is multi-modal, most of which contains the meaning of sarcasm. In recent years, many people have studied the problem of sarcasm detection. Many traditional methods have been proposed in this field, but the study of deep learning methods to detect sarcasm is still insufficient. It is necessary to comprehensively consider the information of the text,the changes of the tone of the audio signal,the facial expressions and the body post= in the image to detect sarcasm. This paper proposes a multilevel late-fusion learning framework with residual connections, a more reasonable experimental data-set split and two model variants based on different experimental settings. Extensive experiments on the MUStARD show that our methods are better than other fusion models. In our speaker-independent experimental split, the multi-modality has a 4.85% improvement over the single-modality, and the Error rate reduction has an improvement of 11.8%. The latest code will be updated to this URL later: https://github.com/DingNing123/m_fusion
C1 [Ding, Ning] Xinjiang Univ, Sch Informat Sci & Engn, 666 Shengli Rd, Urumqi 830046, Xinjiang, Peoples R China.
   [Tian, Sheng-wei] Xinjiang Univ, Sch Software, 499 Xibei Rd, Urumqi 830008, Xinjiang, Peoples R China.
   [Yu, Long] Xinjiang Univ, Network Ctr, 666 Shengli Rd, Urumqi 830046, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University; Xinjiang University
RP Tian, SW (corresponding author), Xinjiang Univ, Sch Software, 499 Xibei Rd, Urumqi 830008, Xinjiang, Peoples R China.
EM dn1992@stu.xju.edu.cn; tianshengwei@163.com; yul@xju.edu.cn
RI Wang, Zhi/GZB-2713-2022
OI Wang, Zhi/0000-0001-6952-8848; Yu, Long/0000-0002-9038-4129; Tian,
   Shengwei/0000-0003-3525-5102
FU National Natural Science Foundation of China [61962057]; Key Program of
   National Natural Science Foundation of China [U2003208]; major
   scientific and technological project of the Autonomous Region, "Research
   and Development of Key Technologies for Public Health and Epidemics
   Prevention System in Xinjiang" [2020A03004-4]; Key research and
   development project of Xinjiang Uygur Autonomous Region [2021B01002]
FX This work was supported by the National Natural Science Foundation of
   China (61962057), Key Program of National Natural Science Foundation of
   China (U2003208), the major scientific and technological project of the
   Autonomous Region, "Research and Development of Key Technologies for
   Public Health and Epidemics Prevention System in Xinjiang", project
   number: 2020A03004-4, and Key research and development project of
   Xinjiang Uygur Autonomous Region (2021B01002). We thank the creators of
   MUSTARD for their efforts and contributions.
CR Abu Farha I., 2021, AclwebOrg 2021, P21
   [Anonymous], 2017, INT C COMP LING INT
   Baziotis C., 2018, ARXIV
   Biewald L., 2020, Experiment tracking with weights and biases
   Cai YT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2506
   Castro S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4619
   Chakrabarty Tuhin, 2020, ARXIV200413248
   Chauhan DS, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P281
   Chauhan DS, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4351
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J., 2018, BERT PRE TRAINING DE
   Diao YF, 2020, IEEE ACCESS, V8, P135152, DOI 10.1109/ACCESS.2020.2967095
   Felbo B., 2017, P 2017 C EMP METH NA, P1615, DOI DOI 10.18653/V1/D17-1169
   Grice H. P., 1975, SYNTAX SEMANTICS, V3, P41, DOI DOI 10.1163/9789004368811_003
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jain D, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106198
   Jena AK, 2020, FIGURATIVE LANGUAGE PROCESSING, P61
   Joshi A., 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, P1006
   Joshi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3124420
   Kumar A, 2020, IEEE ACCESS, V8, P6388, DOI 10.1109/ACCESS.2019.2963630
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Liu Z., 2018, ARXIV PREPRINT ARXIV
   McFee B., 2018, LIBROSA LIBROSA 0 6
   Mishra A, 2016, P AAAI C ART INT, V30
   Paul S, 2022, MULTIMED TOOLS APPL, V81, P26989, DOI 10.1007/s11042-020-09631-w
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pereira MHR, 2019, MULTIMED TOOLS APPL, V78, P23783, DOI 10.1007/s11042-019-7691-4
   Poria S., 2018, ARXIV PREPRINT ARXIV
   Poria S, 2019, IEEE ACCESS, V7, P100943, DOI 10.1109/ACCESS.2019.2929050
   Ren L, 2020, NEUROCOMPUTING, V401, P320, DOI 10.1016/j.neucom.2020.03.081
   Sarsam SM, 2020, INT J MARKET RES, V62, P578, DOI 10.1177/1470785320921779
   Schifanella R., 2016, P 24 ACM INT C MULT, P1136
   Tay Y, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1010
   Tembhurne JV, 2021, MULTIMED TOOLS APPL, V80, P6871, DOI 10.1007/s11042-020-10037-x
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Williams J, 2018, FIRST GRAND CHALLENGE AND WORKSHOP ON HUMAN MULTIMODAL LANGUAGE (CHALLENGE-HML), P11
   Xiong T, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2115, DOI 10.1145/3308558.3313735
   Xu N, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3777
   Yu WM, 2021, AAAI CONF ARTIF INTE, V35, P10790
   Yu WM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3718
   Zadeh A., 2018, P AAAI C ART INT, V32
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2016, IEEE INTELL SYST, V31, P82, DOI 10.1109/MIS.2016.94
   Zhang M, 2016, PROCEEDINGS 2016 INTERNATIONAL CONFERENCE ON NETWORKING AND NETWORK APPLICATIONS NANA 2016, P244, DOI 10.1109/NaNA.2016.12
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 48
TC 13
Z9 13
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8597
EP 8616
DI 10.1007/s11042-022-12122-9
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751246700005
DA 2024-07-18
ER

PT J
AU Kim, BM
AF Kim, Byung-Man
TI Analysis of social recognition network of North Korean children's rights
   and welfare through big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyword network analysis; North Korea; Children; Rights; Welfare
AB The purpose of this study is to provide basic data to prepare policies related to 'North Korean children's rights and welfare' by examining the social perception of North Korean children's rights and welfare through keyword network analysis. Based on the Big Data provided by Textom, we collected rawDATA with the keyword 'North Korea + children + rights' and 'North Korea + children + welfare'. The collected data were subjected to a first and second refinement process, and 20 keywords were selected based on the extracted word frequency. A 1-mode matrix was created and a keyword network analysis was conducted. As a result of the research, it was found that 'North Korea', 'child', 'protect', 'support', 'government', 'children', 'youth', 'relation', 'nation', and 'society' were common keywords in the social awareness of North Korean children's rights and welfare. On the other hand, 'human rights', 'South Korea', 'United Nations', 'UN Convention on the Rights of the Child', 'female', 'world', 'convention', 'Japan', and 'discrimination' were important keywords in North Korean children's rights, while 'North Korean defectors', 'symbol', 'disabled', 'song', 'welfare', 'business', 'history', 'mother-child', 'user', and 'object' were important keywords in North Korean children's welfare. In the future research, it is proposed not only to grasp the tendency, but also to prepare various policies related to North Korean children's rights and welfare be prepared.
C1 [Kim, Byung-Man] Kyungnam Univ, Dept Early Childhood Educ, Chang Won, South Korea.
C3 Kyungnam University
RP Kim, BM (corresponding author), Kyungnam Univ, Dept Early Childhood Educ, Chang Won, South Korea.
EM bmkim@kyungnam.ac.kr
FU Kyungnam University Foundation
FX This work was supported by Kyungnam University Foundation Grant, 2019.
CR Borgatti S.B., 2013, Analysing Social Networks
   Byung-Man Kim., 2019, [Journal of Educational Innovation Research, 교육혁신연구], V29, P17, DOI 10.21024/pnuedi.29.2.201906.17
   Heo E, 2009, THESIS KOREA U TECHN
   Hwang H., 2016, CHILDRENS RIGHTS WEL
   Institute for Unification Education, 2017, I UND UN ISS
   Jung Y., 2013, BIG DATA
   Kang Seung-Ji, 2018, [Journal of Children＇s Literature and Education, 어린이문학교육연구], V19, P399, DOI 10.22154/JCLE.19.3.17
   Kim B., 2018, INDIAN J PUBLIC HLTH, V9, P850, DOI [10.5958/0976-5506.2018.01566.8, DOI 10.5958/0976-5506.2018.01566.8]
   Kim B, 2020, KOREAN J EARLY CHILD, V20, P407
   Kim M., 2019, THESIS EWHA WOMANS U
   Kim S, 2016, THESIS CHUNG ANG U, V54, P1
   Kim Sungwon, 2019, [The Journal of Korea Open Association for Early Childhood Education, 열린유아교육연구], V24, P293, DOI 10.20437/KOAECE24-4-13
   Lee, KOREAN J EARLY CHILD, V37, P585
   Lee J., 2016, ED VISION UNIFIED KO
   Lee Yoonjin, 2016, 한국사회복지조사연구, V50, P189, DOI 10.17997/SWRY.50.1.8.
   Lim S., 2003, UNIFIED UNIFICATION
   Lim S., 2011, N KOREAS LEGISLATION
   Lim Sang Soon, 2019, 북한학연구, V15, P39
   Nooraie RY, 2020, J MIX METHOD RES, V14, P110, DOI 10.1177/1558689818804060
   Son D.W., 2002, SOCIAL NETWORK ANAL
   YOOSUK JUNG, 2016, [Review of North Korean Studies, 현대북한연구], V19, P7
   김영규, 2011, [The studies of New Security Challenges, 신안보연구], V170, P127
NR 22
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 42957
EP 42970
DI 10.1007/s11042-021-11894-w
EA FEB 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000751246700011
DA 2024-07-18
ER

PT J
AU Deepa, BG
   Senthil, S
AF Deepa, B. G.
   Senthil, S.
TI Predicting invasive ductal carcinoma tissues in whole slide images of
   breast Cancer by using convolutional neural network model and multiple
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; Invasive ductal carcinoma; Histopathological images;
   Convolutional neural network; Deep learning; Keras sequential algorithm
AB Breast Cancer (BC) is the common type of cancer found in women which is caused due to the abnormal growth of cells in the breast. Over 80% of the BC type detected till date is the invasive ductal carcinoma (IDC). In this work, a deep learning-based IDC prediction model is proposed based on the convolutional neural network (CNN). The developed deep learning method used a sequential Keras model like conv2D, Maxpooling2D, Dropout, Flatten and Dense. The proposed model is compared with multiple classifiers like logistic regression (LR), random forest (RF), k-nearest neighbor (K-NN), support vector machine (SVM), linear SVM, gaussian naive bayesian (GNB) and decision tree (DT). The CNN model is generated by using SkLearn, Keras and Tensor flow libraries, and results are organized by MatPlot libraries. After evaluations, the proposed CNN based IDC framework provided 80%-86% of accuracy, 92%-94% of precision, 91%-96% of recall and 94%-96% of F1-score in prediction over the IDC dataset and 91%-94% of accuracy, 91%-95% of precision, 93%-96% of recall and 95%-98% of F1-score over the BreakHis dataset.
C1 [Deepa, B. G.; Senthil, S.] REVA Univ, Sch Comp Sci & Applicat, Bengaluru, India.
C3 REVA University
RP Deepa, BG (corresponding author), REVA Univ, Sch Comp Sci & Applicat, Bengaluru, India.
EM deepabg03@gmail.com; Senthil_udt@rediffmail.com
RI B G, Deepa/GSN-0214-2022
OI , Dr. S. Senthil/0000-0002-5947-0715
CR Alghodhaifi H, 2019, PROC NAECON IEEE NAT, P374, DOI [10.1109/naecon46414.2019.9057822, 10.1109/NAECON46414.2019.9057822]
   Alzubaidi L, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030445
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Bolhasani Hamidreza, 2020, Informatics in Medicine Unlocked, V19, P276, DOI 10.1016/j.imu.2020.100341
   Cruz-Roa A, 2014, PROC SPIE, V9041, DOI 10.1117/12.2043872
   Dabeer S., 2019, Inform Med Unlocked, V16, P100231, DOI DOI 10.1016/J.IMU.2019.100231
   Gandomkar Ziba, 2016, J Pathol Inform, V7, P43, DOI 10.4103/2153-3539.192814
   Hamed Ghada, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P322, DOI 10.1007/978-3-030-44289-7_30
   Kumar A, 2020, CANCER MANAG RES, V12, P4573, DOI 10.2147/CMAR.S248166
   Lobov SA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00088
   Maurya AP, 2021, INDIAN J SURG, V83, P316, DOI 10.1007/s12262-020-02388-4
   Ray R., 2019, J PHYS C SER, V1372, DOI 10.1088/1742-6596/1372/1/012062
   Romano AM, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD 2019), P142, DOI [10.1109/icaibd.2019.8837044, 10.1109/ICAIBD.2019.8837044]
   Roy S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60740-w
   Shaikh K, 2020, ARTIF INTELL
   Shen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48995-4
   Shi YX, 2021, IEEE T MULTIMEDIA, V23, P4376, DOI 10.1109/TMM.2020.3042068
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Sun YB, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P98, DOI 10.1109/IPAS.2018.8708869
   Tiwari Monika., 2020, Breast cancer prediction using deep learning and machine learning techniques
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Yang SS, 2022, IEEE T NEUR NET LEAR, V33, P4861, DOI 10.1109/TNNLS.2021.3061630
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T CYBERNETICS, V49, P2490, DOI 10.1109/TCYB.2018.2823730
NR 26
TC 5
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8575
EP 8596
DI 10.1007/s11042-022-12114-9
EA FEB 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751676900002
DA 2024-07-18
ER

PT J
AU Nadeem, Z
   Khan, Z
   Mir, U
   Mir, UI
   Khan, S
   Nadeem, H
   Sultan, J
AF Nadeem, Zain
   Khan, Zainullah
   Mir, Usama
   Mir, Umer Iftikhar
   Khan, Shahnawaz
   Nadeem, Hamza
   Sultan, Junaid
TI Pakistani traffic-sign recognition using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pakistani traffic-sign datasets; Machine learning; Deep learning;
   Convolutional neural networks
ID NEURAL-NETWORKS
AB Initially, the traffic-sign recognition was done using the conventional image processing techniques which are sluggish and can cause fatal delays in real-world implementations. Majority of the state-of-the-art detectors are based on a Convolutional Neural Network (CNN) which is a de-facto leader in computer vision research over the past decade. Easy availability of datasets is the main reason for the interest of researchers in CNNs. These datasets are needed to be organized and maintained as the CNN requires colossal amounts of data to work well. Unfortunately, no traffic-sign dataset exists in Pakistan to enable any detection based on the CNN. Therefore, in our work, we have collected and annotated a dataset to help foray into this research area. We propose an approach revolving around the deep learning where a model is pre-trained on the German traffic-sign dataset. This model is then fine-tuned using the Pakistani dataset (of 359 different images) collected across Pakistan. Preprocessing and regularization are used to improve the overall performance of the model. Through results, we show that our fine-tuned model reaches to a training accuracy of nearly 55% outperforming the other related techniques. The results are encouraging as we have achieved a high accuracy keeping in mind the small size of the available Pakistani dataset.
C1 [Nadeem, Zain; Khan, Zainullah; Mir, Umer Iftikhar; Khan, Shahnawaz; Nadeem, Hamza; Sultan, Junaid] Balochistan Univ Informat Technol, Engn & Management Sci, Quetta, Pakistan.
   [Mir, Usama] Univ Windsor, Windsor, ON, Canada.
   [Khan, Shahnawaz] Univ Coll Bahrain, Saar, Bahrain.
C3 Balochistan University of Information Technology, Engineering &
   Management Sciences BUITEMS; University of Windsor
RP Mir, U (corresponding author), Univ Windsor, Windsor, ON, Canada.
EM nadeem.zain@outlook.com; zain.9496@gmail.com; dr.usama.mir@gmail.com;
   umar.i.mir@gmail.com; skhan@ucb.edu.bh; contact.hanizasheikh@gmail.com;
   mjunaidsultan30@gmail.com
RI Nadeem, Zain/GZM-6327-2022; Mir, Usama/HNT-0516-2023
OI Nadeem, Zain/0000-0002-0608-0828; Nadeem, Hamza/0000-0001-6214-2678;
   Mir, Usama/0000-0002-7221-6279
CR Alam A, 2020, INT J INTELL TRANSP, V18, P98, DOI 10.1007/s13177-019-00178-1
   Bayoudh K, 2021, APPL INTELL, V51, P124, DOI 10.1007/s10489-020-01801-5
   Belaroussi R., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P484, DOI 10.1109/ICPR.2010.1125
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P1274, DOI 10.1109/TIP.2003.816010
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jochem T., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P107, DOI 10.1109/IVS.1995.528266
   keras-team/keras, DEEP LEARNING HUMANS
   Khurshid A, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.14459
   Kingma D.P., 2014, ARXIV14126980
   Kiranyaz S, 2019, INT CONF ACOUST SPEE, P8360, DOI 10.1109/ICASSP.2019.8682194
   Larsson F, 2011, LECT NOTES COMPUT SC, V6688, P238, DOI 10.1007/978-3-642-21227-7_23
   Lawler R, RIDING SHOTGUN TESLA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li Y, 2016, IEEE T INTELL VEHICL, V1, P167, DOI 10.1109/TIV.2016.2615523
   Lin C., 2018, Period. Polytech. Transp. Eng, V47, P242, DOI DOI 10.3311/PPTR.11480
   Lodhi A, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P577, DOI 10.1109/ICICT50816.2021.9358594
   Mahmoud MAB, 2019, IEEE ACCESS, V7, P74602, DOI 10.1109/ACCESS.2019.2919125
   Malik R, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3556
   Malik Z, 2014, INT CONF FRONT INFO, P330, DOI 10.1109/FIT.2014.68
   Manikandan R, 2018, IEEE APP IMG PAT
   Mateen M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010001
   Mathias M, 2013, IEEE IJCNN
   Minhas RA, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030483
   Mogelmose A, IEEE T INTELL TRANSP, P1
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Moiseev B, 2013, LECT NOTES COMPUT SC, V8192, P576, DOI 10.1007/978-3-319-02895-8_52
   Nadeem Z, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONIC AND ELECTRICAL ENGINEERING (ICE CUBE)
   Obulesh A, TRAFFIC SIGN CLASSIF
   Pakistan Bureau of Statistics, ANN TRAFF ACC PAK
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Shakhuro VI, 2016, COMPUT OPT, V40, P294, DOI 10.18287/2412-6179-2016-40-2-294-300
   Shustanov A, 2017, PROCEDIA ENGINEER, V201, P718, DOI 10.1016/j.proeng.2017.09.594
   Singh NS., 2020, LECT NOTES ELECT ENG, P375, DOI [10.1007/978-981-15-0372-6_30, DOI 10.1007/978-981-15-0372-6_30]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Stallkamp J, GERMAN DATASET
   Stallkamp J, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1453, DOI 10.1109/IJCNN.2011.6033395
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Valiente R, 2019, IEEE INT VEH SYM, P2423, DOI [10.1109/IVS.2019.8814260, 10.1109/ivs.2019.8814260]
   Vidushi, 2021, Data Analytics and Management. Proceedings of ICDAM. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 54), P23, DOI 10.1007/978-981-15-8335-3_3
   Wali SB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/250461
   WHO, ROAD TRAFF ACC PAK
   Wigness M., RUGD DATASET AUTONOM
   Xia ZM, 2020, I S BIOMED IMAGING, P416, DOI 10.1109/isbi45749.2020.9098621
   Zhao JD, 2018, INT J INTELL UNMANNE, V6, P2, DOI 10.1108/IJIUS-08-2017-0008
NR 47
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8429
EP 8449
DI 10.1007/s11042-022-12177-8
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800014
DA 2024-07-18
ER

PT J
AU Paul, S
   Nasser, H
   Mollah, AF
   Bhattacharyya, A
   Ngo, P
   Nasipuri, M
   Debled-Rennesson, I
   Basu, S
AF Paul, Soumi
   Nasser, Hayat
   Mollah, Ayatullah Faruk
   Bhattacharyya, Arpan
   Ngo, Phuc
   Nasipuri, Mita
   Debled-Rennesson, Isabelle
   Basu, Subhadip
TI Development of benchmark datasets of multioriented hand gestures for
   speech and hearing disabled
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Benchmark datasets; Discrete curve; Hand gesture recognition; Microsoft
   kinect sensor; Polygonal simplification; Sign language; Statistical
   geometrical features
ID RECOGNITION; MOTION; DECOMPOSITION; TRAJECTORIES; PARTS; GAME
AB Reliable hand gesture recognition is extremely relevant for automatic interpretation of sign languages used by people with hearing and speech disabilities. In this work, we present (i) new benchmark datasets of depth-sensor based, multi-oriented, isolated and static hand gestures of numerals and alphabets following the conventions of American Sign Language (ASL), (ii) an effective strategy for segmentation of hand region from depth data and appropriate preprocessing for feature extraction, and (iii) an effective statistical-geometrical feature set for recognition of multi-oriented hand gestures. Besides setting benchmark performances on the developed datasets, viz. 97.67%, 96.53% and 96.86% on numerals, alphabets and alpha-numerals respectively, the proposed pipeline is also implemented on two related public datasets and is found superior to state-of-the-art methods reported so far.
C1 [Paul, Soumi; Bhattacharyya, Arpan; Nasipuri, Mita; Basu, Subhadip] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Nasser, Hayat; Ngo, Phuc; Debled-Rennesson, Isabelle] Univ Lorraine, LORIA, UMR 7503, F-54506 Vandoeuvre Les Nancy, France.
   [Nasser, Hayat; Ngo, Phuc; Debled-Rennesson, Isabelle] CNRS, LORIA, UMR 7503, F-54506 Vandoeuvre Les Nancy, France.
   [Mollah, Ayatullah Faruk] Aliah Univ, Dept Comp Sci & Engn, Kolkata 700160, India.
C3 Jadavpur University; Universite de Lorraine; Universite de Lorraine;
   Centre National de la Recherche Scientifique (CNRS); Aliah University
RP Paul, S (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
EM spaul.cse.rs@jadavpuruniversity.in; hayat.nasser@loria.fr;
   afmollah@aliah.ac.in; 2013arpan@gmail.com; hoai-diem-phuc.ngo@loria.fr;
   mita.nasipuri@jadavpuruniversity.in; Isabelle.Debled-Rennesson@loria.fr;
   subhadip.basu@jadavpuruniversity.in
RI Bhattacharyya, Arpan/I-9603-2019
OI Bhattacharyya, Arpan/0000-0002-7933-6441; Mollah, Ayatullah
   Faruk/0000-0002-3445-7469
FU Govt. of India of the Department of Science and Technology (DST) within
   the Ministry of Science and Technology [SR/WOS-A/ET-1001/2015,
   EMR/2016/007213]; Department of Biotechnology
   [BT/PR16356/BID/7/596/2016]; Rashtriya Uchchatar Shiksha Abhiyan (RUSA)
   from the Department of Higher Education, Govt. of India
FX This work is partially supported by three grants from the Govt. of
   India, namely, grant no. SR/WOS-A/ET-1001/2015, grant no.
   EMR/2016/007213 of the Department of Science and Technology (DST) within
   the Ministry of Science and Technology, and grant no.
   BT/PR16356/BID/7/596/2016 of the Department of Biotechnology and
   Rashtriya Uchchatar Shiksha Abhiyan (RUSA) from the Department of Higher
   Education, Govt. of India.
CR Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Debled-Rennesson I, 2006, COMPUT GRAPH-UK, V30, P30, DOI 10.1016/j.cag.2005.10.007
   Dewaele G, 2004, LECT NOTES COMPUT SC, V3021, P495
   Dinh DL, 2016, MULTIMED TOOLS APPL, V75, P1333, DOI 10.1007/s11042-014-2370-y
   Geetha M, 2013, 2013 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN COMMUNICATION, CONTROL, SIGNAL PROCESSING AND COMPUTING APPLICATIONS (IEEE-C2SPCA-2013)
   Jadooki S, 2017, NEURAL COMPUT APPL, V28, P3285, DOI 10.1007/s00521-016-2244-5
   Kapuscinski T, 2013, SIG P ALGO ARCH ARR, P291
   Kerautret Bertrand, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P372
   Kerautret B, 2014, IMAGE PROCESS ON LIN, V4, P98, DOI 10.5201/ipol.2014.75
   Kry PG, 2006, ACM T GRAPHIC, V25, P872, DOI 10.1145/1141911.1141969
   Lachaud J, 2010, APPL DISCR GEOM MATH, P14, DOI DOI 10.1007/978-3-642-32313-3_2
   Le Q.K., 2012, IEIE Trans. Smart Process. Comput., V1, P1
   Liang H, 2014, IEEE T MULTIMEDIA, V16, P1241, DOI 10.1109/TMM.2014.2306177
   Lv ZH, 2017, PERVASIVE MOB COMPUT, V41, P504, DOI 10.1016/j.pmcj.2017.04.006
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P436, DOI 10.1109/ICCVW.2013.64
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Nasser H, 2018, J COMPUT SYST SCI, V95, P177, DOI 10.1016/j.jcss.2017.07.007
   Ngo P, 2016, LNCS, V9647, pp439
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Paul S., 2019, EMERGING TECHNOLOGY, P775, DOI [10.1007/978-981-13-7403-6_68, DOI 10.1007/978-981-13-7403-6_68]
   Paul S, 2017, LECT NOTES COMPUT SC, V10256, P256, DOI 10.1007/978-3-319-59108-7_20
   Paul Soumi., 2015, INT SCI PRESS IJCTA, V8, P2071
   Ngo P, 2017, J MATH IMAGING VIS, V59, P123, DOI 10.1007/s10851-017-0723-7
   Phuc Ngo, 2015, Combinatorial Image Analysis. 17th International Workshop, IWCIA 2015. Proceedings, P143, DOI 10.1007/978-3-319-26145-4_11
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Qin SX, 2014, J SIGNAL PROCESS SYS, V74, P47, DOI 10.1007/s11265-013-0778-7
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   REVEILLES JP, 1991, THESIS U L PASTEUR S
   She YY, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1096, DOI 10.1109/CSE.2014.216
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wu Y, 2005, IEEE T PATTERN ANAL, V27, P1910, DOI 10.1109/TPAMI.2005.233
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Zhang C., 2013, IEEE International Conference on Automatic Face and Gesture Recognition, P1
NR 39
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7285
EP 7321
DI 10.1007/s11042-021-11745-8
EA JAN 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000748678300004
DA 2024-07-18
ER

PT J
AU Munir, S
   Malick, RAS
   Jami, SI
   Ahmed, G
   Khan, S
   Rodrigues, JJPC
AF Munir, Siraj
   Malick, Rauf Ahmed Shams
   Jami, Syed Imran
   Ahmed, Ghufran
   Khan, Suleman
   Rodrigues, Joel J. P. C.
TI An integrated approach: using knowledge graph and network analysis for
   harnessing digital advertisement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge graph; Network analysis; Community detection; Semantics
ID SOCIAL NETWORK; CENTRALITY; TIME
AB Complex network analysis helps in finding hidden patterns within a graph network. This concept is extended for knowledge graphs to identify hidden concepts using state-of-the-art network analysis techniques. In this paper, a profiling knowledge graph is analyzed to identify hidden concepts which result in the identification of implicit communities within a campus network. The proposed work is verified with the interesting results achieved by applying different metrics using a state-of-the-art network analysis algorithm. The results of the proposed work are mapped in the domain of digital advertisement to answer intelligent semantic queries. Various factors of centrality measures identify the prospective influencers within a campus network. Moreover, bridge analysis determines amplifier nodes in the knowledge graph that will help in the digital advertisement. The proposed work concludes with a discussion on link prediction. It shows the future interactions to design digital advertising campaigns through billboards.
C1 [Munir, Siraj; Jami, Syed Imran] Mohammad Ali Jinnah Univ, Dept Comp Sci, Karachi, Pakistan.
   [Malick, Rauf Ahmed Shams; Ahmed, Ghufran] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Karachi, Pakistan.
   [Khan, Suleman] Northumbria Univ, Dept Comp & Informat Sci, Newcastle Upon Tyne, Tyne & Wear, England.
   [Rodrigues, Joel J. P. C.] Fed Univ Piaui UFPI, Teresina, Brazil.
   [Rodrigues, Joel J. P. C.] Inst Telecommunicocoes, Aveiro, Portugal.
C3 Mohammad Ali Jinnah University; Northumbria University; Universidade
   Federal do Piaui
RP Munir, S (corresponding author), Mohammad Ali Jinnah Univ, Dept Comp Sci, Karachi, Pakistan.
EM sirajmunir93@gmail.com; rauf.malick@nu.edu.pk; imran.jami@jinnah.edu;
   ghufran.ahmed@nu.edu.pk; suleman.khan@northumbria.ac.uk; joeljr@ieee.org
RI Rodrigues, Joel J. P. C./A-8103-2013
OI Rodrigues, Joel J. P. C./0000-0001-8657-3800; Munir,
   Siraj/0000-0003-0423-7585
CR Abebe R, 2018, MITIGATING OVEREXPOS
   Ahmed AA, 2021, ENG REP, V3, DOI 10.1002/eng2.12416
   Alamsyah A, 2021, ARXIVABS210208888
   Benítez-Andrades JA, 2020, INFORM SCIENCES, V540, P390, DOI 10.1016/j.ins.2020.06.008
   Bashbaghi S, 2019, DEEP LEARNING OBJECT, P133, DOI DOI 10.1007/978-981-10-5152-4_6
   Bauer C., 2016, Manag Rev Quart, V66, P159, DOI DOI 10.1007/S11301-015-0118-Z
   Bhatt S, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P51, DOI 10.1145/3289600.3291031
   Bollacker K, 2019, STUD SYST DECIS CONT, V176, P203, DOI 10.1007/978-3-030-00317-3_9
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   Brandes U, 2008, SOC NETWORKS, V30, P136, DOI 10.1016/j.socnet.2007.11.001
   Buccafurri F, 2013, INFORM SCIENCES, V224, P1, DOI 10.1016/j.ins.2012.10.021
   Chartier JF, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.10.005
   Demar Urka., 2008, Transactions in GIS, V12, P61, DOI 10.1111/j.1467-9671.2008.01086.x
   García-Sánchez F, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102153
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Golbeck J., 2013, Analyzing the Social Web, DOI [10.1016/C2012-0-00171-8, DOI 10.1016/C2012-0-00171-8]
   Güney E, 2019, INFORM SCIENCES, V503, P589, DOI 10.1016/j.ins.2019.07.043
   Hussain N, 2020, INT J SOFTW ENG KNOW, V30, P859, DOI 10.1142/S0218194020400100
   Karczmarczyk A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209372
   Karidi DP, 2018, J AMB INTEL HUM COMP, V9, P2035, DOI 10.1007/s12652-017-0491-7
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lou KH, 2021, IEEE T INTELL TRANSP, V22, P4635, DOI 10.1109/TITS.2020.2991029
   Milovanovic S, 2019, FUTURE GENER COMP SY, V93, P121, DOI 10.1016/j.future.2018.10.028
   More JS, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-018-0548-4
   Munir S, 2021, OPEN COMPUT SCI, V11, P294, DOI 10.1515/comp-2020-0209
   Munir S, 2019, INT J COMPUT SCI NET, V19, P193
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218
   Vahdati S, 2018, UNVEILING SCHOLARLY
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wakil K, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020060
   Wang CB, 2018, COMPUT GEOSCI-UK, V112, P112, DOI 10.1016/j.cageo.2017.12.007
   Wolfe AW, 1997, AM ETHNOL, V24, P219, DOI 10.1525/ae.1997.24.1.219
   Zhang L, 2020, ELECTRON COMMER RES, V20, P3, DOI 10.1007/s10660-018-9316-9
   Zhong C, 2014, INT J GEOGR INF SCI, V28, P2178, DOI 10.1080/13658816.2014.914521
NR 36
TC 3
Z9 3
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8883
EP 8898
DI 10.1007/s11042-021-11856-2
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000745555600002
DA 2024-07-18
ER

PT J
AU Yassin, FM
   Ouarda, W
   Alimi, AM
AF Yassin, Fatima Mohamed
   Ouarda, Wael
   Alimi, Adel M.
TI Fuzzy ontology as a basis for recommendation Systems for Traveler's
   preference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social images; CNN architectures; User interest; Fuzzy ontology;
   Recommendation system
ID PHOTOS
AB As an increasingly larger number of users partake in Facebook, the images shared and posted by user in Facebook provide a richer background to build a more accurate recommendation system. In this paper, we propose an Intelligent Recommendation System for Travelers' Preferences (IRSTP) based on the conceptualization of the travel user's destination based on their activities of sharing visual data and locations through social network. In this system, we performed a Deep Neural Network Architecture transferred on Places356 database to extract important concepts found in the shared visual images. Then, we carried out an inference system based on crisp (DOVUIS) and fuzzy ontology (DFOVUIS) to take into account some ambiguity in Decision making. Both proposed ontologies are tested and evaluated on collected Sudanese Database. The User interest architecture based on Convolutional Neural Network is used for tuning search in the IRSTP recommendation system. The Fuzzy ontology performs well than the crisp inference system in order to personalize the recommendation based on the profile outputted from this ontology. We achieve an accuracy of 94.22\% on the Sudanese database to classify the topic of user interest among 9 classes Food (98.7%), Nature (98.9%), History (80.4%), DIY and Craft (98.0%), Celebrities (87.3%), Architectures (98.6%), Events (95.4%), Holydays (93.9%) and Art (87.0%). These topics are considered from the Facebook generic topics.
C1 [Yassin, Fatima Mohamed] Sudan Univ Sci & Technol, Coll Postgrad Studies, Khartoum, Sudan.
   [Yassin, Fatima Mohamed; Ouarda, Wael; Alimi, Adel M.] Ctr Rech Numer Sfax CRNS, Sfax, Tunisia.
   [Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; University of Johannesburg
RP Yassin, FM (corresponding author), Sudan Univ Sci & Technol, Coll Postgrad Studies, Khartoum, Sudan.; Yassin, FM (corresponding author), Ctr Rech Numer Sfax CRNS, Sfax, Tunisia.
EM fatima.m.yassin@gmail.com; wael.ouarda@ieee.org; adel.alimi@ieee.org
RI Ouarda, Wael/GQP-6480-2022
OI Ouarda, Wael/0000-0002-6338-7092
FU Research Groups in Intelligent Machines (ReGIM-Lab)
FX This research was supported by Research Groups in Intelligent Machines
   (ReGIM-Lab). We thank Wael Ouarda, a Professor-Researcher in Computer
   Science at the University of Sfax and quality manager at the ReGIM-Lab
   at the University of Sfax for comments that greatly improved the
   manuscript and we thank Adel M. Alimi professor in Electrical and
   Computer Engineering at the University of Sfax for assistance with
   application of intelligent methods (neural networks, fuzzy logic) to
   pattern recognition.
CR Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8
   [Anonymous], 2016, INT C HYBRID INTELLI
   [Anonymous], 2016, INT C INTELLIGENT SY
   [Anonymous], 2012, 2012 IEEE COMPUTER S
   Benkaddour FZ, 2018, INT J INTERACT MULTI, V5, P118, DOI 10.9781/ijimai.2018.06.003
   Cao LL, 2010, INT CONF ACOUST SPEE, P2274, DOI 10.1109/ICASSP.2010.5495905
   Choi C, 2009, 2009 THIRD ASIA INTERNATIONAL CONFERENCE ON MODELLING & SIMULATION, VOLS 1 AND 2, P637, DOI 10.1109/AMS.2009.75
   Feng H, 2014, NEUROCOMPUTING, V129, P409, DOI 10.1016/j.neucom.2013.09.018
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   GUARINO N, 1995, TOWARDS VERY LARGE KNOWLEDGE BASES, P25
   Gunjan, 2020, LECT NOTES ELECT ENG, V601
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hiroki I., 2018, PATHOPHYSIOLOGY, V25, P207, DOI [10.1016/j.pathophys.2018.07.106, DOI 10.1016/J.PATHOPHYS.2018.07.106]
   Hong L., 2013, P 6 ACM INT C WEB SE, P557, DOI DOI 10.1145/2433396.2433467
   Jannach D, 2010, TOURISM INFORM VISUA, P38
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kesorn K, 2017, IEEE ACCESS, V5, P26703, DOI 10.1109/ACCESS.2017.2778293
   Kim J.Y., 2012, P WSDM, P213, DOI DOI 10.1145/2124295.2124323
   Kim P., 2006, 2006 8 INT C ADV COM, V1, P624
   Lazzez, 2018, DEEP VISINTERESTS CN
   Li Q., 2008, P 16 ACM SIGSPATIAL, P1, DOI DOI 10.1145/1463434.1463477
   Li Ruiyu, 2017, IEEE INT C COMP VIS
   Logesh R., 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P535, DOI 10.1007/978-981-13-0617-4_52
   Lovato P, 2013, IEEE IMAGE PROC, P2892, DOI 10.1109/ICIP.2013.6738595
   Memon I, 2015, WIRELESS PERS COMMUN, V80, P1347, DOI 10.1007/s11277-014-2082-7
   Middleton SE, 2004, ACM T INFORM SYST, V22, P54, DOI 10.1145/963770.963773
   Noguera JM, 2012, INFORM SCIENCES, V215, P37, DOI 10.1016/j.ins.2012.05.010
   Odobez J.., 2015, LECT NOTES COMPUT SC, V3940, P115, DOI [10.1007/11752790_7, DOI 10.1007/11752790_7]
   Ombabi AH, 2017, PROCEEDINGS OF 2017 SUDAN CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY (SCCSIT), P36
   Qian X., 2013, PAC RIM C MULT, P730
   Qiu F., 2006, Proceedings of the 15th International Conference on World Wide Web, P727, DOI DOI 10.1145/1135777.1135883
   Ravi L, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/1291358
   Sarwat M, 2014, IEEE T KNOWL DATA EN, V26, P1384, DOI 10.1109/TKDE.2013.29
   Simo-Serra E, 2015, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2015.7298688
   Subramaniyaswamy V, 2015, PROCEDIA COMPUT SCI, V50, P447, DOI 10.1016/j.procs.2015.04.014
   Tingting Wang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P85, DOI 10.1007/978-3-642-37456-2_8
   Valencia-Garcia R, 2011, P 3 INT C COMP MOD S, P104
   Wang H., 2013, P 21 ACM SIGSPATIAL, P364
   Wang KL, 2018, IEEE WINT CONF APPL, P2058, DOI 10.1109/WACV.2018.00227
   Wang XH, 2009, PROCEEDINGS OF THE THIRD INTERNATIONAL WORKSHOP ON MATRIX ANALYSIS AND APPLICATIONS, VOL 3, P1
   Wen Z., 2010, P 16 ACM SIGKDD INT, P373
   White RW, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P363, DOI 10.1145/1571941.1572005
   Xing, 2015, 29 AAAI C ART INT
   YANG L, 2015, CORRABS151206785
   Yang SQ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC), P204, DOI 10.1109/SCC.2017.33
   Yassin FM, 2017, PROCEEDINGS OF 2017 SUDAN CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY (SCCSIT), P58
   Yassine A, 2021, SIMUL MODEL PRACT TH, V107, DOI 10.1016/j.simpat.2020.102198
   YOU Q, 2015, CORRABS150404558
   Yue Y., 2018, IEEE C COMP VIS PATT
   Zhou J., 2016, Proceedings of the 22nd international conference on multimedia modeling, Miami, FL, USA, P361, DOI DOI 10.1007/978
NR 50
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6599
EP 6631
DI 10.1007/s11042-021-11780-5
EA JAN 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000742803700001
DA 2024-07-18
ER

PT J
AU Acharjya, DP
   Ahmed, PK
AF Acharjya, D. P.
   Ahmed, P. Kauser
TI A hybridized rough set and bat-inspired algorithm for knowledge
   inferencing in the diagnosis of chronic liver disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rough set; Reduct; Feature selection; Equivalence; Data reduction; Lower
   approximation; Bat algorithm; Healthcare applications
ID FEATURE-SELECTION; APPROXIMATION; PREDICTION
AB Healthcare informatics data is proliferating, and analyzing this data is a challenging issue as it requires multiple levels of extraction of knowledge for decision making. Knowledge discovery of databases is a solution to this end. Nevertheless, healthcare data contains uncertainties, and so there is a need for computational intelligence techniques to process such uncertainties while considering feature selection, classification, clustering, and decision rule generation. The rough set is a relatively new technique towards decision rule generation without considering any additional information. On the other hand, bio-inspired computing techniques are widely used for optimization and feature selection. Primarily, bio-inspired computing uses a minimum number of features to classify a system. Therefore, the integration of rough set and bio-inspired computing leads to optimal rule generation. Keeping it in mind, in this paper, we integrate a rough set and bat algorithm to foster knowledge. At the initial phase, the bat algorithm is employed to identify the chief features that affect the decisions. Further, decision rules are generated using these selected features. It, in turn, helps to diagnose a disease at an early stage. The objective is not to replace a physician but to give an alternative opinion to the physician. It is believed that the proposed system can be used as a tool for the prevention and detection of malignancy of various communicable and non-communicable diseases. Simultaneously, it paves the way for efficient healthcare informatics. A case study on chronic liver disease is considered for analyzing the proposed model. Further, the obtained results are compared with hybridized decision tree algorithms and found significantly better.
C1 [Acharjya, D. P.; Ahmed, P. Kauser] VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Acharjya, DP (corresponding author), VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM dpacharjya@gmail.com; kauserahmed@vit.ac.in
RI Acharjya, Debi/T-1205-2018
OI Acharjya, Debi/0000-0003-3828-2050; Ahmed, Kauser/0000-0001-6031-0826
CR Acharjya DP, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103924
   Anitha A, 2018, NEURAL COMPUT APPL, V30, P3633, DOI 10.1007/s00521-017-2948-1
   Bangyal WH, 2019, J MED IMAG HEALTH IN, V9, P670, DOI 10.1166/jmihi.2019.2654
   Binu D, 2015, J MED IMAG HEALTH IN, V5, P599, DOI 10.1166/jmihi.2015.1428
   Chawla M, 2015, APPL ARTIF INTELL, V29, P617, DOI 10.1080/08839514.2015.1038434
   Chen YS, 2013, KNOWL INF SYST, V34, P453, DOI 10.1007/s10115-012-0490-0
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Gandomi AH, 2013, NEURAL COMPUT APPL, V22, P1239, DOI 10.1007/s00521-012-1028-9
   Gergin Z., 2019, INT J OPERATIONS RES, V10, P56, DOI DOI 10.4018/IJORIS.2019010104
   Kar AK, 2016, EXPERT SYST APPL, V59, P20, DOI 10.1016/j.eswa.2016.04.018
   Liu GL, 2010, KNOWL-BASED SYST, V23, P110, DOI 10.1016/j.knosys.2009.06.011
   Mirjalili S, 2014, NEURAL COMPUT APPL, V25, P663, DOI 10.1007/s00521-013-1525-5
   Ning Zhong, 2001, International Journal of Applied Mathematics and Computer Science, V11, P603
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Perwaiz U, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234625
   Qasim OS, 2020, INT J MATH ENG MANAG, V5, P697, DOI 10.33889/IJMEMS.2020.5.4.056
   Qian YH, 2008, COMPUT MATH APPL, V55, P1754, DOI 10.1016/j.camwa.2007.08.031
   Rathi R, 2018, ARAB J SCI ENG, V43, P4215, DOI 10.1007/s13369-017-2838-y
   Rodrigues D, 2014, EXPERT SYST APPL, V41, P2250, DOI 10.1016/j.eswa.2013.09.023
   Sagban R., 2020, Int. J. Electr. Comput. Eng., V10, P6655
   Saji Y, 2016, NEURAL COMPUT APPL, V27, P1853, DOI 10.1007/s00521-015-1978-9
   Sikder IU, 2009, EXPERT SYST APPL, V36, P102, DOI 10.1016/j.eswa.2007.09.032
   Sun BZ, 2014, ARTIF INTELL REV, V41, P67, DOI 10.1007/s10462-011-9298-7
   Sun CM, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P1722
   Taha AM, 2013, SCI WORLD J, DOI 10.1155/2013/325973
   Yang XB, 2008, INFORM SCIENCES, V178, P1219, DOI 10.1016/j.ins.2007.09.019
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2011, INT J BIO-INSPIR COM, V3, P267, DOI 10.1504/IJBIC.2011.042259
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yao YY, 2010, INFORM SCIENCES, V180, P341, DOI 10.1016/j.ins.2009.09.021
   Zhu W, 2012, INFORM SCIENCES, V201, P80, DOI 10.1016/j.ins.2012.01.026
   ZIMMERMAN DW, 1993, J EXP EDUC, V62, P75, DOI 10.1080/00220973.1993.9943832
NR 33
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13489
EP 13512
DI 10.1007/s11042-021-11495-7
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000742319000013
DA 2024-07-18
ER

PT J
AU Abeywardhana, DL
   Dangalle, CD
   Nugaliyadde, A
   Mallawarachchi, Y
AF Abeywardhana, D. L.
   Dangalle, C. D.
   Nugaliyadde, Anupiya
   Mallawarachchi, Yashas
TI An ultra-specific image dataset for automated insect identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Automated insect identification; Limited data; Tiger beetles;
   Inter-class similarity
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; RECOGNITION
AB Automated identification of insects is a tough task where many challenges like data limitation, imbalanced data count, and background noise needs to be overcome for better performance. This paper describes such an image dataset which consists of a limited, imbalanced number of images regarding six genera of subfamily Cicindelinae (tiger beetles) of order Coleoptera. The diversity of image collection is at a high level as the images were taken from different sources, angles and on different scales. Thus, the salient regions of the images have a large variation. Therefore, one of the main intentions in this process was to get an idea about the image dataset while comparing different unique patterns and features in images. The dataset was evaluated on different classification algorithms including deep learning models based on different approaches to provide a benchmark. The dynamic nature of the dataset poses a challenge to the image classification algorithms. However transfer learning models using softmax classifier performed well on the current dataset. The tiger beetle classification can be challenging even to a trained human eye, therefore, this dataset opens a new avenue for the classification algorithms to develop, to identify features which human eyes have not identified.
C1 [Abeywardhana, D. L.; Dangalle, C. D.] Univ Colombo, Colombo, Sri Lanka.
   [Nugaliyadde, Anupiya] Murdoch Univ, Perth, WA, Australia.
   [Mallawarachchi, Yashas] Sri Lanka Inst Informat Technol, Malabe, Sri Lanka.
C3 University of Colombo; Murdoch University; Sri Lanka Institute of
   Information Technology (SLIIT)
RP Abeywardhana, DL (corresponding author), Univ Colombo, Colombo, Sri Lanka.
EM lakminiab@stu.cmb.ac.lk
OI Abeywardhana, Lakmini/0000-0001-8971-9406
FU National Science Foundation of Sri Lanka [RG/2017/EB/01]
FX This work was funded by the National Science Foundation of Sri Lanka
   [Grant Number RG/2017/EB/01]. We would also like to acknowledge Dr.
   Agasthya Thotagamuwa, Charles Sturt University, Australia for providing
   tiger beetle images for the study.
CR Abeywardhana D.L., 2019, P ANN RES S U COLOMB, P78
   Abualigah L, 2021, ARCH COMPUT METHOD E, V28, P1397, DOI 10.1007/s11831-020-09420-6
   ACCIAVATTI R E, 1989, Annals of Carnegie Museum, V58, P77
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   ALVAREZ AJ, 1993, WATER SCI TECHNOL, V27, P253, DOI 10.2166/wst.1993.0354
   Bloice M.D., 2017, ARXIV170804680, V2, P1, DOI DOI 10.21105/JOSS.00432
   Bouvrie J., 2006, Procedia Technology, P47, DOI DOI 10.1016/J.PROTCY.2014.09.007
   Caramazza P, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30390-0
   Cheng BW, 2018, LECT NOTES COMPUT SC, V11219, P473, DOI 10.1007/978-3-030-01267-0_28
   Dangalle CD., 2017, J BIOL NATURE, V7, P91
   Dangalle CD, 2018, J NATL SCI FOUND SRI, V46, P241, DOI 10.4038/jnsfsr.v46i3.8477
   Deng J, 2010, IMAGENET LARGE SCALE
   Englert B, 2011, CALTECH UCSD BIRDS 2, DOI [10.3182/20090902-3-US-2007.0059, DOI 10.3182/20090902-3-US-2007.0059]
   Evgeniou T., 2001, Machine learning and its applications. Advanced lectures, P249
   Fowler WW, 1912, COLEOPTERA GEN INTRO
   Gebejes A., 2013, Databases, V9, P375
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Google Colab, 2020, GETT START INTR
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Gutierrez A, 2019, J SENSORS, V2019, DOI 10.1155/2019/5219471
   Hamsher SE, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073521
   Hansen OLP, 2020, ECOL EVOL, V10, P737, DOI 10.1002/ece3.5921
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huh Minyoung, 2016, ABS160808614 CORR
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Ismail A., 2019, Malaysian Journal of Computing, V4, P225, DOI 10.24191/mjoc.v4i1.6095
   Jangblad M, 2018, OBJECT DETECTION INF
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Khosla A., 2011, P IEEE C COMP VIS PA, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larios N, 2008, MACH VISION APPL, V19, P105, DOI 10.1007/s00138-007-0086-y
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lokanath M., 2017, IOP Conference Series: Materials Science and Engineering, V263, DOI 10.1088/1757-899X/263/5/052028
   MacLeod N., 2007, AUTOMATED TAXON IDEN
   Mao W., 2012, New advances in intelligence and security informatics
   Marques ACR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192011
   Mora C, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1001127
   Naviaux R., 1991, PUBLICATIONS SOCI T, V60, P209, DOI [10.3406/linly.1991.10944, DOI 10.3406/LINLY.1991.10944]
   Olivas E. S., 2009, HDB RES MACHINE LEAR
   Pang HW, 2019, LECT NOTES COMPUT SC, V11901, P689, DOI 10.1007/978-3-030-34120-6_56
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   PEARSON DL, 1988, ANNU REV ENTOMOL, V33, P123, DOI 10.1146/annurev.en.33.010188.001011
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Shu M., 2019, Creative Components, P14
   Sun J, 2016, IEEE ICCSS 2016 - 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATIVE AND CYBERNETICS FOR COMPUTATIONAL SOCIAL SYSTEMS (ICCSS), P363, DOI 10.1109/ICCSS.2016.7586482
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P1, DOI 10.1007/978-1-4899-7641-3
   Takefuji Y, EFFECTIVENESS ENSEMB
   Thotagamuwa A, 2018, THESIS U COLOMBO SRI
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Veronese E, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/867924
   Wang J, 2018, ENVIRON TECHNOL, V39, P3055, DOI 10.1080/09593330.2017.1371797
   Wang MW, 2019, IEEE ACCESS, V7, P61697, DOI 10.1109/ACCESS.2019.2915553
   Wu XP, 2019, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2019.00899
   Yuan ZW, 2016, PROC SPIE, V10033, DOI 10.1117/12.2243849
   Zhu LQ, 2017, ORIENT INSECTS, V51, P79, DOI 10.1080/00305316.2016.1252805
NR 58
TC 5
Z9 5
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JAN 2
PY 2022
DI 10.1007/s11042-021-11450-6
EA JAN 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XY6SK
UT WOS:000737099300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Varshney, N
   Bakariya, B
   Kushwaha, AKS
   Khare, M
AF Varshney, Neeraj
   Bakariya, Brijesh
   Kushwaha, Alok Kumar Singh
   Khare, Manish
TI Human activity recognition by combining external features with
   accelerometer sensor data using deep learning network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Wearable device Sensor; Human activity
   recognition; Deep learning; Time-series data
AB Various Human Activities are classified through time-series data generated by the sensors of wearable devices. Many real-time scenarios such as Healthcare Surveillance, Smart Cities and Intelligent surveillance etc. are based upon Human Activity Recognition. Despite the popularity of local features-based approaches and machine learning approaches, it fails to capture adequate temporal information. In this paper, the deep convolutional neural model has been proposed by combining external features, i.e. orientation invariant (parallel to v parallel to) and consecutive point trajectory information (parallel to Delta v parallel to) with tri-axis data of the accelerometer. The proposed external features based approach experimented on three different deep learning architecture, namely Long-Short Term Memory (LSTM), Convolutional Neural Networks (CNN) and Convolution Long-Short Term Memory (ConvLSTM). Accuracy of the algorithms radically improve with the additional input feature parallel to v parallel to and parallel to Delta v parallel to along with triaxis data of accelerometer. The results show that the performance of all three LSTM, CNN and ConvLSTM models is better to compare with the state of art methods on WISDOM dataset and Activity dataset also the performance of ConvLSTM is 98.41% for WISDOM dataset and 98.04 for activity dataset, which is higher than that of CNN and LSTM model used in this paper.
C1 [Varshney, Neeraj] IK Gujral Punjab Tech Univ, Kapurthala, Ibban, India.
   [Bakariya, Brijesh] IK Gujral Punjab Tech Univ, Hoshiarpur Campus, Hoshiarpur, India.
   [Kushwaha, Alok Kumar Singh] Guru Ghasidas Vishwavidyalaya, Bilaspur, India.
   [Khare, Manish] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, India.
C3 I. K. Gujral Punjab Technical University; I. K. Gujral Punjab Technical
   University; Guru Ghasidas Vishwavidyalaya; Dhirubhai Ambani Institute of
   Information & Communication Technology
RP Varshney, N (corresponding author), IK Gujral Punjab Tech Univ, Kapurthala, Ibban, India.
EM neeraj.varshney@gla.ac.in; dr.brijeshbakariya@ptu.ac.in;
   alokkumarsingh.jk@gmail.com; mkharejk@gmail.com
RI Khare, Manish/AAF-4582-2019; VARSHNEY, NEERAJ/AAD-9051-2019
OI Khare, Manish/0000-0002-2296-2732; KUSHWAHA, ALOK KUMAR
   SINGH/0000-0003-2928-998X
CR Al Hafiz Khan Md Abdullah, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P545, DOI 10.1109/PERCOMW.2017.7917621
   Anjum A, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P914, DOI 10.1109/CCNC.2013.6488584
   Cao L, 2018, J PARALLEL DISTR COM, V118, P67, DOI 10.1016/j.jpdc.2017.05.007
   Chen YQ, 2015, IEEE SYS MAN CYBERN, P1488, DOI 10.1109/SMC.2015.263
   Chen YW, 2016, ADV INTEL SYS RES, V127
   Cowen, 2018, SCI BUDDIES SCI 0709
   Figo D, 2010, PERS UBIQUIT COMPUT, V14, P645, DOI 10.1007/s00779-010-0293-9
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Klasnja P, 2012, J BIOMED INFORM, V45, P184, DOI 10.1016/j.jbi.2011.08.017
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Kwon MC, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/2618045
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Lu JC, 2020, IEEE INTERNET THINGS, V7, P11137, DOI 10.1109/JIOT.2020.2995940
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Pang J., 2018, Human activity recognition based on transfer learning
   Peppas K, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238482
   Pienaar SW, 2019, 2019 IEEE 2ND WIRELESS AFRICA CONFERENCE (WAC), P80, DOI [10.1109/africa.2019.8843403, 10.1109/africa.2019.8843417]
   Qin Z, 2020, INFORM FUSION, V53, P80, DOI 10.1016/j.inffus.2019.06.014
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Ronao CA, 2015, LECT NOTES COMPUT SC, V9492, P46, DOI 10.1007/978-3-319-26561-2_6
   Shakya Sarbagya Ratna, 2018, International Journal of Machine Learning and Computing, V8, P577, DOI 10.18178/ijmlc.2018.8.6.748
   Shi XJ, 2015, ADV NEUR IN, V28
   Shoaib M, 2014, SENSORS-BASEL, V14, P10146, DOI 10.3390/s140610146
   Singh, 2020, ARXIV PREPRINT ARXIV
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Torres-Huitzil Cesar., 2015, MOBILE HLTH, P147
   Voicu RA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030458
   Walse KH, 2016, IIOAB J, V7, P68
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wu WM, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.2208
NR 33
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34633
EP 34652
DI 10.1007/s11042-021-11313-0
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000737106100003
DA 2024-07-18
ER

PT J
AU Lone, PN
   Singh, D
   Mir, UH
AF Lone, Parveiz Nazir
   Singh, Deep
   Mir, Umar Hussain
TI Image encryption using DNA coding and three-dimensional chaotic systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNA encoding; DNA operations; 3D Arnold map; 3D logistic map
ID ALGORITHM; COMBINATION; PERMUTATION
AB In this article, we present a novel algorithm for image encryption by invoking the well-known Deoxyribonucleic Acid (DNA) method and the three-dimensional chaos maps. The 3D Arnold map creates a key sequence which is changed by DNA rule and XORed with a DNA stream to accomplish an intricate diffusion, and simultaneously get through to scramble all the pixel positions. The decimation level is changed by virtue of three key generating sequences obtained by 3D logistic map with sensitive parameters and initial values. The efficiency of the proposed algorithm is verified via a series of experiments carried on some test images. The numerical outcomes demonstrate that the proposed algorithm performs exceptionally well and provides better encryption results abreast the higher key sensitivity as compared to the previous existing schemes. Nevertheless, the proposed algorithm also exhibits an enhanced resistance to the known statistical, differential, and exhaustive attacks.
C1 [Lone, Parveiz Nazir; Singh, Deep; Mir, Umar Hussain] Cent Univ Jammu, Dept Math, Jammu 181143, Jammu & Kashmir, India.
C3 Central University of Jammu
RP Singh, D (corresponding author), Cent Univ Jammu, Dept Math, Jammu 181143, Jammu & Kashmir, India.
RI lone, parveiz/CAG-2745-2022
OI lone, parveiz nazir/0000-0001-6578-852X; SINGH, DEEP/0000-0003-4628-9607
FU National Board of Higher Mathematics, Department of Atomic Energy, India
   [02011/10/2020 NBHM(R.P.)/RDII/7025]
FX The second Author is thankful to National Board of Higher Mathematics,
   Department of Atomic Energy, India for providing financial support under
   the grant number: 02011/10/2020 NBHM(R.P.)/R&DII/7025.
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Akkasaligar PT, 2020, INF SECUR J, V29, P91, DOI 10.1080/19393555.2020.1718248
   Arora M, 2020, OPT QUANT ELECTRON, V52, DOI 10.1007/s11082-019-2130-3
   Aumasson Jean-Philippe, 2017, Serious cryptography
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Feng W, 2020, IEEE ACCESS, V8, P209471, DOI 10.1109/ACCESS.2020.3038006
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Iqbal N, 2020, IEEE ACCESS, V8, P178167, DOI 10.1109/ACCESS.2020.3025241
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Khade P.N., 2012, Int. J. Comput. Sci. Issues, V9, P323
   Khan JS, 2020, IEEE ACCESS, V8, P159732, DOI 10.1109/ACCESS.2020.3020917
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Liu HJ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3016, DOI 10.1109/ICYCS.2008.449
   Liu HJ, 2013, COMPUT ELECTR ENG, V39, P1164, DOI 10.1016/j.compeleceng.2013.01.017
   Liu YS, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501886
   Lone PN, 2021, J MOD OPTIC, V68, P507, DOI 10.1080/09500340.2021.1924885
   Lone PN, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2020.165155
   Mir UH, 2022, INF SECUR J, V31, P49, DOI 10.1080/19393555.2021.1963018
   Mir UH, 2020, APPL APPL MATH, V15, P1213
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pan T. G., 2011, ADV ENG FORUM, V1, P183, DOI DOI 10.4028/WWW.SCIENTIFIC.NET/AEF.1.183
   Patel S, 2020, MULTIMED TOOLS APPL, V79, P31739, DOI 10.1007/s11042-020-09551-9
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Stallings W., 2006, Cryptography and Network Security, V4th
   Sun S., 2017, OPT ENG, V56, P11
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang XY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75562-z
   Wang XY, 2020, OPT LASER ENG, V125, DOI 10.1016/j.optlaseng.2019.105851
   Wang XY, 2019, MOD PHYS LETT B, V33, DOI 10.1142/S0217984919502634
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wu J, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010005
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu M, 2017, OPTIK, V134, P45, DOI 10.1016/j.ijleo.2017.01.029
   Zhan K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013021
   Zhang J., 2014, MATH PROBL ENG, V2014, P10, DOI DOI 10.1016/J.IJEPES.2014.09.041
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang X, 2021, MULTIMED TOOLS APPL, V80, P8809, DOI 10.1007/s11042-020-09465-6
   Zhu CJ, 2020, MULTIMED TOOLS APPL, V79, P7227, DOI 10.1007/s11042-019-08226-4
NR 54
TC 18
Z9 18
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5669
EP 5693
DI 10.1007/s11042-021-11802-2
EA DEC 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735344900001
DA 2024-07-18
ER

PT J
AU Feng, S
AF Feng, Shu
TI Kernel pooling feature representation of pre-trained convolutional
   neural networks for leaf recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf recognition; Feature representation; Convolutional neural networks;
   Kernel pooling; Second order information
ID NONRIGID SHAPES; PLANT; CLASSIFICATION; DESCRIPTOR; PROJECTION;
   RETRIEVAL; ROTATION; DISTANCE; IMAGE
AB Due to the presence of various types of factors, such as illumination, viewpoint, intra-class complexity, and inter-class similarity, which make plant leaf recognition still a challenging research problem. In this paper, we present a very simple, yet effective feature representation method for plant leaf recognition. Concretely, it comprises four stages. Firstly, each leaf image is fed into an imagenet pre-trained CNN model to extract activated feature maps in a specified layer. Secondly, inspired by 1 x1 convolution, we exploit principle component analysis to learn the 1 x1 convolution filters. As a result, it not only eliminates the redundant information, reduces the feature dimension adaptively that is beneficial to the subsequent high order pooling, but also increases classification accuracy. Thirdly, kernel pooling is employed to capture second order statistics between each pair of features with the purpose of learning more discriminative information. Finally, matrix sqrt and upper triangle are performed to obtain the final leaf representation, which is utilized for classification and retrieval by the euclidean distance based nearest neighbor classifier. Extensive experiments are conducted on four representative plant leaf datasets, Flavia, Swedish, MEW2012, ICL, to validate the effectiveness of our method. For classification task, our method achieves outstanding and better average classification accuracies than the comparative state-of-theart baselines. For retrieval task, our method gets significant higher or competitive MAP scores. Our implementation code will be available at https://github.com/fengshu666666/leafrecognition.
C1 [Feng, Shu] Shanxi Agr Univ, Dept Fdn, Taigu 030801, Shanxi, Peoples R China.
C3 Shanxi Agricultural University
RP Feng, S (corresponding author), Shanxi Agr Univ, Dept Fdn, Taigu 030801, Shanxi, Peoples R China.
EM fengshu666666@163.com
FU National Natural Science Foundation of China [62101376]; Science and
   Technology Innovation Foundation Project of Shanxi Agricultural
   University [2018021]; Natural Science Foundation of Shanxi Province of
   China [201901D211078]; Scientific and Technologial Innovation Programs
   of Higher Education Institutions in Shanxi [2019L0350]
FX The work described in this paper was partially supported by the National
   Natural Science Foundation of China (Grant No. 62101376), Science and
   Technology Innovation Foundation Project of Shanxi Agricultural
   University (Grant Number 2018021), Natural Science Foundation of Shanxi
   Province of China (Grant No. 201901D211078), Scientific and Technologial
   Innovation Programs of Higher Education Institutions in Shanxi (Grant
   No. 2019L0350).
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Araujo VM, 2020, 2 VIEW FINE GRAINED
   Bai X, 2012, IEEE T IMAGE PROCESS, V21, P2747, DOI 10.1109/TIP.2011.2170082
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Carreira J, 2015, IEEE T PATTERN ANAL, V37, P1177, DOI 10.1109/TPAMI.2014.2361137
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen X, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105714
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Engin M, 2018, LECT NOTES COMPUT SC, V11206, P629, DOI 10.1007/978-3-030-01216-8_38
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Gao ZL, 2019, PROC CVPR IEEE, P3019, DOI 10.1109/CVPR.2019.00314
   Ghazi MM, 2017, NEUROCOMPUTING, V235, P228, DOI 10.1016/j.neucom.2017.01.018
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Gupta A., 2020, J CRIT REV, V7, P2398
   Haykin S, 1998, Neural Networks: A Comprehensive Foundation
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Horaisová K, 2016, BIOSYST ENG, V142, P83, DOI 10.1016/j.biosystemseng.2015.12.007
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   Arribas JI, 2011, COMPUT ELECTRON AGR, V78, P9, DOI 10.1016/j.compag.2011.05.007
   Ionescu C, 2015, IEEE I CONF COMP VIS, P2965, DOI 10.1109/ICCV.2015.339
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Koniusz P, 2017, PROC CVPR IEEE, P7139, DOI 10.1109/CVPR.2017.755
   Koniusz P, 2017, IEEE T PATTERN ANAL, V39, P313, DOI 10.1109/TPAMI.2016.2545667
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laga H, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lee S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI [10.14722/ndss.2017.23457, 10.1016/j.patcog.2017.05.015]
   Lee SH, 2018, IEEE T IMAGE PROCESS, V27, P4287, DOI 10.1109/TIP.2018.2836321
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Lin TY, 2017, BRIT MACHINEVISION C, P1
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu NA, 2016, NEUROCOMPUTING, V216, P460, DOI 10.1016/j.neucom.2016.08.005
   Novotny P, 2013, BIOSYST ENG, V115, P444, DOI 10.1016/j.biosystemseng.2013.04.007
   Raina Sakshi, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P900, DOI 10.1109/ICAIS50930.2021.9396023
   Sachar S, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114181
   Shah MP, 2017, IEEE IMAGE PROC, P860, DOI 10.1109/ICIP.2017.8296403
   Shao Y, 2019, COMPUT ELECTRON AGR, V158, P102, DOI 10.1016/j.compag.2019.01.022
   Sharma S., 2020, INT J INTELLIGENCE S, V1, P101
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Trivedi M., 2021, INT J APPL SCI ENG, V18, P1, DOI [DOI 10.6703/IJASE.202106_18(2).003, 10.6703/IJASE.202106_18(2).003]
   Turkoglu M, 2019, APPL MATH COMPUT, V352, P1, DOI 10.1016/j.amc.2019.01.054
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510
   Wang B, 2017, PROC CVPR IEEE, P2047, DOI 10.1109/CVPR.2017.221
   Wang B, 2015, INFORM SCIENCES, V302, P132, DOI 10.1016/j.ins.2014.07.028
   Wang B, 2014, IEEE T IMAGE PROCESS, V23, P4101, DOI 10.1109/TIP.2014.2343457
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Wang XG, 2014, PATTERN RECOGN, V47, P2116, DOI 10.1016/j.patcog.2013.12.008
   Wang X, 2020, IEEE ACCESS, V8, P39175, DOI 10.1109/ACCESS.2020.2976117
   Wang ZB, 2018, NEURAL PROCESS LETT, V47, P99, DOI 10.1007/s11063-017-9635-1
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yang CZ, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107809
   Yang CZ, 2019, SIGNAL PROCESS-IMAGE, V71, P110, DOI 10.1016/j.image.2018.11.004
   Yang CZ, 2016, FRONT ARTIF INTEL AP, V285, P269, DOI 10.3233/978-1-61499-672-9-269
   Yousefi E, 2017, COMPUT ELECTRON AGR, V140, P70, DOI 10.1016/j.compag.2017.05.031
   Zeng SN, 2017, COMPUT ELECTRON AGR, V142, P563, DOI 10.1016/j.compag.2017.11.013
   Zhang JJ, 2021, INT J COMPUT VISION, V129, P300, DOI 10.1007/s11263-020-01376-1
   Zhang SW, 2020, NEUROCOMPUTING, V408, P246, DOI 10.1016/j.neucom.2019.09.113
   Zhang SW, 2020, KNOWL-BASED SYST, V200, DOI 10.1016/j.knosys.2020.105998
   Zhang SW, 2016, PATTERN ANAL APPL, V19, P953, DOI 10.1007/s10044-015-0488-9
   Zhang X, 2019, MULTIMED TOOLS APPL, V78, P27463, DOI 10.1007/s11042-019-07846-0
   Zhao C, 2015, PATTERN RECOGN, V48, P3203, DOI 10.1016/j.patcog.2015.04.004
   Zhou J, 2021, NEUROCOMPUTING, V440, P197, DOI 10.1016/j.neucom.2021.01.035
NR 72
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4255
EP 4282
DI 10.1007/s11042-021-11769-0
EA DEC 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000726263400001
DA 2024-07-18
ER

PT J
AU Elshoush, HT
   Mahmoud, MM
   Altigani, A
AF Elshoush, Huwaida T.
   Mahmoud, Mahmoud M.
   Altigani, Abdelrahman
TI A new high capacity and secure image realization steganography based on
   ASCII code matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Image realization steganography; Information
   hiding; Mapping based techniques; ASCII matching techniques
ID PIXEL-VALUE; COVERLESS; SYSTEM
AB Digital Steganography is the art of hiding secret messages behind an innocent looking digital media that do not raise suspicions. In this paper, a new proposed image realization steganography method is introduced which is a mapping-based method that hides in an unrevealed manner and without any change in the image cover file. The image cover is only used for referencing. The proposed method generates the cover-secret mapping that will realize the concealed secret message without embedding the real message. A mapping between the American Standard Code of Information Interchange (ASCII) codes of a secret message and an image is performed and the positions of the secret message in the image is noted in a position array. This reference positions are then sent to the receiver after first being compressed by Huffman algorithm and then encrypted using Advanced Encryption Standard with 128 bits key (AES-128). The position array and the cover image are transferred separately, so that the interception of any one file alone will not conceal any information. In addition, it has unlimited capacity as specific matching positions can be used more than once. Furthermore, the proposed method has a reduced size of position key and mapping table, hence having high-speed searching and matching compared to prevailing methods. Furthermore, several experimental tests have been applied to assess the efficiency and performance of the new proposed method to evaluate it according to the widely used metrics: Mean Squared Error (MSE) and Peak Signal to Noise Ratio (PSNR). From the security point of view, Structural Similarity Index Measure (SSIM) together with Histogram have been performed. Moreover, it is critiqued showing its pros and cons and further compared with existing state-of-the-art research. The experimental results verified the efficacy of the new proposed method.
C1 [Elshoush, Huwaida T.; Mahmoud, Mahmoud M.] Univ Khartoum, Fac Math Sci & Informat, Comp Sci Dept, Khartoum, Sudan.
   [Altigani, Abdelrahman] Bin Faisal Univ, Coll Comp Sci & Informat Technol, Comp Sci Dept, Dammam, Saudi Arabia.
C3 University of Khartoum
RP Elshoush, HT (corresponding author), Univ Khartoum, Fac Math Sci & Informat, Comp Sci Dept, Khartoum, Sudan.
EM htelshoush@uofk.edu
RI Altigani, Abdelrahman/IVV-4969-2023; Elshoush, Huwaida
   Tagelsir/HGB-9342-2022
OI Elshoush, Huwaida Tagelsir/0000-0003-0142-393X
CR Abbass AA., 2021, J ENG APPL SCI, V16, P161
   Abdulla AA, 2020, P SEC STAND RES
   Akara F, 2004, J NAVAL SCI ENG, V2
   Al-Husainy Mohammed A. F., 2009, Journal of Computer Sciences, V5, P33, DOI 10.3844/jcs.2009.33.38
   Al-Husainy MAF., 2011, COMPUT INF SCI, V4
   Al-Taani AT, 2009, WORLD ACAD SCI ENG T, V27
   Alamsyah MAM, 2015, J THEOR APPL INF TEC, V82
   Ali Abdelmgeid, 2013, INT J COMPUTER SCI E, V3, P1
   Alsarayreh Maher A., 2017, Journal of Theoretical and Applied Information Technology, V95, P1212
   Anitha S, 2020, INT J ENG RES TECHNO
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2018, IMAGE STRUCTURE
   [Anonymous], 2018, J INF HIDING MULTIME
   [Anonymous], 2010, INT J COMPUT SCI INF
   Bandyopadhyay SK, 2010, INT J ADV TECHNOL, V1
   Banerjee I, 2013, PROC TECH, V10, P157, DOI 10.1016/j.protcy.2013.12.348
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhattacharyya S, 2010, P 9 ANN C SEC MAN SA
   Bhattacharyya S., 2013, INT J COMPUT APPL, V70, P29, DOI [10.5120/12169-8282, DOI 10.5120/12169-8282]
   Bhattacharyya S., 2010, WORLD ACAD SCI ENG T, V68, P409
   Bhattacharyya S, 2014, WORLD ACAD SCI ENG T, V8
   Bhattacharyya S, 2011, P WICT 2011 MUMB IND
   Bilal M, 2014, MULTIMED TOOLS APPL, V72, P1073, DOI 10.1007/s11042-013-1415-y
   Cao Y, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00524-4
   Cao Y, 2018, J INTERNET TECHNOL, V19, P1179, DOI 10.3966/160792642018081904020
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Challita Khalil, 2011, International Journal of New Computer Architectures and their Applications, V1, P199
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen XY, 2019, MATH BIOSCI ENG, V16, P4708, DOI 10.3934/mbe.2019236
   Datta B, 2016, PROCEDIA COMPUT SCI, V85, P425, DOI 10.1016/j.procs.2016.05.188
   Elshoush H.T., 2021, J INFORM HIDING MULT, V12, P65
   Fridrich J., 2009, INFORM HIDING
   Geetha S, 2011, INFORM PROCESS LETT, V111, P792, DOI 10.1016/j.ipl.2011.05.013
   Guo W, 2019, J INFORM HIDING PRIV, V1, P49
   Halidou A., 2017, INT J COMPUTER APPL, V168, P0975
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hmood AK, 2010, J APPL SCI, V10
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Husainy MAFA., 2010, P WORLD C ENG COMP S
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussein HL, 2018, J PHYS CONF SER, V1003, DOI 10.1088/1742-6596/1003/1/012032
   Jayaram P., 2011, The International Journal of Multimedia and Its Applications (IJMA), V3, P86
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Joshi K., 2018, INT J ENG RES TECHNO, V7
   Kanzariya N, 2013, P INT C ADV SIGN PRO
   Kaur S, 2011, COMM COM INF SC, V169, P603
   Kaur S, 2010, AIP CONF PROC, V1324, P280, DOI 10.1063/1.3526214
   Kim PH, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/9038650
   Kingsley K. A., 2020, Journal of Information Hiding and Multimedia Signal Processing, V11, P14
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Laskar S. A., 2012, International Journal of Database Management Systems (IJDMS), V4, P57
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu Q, 2021, KSII T INTERNET INF, V15, P1078, DOI 10.3837/tiis.2021.03.014
   Liu Q, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00521-7
   Maji G., 2019, INT J INNOVATIVE TEC, V8, P2278
   Mohan AK., 2015, THESIS PONDICHERRY U
   Mukherjee S, 2019, MULTIMED TOOLS APPL, V78, P17607, DOI 10.1007/s11042-018-7127-6
   Nag A., 2010, International Journal of Computer Science & Information Technology, V2, P103, DOI 10.5121/ijcsit.2010.2308
   Panjabi PK, 2013, INT J COMPUT APPL, V74
   Potdar VM, 2004, 2004 2ND IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, P223, DOI 10.1109/INDIN.2004.1417333
   Qin JH, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091394
   Roy Ratnakirti, 2015, International Journal of Information and Computer Security, V7, P196
   Roy R, 2014, INT CONF CONTEMP, P218, DOI 10.1109/IC3.2014.6897176
   Saad AS, 2021, IEEE ACCESS, V9, P16522, DOI 10.1109/ACCESS.2021.3050737
   Saad AS, 2021, CMC-COMPUT MATER CON, V67, P2077, DOI 10.32604/cmc.2021.015329
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Samima S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P377, DOI 10.1109/ICIIP.2013.6707619
   Sandoval-Bravo LA, 2020, PROC SPIE, V11401, DOI 10.1117/12.2556310
   Santoso KN, 2015, IEICE T FUND ELECTR, VE98A, P1529, DOI 10.1587/transfun.E98.A.1529
   Sharma V., 2013, INT J ADV RES COMPUT, V3, P701
   Shelke F.M., 2014, International Journal of Application or Innovation in Engineering Management, V3, P171
   Shete Kalpana Sanjay, 2016, International Journal of Image, Graphics and Signal Processing, V8, P48, DOI 10.5815/ijigsp.2016.06.06
   Singh Saurabh, 2010, International Journal of Applied Engineering Research, V1, P200
   Singh S., 2013, INT J ADV RES IT ENG, V2, P97
   Swathi B., 2012, ASIAN J COMPUTER SCI, V2, P234
   Tech JKM, 2011, P INT C ADV COMP COM
   Umamaheswari G, 2017, INT J COMPUT SCI INF, V15
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu JB, 2018, IETE TECH REV, V35, P23, DOI 10.1080/02564602.2018.1531735
   Xia SK, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6256872
   Yang L, 2016, IEEE ACCESS, V4
   Zhang SQ, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091152
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zhou ZL, 2019, IEEE ACCESS, V7, P179891, DOI 10.1109/ACCESS.2019.2955990
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 88
TC 4
Z9 4
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5191
EP 5237
DI 10.1007/s11042-021-11741-y
EA DEC 2021
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000725452500001
DA 2024-07-18
ER

PT J
AU Li, LL
   Yang, B
   Chen, SH
AF Li, Linlin
   Yang, Bo
   Chen, Shaohui
TI Detection of agglomerate fog based on a shallow convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Agglomerate fog detection; Image
   classification
AB As a kind of frequent bad weather, Agglomerate fog is a serious danger to people's safe driving, especially on the highway. Therefore, the research on the detection of fog is of great practical significance to ensure the safety of pedestrians. This paper proposes a shallow convolutional neural network for agglomerate fog detection in images, including the framework of the network and the detailed design of each component. Firstly, the image is divided into several sub-images; and then a shallow convolutional neural network is constructed and employed to identify the existence of fog for each of the sub-area images; lastly, the decision results of each sub-area images were integrated to determine whether the whole image contained agglomerate fog. A large quantity of simulation data and real data were used to test the performance of the proposed method, the experimental results show that the presented method can achieve more than 90% detection accuracy, which demonstrated that the advantage of the proposed method comparing with several existed methods.
C1 [Li, Linlin] Renmin Univ China, Sch Informat Resources Management, Beijing 100872, Peoples R China.
   [Yang, Bo] North China Inst Sci & Technol, Sch Emergency Technol & Management, Langfang 065201, Peoples R China.
   [Chen, Shaohui] Beijing Gaocheng Technol Dev Co LTD, Beijing 100043, Peoples R China.
C3 Renmin University of China; North China Institute Science & Technology
RP Yang, B (corresponding author), North China Inst Sci & Technol, Sch Emergency Technol & Management, Langfang 065201, Peoples R China.
EM xinxi_li@tpri.org.cn; 13910700045@139.com; chensh01@ehualu.com
RI Li, Linlin/M-8350-2014
OI Yang, Bo/0000-0002-0961-3861
CR Alami S, 2016, I C COMP GRAPH IM VI, P1, DOI 10.1109/CGiV.2016.10
   Asery T, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P72, DOI 10.1109/ICCP.2014.6936995
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Clevert D., 2016, ARXIV151107289
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Hannun, 2013, 2013 P ICML, V30, P3
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hinton G.E., 2012, RESEARCHGATE, V3, P212, DOI DOI 10.48550/ARXIV.1207.0580
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Kingma D. P., 2014, arXiv
   Klambauer G, 2017, ADV NEUR IN, V30
   Kwang Y C, 2017, IEEE 20 INT C INT TR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2017, ARXIV PREPRINT ARXIV
   Lin D, 2017, IEEE T IMAGE PROCESS, V26, P4154, DOI 10.1109/TIP.2017.2695883
   Lu X, 2020, COMPUTER VISION ECCV, V12348, DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   OJALA T, 2017, IEEE T PATTERN ANAL, V24
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pavlic M, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P1132, DOI 10.1109/IVS.2012.6232256
   Ramashala P A., 2018, International Association for Management of Technology, P1
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spinneker R, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1369, DOI 10.1109/ITSC.2014.6957878
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian Y, 2014, J SYST ENG ELECTRON, V25, P688, DOI 10.1109/JSEE.2014.00079
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang B, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00505-7
   Yang B, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071728
   YU T, 2020, IEEE ACCESS
   Zhao B, 2018, NEUROCOMPUTING, V322, P47, DOI 10.1016/j.neucom.2018.09.048
NR 37
TC 1
Z9 1
U1 7
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2841
EP 2857
DI 10.1007/s11042-021-11540-5
EA NOV 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000715007600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Mondal, R
   Malakar, S
   Smith, EHB
   Sarkar, R
AF Mondal, Riktim
   Malakar, Samir
   Smith, Elisa H. Barney
   Sarkar, Ram
TI Handwritten English word recognition using a deep learning based object
   detection architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Handwriting recognition; Character spotting; IAM dataset; YOLOv3
ID SEQUENCE; MODEL
AB Handwriting is used to distribute information among people. To access this information for further analysis the page needs to be optically scanned and converted to machine recognizable form. Due to unconstrained writing styles along with connected and overlapping characters, handwriting recognition remains a challenging task. Most of the methods in the literature use lexicon-based approaches and train their models on large datasets having near 50 K word samples to achieve good results. This results in high computational requirements. While these models use around 50 K words in their dictionary when recognizing handwritten English text, the actual number of words in the dictionary is much higher than this. To this end, we propose a handwriting recognition technique to recognize handwritten English text based on a YOLOv3 object recognition model that is lexicon-free and that performs sequential character detection and identification with a low number of training samples (only 1200 word images). This model works well without any dependency on writers' style of writing. This is tested on the IAM dataset and it is able to achieve 29.21% Word Error Rate and 9.53% Character Error Rate without a predefined vocabulary, which is on par with the state-of-the-art lexicon-based word recognition models.
C1 [Mondal, Riktim; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
   [Smith, Elisa H. Barney] Boise State Univ, Dept Elect & Comp Engn, Boise, ID 83725 USA.
C3 Jadavpur University; Idaho; Boise State University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM riktimrules@gmail.com; malakarsamir@gmail.com;
   ebarneysmith@boisestate.edu; raamsarkar@gmail.com
RI Malakar, Samir/A-8021-2017; Sarkar, Ram/AAX-3822-2020
OI Malakar, Samir/0000-0003-4217-2372; Sarkar, Ram/0000-0001-8813-4086
CR Almazán J, 2014, IEEE T PATTERN ANAL, V36, P2552, DOI 10.1109/TPAMI.2014.2339814
   [Anonymous], 2008, Advances in Neural Information Processing Systems
   Azeem SA, 2013, INT J DOC ANAL RECOG, V16, P399, DOI 10.1007/s10032-013-0201-8
   Bera SK, 2019, PATTERN RECOGN LETT, V128, P488, DOI 10.1016/j.patrec.2019.10.025
   Bera SK, 2020, J INTELL SYST, V29, P688, DOI 10.1515/jisys-2018-0105
   Bhattacharya Rajdeep, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P582, DOI 10.1007/978-3-030-68790-8_45
   Bhattacharya R, 2021, MULTIMED TOOLS APPL, V80, P3529, DOI 10.1007/s11042-020-09751-3
   Bluche T, 2014, LECT NOTES COMPUT SC, V8791, P199, DOI 10.1007/978-3-319-11397-5_15
   Chakraborty A, 2021, INT C PATT RECOG, P7737, DOI 10.1109/ICPR48806.2021.9412198
   Doetseh P, 2014, INT CONF FRONT HAND, P279, DOI 10.1109/ICFHR.2014.54
   Ghosh S, 2018, WORKSH DOC AN REC, P27
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Gui L., 2018, P BRIT MACH VIS C BM, P207
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hong WC, 2019, ENERGIES, V12, DOI 10.3390/en12061093
   Kirillov A., 2017, A unified architecture for instance and semantic segmentation," ed
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Majid Nishatul, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P228, DOI 10.1109/ICDAR.2019.00045
   Majumder S, 2021, MULTIMED TOOLS APPL, V80, P12411, DOI 10.1007/s11042-020-10363-0
   Malakar S, 2011, P 5 IND INT C ART IN
   MALAKAR S, 2020, J INTELL SYST
   MALAKAR S, 2020, NEURAL COMPUT APPL
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Menasri F, 2012, P DOC REC RETR 19 IN
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Pal U, 2012, INT CONF FRONT HAND, P169, DOI 10.1109/ICFHR.2012.238
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Redmon J., Yolo: Real-time object detection
   Redmon J., 2018, COMPUTER VISION PATT
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sarkar R, 2011, J INTELL SYST, V20, P227, DOI 10.1515/JISYS.2011.013
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Singh PK, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON BUSINESS AND INFORMATION MANAGEMENT (ICBIM)
   Singh Santosh Kumar, 2015, 2015 International Conference on Energy Economics and Environment (ICEEE), P1, DOI 10.1109/EnergyEconomics.2015.7235065
   Stahlberg F, 2015, LECT NOTES COMPUT SC, V9280, P276, DOI 10.1007/978-3-319-23234-8_26
   Sueiras J, 2018, NEUROCOMPUTING, V289, P119, DOI 10.1016/j.neucom.2018.02.008
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Wu XP, 2019, IEEE SIGNAL PROC LET, V26, P597, DOI 10.1109/LSP.2019.2895967
   Zhang YP, 2019, PROC CVPR IEEE, P2735, DOI 10.1109/CVPR.2019.00285
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhou K, 2016, DESTECH TRANS COMP
NR 49
TC 15
Z9 15
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 975
EP 1000
DI 10.1007/s11042-021-11425-7
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698137200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Abiri, M
   Mehrjoo, M
   Rezaei, M
AF Abiri, Majid
   Mehrjoo, Mehri
   Rezaei, Mehdi
TI Scalable video traffic offloading for streaming services in 5G HetNets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Femtocell offloading; 5G heterogeneous cellular networks; Video
   streaming services; Scalable video coding (SVC); Quality of experience
   (QoE)
ID DYNAMIC RESOURCE-ALLOCATION; NETWORKS; TRANSMISSION
AB In this paper, by combining scalable video coding (SVC) and traffic offloading, we propose a scalable video traffic offloading (SVO) approach to provide video streaming services in 5G heterogeneous networks (HetNet). We aim to maximize the number of users receiving the base layer (BL) of the video and to maximize the mean quality of experience (QoE) of users by increasing the number of received enhancement layers (ELs) of the video. Tao this end, we consider a multi-objective mixed-integer programming problem that associates each user to either a macrocell or femtocell and allocates video layers to the users. We solve the multi-objective problem by using the weighted sum of the two objectives, so we obtain a Pareto-optimal solution. To choose one among the solutions, we pick the maximum resource-efficient (ME) one, which uses the least resource blocks (RBs). As obtaining ME solution is computationally complex, we separate the problem into a cell allocation (CA) and a video layers allocation (VLA) problem and propose a two-step heuristic solution. To obtain the heuristic solution, we take advantage of the video traffic scalability; in the first step, we allocate BLs to cells to increase the number of users receiveing service, and we assign ELs to the users to improve the mean QoE in the second step. We evaluate the heuristic solution by comparing it with the upper bound solution. Simulation results show that a narrow gap exists between the upper bound and the heuristic solution, while it has a low computational complexity which makes it appropriate for streaming services implementation. Furthermore, number of users receiving service in SVO has a high impact on grewing resource efficiency.
C1 [Abiri, Majid; Mehrjoo, Mehri; Rezaei, Mehdi] Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
C3 University of Sistan & Baluchestan
RP Mehrjoo, M (corresponding author), Univ Sistan & Baluchestan, Dept Commun Engn, Zahedan, Iran.
EM abiri064@pgs.usb.ac.ir; mehrjoo@ece.usb.ac.ir;
   mehdi.rezaei@ece.usb.ac.ir
RI Mehrjoo, Mehri/AAZ-2343-2020; Rezaei, Mehdi/HPC-0221-2023
OI Mehrjoo, Mehri/0000-0002-1409-5237; 
CR Almadani B, 2016, MULTIMED TOOLS APPL, V75, P5841, DOI 10.1007/s11042-015-2551-3
   [Anonymous], 2019, 38104 3GPP TS
   [Anonymous], 2020, Cisco annual Internet report (2018-2023) white paper
   [Anonymous], 2010, 102643 ETSI TR
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Deng R, 2018, MULTIMED TOOLS APPL, V77, P6445, DOI 10.1007/s11042-017-4551-y
   Ghosh A, 2019, IEEE ACCESS, V7, P127639, DOI 10.1109/ACCESS.2019.2939938
   Guo YS, 2017, IEEE T WIREL COMMUN, V16, P8162, DOI 10.1109/TWC.2017.2758363
   Hu WJ, 2017, IEEE T MOBILE COMPUT, V16, P3182, DOI 10.1109/TMC.2017.2690296
   Ismail M, 2013, IEEE T WIREL COMMUN, V12, P3600, DOI 10.1109/TWC.2013.062713.130302
   Ju Y, 2014, MULTIMED TOOLS APPL, V72, P1093, DOI 10.1007/s11042-013-1413-0
   Kellerer H., 2004, Knapsack Problems, DOI 10.1007/978-3-540-24777-7
   Mahbub, 2002, ENG INTERNET QOS
   MARTELLO S, 1981, COMPUTING, V27, P93, DOI 10.1007/BF02243544
   MARTELLO S, 1981, DISCRETE APPL MATH, V3, P275, DOI 10.1016/0166-218X(81)90005-6
   Nightingale J, 2014, MULTIMED TOOLS APPL, V70, P2011, DOI 10.1007/s11042-012-1219-5
   Park GS, 2019, IEEE T VEH TECHNOL, V68, P5928, DOI 10.1109/TVT.2019.2909547
   Raufmehr F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043013
   Shafi M, 2017, IEEE J SEL AREA COMM, V35, P1201, DOI 10.1109/JSAC.2017.2692307
   Sulyman AI, 2014, IEEE COMMUN MAG, V52, P78, DOI 10.1109/MCOM.2014.6894456
   Tan TK, 2016, IEEE T CIRC SYST VID, V26, P76, DOI 10.1109/TCSVT.2015.2477916
   Yang J, 2019, IEEE T COMMUN, V67, P2114, DOI 10.1109/TCOMM.2018.2883627
   Yang J, 2018, IEEE T COMMUN, V66, P3455, DOI 10.1109/TCOMM.2017.2783974
   Zhou H, 2015, IEEE T WIREL COMMUN, V14, P3673, DOI 10.1109/TWC.2015.2409834
NR 24
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12325
EP 12347
DI 10.1007/s11042-021-11312-1
EA SEP 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000692967600005
DA 2024-07-18
ER

PT J
AU Guefrechi, S
   Ben Jabra, M
   Ammar, A
   Koubaa, A
   Hamam, H
AF Guefrechi, Sarra
   Ben Jabra, Marwa
   Ammar, Adel
   Koubaa, Anis
   Hamam, Habib
TI Deep learning based detection of COVID-19 from chest X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; COVID-19; Convolution Neural Network; CNN; Chest X-ray
AB The whole world is facing a health crisis, that is unique in its kind, due to the COVID-19 pandemic. As the coronavirus continues spreading, researchers are concerned by providing or help provide solutions to save lives and to stop the pandemic outbreak. Among others, artificial intelligence (AI) has been adapted to address the challenges caused by pandemic. In this article, we design a deep learning system to extract features and detect COVID-19 from chest X-ray images. Three powerful networks, namely ResNet50, InceptionV3, and VGG16, have been fine-tuned on an enhanced dataset, which was constructed by collecting COVID-19 and normal chest X-ray images from different public databases. We applied data augmentation techniques to artificially generate a large number of chest X-ray images: Random Rotation with an angle between - 10 and 10 degrees, random noise, and horizontal flips. Experimental results are encouraging: the proposed models reached an accuracy of 97.20 % for Resnet50, 98.10 % for InceptionV3, and 98.30 % for VGG16 in classifying chest X-ray images as Normal or COVID-19. The results show that transfer learning is proven to be effective, showing strong performance and easy-to-deploy COVID-19 detection methods. This enables automatizing the process of analyzing X-ray images with high accuracy and it can also be used in cases where the materials and RT-PCR tests are limited.
C1 [Guefrechi, Sarra; Hamam, Habib] Univ Moncton, Fac Engn, Moncton, NB, Canada.
   [Ben Jabra, Marwa] Charisma Univ, Englewood, England.
   [Ben Jabra, Marwa] Robot & Internet Things Unit RIoT Lab, Riyadh, Saudi Arabia.
   [Ammar, Adel; Koubaa, Anis] Prince Sultan Univ, Riyadh, Saudi Arabia.
   [Koubaa, Anis] Gaitech Robot, Shanghai, Peoples R China.
   [Koubaa, Anis] Polytech Inst Porto, ISEP, INESC TEC, Porto, Portugal.
C3 University of Moncton; Prince Sultan University; INESC TEC; Instituto
   Politecnico do Porto
RP Guefrechi, S (corresponding author), Univ Moncton, Fac Engn, Moncton, NB, Canada.
EM guefrechisarra@gmail.com
RI Ammar, Adel/AAY-6061-2020; Hamam, Habib/C-1761-2019; Koubaa,
   Anis/T-7414-2018
OI Ammar, Adel/0000-0003-0795-132X; Hamam, Habib/0000-0002-5320-1012;
   Koubaa, Anis/0000-0003-3787-7423
CR Ai T, 2020, RADIOLOGY, V296, pE32, DOI 10.1148/radiol.2020200642
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   [Anonymous], COR DIS COVID 19 ADV
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Axell-House DB, 2020, J INFECTION, V81, P681, DOI 10.1016/j.jinf.2020.08.043
   Bergman S J., 2020, Medscape, V2020
   Bloice MD, 2019, BIOINFORMATICS, V35, P4522, DOI 10.1093/bioinformatics/btz259
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Eurosurveillance Editorial Team, 2020, EUROSURVEILLANCE, V25, P2, DOI 10.2807/1560-7917.ES.2020.25.5.200131e
   Gazzah S., 2020, INT C INTELLIGENT SY, P1
   Ghassemi, 2020, ARXIV200611988
   Globalpulse, NEED GREAT COOP PRAC
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Isa A., Computational Intelligence Methods in COVID-19: Surveillance, Prevention, Prediction and Diagnosis, P251
   Kallianos K, 2019, CLIN RADIOL, V74, P338, DOI 10.1016/j.crad.2018.12.015
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lalkhen AG, 2008, BJA EDUC, V8, P221, DOI 10.1093/bjaceaccp/mkn041
   Lopez AR, 2017, 2017 13TH IASTED INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BIOMED), P49, DOI 10.2316/P.2017.852-053
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Narin A., 2020, ARXIV200310849
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Sethy PK, 2020, Detection of coronavirus disease (covid-19) based on deep features
   Shan F., 2020, ARXIV200304655
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stoecklin SB, 2020, EUROSURVEILLANCE, V25, P20, DOI 10.2807/1560-7917.ES.2020.25.6.2000094
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   World health organization, WHO IS WORK TRACK AN
   World Health Organization, Coronavirus
   World health organization, 2020, DIR GEN S OP REM AT
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
NR 34
TC 29
Z9 30
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31803
EP 31820
DI 10.1007/s11042-021-11192-5
EA JUL 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000006
PM 34305440
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, XB
AF Zhang, Xiaobo
TI Image denoising using multidirectional gradient domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Nonlocal means (NLM); Nonlinear diffusion; Gradient
   domain
ID EDGE-DETECTION; WIENER FILTER; ALGORITHM
AB This paper presents a new two-step image denoising method termed multidirectional gradient domain image denoising (MGDID). In each step, unlike previous gradient domain designs, the multidirectional gradient domain information is used to represent the noise component so that the more directional image features are extracted. The Gaussian pre-filter is carried out in the square gradient coefficients. The nonlinear remedied factor is adopted to modify the denoising amount. The whole denoising process originates from classical nonlocal means (NLM) and nonlinear diffusion. MGDID takes full advantage of ability of NLM to better process the image with the rich repetitive features and the denoising scheme of relatively simplicity and efficiency of nonlinear diffusion. Experimental results show MGDID is superior to the related gradient domain methods and NLM methods in peak signal-to-noise ratio (PSNR), mean structural similarity (MSSIM) and visual performance. For example, for Barbara image with the rich repetitive texture feature, MGDID outperforms classical NLM from 0.33 dB to 1.66 dB in PSNR. Usually, classical NLM wins the local adaptive layered Wiener filer (a state-of-the-art gradient domain method) more than 0.44 dB for Barbara. In addition, MGDID is also very efficient compared to the related methods.
C1 [Zhang, Xiaobo] Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
C3 Xianyang Normal University
RP Zhang, XB (corresponding author), Xianyang Normal Univ, Inst Graph & Image Proc, Xianyang 712000, Peoples R China.
EM zhangxiaobo419@126.com
OI Zhang, Xiaobo/0000-0001-6018-4655
FU National Natural Science Foundation of China [61401383]; Basic Research
   Plan of Natural Science in Shaanxi Province [2021JM-518]; Qinglan Talent
   Program of Xianyang Normal University [XSYQL201503]
FX This work is partially supported by National Natural Science Foundation
   of China (Grant No. 61401383), Basic Research Plan of Natural Science in
   Shaanxi Province (Grant No. 2021JM-518) and Qinglan Talent Program of
   Xianyang Normal University (Grant No. XSYQL201503).
CR [Anonymous], 2008, NONLOCAL MEANS FILTE
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Deledalle CA, 2012, J MATH IMAGING VIS, V43, P103, DOI 10.1007/s10851-011-0294-y
   Eom IK, 2004, IEEE SIGNAL PROC LET, V11, P937, DOI 10.1109/LSP.2004.836940
   Hjouji A, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0187-6
   Lai R, 2011, ELECTRON LETT, V47, P182, DOI 10.1049/el.2010.2618
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Maiseli BJ, 2020, SIGNAL IMAGE VIDEO P, V14, P1283, DOI 10.1007/s11760-020-01663-x
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Nguyen MP, 2017, IEEE T IMAGE PROCESS, V26, P1637, DOI 10.1109/TIP.2017.2658941
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Salmon J, 2010, IEEE SIGNAL PROC LET, V17, P269, DOI 10.1109/LSP.2009.2038954
   Vignesh R, 2010, IEEE SIGNAL PROC LET, V17, P277, DOI 10.1109/LSP.2009.2038956
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
   Zhang XB, 2016, J SCI IND RES INDIA, V75, P687
   Zhang XB, 2015, MULTIMED TOOLS APPL, V74, P10495, DOI 10.1007/s11042-014-2182-0
   Zhang XB, 2014, AEU-INT J ELECTRON C, V68, P179, DOI 10.1016/j.aeue.2013.08.009
   Zhang XB, 2013, COMPUT ELECTR ENG, V39, P934, DOI 10.1016/j.compeleceng.2012.07.013
NR 21
TC 4
Z9 5
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29745
EP 29763
DI 10.1007/s11042-021-11184-5
EA JUL 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000672298900003
DA 2024-07-18
ER

PT J
AU Shaik, N
   Malik, PK
AF Shaik, Nilofer
   Malik, Praveen Kumar
TI A comprehensive survey 5G wireless communication systems: open issues,
   research challenges, channel estimation, multi carrier modulation and 5G
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Candidate waveforms; Channel estimation; Internet of things; Machine
   type communication; Massive multiple-input multiple output; Rayleigh
   fading
ID MASSIVE MIMO; WEARABLE TECHNOLOGY; OFDM SYSTEMS; PHASE NOISE; MOBILE;
   ALGORITHM; NETWORKS; VISION; DESIGN; SDN
AB The fifth generation (5G) organize is required to help essentially enormous measure of versatile information traffic and immense number of remote associations. To accomplish better spectrum, energy-efficiency, as a nature of quality of service (QoS) in terms of delay, security and reliability is a requirement for several wireless connectivity. Massive Multiple-input Multiple-output (mMIMO) is a rising innovation for the 5G wireless communication systems. It can possibly give high spectral efficiency, improving link reliability and suit huge number of clients likewise focusing on the efficacy, accuracy and estimation of channel many channel estimations (CE) techniques are developed. Much of the time, the accentuation of most proposed CE schemes is to improve the CE performance and complexity for ensuring improved system throughput and quality signal reception. This article reviews mainly about 5G wireless communication systems that requires efficient channel estimation technique with an efficient candidate wave form. The article also reviews the architecture and design issues that are mere requirement for 5G wireless communication systems.
C1 [Shaik, Nilofer] CMR Inst Technol, Hyderabad, Telangana, India.
   [Shaik, Nilofer; Malik, Praveen Kumar] Lovely Profess Univ, SEEE, Phagwara, Punjab, India.
C3 Lovely Professional University
RP Shaik, N (corresponding author), CMR Inst Technol, Hyderabad, Telangana, India.; Shaik, N (corresponding author), Lovely Profess Univ, SEEE, Phagwara, Punjab, India.
EM nilofershaik@gmail.com; pkmalikmeerut@gmail.com
RI Malik, Praveen Kumar/AAM-6085-2020; Malik, Praveen/AAE-5886-2022; Malik,
   Praveen/ABF-9511-2021; Malik, Dr. Praveen Kumar/D-4885-2016
OI Malik, Dr. Praveen Kumar/0000-0003-3433-8248
CR 5G Forum, 2015, MAKE IT HAPP CREAT N
   Accenture, 2014, CISC VIS NETW IND GL
   Agyapong PK, 2014, IEEE COMMUN MAG, V52, P65, DOI 10.1109/MCOM.2014.6957145
   Akbarpour-Kasgari A, 2019, IEEE WIREL COMMUN LE, V8, P376, DOI 10.1109/LWC.2018.2873339
   Alcala J., 2017, IEEE T INSTRUMENTATI, P1
   Almoneer M, 2017, IEEE T BROADCAST, V63, P449, DOI 10.1109/TBC.2017.2704433
   Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   [Anonymous], 2014, GSMA INTELLIGENCE
   [Anonymous], 2013, ISWCS 2013
   [Anonymous], 2008, UNDERSTANDING MILLIM
   [Anonymous], 2016, P ETIS WORKSH FUT RA
   [Anonymous], 2013, 6 JOINT IFIP WIR MOB
   [Anonymous], 2015, CISC VIS NETW IND GL
   [Anonymous], 2014, P 16 INT TEL NETW ST
   [Anonymous], 2014, CISC VIS NETW IND GL
   [Anonymous], 2014, CISC VIS NETW IND GL
   [Anonymous], 2011, CISCO VISUAL NETWORK
   [Anonymous], 2013, 5G INFRASTRUCTURE PU
   Araújo DC, 2019, IEEE ACCESS, V7, P42133, DOI 10.1109/ACCESS.2019.2908207
   Arslan MY, 2015, IEEE COMMUN MAG, V53, P150, DOI 10.1109/MCOM.2015.7010528
   Asadi A, 2014, IEEE COMMUN SURV TUT, V16, P1801, DOI 10.1109/COMST.2014.2319555
   Bae J, 2014, I C INF COMM TECH CO, P847, DOI 10.1109/ICTC.2014.6983310
   Balevi E, 2020, IEEE T WIREL COMMUN, V19, P2079, DOI 10.1109/TWC.2019.2962474
   Ban YR, 2016, CHINA COMMUN, V13, P72, DOI 10.1109/CC.2016.7582299
   Basaran M, 2018, IEEE T WIREL COMMUN, V17, P8123, DOI 10.1109/TWC.2018.2874228
   Bensan M., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P402, DOI 10.1109/CICN.2012.161
   Bhimsing DV, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON POWER, CONTROL, SIGNALS AND INSTRUMENTATION ENGINEERING (ICPCSI), P1003, DOI 10.1109/ICPCSI.2017.8391861
   Binkley PF, 2003, IEEE ENG MED BIOL, V22, P23, DOI 10.1109/MEMB.2003.1213623
   Boccardi F, 2014, IEEE COMMUN MAG, V52, P74, DOI 10.1109/MCOM.2014.6736746
   Checko A, 2015, IEEE COMMUN SURV TUT, V17, P405, DOI 10.1109/COMST.2014.2355255
   Chen CY, 2018, IEEE T VEH TECHNOL, V67, P5806, DOI 10.1109/TVT.2018.2798360
   Chen JQ, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148704
   Chen L, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-1011-3
   Chen SZ, 2014, IEEE COMMUN MAG, V52, P36, DOI 10.1109/MCOM.2014.6815891
   Cho HH, 2014, IEEE ACCESS, V2, P1196, DOI 10.1109/ACCESS.2014.2357435
   Coleri S, 2002, IEEE T BROADCAST, V48, P223, DOI 10.1109/TBC.2002.804034
   Daryasafar N, 2012, IJCSI INT J COMPUTER, V9
   Desta Yilma Taye, 2011, Information Technology Journal, V10, P914, DOI 10.3923/itj.2011.914.926
   Erol-Kantarci M, 2015, IEEE COMMUN SURV TUT, V17, P179, DOI 10.1109/COMST.2014.2341600
   Farhang-Borotijeny B, 2008, IEEE T SIGNAL PROCES, V56, P1801, DOI 10.1109/TSP.2007.911490
   Goldsmith A., 2009, WIRELESS COMMUNICATI
   Hajjaj M, 2016, IEEE WIREL COMMUN LE, V5, P48, DOI 10.1109/LWC.2015.2493061
   He XY, 2016, IEEE T VEH TECHNOL, V65, P2990, DOI 10.1109/TVT.2015.2441743
   Hoeher P, 1997, MULTI-CARRIER SPREAD-SPECTRUM, P169
   Huang Y, 2019, IEEE WIREL COMMUN LE, V8, P29, DOI 10.1109/LWC.2018.2848916
   Huawei, 2013, CISC VIS NETW IND GL
   Idris A, 2017, 2017 7TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE), P293, DOI 10.1109/ICCSCE.2017.8284422
   Jain A, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P133, DOI 10.1109/CCIntelS.2015.7437893
   JALLOH M, 2006, IEEE MIL COMM C OCT, P1, DOI DOI 10.1109/MILCOM.2006.302360
   Kaur Amandeep, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P90, DOI 10.1109/ICCAKM46823.2020.9051501
   Khan F, 2012, ANN ALLERTON CONF, P1517, DOI 10.1109/Allerton.2012.6483399
   Khan I, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7120382
   Kuai XY, 2019, IEEE T WIREL COMMUN, V18, P3813, DOI 10.1109/TWC.2019.2917905
   Kumar N, 2015, IEEE INTERNET THINGS, V2, P310, DOI 10.1109/JIOT.2015.2388588
   Lai CF, 2015, IEEE NETWORK, V29, P49, DOI 10.1109/MNET.2015.7018203
   Lajnef H, 2016, INT WIREL COMMUN, P638, DOI 10.1109/IWCMC.2016.7577131
   Lara A, 2014, IEEE COMMUN SURV TUT, V16, P493, DOI 10.1109/SURV.2013.081313.00105
   Larsson EG, 2014, IEEE COMMUN MAG, V52, P186, DOI 10.1109/MCOM.2014.6736761
   Lee D, 2016, IEEE COMMUN LETT, V20, P2115, DOI 10.1109/LCOMM.2016.2594059
   Lee HC, 2019, IEEE ACCESS, V7, P115192, DOI 10.1109/ACCESS.2019.2935758
   Li Y, 2000, IEEE T VEH TECHNOL, V49, P1207, DOI 10.1109/25.875230
   Li Y, 1998, IEEE T COMMUN, V46, P902, DOI 10.1109/26.701317
   Liang Pu, 2010, Proceedings of the 2010 International Conference on Communications and Mobile Computing (CMC 2010), P77, DOI 10.1109/CMC.2010.201
   Liu J, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), P165, DOI 10.1109/CCI.2016.7778900
   Liu WJ, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE WORKSHOPS (WCNCW), P24, DOI 10.1109/WCNCW.2013.6533309
   Lu L, 2014, IEEE J-STSP, V8, P742, DOI 10.1109/JSTSP.2014.2317671
   Malik PK., 2017, J TODAYS IDEAS TOMOR, V5, P97, DOI [10.15415/jotitt.2017.52006, DOI 10.15415/JOTITT.2017.52006]
   Malik PK, 2020, INT J WIREL INF NETW, V27, P411, DOI 10.1007/s10776-020-00482-8
   Malik PK, 2011, INT J MICROW WIREL T, V3, P701, DOI 10.1017/S1759078711000791
   Malik & Singh, 2019, INT J RECENT TECHNOL, V8, P5135, DOI [10.35940/ijrte.B2871.078219, DOI 10.35940/IJRTE.B2871.078219]
   Mallick S, 2008, PROCEEDINGS OF ICECE 2008, VOLS 1 AND 2, P205, DOI 10.1109/ICECE.2008.4769201
   Matz G, 2007, IEEE T WIREL COMMUN, V6, P1921, DOI 10.1109/TWC.2007.360393
   Mawatwal K, 2020, IEEE ACCESS, V8, P46682, DOI 10.1109/ACCESS.2020.2976553
   Mawatwal K, 2017, IEEE WIREL COMMUN LE, V6, P70, DOI 10.1109/LWC.2016.2631535
   Mehmood Y, 2013, LARGE SCALED MULTIUS
   Michailow N, 2014, IEEE T COMMUN, V62, P3045, DOI 10.1109/TCOMM.2014.2345566
   Mirzaei J, 2019, IEEE T COMMUN, V67, P1045, DOI 10.1109/TCOMM.2018.2875724
   Ogundile OO, 2016, IEEE ACCESS, V4, P8805, DOI 10.1109/ACCESS.2016.2633285
   Ogundile OO, 2015, IET COMMUN, V9, P2077, DOI 10.1049/iet-com.2015.0234
   Osseiran A, 2014, IEEE COMMUN MAG, V52, P26, DOI 10.1109/MCOM.2014.6815890
   Ozdemir MK, 2007, IEEE COMMUN SURV TUT, V9, P18, DOI 10.1109/COMST.2007.382406
   Park S, 2015, IEEE T SIGNAL PROCES, V63, P3032, DOI 10.1109/TSP.2015.2416684
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Pi ZY, 2011, IEEE COMMUN MAG, V49, P101, DOI 10.1109/MCOM.2011.5783993
   Qi CH, 2011, INT CONF ACOUST SPEE, P3488
   Qin QB, 2018, IEEE ACCESS, V6, P33740, DOI 10.1109/ACCESS.2018.2843783
   Rahim A., 2019, INT J ENG ADV TECHNO, DOI 10.35940/ijeat.A1031.1291S619
   Rajagopal S, 2011, GLOB TELECOMM CONF
   Rappaport TS, 2014, IEEE SPECTRUM, V51, P34, DOI 10.1109/MSPEC.2014.6882985
   Rappaport TS, 2013, IEEE ACCESS, V1, P335, DOI 10.1109/ACCESS.2013.2260813
   Riadi A, 2020, SMART INNOV SYST TEC, V147, P440, DOI 10.1007/978-3-030-21009-0_43
   Roh W, 2014, IEEE COMMUN MAG, V52, P106, DOI 10.1109/MCOM.2014.6736750
   Rutherford JJ, 2010, IEEE ENG MED BIOL, V29, P19, DOI 10.1109/MEMB.2010.936550
   Samsung Electronics Co, 2015, 5G VIS WHIT PAP
   Sathananthan K, 2001, IEEE VTS VEH TECHNOL, P2329, DOI 10.1109/VTC.2001.957164
   Shaik N, 2020, INT J ADV SCI TECHNO, V29, P8469
   Tiwari Praveen, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P24, DOI 10.1109/ICCAKM46823.2020.9051556
   Tomba L, 1998, IEEE T COMMUN, V46, P580, DOI 10.1109/26.668721
   Uwaechia AN, 2019, IEEE ACCESS, V7, P35072, DOI 10.1109/ACCESS.2019.2904596
   VANDEBEEK JJ, 1995, 1995 IEEE 45TH VEHICULAR TECHNOLOGY CONFERENCE - COUNTDOWN TO THE WIRELESS TWENTY-FIRST CENTURY, VOLS 1-2, P815, DOI 10.1109/VETEC.1995.504981
   Wei P, 2016, IEEE T COMMUN, V64, P4331, DOI 10.1109/TCOMM.2016.2598568
   Wu D, 2016, IEEE GLOBE WORK
   Wu SP, 2004, IEEE T COMMUN, V52, P1988, DOI 10.1109/TCOMM.2004.836441
   Wu XZ, 2013, IEEE J SEL AREA COMM, V31, P399, DOI 10.1109/JSAC.2013.SUP.0513036
   Xu BY, 2014, IEEE T IND INFORM, V10, P1578, DOI 10.1109/TII.2014.2306382
   Xu P, 2015, IEEE T VEH TECHNOL, V64, P610, DOI 10.1109/TVT.2014.2322654
   Zhang L, 2018, IEEE T COMMUN, V66, P1205, DOI 10.1109/TCOMM.2017.2771242
   Zhang N, 2015, IEEE COMMUN MAG, V53, P59, DOI 10.1109/MCOM.2015.7120046
   Zhang X, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417854
   Zhang Y, 2012, IEEE NETWORK, V26, P6, DOI 10.1109/MNET.2012.6201210
   Zhenghe Feng, 1999, Wireless Personal Communications, V11, P79, DOI 10.1023/A:1018642207792
   Zhou ZY, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P344, DOI 10.1109/IFITA.2009.368
NR 112
TC 27
Z9 27
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28789
EP 28827
DI 10.1007/s11042-021-11128-z
EA JUN 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000660815700004
DA 2024-07-18
ER

PT J
AU Vijayvergia, A
   Kumar, K
AF Vijayvergia, Aditya
   Kumar, Krishan
TI Selective shallow models strength integration for emotion detection
   using GloVe and LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Sentiment analysis; Emotion detection;
   Recurrent Neural network; Optimized feature extraction
ID RECOGNITION
AB Text analysis has gained immense popularity due to the widespread use of the internet and unrestricted access to people's opinions provided by social media. Analyzing public emotions in real-time can enable us to predict problematic situations like civil unrest that may arise in the future allowing us to take measures to prevent or handle them. This paper proposes a novel technique for emotion detection that can be used in real-time due to its comparatively much smaller run time and smaller memory size. Present well-performing models for emotion detection are incapable of being used in real-time due to the incorporation of large deep learning models that make them considerably slower. This work proposes a technique to use multiple shallow models to surpass the performance of a single large model by selectively combining their strengths and disregarding their weaknesses. These shallow models work independently which allows them to be run in parallel to ensure a smaller execution time. This combined proposal achieved 86.16% accuracy in 00.98 milliseconds per input. Therefore, the experiments show that the proposed model outperforms state-of-the-art models. Moreover, the computational cost shows that the proposal may used for real time applications.
C1 [Vijayvergia, Aditya] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX USA.
   [Kumar, Krishan] Natl Inst Technol Uttarakhand, Srinagar, Garhwal, India.
C3 Texas A&M University System; Texas A&M University College Station;
   National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand
RP Kumar, K (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, Garhwal, India.
EM vijayvergia.aditya15@gmail.com; kkberwal@nituk.ac.in
RI Berwal, Krishan/AAC-3473-2020
OI Berwal, Krishan/0000-0002-7068-6541
CR [Anonymous], 2014, CLP 2014
   Ansari, 2018, 2 IEEE C INF COMM TE
   Araque O, 2017, TASS 2017 WORKSH SEM, P71
   Athar, P ACL
   Baktha K, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P2047, DOI 10.1109/ICCSP.2017.8286763
   Balahur A, 2011, LECT NOTES COMPUT SC, V6716, P27, DOI 10.1007/978-3-642-22327-3_4
   Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007
   Burget R, 2011, RADIOENGINEERING, V20, P39
   Caschera MC, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P137, DOI 10.1145/3012071.3012089
   Ghazi D., 2010, P NAACL HLT 2010 WOR, P140
   Hancock JT, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P929
   Kumar Krishan, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P671, DOI 10.1007/978-981-15-0751-9_62
   Kumar K, 2017, 2017 9 INT C ADV PAT, P1
   Kumar S, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Minaee S., 2020, Deep learning based text classification: A comprehensive review
   Oyebamiji OK, 2019, J COMPUT SCI-NETH, V30, P194, DOI 10.1016/j.jocs.2018.12.007
   Sharma, 2017, C INF COMM TECHN CIC, P1
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Singh H, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P29, DOI 10.1145/3154979.3154996
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Sykora MD, 2013, IADIS-INT J COMPUT S, V8, P106
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wadawadagi R, 2020, ARTIF INTELL REV, V53, P6155, DOI 10.1007/s10462-020-09845-2
   Wang X, 2013, P 2 INT C COMP SCI E
   Yang H, 2012, BIOMED INFORM INSIGH, V5, P17, DOI 10.4137/BII.S8948
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
NR 27
TC 21
Z9 21
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28349
EP 28363
DI 10.1007/s11042-021-10997-8
EA JUN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657588300002
DA 2024-07-18
ER

PT J
AU Regaya, Y
   Fadli, F
   Amira, A
AF Regaya, Yousra
   Fadli, Fodil
   Amira, Abbes
TI Point-Denoise: Unsupervised outlier detection for 3D point clouds
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic envelope; Isolation forest; 3D point cloud; Denoising; Outlier
   detection; Unsupervised machine learning; Point-Denoise
ID ALGORITHM
AB 3D point cloud denoising is an increasingly demanding field as such type of data structure is getting more attention in perceiving the 3D environment for diverse applications. Despite their novelty, recently proposed solutions are still modest in terms of effectiveness and robustness, especially for scenes corrupted with a massive amount of noise. The encountered challenges are mainly due to the data acquisition process and the little-to-no knowledge of the statistical data distribution. In this paper, two promising unsupervised machine learning techniques are investigated, which are the Isolation Forest (If) and the Elliptic Envelope (EE). Each of these techniques detects noise using different philosophies. If uses a forest of iTrees; while EE uses a learned imaginary elliptic. The proposed solution, named Point-Denoise, tunes both techniques and fuses them at the decision-level. Although the solution simplicity, Point-Denoise reports superior results to state-of-the-art techniques. For evaluation purposes, both synthetic and real data are used. The chosen synthetic data is the ModelNet40 benchmark, which is augmented with a Gaussian and emulated 3D scanner noise with three different standard deviations: 0.5%, 1.0%, and 1.5% assessing the robustness of the proposed methodology. Meanwhile, the real data is collected from the Qatar University campus. Considering that a massive amount of noise already corrupts real data at acquisition time, no additional noise is augmented. Point-Denoise outperforms state-of-the-art solutions (i.e., traditional filtering, supervised, and unsupervised learning techniques) by attaining a 0.24 distance error and achieving a 48.93% enhancement.
C1 [Regaya, Yousra] Qatar Univ, Comp Sci & Engn Dept, Doha, Qatar.
   [Fadli, Fodil] Qatar Univ, Dept Architecture & Urban Planning, Coll Engn, Doha, Qatar.
   [Amira, Abbes] De Montfort Univ, Inst Artificial Intelligence, Leicester, Leics, England.
C3 Qatar University; Qatar University; De Montfort University
RP Regaya, Y (corresponding author), Qatar Univ, Comp Sci & Engn Dept, Doha, Qatar.
EM yregaya@qu.edu.qa
RI Fadli, Fodil/AAF-4259-2020
CR Alvarez, 2018, ARXIV180903664
   Amira, 2019, 2019 INT S SYST ENG, P1
   [Anonymous], TECH27 COM RESOURCE
   Brownlee J., 2020, One-class Classification algorithms for imbalanced datasets
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen Y, 2021, VIROL SIN, V36, P365, DOI 10.1007/s12250-020-00250-1
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112316
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Digne J, 2017, IMAGE PROCESS ON LIN, V7, P278, DOI 10.5201/ipol.2017.179
   Domingues R, 2018, PATTERN RECOGN, V74, P406, DOI 10.1016/j.patcog.2017.09.037
   Duan CJ, 2018, IEEE GLOB CONF SIG, P725, DOI 10.1109/GlobalSIP.2018.8646331
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Han XF, 2018, MULTIMED TOOLS APPL, V77, P17397, DOI 10.1007/s11042-017-5310-9
   Han XF, 2017, SIGNAL PROCESS-IMAGE, V57, P103, DOI 10.1016/j.image.2017.05.009
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hoyle B, 2015, MON NOT R ASTRON SOC, V452, P4183, DOI 10.1093/mnras/stv1551
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Javaheri Alireza, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P1, DOI 10.1109/ICMEW.2017.8026263
   Khan SS, 2014, KNOWL ENG REV, V29, P345, DOI 10.1017/S026988891300043X
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Levin D., 1998, Mathematics of Computation, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Li JX, 2019, ADV PHOTONICS, V1, DOI 10.1117/1.AP.1.4.046001
   Liu FT, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133363
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Liu KQ, 2019, IEEE ACCESS, V7, P23270, DOI 10.1109/ACCESS.2019.2899674
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Rousseeuw PJ, 1999, TECHNOMETRICS, V41, P212, DOI 10.2307/1270566
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Wand M, 2008, COMPUT GRAPH-UK, V32, P204, DOI 10.1016/j.cag.2008.01.010
   Wang Q, 2019, ADV ENG INFORM, V39, P306, DOI 10.1016/j.aei.2019.02.007
   Zhou LY, 2020, IEEE ACCESS, V8, P30436, DOI 10.1109/ACCESS.2020.2972269
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 37
TC 7
Z9 11
U1 5
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28161
EP 28177
DI 10.1007/s11042-021-10924-x
EA MAY 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000656384900004
DA 2024-07-18
ER

PT J
AU Dammak, S
   Mliki, H
   Fendri, E
AF Dammak, Sahar
   Mliki, Hazar
   Fendri, Emna
TI Gender effect on age classification in an unconstrained environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age classification; Gender estimation; VGG-16; MB-LBP; SVM; VGG-face
ID FEATURES
AB The face aging process is subject to multiple influences. This may probably involve several inherited and various environmental and biological factors like the differences observed between males and females. In fact, male and female facial skin differs as far as the type, the consistency and the sensitivity to external factors is concerned. In this paper, we proposed a new age classification method that consists of classifying human faces into various age groups by exploring the correlation between age and gender information. Moreover, we suggested a two-level age classification to reduce confusion between age groups. Our experiments were conducted on the Adience benchmark and the FG-Net dataset for the age classification and on the Groups and FERET datasets for the gender estimation. The experimental results reveal the good performance of our method while identifying the age groups in challenging contexts.
C1 [Dammak, Sahar] Univ Sfax, MIRACL FSEG, Fac Econ & Management Sfax, Rd Airport Km 4, Sfax 3018, Tunisia.
   [Mliki, Hazar] Univ Sfax, MIRACL FSEG, Natl Sch Elect & Telecommun Sfax, Rd Tunis City El Ons, Sfax 3018, Tunisia.
   [Fendri, Emna] Univ Sfax, MIRACL FSEG, Fac Sci Sfax, Rd Sokra Km 3, Sfax 3018, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Universite de Sfax; Multimedia,
   InfoRmation Systems & Advancing Computing Laboratory (MIRACL);
   Universite de Sfax; Faculty of Sciences Sfax; Multimedia, InfoRmation
   Systems & Advancing Computing Laboratory (MIRACL)
RP Dammak, S (corresponding author), Univ Sfax, MIRACL FSEG, Fac Econ & Management Sfax, Rd Airport Km 4, Sfax 3018, Tunisia.
EM sahardammak@fsegs.u-sfax.tn
RI Mliki, Hazar/ABF-7500-2021
OI Mliki, Hazar/0000-0002-0285-0944; Dammak, Sahar/0000-0003-1812-8355;
   Emna, Fendri/0000-0002-2328-2616
CR Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   Agbo-Ajala O, 2021, ARTIF INTELL REV, V54, P179, DOI 10.1007/s10462-020-09855-0
   [Anonymous], 2003, STAT PATTERN RECOGNI
   [Anonymous], 2008, LABELED FACES WILD D
   Aslam A, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013012
   Aslam A, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053023
   Baez-Suarez A., 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P769, DOI 10.1007/978-3-319-50835-1_69
   Burrus C. S., 2015, Introduction to wavelets and wavelet transforms. A primer
   Chen LM, 2018, SIGNAL IMAGE VIDEO P, V12, P1531, DOI 10.1007/s11760-018-1309-6
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dagher I, 2019, EXPERT SYST, V36, DOI 10.1111/exsy.12372
   Duan MX, 2018, NEUROCOMPUTING, V275, P448, DOI 10.1016/j.neucom.2017.08.062
   Dwivedi N, 2019, ADV INTELL SYST COMP, V741, P1089, DOI 10.1007/978-981-13-0761-4_102
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fu X., 2018, MATH PROBL ENG, V2018
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jagtap J, 2016, COGN SYST RES, V40, P116, DOI 10.1016/j.cogsys.2016.05.002
   Jung M, 2020, AUTOMAT CONSTR, V114, DOI 10.1016/j.autcon.2020.103177
   Kemelmacher-Shlizerman I, 2014, PROC CVPR IEEE, P3334, DOI 10.1109/CVPR.2014.426
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levi G, 2015, IEEE COMPUT SOC CONF
   Liu KH, 2019, IEEE T IMAGE PROCESS, V28, P5187, DOI 10.1109/TIP.2019.2916768
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Minaei S, 2022, INT J SPORT NUTR EXE, V32, P16, DOI 10.1123/ijsnem.2021-0090
   Mliki H, 2020, SIGNAL IMAGE VIDEO P, V14, P1345, DOI 10.1007/s11760-020-01680-w
   Ng C.-B., 2019, IOP C SERIES MAT SCI, V495, P012
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Ruder S., ARXIV160904747
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smulyan H, 2001, J AM COLL CARDIOL, V37, P1374, DOI 10.1016/S0735-1097(01)01166-4
   Sveikata Kestutis, 2011, Stomatologija, V13, P113
   Tajbakhsh N, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101693
   Vijayan M, 2020, MULTIMED TOOLS APPL, V79, P34835, DOI 10.1007/s11042-020-08977-5
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Yuan J, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107131
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
NR 43
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28001
EP 28014
DI 10.1007/s11042-021-11060-2
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000655574500004
DA 2024-07-18
ER

PT J
AU Singh, I
   Jindal, R
AF Singh, Indu
   Jindal, Rajni
TI Expectation maximization clustering and sequential pattern mining based
   approach for detecting intrusive transactions in databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Database intrusion detection; Database security; Expectation
   maximization clustering; Data dependency mining; Sequential pattern
   mining; Anomaly detection
AB Database security is pertinent to every organisation with the onset of increased traffic over large networks especially the internet and increase in usage of cloud based transactions and interactions. Greater exposure of organisations to the cloud implies greater risks for the organisational as well as user data. In this paper, we propose a novel approach towards database intrusion detection systems (DIDS) based on Expectation maximization Clustering and Sequential Pattern Mining (EMSPM). This approach unlike any other does not have records and assumes a predetermined policy to be maintained in an organisational database and can operate seamlessly on databases that follow Role Based Access Control as well as on those which do not conform to any such access control and restrictions. This is achieved by focusing on pre-existing logs for the database and using the Expectation maximization clustering algorithm to allot role profiles according to the database user's activities. These clusters and patterns are then processed into an algorithm that prevents generation of unwanted rules followed by prevention of malicious transactions. Assessment into the accuracy of EMSPM over sets of synthetically generated transactions yielded propitious results with accuracies over 93%.
C1 [Singh, Indu; Jindal, Rajni] Delhi Technol Univ, Dept Comp Sci Engn, Delhi 110042, India.
C3 Delhi Technological University
RP Singh, I (corresponding author), Delhi Technol Univ, Dept Comp Sci Engn, Delhi 110042, India.
EM indusingh@dtu.ac.in; rajnijindal@dce.ac.in
RI Singh, Indu/AAA-1680-2022
OI Singh, Indu/0000-0002-3635-173X
CR AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Bertino E, 2005, 21ST ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P155
   Bertino E, 2005, IEEE T DEPEND SECURE, V2, P2, DOI 10.1109/TDSC.2005.9
   Bilmes JA., 1998, INTCOMPUT SCIINST, V4, P126
   Bu SJ, 2020, INFORM SCIENCES, V512, P123, DOI 10.1016/j.ins.2019.09.055
   Cappelli DM., 2012, CERT GUIDE INSIDER T
   Cardenas A. A., 2011, P 6 ACM S INF COMP C, P355, DOI DOI 10.1145/1966913.1966959
   Chen MS, 1996, IEEE T KNOWL DATA EN, V8, P866, DOI 10.1109/69.553155
   Chung ChristinaYip., 1999, Proceedings of the Integrity and Internal Control in Information System, P159
   Corney M., 2011, P 9 AUSTRALASIAN INF, P23
   Debar H, 1999, COMPUT NETW, V31, P805, DOI 10.1016/S1389-1286(98)00017-6
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DENNING DE, 1987, IEEE T SOFTWARE ENG, V13, P222, DOI 10.1109/TSE.1987.232894
   Do CB, 2008, NAT BIOTECHNOL, V26, P897, DOI 10.1038/nbt1406
   Doroshenko ME, 2014, 2014 INTERNATIONAL CONFERENCE LASER OPTICS, DOI 10.1109/LO.2014.6886227
   El Assaad H, 2016, COMPUT STAT DATA AN, V103, P206, DOI 10.1016/j.csda.2016.05.007
   Fournier-Viger P., 2017, DATA SCI PATTERN REC, V1, P54, DOI DOI 10.1007/978-3-030-04921-8_4
   Hashemi S, 2008, EXPERT SYST, V25, P460, DOI 10.1111/j.1468-0394.2008.00467.x
   Hastie T., 2009, The Elements of Statistical Learning
   Heady R., 1990, The Architecture of a Network Level Intrusion Detection System (No. LASUB93219)
   Höglund AJ, 2000, IEEE IJCNN, P411
   Hu Y, 2003, SEVENTH INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P329
   Hu Y., 2004, SAC 04, P711
   Jiawei Han, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P355
   Kamra A, 2008, VLDB J, V17, P1063, DOI 10.1007/s00778-007-0051-4
   Kim TY, 2019, COMM COM INF SC, V1142, P131, DOI 10.1007/978-3-030-36808-1_15
   Kuang F-J., 2017, J. Netw. Intell, V2, P195
   Lan GC, 2014, APPL INTELL, V41, P439, DOI 10.1007/s10489-014-0530-4
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Liao HJ, 2013, J NETW COMPUT APPL, V36, P16, DOI 10.1016/j.jnca.2012.09.004
   Liu Pei-yu, 2011, Proceedings of the 2011 International Symposium on Information Technology in Medicine and Education (ITME 2011), P103, DOI 10.1109/ITiME.2011.6130794
   Lunt TeresaF., 1992, REAL TIME INTRUSION
   Luo CN, 2005, SIAM PROC S, P415
   Mazzawi H, 2017, PROC INT CONF DATA, P1140, DOI 10.1109/ICDE.2017.158
   McLachlan GJ, 2008, WILEY SER PROBAB ST, P365
   Mitra P, 2003, PATTERN RECOGN LETT, V24, P863, DOI 10.1016/S0167-8655(02)00198-8
   Neal RM., 1998, Learning in Graphical Models
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Ordonez C., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P590, DOI 10.1145/584792.584889
   Panigrahi S, 2013, INFORM SYST FRONT, V15, P35, DOI 10.1007/s10796-010-9252-2
   Pei J, 2004, IEEE T KNOWL DATA EN, V16, P1424, DOI 10.1109/TKDE.2004.77
   Pei J, 2001, PROC INT CONF DATA, P215
   Rahman MM, 2019, INFORM SCIENCES, V479, P76, DOI 10.1016/j.ins.2018.11.026
   Rahman MM, 2018, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INFORMATION MANAGEMENT AND COMMUNICATION (IMCOM 2018), DOI 10.1145/3164541.3164627
   Rashid T, 2016, MIST'16: PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON MANAGING INSIDER SECURITY THREATS, P47, DOI 10.1145/2995959.2995964
   Ronao CA, 2016, INFORM SCIENCES, V369, P238, DOI 10.1016/j.ins.2016.06.038
   Sallam A, 2019, PROCEEDINGS OF THE NINTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY '19), P133, DOI 10.1145/3292006.3300039
   Sallam A, 2016, WIRES DATA MIN KNOWL, V6, P231, DOI 10.1002/widm.1195
   Sandhu R., 2000, Symposium on Access Control Models and Technologies: Proceedings of the fifth ACM workshop on Role-based access control, V26, P47, DOI 10.1145/344287.344301
   Sandhu RS, 1996, COMPUTER, V29, P38, DOI 10.1109/2.485845
   Shirkhorshidi AS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144059
   Shou ZY, 2018, TRANSPORT RES C-EMER, V96, P122, DOI 10.1016/j.trc.2018.09.018
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Sohrabi M, 2014, J INTELL INF SYST, V42, P619, DOI 10.1007/s10844-013-0286-z
   Srikant R, 1996, LNCS, P1, DOI DOI 10.1007/BFB0014140
   Srivastava A, 2006, J COMPUT, V1, P8, DOI 10.4304/jcp.1.4.8-17
   Subudhi S., 2019, J KING SAUD UNIV-COM
   Talpade R, 1999, IEEE SYMP COMP COMMU, P442, DOI 10.1109/ISCC.1999.780942
   Yip RW, 1998, 11TH IEEE COMPUTER SECURITY FOUNDATIONS WORKSHOP - PROCEEDINGS, P179, DOI 10.1109/CSFW.1998.683168
   Zamanian Z, 2019, LECT NOTES ELECTR EN, V481, P59, DOI 10.1007/978-981-13-2622-6_6
NR 61
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27649
EP 27681
DI 10.1007/s11042-021-10786-3
EA MAY 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652940300001
DA 2024-07-18
ER

PT J
AU Gong, JL
   Chen, T
   Zhang, YF
AF Gong, Jinliang
   Chen, Tao
   Zhang, Yanfei
TI Complex lane detection based on dynamic constraint of the double
   threshold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex environments; Lane line detection; Region of interest; Canny
   operator; Kalman filter; Hough transform; Lane correction
AB In order to adapt to various complex lane environments, a general fast lane extraction algorithm was proposed. Firstly, according to the mutability of the local gray value and the characteristics of image saliency, the collected road image was preprocessed, and the region of interest was obtained by the proposed double threshold algorithm. Only in the significant region of the road were the image gray value change and image smoothing carried out to solve the problems of consuming too much time and poor noise resistance in lane detection. The lane line edge was then extracted based on the improved Canny operator. When the Otsu threshold was selected, the Kalman filter algorithm was introduced to quickly predict the optimal threshold of the subsequent image sequence in accordance with the characteristics of optimized autoregressive data processing.. Finally, for the straight line fitted by the Hough transform, an effective multi-layer evaluation function was established to realize the online correction of lane lines. Compared with the traditional lane line extraction algorithm, the experimental results show that the proposed algorithm has better accuracy, real-time performance and robustness.
C1 [Gong, Jinliang; Chen, Tao] Shandong Univ Technol, Sch Mech Engn, Zhangdian Dist 255049, Zibo, Peoples R China.
   [Zhang, Yanfei] Shandong Univ Technol, Sch Agr Engn & Food Sci, Zhangdian Dist 255049, Zibo, Peoples R China.
C3 Shandong University of Technology; Shandong University of Technology
RP Zhang, YF (corresponding author), Shandong Univ Technol, Sch Agr Engn & Food Sci, Zhangdian Dist 255049, Zibo, Peoples R China.
EM gjlwing@qq.com
RI yang, zhou/JKI-3744-2023; Gong, Jinliang/AAJ-9605-2020; Li,
   Juan/JEO-6872-2023; LI, Wenhui/JCD-9947-2023
FU National Natural Science Foundation of China [61303006]; Top Talents
   Program for One Case One Discussion of Shandong Province; Research Award
   Fund for Outstanding Young Scholars of Shandong Province [BS2012ZZ009];
   National Key Research and Development Program in Shandong Province
   [2019GNC106127]
FX This work was funded by the National Natural Science Foundation of China
   (61303006), Top Talents Program for One Case One Discussion of Shandong
   Province, The Research Award Fund for Outstanding Young Scholars of
   Shandong Province (Grant No. BS2012ZZ009), National Key Research and
   Development Program in Shandong Province (2019GNC106127).
CR Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Babashakoori S, 2019, MEASUREMENT, V141, P364, DOI 10.1016/j.measurement.2019.04.051
   ChamberlandRobert A, 2020, MED PHYS, V47, P3402, DOI [10.1016/j.neucom.2020.10.009, DOI 10.1016/J.NEUCOM.2020.10.009]
   Cui R, 2015, P 2015 INT C ART INT, P554, DOI [10.2991/aiie-15.2015.144, DOI 10.2991/AIIE-15.2015.144]
   Du XX, 2016, MACH VISION APPL, V27, P175, DOI 10.1007/s00138-015-0735-5
   Gong SJ, 2019, J ENG-JOE, P543, DOI 10.1049/joe.2018.9377
   Gonzalez CI, 2016, SOFT COMPUT, V20, P773, DOI 10.1007/s00500-014-1541-0
   Huang L, 2019, COMPUTER DIGITAL ENG, V47, P451
   Jiao XY, 2019, P I MECH ENG D-J AUT, V233, P2301, DOI 10.1177/0954407019866989
   Lee C, 2018, IEEE T INTELL TRANSP, V19, P4043, DOI 10.1109/TITS.2018.2791572
   Li L, 2016, IET INTELL TRANSP SY, V10, P545, DOI 10.1049/iet-its.2015.0173
   Lv C, 2018, IEEE-CAA J AUTOMATIC, V5, P58, DOI 10.1109/JAS.2017.7510745
   Lyu P, 2019, CHINESE J ELECTRON, V28, P344, DOI 10.1049/cje.2019.01.005
   Narote SP, 2018, PATTERN RECOGN, V73, P216, DOI 10.1016/j.patcog.2017.08.014
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Pare S, 2019, IEEE-CAA J AUTOMATIC, V6, P1471, DOI 10.1109/JAS.2017.7510697
   Pei S., 2018, INT J PRECIS AGR AVI, V1, P51
   [秦煜 Qin Yu], 2017, [计算机工程与科学, Computer Engineering and Science], V39, P1495
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Sangeetha D, 2019, J REAL-TIME IMAGE PR, V16, P957, DOI 10.1007/s11554-016-0582-2
   Wang P., 2019, INT J PRECISION AGR, V2, P62
   Wang Qidong, 2019, China Mechanical Engineering, V30, P393, DOI 10.3969/j.issn.1004-132X.2019.04.003
   Wei Y., 2018, HIGH TECHNOLOGY COMM, V28, P867
   Xiao X., 2016, COMPUTER AIDED DRAFT, V26, P18
   Xin C, 2019, B SURVEYING MAPPING, P52
   Xiong, 2017, P 2017 17 IEEE INT C, V2017, P1565, DOI [10.1109/ICCT.2017.8359886, DOI 10.1109/ICCT.2017.8359886]
   Xu XB, 2019, SENSOR REV, V39, P708, DOI 10.1108/SR-10-2018-0255
   [宣寒宇 Xuan Hanyu], 2017, [计算机科学, Computer Science], V44, P305
   Yoo JH, 2017, IEEE T INTELL TRANSP, V18, P3254, DOI 10.1109/TITS.2017.2679222
   Yu J., 2019, J TONGJI U NATURAL S, V47, P213
   Zhang T, 2018, P I MECH ENG G-J AER, V232, P3024, DOI 10.1177/0954410017723359
   Zhao Zhiguo, 2018, Journal of Mechanical Engineering, V54, P166, DOI 10.3901/JME.2018.24.166
   Zhou H., 2020, COMPUT ENG DESIGN, V41, P1719
NR 34
TC 1
Z9 1
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27095
EP 27113
DI 10.1007/s11042-021-10978-x
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650129400002
DA 2024-07-18
ER

PT J
AU Faragallah, OS
   Elaskily, MA
   Alenezi, AF
   El-sayed, HS
   Kelash, HM
AF Faragallah, Osama S.
   Elaskily, Mohamed A.
   Alenezi, Abdullah F.
   El-sayed, Hala S.
   Kelash, Hamdy M.
TI Quadruple histogram shifting-based reversible information hiding
   approach for digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram shifting; Predictive error; Hiding payload
AB Nowadays, data hiding techniques are one of the most growing researching areas. This paper introduces a quadruple histogram shifting-based reversible data embedding approach for digital images. Pixel differences distribution is utilized for maximizing the hiding payload capacity while preserving minimum degradations for stego-images. The improved histogram-based reversible data embedding algorithm is designed with the potential of maximizing the hiding payload capacity while keeping a perfect stego-image quality with data lossless. The proposed algorithm utilizes a 3 x 3 -box predictive filter and can hide 2-bits per pixel to increase the payload capacity. Firstly, an embedding phase has been performed by applying a numerical ordering strategy of the pixels to be predicted by the 3-by-3 box filter. The proposed algorithm is performing this ordering strategy in four stages to avoid affecting the follow-up prediction of all other pixels. In the other side, an extracting phase has been performed by reversing the four stages to generate the embedded data. The comparison with state-of-the-art schemes is performed to validate and guarantee the prevalence of the improved histogram-based reversible data embedding approach. The obtained test results demonstrated and confirmed that the proposed improved histogram-based reversible data embedding approach not only can improve the payload capacity but also can save the stego-image quality.
C1 [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, POB 11099, At Taif 21944, Saudi Arabia.
   [Elaskily, Mohamed A.] Elect Res Inst ERI, Dept Informat, Cairo, Egypt.
   [Alenezi, Abdullah F.; Kelash, Hamdy M.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [El-sayed, Hala S.] Menoufia Univ, Dept Elect Engn, Fac Engn, Shibin Al Kawm 32511, Egypt.
C3 Taif University; Egyptian Knowledge Bank (EKB); Electronics Research
   Institute (ERI); Egyptian Knowledge Bank (EKB); Menofia University;
   Egyptian Knowledge Bank (EKB); Menofia University
RP Elaskily, MA (corresponding author), Elect Res Inst ERI, Dept Informat, Cairo, Egypt.
EM Eng_mohamed_elaskily@yahoo.com
RI Faragallah, Osama S./AHB-8031-2022; Elaskily, Mohamed A./AAA-8852-2022;
   El-Sayed, Hala S./GXG-7641-2022
OI Faragallah, Osama S./0000-0003-1982-335X; Elaskily, Mohamed
   A./0000-0002-9136-0970; El-Sayed, Hala S./0000-0002-2776-783X
FU Taif University, Taif, Saudi Arabia [TURSP-2020/08]
FX This study was funded by the Deanship of Scientific Research, Taif
   University Researchers Supporting Project number (TURSP-2020/08), Taif
   University, Taif, Saudi Arabia.
CR Almangush HM, 2015, INT REV COMPUTERS SO, V10
   Amirtharajan, 2017, J ARTIF INTEL, V10, P22, DOI [10.3923/jai.2017.22.31, DOI 10.3923/JAI.2017.22.31]
   Arunkumar S., 2018, INT J PURE APPL MATH, V119, P13233
   Asamoah D., 2018, INT J COMPUTER APPL, V181, P0975
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Dittmann J, 2003, PROC SPIE, V5020, P653, DOI 10.1117/12.476824
   Du R, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P893
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Kim C, 2018, SEPARABLE REVERSIBLE, DOI [10.1016/j.displa.2018.04.002, DOI 10.1016/J.DISPLA.2018.04.002]
   Kim C, 2016, J REAL-TIME IMAGE PR, DOI DOI 10.1007/S11554-016
   Kim C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155336
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Puteaux P, 2016, INT CONF IMAG PROC
   Rani R, 2020, 7 IEEE INT C SIGN PR
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   van der Veen M, 2003, P SOC PHOTO-OPT INS, V5020, P1, DOI 10.1117/12.476858
   Welstead StephenT., 1999, Fractal and wavelet image compression techniques, P155, DOI DOI 10.1117/3.353798
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
NR 26
TC 6
Z9 6
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26297
EP 26317
DI 10.1007/s11042-021-10956-3
EA APR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645496900001
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI A high payload reversible data hiding algorithm for homomorphic
   encrypted absolute moment block truncation coding compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Absolute moment block truncation coding (AMBTC); Reversible data hiding
   in encrypted compressed images; Homomorphic encryption; Variable size
   secret message; Security analysis
AB With the aim to ensure privacy and security of secret message, an enhanced reversible data hiding algorithm in encrypted as well as compressed domain is proposed here. After compression of grey-scale image using absolute moment block truncation coding (AMBTC) method, pixels of AMBTC compressed image is segmented into two types - seed pixels (2(k) horizontal ellipsis 255) and remaining pixels are called non-seed pixels. Now, embedded k, (k >= 1) binary bits of secret message by changed over it into base(10) numeral framework at seed pixels of AMBTC compressed image whereas seed pixel is divided into two individual units which are encrypted through Paillier cryptosytem separately. Highlight of proposed method is to embed variable size secret message at seed pixels of AMBTC compressed image without any occurrence of overflow problem. Experimental study revealed that for all type of test images, proposed method altogether beated all the compared methods in its ability to embed secret message and precisely recover it with a PSNR value of infinity dB between cover image and reconstructed image too.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
RI Bhardwaj, Rupali/AAO-6850-2021
CR Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Bhardwaj R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023017
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin J, 2019, J INF HIDING MULTIME, V10, P408
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P14151, DOI 10.1007/s11042-016-3815-2
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Tian C, 2020, MULTIMED TOOLS APPL, V79, P7515, DOI 10.1007/s11042-019-08530-z
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu JY, 2020, MULTIMED TOOLS APPL, V79, P22727, DOI 10.1007/s11042-020-08987-3
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao B, 2010, IEEE ICC
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng W., 2020, J NETWORK INTELLIGEN, V5, P77
NR 34
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26161
EP 26179
DI 10.1007/s11042-021-10722-5
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645531100001
DA 2024-07-18
ER

PT J
AU Al-Haj, A
   Abdel-Nabi, H
AF Al-Haj, Ali
   Abdel-Nabi, Heba
TI An efficient watermarking algorithm for medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image security; Reversible data hiding; Reversibility;
   Separability; Spatial domain watermarking; Encrypted domain
   watermarking; Embedding capacity; Entropy
AB Medical images exchanged over vulnerable networks are sensitive to modifications or tampering which could lead to misdiagnosis, risking the lives of the patients. Therefore, to provide safe and secure transmission of medical images, key security requirements such as authenticity, integrity, and confidentiality must be addressed. In this paper, a novel and efficient algorithm is proposed which provides security services for transmitted medical images in tele-medicine applications. The proposed algorithm employs joint encryption/watermarking procedures to provide the required security services, as well as to provide control access privileges at the receiving side. The algorithm is based on reversible data hiding principles that guarantee the extraction of the hidden data while restoring the original image unaffected. The embedded data is basically two watermarks; a spatial domain watermark and an encrypted domain watermark. The dual watermarks allow the authenticity and integrity of the transmitted medical images to be verified in the spatial and encrypted domains. The proposed algorithm has been extensively evaluated using three performance metrics; embedding capacity, visual image quality, and entropy. The ability of the algorithm to fulfill the security, reversibility, and separability requirements has been validated.
C1 [Al-Haj, Ali; Abdel-Nabi, Heba] Princess Sumaya Univ Technol, Dept Comp Engn, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology
RP Al-Haj, A (corresponding author), Princess Sumaya Univ Technol, Dept Comp Engn, Amman 11941, Jordan.
EM ali@psut.edu.jo; heb20179004@std.psut.edu.jocom
OI Abdel-Nabi, Heba/0000-0001-6238-3244; Al-Haj, Ali/0000-0002-4215-2286
CR Abdel-Nabi Hiba, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P802, DOI 10.1109/ICITECH.2017.8079950
   Abdel-Nabi H, 2017, INT CONF INFORM COMM, P147, DOI 10.1109/IACS.2017.7921962
   Al-Haj A, 2016, PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM2016)
   Al-Haj A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT (ICIM 2017), P437, DOI 10.1109/INFOMAN.2017.7950423
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Fujiyoshi M, 2013, IEEE INT CONF MULTI
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma GY, 2019, SIGNAL PROCESS-IMAGE, V75, P55, DOI 10.1016/j.image.2019.03.013
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2020, MULTIMED TOOLS APPL, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2020, IEEE ACCESS, V8, P23209, DOI 10.1109/ACCESS.2020.2969252
   Stallings W., 2013, Cryptography and network security: Principles and practice, V6th
   Xiong LZ, 2018, MULTIDIM SYST SIGN P, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yin ZX, 2017, MULTIMED TOOLS APPL, V76, P3899, DOI 10.1007/s11042-016-4049-z
   Zhang S, 2014, J APPL MATH, V2014
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 25
TC 5
Z9 5
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26021
EP 26047
DI 10.1007/s11042-021-10801-7
EA APR 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000644761700004
DA 2024-07-18
ER

PT J
AU Liu, J
   Chen, AB
   Zhou, GX
   Chen, WJ
   Peng, N
   Yan, N
AF Liu, Jing
   Chen, Aibin
   Zhou, Guoxiong
   Chen, Wenjie
   Peng, Ning
   Yan, Na
TI Dermatoscopic image melanoma recognition based on CFLDnet fusion network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dermatoscopy image; Melanoma recognition; Densenet; Convolutional block
   attention module; Focal loss
ID CANCER STATISTICS; SKIN-CANCER; CLASSIFICATION
AB As a common skin disease, malignant melanoma has attracted great attention in dermatology with high morbidity and mortality. Traditional medical diagnoses rely on clinical experience and have a certain subjective bias. Aiming at the problem of similarity between classes of melanoma dermoscopic images and the imbalance of lesion data set, we propose a CFLDnet-based dermoscopic image lesion classification model, it mainly uses the improved convolutional block attention (CBA) DenseNet algorithm to enhance beneficial features. To better integrate the attention module into DenseNet without increasing too many parameters and wasting the computing resources, we discussed three types of variant networks derived from the CFLDnet. Moreover, to balance the different categories of the data set, we also use the Sample Focal Loss (SFL) to calculate the effective sample size of the data set and smooth the focal loss function. Large numbers of comparative experiments were done based on the ISIC2018 task3 dataset, the average recognition accuracy of the CFLDnet network proposed in this paper is 86.89%, which is much higher than other similar methods (VGG16, ResNet50, InceptionV3 and DenseNet121 with cross-entropy loss function).
C1 [Liu, Jing; Chen, Aibin; Zhou, Guoxiong; Chen, Wenjie; Peng, Ning; Yan, Na] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Hunan, Peoples R China.
C3 Central South University of Forestry & Technology
RP Chen, AB (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Hunan, Peoples R China.
EM hotaibin@163.com
RI yan, na/HDM-3747-2022; yan, na/JAC-6056-2023
OI Zhou, Guoxiong/0000-0002-5142-4845
FU Scientific Innovation Fund for Post-graduates of Central South
   University of Forestry and Technology [CX20192014]
FX This work supported in part by Scientific Innovation Fund for
   Post-graduates of Central South University of Forestry and Technology
   CX20192014.
CR Abbasi NR, 2004, JAMA-J AM MED ASSOC, V292, P2771, DOI 10.1001/jama.292.22.2771
   Ba J., 2014, ARXIV PREPRINT ARXIV
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeSilva MS, 2019, SKIN LESION SEGMENTA
   Dickson PV, 2011, SURG ONCOL CLIN N AM, V20, P1, DOI 10.1016/j.soc.2010.09.007
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gehring J, 2017, PR MACH LEARN RES, V70
   Goyal M., 2018, Deep neural network ensemble by data augmentation and bagging for skin lesion classification
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Henning JS, 2007, J AM ACAD DERMATOL, V56, P45, DOI 10.1016/j.jaad.2006.09.003
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Khan MA, 2020, NEURAL COMPUT APPL, V32, P15929, DOI 10.1007/s00521-019-04514-0
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P293, DOI 10.1016/j.patrec.2019.11.034
   Khan MA, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12497
   Khan MA, 2019, MICROSC RES TECHNIQ, V82, P741, DOI 10.1002/jemt.23220
   Kitada S Iyatomi, 2018, SKIN LESION CLASSIFI
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu J, 2020, CMC-COMPUT MATER CON, V62, P1187, DOI 10.32604/cmc.2020.05883
   Marchesini R, 2002, MELANOMA RES, V12, P279, DOI 10.1097/00008390-200206000-00012
   Menzies SW, 1996, ARCH DERMATOL, V132, P1178, DOI 10.1001/archderm.132.10.1178
   Mishra N, 2018, ANN OPER RES, V270, P337, DOI 10.1007/s10479-016-2303-4
   Mnih V, 2014, ADV NEUR IN, V27
   Nasir M, 2020, CURR MED IMAGING, V16, P794, DOI 10.2174/1573405615666191223122401
   Nazar U, 2020, CURR MED IMAGING, V16, P823, DOI 10.2174/1573405615666191120110855
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schilling N, 2015, LECT NOTES ARTIF INT, V9285, P87, DOI 10.1007/978-3-319-23525-7_6
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   SILVERBERG E, 1990, CA-CANCER J CLIN, V40, P9, DOI 10.3322/canjclin.40.1.9
   Sorokin AJapa, 2018, LESION ANAL DIAGNOSI
   Sun LY, 2020, IEEE J BIOMED HEALTH, V24, P2303, DOI 10.1109/JBHI.2020.2964016
   Vaswani A, 2017, ADV NEUR IN, V30
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie FY, 2016, IEEE T BIO-MED ENG, V63, P1248, DOI 10.1109/TBME.2015.2493580
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zahoor S, 2020, CURR MED IMAGING, V16, P1187, DOI 10.2174/1573405616666200406110547
   Zhang X, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522978
NR 45
TC 2
Z9 3
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 25477
EP 25494
DI 10.1007/s11042-021-10920-1
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000640862600004
DA 2024-07-18
ER

PT J
AU Rohith, G
   Kumar, LS
AF Rohith, G.
   Kumar, Lakshmi Sutha
TI Super-resolution decision-making tool using deep convolution neural
   networks for panchromatic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution (SR); Decision-making tool; Deep CNN network; Raw
   panchromatic image; Adam optimizer
ID CLASSIFICATION
AB In this paper, a Deep Convolution Neural Network (CNN) based Super-Resolution (SR) decision-making tool is proposed for the raw panchromatic satellite image. Conventionally, human visual interpretation through spotting recognizable objects and visualizing the patterns at a certain zooming level in terms of sharp edges, blurs, etc., is in practice at the cost of time consumption and expertise knowledge requirement. A 10-layer deep convolutional neural network is carried out in three steps with inspiration from the categorical signature classification. In the first step, the higher the potential interpretive features for defining the pattern are analyzed. The cross-correlation of interpretative features with the trained images is done in the second step. In the final step, whether the SR technique application is inevitable for the image or not rendered is provided with an accuracy of 83.3% at a minimized loss. The proposed method is tested with seven state-of-the-art classifier architectures for the decision-making tool. The proposed method works well with the dataset considered counterfeiting other techniques.
C1 [Rohith, G.; Kumar, Lakshmi Sutha] Natl Inst Technol Puducherry, Dept Elect & Commun Engn, Pondicherry 609609, Karaikal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Puducherry
RP Rohith, G (corresponding author), Natl Inst Technol Puducherry, Dept Elect & Commun Engn, Pondicherry 609609, Karaikal, India.
EM rohith.giridharan@gmail.com
RI Kumar, Lakshmi Sutha/P-9990-2019; Rohith, Gorrepati/ABH-7282-2020
OI Rohith, Gorrepati/0000-0003-1081-027X; Kumar, Lakshmi
   Sutha/0000-0002-9069-3132
CR Alhassan V, 2020, NEURAL COMPUT APPL, V32, P8529, DOI 10.1007/s00521-019-04349-9
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bhosle K, 2019, J INDIAN SOC REMOTE, V47, P1949, DOI 10.1007/s12524-019-01041-2
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Borzov SM, 2018, OPTOELECTRON INSTRUM, V54, P582, DOI [10.3103/S8756699018060079, 10.15372/AUT20180607]
   Bouros P, 2019, EDBT ICDT WORKSH
   Chen ST, 2021, MULTIMED TOOLS APPL, V80, P1859, DOI 10.1007/s11042-020-09480-7
   Djerriri K, 2018, INT GEOSCI REMOTE SE, P2479, DOI 10.1109/IGARSS.2018.8518501
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dubey SR, 2020, IEEE T NEUR NET LEAR, V31, P4500, DOI 10.1109/TNNLS.2019.2955777
   Singh PG, 2021, INT J REMOTE SENS, V42, P1096, DOI 10.1080/01431161.2020.1823041
   Guo W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010131
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jiang JH, 2019, IEEE ACCESS, V7, P20607, DOI 10.1109/ACCESS.2019.2896128
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lee S, 2020, J EUR ACAD DERMATOL, V34, P1842, DOI 10.1111/jdv.16185
   Li, 2019, IEEE GEOSCI REMOTE S, V16
   Li T, 2019, MULTIMED TOOLS APPL, V78, P3411, DOI 10.1007/s11042-018-5986-5
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Lin LL, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-01666-9
   Liu F, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050867
   Liu N, 2018, IEEE ACCESS, V6, P11215, DOI 10.1109/ACCESS.2018.2798799
   Merugu S, 2021, J INDIAN SOC REMOTE, V49, P703, DOI 10.1007/s12524-020-01265-7
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Navin MS, 2020, MULTIMED TOOLS APPL, V79, P29751, DOI 10.1007/s11042-020-09531-z
   Nijhawan R, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS (SITIS), P192, DOI 10.1109/SITIS.2017.41
   Paul A, 2021, NEURAL COMPUT APPL, V33, P1575, DOI 10.1007/s00521-020-05069-1
   Riquelme D, 2020, AI-BASEL, V1, P28, DOI 10.3390/ai1010003
   Rohith G, 2021, VISUAL COMPUT, V37, P1965, DOI 10.1007/s00371-020-01957-8
   Rohith G., 2020, MIND 2020 COMMUNICAT, DOI [10.1007/978-981-15-6315-7_28, DOI 10.1007/978-981-15-6315-7_28]
   Sabol P, 2019, IEEE IJCNN
   Sasidhar TT, 2019, INT CONF COMPUT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su TF, 2019, MULTIMED TOOLS APPL, V78, P34173, DOI 10.1007/s11042-019-08224-6
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P82, DOI 10.1109/TGRS.2019.2931801
   Tantalaki N, 2019, J AGRIC FOOD INF, V20, P344, DOI 10.1080/10496505.2019.1638264
   Tognetti L, 2021, J DERMATOL SCI, V101, P115, DOI 10.1016/j.jdermsci.2020.11.009
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Unnikrishnan A, 2019, MULTIMED TOOLS APPL, V78, P18379, DOI 10.1007/s11042-019-7179-2
   Xu WJ, 2018, INT GEOSCI REMOTE SE, P8889, DOI 10.1109/IGARSS.2018.8518855
   Xu YH, 2019, IEEE J-STARS, V12, P1709, DOI 10.1109/JSTARS.2019.2911113
   Yang J, 2018, P INT COMP SOFTW APP, P492, DOI 10.1109/COMPSAC.2018.00076
   Yang M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/2836064
   Zhao LJ, 2019, MULTIMED TOOLS APPL, V78, P9667, DOI 10.1007/s11042-018-6548-6
NR 50
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25033
EP 25085
DI 10.1007/s11042-021-10861-9
EA APR 2021
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518600001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Ji, JY
   Zhu, YY
AF Wang, Xuanyin
   Ji, Jiayu
   Zhu, Yanyu
TI A zoom tracking algorithm based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time zoom tracking; deep learning; trace curve; auto focus
ID REAL-TIME IMPLEMENTATION
AB Zoom tracking is an essential and critical technology of digital cameras. Zoom tracking is typically achieved by moving the zoom and focus motors in lenses following the "trace curve". The trace curve shows the in-focus motor positions versus the zoom motor positions for a specific object distance. Considering the limitations of the existing methods in responsiveness and accuracy, we propose a new zoom tracking algorithm based on deep learning, DPZT (Deep Predictive Zoom Tracking). The input of DPZT is a two-dimensional vector, consisting of image distance in two specific focus length. The structure of DPZT is a network with three hidden layers, which consists of 30, 30 and 3 neurons of each layer. Our method optimizes the mean offsets to 0.842 steps. With sufficient amount of field experiments, the newly proposed algorithm has proven its superiority as compared to the existing ones. Particularly, the architecture solves the one-to-many map problem at the root cause. Despite the slight increase in the storage capacity, the unprecedented enhancement of tracking accuracy and responsiveness outweighs the side effect.
C1 [Wang, Xuanyin; Ji, Jiayu; Zhu, Yanyu] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Ji, JY (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Hangzhou 310027, Peoples R China.
EM xywang@zju.edu.cn; 11625039@zju.edu.cn; zhuyanyu0877@outlook.com
RI wang, xuan/JBJ-6948-2023; wang, xuan/GXF-3679-2022
FU National Natural Science Foundation of China [52075483]
FX This project is supported by National Natural Science Foundation of
   China (Grant No. 52075483).
CR [Anonymous], RETHINKING INCEPTION
   [Anonymous], 2016, LEARNING COMPOSE NEU
   Bahdanau D., NEURAL MACHINE TRANS, P1
   Bochkovskiy A., 2020, YOLOV4 OPTIMAL SPEED, DOI [DOI 10.48550/ARXIV.2004.10934,ARXIV, 10.48550/arXiv.2004.10934]
   Cao Y, 2018, RES IMPLEMENTATION A
   Chen YL, 2012, SENSORS-BASEL, V12, P2373, DOI 10.3390/s120302373
   Cheng HY, 2011, IEEE T INTELL TRANSP, V12, P1462, DOI 10.1109/TITS.2011.2160171
   Com T. G., 2014, DISTRIBUTED REPRESEN, V32
   Cong BD, 2013, REAL TIME ZOOM TRACK, V16, P1261
   Fayman JA, 2001, MACH VISION APPL, V13, P25, DOI 10.1007/PL00013268
   Foresti GL, 2009, SENSORS-BASEL, V9, P2252, DOI 10.3390/s90402252
   Gamadia M, 2004, PROC SPIE, V5297, P10, DOI 10.1117/12.519600
   Ghimire S, 2020, MULTIMED TOOLS APPL, V79, P30163, DOI 10.1007/s11042-020-09482-5
   Head GR, 1995, AUTOMATIC CONTROL CA, V410, P4
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai PK, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P286, DOI 10.1109/AVSS.2016.7738018
   Peddigari V, 2005, IEEE T CONSUM ELECTR, V51, P1051, DOI 10.1109/TCE.2005.1561824
   Peddigari V, 2005, PROC SPIE, V5671, P8, DOI 10.1117/12.583354
   Peddigari V, 2007, J REAL-TIME IMAGE PR, V2, P45, DOI 10.1007/s11554-007-0036-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y., 2015, DEEPID3 FACE RECOGNI, P2
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tordoff BJ, 2007, COMPUT VIS IMAGE UND, V105, P131, DOI 10.1016/j.cviu.2006.09.006
   Weston J., 2015, Towards ai-complete question answering: A set of prerequisite toy tasks
   Zhong L. A. Lin, 2015, J APPL OPT, V36
   Zhu Y, 2017, HIGH DEFJ WANGINITIO
   Zou TY, 2012, SENSORS-BASEL, V12, P8073, DOI 10.3390/s120608073
NR 29
TC 2
Z9 2
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 25087
EP 25105
DI 10.1007/s11042-021-10868-2
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639743500004
DA 2024-07-18
ER

PT J
AU Hou, Y
   Zhao, Y
   Shan, X
AF Hou, Yu
   Zhao, Yong
   Shan, Xin
TI 3D mesh segmentation via <i>L</i><sub>0</sub>-constrained random walks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh segmentation; L-0 constraint; Sparsity; Random walks
AB 3D mesh segmentation is a challenging problem in computer graphics, computer vision, and multimedia. In this paper, we cast mesh segmentation as a L-0 minimization problem using random walks and L-0 norm. In random walks method, the probabilities of random walks change smoothly over the whole model, which may lead to inaccurate segmentation boundaries. To attain a perception-aware result, the changes of probabilities should comply with mesh geometry. That is, the changes of probabilities near region boundaries should be more drastic than those inside the regions. Therefore, we introduce a L-0 constraint to reflect the sparsity of probability changes, and identify region boundaries more precisely. Experimental results show that the proposed algorithm is effective, robust, and outperforms the state-of-the-art methods on various 3D meshes.
C1 [Hou, Yu; Zhao, Yong] Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
   [Shan, Xin] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
C3 Ocean University of China; Ocean University of China
RP Zhao, Y (corresponding author), Ocean Univ China, Sch Math Sci, Qingdao, Peoples R China.
EM zhaoyong@ouc.edu.cn
OI zhao, yong/0000-0002-5617-0004
FU Natural Science Foundation of Shandong Province, China [ZR2018MF006];
   National Natural Science Foundation of China [11701538]
FX This research is supported in part by Natural Science Foundation of
   Shandong Province, China (ZR2018MF006), and National Natural Science
   Foundation of China (11701538).
CR [Anonymous], P IEEE C COMP VIS PA, P8599
   [Anonymous], P IEEE C COMP VIS PA, P6584
   [Anonymous], P IEEE C COMP VIS PA, P8620
   [Anonymous], P GRAPH INT KEL CAN, P23
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131
   Benhabiles H, 2011, COMPUT GRAPH FORUM, V30, P2170, DOI 10.1111/j.1467-8659.2011.01967.x
   Benjamin W, 2011, COMPUT GRAPH FORUM, V30, P2097, DOI 10.1111/j.1467-8659.2011.02060.x
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chen HK, 2018, MULTIMED TOOLS APPL, V77, P17223, DOI 10.1007/s11042-017-5287-4
   Chen MJ, 2019, COMPUT AIDED GEOM D, V72, P19, DOI 10.1016/j.cagd.2019.04.021
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   de Goes F, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392389
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fan LB, 2011, COMPUT GRAPH FORUM, V30, P603, DOI 10.1111/j.1467-8659.2011.01895.x
   George D, 2018, GRAPH MODELS, V96, P1, DOI 10.1016/j.gmod.2018.01.001
   Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098
   Guo K, 2018, GRAPH MODELS, V96, P30, DOI 10.1016/j.gmod.2018.02.001
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   Haiyong Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12793, DOI 10.1109/CVPR42600.2020.01281
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Ji ZP, 2006, COMPUT GRAPH FORUM, V25, P283, DOI 10.1111/j.1467-8659.2006.00947.x
   Jiao X, 2018, J COMPUT APPL MATH, V329, P134, DOI 10.1016/j.cam.2017.05.007
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183
   Lai YK, 2009, COMPUT AIDED GEOM D, V26, P665, DOI 10.1016/j.cagd.2008.09.007
   Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liu XP, 2015, COMPUT GRAPH-UK, V46, P99, DOI 10.1016/j.cag.2014.09.019
   Lv JJ, 2012, COMPUT GRAPH FORUM, V31, P2241, DOI 10.1111/j.1467-8659.2012.03217.x
   Meng M, 2011, COMPUT ANIMAT VIRT W, V22, P334, DOI 10.1002/cav.422
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Shu ZY, 2020, IEEE T VIS COMPUT GR, V26, P2671, DOI 10.1109/TVCG.2019.2892076
   Shu ZY, 2016, COMPUT AIDED GEOM D, V43, P39, DOI 10.1016/j.cagd.2016.02.015
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Taime A, 2018, MULTIMED TOOLS APPL, V77, P27143, DOI 10.1007/s11042-018-5911-y
   Wang YH, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508393
   Xie ZG, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12740
   Xu HT, 2017, IEEE I CONF COMP VIS, P2717, DOI 10.1109/ICCV.2017.294
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu WW, 2014, COMPUT GRAPH FORUM, V33, P107, DOI 10.1111/cgf.12436
   Xun Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13703, DOI 10.1109/CVPR42600.2020.01372
   Yamauchi H, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P236, DOI 10.1109/SMI.2005.21
   Yan DM, 2012, COMPUT AIDED DESIGN, V44, P1072, DOI 10.1016/j.cad.2012.04.005
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhang JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2167076.2167079
   Zhang JY, 2011, IEEE T VIS COMPUT GR, V17, P357, DOI 10.1109/TVCG.2010.57
   Zhang JY, 2010, COMPUT GRAPH FORUM, V29, P517, DOI 10.1111/j.1467-8659.2009.01621.x
   Zheng YY, 2012, IEEE T VIS COMPUT GR, V18, P1304, DOI 10.1109/TVCG.2011.140
   Zheng YY, 2010, COMPUT GRAPH FORUM, V29, P527, DOI 10.1111/j.1467-8659.2009.01622.x
NR 54
TC 4
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24885
EP 24899
DI 10.1007/s11042-021-10816-0
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700001
DA 2024-07-18
ER

PT J
AU Shi, H
   Wang, Y
   Li, YN
   Ren, YG
   Guo, C
AF Shi, Hui
   Wang, Ying
   Li, Yanni
   Ren, Yonggong
   Guo, Cheng
TI Region-based reversible medical image watermarking algorithm for privacy
   protection and integrity authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image watermarking; Tamper detection; Privacy protection;
   Reversibility; High capacity and security
AB Medical images are widely used in telemedicine, sharing and electronic transmission between hospitals. While enjoying convenience, medical images also face privacy disclosure, illegal copy and malicious tamper, etc. It is highly important to ensure privacy and integrity of medical images. Cogitating the above needs, a reversible medical image watermarking algorithm for privacy protection and integrity authentication is proposed. Firstly, the medical image is divided into the ROI (Region of Interest) and RONI (Region of Non-Interest) based on active contour model. Then, the proposed "Three-Dimensional Watermarks" are generated, including authentication watermark, restoration watermark and privacy watermark, which are produced by the novel Parallel Lattice Hash Function, the proposed Neighborhood Difference Method, and the proposed encryption algorithm, respectively. Moreover, "Double-Layer Reversible Embedding Strategy Based on Difference Expansion" is modified in ROI to improve embedding capacity, and "Histogram Modification Reversible Embedding Strategy of Difference Image" is modified to adaptively acquire four or more peak points, which is more flexible than common algorithms. Experimental results confirm the efficient of the proposed scheme, and demonstrate it not only realizes privacy protection, integrity authentication, reversibility, but also holds the characteristics of higher security, larger capacity and better restoration quality.
C1 [Shi, Hui; Wang, Ying; Li, Yanni; Ren, Yonggong] Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
   [Guo, Cheng] Dalian Univ Technol, Sch Software Technol, Dalian 116620, Peoples R China.
C3 Liaoning Normal University; Dalian University of Technology
RP Shi, H; Ren, YG (corresponding author), Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com; ryg@lnnu.edu.cn
FU Liaoning Provincial Social Science Planning Fund [L19BTQ001]
FX This work was supported by Liaoning Provincial Social Science Planning
   Fund under Grant L19BTQ001.
CR Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Anjum, 2019, INT C ADV COMP DAT S, P92
   [Anonymous], 2017, MEDICAL IMAGE DATABA
   Davie B, 2001, IEEE INTERNET COMPUT, V5, P42, DOI 10.1109/4236.935176
   Fang LL, 2018, COMPUT MATH APPL, V75, P4286, DOI 10.1016/j.camwa.2018.03.029
   Farfoura Mahmoud E., 2010, 2010 International Symposium on Parallel and Distributed Processing with Applications (ISPA 2010), P563, DOI 10.1109/ISPA.2010.63
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Gomez-Coronel, 2015, 10 INT S MED INF PRO, P28717
   Harjito B, 2019, P INT S EL SMART DEV
   He HJ, 2009, LECT NOTES COMPUT SC, V5806, P132
   He HJ, 2008, LECT NOTES COMPUT SC, V5284, P147
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Huang YL, 2011, INT J INNOV COMPUT I, V7, P4027
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Nazari M, 2021, MULTIMED TOOLS APPL, V80, P10615, DOI 10.1007/s11042-020-10032-2
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Prasetyo H, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P181, DOI 10.1109/IC3INA.2018.8629513
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Sabbane F, 2019, MULTIMED TOOLS APPL, V78, P34129, DOI 10.1007/s11042-019-08134-7
   Shi H, 2017, MULTIMED TOOLS APPL, V76, P6941, DOI 10.1007/s11042-016-3328-z
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Soni GK., 2020, SMART SYSTEMS IOT IN, P483, DOI 10.1007/978-981-13-8406-6_46
   Soualmi A, 2018, ADV INTELL SYST COMP, V723, P693, DOI 10.1007/978-3-319-74690-6_68
   Soualmi A, 2018, ARAB J SCI ENG, V43, P7893, DOI 10.1007/s13369-018-3246-7
   [苏文桂 Su Wengui], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P1498
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P4307, DOI 10.1007/s11042-020-09941-z
   Thanki R, 2019, MULTIMED TOOLS APPL, V78, P13905, DOI 10.1007/s11042-018-6746-2
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Thanki R, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0795-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Ustubioglu A, 2017, J DIGIT IMAGING, V30, P665, DOI 10.1007/s10278-017-9960-y
   Varalakshmi LM, 2013, MULTIMED TOOLS APPL, V64, P717, DOI 10.1007/s11042-011-0963-2
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Wu CH, 2001, PATTERN RECOGN, V34, P1319, DOI 10.1016/S0031-3203(00)00100-X
   Wu YD, 2005, IEEE T CIRC SYST VID, V15, P161, DOI 10.1109/TCSVT.2004.839978
   [项世军 Xiang Shijun], 2016, [计算机学报, Chinese Journal of Computers], V39, P571
   Xiaoqi Wu, 2019, Innovation in Medicine and Healthcare Systems, and Multimedia. Proceedings of KES-InMed-19 and KES-IIMSS-19 Conferences. Smart Innovation, Systems and Technologies (SIST 145), P115, DOI 10.1007/978-981-13-8566-7_11
   Yang YJ, 2019, SOFT COMPUT, V23, P8907, DOI 10.1007/s00500-018-3489-y
   Yin ZX, 2018, MULTIMED TOOLS APPL, V77, P18067, DOI 10.1007/s11042-017-4957-6
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 47
TC 6
Z9 6
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24631
EP 24667
DI 10.1007/s11042-021-10853-9
EA APR 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000638027800001
DA 2024-07-18
ER

PT J
AU Guenounou, A
   Aillerie, M
   Mahrane, A
   Bouzaki, M
   Boulouma, S
   Charles, JP
AF Guenounou, Abderrezak
   Aillerie, Michel
   Mahrane, Achour
   Bouzaki, Moustafa
   Boulouma, Sabri
   Charles, Jean-Pierre
TI Human home daily living activities recognition based on a LabVIEW
   implemented hidden Markov model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Daily living activities; HMM; LabVIEW; Machine learning; Sensor data;
   Smart home
AB The recognition of human daily living activities within a house represents an efficient tool to model its power consumption and is also a good indicator for monitoring the health status of the inhabitants. The problematic of activities recognition in smart homes has been extensively addressed in several studies. In this paper, we present an original interactive tool developed under LabVIEW environment with a graphical user interface allowing the modeling of the daily living activities, based on a machine learning Hidden Markov Model. After an overview of the advantage for the consideration of this model in current human activities, we examine how the associated scientific problematic can find an interest and a solution by the integration of machine learning tools. Thus, the application based on a Hidden Markov model approach, is presented and evaluated using two sets of experimental data from literature. Comparing with results obtained by other daily living activities recognition methods, we point out the very satisfactory recognition performance of the Hidden Markov Model and the likelihood of our development associated to a user-friendly graphical interface. This work opens the way to applications dedicated to the supervision of human daily living activities and / or to the management of the electrical consumption within a smart home equipped with non-intrusive sensors.
C1 [Guenounou, Abderrezak; Bouzaki, Moustafa] Univ BLIDA 1, Fac Technol, Dept Energies Renouvelables, Blida 09000, Algeria.
   [Guenounou, Abderrezak; Aillerie, Michel; Bouzaki, Moustafa; Charles, Jean-Pierre] Univ Lorraine, LMOPS, Lab Mat Opt Photon & Syst, EA 4423, F-57070 Metz, France.
   [Guenounou, Abderrezak; Aillerie, Michel; Bouzaki, Moustafa; Charles, Jean-Pierre] Univ Paris Saclay, Cent Supelec, LMOPS, Lab Mat Opt Photon & Syst, F-57070 Metz, France.
   [Mahrane, Achour; Boulouma, Sabri] EPST Ctr Dev Energies Renouvelables CDER, Unite Dev Equipements Solaires UDES, Bou Ismail 42415, Tipaza, Algeria.
C3 Universite de Lorraine; Universite Paris Saclay; Universite Paris
   Saclay; Universite Paris Cite; Universite de Lorraine
RP Guenounou, A (corresponding author), Univ BLIDA 1, Fac Technol, Dept Energies Renouvelables, Blida 09000, Algeria.; Guenounou, A (corresponding author), Univ Lorraine, LMOPS, Lab Mat Opt Photon & Syst, EA 4423, F-57070 Metz, France.; Guenounou, A (corresponding author), Univ Paris Saclay, Cent Supelec, LMOPS, Lab Mat Opt Photon & Syst, F-57070 Metz, France.
EM aguenounou@yahoo.fr
RI GUENOUNOU, ABDERREZAK/N-4593-2015; Salame, Chafic Touma/IQV-0202-2023
OI GUENOUNOU, ABDERREZAK/0000-0001-8139-2699; Salame, Chafic
   Touma/0000-0002-8476-1864; Boulouma, Sabri/0000-0002-5910-7561
CR Alaa M, 2017, J NETW COMPUT APPL, V97, P48, DOI 10.1016/j.jnca.2017.08.017
   Aldrich F., 2003, Inside the Smart Home, P17, DOI DOI 10.1007/1-85233-854-7_2
   Bitter R., 2007, LABVIEW ADV PROGRAMM, V2nd
   Brecha RJ, 2011, ENERG POLICY, V39, P2982, DOI 10.1016/j.enpol.2011.03.011
   Chernbumroong S, 2013, EXPERT SYST APPL, V40, P1662, DOI 10.1016/j.eswa.2012.09.004
   Cornuejols Antoine., 2002, Apprentissage artificiel : concepts et algorithmes (2002)
   Ferrández-Pastor F, 2017, J AMB INTEL HUM COMP, V8, P469, DOI 10.1007/s12652-016-0431-y
   Flach PA., 2011, ENCY MACHINE LEARNIN, P416, DOI [10.1007/978-0-387-30164-8_315, DOI 10.1007/978-0-387-30164-8_315]
   Fleury A, 2010, IEEE T INF TECHNOL B, V14, P274, DOI 10.1109/TITB.2009.2037317
   Geller H, 2004, ENERG POLICY, V32, P1437, DOI 10.1016/S0301-4215(03)00122-8
   Grewal JK, 2019, NAT METHODS, V16, P795, DOI 10.1038/s41592-019-0532-6
   Hellgren M, 2015, ENERGY USE CONSEQUEN, DOI [10.3384/diss.diva-122253, DOI 10.3384/DISS.DIVA-122253]
   Hu QR, 2013, IEEE T SMART GRID, V4, P1878, DOI 10.1109/TSG.2013.2258181
   Japkowicz N, 2006, AAAI 2006 WORKSH EV, V6
   Ordóñez FJ, 2013, SENSORS-BASEL, V13, P5460, DOI 10.3390/s130505460
   Kang J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071036
   Karaman S, 2014, MULTIMED TOOLS APPL, V69, P743, DOI 10.1007/s11042-012-1117-x
   Kim MJ, 2013, INDOOR BUILT ENVIRON, V22, P260, DOI 10.1177/1420326X12469733
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P18, DOI 10.1109/MIC.2020.2969610
   Liouane Zaineb, 2016, SENSORNETS 2016. Proceedings of the 5th International Conference on Sensor Networks, P214
   Ricquebourg V, 2006, 2006 1ST IEEE INTERNATIONAL CONFERENCE ON E-LEARNING IN INDUSTRIAL ELECTRONICS, P23, DOI 10.1109/ICELIE.2006.347206
   Sammut C., 2010, Encyclopedia of Machine Learning, P9
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Tahir SF, 2020, J AMB INTEL HUM COMP, V11, P2105, DOI 10.1007/s12652-019-01236-y
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   Ting K.M., 2010, Encyclopedia of Machine Learning, Precision, P780, DOI [10.1007/978-0-387-30164-8_651, DOI 10.1007/978-0-387-30164-8_651]
   van Kasteren TLM, 2011, ATL AMB PERVAS INTEL, V4, P165
   van Kasteren TLM, 2010, J AMB INTEL SMART EN, V2, P311, DOI 10.3233/AIS-2010-0070
   VANKASTEREN T, 2008, P 10 INT C UBIQUITOU
   Webb G.I., 2011, ENCY MACHINE LEARNIN, P209, DOI [DOI 10.1007/978-0-387-30164-8_157, 10.1007/978-0-387-30164-8_157]
   Webb GI, 2010, ENCY MACHINE LEARNIN, V829, DOI [10.1007/978-0-387-30164-8_702, DOI 10.1007/978-0-387-30164-8_702]
   Weber S, 2017, ENERG ECON, V68, P255, DOI 10.1016/j.eneco.2017.10.010
   Zhou B, 2016, RENEW SUST ENERG REV, V61, P30, DOI 10.1016/j.rser.2016.03.047
   Zipperer A, 2013, P IEEE, V101, P2397, DOI 10.1109/JPROC.2013.2270172
NR 34
TC 2
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24419
EP 24435
DI 10.1007/s11042-021-10814-2
EA APR 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000637475700001
DA 2024-07-18
ER

PT J
AU Kumar, BS
   Seetharaman, K
AF Kumar, B. Satheesh
   Seetharaman, K.
TI Video sequence feature extraction and segmentation using likelihood
   regression model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video sequence; Retrieval; Likelihood estimation; Regression model;
   Frame
AB The development of digital technology is utilized by people to capture and share video frames. At present, rather than capturing images, people are interested in recording video footage for exploring information. Here, retrieval of video from large databases is challenging due to the continuous frame count. To overcome these challenges associated with the retrieval of video from available databases, this research proposed a likelihood-based regression approach for video processing. To improve the retrieval accuracy of video sequences, the proposed method utilizes a likelihood estimation technique integrated with a regression model. The likelihood estimate measures the pixel level roughly for estimating the pixel range, after which the regression approach measures the pixel level for transforming certainly blurred and unwanted pixels. In the proposed likelihood regression approach, the video is converted into a video frame and stored in a database. Query frames are taken into account by the generated database depending on the features which are used for a given video to be retrieved. The significant video retrieval performance obtained from the simulation results for the proposed likelihood-based regression model shows that the proposed model performs well over the other state-of-the-art techniques.
C1 [Kumar, B. Satheesh] Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar, Tamil Nadu, India.
   [Seetharaman, K.] Annamalai Univ, Dept Comp & Informat Sci, Annamalainagar, Tamil Nadu, India.
C3 Annamalai University; Annamalai University
RP Kumar, BS (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar, Tamil Nadu, India.
EM vbsatheesh30@gmail.com; kseethaddeau@gmail.com
RI Kumar, B. Satheesh/GPK-7636-2022
OI Kumar, B. Satheesh/0000-0001-7964-616X
CR Aparajeeta J, 2018, EXPERT SYST APPL, V92, P317, DOI 10.1016/j.eswa.2017.09.049
   Araujo A, 2018, IEEE T CIRC SYST VID, V28, P1406, DOI 10.1109/TCSVT.2017.2667710
   Bouyahi Mohamed, 2020, Procedia Computer Science, V176, P10, DOI 10.1016/j.procs.2020.08.002
   Golgiyaz S, 2019, FUEL, V255, DOI 10.1016/j.fuel.2019.115827
   Gurkan F, 2021, NEUROCOMPUTING, V423, P284, DOI 10.1016/j.neucom.2020.09.072
   Hollink V, 2011, J AM SOC INF SCI TEC, V62, P691, DOI 10.1002/asi.21484
   Jamal Deen M, 2020, IEEE INTERNET THINGS
   Kovashka A, 2017, ADV COMPUT VIS PATT, P89, DOI 10.1007/978-3-319-50077-5_5
   Lee S, 2017, OPTIK, V150, P131, DOI 10.1016/j.ijleo.2017.09.101
   [刘冶 Liu Ye], 2016, [计算机科学, Computer Science], V43, P39
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Mahmoud-Ghoneim D, 2003, MAGN RESON IMAGING, V21, P983, DOI 10.1016/S0730-725X(03)00201-7
   Martins I, 2020, COMPUT VIS IMAGE UND, V200, DOI 10.1016/j.cviu.2020.103032
   Mirza A, 2020, IET IMAGE PROCESS, V14, P3444, DOI 10.1049/iet-ipr.2019.1070
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   P?rez-Aguila R, 2016, ADV ARTIFICIAL INTEL
   Palander TS, 2019, BIOSYST ENG, V180, P36, DOI 10.1016/j.biosystemseng.2019.01.011
   Patmanidis S, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105165
   Pun CM, 2016, J VIS COMMUN IMAGE R, V41, P391, DOI 10.1016/j.jvcir.2016.10.017
   Rajesh K, 2019, FUTURE GENER COMP SY, V98, P688, DOI 10.1016/j.future.2018.12.042
   Rao AS., 2014, IJCT, V13, P2277, DOI [10.24297/ijct.v13i12.5282, DOI 10.24297/IJCT.V13I12.5282]
   Rejeesh MR, 2019, MULTIMED TOOLS APPL, V78, P22691, DOI 10.1007/s11042-019-7577-5
   Revathi R., 2012, CS CSCP, P69
   Samet N, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1321, DOI 10.1109/SIU.2016.7495991
   Scherrer B, 2009, IEEE T MED IMAGING, V28, P1278, DOI 10.1109/TMI.2009.2014459
   Scipioni M, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103481
   Sharma VK, 2020, PATTERN RECOGN LETT, V140, P49, DOI 10.1016/j.patrec.2020.09.028
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Trede M, 2019, STAT PROBABIL LETT
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115858
   Wu L, 2019, IEEE T NEUR NET LEAR, V30, P3347, DOI 10.1109/TNNLS.2019.2891244
   Zhang CY, 2019, PATTERN RECOGN LETT, V123, P82, DOI 10.1016/j.patrec.2019.03.015
   Zhang CY, 2019, MULTIMED TOOLS APPL, V78, P30561, DOI 10.1007/s11042-018-6284-y
   Zhang T, 2012, IEEE ENG MED BIO, P3215, DOI 10.1109/EMBC.2012.6346649
NR 35
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24343
EP 24361
DI 10.1007/s11042-021-10829-9
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000636933000001
DA 2024-07-18
ER

PT J
AU Rani, A
   Jain, A
   Kumar, M
AF Rani, Anuj
   Jain, Ajit
   Kumar, Manoj
TI Identification of copy-move and splicing based forgeries using advanced
   SURF and revised template matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image manipulation; Enhanced SURF; Template matching; Copy-move forgery;
   Splicing detection; Forgery detection
ID IMAGE; AUTHENTICATION
AB Various image tampering detection approaches are used to find the variations or inconsistencies in statistical image features. But still these techniques lack behind to identify copy-move and splicing based manipulations. The manipulation in digital data encourages the crimes, particularly in the domain of image processing and computer vision-based applications. Therefore, to find image forgeries, new method needs to be designed so that originality of data is authenticated in the court of law or jurisdiction. To achieve, a pixel based forgery detection framework for copy-move and splicing based forgeries is suggested in this paper. Initially, pre-processing over image data is performed to enhance the textural information. The proposed system estimates various features using enhanced SURF and template matching for the identification of fake image regions. The relevant key parameters are estimated and compared with the calculated threshold value. The evaluation is carried out using CASIA forged image dataset. The results are evaluated and compared with other existing methods through a comprehensive set of experiments. The enhanced SURF method produces a forgery detection accuracy of 97%, while template matching gives 100% forgery detection. As a whole system, the accuracy is 97.5%. Thus, the demonstrated result shows that the proposed framework attains considerably more detection accuracy compared to other state-of-art techniques.
C1 [Rani, Anuj] GL Bajaj Inst Technol & Management, Dept Comp Sci, Greater Noida, UP, India.
   [Rani, Anuj] Bansathali Vidyapith, Tonk, Rajasthan, India.
   [Jain, Ajit] Bansathali Vidyapith, Dept Comp Sci, Tonk, Rajasthan, India.
   [Kumar, Manoj] Univ Petr & Energy Studies, Sch Comp Sci, Dehra Dun, Uttarakhand, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Jain, A (corresponding author), Bansathali Vidyapith, Dept Comp Sci, Tonk, Rajasthan, India.
EM anuanuj1989@gmail.com; ajitjain_2k@yahoo.co.in; wss.manojkumar@gmail.com
RI KUMAR, MANOJ/P-7489-2014; Jain, Ajit Kumar/GXG-9895-2022; Bueno, Regis
   Cortez/AAG-3852-2020
OI KUMAR, MANOJ/0000-0001-5113-0639; Jain, Ajit Kumar/0000-0001-7953-3157;
   Bueno, Regis Cortez/0000-0002-2923-4930
CR ABDELBASSE M, 2018, MULTIMED TOOLS APPL
   Abrahim AR, 2019, CLUSTER COMPUT, V22, P647, DOI 10.1007/s10586-017-1668-8
   Al azrak FM, 2020, WIRELESS PERS COMMUN, V110, P503, DOI 10.1007/s11277-019-06739-7
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Dang TT, 2014, SIGNAL PROCESS, V103, P127, DOI 10.1016/j.sigpro.2013.11.036
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Fadl SM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P253, DOI 10.1109/VCIP.2014.7051552
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hayat K, 2017, COMPUT ELECTR ENG, V62, P448, DOI 10.1016/j.compeleceng.2017.03.013
   Kumar M, 2019, INT J IMAGE GRAPH, V19, DOI 10.1142/S0219467819500141
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P243, DOI 10.1080/00450618.2017.1356871
   Kumar M, 2019, MULTIMED TOOLS APPL, V78, P12451, DOI 10.1007/s11042-018-6775-x
   Kumar M, 2019, AUST J FORENSIC SCI, V51, P119, DOI 10.1080/00450618.2017.1356868
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Ma, 2015, ADV SIGNAL PROCESSIN
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Mistry D., 2017, GRD JOURNALSGLOBAL R, V2, P7
   Pandey, 2014, 3 INT C FRONT INT CO, V327
   Parveen A., 2019, Iran Journal of Computer Science, V2, P89, DOI DOI 10.1007/S42044-019-00029-Y
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rao Y, 2016, IEEE INT WORKS INFOR
   Sadeghi S, 2017, MALAYS J COMPUT SCI, V30, P117, DOI 10.22452/mjcs.vol30no2.4
   Shen XJ, 2017, IET IMAGE PROCESS, V11, P44, DOI 10.1049/iet-ipr.2016.0238
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Yaduwanshi J, 2017, ADV INTELLIGENT SYST, V508
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 36
TC 24
Z9 25
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23877
EP 23898
DI 10.1007/s11042-021-10810-6
EA MAR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000633749600002
DA 2024-07-18
ER

PT J
AU Singh, S
   Ahuja, U
   Kumar, M
   Kumar, K
   Sachdeva, M
AF Singh, Sunil
   Ahuja, Umang
   Kumar, Munish
   Kumar, Krishan
   Sachdeva, Monika
TI Face mask detection using YOLOv3 and faster R-CNN models: COVID-19
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; YOLO v3; Faster R-CNN; Face mask detection; Deep learning
AB There are many solutions to prevent the spread of the COVID-19 virus and one of the most effective solutions is wearing a face mask. Almost everyone is wearing face masks at all times in public places during the coronavirus pandemic. This encourages us to explore face mask detection technology to monitor people wearing masks in public places. Most recent and advanced face mask detection approaches are designed using deep learning. In this article, two state-of-the-art object detection models, namely, YOLOv3 and faster R-CNN are used to achieve this task. The authors have trained both the models on a dataset that consists of images of people of two categories that are with and without face masks. This work proposes a technique that will draw bounding boxes (red or green) around the faces of people, based on whether a person is wearing a mask or not, and keeps the record of the ratio of people wearing face masks on the daily basis. The authors have also compared the performance of both the models i.e., their precision rate and inference time.
C1 [Singh, Sunil; Ahuja, Umang; Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Dept Informat Technol, Chandigarh, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Sachdeva, Monika] LKG Punjab Tech Univ, Dept Comp Sci & Engn, Kapurthala, Punjab, India.
C3 Panjab University; I. K. Gujral Punjab Technical University
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM sunil32123singh@gmail.com; umangahuja1203@gmail.com;
   munishcse@gmail.com; k.salujauiet@gmail.com; monasach1975@gmail.com
RI Kumar, Munish/P-7756-2018; Sachdeva, Monika/AAY-3623-2021; Kumar,
   Krishan/F-6049-2016
OI Kumar, Munish/0000-0003-0115-1620; Kumar, Krishan/0000-0001-9877-0238
CR Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jason, GENTLE INTRO TRANSFE
   Matuschek C, 2020, EUR J MED RES, V25, DOI 10.1186/s40001-020-00430-5
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   W H Organization, 2020, WH COR COVID 19
NR 10
TC 103
Z9 105
U1 3
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19753
EP 19768
DI 10.1007/s11042-021-10711-8
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000623716500005
PM 33679209
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Elakkiya, R
   Teja, KSS
   Deborah, LJ
   Bisogni, C
   Medaglia, C
AF Elakkiya, R.
   Teja, Kuppa Sai Sri
   Deborah, L. Jegatha
   Bisogni, Carmen
   Medaglia, Carlo
TI Imaging based cervical cancer diagnostics using small object
   detection-generative adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cervical cancer; Detection; Classification; Stage identification;
   Diagnosis; And prognosis
ID CLASSIFICATION
AB Cervical cancer is one of the curable cancers when it is diagnosed in the early stages. Pap smear test and visual inspection using acetic acid are the most common screening mechanism for the cervical lesion to categorize the cervical cells as normal, precancerous, or cancerous. However, most of the classification methods success depends on the accurate spotting and segmenting of cervical location. These challenges pave the way for sixty years of research in cervical cancer diagnosis, but still, accurate spotting of the cervical cell remains an open challenge. Moreover, state-of-the-art classification methods are developed based upon the extraction of manual annotations of features. In this paper, an effective hybrid deep learning technique using Small-Object Detection-Generative Adversarial Networks (SOD-GAN) with Fine-tuned Stacked Autoencoder (F-SAE) is developed to address the shortcomings mentioned above. The generator and discriminator of the SOD-GAN are developed using Region-based Convolutional Neural Network (RCNN). The model parameters are fine-tuned using F-SAE, and the hyperparameters of the SOD-GAN are normalized and optimized to make the lesion detection faster. The proposed approach automatically detects and classifies the cervical premalignant and malignant conditions based on deep features without any preliminary classification and segmentation assistance. Extensive experimentation has also been done with multivariate heterogeneous data, and the proposed approach has shown promising improvement in efficiency and reduces the time complexity.
C1 [Elakkiya, R.] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
   [Teja, Kuppa Sai Sri] SASTRA Deemed Univ, Dept Elect & Commun Engn, Thanjavur, India.
   [Deborah, L. Jegatha] Univ Coll Engn, Dept Comp Sci & Engn, Tindivanam, India.
   [Bisogni, Carmen] Univ Salerno, Fisciano, Italy.
   [Medaglia, Carlo] Link Campus Univ, Rome, Italy.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   University of Salerno
RP Elakkiya, R (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
EM elakkiya@cse.sastra.edu; 120004117@sastra.ac.in; blessesjeny@gmail.com;
   cbisogni@unisa.it; c.medaglia@unilink.it
RI Rajasekar, Elakkiya/IRZ-8510-2023; Bisogni, Carmen/GXG-4181-2022; R,
   Elakkiya/CAF-8407-2022
OI Rajasekar, Elakkiya/0000-0002-2257-0640; Bisogni,
   Carmen/0000-0003-1358-006X; R, Elakkiya/0000-0001-6276-9470; DEBORAH,
   JEGATHA/0000-0001-8069-3801
CR Aguirre AJ, 2017, CANCER CELL, V32, P185, DOI 10.1016/j.ccell.2017.07.007
   Aina OE, 2019, INT CONF ELECT COMP, DOI 10.1109/ICECCO48375.2019.9043220
   [Anonymous], 2018, P 2018 IISE ANN C
   Bagcchi S, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i5574
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bailey HH, 2016, J CLIN ONCOL, V34, P1803, DOI 10.1200/JCO.2016.67.2014
   Chandran KP, 2015, Int J Sci Eng Technol Res, V4, P3141
   Dasari S, 2015, CLIN CHIM ACTA, V445, P7, DOI 10.1016/j.cca.2015.03.005
   de Martel C, 2017, INT J CANCER, V141, P664, DOI 10.1002/ijc.30716
   Deng SP, 2016, IEEE ACM T COMPUT BI, V13, P27, DOI 10.1109/TCBB.2015.2476790
   Fatlawi HK, 2017, INT J COMPUTER TECHN, V4
   Fernandes K, 2017, LECT NOTES COMPUT SC, V10255, P243, DOI 10.1007/978-3-319-58838-4_27
   Ghebre RG, 2017, GYNECOL ONCOL REP, V21, P101, DOI 10.1016/j.gore.2017.07.009
   Hu LM, 2019, JNCI-J NATL CANCER I, V111, P923, DOI 10.1093/jnci/djy225
   Hu ZL, 2018, PATTERN RECOGN, V83, P134, DOI 10.1016/j.patcog.2018.05.014
   Jantzen J., 2005, Nature inspired Smart Information Systems (NiSIS 2005), P1
   Li C, 2019, THIRD INTERNATIONAL SYMPOSIUM ON IMAGE COMPUTING AND DIGITAL MEDICINE (ISICDM 2019), P102, DOI 10.1145/3364836.3364857
   Oak Pratik, 2020, Emerging Trends in Electrical, Communications, and Information Technologies. Proceedings of ICECIT-2018. Lecture Notes in Electrical Engineering (LNEE 569), P683, DOI 10.1007/978-981-13-8942-9_58
   Obukhova NA, 2017, PROC CONF OPEN INNOV, P345, DOI 10.23919/FRUCT.2017.8071332
   Sato M, 2018, ONCOL LETT, V15, P3518, DOI 10.3892/ol.2018.7762
   Singh SK, 2020, INT J HEALTHC INF SY, V15, P1, DOI 10.4018/IJHISI.2020040101
   Torheim T, 2017, ACTA ONCOL, V56, P806, DOI 10.1080/0284186X.2017.1285499
   Wang P, 2019, BIOMED SIGNAL PROCES, V48, P93, DOI 10.1016/j.bspc.2018.09.008
   William W, 2018, COMPUT METH PROG BIO, V164, P15, DOI 10.1016/j.cmpb.2018.05.034
   Win K.P., 2019, P 2019 4 INT C BIOM
   Wu W, 2017, IEEE ACCESS, V5, P25189, DOI 10.1109/ACCESS.2017.2763984
   Zhang L, 2017, IEEE J BIOMED HEALTH, V21, P1633, DOI 10.1109/JBHI.2017.2705583
NR 27
TC 21
Z9 21
U1 3
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 191
EP 207
DI 10.1007/s11042-021-10627-3
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000622247800001
DA 2024-07-18
ER

PT J
AU Wang, KS
   Wu, XJ
   Wang, H
   Kan, HB
   Kurths, J
AF Wang, Kunshu
   Wu, Xiangjun
   Wang, Hui
   Kan, Haibin
   Kurths, Jurgen
TI New color image cryptosystem via SHA-512 and hybrid domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; SHA-512; Discrete wavelet transform (DWT); Chaotic
   maps; Spatial domain
ID DNA-SEQUENCE OPERATION; HYPER-CHAOTIC SYSTEM; ENCRYPTION SCHEME; WAVELET
   TRANSFORM; ARNOLD TRANSFORM; ALGORITHM; MAP; COMPRESSION; BLEND; CODE
AB Most current image encryption algorithms directly confuse and/or diffuse the image pixels only in spatial domain which results in reducing storage efficiency and making the cipher-image incompressible. In this paper, we introduce a new color image encryption scheme based on the hash function SHA-512, discrete wavelet transform (DWT) and chaotic maps with excellent performance. Combining with the plain-image and the secret keys, the SHA-512 is employed to generate the new keys. In the proposed algorithm, both the 2D-LASM and the 2D-SIMM are used to generate the keystreams, where the initial values and parameters are produced by the SHA-512 hash value. The single-level DWT is applied to decompose the plain-image into four image sub-bands. Then these sub-bands are shuffled, minified, reversed and swapped by the keystreams. The image after inverse discrete wavelet transform (IDWT) reconstruction is further divided and diffused using the keystreams (more than 2(349)) in spatial domain. Experimental results and performance analysis demonstrate the proposed scheme is an efficient, secure and robust encryption mechanism. Besides, the duration of the experiment was relatively short and required only 0.3628 s on average.
C1 [Wang, Kunshu] Nankai Univ, Coll Software, Tianjin 300000, Peoples R China.
   [Wu, Xiangjun; Wang, Hui] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
   [Wu, Xiangjun; Kan, Haibin] Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China.
   [Kurths, Jurgen] Potsdam Inst Climate Impact Res PIK, D-14473 Potsdam, Germany.
   [Kurths, Jurgen] Humboldt Univ, Dept Phys, D-12489 Berlin, Germany.
C3 Nankai University; Henan University; Fudan University; Potsdam Institut
   fur Klimafolgenforschung; Humboldt University of Berlin
RP Wu, XJ (corresponding author), Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.; Wu, XJ (corresponding author), Fudan Univ, Shanghai Key Lab Intelligent Informat Proc, Sch Comp Sci, Shanghai 200433, Peoples R China.
EM wuhsiang@yeah.net
RI WANG, YONGJIA/KFQ-4823-2024; zhong, jing/KBP-7800-2024
OI Wu, Xiangjun/0000-0003-0371-8707
FU National Natural Science Foundation of China [61004006, 61203094]; China
   Postdoctoral Science Foundation [2013 M530181, 2015 T80396]; Program for
   Science & Technology Innovation Talents in Universities of Henan
   Province, China [14HASTIT042]; Foundation for University Young Key
   Teacher Program of Henan Province, China [2011GGJS-025]; Shanghai
   Postdoctoral Scientific Program [13R21410600]
FX This research was jointly supported by the National Natural Science
   Foundation of China (Grant Nos 61004006 and 61203094), China
   Postdoctoral Science Foundation (Grant Nos 2013 M530181 and 2015
   T80396), Program for Science & Technology Innovation Talents in
   Universities of Henan Province, China (Grant No 14HASTIT042), the
   Foundation for University Young Key Teacher Program of Henan Province,
   China (Grant No 2011GGJS-025), Shanghai Postdoctoral Scientific Program
   (Grant No 13R21410600).
CR Abdulla, EXPLOITING SIMILARIT
   Algredo-Badillo I, 2013, MICROPROCESS MICROSY, V37, P750, DOI 10.1016/j.micpro.2012.06.007
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bahrami S, 2013, OPTIK, V124, P3693, DOI 10.1016/j.ijleo.2012.11.028
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Lang J, 2015, OPT COMMUN, V338, P181, DOI 10.1016/j.optcom.2014.10.049
   Li PY, 2017, J VIS COMMUN IMAGE R, V44, P61, DOI 10.1016/j.jvcir.2017.01.021
   Li XW, 2016, OPT COMMUN, V381, P260, DOI 10.1016/j.optcom.2016.06.079
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu ZJ, 2013, OPT LASER ENG, V51, P967, DOI 10.1016/j.optlaseng.2013.02.015
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Olkkonen J., 2011, DISCRETE WAVELET TRA
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Radwan AG, 2016, J ADV RES, V7, P193, DOI 10.1016/j.jare.2015.07.002
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Singh H, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0110-y
   Singh H, 2015, OPT LASER ENG, V67, P145, DOI 10.1016/j.optlaseng.2014.10.011
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   Skrobek A, 2007, PHYS LETT A, V363, P84, DOI 10.1016/j.physleta.2006.10.081
   Stallings W., 2011, INT J ENG COMPUT SCI, V1, P121
   Sui LS, 2013, OPT LASER ENG, V51, P1297, DOI 10.1016/j.optlaseng.2013.06.005
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Tedmori S, 2014, INFORM SCIENCES, V269, P21, DOI 10.1016/j.ins.2014.02.004
   Tedmori S, 2012, INT ARAB J INF TECHN, V9, P471
   Toughi S, 2017, SIGNAL PROCESS, V141, P217, DOI 10.1016/j.sigpro.2017.06.010
   Vashisth S, 2014, OPTIK, V125, P5309, DOI 10.1016/j.ijleo.2014.06.068
   Wang Y, 2014, OPT COMMUN, V330, P91, DOI 10.1016/j.optcom.2014.05.032
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wei Y, 2017, OPT COMMUN, V403, P62, DOI 10.1016/j.optcom.2017.06.087
   Wu XJ, 2018, MULTIMED TOOLS APPL, V77, P12349, DOI 10.1007/s11042-017-4885-5
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XQ, 2012, OPT COMMUN, V285, P1736, DOI 10.1016/j.optcom.2011.12.023
   Zhang YQ, 2015, APPL SOFT COMPUT, V26, P10, DOI 10.1016/j.asoc.2014.09.039
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 58
TC 8
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18875
EP 18899
DI 10.1007/s11042-021-10511-0
EA FEB 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619905700004
DA 2024-07-18
ER

PT J
AU Singh, I
   Verma, OP
AF Singh, Isha
   Verma, Om Prakash
TI Impulse noise removal in color image sequences using fuzzy logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Impulse noise; Spatio-temporal filter; Peak signal to noise ratio; Fuzzy
   filter
ID DIRECTIONAL MEDIAN FILTER; FD FILTER; VIDEO; REDUCTION; ROBUST
AB This paper presents a two-step fuzzy filter to remove impulse noise from a color image sequence in RGB color space. The primary filter recognizes the pixels corrupted by impulse noise. It also computes the extent of noise and afterward rectifies them. The output of the first filter acts as an input to the secondary filter and further refines the outcome to give the final output. Excellent alignment is seen between noise removal and structure conservation of an image due to the classifying nature of the algorithm. To minimize blurring, noisy pixels are exclusively rectified and noise-free pixels remain intact. The proposed filter is a 3-D Spatio-temporal filter that considers spatial, temporal as well as color information. A pixel of one color component is compared to its neighboring pixels within the same frame and with the corresponding pixels in neighboring frames. It is likewise compared with the pixels of the other two color components. Peak Signal to Noise Ratio (PSNR) and structural similarity index (SSIM), Miss Detection (MD), and False Alarm (FA) rates are utilized as a performance metric. The experimental result of several color image sequences demonstrates the efficacy of the proposed fuzzy filter both qualitatively and quantitatively.
C1 [Singh, Isha; Verma, Om Prakash] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
C3 Delhi Technological University
RP Singh, I (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM 222ishasingh@gmail.com; opverma.dce@gmail.com
RI Singh, Isha/AAU-5006-2021; Verma, Om/AAD-1007-2019
OI Verma, Om/0000-0002-7421-295X
CR Al Zu'bi S, 2010, PROCEEDINGS OF THE 2010 IEEE ASIA PACIFIC CONFERENCE ON CIRCUIT AND SYSTEM (APCCAS), P604, DOI 10.1109/APCCAS.2010.5774847
   Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Al-Zu'bi S, 2017, PROCEDIA COMPUT SCI, V113, P531, DOI 10.1016/j.procs.2017.08.318
   Aliakhmet K, 2019, IEEE T CIRCUITS-II, V66, P868, DOI 10.1109/TCSII.2019.2907817
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   Arnal J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010243
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   BROWNE M, 2003, LECT NOTES COMPUTER, V2903
   Chen JY, 2019, IET IMAGE PROCESS, V13, P946, DOI 10.1049/iet-ipr.2018.6331
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chervyakov NI, 2020, COMPUT OPT, V44, P92, DOI 10.18287/2412-6179-CO-577
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Guo LW, 2007, IEEE T CIRC SYST VID, V17, P1423, DOI 10.1109/TCSVT.2007.903797
   Habib M, 2016, AEU-INT J ELECTRON C, V70, P689, DOI 10.1016/j.aeue.2016.02.005
   Huang SC, 2020, IEEE ACCESS, V8, P99180, DOI 10.1109/ACCESS.2020.2995647
   Hussain A, 2017, MULTIMED TOOLS APPL, V76, P22001, DOI 10.1007/s11042-017-4757-z
   Kang CC, 2009, SIGNAL PROCESS, V89, P344, DOI 10.1016/j.sigpro.2008.09.003
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   LE T, 2020, IEEE OPEN J COMPUTER
   Lee SW, 2005, IEEE T CONSUM ELECTR, V51, P648, DOI 10.1109/TCE.2005.1468014
   Li YY, 2008, APPL SOFT COMPUT, V8, P872, DOI 10.1016/j.asoc.2007.07.006
   Maity Alenrex., 2018, Comput Vis Graph Image Process, V4, P6
   Malinski L, 2019, J REAL-TIME IMAGE PR, V16, P1077, DOI 10.1007/s11554-016-0599-6
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Mélange T, 2011, IEEE T IMAGE PROCESS, V20, P959, DOI 10.1109/TIP.2010.2077305
   Mélange T, 2011, IMAGE VISION COMPUT, V29, P407, DOI 10.1016/j.imavis.2011.01.005
   Nair MS, 2013, COMPUT ELECTR ENG, V39, P663, DOI 10.1016/j.compeleceng.2012.06.004
   Owotogbe JS., 2019, INT J SCI ENG RES, V10, P388
   Ponomaryov V, 2010, IEICE T FUND ELECTR, VE93A, P570, DOI 10.1587/transfun.E93.A.570
   Rajagopalan R, 2002, IEEE T IMAGE PROCESS, V11, P26, DOI 10.1109/83.977880
   Rosales-Silva AJ, 2012, J VIS COMMUN IMAGE R, V23, P143, DOI 10.1016/j.jvcir.2011.09.007
   Roy A, 2018, IEEE T IND ELECTRON, V65, P7268, DOI 10.1109/TIE.2018.2793225
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P3567, DOI 10.1109/TIP.2006.877494
   Singh I, 2016, DEFENCE SCI J, V66, P30, DOI 10.14429/dsj.66.8722
   Szczepanski M, 2019, J REAL-TIME IMAGE PR, V16, P477, DOI 10.1007/s11554-016-0561-7
   Thirilogasundari V, 2012, PROCEDIA ENGINEER, V38, P2858, DOI 10.1016/j.proeng.2012.06.334
   Wang D., 2006, ADV IND CONTROL, DOI 10.1007/978-1-84628-469-4_7
   Wang GH, 2010, SIGNAL PROCESS, V90, P3213, DOI 10.1016/j.sigpro.2010.05.026
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JT, 2014, SIGNAL PROCESS, V98, P359, DOI 10.1016/j.sigpro.2013.11.035
   Yan, 2008, 2008 C IM SIGN PROC
   Yongacoglu, 2019, 2019 INT C ENG TEL E, P1, DOI DOI 10.1109/ENT47717.2019.9030589
   Yüksel ME, 2012, IEEE COMPUT INTELL M, V7, P25, DOI 10.1109/MCI.2012.2200624
   Zohrevand A, 2019, 2019 7 IR JOINT C, P1
NR 50
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18279
EP 18300
DI 10.1007/s11042-021-10643-3
EA FEB 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700007
DA 2024-07-18
ER

PT J
AU Gobi, R
AF Gobi, R.
TI Smartphone based indoor localization and tracking model using bat
   algorithm and Kalman filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Localization; Kalman filter; Bat algorithm; Fingerprint
ID FINGERPRINTING LOCALIZATION
AB In recent days, accurate localization becomes essential for enabling smartphone-based navigation to attain maximum accuracy in the construction of the real world.Fingerprint-based localization is the widespread solution to achieve and assure effective performance. In this study, a new fingerprint-based localization model using a bat algorithm (BA) is presented stimulated by the echolocation nature of microbats. The presented model adapts BA for estimating the location information. Initially, the presented model applies a Bayesian-rule based objective function. Then, the BA is used for improving the accuracy and analyzing the effects of the initial position of the bats on the localization outcome. For mitigating the estimation error, the Kalman filter is employed for updating the initially determined position using the BA for tracking purposes. The experimental analysis indicated an improvement in real-time performance and decrease in computation complexity. The presented model also obtained maximum localization accuracy with minimum localization error over the compared methods.
C1 [Gobi, R.] Christ Univ, Bangalore, Karnataka, India.
C3 Christ University
RP Gobi, R (corresponding author), Christ Univ, Bangalore, Karnataka, India.
EM gobi.r@christuniversity.in
RI Ramasamy, Gobi/AAF-7172-2019
OI Ramasamy, Gobi/0000-0002-0176-5414
CR Atia MM, 2013, IEEE T MOBILE COMPUT, V12, P1774, DOI 10.1109/TMC.2012.143
   Au AWS, 2013, IEEE T MOBILE COMPUT, V12, P2050, DOI 10.1109/TMC.2012.175
   Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P775, DOI 10.1109/INFCOM.2000.832252
   Ding GM, 2015, IEICE T COMMUN, VE98B, P502, DOI 10.1587/transcom.E98.B.502
   Ding GM, 2014, IEICE T COMMUN, VE97B, P1728, DOI 10.1587/transcom.E97.B.1728
   Edwardes A, 2012, FDN LOCATION BASED S
   Feng C, 2012, IEEE T MOBILE COMPUT, V11, P1983, DOI 10.1109/TMC.2011.216
   Guo XT, 2013, CONTRIB ECON, P1, DOI 10.1007/978-3-642-41585-2_1
   Honkavirta V, 2009, WORKS POSIT NAVIGAT, P243, DOI 10.1109/WPNC.2009.4907834
   Jadad HA, 2020, INT J CLOUD APPL COM, V10, P36, DOI 10.4018/IJCAC.2020040103
   Jadad HA, 2019, INT J CLOUD APPL COM, V9, P58, DOI 10.4018/IJCAC.2019070104
   Laoudias C, 2009, IEEE GLOB COMM C GLO, P1
   Lee K, 2017, IEEE ACCESS, V5, P11437, DOI 10.1109/ACCESS.2017.2700488
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P18, DOI 10.1109/MIC.2020.2969610
   Li YT, 2018, IET COMMUN, V12, P751, DOI 10.1049/iet-com.2017.0502
   Li YT, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3178
   Liu H, 2007, IEEE T SYST MAN CY C, V37, P1067, DOI 10.1109/TSMCC.2007.905750
   Murata M, 2018, INT CONF PERVAS COMP, P254
   Rastogi S, 2016, PROCEDIA COMPUT SCI, V78, P26, DOI 10.1016/j.procs.2016.02.006
   Wu KS, 2013, IEEE T PARALL DISTR, V24, P1300, DOI 10.1109/TPDS.2012.214
   Xu L., 2019, Int. J. High Perform. Comput. Netw., V14, P112
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yin J, 2005, THIRD IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P85
NR 23
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15377
EP 15390
DI 10.1007/s11042-020-10438-y
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000614341400005
DA 2024-07-18
ER

PT J
AU Zohrevandi, M
   Setayeshi, S
   Rabiee, A
   Reshadi, M
AF Zohrevandi, Mahbanou
   Setayeshi, Saeed
   Rabiee, Azam
   Reshadi, Midia
TI Blind separation of underdetermined Convolutive speech mixtures by
   time-frequency masking with the reduction of musical noise of separated
   signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind source separation (BSS); Sparseness; Underdetermined; Convolutive;
   Time-frequency masking
ID SPARSE
AB The main focus of this paper is the separation of underdetermined convolutive blind speech in a multi-speaker environment. We present a method based on mask prediction in the time-frequency domain. Firstly, depending on the sparsity of signals in the time-frequency (TF) domain, we extimate speakers' masks by clustering the relative absolute and Hermitian angle features extracted from the frequency components of the mixtures. Speech separation algorithms that are based on the sparsity and disjoint orthogonality of the speech signals in the time-frequency domain are not efficient when more than one source is active. Hence, in this paper, the cluster centers are estimated mostly based on the TF units that probably have only one active source. The correlations between the estimated masks, belonging to adjacent frequency bins, are leveraged to solve the permutation problem. To increase the accuracy, we have zeroed the value of masks at the TF unit without any active source. Moreover, in clustering, we employ a weighting function to consider the parts of masks that probably contains just one active source. Finally, in order to decrease the musical noise of the separated signals and improve their quality, sparse filters in the time-domain are utilized to re-estimate the separated signals. Performance of the proposed method is evaluated by a number of simulated and real speech signals. The simulated experiments were performed using a public dataset and Roomsim simulator. Compared the proposed method with some conventional algorithms, we observed that our separation method is more accurate than other approaches.
C1 [Zohrevandi, Mahbanou; Reshadi, Midia] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
   [Setayeshi, Saeed] Amirkabir Univ Technol, Dept Med Radiat, Tehran, Iran.
   [Rabiee, Azam] Islamic Azad Univ, Dept Comp Sci, Dolatabad Branch, Esfahan, Iran.
C3 Islamic Azad University; Amirkabir University of Technology; Islamic
   Azad University
RP Setayeshi, S (corresponding author), Amirkabir Univ Technol, Dept Med Radiat, Tehran, Iran.
EM m.zohrevandi@srbiau.ac.ir; setayesh@aut.ac.ir; azrabiee@gmail.com;
   reshadi@srbiau.ac.ir
RI Setayeshi, Saeed/JPY-2228-2023
OI Setayeshi, Saeed/0000-0002-1415-222X
CR Aïssa-El-Bey A, 2007, IEEE T AUDIO SPEECH, V15, P1540, DOI 10.1109/TASL.2007.898455
   Araki S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P881
   Araki S, 2012, 10 INT C LAT VAR AN, P414
   Araki S, 2007, SIGNAL PROCESS, V87, P1833, DOI 10.1016/j.sigpro.2007.02.003
   Asaei A, 2016, SPEECH COMMUN, V76, P201, DOI 10.1016/j.specom.2015.07.002
   Bofill P., 2000, Second International Workshop on Independent Component Analysis and Blind Signal Separation. Proceedings, P87
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Bouafif M, 2016, INT J SPEECH TECHNOL, V19, P697, DOI 10.1007/s10772-016-9361-5
   Jeon KM, 2020, DIGIT SIGNAL PROCESS, V97, DOI 10.1016/j.dsp.2019.102632
   Kitamura D, 2016, IEEE-ACM T AUDIO SPE, V24, P1626, DOI 10.1109/TASLP.2016.2577880
   Kumar MKP, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P95, DOI 10.1109/ICCSP.2015.7322636
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Ma WY, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P402
   Nesta Francesco, 2012, Latent Variable Analysis and Signal Separation. Proceedings 10th International Conference, LVA/ICA 2012, P222, DOI 10.1007/978-3-642-28551-6_28
   O'Grady PD, 2005, INT J IMAG SYST TECH, V15, P18, DOI 10.1002/ima.20035
   Ochs P, 2014, SIAM J IMAGING SCI, V7, P1388, DOI 10.1137/130942954
   Peng B, 2012, IET SIGNAL PROCESS, V6, P34, DOI 10.1049/iet-spr.2011.0015
   Reju VG, 2010, IEEE T AUDIO SPEECH, V18, P101, DOI 10.1109/TASL.2009.2024380
   Sawada H, 2006, IEEE T AUDIO SPEECH, V14, P2165, DOI 10.1109/TASL.2006.872599
   Scharnhorst K, 2001, ACTA APPL MATH, V69, P95, DOI 10.1023/A:1012692601098
   Tu YH, 2020, INT CONF ACOUST SPEE, P6664, DOI [10.1109/icassp40776.2020.9054615, 10.1109/ICASSP40776.2020.9054615]
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Yatabe K, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P776, DOI 10.1109/ICASSP.2018.8462338
NR 24
TC 3
Z9 3
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12601
EP 12618
DI 10.1007/s11042-020-10398-3
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000607038000001
DA 2024-07-18
ER

PT J
AU Kaur, G
   Singh, K
   Gill, HS
AF Kaur, Gurvir
   Singh, Kuldeepak
   Gill, Harsimranjit Singh
TI Chaos-based joint speech encryption scheme using SHA-1
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech-signal; One-dimensional chaotic maps; Three-dimensional chaos
   map; SHA-1; Blowfish
ID ATTACK; MAPS
AB In this paper, the speech signal is encrypted using multiple chaotic maps and cryptographic protocols. The input signal is fragmented and scrambled into four segments using cubic map. In order to make the signal invulnerable against attacks, scrambled signal is processed through various one-dimensional chaotic maps like cubic, logistic, skew-tent, and quadratic map. All chaotic maps are employed to provide an encryption at transmitter side; however, reversal of the same is carried out at other end. To protect the various parameters of all chaotic techniques, blowfish algorithm is employed with the private key. On top of that, additional layer of security is provided through hashing algorithm for authentication of shared data and the blowfish key of system between two ends. The computed message digest of secure hash algorithm should be same for successful communication, which authenticates and verify the parameters of chaotic maps. Furthermore, several tests have been performed on 8 KHz secured speech signal such as signal-to-noise ratio, power-spectral density, peak signal-to-noise ratio, and correlation test in order to check the efficiency of proposed system. The various statistical tests and analysis of adversary model validates the encryption model and embraces stronger security, thus making it as invulnerable to the attacks of intruder. The result promises that presented technique is extremely secure, provides end-to-end encryption and can be utilized in a real time speech communication.
C1 [Kaur, Gurvir; Singh, Kuldeepak; Gill, Harsimranjit Singh] Guru Nanak Dev Engn Coll, Dept Elect & Commun, Ludhiana, Punjab, India.
C3 Guru Nanak Dev Engineering College Ludhiana
RP Gill, HS (corresponding author), Guru Nanak Dev Engn Coll, Dept Elect & Commun, Ludhiana, Punjab, India.
EM grewalgurr31@gmail.com; gne.kuldeepaksingh@gmail.com;
   harsimran18@gmail.com
RI Gill, Harsimranjit/AAL-4367-2021
OI Gill, Harsimranjit/0000-0001-9605-0237
CR AHMAD M, 2017, 3D RES, V8
   Albahrani DEA, 2017, ANN C NEW TRENDS INF, P7
   Aliu F, 2016, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON FINANCE AND ECONOMICS 2016, P1
   [Anonymous], 2008, J LATE ANTIQUE RELIG, V2, P1
   [Anonymous], 1993, P 13 ANN INT CRYPT C
   Aradhana, 2017, INT J TECH INNOV MOD, V3, P2455
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Bogdanov A, 2011, LECT NOTES COMPUT SC, V7073, P344, DOI 10.1007/978-3-642-25385-0_19
   Ching-Kun Chen, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P1741, DOI 10.1109/ICIEA.2010.5515285
   Demirci H, 2008, LECT NOTES COMPUT SC, V5086, P116
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   El Bakry H.M., 2016, INT J COMPUTER APPL, V144, P24
   Farsana FJ, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P2197, DOI 10.1109/ICCSP.2017.8286804
   Farsana FJ, 2016, PROCEDIA COMPUT SCI, V93, P816, DOI 10.1016/j.procs.2016.07.302
   *FIPS, 1995, 1801 FIPS
   Gandhi RA, 2016, INT J RES APPL SCI E, V4, P671
   Hameed S.M., 2018, Iraqi Journal of Science, V59, P434
   Hu HP, 2013, COMPUT PHYS COMMUN, V184, P765, DOI 10.1016/j.cpc.2012.11.017
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kelsey J., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P237
   Kocarev L, 2013, IEEE CIRCUITS MAGAZI, P5
   Lawande Q. V., 2005, BARC Newsletter, P1
   Lin CF, 2017, ADV SECUR COMPUT COM, P168
   Liu J, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P283, DOI 10.1109/IIH-MSP.2008.91
   Maqsood F, 2017, INT J ADV COMPUT SC, V8, P442
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mosa E, 2011, INT J SPEECH TECHNOL, V14, P285, DOI 10.1007/s10772-011-9103-7
   Mousa A, 2014, INT J COMPUT SCI APP, V3, P44
   Mousa A, 2013, JAP EGY CONF ELECTR, P154, DOI 10.1109/JEC-ECC.2013.6766404
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rahem AT, 2016, I SYMPOS TELECOM TEC, P112, DOI 10.1109/ISTT.2016.7918095
   Rahmawati W. M., 2018, IOP C SERIES MAT SCI
   Ramadan N., 2016, AM J SIGNAL PROCESS, V6, P1, DOI DOI 10.5923/J
   Sahu HK, 2016, DEFENCE SCI J, V66, P582, DOI 10.14429/dsj.66.10798
   Sathishkumar GA, 2011, COMM COM INF SC, V133, P290
   Sathishkumar GA, 2011, INT J NETW SECUR APP, V3, P1
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Schneier B., 1994, Fast Software Encryption. Cambridge Security Workshop Proceedings, P191
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Slimani D, 2018, PROCEDIA COMPUT SCI, V128, P79, DOI 10.1016/j.procs.2018.03.011
   Telem ANK, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/602921
   Wang GL, 2013, J COMPUT SCI TECH-CH, V28, P129, DOI 10.1007/s11390-013-1317-5
   Wang X, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413300115
NR 43
TC 14
Z9 14
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10927
EP 10947
DI 10.1007/s11042-020-10223-x
EA JAN 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100004
DA 2024-07-18
ER

PT J
AU Tran, MT
   Vo, QN
   Lee, GS
AF Tran, Minh-Trieu
   Vo, Quang-Nhat
   Lee, Guee-Sang
TI Binarization of music score with complex background by deep
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binarization; Music score images; Convolutional neural networks; Deep
   learning; U-net
ID DOCUMENT; FRAMEWORK
AB Binarization is an important step for most of document analysis systems. Regarding music score images with a complex background, the existence of background clutters with a variety of shapes and colors creates many challenges for the binarization. This paper presents a model for binarization of the complex background music score images by fusion of deep convolutional neural networks. Our model is directly trained from image regions using pixel values as inputs and the binary ground truth as labels. By utilizing the generalization capability of the residual network backbone and useful feature learning ability of dense layer, the proposed network structures can differentiate foreground pixels from background clutters, minimize the possibility of overfitting phenomenon and thus can deal with complex background noises appearing in the music score images. Comparing to traditional algorithms, binary images generated by our method have a cleaner background and better-preserved strokes. The experiments with captured and synthetic music score images show promising results compared to existing methods.
C1 [Tran, Minh-Trieu; Lee, Guee-Sang] Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju, South Korea.
   [Vo, Quang-Nhat] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
C3 Chonnam National University; University of Oulu
RP Lee, GS (corresponding author), Chonnam Natl Univ, Dept Artificial Intelligence Convergence, Gwangju, South Korea.
EM tmtvaa@gmail.com; nhat.vo@oulu.fi; gslee@jnu.ac.kr
OI Tran, Minh-Trieu/0000-0002-5015-5604
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2018R1D1A3B05049058,
   NRF-2020R1A4A1019191]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2018R1D1A3B05049058 & NRF-2020R1A4A1019191).
CR Chou CH, 2010, PATTERN RECOGN, V43, P1518, DOI 10.1016/j.patcog.2009.10.016
   Clevert D., 2016, ARXIV151107289
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Gatos B, 2004, LECT NOTES COMPUT SC, V3163, P102
   Guan S, 2020, IEEE J BIOMED HEALTH, V24, P568, DOI 10.1109/JBHI.2019.2912935
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x
   Moghaddam RF, 2010, PATTERN RECOGN, V43, P2186, DOI 10.1016/j.patcog.2009.12.024
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2010, PATTERN RECOGN, V43, P3177, DOI 10.1016/j.patcog.2010.03.014
   Pinto T, 2011, LECT NOTES COMPUT SC, V6669, P700
   Vo QN, 2016, PATTERN RECOGN LETT, V69, P88, DOI 10.1016/j.patrec.2015.10.017
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Su BL, 2012, INT C PATT RECOG, P3200
   Wu Y, 2016, IEEE IMAGE PROC, P3763, DOI 10.1109/ICIP.2016.7533063
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 19
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11031
EP 11047
DI 10.1007/s11042-020-10272-2
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604225200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, QY
   Chen, X
   Liang, RY
   Liu, HC
AF Wang, Qingyun
   Chen, Xin
   Liang, Ruiyu
   Liu, Haicheng
TI A frequency-domain nonlinear echo processing algorithm for high quality
   hands-free voice communication devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic echo cancellation (AEC); Double-talk (DT); Frequency nonlinear
   processing (FNLP); Variable step-size partitioned block frequency-domain
   adaptive filtering (VSS-PBFDAF); Hands-free communication device
ID CANCELLATION; EFFICIENT
AB A frequency-domain nonlinear echo processing algorithm is proposed to improve the audio quality during double-talk periods for hands-free voice communication devices. To achieve acoustic echo cancellation (AEC), a real-time AEC algorithm based on variable step-size partitioned block frequency-domain adaptive filtering (VSS-PBFDAF) and frequency-domain nonlinear echo processing (FNLP) algorithm was employed in the DSP chip of the prototype device. To avoid divergence during double-talk periods, normalized variable step-sizes for each frequency were introduced to adjust the convergence speed. Then, the nonlinear suppression function of FNLP was applied to inhibit the residual nonlinear acoustic echo and ensure the good quality of the near-end voice. The results of the experiment with the prototype device show that the proposed algorithm achieved deeper and more stable convergence during double-talk periods compared to the NLMS, FNLMS and traditional PBFDAF algorithms. Less nonlinear acoustic echo in the output was also obtained due to the use of FNLP. A speech quality assessment based on ITU-T P.563 showed that the Sout of the proposed algorithm achieved higher scores than that of the WebRTC algorithm. In addition, the speech output of the proposed algorithm during the double-talk periods was clear and coherent.
C1 [Wang, Qingyun; Chen, Xin; Liang, Ruiyu] Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing, Peoples R China.
   [Liu, Haicheng] Southeast Univ, Informat Sci & Engn, Nanjing, Peoples R China.
C3 Nanjing Institute of Technology; Southeast University - China
RP Liang, RY (corresponding author), Nanjing Inst Technol, Sch Informat & Commun Engn, Nanjing, Peoples R China.
EM liangry@njit.edu.cn
FU National Key Research and Development Program of China [2020YFC2004003,
   2020YFC2004002]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFC2004003 and Grant
   2020YFC2004002. The authors would like to thank the reviewers for their
   valuable comments that helped in significant improvement of the quality
   of the paper. They would also like to thank Professor Zou Cairong for
   the suggestions of experimental analysis and discussions.
CR Åhgren P, 2006, IEEE T CONSUM ELECTR, V52, P515, DOI 10.1109/TCE.2006.1649673
   [Anonymous], 2000, ENH ITU T G 168 ECH, P128
   Azpicueta-Ruiz LA, 2011, IEEE T AUDIO SPEECH, V19, P97, DOI 10.1109/TASL.2010.2045185
   Bekrani M, 2011, IEEE T AUDIO SPEECH, V19, P1743, DOI 10.1109/TASL.2010.2098868
   Bernardi Giuliano, 2015, 2015 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Proceedings, P1, DOI 10.1109/WASPAA.2015.7336931
   Birkett A. N., 1995, Neural Networks for Signal Processing V. Proceedings of the 1995 IEEE Workshop (Cat. No.95TH8094), P449, DOI 10.1109/NNSP.1995.514919
   Cecchi S, 2016, IEEE SIGNAL PROC LET, V23, P94, DOI 10.1109/LSP.2015.2502761
   Chandra, 2014, INT C COMM SIGN PROC, P076
   Comminiello D, 2017, EUR SIGNAL PR CONF, P1145, DOI 10.23919/EUSIPCO.2017.8081387
   Comminiello D, 2013, IEEE T AUDIO SPEECH, V21, P1502, DOI 10.1109/TASL.2013.2255276
   Eneman K, 2003, IEEE T SPEECH AUDI P, V11, P143, DOI 10.1109/TSA.2003.809194
   Fukui M, 2014, IEEE T CONSUM ELECTR, V60, P468, DOI 10.1109/TCE.2014.6937332
   Gänsler T, 2000, IEEE T SPEECH AUDI P, V8, P656, DOI 10.1109/89.876299
   Gil-Cacho JM, 2013, IEEE T AUDIO SPEECH, V21, P1867, DOI 10.1109/TASL.2013.2260742
   Guérin A, 2003, IEEE T SPEECH AUDI P, V11, P672, DOI 10.1109/TSA.2003.818077
   Halimeh MM, 2019, IEEE SIGNAL PROC LET, V26, P1827, DOI 10.1109/LSP.2019.2951311
   Huang FY, 2018, IEEE T VEH TECHNOL, V67, P11924, DOI 10.1109/TVT.2018.2877457
   Jiang T, 2019, IEEE ACCESS, V7, P61353, DOI 10.1109/ACCESS.2019.2910858
   Lee GA, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364782
   Lei Q., 2019, ICMSSP, P94
   Li XH, 1996, IEEE T SIGNAL PROCES, V44, P1813, DOI 10.1109/78.510628
   Liu JF, 2004, IEEE T COMMUN, V52, P1288, DOI 10.1109/TCOMM.2004.833010
   LONG G, 1989, IEEE T ACOUST SPEECH, V37, P1397, DOI 10.1109/29.31293
   Pao YH., 1989, Adaptive Pattern Recognition and Neural Networks
   Papp II, 2011, IEEE T CONSUM ELECTR, V57, P606, DOI 10.1109/TCE.2011.5955198
   Park YJ, 2010, ELECTRON LETT, V46, P866, DOI 10.1049/el.2010.0848
   Schwartz A, 2013, PROC IEEE INT CONF S, P1, DOI 10.1109/ICSM.2013.11
   Shynk JJ, 1992, IEEE SIGNAL PROC MAG, V9, P14, DOI 10.1109/79.109205
   Tashev IJ, 2012, INT CONF ACOUST SPEE, P165, DOI 10.1109/ICASSP.2012.6287843
   Tournery C, 2006, IEEE INT C AC SPEECH
   Union T I T, 2004, ITU P 563 SINGL END
   van Waterschoot T, 2011, P IEEE, V99, P288, DOI 10.1109/JPROC.2010.2090998
   Widrow B, 2005, IEEE SIGNAL PROC MAG, V22, P100, DOI 10.1109/MSP.2005.1407720
   Yu D, 2017, IEEE-CAA J AUTOMATIC, V4, P396, DOI 10.1109/JAS.2017.7510508
   Zhang H, 2018, INTERSPEECH, P3239
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
NR 36
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10777
EP 10796
DI 10.1007/s11042-020-10230-y
EA JAN 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604479100010
DA 2024-07-18
ER

PT J
AU Chowdhury, DP
   Bakshi, S
   Sa, PK
   Majhi, B
AF Chowdhury, Debbrota Paul
   Bakshi, Sambit
   Sa, Pankaj Kumar
   Majhi, Banshidhar
TI Semantic ear feature reduction for source camera identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ear biometrics; Source camera identification; Biometric Anti-spoofing;
   Forensic validation
AB Energy based Bior 4.4 feature is proven suitable for identifying source camera of ear biometric images when a small number of distinct camera sources are used. This level-2 Bior 4.4 feature vector bears 36 energy values. In this paper, a semantic way of reducing this feature vector is discussed which is capable of identifying the source camera of ear biometric images. We analyze the consequences of the reduction towards performance in terms of accuracy. Based on the mean of variances of wavelet energy feature, the size of the feature vector is gradually reduced. Reduction of accuracy of source camera identification is expected with reduction of the feature vector size. However interestingly, we can remove less important feature dimensions without affecting the accuracy much. We need to ensure preserving the feature indices that are deciding factors in yielding the accuracy. From the experiment on 3-class source camera classification, it has been found that even the feature size can be reduced to 1/3rd (i.e. up to 12 values from 36 values) with a tolerance of only 1% degradation in accuracy. Hence we grossly conclude that very low dimensional feature can be potent to predict source camera blindly with good accuracy.
C1 [Chowdhury, Debbrota Paul; Bakshi, Sambit; Sa, Pankaj Kumar; Majhi, Banshidhar] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Chowdhury, DP (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM debbrota@gmail.com; sambitbaksi@gmail.com; pankajksa@nitrkl.ac.in;
   bmajhi@nitrkl.ac.in
RI K, Pankaj/A-9362-2017; Bakshi, Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X; Paul Chowdhury,
   Debbrota/0000-0002-4622-2157
CR [Anonymous], 2013, SIN 13, DOI DOI 10.1145/2523514.2523597
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Chowdhury DP, 2020, PATTERN RECOGN LETT, V130, P139, DOI 10.1016/j.patrec.2018.10.009
   Chowdhury DP, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0855-8
   Emersic Z, 2017, NEUROCOMPUTING, V255, P26, DOI 10.1016/j.neucom.2016.08.139
   Frejlichowski D, 2010, LECT NOTES COMPUT SC, V6112, P227, DOI 10.1007/978-3-642-13775-4_23
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Marra F, 2018, PATTERN RECOGN LETT, V113, P46, DOI 10.1016/j.patrec.2017.04.010
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Rida I, 2020, MULTIMED TOOLS APPL, V79, P4867, DOI 10.1007/s11042-018-6808-5
   Van LT, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P883
   2012, IITD EAR DATABASE
   2008, AMI EAR DATABASE
   2010, WPUT EAR DATABASE
NR 15
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35315
EP 35331
DI 10.1007/s11042-019-7665-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900033
DA 2024-07-18
ER

PT J
AU Barik, RC
   Changder, S
AF Barik, Ram Chandra
   Changder, Suvamoy
TI A novel and efficient amino acid codon based medical image encryption
   scheme colligating multiple chaotic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Amino acid codon; Medical image encryption; Linear Congruential
   generator; Logistic map; Tent map; AES; RSA; Block circular shift
ID HYBRID GENETIC ALGORITHM; SECURITY
AB Advancement of medical imaging in health care sector emerges new challenge of secure image transmission. Security of medical imaging is a prominent issue to keep patients information safe. In this paper an efficient and secure biomedical image encryption algorithm is proposed with two phases of encryption. In the first phase the image has to undergone a random substitution of 20 Amino Acid based Codon with one or more than alternate Codon in the form of triplets using the base DNA code (A, T, C and G) using Linear Congruential Generator. Upshot of the first phase encrypted image is divided into blocks and a logistic map is used to generate a series of unique initial condition and control parameter. Using a random ASCII character as a seed the unique initial conditions for each block is generating some Pseudo Random Number Generator. The seed is encrypted using RSA. Each block is circularly shifted using unique PRNG. These unique initial conditions and control parameters are utilized by a series of Tent Maps to perform block by block confusion in the second phase encryption using XOR operation. Keys used in both the phases are encrypted using AES technique. Proposed method is used to encrypt any biomedical and other images also. All type of security measure such as Differential attack, key space analysis to resist Brute force attack, Correlation analysis, key sensitivity test, resistance to Noise attack and plain text attack along with time analysis has been taken into consideration to test the vulnerability of the proposed algorithm. From the comparative study the proposed method outperform in many aspects than the existing methods.
C1 [Barik, Ram Chandra; Changder, Suvamoy] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Barik, RC (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, W Bengal, India.
EM ramchbarik@gmail.com; suvamoy.nitdgp@gmail.com
RI Barik, Dr. Ram Chandra/ABG-1736-2021
OI Barik, Dr. Ram Chandra/0000-0002-2803-5868
CR Abanda Y, 2016, IET IMAGE PROCESS, V10, P742, DOI 10.1049/iet-ipr.2015.0244
   Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P19717, DOI 10.1007/s11042-020-08788-8
   Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Barik RC, 2018, INT J ELECTRON SECUR, V10, P109
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Cao F, 2003, COMPUT MED IMAG GRAP, V27, P185, DOI 10.1016/S0895-6111(02)00073-3
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2019, MULTIMED TOOLS APPL, V78, P35419, DOI 10.1007/s11042-019-08168-x
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Das JK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0167651
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hasimoto-Beltran R, 2011, STUD COMPUT INTELL, V354, P375
   Ismail SM, 2018, J ADV RES, V10, P85, DOI 10.1016/j.jare.2018.01.009
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kaur M, 2018, ARAB J SCI ENG, V43, P8127, DOI 10.1007/s13369-018-3355-3
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Lawande Q. V., 2005, BARC Newsletter, P1
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li-bo Zhang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/940638
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mozaffari S, 2018, MULTIMED TOOLS APPL, V77, P25799, DOI 10.1007/s11042-018-5817-8
   Naz F, 2020, MULTIMED TOOLS APPL, V79, P22107, DOI 10.1007/s11042-020-08897-4
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Shafique A, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-12138-3
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Talarposhti KM, 2016, OPT LASER ENG, V81, P21, DOI 10.1016/j.optlaseng.2016.01.006
   UbaidurRahman NH, 2015, PROCEDIA COMPUT SCI, V46, P463, DOI 10.1016/j.procs.2015.02.045
   Wang XY, 2019, MULTIMED TOOLS APPL, V78, P26111, DOI 10.1007/s11042-019-07794-9
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wen HP, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12797-4
   Zhang LB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/913476
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
NR 44
TC 10
Z9 10
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10723
EP 10760
DI 10.1007/s11042-020-09930-2
EA NOV 2020
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593447300002
DA 2024-07-18
ER

PT J
AU Du, SS
   Yang, JF
   Zhang, HG
   Zhang, B
   Su, ZG
AF Du, Shanshan
   Yang, Jinfeng
   Zhang, Haigang
   Zhang, Bob
   Su, Zhigang
TI FVSR-Net: an end-to-end Finger Vein Image Scattering Removal Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scattering removal; Image restoration; Finger vein recognition;
   Convolutional neural networks
ID RESTORATION; ENHANCEMENT; FUSION
AB Based on the ever-growing emphasis on high security of biometrics recognition, finger vein recognition has captured more and more attention. However, due to the light scattering in human skin tissue during near-infrared light transmission imaging, the collected finger vein images are always degraded dramatically, which leads to the unreliability of vein features and the low accuracy of finger vein recognition. Although considerable traditional methods are dedicated to eliminating the effect of light scattering on imaging, the clearer images cannot be output end-to-end, the processes of restoring degraded finger vein images are laborious as well. Thereupon, with the aim at improving the visibility of finger vein features and generating clear finger vein images end-to-end, this effort represents a simple and effective method utilizing Convolutional Neural Network (CNN). First, in our previous work, the biological optical model used to settle the matter of skin scattering is modified to output restored finger vein images in an end-to-end manner. Second, a multi-scale CNN named E-Net is established to acquire credible estimation map of finger vein features, which is conducive to the acquisition of pleasurable restoration outcome. Finally, a scattering removal framework, addressed as Finger Vein Image Scattering Removal Network (FVSR-Net), is designed via integrating improved biological optical model with E-Net. Such a novel design facilitates the generation of clearer venous regions and increases computational efficiency and stability. Experiments accomplished on two finger vein datasets demonstrate the superiority of our proposed method in terms of visual quality and recognition performance.
C1 [Du, Shanshan; Su, Zhigang] Civil Aviat Univ China, Tianjin Key Lab Adv Signal Proc, Tianjin, Peoples R China.
   [Yang, Jinfeng; Zhang, Haigang] Shenzhen Polytech, Inst Appl Artificial Intelligence, Guangdong Hong Kong Macao Greater Bay Area, Shenzhen, Peoples R China.
   [Zhang, Bob] Univ Macau, Dept Comp & Informat Sci, Taipa, Macao, Peoples R China.
   [Su, Zhigang] Civil Aviat Univ China, Sino European Inst Aviat Engn, Tianjin, Peoples R China.
C3 Civil Aviation University of China; Shenzhen Polytechnic University;
   Southern Medical University - China; University of Macau
RP Su, ZG (corresponding author), Civil Aviat Univ China, Tianjin Key Lab Adv Signal Proc, Tianjin, Peoples R China.; Yang, JF (corresponding author), Shenzhen Polytech, Inst Appl Artificial Intelligence, Guangdong Hong Kong Macao Greater Bay Area, Shenzhen, Peoples R China.; Su, ZG (corresponding author), Civil Aviat Univ China, Sino European Inst Aviat Engn, Tianjin, Peoples R China.
EM dushanshan2020@gmail.com; jfyang@szpt.edu.cn; zhg2018@sina.com;
   bobzhang@um.edu.mo; ssrsu@vip.sina.com
RI Zhang, Bob/ABD-5926-2021; Zhang, Bob/HIR-3656-2022; Yang,
   Jinfeng/GSN-6506-2022
OI Zhang, Bob/0000-0003-2497-9519; Zhang, Bob/0000-0001-6512-0474; SU,
   Zhigang/0000-0002-3512-0147
CR Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chanukya PSVVN, 2020, MULTIMED TOOLS APPL, V79, P659, DOI 10.1007/s11042-019-08123-w
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fu Bin, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P2447, DOI 10.1109/ICINFA.2010.5512278
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kingma D. P., 2014, arXiv
   Lee EC, 2009, ELECTRON LETT, V45, P1074, DOI 10.1049/el.2009.1231
   Lee EC, 2011, OPT LASER ENG, V49, P816, DOI 10.1016/j.optlaseng.2011.03.004
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Qin HF, 2018, MULTIMED TOOLS APPL, V77, P2505, DOI 10.1007/s11042-016-4317-y
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin KY, 2014, SENSORS-BASEL, V14, P3095, DOI 10.3390/s140203095
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wax AP, 2010, BIOMEDICAL APPL LIGH, VIV, P7573
   Wen X. B., 2008, J JILIN U SCI EDITIO, V2, P026
   Yang J., 2011, PROC INT C HAND BASE, P1
   Yang JH, 2009, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON PRODUCT INNOVATION MANAGEMENT, VOLS I AND II, P346
   Yang JF, 2014, INFORM SCIENCES, V268, P33, DOI 10.1016/j.ins.2013.10.009
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2012, SENSORS-BASEL, V12, P3627, DOI 10.3390/s120303627
   Yang JF, 2010, INT CONF SIGN PROCES, P1706, DOI 10.1109/ICOSP.2010.5656832
   Yang JF, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P87, DOI 10.1109/ICIG.2009.170
   Yang TH, 2010, PROCEEDINGS OF THE 1ST INTERNATIONAL CONFERENCE ON SUSTAINABLE CONSTRUCTION & RISK MANAGEMENT, VOLS I AND II, P1145
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Zhang HG, 2019, IEEE ACCESS, V7, P28607, DOI 10.1109/ACCESS.2019.2902133
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J., 2020, PROC IEEECVFCONF COM, DOI DOI 10.1109/CVPR42600.2020.01256
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 39
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 10705
EP 10722
DI 10.1007/s11042-020-09270-1
EA NOV 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000593447300003
DA 2024-07-18
ER

PT J
AU Abbas, SQ
   Ahmed, F
   Chen, YPP
AF Abbas, S. Qasim
   Ahmed, Fawad
   Chen, Yi-Ping Phoebe
TI Perceptual image hashing using transform domain noise resistant local
   binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform; Local binary pattern; Perceptual image
   hashing; Robust hash; Transform domain hashing
ID ROBUST; SECURE
AB A new Discrete Cosine Transform (DCT) domain Perceptual Image Hashing (PIH) scheme is proposed in this paper. PIH schemes are designed to extract a set of features from an image to form a compact representation that can be used for image integrity verification. A PIH scheme takes an image as the input, extracts its invariant features and constructs a fixed length output, which is called a hash value. The hash value generated by a PIH scheme is then used for image integrity verification. The basic requirement for any PIH scheme is its robustness to non-malicious distortions and discriminative ability to detect minute level of tampering. The feature extraction phase plays a major role in guaranteeing robustness and tamper detection ability of a PIH scheme. The proposed scheme fuses together the DCT and Noise Resistant Local Binary Pattern (NRLBP) to compute image hash. In this scheme, an input image is divided into non-overlapping blocks. Then, DCT of each non-overlapping block is computed to form a DCT based transformed image block. Subsequently, NRLBP is applied to calculate NRLBP histogram. Histograms of all the blocks are concatenated together to get a hash vector for a single image. It is observed that low frequency DCT coefficients inherently have quite high robustness against non-malicious distortions, hence the NRLBP features extracted from the low frequency DCT coefficients provide high robustness. Computational results exhibit that the proposed hashing scheme outperforms some of the existing hashing schemes as well as can detect localized tamper detection as small as 3% of the original image size and at the same time resilient against non-malicious distortions.
C1 [Abbas, S. Qasim; Chen, Yi-Ping Phoebe] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic 3086, Australia.
   [Ahmed, Fawad] HITEC Univ, Dept Elect Engn, Taxila, Punjab, Pakistan.
C3 La Trobe University; NITEC University
RP Chen, YPP (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne, Vic 3086, Australia.
EM Phoebe.Chen@latrobe.edu.au
RI Abbas, Syed Qasim/ABP-4797-2022; Abbas, Syed Qasim/GYD-6630-2022; Chen,
   Yi-Ping Phoebe/B-8844-2008
OI Abbas, Syed Qasim/0000-0003-0565-4022; Abbas, Syed
   Qasim/0000-0003-0565-4022; Ahmed, Fawad/0000-0003-4796-1063; Chen,
   Yi-Ping Phoebe/0000-0002-4122-3767
CR Abbas SQ, 2016, INT C ULTRA MOD TELE, P401, DOI 10.1109/ICUMT.2016.7765393
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2016, CONTEXT AWARE HUMAN, DOI DOI 10.1007/978-3-319-19947-4_1
   Vega EAA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103372
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chang SJ, 2013, 27TH INTERNATIONAL SYMPOSIUM ON BALLISTICS, VOLS. 1 AND 2, P173
   Chaudhary C, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3375786
   Chaudhary C, 2020, IEEE T MULTIMEDIA, V22, P897, DOI 10.1109/TMM.2019.2937181
   Chen XQ, 2015, ASIAPAC SIGN INFO PR, P856, DOI 10.1109/APSIPA.2015.7415392
   Davarzani R., 2015, J AI DATA MINING, V3, P21
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Devadoss R, 2019, I CONF VLSI DESIGN, P464, DOI 10.1109/VLSID.2019.00098
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Du L, 2021, MULTIMED TOOLS APPL, V80, P22927, DOI 10.1007/s11042-020-08736-6
   Eskenazi S, 2017, PROC INT CONF DOC, P741, DOI 10.1109/ICDAR.2017.126
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Hassan AM, 2012, INT C COMM INF TECHN, P763
   Hernandez R., 2011, Proceedings of 2011 IEEE 54th International Midwest Symposium on Circuits and Systems (MWSCAS '11), P1
   Holmgren J, 2018, ANN IEEE SYMP FOUND, P850, DOI 10.1109/FOCS.2018.00085
   Karsh RK, 2018, MULTIMED TOOLS APPL, V77, P25409, DOI 10.1007/s11042-018-5799-6
   Khelaifi F, 2020, MULTIMED TOOLS APPL, V79, P19025, DOI 10.1007/s11042-020-08619-w
   Lee H, 2015, EXPERT SYST APPL, V42, P5356, DOI 10.1016/j.eswa.2015.02.005
   Lee H, 2014, PATTERN RECOGN LETT, V49, P155, DOI 10.1016/j.patrec.2014.06.010
   Lei YQ, 2011, SIGNAL PROCESS-IMAGE, V26, P280, DOI 10.1016/j.image.2011.04.007
   Li YN, 2019, MULTIMED TOOLS APPL, V78, P24431, DOI 10.1007/s11042-018-7072-4
   Liu HJ, 2019, IEEE ACCESS, V7, P37211, DOI 10.1109/ACCESS.2019.2896661
   Liu XA, 2015, MULTIMED TOOLS APPL, V74, P2803, DOI 10.1007/s11042-013-1698-z
   Liu YL, 2013, RADIOENGINEERING, V22, P1072
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qin C, 2019, IEEE ACCESS, V7, P45460, DOI 10.1109/ACCESS.2019.2908029
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sajjad M, 2019, IEEE T IND INFORM, V15, P6541, DOI 10.1109/TII.2019.2921652
   Sebastian LS, 2015, PROCEDIA COMPUT SCI, V46, P1554, DOI 10.1016/j.procs.2015.02.081
   Stallings W., 2017, CRYPTOGRAPHY NETWORK, V7th
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang ZJ, 2019, MATH BIOSCI ENG, V16, P6103, DOI 10.3934/mbe.2019305
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wu M, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P166
   Yang HF, 2019, IEEE ACCESS, V7, P51656, DOI 10.1109/ACCESS.2019.2911207
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zhenjun Tang, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P237, DOI 10.1007/978-3-642-35236-2_24
NR 45
TC 8
Z9 8
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 9849
EP 9875
DI 10.1007/s11042-020-10135-w
EA NOV 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000589499300003
DA 2024-07-18
ER

PT J
AU Deebak, BD
   Al-Turjman, F
   Nayyar, A
AF Deebak, B. D.
   Al-Turjman, Fadi
   Nayyar, Anand
TI Chaotic-map based authenticated security framework with privacy
   preservation for remote point-of-care
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote point-of-care; Authentication; And key agreement; Security and
   privacy; Chaotic-map; Real-or-random
ID KEY AGREEMENT SCHEME; USER AUTHENTICATION; MUTUAL AUTHENTICATION;
   PASSWORD AUTHENTICATION; PROTOCOL; CRYPTANALYSIS; INTERNET
AB The challenge of COVID-19 has become more prevalent across the world. It is highly demanding an intelligent strategy to outline the precaution measures until the clinical trials find a successful vaccine. With technological advancement, Wireless Multimedia Sensor Networks (WMSNs) has extended its significant role in the development of remote medical point-of-care (RM-PoC). WMSN is generally located on a communication device to sense the vital signaling information that may periodically be transmitted to remote intelligent pouch This modern remote system finds a suitable professional system to inspect the environment condition remotely in order to facilitate the intelligent process. In the past, the RM-PoC has gained more attention for the exploitation of real-time monitoring, treatment follow-up, and action report generation. Even though it has additional advantages in comparison with conventional systems, issues such as security and privacy are seriously considered to protect the modern system information over insecure public networks. Therefore, this study presents a novel Single User Sign-In (SUSI) Mechanism that makes certain of privacy preservation to ensure better protection of multimedia data. It can be achieved over the negotiation of a shared session-key to perform encryption or decryption of sensitive data during the authentication phase. To comply with key agreement properties such as appropriate mutual authentication and secure session key-agreement, a proposed system design is incorporated into the chaotic-map. The above assumption claims that it can not only achieve better security efficiencies but also can moderate the computation, communication, and storage cost of some intelligent systems as compared to elliptic-curve cryptography or RSA. Importantly, in order to offer untraceability and user anonymity, the RM-PoC acquires dynamic identities from proposed SUSI. Moreover, the security efficiencies of proposed SUSI are demonstrated using informal and formal analysis of the real-or-random (RoR) model. Lastly, a simulation study using NS3 is extensively conducted to analyze the communication metrics such as transmission delay, throughput rate, and packet delivery ratio that demonstrates the significance of the proposed SUSI scheme.
C1 [Deebak, B. D.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Al-Turjman, Fadi] Near East Univ, Res Ctr Al & IoT, Mersin 10, Nicosia, Turkey.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Near East
   University; Duy Tan University; Duy Tan University
RP Deebak, BD (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
EM deebakbd@gmail.com
RI Nayyar, Anand/F-3732-2015; B D, Deebak/ABC-5122-2022; Al-Turjman,
   Fadi/L-2998-2019; Bakkiam David, Deebak/B-2795-2014
OI Nayyar, Anand/0000-0002-9821-6146; Al-Turjman, Fadi/0000-0001-5418-873X;
   Bakkiam David, Deebak/0000-0002-4008-6350
CR Al-Turjman F, 2017, IEEE ACCESS, V5, P24617, DOI 10.1109/ACCESS.2017.2766090
   Amin R, 2017, WIRELESS PERS COMMUN, V96, P4629, DOI 10.1007/s11277-017-4408-8
   Awasthi AK, 2011, COMPUT ELECTR ENG, V37, P869, DOI 10.1016/j.compeleceng.2011.09.015
   Chandrakar P, 2019, INT J AMBIENT COMPUT, V10, P96, DOI 10.4018/IJACI.2019010106
   Chaudhary R.R.K., 2020, J COMPUT THEOR NANOS, V17, P246, DOI 10.1166/jctn.2020.8658
   Chen TH, 2010, ETRI J, V32, P704, DOI 10.4218/etrij.10.1510.0134
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9969-9
   David DB, 2015, WIRELESS PERS COMMUN, V85, P241, DOI 10.1007/s11277-015-2736-0
   Deebak BD, 2019, IEEE ACCESS, V7, P135632, DOI 10.1109/ACCESS.2019.2941575
   Deebak BD, 2015, WIRELESS PERS COMMUN, V81, P77, DOI 10.1007/s11277-014-2118-z
   Deebak BD, 2016, MULTIMED TOOLS APPL, V75, P5795, DOI 10.1007/s11042-015-2542-4
   Deebak BD, 2017, MULTIMEDIA TOOLS APP, V76
   Dharminder Dharminder, 2021, International Journal of Computers and Applications, V43, P1095, DOI 10.1080/1206212X.2019.1682238
   Farash MS, 2016, AD HOC NETW, V36, P152, DOI 10.1016/j.adhoc.2015.05.014
   FRANKS J, 1999, 2617 RFC
   Gope P, 2019, IEEE T IND INFORM, V15, P4957, DOI 10.1109/TII.2019.2895030
   Gunasinghe H, 2018, IEEE T INF FOREN SEC, V13, P1042, DOI 10.1109/TIFS.2017.2777787
   Hu PF, 2017, IEEE INTERNET THINGS, V4, P1143, DOI 10.1109/JIOT.2017.2659783
   Huang XY, 2011, IEEE T PARALL DISTR, V22, P1390, DOI 10.1109/TPDS.2010.206
   ICS, 2011, 3504050 ICS, P1
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Kumari A, 2019, J DISCRET MATH SCI C, V22, P521, DOI 10.1080/09720529.2019.1637155
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Li CT, 2018, COMPUT METH PROG BIO, V157, P191, DOI 10.1016/j.cmpb.2018.02.002
   Li JP, 2020, IEEE INTERNET THINGS, V7, P7334, DOI 10.1109/JIOT.2020.2984618
   Li X, 2020, IEEE SYST J, V14, P39, DOI 10.1109/JSYST.2019.2899580
   Li X, 2016, SECUR COMMUN NETW, V9, P2643, DOI 10.1002/sec.1214
   Liu H, 2019, IEEE INTERNET THINGS, V6, P1352, DOI 10.1109/JIOT.2018.2843561
   Liu H, 2015, IEEE T PARALL DISTR, V26, P241, DOI 10.1109/TPDS.2014.2308218
   Madhusudhan R, 2020, PEER PEER NETW APPL, V13, P82, DOI 10.1007/s12083-019-0717-x
   Mo JQ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/5047379
   Odelu V, 2015, J INF SECUR APPL, V21, P1, DOI 10.1016/j.jisa.2015.01.001
   Oueida S, 2019, MULTIMED TOOLS APPL, V78, P24573, DOI 10.1007/s11042-018-6647-4
   Oueida S, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124307
   Shen JJ, 2003, COMPUT SECUR, V22, P591, DOI 10.1016/S0167-4048(03)00709-0
   Srinivas J, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0720-9
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Wang FF, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/3805058
   Wang FF, 2019, IEEE ACCESS, V7, P101596, DOI 10.1109/ACCESS.2019.2930542
   Wang LQ, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/430806
   Wu F, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9958-z
   Xuan Hung Le, 2011, Journal of Networks, V6, P355, DOI 10.4304/jnw.6.3.355-364
   Yang GM, 2008, J COMPUT SYST SCI, V74, P1160, DOI 10.1016/j.jcss.2008.04.002
   Yu Y, 2017, IEEE T INF FOREN SEC, V12, P767, DOI 10.1109/TIFS.2016.2615853
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhu H, 2015, J INF HIDING MULTIME, V6, P500
NR 46
TC 14
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17103
EP 17128
DI 10.1007/s11042-020-10134-x
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000588867800002
PM 33204211
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Chatterjee, A
   Sen, S
   Kumar, N
   Sarkar, R
AF Ghosh, Soulib
   Chatterjee, Agneet
   Sen, Shibaprasad
   Kumar, Neeraj
   Sarkar, Ram
TI CTRL -CapTuRedLight: a novel feature descriptor for online Assamese
   numeral recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Numeral recognition; Online handwriting; Assamese; Shape based feature;
   Light ray
ID HANDWRITTEN; MODEL
AB Online handwriting recognition (OHR) has gained major research interest not just due to the enormous technological advancement in recent years, but also the easy availability of the various electronic devices. This digital revolution is opening up a new dimension in every passing day to the regional and low resource languages with these languages get noticed by the researchers. In this paper, we have targeted a low resource language, Assamese, which is mainly spoken in the eastern region of India. We have proposed a novel and efficient feature vector for recognition of online handwritten Assamese numeral images. Our feature vector has been conceptualized based on the properties of light rays emerging out from a point source. Here we consider that there are multiple hypothetical light emerging sources in a sample numeral image. The amount of light fenced by the image is quantified and considered as a feature. The idea of using point light source to estimate the shape of online handwritten numerals is completely new and efficient. Impressive recognition accuracy is obtained on application of the feature vector on a standard online handwritten Assamese numeral database and it outnumbers some popular and standard feature descriptors, available in the literature. The source code of this work can be found in the following github link: https://github.com/ghoshsoulib/CTRLAssamese-Digit-Recognition.
C1 [Ghosh, Soulib; Chatterjee, Agneet; Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Sen, Shibaprasad] Future Inst Engn & Management, Dept Comp Sci & Engn, Kolkata, India.
   [Kumar, Neeraj] Thapar Inst Engn & Technol, Dept CSED, Patiala, Punjab, India.
   [Kumar, Neeraj] Univ Petr & Energy Studies, Sch Comp, Dehra Dun, Uttarakhand, India.
   [Kumar, Neeraj] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Jadavpur University; Thapar Institute of Engineering & Technology;
   University of Petroleum & Energy Studies (UPES); Asia University Taiwan
RP Kumar, N (corresponding author), Thapar Inst Engn & Technol, Dept CSED, Patiala, Punjab, India.; Kumar, N (corresponding author), Univ Petr & Energy Studies, Sch Comp, Dehra Dun, Uttarakhand, India.; Kumar, N (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
EM ghoshsoulib@gmail.com; agneet257@gmail.com; shibubiet@gmail.com;
   neeraj.kumar@thapar.edu; ramjucse@gmail.com
RI Sarkar, Ram/AAX-3822-2020; Kumar, Neeraj/L-3500-2016; sen,
   shibaprasad/J-2304-2019
OI Sarkar, Ram/0000-0001-8813-4086; Kumar, Neeraj/0000-0002-3020-3947; sen,
   shibaprasad/0000-0003-4815-6621
CR Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Alam F, 2020, EAI SPRINGER INNOVAT, P135, DOI 10.1007/978-3-030-13705-2_6
   Albregtsen F., 2008, STAT TEXTURE MEASURE, P1
   Alghazo J. M, 2017, J TELECOMMUNICATION, V9, P33
   Ali Abuzaraida M, 2015, ONLINE RECOGNITION S, P45
   Azeem SA, 2012, INT CONF FRONT HAND, P135, DOI 10.1109/ICFHR.2012.249
   Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308
   Baruah U, 2015, J INF PROCESS SYST, V11, P325, DOI 10.3745/JIPS.02.0008
   Bhattacharya U, 2007, PROC INT CONF DOC, P58
   Cilia ND, 2019, PATTERN RECOGN LETT, V121, P77, DOI 10.1016/j.patrec.2018.04.007
   Das N., 2015, IMPROVED FEATURE DES
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Ghosh S, 2019, FILTER ENSEMBLE FEAT
   Ghosh S, 2021, VISUAL COMPUT, V37, P1781, DOI 10.1007/s00371-020-01938-x
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Jindal A., 2018, Pattern Recognition and Image Analysis, V28, P288, DOI 10.1134/S1054661818020086
   Kapoor V., 2013, INT J COMPUTER APPL, V83, P33
   Kherallah M, 2008, PATTERN RECOGN LETT, V29, P580, DOI 10.1016/j.patrec.2007.11.011
   Li XL, 1998, INT C PATT RECOG, P1134, DOI 10.1109/ICPR.1998.711895
   Malakar, 2019, COMMUN COMPUT INF SC, V1020, P27, DOI DOI 10.1007/978-981-13-9361-7_3
   Mandal A, 2018, INT C EM TECHN SUST
   Medhi K, 2015, INT J COMPUT APPL, V109, P34
   Musleh D, 2017, INT ARAB J INF TECHN, V14, P502
   Pal A, 2016, 2016 TWENTY SECOND NATIONAL CONFERENCE ON COMMUNICATION (NCC)
   Potrus MY, 2010, ICEIE 2010 2010 INT, P1
   Ramakrishnan AG, 2013, ACM INT SONF P SER
   Razzak MI, 2009, INT CONF EMERG TECHN, P44, DOI 10.1109/ICET.2009.5353203
   Reddy G.S., 2012, P WORKSH DOC AN REC, P108, DOI [DOI 10.1145/2432553.2432573, 10.1145/2432553]
   Roy K, 2012, STROKE DATABASE DESI, V2, P2534
   Samanta R, 2019, INT J COMPUT VIS IMA, V10
   Sarma B, 2013, NTNL C COMM NCC 2013, V2013, P2013
   Sen S, 2018, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3178457
   Sen S, 2016, LECT NOTES ARTIF INT, V9896, P246, DOI 10.1007/978-3-319-46182-3_21
   Shim J, 2017, J MULTIMED INF SYST, V4, P39
   Singh H., 2020, Revised Selected Papers, V4, P457
   Tagougui N, 2013, INT J DOC ANAL RECOG, V16, P209, DOI 10.1007/s10032-012-0186-8
   Tarannum A, 2020, J BIOMOL STRUCT DYN, V38, P918, DOI 10.1080/07391102.2019.1585952
NR 37
TC 1
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30033
EP 30056
DI 10.1007/s11042-020-10081-7
EA NOV 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000587972400005
DA 2024-07-18
ER

PT J
AU Huan, RH
   Shu, J
   Bao, SL
   Liang, RH
   Chen, P
   Chi, KK
AF Huan, Ruo-Hong
   Shu, Jia
   Bao, Sheng-Lin
   Liang, Rong-Hua
   Chen, Peng
   Chi, Kai-Kai
TI Video multimodal emotion recognition based on Bi-GRU and attention
   fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video emotion recognition; Multimodal; Bi-GRU; Attention mechanism;
   Fusion
AB A video multimodal emotion recognition method based on Bi-GRU and attention fusion is proposed in this paper. Bidirectional gated recurrent unit (Bi-GRU) is applied to improve the accuracy of emotion recognition in time contexts. A new network initialization method is proposed and applied to the network model, which can further improve the video emotion recognition accuracy of the time-contextual learning. To overcome the weight consistency of each modality in multimodal fusion, a video multimodal emotion recognition method based on attention fusion network is proposed. The attention fusion network can calculate the attention distribution of each modality at each moment in real-time so that the network model can learn multimodal contextual information in real-time. The experimental results show that the proposed method can improve the accuracy of emotion recognition in three single modalities of textual, visual, and audio, meanwhile improve the accuracy of video multimodal emotion recognition. The proposed method outperforms the existing state-of-the-art methods for multimodal emotion recognition in sentiment classification and sentiment regression.
C1 [Huan, Ruo-Hong; Shu, Jia; Bao, Sheng-Lin; Liang, Rong-Hua; Chen, Peng; Chi, Kai-Kai] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Huan, RH (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM huanrh@zjut.edu.cn; Shujia1218@qq.com; baoshenglin1994@gmail.com;
   rhliang@zjut.edu.cn; chenpeng@zjut.edu.cn; kkchi@zjut.edu.cn
RI liang, ronghua/H-4463-2012; Chen, Peng/T-7500-2019
OI Chen, Peng/0000-0001-6122-0574
FU Zhejiang Provincial Natural Science Foundation of China [LY19F020032];
   National Natural Science Foundation of China [U1909203, 61872322]
FX This study was funded by the Zhejiang Provincial Natural Science
   Foundation of China (grant number LY19F020032), and National Natural
   Science Foundation of China (grant number U1909203, 61872322).
CR Bairaju SPR, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), DOI 10.1109/i2ct45611.2019.9033902
   Byeon YH, 2014, INT J ADV COMPUT SC, V5, P107, DOI 10.14569/ijacsa.2014.051215
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   Drugman T, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1984
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P994, DOI 10.1109/TASL.2011.2170835
   EKMAN P, 1980, J PERS SOC PSYCHOL, V39, P1125, DOI 10.1037/h0077722
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Fujisaki H., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1605
   Ghosh S, 2016, INTERSPEECH, P3603, DOI 10.21437/Interspeech.2016-692
   Hashimoto K, 2019, PROG THEOR EXP PHYS, V2019, DOI 10.1093/ptep/pty131
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kane J, 2013, IEEE T AUDIO SPEECH, V21, P1170, DOI 10.1109/TASL.2013.2245653
   Kingma D. P., 2014, arXiv
   Kumawat S, 2019, IEEE COMPUT SOC CONF, P207, DOI 10.1109/CVPRW.2019.00030
   Lee J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1537
   Li J, 2013, IEEJ T ELECTR ELECTR, V8, P616, DOI 10.1002/tee.21905
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Ma L, 2019, PERS UBIQUIT COMPUT, V23, P363, DOI 10.1007/s00779-019-01232-1
   Moilanen K., 2007, P REC ADV NAT LANG P, P378
   Morency L.-P., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Nojavanasghari B, 2016, INT C MULT INT ICMI
   Orjesek R, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P213, DOI 10.1109/radioelek.2019.8733572
   Park S, 2014, PROC EUR S-STATE DEV, P50, DOI 10.1109/ESSDERC.2014.6948755
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Rajagopalan SS, 2016, COMPUTER VISION ECCV
   SEYEDITABARI A, 2019, ARXIV190709369
   Shrivastava K, 2019, MULTIMED TOOLS APPL, V78, P29607, DOI 10.1007/s11042-019-07813-9
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Takamura Hiroya., 2006, Proceedings of the 11th Meeting of the European Chapter of the Association for Computational Linguistics (EACL-2006), P201
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Yang B., 2012, P 2012 JOINT C EMPIR, P1335
   Zadeh A., 2018, P AAAI C ART INT, V32
   Zadeh A., 2016, ABS160606259 CORR
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zhao J, 2018, Evid Based Complement Alternat Med, V2018, P1, DOI DOI 10.1109/IJCNN.2018.8489298
NR 45
TC 26
Z9 27
U1 11
U2 126
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 8213
EP 8240
DI 10.1007/s11042-020-10030-4
EA OCT 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587057900001
DA 2024-07-18
ER

PT J
AU Liu, YC
   Shahid, M
   Sarapugdi, W
   Lin, YX
   Chen, JC
   Hua, KL
AF Liu, Yu-Cheng
   Shahid, Mohammad
   Sarapugdi, Wannaporn
   Lin, Yong-Xiang
   Chen, Jyh-Cheng
   Hua, Kai-Lung
TI Cascaded atrous dual attention U-Net for tumor segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT image segmentation; Tumor segmentation; Atrous encoder; Attention
   gate
ID NETWORKS; CANCER; LIVER
AB Automatic segmentation of the organ's tumor and lesion on biomedical imaging is an essential initiative towards clinical study, treatment planning and digital biomedical research. However, precise tumor segmentation on medical imaging is still an open challenge due to the presence of noise in the imaging sequence, the similar tumor pixel intensity with its neighboring tissues, and heterogeneity among human anatomy. Although most of the state-of-the-art algorithms are architecturally dependent on deep convolution networks (DCNs), like 2D and 3D U-Net, they act as a foundation for many biomedical image segmentation. However, 2D DCNs are incompetent to leverage context information from inter-slice completely. At the same time, 3D DCNs can accumulate inter-slice contextual information over the sizeable receptive texture in the organ, but it consumes a considerable amount of GPU memory and burdens with the high execution cost. In order to achieve a promising solution, we proposed a segmentation network called Cascaded Atrous Dual-Attention U-Net. First, our network structure concatenates features from 3D liver segmentation to 2D tumor segmentation for preserving volumetric information as well as enlarging resolution with segmentation accuracy. Second, we embedded dual attention gate in each skip connection layer of the 2D segmentation model, which determines to concentrate on certain discriminative features in order to find tumor segmentation in different organs. Finally, we adopted atrous encoder which extracts wider context features from computed tomography as compared to normal encoder. Furthermore, we tested the proposed method on four different datasets, including liver tumor segmentation benchmark (LiTS), MSD liver, pancreas tumor segmentation and Kidney tumor segmentation (KiTS). Experimental results were compared with the other state-of-the-art segmentation methods. Our proposed approach performs remarkably better than existing methods with around 4 similar to 6% improvement on each benchmark.
C1 [Liu, Yu-Cheng; Shahid, Mohammad; Sarapugdi, Wannaporn; Lin, Yong-Xiang; Hua, Kai-Lung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chen, Jyh-Cheng] Natl Yang Ming Univ, Dept Biomed Imaging & Radiol Sci, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; National Yang Ming
   Chiao Tung University
RP Chen, JC (corresponding author), Natl Yang Ming Univ, Dept Biomed Imaging & Radiol Sci, Taipei, Taiwan.
EM jcchen@ym.edu.tw; hua@mail.ntust.edu.tw
RI SHAHID, MOHAMMAD/AAL-2044-2021; Liu, Yu Cheng/F-7469-2019
OI Hua, Kai-Lung/0000-0002-7735-243X
FU center for Cyber-physical System Innovation from The Featured Areas
   Research Center Program within Higher Education Sprout Project by the
   Ministry of Education (MOE) in Taiwan; Ministry of Science and
   Technology of Taiwan [MOST109-2218-E-011-010,
   MOST109-2221-E-011-125-MY3, MOST108-2221-E-011-116]; NTUST-NYMU Joint
   Research Program [NTUST-NYMU-107-06]
FX This work was financially supported in part by the center for
   Cyber-physical System Innovation from The Featured Areas Research Center
   Program within the framework of the Higher Education Sprout Project by
   the Ministry of Education (MOE) in Taiwan and Ministry of Science and
   Technology of Taiwan (MOST109-2218-E-011-010,
   MOST109-2221-E-011-125-MY3, MOST108-2221-E-011-116), and NTUST-NYMU
   Joint Research Program (NTUST-NYMU-107-06).
CR Albishri AA, 2019, IEEE INT C BIOINFORM, P1416, DOI 10.1109/BIBM47256.2019.8983266
   Alom M. Z., 2018, ARXIV180206955, V6, P014006, DOI 10.1109/NAECON.2018.8556686
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2019, CT Semantic Segmentations, and Surgical Outcomes
   [Anonymous], 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.683
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2019, The liver tumor segmentation benchmark (lits)
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Caizi Li, 2019, Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges. 9th International Workshop, STACOM 2018. Held in Conjunction with MICCAI 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11395), P255, DOI 10.1007/978-3-030-12029-0_28
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chartrand G, 2014, I S BIOMED IMAGING, P641, DOI 10.1109/ISBI.2014.6867952
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng JH, 2019, IEEE INT C BIOINFORM, P1031, DOI [10.1109/bibm47256.2019.8983092, 10.1109/BIBM47256.2019.8983092]
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   cicek Ozgtin, 2016, INT C MED IM COMP CO, P424, DOI DOI 10.1007/978-3-319-46723-8_49
   Dolz J, 2018, NEUROIMAGE, V170, P456, DOI 10.1016/j.neuroimage.2017.04.039
   Fathy ME, 2018, LECT NOTES COMPUT SC, V11219, P832, DOI 10.1007/978-3-030-01267-0_49
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Giusti A, 2013, IEEE IMAGE PROC, P4034, DOI 10.1109/ICIP.2013.6738831
   Gkika E, 2017, STRAHLENTHER ONKOL, V193, P823, DOI 10.1007/s00066-017-1177-y
   Hatamizadeh A., 2019, ARXIV PREPRINT ARXIV
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jiang AW, 2017, J COMPUT SCI TECH-CH, V32, P738, DOI 10.1007/s11390-017-1755-6
   Li GD, 2015, IEEE T IMAGE PROCESS, V24, P5315, DOI 10.1109/TIP.2015.2481326
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Lin D, 2017, IEEE I CONF COMP VIS, P1320, DOI 10.1109/ICCV.2017.147
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Linguraru MG, 2012, IEEE T MED IMAGING, V31, P1965, DOI 10.1109/TMI.2012.2211887
   Liu YC, 2019, IEEE IMAGE PROC, P3322, DOI [10.1109/ICIP.2019.8803471, 10.1109/icip.2019.8803471]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Qi Dou, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P149, DOI 10.1007/978-3-319-46723-8_18
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Sevilla-Lara L, 2016, PROC CVPR IEEE, P3889, DOI 10.1109/CVPR.2016.422
   Shen C., 2017, INFLUENCE DICE LOSS, V281, P117, DOI [10.48550/arXiv.1801.05912, DOI 10.48550/ARXIV.1801.05912]
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Simpson A.L., 2019, LARGE ANNOTATED MEDI
   Snaauw G, 2019, I S BIOMED IMAGING, P802, DOI [10.1109/ISBI.2019.8759276, 10.1109/isbi.2019.8759276]
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tummala P, 2011, J GASTROINTEST ONCOL, V2, P168, DOI 10.3978/j.issn.2078-6891.2011.036
   van Oostenbrugge TJ, 2018, KIDNEY CANCER, V2, P79, DOI 10.3233/KCA-180028
   Velazquez ER, 2013, SCI REP-UK, V3, DOI 10.1038/srep03529
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
   Zhang Yang, 2019, INT C LEARN REPR
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou XY, 2019, ARXIV190109203
NR 65
TC 10
Z9 13
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30007
EP 30031
DI 10.1007/s11042-020-10078-2
EA OCT 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000583128600004
DA 2024-07-18
ER

PT J
AU Alghafis, A
   Munir, N
   Khan, M
AF Alghafis, Abdullah
   Munir, Noor
   Khan, Majid
TI An encryption scheme based on chaotic Rabinovich-Fabrikant system and
   <i>S</i><sub><i>8</i></sub> confusion component
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rabinovich-Fabrikant chaotic system; Confusion component; Security
   analyses
ID HYPERCHAOTIC RABINOVICH; BIFURCATION-ANALYSIS; SECURITY ANALYSIS; IMAGE;
   CONSTRUCTION; OPTIMIZATION; ALGORITHM; BOXES
AB In this research article, we have proposed a novel image encryption scheme for the confidentiality of digital information. The modern block ciphers based on confusion and diffusion characteristic, as proposed by Claude Shannon in 1949. Firstly, we have designed a nonlinear confusion component of a block cipher and apply the action of symmetry group S-8 to generate a pool of 40,320 substitution boxes with the same cryptographic strength. These nonlinear components are responsible for adding confusion in the encryption algorithm. Secondly, we have utilized a nonlinear chaotic dynamical system to add diffusion capability in our proposed encryption scheme. The suggested scheme is further examined under security performance evaluations, which shows the appropriateness of our offered scheme for digital contents.
C1 [Alghafis, Abdullah] King Abdul Aziz City Sci & Technol, Riyadh, Saudi Arabia.
   [Munir, Noor; Khan, Majid] Inst Space Technol, Cyber & Informat Secur Lab CISL, Islamabad, Pakistan.
   [Munir, Noor; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
C3 King Abdulaziz City for Science & Technology
RP Khan, M (corresponding author), Inst Space Technol, Cyber & Informat Secur Lab CISL, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770
CR Ahmad M, 2018, J KING SAUD U CIS
   Ahmad M, 2018, WIRELESS PERS COMMUN, V101, P1715, DOI 10.1007/s11277-018-5787-1
   Ahmad M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070266
   Ahmad M, 2018, J INTELL FUZZY SYST, V34, P1323, DOI 10.3233/JIFS-169428
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Alghafis A, 2020, INT J THEOR PHYS, V59, P1227, DOI 10.1007/s10773-020-04402-7
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Alzaidi AA, 2018, IEEE ACCESS, V6, P55405, DOI 10.1109/ACCESS.2018.2871557
   [Anonymous], 2009, HINDAWI PUBL CORP MA
   Batool SI, 2019, MULTIMED TOOLS APPL, V78, P27611, DOI 10.1007/s11042-019-07881-x
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Hamza R, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/1625678
   Hamza R, 2020, INFORM SCIENCES, V527, P493, DOI 10.1016/j.ins.2019.01.070
   Ibáñez R, 2018, COMPLEXITY, DOI 10.1155/2018/5608286
   Khan M, 2018, UTILIZATION SMALL S
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2019, WIRELESS PERS COMMUN, V109, P849, DOI 10.1007/s11277-019-06594-6
   Khan M, 2019, INT J THEOR PHYS, V58, P2720, DOI 10.1007/s10773-019-04162-z
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, J VIB CONTROL, V21, P3450, DOI 10.1177/1077546314523029
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan MT, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/6081804
   Khanzadi H, 2010, INT CONF SIGN PROCES, P2608, DOI 10.1109/ICOSP.2010.5656132
   Lambic D, 2018, J ELECTRON TEST, V34, P709, DOI 10.1007/s10836-018-5767-0
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Li YT, 2016, NONLINEAR DYNAM, V84, P2387, DOI 10.1007/s11071-016-2652-1
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Munir N, 2018, INT C APPL ENG MATH, DOI [10.1109/ICAEM.2018.8536308, DOI 10.1109/ICAEM.2018.8536308]
   Munir N, 2020, WIREL NETW, DOI 10.1007/s11276-020-02361-9
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rafiq A, 2019, MULTIMED TOOLS APPL, V78, P15527, DOI 10.1007/s11042-018-6953-x
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Waseem HM, 2018, INT J THEOR PHYS, V57, P3584, DOI 10.1007/s10773-018-3872-6
   Wei ZC, 2019, APPL MATH COMPUT, V347, P265, DOI 10.1016/j.amc.2018.10.090
   Wei ZC, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S021812741650125X
   Wei ZC, 2016, NONLINEAR DYNAM, V85, P1635, DOI 10.1007/s11071-016-2783-4
   Wei ZC, 2015, NONLINEAR DYNAM, V82, P131, DOI 10.1007/s11071-015-2144-8
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
NR 50
TC 27
Z9 27
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7967
EP 7985
DI 10.1007/s11042-020-10142-x
EA OCT 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000013
DA 2024-07-18
ER

PT J
AU Li, JH
   Xia, SX
AF Li, Jinhong
   Xia, Shengxiang
TI On the local behavior of spaces of range image patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Range images; Topology; Persistent homology; Klein bottle; Barcode
ID HIGH-CONTRAST PATCHES; NONLINEAR STATISTICS; TOPOLOGY
AB We focus on the quantitative and local topological properties of range images. We consider the spaces M-m of m x m high-contrast patches of range images for m= 3, 5, 7, 9, 11. Using computational topological tools to analyze range image patches, we detect that M-3 (M-9, M-11) has core subsets with the topology of a circle, M-3, M-5, M-7, M-9 and that M-11 have some subspaces with the topology of a Klein bottle. We also discover that the largest subspace with the Klein bottle's topology decreases as the measurements of patches increase, which generalizes the results in the paper of H. Adams and G. Carlsson, and demonstrates properties among optical images and range image patches, which are more similar than those established by Lee et al.
C1 [Li, Jinhong] Qilu Univ Technol, Sch Math & Stat, Jinan 250353, Peoples R China.
   [Xia, Shengxiang] Shandong Jianzhu Univ, Sch Sci, Jinan 250101, Peoples R China.
C3 Qilu University of Technology; Shandong Jianzhu University
RP Xia, SX (corresponding author), Shandong Jianzhu Univ, Sch Sci, Jinan 250101, Peoples R China.
EM lijinhong@qlu.edu.cn; xias@sdjzu.edu.cn
FU National Natural Science Foundation of China [61471409]
FX The authors are very grateful to the reviewers for valuable comments and
   corrections. This work was supported by the National Natural Science
   Foundation of China (No. 61471409).
CR Adams H., 2018, Javaplex tutorial
   Adams H, 2015, TOPOL METHOD NONL AN, V45, P247
   Adams H, 2009, SIAM J IMAGING SCI, V2, P110, DOI 10.1137/070711669
   Borges MS, 2020, MULTIMED TOOLS APPL, V79, P6247, DOI 10.1007/s11042-019-08485-1
   Carlsson G, 2008, INT J COMPUT VISION, V76, P1, DOI 10.1007/s11263-007-0056-x
   Carlsson G, 2009, B AM MATH SOC, V46, P255, DOI 10.1090/S0273-0979-09-01249-X
   de Silva V, 2004, P S POINT BAS GRAPH, DOI [10.2312/SPBG/SPBG04/157-166, DOI 10.2312/SPBG/SPBG04/157-166]
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Ghrist R, 2008, B AM MATH SOC, V45, P61, DOI 10.1090/s0273-0979-07-01191-3
   Hatcher A., 2003, ALGEBRAIC TOPOLOGY
   Huang JG, 2000, PROC CVPR IEEE, P324, DOI 10.1109/CVPR.2000.855836
   Idrobo-Pizo GA, 2019, IET IMAGE PROCESS, V13, P964, DOI 10.1049/iet-ipr.2018.6105
   Jung S, 2018, COMPUT AIDED DESIGN, V94, P16, DOI 10.1016/j.cad.2017.08.001
   Kewen Cha, 2018, Journal of Physics: Conference Series, V1098, DOI 10.1088/1742-6596/1098/1/012026
   Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078
   Qingli Yin, 2015, Proceedings of the 4th International Conference on Computer Engineering and Networks. CENet2014. LNEE 355, P573, DOI 10.1007/978-3-319-11104-9_67
   Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x
   Shen YQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111792
   VANHATEREN JH, 1992, J COMP PHYSIOL A, V171, P157, DOI 10.1007/BF00188924
   Xia SX, 2016, J NONLINEAR SCI APPL, V9, P126, DOI 10.22436/jnsa.009.01.12
   Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y
NR 22
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16441
EP 16472
DI 10.1007/s11042-020-09913-3
EA OCT 2020
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000587058000010
DA 2024-07-18
ER

PT J
AU Malik, A
   Dhall, S
   Gupta, S
AF Malik, Anjali
   Dhall, Sangeeta
   Gupta, Shailender
TI An improved bit plane image encryption technique using RC4 and quantum
   chaotic demeanour
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit planes; Chosen plaintext attack; Cipher block chaining block;
   Encryption; Known plaintext attack; Quantum chaotic logistic map; RC4
ID SCHEME; MAPS
AB To compete with the rising apprehension of data/image security, corporations are endorsing cryptography for protection. A high-quality image encryption scheme must ensure high Entropy, high key sensitivity, ability to resist known and chosen-plaintext attack, large keyspace, high randomness, and resistance towards differential attack. To accomplish this need, an improved bit plane image encryption scheme using RC4 and Quantum Chaotic behavior is proposed. In the projected mechanism, to ensure less bandwidth usage and efficient transmission of data over the network, YCbCr format is used. The keys are generated using the s- logistic map due to its high randomness, non-periodic behavior, and large keyspace to resist brute-force attacks. This contemporary encryption process includes confusion and diffusion stages. For the confusion stage, the Channel transformation process is employed, which helps in attaining randomness. A multilevel diffusion stage is implemented using CBC (Cipher Block chaining block), Zigzag permutation, and Inter bit plane permutation process. Additionally, the technique's randomness and complexity are strengthened by utilizing RC4 to generate S-box for byte substitution. The projected framework is implemented in MATLAB and assessed using various performance metrics like mean square error (MSE), Peak Signal to noise ratio (PSNR), Entropy, and others referenced in writing. Result analysis illustrates that the proposed model reveals its capacity to conceal the confidentiality of information of the transmitted image and is more efficient than its classical counterpart. Its security is verified by the statistical, key-space, and key analysis.
C1 [Malik, Anjali; Dhall, Sangeeta; Gupta, Shailender] JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Dhall, S (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, India.
EM anjalimalik0611@gmail.com; sangeeta_dhall@yahoo.co.in;
   shailender81@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Malik, Anjali/0009-0006-9598-3522
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abura'ed N, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3009965
   Ahmed HAM, 2007, INZ MINER, P1
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Anderson T. W., 1958, INTRO MULTIVARIATE S, V2
   [Anonymous], 2014, P INT J INN RES ADV
   [Anonymous], 2015, INT J MAG ENG TECHNO
   [Anonymous], RESEARCH-CHINA, DOI DOI 10.18502/JDER.4069
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Barker E, 2017, NIST Special Publication (SP) 800-67 Rev. 2 (Draft))
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Dhall S, 2020, MULTIMED TOOLS APPL, V79, P1987, DOI 10.1007/s11042-019-08223-7
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Hui Liu, 2017, International Journal of Network Security, V19, P347, DOI 10.6633/IJNS.201703.19(3).04
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kester QA, 2013, ARXIV13077786
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Li PC, 2018, INT J THEOR PHYS, V57, P258, DOI 10.1007/s10773-017-3561-x
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu B, 2015, SCI CHINA PHYS MECH, V58, DOI 10.1007/s11433-015-5714-3
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Matsui M., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Rayarikar R., 2012, Int J Comput Appl, V50, P12
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Wei CY, 2018, IEEE T COMPUT, V67, P2, DOI 10.1109/TC.2017.2721404
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yan F, 2017, INT J QUANTUM INF, V15, DOI 10.1142/S0219749917300017
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 42
TC 8
Z9 9
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7911
EP 7937
DI 10.1007/s11042-020-09973-5
EA OCT 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000019
DA 2024-07-18
ER

PT J
AU Kala, TS
   Christy, A
AF Sree Kala, T.
   Christy, A.
TI HFFPNN classifier: a hybrid approach for intrusion detection based OPSO
   and hybridization of feed forward neural network (FFNN) and
   probabilistic neural network (PNN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature reduction; Feature classification; Intrusion detection; HFFPNN;
   Feed-forward neural network (FFNN); Probabilistic neural network (PNN);
   Oppositional particle swarm optimization (OPSO)
AB Quick increase in web and system advancements has prompted significant increase in number of attacks and intrusions. Identification and prevention of these attacks has turned into an important part of security. Intrusion detection framework is one of the vital approaches to accomplish high security in computer systems and used to oppose attacks. Intrusion detection frameworks have reviled of dimensionality which tends to build time complexity and reduce resource use. Therefore, it is desirable that critical components of information must be examined by interruption detection framework to decrease dimensionality. These reduced features are then fed to a HFFPNN for training and testing on NSL-KDD dataset. HFFPNN is the hybridization of feed forward neural network (FFNN) and probabilistic neural network (PNN). Pre-processing of NSL-KDD dataset has been done to convert string attributes into numeric attributes before training. Comparisons with recent and relevant approaches are also tabled. Experimental results show the prominence of HFFPNN technique over the existing techniques in terms of intrusion detection classification. Therefore, the scope of this study has been expanded to encompass hybrid classifiers.
C1 [Sree Kala, T.] VISTAS, Dept Comp Sci, Chennai, Tamil Nadu, India.
   [Christy, A.] Sathyabama Univ, Dept Comp Sci, Chennai, Tamil Nadu, India.
C3 Vels Institute of Science, Technology & Advanced Studies; Sathyabama
   Institute of Science & Technology
RP Kala, TS (corresponding author), VISTAS, Dept Comp Sci, Chennai, Tamil Nadu, India.
EM sreekalatm@gmail.com; achristy@gmail.com
RI T, Sree Kala/ABD-6102-2021
OI A, CHRISTY/0000-0001-5452-4510
CR Ahmad I] I., 2009, IEEE S IND EL APPL I
   An N, 2013, ENERGY, V49, P279, DOI 10.1016/j.energy.2012.10.035
   [Anonymous], 1990, TECHNICAL REPORT
   [Anonymous], 2017, J COMPUT SCI
   Ashfaq RAR, 2017, INFORM SCIENCES, V378, P484, DOI 10.1016/j.ins.2016.04.019
   Berthold MR, 1998, NEUROCOMPUTING, V19, P167, DOI 10.1016/S0925-2312(97)00063-5
   Conti Gregory., 2006, Countering Security Analyst and Network Administrator Overload Through Alert and Packet Visualization
   Dhanabal L., 2015, Int. J. adv. res. comput. commun. eng, V4
   Duque S, 2015, PROCEDIA COMPUT SCI, V61, P46, DOI 10.1016/j.procs.2015.09.145
   Egham Hooper E, 2007, IEEE INT C MULT UB E
   Gao YM, 2018, RIV PUBL SER INNOV, P1, DOI 10.1109/ACCESS.2017.2788877
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Jiawei H, 2006, DATA MINING CONCEPTS, P296
   Jin H, 2004, P 10 IEEE INT WORKSH
   Kala T. Sree, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P184, DOI 10.1109/COMITCon.2019.8862237
   Khatib EJ, 2015, EXPERT SYSTEMS APPL
   Lei JZ, 2004, P 2 ANN C COMM NETW
   Mohammad MN, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.198
   Nguyen HA, 2008, LECT NOTES COMPUT SC, V5297, P399, DOI 10.1007/978-3-540-88623-5_41
   Olusola A. A., 2010, P WORLD C ENG COMP S, V1
   Revathi S., 2013, INT J ENG RES TECHNO, V2, P1848
   Roy PK, 2014, INT J ELEC POWER, V57, P392, DOI 10.1016/j.ijepes.2013.12.006
   Scarfone K., 2007, Special Publication (NIST SP)
   Sharma N, 2012, ICACCI 12
   Soon tee T, 2004, IEEE COMPUTER GRAPHI
   Sree Kala T, 2017, J ADV RES DYNAMICAL, V04, P40
   Sree Kala T, 2016, INT J ENG TECHNOL, V8, P580
   Tejavibulya N, 2011, BIOFABRICATION, V3, DOI 10.1088/1758-5082/3/3/034110
   Tiwari KK, 2011, INT J ADV COMP TECHN
   Wang BX, 2008, J CENTR S U TECHNOL, V15
   Wang J, 2017, KNOWL-BASED SYST, V132, P167, DOI 10.1016/j.knosys.2017.06.022
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Xu Xin., 2006, International Journal of Web Services Practices, V2, P49
NR 34
TC 5
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 6457
EP 6478
DI 10.1007/s11042-020-09804-7
EA OCT 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000579257900001
DA 2024-07-18
ER

PT J
AU Donev, R
   Alsadoon, A
   Prasad, PWC
   Dawoud, A
   Haddad, S
   Alrubaie, A
AF Donev, Risto
   Alsadoon, Abeer
   Prasad, P. W. C.
   Dawoud, Ahmed
   Haddad, Sami
   Alrubaie, Ahmad
TI A novel secure solution of using mixed reality in data transmission for
   bowel and jaw surgical telepresence: enhanced rivest cipher RC6 block
   cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Surgical Telepresence; Secure data transmission; Hybrid
   RC6 and Rubik's cube algorithm; Brute force attack
ID SIMULTANEOUS FUSION; ENCRYPTION; IMAGE; COMPRESSION; EFFICIENT; SCHEME;
   PROTECTION; H.264/AVC
AB Security threats are crucial challenges that deter Mixed reality (MR) communication in medical telepresence. This research aims to improve the security by reducing the chances of types of various attacks occurring during the real-time data transmission in surgical telepresence as well as reduce the time of the cryptographic algorithm and keep the quality of the media used. The proposed model consists of an enhanced RC6 algorithm in combination. Dynamic keys are generated from the RC6 algorithm mixed with RC4 to create dynamic S-box and permutation table, preventing various known attacks during the real-time data transmission. For every next session, a new key is created, avoiding possible reuse of the same key from the attacker. The results obtained from our proposed system are showing better performance compared to the state of art. The resistance to the tested attacks is measured throughout the entropy, Pick to Signal Noise Ratio (PSNR) is decreased for the encrypted image than the state of art, structural similarity index (SSIM) closer to zero. The execution time of the algorithm is decreased for an average of 20%. The proposed system is focusing on preventing the brute force attack occurred during the surgical telepresence data transmission. The paper proposes a framework that enhances the security related to data transmission during surgeries with acceptable performance.
C1 [Donev, Risto; Alsadoon, Abeer; Prasad, P. W. C.; Dawoud, Ahmed] Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
   [Haddad, Sami] Greater Western Sydney Area Hlth Serv, Dept Oral & Maxillofacial Serv, Mt Druitt, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
   [Alrubaie, Ahmad] Univ New South Wales, Fac Med, Sydney, NSW, Australia.
C3 Charles Sturt University; Florey Institute of Neuroscience & Mental
   Health; University of New South Wales Sydney
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Dawoud, Ahmed/AAD-1295-2022; Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Dawoud, Ahmed/0000-0002-2051-5920
CR Alfalou A, 2013, OPT EXPRESS, V21, P8025, DOI 10.1364/OE.21.008025
   Alfalou A, 2011, OPT EXPRESS, V19, P24023, DOI 10.1364/OE.19.024023
   Almalowi SJ, 2012, J APPL MATH, DOI 10.1155/2012/135173
   [Anonymous], 2019, MULTIMEDIA TOOLS APP
   [Anonymous], 2007, Fundamentals of WiMAX: understanding broadband wireless networking
   [Anonymous], SENSORS, DOI DOI 10.1109/JSEN.2017.2671241
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Chen SK, 2018, IEEE T CIRC SYST VID, V28, P2359, DOI 10.1109/TCSVT.2017.2703946
   Darwish SM, 2019, MULTIMED TOOLS APPL, V78, P19229, DOI 10.1007/s11042-019-7256-6
   El-Bakary EM, 2019, MULTIMED TOOLS APPL, V78, P14173, DOI 10.1007/s11042-018-6765-z
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Haque SA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/217415
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Jridi M, 2018, OPT LASER ENG, V102, P59, DOI 10.1016/j.optlaseng.2017.10.007
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P15457, DOI 10.1007/s11042-017-5124-9
   Noura HN, 2019, MULTIMED TOOLS APPL, V78, P14837, DOI 10.1007/s11042-018-6845-0
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Premkumar R, 2019, MULTIMED TOOLS APPL, V78, P9577, DOI 10.1007/s11042-018-6534-z
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Selecky M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030853
   Shah RA, 2019, MULTIMED TOOLS APPL, V78, P21455, DOI 10.1007/s11042-019-7451-5
   Sharma A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092119
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Venckauskas A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051554
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Xiang T, 2014, APPL SOFT COMPUT, V21, P159, DOI 10.1016/j.asoc.2014.03.009
   Xu DW, 2019, IEEE ACCESS, V7, P66028, DOI 10.1109/ACCESS.2019.2916484
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P21803, DOI 10.1007/s11042-017-5590-0
   Yang J, 2018, IEEE T IND ELECTRON, V65, P4257, DOI 10.1109/TIE.2017.2772190
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
NR 36
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5021
EP 5046
DI 10.1007/s11042-020-09934-y
EA OCT 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600004
DA 2024-07-18
ER

PT J
AU Hosseini, S
   Sardo, SR
AF Hosseini, Soodeh
   Sardo, Saman Rafiee
TI Data mining tools -a case study for network intrusion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining tools; Machine learning algorithms; Intrusion detection;
   Knime; Scikit-learn
ID EMPIRICAL MODE DECOMPOSITION; SUPPORT VECTOR REGRESSION; SVR;
   RAPIDMINER; ALGORITHMS; KEEL
AB With the growth of data mining and machine learning approaches in recent years, many efforts have been made to generalize these sciences so that researchers from any field can easily utilize these sciences. One of the most important of these efforts is the development of data mining tools that try to hide the complexities from researchers so that they can achieve a professional output with any level of knowledge. This paper is focused on reviewing and comparing data mining and machine learning tools including WEKA, KNIME, Keel, Orange, Azure, IBM SPSS Modeler, R and Scikit-Learn to show what approach each of these methods has taken in the face of the complexities and problems of different scenarios of generalization of data mining and machine learning. In addition, for a more detailed review, this paper examines the challenge of network intrusion detection in two tools, Knime with graphical interface and Scikit-Learn with coding environment.
C1 [Hosseini, Soodeh; Sardo, Saman Rafiee] Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
   [Hosseini, Soodeh] Shahid Bahonar Univ Kerman, Mahani Math Res Ctr, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK); Shahid Bahonar University of
   Kerman (SBUK)
RP Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.; Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Mahani Math Res Ctr, Kerman, Iran.
EM so_hosseini@uk.ac.ir; saman.rafiee.rs@gmail.com
RI hosseini, soodeh/AAC-2047-2022
CR Abdar M, 2015, J SCI CSJ, V36, P1
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Altalhi AH, 2017, WIRES DATA MIN KNOWL, V7, DOI 10.1002/widm.1204
   [Anonymous], 2000, R LANG DEF
   Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI [10.1080/713827181, 10.1080/08839510390219309]
   Berthold MR, 2008, STUD CLASS DATA ANAL, P319, DOI 10.1145/1656274.1656280
   Brahmeswara Kadaru B, 2017, INT RES J ENG TECHNO, V04, P930
   Casas P, 2012, COMPUT COMMUN, V35, P772, DOI 10.1016/j.comcom.2012.01.016
   Chappel D, 2015, INTRO AZURE MACHINE, P1
   Elavarasan D, 2018, COMPUT ELECTRON AGR, V155, P257, DOI 10.1016/j.compag.2018.10.024
   Elder JF, 1998, 4 INT C KNOWL DISC D, P1
   Fan GF, 2016, NEUROCOMPUTING, V173, P958, DOI 10.1016/j.neucom.2015.08.051
   Goebel Michael., 1999, SIGKDD EXPLOR NEWSL, V1, P20
   Graczyk M, 2009, LECT NOTES ARTIF INT, V5796, P800
   Hassan MM, 2020, INFORM SCIENCES, V513, P386, DOI 10.1016/j.ins.2019.10.069
   Hodo E., 2017, Shallow and deep networks intrusion detection system: A taxonomy and survey
   Hong WC, 2013, INT J ELEC POWER, V44, P604, DOI 10.1016/j.ijepes.2012.08.010
   Hong WC, 2011, ENERGY, V36, P5568, DOI 10.1016/j.energy.2011.07.015
   Jovic A, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1112, DOI 10.1109/MIPRO.2014.6859735
   Juniper Networks, 2015, JUN NETW MAN PACK PE
   Kumar V., 2006, Introduction to Data Mining
   Li MW, 2019, NONLINEAR DYNAM, V97, P2579, DOI 10.1007/s11071-019-05149-5
   Liu H, 2002, DATA MIN KNOWL DISC, V6, P393, DOI 10.1023/A:1016304305535
   McHugh J., 2000, ACM Transactions on Information and Systems Security, V3, P262, DOI 10.1145/382912.382923
   Mikut R, 2011, WIRES DATA MIN KNOWL, V1, P431, DOI 10.1002/widm.24
   Naik A, 2016, PROCEDIA COMPUT SCI, V85, P662, DOI 10.1016/j.procs.2016.05.251
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pop Daniel., Overview of Machine Learning Tools and Libraries
   Raut R, 2015, INT J ELECT COMMUN S, V2015, P128
   Rexer K, 2015, DATA SCI SURVEY
   Rodríguez-Fdez I, 2015, IEEE INT FUZZY SYST
   Tavallaee M, 2009, 2009 IEEE S COMP INT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
NR 36
TC 8
Z9 10
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 4999
EP 5019
DI 10.1007/s11042-020-09916-0
EA OCT 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000574727600007
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, E
   Hou, YY
   Li, GL
AF Zhang, En
   Hou, Yingying
   Li, Gongli
TI A lattice-based searchable encryption scheme with the validity period
   control of files
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Searchable encryption; Keyword search; LWE problem; Validity period
   control; Multimedia data
ID PUBLIC-KEY ENCRYPTION; KEYWORD SEARCH
AB In recent years, with the dramatic increase in the use of multimedia data, rapid retrieval and sharing of the multimedia data have become major trends. The validity period control function widely used in daily softwares, which enables multimedia data to be shared from a specific time and revokes the authorization of shared data at another specific time, thereby effectively enhancing the personalized experience of multimedia data users. At the same time, to protect privacy, databases usually store data in an encrypted form and use searchable encryption technology to retrieve keywords on the ciphertext to quickly extract the required multimedia data. However, the existing searchable encryption scheme cannot control the reading of multimedia data by using validity period. To solve this problem, we propose a lattice-based searchable encryption scheme with the validity period control of files. In order that the data owners have flexible and fine-grained control over the files, we convert the time information into a lattice vector for setting a different valid time for each file. Meanwhile, we embed the time information into the ciphertext, so that the data owner only needs to set the validity period once to automatically maintain the life cycle of the files over encrypted data, instead of manually withdrawing each expired file. Furthermore, we combine searchable encryption and time-distance so that our scheme returns valid files only if the keywords match correctly and the search time matches the file's validity period. This scheme is a candidate for time-controlled searchable encryption technology in the post-quantum era because our scheme constructed on learning with error (LWE) problem which has been proven to resist quantum attacks.
C1 [Zhang, En; Hou, Yingying; Li, Gongli] Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.
   [Zhang, En; Hou, Yingying; Li, Gongli] Internet Things Henan Prov, Lab Intelligence Business, Xinxiang 453007, Henan, Peoples R China.
C3 Henan Normal University
RP Zhang, E (corresponding author), Henan Normal Univ, Coll Comp & Informat Engn, Xinxiang 453007, Henan, Peoples R China.; Zhang, E (corresponding author), Internet Things Henan Prov, Lab Intelligence Business, Xinxiang 453007, Henan, Peoples R China.
EM zhangenzdrj@163.com
OI Hou, Yingying/0000-0002-0929-4477; Zhang, En/0000-0003-4106-6877
FU National Natural Science Foundation of China [U1604156, 61901160,
   U1804164]; Science and Technology Research Project of Henan Province
   [192102210131]
FX This work was supported by National Natural Science Foundation of China
   (U1604156, 61901160. U1804164) and Science and Technology Research
   Project of Henan Province (192102210131).
CR Agrawal S, 2010, LECT NOTES COMPUT SC, V6223, P98, DOI 10.1007/978-3-642-14623-7_6
   Alwen J, 2011, THEOR COMPUT SYST, V48, P535, DOI 10.1007/s00224-010-9278-3
   [Anonymous], 2013, INT J INFORM TECHNOL
   Baek J, 2008, LECT NOTES COMPUT SC, V5072, P1249, DOI 10.1007/978-3-540-69839-5_96
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Cash D, 2010, LECT NOTES COMPUT SC, V6110, P523
   Emura K, 2011, IEICE T FUND ELECTR, VE94A, P1682, DOI 10.1587/transfun.E94.A.1682
   Farràs O, 2019, INT J INF SECUR, V18, P533, DOI 10.1007/s10207-018-00426-7
   Gentry C, 2008, ACM S THEORY COMPUT, P197
   Gentry C, 2010, LECT NOTES COMPUT SC, V6110, P506
   Goh E.-J., 2003, Rep. 2003/216
   Guo ZQ, 2018, J SYST SOFTWARE, V137, P380, DOI 10.1016/j.jss.2017.12.008
   Handa R, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5201
   Hong J, 2019, CLUSTER COMPUT, V22, pS5763, DOI 10.1007/s10586-017-1521-0
   Hou CJ, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P336, DOI 10.1109/3PGCIC.2013.57
   Li JG, 2017, IEEE T SERV COMPUT, V10, P715, DOI 10.1109/TSC.2016.2542813
   Li WB, 2017, J THORAC ONCOL, V12, P94, DOI 10.1016/j.jtho.2016.08.145
   Lin L, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P132, DOI 10.1109/ICMIPE.2013.6864519
   Ma MM, 2018, IEEE T IND INFORM, V14, P759, DOI 10.1109/TII.2017.2703922
   Miao Y., 2017, IEEE Trans Serv Comput
   Miao Y, 2019, IEEE Trans Dependable Secure Comput
   Miao YB, 2017, PEER PEER NETW APPL, V10, P995, DOI 10.1007/s12083-016-0458-z
   Peikert C, 2009, ACM S THEORY COMPUT, P333
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   Song DX, 2000, IEEE COMPUT SOC
   Tahir S, 2017, IEEE TRUST BIG, P425, DOI 10.1109/Trustcom/BigDataSE/ICESS.2017.267
   Wang SP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206126
   Xie R, 2018, INT J WEB GRID SERV, V14, P3, DOI 10.1504/IJWGS.2018.088357
   Xu L, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P122, DOI 10.1145/3321705.3329814
   Xu P, 2013, IEEE T COMPUT, V62, P2266, DOI 10.1109/TC.2012.215
   Yang Y, 2018, MULTIMED TOOLS APPL, V77, P9927, DOI 10.1007/s11042-017-4560-x
   Yang Y, 2016, IEEE T INF FOREN SEC, V11, P746, DOI 10.1109/TIFS.2015.2509912
   Yin H, 2019, IEEE ACCESS, V7, P5682, DOI 10.1109/ACCESS.2018.2889754
   Zhang B, 2011, J NETW COMPUT APPL, V34, P262, DOI 10.1016/j.jnca.2010.07.007
   Zhang E, 2017, INFORM SCIENCES, V387, P180, DOI 10.1016/j.ins.2016.09.056
   Zhang XJ, 2019, INFORM SCIENCES, V494, P193, DOI 10.1016/j.ins.2019.04.051
   Zhang XJ, 2018, WIRELESS PERS COMMUN, V100, P907, DOI 10.1007/s11277-018-5357-6
   Zhang Y, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010018
NR 39
TC 3
Z9 3
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4655
EP 4672
DI 10.1007/s11042-020-09898-z
EA SEP 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100003
DA 2024-07-18
ER

PT J
AU Jung, H
   Lee, R
   Lee, SH
   Hwang, W
AF Jung, Hyungho
   Lee, Ryong
   Lee, Sang-Hwan
   Hwang, Wonjun
TI Active weighted mapping-based residual convolutional neural network for
   image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Object recognition; Convolutional neural network;
   Residual convolutional network
AB In visual recognition, the key to the performance improvement of ResNet is the success in establishing the stack of deep sequential convolutional layers using identical mapping by a shortcut connection. It results in multiple paths of data flow under a network and the paths are merged with the equal weights. However, it is questionable whether it is correct to use the fixed and predefined weights at the mapping units of all paths. In this paper, we introduce the active weighted mapping method which infers proper weight values based on the characteristic of input data on the fly. The weight values of each mapping unit are not fixed but changed as the input image is changed, and the most proper weight values for each mapping unit are derived according to the input image. For this purpose, channel-wise information is embedded from both the shortcut connection and convolutional block, and then the fully connected layers are used to estimate the weight values for the mapping units. We train the backbone network and the proposed module alternately for a more stable learning of the proposed method. Results of the extensive experiments show that the proposed method works successfully on the various backbone architectures from ResNet to DenseNet. We also verify the superiority and generality of the proposed method on various datasets in comparison with the baseline.
C1 [Jung, Hyungho; Hwang, Wonjun] Ajou Univ, Dept Artificial Intelligence, San 5-1, Suwon 16499, Gyeonggi Do, South Korea.
   [Lee, Ryong; Lee, Sang-Hwan] Korea Inst Sci & Technol Informat, Res Data Sharing Ctr, Daejeon 34141, South Korea.
C3 Ajou University; Korea Institute of Science & Technology Information
   (KISTI)
RP Hwang, W (corresponding author), Ajou Univ, Dept Artificial Intelligence, San 5-1, Suwon 16499, Gyeonggi Do, South Korea.
EM hhjung1202@ajou.ac.kr; ryonglee@kisti.re.kr; sanglee@kisti.re.kr;
   wjhwang@ajou.ac.kr
RI Hwang, Wonjun/AAD-9090-2021; Hwang, Wonjun/G-8560-2016
OI Hwang, Wonjun/0000-0001-8895-0411
FU Research and Development project, Enabling a System for Sharing and
   Disseminating Research Data of Korea Institute of Science and Technology
   (KISTI), South Korea [K-20-L01-C04-S01]
FX This work was supported by a Research and Development project, Enabling
   a System for Sharing and Disseminating Research Data of Korea Institute
   of Science and Technology (KISTI), South Korea, under Grant
   K-20-L01-C04-S01. The corresponding author is Dr. Wonjun Hwang.
CR Duda R., 1973, Pattern Classification and Scene Analysis
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Hwang W, 2018, IEICE T INF SYST, VE101D, P1213, DOI 10.1587/transinf.2017EDL8233
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsson G., 2017, ICLR, P1
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Moharana PC, 2019, ENVIRON EARTH SCI, V78, DOI 10.1007/s12665-019-8460-4
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RupeshKumar., 2015, CoRR
   Sun X, 2021, IEEE T IND ELECTRON, V68, P3588, DOI 10.1109/TIE.2020.2977553
   Sun Y, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259399
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Veit A, 2018, LECT NOTES COMPUT SC, V11205, P3, DOI 10.1007/978-3-030-01246-5_1
   Veit A, 2016, ADV NEUR IN, V29
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
NR 30
TC 4
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33139
EP 33153
DI 10.1007/s11042-020-09808-3
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000572601100003
DA 2024-07-18
ER

PT J
AU Tiotsop, LF
   Mizdos, T
   Uhrina, M
   Barkowsky, M
   Pocta, P
   Masala, E
AF Fotio Tiotsop, Lohic
   Mizdos, Tomas
   Uhrina, Miroslav
   Barkowsky, Marcus
   Pocta, Peter
   Masala, Enrico
TI Modeling and estimating the subjects' diversity of opinions in video
   quality assessment: a neural network based approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video quality; Subjective testing; Opinions diversity; Neural networks
AB Subjective experiments are considered the most reliable way to assess the perceived visual quality. However, observers' opinions are characterized by large diversity: in fact, even the same observer is often not able to exactly repeat his first opinion when rating again a given stimulus. This makes the Mean Opinion Score (MOS) alone, in many cases, not sufficient to get accurate information about the perceived visual quality. To this aim, it is important to have a measure characterizing to what extent the observed or predicted MOS value is reliable and stable. For instance, the Standard deviation of the Opinions of the Subjects (SOS) could be considered as a measure of reliability when evaluating the quality subjectively. However, we are not aware of the existence of models or algorithms that allow to objectively predict how much diversity would be observed in subjects' opinions in terms of SOS. In this work we observe, on the basis of a statistical analysis made on several subjective experiments, that the disagreement between the quality as measured by means of different objective video quality metrics (VQMs) can provide information on the diversity of the observers' ratings on a given processed video sequence (PVS). In light of this observation we: i) propose and validate a model for the SOS observed in a subjective experiment; ii) design and train Neural Networks (NNs) that predict the average diversity that would be observed among the subjects' ratings for a PVS starting from a set of VQMs values computed on such a PVS; iii) give insights into how the same NN based approach can be used to identify potential anomalies in the data collected in subjective experiments.
C1 [Fotio Tiotsop, Lohic; Masala, Enrico] Politecn Torino, Turin, Italy.
   [Mizdos, Tomas; Uhrina, Miroslav; Pocta, Peter] Univ Zilina, Zilina, Slovakia.
   [Barkowsky, Marcus] Deggendorf Inst Technol DIT, Deggendorf, Germany.
C3 Polytechnic University of Turin; University of Zilina
RP Masala, E (corresponding author), Politecn Torino, Turin, Italy.
EM lohic.fotiotiotsop@polito.it; tomas.mizdos@feit.uniza.sk;
   miroslav.uhrina@feit.uniza.sk; marcus.barkowsky@th-deg.de;
   peter.pocta@feit.uniza.sk; enrico.masala@polito.it
RI Pocta, Peter/A-6228-2010; Uhrina, Miroslav/GPG-1668-2022
OI Pocta, Peter/0000-0001-6791-1325; Uhrina, Miroslav/0000-0002-5983-6019
FU Politecnico di Torino within the CRUI-CARE Agreement
FX Open access funding provided by Politecnico di Torino within the
   CRUI-CARE Agreement.
CR Aldahdooh A, 2019, SIGNAL PROCESS-IMAGE, V74, P32, DOI 10.1016/j.image.2019.01.004
   [Anonymous], 2012, ITU T REC P 910 SUBJ
   [Anonymous], 2018, VMAF VID MULT ASS FU
   [Anonymous], 2010, VQEG REPORT VALIDATI
   [Anonymous], 2012, ITU T REC BT 500 MET
   [Anonymous], 2012, ITU T REC P 1401 MET
   Aroussi S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P200, DOI 10.1109/ComManTel.2014.6825604
   Bhattacharya A, 2020, MULTIMED TOOLS APPL, V79, P5545, DOI 10.1007/s11042-019-08444-w
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Ding Y, 2017, SIGNAL PROCESS-IMAGE, V54, P81, DOI 10.1016/j.image.2017.03.001
   Fotio Tiotsop L, 2020, P INT C AC SPEECH SI
   Freitas PG, 2018, SIGNAL PROCESS-IMAGE, V64, P1, DOI 10.1016/j.image.2018.02.010
   Hossfeld T, 2011, INT WORK QUAL MULTIM, P131, DOI 10.1109/QoMEX.2011.6065690
   Janowski L, 2015, IEEE T MULTIMEDIA, V17, P2210, DOI 10.1109/TMM.2015.2484963
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Li Z, 2017, IEEE DATA COMPR CONF, P52, DOI 10.1109/DCC.2017.26
   Mocanu DC, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.061208
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Mu M, 2012, MULTIMED TOOLS APPL, V61, P787, DOI 10.1007/s11042-011-0946-3
   Mushtaq MS., 2012, Networks and Optical Communications (NOC), 2012 17th European Conference on, P1, DOI DOI 10.1109/NOC.2012.6249939
   Paudyal P, 2016, MULTIMED TOOLS APPL, V75, P16461, DOI 10.1007/s11042-015-3214-0
   Pinson M. H, 2018, TM18532 NTIA
   Reiter U, 2014, T-LAB SER TELECOMMUN, P55, DOI 10.1007/978-3-319-02681-7_4
   Seufert M, 2019, CONF INNOV CLOUD, P7, DOI 10.1109/ICIN.2019.8685913
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tiotsop L.F., 2019, 11 INT C QUAL MULT E, P1, DOI [10.1109/QoMEX.2019.8743303, DOI 10.1109/QOMEX.2019.8743303]
   von der Gracht HA, 2012, TECHNOL FORECAST SOC, V79, P1525, DOI 10.1016/j.techfore.2012.04.013
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wierman MJ, 2005, NAFIPS 2005 - 2005 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P75, DOI 10.1109/NAFIPS.2005.1548511
   Xu Long., 2015, Visual quality assessment by machine learning
NR 31
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3469
EP 3487
DI 10.1007/s11042-020-09704-w
EA SEP 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400002
OA hybrid
DA 2024-07-18
ER

PT J
AU Khan, A
AF Khan, Ahmed
TI 2DOTS-multi-bit-encoding for robust and imperceptible image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Multi-bit encoding-decoding; Robustness; Imperceptibility;
   Otsu-DWT
ID SCHEME; SECURITY
AB In this article, a new and improvised image watermarking (IW) technique on colored images is proposed to mitigate robustness and imperceptibility issues found often in the past presented schemes. Most schemes exhibit low robustness due to LSB's (Least Significant Bit) and MSB's (Most Significant Bit) based information hiding in the cover image. However, most of these IW schemes have low imperceptibility as the cover image distortion reveals to the attacker due to information hiding in MSB's. Such IW schemes used to hide the secret message via MSBs and LSBs are susceptible to malicious intruder attacks which results in low robustness, whereas, the attacks on MSB's have an impact of reduced imperceptibility. Therefore, this paper propounds a digital IW method named as 2D Otsu algorithm, which allows embedding of a grayscale image into a colored host in the wavelet domain. According to this algorithm, the host image is disintegrated into three color bands of blue, red, and green. Each band is divided into small patches leading to the calculation of entropy followed by finding of the threshold that is estimated by taking the average of entropies of all the patches. Wavelet representation of each patch with entropy less than the threshold is given by applying DWT (Discrete Wavelet Transform). Later, by decomposing gray-scale image into binary bits, secret information embedded by quantization technique into optimal wavelet coefficient blocks either encoding wavelet coefficient differences to 0-bits or 1-bits called MultiBit Encoding (MBE). The results obtained show that the imperceptibility and robustness of this proposed model are superior to other proposed watermarking models and this model gives better results than other models at the same payload.
C1 [Khan, Ahmed] Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
C3 Monash University; Monash University Malaysia
RP Khan, A (corresponding author), Monash Univ Malaysia, Sch Informat Technol, Subang Jaya, Malaysia.
EM ahmed.khan1@monash.edu
CR Abdul W, 2017, IEEE ACCESS, V5, P5531, DOI 10.1109/ACCESS.2017.2693438
   Aherrahrou N, 2018, SOFT COMPUT, V22, P2369, DOI 10.1007/s00500-017-2501-2
   Bhowal K, 2017, TURK J ELECTR ENG CO, V25, P2136, DOI [10.3906/elk-1602-267, 10.3906/elk-162-267]
   El-Shafai W, 2019, MULTIMED TOOLS APPL, V78, P27211, DOI 10.1007/s11042-019-7448-0
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Khanduja V, 2019, MULTIMED TOOLS APPL, V78, P28111, DOI 10.1007/s11042-019-07932-3
   Khorsand Movaghar R, 2017, TURK J ELECTR ENG CO, V25, P644, DOI 10.3906/elk-1507-232
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lei BY, 2019, MULTIMED TOOLS APPL, V78, P27085, DOI 10.1007/s11042-017-4743-5
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Noor R., 2019, SOFT COMPUT, P1
   Noor R, 2019, WIRELESS PERS COMMUN, V104, P1535, DOI 10.1007/s11277-018-6097-3
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Pilato G, 2015, IEEE T EMERG TOP COM, V3, P185, DOI 10.1109/TETC.2014.2385594
   Prasetyo Heri, 2019, MULTIMED TOOLS APPL, V78, P29089, DOI [10.1007/s11042-018-6304-y, DOI 10.1007/S11042-018-6304-Y]
   Shafi I, 2018, SOFT COMPUT, V22, P1555, DOI 10.1007/s00500-017-2944-5
   Sheng GR, 2017, SOFT COMPUT, V21, P5693, DOI 10.1007/s00500-016-2146-6
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Thakkar F, 2017, TURK J ELECTR ENG CO, V25, P3273, DOI 10.3906/elk-1603-17
   Veni M, 2019, MULTIMED TOOLS APPL, V78, P27491, DOI 10.1007/s11042-019-7650-0
   Venugopala PS, 2017, SUSTAIN COMPUT-INFOR, V15, P82, DOI 10.1016/j.suscom.2017.06.003
   Wang X, 2019, MULTIMED TOOLS APPL, V78, P27001, DOI 10.1007/s11042-017-4666-1
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Wei Q., 2017, MULTIMED TOOLS APPL, V25, P1
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
NR 34
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2395
EP 2411
DI 10.1007/s11042-020-09508-y
EA SEP 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569773300002
DA 2024-07-18
ER

PT J
AU AlKhodaidi, T
   Gutub, A
AF AlKhodaidi, Taghreed
   Gutub, Adnan
TI Refining image steganography distribution for higher security multimedia
   counting-based secret-sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information security; Secret sharing scheme; Share key; Counting based
   secret sharing; Steganography; Image steganography; Cover image
ID SPATIAL DOMAIN
AB Counting-based secret sharing is becoming a vital efficient multimedia technique for raising the security of sensitive data especially when collective access to data are essential. Secret sharing distributes shares to participants forcing their joint availability in order to give permission. The share keys of the system deserve to be remembered and highly protected against intruders, presenting a challenging issue, noticing that shares are normally produced without giving participants any preference. Therefore, this research adds image steganography technique to the counting-based secret-sharing system to gain more applicable security. The paper proposes redistribution of LSB image steganography to embed share keys in colour cover image. The proposed method ensured that the shares hiding locations differ within cover images to increase the level of security. The paper analysis show that stego-image quality and security is attractive. It showed interesting results in terms of performance and payload capacity motivating this research to be a direction for coming improvements.
C1 [AlKhodaidi, Taghreed] Umm Al Qura Univ, Comp Sci Dept Al Qunfudhah, Al Qunfudhah, Saudi Arabia.
   [Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM tmkhodaidi@uqu.edu.sa; aagutub@uqu.edu.sa
RI Alkhodaidi, Taghreed/AAH-2964-2020; Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Alkhodaidi, Taghreed/0000-0001-5366-3295; Gutub, Adnan
   Abdul-Aziz/0000-0003-0923-202X
FU Umm Al-Qura University, Saudi Arabia
FX Thanks to Umm Al-Qura University, Saudi Arabia, for the educational
   support given toward this research.
CR Aabed MA, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P756
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Juaid N, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0875-8
   Al-Nofaie SMA, 2020, MULTIMED TOOLS APPL, V79, P19, DOI 10.1007/s11042-019-08025-x
   Al-Qurashi A., 2018, J. Comput. Sci. Comput. Math. (JCSCM), V8, P87, DOI [10.20967/jcscm.2018.04.006, DOI 10.20967/JCSCM.2018.04.006]
   al-Shatanawi O.M., 2015, INT J NETWORK SECURI, V7, P37, DOI [DOI 10.5121/IJNSA.2015.7203, 10.5121/ijnsa.2015.7203]
   Alanazi N, 2020, J KING SAUD UNIV-COM, V34, P1343, DOI 10.1016/j.jksuci.2020.04.011
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   AlKhodaidi T, 2020, ARAB J SCI ENG, V45, P3403, DOI 10.1007/s13369-020-04422-9
   Almutairi SM, 2020, INT J TECHNOL ENHANC, V12, P200
   [Anonymous], 2015, INT J ENG TRENDS TEC, DOI DOI 10.5121/ijsptm.2015.4102
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bedi P, 2013, COMPUT ELECTR ENG, V39, P640, DOI 10.1016/j.compeleceng.2012.12.021
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Ching-Sheng Hsu, 2010, Proceedings of the Second International Conference on Communication Software and Networks (ICCSN 2010), P293, DOI 10.1109/ICCSN.2010.61
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P48, DOI 10.4304/jetwi.2.1.48-55
   Gutub A, 2020, MULTIMED TOOLS APPL, V79, P17373, DOI 10.1007/s11042-020-08695-y
   Gutub A, 2020, ARAB J SCI ENG, V45, P2631, DOI 10.1007/s13369-020-04413-w
   Gutub A, 2020, ARAB J SCI ENG, V45, P2433, DOI 10.1007/s13369-019-04010-6
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2007, KUWAIT J SCI ENG, V34, P165
   Gutub AAA, 2021, J KING SAUD UNIV-COM, V33, P1108, DOI 10.1016/j.jksuci.2019.06.014
   Gutub AAA, 2010, ISECURE-ISC INT J IN, V2, P107
   Handel TG, 2005, LECT NOTES COMPUT SC, V1174, P23, DOI [10.1007/3-540-61996-8_29, DOI 10.1007/3-540-61996-8_29]
   Hassan FS, 2022, J KING SAUD UNIV-COM, V34, P2017, DOI 10.1016/j.jksuci.2020.07.008
   Hassan FS, 2020, MULTIMED TOOLS APPL, V79, P30087, DOI 10.1007/s11042-020-09513-1
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jalbrzikowski M, 2017, BIOL PSYCHIAT-COGN N, V2, P53, DOI 10.1016/j.bpsc.2016.06.007
   Karim S, 2011, THIRD INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND TECHNOLOGY (ICCET 2011), P251
   Katzenbeisser S., 2000, The EDP Audit, Control, and Security Newsletter, V26, P1, DOI [10.1201/1079/43263.28.6.20001201/30373.5, DOI 10.1201/1079/43263.28.6.20001201/30373.5]
   Kurup S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1982, DOI 10.1109/ICACCI.2015.7275908
   Mondal Anupam, 2015, International Journal of Computer Network and Information Security, V7, P42, DOI 10.5815/ijcnis.2015.03.06
   Nickfarjam A. M., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P360, DOI 10.1109/AISP.2012.6313773
   Nilizadeh Amir Farhad, 2013, International Journal of Modern Education and Computer Science, V5, P8, DOI 10.5815/ijmecs.2013.04.02
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Taouil Youssef, 2016, Int. J. Comput. Appl., V138, P38
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zöllner J, 1998, LECT NOTES COMPUT SC, V1525, P344
   [No title captured]
NR 44
TC 23
Z9 23
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1143
EP 1173
DI 10.1007/s11042-020-09720-w
EA SEP 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318500001
DA 2024-07-18
ER

PT J
AU Yang, L
   Song, Q
   Wu, YQ
AF Yang, Lu
   Song, Qing
   Wu, Yingqi
TI Attacks on state-of-the-art face recognition using attentional
   adversarial attack generative network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Generative adversarial networks; Adversarial attack
AB With the broad use of face recognition, its weakness gradually emerges that it is able to be attacked. Therefore, it is very important to study how face recognition networks are subject to attacks. Generating adversarial examples is an effective attack method, which misleads the face recognition system through obfuscation attack (rejecting a genuine subject) or impersonation attack (matching to an impostor). In this paper, we introduce a novel GAN, Attentional Adversarial Attack Generative Network (A(3)GN), to generate adversarial examples that mislead the network to identify someone as the target person not misclassify inconspicuously. For capturing the geometric and context information of the target person, this work adds a conditional variational autoencoder and attention modules to learn the instance-level correspondences between faces. Unlike traditional two-player GAN, this work introduces a face recognition network as the third player to participate in the competition between generator and discriminator which allows the attacker to impersonate the target person better. The generated faces which are hard to arouse the notice of onlookers can evade recognition by state-of-the-art networks and most of them are recognized as the target person.
C1 [Yang, Lu; Song, Qing; Wu, Yingqi] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligence Vis Lab, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Song, Q (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligence Vis Lab, Beijing, Peoples R China.
EM soeaver@bupt.edu.cn; priv@bupt.edu.cn; wuyqq@bupt.edu.cn
RI yang, lu/GLV-5144-2022
CR Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   [Anonymous], 2018, ARXIV180406655
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bose A, 2018, ARXIV180512302
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Dabouei A, 2018, ARXIV180908999
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dong YP, 2019, PROC CVPR IEEE, P4307, DOI 10.1109/CVPR.2019.00444
   Engstrom L., 2017, arXiv preprint arXiv:1712.02779
   Gao Z, 2017, PATTERN RECOGNIT
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gonçalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goswami G, 2018, AAAI CONF ARTIF INTE, P6829
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Q, 2019, MULTIMED TOOLS APPL
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Huang R, 2015, ARXIV 1511 03034
   Huang Z, 2016, TPAMI
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kanbak C., 2017, ARXIV171109115
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma D. P., 2014, arXiv
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu WY, 2016, PR MACH LEARN RES, V48
   Mao SN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P883
   Mathieu M., 2016, Neural Information Processing Symposium, pages, P5041
   Miyato T., 2016, ICLR
   Miyato T, 2018, INT C LEARN REPR
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Odena A, 2017, PR MACH LEARN RES, V70
   Radford A., 2016, INT C LEARN REPR
   Salimans T, 2016, ADV NEUR IN, V29
   Salimans Tim, 2018, ICLR
   Sanakoyeu A, 2019, PROC CVPR IEEE, P471, DOI 10.1109/CVPR.2019.00056
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S., 2016, 2016 IEEE WINT C APP, P1, DOI [DOI 10.1109/WACV.2016.7477558, 10.1109/WACV.2016.7477558]
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Sharif Mahmood, 2018, ARXIV180100349
   Sohn Kihyuk, 2015, NIPS, P3483
   Song Y, 2018, ADV NEUR IN, V31
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Xiao Chaowei, 2018, 6 INT C LEARN REPR I
   Yan X, 2016, ARXIV151200570
   Yao HT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P342, DOI 10.1145/3123266.3123278
   Yi Dong, 2014, ARXIV14117923
   Zhang X, 2017, TOMM
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   ZHU JY, 2017, NIPS
NR 71
TC 34
Z9 36
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 855
EP 875
DI 10.1007/s11042-020-09604-z
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Niu, PP
   Shen, X
   Song, YF
   Liu, YN
   Wang, XY
AF Niu, Pan-pan
   Shen, Xin
   Song, Ya-fei
   Liu, Yu-nan
   Wang, Xiang-yang
TI Locally optimum watermark decoder in NSST domain using RSS-based Cauchy
   distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Multiplicative watermark; Nonlinear embedding
   strength function; RSS-based Cauchy distribution; Local optimum decoder
ID ROBUST IMAGE WATERMARKING; DATA HIDING SCHEME; WAVELET DOMAIN; DIGITAL
   WATERMARKING; DETECTOR; INTERPOLATION; MODEL
AB It is important to consider the tradeoff between imperceptibility and robustness requirements in developing an image-watermarking technique, some statistical model-based image watermarking schemes have been designed in the past decade. The effectiveness of a statistical watermark decoder depends highly on the modeling of the transform-domain coefficients and the use of hypothesis testing. In this study, a multiplicative image watermarking scheme is proposed in the nonsubsampled Shearlet transform (NSST) domain, where NSST coefficients are modeled by ranked set sample (RSS) based Cauchy statistical distribution and locally most powerful (LMP) test criterion is applied. Digital image watermarking technique consists of two parts, namely, embedding and extracting. In the embedding process, to achieve relatively good imperceptibility and robustness, watermark data is inserted into the significant NSST directional subband that has the highest energy value, by modifying nonlinearly the significant NSST coefficients. In the extracting phase, a scheme is proposed for designing a blind NSST domain watermark decoder incorporating the RSS based Cauchy statistical distribution and LMP test criterion. Here, the RSS method is used to estimate the location parameter and shape parameter of Cauchy statistical distribution instead of traditional maximum-likelihood (ML) method, which can provide the Cauchy model with higher precision parameters. Experimental results on a set of standard test images show significant improvements in imperceptibility and robustness using the proposed method compared with the best known state-of-the-art approaches.
C1 [Niu, Pan-pan; Shen, Xin; Song, Ya-fei; Liu, Yu-nan; Wang, Xiang-yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Liu, Yunan/GXH-9776-2022; Liu, Yunan/JGM-3801-2023; Niu,
   Panpan/Q-9953-2017; Shen, Xin/JBI-6913-2023; Song, Yafei/M-7992-2014
OI Song, Yafei/0000-0003-0962-0671
FU National Natural Science Foundation of China [61472171, 61701212]; China
   Postdoctoral Science Foundation [2017 M621135, 2018 T110220]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LZ2019001]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]; High-level Innovation Talents Foundation of Dalian
   [2017RQ055]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), China Postdoctoral
   Science Foundation (Nos. 2017 M621135 & 2018 T110220), Key Scientific
   Research Project of Liaoning Provincial Education Department
   (LZ2019001), Natural Science Foundation of Liaoning Province
   (2019-ZD-0468), and High-level Innovation Talents Foundation of Dalian
   (No.2017RQ055).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2015, MULTIMED TOOLS APPL, V74, P5995, DOI 10.1007/s11042-014-1904-7
   Akhaee MA, 2010, SIGNAL PROCESS, V90, P2487, DOI 10.1016/j.sigpro.2010.02.013
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Chaurasia P, 2014, PERS INDIV DIFFER, V63, P81
   Chuiv N., 1995, METR INT J THEOR APP, V42, P234, DOI [10.1007/BF01894304, DOI 10.1007/BF01894304]
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Hou B, 2012, IEEE J-STARS, V5, P809, DOI 10.1109/JSTARS.2012.2196680
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Khosravi MR, 2020, IEEE INTERNET THINGS, V7, P2603, DOI 10.1109/JIOT.2019.2952284
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Khosravi MR, 2018, INT J AGRIC ENVIRON, V9, P53, DOI 10.4018/IJAEIS.2018040104
   Khosravi MR., 2019, EURASIP J WIREL COMM, V2019, P1, DOI [10.1186/s13638-018-1318-8, DOI 10.1186/S13638-018-1318-8]
   Kwitt R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P33, DOI 10.1145/1411328.1411337
   Ng TM, 2005, IEEE SIGNAL PROC LET, V12, P285, DOI 10.1109/LSP.2005.843776
   Panah AS, 2016, IEEE ACCESS, V4, P2670, DOI 10.1109/ACCESS.2016.2570812
   Qasim AF, 2018, COMPUT SCI REV, V27, P45, DOI 10.1016/j.cosrev.2017.11.003
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   SONG I, 1990, IEEE T INFORM THEORY, V36, P502, DOI 10.1109/18.54899
   Song I, 2009, ADV THEORY SIGNAL DE, V2, P63
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Winkler T, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2545883
NR 35
TC 14
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33071
EP 33101
DI 10.1007/s11042-020-09621-y
EA AUG 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564527000010
DA 2024-07-18
ER

PT J
AU Smolka, B
   Kusnik, D
AF Smolka, Bogdan
   Kusnik, Damian
TI On the application of the reachability distance in the suppression of
   mixed Gaussian and impulsive noise in color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise; Color image enhancement; Impulsive noise; Gaussian noise; Mixed
   noise; Denoising; Reachability
ID VECTOR MEDIAN FILTER; EDGE-DETECTION; REMOVAL; REDUCTION; SPACE;
   ALGORITHM
AB In this paper, we address the problem of mixed Gaussian and impulsive noise reduction in color images. A robust filtering technique is proposed, which is utilizing a novel concept of pixels dissimilarity based on the reachability distance. The structure of the denoising method requires the estimation of the impulsiveness of each pixel in the processing block using the introduced local reachability concept. Furthermore, we determine the similarity of each pixel in the block to the central patch consisting of the processed pixel and its neighbors. Both measures are calculated as an average of modified reachability distances to the most similar pixels of the central patch and the final filtering output is a weighted average of all pixels belonging to the processing block. The proposed technique was compared with widely used filtering methods and the performed experiments proved its satisfying denoising properties. The introduced filtering design is insensitive to outliers and their clusters introduced by the impulsive noise process, preserves details and is able to efficiently suppress the Gaussian noise while enhancing the image edges. Additionally, we proposed a method which estimates the noise contamination intensity, so that the proposed filter is able to adaptively tune its parameters.
C1 [Smolka, Bogdan; Kusnik, Damian] Silesian Tech Univ, Fac Automat Elect & Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Kusnik, D (corresponding author), Silesian Tech Univ, Fac Automat Elect & Comp Sci, Akad 16, PL-44100 Gliwice, Poland.
EM Bogdan.Smolka@polsl.pl; Damian.Kusnik@polsl.pl
RI Kusnik, Damian/KFQ-5844-2024; Smolka, Bogdan/AFK-4617-2022
OI Kusnik, Damian/0000-0002-6282-7594; Smolka, Bogdan/0000-0003-1883-3580
FU National Science Centre (NCN), Poland - Silesian University of
   Technology, Poland [2017/25/B/ST6/02219];  [BK/200/RAU1/2020]
FX This work was supported by a research grant 2017/25/B/ST6/02219 from the
   National Science Centre (NCN), Poland and was also funded by the
   Silesian University of Technology, Poland, BK/200/RAU1/2020.
CR Angiulli F., 2002, Principles of Data Mining and Knowledge Discovery. 6th European Conference, PKDD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2431), P15
   [Anonymous], 2004, Nonlinear Signal and Image Processing: Theory, Methods, and Applications
   [Anonymous], 2005, Image Sensors and Signal Processing for Digital Still Cameras
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Boncelet C, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P397, DOI 10.1016/B978-012119792-6/50087-5
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger W., 2013, UNDERGRADUATE TOPICS
   Cai JF, 2008, INVERSE PROBL IMAG, V2, P187
   Cai JF, 2010, J MATH IMAGING VIS, V36, P46, DOI 10.1007/s10851-009-0169-7
   Celebi ME, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2772639
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   DeerghaRao K, 2002, IEEE INT C AC SPEECH, V4
   Delon J, 2016, IMAGE PROCESS ON LIN, V6, P130, DOI 10.5201/ipol.2016.161
   Delon J, 2013, SIAM J IMAGING SCI, V6, P1140, DOI 10.1137/120885000
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Faraji H, 2006, IEEE T IMAGE PROCESS, V15, P2676, DOI 10.1109/TIP.2006.877363
   Furht B., 2008, Encyclopedia of Multimedia, P651, DOI 10.1007/978-0-387-78414-4_159
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   [胡浩 Hu Hao], 2015, [泥沙研究, Journal of Sediment Research], P1
   Hussain A, 2012, MULTIMED TOOLS APPL, V60, P551, DOI 10.1007/s11042-011-0829-7
   Ji LP, 2008, NEUROCOMPUTING, V71, P2986, DOI 10.1016/j.neucom.2007.04.015
   Jin KH, 2018, IEEE T IMAGE PROCESS, V27, P1448, DOI 10.1109/TIP.2017.2771471
   Jin LH, 2007, SIGNAL PROCESS, V87, P1345, DOI 10.1016/j.sigpro.2006.11.008
   Jin LH, 2019, SIGNAL PROCESS, V155, P334, DOI 10.1016/j.sigpro.2018.10.007
   Jin LH, 2016, SIGNAL PROCESS, V128, P171, DOI 10.1016/j.sigpro.2016.03.025
   Kang CC, 2009, SIGNAL PROCESS, V89, P344, DOI 10.1016/j.sigpro.2008.09.003
   Kenney C, 2001, IEEE T IMAGE PROCESS, V10, P326, DOI 10.1109/83.902298
   Kusnik D., 2015, INF INT SYST APPL II, P1
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Lin CH, 2010, INT CONF ACOUST SPEE, P1434, DOI 10.1109/ICASSP.2010.5495475
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2007, SIGNAL PROCESS, V87, P2085, DOI 10.1016/j.sigpro.2007.02.009
   Malinski L, 2016, J REAL-TIME IMAGE PR, P1, DOI 10.1007/s11554-016-0599-6
   Malinski L, 2016, J REAL-TIME IMAGE PR, V11, P427, DOI 10.1007/s11554-015-0500-z
   Mélange T, 2011, IEEE T IMAGE PROCESS, V20, P959, DOI 10.1109/TIP.2010.2077305
   Morillas S, 2008, COMPUT VIS IMAGE UND, V110, P102, DOI 10.1016/j.cviu.2007.05.001
   Morillas S, 2011, SENSORS-BASEL, V11, P8115, DOI 10.3390/s110808115
   Morillas S, 2011, SENSORS-BASEL, V11, P3205, DOI 10.3390/s110303205
   Morillas S, 2009, IEEE T IMAGE PROCESS, V18, P1452, DOI 10.1109/TIP.2009.2019305
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Ponomaryov V, 2013, P SOC PHOTO-OPT INS, V8656, P1
   Ponomaryov V, 2010, IEICE T FUND ELECTR, VE93A, P570, DOI 10.1587/transfun.E93.A.570
   Schubert E, 2014, DATA MIN KNOWL DISC, V28, P190, DOI 10.1007/s10618-012-0300-z
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Sheikh YA, 2007, IEEE I CONF COMP VIS, P1175
   Shen YZ, 2004, IEEE T VIS COMPUT GR, V10, P252, DOI 10.1109/TVCG.2004.1272725
   Smolka B, 2019, REAL TIME IMAGE PROC, P140
   Smolka B, 2015, SIGNAL IMAGE VIDEO P, V9, P49, DOI 10.1007/s11760-015-0830-0
   Smolka B, 2007, IMAGE PROCESS SER, P75
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vardavoulia MI, 2001, PATTERN RECOGN LETT, V22, P675, DOI 10.1016/S0167-8655(00)00141-0
   Wang GH, 2014, SIGNAL PROCESS, V102, P216, DOI 10.1016/j.sigpro.2014.03.027
   Wang W, 2011, IEEE SIGNAL PROC LET, V18, P551, DOI 10.1109/LSP.2011.2162583
   Wang XY, 2010, DIGIT SIGNAL PROCESS, V20, P1173, DOI 10.1016/j.dsp.2009.11.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang M., 2009, WiCom '09. 5th International Conference on Wireless Communications, Networking and Mobile Computing, P1
   Yu HC, 2008, IEEE SIGNAL PROC LET, V15, P922, DOI 10.1109/LSP.2008.2005051
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   ZHENG J, 1993, J INTELL ROBOT SYST, V7, P257, DOI 10.1007/BF01257768
   Zhu ZL, 2018, IEEE SIGNAL PROC LET, V25, P843, DOI 10.1109/LSP.2018.2808343
NR 65
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32857
EP 32879
DI 10.1007/s11042-020-09550-w
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563606500002
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, HJ
   Zhu, WP
   Ouyang, ZH
   Champagne, B
AF Yu, Hongjiang
   Zhu, Wei-Ping
   Ouyang, Zhiheng
   Champagne, Benoit
TI A hybrid speech enhancement system with DNN based speech reconstruction
   and Kalman filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Deep neural network; Kalman filter; Unmatched
   acoustic environment
ID PHASE; NOISE; NETWORK
AB In this paper, we propose a hybrid speech enhancement system that exploits deep neural network (DNN) for speech reconstruction and Kalman filtering for further denoising, with the aim to improve performance under unseen noise conditions. Firstly, two separate DNNs are trained to learn the mapping from noisy acoustic features to the clean speech magnitudes and line spectrum frequencies (LSFs), respectively. Then the estimated clean magnitudes are combined with the phase of the noisy speech to reconstruct the estimated clean speech, while the LSFs are converted to linear prediction coefficients (LPCs) to implement Kalman filtering. Finally, the reconstructed speech is Kalman-filtered for further removing the residual noises. The proposed hybrid system takes advantage of both the DNN based reconstruction and traditional Kalman filtering, and can work reliably in either matched or unmatched acoustic environments. Computer based experiments are conducted to evaluate the proposed hybrid system with comparison to traditional iterative Kalman filtering and several state-of-the-art DNN based methods under both seen and unseen noises. It is shown that compared to the DNN based methods, the hybrid system achieves similar performance under seen noise, but notably better performance under unseen noise, in terms of both speech quality and intelligibility.
C1 [Yu, Hongjiang; Zhu, Wei-Ping; Ouyang, Zhiheng] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
   [Champagne, Benoit] McGill Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada; McGill University
RP Yu, HJ (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
EM ho_yu@encs.concordia.ca
FU NSERC of Canada under a CRD grant - Microchip in Ottawa, Canada; China
   Scholarships Council (CSC) [201606270200]
FX The work was supported by NSERC of Canada under a CRD grant sponsored by
   Microchip in Ottawa, Canada. H. Yu also acknowledges the financial
   support from the China Scholarships Council (CSC No.201606270200).
CR [Anonymous], 1969, IEEE T ACOUST SPEECH, VAU17, P225
   Donahue C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5024, DOI 10.1109/ICASSP.2018.8462581
   FU SW, 2017, MACHINE LEARNING SIG, P6
   Gannot S, 1998, IEEE T SPEECH AUDI P, V6, P373, DOI 10.1109/89.701367
   GIBSON JD, 1991, IEEE T SIGNAL PROCES, V39, P1732, DOI 10.1109/78.91144
   Han W, 2017, MULTIMED TOOLS APPL, V76, P11143, DOI 10.1007/s11042-016-3656-z
   ITU-T, 2001, PERC EV SPEECH QUAL, P862
   Jeon KM, 2017, ETRI J, V39, P398, DOI 10.4218/etrij.17.0116.0773
   Kavalekalam MS, 2016, INT CONF ACOUST SPEE, P191, DOI 10.1109/ICASSP.2016.7471663
   Krawczyk M, 2014, IEEE-ACM T AUDIO SPE, V22, P1931, DOI 10.1109/TASLP.2014.2354236
   LIM JS, 1979, P IEEE, V67, P1586, DOI 10.1109/PROC.1979.11540
   Loweimi E, 2017, INT CONF ACOUST SPEE, P5310, DOI 10.1109/ICASSP.2017.7953170
   McLoughlin IV, 2008, SIGNAL PROCESS, V88, P448, DOI 10.1016/j.sigpro.2007.09.003
   Mellahi T, 2015, AEU-INT J ELECTRON C, V69, P545, DOI 10.1016/j.aeue.2014.11.007
   Moattar M. H., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P2549
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038
   Nicolson A, 2019, SPEECH COMMUN, V111, P44, DOI 10.1016/j.specom.2019.06.002
   Nie S, 2018, INTERSPEECH, P3219
   Nower N, 2015, SPEECH COMMUN, V70, P13, DOI 10.1016/j.specom.2015.02.006
   Ouyang ZH, 2018, INTERSPEECH, P3224
   Ouyang ZH, 2019, INT CONF ACOUST SPEE, P5756, DOI 10.1109/ICASSP.2019.8683423
   Paliwal K. K., 1987, Proceedings: ICASSP 87. 1987 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.87CH2396-0), P177
   Paliwal K, 2011, SPEECH COMMUN, V53, P465, DOI 10.1016/j.specom.2010.12.003
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Roy SK, 2016, IEEE INT SYMP CIRC S, P762, DOI 10.1109/ISCAS.2016.7527352
   Shi GJ, 2006, IEEE T AUDIO SPEECH, V14, P1867, DOI 10.1109/TSA.2005.858512
   So S, 2009, INT CONF ACOUST SPEE, P4405, DOI 10.1109/ICASSP.2009.4960606
   Soni MH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5039, DOI 10.1109/ICASSP.2018.8462068
   Srivastava A., 2017, Advances in Neural Information Processing Systems, P3308
   Taal CH, 2011, IEEE T AUDIO SPEECH, V19, P2125, DOI 10.1109/TASL.2011.2114881
   Tu M, 2017, INT CONF ACOUST SPEE, P5565, DOI 10.1109/ICASSP.2017.7953221
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wan E. A., 1999, HDB NEURAL NETWORKS, V139, P1
   WANG DL, 1982, IEEE T ACOUST SPEECH, V30, P679, DOI 10.1109/TASSP.1982.1163920
   Wang Q, 2019, IEEE INT C INTELL TR, P2722, DOI 10.1109/ITSC.2019.8917301
   Wang YX, 2014, IEEE-ACM T AUDIO SPE, V22, P1849, DOI 10.1109/TASLP.2014.2352935
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459
   Williamson DS, 2017, IEEE-ACM T AUDIO SPE, V25, P1492, DOI 10.1109/TASLP.2017.2696307
   Williamson DS, 2016, IEEE-ACM T AUDIO SPE, V24, P483, DOI 10.1109/TASLP.2015.2512042
   Xia YS, 2015, NEURAL NETWORKS, V67, P131, DOI 10.1016/j.neunet.2015.03.008
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yu HL, 2019, IEEE T FUZZY SYST, V27, P2353, DOI 10.1109/TFUZZ.2019.2898371
   Zheng NJ, 2019, IEEE-ACM T AUDIO SPE, V27, P63, DOI 10.1109/TASLP.2018.2870742
NR 44
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32643
EP 32663
DI 10.1007/s11042-020-09563-5
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000563739900008
DA 2024-07-18
ER

PT J
AU van Beurden, M
   Brouwer, AM
   van Baardewijk, JU
   Binsch, O
   Vermetten, E
   Roijendijk, L
AF van Beurden, Maurice
   Brouwer, Anne-Marie
   van Baardewijk, Jan Ubbo
   Binsch, Olaf
   Vermetten, Eric
   Roijendijk, Linsey
TI Towards user-adapted training paradigms: Physiological responses to
   physical threat during cognitive task performance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cognitive task performance; Stress; Physiological measures; Threat;
   Workload
ID STRESS
AB Feedback of physiological responses have a great potential to support virtual training paradigms aimed to increase cognitive task performance under stressful threatening conditions. In the current study, we examined the sensitivity of a range of physiological indicators derived from electrodermal activity (EDA), blood pressure (BP) and heart rate (HR) to measure stress as induced by the threat of an electric shock (ES). In contrast to previous work that studied physiological stress responses compared to a rest condition, we compared conditions with high cognitive load combined with stress caused by threat of an ES, to conditions with high cognitive load without such stress. Twenty-five participants performed a cognitively demanding task in an experimental setup. At certain 10 s time intervals, indicated by a continuous tone, participants were either asked to do their best and increase cognitive task performance (non-threat condition), or they were told that they could receive an ES during this interval if cognitive task performance was not high enough (threat condition). Physiological measures, task performance and self-reported measures of stress and workload were analysed. Task performance and self-reported measures of stress and workload were roughly the same in both conditions. Especially EDA measures were affected by the threat of an ES. Threat and non-threat conditions could be distinguished with an across-participant classifier using EDA and BP features with an accuracy of 70%. These results suggest that EDA and BP can be used to evaluate stress coping training paradigms or to individually adapt the stress levels in virtual training environments.
C1 [van Beurden, Maurice; Brouwer, Anne-Marie; van Baardewijk, Jan Ubbo; Binsch, Olaf; Roijendijk, Linsey] Netherlands Org Appl Sci Res, Dept Human Factors, Soesterberg, Netherlands.
   [Vermetten, Eric] Dutch Minist Def, Cent Mil Hosp, Utrecht, Netherlands.
   [Vermetten, Eric] Leiden Univ, Leiden, Netherlands.
C3 Netherlands Organization Applied Science Research; Leiden University;
   Leiden University - Excl LUMC
RP van Beurden, M (corresponding author), Netherlands Org Appl Sci Res, Dept Human Factors, Soesterberg, Netherlands.
EM Maurice.vanbeurden@tno.nl
RI Vermetten, Eric/B-1335-2008
OI Vermetten, Eric/0000-0003-0579-4404; Brouwer,
   Anne-Marie/0000-0003-1961-4291
FU Dutch Ministry of Defense [V1532]; TNO research ERP-Body Brain
   Interactions
FX We would like to thank Lucas Heijdt and Emiel Stoelinga for assisting in
   data collection and implementing the cognitive task. This work was
   funded by the Dutch Ministry of Defense (V1532 program) and the TNO
   research ERP-Body Brain Interactions.
CR Bartone PT, 1998, MIL MED, V163, P587, DOI 10.1093/milmed/163.9.587
   BEATTY J, 1982, PSYCHOL BULL, V91, P276, DOI 10.1037/0033-2909.91.2.276
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   Beurden Maurice, 2019, Engineering Psychology and Cognitive Ergonomics. 16th International Conference, EPCE 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11571), P123, DOI 10.1007/978-3-030-22507-0_10
   Blascovich J.J., 2000, FEELING THINKING ROL, P59
   Borghini G, 2014, NEUROSCI BIOBEHAV R, V44, P58, DOI 10.1016/j.neubiorev.2012.10.003
   Bosse Tibor, 2014, Brain Inform, V1, P27
   Bradley MM, 2000, PSYCHOPHYSIOLOGY, V37, P204, DOI 10.1017/S0048577200990012
   Braver TS, 1997, NEUROIMAGE, V5, P49, DOI 10.1006/nimg.1996.0247
   Brouwer A., 2011, Journal of Cybertherapy and Rehabilitation, V4, P27
   Brouwer AM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00136
   Brouwer AM, 2014, INT J PSYCHOPHYSIOL, V93, P242, DOI 10.1016/j.ijpsycho.2014.05.004
   Campbell DJ, 2009, MIL PSYCHOL, V21, pS47, DOI 10.1080/08995600903249149
   Cinaz B, 2013, PERS UBIQUIT COMPUT, V17, P229, DOI 10.1007/s00779-011-0466-1
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cosic K, 2010, CYBERPSYCH BEH SOC N, V13, P73, DOI 10.1089/cyber.2009.0260
   DAVIS M, 1989, BEHAV NEUROSCI, V103, P495, DOI 10.1037/0735-7044.103.3.495
   Dawson ME., 2017, Handbook of Psychophysiology, V4, P217, DOI [DOI 10.1017/9781107415782, 10.1017/9781107415782.010]
   DEANE GE, 1961, J EXP PSYCHOL, V61, P489, DOI 10.1037/h0049220
   Fairclough SH, 2006, BIOL PSYCHOL, V71, P100, DOI 10.1016/j.biopsycho.2005.03.007
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   FOLKINS CH, 1970, J PERS SOC PSYCHOL, V14, P173, DOI 10.1037/h0028688
   FOWLES DC, 1981, PSYCHOPHYSIOLOGY, V18, P232, DOI 10.1111/j.1469-8986.1981.tb03024.x
   Gehrman PR, 2016, BEHAV SLEEP MED, V14, P23, DOI 10.1080/15402002.2014.940112
   GIANNAKAKIS G, 2019, IEEE T AFFECT COMPUT, V1
   Gladwin TE, 2016, NEUROSCI LETT, V619, P182, DOI 10.1016/j.neulet.2016.03.027
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goldstein DS, 2010, CELL MOL NEUROBIOL, V30, P1433, DOI 10.1007/s10571-010-9606-9
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Kreibig SD, 2011, MOTIVATION AFFECTS A, P93
   Lago TR, 2018, DEPRESS ANXIETY, V35, P868, DOI 10.1002/da.22748
   LILJESTRAND G., 1928, ZEITSCHR GES EXP MED, V59, P105, DOI 10.1007/BF02608853
   Lingenfelser F, 2018, IEEE T AFFECT COMPUT, V9, P410, DOI 10.1109/TAFFC.2016.2635124
   Manoach DS, 1997, NEUROREPORT, V8, P545, DOI 10.1097/00001756-199701200-00033
   Maris E, 2007, J NEUROSCI METH, V164, P177, DOI 10.1016/j.jneumeth.2007.03.024
   MARTEAU TM, 1992, BRIT J CLIN PSYCHOL, V31, P301, DOI 10.1111/j.2044-8260.1992.tb00997.x
   McDougal DH, 2015, COMPR PHYSIOL, V5, P439, DOI 10.1002/cphy.c140014
   Moroney WF, 1995, INT J AVIAT PSYCHOL, V5, P87, DOI 10.1207/s15327108ijap0501_6
   Parent M, 2019, INT J PSYCHOPHYSIOL, V146, P139, DOI 10.1016/j.ijpsycho.2019.09.005
   Repetto Claudia, 2009, J Vis Exp, DOI 10.3791/1554
   SHERWOOD A, 1990, PSYCHOPHYSIOLOGY, V27, P1, DOI 10.1111/j.1469-8986.1990.tb02171.x
   Slavich GM, 2014, PSYCHOL BULL, V140, P774, DOI 10.1037/a0035302
   SMITH TW, 1985, BIOL PSYCHOL, V20, P31, DOI 10.1016/0301-0511(85)90039-0
   Soeter M, 2012, PSYCHONEUROENDOCRINO, V37, P1769, DOI 10.1016/j.psyneuen.2012.03.011
   Starcke K, 2012, NEUROSCI BIOBEHAV R, V36, P1228, DOI 10.1016/j.neubiorev.2012.02.003
   Sun JX, 2009, CRIT CARE MED, V37, P72, DOI 10.1097/CCM.0b013e3181930174
   Toet A, 2017, SAGE OPEN, V7, DOI 10.1177/2158244017725386
   Valk PJ, 1997, AM J RHINOL, V11, P27, DOI 10.2500/105065897781446838
   van der Bij Akke K, 2003, Community Genet, V6, P84, DOI 10.1159/000073003
   van der Vijgh B, 2015, PSYCHOPHYSIOLOGY, V52, P1080, DOI 10.1111/psyp.12431
   van der Vijgh B, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00400
   van Maanen L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46073-3
   vanderPloeg HM, 1980, HANDLEID BIJ ZELF BE
NR 54
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35867
EP 35884
DI 10.1007/s11042-020-09575-1
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000563606600002
DA 2024-07-18
ER

PT J
AU Bhojan, A
   Ng, SP
   Ng, J
   Ooi, WT
AF Bhojan, Anand
   Ng, Siang Ping
   Ng, Joel
   Ooi, Wei Tsang
TI CloudyGame: Enabling cloud gaming on the edge with dynamic asset
   streaming and shared game instances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud gaming; Gaming as a service; Game engine architecture
ID RESOURCE; SYSTEM
AB Cloud gaming has emerged as a new computer game delivery paradigm that promises gaming anywhere, anytime, on any device, by running the computer game on a cloud server and streaming the rendered frames to users. To fulfill its promises, a cloud gaming provider must face three main challenges: reducing the interaction latency, reducing the cloud infrastructure cost, and reducing the network bandwidth demand. One way to reduce interaction latency is to run the game on the edge instead of the cloud. This introduces two additional challenges due to the limited resources available on the edge servers. First, there is a high initialization cost to install a game on the edge server if the game that a player wishes to play is not already installed. Second, an edge server typically has limited computing resources compared to the servers in the cloud. In this work, we address these two issues by proposing CloudyGame, a new software architecture for developing computer games, in which (i) resources are more efficiently shared and managed between different playing instances, and (ii) game assets are streamed on-demand to reduce the initialization cost. CloudyGame is implemented with a popular game engine, and thus any game built on the engine supports CloudyGame out of the box. Our evaluation shows that a game running on CloudyGame architecture needs 70-80% less RAM, VRAM, and CPU than a game using conventional architecture when running with four players. Furthermore, the game asset streaming system reduces the game's initial loading time by 70%. Hence, our cloud gaming architecture is highly scalable and economically deployable to the edge. Further, due to a reduction in resource usage, the CloudyGame architecture would benefit games running in the cloud as well.
C1 [Bhojan, Anand; Ng, Siang Ping; Ng, Joel; Ooi, Wei Tsang] Natl Univ Singapore, Sch Comp, 13 Comp Dr, Singapore 117417, Singapore.
C3 National University of Singapore
RP Bhojan, A (corresponding author), Natl Univ Singapore, Sch Comp, 13 Comp Dr, Singapore 117417, Singapore.
EM banand@comp.nus.edu.sg; ooiwt@comp.nus.edu.sg
RI Ooi, Wei Tsang/HLW-5142-2023
OI Ooi, Wei Tsang/0000-0001-8994-1736
FU Singapore Ministry of Education Academic Research Fund [Tier 1
   T1251RES1506]
FX This work is supported by Singapore Ministry of Education Academic
   Research Fund Tier 1 T1251RES1506 "Cloud-based Multi-user Interactive
   Virtual Environments"
CR Amiri M, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2983639
   Anand B, 2014, 2014 SEVENTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORKING (ICMU), P14, DOI 10.1109/ICMU.2014.6799051
   Anand B, 2009, MOBIHELD 09, P55
   Basiri M, 2018, IEEE T CIRC SYST VID, V28, P972, DOI 10.1109/TCSVT.2016.2632121
   Cai W, 2018, IEEE SYST J, V12, P2483, DOI 10.1109/JSYST.2018.2797080
   Chen H, 2019, IEEE T PARALL DISTR, V30, P2849, DOI 10.1109/TPDS.2019.2922205
   Chen K.-T., 2011, P 19 ACM INT C MULT, P1269
   Deng Yunhua, 2016, P 24 ACM INT C MULT, P918
   Eu, 2016, P 2016 ACM MULT C MM, P737, DOI [10.1145/2964284.2973827, DOI 10.1145/2964284.2973827]
   Gharsallaoui R, 2017, INT WIREL COMMUN, P1072, DOI 10.1109/IWCMC.2017.7986434
   Hong HJ, 2015, IEEE T CLOUD COMPUT, V3, P42, DOI 10.1109/TCC.2014.2338295
   Jarschel M, 2013, MATH COMPUT MODEL, V57, P2883, DOI 10.1016/j.mcm.2011.12.014
   Li YS, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P231, DOI 10.1145/3307681.3325409
   Li Z., 2016, NETFLIX TECH BLOG, V6
   Qi ZW, 2014, ACM T ARCHIT CODE OP, V11, P61, DOI 10.1145/2632216
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Sun KR, 2015, J VIS COMMUN IMAGE R, V30, P234, DOI 10.1016/j.jvcir.2015.03.012
   Wang SX, 2010, GLOB TELECOMM CONF
   Wu JY, 2015, IEEE T CIRC SYST VID, V25, P1988, DOI 10.1109/TCSVT.2015.2441412
   Zhang C, 2014, IEEE T PARALL DISTR, V25, P3036, DOI 10.1109/TPDS.2013.288
   Zhang W, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P324, DOI 10.1145/3123266.3123306
   Zhang YH, 2016, IEEE T PARALL DISTR, V27, P1239, DOI 10.1109/TPDS.2015.2433916
NR 22
TC 8
Z9 9
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32503
EP 32523
DI 10.1007/s11042-020-09612-z
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564978000008
DA 2024-07-18
ER

PT J
AU Pucci, R
   Micheloni, C
   Foresti, GL
   Martinel, N
AF Pucci, Rita
   Micheloni, Christian
   Foresti, Gian Luca
   Martinel, Niki
TI Deep interactive encoding with capsule networks for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Capsule network; Image classification; Bilinear
   function; Feature interaction
AB With new architectures providing astonishing performance on many vision tasks, the interest in Convolutional Neural Networks (CNNs) has grown exponentially in the recent past. Such architectures, however, are not problem-free. For instance, one of the many issues is that they require a huge amount of labeled data and are not able to encode pose and deformation information. Capsule Networks (CapsNets) have been recently proposed as a solution to the issues related to CNNs. CapsNet achieved interesting results in images recognition by addressing pose and deformation encoding challenges. Despite their success, CapsNets are still an under-investigated architecture with respect to the more classical CNNs. Following the ideas of CapsNet, we propose to introduce Residual Capsule Network (ResNetCaps) and Dense Capsule Network (DenseNetCaps) to tackle the image recognition problem. With these two architectures, we expand the encoding phase of CapsNet by adding residual convolutional and densely connected convolutional blocks. In addition to this, we investigate the application of feature interaction methods between capsules to promote their cooperation while dealing with complex data. Experiments on four benchmark datasets demonstrate that the proposed approach performs better than existing solutions.
C1 [Pucci, Rita; Micheloni, Christian; Foresti, Gian Luca; Martinel, Niki] Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
C3 University of Udine
RP Pucci, R (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
EM rita.pucci@uniud.it
RI Micheloni, Christian/E-5427-2012; Pucci, Rita/U-4201-2018
OI Pucci, Rita/0000-0002-2970-1180; Micheloni,
   Christian/0000-0003-4503-7483
FU NVIDIA Corporation
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan Xp GPU used for this research. Thanks to Patrizia
   Papalini for proofreading the article.
CR Akar E., 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P982, DOI 10.1007/978-3-030-22871-2_70
   Akcay S, 2018, IEEE T INF FOREN SEC, V13, P2203, DOI 10.1109/TIFS.2018.2812196
   [Anonymous], 2018, ARXIV180507706
   Armenteros JJA, 2019, NAT BIOTECHNOL, V37, P420, DOI 10.1038/s41587-019-0036-z
   Asuntha A, 2020, MULTIMED TOOLS APPL, V79, P7731, DOI 10.1007/s11042-019-08394-3
   Bakkouri Ibtissam, 2019, MULTIMED TOOLS APPL, P1
   Barbuti Roberto, 2013, 50 ANNIVERSARY CONVE, P62
   Bi L., 2017, Automatic Skin Lesion Analysis using Largescale Dermoscopy Images and Deep Residual Networks
   Chao H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092212
   Chessa S, 2017, APPL ARTIF INTELL, V31, P453, DOI 10.1080/08839514.2017.1378162
   Deliege A, 2018, ARXIV PREPRINT ARXIV
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Habibzadeh M, 2018, INT SOC OPT PHOTO
   Han SS, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191493
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinrichs A, 2011, RANDOM STRUCT ALGOR, V39, P391, DOI 10.1002/rsa.20360
   Hinton G.E., 2018, INT C LEARN REPR
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hou, 2019, ARXIV190903108
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang Yanping, 2018, Advances in Neural Information Processing Systems
   Jiménez J, 2018, J CHEM INF MODEL, V58, P287, DOI 10.1021/acs.jcim.7b00650
   Kang MJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155781
   Kermany Daniel, 2018, Mendeley Data, V3
   Kingma D. P., 2014, arXiv
   Kosiorek A. R., 2019, Adv. Neural Inf. Process Syst, P15486
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu JW, 2019, LECT NOTES COMPUT SC, V11727, P152, DOI 10.1007/978-3-030-30487-4_13
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Martinel Niki, 2015, IEEE Systems, Man, and Cybernetics Magazine, V1, P17, DOI 10.1109/MSMC.2015.2461151
   Martinel N, 2015, IEEE SIGNAL PROC LET, V22, P455, DOI 10.1109/LSP.2014.2362573
   Morota G, 2018, J ANIMAL SCI
   Nair Prem, 2018, PUSHING LIMITS CAPSU
   Pan XY, 2018, BIOINFORMATICS, V34, P3427, DOI 10.1093/bioinformatics/bty364
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Phaye SSR, 2018, ARXIV180504001
   Pucci R, 2019, ICDSC
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Rakhlin A, 2018, LECT NOTES COMPUT SC, V10882, P737, DOI 10.1007/978-3-319-93000-8_83
   Rubinstein R, METHODOLOGY COMPUTIN, V1, P127
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sabour S, 2017, ADV NEUR IN, V30
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tabak MA, 2019, METHODS ECOL EVOL, V10, P585, DOI 10.1111/2041-210X.13120
   Wang Dilin, 2018, An optimization view on dynamic routing between capsules
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xu PF, 2018, MULTIMED TOOLS APPL, V77, P3143, DOI 10.1007/s11042-017-4984-3
   Zhou TQ, 2021, MOBILE NETW APPL, V26, P909, DOI 10.1007/s11036-019-01351-2
NR 55
TC 10
Z9 10
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32243
EP 32258
DI 10.1007/s11042-020-09455-8
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562943300010
DA 2024-07-18
ER

PT J
AU Roy, S
   Bhattacharya, A
   Sarkar, N
   Malakar, S
   Sarkar, R
AF Roy, Soham
   Bhattacharya, Archan
   Sarkar, Navonil
   Malakar, Samir
   Sarkar, Ram
TI Offline hand-drawn circuit component recognition using texture and
   shape-based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand-drawn circuit components; Texture based feature; Shape based
   feature; Sequential minimal optimization; Feature selection
ID CLASSIFICATION
AB Circuit diagram is the very foundation of electrical and electronic sciences. A circuit diagram consists of various symbols called circuit components that specify the functionality of that circuit. Every day-to-day gadgets that we use are made up with a number of electrical/electronic circuits to play out their particular tasks. Till date circuit designers have to physically enter all data from the hand-drawn circuits into computers, and this procedure requires some investment in terms of time and carries mistakes with high likelihood. To this end, in this paper, we propose a method that relaxes this constraint by introducing a method for recognition of hand-drawn electrical and electronic circuit components, with both analog and digital components included. In the proposed method, the pre-processed images of circuit components are used for training and testing a recognition model using a feature set consisting of a texture based feature descriptor, called histogram of oriented gradients (HOG), and shape based features that include centroid distance, tangent angle, and chain code histogram. In addition, the texture based feature, being large in number compared to others is optimized using a feature selection algorithm called ReliefF. Classification of components is done by using sequential minimal optimization (SMO) classifier. The proposed method has been evaluated on a dataset of 20 different circuit components with 150 samples in each class. The experimental outcome shows that the proposed approach provides average 93.83% accuracy on the present database. We also compare our method with some of the state-of-the-art methods and we see that our method outperforms these methods.
C1 [Roy, Soham; Bhattacharya, Archan; Sarkar, Navonil] Jadavpur Univ, Dept Elect & Telecommun, Kolkata, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata, India.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University; Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata, India.
EM sohamroymiller@gmail.com; archanbhattacharya4@gmail.com;
   sarkar.navonil2000@gmail.com; malakarsamir@gmail.com;
   raamsarkar@gmail.com
RI Malakar, Samir/A-8021-2017; Sarkar, Ram/AAX-3822-2020
OI Malakar, Samir/0000-0003-4217-2372; Sarkar, Ram/0000-0001-8813-4086
FU PURSE-II, Jadavpur University; UPE-II, Jadavpur University; DST, Govt.
   of India [EMR/2016/007213]
FX We would like to thank CMATER research laboratory of the Computer
   Science and Engineering Department, Jadavpur University, India for
   providing us the infrastructural support. This work is partially
   supported by the PURSE-II and UPE-II, Jadavpur University projects. Ram
   Sarkar is thankful to DST, Govt. of India, for the grant
   (EMR/2016/007213) to carry out this research.
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2014, INT J COMPUTSCI MOB
   [Anonymous], 2013, BMVC
   Avola D, 2020, MULTIMED TOOLS APPL, V79, P4463, DOI 10.1007/s11042-019-7196-1
   Avola D, 2017, LECT NOTES COMPUT SC, V10484, P223, DOI 10.1007/978-3-319-68560-1_20
   Barua S, 2017, ADV INTELL SYST, V515, P343, DOI 10.1007/978-981-10-3153-3_34
   Bhattacharya A, 2020, 2020 IEEE CALCUTTA CONFERENCE (CALCON), P80, DOI 10.1109/CALCON49167.2020.9106527
   Bhowmik S, 2019, NEURAL COMPUT APPL, V31, P5783, DOI 10.1007/s00521-018-3389-1
   Chao T, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P255, DOI 10.1109/WCICA.2012.6357878
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deufemia V, 2014, PATTERN RECOGN, V47, P1159, DOI 10.1016/j.patcog.2013.09.016
   Dewangan A., 2018, INT J RES APPL SCI E, V6, P1
   Dinesh R, 2018, J THEOR APPL INF TEC, V96
   Feng GH, 2009, PATTERN RECOGN, V42, P3215, DOI 10.1016/j.patcog.2009.01.031
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Jana P, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P226, DOI 10.1109/CALCON.2017.8280729
   Kononenko I, 1996, FR ART INT, V35, P31
   Lakshman Naika R., 2019, International Journal of Machine Learning and Computing, V9
   LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042
   Liu Y, 2013, ELECTRON J DIFFER EQ
   Malakar Samir, 2017, International Journal of Computer Vision and Image Processing, V7, P59, DOI 10.4018/IJCVIP.2017010104
   Mohanaiah P., 2013, INT J SCI RES PUB, V3, P1, DOI 10.5772/58692
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rabbani M, 2016, PROCEDIA COMPUT SCI, V84, P41, DOI 10.1016/j.procs.2016.04.064
   Sahoo Samanway, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P451, DOI 10.1007/978-981-10-7566-7_44
   Sala P, 2004, 2515 CSC
NR 27
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31353
EP 31373
DI 10.1007/s11042-020-09570-6
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259400002
DA 2024-07-18
ER

PT J
AU Liu, WR
   Gao, HL
   Liu, J
   Liu, CR
   Li, BS
   Song, XH
AF Liu, Weirong
   Gao, Huiling
   Liu, Jie
   Liu, Chaorong
   Li, Binshan
   Song, Xuhui
TI A robust tracker integrating particle filter into correlation filter
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking correlation filter particle filter long-time and
   short-time update scheme
ID OBJECT TRACKING; VISUAL TRACKING
AB The location and scale filters in discriminative correlation filter methods are lack of accurate rotation representation capability and updated with fixed intervals, which leads to tracking failure and time-consuming in complex scenarios. In this manuscript, a robust tracker integrating particle filter into correlation filter is presented to cope with sharp rotation and remarkable deformation. The target position and scale factor are firstly estimated from the correlation filter, and then the rotation factor is determined by similarity between candidates and template based on the particle filter. As a result, target variation can be accurately described with position, scale and rotation factor. Moreover, a long-time and short-time update scheme is proposed to solve target template drifting problem. Extensive experimental results conducted on OTB-2013, OTB-2015 and VOT-2016 show that the proposed tracker improves the accuracy and robustness of discriminative correlation filter methods.
C1 [Liu, Weirong; Gao, Huiling; Li, Binshan; Song, Xuhui] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou, Peoples R China.
   [Liu, Jie] Lanzhou Univ Technol, Natl Demonstrat Ctr Expt Elect & Control Engn Edu, Lanzhou, Peoples R China.
   [Liu, Chaorong] Lanzhou Univ Technol, Key Lab Gansu Adv Control Ind Proc, Lanzhou, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology;
   Lanzhou University of Technology
RP Liu, WR (corresponding author), Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou, Peoples R China.
EM liu_weirong@163.com
FU National Natural Science Foundation of China [61861027]
FX The authors would like to thank the editors and the anonymous reviewers,
   whose comments helped to improve the paper greatly. This work was
   supported by the National Natural Science Foundation of China (No.
   61461028) and the National Natural Science Foundation of China (No.
   61861027).
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Biresaw TA, 2015, IEEE T CIRC SYST VID, V25, P776, DOI 10.1109/TCSVT.2014.2360027
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chang C, 2005, IEEE SIGNAL PROC LET, V12, P242, DOI 10.1109/LSP.2004.842254
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Choe GM, 2015, MULTIMED TOOLS APPL, V74, P7595, DOI 10.1007/s11042-014-1993-3
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Danelljan Martin, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P117, DOI 10.1007/978-3-319-19665-7_10
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang W, 2019, MULTIMED TOOLS APPL, V78, P16011, DOI 10.1007/s11042-018-6956-7
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Truong MTN, 2018, MULTIMED TOOLS APPL, V77, P30067, DOI 10.1007/s11042-018-6180-5
   Pi JT, 2016, IEICE T INF SYST, VE99D, P1895, DOI 10.1587/transinf.2015EDP7459
   Qian C, 2016, IEEE T CIRC SYST VID, V26, P1293, DOI 10.1109/TCSVT.2015.2424091
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang Q., 2017, ARXIV170404057
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang CJ, 2005, IEEE I CONF COMP VIS, P212
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
   Zhang XY, 2019, IEEE ACCESS, V7, P134772, DOI 10.1109/ACCESS.2019.2942047
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zia K, 2004, IEEE COMP SOC C COMP, pII, DOI [10.1109/CVPR.2004.1315271, DOI 10.1109/CVPR.2004.1315271]
NR 40
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28431
EP 28452
DI 10.1007/s11042-020-09240-7
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555361800004
DA 2024-07-18
ER

PT J
AU Gao, Q
   Wang, CH
   Wang, Z
   Song, XL
   Dong, EZ
   Song, Y
AF Gao, Qiang
   Wang, Chu-han
   Wang, Zhe
   Song, Xiao-lin
   Dong, En-zeng
   Song, Yu
TI EEG based emotion recognition using fusion feature extraction method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Power spectrum feature; Wavelet energy entropy feature; Fusion feature;
   EEG; Emotion recognition
ID CLASSIFICATION; MACHINE
AB As a high-level function of the human brain, emotion is the external manifestation of people's psychological characteristics. The emotion has a great impact on people's personality and mental health. At the same time, emotion classification from electroencephalogram (EEG) signals have attracted much attention. To improve the precision of EEG-based emotion recognition, we proposed a fused feature extraction method to complete the classification of three emotions (neutral, happiness, and sadness). The standardized movie clips were selected to induce the corresponding emotion and the EEG response of 10 participants is collected by Emotiv EPOC. This paper systematically compared two kinds of EEG features (power spectrum and wavelet energy entropy) and their fusion for emotion classification. To reduce the dimension of fused features, we used principal component analysis (PCA) for dimensionality reduction and feature selection. The support vector machine (SVM) classifier and the relevance vector machines (RVM) classifier were utilized for emotion recognition respectively. From experimental results, we found that the fusion of two kinds of features outperformed a single feature for emotion classification by both the SVM classifier and the RVM classifier, and the averaged classification accuracy was 89.17% and 91.18%, respectively.
C1 [Gao, Qiang; Wang, Chu-han; Wang, Zhe; Dong, En-zeng; Song, Yu] Tianjin Key Lab Control Theory & Applicat Complic, Tianjin, Peoples R China.
   [Song, Xiao-lin] Tianjin Univ Technol, Training Ctr, Tianjin, Peoples R China.
C3 Tianjin University of Technology
RP Song, Y (corresponding author), Tianjin Key Lab Control Theory & Applicat Complic, Tianjin, Peoples R China.
EM wang94627@gmail.com; jasonsongrain@hotmail.com
RI Song, Yu/ABT-2116-2022; wang, chu/GYJ-2191-2022
OI Song, Yu/0000-0002-9295-7795
FU Fundamental Research on Advanced Technology and Engineering Application
   Team, Tianjin, China [20160524]; Natural Science Foundation of Tianjin
   [18JCYBJC87700]
FX This work was supported by the Fundamental Research on Advanced
   Technology and Engineering Application Team, Tianjin, China (grant
   No.20160524) and Natural Science Foundation of Tianjin
   (No.18JCYBJC87700).
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   AHERN GL, 1985, NEUROPSYCHOLOGIA, V23, P745, DOI 10.1016/0028-3932(85)90081-8
   Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   [Anonymous], 2012, SENSORS
   [Anonymous], 2017, IEEE T AFFECT COMPUT
   [Anonymous], 2011, LIBSVM: a library for support vector machines
   [Anonymous], 2000, P ISCA TUT RES WORKS
   Arshad H, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12541
   Candra H, 2015, IEEE ENG MED BIO, P7250, DOI 10.1109/EMBC.2015.7320065
   de Cheveigne A, 2018, MULTIWAY CANONICAL C
   Ekman P., 1970, California Mental Health Research Digest, V8, P151
   Forster J, 1996, J PERS SOC PSYCHOL, V71, P421, DOI 10.1037/0022-3514.71.3.421
   Geng Xueqing, 2017, Chinese Journal of Sensors and Actuators, V30, P378, DOI 10.3969/j.issn.1004-1699.2017.03.008
   Hillman CH, 2004, BIOL PSYCHOL, V66, P51, DOI 10.1016/j.biopsycho.2003.07.005
   HUBERT W, 1991, INT J PSYCHOPHYSIOL, V11, P131, DOI 10.1016/0167-8760(91)90005-I
   Huss N, 2020, MED TEACH, V42, P1097, DOI 10.1080/0142159X.2020.1797998
   Hyvärinen A, 2010, NEUROIMAGE, V49, P257, DOI 10.1016/j.neuroimage.2009.08.028
   Iacoviello D, 2015, COMPUT METH PROG BIO, V122, P293, DOI 10.1016/j.cmpb.2015.08.011
   Ji N, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9080201
   Jung TP, 1997, IEEE T BIO-MED ENG, V44, P60, DOI 10.1109/10.553713
   Khan M., 2019, PATTERN RECOGN LETT
   Khosrowabadi R, 2014, IEEE T NEUR NET LEAR, V25, P609, DOI 10.1109/TNNLS.2013.2280271
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Li DH, 2019, TECHNOL HEALTH CARE, V27, P373, DOI 10.3233/THC-181538
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P437, DOI 10.1016/j.bspc.2013.01.005
   Mehmood A, 2024, MULTIMED TOOLS APPL, V83, P14979, DOI 10.1007/s11042-020-08928-0
   Momennezhad A, 2018, MULTIMED TOOLS APPL, V77, P27089, DOI 10.1007/s11042-018-5906-8
   Morris J, 1995, OBSERVATIONS SAM SEL
   Newson JJ, 2019, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00521
   Pane ES, 2019, COGN PROCESS, V20, P405, DOI 10.1007/s10339-019-00924-z
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Perales FJ, 2019, MULTIMED TOOLS APPL, V78, P32869, DOI 10.1007/s11042-019-07953-y
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer KR, 2004, J NEW MUSIC RES, V33, P239, DOI 10.1080/0929821042000317822
   Tao R, 2010, IEEE T SIGNAL PROCES, V58, P2568, DOI 10.1109/TSP.2009.2028095
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Xue W, 2009, 2009 8 IEEE INT C CO
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 41
TC 45
Z9 48
U1 8
U2 99
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27057
EP 27074
DI 10.1007/s11042-020-09354-y
EA JUL 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000551375500001
DA 2024-07-18
ER

PT J
AU Chou, KP
   Prasad, M
   Yang, J
   Su, SY
   Tao, X
   Saxena, A
   Lin, WC
   Lin, CT
AF Chou, Kuang Pen
   Prasad, Mukesh
   Yang, Jie
   Su, Sheng-Yao
   Tao, Xian
   Saxena, Amit
   Lin, Wen-Chieh
   Lin, Chin-Teng
TI A robust real-time facial alignment system with facial landmarks
   detection and rectification for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face alignment; Facial feature localization; Head pose estimation; Face
   recognition
ID FACE RECOGNITION; FEATURES
AB Face detection often plays the first step in various visual applications. Large variants of facial deformations due to head movements and facial expression make it difficult to identify appropriate face region. In this paper, a robust real-time face alignment system, including facial landmarks detection and face rectification, is proposed. A facial landmarks detection model based on regression tree is utilized in the proposed system. In face rectification framework, 2-D geometrical analysis based on pitch, yaw and roll movements is designed to solve the misalignment problem in face detection. The experiments on the two datasets verify the performance significantly improved by the proposed method in the facial recognition task and outperform than those obtained by other alignment methods. Furthermore, the proposed method can achieve robust recognition results even if the amount of training images is not large.
C1 [Chou, Kuang Pen; Su, Sheng-Yao; Lin, Wen-Chieh] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Prasad, Mukesh; Yang, Jie; Lin, Chin-Teng] Univ Technol Sydney, Ctr Artificial Intelligence, Sch Comp Sci, FEIT, Ultimo, NSW, Australia.
   [Tao, Xian] Chinese Acad Sci, Res Ctr Precis Sensing & Control, Inst Automat, Beijing, Peoples R China.
   [Saxena, Amit] Guru Ghasidas Univ, Dept Comp Sci & IT, Bilaspur, India.
C3 National Yang Ming Chiao Tung University; University of Technology
   Sydney; Chinese Academy of Sciences; Institute of Automation, CAS; Guru
   Ghasidas Vishwavidyalaya
RP Prasad, M (corresponding author), Univ Technol Sydney, Ctr Artificial Intelligence, Sch Comp Sci, FEIT, Ultimo, NSW, Australia.
EM mukesh.prasad@uts.edu.au
RI ; Lin, Chin-Teng (CT)/G-8129-2017
OI Prasad, Mukesh/0000-0002-7745-9667; Lin, Chin-Teng
   (CT)/0000-0001-8371-8197
FU Australian Research Council (ARC) [DP180100670, DP180100656]; U.S. Army
   Research Laboratory [W911NF-10-2-0022]; Taiwan Ministry of Science and
   Technology [MOST 106-2218-E-009-027-MY3]
FX This work was supported in part by the Australian Research Council (ARC)
   under Grant DP180100670 and Grant DP180100656, in part by the U.S. Army
   Research Laboratory under Agreement W911NF-10-2-0022, and in part by the
   Taiwan Ministry of Science and Technology under Grant MOST
   106-2218-E-009-027-MY3.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 1995, P 2 EUR C COMP LEARN
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N., 2005, IEEE C COMP VIS PATT
   Dapogny A, 2019, IEEE I CONF COMP VIS, P6892, DOI 10.1109/ICCV.2019.00699
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Ge Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P12
   Hanxi Li, 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P262, DOI 10.1109/DICTA.2010.54
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kotropoulos C, 1997, INT CONF ACOUST SPEE, P2537, DOI 10.1109/ICASSP.1997.595305
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LANITIS A, 1995, IMAGE VISION COMPUT, V13, P393, DOI 10.1016/0262-8856(95)99726-H
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu H., 2014, ACTIVE SHAPE MODEL I, P1
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhao YC, 2019, MULTIMED TOOLS APPL, V78, P13131, DOI 10.1007/s11042-018-5609-1
NR 32
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16635
EP 16657
DI 10.1007/s11042-020-09216-7
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000545938900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Musanna, F
   Dangwal, D
   Kumar, S
AF Musanna, Farhan
   Dangwal, Deepak
   Kumar, Sanjeev
TI A novel chaos-based approach in conjunction with MR-SVD and pairing
   function for generating visually meaningful cipher images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-Arnold Cat map; Logistic equation; Multi-resolution singular value
   decomposition; Pairing functions; Pixel-encoding; Visually meaningful
   cipher image
ID SINGULAR-VALUE DECOMPOSITION; ENCRYPTION; SCHEME; MAP; ALGORITHM
AB For secure transmission of digital images, existing cryptographic algorithms transform images into a noise-like appearance. One obvious inference that an adversary could draw is that the noise-like texture is a cipher, prompting to apply classical cryptanalysis. This article proposes an efficient algorithm that produces a visually coherent and meaningful cipher image to bypass the cryptanalysis. In the partial-encryption phase, the Arnold-3D map drives the permutation mechanism, whereas the implementation of the diffusion phase is done by harnessing the iterates of the chaotic Logistic map. The partial cipher is compressed using a Cantor-like pairing function that does a 4 to 1 pixel encoding to facilitate embedding. The embedding phase is implemented in the spatial domain by applying Multi-resolution singular value decomposition on the reference image and replacing the vertical, horizontal, diagonal sub-band with the encoded cipher. The encoding of pixels facilitates the transmission of the visually meaningful cipher image to be of the same size as the original image rather than four-times the original image as reported in earlier schemes. Simulation results confirm the security of the scheme.
C1 [Musanna, Farhan; Dangwal, Deepak; Kumar, Sanjeev] Indian Inst Technol, Dept Math, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kumar, S (corresponding author), Indian Inst Technol, Dept Math, Roorkee, Uttar Pradesh, India.
EM fmusanna@ma.iitr.ac.in; ddangwalj@gmail.com; sanjeev.kumar@ma.iitr.ac.in
RI Kumar, Sanjeev/HKN-6866-2023; Kumar, Sanjeev/JTV-5459-2023
OI Kumar, Sanjeev/0000-0001-7728-3668; MUSANNA, FARHAN/0000-0001-8428-3551
FU Ministry of Human Resource Development, India [MHR-01-23-200-428]
FX One of the authors, Farhan Musanna, is grateful to the Ministry of Human
   Resource Development, India and the Indian Institute of Technology,
   Roorkee for being the funding agency of this work. The grant number is
   MHR-01-23-200-428.
CR Akhbari B, 2005, I S INTELL SIG PROC, P325
   [Anonymous], 2008, Introduction to Modern Cryptography
   [Anonymous], 2019, INT J ADV INTELL PAR
   Ashin R, 2005, MATH COMPUT MODEL, V41, P773, DOI 10.1016/j.mcm.2003.12.014
   Ashino R, 2005, ADV IN ANAL, P457
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Cantor Georg, 1874, Journal fur die reine und angewandte Mathematik, P258
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen MS, 2016, PROC SPIE, V10033, DOI 10.1117/12.2245059
   FEIGENBAUM MJ, 1978, J STAT PHYS, V19, P25, DOI 10.1007/BF01020332
   Francois M., 2012, APPL MATH, V3, P1910, DOI DOI 10.4236/AM.2012.312262
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Guo CL, 2014, OPT COMMUN, V321, P61, DOI 10.1016/j.optcom.2014.01.061
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Khan JS, 2019, J INTELL FUZZY SYST, V37, P2549, DOI 10.3233/JIFS-182778
   Lima JB, 2014, SIGNAL PROCESS, V94, P521, DOI 10.1016/j.sigpro.2013.07.020
   Lima JB, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1071, DOI 10.1109/GlobalSIP.2015.7418362
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Malini S, 2015, PROCEDIA COMPUT SCI, V46, P1708, DOI 10.1016/j.procs.2015.02.114
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Martin K, 2005, PATTERN RECOGN, V38, P1111, DOI 10.1016/j.patcog.2005.01.002
   Musanna F, 2019, MULTIMED TOOLS APPL, V78, P14867, DOI 10.1007/s11042-018-6827-2
   Patidar V, 2011, OPT COMMUN, V284, P4331, DOI 10.1016/j.optcom.2011.05.028
   PHATAK SC, 1995, PHYS REV E, V51, P3670, DOI 10.1103/PhysRevE.51.3670
   Rukhin A., 2001, TECHNICAL REPORT
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Sharma K, 2017, SCALABLE COMPUT-PRAC, V18, pIII, DOI 10.12694/scpe.v18i3.1299
   Shaw AK, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, ENERGY & COMMUNICATION (CIEC), P193, DOI 10.1109/CIEC.2016.7513816
   Shrivastava G., 2018, HDB RES NETWORK FORE
   Shrivastava G, 2018, SPECIAL ISSUE ADV RE
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Szudzik M., 2006, Special NKS 2006 Wolfram Science Conference, P1
   Wen WY, 2018, NEURAL COMPUT APPL, V29, P653, DOI 10.1007/s00521-016-2490-6
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yang Y., 2015, IEEE T PARALL DISTR, P1, DOI DOI 10.18632/0NC0TARGET.3970
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Zeghid M., 2007, INT J COMPUT SCI ENG, V1, P70
NR 45
TC 21
Z9 23
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 25115
EP 25142
DI 10.1007/s11042-020-09034-x
EA JUN 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000544580400002
DA 2024-07-18
ER

PT J
AU Huang, YB
   Wang, Y
   Zhang, QY
   Zhang, WZ
   Fan, MH
AF Huang, Yi-bo
   Wang, Yong
   Zhang, Qiu-yu
   Zhang, Wei-zhao
   Fan, Man-hong
TI Multi-format speech BioHashing based on spectrogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech content authentication; BioHashing; Spectrogram; Henon map;
   Comparative difference method
ID DISCRETE-WAVELET-TRANSFORM; NONNEGATIVE MATRIX; AUTHENTICATION; AUDIO;
   BIOMETRICS; ALGORITHM; HASH
AB In order to solve the security problem of speech perception hash authentication, the application scope of speech authentication algorithm, and improve the robustness, discrimination and real-time authentication in the process of authentication, a multi-format speech BioHashing algorithm based on spectrogram is proposed. Firstly, the speech signal to be processed is converted into spectrogram and feature extraction is carried out by two-dimensional discrete cosine transform. Then, the dimensionality of the eigenvector is reduced by non-negative matrix factorization, and generation of BioHashing sequences by inner product of reduced dimension eigenvectors and orthogonal normalized random matrices. Finally, the BioHashing is encrypted by equal-length scrambling using Henon chaotic map. The algorithm also validates the unidirectionality of BioHashing with trapdoor by comparative difference method. The experimental results show that the proposed algorithm has the characteristics of good security, strong robustness, high real-time performance and wide application range.
C1 [Huang, Yi-bo; Wang, Yong; Zhang, Wei-zhao; Fan, Man-hong] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@foxmail.com
RI zhang, qiu/GXG-5600-2022; Yong, Wang/AAW-8984-2020
OI Yong, Wang/0000-0002-8326-2924; /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Youth Science
   and Technology Fund of Gansu Province of China [1606RJYA274]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Youth Science and Technology Fund of Gansu Province
   of China(No.1606RJYA274).
CR Alpar O, 2018, APPL INTELL, V48, P1189, DOI 10.1007/s10489-017-1009-x
   Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0258-7
   [Anonymous], 2015, J INF HIDING MULTIME
   Awais A, 2018, INT C ART INT BIG DA, P2018
   Chen N, 2010, IET COMMUN, V4, P1722, DOI 10.1049/iet-com.2009.0749
   Chen N, 2010, ETRI J, V32, P345, DOI 10.4218/etrij.10.0209.0309
   Frackowiak M, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009027.pub3
   Hammad M, 2019, MULTIMED TOOLS APPL, V78, P1857, DOI 10.1007/s11042-018-6300-2
   Huang Y-B, 2018, IJ NETW SECUR, V20, P206
   Huang Y-B, 2017, J SOFTW ENG, V11, P22, DOI [10.3923/jse.2017.22.31, DOI 10.3923/JSE.2017.22.31]
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Jiao YH, 2009, IEEE SIGNAL PROC LET, V16, P818, DOI 10.1109/LSP.2009.2025827
   Jin Z, 2018, IEEE T INF FOREN SEC, V13, P393, DOI 10.1109/TIFS.2017.2753172
   Kanak A, 2017, IET BIOMETRICS, V6, P457, DOI 10.1049/iet-bmt.2016.0148
   Kaur H, 2019, PATTERN RECOGN LETT, V126, P31, DOI 10.1016/j.patrec.2018.02.016
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Kumari S, 2017, FUTURE GENER COMP SY, V68, P320, DOI 10.1016/j.future.2016.10.004
   Lacharme P, 2013, IET BIOMETRICS, V2, P130, DOI 10.1049/iet-bmt.2012.0041
   Li JF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P363, DOI 10.1109/CIS.2015.94
   Li JF, 2015, CHINESE J ELECTRON, V24, P579, DOI 10.1049/cje.2015.07.024
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Lotia P, 2013, IJRCCT, V2, P579
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Plapous C, 2018, MULTIMED TOOLS APPL, V77, P5929, DOI 10.1007/s11042-017-4505-4
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qiuyu Zhang, 2017, 2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P1295, DOI 10.1109/FSKD.2017.8392951
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Siddavatam I, 2019, STUD COMPUT INTELL, V771, P293, DOI 10.1007/978-981-10-8797-4_31
   Teoh ABJ, 2008, PATTERN RECOGN, V41, P2034, DOI 10.1016/j.patcog.2007.12.002
   Wang NF, 2019, J VIB ENG TECHNOL, V7, P311, DOI 10.1007/s42417-019-00126-z
   Wodecki J, 2019, MECH SYST SIGNAL PR, V130, P585, DOI 10.1016/j.ymssp.2019.05.020
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   Zhang C, 2017, INFORM SCIENCES, V409, P56, DOI 10.1016/j.ins.2017.05.006
   Zhang Q, 2018, INT J INF COMMUN TEC, V12, P31, DOI DOI 10.1504/IJICT.2018.089021
   Zhang Q.Y., 2018, J INF HIDING MULTIME, V9, P1452
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P1555, DOI 10.1007/s11042-017-4381-y
   Zhang Qiuyu, 2018, Journal of Huazhong University of Science and Technology (Natural Science Edition), V46, P58, DOI 10.13245/j.hust.180311
   Zhang Qiuyu, 2017, Journal of Huazhong University of Science and Technology (Natural Science Edition), V45, P33, DOI 10.13245/j.hust.170907
   Zhang Qiuyu, 2016, Journal of Huazhong University of Science and Technology (Natural Science Edition), V44, P127, DOI 10.13245/j.hust.161222
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
   Zhang QY., 2019, INT J NETW SECUR, V21, P259
   Zhang XM, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P110, DOI 10.1145/3301551.3301600
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 46
TC 5
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24889
EP 24909
DI 10.1007/s11042-020-09211-y
EA JUN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000543615200003
DA 2024-07-18
ER

PT J
AU Danapur, N
   Dizaj, SAA
   Rostami, V
AF Danapur, Navid
   Dizaj, Sakineh Asghari Aghjeh
   Rostami, Vahid
TI An efficient image retrieval based on an integration of HSV, RLBP, and
   CENTRIST features using ensemble classifier learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Feature extraction; HSV feature; Texture
   feature; Structural feature; RLBP; CENTRIST; And PCA
ID DIMENSIONALITY REDUCTION; ROTATION-INVARIANT; FEATURE DESCRIPTOR; COLOR;
   SCALE; PATTERNS; SYSTEM
AB Recently, we have been witnessing a tremendous rise in digital image quantities, which in return calls for an adjustment and management system to fulfill user's queries in the shortest time with maximum accuracy. In this regard, Content-Based Image Retrieval (CBIR) approaches have gained unprecedented attention. In CBIR systems, image search is based on their actual contents instead of textual annotations. Due to the fact that users do not think of low-level image features such as color, texture, structure, and shape and are looking for high-level image features or semantic features while querying images, the performance of image retrieval systems becomes weak. On the one hand, the huge amount of extracted features and the complexity of feature spaces are considered as two main challenges in image retrieval study area. Therefore, this article trying to extract the key features of the image in order to increase the accuracy and speed of image recovery over big data. This study combines two feature extraction techniques namely Census Transform Histogram (CENTRIST) and Rotated Local Binary Pattern (RLBP) following by Kernel Principal Component Analysis (PCA) method to reduce the dimensional feature space. In fact, after feature extraction phase we utilize Adaboost M2 classifying method on the train data to learn the different classes of images that are existed in the database. Furthermore, instead of using RGB color space, images are transformed to HSV color space. The reason for using the HSV color space instead of the RGB one is the fact that it is closer to human perception. Performance evaluations of the proposed method are conducted on the Corel-1 K and UW datasets. Simulation results indicate that proposed method performs better than other methods.
C1 [Danapur, Navid; Rostami, Vahid] Islamic Azad Univ, Dept Comp Engn, Qazvin Branch, Qazvin, Iran.
   [Dizaj, Sakineh Asghari Aghjeh] Islamic Azad Univ, Dept Comp Engn, Bonab Branch, Bonab, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Dizaj, SAA (corresponding author), Islamic Azad Univ, Dept Comp Engn, Bonab Branch, Bonab, Iran.
EM sakineh154asghari@gmail.com
RI asghari, sakineh/AAX-3426-2020; Rostami, Vahid/IZP-6753-2023
OI Rostami, Vahid/0000-0001-9973-4271
CR Ahmad J, 2017, J REAL-TIME IMAGE PR, V13, P431, DOI 10.1007/s11554-015-0536-0
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Al-Shuhaib MBS, 2021, ANIM BIOTECHNOL, V32, P273, DOI 10.1080/10495398.2019.1683568
   [Anonymous], 2016, FEATURE DETECTORS MO
   [Anonymous], 2015, International Journal of Image Mining, DOI DOI 10.1504/IJIM.2015.070024
   [Anonymous], 2013, BMVC
   Belalia A, 2016, MULTIMED TOOLS APPL, V75, P10175, DOI 10.1007/s11042-015-3026-2
   Belarbi MA, 2017, INT J AMBIENT COMPUT, V8, P45, DOI 10.4018/IJACI.2017100104
   Belloulata K, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P470, DOI 10.1109/ChinaSIP.2014.6889287
   Boutoulle M, 2004, CONNAISSANCE ARTS, P104
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Charles YR, 2016, AEU-INT J ELECTRON C, V70, P225, DOI 10.1016/j.aeue.2015.11.009
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Chu WT, 2012, P 2 ACM INT C MULT R, p[Color, 1]
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dey S, 2018, INT C PATT RECOG, P916, DOI 10.1109/ICPR.2018.8545452
   Du YP, 2001, IEEE IMAGE PROC, P22, DOI 10.1109/ICIP.2001.958943
   Farhidzadeh H, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216976
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Goodrum A. A., 2000, Informing Science, V3, P63
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Hassanien AE, 2016, APPL INTELLIGENT OPT
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hoi SCH, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508854
   Jolliffe I. T., 1986, SPRINGER SERIES STAT, P1
   Kabbai L, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P151, DOI 10.1109/ATSIP.2016.7523086
   Kastner S, 2001, NEUROPSYCHOLOGIA, V39, P1263, DOI 10.1016/S0028-3932(01)00116-6
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lin CH, 2014, EXPERT SYST APPL, V41, P6611, DOI 10.1016/j.eswa.2014.04.033
   Lin CH, 2011, COMPUT J, V54, P1136, DOI 10.1093/comjnl/bxq066
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Junling, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P921
   Liu P, 2006, SIGN PROC 2006 8 INT, V3
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   LIVINGSTONE MS, 1984, J NEUROSCI, V4, P309
   Long FH, 2003, SIG COM TEC, P1
   Loupias E, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P518, DOI 10.1109/ICIP.2000.899469
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Marée R, 2007, LECT NOTES COMPUT SC, V4844, P611
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Mistry Yogita, 2018, Journal of Electrical Systems and Information Technology, V5, P874, DOI 10.1016/j.jesit.2016.12.009
   Moon YS, 1999, IEICE T FUND ELECTR, VE82A, P1026
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mutasem K.A., 2017, Egyptian Journal of Basic and Applied Sciences, V4, P112, DOI 10.1016/j.ejbas.2017.02.004
   Nachtegael M, 2007, ICIP, V6, pVI
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Polito M, 2002, ADV NEUR IN, V14, P1255
   Radwan A. A. A., 2008, WORLD ACAD SCI ENG T, V17, P1021
   Rocchio J. J., 1966, THESIS
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sagarmay D., 2004, MULTIMEDIE SYSTEMS C
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Sathiamoorthy S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1941-y
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Tzagkarakis G, 2008, IEEE T IMAGE PROCESS, V17, P1212, DOI 10.1109/TIP.2008.924390
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Vasconcelos N, 2007, COMPUTER, V40, P20, DOI 10.1109/MC.2007.239
   Vatamanu OA, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707396
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wang YL, 2020, ISA T, V96, P457, DOI 10.1016/j.isatra.2019.07.001
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu Q., 2019, MULTIMED TOOLS APPL, P1
   Xu YY, 2017, J VIS COMMUN IMAGE R, V43, P164, DOI 10.1016/j.jvcir.2017.01.006
   Yang XH, 2014, IET COMPUT VIS, V8, P141, DOI 10.1049/iet-cvi.2012.0157
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Yuan XF, 2020, IEEE T IND INFORM, V16, P3721, DOI 10.1109/TII.2019.2938890
   Yuan XF, 2020, IEEE T IND INFORM, V16, P3168, DOI [10.1109/TII.2019.2902129, 10.1002/er.4607]
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang LG, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P727, DOI 10.1109/FSKD.2017.8393364
   Zhang XF, 2016, IEEE J BIOMED HEALTH, V20, DOI 10.1109/JBHI.2015.2461671
   Zhou JX, 2019, MULTIMED TOOLS APPL, V78, P6163, DOI 10.1007/s11042-018-6192-1
   Zhou JX, 2014, SPRINGER P MATH STAT, V86, P197, DOI 10.1007/978-3-662-43404-8_11
NR 85
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 24463
EP 24486
DI 10.1007/s11042-020-09109-9
EA JUN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000542143000002
DA 2024-07-18
ER

PT J
AU Jeripothula, AB
   Velamala, SK
   Banoth, SK
   Mukherjee, S
AF Jeripothula, Aravind Babu
   Velamala, Santosh Kumar
   Banoth, Sunil Kumar
   Mukherjee, Snehasis
TI Blind image quality assessment using a combination of statistical
   features and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image quality assessment; NSS; CNN
ID NATURAL IMAGES; NETWORK
AB Blind Image Quality Assessment (BIQA) has been an enticing research problem in image processing, during the last few decades. In spite of the introduction of several BIQA algorithms, quantifying image quality without the help of a reference image still remains an unsolved problem. We propose a method for BIQA, combining Natural Scene Statistics (NSS) feature and Probabilistic Quality representation by a CNN. A certain number of features are considered for each image. We also propose to increase the NSS feature set alongside with the same CNN architecture and compare its results accordingly. Support Vector Machine (SVM) regression is applied on these features to get a quality score for that particular image. The results obtained by applying the proposed quality score on benchmark datasets, show the effectiveness of the proposed quality metric compared to the state-of-the-art metrics.
C1 [Jeripothula, Aravind Babu; Velamala, Santosh Kumar; Banoth, Sunil Kumar; Mukherjee, Snehasis] Indian Inst Informat Technol, Sri City, AP, India.
RP Mukherjee, S (corresponding author), Indian Inst Informat Technol, Sri City, AP, India.
EM aravindbabu.j15@iiits.in; santhosh.v15@iiits.in;
   sunilkumar.b15@iiits.in; snehasis.mukherjee@iiits.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Mukherjee, Snehasis/0000-0002-2196-8980
FU NVIDIA
FX The authors wish to thank NVIDIA for their research grant in form of a
   TITANX GPU as faculty GPU grant.
CR Al-Bandawi H, 2018, IET IMAGE PROCESS, V12, P1983, DOI 10.1049/iet-ipr.2018.5385
   [Anonymous], 2015, Live in the wild image quality challenge database
   Dendi SVR, 2019, IEEE SIGNAL PROC LET, V26, P89, DOI 10.1109/LSP.2018.2879518
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Kamble V, 2015, OPTIK, V126, P1090, DOI 10.1016/j.ijleo.2015.02.093
   Kundu D, 2018, SIGNAL PROCESS-IMAGE, V61, P54, DOI 10.1016/j.image.2017.11.004
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li YM, 2015, NEUROCOMPUTING, V154, P94, DOI 10.1016/j.neucom.2014.12.015
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Oszust M, 2019, IEEE SIGNAL PROC LET, V26, P322, DOI 10.1109/LSP.2019.2891416
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun TF, 2018, COMPUT ELECTR ENG, V70, P764, DOI 10.1016/j.compeleceng.2017.12.019
   Temel D, 2016, IEEE SIGNAL PROC LET, V23, P1414, DOI 10.1109/LSP.2016.2601119
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang XC, 2019, COMPUT VIS MEDIA, V5, P193, DOI 10.1007/s41095-019-0131-6
   Wang Y, 2018, COMPUT ELECTR ENG, V70, P904, DOI 10.1016/j.compeleceng.2017.12.006
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu QB, 2018, IEEE T CIRC SYST VID, V28, P2078, DOI 10.1109/TCSVT.2017.2710419
   Yang JC, 2018, ELECTRON LETT, V54, P754, DOI 10.1049/el.2018.0958
   Yang XC, 2018, COMPUT ELECTR ENG, V70, P349, DOI 10.1016/j.compeleceng.2016.08.014
   Zeng H., 2017, PROC IEEE 25 INT C I, DOI DOI 10.1109/ICIP.2018.8451285
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang YZ, 2016, DIGIT SIGNAL PROCESS, V57, P56, DOI 10.1016/j.dsp.2016.05.012
NR 43
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23243
EP 23260
DI 10.1007/s11042-020-08990-8
EA JUN 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382000003
DA 2024-07-18
ER

PT J
AU You, LH
   Yang, XS
   Pan, JJ
   Lee, TYE
   Bian, SJ
   Qian, K
   Habib, Z
   Sargano, AB
   Kazmi, I
   Zhang, JJ
AF You, Lihua
   Yang, Xiaosong
   Pan, Junjun
   Lee, Tong-Yee
   Bian, Shaojun
   Qian, Kun
   Habib, Zulfiqar
   Sargano, Allah Bux
   Kazmi, Ismail
   Zhang, Jian J.
TI Fast character modeling with sketch-based PDE surfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual characters; Model building; Sketch-guided global modeling;
   Template-based global modeling; Local modeling techniques; Generalized
   elliptic curves; PDE surfaces
ID FRAMEWORK
AB Virtual characters are 3D geometric models of characters. They have a lot of applications in multimedia. In this paper, we propose a new physics-based deformation method and efficient character modelling framework for creation of detailed 3D virtual character models. Our proposed physics-based deformation method uses PDE surfaces. Here PDE is the abbreviation of Partial Differential Equation, and PDE surfaces are defined as sculpting force-driven shape representations of interpolation surfaces. Interpolation surfaces are obtained by interpolating key cross-section profile curves and the sculpting force-driven shape representation uses an analytical solution to a vector-valued partial differential equation involving sculpting forces to quickly obtain deformed shapes. Our proposed character modelling framework consists of global modeling and local modeling. The global modeling is also called model building, which is a process of creating a whole character model quickly with sketch-guided and template-based modeling techniques. The local modeling produces local details efficiently to improve the realism of the created character model with four shape manipulation techniques. The sketch-guided global modeling generates a character model from three different levels of sketched profile curves called primary, secondary and key cross-section curves in three orthographic views. The template-based global modeling obtains a new character model by deforming a template model to match the three different levels of profile curves. Four shape manipulation techniques for local modeling are investigated and integrated into the new modelling framework. They include: partial differential equation-based shape manipulation, generalized elliptic curve-driven shape manipulation, sketch assisted shape manipulation, and template-based shape manipulation. These new local modeling techniques have both global and local shape control functions and are efficient in local shape manipulation. The final character models are represented with a collection of surfaces, which are modeled with two types of geometric entities: generalized elliptic curves (GECs) and partial differential equation-based surfaces. Our experiments indicate that the proposed modeling approach can build detailed and realistic character models easily and quickly.
C1 [You, Lihua; Yang, Xiaosong; Bian, Shaojun; Zhang, Jian J.] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
   [Pan, Junjun] Beihang Univ, State Key Lab VR, 37 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan 701, Taiwan.
   [Qian, Kun] Kings Coll London, London WC2R 2LS, England.
   [Habib, Zulfiqar; Sargano, Allah Bux] COMSATS Univ Islamabad, Lahore, Pakistan.
   [Kazmi, Ismail] Teesside Univ, Campus Heart,Southfield Rd, Middlesbrough TS1 3BX, Cleveland, England.
C3 Bournemouth University; Beihang University; National Cheng Kung
   University; University of London; King's College London; COMSATS
   University Islamabad (CUI); University of Teesside
RP You, LH (corresponding author), Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
EM lyou@bournemouth.ac.uk
RI Habib, Zulfiqar/B-6355-2013; Pan, Junjun/A-1316-2013; Sargana,
   AllahBux/AFO-1591-2022
OI Habib, Zulfiqar/0000-0001-9758-9162; Sargana,
   AllahBux/0000-0003-2024-2843; Bian, Shaojun/0000-0003-1108-744X; Yang,
   Xiaosong/0000-0003-3815-0584
FU PDE-GIR project - European Unions Horizon 2020 research and innovation
   programme under the Marie Skodowska-Curie grant [778035]; Innovate UK
   [KTP010860]; National Science Council of Taiwan [107-2221-E-006-196-MY3]
FX This research was supported by the PDE-GIR project which had received
   funding from the European Unions Horizon 2020 research and innovation
   programme under the Marie Skodowska-Curie grant agreement No 778035 and
   Innovate UK (Knowledge Transfer Partnerships Ref: KTP010860), and
   supported in part by the National Science Council of Taiwan under Grant
   No. 107-2221-E-006-196-MY3.
CR Abu Arqub O, 2017, SOFT COMPUT, V21, P7191, DOI 10.1007/s00500-016-2262-3
   Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Akman A, 2020, IEEE INT WORKSH COMP
   [Anonymous], 2010, ACM SIGGRAPH 2010 PA, DOI DOI 10.1145/1778765.1778846
   [Anonymous], 2016, ACM T GRAPHIC
   Bermano A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019632
   Botsch M, 2004, ACM T GRAPHIC, V23, P630, DOI 10.1145/1015706.1015772
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   Gryaditskaya Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356533
   Guo XK, 2016, COMPUT GRAPH FORUM, V35, P89, DOI 10.1111/cgf.12966
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   He J, 2020, GENET TEST MOL BIOMA, V24, P1, DOI 10.1089/gtmb.2019.0094
   Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Johnston H, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030397
   Jones B, 2016, ACM T GRAPHIC, V35, DOI [10.1145/2956233, 10.1145/2897824.2925979]
   Kazmi IK, 2015, COMPUT ANIMAT VIRT W, V26, P469, DOI 10.1002/cav.1656
   KRAEVOY V, 2009, P 6 EUR S SKETCH BAS, P37, DOI DOI 10.1145/1572741.1572749]
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li CL, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3238250
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Liu JC, 2020, MULTIMED TOOLS APPL, V79, P18121, DOI 10.1007/s11042-020-08677-0
   Liu S, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303965
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Madsen DavidA., 2016, ENG DRAWING DESIGN
   Mezger J, 2009, COMPUT AIDED GEOM D, V26, P680, DOI 10.1016/j.cagd.2008.09.009
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276429
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   SMIRNOV D, 1906, ARXIV190612337V1
   SORKINE O, 2014, P 2014 EUR ACM SIGGR, P175
   Wang B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766911
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu K., 2013, ACM Trans. Graph., V32, P1
   You LH, 2011, COMPUT AIDED DESIGN, V43, P720, DOI 10.1016/j.cad.2011.01.021
   You LH, 2004, COMPUT GRAPH-UK, V28, P895, DOI 10.1016/j.cag.2004.08.003
   YOU LH, 2004, VISUAL COMPUT, V20, P109
   Zhang HJ, 2002, COMPUT GRAPH-UK, V26, P89, DOI 10.1016/S0097-8493(01)00160-1
   Zhou W, 2019, PATTERN RECOGN LETT, V117, P119, DOI 10.1016/j.patrec.2018.09.005
   Zimmermann J, 2007, SKETCH-BASED INTERFACES AND MODELING 2007, P23
   Zou M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766976
NR 47
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23161
EP 23187
DI 10.1007/s11042-020-09060-9
EA JUN 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, YC
   Liu, Y
   Sun, R
   Guo, R
   Zhu, L
   Qi, Y
AF Li, Yaochen
   Liu, Ying
   Sun, Rui
   Guo, Rui
   Zhu, Li
   Qi, Yong
TI Multi-view point cloud registration with adaptive convergence threshold
   and its application in 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point cloud registration; ICP algorithm; Convergence threshold;
   Geometric saliency; 3D model retrieval
AB Multi-view point cloud registration is a hot topic in the communities of artificial intelligence and multimedia technology. In this paper, we propose a novel framework to reconstruct 3D models with a multi-view point cloud registration algorithm with adaptive convergence threshold, and apply it to 3D model retrieval subsequently. The iterative closest point (ICP) algorithm is implemented with an adaptive convergence threshold, and further combines with a motion average algorithm for the registration of multi-view point cloud data. After the registration process, the applications are designed for 3D model retrieval. The geometric saliency map is computed based on the vertex curvatures. The test facial triangles are selected to compare with the standard facial triangle. The face and non-face models are then discriminated. The experiments and comparisons demonstrate the effectiveness of the proposed framework.
C1 [Li, Yaochen; Liu, Ying; Sun, Rui; Guo, Rui; Zhu, Li] Xi An Jiao Tong Univ, Sch Software Engn, Xian, Shaanxi, Peoples R China.
   [Qi, Yong] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Li, YC (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian, Shaanxi, Peoples R China.
EM yaochenli@mail.xjtu.edu.cn
RI LIU, YING/GZL-7252-2022
CR Akagündüz E, 2010, ELECTRON LETT, V46, P905, DOI 10.1049/el.2010.0132
   [Anonymous], 2015, WORLD S COMP NETW IN
   Baker K, 2016, BUILDSYS'16: PROCEEDINGS OF THE 3RD ACM CONFERENCE ON SYSTEMS FOR ENERGY-EFFCIENT BUILT ENVIRONMENTS, P119, DOI 10.1145/2993422.2993569
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Chane CS, 2013, COMPUT IND, V64, P1082, DOI 10.1016/j.compind.2013.03.017
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Creusot C., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P204, DOI 10.1109/3DIMPVT.2011.33
   Fantoni S, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P73, DOI 10.1109/3DIMPVT.2012.63
   Guo R, 2018, MULTIMED TOOLS APPL, V77, P10651, DOI 10.1007/s11042-017-4704-z
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   Jin X, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9266-1
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lei JJ, 2013, IEEE IMAGE PROC, P4200, DOI 10.1109/ICIP.2013.6738865
   Li YJ, 2017, ARTIF INTELL ROBOT, V752, P295
   Lomonosov E, 2006, PATTERN RECOGN LETT, V27, P1201, DOI 10.1016/j.patrec.2005.07.018
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Rabiu H, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P237, DOI 10.1109/ICSIPA.2013.6708010
   Sandhu R, 2010, IEEE T PATTERN ANAL, V32, P1459, DOI 10.1109/TPAMI.2009.142
   Shih SW, 2008, IEEE T IMAGE PROCESS, V17, P968, DOI 10.1109/TIP.2008.921987
   Wang Y, 2016, ACTA PHYS SINICA, V65, P267
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Zhu JH, 2014, IET IMAGE PROCESS, V8, P582, DOI 10.1049/iet-ipr.2013.0545
NR 22
TC 2
Z9 3
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14793
EP 14810
DI 10.1007/s11042-019-7524-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900027
DA 2024-07-18
ER

PT J
AU Zhang, SZ
   Sun, YB
   Meng, FZ
   Fu, YS
   Jia, BW
   Wu, ZG
AF Zhang, Shuzhuang
   Sun, Yanbin
   Meng, Fanzhi
   Fu, Yunsheng
   Jia, Bowei
   Wu, Zhigang
TI XWM: a high-speed matching algorithm for large-scale URL rules in
   wireless surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-string matching; URL matching; Wu-Manber algorithm
ID KEY MANAGEMENT SCHEME; INTERNET
AB Large-scale high-speed URL matching is a key operation in many network security systems and surveillance applications in Wireless Sensor Networks. Classic string matching algorithms are unsuitable for large-scale URL filtering due to speed or memory consumption. This paper proposes an extend Wu-Manber algorithm (XWM) which takes advantage of the encoding characteristics of the URL greatly to improve the matching performance of the algorithm. It first adopts the pattern string window selection method to optimize Wu-Manber's hash process, and then combines hash tables and associative containers to optimize the string comparison process. The experimental results on actual 10 million patterns show that XWM can achieve speeds that are twice as fast as traditional algorithms, especially when the shortest pattern string length is longer, it is more advantageous.
C1 [Zhang, Shuzhuang; Jia, Bowei; Wu, Zhigang] Beijing Univ Posts & Telecommun, Inst Network Technol, Beijing 100786, Peoples R China.
   [Sun, Yanbin] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Peoples R China.
   [Meng, Fanzhi; Fu, Yunsheng] China Acad Engineer Phys, Inst Comp Applicat, Mianyang 621900, Sichuan, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Guangzhou University;
   Chinese Academy of Engineering Physics
RP Sun, YB (corresponding author), Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Peoples R China.
EM sunyanbin@gzhu.edu.cn
RI Meng, Fanzhi/HHZ-1686-2022; WANG, JINGYI/GSJ-1241-2022; wu,
   zhi/GXH-3041-2022
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   Allauzen C, 1999, LECT NOTES COMPUT SC, V1725, P295
   [Anonymous], 1994, FAST ALGORITHM MULTI
   Du XJ, 2007, AD HOC NETW, V5, P24, DOI 10.1016/j.adhoc.2006.05.012
   Du XJ, 2009, IEEE T WIREL COMMUN, V8, P1223, DOI 10.1109/TWC.2009.060598
   Kalnoor G, 2016, INT C ADV EL IEEE
   Kalnoor G, 2018, PROCEDIA COMPUT SCI, V125, P187, DOI 10.1016/j.procs.2017.12.026
   [刘燕兵 Liu Yanbing], 2014, [计算机学报, Chinese Journal of Computers], V37, P1159
   Navarro G, 1998, LECT NOTES COMPUT SC, V1448, P14, DOI 10.1007/BFb0030778
   Navarro G, 2002, FLEXIBLE PATTERN MAT, P1
   Qiu J, 2018, IEEE ACCESS, V6, P74854, DOI 10.1109/ACCESS.2018.2881422
   Salmela L, 2007, J EXPT ALGORITHMICS, V11, P1
   Tan QF, 2019, IEEE INTERNET THINGS, V6, P1584, DOI 10.1109/JIOT.2018.2846624
   Tian ZH, 2019, IEEE T VEH TECHNOL, V68, P5971, DOI 10.1109/TVT.2019.2910217
   Tian ZH, 2019, INFORM SCIENCES, V491, P151, DOI 10.1016/j.ins.2019.04.011
   Tian ZH, 2019, IEEE T IND INFORM, V15, P4285, DOI 10.1109/TII.2019.2907754
   Tian ZH, 2019, FUTURE GENER COMP SY, V95, P212, DOI 10.1016/j.future.2018.12.054
   Wang YM, 2016, INT J COMMUN SYST, V29, P2084, DOI 10.1002/dac.2911
   Xiong G, 2015, J COMMUN
   Xu DL, 2015, RES HIGH PERFORMANCE
   Yu X., 2018, JOULE, V2, P1
   Zhang P, 2015, J COMMUN
   Zhenlong Yuan, 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P359, DOI 10.1109/ICCNC.2013.6504109
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16245
EP 16263
DI 10.1007/s11042-019-07822-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600024
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, RB
   Marikkannu, P
AF Kumar, R. Biji
   Marikkannu, P.
TI An Efficient Content Based Image Retrieval using an Optimized Neural
   Network for Medical Application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Particle Swarm Optimization Artificial Neural Network PSO-ANN;
   k-means clustering algorithm; Gray Level Co-occurrence Matrix
AB Content Based Image Retrieval (CBIR) is a popular method to search and retrieve the similar images. For medical applications, it plays an important role to find the diseasessuch as breast cancer in human body. Many existing methods were presented for improving the performance of CBIR method. Nevertheless, retrieval time and accuracy of CBIR are further to be improved. To solve this issue, an optimal classifier is to be used in CBIR. In this paper, Artificial Neural Network based on Particle Swarm Optimization based (PSO-ANN) is presented as an optimized classifier. Also, the features of images such as shape, texture, mean and standard deviation are extracted. To increase the speed of the classification, these extracted features are to be clustered using k-means clustering algorithm. From the clustered features, similar images of query image are retrieved using the proposed PSO-ANN classifier. Simulation results prove that performance of this proposed CBIR outperforms than that of existing methods in terms of accuracy and CBIR time.
C1 [Kumar, R. Biji] Pentagram Res Ctr Pvt Ltd, Hyderabad, India.
   [Marikkannu, P.] Anna Univ, Dept Informat Technol, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Kumar, RB (corresponding author), Pentagram Res Ctr Pvt Ltd, Hyderabad, India.
EM bijikumar_r@yahoo.com; pmarikkannu@gmail.com
OI P, Marikkannu/0000-0002-9590-4541
CR Abd El Aziz M, 2018, MULTIMED TOOLS APPL, V77, P26135, DOI 10.1007/s11042-018-5840-9
   [Anonymous], P WORLD C ENG
   Beecks C, 2014, MULTIMED TOOLS APPL, V71, P349, DOI 10.1007/s11042-012-1334-3
   Jin C, 2017, 3D RES, V8
   Khapli V, 2008, IET C WIR MOB MULT N
   Kodgirwar V, 2016, 2016 WORLD CONFERENCE ON FUTURISTIC TRENDS IN RESEARCH AND INNOVATION FOR SOCIAL WELFARE (STARTUP CONCLAVE)
   Kumar A, 2016, COMPUT MED IMAG GRAP, V49, P37, DOI 10.1016/j.compmedimag.2016.01.001
   Long FH, 2003, SIG COM TEC, P1
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Phadikar Baisakhi Sur, 2017, CSI Transactions on ICT, V5, P45, DOI 10.1007/s40012-016-0134-8
   Schaefer G, 2013, 8 INT C DIG INF MAN
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Xie X, 2013, J CHINA U POSTS TELE, V20, P136, DOI [10.1016/S1005-8885(13)60209-5, DOI 10.1016/S1005-8885(13)60209-5]
   Younus ZS, 2015, ARAB J GEOSCI, V8, P6211, DOI 10.1007/s12517-014-1584-7
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
NR 16
TC 5
Z9 5
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22277
EP 22292
DI 10.1007/s11042-020-08953-z
EA MAY 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000534441900004
DA 2024-07-18
ER

PT J
AU Yang, B
   Xiang, XQ
   Yao, JL
   Xu, DQ
AF Yang, Bing
   Xiang, Xueqin
   Yao, Jinliang
   Xu, Duanqing
TI 3D palmprint recognition using complete block wise descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bioinformatics; 3D palmprint recognition; Shape index; Binary coding;
   Block wise descriptor
ID REPRESENTATION; PROJECTIONS; FLOW
AB Recent years have witnessed a growing interesting in developing automatic 3D palmprint recognition systems. The key problem of 3D palmprint recognition is to contrive an effective representation. In this paper, we propose a 3D palmprint recognition method by completely fusing of multiple block wise features. First, we propose a shape index multi-direction binary code strategy to extract 2D texture-level features of 3D palmprint. Then, we use the compact surface type binary code scheme to characterize 3D structure-level features of 3D palmprint. Finally, we integrate them together to construct the complete block wise descriptor for 3D palmprint recognition. Experiments conducted on the public available 3D palmprint database validate the effectiveness of our proposed method.
C1 [Yang, Bing; Xiang, Xueqin; Yao, Jinliang] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Xiasha Higher Educ Zone, Hangzhou 310018, Peoples R China.
   [Yang, Bing; Yao, Jinliang] Key Lab Brain Machine Collaborat Intelligence Zhe, Xiasha Higher Educ Zone, Hangzhou 310018, Peoples R China.
   [Xu, Duanqing] Zhejiang Univ, Comp Sci Coll, Yuquan Rd, Hangzhou 310007, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University
RP Yang, B (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Xiasha Higher Educ Zone, Hangzhou 310018, Peoples R China.; Yang, B (corresponding author), Key Lab Brain Machine Collaborat Intelligence Zhe, Xiasha Higher Educ Zone, Hangzhou 310018, Peoples R China.
EM yb@hdu.edu.cn
OI yang, bing/0000-0002-0585-0579; xiang, xueqin/0009-0004-4767-8078
FU National Natural Science Foundation of China [U1909202]; Key Laboratory
   of Brain Machine Collaborative Intelligence of Zhejiang Province
   [2020E10010]
FX Our special thanks go to Professor Wanzeng Kong for his participating in
   the revised version. This work was supported by the National Natural
   Science Foundation of China (61402143), National Natural Science
   Foundation of China (U1909202) and Key Laboratory of Brain Machine
   Collaborative Intelligence of Zhejiang Province (2020E10010).
CR Benedikt L, 2010, IEEE T SYST MAN CY A, V40, P449, DOI 10.1109/TSMCA.2010.2041656
   BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881
   Dai JF, 2011, IEEE T PATTERN ANAL, V33, P945, DOI 10.1109/TPAMI.2010.164
   Fei LK, 2019, PATTERN RECOGN, V87, P237, DOI 10.1016/j.patcog.2018.10.018
   Fei LK, 2018, IEEE T INSTRUM MEAS, V67, P2761, DOI 10.1109/TIM.2018.2830858
   Fei LK, 2019, IEEE T SYST MAN CY-S, V49, P346, DOI 10.1109/TSMC.2018.2795609
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   Gao ZF, 2020, NEURAL NETWORKS, V123, P82, DOI 10.1016/j.neunet.2019.11.017
   Gao ZF, 2020, IEEE T MED IMAGING, V39, P1524, DOI 10.1109/TMI.2019.2952939
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hetzel G, 2001, PROC CVPR IEEE, P394
   Hu DW, 2007, PATTERN RECOGN, V40, P339, DOI 10.1016/j.patcog.2006.06.022
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Jia W, 2014, IEEE T SYST MAN CY-S, V44, P385, DOI 10.1109/TSMC.2013.2258010
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Li W, 2012, IEEE T SYST MAN CY A, V42, P443, DOI 10.1109/TSMCA.2011.2164066
   Li W, 2011, IEEE T SYST MAN CY C, V41, P274, DOI 10.1109/TSMCC.2010.2055849
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Malina W, 2001, IEEE T SYST MAN CY B, V31, P629, DOI 10.1109/3477.938265
   McKeon RT, 2010, IEEE T INSTRUM MEAS, V59, P774, DOI 10.1109/TIM.2009.2037874
   Sun FR, 2017, INT J HEAT MASS TRAN, V113, P850, DOI 10.1016/j.ijheatmasstransfer.2017.05.105
   Yang B, 2017, MULTIMED TOOLS APPL, V76, P15357, DOI 10.1007/s11042-016-3832-1
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang L, 2017, PATTERN RECOGN, V69, P199, DOI 10.1016/j.patcog.2017.04.016
   Zhang L, 2015, IEEE T PATTERN ANAL, V37, P1730, DOI 10.1109/TPAMI.2014.2372764
   Zhang NY, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P1, DOI 10.1109/KAMW.2008.4810408
   Zheng Q, 2016, IEEE T PATTERN ANAL, V38, P1272, DOI 10.1109/TPAMI.2015.2509968
NR 31
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21987
EP 22006
DI 10.1007/s11042-020-09000-7
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532899700001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Zhang, JD
AF Liu, Yang
   Zhang, Jindong
TI A Multidimensional Chaotic Image Encryption Algorithm based on DNA
   Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Multi-dimensional chaotic sequence; DNA sequence
AB Based on chaotic encryption technology and DNA cryptography, a multidimensional chaotic image encryption algorithm based on DNA coding is proposed in this paper. Firstly, the MD5 algorithm is used to extract the features of the image, generate a new key in association with the user key, and then encode the original image in DNA. The traditional three-dimensional Lorenz system is improved to form a four-dimensional hyperchaotic Lorenz system. According to the principle of DNA cryptography, a series of operations such as scrambling, mutation, DNA addition and DNA XOR are performed on the DNA coding sequence, and finally decoded to obtain a password image. Key space analysis, statistical analysis, known plaintext attack analysis and experimental results show that the algorithm has better image encryption performance and ability to resist various common attacks.
C1 [Liu, Yang; Zhang, Jindong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
C3 Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Peoples R China.
EM zhangjindong_100@163.com
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018; Jilin University
   [5157050847, 2017XYB252, 2017A53216]
FX This work is supported in part by the National Key Research and
   Development Program of China (2017YFB0102500), Natural Science
   Foundation of Jilin province (20170101133JC), the Korea Foundation for
   Advanced Studies' International Scholar Exchange Fellowship for the
   academic year of 2017-2018, and Jilin University (5157050847,
   2017XYB252, 2017A53216).
CR Abuturab MR, 2017, OPT LASER ENG, V98, P1, DOI 10.1016/j.optlaseng.2017.05.001
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Gupta S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P726
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Ochani A, 2016, P INT C INVEN COMPUT, V1, P1, DOI [10.1109/INVENTIVE.2016.7823276, DOI 10.1109/INVENTIVE.2016.7823276]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Ratnavelu K, 2017, SIGNAL PROCESS, V140, P87, DOI 10.1016/j.sigpro.2017.05.002
   Tian Y, 2017, AIP ADV, V7, DOI 10.1063/1.4994860
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Yu WQ, 2019, MULTIMED TOOLS APPL, V78, P20037, DOI 10.1007/s11042-018-7110-2
   Zhang S, 2016, MULTIMED TOOLS APPL, V75, P17157, DOI 10.1007/s11042-015-2982-x
   Zhang Y, 2017, CHINESE J ELECTRON, V26, P1022, DOI 10.1049/cje.2017.08.022
   Zhou NR, 2017, QUANTUM INF PROCESS, V16, DOI 10.1007/s11128-016-1461-2
NR 14
TC 42
Z9 42
U1 5
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21579
EP 21601
DI 10.1007/s11042-020-08880-z
EA MAY 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531131500002
DA 2024-07-18
ER

PT J
AU Vedantham, R
   Reddy, ES
AF Vedantham, Ramachandran
   Reddy, Edara Sreenivasa
TI A robust feature extraction with optimized DBN-SMO for facial expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FER; Feature extraction; DCT; PCA; Deep belief network; SMO
ID DEEP; FRAMEWORK; PATTERNS; IMAGES; PCA
AB Facial expression is the most common technique is used to convey the expressions of human beings. Due to different ethnicity and age, faces differ from one individual to another so that an automatic facial expression analysis and recognition is a difficult operation. To solve this difficulty, this paper proposes a robust feature extraction with optimized DBN-SMO for facial expression recognition (FER). Initially, the pre-processing stage is performed then texture descriptors of Local Phase Quantization (LPQ), Weber Local Descriptor (WLD) and Local Binary Pattern (LBP) are used to extract the features. Moreover, Discrete Cosine Transform (DCT) features are extracted to enhance the recognition rate and reduce the computational cost. After that, the Principal component analysis (PCA) is used for dimension reduction. Finally, a deep belief network (DBN) with Spider monkey optimization (SMO) algorithm is used to classify basic expressions for FER. Here, SMO algorithm is used to optimize bias factors and initial connection weights that control the efficiency of the DBN. The proposed work is performed in the MATLAB environment. Experiments performed on Karolinska Directed Emotional Faces (KDEF), Man-Machine Interaction (MMI), Cohn Kanade (CK+), Extended Denver Intensity of Spontaneous Facial Actions (DISFA+) and Oulu-Chinese Academy of Science Institute of Automation (Oulu-CASIA) datasets and it provides a classification accuracy of 97.93%, 95.42%, 97.58%, 95.76%, and 92.38% respectively, this is higher than other current procedures for seven-class emotion.
C1 [Vedantham, Ramachandran] Vasireddy Venkatadri Inst Technol, IT Dept, Nambur 522508, Andhra Pradesh, India.
   [Reddy, Edara Sreenivasa] Acharya Nagarjuna Univ, ANU Coll Engn & Technol, Nambur 522510, Andhra Pradesh, India.
C3 Acharya Nagarjuna University
RP Vedantham, R (corresponding author), Vasireddy Venkatadri Inst Technol, IT Dept, Nambur 522508, Andhra Pradesh, India.
EM vrc.bhatt@gmail.com
RI Ramachandran, Vedantham/E-7627-2016; REDDY, EDARA
   SREENIVASA/AAS-8105-2020
OI Ramachandran, Vedantham/0000-0002-3857-8145; REDDY, EDARA
   SREENIVASA/0000-0001-7347-2680
CR Ali Z, 2018, BOUND VALUE PROBL, DOI 10.1186/s13661-018-1096-6
   Alphonse AS, 2018, MULTIMED TOOLS APPL, V77, P9455, DOI 10.1007/s11042-017-5141-8
   ALRJEBI MM, 2018, MULTIMED TOOLS APPL, P1
   [Anonymous], 2019, arXiv preprint arXiv:1909.13135
   Chen JY, 2019, J PARALLEL DISTR COM, V131, P97, DOI 10.1016/j.jpdc.2019.04.017
   Dabhi M.K., 2016, International Journal of Science and Research (IJSR), V5, P62, DOI 10.21275/v5i4.nov162465
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Ijjina EP, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P392, DOI 10.1109/ICMLA.2014.70
   Jain D.K., 2017, Pattern Recognition Letters
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jiang R, 2017, PATTERN RECOGN, V67, P245, DOI 10.1016/j.patcog.2017.02.003
   Jung H., 2015, ICCV
   Khan SA, 2018, MULTIMED TOOLS APPL, V77, P1133, DOI 10.1007/s11042-016-4324-z
   Kumar S, 2015, PROCEDIA COMPUT SCI, V62, P442, DOI 10.1016/j.procs.2015.08.504
   Li M, 2021, IEEE T AFFECT COMPUT, V12, P544, DOI 10.1109/TAFFC.2018.2880201
   Liang DD, 2020, VISUAL COMPUT, V36, P499, DOI 10.1007/s00371-019-01636-3
   Liu X, 2012, SPRINGERBRIEF COMPUT, P51, DOI 10.1007/978-1-4614-1933-4_5
   Liu YY, 2018, IEEE INT CONF AUTOMA, P458, DOI 10.1109/FG.2018.00074
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Maheswari VU, 2019, 2019 FIFTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP 2019), P167, DOI 10.1109/ICIIP47207.2019.8985829
   Mandal M, 2019, IET IMAGE PROCESS, V13, P850, DOI 10.1049/iet-ipr.2018.5683
   Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182
   Muhammad G., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P421
   Munir A., 2018, OPTIK INT J LIGHT EL
   Naik Shraddha, 2018, Advances in Machine Learning and Data Science. Recent Achievements and Research Directives. Advances in Intelligent Systems and Computing (AISC 705), P129, DOI 10.1007/978-981-10-8569-7_14
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sajjad E, 2019, ARCH TECH SCI, P1, DOI 10.7251/afts.2019.1121.001E
   Sajjad M, 2018, CLUSTER COMPUT, V21, P549, DOI 10.1007/s10586-017-0935-z
   Sarode N., 2010, Int. J. Comput. Sci. Eng, V2, P1552
   Sharma R, 2015, OPTIK, V126, P3483, DOI 10.1016/j.ijleo.2015.08.205
   Sun Z, 2019, ARTIF INTELL REV, V51, P1, DOI 10.1007/s10462-017-9554-6
   Sun ZW, 2018, ARTIF CELL NANOMED B, V46, pS308, DOI 10.1080/21691401.2018.1492419
   Tripathi A, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P187, DOI 10.1109/PDGC.2018.8745850
   Uddin MZ, 2017, COMPUT ELECTR ENG, V63, P114, DOI 10.1016/j.compeleceng.2017.04.019
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Valstar MF, 2017, IEEE INT CONF AUTOMA, P839, DOI 10.1109/FG.2017.107
   Verma Monu, 2019, IEEE Letters of the Computer Society, V2, P36, DOI 10.1109/LOCS.2019.2927959
   Videla Lakshmi Sarvani, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P135, DOI 10.1007/978-981-13-1921-1_13
   Xie WC, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106966
   Xu L, 2018, 2018 AUSTRALIAN & NEW ZEALAND CONTROL CONFERENCE (ANZCC), P115, DOI 10.1109/ANZCC.2018.8606597
   Yang JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P469, DOI 10.1145/3123266.3123350
   Yang RP, 2018, CHIN CONTR CONF, P3227, DOI 10.23919/ChiCC.2018.8483540
   YANG Y, 2016, REV TEC FAC ING UNIV, V39, P384
   Yuchun Fang, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P224, DOI 10.1007/978-3-319-14445-0_20
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhang T, 2016, IEEE T MULTIMEDIA, V18, P2528, DOI 10.1109/TMM.2016.2598092
   Zhang W, 2019, IEEE T AUTOM SCI ENG, V16, P1522, DOI 10.1109/TASE.2018.2877499
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
NR 52
TC 10
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21487
EP 21512
DI 10.1007/s11042-020-08901-x
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530987700001
DA 2024-07-18
ER

PT J
AU Hurrah, NN
   Parah, SA
   Sheikh, JA
AF Hurrah, Nasir N.
   Parah, Shabir A.
   Sheikh, Javaid A.
TI Embedding in medical images: an efficient scheme for authentication and
   tamper localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-healthcare; Electronic medical record (EMR); Security; Reversibility;
   Watermarking; Tamper detection; Tamper localization
ID FRAGILE WATERMARKING SCHEME; SECURE; ROBUST; FRAMEWORK; DOMAIN
AB In e-healthcare applications integrity of the received information is of prime importance for ensuring the accurate diagnosis. The integrity of electronic medical record (EMR) is possible only when the medical images and other relevant data received are tamper free. Reversibility of medical images after certain degree of processing is always a desired property in medical images as it aids proper diagnosis. This paper proposes a novel reversible image authentication (RIA) scheme for tamper detection and authentication of medical images. In the proposed RIA scheme, the medical image is divided into 4 x 4 blocks followed by embedding fragile watermark bit (for authentication) in each of these blocks. Along with authentication, the localization of tamper is achieved accurately by using LSB embedding along with mean modification approach. The security of the watermark has been enhanced with Arnold cat map, Gray coding and AES-128 encryption. The experimental results show that the scheme offers better fragility against all intentional/unintentional signal processing attacks. The comparison results between proposed RIA scheme and similar state-of-the-art schemes show superiority of our scheme in terms of imperceptivity, fragility and tamper localization. For a payload of 16 kb, the average PSNR achieved for 50 Gray scale images of size 512 x 512 is more than 47 dB. In addition, the scheme offers very less complexity; the embedding and extraction times are around 0.6 s and 0.5 s respectively. Given the features of proposed scheme it could serve as a potential candidate for transfer of EMR in an e-healthcare system.
C1 [Hurrah, Nasir N.; Parah, Shabir A.; Sheikh, Javaid A.] Univ Kashmir, Dept Elect & IT, Srinagar 190006, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & IT, Srinagar 190006, India.
EM shabireltr@gmail.com
RI Hurrah, Nasir/AAX-2729-2021; Parah, Shabir/AAB-7603-2021
OI Hurrah, Nasir/0000-0002-0798-0158; Parah, Shabir/0000-0001-5983-0912;
   Hurrah, Nasir/0000-0003-3011-4255; Sheikh, Javaid A/0000-0003-3113-3802
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Agrawal S, 2016, 2016 IEEE STUDENTS' CONFERENCE ON ELECTRICAL, ELECTRONICS AND COMPUTER SCIENCE (SCEECS)
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Hamza R, 2017, PERVASIVE MOB COMPUT, V41, P436, DOI 10.1016/j.pmcj.2017.03.011
   Hamza R, 2016, INF SECUR J, V25, P162, DOI 10.1080/19393555.2016.1212954
   Hassan B, 2019, IEEE ACCESS, V7, P69758, DOI 10.1109/ACCESS.2019.2919381
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Huang Y, 2019, IEEE T MULTIMEDIA, V21, P2447, DOI 10.1109/TMM.2019.2907475
   Hurrah NN, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P21
   HURRAH NN, 2018, FUTURE GENERATION CO
   HURRAH NN, 2019, SECURE DATA TRANSMIS
   Kumar CV, 2016, COMPUT ELECTR ENG, V53, P333, DOI 10.1016/j.compeleceng.2015.11.033
   Li M, 2016, ARAB J SCI ENG, V41, P941, DOI 10.1007/s13369-015-1941-1
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Parah SA, 2017, J GLOB INF MANAG, V25, P80, DOI 10.4018/JGIM.2017100106
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   SIVAKANNAN S, 2016, WORLD APPL SCI J, V34, P1197
   Tay CP, 2019, IEEE INT SYMP CIRC S
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wójtowicz W, 2016, J VIS COMMUN IMAGE R, V38, P1, DOI 10.1016/j.jvcir.2016.02.006
   Wu N.-I., 2007, IJ Network Security, V4, P1
   WU Y, 2019, IEEE T MULTIMED, V1
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   2018, HLTH CARE IT NEWS
   2018, DIGITAL GUARDIAN
NR 39
TC 21
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21441
EP 21470
DI 10.1007/s11042-020-08988-2
EA MAY 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531339200001
DA 2024-07-18
ER

PT J
AU AsSadhan, B
   AlShaalan, R
   Diab, DM
   Alzoghaiby, A
   Alshebeili, S
   Al-Muhtadi, J
   Bin-Abbas, H
   Abd El-Samie, FE
AF AsSadhan, Basil
   AlShaalan, Rayan
   Diab, Diab Mahmoud
   Alzoghaiby, Abraham
   Alshebeili, Saleh
   Al-Muhtadi, Jalal
   Bin-Abbas, Hesham
   Abd El-Samie, Fathi E.
TI A robust anomaly detection method using a constant false alarm rate
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Constant false alarm rate; Cross-correlation;
   Volume-based anomalies
ID NETWORK INTRUSION DETECTION
AB With the rapid growth of information and communication technologies, the number of security threats in computer networks is substantially increasing; thus, the development of more proactive security warning measures is required. In this work, we propose a new anomaly detection method that operates by decomposing TCP traffic into control and data planes, which exhibit similar behaviors in the absence of attacks. The proposed method exploits the statistics of the cross-correlation function of the two planes traffic and the constant false alarm rate (CFAR) scheme for detecting anomalies of the underlying network traffic. Both the fixed and adaptive thresholding schemes are implemented. The adaptive thresholding is setup by adjusting the value of the threshold in accordance with the local statistics of the cross-correlation function of the two planes traffic. We evaluate the performance of the proposed method by analyzing the real traffic captured from a deployed network and traffic obtained from other publicly available datasets; we focus on TCP traffic with three different aggregated count features: packet count, IP address count, and port count sequences. Although both the fixed and adaptive thresholding schemes perform well and detect the presence of a distributed denial-of-service efficiently. The adaptive thresholding scheme is more reliable because it detects anomalies as they start.
C1 [AsSadhan, Basil; Alshebeili, Saleh] King Saud Univ, Dept Elect Engn, Riyadh, Saudi Arabia.
   [AsSadhan, Basil; Al-Muhtadi, Jalal] King Saud Univ, Ctr Excellence Informat Assurance CoEIA, Riyadh, Saudi Arabia.
   [AlShaalan, Rayan] Commun & Informat Technol Commiss, Riyadh, Saudi Arabia.
   [Diab, Diab Mahmoud; Al-Muhtadi, Jalal] King Saud Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Alzoghaiby, Abraham; Bin-Abbas, Hesham] King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia.
   [Alshebeili, Saleh] King Saud Univ, ICACST TIC RF & Photon C Soc RFTONICS, Riyadh, Saudi Arabia.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Menoufia, Egypt.
C3 King Saud University; King Saud University; King Saud University; King
   Abdulaziz City for Science & Technology; King Saud University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Diab, DM (corresponding author), King Saud Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
EM bsadhan@ksu.edu.sa; Eng.riyan@gmail.com; ddiab@ksu.edu.sa;
   aalzoghaiby@kacst.edu.sa; dsaleh@ksu.edu.sa; jalal@ccis.edu.sa;
   hbinabbas@gmail.com; fathisayed@yahoo.com
RI Alshebeili, Saleh/GZB-2540-2022; Sayed, Fathi/HRA-4752-2023; AsSadhan,
   Basil/O-5722-2018; Almuhtadi, Jalal/GYA-1533-2022
OI Alshebeili, Saleh/0000-0003-4157-9277; Sayed, Fathi/0000-0001-8749-9518;
   AsSadhan, Basil/0000-0002-8074-0433; Almuhtadi,
   Jalal/0000-0003-0246-2148
CR Agosta J.M., 2007, Proceedings of USENIX Workshop on Tackling Computer Systems Problems with Machine Learning Techniques (SysML), P1
   AlShaalan R, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON HIGH CAPACITY OPTICAL NETWORKS AND ENABLING TECHNOLOGIES (HONET-CNS), P141, DOI 10.1109/HONET.2013.6729773
   [Anonymous], WIRESH GO DEEP
   [Anonymous], 2014, NETWORK SCI CYBERSEC
   [Anonymous], 2016, P 2016 IEEE BIENNIAL, DOI DOI 10.1109/ARGENCON.2016.7585247
   [Anonymous], 2013, GLOB STAT INF SEC SU
   [Anonymous], P 4 ACM SIGCOMM C IN
   [Anonymous], USING DECISION TREES
   [Anonymous], 2017, SHOCK VIBRATION
   [Anonymous], 2018, SECUR COMMUN NETW
   [Anonymous], STAT ANAL NETWORK TR
   [Anonymous], 2005, SIGNAL DETECTION EST
   AsSadhan B, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P3658
   AsSadhan B, 2018, PEER PEER NETW APPL, V11, P848, DOI 10.1007/s12083-017-0586-0
   AsSadhan B, 2017, IEEE ACCESS, V5, P13501, DOI 10.1109/ACCESS.2017.2689001
   Brahmi Hanen, 2012, Advances in Knowledge Discovery and Data Mining. Proceedings 16th Pacific-Asia Conference (PAKDD 2012), P13, DOI 10.1007/978-3-642-30220-6_2
   Cannady J., 1998, P 21 NATL INFORM SYS, P368
   Casas P, 2012, COMPUT COMMUN, V35, P772, DOI 10.1016/j.comcom.2012.01.016
   Chitrakar R, 2012, INT C WIREL COMM NET
   Davis JJ, 2011, COMPUT SECUR, V30, P353, DOI 10.1016/j.cose.2011.05.008
   Ege E, 2006, TUBERK TORAK, V54, P65
   Farnia F., 2017, LOW RATE FALSE ALARM
   Gan XS, 2013, KNOWL-BASED SYST, V40, P1, DOI 10.1016/j.knosys.2012.09.004
   He D, 2008, IEEE T INSTRUM MEAS, V57, P490, DOI 10.1109/TIM.2007.910108
   He D, 2009, CIRC SYST SIGNAL PR, V28, P361, DOI 10.1007/s00034-008-9087-y
   Javaid A., 2016, Eai Endorsed Transac- 3, V3, P2
   Jemili Farah, 2007, 2007 IEEE Intelligence and Security Informatics, P66, DOI 10.1109/ISI.2007.379535
   Jiang CB, 2016, INT J NETW MANAG, V26, P156, DOI 10.1002/nem.1923
   Kang Eyung W., 2008, Radar System analysis, design, and simulation
   Kim SS, 2008, IEEE ACM T NETWORK, V16, P562, DOI 10.1109/TNET.2007.902685
   Li YH, 2012, EXPERT SYST APPL, V39, P424, DOI 10.1016/j.eswa.2011.07.032
   Liang D, 2019, MULTIMED TOOLS APPL, V78, P4131, DOI 10.1007/s11042-017-5352-z
   Lu XJ, 2019, MABS-AUSTIN, V11, P45, DOI 10.1080/19420862.2018.1548233
   Ma T, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101701
   Mazel J, 2015, INT J NETW MANAG, V25, P283, DOI 10.1002/nem.1903
   Omar S., 2013, Int. J. Comput. Appl., V79, DOI DOI 10.5120/13715-1478
   Shavlik Jude., 2004, P 10 ACM SIGKDD INT, P276
   Su MY, 2011, J NETW COMPUT APPL, V34, P722, DOI 10.1016/j.jnca.2010.10.009
   Tartakovsky AG, 2006, IEEE T SIGNAL PROCES, V54, P3372, DOI 10.1109/TSP.2006.879308
   Thatte G, 2011, IEEE ACM T NETWORK, V19, P512, DOI 10.1109/TNET.2010.2070845
   Wang HY, 2015, INT J FUTUR GENER CO, V8, P205, DOI 10.14257/ijfgcn.2015.8.6.20
   Wang W, 2018, IEEE ACCESS, V6, P1792, DOI 10.1109/ACCESS.2017.2780250
   Wang W, 2017, 2017 31ST INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P712, DOI 10.1109/ICOIN.2017.7899588
   Wang W, 2014, KNOWL-BASED SYST, V70, P103, DOI 10.1016/j.knosys.2014.06.018
   Whalen TM, 2004, J WIND ENG IND AEROD, V92, P219, DOI 10.1016/j.jweia.2003.09.042
   Wood P., 2016, Internet security threat report
   Yousefi-Azar M, 2017, IEEE IJCNN, P3854, DOI 10.1109/IJCNN.2017.7966342
   Yu M, 2013, INT J SECUR APPL, V7, P279, DOI 10.14257/ijsia.2013.7.5.26
   Zeb K, 2014, 2014 FOURTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P52, DOI 10.1109/INTECH.2014.6927746
   Zhang J, 2008, IEEE T SYST MAN CY C, V38, P649, DOI 10.1109/TSMCC.2008.923876
NR 50
TC 5
Z9 5
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12727
EP 12750
DI 10.1007/s11042-020-08653-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400065
DA 2024-07-18
ER

PT J
AU Imani, Z
   Soltanizadeh, H
   Orouji, AA
AF Imani, Zeynab
   Soltanizadeh, Hadi
   Orouji, Ali A.
TI Tensor-based sparse canonical correlation analysis via low rank matrix
   approximation for RGB-D long-term person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse canonical correlation analysis; Tensor space; Low rank matrix
   approximation; Person re-identification
ID LOCAL BINARY PATTERN; DESCRIPTORS; FEATURES; KISS
AB Person re-identification can be a part of almost any multi-camera surveillance systems. Most previous works propose strategies for short-term person re-identification which are usually driven from appearance features of RGB images. However, when people appear in excessive lighting or change clothes (i.e. long-term case), short-term person re-identification approaches have a tendency to fail. In this paper, we propose a novel approach for long-term person re-identification by employing depth videos of RGB-D sensors. We also develop a sparse canonical correlation analysis using a local third-order tensor model to accomplish multi-level person re-identification. The tensor representations of images make the space for performing the multi-level person re-identification simpler compared to existing methods. Finally, we evaluate our experiments on RGB-D long-term datasets consisting of BIWI RGBD-ID dataset and IAS-Lab RGBD-ID dataset. The results demonstrate the efficiency of the proposed method compared to recent methods.
C1 [Imani, Zeynab; Soltanizadeh, Hadi; Orouji, Ali A.] Semnan Univ, Elect & Comp Engn Fac, Semnan, Iran.
C3 Semnan University
RP Soltanizadeh, H (corresponding author), Semnan Univ, Elect & Comp Engn Fac, Semnan, Iran.
EM z_imani@semnan.ac.ir; h_soltanizadeh@semnan.ac.ir;
   aliaorouji@semnan.ac.ir
RI Soltanizadeh, Hadi/AAH-1840-2019; Orouji, Ali A./AAE-4018-2019
OI Soltanizadeh, Hadi/0000-0002-2210-675X; Orouji, Ali
   A./0000-0002-8664-6069
CR Ahmed E, 2015, P IEEE INT C COMP VI
   An L, 2018, IEEE T CIRC SYST VID, V28, P1777, DOI 10.1109/TCSVT.2017.2680118
   An L, 2016, INFORM SCIENCES, V355, P74, DOI 10.1016/j.ins.2016.02.055
   An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561
   An L, 2015, IEEE SIGNAL PROC LET, V22, P1103, DOI 10.1109/LSP.2015.2390222
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Chahla C, 2017, ENG APPL ARTIF INTEL, V58, P27, DOI 10.1016/j.engappai.2016.11.004
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Chu HF, 2019, MULTIMED TOOLS APPL, V78, P27067, DOI 10.1007/s11042-017-4817-4
   Dai J, 2018, PATTERN RECOGN, V75, P63, DOI 10.1016/j.patcog.2017.04.022
   Fang W, 2018, NEUROCOMPUTING, V272, P520, DOI 10.1016/j.neucom.2017.07.019
   Fehr D, 2012, IEEE INT CONF ROBOT, P1793, DOI 10.1109/ICRA.2012.6224740
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   GAO Bin, 2016, ELECTRON LETT, V52, P1914, DOI [10.1049/el.2016.2639, DOI 10.1049/EL.2016.2639]
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   Geng YB, 2015, J VIS COMMUN IMAGE R, V29, P89, DOI 10.1016/j.jvcir.2015.02.001
   Hu HM, 2017, MULTIMED TOOLS APPL, V76, P26633, DOI 10.1007/s11042-016-4188-2
   Ibn Khedher M, 2017, NEUROCOMPUTING, V248, P94, DOI 10.1016/j.neucom.2016.11.073
   Imani Z, 2020, IJST-T ELECTR ENG, V44, P669, DOI 10.1007/s40998-019-00249-9
   Imani Z, 2019, NATL ACAD SCI LETT, V42, P233, DOI 10.1007/s40009-018-0736-9
   Imani Z, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-016-9086-8
   Imani Z, 2016, IEEE SENS J, V16, P6227, DOI 10.1109/JSEN.2016.2579645
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Koukiou G, 2018, MULTIMED TOOLS APPL, V77, P9293, DOI 10.1007/s11042-017-4892-6
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li W, 2017, PATTERN RECOGN, V61, P327, DOI 10.1016/j.patcog.2016.08.001
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liong VE, 2015, PATTERN RECOGN LETT, V68, P288, DOI 10.1016/j.patrec.2015.05.001
   Liu H, 2017, CAAI T INTELL TECHNO, V2, P48, DOI 10.1016/j.trit.2017.04.001
   Liu YZ, 2015, IEEE T IMAGE PROCESS, V24, P236, DOI 10.1109/TIP.2014.2378019
   Lu HP, 2011, PATTERN RECOGN, V44, P1540, DOI 10.1016/j.patcog.2011.01.004
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Martinel N, 2015, IEEE T PATTERN ANAL, V37, P1656, DOI 10.1109/TPAMI.2014.2377748
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8
   Munaro M, 2014, IEEE INT CONF ROBOT, P5644, DOI 10.1109/ICRA.2014.6907689
   Nanni Loris, 2016, Applied Computing and Informatics, V12, P142, DOI 10.1016/j.aci.2015.02.002
   Pala F, 2016, IEEE T CIRC SYST VID, V26, P788, DOI 10.1109/TCSVT.2015.2424056
   Patruno C, 2019, PATTERN RECOGN, V89, P77, DOI 10.1016/j.patcog.2019.01.003
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Rahmawati E, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON ENGINEERING TECHNOLOGY AND APPLICATIONS (IES-ETA), P234, DOI 10.1109/ELECSYM.2017.8240409
   Ren LL, 2017, PATTERN RECOGN, V72, P446, DOI 10.1016/j.patcog.2017.06.037
   Skelly LJ, 2007, P SOC PHOT INSTR ENG
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Wang J, 2018, PATTERN RECOGN, V74, P38, DOI 10.1016/j.patcog.2017.09.014
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Wu AC, 2017, IEEE T IMAGE PROCESS, V26, P2588, DOI 10.1109/TIP.2017.2675201
   Xu XX, 2015, IEEE T NEUR NET LEAR, V26, P3150, DOI 10.1109/TNNLS.2015.2405574
   Xu YL, 2018, MULTIMED TOOLS APPL, V77, P10715, DOI 10.1007/s11042-017-4893-5
   Yan CX, 2018, MULTIMED TOOLS APPL, V77, P3553, DOI 10.1007/s11042-017-5202-z
   Yan JJ, 2012, IEEE SIGNAL PROC LET, V19, P51, DOI 10.1109/LSP.2011.2177259
   Yang Z, 2018, MACH VISION APPL, V29, P1019, DOI 10.1007/s00138-018-0917-z
   Zhao CR, 2019, NEURAL PROCESS LETT, V49, P899, DOI 10.1007/s11063-018-9820-x
   Zhao CR, 2018, PATTERN RECOGN, V79, P79, DOI 10.1016/j.patcog.2018.01.033
   Zhao CR, 2018, NEUROCOMPUTING, V275, P403, DOI 10.1016/j.neucom.2017.08.064
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhou Q, 2017, PATTERN RECOGN, V72, P196, DOI 10.1016/j.patcog.2017.06.026
NR 61
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11787
EP 11811
DI 10.1007/s11042-019-08311-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400024
DA 2024-07-18
ER

PT J
AU Vishwakarma, VP
   Dalal, S
AF Vishwakarma, Virendra P.
   Dalal, Sahil
TI A novel non-linear modifier for adaptive illumination normalization for
   robust face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete Cosine transform (DCT); Face recognition; Illumination
   normalization; Adaptive illumination normalization
ID VARYING ILLUMINATION; FUZZY FILTER; DCT DOMAIN; COMPENSATION; POSE
AB In this paper, a novel approach is presented for adaptive illumination normalization for face recognition under varying illuminations due to change in angle of light projection. Illumination normalization is performed over some of the low frequency discrete Cosine transform (DCT) coefficients which are computed adaptively based upon the significance of alteration of these coefficients. These are, then, modified using a non-linear modifier. The significance of the proposed approach is that the approach is adaptive in normalizing the illumination from the face images as the number of low frequency DCT coefficients that need to be modified using non-linear modifier are selected on the basis of variations of illumination present in the image. This variation in the illumination is also used in developing the non-linear modifier. The proposed approach is important in such a way that the level of illumination variations decides the computations needed i.e. lesser in comparison to the other existing state-of-art approaches as large number of frequency coefficients are not altered. The proposed approach is tested over various face databases: YALE B, Extended YALE B, CMU PIE, AR and YALE face database. The experimental results clearly reveal that the performance of the proposed approach is significantly better than the existing approaches of illumination normalization for face recognition. With the proposed approach, 100% accuracy is attained on all the subsets of YALE B, CMU PIE and on Subset 3 of Extended YALE B database. Promising results are achieved over remaining face databases as well.
C1 [Vishwakarma, Virendra P.; Dalal, Sahil] Gum Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect 16-C, New Delhi, India.
C3 GGS Indraprastha University
RP Dalal, S (corresponding author), Gum Gobind Singh Indraprastha Univ, Univ Sch Informat Commun & Technol, Sect 16-C, New Delhi, India.
EM dalalsahil22@yahoo.co.in
OI Vishwakarma, Virendra P./0000-0003-4276-8766; DALAL,
   SAHIL/0000-0003-3171-5116
CR [Anonymous], INT C AUD BID BAS BI
   [Anonymous], 2006, P IEEE ICASSP
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Chen XY, 2017, MULTIMED TOOLS APPL, V76, P22043, DOI 10.1007/s11042-017-4782-y
   Chen ZW, 2017, MULTIMED TOOLS APPL, V76, P17669, DOI 10.1007/s11042-015-2882-0
   Cheng Y, 2017, IEEE ACCESS, V5, P25835, DOI 10.1109/ACCESS.2017.2766128
   De Marsico M, 2013, IEEE T SYST MAN CY-S, V43, P149, DOI 10.1109/TSMCA.2012.2192427
   Faraji MR, 2014, IEEE SIGNAL PROC LET, V21, P1457, DOI 10.1109/LSP.2014.2343213
   Georghiades A., 1997, Yale face database
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Huang SM, 2012, IEEE SIGNAL PROC LET, V19, P179, DOI 10.1109/LSP.2012.2185492
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Jaliya UK, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE), P185, DOI 10.1109/SAPIENCE.2016.7684143
   Kim YH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0023
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lee PH, 2012, IEEE T IMAGE PROCESS, V21, P4280, DOI 10.1109/TIP.2012.2202670
   Li Q., 2005, ADV NEURAL INFORM PR, P1569, DOI DOI 10.5555/2976040.2976237
   Mansoorizadeh M, 2010, MULTIMED TOOLS APPL, V49, P277, DOI 10.1007/s11042-009-0344-2
   Marciniak T, 2015, MULTIMED TOOLS APPL, V74, P4329, DOI 10.1007/s11042-013-1568-8
   Martinez A., 1998, AR FACE DATABASE
   McLaughlin N, 2017, IEEE T CYBERNETICS, V47, P796, DOI 10.1109/TCYB.2016.2529300
   Mudunuri SP, 2016, IEEE T PATTERN ANAL, V38, P1034, DOI 10.1109/TPAMI.2015.2469282
   Ochoa-Villegas MA, 2015, IET COMPUT VIS, V9, P978, DOI 10.1049/iet-cvi.2014.0086
   Punnappurath Abhijith, 2015, IEEE Trans Image Process, V24, P2067, DOI 10.1109/TIP.2015.2412379
   Samet H, 2008, IEEE T PATTERN ANAL, V30, P243, DOI 10.1109/TPAMI.2007.1182
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561
   Vishwakarma Virendra P., 2009, International Journal of Recent Trends in Engineering, V1, P318
   Vishwakarma Virendra P., 2010, Journal of Computing and Information Technology - CIT, V18, P53, DOI 10.2498/cit.1001427
   Vishwakarma VP, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P535, DOI 10.1109/ADCOM.2007.12
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Vishwakarma VP, 2015, INT J MACH LEARN CYB, V6, P17, DOI 10.1007/s13042-013-0182-4
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Xu X, 2012, INT J MACH LEARN CYB, V3, P259, DOI 10.1007/s13042-011-0060-x
   Yadav J, 2018, J INTELL FUZZY SYST, V35, P5265, DOI 10.3233/JIFS-169810
   Yadav J, 2018, INT J APPL PATTERN R, V5, P149, DOI 10.1504/IJAPR.2018.092523
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yang HX, 2016, IET BIOMETRICS, V5, P76, DOI 10.1049/iet-bmt.2014.0082
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
NR 45
TC 25
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11503
EP 11529
DI 10.1007/s11042-019-08537-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400011
DA 2024-07-18
ER

PT J
AU Lee, JY
   Park, HW
AF Lee, Jin Young
   Park, Hyun Wook
TI HEVC-based three-layer texture and depth coding for lossless synthesis
   in 3D video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video coding; Depth coding; HEVC; Lossless coding; Lossless synthesis
ID IMAGE
AB Efficient lossless coding of a texture image and its corresponding depth map is important to perform accurate view synthesis in 3D applications. In this paper, a novel HEVC-based three-layer texture and depth coding method is proposed for lossless synthesis in 3D video coding. The proposed method performs lossy and lossless texture coding in the first and second layers, respectively. A quantization parameter (QP) in the first lossy coding layer is adaptively selected for each block, based on a relationship between the first and second layers. In the third layer, the lossy depth coding is performed by using synthesis-based depth coding and texture-based depth intra prediction mode. The synthesis-based depth coding technique adopts the lossy coding but guarantees zero synthesis distortion. The texture-based depth intra prediction mode performs the depth prediction by using the associated texture information. Experimental results demonstrate that the proposed method obtains higher coding performance than conventional lossless coding methods.
C1 [Lee, Jin Young] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
   [Park, Hyun Wook] Korea Adv Inst Sci & Technol KAIST, Dept Elect Engn, Daejeon, South Korea.
C3 Sejong University; Korea Advanced Institute of Science & Technology
   (KAIST)
RP Lee, JY (corresponding author), Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
EM jinyounglee@sejong.ac.kr
CR [Anonymous], 2012, Document JCTVC-K1100
   [Anonymous], 2019, IEEE T CIRC SYST VID
   Antony A, 2017, SIGNAL IMAGE VIDEO P, V11, P1057, DOI 10.1007/s11760-017-1057-z
   Antony A, 2017, MULTIMED TOOLS APPL, V76, P1639, DOI 10.1007/s11042-015-3138-8
   Chen WJ, 2015, APPL PHYS EXPRESS, V8, DOI 10.7567/APEX.8.032102
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   *ISO IEC MPEG, 2007, JVTW100 ISOIEC MPEG
   *ITU T, 2019, 230082 ITUT ISOIEC
   Lee JY, 2016, IEEE T CIRC SYST VID, V26, P1107, DOI 10.1109/TCSVT.2015.2441491
   Lee JY, 2015, IEEE T CIRC SYST VID, V25, P1347, DOI 10.1109/TCSVT.2014.2380191
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Lee YL, 2006, IEEE T IMAGE PROCESS, V15, P2610, DOI 10.1109/TIP.2006.877396
   Müller K, 2012, ASIAPAC SIGN INFO PR
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   OH H, 2006, LECT NOTES COMPUTER, V4319
   OH KJ, 2012, P PICT COD S
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Rusanovskyy D., 2013, document JCT3V-E1100
   Sanchez V, 2015, IEEE IMAGE PROC, P4604, DOI 10.1109/ICIP.2015.7351679
   Schiopu I, 2018, ELECTRON LETT, V54, P1032, DOI 10.1049/el.2018.0889
   SCHIOPU I, 2018, P PICT COD S
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan YH, 2013, IEEE INT C AC SPEECH
   WIGE E, 2013, IEEE INT C IM PROC
   ZHANG J, 2016, VIS COMM IM PROC C
   Zhou MH, 2012, IEEE T CIRC SYST VID, V22, P1839, DOI 10.1109/TCSVT.2012.2221524
NR 28
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20929
EP 20945
DI 10.1007/s11042-020-08938-y
EA APR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529468100001
DA 2024-07-18
ER

PT J
AU Yong, BB
   Wang, C
   Shen, J
   Li, FC
   Yin, H
   Zhou, R
AF Yong, Binbin
   Wang, Chen
   Shen, Jun
   Li, Fucun
   Yin, Hang
   Zhou, Rui
TI Automatic ventricular nuclear magnetic resonance image processing with
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiovascular disease; NMR image segmentation; Layered mask R-CNN;
   Ventricular systolic function detection
ID SEGMENTATION
AB Cardiovascular diseases (CVD) seriously threaten the health of human beings, and they have caused widespread concern in recent years. At present, the diagnosis of CVD is mainly conducted by computed tomography (CT), echocardiography and nuclear magnetic resonance (NMR) technologies. NMR imaging technology is widely used in medical applications owing to its characteristics of high resolution and very low radiation. However, manual NMR image segmentation is time-consuming and error-prone, which has led to the research on automatic NMR image segmentation technologies. Researchers tend to explore the ventricular NRM image segmentation to improve the accuracy of CVD diagnosis. In this study, based on deep learning technology, we propose a layered Mask R-CNN segmentation method to segment ventricular NMR images. The experimental results show that the mean dice metrics (DM) of left ventricular segmentation and right ventricular segmentation are 0.92 and 0.89, and the Hausdorff distance (HD) metrics are 4.78 mm and 7.03 mm. Our research indicates that the proposed novel method has great potential to automate the ventricular NMR image segmentation. We also discuss the automatic abnormal ventricular systolic function detection method based on the proposed layered segmentation model.
C1 [Yong, Binbin; Wang, Chen; Yin, Hang; Zhou, Rui] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Shen, Jun; Li, Fucun] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia.
C3 Lanzhou University; University of Wollongong
RP Zhou, R (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
EM yongbb@lzu.edu.cn; chenwang15@lzu.edu.cn; jshen@uow.edu.au;
   fl626@uowmail.edu.au; yinh2016@lzu.edu.cn; zr@lzu.edu.cn
RI Shen, Jun/R-5831-2019; Zhou, Rui/HRA-8327-2023
OI Shen, Jun/0000-0002-9403-7140; 
FU National Natural Science Foundation of China [61402210, 61872079];
   Fundamental Research Funds for the Central Universities
   [lzujbky-2019-kb51, lzujbky-2018-k12]; Ministry of Education -China
   Mobile Research Foundation [MCM20170206]; Major National Project of High
   Resolution Earth Observation System [30-Y20A34-9010-15/17]; State Grid
   Corporation Science and Technology Project [SGGSKY00FJJS1800403,
   522722160071]; Program for New Century Excellent Talents in University
   [NCET-12-0250]; Double first class Funding-International Cooperation and
   Exchange Program [227000-560001]; Strategic Priority Research Program of
   the Chinese Academy of Sciences [XDA03030100]; Google Research Awards;
   Google Faculty Award; international expert exchange programs; UOW's UGPN
   RCF 2018-2019
FX This work was partially supported by National Natural Science Foundation
   of China under Grant No. 61402210 and 61872079, The Fundamental Research
   Funds for the Central Universities under Grant No. lzujbky-2019-kb51 and
   lzujbky-2018-k12, Ministry of Education -China Mobile Research
   Foundation under Grant No. MCM20170206, Major National Project of High
   Resolution Earth Observation System under Grant No.
   30-Y20A34-9010-15/17, State Grid Corporation Science and Technology
   Project under Grant No. SGGSKY00FJJS1800403 and No.522722160071, Program
   for New Century Excellent Talents in University under Grant No.
   NCET-12-0250, and Double first class Funding-International Cooperation
   and Exchange Program under Grant No. 227000-560001, and Strategic
   Priority Research Program of the Chinese Academy of Sciences with Grant
   No. XDA03030100. Google Research Awards and Google Faculty Award. We
   appreciate co-author Mr. Hang Yin's hard work during postgraduate for
   the contribution of this paper is based on his master thesis [31] and
   co-authored conference paper [30]. Jun Shen's work was supported by
   international expert exchange programs and UOW's UGPN RCF 2018-2019.
CR Bai WJ, 2015, MED IMAGE ANAL, V19, P98, DOI 10.1016/j.media.2014.09.005
   Balla-Arabé S, 2016, IEEE T CYBERNETICS, V46, P3181, DOI 10.1109/TCYB.2015.2499206
   Ben Ayed I, 2009, LECT NOTES COMPUT SC, V5762, P901, DOI 10.1007/978-3-642-04271-3_109
   Brown AF, 2018, ANN INTERN MED, V168, P541, DOI 10.7326/M17-0996
   Cong C, 2018, J ENG-JOE, P1463, DOI 10.1049/joe.2018.8302
   Dezaki Fatemeh Taheri, 2018, IEEE transactions on medical imaging, V38, P1821, DOI DOI 10.1109/TMI.2018.2888807
   Grosgeorge D, 2011, INT J COMPUT ASS RAD, V6, P573, DOI 10.1007/s11548-010-0532-6
   Han Y, 2018, IEEE T MED IMAGING, V37, P1418, DOI 10.1109/TMI.2018.2823768
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445
   Hu YL, 2019, IEEE 17TH INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP / IEEE 17TH INT CONF ON PERVAS INTELLIGENCE AND COMP / IEEE 5TH INT CONF ON CLOUD AND BIG DATA COMP / IEEE 4TH CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P309, DOI 10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00064
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Liao F, 2017, IEEE T CYBERNETICS, VPP, P1
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P4527, DOI 10.1007/s11042-018-6058-6
   Pan G, 2017, MULTIMED TOOLS APPL, V77, P1
   Petitjean C, 2015, MED IMAGE ANAL, V19, P187, DOI 10.1016/j.media.2014.10.004
   Ramaswamy A, 2018, IEEE T AUTOMAT CONTR, V63, P1465, DOI 10.1109/TAC.2017.2744598
   Ringenberg J, 2014, COMPUT MED IMAG GRAP, V38, P190, DOI 10.1016/j.compmedimag.2013.12.011
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shan J, 2012, ULTRASOUND MED BIOL, V38, P262, DOI 10.1016/j.ultrasmedbio.2011.10.022
   Tan LK, 2017, MED IMAGE ANAL, V39, P78, DOI 10.1016/j.media.2017.04.002
   Varga-Szemes A, 2015, J CARDIOVASC MAGN R, V17, P1, DOI [10.1186/s12968-014-0101-1, DOI 10.1186/S12968-014-0101-1]
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Vu Tran P., 2016, ARXIV160400494
   Wang K., 2017, THESIS
   Wang L, 2016, BIOMED RES INT, V2015, P1
   Wu H. S., 2013, INT J CARDIOL, V164, pS13, DOI DOI 10.1016/S0167-5273(13)70558-8
   Yee CH, 2018, CARDIAC MRI SEGMENTA
   Yin H., 2019, THESIS
   Zotti C, 2017, ARXIV170508943V1, V1
NR 32
TC 5
Z9 5
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34103
EP 34119
DI 10.1007/s11042-020-08911-9
EA APR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000527485500002
DA 2024-07-18
ER

PT J
AU Abdel-Basset, M
   Gamal, A
   Manogaran, G
   Son, L
   Long, HV
AF Abdel-Basset, Mohamed
   Gamal, Abduallah
   Manogaran, Gunasekaran
   Son, Le Hoang
   Long, Hoang Viet
TI A novel group decision making model based on neutrosophic sets for heart
   disease diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heart failure; Internet of things (IoT); Neutrosophic multi criteria
   decision making; Biomedical data analysis
ID OF-THE-ART; HEALTH-CARE; SUPPORT-SYSTEM; BIG DATA; CLOUD; IOT; INTERNET;
   THINGS; ARCHITECTURE; PREDICTION
AB In a developed society, people have more concerned about their health. Thus, improvement of medical field application has been one of the greatest active study areas. Medical statistics show that heart disease is the main reason for morbidity and death in the world. The physician's job is difficult because of having too many factors to analyze in the diagnosis of heart disease. Besides, data and information gained by the physician for diagnosis are often partial and immersed. Recently, health care applications with the Internet of Things (IoT) have offered different dimensions and other online services. These applications have provided a new platform for millions of people to receive benefits from the regular health tips to live a healthy life. In this paper, we propose a novel framework based on computer supported diagnosis and IoT to detect and monitor heart failure infected patients, where the data are attained from various other sources. The proposed healthcare system aims at obtaining better precision of diagnosis with ambiguous information. We suggest neutrosophic multi criteria decision making (NMCDM) technique to aid patient and physician to know if patient is suffering from heart failure. Furthermore, through dealing with the uncertainty of imprecision and vagueness resulted from the symmetrical priority scales of different symptoms of disease, users know what extent the disease is dangerous in their body. The proposed model is validated by numerical examples on real case studies. The experimental results indicate that the proposed system provides a viable solution that can work at wide range, a new platform to millions of people getting benefit over the decreasing of mortality and cost of clinical treatment related to heart failure.
C1 [Abdel-Basset, Mohamed; Gamal, Abduallah] Zagazig Univ, Fac Comp & Informat, Dept Operat Res, Sharqiyah, Egypt.
   [Manogaran, Gunasekaran] Univ Calif Davis, Davis, CA 95616 USA.
   [Son, Le Hoang] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Long, Hoang Viet] Ton Duc Thang Univ, Inst Computat Sci, Div Computat Math & Engn, Ho Chi Minh City, Vietnam.
   [Long, Hoang Viet] Ton Duc Thang Univ, Fac Math & Stat, Ho Chi Minh City, Vietnam.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; University of
   California System; University of California Davis; Vietnam National
   University Hanoi; Ton Duc Thang University; Ton Duc Thang University
RP Abdel-Basset, M (corresponding author), Zagazig Univ, Fac Comp & Informat, Dept Operat Res, Sharqiyah, Egypt.
EM analyst_mohamed@zu.edu.eg; abduallahgamal@gmail.com;
   gmanogaran@ucdavis.edu; sonlh@vnu.edu.vn; hoangvietlong@tdtu.edu.vn
RI Abdel-Basset, Mohamed/AAH-2833-2019; Gamal, Abduallah/ABI-5916-2020
OI Abdel-Basset, Mohamed/0000-0003-1102-1387; Gamal,
   Abduallah/0000-0002-3819-0714; Hoang Son, Le/0000-0001-6356-0046
CR Abdel-Basset M, 2018, NOVEL METHOD SOLVING, DOI [10.1007/s00521-018-3404-6, DOI 10.1007/S00521-018-3404-6]
   Abdel-Basset M, 2018, J AMB INTEL HUM COMP, V9, P1427, DOI 10.1007/s12652-017-0548-7
   Abdel-Basset M, 2018, J INTELL FUZZY SYST, V34, P4213, DOI 10.3233/JIFS-171952
   Abdel-Basset M, 2018, SOFT COMPUT, V22, P4221, DOI 10.1007/s00500-017-2744-y
   Abdel-Basset M, 2017, J INTELL FUZZY SYST, V33, P4055, DOI 10.3233/JIFS-17981
   Abdel-Basset M, 2018, SOFT COMPUT, V22, P6629, DOI 10.1007/s00500-017-2758-5
   Al Hemairy M., 2018, Technology for Smart Futures, P113, DOI [10.1007/978-3-319-60137-3_6, DOI 10.1007/978-3-319-60137-3_6]
   Ali M, 2018, APPL SOFT COMPUT, V71, P1054, DOI 10.1016/j.asoc.2017.10.012
   Ali M, 2018, INT J FUZZY SYST, V20, P986, DOI 10.1007/s40815-017-0380-4
   Ali M, 2017, J INTELL FUZZY SYST, V33, P4077, DOI 10.3233/JIFS-17999
   Alshurafa N, 2017, IEEE J BIOMED HEALTH, V21, P507, DOI 10.1109/JBHI.2016.2518673
   [Anonymous], 2013, ARXIV13105220
   Bhatla Nidhi, 2012, INT J COMPUTER APPL, V54, P16
   da Costa CA, 2018, ARTIF INTELL MED, V89, P61, DOI 10.1016/j.artmed.2018.05.005
   Das A, 2019, FUTURE GENER COMP SY, V93, P486, DOI 10.1016/j.future.2018.10.050
   Deli I, 2015, ARXIV150402773
   Firouzi F, 2018, FUTURE GENER COMP SY, V78, P583, DOI 10.1016/j.future.2017.09.016
   Nguyen GN, 2019, INT J MACH LEARN CYB, V10, P1, DOI 10.1007/s13042-017-0691-7
   Gia TN, 2019, FUTURE GENER COMP SY, V93, P198, DOI 10.1016/j.future.2018.10.029
   Gravina R, 2017, INFORM FUSION, V35, P68, DOI 10.1016/j.inffus.2016.09.005
   Haghi M, 2017, HEALTHC INFORM RES, V23, P4, DOI 10.4258/hir.2017.23.1.4
   Ho W, 2010, EUR J OPER RES, V202, P16, DOI 10.1016/j.ejor.2009.05.009
   Long HV, 2019, COMPUT IND ENG, V127, P687, DOI 10.1016/j.cie.2018.11.007
   Long HV, 2018, VIETNAM J MATH, V46, P531, DOI 10.1007/s10013-017-0254-y
   Long HV, 2018, COMPUT APPL MATH, V37, P2738, DOI 10.1007/s40314-017-0478-1
   Long HV, 2014, FUZZY OPTIM DECIS MA, V13, P435, DOI 10.1007/s10700-014-9186-0
   Jha S, 2019, EVOL SYST-GER, V10, P621, DOI 10.1007/s12530-018-9247-7
   Kalantari A, 2018, NEUROCOMPUTING, V276, P2, DOI 10.1016/j.neucom.2017.01.126
   Khan M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080314
   Kumar PM, 2018, FUTURE GENER COMP SY, V86, P527, DOI 10.1016/j.future.2018.04.036
   Li C, 2017, PROCEDIA COMPUT SCI, V112, P2328, DOI 10.1016/j.procs.2017.08.265
   Dat LQ, 2019, IEEE ACCESS, V7, P38902, DOI 10.1109/ACCESS.2019.2902841
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Nazari S, 2018, EXPERT SYST APPL, V95, P261, DOI 10.1016/j.eswa.2017.11.001
   Nedungadi P, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0854-9
   Son NTK, 2020, MULTIMED TOOLS APPL, V79, P16845, DOI 10.1007/s11042-019-7388-8
   Thong NT, 2019, COMPUT IND, V108, P45, DOI 10.1016/j.compind.2019.02.009
   Poornima V., 2018, Biomed Res, DOI [10.4066/biomedicalresearch.38-18-434, DOI 10.4066/BIOMEDICALRESEARCH.38-18-434]
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Riedel O, 2018, CLIN RES CARDIOL, V107, P487, DOI 10.1007/s00392-018-1210-x
   Ngan RT, 2018, APPL SOFT COMPUT, V69, P393, DOI 10.1016/j.asoc.2018.04.036
   Sagir AM, 2017, PERTANIKA J SCI TECH, V25, P43
   Samuel OW, 2017, EXPERT SYST APPL, V68, P163, DOI 10.1016/j.eswa.2016.10.020
   Ngan TT, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0634-y
   Verma P, 2018, J AMB INTEL HUM COMP, V9, P1293, DOI 10.1007/s12652-017-0520-6
   Verma P, 2018, J PARALLEL DISTR COM, V116, P27, DOI 10.1016/j.jpdc.2017.11.018
   Wang YC, 2018, TECHNOL FORECAST SOC, V126, P3, DOI 10.1016/j.techfore.2015.12.019
   Xu BY, 2017, ENTERP INF SYST-UK, V11, P17, DOI 10.1080/17517575.2015.1053416
   Yin YH, 2016, J IND INF INTEGR, V1, P3, DOI 10.1016/j.jii.2016.03.004
NR 49
TC 71
Z9 72
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9977
EP 10002
DI 10.1007/s11042-019-07742-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600014
DA 2024-07-18
ER

PT J
AU Cao, XF
   Gao, S
   Chen, LC
   Wang, Y
AF Cao, Xiufeng
   Gao, Shu
   Chen, Liangchen
   Wang, Yan
TI Ship recognition method combined with image segmentation and deep
   learning feature extraction in video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ship recognition; Image segmentation; Deep learning CNN; Zemike moment;
   KNN-SVM classifier
AB To solve the problem of ship recognition in video images, a ship recognition method based on Morphological Watershed image segmentation and Zemike moment is proposed. Firstly, the video frame image is pre-processed by gray algorithm, and then the gray image is filtered by wavelet transform to remove noise. After denoising, the Morphological Watershed algorithm is used to segment the image and extract the ship area in the image. Next, the feature of ship image is extracted based on deep learning convolution neural network (CNN) and Zemike moment method. Finally, the KNN-SVM classifier is trained according to the image features and class labels to realize the automatic recognition of ships. Experimental results show that the method can effectively identify 3 types of ships, with an average detection accuracy of 87%.
C1 [Cao, Xiufeng; Gao, Shu; Chen, Liangchen] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430000, Peoples R China.
   [Gao, Shu] Wuhan Univ Technol, Hubei Key Lab Transportat Internet Things, Wuhan 430000, Peoples R China.
   [Chen, Liangchen] China Inst Ind Relat, Dept Comp Applicat, Beijing 100000, Peoples R China.
   [Wang, Yan] Guizhou Univ Engn Sci, Sch Informat Engn, Bijie 551700, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology
RP Cao, XF (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430000, Peoples R China.
EM cxf0417@hotmail.com; gshu418@163.com; chenlc@ihep.ac.cn;
   604788055@qq.com
CR Abd Rahman HA, 2015, COMM COM INF SC, V545, P54, DOI 10.1007/978-981-287-936-3_6
   An Ting, 2014, Applied Mechanics and Materials, V536-537, P148, DOI 10.4028/www.scientific.net/AMM.536-537.148
   [Anonymous], INT C COMP COMM CONT
   [Anonymous], INT C IM GRAPH
   [Anonymous], LECT NOTES ELECT ENG
   [Anonymous], INT SOC OPTICS PHOTO
   Caponetti L, 2014, APPL INTELL, V41, P117, DOI 10.1007/s10489-013-0509-6
   Ismael SH, 2016, 2016 WORLD SYMPOSIUM ON COMPUTER APPLICATIONS & RESEARCH (WSCAR), P36, DOI 10.1109/WSCAR.2016.30
   Jain P, 2017, MULTIMED TOOLS APPL, V76, P1659, DOI 10.1007/s11042-015-3154-8
   LEE HJ, 1990, PATTERN RECOGN, V23, P785, DOI 10.1016/0031-3203(90)90101-P
   Lee JCK, 2016, PROF LEARN DEV SCH H, P39, DOI 10.1007/978-3-319-24139-5_3
   Li X, 2010, INT ASIA CONF INFORM, P276
   Liu BX, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P158, DOI [10.1109/HPCC-SmartCity-DSS.2016.124, 10.1109/HPCC-SmartCity-DSS.2016.0033]
   Mi C, 2015, J COASTAL RES, P28, DOI 10.2112/SI73-006.1
   Nandi A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P55, DOI 10.1109/CGVIS.2015.7449892
   Nugroho HA, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P450, DOI 10.1109/ELECSYM.2016.7861048
   Rainey K, 2016, PROC SPIE, V9844, DOI 10.1117/12.2229366
   Wu YY, 2009, PROCEEDINGS OF PICMET 09 - TECHNOLOGY MANAGEMENT IN THE AGE OF FUNDAMENTAL CHANGE, VOLS 1-5, P581
   Yao Y, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042611
NR 19
TC 40
Z9 43
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9177
EP 9192
DI 10.1007/s11042-018-7138-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600045
DA 2024-07-18
ER

PT J
AU Chen, JX
   Mao, ZJ
   Yao, WX
   Huang, YF
AF Chen, J. X.
   Mao, Z. J.
   Yao, W. X.
   Huang, Y. F.
TI EEG-based biometric identification with convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric identification; Electroencephalogram (EEG); Convolutional
   neural networks; Deconvolutional networks; Brain-computer interface
ID BRAIN; POTENTIALS; DYNAMICS
AB Although more interest arising in biometric identification with electroencephalogram (EEG) signals, there is still a lack of simple and robust models that can be applied in real applications. This work proposes a new convolutional neural network with global spatial and local temporal filter called (GSLT-CNN), which works directly with raw EEG data, not requiring the need for engineering features. We investigate the performance of the GSLT-CNN model on datasets of 157 subjects collected from 4 different experiments that measure endogenous brain states (driving fatigue and emotion) as well as time-locked artificially induced brain responses such as rapid serial visual response (RSVP). We evaluate the GSLT-CNN model against the comparable SVM, Bagging Tree and LDA models with effective feature selection method. The results show the GSLT-CNN model is highly efficient and robust in training more than 279 K epochs within less than 0.5 h and achieves 96% accuracy in identifying 157 subjects, which is 3% better than the best accuracy of SVM on selected PSD feature, 10% better than that of SVM on selected AR feature and 23% better than that of normal CV-CNN model on raw EEG feature. It demonstrates the potential of deep learning solutions for real-life EEG-based biometric identification. We also show that the cross-session identification accuracy from time-locked RSVP data (99%) is slightly higher than that from single-session non-time-locked driving fatigue data (97%) and much higher than that from epochs measuring random brain states (90%), which implies RSVP could be a more beneficial design to achieve high identification accuracy with EEG and our GSLT-CNN model is robust for cross-session identification in RSVP experiment.
C1 [Chen, J. X.] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
   [Mao, Z. J.; Huang, Y. F.] Univ Texas San Antonio, Dept Elect & Comp Engn, San Antonio, TX 78249 USA.
   [Yao, W. X.] Univ Texas San Antonio, Dept Kinesiol, San Antonio, TX 78249 USA.
   [Huang, Y. F.] Univ Texas Hlth Sci Ctr San Antonio, Dept Epidemiol & Biostat, San Antonio, TX 78284 USA.
C3 Shaanxi University of Science & Technology; University of Texas System;
   University of Texas at San Antonio (UTSA); University of Texas System;
   University of Texas at San Antonio (UTSA); University of Texas System;
   University of Texas Health Science Center at San Antonio
RP Chen, JX (corresponding author), Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Shaanxi, Peoples R China.
EM chenjx_sust@foxmail.com
OI Chen, Jingxia/0000-0002-1994-4752
CR Abadi Martin, 2016, arXiv
   Bigdely-Shamlo N, 2015, FRONT NEUROINFORM, V9, DOI 10.3389/fninf.2015.00016
   Brigham K, 2010, INT CONF BIOINFORM
   Campisi P, 2014, IEEE T INF FOREN SEC, V9, P782, DOI 10.1109/TIFS.2014.2308640
   Cecotti H, 2014, IEEE T NEUR NET LEAR, V25, P2030, DOI 10.1109/TNNLS.2014.2302898
   Cecotti H, 2011, IEEE T PATTERN ANAL, V33, P433, DOI 10.1109/TPAMI.2010.125
   Chen YY, 2016, IEEE T INF FOREN SEC, V11, P2635, DOI 10.1109/TIFS.2016.2577551
   Davis H, 1936, ARCH NEURO PSYCHIATR, V36, P1214, DOI 10.1001/archneurpsyc.1936.02260120061004
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   DelPozo-Banos M, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/5/056019
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lance BJ, 2012, P IEEE, V100, P1585, DOI 10.1109/JPROC.2012.2184830
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Maiorana E, 2016, NEUROCOMPUTING, V171, P638, DOI 10.1016/j.neucom.2015.07.005
   Mao ZJ, 2017, IEEE ENG MED BIO, P2035, DOI 10.1109/EMBC.2017.8037252
   Mao ZJ, 2017, I IEEE EMBS C NEUR E, P609, DOI 10.1109/NER.2017.8008425
   Mao ZJ, 2016, LECT NOTES ARTIF INT, V9743, P57, DOI 10.1007/978-3-319-39955-3_6
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Moharnmadi G, 2006, PROC WRLD ACAD SCI E, V11, P281
   Palaniappan R., 2005, 2005 3rd International Conference on Intelligent Sensing and Information Processing, P238
   Roselin V, 2013, INT J COMPUT APPL, V24, P1
   Ruiz-Blondet MV, 2016, IEEE T INF FOREN SEC, V11, P1618, DOI 10.1109/TIFS.2016.2543524
   Samuel RDJ, 2020, MULTIMED TOOLS APPL, V79, P5225, DOI 10.1007/s11042-018-6356-z
   Samuel RDJ, 2019, NEURAL COMPUT APPL, V31, P1533, DOI 10.1007/s00521-018-3564-4
   Scholkopft B., 1999, Neural networks for signal processing IX, V1, P1
   Sharma K.K., 2014, International Research Journal of Biological Sciences, V3, P1
   Singhal GK, 2008, BIOMETR S, V74, P1
   Touryan J, 2016, BIOL PSYCHOL, V114, P93, DOI 10.1016/j.biopsycho.2015.12.009
   Touryan J, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00155
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Ververidis D, 2008, SIGNAL PROCESS, V88, P2956, DOI 10.1016/j.sigpro.2008.07.001
   Ververidis D, 2009, IEEE T PATTERN ANAL, V31, P2275, DOI 10.1109/TPAMI.2009.84
   Wolpaw JR, 2007, J PHYSIOL-LONDON, V579, P613, DOI 10.1113/jphysiol.2006.125948
   Yeom SK, 2013, PATTERN RECOGN, V46, P1159, DOI 10.1016/j.patcog.2012.10.023
   Yonggun Lee, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P182, DOI 10.1109/BHI.2018.8333399
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 38
TC 28
Z9 28
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10655
EP 10675
DI 10.1007/s11042-019-7258-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600051
DA 2024-07-18
ER

PT J
AU Pan, F
   Chen, DQ
   Lu, L
AF Pan, Feng
   Chen, Deqiang
   Lu, Lu
TI Improved PSO based clustering fusion algorithm for multimedia image data
   projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia image data projection; Clustering fusion; Inertia weight
   linear decreasing PSO algorithm; Optimized base clustering subset;
   Global optimization; Error back propagation
AB Aiming at the problem that the existing multimedia image clustering fusion algorithm has poor effect on the projection processing of multimedia image data, and the result of the fusion is dispersive, a multimedia image data projection clustering fusion optimization algorithm based on improved particle swarm optimization is proposed. Firstly, using the gradient descent training of error back propagation, the cluster members of the multimedia image data projection are selected to provide an accurate data basis for subsequent cluster fusion. Secondly, each multimedia image data projection base clustering algorithm is selected into the optimized base. Probability of subsets of classes; finally, the improved inertia weight linear decrement PSO algorithm is used for global optimization, and the optimization of multimedia image data projection clustering algorithm is realized. Through experimental verification and analysis, the results show that the algorithm proposed in this paper has high accuracy of projection and clustering of multimedia image data on Data-Set virtual dataset or Iris actual dataset, and the average accuracy is above 90%.
C1 [Pan, Feng] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Pan, Feng; Chen, Deqiang] Guizhou Minzu Univ, Sch Data Sci & Informat Engn, Guiyang 550025, Guizhou, Peoples R China.
   [Lu, Lu] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology; Guizhou Minzu University; South
   China University of Technology
RP Pan, F (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510006, Guangdong, Peoples R China.; Pan, F (corresponding author), Guizhou Minzu Univ, Sch Data Sci & Informat Engn, Guiyang 550025, Guizhou, Peoples R China.
EM fpangz@163.com
CR Cai Hua, 2016, Journal of Jilin University (Science Edition), V54, P1087, DOI 10.13413/j.cnki.jdxblxb.2016.05.28
   Cai-Hong M U, 2015, ACTA ELECT SIN, V43, P1375
   Chen YL, 2017, INFORM FUSION, V36, P225, DOI 10.1016/j.inffus.2016.11.015
   Da K, 2015, J GLOBAL OPTIM, V62, P1
   Fu Y, 2015, INT C SIGN PROC
   Gianoli C, 2016, NUCL SCI S MED IM C
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hou SD, 2014, J VIS COMMUN IMAGE R, V25, P785, DOI 10.1016/j.jvcir.2014.01.009
   Knyaz VA, 2016, PROC SPIE, V9840, DOI 10.1117/12.2224086
   Le MT, 2017, OPT LASER ENG, V96, P17, DOI 10.1016/j.optlaseng.2017.04.002
   Lian CF, 2019, IEEE T IMAGE PROCESS, V28, P755, DOI 10.1109/TIP.2018.2872908
   Liang GZ, 2015, IEEE T IMAGE PROCESS, V24, P4488, DOI 10.1109/TIP.2015.2465169
   Ma KD, 2015, IEEE T IMAGE PROCESS, V24, P3086, DOI [10.1109/TIP.2015.2436340, 10.1109/TIP.2015.2456638]
   Mariesainte SL, 2016, 2016 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS AND COMPUTER SYSTEMS (CIICS)
   Meng L, 2014, IEEE T KNOWL DATA EN, V26, P2293, DOI 10.1109/TKDE.2013.47
   Min L, 2016, GEOSC REM SENS S
   Ni J, 2017, IEEE INT C SMART CLO
   Ogata Y, 2017, ANN NUCL MED, V31, P304, DOI 10.1007/s12149-017-1158-3
   Ozay M, 2014, IEEE INT C IM PROC
   Prasad S, 2014, IEEE INT C IM PROC
   Sevillano X, 2014, MULTIMED TOOLS APPL, V73, P1507, DOI 10.1007/s11042-013-1655-x
   Shabanzade F, 2017, INT S TEL
   Shen H, 2014, P 2014 IEEE INT C SE
   Stieglitz LH, 2014, OPER NEUROSURG, V10, P506, DOI 10.1227/NEU.0000000000000473
   [王慧利 Wang Huili], 2015, [光电子·激光, Journal of Optoelectronics·Laser], V26, P992
   Wang R, 2014, INT J REMOTE SENS, V35, P1640, DOI 10.1080/01431161.2014.880819
   Wang SH, 2015, NEUROCOMPUTING, V168, P747, DOI 10.1016/j.neucom.2015.05.049
   Xiong FY, 2016, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2789212
   Yadav M., 2014, Int. J. Eng. Sci. Res. Technol., V3
   Zhang H, 2015, MED PHYS, V42, P3682, DOI 10.1118/1.4926015
   Zhang Q, 2015, PROC SPIE, V9474, DOI 10.1117/12.2177535
   Zhao M, 2017, COMP COMM WORKSH
   Zhe X, 2015, IEEE INT C MULT EXP
   Zou G, 2016, INT J BIOAUTOMATION
   [左绍山 Zuo Shaoshan], 2015, [电子与信息学报, Journal of Electronics & Information Technology], V37, P1389
NR 35
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9509
EP 9522
DI 10.1007/s11042-019-08015-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600065
DA 2024-07-18
ER

PT J
AU Sharif, M
   Amin, J
   Yasmin, M
   Rehman, A
AF Sharif, Muhammad
   Amin, Javeria
   Yasmin, Mussarat
   Rehman, Amjad
TI Efficient hybrid approach to segment and classify exudates for DR
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Green channel; Median filter; Global threshold; Local binary pattern
   (LBP); Histogram orientation gradient (HOG)
ID DIGITAL FUNDUS IMAGES; COLOR RETINAL IMAGES; HYPERTENSIVE RETINOPATHY;
   AUTOMATED DETECTION; NEURAL-NETWORK; OPTIC DISC; CLASSIFICATION;
   EXTRACTION; DIAGNOSIS; SUPPORT
AB Diabetic retinopathy (DR) is initiated due to the severity of diabetes which can finally lead to an incurable blindness. It is a significant reason for optical damage that may cause blindness permanently. There are no main symptoms of DR appearing initially but its quantity and severity rises with the passage of time. Initial screening and diagnosis of DR may help to stop vision loss. Exudates (EXs) are one of the primary clinical symptoms of DR. In this manuscript, a computerized technique is proposed for DR detection based on EXs. The proposed system is consisting of four major steps. The first step is enhancement of region of interest using median filter and adaptive contrast enhancement method. After that, local variance and global threshold methods are utilized for candidate lesions segmentation. Moreover, texture features with multiple classifiers are applied for classification. The proposed method is evaluated in terms of sensitivity, specificity, accuracy and area under curve on DIARETDB1, MESSIDOR and local data sets.
C1 [Sharif, Muhammad; Yasmin, Mussarat] COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
   [Amin, Javeria] Univ Wah, Dept Comp Sci, Wah Cantt, Pakistan.
   [Rehman, Amjad] Al Yamamah Univ, Coll Comp & Informat Syst, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Al-Yamamah University
RP Yasmin, M (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Wah Campus, Wah Cantt, Pakistan.
EM mussaratabdullah@gmail.com
RI Yasmin, Mussarat/HPC-9476-2023; Sharif, Muhammad/ACD-2598-2022; AMIN,
   JAVARIA/IAQ-1843-2023; Sharif, Muhammad/AAB-8376-2022; Rehman,
   Amjad/GXV-0915-2022
OI Sharif, Muhammad/0000-0002-7258-8400; Rehman, Amjad/0000-0002-3817-2655
CR Acharya UR, 2017, COMPUT BIOL MED, V84, P59, DOI 10.1016/j.compbiomed.2017.03.016
   Acharya UR, 2012, J MED SYST, V36, P2011, DOI 10.1007/s10916-011-9663-8
   Agurto C, 2010, IEEE T MED IMAGING, V29, P502, DOI 10.1109/TMI.2009.2037146
   Akram MU, 2014, COMPUT BIOL MED, V45, P161, DOI 10.1016/j.compbiomed.2013.11.014
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Amin J, 2017, J COMPUT SCI-NETH, V19, P153, DOI 10.1016/j.jocs.2017.01.002
   Amin J, 2016, SCIENTIFICA, V2016, DOI 10.1155/2016/6838976
   [Anonymous], 2016, COMMUN COMPUT INFORM, DOI DOI 10.1007/978-981-10-2053-7
   [Anonymous], 2016, IIOAB J
   [Anonymous], 2018, NEURAL COMPUT APPL
   [Anonymous], MED BIOL ENG COMPUTI
   [Anonymous], TENCON 2015
   [Anonymous], 2014, INT J COMPUT SCI INF
   [Anonymous], 2018, DETECTION HARD EXUDA
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], OPTICS LASER TECHNOL
   [Anonymous], IMPERIAL J INTERDISC
   [Anonymous], COMPUTER METHODS PRO
   Bokhari STF, 2018, CURR MED IMAGING REV, V14, P77, DOI 10.2174/1573405613666170405145913
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Capdehourat G, 2011, PATTERN RECOGN LETT, V32, P2187, DOI 10.1016/j.patrec.2011.06.015
   Colomer A, 2018, J COMPUT APPL MATH, V337, P341, DOI 10.1016/j.cam.2018.01.005
   Cuspidi C, 2015, J HYPERTENS, V33, P2204, DOI 10.1097/HJH.0000000000000733
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dashtbozorg B, 2016, LECT NOTES COMPUT SC, V9730, P697, DOI 10.1007/978-3-319-41501-7_78
   Ege BM, 2000, COMPUT METH PROG BIO, V62, P165, DOI 10.1016/S0169-2607(00)00065-1
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Fernandes S., 2015, Recent Patents on Engineering, V9, P29, DOI [10.2174/2210686303666131118220632, DOI 10.2174/2210686303666131118220632]
   Fernandes SL, 2017, CURR MED IMAGING REV, V13, P176, DOI 10.2174/1573405612666160606143938
   Fernandes SL, 2017, J MED IMAG HEALTH IN, V7, P1841, DOI 10.1166/jmihi.2017.2280
   Fernandes SL, 2016, J INTEGR DES PROCESS, V20, P33, DOI 10.3233/jid-2016-0002
   Fernandes SL, 2016, PROCEDIA COMPUT SCI, V78, P248, DOI 10.1016/j.procs.2016.02.040
   Ganesan K, 2014, P I MECH ENG H, V228, P962, DOI 10.1177/0954411914550847
   García M, 2009, COMPUT METH PROG BIO, V93, P9, DOI 10.1016/j.cmpb.2008.07.006
   Jaya T, 2015, J DIGIT IMAGING, V28, P761, DOI 10.1007/s10278-015-9793-5
   Kaur J, 2018, BIOCYBERN BIOMED ENG, V38, P27, DOI 10.1016/j.bbe.2017.10.003
   Khan MW, 2016, J INTEGR DES PROCESS, V20, P77, DOI 10.3233/jid-2016-0004
   Kolman SAM, 2017, J HUM HYPERTENS, V31, P121, DOI 10.1038/jhh.2016.49
   Kumara S, 2017, J COMPUT SCI-NETH, V19, P121, DOI 10.1016/j.jocs.2016.11.009
   Lahmiri S, 2014, BIOMED ENG-BIOMED TE, V59, P357, DOI 10.1515/bmt-2013-0082
   Li HQ, 2004, IEEE T BIO-MED ENG, V51, P246, DOI 10.1109/TBME.2003.820400
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Lim JI, 2000, OPHTHALMOLOGY, V107, P866, DOI 10.1016/S0161-6420(00)00057-9
   Margineantu D.D., 1997, ICML, V97, P211
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Naqi SM, 2018, CURR MED IMAGING, V14, P108, DOI 10.2174/1573405613666170306114320
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Qureshi I, 2016, CURR MED IMAGING, V12, P234, DOI 10.2174/1573405611666150929234644
   Reza AW, 2011, J MED SYST, V35, P1491, DOI 10.1007/s10916-009-9426-y
   Shabbir B, 2016, J INTEGR DES PROCESS, V20, P65, DOI 10.3233/jid-2016-0003
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   Wong TY, 2005, BRIT MED BULL, V73-74, P57, DOI 10.1093/bmb/ldh050
   Yazid H, 2012, J MED SYST, V36, P1997, DOI 10.1007/s10916-011-9659-4
   Youssef D, 2012, COMPUT METH PROG BIO, V108, P1052, DOI 10.1016/j.cmpb.2012.06.006
   Zhang XH, 2004, IEEE IMAGE PROC, P139
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
   Zhao QY, 2008, INT C WAVEL ANAL PAT, P362, DOI 10.1109/ICWAPR.2008.4635805
NR 58
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11107
EP 11123
DI 10.1007/s11042-018-6901-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600074
DA 2024-07-18
ER

PT J
AU Yang, XM
   Wu, W
   Lu, L
   Yan, BY
   Zhang, L
   Liu, K
AF Yang, Xiaomin
   Wu, Wei
   Lu, Lu
   Yan, Binyu
   Zhang, Lei
   Liu, Kai
TI Multiple Regressions based Image Super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Sparse coding; Ridge Regression
ID HIGH-RESOLUTION IMAGE; INTERPOLATION; SPARSE; RECONSTRUCTION
AB The limitation of optical sensors set a challenge to acquire high resolution (HR) images. Previous sparse coding-based SR methods fail to reconstruct satisfied high resolution image due to three problems. First, sparse representation calculation is time consuming, which restricts its application in real-time systems. Second, sparse coding-based SR methods cannot represent diversity of patterns with one dictionary pair. Finally, it is supposed that the sparse representations of HR-LR patch pair are identical. However, the hypothesis cannot deal with all patterns. To address these problems, a multiple regressions based image super-resolution is proposed in this paper. First, to relax the hypothesis, the proposed method works on the assumption that the sparse representations of HR-LR patch pair are linear related. Secondly, training HR-LR patch pairs are departed into clusters. Then linear mappings is learned for each cluster. Finally, ridge regression is used to calculate the sparse representation. Experiments demonstrate that our method outperform some previous methods in objective and subjective evaluation. Additionally, our method is less computational complexity.
C1 [Yang, Xiaomin; Wu, Wei; Lu, Lu; Yan, Binyu] Univ Sichuan, Coll Elect & Informat Engn, Chengdu, Peoples R China.
   [Zhang, Lei] Univ Sichuan, Coll Comp Sci, Chengdu, Peoples R China.
   [Liu, Kai] Univ Sichuan, Coll Elect & Engn Informat, Chengdu, Peoples R China.
C3 Sichuan University; Sichuan University; Sichuan University
RP Wu, W (corresponding author), Univ Sichuan, Coll Elect & Informat Engn, Chengdu, Peoples R China.
EM arielyang@scu.edu.cn; wuwei@scu.edu.cn; lulu19900303@126.com;
   yby@scu.edu.cn; zhanglei@scu.edu.cn; kailiu@scu.edu.cn
RI lu, lu/HII-7530-2022; yang, xiao/HJI-7815-2023; Lu, Lu/GPX-6708-2022;
   lu, lu/HGA-0894-2022; Huang, Yu/KDM-9182-2024; chen,
   yanhong/JVE-0289-2024; LU, LU/JEZ-4760-2023; Liu, Kai/IST-6808-2023
CR Ameer S, 2008, INT CONF SIGN PROCES, P728, DOI 10.1109/ICOSP.2008.4697233
   [Anonymous], 2 INT C GREEN COMM N
   [Anonymous], J CHIN U
   [Anonymous], P INT C MATH 2006
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chavez-Roman H, 2014, IEEE GEOSCI REMOTE S, V11, P1777, DOI 10.1109/LGRS.2014.2308905
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Juliet S, 2015, SIGNAL IMAGE VIDEO P, V9, P1691, DOI 10.1007/s11760-014-0625-8
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Quevedo E, 2014, IEEE T CONSUM ELECTR, V60, P420, DOI 10.1109/TCE.2014.6937326
   Sánchez-Beato A, 2008, IEEE T IMAGE PROCESS, V17, P1817, DOI 10.1109/TIP.2008.2002833
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang XM, 2018, IEEE ACCESS, V6, P5511, DOI 10.1109/ACCESS.2018.2790482
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhao Li, 2014, Applied Mechanics and Materials, V568-570, P652, DOI 10.4028/www.scientific.net/AMM.568-570.652
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8911
EP 8927
DI 10.1007/s11042-019-7716-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600028
DA 2024-07-18
ER

PT J
AU Zhu, XL
   Liu, YG
   Li, QQ
   Zhang, Y
   Wen, CB
AF Zhu, Xiaolin
   Liu, Yongguo
   Li, Qiaoqin
   Zhang, Yi
   Wen, Chuanbiao
TI Mining patterns of Chinese medicinal prescription for diabetes mellitus
   based on therapeutic effect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetes mellitus; Therapeutic effect; Traditional Chinese medicine;
   Weighted association rule
ID ASSOCIATION RULES; NATIONWIDE; ITEMSETS; NETWORK
AB Traditional Chinese medicine (TCM) prescription comprises groups of Chinese herbs that embody thousands of years of history with respect to the treatment of diabetes mellitus (DM), a condition for which there are numerous prescriptions with different therapeutic effects. Existing studies on prescription patterns are based on the frequencies calculated using the traditional association rule algorithm. However, the most important concern for physicians is the efficacy of drug combinations in clinical practice, as no existing study has considered the efficacy of prescriptions. In this study, a weighted association rule algorithm called MWFPP (Mining Weighted Frequent Patterns of Prescription) was used to mine and analyze TCM prescriptions for the treatment of DM based on the therapeutic effect. As a result, the ranking of drug combinations with a low frequency but the good therapeutic effect in the randomized controlled trials (RCT) increased. These drug combinations were also effective in the treatment of DM according to TCM theory. Hence, effective drug combinations could be promising for prescription compatibility in clinical practice and drug discovery.
C1 [Zhu, Xiaolin; Liu, Yongguo; Li, Qiaoqin] Univ Elect Sci & Technol China, Sch Informat & Software Engn, Knowledge & Data Engn Lab Chinese Med, Chengdu 610054, Peoples R China.
   [Zhang, Yi] Chengdu Univ Tradit Chinese Med, Coll Ethn Med, Chengdu 611137, Peoples R China.
   [Wen, Chuanbiao] Chengdu Univ Tradit Chinese Med, Coll Med Informat Engn, Chengdu 611137, Peoples R China.
C3 University of Electronic Science & Technology of China; Chengdu
   University of Traditional Chinese Medicine; Chengdu University of
   Traditional Chinese Medicine
RP Liu, YG (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Software Engn, Knowledge & Data Engn Lab Chinese Med, Chengdu 610054, Peoples R China.
EM liuyg_cn@163.com
RI Zhu, Xiaolin/K-9277-2016
CR Agapito G, 2016, IEEE ACM T COMPUT BI, V13, P197, DOI 10.1109/TCBB.2015.2462348
   [Anonymous], WAV ACT MED TECHN IN
   [Anonymous], CHIN J CLIN RATIONAL
   [Anonymous], WORLD CHINESE MED
   [Anonymous], WORLD CHINESE MED
   [Anonymous], CHIN J CLIN RATIONAL
   [Anonymous], CHINA HLTH STANDARD
   Borenstein M., 2009, INT STAT REV
   Canizares M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177307
   Chan ST, 2017, INT J MATH, V28, DOI 10.1142/S0129167X17400109
   Chen HY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0154897
   Chen HY, 2016, J ETHNOPHARMACOL, V179, P1, DOI 10.1016/j.jep.2015.12.032
   Chen HY, 2015, J ETHNOPHARMACOL, V168, P260, DOI 10.1016/j.jep.2015.04.002
   Chien PS, 2013, BMC COMPLEM ALTERN M, V13, DOI 10.1186/1472-6882-13-209
   Chung VCH, 2014, HEALTH EXPECT, V17, P622, DOI 10.1111/j.1369-7625.2012.00794.x
   Chung VCH, 2013, EVID-BASED COMPL ALT, V2013, DOI 10.1155/2013/426360
   Han JW, 2000, SIGMOD RECORD, V29, P1
   He YH, 2012, J TRANSL MED, V10, DOI 10.1186/1479-5876-10-S1-S12
   Huang CY, 2015, J ETHNOPHARMACOL, V176, P311, DOI 10.1016/j.jep.2015.11.002
   Bui H, 2018, EXPERT SYST APPL, V96, P388, DOI 10.1016/j.eswa.2017.10.039
   Indhumathy M, 2018, CURR BIOINFORM, V13, P73, DOI 10.2174/1574893611666161123142425
   Lee AL, 2016, MEDICINE, V95, DOI 10.1097/MD.0000000000002536
   Lee G, 2017, INT J UNCERTAIN FUZZ, V25, P111, DOI 10.1142/S0218488517500052
   Li WL, 2004, J ETHNOPHARMACOL, V92, P1, DOI 10.1016/j.jep.2003.12.031
   Lin JCW, 2015, ENG APPL ARTIF INTEL, V45, P18, DOI 10.1016/j.engappai.2015.06.009
   Lin JF, 2014, COMPLEMENT THER MED, V22, P141, DOI 10.1016/j.ctim.2013.12.003
   Pang B, 2016, NEURAL REGEN RES, V11, P1347, DOI 10.4103/1673-5374.189202
   Tian HP, 2016, J ETHNOPHARMACOL, V191, P206, DOI 10.1016/j.jep.2016.05.062
   [吴嘉瑞 Wu Jiarui], 2015, [中国实验方剂学杂志, Chinese Journal of Experimental Traditional Medical Formulae], V21, P214
   Zhang XP, 2011, CHIN J INTEGR MED, V17, P307, DOI 10.1007/s11655-011-0699-x
   Zhao HL, 2006, NES NUTR WS, V11, P15, DOI 10.1159/000094399
NR 31
TC 1
Z9 2
U1 7
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10519
EP 10532
DI 10.1007/s11042-019-7226-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600043
DA 2024-07-18
ER

PT J
AU Luo, DP
   Mou, QZ
   Zeng, ZP
   Luo, C
   Wei, LS
   Zhang, XL
AF Luo, Dapeng
   Mou, Quanzheng
   Zeng, Zhipeng
   Luo, Chen
   Wei, Longsheng
   Zhang, Xiangli
TI Bio-inspired head detection framework based on online learning algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online learning; Online bootstrap cascade classifier; Object detection;
   Object tracking
ID TRACKING; CLASSIFICATION; ADAPTATION; SELECTION
AB Online learning algorithms have been widely used to address vision-related issues such as object detection and tracking. However, a robust online learning object detection system that can continuously improve performance through self-learning continues to elude designers. This study proposes a novel online learning framework, which combines detection and verification modules to train a scene-specific head detector on a fly. For the detection module, a proposed online bootstrap cascade classifier is employed as the object detector of the framework. The cascade decision strategy is used to integrate a number of weak online classifiers. The resulting system contains sufficient weak classifiers and maintains a low computation cost. During the online learning process, the complexity of the cascade structure adapts to the difficulty of the detection task. For the verification module, a simple yet effective particle filter tracking algorithm, based on information fusion, is used to automatically label online learning samples produced by detection responses. With this method, the object detector improves detection performance by autonomously learning the samples. The online head detection framework is ported to the NVIDIA Jetson TK1 embedded platform, which enables the platform to recognize different head postures through self-learning. Experimental results on three video datasets demonstrate the effectiveness of the framework.
C1 [Luo, Dapeng; Mou, Quanzheng; Zeng, Zhipeng; Zhang, Xiangli] China Univ Geosci, Sch Elect Informat & Mech, Wuhan 430074, Peoples R China.
   [Luo, Chen] Beijing Normal Univ, Huizhou Sch, Huizhou 516002, Peoples R China.
   [Wei, Longsheng] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
C3 China University of Geosciences; Beijing Normal University; China
   University of Geosciences
RP Zhang, XL (corresponding author), China Univ Geosci, Sch Elect Informat & Mech, Wuhan 430074, Peoples R China.; Wei, LS (corresponding author), China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
EM weilongsheng@cug.edu.cn; zhangxiangli@cug.edu.cn
FU National Natural Science Foundation of China [61302137, 61603357];
   Fundamental Research Funds for the Central Universities Young Teacher
   Promotion Program-Outstanding Youth Foundation, China University of
   Geosciences (Wuhan) [CUGL170210]; Wuhan "Huanghe Elite Project"
FX This work was supported by the National Natural Science Foundation of
   China (61302137 and 61603357), Wuhan "Huanghe Elite Project",
   Fundamental Research Funds for the Central Universities Young Teacher
   Promotion Program-Outstanding Youth Foundation, China University of
   Geosciences (Wuhan)(CUGL170210).
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Bruzzone L, 1999, PATTERN RECOGN LETT, V20, P1241, DOI 10.1016/S0167-8655(99)00091-4
   Cancela B, 2013, EXPERT SYST APPL, V40, P1116, DOI 10.1016/j.eswa.2012.08.025
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Cinbis RG, 2017, IEEE T PATTERN ANAL, V39, P189, DOI 10.1109/TPAMI.2016.2535231
   Cong Y, 2013, IEEE T IMAGE PROCESS, V22, P3179, DOI 10.1109/TIP.2013.2260168
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Diehl CP, 2003, IEEE IJCNN, P2685
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   DUTTA JK, 2018, ARXIV180108577
   Erzin E, 2005, IEEE T MULTIMEDIA, V7, P840, DOI 10.1109/TMM.2005.854464
   Fern A, 2003, MACH LEARN, V53, P71, DOI 10.1023/A:1025619426553
   Ferrer-Troyano F., 2005, Proc. ACM symposium on Applied computing, P568
   Ge ZY, 2016, IEEE WINT CONF APPL
   Gepperth A., 2016, EUR S ART NEUR NETW, P1
   Hochstein S, 2002, NEURON, V36, P791, DOI 10.1016/S0896-6273(02)01091-7
   Huang C, 2007, IEEE I CONF COMP VIS, P177
   Huerta I, 2015, PATTERN RECOGN, V48, P709, DOI 10.1016/j.patcog.2014.09.023
   Impedovo S, 2014, PATTERN RECOGN, V47, P1002, DOI 10.1016/j.patcog.2013.04.016
   Javed O, 2005, PROC CVPR IEEE, P696
   Juan CH, 2003, EXP BRAIN RES, V150, P259, DOI 10.1007/s00221-003-1478-5
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kalogeratos A., 2012, Advances in Neural Information Processing Systems, V25, P2393
   Kang SK, 2014, PERS UBIQUIT COMPUT, V18, P515, DOI 10.1007/s00779-013-0668-9
   LAROZE M, 2018, 2018 INT C CONT BAS, P1
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P626
   Li Z.L., 2017, J AM TAX ASSOC, V29, P1
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008
   Mukherjee S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2969, DOI 10.1109/ICIP.2011.6116284
   Nair V, 2004, PROC CVPR IEEE, P317
   Oza NC, 2005, IEEE SYS MAN CYBERN, P2340
   Pang JB, 2011, IEEE T IMAGE PROCESS, V20, P1388, DOI 10.1109/TIP.2010.2103951
   Pham MT, 2007, IEEE I CONF COMP VIS, P1634
   Polikar R, 2001, IEEE T SYST MAN CY C, V31, P497, DOI 10.1109/5326.983933
   Qi ZQ, 2011, NEUROCOMPUTING, V74, P1769, DOI 10.1016/j.neucom.2011.02.011
   ROHEKAR RYY, 2018, ARXIV180609141
   Roth P. M., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P223
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schlimmer J. C., 1986, Proceedings AAAI-86: Fifth National Conference on Artificial Intelligence, P496
   Sharma P, 2013, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2013.418
   Singh KK, 2016, PROC CVPR IEEE, P3548, DOI 10.1109/CVPR.2016.386
   Tanaka K, 1997, CURR OPIN NEUROBIOL, V7, P523, DOI 10.1016/S0959-4388(97)80032-3
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   Villamizar M, 2012, PATTERN RECOGN, V45, P3141, DOI 10.1016/j.patcog.2012.03.025
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064
   Wang XY, 2012, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2012.6247695
   Wu X, 2015, IEEE T NEUR NET LEAR, V26, P1659, DOI 10.1109/TNNLS.2014.2350957
   Wu YG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P353
   Yang Y, 2013, PROC CVPR IEEE, P1650, DOI 10.1109/CVPR.2013.216
   ZEHNDER P, 2008, P BRIT MACH VIS C BM, P1
   Zhang Y.-L., 2018, ARXIV180504234
   Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553
NR 58
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19509
EP 19536
DI 10.1007/s11042-020-08744-6
EA MAR 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521787600003
DA 2024-07-18
ER

PT J
AU Park, ST
   Kim, D
   Li, GH
AF Park, Seong-Taek
   Kim, Do-Yeon
   Li, Guozhong
TI An analysis of environmental big data through the establishment of
   emotional classification system model based on machine learning: focus
   on multimedia contents for portal applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Bigdata; Emotional classification system; Marchining
   learning; Deep learning; CNN; Bi-LSTM
AB With the advent of the Internet, there have been many changes. As existing means of off-line communication have transferred to the Internet, a wide range of multimedia services are emerging. And unlike in the past, these work as tremendous sources from which people's opinions and attitudes can be obtained. Particularly, diverse opinions and reviews posted on the web in real time help corporations or the State establish the directions of policies. In this context, this study developed machine learning-based environment issue sentiment classifier in order to find out, from comments posted below news, how people recognize issues about climate change in terms of environment. Based on training data constructed by this study, a sentiment classification algorithm was constructed by applying SVM (support vector machine) and Naive Bayes, which are machine learning techniques, and a sentiment classifier was constructed by applying CNN (convolutional neural networks) and Bi-LSTM (bidirectional long-short term memory) techniques among deep learning techniques recently researched vigorously; and then their performance was compared.
C1 [Park, Seong-Taek] Chungbuk Natl Univ, Dept MIS, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
   [Kim, Do-Yeon] Korea Environm Inst, Environm Econ Lab, 370 Sicheong Daero, Sejong Si 30147, South Korea.
   [Li, Guozhong] Kunming Univ Sci & Technol, Dept MSIS, 68 Wenchang Rd,121 St, Kunming 650093, Yunnan, Peoples R China.
C3 Chungbuk National University; Korea Environment Institute (KEI); Kunming
   University of Science & Technology
RP Li, GH (corresponding author), Kunming Univ Sci & Technol, Dept MSIS, 68 Wenchang Rd,121 St, Kunming 650093, Yunnan, Peoples R China.
EM narin2017@kmust.edu.cn
OI Kim, Doyeon/0000-0003-2215-0483
CR Appel O, 2015, ACTA POLYTECH HUNG, V12, P87, DOI 10.12700/APH.12.3.2015.3.6
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Chanley VA, 2002, POLIT PSYCHOL, V23, P469, DOI 10.1111/0162-895X.00294
   Cliche M., 2017, P 11 INT WORKSHOP SE, P573, DOI [DOI 10.18653/V1/S17-2094, 10.18653/v1/S17-2094]
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI [DOI 10.1145/1341531.1341561, 10.1145/1341531.1341561]
   El Bahi H, 2019, MULTIMED TOOLS APPL, V78, P26453, DOI 10.1007/s11042-019-07855-z
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kang S.W., 2018, BIG DATA ANAL APPL E
   Kowsari K, 2017, 2017 16TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P364, DOI 10.1109/ICMLA.2017.0-134
   Lewis D.D., 1998, Machine Learning: ECML-98, P4
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Lim Joa Sang, 2014, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V17, P232, DOI 10.9717/kmms.2014.17.2.232
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu F, 2019, MULTIMED TOOLS APPL, V78, P4527, DOI 10.1007/s11042-018-6058-6
   Nanda MA, 2018, INFORMATION, V9, DOI 10.3390/info9010005
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Park EM, 2016, CLUSTER COMPUT, V19, P1647, DOI 10.1007/s10586-016-0609-2
   Park ST, 2019, CLUSTER COMPUT, V22, P1873, DOI 10.1007/s10586-017-1518-8
   Plutchik R., 1984, APPROACHES EMOTION, P197, DOI DOI 10.1016/B978-0-12-558701-3.50007-7
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sebastiani F., 2007, Evaluation, V17, P1
   Seo JH, 2018, WIRELESS PERS COMMUN, V98, P3109, DOI 10.1007/s11277-017-4121-7
   Seung-Won Yang, 2016, KIISE Transactions on Computing Practices, V22, P240, DOI 10.5626/KTCP.2016.22.5.240
   Sohrabi MK, 2019, MULTIMED TOOLS APPL, V78, P24863, DOI 10.1007/s11042-019-7586-4
   Song TM, 2014, YONSEI MED J, V55, P254, DOI 10.3349/ymj.2014.55.1.254
   Sosa P.M., 2017, Twitter Sentiment Analysis using Combined LSTM-CNN Models
   STITSON MO, 1996, THEORY SUPPORT VECTO, V117, P827
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tan PN., 2013, Introduction to data mining
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Tian Q, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1199, DOI 10.1109/ICME.2000.871576
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Wang Y, 2016, PROCEEDINGS OF THE 2016 SECOND CONFERENCE ON MOBILE AND SECURE SERVICES (MOBISECSERV)
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   YUAN Y, 2015, CS224D COURSE PROJEC
NR 38
TC 6
Z9 6
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34459
EP 34477
DI 10.1007/s11042-020-08818-5
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000521673400002
DA 2024-07-18
ER

PT J
AU Chouksey, M
   Jha, RK
   Sharma, R
AF Chouksey, Mausam
   Jha, Rajib Kumar
   Sharma, Rajat
TI A fast technique for image segmentation based on two Meta-heuristic
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Image segmentation; Antlion optimization;
   Multiverse optimization; Kapur's entropy and between class variance;
   Wilcoxon rank sum test
ID MOTH-FLAME OPTIMIZATION; DIFFERENTIAL EVOLUTION; MULTILEVEL; ENTROPY
AB Image segmentation is a primary task in image processing which is widely used in object detection and recognition. Multilevel thresholding is one of the prominent technique in the field of image segmentation. However, the computational cost of multilevel thresholding increases exponentially as the number of threshold value increases, which leads to use of meta-heuristic optimization to find the optimal number of threshold. To overcome this problem, this paper investigates the ability of two nature-inspired algorithms namely: antlion optimisation (ALO) and multiverse optimization (MVO). ALO is a population-based method and mimics the hunting behaviour of antlions in nature. Whereas, MVO is based on the multiverse theory which depicts that there is over one universe exist. These two metaheuristic algorithms are used to find the optimal threshold values using Kapur's entropy and Otsu's between class variance function. They examine the outcomes of the proposed algorithm with other evolutionary algorithms based on cost value, stability analysis, feature similarity index (FSIM), structural similarity index (SSIM), peak signal to noise ratio (PSNR), computational time. We also provide Wilcoxon test which justify the response of these parameters. The experimental results showed that the proposed algorithm gives better results than other existing methods. It is noticed that MVO is faster than other algorithms. The proposed method is also tested on medical images to detect the tumor from MRI T1-weighted contrast-enhanced brain images.
C1 [Chouksey, Mausam; Jha, Rajib Kumar] Indian Inst Technol, Dept Elect Engn, Patna 801103, Bihar, India.
   [Sharma, Rajat] Ajay Kumar Engn Coll, Dept Comp Sci & Technol, Ghaziabad 200109, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Chouksey, M (corresponding author), Indian Inst Technol, Dept Elect Engn, Patna 801103, Bihar, India.
EM mausam.chouksey11@gmail.com; jharajib@gmail.com
RI Chouksey, Mausam/AAZ-1972-2020
OI Chouksey, Mausam/0000-0003-4922-2387
FU Digital India Corporation (Formerly Media Lab Asia)
   [U72900MH2001NPL133410]; Ministry of Electronics & Information
   Technology, Government of India
FX This publication is an outcome of the R & D work supported by Digital
   India Corporation (Formerly Media Lab Asia) (Grant No.
   U72900MH2001NPL133410) under the Ministry of Electronics & Information
   Technology, Government of India.
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd ElAziz M, 2016, HYBRID SOFT COMPUTIN, P1, DOI DOI 10.1007/978-3-319-47223-2_1
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   Bhandari AK, 2016, EXPERT SYST APPL, V63, P112, DOI 10.1016/j.eswa.2016.06.044
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari A.K., 2018, IEEE Journal of Selected Topics in Applied Earth Observations Remote Sensing, P1
   Bhandari AK, 2020, NEURAL COMPUT APPL, V32, P4583, DOI 10.1007/s00521-018-3771-z
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bozorg-Haddad O, 2006, WATER RESOUR MANAG, V20, P661, DOI 10.1007/s11269-005-9001-3
   Cheng J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115339
   Choy SK, 2017, PATTERN RECOGN, V68, P141, DOI 10.1016/j.patcog.2017.03.009
   Cuevas E, 2010, EXPERT SYST APPL, V37, P5265, DOI 10.1016/j.eswa.2010.01.013
   DORIGO M, 2006, CP, V194
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gandomi AH, 2013, ENG COMPUT-GERMANY, V29, P245, DOI 10.1007/s00366-012-0308-4
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Ghamisi P, 2012, EXPERT SYST APPL, V39, P12407, DOI 10.1016/j.eswa.2012.04.078
   Gould Stephen., 2009, ADV NEURAL INFORM PR, P655
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D., 2005, Technical Report-TR06
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaur R, 2018, MULTIMED TOOLS APPL, P1
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Kotte S., 2016, AIN SHAMS ENG J
   Li LG, 2016, IEEE ACCESS, V4, P6438, DOI 10.1109/ACCESS.2016.2613940
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   Manikandan S, 2014, MEASUREMENT, V47, P558, DOI 10.1016/j.measurement.2013.09.031
   Martí R, 2011, APPL MATH SCI, V175, P1, DOI 10.1007/978-3-642-16729-4_1
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mousavirad SJ, 2017, EVOL INTELL, V10, P45, DOI 10.1007/s12065-017-0152-y
   Obaidullah SM, 2018, MULTIMED TOOLS APPL, V77, P1643, DOI 10.1007/s11042-017-4373-y
   Ruikar DD, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1176-x
   Saremi S, 2015, NEURAL COMPUT APPL, V26, P1257, DOI 10.1007/s00521-014-1806-7
   Sathya P., 2010, International Journal of Computer Science Issues, V7, P336
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   SAUNDERS DA, 1991, CONSERV BIOL, V5, P18, DOI 10.1111/j.1523-1739.1991.tb00384.x
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilcoxon Frank, 1970, SELECTED TABLES MATH, V1, P171, DOI [DOI 10.1002/9780471462422.EOCT, DOI 10.1007/SPRINGERREFERENCE_205698]
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Yang X.-S., 2010, ENG OPTIMIZATION INT, DOI DOI 10.1002/9780470640425
   Yang XS, 2010, RESEARCH AND DEVELOPMENT IN INTELLIGENT SYSTEMS XXVI, P209, DOI 10.1007/978-1-84882-983-1_15
   Yu JJQ, 2015, APPL SOFT COMPUT, V30, P614, DOI 10.1016/j.asoc.2015.02.014
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 53
TC 21
Z9 21
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19075
EP 19127
DI 10.1007/s11042-019-08138-3
EA MAR 2020
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520640600003
DA 2024-07-18
ER

PT J
AU Taheri, R
   Javidan, R
   Pooranian, Z
AF Taheri, Rahim
   Javidan, Reza
   Pooranian, Zahra
TI Adversarial android malware detection for mobile multimedia applications
   in IoT environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IoT Environment; Adversarial malware detection; Perturbing training set;
   Deep learning; IoT malware detection
AB In this paper, we propose two defense methods against adversarial attack to a malware detection system for mobile multimedia applications in IoT environments. They are Robust-NN and a combination of convolutional neural network and 1- nearest neighbors(C4N) which modify training data that has been poisoned by an adversarial attack. As a result, the trained machine learning model will be accurate and if the malicious program is entered by any IoT device, the model generates necessary alerts. We provide an explanation of the used attack method and the algorithms proposed to defend against this attack. In order to evaluate the suitability of the proposed defense methods, sufficient analysis is presented, i.e. Drebin, Contagio and Genome datasets which include benign and malware Android apps are applied to perform experiments. To confirm the effectiveness of the suggested defense algorithms, this paper compared their performance with two state-of-the-art defense algorithms used to detect adversarial samples, namely e2SAD and EAT. The experiments are performed on two types of API and Permission features from the mentioned datasets. The results confirm that accuracy rates of classification algorithms decrease to 40% after attack in some cases (related to Drebin dataset by reviewing API feature sets). Additionally, the accuracy rates increase to 94.94% and 96.03% by applying Robust-NN and C4N algorithms, respectively. Therefore, they are comparable with existing cutting-edge defense algorithms. Also, the adversarial attack increased the FPR to 45.81% which will be reduced to 4.84% and 4.15% using Robust-NN and C4N, respectively. Consequently, the proposed methods will be robust against adversarial attacks.
C1 [Taheri, Rahim; Javidan, Reza] Shiraz Univ Technol, Dept Comp Engn & Informat Technol, Shiraz, Iran.
   [Pooranian, Zahra] Univ Padua, Dept Math, SPRITZ, Padua, Italy.
C3 Shiraz University of Technology; University of Padua
RP Javidan, R (corresponding author), Shiraz Univ Technol, Dept Comp Engn & Informat Technol, Shiraz, Iran.
EM r.taheri@sutech.ac.ir; javidan@sutech.ac.ir; zahra@math.unipd.it
RI Javidan, Reza/L-2861-2019; Taheri, Rahim/AAL-9834-2020; Pooranian,
   Zahra/S-6654-2019; Taheri, Rahim/ABA-1175-2021
OI Javidan, Reza/0000-0002-7788-6597; Taheri, Rahim/0000-0002-4078-3105;
   Pooranian, Zahra/0000-0003-3767-0377; 
CR Arp D, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23247
   Bazrafshan Z, 2013, 2013 5TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P113, DOI 10.1109/IKT.2013.6620049
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P2815, DOI 10.1007/s11042-018-5853-4
   Chang T.-J., 2018, ARXIV181003739
   CHEN X, 2019, IEEE T INFORM FORENS
   Demetrio L., 2019, 3 ITALIAN C CYBER SE, V2315, P1
   Dinakarrao SMP, 2019, DES AUT TEST EUROPE, P776, DOI [10.23919/DATE.2019.8715057, 10.23919/date.2019.8715057]
   Dovom EM, 2019, J SYST ARCHITECT, V97, P1, DOI 10.1016/j.sysarc.2019.01.017
   FAN W, 2019, MULTIMED TOOLS APPL, P1
   Goodfellow I.J., 2014, ARXIV 14126572
   Ham HS, 2014, J APPL MATH, DOI 10.1155/2014/594501
   Hossain MS, 2019, INT J REMOTE SENS, V40, P3571, DOI 10.1080/01431161.2018.1547931
   Hu X, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P611
   Jeong ES, 2017, MULTIMED TOOLS APPL, V76, P18153, DOI 10.1007/s11042-016-4189-1
   Karbab EB, 2018, DIGIT INVEST, V24, pS48, DOI 10.1016/j.diin.2018.01.007
   LEI T, 2019, IEEE INTERNET THINGS
   Liu XL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040974
   Narudin FA, 2016, SOFT COMPUT, V20, P343, DOI 10.1007/s00500-014-1511-6
   Shaerpour K, 2013, J DIGIT FORENSICS SE, V8, P21
   Shen SG, 2018, IEEE INTERNET THINGS, V5, P1043, DOI 10.1109/JIOT.2018.2795549
   Su JW, 2018, P INT COMP SOFTW APP, P664, DOI 10.1109/COMPSAC.2018.10315
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Wang Z, 2018, IEEE ACCESS, V6, P38367, DOI [10.1109/ACCESS.2018.2854599, 10.1109/access.2018.2854599]
   Zhang M, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1105, DOI 10.1145/2660267.2660359
   Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16
NR 25
TC 14
Z9 14
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16713
EP 16729
DI 10.1007/s11042-020-08804-x
EA MAR 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000520640600002
DA 2024-07-18
ER

PT J
AU He, P
   Chang, XC
   Xu, XH
   Jing, TY
   Zhang, ZJ
AF He, Ping
   Chang, Xincheng
   Xu, Xiaohua
   Jing, Tianyu
   Zhang, Zhijun
TI Supervised local spline embedding for medical diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Manifold learning; Medical diagnosis; Dimension reductionn; Local spline
   embedding
ID PROJECTIONS; FACE
AB A common difficulty of intelligent medical diagnosis is the high dimensionality of medical data. Manifold learning provides an elegant way to solve this problem by mapping the high-dimensional data into the low-dimensional embedding. However, traditional manifold learning algorithms fail to fully utilize the supervised information in medical diagnosis. To overcome this problem, in this paper we propose a novel Supervised Local Spline Embedding (SLSE) algorithm, which incorporates the supervised information into the local spline manifold embedding. SLSE not only preserves the local neighborhood structure, but also utilizes the global manifold shape through spline interpolation. Moreover, SLSE leverages the supervised information by maximizing the inter-class scatterness and minimizing the intra-class scatterness in the low-dimensional embedding. The promising experimental results on real-world medical datasets illustrate the superiority of our proposed approach in comparison with the existing popular manifold learning algorithms.
C1 [He, Ping; Chang, Xincheng; Xu, Xiaohua; Jing, Tianyu; Zhang, Zhijun] Yangzhou Univ, Dept Comp Sci, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University
RP Xu, XH (corresponding author), Yangzhou Univ, Dept Comp Sci, Yangzhou, Jiangsu, Peoples R China.
EM arterx@gmail.com
FU Chinese National Natural Science Foundation [61402395, 61802336,
   61906100]; Natural Science Foundation of Jiangsu Province [BK20151314,
   BK20140492, BK20180822]; Natural Science Foundation of Education
   Department of Jiangsu Province [18KJB520040]; Jiangsu Overseas Research
   and Training Program for University Prominent Young and Middle-aged
   Teachers and Presidents; Jiangsu Government Scholarship for Overseas
   Studies
FX This work was supported in part by the Chinese National Natural Science
   Foundation under Grant Nos. 61402395, 61802336 and 61906100, Natural
   Science Foundation of Jiangsu Province under contracts BK20151314,
   BK20140492 and BK20180822, Jiangsu Overseas Research and Training
   Program for University Prominent Young and Middle-aged Teachers and
   Presidents, Jiangsu Government Scholarship for Overseas Studies, Natural
   Science Foundation of Education Department of Jiangsu Province under
   contract 18KJB520040.
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abuhasel Khaled A., 2015, Information Science and Applications, P801, DOI 10.1007/978-3-662-46578-3_95
   Azar AT, 2013, NEURAL COMPUT APPL, V23, P2387, DOI 10.1007/s00521-012-1196-7
   Balasubramanian M, 2002, SCIENCE, V295
   Cai D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P714
   Chang RF, 2003, ACAD RADIOL, V10, P189, DOI 10.1016/S1076-6332(03)80044-2
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   de Ridder D, 2003, LECT NOTES COMPUT SC, V2714, P333
   Duchon Jean, 1976, LECT NOTES MATH, V571, P85, DOI DOI 10.1007/BFB0086566
   Foster KR, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-94
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   He X., 2003, ADV NEURAL INFORM PR, P153
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   LAN R, 2019, IEEE ACCESS, P1
   Li HF, 2004, ADV NEUR IN, V16, P97
   Liu X, 2013, NEUROIMAGE, V83, P148, DOI 10.1016/j.neuroimage.2013.06.033
   Lou SJ, 2016, NEUROCOMPUTING, V173, P290, DOI 10.1016/j.neucom.2015.04.116
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   MAYORAZ E, 2004, MICROELECTRON COMPUT, V1607, P833
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Wang GQ, 2016, NEURAL PROCESS LETT, V43, P1, DOI 10.1007/s11063-014-9398-x
   Wang YH, 2019, IEEE ACCESS, V7, P10224, DOI [10.1109/ACCESS.2019.2891065, 10.1002/suco.201800261]
   Wang YL, 2019, IEEE T PATTERN ANAL, V41, P6, DOI 10.1109/TPAMI.2017.2780094
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Weng S, 2005, MED BIOL ENG COMPUT, V43, P410, DOI 10.1007/BF02345820
   Xiang SM, 2009, IEEE T KNOWL DATA EN, V21, P1285, DOI 10.1109/TKDE.2008.204
   Yang X, 2017, MED IMAGE ANAL, V42, P212, DOI 10.1016/j.media.2017.08.006
   Zhang JB, 2017, NEUROCOMPUTING, V260, P321, DOI 10.1016/j.neucom.2017.04.051
   Zhou Y, 2017, IEEE T CYBERNETICS, V47, P830, DOI 10.1109/TCYB.2016.2529299
NR 29
TC 0
Z9 0
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15025
EP 15042
DI 10.1007/s11042-019-08581-2
EA MAR 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000519864800001
DA 2024-07-18
ER

PT J
AU Khan, FA
   Butt, AUR
   Asif, M
   Ahmad, W
   Nawaz, M
   Jamjoom, M
   Alabdulkreem, E
AF Khan, Fakhri Alam
   Butt, Ateeq Ur Rehman
   Asif, Muhammad
   Ahmad, Waqar
   Nawaz, Muhammad
   Jamjoom, Mona
   Alabdulkreem, Eatedal
TI Computer-aided diagnosis for burnt skin images using deep convolutional
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Burnt skin images; Image mining; Segmentation; CAD; Image enhancement;
   Feature extraction; Classification; DCNN
ID CLASSIFICATION; DEPTH
AB Numerous patients died every year due to the leading causes of deaths all over the world and burn injuries are one of them. Burn injury cases are most viewed in low and middle-income countries (LMIC). Researchers show great interest to classify the burn into different depths through digital means. In Pakistan, at provisional level, it's really a significant issue to categorize the burn and its depths due to the non-availability of expert doctors and surgeons; hence the decision for the correct first treatment can't be made, so this may cause a serious issue later on. The main objectives of this research work are to segment the burn wounds and classification of burn depths into 1(st), 2(nd) and 3(rd) degrees respectively. A real-time dataset of burnt patients has been collected from the burn unit of Allied Hospital Faisalabad, Pakistan. The dataset used for this research task contains 450 images of all the three levels of burn depths. Segmentation of the burnt area was done by the use of Otsu's method of thresholding and feature vector was obtained through the use of statistical methods. We have used the Deep Convolutional Neural Network (DCNN) to estimate the burn depths. The network was trained by 65 percent of the images and the remaining 35 percent images were used for testing the accuracy of the classifier. The maximum average accuracy obtained by using the Deep Convolutional Neural Network (DCNN) classifier is reported round about 79.4% and these results are the best if we compare them with previous results. From the obtained results of this research work, non-expert doctors will be able to apply the correct first treatment for the quality evaluation of burn depths.
C1 [Khan, Fakhri Alam] Inst Management Sci, Ctr Excellence Data Sci CEDS IMSci, Peshawar, Pakistan.
   [Butt, Ateeq Ur Rehman] Natl Text Univ, Faisalabad, Punjab, Pakistan.
   [Asif, Muhammad; Ahmad, Waqar] Natl Text Univ, Dept Comp Sci, Faisalabad, Punjab, Pakistan.
   [Nawaz, Muhammad] Inst Management Sci, Peshawar, Pakistan.
   [Jamjoom, Mona] Princess Nora bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Alabdulkreem, Eatedal] Princess Nora bint Abdulrahman Univ, Riyadh, Saudi Arabia.
C3 National Textile University - Pakistan; National Textile University -
   Pakistan; Princess Nourah bint Abdulrahman University; Princess Nourah
   bint Abdulrahman University
RP Asif, M (corresponding author), Natl Text Univ, Faisalabad, Punjab, Pakistan.
EM fakhri.alam@imsciences.edu.pk; ateeqbutt13@live.com; asif@ntu.edu.pk;
   waqar@ntu.edu.pk; m.nawaz@imsciences.edu.pk; mmjamjoom@pnu.edu.sa;
   eaalabdulkareem@pnu.edu.sa
RI Khan, Fakhri Alam/GPP-4180-2022; Butt, Ateeq Ur Rehman/JBS-8483-2023;
   Asif, Muhammad/B-6072-2012; Asif, Muhammad/IQS-5311-2023; Jamjoom,
   Mona/AFW-3276-2022; Nawaz, Muhammad/AAA-8063-2019; Khan, Fakhri
   Alam/S-5340-2017
OI Butt, Ateeq Ur Rehman/0009-0006-1512-792X; Asif,
   Muhammad/0000-0003-1839-2527; Jamjoom, Mona/0000-0001-9149-2810; Nawaz,
   Muhammad/0000-0003-3658-694X; Khan, Fakhri Alam/0000-0002-9130-1874
CR Agarwal A, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P743, DOI 10.1109/TSP.2017.8076087
   Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   [Anonymous], 2012, 4 2011 BIOM ENG INT
   [Anonymous], BRAIN MRI TUMOR DETE
   Aslam M, 2017, Pak J Surg, V33, P87
   Badea MS, 2016, INT CONF COMM, P65, DOI 10.1109/ICComm.2016.7528325
   Baig-Ansari N, 2016, SEVERITY BURN ITS RE
   Batagelj B, 2017, INT J ARTS TECHNOL, V10, P206, DOI 10.1504/IJART.2017.086669
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Buttner A., 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8871727
   Calin MA, 2015, BURNS, V41, P118, DOI 10.1016/j.burns.2014.05.002
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Deepak L., 2012, 19 IEEE INT C HIGH P
   Ding H., 2018, J ENG SCI MEDICAL DI, V1, DOI DOI 10.1115/1.4040470
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Gupta G.K., 2014, Introduction to data mining with case studies
   Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028
   Havelaar AH, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001923
   Haynes H.J.G., 2017, FIRE LOSS US 2014
   Jan SN, 2018, BURNS, V44, P405, DOI 10.1016/j.burns.2017.08.020
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Kuan P., 2017, Journal of Telecommunication, Electronic and Computer Engineering (JTEC), V9, P15
   Kumar AS, 2016, INT J COMPUT APPL, V149
   Machhale K, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P60, DOI 10.1109/IIC.2015.7150592
   Moussa R, 2016, MID EAST CONF BIO, P125, DOI 10.1109/MECBME.2016.7745423
   Mukherjee R., 2014, BIOMED RES INT
   Poon CS, 2016, EARLY ASSESSMENT BUR
   Rehman Mobeen Ur, 2018, 2018 2nd International Conference on Engineering Innovation (ICEI), P81, DOI 10.1109/ICEI18.2018.8448814
   Sabeena B, DIAGNOSIS DETECTION
   Sawakare S, 2014, INT J RES EMERG SCI, V1, P13
   Serrano C, 2005, BURNS, V31, P275, DOI 10.1016/j.burns.2004.11.019
   Shah HU, 2017, PAK J SURG, V33, P64
   Shin JY, 2016, BURNS, V42, P1369, DOI 10.1016/j.burns.2016.03.012
   Singh N, 2017, 2017 2ND INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT), P100, DOI 10.1109/I2CT.2017.8226102
   Smolle C, 2017, BURNS, V43, P249, DOI 10.1016/j.burns.2016.08.013
   Soumya RS, 2016, INT CONF COMMUN SYST, P190, DOI 10.1109/CSN.2016.7824012
   Sutojo T, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P182, DOI 10.1109/ICITISEE.2017.8285491
   Suvarna Malini, 2013, International Journal of Computer Science & Information Technology, V5, P104, DOI 10.5121/ijcsit.2013.5109
   Tran H, 2015, Context-Aware Systems and Applications. ICCASA 2015, P233
   W. H. Organization, BURNS GEN CH
   Wada D, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P483, DOI 10.23919/SICE.2017.8105626
   World Health Organization, 2017, VIOL INJ PREV BURNS
   World Health Organization, 2018, A fact sheet about Burns
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
NR 44
TC 25
Z9 25
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34545
EP 34568
DI 10.1007/s11042-020-08768-y
EA MAR 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000520701600002
DA 2024-07-18
ER

PT J
AU Bounik, Z
   Shamsi, M
   Sedaaghi, LMH
AF Bounik, Zahra
   Shamsi, Mousa
   Sedaaghi, Mohammad Hossein L.
TI Accurate coarse soft tissue modeling using FEM-based fine simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft tissue modelling; Physically-based simulation; Finite element
   method; Coarse and fine models; Deformation
ID DEFORMATIONS; ANIMATION
AB Finite element method is a well-known approach in soft tissue modeling. However, it introduces nonconforming deformations for a soft tissue in different resolutions in response to the same applied force. These deformations make the approach inefficient in data-driven enrichment schemes which demand more accurate conforming models of an object in both low and high resolutions at the same time. This paper presents two methods based on (1) Sampling and (2) Barycentric mapping to overcome this problem and to generate geometrically conforming deformations in different resolutions. In proposed methods, first, the soft tissue is modeled in high resolution by using finite element method to achieve the desired accuracy. The coordinates of this accurate model are then used to find the corresponding coordinates of the coarse model. This step is done by using either Sampling or Barycentric mapping. Quantitative evaluation of the simulation results confirms the efficiency of suggested methods in modeling geometrically conforming soft tissues in different resolutions.
C1 [Bounik, Zahra; Sedaaghi, Mohammad Hossein L.] Sahand Univ Technol, Fac Elect Engn, Tabriz, Iran.
   [Shamsi, Mousa] Sahand Univ Technol, Fac Biomed Engn, Tabriz, Iran.
C3 Sahand University of Technology; Sahand University of Technology
RP Shamsi, M (corresponding author), Sahand Univ Technol, Fac Biomed Engn, Tabriz, Iran.
EM z_bounik@sut.ac.ir; shamsi@sut.ac.ir; sedaaghi@sut.ac.ir
CR Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   BARBIC J., 2012, ACM Trans. Graph, V31, p70:1, DOI DOI 10.1145/2185520.2185566
   Bell N., 2005, P 2005 ACM SIGGRAPH, P77, DOI DOI 10.1145/1073368.1073379
   BroNielsen M, 1996, COMPUT GRAPH FORUM, V15, pC57
   Capell S., 2002, P 2002 ACM SIGGRAPHE, P41
   Chen D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073669
   Chen Y., 2018, PICTURE CODING S PCS, P5
   Cotin S, 1999, IEEE T VIS COMPUT GR, V5, P62, DOI 10.1109/2945.764872
   Debunne G, 1999, SPRING COMP SCI, P133
   Delingette F, 2004, HDBK NUM AN, V12, P453
   Der KG, 2006, ACM T GRAPHIC, V25, P1174, DOI 10.1145/1141911.1142011
   Etzmuss O, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P244, DOI 10.1109/PCCGA.2003.1238266
   Faure F., 2012, Studies in Mechanobiology, Tissue Engineering and Biomaterials,, V11, P283, DOI [DOI 10.1007/8415_2012_125, DOI 10.1007/84152012125]
   Feng WW, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778845
   Fulton L, 2019, COMPUT GRAPH FORUM, V38, P379, DOI 10.1111/cgf.13645
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   Kharevych L, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1531326.1531357, 10.1145/15313261531357]
   Kim M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073685
   Koch R.M., 1996, TECHNISCHEN BERICHTE, P246
   Liu H.T.D., 2019, SPECTRAL COARSENING
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma WC, 2012, COMPUT ANIMAT VIRT W, V23, P235, DOI 10.1002/cav.1441
   Müller M, 2004, PROC GRAPH INTERF, P239
   Nedel LP, 1998, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P156, DOI 10.1109/CGI.1998.694263
   Nesme M., 2005, EUROGRAPHICS
   Nesme M., 2006, VRIPHYS
   Nesme M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531358
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Seiler M., 2012, P ACM SIGGRAPH EUR S, P9
   Seiler M, 2014, IEEE T VIS COMPUT GR, V20, P1379, DOI 10.1109/TVCG.2014.2317192
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Torres R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982414
   Xu HY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699648
   Zhou JY, 2018, COMPUT METH PROG BIO, V153, P237, DOI 10.1016/j.cmpb.2017.09.008
   Zou YN, 2017, COMPUT METH PROG BIO, V148, P113, DOI 10.1016/j.cmpb.2017.06.013
   Zurdo JS, 2013, IEEE T VIS COMPUT GR, V19, P149, DOI 10.1109/TVCG.2012.79
NR 37
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7121
EP 7134
DI 10.1007/s11042-019-08532-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100010
DA 2024-07-18
ER

PT J
AU Guo, X
   Xiao, N
   Zhang, LK
AF Guo, Xin
   Xiao, Ning
   Zhang, Likun
TI Sequential binary code selection for robust object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust object tracking; Sequential binary code selection
AB The appearance model, which is required to be adaptive to the non-stationary environment, is the essential step in object tracking but normally suffers from imbalance between effectiveness and efficiency. In this paper, a novel method named as sequential binary code selection (SBC) is proposed to learn a set of compact binary codes for image patch representation. Using the sparse projections, the high dimensional feature can be speedily embedded into the compact binary codes with preserving both the label information and geometrical distance. By the sequential learning, the latter learned binary code which corrects the errors made by the previous codes is more discriminative to the present environment. Furthermore, though binary code selection, the most compact and least redundant hash codes from the candidate pool will be selected and kept. Experimental results illustrate the effectiveness of the SBC, as well as the state-of-the-art tracking performance of the proposed approach.
C1 [Guo, Xin; Xiao, Ning; Zhang, Likun] Beijing Anrui Zhongxing Technol Co Ltd, Beijing, Peoples R China.
RP Guo, X (corresponding author), Beijing Anrui Zhongxing Technol Co Ltd, Beijing, Peoples R China.
EM guoxin.jn@139.com; xiaoning006@sina.com; zlklingdang@163.com
RI Zhang, Likun/A-2742-2011
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], 2013, P CVPR
   [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], 1999, P INT C VER LARG DAT
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chen K, 2017, INFORM SCIENCES, V394, P232, DOI 10.1016/j.ins.2017.02.012
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Gao J, 2013, P ICCV
   He J, 2011, P CVPR
   Henriques J. F., 2012, P ECCV
   Jin Z, 2013, P ICCV
   JOHNSON W, 1982, C MOD AN PROB
   Kulis B, 2009, IEEE T TPAMI
   Kwon J., 2011, P ICCV
   Kwon J, 2010, P CVPR
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li P., 2006, P ACM SIGKDD INT C K, P287
   Lin G., 2013, P ICCV
   Liu H., 2010, P ICML
   Luenberger DG, 2008, INT SER OPER RES MAN, V116, P1
   Mei X., 2009, P ICCV
   Mu YD, 2012, INT J MULTIMED INF R, V1, P59, DOI 10.1007/s13735-012-0003-7
   Oron S, 2012, P CVPR
   Pavan M, 2007, IEEE T TPAMI, V29
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang J., 2010, P ICML
   Wang J, 2012, IEEE TANSACTIONS TPA
   Weibull J. W., 1997, EVOLUTIONARY GAME TH
   Weiss Y., 2008, P NIPS, P1
   Wu Y., 2013, P CVPR
   Yi SH, 2016, INFORM SCIENCES, V364, P33, DOI 10.1016/j.ins.2016.05.019
   Zhang K., 2012, P ECCV
   Zhang T., 2012, P CVPR
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhong Wei, 2012, P CVPR
NR 38
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 6951
EP 6963
DI 10.1007/s11042-019-08258-w
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100002
DA 2024-07-18
ER

PT J
AU Ilhan, HO
   Aydin, N
AF Ilhan, Hamza Osman
   Aydin, Nizamettin
TI Smartphone based sperm counting-an alternative way to the visual
   assessment technique in sperm concentration analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computerized sperm counting; Smartphone aided diagnosis systems; Sperm
   concentration analysis; Computer aided semen analysis; Biomedical image
   processing
ID AUTOMATIC DETECTION; ACROSOME INTEGRITY; SEMEN; SYSTEM; IMAGES;
   MOTILITY; SEGMENTATION; FRAMEWORK; CHAMBERS; CONTOURS
AB Sperm Counting is the first phase of the infertility diagnosis. Computer Aided Sperm Analysis (CASA) and Visual Assessment (VA) are two evaluation techniques employed in analyses. VA is carried out by observing sperm on counting chambers. Therefore, diagnosis strongly depends on the skills and experiences. CASA isolates the human factor by utilizing the computer based techniques. However, it is more costly than VA and requires exhausted parameter settings. In this study, we present a novel approach that uses smartphone and computer for sperm counting analysis. Smartphone is used to obtain images similar to VA technique. Then, sample videos are transferred to the computer side where we developed the Computerized Sperm Counting Software (CSCS) to count the sperm using counting chambers and eliminate human effects. CSCS consists of four modules: (1) Data Acquisition and Organization, (2) Regions of Interest (ROI) detection, (3) Motile/Immotile Sperm Detection, (4) Counting. Smartphone based data acquisition provided less costly design contrary to CASA systems. ROI extraction was realized by a combinational approach of line detection and segmentation methods. Background and Foreground extractions were employed in immotile and motile sperm detection process, respectively. Additionally, active contour was implemented to enhance the segmentation of immotile sperm. As the final step, detected sperms were counted by pixel based blob analysis. According to experimental results, the proposed smartphone based sperm concentration analysis can be adapted in laboratories due to its modularity, functionality, accuracy and cost when compare to CASA and VA based sperm counting analysis.
C1 [Ilhan, Hamza Osman; Aydin, Nizamettin] YTU, Dept Comp Engn, TR-34220 Istanbul, Turkey.
C3 Yildiz Technical University
RP Ilhan, HO (corresponding author), YTU, Dept Comp Engn, TR-34220 Istanbul, Turkey.
EM hoilhan@yildiz.edu.tr
RI AYDIN, Nizamettin/AAZ-6030-2020; ilhan, hamza osman/V-5453-2017
OI AYDIN, Nizamettin/0000-0003-0022-2247; ilhan, hamza
   osman/0000-0002-1753-2703
CR Abbiramy V. S., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P265, DOI 10.1109/ICSIP.2010.5697481
   Alegre E, 2013, COMPUT METH PROG BIO, V111, P525, DOI 10.1016/j.cmpb.2013.05.003
   Alegre E, 2012, COMPUT METH PROG BIO, V108, P873, DOI 10.1016/j.cmpb.2012.01.004
   Amann RP, 2014, THERIOGENOLOGY, V81, P5, DOI 10.1016/j.theriogenology.2013.09.004
   [Anonymous], AUTOMATED SEMEN ANAL
   Baazaoui A, 2017, IRBM, V38, P98, DOI 10.1016/j.irbm.2017.02.003
   Bijar A., 2012, Journal of Biomedical Science and Engineering, V5, P384, DOI [DOI 10.4236/JBISE.2012.57049, 10.4236/jbise.2012.57049]
   Bjorndahl L., 2010, PRACTICAL GUIDE BASI
   Björndahl L, 2016, HUM REPROD, V31, P227, DOI 10.1093/humrep/dev305
   Boryshpolets S, 2013, THERIOGENOLOGY, V80, P758, DOI 10.1016/j.theriogenology.2013.06.019
   CARLSEN E, 1992, BRIT MED J, V305, P609, DOI 10.1136/bmj.305.6854.609
   Carrillo H, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P1152
   Centola GM, 2014, UROL CLIN N AM, V41, P163, DOI 10.1016/j.ucl.2013.08.007
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang V, 2014, COMPUT METH PROG BIO, V117, P225, DOI 10.1016/j.cmpb.2014.06.018
   García-Olalla O, 2015, COMPUT METH PROG BIO, V120, P49, DOI 10.1016/j.cmpb.2015.03.005
   Ghasemian F, 2015, COMPUT METH PROG BIO, V122, P409, DOI 10.1016/j.cmpb.2015.08.013
   Hardy GH, 1918, P LOND MATH SOC, V17, P75
   Ilhan H., 2017, 2017 MED TECHN NAT C, P1
   Ilhan H, 2019, ELECT LETT
   Ilhan HO, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P658, DOI 10.1109/UBMK.2018.8566489
   Ilhan HO, 2018, CURR MED IMAGING, V14, P981, DOI 10.2174/1573405613666170607150203
   Ilhan HO, 2018, BIOMED SIGNAL PROCES, V41, P129, DOI 10.1016/j.bspc.2017.11.009
   Kathiravan P, 2011, REPROD DOMEST ANIM, V46, P165, DOI 10.1111/j.1439-0531.2010.01603.x
   Keel BA., 1990, HDB LAB DIAGNOSIS TR
   Liu J, 2013, IEEE T BIO-MED ENG, V60, P390, DOI 10.1109/TBME.2012.2227319
   Lu JC, 2014, ANDROLOGIA, V46, P329, DOI 10.1111/and.12093
   Mahmoud AMA, 1997, FERTIL STERIL, V68, P340, DOI 10.1016/S0015-0282(97)81526-9
   Makler A, 1997, FERTIL STERIL, V67, P978, DOI 10.1016/S0015-0282(97)90145-X
   Möller M, 2014, J VIS COMMUN IMAGE R, V25, P396, DOI 10.1016/j.jvcir.2013.12.002
   Oku H, 2008, IEEE ENG MED BIO, P125, DOI 10.1109/IEMBS.2008.4649106
   Patel B, 2012, INT J COMPUT SCI NET, V12, P100
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Qiaoliang Li, 2012, 2012 5th International Conference on BioMedical Engineering and Informatics (BMEI), P224, DOI 10.1109/BMEI.2012.6513003
   Rittscher J., 2008, Microscopic image analysis for life science applications
   Savkay O. L., 2012, 2012 13 INT WORKSH C, P1
   Seaman EK, 1996, FERTIL STERIL, V66, P662, DOI 10.1016/S0015-0282(16)58587-2
   Shaker F, 2016, COMPUT METH PROG BIO, V132, P11, DOI 10.1016/j.cmpb.2016.04.026
   Shi LZ, 2008, BIOMED MICRODEVICES, V10, P573, DOI 10.1007/s10544-008-9169-4
   Suwen Qi, 2019, 2019 International Conference on Systems, Signals and Image Processing (IWSSIP). Proceedings, P163, DOI 10.1109/IWSSIP.2019.8787312
   Swan SH, 2000, ENVIRON HEALTH PERSP, V108, P961, DOI 10.2307/3435055
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Wilson-Leedy JG, 2007, THERIOGENOLOGY, V67, P661, DOI 10.1016/j.theriogenology.2006.10.003
   Witkowski L, 2013, BIOCYBERN BIOMED ENG, V33, P179, DOI 10.1016/j.bbe.2013.07.007
   World Health Organization, 2010, WHO LAB MAN EX HUM S
   WU KN, 1995, IEEE T BIO-MED ENG, V42, P1, DOI 10.1109/10.362924
NR 46
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6409
EP 6435
DI 10.1007/s11042-019-08421-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900043
DA 2024-07-18
ER

PT J
AU Kumar, N
   Sukavanam, N
AF Kumar, N.
   Sukavanam, N.
TI A cascaded CNN model for multiple human tracking and re-localization in
   complex video sequences with large displacement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human tracking; Re-localization; Cascading of networks; Convolutional
   neural network; Semi-synthesized dataset
ID VISUAL TRACKING; OBJECT TRACKING
AB Human tracking and localization play a crucial role in many applications like accident avoidance, action recognition, safety and security, surveillance and crowd analysis. Inspired by its use and scope, we introduced a novel method for human tracking (one or many) and re-localization in a complex environment with large displacement. The model can handle complex background, variations in illumination, changes in target pose, the presence of similar target and appearance (pose and clothes), the motion of target and camera, occlusion of the target, background variation, and massive displacement of the target. Our model uses three convolutional neural network based deep architecture and cascades their learning such that it improves the overall efficiency of the model. The first network learns the pixel level representation of small regions. The second architecture uses these features and learns the displacement of a region with its category between moved, not-moved, and occluded classes. Whereas, the third network improves the displacement result of the second network by utilizing the previous two learning. We also create a semi-synthetic dataset for training purpose. The model is trained on this dataset first and tested on a subset of CamNeT, VOT2015, LITIV-tracking and Visual Tracker Benchmark database without training with real data. The proposed model yield comparative results with respect to current state-of-the-art methods based on evaluation criteria described in Object Tracking Benchmark, TPAMI 2015, CVPR 2013 and ICCV 2017.
C1 [Kumar, N.; Sukavanam, N.] IIT Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kumar, N (corresponding author), IIT Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM naresh7iit@gmail.com; nsukvfma@iitr.ac.in
RI Kumar, Naresh/AAL-8323-2021
OI Kumar, Naresh/0000-0001-7802-0026
CR [Anonymous], 2017, VISUAL TRACKER BENCH
   [Anonymous], 2017, COMPUTER VISION PATT
   [Anonymous], 2016, CVPR
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2017, LITIV DATASETS
   [Anonymous], 2016, ARXIV160805442
   [Anonymous], 2012, CoRR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bouachir W, 2015, COMPUT VIS IMAGE UND, V137, P88, DOI 10.1016/j.cviu.2015.03.010
   Chen K., 2018, IEEE T MULTIMED
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Dauphin YN, 2015, ADV NEUR IN, V28
   Fan H., 2017, P IEEE C COMP VIS PA, P42
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Fang K., 2017, ARXIV171102741
   Gan WH, 2018, SIGNAL PROCESS-IMAGE, V66, P95, DOI 10.1016/j.image.2018.05.008
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Laaroussi K, 2016, PROCEEDINGS OF THE M, P297
   Laaroussi K, 2018, MULTIMED TOOLS APPL, V77, P13947, DOI 10.1007/s11042-017-5000-7
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   Lu X, 2018, PATTERN RECOGN LETT
   Ma CQ, 2020, IEEE T SYST MAN CY-S, V50, P1976, DOI 10.1109/TSMC.2018.2819703
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Takada H, 2016, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2016.7899899
   Wang D, 2016, MULTIMED TOOLS APPL, V75, P11865, DOI 10.1007/s11042-015-2665-7
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiao H, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P192, DOI 10.1145/3240508.3240539
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zheng YD, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/7/070302
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 41
TC 11
Z9 11
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6109
EP 6134
DI 10.1007/s11042-019-08501-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900031
DA 2024-07-18
ER

PT J
AU Liu, HH
   Li, L
   Lu, S
   Zhang, KX
   Liu, XX
AF Liu, Honghao
   Li, Liang
   Lu, Shan
   Zhang, Kaixing
   Liu, Xianxi
TI 3D model similarity evaluation for mechanical design reuse based on
   spatial correlated shape-word clique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model; Design reuse; Partial feature; Topological correlation; Model
   retrieval
ID OBJECT RETRIEVAL; BAG; ALGORITHM
AB A novel 3D model similarity evaluation method is proposed to improve the model retrieval accuracy. The bag of words (BoW) method is widely used for 3D model evaluation, in which all the partial features are regarded as independent and disordered. However, 3D model shape diversity is characterized by the spatial differences between partial features. Based on the BoW method, the hidden spatial correlation that could be used to enrich model feature descriptors was analyzed. Given a 3D model, the method begins by building a spatial-relation graph to record the spatial relations. The feature graph is then converted and deconstructed, so that the shape-word cliques hidden in the graph can be revealed. Thereafter, the 3D model similarity evaluation is transformed into the similarity calculation with its corresponding shape-word clique histograms. The ESB benchmark and an agricultural model dataset were used to test the retrieval results. The results show that the proposed method has higher retrieval accuracy, which could satisfy the practical retrieval requirements.
C1 [Liu, Honghao; Lu, Shan; Zhang, Kaixing; Liu, Xianxi] Shandong Agr Univ, Coll Mech & Elect Engn, Tai An 271018, Shandong, Peoples R China.
   [Li, Liang] China Airborne Missile Acad, Luoyang 471000, Peoples R China.
C3 Shandong Agricultural University
RP Zhang, KX (corresponding author), Shandong Agr Univ, Coll Mech & Elect Engn, Tai An 271018, Shandong, Peoples R China.
EM mobeikehan@126.com; kaixingzhang@139.com
CR Bahmanyar R, 2015, IEEE GEOSCI REMOTE S, V12, P1357, DOI 10.1109/LGRS.2015.2402391
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Cao CH, 2016, TECHNOL HEALTH CARE, V24, pS665, DOI 10.3233/THC-161194
   Cao JW, 2016, MULTIMED TOOLS APPL, V75, P2839, DOI 10.1007/s11042-014-2424-1
   Corcoran P, 2012, ISPRS INT J GEO-INF, V1, P333, DOI 10.3390/ijgi1030333
   Deng Y, 2012, APPL SOFT COMPUT, V12, P1231, DOI 10.1016/j.asoc.2011.11.011
   Ding K, 2014, MULTIMED TOOLS APPL, V72, P2701, DOI 10.1007/s11042-013-1560-3
   Furuya T, 2018, COMPUT VIS IMAGE UND, V166, P102, DOI 10.1016/j.cviu.2017.11.007
   Han ZZ, 2017, IEEE T IMAGE PROCESS, V26, P3707, DOI 10.1109/TIP.2017.2704426
   Huangfu ZM, 2017, MULTIMED TOOLS APPL, V76, P8145, DOI 10.1007/s11042-016-3456-5
   Jayanti S, 2009, COMPUT AIDED DESIGN, V41, P999, DOI 10.1016/j.cad.2009.07.003
   Ji Z, 2015, INFORM SCIENCES, V302, P83, DOI 10.1016/j.ins.2014.10.037
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003
   Kim HK, 2017, NEUROCOMPUTING, V266, P336, DOI 10.1016/j.neucom.2017.05.046
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lavoué G, 2012, VISUAL COMPUT, V28, P931, DOI 10.1007/s00371-012-0724-x
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li L, 2013, INT C COMP AID DES C, P172, DOI 10.1109/CADGraphics.2013.30
   Li Z, 2015, COMPUT AIDED DESIGN, V62, P190, DOI 10.1016/j.cad.2014.05.008
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Rantoson R, 2018, COMPUT VIS IMAGE UND, V167, P89, DOI 10.1016/j.cviu.2017.08.004
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Sfikas K, 2013, VISUAL COMPUT, V29, P1351, DOI 10.1007/s00371-013-0876-3
   Sfikas K, 2011, INT J COMPUT VISION, V91, P262, DOI 10.1007/s11263-010-0395-x
   Tao SQ, 2012, PATTERN RECOGN, V45, P1721, DOI 10.1016/j.patcog.2011.09.017
   Wang F, 2014, GRAPH MODELS, V76, P128, DOI 10.1016/j.gmod.2013.11.002
   Wang JY, 2011, IEEE T MED IMAGING, V30, P1996, DOI 10.1109/TMI.2011.2161673
   Xiong LS, 2016, INT J ADV MANUF TECH, V82, P889, DOI 10.1007/s00170-015-7165-4
   Yang JB, 2018, NEUROCOMPUTING, V275, P1, DOI 10.1016/j.neucom.2017.01.030
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhuo L, 2014, NEUROCOMPUTING, V141, P202, DOI 10.1016/j.neucom.2014.03.014
   Zou KS, 2011, ELECTRON LETT, V47, P796, DOI 10.1049/el.2011.0012
NR 33
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8181
EP 8195
DI 10.1007/s11042-019-08315-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100059
DA 2024-07-18
ER

PT J
AU Watson, G
   Bhalerao, A
AF Watson, Gregory
   Bhalerao, Abhir
TI Person re-identification combining deep features and attribute detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Attributes; Deep learning; Convolutional
   neural networks
AB Attributes-Based Re-Identification is a way of identifying individuals when presented with multiple pictures taken under varying conditions. The method typically builds a classifier to detect the presence of certain appearance characteristics in an image, and creates feature descriptors based on the output of the classifier. We improve attribute detection through spatial segregation of a person's limbs using a skeleton prediction method. After a skeleton has been predicted, it is used to crop the image into three parts - top, middle and bottom. We then pass these images to an attribute prediction network to generate robust feature descriptors. We evaluate the performance of our method on the VIPeR, PRID2011 and i-LIDS data sets, comparing our results against the state-of-the-art to demonstrate competitive overall matching performance.
C1 [Watson, Gregory; Bhalerao, Abhir] Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
C3 University of Warwick
RP Watson, G (corresponding author), Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
EM g.a.watson@warwick.ac.uk; Abhir.Bhalerao@warwick.ac.uk
OI Watson, Gregory/0000-0002-5195-6817
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2008, P 19 BRIT MACH VIS C
   [Anonymous], 2008, I LIDS MULT CAM TRAC
   [Anonymous], 2016, Tensorpack
   [Anonymous], ARXIV150401942
   Baltieri D, 2011, LECT NOTES COMPUT SC, V6978, P197, DOI 10.1007/978-3-642-24085-0_21
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Benfold B., 2009, P 20 BRIT MACH VIS C
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Dai J, 2018, PATTERN RECOGN, V75, P63, DOI 10.1016/j.patcog.2017.04.022
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Dong H, 2015, DIS MARKERS, V2015, DOI 10.1155/2015/625659
   Elkan C., 2001, IJCAI 2001, V17, P973, DOI DOI 10.5555/1642194.1642224
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Kingma D. P., 2014, arXiv
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Li D, 2017, INT SYM COMPUT INTEL, P338, DOI 10.1109/ISCID.2017.51
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao S., 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, P1301, DOI DOI 10.1109/CVPR.2010.5539817
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu J, 2015, LECT NOTES COMPUT SC, V9314, P591, DOI 10.1007/978-3-319-24075-6_57
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Reddi S. J., 2018, INT C LEARN REPR
   Sharma S, 2018, IEEE DATA MINING, P447, DOI 10.1109/ICDM.2018.00060
   Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005
   Su C, 2017, PATTERN RECOGN, V66, P4, DOI 10.1016/j.patcog.2017.01.006
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Su C, 2015, IEEE I CONF COMP VIS, P3739, DOI 10.1109/ICCV.2015.426
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Wang Z, 2016, IEEE T MULTIMEDIA, V18, P260, DOI 10.1109/TMM.2015.2505083
   Watson G, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051215
   Watson G, 2017, LECT NOTES COMPUT SC, V10485, P25, DOI 10.1007/978-3-319-68548-9_3
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Wu QY, 2020, SUBST ABUS, V41, P493, DOI 10.1080/08897077.2019.1675117
   Xu JM, 2012, GLOB CONGRESS INTELL, P394, DOI 10.1109/GCIS.2012.70
   Ye X, 2019, NEURAL PROCESS LETT, V49, P1111, DOI 10.1007/s11063-018-9887-4
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
NR 54
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6463
EP 6481
DI 10.1007/s11042-019-08499-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900046
DA 2024-07-18
ER

PT J
AU Yu, HP
   He, FZ
   Pan, YT
AF Yu, Haiping
   He, Fazhi
   Pan, Yiteng
TI A scalable region-based level set method using adaptive bilateral filter
   for noisy image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Bilateral filter; Range-based; Active contour model
ID ACTIVE CONTOUR MODEL; BLOOD-VESSEL SEGMENTATION; LOCALIZING REGION;
   FITTING ENERGY; FRAMEWORK; DRIVEN; EFFICIENT; FUSION; SCHEME
AB Image segmentation plays an important role in the computer vision . However, it is extremely challenging due to low resolution, high noise and blurry boundaries. Recently, region-based models have been widely used to segment such images. The existing models often utilized Gaussian filtering to filter images, which caused the loss of edge gradient information. Accordingly, in this paper, a novel local region model based on adaptive bilateral filter is presented for segmenting noisy images. Specifically, we firstly construct a range-based adaptive bilateral filter, in which an image can well be preserved edge structures as well as resisted noise. Secondly, we present a data-driven energy model, which utilizes local information of regions centered at each pixel of image to approximate intensities inside and outside of the circular contour. The estimation approach has improved the accuracy of noisy image segmentation. Thirdly, under the premise of keeping the image original shape, a regularization function is used to accelerate the convergence speed and smoothen the segmentation contour. Experimental results of both synthetic and real images demonstrate that the proposed model is more efficient and robust to noise than the state-of-art region-based models.
C1 [Yu, Haiping; He, Fazhi; Pan, Yiteng] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Yu, Haiping] Wuhan Univ Sci & Technol, City Coll, Wuhan, Peoples R China.
C3 Wuhan University; Wuhan University of Science & Technology
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
EM seaping@whu.edu.cn; fzhe@whu.edu.cn; panyiteng@whu.edu.cn
RI Pan, Yi/AAJ-2341-2021; He, Fazhi/Q-3691-2018
CR Allner S, 2016, PHYS MED BIOL, V61, P3867, DOI 10.1088/0031-9155/61/10/3867
   Casciaro S, 2008, J MATER SCI-MATER M, V19, P899, DOI 10.1007/s10856-007-3007-8
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chen D, 2019, IEEE T IMAGE PROCESS, V28, P1271, DOI 10.1109/TIP.2018.2874282
   Chen SQ, 2018, ADV HEALTHC MATER, V7, DOI 10.1002/adhm.201800485
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Ciecholewski M, 2016, EXPERT SYST APPL, V44, P22, DOI 10.1016/j.eswa.2015.09.013
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fu HZ, 2016, I S BIOMED IMAGING, P698, DOI 10.1109/ISBI.2016.7493362
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Ghoshal R, 2019, MULTIMED TOOLS APPL, V78, P25221, DOI 10.1007/s11042-019-7719-9
   Guo S., 2018, arXiv:1803.03963, P1
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Heshmati A, 2016, IET IMAGE PROCESS, V10, P464, DOI 10.1049/iet-ipr.2015.0738
   Hou N, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8184-3
   Huazhu Fu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P132, DOI 10.1007/978-3-319-46723-8_16
   Jeon G, 2016, J REAL-TIME IMAGE PR, V11, P223, DOI 10.1007/s11554-013-0336-3
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li HR, 2019, APPL MATH SER B, V34, P1, DOI 10.1007/s11766-019-3706-1
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu SH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S021800141759008X
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Long CC, 2018, IEEE T MULTIMEDIA, V20, P1126, DOI 10.1109/TMM.2017.2764330
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Memon KH, 2017, IET IMAGE PROCESS, V11, P1, DOI 10.1049/iet-ipr.2016.0282
   Ni B, 2016, APPL MATH SER B, V31, P37, DOI 10.1007/s11766-016-3340-0
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Sun B, 2018, MULTIMED TOOLS APPL, P1
   Wang B, 2010, IEEE T SYST MAN CY B, V40, P857, DOI 10.1109/TSMCB.2009.2031090
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yang P, 2018, IEEE T IND INFORM, V14, P1347, DOI 10.1109/TII.2017.2731362
   Yang ZY, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P277, DOI 10.1109/CLOUD.2018.00042
   Yong JS, 2019, APPL MATH SER B, V34, P480, DOI 10.1007/s11766-019-3714-1
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Yu HP, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0100
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang J, 2020, MULTIMED TOOLS APPL, V79, P2085, DOI 10.1007/s11042-019-08399-y
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang L, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540155
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
   Zhao YT, 2017, NEUROCOMPUTING, V259, P201, DOI 10.1016/j.neucom.2016.07.077
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhou Y, 2015, NEUROCOMPUTING, V156, P199, DOI 10.1016/j.neucom.2014.12.061
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 69
TC 89
Z9 90
U1 0
U2 78
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5743
EP 5765
DI 10.1007/s11042-019-08493-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900014
DA 2024-07-18
ER

PT J
AU Padmapriya, VM
   Thenmozhi, K
   Praveenkumar, P
   Amirtharajan, R
AF Padmapriya, V. M.
   Thenmozhi, K.
   Praveenkumar, Padmapriya
   Amirtharajan, Rengarajan
TI ECC joins first time with SC-FDMA for Mission "security"
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform (DWT); Elliptic curve cryptography (ECC);
   Inverse wavelet transform; Single carrier frequency division multiple
   access
ID ELLIPTIC CURVE CRYPTOGRAPHY; ENCRYPTION
AB The recent advancements in the internet technology have created the urgency in developing critical data security framework around the globe. One of the most shared multimedia objects is the image which is safeguarded through a task called image encryption. An integrated approach to image encryption is the need of the hour which can combine algorithm and communication model. In this context, this work presents the first- of- its- kind approach addressing Elliptic Curve Cryptography (ECC) to encrypt and decrypt the images to enhance their security during transmission via Single Carrier Frequency Division Multiple Access (SC-FDMA) communication systems. The uniqueness of this work is to combine the encryption scheme and subsequent wireless transmission. Modified Huffman coding has been employed to achieve compression. The viability of the proposed approach was tested and the performance metrics namely Entropy, PSNR, Histogram, correlation coefficient, differential attack, NIST test, and occulation attack analyses were evaluated. The simulation results prove the efficiency of the proposed integrated encryption - compression - communication schema.
C1 [Padmapriya, V. M.; Thenmozhi, K.; Praveenkumar, Padmapriya; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Dept Elect & Commun Engn, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Dept Elect & Commun Engn, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI praveenkumar, padmapriya/AAH-9426-2019; Amirtharajan,
   Rengarajan/C-6471-2011
OI praveenkumar, padmapriya/0000-0001-8483-1538; Amirtharajan,
   Rengarajan/0000-0003-1574-3045; meikandan,
   Padmapriya/0000-0003-0618-7200; Karuppuswamy,
   Thenmozhi/0000-0001-9829-0189
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Babaheidarian P, 2012, INT ISC CONF INFO SE, P111, DOI 10.1109/ISCISC.2012.6408200
   Bharti SS, 2019, MULTIMED TOOLS APPL, V78, P23179, DOI 10.1007/s11042-019-7630-4
   Bharti SS, 2018, MULTIMED TOOLS APPL, V77, P25629, DOI 10.1007/s11042-018-5810-2
   Britto J, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P791, DOI 10.1109/ISS1.2017.8389285
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Gupta K, 2009, 2009 1ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS(CICSYN 2009), P342, DOI 10.1109/CICSYN.2009.33
   Hu ZY, 2018, IEEE PHOTONIC TECH L, V30, P1455, DOI 10.1109/LPT.2018.2853155
   Ismail S.M., 2017, 2017 6 INT C MOD CIR, P1, DOI DOI 10.1109/MOCAST.2017.7937643
   Jen-Wei Lee, 2010, Proceedings of the 36th European Solid State Circuits Conference (ESSCIRC 2010), P206, DOI 10.1109/ESSCIRC.2010.5619893
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Litasari, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P95, DOI 10.1109/ICITISEE.2017.8285567
   Lohachab A, 2019, J INF SECUR APPL, V46, P1, DOI 10.1016/j.jisa.2019.02.005
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Pandey A, 2019, MULTIMED TOOLS APPL, V78, P11223, DOI 10.1007/s11042-018-6681-2
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P73, DOI 10.1016/j.procs.2015.06.009
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Sokouti M, 2018, COMPUT SCI REV, V29, P14, DOI 10.1016/j.cosrev.2018.05.002
   Sujihelen L, 2018, WIRELESS PERS COMMUN, V99, P893, DOI 10.1007/s11277-017-5157-4
   Tawalbeh L, 2013, IET INFORM SECUR, V7, P67, DOI 10.1049/iet-ifs.2012.0147
   Vanstone SA., 1997, Environ Inform Secur Techn Report, V2, P78
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Zhao JF, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/8672716
NR 29
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17945
EP 17967
DI 10.1007/s11042-020-08610-5
EA FEB 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000515925400004
DA 2024-07-18
ER

PT J
AU Singh, S
   Batra, S
AF Singh, Sachendra
   Batra, Shalini
TI An efficient bi-layer content based image retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Feature space; Sub-space features; Layer
   based image retrieval
ID COLOR; INFORMATION; DESCRIPTOR
AB Large amount of multi-media content, generated by various image capturing devices, is shared and downloaded by millions of users across the globe, every second. High computation cost is inured in providing visually similar results to the user's query. Annotation based image retrieval is not efficient since annotations vary in terms of languages while pixel wise matching of images is not preferred since the orientation, scale, image capturing style, angle, storage pattern etc. bring huge amount of variations in the images. Content Based Image Retrieval (CBIR) system is frequently used in such cases since it computes similarity between query image and images of reference dataset efficiently. A Bi-layer Content Based Image Retrieval (BiCBIR) system has been proposed in this paper which consists of two modules: first module extracts the features of dataset images in terms of color, texture and shape. Second module consists of two layers: initially all images are compared with query image for shape and texture feature space and indexes of M most similar images to the query image are retrieved. Next, M images retrieved from previous layer are matched with query image for shape and color feature space and F images similar to the query image are returned as a output. Experimental results show that BiCBIR system outperforms the available state-of-the-art image retrieval systems.
C1 [Singh, Sachendra; Batra, Shalini] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, S (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM sachendrac@gmail.com; sbatra@thapar.edu
CR Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Cheng ZY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3291060
   Chih-Fong Tsai, 2012, ISRN Artificial Intelligence, DOI 10.5402/2012/376804
   Choras RS, 2007, PATTERN ANAL APPL, V10, P333, DOI 10.1007/s10044-007-0071-0
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fadaei S, 2016, NEW CONTENT BASED IM, V11
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Garcia N, 2019, IMAGE VISION COMPUT, V82, P18, DOI 10.1016/j.imavis.2019.01.001
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Lande M.V., 2014, INTELLIGENT COMPUTIN, V243, P1163, DOI [10.1007/978-81-322-1665-0_119, DOI 10.1007/978-81-322-1665-0_119]
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P2047, DOI 10.1109/TIP.2014.2312283
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Mahmood T, 2018, APPL INTELL, V48, P1791, DOI 10.1007/s10489-017-1038-5
   Mansoori NS, 2013, IRAN CONF ELECTR ENG
   Marin-Castro HM, 2019, MULTIMED TOOLS APPL, V78, P26263, DOI 10.1007/s11042-019-07815-7
   Mehmood Z, 2018, APPL INTELL, V48, P166, DOI 10.1007/s10489-017-0957-5
   Mezzoudj Saliha, 2019, J KING SAUD U COMPUT
   Ouni A, 2018, MULTIMED TOOLS APPL, V77, P26173, DOI 10.1007/s11042-018-5841-8
   Pandey S, 2016, COMPUT ELECTR ENG, V54, P506, DOI 10.1016/j.compeleceng.2016.04.003
   Pavithra LK, 2017, COMPUTERS ELECT ENG
   Phadikar BS, 2018, PATTERN ANAL APPL, V21, P469, DOI 10.1007/s10044-016-0589-0
   Pradhan J, 2018, DIGITAL SIGNAL PROCE
   Shao J, 2019, MULTIMED TOOLS APPL, V78, P16615, DOI 10.1007/s11042-018-7068-0
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Sotoodeh M, 2019, EXPERT SYST APPL
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tong LJ, 2020, MULTIMED TOOLS APPL, V79, P9469, DOI 10.1007/s11042-019-07886-6
   Tou JingYi., 2007, MMU International Symposium on Information and Communications Technologies, P197
   Wang D, 2019, PATTERN RECOGN, V86, P134, DOI 10.1016/j.patcog.2018.09.006
   Wang XY, 2014, NEUROCOMPUTING, V127, P214, DOI 10.1016/j.neucom.2013.08.007
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XF, 2019, J VIS COMMUN IMAGE R, V61, P260, DOI 10.1016/j.jvcir.2019.03.024
   [王永林 WANG Yonglin], 2010, [纺织学报, Journal of Textile Research], V31, P60
   Yan LY, 2019, MULTIMED TOOLS APPL, V78, P15101, DOI 10.1007/s11042-018-6855-y
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Yousuf M, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2134395
   Yu ZW, 2012, INFORM SCIENCES, V203, P83, DOI 10.1016/j.ins.2012.03.012
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhou JX, 2019, MULTIMED TOOLS APPL, V78, P6163, DOI 10.1007/s11042-018-6192-1
   Zhou W., 2017, Recent Advance in Content-based Image Retrieval: A Literature Survey
   Zhu SH, 2014, J INTELL INF SYST, V42, P95, DOI 10.1007/s10844-013-0257-4
NR 49
TC 23
Z9 23
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17731
EP 17759
DI 10.1007/s11042-019-08401-7
EA FEB 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300002
DA 2024-07-18
ER

PT J
AU Arun, MR
   Selvakumar, S
AF Arun, M. R.
   Selvakumar, S.
TI Ultra-HEVC using frame frequency error optimization technique for IPTV
   realization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UHEVC; Streaming server; Packet loss; Video coding
ID VIDEO
AB Internet Protocol Television (IPTV) is an emerging network application in the internet world. One of the most reliable networks is IPTV which gives high speed for internet services. As IPTV offers many live services on user demand and it has many advantages. But still, some problem exists in the existing implementation such as degradation of quality and delay while maintaining limited frames and efficient bandwidth consumption over the network channel. The efficient bandwidth utilization is a major issue in IPTV platforms. Integrating the video processing on network platform is the challenging task in video on demand (VoD) application. This paper overcomes the drawbacks of existing IPTV by using Frame Frequency Error Optimization (FFEO) based HEVC approach which is called as U-HEVC. The FFEO method upgrades the video quality by interpolation of frames. U-HEVC delivers 50% better compression similar to the existing HEVC standard and it also provides better visual quality at half the bit rates. The Analysis of proposed U-HEVC attain better results compared to existing HEVC compression algorithms that higher number of packets get affected at different bit rate levels. In HEVC the Frame loss of 1 Mbps is 0.38%, 2 Mbps is 0.46%, 4 Mbps is 0.63% and 8 Mbps is 0.94%. When compared to the U-HEVC the Frame loss is somewhat high in HEVC. This paper presents the studies on IPTV environment based on U-HEVC using frame frequency error optimization technique.
C1 [Arun, M. R.] St Xaviers Catholic Coll Engn, Elect & Elect Engn, Nagercoil 629003, Tamil Nadu, India.
   [Selvakumar, S.] GKM Coll Engn & Technol, Chennai 600063, Tamil Nadu, India.
RP Arun, MR (corresponding author), St Xaviers Catholic Coll Engn, Elect & Elect Engn, Nagercoil 629003, Tamil Nadu, India.
EM mrarunresearch@gmail.com; sselvakumar@yahoo.com
RI Subramanian, Selvakumar/AEO-1935-2022; M R, Arun/HNR-9159-2023
CR Ahilan A, 2015, MICROELECTRON RELIAB, V55, P2108, DOI 10.1016/j.microrel.2015.06.075
   Anegekuh L, 2015, IEEE T MULTIMEDIA, V17, P1323, DOI 10.1109/TMM.2015.2444098
   [Anonymous], FPGA INT C ADV COMP
   [Anonymous], EUR C DIG SYST DES D
   [Anonymous], INTRO IPTV
   [Anonymous], 2012, INTRO DATA COMPRESSI
   [Anonymous], MPEG FRAM LOSS RAT I, DOI DOI 10.1109/SAC0NET.2013.6654554
   [Anonymous], 7 IEEE CONS COMM NET
   [Anonymous], J IMAGE PROCESSING A
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], 5 INT C IM SIGN PROC
   [Anonymous], IEEE INT C EL CIRC S
   [Anonymous], INT J ENG MANUF
   [Anonymous], AS PAC SIGN INF PROC
   [Anonymous], EXISTING THREATS IPT
   [Anonymous], 1999, IMAGE VIDEO COMPRESS
   [Anonymous], SCI INF C SAI
   Chung YU, 2010, IEEE T CONSUM ELECTR, V56, P2790, DOI 10.1109/TCE.2010.5681170
   Degrande N, 2008, BELL LABS TECH J, V13, P35, DOI 10.1002/bltj.20281
   Engelhardt D, 2014, IEEE T CONSUM ELECTR, V60, P476, DOI 10.1109/TCE.2014.6937333
   Gutiérrez J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P172, DOI 10.1109/ICCE.2012.6161815
   Kalali E, 2014, IEEE T CONSUM ELECTR, V60, P754, DOI 10.1109/TCE.2014.7027352
   Kammoun M, 2014, 2014 FIRST INTERNATIONAL IMAGE PROCESSING, APPLICATIONS AND SYSTEMS CONFERENCE (IPAS)
   Khabbiza E, 2016, INT CONF MULTIMED, P687, DOI 10.1109/ICMCS.2016.7905550
   Lee H, 2016, IEEE T CONSUM ELECTR, V62, P463, DOI 10.1109/TCE.2016.7838100
   Ma L, 2016, DESTECH TRANS COMP, P7
   Ma SW, 2013, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC.2013.15
   Song JR, 2017, IEEE T MULTIMEDIA, V19, P1015, DOI 10.1109/TMM.2016.2638621
   Sridhar K, 2008, BELL LABS TECH J, V13, P29, DOI 10.1002/bltj.20280
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wige E, 2013, IEEE IMAGE PROC, P1806, DOI 10.1109/ICIP.2013.6738372
   Xu WZ, 2016, PICT COD SYMP
   Yu G., 2009, Broadband Multimedia Systems and Broadcasting, P1
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5083
EP 5097
DI 10.1007/s11042-018-6316-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500048
DA 2024-07-18
ER

PT J
AU Gao, K
   Kong, WW
   Niu, SJ
   Li, DW
   Chen, YH
AF Gao, Kun
   Kong, Wenwen
   Niu, Sijie
   Li, Dengwang
   Chen, Yuehui
TI Automatic retinal layer segmentation in SD-OCT images with CSC guided by
   spatial characteristics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SD OCT; Central serious chorioretinaopathy; Graph theory; Retinal layers
   segmentation
ID OPTICAL COHERENCE TOMOGRAPHY; GRADIENT
AB Segmentation of retinal layers with central serious chorioretinopathy (CSC) in Spectral Domain Optical Coherence Tomography (SD-OCT) images is significant for quantitative analysis including the volume, location and shape of CSC region. In this paper, we present an automatic segmentation method to segment retinal layers based on graph theory and the previous B-scan information. Firstly, the boundaries of Vitreous-ILM (inner limiting membrane), ONL (outer nuclear layer)-IS (photoreceptor inner segments) or LR (lesion region)-RPE (retinal pigment epithelium), and RPE-Choroid are estimated based on graph search model. Next, a flexible search region is constructed by calculating the thickness between Vitreous-ILM and ONL-IS based on the difference between two consecutive B-scans, which is used to refine the ONL-IS. The proposed method was quantitatively evaluated in total of 200 B-scan images from 5 abnormal cubes with CSC and 5 normal cubes, where we choose 20 B-scan images randomly in each cube. Experimental results illustrated that the proposed method can segment retinal layers in SD OCT images with CSC accurately. And the overall mean absolute boundary positioning differences and the overall mean absolute thickness differences compared to manual segmentation results are 3.68 +/- 2.96 mu m and 5.84 +/- 4.78 mu m.
C1 [Gao, Kun; Niu, Sijie; Chen, Yuehui] Univ Jinan, Sch Informat Sci & Engn, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
   [Kong, Wenwen; Li, Dengwang] Shandong Normal Univ, Sch Phys & Elect, Jinan 250014, Peoples R China.
C3 University of Jinan; Shandong Normal University
RP Niu, SJ (corresponding author), Univ Jinan, Sch Informat Sci & Engn, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
EM sjniu@hotmail.com
RI Li, Kun/JLL-6505-2023
OI Li, Kun/0000-0002-3638-2974; Gao, Kun/0000-0003-1729-2700
CR Chiu SJ, 2010, OPT EXPRESS, V18, P19413, DOI 10.1364/OE.18.019413
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Dufour PA, 2013, IEEE T MED IMAGING, V32, P531, DOI 10.1109/TMI.2012.2225152
   Fabritius T, 2009, OPT EXPRESS, V17, P15659, DOI 10.1364/OE.17.015659
   Gurusamy R, 2017, CMC-COMPUT MATER CON, V53, P91
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Kafieh R, 2013, MED IMAGE ANAL, V17, P907, DOI 10.1016/j.media.2013.05.006
   Lee K, 2010, IEEE T MED IMAGING, V29, P159, DOI 10.1109/TMI.2009.2031324
   Li A, 2015, CMC-COMPUT MATER CON, V45, P17
   Niu SJ, 2014, COMPUT BIOL MED, V54, P116, DOI 10.1016/j.compbiomed.2014.08.028
   Song Q, 2013, IEEE T MED IMAGING, V32, P376, DOI 10.1109/TMI.2012.2227120
   Srinivasan VJ, 2008, INVEST OPHTH VIS SCI, V49, P1571, DOI 10.1167/iovs.07-0838
   Tan O, 2008, OPHTHALMOLOGY, V115, P949, DOI 10.1016/j.ophtha.2007.08.011
   Tang ZJ, 2018, CMC-COMPUT MATER CON, V55, P331, DOI 10.3970/cmc.2018.02222
   Wang M, 2008, ACTA OPHTHALMOL, V86, P126, DOI 10.1111/j.1600-0420.2007.00889.x
   Yang Q, 2010, OPT EXPRESS, V18, P21293, DOI 10.1364/OE.18.021293
   Yazdanpanah A, 2011, IEEE T MED IMAGING, V30, P484, DOI 10.1109/TMI.2010.2087390
NR 17
TC 4
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4417
EP 4428
DI 10.1007/s11042-019-7395-9
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500011
DA 2024-07-18
ER

PT J
AU Jayalakshmi, M
   Gomathi, V
AF Jayalakshmi, M.
   Gomathi, V.
TI Pervasive health monitoring through video-based activity information
   integrated with sensor-cloud oriented context-aware decision support
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor data; Machine learning; WSN; Multimedia; Video-based activity
   information; Cloud computing; IoT
ID TECHNOLOGY
AB Medical informatics comprises of huge amount of medical resources to enhance storage, retrieval, and employ these resources in healthcare. The advancement has been done to monitor the health of the patients and provide the details to the caretakers, who are near by the remote areas. This could be done in a real-time with the help of the internet access. Due to the condition of monitoring the patient at a real-time, the caretaker can provide the suggestions regarding their essential signs of their body situation through a video conference. In this paper, we have proposed a system to report the progress of the elderly in an appropriate manner with the help of the technology used in the healthcare system and integrate the report of progress to the remote caretakers employing smartphones and videos. Through this advanced method we could able to identify the abnormalities at early stages so that the doctors could cure it without any difficulty. This could increase the physical and mental health of the patients. The system incorporated in this method requires certain sensors which are of very low in cost, certain electronic devices and smart phone for the communication purpose and WSN.
C1 [Jayalakshmi, M.; Gomathi, V.] Natl Engn Coll, Kovilpatti, Tamil Nadu, India.
C3 National Engineering College - India
RP Jayalakshmi, M (corresponding author), Natl Engn Coll, Kovilpatti, Tamil Nadu, India.
EM jayalacsmi@gmail.com; vgcse@nec.edu.in
RI Murugan, Jayalakshmi/J-8048-2017; V., GOMATHI/B-8105-2013
OI Murugan, Jayalakshmi/0000-0002-7297-9161; V.,
   GOMATHI/0000-0003-3639-485X
CR Ahuja SP., 2012, Network and Communication Technologies, V1, P12, DOI DOI 10.5539/NCT.V1N2P12
   Jothikumar R., 2017, INT J PURE APPL MATH, V117, P199
   Kern SE, 2003, IEEE ENG MED BIOL, V22, P16, DOI 10.1109/MEMB.2003.1191444
   Lee RG, 2000, IEEE T INF TECHNOL B, V4, P37, DOI 10.1109/4233.826857
   Polat K, 2007, EXPERT SYST APPL, V32, P625, DOI 10.1016/j.eswa.2006.01.027
   Singh MR, 2002, IEEE INTERNET COMPUT, V6, P4, DOI 10.1109/MIC.2002.1036032
   Sun HM, 2014, MULTIMED TOOLS APPL, V69, P1021, DOI 10.1007/s11042-012-1141-x
   Suresh A, 2020, J SUPERCOMPUT, V76, P4262, DOI 10.1007/s11227-018-2302-0
   Tazaree A, 2014, MULTIMED TOOLS APPL, V69, P921, DOI 10.1007/s11042-012-1123-z
   Udendhran R, 2017, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, DATA AND CLOUD COMPUTING (ICC 2017), DOI 10.1145/3018896.3025138
   Vijayalakshmi K., 2018, International Journal of Engineering and Technology(UAE), V7, P1, DOI DOI 10.14419/IJET.V7I1.7.9377
   Wells PNT, 2003, IEEE ENG MED BIOL, V22, P20, DOI 10.1109/MEMB.2003.1191445
   Yuan BC, 2012, PROCEDIA COMPUT SCI, V10, P357, DOI 10.1016/j.procs.2012.06.047
   Zhang JG, 2000, IEEE T INF TECHNOL B, V4, P178, DOI 10.1109/4233.845212
   Zhang MJ, 2018, MULTIMED TOOLS APPL, V77, P4283, DOI 10.1007/s11042-017-4552-x
   Ziefle M, 2010, 4 INT C PERV COMP MU
NR 16
TC 7
Z9 7
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3699
EP 3712
DI 10.1007/s11042-018-6716-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700032
DA 2024-07-18
ER

PT J
AU Li, Z
   Guo, J
   Jiao, WL
   Xu, PF
   Liu, BY
   Zhao, XW
AF Li, Zhi
   Guo, Jun
   Jiao, Wenli
   Xu, Pengfei
   Liu, Baoying
   Zhao, Xiaowei
TI Random linear interpolation data augmentation for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Data augmentation; Linear interpolation
AB Person Re-Identification (person re-ID) is an image retrieval task which identifies the same person in different camera views. Generally, a good person re-ID model requires a large dataset containing over 100000 images to reduce the risk of over-fitting. Most current handcrafted person re-ID datasets, however, are insufficient for training a learning model with high generalization ability. In addition, the lacking of images with various levels of occlusion is still remaining in most existing datasets. Motivated by these two problems, this paper proposes a new data augmentation method called Random Linear Interpolation that can enlarge the sizes of person re-ID datasets and improve the generalization ability of the learning model. The key enabler of our approach is generating fused images by interpolating pairs of original images. In other words, the innovation of the proposed approach is considering data augmentation between two random samples. Plenty of experimental results demonstrates that the proposed method is effective to improve baseline models. On Market1501 and DukeMTMC-reID datasets, our approach can achieve 92.71% and 82.19% rank-1 accuracy, respectively.
C1 [Li, Zhi; Guo, Jun; Jiao, Wenli; Xu, Pengfei; Liu, Baoying; Zhao, Xiaowei] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
C3 Northwest University Xi'an
RP Xu, PF (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
EM zhili@stumail.nwu.edu.cn; guojun@nwu.edu.cn;
   jiaowenli@stumail.nwu.edu.cn; pfxu@nwu.edu.cn; pola.liu@nwu.edu.cn;
   xiaoweizhao4@gmail.com
CR [Anonymous], 2016, PERSON REIDENTIFICAT
   [Anonymous], 2017, COMPUTER VISION IMAG
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2013, ICML
   [Anonymous], 2017, ARXIV170307737
   [Anonymous], 2017, RANDOM ERASING DATA
   [Anonymous], 2017, PEDESTRIAN ALIGNMENT
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Boroujeni FR, 2018, AAAI CONF ARTIF INTE, P2746
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chapelle O, 2011, ADV NEURAL INFORM PR, P416
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Geng M, 2016, COMPUTER VISION IMAG
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, IEEE C COMP VIS PATT
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kodirov E, 2015, BRIT MACH VIS C, V44, P1
   Kodirov E, 2007, HYDROBIOLOGIA, V415, P35
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JN, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P181, DOI 10.1145/3123266.3123439
   Li ZY, 2017, AIP CONF PROC, V1863, DOI 10.1063/1.4992364
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lisanti I., 2014, IEEE transactions on pattern analysis and machine intelligence, P1, DOI [DOI 10.1109/TPAMI.2014.2369055, 10.1145/2659021.2659036, DOI 10.1145/2659021.2659036]
   Maas A.L, 2013, ICML
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   TANNER MA, 1987, J AM STAT ASSOC, V82, P528, DOI 10.2307/2289457
   Torralba A, 2008, 80 MILLION TINY IMAG
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Xu FJ, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P964, DOI 10.1109/FSKD.2017.8393408
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 42
TC 8
Z9 8
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4931
EP 4947
DI 10.1007/s11042-018-7071-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500038
DA 2024-07-18
ER

PT J
AU Xue, DN
   Sun, JQ
   Hu, YQ
   Zheng, YS
   Zhu, Y
   Zhang, YN
AF Xue, Danna
   Sun, Jinqiu
   Hu, Yaoqi
   Zheng, Yushu
   Zhu, Yu
   Zhang, Yanning
TI Dim small target detection based on convolutinal neural network in star
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dim small target detection; Low SNR; Semantic segmentation;
   Convolutional neural network
ID LOW-RANK; RECOGNITION; TRACKING
AB The detection of dim target in star image is a challenging task because of the low SNR target and complex background. In this paper, we present a deep learning approach to detecting dim small targets in single-frame star image under uneven background and different kinds of noises. We propose a fully convolutional neural network to achieve pixel-wise classification, which can complete target-background separation in a single stage rapidly. To train this network, we also build a synthetic star image dataset covering various noises and background distribution. The precise annotations of the target regions and centroid positions provided by this dataset make the supervised learning approach possible. Experimental results show that the proposed method outperforms the state-of-the-art in terms of higher detection rate and less false alarm caused by noises.
C1 [Xue, Danna; Hu, Yaoqi; Zhu, Yu; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
   [Sun, Jinqiu] Northwestern Polytech Univ, Sch Aeronaut, Xian 710072, Peoples R China.
   [Zheng, Yushu] Northwestern Polytech Univ, Sch Software & Microelect, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Northwestern Polytechnical University
RP Sun, JQ (corresponding author), Northwestern Polytech Univ, Sch Aeronaut, Xian 710072, Peoples R China.
EM sunjinqiu@nwpu.edu.com
CR [Anonymous], 2009, ORBITAL DEBRIS Q NEW, P1
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392
   BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Dai YM, 2016, INFRARED PHYS TECHN, V77, P421, DOI 10.1016/j.infrared.2016.06.021
   Deng LZ, 2018, MULTIMED TOOLS APPL, V77, P10539, DOI 10.1007/s11042-017-4592-2
   Ding WB, 2014, INT CONF SIGN PROCES, P774, DOI 10.1109/ICOSP.2014.7015109
   Fan W, 2016, OPTICAL TECHNIQUE
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gui Lang, 2018, Aquaculture and Fisheries, V3, P1, DOI 10.1016/j.aaf.2017.12.003
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He YJ, 2015, INFRARED PHYS TECHN, V68, P98, DOI 10.1016/j.infrared.2014.10.022
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Leitch R, 2010, SAPPHIRE SMALL SATEL
   Levesque Martin P, 2007, TECHNICAL REPORT
   Levesque MP, 2011, P AMOS TECH C WAIL M, V66
   [李旭 Li Xu], 2013, [红外技术, Infrared Technology], V35, P492
   Li Y, 2014, MULTIMED TOOLS APPL, V71, P1179, DOI 10.1007/s11042-012-1258-y
   Liu G, 2017, MULTIMED TOOLS APPL, V76, P19809, DOI 10.1007/s11042-016-3568-y
   Liu YG, 2018, MULTIMED TOOLS APPL, V77, P22159, DOI 10.1007/s11042-018-5704-3
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maciejewski T., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P104, DOI 10.1109/CIDM.2011.5949434
   NASA, NASA IM VID LIB
   Pych W., 2003, PUBL ASTRON SOC PAC, V116, P816, DOI DOI 10.1086/381786
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Royal Observatory Blackford Hill WFAU Institute for Astronomy, SUP SKY SURV
   Schiattarella V, 2017, ADV SPACE RES, V59, P2133, DOI 10.1016/j.asr.2017.01.034
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Sun Jin-Qiu, 2011, OPTICS PRECISION ENG, V12, P032
   Sun JQ, 2017, LECT NOTES COMPUT SC, V10667, P174, DOI 10.1007/978-3-319-71589-6_16
   van Dokkum PG, 2001, PUBL ASTRON SOC PAC, V113, P1420, DOI 10.1086/323894
   Windhorst R.A., 1994, J PASP, V106, P798, DOI DOI 10.1086/133443
   Yao Rui, 2012, Optics and Precision Engineering, V20, P179, DOI 10.3788/OPE.20122001.0179
   Zhang W, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P643
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1466, DOI 10.1109/TIP.2017.2651396
   Zhou XW, 2012, PROC CVPR IEEE, P972, DOI 10.1109/CVPR.2012.6247773
NR 40
TC 9
Z9 10
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4681
EP 4698
DI 10.1007/s11042-019-7412-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500024
DA 2024-07-18
ER

PT J
AU Chen, TH
   Wu, XW
AF Chen, Tzung-Her
   Wu, Xi-Wen
TI Multiple secret image sharing with general access structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boolean operation; General access structure; Multiple secret image
   sharing; Visual secret sharing
ID VISUAL CRYPTOGRAPHY; UNIVERSAL SHARE; SCHEME; AUTHENTICATION
AB Boolean-operation-based secret image sharing (BSIS), which aims to encode a secret image into some shared images and discloses the original secret image later, has drawn more and more attention in academia. Since Chen and Wu pioneer in proposing the Boolean-operation-based multiple secret image sharing (BMSIS) scheme, there more and more BMSIS schemes proposed in the literature. In order to remove the limitation that in the existing BMSIS schemes, this paper presents Boolean-operation-based multiple-secret image sharing with general access structure for secret reconstruction. Compared with the existing related BMSIS schemes with the property of all-or-nothing reconstruction, the proposed scheme achieves a milestone, i.e., secrets can be reconstructed by the pre-defined access structure. Hence, the secret reconstruction no longer needs to collect all share images. Furthermore, distinct combinations of shares have the ability to disclose the secrets defined in the qualified set. The theoretical analysis and the experimental results demonstrate the proposed scheme does work.
C1 [Chen, Tzung-Her; Wu, Xi-Wen] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
C3 National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU Ministry of Science and Technology of Taiwan [MOST 107-2221-E-415 -001
   -MY3]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under grant MOST 107-2221-E-415 -001 -MY3.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Chen CC, 2016, MULTIMED TOOLS APPL, V75, P7113, DOI 10.1007/s11042-015-2634-1
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen J, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993627
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P12979, DOI 10.1007/s11042-017-4927-z
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Fang WP, 2007, J CHIN INST ENG, V30, P753, DOI 10.1080/02533839.2007.9671301
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Lee KH, 2012, IEEE T INF FOREN SEC, V7, P219, DOI 10.1109/TIFS.2011.2167611
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Meghrajani YK, 2016, IEEE SIGNAL PROC LET, V23, P1429, DOI 10.1109/LSP.2016.2599076
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ni Z, 2003, P IEEE 2003 INT S CI, V2, pII
   Qin Z., 2016, IEEE Trans. Serv. Comput, DOI [10.1109/TSC.2016.2551238, DOI 10.1109/TSC.2016.2551238]
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tsao KH, 2015, DISPLAYS, V39, P80, DOI 10.1016/j.displa.2015.09.001
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 28
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13247
EP 13265
DI 10.1007/s11042-019-08524-x
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515728500001
DA 2024-07-18
ER

PT J
AU Feng, YF
   Lu, HQ
   Bai, JB
   Cao, L
   Yin, H
AF Feng, Yufang
   Lu, Houqing
   Bai, Jingbo
   Cao, Lin
   Yin, Hong
TI Fully convolutional network-based infrared and visible image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Full convolutional neural networks; LNSST; Weight map; Image fusion
ID INFORMATION; ALGORITHM; PCNN
AB This study proposes a novel fusion framework for infrared and visual images based on a full convolutional network (FCN) in the local non-subsampled shearlet transform (LNSST) domain. First, the LNSST is used as a multi-scale analysis tool to decompose the source images into low-frequency and high-frequency sub-images. Second, the coefficients of the high-frequency sub-images are fed into the FCN to obtain the weight map, and then the average gradient (AVG) is used as the fusion rule to fuse the high-frequency sub-images while the low-frequency coefficients are fused by local energy fusion strategy. Finally, the inverse of the LNSST is applied to obtain the final fused image. The experimental results showed that the proposed fusion framework performed better than other typical fusion methods in both visual quality and objective assessment.
C1 [Feng, Yufang; Lu, Houqing; Bai, Jingbo; Cao, Lin; Yin, Hong] Army Engn Univ PLA, Nanjing, Peoples R China.
   [Feng, Yufang] Troops 71375, Harbin, Peoples R China.
C3 Army Engineering University of PLA
RP Yin, H (corresponding author), Army Engn Univ PLA, Nanjing, Peoples R China.
EM 1828316527@qq.com; luhouqing@qq.com; baijingbo1982@163.com;
   1055684077@qq.com; nanjingyh@126.com
CR Bai XZ, 2016, INFRARED PHYS TECHN, V76, P546, DOI 10.1016/j.infrared.2016.04.015
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cheng BY, 2018, NEUROCOMPUTING, V310, P135, DOI 10.1016/j.neucom.2018.05.028
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hossny M, 2010, ELECTRON LETT, V46, P1266, DOI 10.1049/el.2010.1778
   Jiang ZT, 2018, ACTA OPT SIN, V38, DOI 10.3788/AOS201838.0210002
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li H, 2018, INT C PATT RECOG, P2705, DOI 10.1109/ICPR.2018.8546006
   Li JX, 2018, OPT COMMUN, V407, P234, DOI 10.1016/j.optcom.2017.08.057
   Li J, 2018, INFRARED PHYS TECHN, V89, P129, DOI 10.1016/j.infrared.2018.01.003
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500182
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Lu HM, 2019, IEEE WIREL COMMUN, V26, P90, DOI 10.1109/MWC.2019.1800325
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Ma Y, 2016, NEUROCOMPUTING, V202, P12, DOI 10.1016/j.neucom.2016.03.009
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shreyamsha Kumar B.K., 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI DOI 10.1007/S11760-013-0556-9
   TOET A, 1989, PATTERN RECOGN LETT, V9, P255, DOI 10.1016/0167-8655(89)90004-4
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   XIANG Y, 2018, LASER OPTOELECTRON P, V1, P33
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan X, 2015, J OPT SOC AM A, V32, P1643, DOI 10.1364/JOSAA.32.001643
   Zhang BH, 2015, INFRARED PHYS TECHN, V73, P286, DOI 10.1016/j.infrared.2015.10.004
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao CH, 2014, OPTIK, V125, P6247, DOI 10.1016/j.ijleo.2014.08.024
   Zhao WD, 2018, IEEE T MULTIMEDIA, V20, P866, DOI 10.1109/TMM.2017.2760100
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
NR 36
TC 12
Z9 12
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15001
EP 15014
DI 10.1007/s11042-019-08579-w
EA JAN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000515608600005
DA 2024-07-18
ER

PT J
AU Ortiz-Barrios, MA
   Lundström, J
   Synnott, J
   Järpe, E
   Sant'Anna, A
AF Ortiz-Barrios, M. A.
   Lundstrom, J.
   Synnott, J.
   Jarpe, E.
   Sant'Anna, A.
TI Complementing real datasets with simulated data: a regression-based
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activity recognition; Activity duration; Regression analysis; Non-linear
   models; Determination coefficient; Quantile-quantile plots
ID RECOGNITION; HOME
AB Activity recognition in smart environments is essential for ensuring the wellbeing of older residents. By tracking activities of daily living (ADLs), a person's health status can be monitored over time. Nonetheless, accurate activity classification must overcome the fact that each person performs ADLs in different ways and in homes with different layouts. One possible solution is to obtain large amounts of data to train a supervised classifier. Data collection in real environments, however, is very expensive and cannot contain every possible variation of how different ADLs are performed. A more cost-effective solution is to generate a variety of simulated scenarios and synthesize large amounts of data. Nonetheless, simulated data can be considerably different from real data. Therefore, this paper proposes the use of regression models to better approximate real observations based on simulated data. To achieve this, ADL data from a smart home were first compared with equivalent ADLs performed in a simulator. Such comparison was undertaken considering the number of events per activity, number of events per type of sensor per activity, and activity duration. Then, different regression models were assessed for calculating real data based on simulated data. The results evidenced that simulated data can be transformed with a prediction accuracy R-2 = 97.03%.
C1 [Ortiz-Barrios, M. A.] Univ Costa CUC, Dept Ind Management Agroind & Operat, Barranquilla, Colombia.
   [Lundstrom, J.] Convergia Consulting, Halmstad, Sweden.
   [Synnott, J.] Ulster Univ, Sch Comp, Comp Sci Res Inst, Belfast BT37 0QB, Antrim, North Ireland.
   [Jarpe, E.; Sant'Anna, A.] Halmstad Univ, Dept Intelligent Syst & Digital Design, Halmstad, Sweden.
C3 Universidad de la Costa; Ulster University; Halmstad University
RP Ortiz-Barrios, MA (corresponding author), Univ Costa CUC, Dept Ind Management Agroind & Operat, Barranquilla, Colombia.
EM mortiz1@cuc.edu.co; jens@convergia-consulting.io;
   j.synnott@ulster.ac.uk; eric.jarpe@hh.se; anita.santanna@hh.se
RI Barrios, Miguel Ángel Ortíz/AAW-2705-2021
OI Ortiz Barrios, Miguel Angel/0000-0001-6890-7547; Jarpe,
   Eric/0000-0001-9307-9421
FU REMIND Project from the European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie grant [734355]
FX The Authors which to acknowledge support from the REMIND Project from
   the European Union's Horizon 2020 research and innovation programme
   under the Marie Sklodowska-Curie grant agreement No 734355.
CR Alberdi A, 2018, IEEE J BIOMED HEALTH, V22, P1720, DOI 10.1109/JBHI.2018.2798062
   Alshammari N, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051003
   Alshammari T, 2018, DATA, V3, DOI 10.3390/data3020011
   [Anonymous], 2006, DATA ANAL USING REGR, DOI DOI 10.1017/CBO9780511790942
   [Anonymous], 2003, STAT MINITAB
   De-La-Hoz-Franco E, 2018, IEEE ACCESS, V6, P59192, DOI 10.1109/ACCESS.2018.2873502
   Debes C, 2016, IEEE SIGNAL PROC MAG, V33, P81, DOI 10.1109/MSP.2015.2503881
   DESA UN, 2015, KEY FINDINGS ADV TAB
   Francillette Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112562
   Gergonne J., 1974, HIST MATH, V1, P439, DOI [DOI 10.1016/0315-0860(74)90034-2, 10.1016/0315-0860(74)90034-2]
   Hamad R, 2018, 2018 IEEE INT C SYST
   Helal S., 2010, P 8 INT C PERV WORKS, P450
   Helal S, 2011, 2011 7 INT C INT ENV, P192
   Holmes J, 2016, OVERVIEW DOMICILIARY
   Kamara-Esteban O, 2017, PERVASIVE MOB COMPUT, V40, P279, DOI 10.1016/j.pmcj.2017.07.007
   Krishnan NC, 2014, PERVASIVE MOB COMPUT, V10, P138, DOI 10.1016/j.pmcj.2012.07.003
   Larsen RichardJ., 2006, An Introduction to Mathematical Statistics and Its Applications
   Lee JW, 2015, IEEE T AUTOM SCI ENG, V12, P1243, DOI 10.1109/TASE.2015.2467353
   Lundström J, 2016, L N INST COMP SCI SO, V187, P9, DOI 10.1007/978-3-319-51234-1_2
   Mendoza-Palechor F, 2019, J AMB INTEL HUM COMP, V10, P3955, DOI 10.1007/s12652-018-1065-z
   Millán-Calenti JC, 2010, ARCH GERONTOL GERIAT, V50, P306, DOI 10.1016/j.archger.2009.04.017
   Mlinac ME, 2016, ARCH CLIN NEUROPSYCH, V31, P506, DOI 10.1093/arclin/acw049
   National Statistics Office, 2018, LAB FORC SURV
   Nugent C, 2016, LECT NOTES COMPUT SC, V10070, P104, DOI 10.1007/978-3-319-48799-1_13
   Barrios MO, 2015, LECT NOTES COMPUT SC, V9456, P293, DOI 10.1007/978-3-319-26508-7_29
   Ortiz M, 2016, LECT NOTES COMPUT SC, V9713, P47, DOI 10.1007/978-3-319-41009-8_6
   Paterson C., 2018, World Alzheimer Report 2018 The state of the art of dementia research: New frontiers (7)
   Prince MJ, 2015, LANCET, V385, P549, DOI 10.1016/S0140-6736(14)61347-7
   Stepler Renee., 2016, Smaller Share of Women Ages 65 and Older are Living Alone: More are living with spouse or children
   SUITS DB, 1957, J AM STAT ASSOC, V52, P548, DOI 10.2307/2281705
   Synnott J, 2016, 2016 IEEE INT C SMAR, P1
   Synnott J, 2015, SENSORS-BASEL, V15, P14162, DOI 10.3390/s150614162
   Vittinghoff E, 2005, STAT BIOL HEALTH, pVII
   World Health Organization, 2018, Ageing and health
NR 34
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34301
EP 34324
DI 10.1007/s11042-019-08368-5
EA JAN 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000507701400004
DA 2024-07-18
ER

PT J
AU Xia, DL
   Miao, L
   Fan, AW
AF Xia, Dongliang
   Miao, Lu
   Fan, Aiwan
TI A cross-modal multimedia retrieval method using depth correlation mining
   in big data environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep correlation mining; Cross-modal; Big data; Multimedia retrieval;
   Similarity; Levenberg-Marquart method
AB Cross-media retrieval is a technology aimed at breaking through the shackles of single-mode retrieval technology, which is limited to the same multimedia form. It is also hoped to be able to search each other across the media form. Comprehensive processing of different multimedia morphological data is an urgent problem to be solved in cross-media retrieval area, in other words, the semantic relationship between potential features should be mined, which will improve their similarity. To solve the above problems, a deep correlation mining method is proposed, which trains different media features by deep learning, and then fuses the correlation between the trained features to solve the heterogeneity between different features, which will make the features of different multimedia data comparable. On this basis, Levenberg-Marquart method is applied to solve the problem that deep learning is easy to fall into local minimum solution in gradient training. Experiments on different databases show that the proposed method is effective in the field of cross-media retrieval. Compared with other advanced multimedia retrieval methods, the proposed method has achieved better retrieval results.
C1 [Xia, Dongliang; Miao, Lu; Fan, Aiwan] Pingdingshan Univ, Sch Software, Pingdingshan 467000, Henan, Peoples R China.
C3 Pingdingshan University
RP Miao, L (corresponding author), Pingdingshan Univ, Sch Software, Pingdingshan 467000, Henan, Peoples R China.
EM pdsu2018@126.com
FU applied research plan of key scientific research projects in Henan
   colleges and Universities [18B520028]; Technology Plan Project of Henan
   Science [182102210471]
FX This work was supported by the applied research plan of key scientific
   research projects in Henan colleges and Universities (No. 18B520028);
   The Technology Plan Project of Henan Science (No. 182102210471).
CR [Anonymous], ACM INT C MULT RETR
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], INT C SEM
   [Anonymous], IEEE INT C MULT EXP
   Cao GQ, 2018, IEEE T CYBERNETICS, V48, P2542, DOI 10.1109/TCYB.2017.2742705
   Carvalho M., 2018, CROSS MODAL RETRIEVA
   Irie G, 2017, IEEE INT C AC
   Jia Y, 2018, MULTIMED TOOLS APPL, V2, P1
   Kai L, 2017, IEEE T PATTERN ANAL, P1825
   Kumalasari R, 2018, LOCATION SINABUNG VO
   Liang Z, 2017, IEEE T MULTIMED, V19, P1, DOI [10.1109/TMM.2017.2700527, DOI 10.1109/TMM.2017.2700527]
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P28665, DOI 10.1007/s11042-018-6006-5
   Tang YL, 2017, NANOMED NANOTOXICOL, P1, DOI 10.1007/978-981-10-5864-6_1
   Tran TQN, 2016, ACM WORKSH VIS LANG
   Uma R, 2017, CYBERNET SYST, V48, P393, DOI 10.1080/01969722.2017.1285163
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang J, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1700004
   Wang L, 2018, INT C NEUR INF PROC
   Wang LQ, 2017, SIGNAL PROCESS, V131, P249, DOI 10.1016/j.sigpro.2016.08.012
   Wang S., 2015, IEEE INT C MULT EXP, P1
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yan H, 2016, VISUAL COMMUNICATION
   Yang Y, 2017, MULTIMED TOOLS APPL, V1, P1, DOI DOI 10.1007/s11042-006-0058-7
   Zhang L, 2017, ACM MULT C
   Zhong FM, 2018, PATTERN RECOGN, V83, P64, DOI 10.1016/j.patcog.2018.05.018
   Zou FH, 2019, WORLD WIDE WEB, V22, P825, DOI 10.1007/s11280-018-0581-2
NR 26
TC 7
Z9 10
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1339
EP 1354
DI 10.1007/s11042-019-08238-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600054
DA 2024-07-18
ER

PT J
AU Bastian, BT
   Jiji, CV
AF Bastian, Blossom Treesa
   Jiji, C., V
TI Integrated feature set using aggregate channel features and histogram of
   sparse codes for human detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human detection; Aggregate channel features; Histogram of sparse codes;
   Dictionary learning
AB The scientific community witnessed revolutionary changes with algorithms and data sets aiming for precise human detection from images and videos which are largely driven by the quality of features extracted. Regardless of the labyrinth of the existing detectors, featured human detection with near accuracy from complicated real-time data sets remains a major challenge. Here we propose an improved feature set by merging the fast and accurate aggregate channel features (ACF) and the data specific dictionary learned histogram of sparse codes (HSC) for human detection. This integrated feature set efficiently fuses the first-order information from the histogram of oriented gradient channels embedded in the ACF detector and the data specific intelligence contained in the HSC channels. The proposed detector outperforms the state-of-the-art ACF detector in terms of miss rate and average precision on challenging datasets. It is worth to be noted that there is a decrease with the miss rate by a factor of 13% and 5% for INRIA and Caltech pedestrian datasets respectively in comparison with baseline detector. Along with the detection of more instances, our detector reduced the number of false positives compared to other existing detectors. Although further modifications are warranted, our proposed detector could produce a tangible and palpable response with human detection in the vast arena of computer vision.
C1 [Bastian, Blossom Treesa] Coll Engn Trivandrum, Elect & Commun, Comp Vis Lab, Trivandrum, Kerala, India.
   [Jiji, C., V] Coll Engn Trivandrum, Dept Elect & Commun, Trivandrum, Kerala, India.
C3 College of Engineering, Trivandrum; College of Engineering, Trivandrum
RP Bastian, BT (corresponding author), Coll Engn Trivandrum, Elect & Commun, Comp Vis Lab, Trivandrum, Kerala, India.
EM blossombastian@cet.ac.in; jijicv@cet.ac.in
RI V, Jiji C/O-8644-2019
OI V, Jiji C/0000-0002-6667-226X; Bastian, Blossom
   Treesa/0000-0001-5642-4812
CR Al-Hazaimeh OM, 2019, MULTIMED TOOLS APPL, V78, P7029, DOI 10.1007/s11042-018-6401-y
   [Anonymous], 2013, P IEEE C COMP VIS PA
   Bai XF, 2013, IEICE T INF SYST, VE96D, P387, DOI 10.1587/transinf.E96.D.387
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Dalal N., CVPR, P886, DOI [DOI 10.1109/CVPR.2005.177, 10.1109/CVPR.2005.177]
   Ding JH, 2013, MULTIMED TOOLS APPL, V63, P791, DOI 10.1007/s11042-011-0896-9
   Dollar P., PIOTRS COMPUTER VISI
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Fang YQ, 2016, IEEE IMAGE PROC, P1052, DOI 10.1109/ICIP.2016.7532518
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Jing HY, 2014, NEUROCOMPUTING, V129, P114, DOI 10.1016/j.neucom.2013.02.048
   Li A, 2017, MULTIMED TOOLS APPL, V76, P26249, DOI 10.1007/s11042-016-4115-6
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Peng B, 2012, 3RD INTERNATIONAL SYMPOSIUM ON HIGH-TEMPERATURE METALLURGICAL PROCESSING, P453
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang HH, 2019, MULTIMED TOOLS APPL, V78, P16945, DOI 10.1007/s11042-018-6888-2
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Xiong JP, 2016, MULTIMED TOOLS APPL, V75, P17531, DOI 10.1007/s11042-016-3464-5
   Yang BQ, 2017, MULTIMED TOOLS APPL, V76, P8969, DOI 10.1007/s11042-016-3492-1
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang S, 2014, CVPR
   ZHANG T, 2013, INF TECHNOL J, V12, P2342, DOI DOI 10.3923/itj.2013.2342.2349
   ZHANG T, 2012, 4 INT C DIG IM PROC, V8334, P593
   Zhao ZQ, 2017, LECT NOTES COMPUT SC, V10361, P735, DOI 10.1007/978-3-319-63309-1_65
NR 33
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2931
EP 2944
DI 10.1007/s11042-019-08498-w
EA DEC 2019
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500612000001
DA 2024-07-18
ER

PT J
AU Caruccio, L
   Deufemia, V
   Polese, G
AF Caruccio, Loredana
   Deufemia, Vincenzo
   Polese, Giuseppe
TI Visualization of (multimedia) dependencies from big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge visualization; Visual analytics; Relaxed functional
   dependencies; Multimedia data; Visual metaphors
ID FUNCTIONAL-DEPENDENCIES; EFFICIENT DISCOVERY; ALGORITHM
AB Data dependencies represent one of the key metadata to characterize and profile multimedia and big data sources. With respect to traditional databases, in these new contexts it has been necessary to introduce some approximations in the definition of dependencies. This yields a proliferation of dependencies, which makes it difficult for a user to effectively analyze them. To this end, in this paper we present a technique for ranking and visualizing dependencies holding on big and multimedia data. A qualitative evaluation has highlighted the advantages of the proposed visualization metaphors.
C1 [Caruccio, Loredana; Deufemia, Vincenzo; Polese, Giuseppe] Univ Salerno, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
C3 University of Salerno
RP Caruccio, L (corresponding author), Univ Salerno, Via Giovanni Paolo II 132, I-84084 Fisciano, SA, Italy.
EM lcaruccio@unisa.it; deufemia@unisa.it; gpolese@unisa.it
RI Polese, Giuseppe/CAG-5264-2022; Deufemia, Vincenzo/M-3553-2016
OI Polese, Giuseppe/0000-0002-8496-2658; Deufemia,
   Vincenzo/0000-0002-6711-3590; Caruccio, Loredana/0000-0002-2418-1606
CR Abedjan Z., 2014, P 23 ACM INT C INF K, P949
   Abedjan Z, 2015, VLDB J, V24, P557, DOI 10.1007/s00778-015-0389-y
   Arenas M, 2004, ACM T DATABASE SYST, V29, P195, DOI 10.1145/974750.974757
   Bobrov N, 2017, P 2 C SOFTW ENG INF
   Bohannon P., 2007, ICDE, P746, DOI [10.1109/ICDE.2007.367920, DOI 10.1109/ICDE.2007.367920]
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Caruccio L, 2018, THESIS
   Caruccio L, 2017, P 7 INT C WEB INT MI
   Caruccio L, 2016, IEEE T KNOWL DATA EN, V28, P147, DOI 10.1109/TKDE.2015.2472010
   Caruccio Loredana, 2016, Proceedings of the 20th International Database Engineering Applications Symposium, IDEAS 2016, Montreal, QC, Canada, July 11-13, 2016, P53
   Chang SK, 2007, IEEE T KNOWL DATA EN, V19, P1666, DOI 10.1109/TKDE.2007.190651
   Chen F, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P108, DOI 10.1145/2856767.2856787
   Chen W, 2017, J VISUAL LANG COMPUT, V42, P76, DOI 10.1016/j.jvlc.2017.08.007
   Chiang F, 2008, PROC VLDB ENDOW, V1, P1166, DOI 10.14778/1453856.1453980
   Fan WF, 2011, VLDB J, V20, P495, DOI 10.1007/s00778-010-0206-6
   Fan WF, 2009, PROC INT CONF DATA, P1231, DOI 10.1109/ICDE.2009.208
   Flach PA, 1999, AI COMMUN, V12, P139
   GALLO G, 1993, DISCRETE APPL MATH, V42, P177, DOI 10.1016/0166-218X(93)90045-P
   Giannella C, 2004, INFORM SYST, V29, P483, DOI 10.1016/j.is.2003.10.006
   Golab L, 2008, PROC VLDB ENDOW, V1, P376
   Hofmann H., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P227, DOI 10.1145/347090.347133
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huhtala Y, 1999, COMPUT J, V42, P100, DOI 10.1093/comjnl/42.2.100
   Huhtala Y, 1998, PROC INT CONF DATA, P392, DOI 10.1109/ICDE.1998.655802
   Ilyas I.F., 2004, SIGMOD, P647, DOI DOI 10.1145/1007568.1007641
   King R. S., 2003, Journal of Applied Mathematics and Decision Sciences, V7, P49, DOI 10.1155/S117391260300004X
   KIVINEN J, 1995, THEOR COMPUT SCI, V149, P129, DOI 10.1016/0304-3975(95)00028-U
   Kwashie S, 2015, LECT NOTES COMPUT SC, V9282, P3, DOI 10.1007/978-3-319-23135-8_1
   Kwashie S, 2014, LECT NOTES COMPUT SC, V8506, P50
   Lee ML, 2002, LECT NOTES COMPUT SC, V2287, P124
   Leung CKS, 2008, IEEE DATA MINING, P875, DOI 10.1109/ICDM.2008.93
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Li JY, 2006, IEEE T KNOWL DATA EN, V18, P460, DOI 10.1109/TKDE.2006.1599385
   Liu JX, 2012, IEEE T KNOWL DATA EN, V24, P251, DOI 10.1109/TKDE.2010.197
   Liu Y, 2012, INT CONF SIGN PROCES, P1536, DOI 10.1109/ICoSP.2012.6491866
   Lopes S, 2000, LECT NOTES COMPUT SC, V1777, P350
   Newman D., 1998, UCI REPOSITORY MACHI
   Novelli N, 2001, LECT NOTES COMPUT SC, V1973, P189
   Papenbrock T, 2015, PROC VLDB ENDOW, V8, P1861
   RAJU KVSVN, 1988, ACM T DATABASE SYST, V13, P129, DOI 10.1145/42338.42344
   Sekhavat Y. A., 2013, INT J INTELL SCI, V3, P34
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168158
   Song SX, 2014, IEEE T KNOWL DATA EN, V26, P2179, DOI 10.1109/TKDE.2013.84
   Song SX, 2013, DATA KNOWL ENG, V87, P146, DOI 10.1016/j.datak.2013.06.003
   Song SX, 2011, ACM T DATABASE SYST, V36, DOI 10.1145/2000824.2000826
   Sugibuchi T, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P18, DOI 10.1109/IV.2009.56
   Vassiliev V. A., 1990, Theory of Singularities and its Applications, V1, P23
   VIANU V, 1987, J ACM, V34, P28, DOI 10.1145/7531.7918
   Wang YH, 2017, ACM T KNOWL DISCOV D, V11, DOI 10.1145/3070647
   Wyss C., 2001, Data Warehousing and Knowledge Discovery. Third International Conference, DaWaK 2001. Proceedings (Lecture Notes in Computer Science Vol.2114), P101
   Xie C, 2014, IEEE T VIS COMPUT GR, V20, P1743, DOI 10.1109/TVCG.2014.2346913
   Yao H, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P729, DOI 10.1109/ICDM.2002.1184040
NR 53
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33151
EP 33167
DI 10.1007/s11042-019-07951-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600024
DA 2024-07-18
ER

PT J
AU Devarajan, M
   Ravi, L
AF Devarajan, Malathi
   Ravi, Logesh
TI Intelligent cyber-physical system for an efficient detection of
   Parkinson disease using fog computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Fog computing; Cloud computing; FKNN-CBR;
   Parkinson's disease; Hybrid classifier
ID RECOMMENDATION SYSTEM; HEALTH; BRAIN
AB Parkinson's disease is one of the notable neurodegenerative disorders caused by insufficient production of dopamine which damages the motor skills and voice. Advancement of the Internet of Things (IoT) has fuelled the development of healthcare systems. In this article, we propose an intelligent system for detecting Parkinson's disease to provide proper medication by analysing voice samples. Instead of relying on limited storage capacity and computational resources of IoT, the recent healthcare systems take advantages of the cloud server. On the other hand, the utilization of cloud computing incurs the issues of data privacy and additional communication costs to the healthcare systems. To address this issue, we propose to utilize Fog computing as a midway layer between end devices and the cloud server. The proposed system employs the combinatorial Fuzzy K-nearest Neighbor and Case-based Reasoning classifier for the better classification of the Parkinson patients from healthy individuals. On the detection of abnormality, the proposed healthcare system is designed to generate an immediate alert to the patient. The proposed system is experimentally evaluated on the UCI-Parkinson dataset, and the results reveal the improved performance of our system over baseline approaches.
C1 [Devarajan, Malathi; Ravi, Logesh] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Ravi, L (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
EM malathipuducherry@gmail.com; LogeshPhD@gmail.com
OI D, Malathi/0000-0003-3154-1769; R, Logesh/0000-0002-0034-4714
FU SASTRA Deemed University, Thanjavur, India
FX The authors express their gratitude to SASTRA Deemed University,
   Thanjavur, India for the financial support and infrastructural
   facilities provided to carry out this research work.
CR AAMODT A, 1994, AI COMMUN, V7, P39
   Abawajy JH, 2017, IEEE COMMUN MAG, V55, P48, DOI 10.1109/MCOM.2017.1600374CM
   Abbas A, 2014, IEEE J BIOMED HEALTH, V18, P1431, DOI 10.1109/JBHI.2014.2300846
   Al Mamun KA, 2017, FUTURE GENER COMP SY, V66, P36, DOI 10.1016/j.future.2015.11.010
   Alhussein M, 2017, IEEE ACCESS, V5, P19835, DOI 10.1109/ACCESS.2017.2748561
   [Anonymous], 2018, CLUSTER COMPUTING
   [Anonymous], J INFORM SCI ENG
   [Anonymous], INT J WEB PORTALS
   Armbrust M., 2009, CLOUDS BERKELEY VIEW, V4, P506
   Arora S, 2015, PARKINSONISM RELAT D, V21, P650, DOI 10.1016/j.parkreldis.2015.02.026
   Arunkumar S., 2018, BIOMED RES-TOKYO, V29, P394
   Bakar Z. A., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P63, DOI 10.1109/CSPA.2012.6194692
   Bhattacharya I., 2010, P 1 AMR ACM W CEL WO, P14
   Bohanec M, 2018, J DECIS SYST, V27, P164, DOI 10.1080/12460125.2018.1469320
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Chaabouni S, 2017, MULTIMED TOOLS APPL, V76, P22527, DOI 10.1007/s11042-017-4796-5
   Costanzo Alfio, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P972, DOI 10.1109/CCNC.2016.7444920
   Das R, 2010, EXPERT SYST APPL, V37, P1568, DOI 10.1016/j.eswa.2009.06.040
   Dauer W, 2003, NEURON, V39, P889, DOI 10.1016/S0896-6273(03)00568-3
   Ene M, 2008, ANN UNIV CRAIOVA-MAT, V35, P112
   Engel AK, 2005, NAT REV NEUROSCI, V6, P35, DOI 10.1038/nrn1585
   Gandhi VI, 2017, J ENG SCI TECHNOL, V12, P1541
   Georgiou PG, 2015, 16 ANN C INT SPEECH, P1
   Goetz CG, 2009, MOVEMENT DISORD, V24, P551, DOI 10.1002/mds.22379
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Hossain MS, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/858712
   Indragandhi V, 2017, RENEW SUST ENERG REV, V69, P129, DOI 10.1016/j.rser.2016.11.209
   Indragandhi V, 2018, COMPUTERS ELECT ENG
   Jagadeeswari V, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0049-x
   Gil JJ, 2009, J COMPUT INF SCI ENG, V9, DOI 10.1115/1.3074283
   Kassavetis P, 2016, MOV DISORD CLIN PRAC, V3, P59, DOI 10.1002/mdc3.12239
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Khemphila A., 2012, WORLD ACAD SCI ENG T, V64, P15
   Kringelbach ML, 2007, NAT REV NEUROSCI, V8, P623, DOI 10.1038/nrn2196
   Little MA, 2009, IEEE T BIO-MED ENG, V56, P1015, DOI 10.1109/TBME.2008.2005954
   Logesh R., 2019, Cognitive Informatics and Soft Computing. Proceeding of CISC 2017. Advances in Intelligent Systems and Computing (AISC 768), P535, DOI 10.1007/978-981-13-0617-4_52
   Logesh R, 2019, MOBILE NETW APPL, V24, P1018, DOI 10.1007/s11036-018-1059-2
   Logesh R, 2018, FUTURE GENER COMP SY, V83, P653, DOI 10.1016/j.future.2017.08.060
   Logesh R., 2018, Electronic Government, V14, P90
   Logesh R, 2017, WIRELESS PERS COMMUN, V97, P2751, DOI 10.1007/s11277-017-4633-1
   Logesh R, 2017, BIOMED RES-INDIA, V28, P5646
   Lounis A, 2016, FUTURE GENER COMP SY, V55, P266, DOI 10.1016/j.future.2015.01.009
   Mantri S, 2018, J PARKINSON DIS, V8, P107, DOI 10.3233/JPD-171218
   Muhammad G, 2015, CLUSTER COMPUT, V18, P795, DOI 10.1007/s10586-015-0439-7
   Nelson ME, 2007, MED SCI SPORT EXER, V39, P1435, DOI 10.1249/mss.0b013e3180616aa2
   Pan D, 2015, JMIR MHEALTH UHEALTH, V3, DOI 10.2196/mhealth.3956
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Pun K, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1, DOI 10.1109/ICEPT.2014.6922552
   Putri FT, 2018, STUD COMPUT INTELL, V777, P397, DOI 10.1007/978-3-319-89629-8_15
   Ramani R., 2011, Int J Comput Appl (IJCA), V32, P17
   Ravi L, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/1291358
   Robichaud JA, 2009, CLIN NEUROPHYSIOL, V120, P390, DOI 10.1016/j.clinph.2008.10.015
   Sakar CO, 2010, J MED SYST, V34, P591, DOI 10.1007/s10916-009-9272-y
   Shirvan R. A., 2011, 2011 18th Iranian Conference of Biomedical Engineering (ICBME), P278, DOI 10.1109/ICBME.2011.6168572
   Stamate C, 2018, PERVASIVE MOB COMPUT, V43, P146, DOI 10.1016/j.pmcj.2017.12.005
   Subramanian V, 2018, DEEP LEARNING PYTORC, P48
   Subramaniyaswamy V, 2019, J SUPERCOMPUT, V75, P3184, DOI 10.1007/s11227-018-2331-8
   Subramaniyaswamy V., 2018, International Journal of Advanced Intelligence Paradigms, V10, P103
   Subramaniyaswamy V, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P182, DOI 10.1109/ISS1.2017.8389394
   Subramaniyaswamy V, 2017, WIRELESS PERS COMMUN, V97, P2229, DOI 10.1007/s11277-017-4605-5
   Subramaniyaswamy V, 2017, J ORGAN END USER COM, V29, P51, DOI 10.4018/JOEUC.2017100103
   Subramaniyaswamy V., 2017, International Journal of High Performance Computing and Networking, V10, P54
   Subramaniyaswamy V, 2015, PROCEDIA COMPUT SCI, V50, P466, DOI 10.1016/j.procs.2015.04.016
   Subramaniyaswamy V, 2015, PROCEDIA COMPUT SCI, V50, P456, DOI 10.1016/j.procs.2015.04.015
   Subramaniyaswamy V, 2015, PROCEDIA COMPUT SCI, V50, P447, DOI 10.1016/j.procs.2015.04.014
   Sujatha J., 2017, Int J Appl Eng Res, V12, P10669
   Tsanas A, 2010, IEEE T BIO-MED ENG, V57, P884, DOI 10.1109/TBME.2009.2036000
   Uma Rani, 2012, P LOUGHB ANT PROP C, P1, DOI 10.1109/ICCCNT.2012.6395886
   Vairavasundaram S, 2015, WIRES DATA MIN KNOWL, V5, P87, DOI 10.1002/widm.1149
   Wooten GF, 2004, J NEUROL NEUROSUR PS, V75, P637, DOI 10.1136/jnnp.2003.020982
   Yan AJ, 2017, EXPERT SYST APPL, V89, P91, DOI 10.1016/j.eswa.2017.07.022
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 72
TC 34
Z9 35
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32695
EP 32719
DI 10.1007/s11042-018-6898-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600005
DA 2024-07-18
ER

PT J
AU Kasban, H
   Salama, DH
AF Kasban, H.
   Salama, D. H.
TI A robust medical image retrieval system based on wavelet optimization
   and adaptive block truncation coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Discrete wavelet transform; Block truncation codes
ID TRANSFORM; EFFICIENT; COLOR; DESCRIPTOR; PATTERN; MODEL
AB This paper presents a proposed method for medical image retrieval in order to search in a database for an image that is similar to a query image. The proposed Medical Image Retrieval System (MIRS) consists of two phases; enrollment phase and querying phase. In enrollment phase, the DiscreteWavelet Transform (DWT) coefficients are computed from every incoming image. Four wavelet types; Haar, Daubechies, Coiflet, and Symlet wavelets with different decomposition levels have been tested and compared in order to determine the most suitable wavelet type for the retrieval approach. Then, the Block Truncation Codes (BTCs) are extracted from the wavelet coefficients. To make the proposed image retrieval system robust, the BTC is adaptive by dividing the image into sub-blocks using one of four different scanning methods; raster, zigzag, Morton or Hilbert scanning. Finally, the extracted codes are stored as features vectors database. In querying phase, the BTCs are extracted from the wavelet coefficients of the query image. The similarity measurement between the features vector of the query images and the features vectors stored in the features vectors database is carried out using 8 different distance metrics to select the most suitable one. The proposed MIRS has been tested with a medical image database consists of 7500 CT brain images collected from a teaching hospital in Egypt. The results demonstrated that the proposed approach gives good results with extracting the BTCs with Morton scanning from the DB2 DWT. Moreover, Manhattan distance achieved the best similarity measurement results. The performance of the proposed MIRS has been compared with the published medical image retrieval approaches for VIA-ELCAP and Kvasir databases. The results indicated that, the proposed MIRS is robust and efficient for different medical image databases due to the advantages of dividing the image into blocks and each block can be retrieved separately according to its variance.
C1 [Kasban, H.] Atom Energy Author, Nucl Res Ctr, Dept Engn, Cairo, Egypt.
   [Salama, D. H.] Atom Energy Author, Natl Ctr Radiat Res & Technol, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   Egyptian Knowledge Bank (EKB); National Center for Radiation Research &
   Technology; Egyptian Atomic Energy Authority (EAEA)
RP Kasban, H (corresponding author), Atom Energy Author, Nucl Res Ctr, Dept Engn, Cairo, Egypt.
EM Hany_kasban@yahoo.com
RI Kasban, Hani/AAJ-6375-2020
OI Kasban, Hani/0000-0002-2249-5804
CR Abuturab MR, 2019, OPT LASER ENG, V118, P42, DOI 10.1016/j.optlaseng.2019.01.015
   Ahmad J, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0875-4
   [Anonymous], 2019, VIA ELCAP DATABASE
   [Anonymous], 2019, KVASIR DATABASE
   Arora S., 2014, International Journal of Advanced Computer and Mathematical Science, V5, P27
   Bashar MK, 2005, PATTERN RECOGN LETT, V26, P2315, DOI 10.1016/j.patrec.2005.04.009
   Bhandari KA, 2016, PROCEDIA COMPUT SCI, V79, P391, DOI 10.1016/j.procs.2016.03.051
   Bressan RS, 2019, NEUROCOMPUTING, V357, P1, DOI 10.1016/j.neucom.2019.05.041
   Cai YH, 2019, IEEE ACCESS, V7, P51877, DOI 10.1109/ACCESS.2019.2911630
   Chandy DA, 2017, MED BIOL ENG COMPUT, V55, P493, DOI 10.1007/s11517-016-1513-x
   Chen YH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010021
   Conjeti Sailesh, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P550, DOI 10.1007/978-3-319-66179-7_63
   Deep G, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0783-4
   Deep G, 2016, ENG SCI TECHNOL, V19, P1895, DOI 10.1016/j.jestch.2016.05.006
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Galshetwar GM, 2018, INT J MULTIMED INF R, V7, P231, DOI 10.1007/s13735-018-0156-0
   Gao Z, 2019, FUTURE GENER COMP SY, V94, P641, DOI 10.1016/j.future.2018.12.039
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Guo JM, 2016, SIGNAL PROCESS, V123, P143, DOI 10.1016/j.sigpro.2015.11.009
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Jenitta A, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0799-z
   JOSHI SS, 2015, IJSER, V6, P491
   JOSHI SS, 2016, IJECS, V5, P19339
   Kandasamy A, 2018, COMPUT ELECTR ENG, V67, P825, DOI 10.1016/j.compeleceng.2017.06.026
   Karine A, 2018, J VIS COMMUN IMAGE R, V50, P27, DOI 10.1016/j.jvcir.2017.11.006
   Kasban H, 2019, J AMB INTEL HUM COMP, V10, P2855, DOI 10.1007/s12652-018-1016-8
   Kasban H., 2012, INT J SIGNAL PROCESS, V5, P73
   Kasban H, 2008, THESIS
   KATO T, 1992, P SOC PHOTO-OPT INS, V1662, P112, DOI 10.1117/12.58497
   Kaur J., 2013, BIOMEDICAL IMAGES DE
   Kekre H. B., 2010, IJCSE INT J COMPUTER, V02, P2471
   Khatami A, 2018, EXPERT SYST APPL, V100, P224, DOI 10.1016/j.eswa.2018.01.056
   Khatami A, 2018, APPL SOFT COMPUT, V63, P197, DOI 10.1016/j.asoc.2017.11.024
   Kitanovski I, 2017, MULTIMED TOOLS APPL, V76, P2955, DOI 10.1007/s11042-016-3261-1
   Kumar A, 2016, COMPUT MED IMAG GRAP, V49, P37, DOI 10.1016/j.compmedimag.2016.01.001
   Kumar A, 2015, IEEE J BIOMED HEALTH, V19, P1734, DOI 10.1109/JBHI.2014.2361318
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Lan RS, 2018, COMPUT ELECTR ENG, V69, P669, DOI 10.1016/j.compeleceng.2018.01.027
   Li CR, 2017, PATTERN RECOGN, V64, P118, DOI 10.1016/j.patcog.2016.10.030
   Liu Y, 2016, NEUROCOMPUTING, V214, P894, DOI 10.1016/j.neucom.2016.07.024
   MAHAJAN VR, 2018, INT J ADV RES COMPUT, V7, P46
   Mandal M, 2019, IET COMPUT VIS, V13, P31, DOI 10.1049/iet-cvi.2018.5206
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   PRASAD BE, 1987, IEEE T IND ELECTRON, V34, P83, DOI 10.1109/TIE.1987.350929
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Reeves AP, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.2.024505
   Sakr NA, 2016, COMPUT ELECTR ENG, V54, P522, DOI 10.1016/j.compeleceng.2016.04.015
   Shamna P, 2019, J BIOMED INFORM, V91, DOI 10.1016/j.jbi.2019.103112
   Shinde A, 2019, BIOMED ENG LETT, V9, P387, DOI 10.1007/s13534-019-00112-0
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Singh VP, 2018, BIOCYBERN BIOMED ENG, V38, P90, DOI 10.1016/j.bbe.2017.09.003
   SONG J, 2015, J LATEX CLASS FILES, V14, P1
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Strang G., 1997, WAVELETS FILTER BANK
   Tang QL, 2018, J DIGIT IMAGING, V31, P107, DOI 10.1007/s10278-017-0017-z
   THANGARASU J, 2017, J COMPUT THEOR NANOS, V14, P3874
   Torjmen-Khemakhem M, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103210
   Vo A, 2010, SIGNAL PROCESS-IMAGE, V25, P28, DOI 10.1016/j.image.2009.09.003
   WANG J, 1997, INT J DIGIT LIB, V4, P311
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P256, DOI 10.1016/j.jvcir.2016.03.008
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang Y, 2019, J VIS COMMUN IMAGE R, V58, P130, DOI 10.1016/j.jvcir.2018.11.022
   Wu HY, 2016, NEUROCOMPUTING, V215, P110, DOI 10.1016/j.neucom.2015.05.147
   Yildizer E, 2012, KNOWL-BASED SYST, V31, P55, DOI 10.1016/j.knosys.2012.01.013
   Zhou J, 2018, MULTIMED TOOLS APPL
NR 72
TC 17
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35211
EP 35236
DI 10.1007/s11042-019-08100-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800044
DA 2024-07-18
ER

PT J
AU Srivastava, P
   Khare, A
AF Srivastava, Prashant
   Khare, Ashish
TI Content-based image retrieval using local ternary wavelet gradient
   pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Discrete wavelet transform; Local ternary
   pattern; Histogram of oriented gradients
ID COOCCURRENCE PATTERN; CURVELET TRANSFORM; DESCRIPTOR; COLOR; FEATURES;
   INTEGRATION; MOMENTS
AB With the invention of low cost image capturing devices, image acquisition is no longer a difficult task. The immense popularity of such devices has led to the production of large number of images. For accessing these images easily, efficient indexing and organization of images is required. The field of Content-Based Image Retrieval (CBIR) attempts to achieve this goal. This paper proposes a new multiresolution descriptor- Local Ternary Wavelet Gradient Pattern (LTWGP), for CBIR which combines shape feature and texture feature and utilizes this combination at multiple scales of image to construct feature vector for retrieval. DiscreteWavelet Transform (DWT) coefficients of grayscale image are computed followed by computation of Local Ternary Pattern (LTP) codes of resulting DWT coefficients. Finally, Histogram of Oriented Gradients (HOG) of resulting LTP codes is computed to construct feature vector. The advantage of this technique is that it computes texture through LTP which extracts complex structural arrangement of pixels more efficiently than other texture features such as Local Binary Pattern (LBP), and shape feature through HOG which measures shape of an object as a local feature without performing any segmentation operation. The combination of LTP and HOG is exploited at multiple resolutions of image through DWT to extract varying level of details so that the features left undetected at one level get detected at another level. The combination of LTP, HOG, and DWT constructs efficient feature descriptor which exploits multiple features at more than one resolution of image. The proposed feature descriptor efficiently extracts local directional information obtained through the combination of LTP and HOG at multiple levels of resolution decomposed through DWT. Performance of the proposed method is measured in terms of precision and recall and tested on four benchmark datasets, namely, Corel-1 K, Corel-5 K, Corel-10 K, and GHIM-10 K. The experimental results demonstrate that the proposed method outperforms other state-of-the-art CBIR techniques in terms of precision and recall.
C1 [Srivastava, Prashant] NIIT Univ, Neemrana, Rajasthan, India.
   [Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
C3 NIIT University, Rajasthan; University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM prashant.jk087@gmail.com; ashishkhare@hotmail.com
RI Khare, Ashish/D-4566-2012; Prakash, Om/AAL-4460-2021
OI Prakash, Om/0000-0001-6395-9989; Srivastava,
   Prashant/0000-0002-5812-2022
CR Agarwal M, 2012, INT J MULTIMED INF R, V1, P129, DOI 10.1007/s13735-012-0005-5
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Fu X, 2006, INT C PATT RECOG, P417
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Khare M, 2015, SIGNAL IMAGE VIDEO P, V9, P635, DOI 10.1007/s11760-013-0496-4
   Kumar A, 2013, 2013 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES (IMPACT), P159, DOI 10.1109/MSPCT.2013.6782109
   Liu GH, 2015, AER ADV ENG RES, V22, P838
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Long FH, 2003, SIG COM TEC, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ludwig O, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P432
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pal K, 2016, ENERG SYST, P297, DOI 10.1007/978-3-662-49434-9_13
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Srivastava P, 2014, 2 INT C CONT AW SYST, P228, DOI DOI 10.1007/978-3-319-05939-6_23
   Srivastava P, 2017, P INT C INT THINGS T, P85
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Srivastava P, 2018, COMPUT J, V61, P369, DOI 10.1093/comjnl/bxx086
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiwari AK, 2017, SIGNAL PROCESS-IMAGE, V53, P73, DOI 10.1016/j.image.2017.01.010
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yildizer E, 2012, KNOWL-BASED SYST, V31, P55, DOI 10.1016/j.knosys.2012.01.013
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
NR 43
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34297
EP 34322
DI 10.1007/s11042-019-08039-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800005
DA 2024-07-18
ER

PT J
AU Wang, XY
   Zhang, SY
   Wen, TT
   Zhang, W
   Yang, HY
AF Wang, Xiang-Yang
   Zhang, Si-Yu
   Wen, Tao-Tao
   Zhang, Wei
   Yang, Hong-Ying
TI Fusing PDTDFB magnitude and relative phase modeling for geometrical
   correction-based image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Geometric distortions; PDTDFB magnitude and relative
   phase; Statistical modeling; LS-SVR forecasting
ID SUPPORT VECTOR MACHINE; INTERBLOCK PREDICTION; DCT; SCHEME
AB Robustness, which refers to the ability that watermark signal survives various attacks, like additive noise, compression, rotation, etc., has played extremely important role in the multiple applications of digital watermarking. As one of the most difficult kinds of signal processing operations for a digital watermark to survive, geometric distortions have become a central problem in image watermarking research. Therefore, developing a greatly robust digital image watermarking approach, which can withstand geometrical distortions, remains a quite challenging work. In this paper, a new geometrical correction-based image watermarking approach using PDTDFB magnitude and relative phase modeling is proposed. This approach consists of digital watermark embedding, geometric distortions correction, and digital watermark extraction. In the watermark embedding process, PDTDFB (Pyramidal dual-tree directional filter bank) decomposition is performed on the original host image, followed by the low-pass subband partitioning. Watermark bit is inserted into low-pass subband block by modifying (quantization index modulation, QIM) the set of low-pass PDTDFB coefficients. In the geometric correction, the PDTDFB magnitude and relative phase are modeled by using Weibull distribution and Vonn distribution, respectively. Utilizing the compact statistical model parameters, the LS-SVR (Least squares support vector regression) correction is performed to estimate the geometrical distortions parameters. After LS-SVR geometrical correction, the watermark bits are extracted from the watermarked low-pass subband by employing the inverse QIM. Experimental results confirm that, under various well-known practical attacks, including common signal processing operations and geometrical distortions, the proposed approach performs well compared to conventional image watermarking methods.
C1 [Wang, Xiang-Yang; Zhang, Si-Yu; Wen, Tao-Tao; Zhang, Wei; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863; Zhang, siyu/0000-0002-0001-0204
FU National Natural Science Foundation of China [61701212, 61472171]; China
   Postdoctoral Science Foundation [2017 M621135, 2018 T110220]; High-level
   Innovation Talents Foundation of Dalian [2017RQ055]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61701212 & 61472171), China Postdoctoral
   Science Foundation (No. 2017 M621135, 2018 T110220), and High-level
   Innovation Talents Foundation of Dalian (No.2017RQ055).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Ahmed T, 2014, ADV INTELLIGENT SYST, VII, P281, DOI DOI 10.1007/978-3-319-03095-/1_31
   Andalibi M, 2015, IEEE T IMAGE PROCESS, V24, P5060, DOI 10.1109/TIP.2015.2476961
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Botta M, 2016, SIGNAL PROCESS, V119, P102, DOI 10.1016/j.sigpro.2015.07.018
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Kaur M, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY, PROCEEDINGS, P296, DOI 10.1109/ICIMT.2009.81
   Li JZ, 2014, 2014 IEEE 7TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC), P48, DOI 10.1109/ITAIC.2014.7065003
   Li J, 2017, STRUCT INFRASTRUCT E, V13, P683, DOI 10.1080/15732479.2016.1188125
   Liu Z, 2016, 8 INT C DIG IM PROC
   Murthy D., 2003, Weibull models, V358
   Nguyen TT, 2008, IEEE T SIGNAL PROCES, V56, P4661, DOI 10.1109/TSP.2008.927461
   Nguyen TT, 2008, IEEE T SIGNAL PROCES, V56, P4651, DOI 10.1109/TSP.2007.912897
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Song XH, 2014, MULTIMEDIA SYST, V20, P379, DOI 10.1007/s00530-014-0355-3
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Vo A, 2011, SIGNAL PROCESS, V91, P114, DOI 10.1016/j.sigpro.2010.06.014
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Xie Y, 2014, PROC SPIE, V9069, DOI 10.1117/12.2050051
   YAN X, 2013, SIVIP, V9, P499, DOI DOI 10.1007/s11760-013-0465-y
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhao Y, 2012, SCI CHINA INFORM SCI, V55, P650, DOI 10.1007/s11432-011-4470-x
NR 31
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34867
EP 34899
DI 10.1007/s11042-019-08058-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800029
DA 2024-07-18
ER

PT J
AU Zhang, J
   Zhu, XS
   Feng, JH
   Yang, YF
AF Zhang, Jie
   Zhu, Xiaoshu
   Feng, Junhong
   Yang, Yifang
TI Finding community of brain networks based on artificial bee colony with
   uniform design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain networks; Modularity; Artificial bee colony; Uniform design
ID EVOLUTIONARY ALGORITHM; COMPLEX NETWORKS; ORGANIZATION; MODULARITY;
   CONNECTIVITY
AB The brain networks can offer fundamental insights into healthy human cognition and the alteration in disease. Some neural unit modules in brain networks can provide us a great deal of useful information. It is appealing how to find these neural unit modules and how to partition the brain network into several dense modules. There are as high within-module densities as possible and as low between-module densities as possible in these dense modules. The modularity metrics can well evaluate whether a community is good or not. Therefore, we present a novel method to find community modules of brain networks in this study. It integrates uniform design into artificial bee colony (abbreviated as UABC) in order to maximize the modularity metrics. The difference between UABC and the other existing methods lies in that UABC is presented at the first time for detecting community modules. Several brain networks generated from functional MRI for studying Autism are used to test the proposed algorithm. Experimental results performing on these brain networks demonstrate that the proposed algorithm UABC can acquire better modularity and higher stability than other competing methods.
C1 [Zhang, Jie; Zhu, Xiaoshu; Feng, Junhong] Yulin Normal Univ, Sch Comp Sci & Engn, Yulin 537000, Guangxi, Peoples R China.
   [Zhang, Jie; Zhu, Xiaoshu; Feng, Junhong] Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Guangxi, Peoples R China.
   [Yang, Yifang] Xian Shiyou Univ, Coll Sci, Xian 710065, Shaanxi, Peoples R China.
C3 Yulin Normal University; Yulin Normal University; Xi'an Shiyou
   University
RP Zhu, XS (corresponding author), Yulin Normal Univ, Sch Comp Sci & Engn, Yulin 537000, Guangxi, Peoples R China.; Zhu, XS (corresponding author), Yulin Normal Univ, Guangxi Coll & Univ Key Lab Complex Syst Optimiza, Yulin 537000, Guangxi, Peoples R China.
EM jgxyzjzj@126.com; jgxyzxs@126.com; jgxyfjh@126.com;
   yangyifang@xsyu.edu.cn
OI Feng, Junhong/0000-0001-6443-3153; Zhang, Jie/0000-0002-1078-1766
FU National Natural Science Foundation of China [61841603, 61762087];
   Guangxi Natural Science Foundation [2018JJA170050, 2018JJA130028,
   2018JJA170175]; Scientific Research Plan Projects of Shaanxi Education
   Department [17JK0610]; Open Foundation for Guangxi Colleges and
   Universities Key Lab of Complex System Optimization and Big Data
   Processing [2017CSOBDP0301]
FX This research was supported by National Natural Science Foundation of
   China (No.61841603, No. 61762087), Guangxi Natural Science Foundation
   (No. 2018JJA170050, No.2018JJA130028, No.2018JJA170175), Scientific
   Research Plan Projects of Shaanxi Education Department (No. 17JK0610),
   and Open Foundation for Guangxi Colleges and Universities Key Lab of
   Complex System Optimization and Big Data Processing (No.
   2017CSOBDP0301).
CR Almeida H, 2011, LECT NOTES ARTIF INT, V6911, P44, DOI 10.1007/978-3-642-23780-5_13
   [Anonymous], SWARM EVOLUTIONARY C
   [Anonymous], P IEEE
   [Anonymous], SOFT COMPUT
   Azevedo FAC, 2009, J COMP NEUROL, V513, P532, DOI 10.1002/cne.21974
   Betzel RF, 2014, NEUROIMAGE, V102, P345, DOI 10.1016/j.neuroimage.2014.07.067
   Bilal S, 2017, PHYSICA A, V473, P89, DOI 10.1016/j.physa.2017.01.018
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Brown J, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00028
   Cao Y, 2019, COGN AFFECT BEHAV NE, V19, P154, DOI 10.3758/s13415-018-00652-5
   Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527
   Cui LZ, 2018, SOFT COMPUT, V22, P2217, DOI 10.1007/s00500-017-2485-y
   Dai C, 2015, APPL SOFT COMPUT, V30, P238, DOI 10.1016/j.asoc.2015.01.062
   Duch J, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.027104
   Feng JH, 2017, MULTIMED TOOLS APPL, V76, P17405, DOI 10.1007/s11042-016-3907-z
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Herculano-Houzel S, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.031.2009
   Jia LP, 2016, INT J COMPUT SCI ENG, V12, P38, DOI 10.1504/IJCSE.2016.074562
   Juneja A, 2018, MULTIMED TOOLS APPL, V77, P3963, DOI 10.1007/s11042-017-4404-8
   Karaboga D., 2005, Technical report-tr06
   Koenis MMG, 2018, HUM BRAIN MAPP, V39, P822, DOI 10.1002/hbm.23885
   Leung YW, 2000, IEEE T SYST MAN CY C, V30, P293, DOI 10.1109/5326.885111
   Li YX, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3106370
   Li ZP, 2008, PHYS REV E, V77, DOI 10.1103/PhysRevE.77.036109
   Liu J, 2010, PHYSICA A, V389, P2300, DOI 10.1016/j.physa.2010.01.042
   Liu J, 2017, COMPLEXITY, DOI 10.1155/2017/8362741
   LIU X, 2017, J COMPUT, V28, P93
   Mears D, 2016, J NEUROSCI RES, V94, P590, DOI 10.1002/jnr.23705
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Newman MEJ, 2013, PHYS REV E, V88, DOI 10.1103/PhysRevE.88.042822
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.066133
   Ning JX, 2018, NEURAL COMPUT APPL, V30, P775, DOI 10.1007/s00521-016-2687-8
   Papadakis H, 2014, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2014/03/P03013
   Power JD, 2011, NEURON, V72, P665, DOI 10.1016/j.neuron.2011.09.006
   Reichardt J, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.218701
   Rubinov M, 2010, NEUROIMAGE, V52, P1059, DOI 10.1016/j.neuroimage.2009.10.003
   Rubinov M, 2011, NEUROIMAGE, V56, P2068, DOI 10.1016/j.neuroimage.2011.03.069
   Rudie JD, 2013, NEUROIMAGE-CLIN, V2, P79, DOI 10.1016/j.nicl.2012.11.006
   Sporns O, 2004, TRENDS COGN SCI, V8, P418, DOI 10.1016/j.tics.2004.07.008
   Sporns O, 2011, ANN NY ACAD SCI, V1224, P109, DOI 10.1111/j.1749-6632.2010.05888.x
   Tian LP, 2018, NEUROCOMPUTING, V275, P2031, DOI 10.1016/j.neucom.2017.10.039
   Wang GX, 2008, PROG NAT SCI-MATER, V18, P1043, DOI 10.1016/j.pnsc.2008.03.015
   Wang YP, 2009, IEEE C EVOL COMPUTAT, P2927, DOI 10.1109/CEC.2009.4983311
   Wu XC, 2018, MULTIMED TOOLS APPL, V77, P3493, DOI 10.1007/s11042-017-5162-3
   Zalesky A, 2012, NEUROIMAGE, V60, P1055, DOI 10.1016/j.neuroimage.2012.01.068
   Zhang J, 2014, SOFT COMPUT, V18, P961, DOI 10.1007/s00500-013-1115-6
   Zhang J, 2013, SCI WORLD J, DOI 10.1155/2013/259347
   Zheng W, 2018, MULTIMED TOOLS APPL, V77, P29739, DOI 10.1007/s11042-017-5272-y
   Zhou XY, 2018, ANN OPER RES, V271, P1045, DOI 10.1007/s10479-018-2769-3
   Zhu X, 2015, GASTROENT RES PRACT, V2015, P1, DOI DOI 10.1093/JXB/ERV367
   Zhu XQ, 2019, IEEE T SMART GRID, V10, P4838, DOI 10.1109/TSG.2018.2869367
   Zhu XF, 2019, IEEE T KNOWL DATA EN, V31, P2022, DOI 10.1109/TKDE.2018.2873378
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zhu XS, 2019, GENES-BASEL, V10, DOI 10.3390/genes10020098
NR 57
TC 5
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33297
EP 33317
DI 10.1007/s11042-019-7472-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600033
DA 2024-07-18
ER

PT J
AU Ge, ZY
   Mahapatra, D
   Chang, XJ
   Chen, ZT
   Chi, LH
   Lu, HM
AF Ge, Zongyuan
   Mahapatra, Dwarikanath
   Chang, Xiaojun
   Chen, Zetao
   Chi, Lianhua
   Lu, Huimin
TI Improving multi-label chest X-ray disease diagnosis by exploiting
   disease and health labels dependencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chest X-Ray disease recognition; Multi-label learning; Deep
   convolutional neural network; Model fusion
AB The widely used ChestX-ray14 dataset addresses an important medical image classification problem and has the following caveats: 1) many lung pathologies are visually similar, 2) a variant of multiple diseases including lung cancer, tuberculosis, and pneumonia are present in a single scan at the same time, i.e. multiple labels. Existing literature uses state-of-the-art deep learning models being transfer learned where output neurons of the networks are trained for individual diseases to cater for multiple disease labels in each image. However, most of them don't consider the label relationship explicitly between present and absent classes. In this work we have proposed a pair of novel error functions that can be employed for any deep learning model, Multi-label Softmax Loss (MSML) and Correlation Loss (CorLoss), to specifically address the properties of multiple labels and visually similar data. Moreover, we provide a fine-grained perspective into this problem and use bilinear pooling as an encoding scheme to increase discrimination of the model. The experiments are conducted on the ChestX-ray14 dataset. We first report improvements using our proposed loss with various backbone networks. After that, we extend our experiments to prove the rich disparity being learned by the model with our proposed losses, which can be fused with other models to improve the overall performances.
C1 [Ge, Zongyuan; Chang, Xiaojun] Monash Univ, Clayton, Vic, Australia.
   [Ge, Zongyuan] Airdoc Res, Melbourne, Vic, Australia.
   [Ge, Zongyuan] Nividia AI Technol Ctr, Edinburgh, Midlothian, Scotland.
   [Mahapatra, Dwarikanath] IBM Res, Melbourne, Vic, Australia.
   [Chen, Zetao] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Chi, Lianhua] La Trobe Univ, Bundoora, Vic, Australia.
   [Lu, Huimin] Kyushu Inst Technol, Kitakyushu, Fukuoka, Japan.
C3 Monash University; IBM Research - Australia; Swiss Federal Institutes of
   Technology Domain; ETH Zurich; La Trobe University; Kyushu Institute of
   Technology
RP Ge, ZY (corresponding author), Monash Univ, Clayton, Vic, Australia.; Ge, ZY (corresponding author), Airdoc Res, Melbourne, Vic, Australia.; Ge, ZY (corresponding author), Nividia AI Technol Ctr, Edinburgh, Midlothian, Scotland.
EM zongyuan.ge@monash.edu
RI Chang, Xiaojun/A-2055-2015; Chi, Lianhua/AEW-2056-2022; Chen,
   Zetao/AAG-5530-2020; Chi, Lianhua/JAC-5202-2023
OI Chang, Xiaojun/0000-0002-7778-8807; Ge, Zongyuan/0000-0002-5880-8673
FU Airdoc
FX We would like to acknowledge the Airdoc for research funding support.
   The authors acknowledge Zitong Huang for driving useful discussions and
   support for the project. We also thank Nvidia AI Technology Centre for
   providing technical and hardware support for this project.
CR [Anonymous], 2017, Learning to diagnose from scratch by exploiting dependencies among labels
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238
   Ge ZY, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301271
   Ge ZY, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P442
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Kingma D. P., 2014, arXiv
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   LUKE MJ, 1966, PEDIATRICS, V37, P762
   Mahapatra D, 2018, LECT NOTES COMPUT SC, V11046, P73, DOI 10.1007/978-3-030-00919-9_9
   Martins AFT, 2016, PR MACH LEARN RES, V48
   Payer Christian, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P230, DOI 10.1007/978-3-319-46723-8_27
   Quan Z, 2018, WORLD WIDE WEB, V22, P1
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sedai S, 2018, LECT NOTES COMPUT SC, V11046, P267, DOI 10.1007/978-3-030-00919-9_31
   VERBEEK J, DISCRIMINATIVE METRI
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 31
TC 14
Z9 14
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14889
EP 14902
DI 10.1007/s11042-019-08260-2
EA NOV 2019
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000496214200001
DA 2024-07-18
ER

PT J
AU Tan, YJ
   Qin, J
AF Tan, Yongjie
   Qin, Jie
TI A reversible water marking algorithm for multimedia images using
   two-dimensional non-causal prediction and ESPVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia images; Reversible water marking algorithm; Morphological
   edge (ME); Two-dimensional non-causal prediction; Edge based sorted
   pixel value difference (ESPVD)
ID WATERMARKING
AB Reversible image watermarking algorithm is an important branch of information hiding, which can protect the integrity of data. Therefore, it is of great practical significance and practical value to study the reversible image water marking algorithm. A multimedia image watermarking algorithm based on two-dimensional non-causal prediction and edge based sorted pixel value difference (ESPVD) is proposed in this paper, which is used to protect the security of multimedia information. Firstly, the optimum prediction coefficients in the horizontal and vertical directions of image are calculated. Then, two-dimensional non-causal prediction of image is carried out according to raster scanning sequence, and prediction pixels and prediction errors are calculated. Finally, the morphological edge (ME) operator is used to identify edge pixel positions, and the ESPVD technology is used to embed the watermarking information. The experimental results show that the proposed algorithm has better performance than those of other image watermarking algorithms under the same embedding ability.
C1 [Tan, Yongjie; Qin, Jie] Zhoukou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466100, Henan, Peoples R China.
C3 Zhoukou Normal University
RP Tan, YJ (corresponding author), Zhoukou Normal Univ, Sch Comp Sci & Technol, Zhoukou 466100, Henan, Peoples R China.
EM zknutyj@126.com
FU Natural Science Foundation of China [U1504613]; Soft Science Research
   Project of Henan Intellectual Property Bureau [20170106036]
FX This work is supported by the Natural Science Foundation of China (No.
   U1504613) and the Soft Science Research Project of Henan Intellectual
   Property Bureau (No. 20170106036).
CR [Anonymous], 2016, INDIAN J SCITECHNOL
   [Anonymous], 2017, IEEE T INFORM FORENS
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Elshazly AR, 2017, INT J SPEECH TECHNOL, V20, P951, DOI 10.1007/s10772-017-9462-9
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Haribabu M, 2016, PROCEDIA COMPUT SCI, V93, P462, DOI 10.1016/j.procs.2016.07.234
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Jiang LP, 2019, MULTIMED TOOLS APPL, V78, P4397, DOI 10.1007/s11042-018-5766-2
   [李淑芝 Li Shuzhi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P411
   Pakdaman Z, 2016, MULTIMED TOOLS APPL, V76, P1
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Rahmani P, 2018, IET IMAGE PROCESS, V12, P1195, DOI 10.1049/iet-ipr.2016.0618
   Roy A, 2019, MULTIMED TOOLS APPL, V78, P1785, DOI 10.1007/s11042-018-6303-z
   Sakthivel SM, 2018, MULTIMED TOOLS APPL, V78:4, P27
   Ustubioglu A, 2019, MULTIMED TOOLS APPL, V78, P22269, DOI 10.1007/s11042-019-7529-0
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yu X, 2018, MULTIMED TOOLS APPL, V77, P18085, DOI 10.1007/s11042-018-5794-y
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
NR 20
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1625
EP 1640
DI 10.1007/s11042-019-08219-3
EA NOV 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000494794000001
DA 2024-07-18
ER

PT J
AU Li, Y
   Kong, XW
   Fu, HY
AF Li, Ying
   Kong, Xiangwei
   Fu, Haiyan
TI Exploring geometric information in CNN for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Spatial pooling; Feature weighting
ID SIMILARITY; FEATURES
AB Convolutional Neural Network (CNN) has brought significant improvements for various multimedia tasks. In contrast, image retrieval has not yet benefited as much since no training database is available. In this paper, we propose an unsupervised weighting scheme for pre-trained CNN models to adaptively emphasize image center. Different from the general preference for fully connected layers which represent abstract semantics, we aggregate the activations of convolutional layers on image patches to depict local patterns in details. It is an empirical observation that the target of searching is naturally the focus of an image. Thus we pooling the features with respect to their positions, since they innately maintain the geometric layout of an image. Experimental results on two benchmarks prove the effectiveness of our methods.
C1 [Li, Ying; Fu, Haiyan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Kong, Xiangwei] Zhejiang Univ, Dept Data Sci & Engn Management, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Dalian University of Technology; Zhejiang University
RP Kong, XW (corresponding author), Zhejiang Univ, Dept Data Sci & Engn Management, Hangzhou 310058, Zhejiang, Peoples R China.
EM kongxiangwei@zju.edu.cn
RI Kong, Xiangwei/IWL-9350-2023
OI Li, Ying/0000-0002-5695-4706
FU National Natural Science Foundation of China (NSFC) [61502073,
   61772111]; Foundation for Innovative Research Groups of the National
   Natural Science Foundation of China (NSFC) [71421001]; Fundamental
   Research Funds for the Central Universities [DUT18JC02]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant 61772111, in part by the
   Foundation for Innovative Research Groups of the National Natural
   Science Foundation of China (NSFC) under Grant 71421001, in part by the
   National Natural Science Foundation of China (NSFC) under Grant
   61502073, and in part by the Fundamental Research Funds for the Central
   UniversitiesDUT18JC02.
CR [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], 2014, IEEE C COMP VIS PATT
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai S, 2018, IEEE T PATTERN ANAL
   Bai S, 2017, IEEE I CONF COMP VIS, P774, DOI 10.1109/ICCV.2017.90
   Bai S, 2017, AAAI CONF ARTIF INTE, P3967
   Bai S, 2016, LECT NOTES COMPUT SC, V9906, P592, DOI 10.1007/978-3-319-46475-6_37
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Diaz IG, 2017, IEEE T MULTIMEDIA
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Husain SS, 2017, IEEE T PATTERN ANAL, V39, P1783, DOI 10.1109/TPAMI.2016.2613873
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Kumar M, 2018, MAR BIOTECHNOL, V20, P269, DOI 10.1007/s10126-018-9812-x
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li Ying., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P132
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Qin DF, 2013, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2013.211
   Radenovi F, 2018, IEEE T PATTERN ANAL
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun SY, 2017, INFORM SCIENCES, V417, P143, DOI 10.1016/j.ins.2017.07.004
   Tolias G., 2016, Conference Track Proceedings,
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   Zheng L., 2016, ARXIV160400133
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329
   Zhu YY, 2017, INFORM SCIENCES, V375, P246, DOI 10.1016/j.ins.2016.09.021
NR 40
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30585
EP 30598
DI 10.1007/s11042-018-6414-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200053
DA 2024-07-18
ER

PT J
AU Liu, PS
   Cui, H
   Cao, YM
   Hou, XH
   Zou, L
AF Liu, Pengsen
   Cui, Hui
   Cao, Yiming
   Hou, Xuehui
   Zou, Li
TI A method of multimedia teaching evaluation based on fuzzy linguistic
   concept lattice
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy linguistic concept lattice; Incomplete formal context; Rule
   extraction; Multimedia teaching evaluation
ID FORMAL CONCEPT ANALYSIS; DECISION-MAKING; ROUGH SETS; INFORMATION;
   CONSENSUS
AB With the development of multimedia technology, multimedia based teaching has become a popular style for educations. However, multimedia teaching evaluation performance is not an easy task as it involves human decision making which is imprecise, vague and uncertain. In order to acquire the effect of multimedia teaching in incomplete formal context, this paper mainly focuses on an algorithm of rule extraction based on incomplete multi-expert fuzzy linguistic formal decision context. Specifically, we propose a kind of fuzzy linguistic concept lattice combining with fuzzy linguistic information in uncertainty linguistic environment. The corresponding confidence level, the support degree of linguistic decision rules in fuzzy linguistic decision concept are discussed. Based on fuzzy linguistic formal context, we construct a multi-expert fuzzy linguistic concept lattice to handle multi-expert linguistic evaluation information. To address the scenario that the experts' weights are unknown, we present a maximization deviation method in multi-expert fuzzy linguistic formal context through the distance of linguistic evaluation matrix. Furthermore, we develop a linguistic aggregation operator of multi-expert fuzzy linguistic concept lattice to obtain the association rules. A novel linguistic completing method using similarity and average difference is proposed to deal with the information missing problem, which can make the linguistic evaluation information more compact and the decision results more reasonable. We validate the effectiveness and practicability of our method via an intuitive example of multimedia teaching evaluation.
C1 [Liu, Pengsen] Univ Elect Sci & Technol China, Glasgow Coll, Chengdu 610054, Sichuan, Peoples R China.
   [Cui, Hui; Cao, Yiming] Liaoning Normal Univ, Sch Math, Dalian 116029, Peoples R China.
   [Hou, Xuehui; Zou, Li] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
C3 University of Electronic Science & Technology of China; Liaoning Normal
   University; Liaoning Normal University
RP Zou, L (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116081, Peoples R China.
EM zoulicn@163.com
FU National Natural Science Foundation of P. R. China [61772250, 61673320,
   61672127]; Fundamental Research Funds for the Central Universities
   [2682017ZT12]
FX This work is partially supported by the National Natural Science
   Foundation of P. R. China (Nos.61772250, 61673320, 61672127), the
   Fundamental Research Funds for the Central Universities (No.
   2682017ZT12).
CR [Anonymous], 2010, OTECHNOL
   Baker JP, 2018, COMPUT EDUC, V126, P376, DOI 10.1016/j.compedu.2018.08.003
   Cabrerizo FJ, 2018, EXPERT SYST APPL, V99, P83, DOI 10.1016/j.eswa.2018.01.030
   Cintra ME, 2016, INFORM SCIENCES, V349, P199, DOI 10.1016/j.ins.2016.02.026
   Djouadi Yassine, 2010, Computational Intelligence for Knowledge-Based Systems Design. Proceedings 13th International Conference on Information Processing and Management of Uncertainty, IPMU 2010, P260, DOI 10.1007/978-3-642-14049-5_27
   Ganter B, 1999, FORMAL CONCEPT ANAL, P157
   Gong WM, 2018, COGN SYST RES, V52, P678, DOI 10.1016/j.cogsys.2018.08.005
   Hai W, 2018, INFORM FUSION, V43, P1, DOI 10.1016/j.inffus.2017.11.010
   Hartman H, 2018, COMPUT EDUC, V125, P202, DOI 10.1016/j.compedu.2018.06.014
   Herrera F, 1996, FUZZY SET SYST, V78, P73, DOI 10.1016/0165-0114(95)00107-7
   Herrera F., 1998, FUZZY SETS SYST, V115, P67
   Huysegoms Tom, 2013, PROCESS TECHNOL INT, V9, P189, DOI DOI 10.1016/J.PROTCY.2013.12.021
   Krupka M, 2012, COMMUNICATIONS COMPU, V299, P171
   Kumar CA, 2015, MATH COMPUT SIMULAT, V109, P46, DOI 10.1016/j.matcom.2014.08.004
   Lakhal L, 2005, LECT NOTES ARTIF INT, V3626, P180
   Lekha A., 2015, Journal of Computer Science, V11, P71, DOI 10.3844/jcssp.2015.71.74
   Li CC, 2018, KNOWL-BASED SYST, V145, P156, DOI 10.1016/j.knosys.2018.01.011
   Li J, 2018, TOURISM MANAGE, V69, P317, DOI 10.1016/j.tourman.2018.06.027
   Li JH, 2017, INT J APPROX REASON, V80, P100, DOI 10.1016/j.ijar.2016.08.007
   Li JH, 2016, KNOWL-BASED SYST, V91, P152, DOI 10.1016/j.knosys.2015.07.024
   Li JH, 2013, INT J APPROX REASON, V54, P149, DOI 10.1016/j.ijar.2012.07.005
   Li Jinxi Michelle, 2016, [Journal of Human Resource Management Research, 인적자원관리연구], V23, P1, DOI 10.14396/jhrmr.2016.23.1.1
   Liang DC, 2015, APPL SOFT COMPUT, V29, P256, DOI 10.1016/j.asoc.2015.01.008
   Montoneri B, 2012, TEACH TEACH EDUC, V28, P382, DOI 10.1016/j.tate.2011.11.006
   Nan Guan, 2018, Procedia Computer Science, V131, P727, DOI 10.1016/j.procs.2018.04.317
   Pang Q, 2016, INFORM SCIENCES, V369, P128, DOI 10.1016/j.ins.2016.06.021
   Poelmans Jonas, 2012, Advances in Data Mining. Applications and Theoretical Aspects. Proceedings 12th Industrial Conference, ICDM 2012, P273, DOI 10.1007/978-3-642-31488-9_22
   Poelmans J, 2013, EXPERT SYST APPL, V40, P6538, DOI 10.1016/j.eswa.2013.05.009
   Priss U, 2006, ANNU REV INFORM SCI, V40, P521, DOI 10.1002/aris.1440400120
   Quan TT, 2009, 2009 IEEE RIVF INT C, P1, DOI DOI 10.1109/RIVF.2009.5174619
   Shen LQ, 2018, NURSE ED TODAY
   Singh PK, 2014, INFORM SCIENCES, V288, P437, DOI 10.1016/j.ins.2014.07.038
   Spector J.M., 2013, Handbook of research on educational communications and technology, V4th
   Valtchev P, 2004, LECT NOTES ARTIF INT, V2961, P352
   Wang Y., 1997, J. Syst. Eng. Electron, V8, P21
   Wang Y, 2018, IEEE T NEUR NET LEAR, V29, P4833, DOI 10.1109/TNNLS.2017.2777489
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wille R, 2009, LECT NOTES ARTIF INT, V5548, P314
   Wu L, 2019, IEEE T NEURAL NETWOR
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Xu WH, 2016, IEEE T CYBERNETICS, V46, P366, DOI 10.1109/TCYB.2014.2361772
   Xu ZS, 2013, KNOWL-BASED SYST, V52, P53, DOI 10.1016/j.knosys.2013.05.011
   Yan HB, 2017, COMPUT IND ENG, V109, P15, DOI 10.1016/j.cie.2017.03.032
   Yang L, 2008, COMP INT DEC CONTR I
   Zadeh LA, 1974, LEARNING SYSTEMS INT
   Zaki MJ, 2004, DATA MIN KNOWL DISC, V9, P223, DOI 10.1023/B:DAMI.0000040429.96086.c7
NR 49
TC 25
Z9 25
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30975
EP 31001
DI 10.1007/s11042-019-7669-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200072
DA 2024-07-18
ER

PT J
AU Papadimitriou, S
   Chrysafiadi, K
   Virvou, M
AF Papadimitriou, Spyros
   Chrysafiadi, Konstantina
   Virvou, Maria
TI FuzzEG: Fuzzy logic for adaptive scenarios in an educational adventure
   game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy logic; Edutainment; Adventure games; Adaptive games
ID LEARN
AB Nowadays, there is an increased interest in using computer games for educational purposes. Educational computer games attempt to increase the students' motivation and engagement. However, they should provide adaptivity to learners' different needs and characteristics for better educational results. Towards this direction, this paper presents a novel adaptive educational game named FuzzEG, which teaches the knowledge domain of HTML programming language. It uses fuzzy sets to represent the learner's knowledge level more realistically. Taking into consideration the learner's progress, the game decides about the level of difficulty of the quizzes and whether the scenario is going to be dynamically expanded or not. The gain of this is that it provides the learner with a personalised learning and gaming experience. The game has been evaluated, and the results are very encouraging.
C1 [Papadimitriou, Spyros; Chrysafiadi, Konstantina; Virvou, Maria] Univ Piraeus, Dimitriou Str 80, GR-18534 Piraeus, Greece.
C3 University of Piraeus
RP Papadimitriou, S (corresponding author), Univ Piraeus, Dimitriou Str 80, GR-18534 Piraeus, Greece.
EM spap@unipi.gr; kchrysafiadi@unipi.gr; mvirvou@unipi.gr
RI Chrysafiadi, Konstantina/AAR-2315-2021; VIRVOU, Maria/AAR-1415-2021
OI Papadimitriou, Spyros/0000-0003-2581-1195; VIRVOU,
   MARIA/0000-0002-4008-4654
CR Boyle T., 1997, Design for Multimedia Learning
   Chrysafiadi K, 2016, ADV PERSONALIZED WEB
   Chrysafiadi K, 2010, SMART INNOV SYS, V6, P23
   D'Apice C, 2015, J VISUAL LANG COMPUT, V31, P260, DOI 10.1016/j.jvlc.2015.10.004
   Drigas AS, 2009, COMM COM INF SC, V49, P552
   ESA, 2014, ESA 2014 ANN REP
   Gaeta M, 2014, COMPUT HUM BEHAV, V31, P620, DOI 10.1016/j.chb.2013.07.011
   Hou HT, 2014, COMPUT HUM BEHAV, V30, P29, DOI 10.1016/j.chb.2013.07.052
   Jeremic Z, 2012, EXPERT SYST APPL, V39, P210, DOI 10.1016/j.eswa.2011.07.010
   Karpinskyj S, 2014, ENTERTAIN COMPUT, V5, P211, DOI 10.1016/j.entcom.2014.09.002
   Lo JJ, 2012, COMPUT EDUC, V58, P209, DOI 10.1016/j.compedu.2011.08.018
   Marti-Parreno J, 2017, COMPUTERS HUMAN BEHA
   Mehm Florian, 2012, E-Learning and Games for Training, Education, Health and Sports. Proceedings of the 7th International Conference, Edutainment 2012 and 3rd International Conference, GameDays 2012, P144, DOI 10.1007/978-3-642-33466-5_16
   Minovic M, 2015, COMPUT HUM BEHAV, V47, P98, DOI 10.1016/j.chb.2014.09.005
   Moreno-Ger P, 2007, SCI COMPUT PROGRAM, V67, P3, DOI 10.1016/j.scico.2006.07.003
   Papadopoulos S, 2018, J BUILD PERFORM SIMU, V11, P322, DOI 10.1080/19401493.2017.1354919
   Papert S., 1993, The children's machine: rethinking school in the age of the computer
   Peirce N, 2008, DIGITEL 2008: SECOND IEEE INTERNATIONAL CONFERENCE ON DIGITAL GAME AND INTELLIGENT TOY ENHANCED LEARNING, PROCEEDINGS, P28, DOI 10.1109/DIGITEL.2008.30
   Petri G, 2017, COMPUT EDUC, V107, P68, DOI 10.1016/j.compedu.2017.01.004
   Pilegard C, 2016, CONTEMP EDUC PSYCHOL, V44-45, P12, DOI 10.1016/j.cedpsych.2015.12.002
   Pivec M, 2007, BRIT J EDUC TECHNOL, V38, P387, DOI 10.1111/j.1467-8535.2007.00722.x
   Polycarpou I, 2010, PROCD SOC BEHV, V9, DOI 10.1016/j.sbspro.2010.12.246
   Riemer V, 2015, COMPUT EDUC, V88, P160, DOI 10.1016/j.compedu.2015.05.003
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Virvou M, 2008, COMPUT EDUC, V50, P154, DOI 10.1016/j.compedu.2006.04.004
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   Zapata-Rivera D, 2010, LECT NOTES COMPUT SC, V6095, P435
NR 27
TC 17
Z9 17
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32023
EP 32053
DI 10.1007/s11042-019-07955-w
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000046
DA 2024-07-18
ER

PT J
AU Tang, LL
   Li, ZH
   Su, JY
   Lu, HF
   Li, ZY
   Pang, Z
   Zhang, Y
AF Tang, Linlin
   Li, Zuohua
   Su, Jingyong
   Lu, Huifen
   Li, Zhangyan
   Pang, Zhen
   Zhang, Yong
TI Kernel nearest-farthest subspace classifier for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Kernel function; Nearest-farthest subspace classifier
ID LINEAR-REGRESSION; EIGENFACES
AB In this paper, a novel classifier named Kernel Nearest-Farthest Subspace (KNFS) classifier is proposed for face recognition. Inspired by the kernel-based classifier and the Nearest-Farthest Subspace (NFS) classifier, KNFS can make the sample points to be linear separable by utilizing the kernel function to map linear inseparable sample points in low-dimensional space to high-dimensional kernel space. And it can improve the recognition accuracy of crossed sample points between classes. The algorithm provides the highest reported recognition accuracy on AR and AT&T database. The results are comparable with many other state-of-art face recognition algorithms.
C1 [Tang, Linlin; Li, Zuohua; Lu, Huifen; Li, Zhangyan; Pang, Zhen] Harbin Inst Technol, Shenzhen, Peoples R China.
   [Su, Jingyong] Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA.
   [Zhang, Yong] Shenzhen Univ, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; Texas Tech University System; Texas Tech
   University; Shenzhen University
RP Tang, LL (corresponding author), Harbin Inst Technol, Shenzhen, Peoples R China.
EM hittang@126.com
RI sun, jiamin/JPY-2155-2023; liu, peiyao/KFT-1810-2024
FU Shenzhen Science and Technology Plan Fundamental Research Funding
   [JCYJ20180306171938767]; Shenzhen Foundational Research Funding
   [JCYJ20180507183527919]; Shenzhen Technology Innovation
   [JCYJ20170811160003571, JCYJ20170302145623566]
FX This work was supported by Shenzhen Science and Technology Plan
   Fundamental Research Funding JCYJ20180306171938767 and Shenzhen
   Foundational Research Funding JCYJ20180507183527919. And it was also
   partly supported by the Shenzhen Technology Innovation with grant number
   JCYJ20170811160003571 and JCYJ20170302145623566.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Abeni P, 2006, CAN C COMP ROB VIS, P42
   Argyri AA, 2010, SENSOR ACTUAT B-CHEM, V145, P146, DOI 10.1016/j.snb.2009.11.052
   Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chien Y, 1973, WILEY, V19, P462
   Comon BP, 2014, SIGNAL PROCESS, V36, P11
   Feng QX, 2015, IEEE IMAGE PROC, P3630, DOI 10.1109/ICIP.2015.7351481
   Gao QB, 2007, PATTERN RECOGN, V40, P346, DOI 10.1016/j.patcog.2006.06.033
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Huang SM, 2013, IEEE SIGNAL PROC LET, V20, P91, DOI 10.1109/LSP.2012.2230257
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li HQ, 2004, LECT NOTES COMPUT SC, V3322, P716
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu YW, 2014, NEURAL COMPUT APPL, V24, P1843, DOI 10.1007/s00521-013-1435-6
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Mi JX, 2013, NEUROCOMPUTING, V113, P241, DOI 10.1016/j.neucom.2013.01.003
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nastar C, 1996, IEEE T PATTERN ANAL, P18
   Pan JS, 2015, IEEE T CIRC SYST VID, V25, P387, DOI 10.1109/TCSVT.2014.2351092
   Peng YZ, 2019, IEEE T IND INFORM, V15, P822, DOI 10.1109/TII.2018.2810284
   Tsai PW, 2014, IEEE SYST J, V8, P395, DOI 10.1109/JSYST.2012.2208153
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
NR 29
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32007
EP 32021
DI 10.1007/s11042-019-07897-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000045
DA 2024-07-18
ER

PT J
AU Xie, ZW
   Li, L
   Zhong, X
   He, Y
   Zhong, L
AF Xie, Zhongwei
   Li, Lin
   Zhong, Xian
   He, Yang
   Zhong, Luo
TI Enhancing multimodal deep representation learning by fixed model reuse
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal representation learning; Fixed model reuse; Multilingual OCR;
   Long-text-based image retrieval
ID NETWORKS
AB As we all know, inconsistent distribution and representation of different modalities, such as image, text and audio, cause the "media gap", which poses a great challenge to deal with such heterogeneous data. Currently, state-of-the-art multimodal approaches mainly focus on the data provided by target task, neglecting the extra information on different but related tasks. In this paper, we explore a multimodal representation learning architecture by leveraging embedding representation trained from extra information. Specifically speaking, the approach of fixed model reuse is integrated into our architecture, which can incorporate helpful information from existing models/features into a new model. Based on our proposed architecture, we study multilingual OCR and long-text-based image retrieval tasks. Multilingual OCR is a difficult task that deals with multiple languages on the same page. We take advantage of extra textual embedding layer in an existing text-generating model to improve the accuracy of multilingual OCR. As for the long-text-based image retrieval, a cross-modal task, intermediate visual embedding layer in an off-the-shelf image-captioning model is leveraged to enhance the retrieval ability. The experimental results validate the effectiveness of our proposed architecture on narrowing down the "media gap" and yield observable improvement in these two tasks. Our architecture outperform the state-of-the-art approaches by 4.2% improvements in terms of accuracy in multilingual OCR task and yields improvement from 9 to 6 with regard to the median rank of retrieval result in long-text-based image retrieval task.
C1 [Xie, Zhongwei; Li, Lin; Zhong, Xian; He, Yang; Zhong, Luo] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan Shi, Peoples R China.
C3 Wuhan University of Technology
RP Xie, ZW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan Shi, Peoples R China.
EM kevinsnest@whut.edu.cn
RI Li, Li/AEM-3636-2022; ARSLAN, Okan/AAA-3232-2020; li, li/HII-4157-2022
OI Zhong, Xian/0000-0002-5242-0467; Xie, Zhongwei/0000-0001-6346-0707
FU National Social Science Foundation of China [15BGL048]; Hubei Province
   Science and Technology Support Project [2015BAA072]; Hubei Provincial
   Natural Science Foundation of China [2017CFA012]; Fundamental Research
   Funds for the Central Universities [WUT: 2017II39GX]
FX This work is supported by the National Social Science Foundation of
   China (Grant No: 15BGL048), Hubei Province Science and Technology
   Support Project (Grant No: 2015BAA072), Hubei Provincial Natural Science
   Foundation of China (Grant No: 2017CFA012), The Fundamental Research
   Funds for the Central Universities (WUT: 2017II39GX).
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2017, WHAT AND WHERE MATCH
   [Anonymous], 2014, RES J APPL SCI ENG T
   Baird H. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P62, DOI 10.1109/ICDAR.1993.395781
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Breuel TM, 2008, PROC SPIE, V6815, DOI 10.1117/12.783598
   Chrupala G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P613, DOI 10.18653/v1/P17-1057
   Clinchant S., 2011, ICMR, P44
   Firmani D., 2017, CEUR Workshop Proceedings, V2034, P9
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Klein E, 2015, PROC CVPR IEEE, P4437, DOI 10.1109/CVPR.2015.7299073
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Quoc V., 2014, P INT C MACH LEARN I
   Li D., 2003, P 11 ACM INT C MULTI, P604
   Li N, 2013, IEEE T PATTERN ANAL, V35, P1370, DOI 10.1109/TPAMI.2012.172
   Liu Y., 2010, Proc. ACM International Conference on Image and Video Re- trieval, P89, DOI DOI 10.1145/1816041.1816057
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Peng YW, 2017, INT GEOL REV, V59, P1344, DOI 10.1080/00206814.2016.1236354
   Philip Bindu, 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P252, DOI 10.1109/ICETET.2009.14
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Silberer C, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P721
   Smith RLL, 2009, GENOME MED, V1, DOI 10.1186/gm72
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Song RH, 2016, DATA SCI ENG, V1, P101, DOI 10.1007/s41019-016-0012-2
   Srivastava N., 2012, INT C MACH LEARN WOR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5181
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Ul-Hasan A., 2013, P 4 INT WORKSH MULT, P9, DOI DOI 10.1145/2505377.2505394
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang DX, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2291
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Weston J, 2011, IJCAI
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Yang Y, 2017, AAAI CONF ARTIF INTE, P2831
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang LH, 2015, INT CONF SOFTW ENG, P931, DOI 10.1109/ICSESS.2015.7339207
   Zhou ZH, 2016, LEARNWARE FUTURE MAC
NR 53
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30769
EP 30791
DI 10.1007/s11042-018-6556-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200062
DA 2024-07-18
ER

PT J
AU Ma, JB
   Wang, RL
   Ji, WT
   Zheng, H
   Zhu, E
   Yin, JP
AF Ma, Junbo
   Wang, Ruili
   Ji, Wanting
   Zheng, Hao
   Zhu, En
   Yin, Jianping
TI Relational recurrent neural networks for polyphonic sound event
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things; smart environment; deep neural networks; recurrent
   neural networks; sound event detection
AB A smart environment is one of the application scenarios of the Internet of Things (IoT). In order to provide a ubiquitous smart environment for humans, a variety of technologies are developed. In a smart environment system, sound event detection is one of the fundamental technologies, which can automatically sense sound changes in the environment and detect sound events that cause changes. In this paper, we propose the use of Relational Recurrent Neural Network (RRNN) for polyphonic sound event detection, called RRNN-SED, which utilized the strength of RRNN in long-term temporal context extraction and relational reasoning across a polyphonic sound signal. Different from previous sound event detection methods, which rely heavily on convolutional neural networks or recurrent neural networks, the proposed RRNN-SED method can solve long-lasting and overlapping problems in polyphonic sound event detection. Specifically, since the historical information memorized inside RRNNs is capable of interacting with each other across a polyphonic sound signal, the proposed RRNN-SED method is effective and efficient in extracting temporal context information and reasoning the unique relational characteristic of the target sound events. Experimental results on two public datasets show that the proposed method achieved better sound event detection results in terms of segment-based F-score and segment-based error rate.
C1 [Ma, Junbo; Wang, Ruili; Ji, Wanting] Massey Univ, Auckland, New Zealand.
   [Ma, Junbo] Natl Univ Def Technol, Sch Comp, Changsha, Hunan, Peoples R China.
   [Wang, Ruili; Ji, Wanting] Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Zheng, Hao] Nanjing Xiaozhuang Univ, Coll informat Engn, Nanjing, Jiangsu, Peoples R China.
   [Zhu, En] Natl Univ Def Technol, Sch Comp, Changsha, Hunan, Peoples R China.
   [Yin, Jianping] Dongguan Univ Technol, Comp Sci, Dongguan, Peoples R China.
C3 Massey University; National University of Defense Technology - China;
   Zhejiang Gongshang University; Nanjing Xiaozhuang University; National
   University of Defense Technology - China; Dongguan University of
   Technology
RP Wang, RL; Ji, WT (corresponding author), Massey Univ, Auckland, New Zealand.; Wang, RL; Ji, WT (corresponding author), Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
EM nudt_mjb@outlook.com; Wang@massey.ac.nz; jwt@escience.cn;
   zhh710@163.com; enzhu@nudt.edu.cn; jpyin@dgut.edu.cn
RI Ma, Junbo/AAT-5699-2021; zheng, hao/JQI-4215-2023; LEE, YU/JXY-2338-2024
OI Ma, Junbo/0000-0002-5859-8389; 
FU National Key RAMP;D Program of China [2018YFB1003203]; Natural Science
   Foundation of Zhejiang Province [LY18F010008]; National Science
   Foundation of China [61672528, 61773392]; Marsden Fund of New Zealand
FX This work is partially supported by the National Key R&D Program of
   China (2018YFB1003203), the Natural Science Foundation of Zhejiang
   Province (No. LY18F010008), the National Science Foundation of China
   (No. 61672528, 61773392), and the Marsden Fund of New Zealand.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adavanne S, 2017, INT CONF ACOUST SPEE, P771, DOI 10.1109/ICASSP.2017.7952260
   [Anonymous], IEEE COMMUN SURV TUT
   [Anonymous], 2015, P IEEE INT JOINT C N, DOI DOI 10.1109/IJCNN.2015.7280624
   [Anonymous], IEEE DET CLASS AC SC
   [Anonymous], 2017, DIGITAL COMMUNICATIO
   [Anonymous], IEEE AASP CHALL DET
   [Anonymous], DET CLASS AC SCEN EV
   [Anonymous], ARXIV171002997
   [Anonymous], 2017, ARXIV170602293
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], ARXIV180109522
   [Anonymous], 2017, P DCASE MUN GERM 16
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, arXiv preprint arXiv:1708.03211
   Çakir E, 2017, IEEE-ACM T AUDIO SPE, V25, P1291, DOI 10.1109/TASLP.2017.2690575
   Cakir Emre, 2018, JCNN, P1
   Chen Y, 2017, DCASE2017 SOUND EVEN
   Dang A, 2017, INT CONF ORANGE TECH, P75, DOI 10.1109/ICOT.2017.8336092
   Heittola T, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-1
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jeong I.-Y., 2017, DETECTION CLASSIFICA
   Kingma D. P., 2014, arXiv
   Li P, 2018, IEEE T IND INFORM, V14, P790, DOI 10.1109/TII.2017.2739340
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Mesaros A, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060162
   Mesaros A, 2015, INT CONF ACOUST SPEE, P151, DOI 10.1109/ICASSP.2015.7177950
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Morrison D, 2005, 2005 IEEE International Conference on Granular Computing, Vols 1 and 2, P583
   Morrison D, 2005, Third International Conference on Information Technology and Applications, Vol 1, Proceedings, P483
   Ozer I, 2018, NEUROCOMPUTING, V272, P505, DOI 10.1016/j.neucom.2017.07.021
   Parascandolo G, 2016, INT CONF ACOUST SPEE, P6440, DOI 10.1109/ICASSP.2016.7472917
   Poliner GE, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/48317
   Santoro A., 2018, ARXIV180601822
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu T.H., 2016, DETECTION CLASSIFICA
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zhang HM, 2016, INTERSPEECH, P2977, DOI 10.21437/Interspeech.2016-392
   Zhou J, 2017, Sound event detection in multichannel audio LSTM network. Detection and classification of acoustic scenes and events
NR 42
TC 5
Z9 6
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29509
EP 29527
DI 10.1007/s11042-018-7142-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700060
DA 2024-07-18
ER

PT J
AU Ma, MY
   Mei, SH
   Wan, S
   Wang, ZY
   Feng, DD
AF Ma, Mingyang
   Mei, Shaohui
   Wan, Shuai
   Wang, Zhiyong
   Feng, David Dagan
TI Robust video summarization using collaborative representation of
   adjacent frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Sparse representation; Dictionary selection;
   Robustness
ID SELECTION
AB With the ever increasing volume of video content, efficient and effective video summarization (VS) techniques are urgently demanded to manage a large amount of video data. Recent developments on sparse representation based approaches have demonstrated promising results for VS. However, these existing approaches treat each frame independently, so the performance can be greatly influenced by each individual frame. In this paper, we formulate the VS problem with a collaborative representation model to take the visual similarity of adjacent frames into consideration. To be specific, during the procedure of reconstruction, both each individual frame and their adjacent frames are reconstructed collaboratively, so the impact of an individual frame can be weakened. In addition, a greedy iterative algorithm is designed for model optimization, where the sparsity and the average percentage of reconstruction (APOR) are adopted to control the iteration. Experimental results on two benchmark datasets with various types of videos demonstrate that the proposed method not only outperforms the state of the art, but also improves the robustness to transitional frames and "outlier" frames.
C1 [Ma, Mingyang] Northwestern Polytech Univ, Informat & Commun Engn, Xian, Shaanxi, Peoples R China.
   [Mei, Shaohui] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Wan, Shuai] Northwestern Polytech Univ, Xian, Shaanxi, Peoples R China.
   [Wang, Zhiyong] Univ Sydney, Multimedia Lab, Sch Informat Technol, Sydney, NSW, Australia.
   [Feng, David Dagan] Univ Sydney, Biomed & Multimedia Informat Technol Res Grp, Sydney, NSW, Australia.
   [Feng, David Dagan] Univ Sydney, Inst Biomed Engn & Technol, Sydney, NSW, Australia.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Northwestern Polytechnical University; University of Sydney;
   University of Sydney; University of Sydney
RP Mei, SH (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
EM meish@nwpu.edu.cn
RI Wan, Shuai/AAA-8777-2022; Ma, Mingyang/JXM-3330-2024; Mei,
   Shao-Hui/AAB-9154-2022; Ma, Mingyang/AAA-8074-2022
OI Wan, Shuai/0000-0001-8617-149X; MEI, Shaohui/0000-0002-8018-596X; Ma,
   Mingyang/0000-0002-2944-628X; Feng, Dagan/0000-0002-3381-214X
FU National Natural Science Foundation of China [61671383]; Fundamental
   Research Funds for the Central Universities [3102018AX001]
FX This work is partially supported by National Natural Science Foundation
   of China (61671383) and the Fundamental Research Funds for the Central
   Universities (3102018AX001).
CR [Anonymous], 2014, 2014 IEEE INT C MULT
   Besiris D, 2009, MULTIMED TOOLS APPL, V44, P161, DOI 10.1007/s11042-009-0277-9
   Cong Y, 2017, IEEE T IMAGE PROCESS, V26, P185, DOI 10.1109/TIP.2016.2619260
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Demir B, 2016, 2016 NATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND BIOMEDICAL ENGINEERING (ELECO), P710
   Deng W., 2017, IEEE transactions on pattern analysis and machine intelligence
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Etezadifar P, 2016, MULTIMED TOOLS APPL, P1
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   GAO T, 2017, MULTIMED TOOLS APPL, V76, p12,89, DOI DOI 10.1007/s11042-016-3701-y
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Li BX, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P132, DOI 10.1109/IVL.2001.990867
   Liu D, 2010, IEEE T PATTERN ANAL, V32, P2178, DOI 10.1109/TPAMI.2010.31
   Liu HP, 2014, IEEE T IND INFORM, V10, P1736, DOI 10.1109/TII.2014.2330798
   Lu SY, 2014, IEEE T MULTIMEDIA, V16, P1497, DOI 10.1109/TMM.2014.2319778
   Ma MY, 2017, IEEE IMAGE PROC, P2911, DOI 10.1109/ICIP.2017.8296815
   Ma MY, 2017, IEEE INT CON MULTI, P637, DOI 10.1109/ICME.2017.8019387
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Peyrard N, 2005, MULTIMED TOOLS APPL, V26, P259, DOI 10.1007/s11042-005-0891-0
   Song Y, 2015, COMPUTER VISION PATT
   Tao G, 2017, PATTERN RECOGN, V69, P124, DOI 10.1016/j.patcog.2017.04.010
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   WU J, 2017, MULTIMED TOOLS APPL, V76, P1, DOI DOI 10.1007/s11042-016-3569-x
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yin XX, 2017, HEALTH INFOR SCI, DOI 10.1007/978-3-319-57027-3
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
NR 32
TC 4
Z9 4
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28985
EP 29005
DI 10.1007/s11042-018-6053-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700035
DA 2024-07-18
ER

PT J
AU Qin, X
   Ji, WT
   Wang, RL
   Yuan, CA
AF Qin, Xiao
   Ji, Wanting
   Wang, Ruili
   Yuan, ChangAn
TI Learnt dictionary based active learning method for environmental sound
   event tagging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of things; Dictionary learning; Sparse coding; Active learning;
   k-medoids clustering; Sound event tagging
ID MATCHING PURSUITS; CLASSIFICATION; ALGORITHM; SPEECH
AB Sound event tagging is a process that adds texts or labels to sound segments based on their salient features and/or annotations. In the real world, since annotating cost is much expensive, tagged sound segments are limited, while untagged sound segments can be obtained easily and inexpensively. Thus, semi-automatic tagging becomes very important, which can assign labels to massive untagged sound segments according to a small number of manually annotated sound segments. Active learning is an effective technique to solve this problem, in which selected sound segments are manually tagged while other sound segments are automatically tagged. In this paper, a learnt dictionary based active learning method is proposed for environmental sound event tagging, which can significantly reduce the annotating cost in the process of semi-automatic tagging. The proposed method is based on a learnt dictionary, as dictionary learning is more adapt to sound feature extraction. Moreover, tagging accuracy and annotating cost are used to measure the performance of the proposed method. Experimental results demonstrate that the proposed method has higher tagging accuracy but requires much less annotating cost than other existing methods.
C1 [Qin, Xiao; Yuan, ChangAn] Nanning Normal Univ, Nanning, Peoples R China.
   [Ji, Wanting; Wang, Ruili] Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Ji, Wanting; Wang, Ruili] Massey Univ, Auckland, New Zealand.
C3 Nanning Normal University; Zhejiang Gongshang University; Massey
   University
RP Ji, WT (corresponding author), Zhejiang Gongshang Univ, Hangzhou, Zhejiang, Peoples R China.; Ji, WT (corresponding author), Massey Univ, Auckland, New Zealand.
EM 7670172@qq.com; jwt@escience.cn; prof.ruili.wang@gmail.com;
   68852917@qq.com
FU National Natural Science Foundation of Guangxi [2016GXNSFAA380209,
   2014GXNSFDA118037]; Natural Science Foundation of Zhejiang Province
   [LY18F010008]; BBAGUI Scholar Program of Guangxi Zhuang Autonomous
   Region of China; project of Scientific Research and Technology
   Development in Guangxi [AB16380272, AA18118047]; project of Scientific
   Research and Technology Development in Guangxi Nanning [20175177]
FX This work is partially supported by the National Natural Science
   Foundation of Guangxi under Grant (2016GXNSFAA380209,
   2014GXNSFDA118037), the Natural Science Foundation of Zhejiang Province
   (No. LY18F010008), the BBAGUI Scholar Program of Guangxi Zhuang
   Autonomous Region of China, the project of Scientific Research and
   Technology Development (AB16380272, AA18118047) in Guangxi, and the
   project of Scientific Research and Technology Development (#20175177) in
   Guangxi Nanning.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], J MACH LEARN RES
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, COMPUTER ENG NETWORK
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   Duan SF, 2014, ARTIF INTELL REV, V42, P637, DOI 10.1007/s10462-012-9362-y
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Fleury A, 2008, IEEE ENG MED BIO, P4644, DOI 10.1109/IEMBS.2008.4650248
   Foggia P, 2016, IEEE T INTELL TRANSP, V17, P279, DOI 10.1109/TITS.2015.2470216
   Gadde A, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P492, DOI 10.1145/2623330.2623760
   Han WJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0162075
   Jayalakshmi SL, 2018, APPL ACOUST, V139, P113, DOI 10.1016/j.apacoust.2018.04.026
   Jin Xin, 2011, ENCY MACHINE LEARNIN, P564, DOI DOI 10.1007/978-0-387-30164-8_426
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Maijala P, 2018, APPL ACOUST, V129, P258, DOI 10.1016/j.apacoust.2017.08.006
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Morrison D, 2005, 2005 IEEE International Conference on Granular Computing, Vols 1 and 2, P583
   Morrison D, 2005, Third International Conference on Information Technology and Applications, Vol 1, Proceedings, P483
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Ren JF, 2017, IEEE T MULTIMEDIA, V19, P447, DOI 10.1109/TMM.2016.2618218
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Schroeder J, 2016, INT CONF ACOUST SPEE, P6455, DOI 10.1109/ICASSP.2016.7472920
   Sharan RV, 2017, INFORM SCIENCES, V396, P24, DOI 10.1016/j.ins.2017.02.013
   Shen J, 2017, PR IEEE I C PROGR IN, P179, DOI 10.1109/PIC.2017.8359538
   Shi YH, 2013, APPL INTELL, V38, P16, DOI 10.1007/s10489-012-0354-z
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Tüysüzoglu G, 2018, EXPERT SYST APPL, V91, P364, DOI 10.1016/j.eswa.2017.09.024
   Vera-Candeas P, 2004, IEEE SIGNAL PROC LET, V11, P349, DOI 10.1109/LSP.2003.822904
   Wang C-Y, 2017, IEEEACM T AUDIO SPEE, P1
   Wang YG, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P15, DOI 10.1109/MMIT.2008.15
   Ye JX, 2017, APPL ACOUST, V117, P246, DOI 10.1016/j.apacoust.2016.08.002
   Zhao SY, 2017, IEEE WORK APPL SIG, P16, DOI 10.1109/WASPAA.2017.8169986
   Zhao SY, 2017, INT CONF ACOUST SPEE, P751, DOI 10.1109/ICASSP.2017.7952256
   Zhu XF, 2018, IEEE T KNOWL DATA EN, V30, P517, DOI 10.1109/TKDE.2017.2763618
NR 42
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29493
EP 29508
DI 10.1007/s11042-018-7139-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700059
DA 2024-07-18
ER

PT J
AU Shrivastava, K
   Kumar, S
   Jain, DK
AF Shrivastava, Kush
   Kumar, Shishir
   Jain, Deepak Kumar
TI An effective approach for emotion detection in multimedia text data
   using sequence based convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia data; Emotion detection; Deep learning; Convolutional neural
   network; Deep neural network
ID AGREEMENT; RECOGNITION; EXPRESSION; SPEECH
AB In the recent trends, the world has stepped into a multimedia era for enhancing business, recommendation systems, and information retrieval, etc. Multimedia data is highly rich in contents which express different human emotions. Several issues for emotion detection from multimedia images & videos have been addressed in this domain, but a very less effort has been applied for text data. The evaluation of deep learning has outperformed traditional techniques in sentiment analysis tasks. Inspired by the work done in the field of sentiment analysis, a deep learning based framework has been implemented on multimedia text data for the task of fine-grained emotion detection. The presented work introduces a new corpus which expresses different forms of emotions collected from a TV show's transcript. A manual annotation of the corpus has been conducted with the help of English expert annotators. As an emotion detection framework, this paper proposes a sequence-based convolutional neural network(CNN) with word embedding to detect the emotions. An attention mechanism is applied in the proposed model which allows CNN to focus on the words that have more effect on the classification or the part of the features that should be attended more. The main aim of the work is to develop a framework such a way to generalize to newly collected data and help business to understand the customer's mind and social media monitoring as it allows us to gain an overview of the wider public opinion behind certain topics. Experiments conducted on the dataset shows that the proposed framework correctly detects the emotions from the text with good precision and accuracy score.
C1 [Shrivastava, Kush; Kumar, Shishir] Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
   [Jain, Deepak Kumar] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Kumar, S (corresponding author), Jaypee Univ Engn & Technol, Dept Comp Sci & Engn, Guna, MP, India.
EM kush.shri05@gmail.com; shishir.kumar@juet.ac.in;
   deepak.juet@cripac.ia.ac.cn
RI Kumar, Shishir/AAE-9164-2020
CR Altman DG, 1991, PRACTICAL STAT MED R
   Aman S, 2007, LECT NOTES ARTIF INT, V4629, P196
   [Anonymous], 2015, 2015 International Joint Conference on Neural Networks (IJCNN)
   [Anonymous], 2015, NIPS
   [Anonymous], 2013, HUMAN EMOTIONS
   [Anonymous], 2005, P 14 ACM INT C INF
   [Anonymous], 2018, NONTECHNICAL SURVEY
   [Anonymous], 2014, 52 ANN M ASS COMP LI
   [Anonymous], 2005, P HUM LANG TECHN C C, DOI DOI 10.3115/1220575.1220648
   [Anonymous], 2017, PATTERN RECOGNITION
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 1995, CONVOLUTIONAL NETWOR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ACOUST SPEECH SIG PR
   [Anonymous], 2012, CSI J COMPUTING
   [Anonymous], NUMBER RASA
   [Anonymous], 2017, ELECTRON LETT, DOI DOI 10.1049/el.2016.4328
   [Anonymous], ARXIV160902748
   [Anonymous], 1962, Affect imagery consciousness: Volume I: The positive affects
   [Anonymous], INTELLIGENT COMPUTAT
   Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2
   Bahdanau Dzmitry, 2014, NEURAL MACHINE TRANS
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chorowski J, 2015, ADV NEUR IN, V28
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Figijeiredo S, 2017, PORTA LINGUARUM, P21
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Gao K, 2015, EXPERT SYST APPL, V42, P4517, DOI 10.1016/j.eswa.2015.01.064
   Garcia D., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P483, DOI 10.1109/PASSAT/SocialCom.2011.219
   Geertzen J., 2012, Interrater agreement with multiple raters and variables
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Ghazi D., 2010, P NAACL HLT 2010 WOR, P140
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo L, 2018, LECT NOTES COMPUT SC, V11157, P571, DOI 10.1007/978-3-030-00847-5_42
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Islam J, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P124, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.29
   Jain VK, 2018, J COMPUT SCI-NETH, V25, P406, DOI 10.1016/j.jocs.2017.07.003
   Jain VK, 2018, INT J ENTERP INF SYS, V14, P77, DOI 10.4018/IJEIS.2018040105
   Jain VK, 2017, ADV BUS INFORM SYST, P125, DOI 10.4018/978-1-5225-2148-8.ch008
   Jain VK, 2017, J COMPUT SCI-NETH, V21, P316, DOI 10.1016/j.jocs.2017.01.010
   Johnson Rie, 2015, Adv Neural Inf Process Syst, V28, P919
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Kingma D. P., 2014, arXiv
   Krippendorff K, 1995, SOCIOL METHODOL, V25, P47, DOI 10.2307/271061
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei JS, 2014, FUTURE GENER COMP SY, V37, P438, DOI 10.1016/j.future.2013.09.024
   Levi G, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P503, DOI 10.1145/2823327.2823333
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu P, 2016, 2016 17TH INTERNATIONAL CONFERENCE ON ELECTRONIC PACKAGING TECHNOLOGY (ICEPT), P1480, DOI 10.1109/ICEPT.2016.7583403
   Lopes AT, 2015, SIBGRAPI, P273, DOI 10.1109/SIBGRAPI.2015.14
   Mishne G., 2005, P ACM SIGIR 2005 WOR, P321
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Mohammad SaifM., 2011, Proceedings of the 2nd Workshop on Com- putational Approaches to Subjectivity and Sentiment Analysis (ACL-HLT) 2011, P70
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   NOWLAN SJ, 1992, NEURAL COMPUT, V4, P473, DOI 10.1162/neco.1992.4.4.473
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Plutchik R., 1990, EMOTION, P3, DOI [10.1016/B978-0-12-558705-1.50007-5, DOI 10.1016/B978-0-12-558705-1.50007-5]
   Raghuvanshi A., 2016, Facial expression recognition with convolutional neural networks
   Read J, 2012, LANG RESOUR EVAL, V46, P421, DOI 10.1007/s10579-010-9135-7
   Rolls E.T., 2016, CEREBRAL CORTEX PRIN
   Scherer Klaus R., 1997, The ISEAR Questionnaire and Codebook
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schuff J., 2017, P 8 WORKSHOP COMPUTA, P13
   Sorjonen M.L., 2012, Emotion in Interaction
   Stergiou Christos., 2010, Neural Networks
   Strapparava C., 2004, Lrec, Volume, V4, P1083
   Strapparava C., 2007, P 4 INT WORKSH SEM E, P70
   Strapparava C, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tang Y, 2013, ARXIV
   Xi Ouyang, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P2359, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.349
   Yanaru T, 1997, INFORM SCIENCES, V101, P217, DOI 10.1016/S0020-0255(97)00011-X
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   Zhang Xiang., 2015, Text Understanding From Scratch
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 90
TC 37
Z9 37
U1 1
U2 68
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29607
EP 29639
DI 10.1007/s11042-019-07813-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700065
DA 2024-07-18
ER

PT J
AU Veni, M
   Meyyappan, T
AF Veni, M.
   Meyyappan, T.
TI Digital image Watermark embedding and extraction using oppositional
   fruit Fly algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Singular value decomposition; Variance;
   Oppositional fruit Fly algorithm; Mean square error; Normalize
   correlation and peak signal to noise ratio
ID FRAGILE WATERMARKING; DISCRETE WAVELET; AUTHENTICATION; DETECTOR
AB The proposed method discusses digital image watermark embedding and extraction utilizing discrete wavelet transform and singular value decomposition (DWT-SVD) as well as oppositional fruit fly algorithm. Initially, for partitioning the original input image into several sub-bands DWT-SVD is utilized. After decomposition variance value is calculated for all sub bands and the band with low variance is selected for further process. Then Oppositional Fruit Fly Algorithm (OFA) is used for optimal position selection of selected low variance blocks for embedding the watermark bits. In order to perform the embedding process at first, the conversion of watermark image into its corresponding bits occurs. Then the generated watermark bit is added together with gold code and the combination is utilized for performing watermark embedding. The method used for retrieving the watermarked image from the original image is called watermark extraction. The performance of the proposed image watermarking scheme is analyzed through various metrics such as the Mean square error (MSE), Normalize correlation (NC) and the peak signal to noise ratio (PSNR). The proposed scheme maintains the embedding quality with an average PSNR value of 47.49 dB.
C1 [Veni, M.; Meyyappan, T.] Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
C3 Alagappa University
RP Veni, M (corresponding author), Alagappa Univ, Dept Comp Sci, Karaikkudi, Tamil Nadu, India.
EM venim0711@gmail.com
OI T, MEYYAPPAN/0000-0001-5568-1278
CR Abuturab RM, 2016, ELSEVIER OPTICS LASE, P1
   AL-Nabhani Y, 2015, J KING SAUD UNIV-COM, V27, P393, DOI 10.1016/j.jksuci.2015.02.002
   [Anonymous], EVID BASED COMPLEMEN
   [Anonymous], 2016, EXPERT SYST APPL
   Bouslimia D, 2016, ELSEVIER SIGNAL PROC, P1
   Gonge SS, 2016, PROCEDIA COMPUT SCI, V89, P732, DOI 10.1016/j.procs.2016.06.046
   Hu H, 2016, ELSEVIER INT J ELECT, P1
   Khandare S, 2016, PROCEDIA COMPUT SCI, V78, P698, DOI 10.1016/j.procs.2016.02.119
   Liu XY, 2016, ENERGY STORAGE MATER, V3, P1, DOI 10.1016/j.ensm.2015.12.002
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Nayak MR, 2016, ELSEVIER INT J ELECT, V71, P1
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Shao Z., 2016, EXP MECH, P1
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Su P-C, 2016, ELSEVIER J VISUAL CO, P1
   Thien H-T, 2016, ELSEVIER EXPERT SYST, P1
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wójtowicz W, 2016, J VIS COMMUN IMAGE R, V38, P1, DOI 10.1016/j.jvcir.2016.02.006
   Zhi-qiua X, 2016, EFFECT EMOTIONAL MOT, P1
NR 24
TC 19
Z9 19
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27491
EP 27510
DI 10.1007/s11042-019-7650-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000032
DA 2024-07-18
ER

PT J
AU Zhang, JD
   Yin, XL
   Luan, J
   Liu, T
AF Zhang, Jindong
   Yin, Xuelong
   Luan, Jing
   Liu, Tong
TI An improved vehicle panoramic image generation algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle panoramic image; Fisheye image correction; Inverse perspective
   mapping; Image mosaic
AB In order to reduce the traffic accidents caused by the blind area, vehicle panoramic view system has been paid more and more attention. However, the panoramic system is a complex and difficult system. In this paper, we propose an improved vehicle panoramic image generation algorithm. Several key technologies have been improved to ensure reliability and efficiency. First of all, we improve the spherical perspective projection algorithm (SPP) based on the scanning line idea and bilinear interpolation to rectification the fisheye image. Then the inverse perspective projection mapping of undistorted image is used to obtain a top view. In order to reduce computation, the method of manually selecting the target point is carried out. Finally, SURF algorithm is used to find the feature points between the bird's-eye view images around vehicle. We further put forward to utilize a RANSAC algorithm based on block matching to eliminate the mismatched points in the key point matching process. Experimental results indicate that our vehicle panoramic image generation method works efficiently. The proposed algorithm can effectively remove the serious distortion of fisheye lens, and generate a panoramic image around the vehicle in the end. It possesses good robustness, and can be widely used.
C1 [Zhang, Jindong; Yin, Xuelong; Liu, Tong] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
   [Zhang, Jindong] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.
   [Zhang, Jindong] Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Jilin, Peoples R China.
   [Luan, Jing] Jilin Univ, Coll Software, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Zhang, JD (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Jilin, Peoples R China.; Zhang, JD (corresponding author), Jilin Univ, State Key Lab Automobile Simulat & Control, Changchun 130025, Jilin, Peoples R China.
EM zhangjindong_100@163.com
FU National Key Research and Development Program of China [2017YFB0102500];
   Natural Science Foundation of Jilin province [20170101133JC]; Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018; Jilin University
   [5157050847, 2017XYB252]
FX This work was supported by the National Key Research and Development
   Program of China (Grant No. 2017YFB0102500); the Natural Science
   Foundation of Jilin province (Grant No. 20170101133JC); the Korea
   Foundation for Advanced Studies' International Scholar Exchange
   Fellowship for the academic year of 2017-2018, and Jilin University
   (Grant No. 5157050847, 2017XYB252).
CR [Anonymous], 2014, IEEE CVPR WORKSH
   Bawa VS, 2017, IMAGE ANAL STEREOL, V36, P141, DOI 10.5566/ias.1660
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cai CT, 2016, INT C COMP SUPP COOP, P411, DOI 10.1109/CSCWD.2016.7566024
   Dong Q, 2017, J ELECTRON INF TECHN, V39, P444, DOI 10.11999/JEIT160324
   Dou JF, 2018, OPTIK, V171, P850, DOI 10.1016/j.ijleo.2018.06.094
   Gao Y, 2018, IEEE T INTELL TRANSP, V19, P320, DOI 10.1109/TITS.2017.2750087
   He Y, 2018, OPTIK, V152, P21, DOI 10.1016/j.ijleo.2017.09.075
   Imran M, 2018, 2018 INTERNATIONAL CONFERENCE ON ENGINEERING & EMERGING TECHNOLOGIES (ICEET), P1
   Ji XY, 2018, IEEE T INTELL TRANSP, V19, P518, DOI 10.1109/TITS.2017.2784486
   Lai SM, 2014, OPT REV, V21, P162, DOI 10.1007/s10043-014-0025-x
   Lee JH, 2017, TRANS ELECTR ELECTRO, V18, P273, DOI 10.4313/TEEM.2017.18.5.273
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu Y, 2016, 30 AAAI C ART INT
   Liu Y, 2015, 24 INT JOINT C ART I
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2018, COMPUT SCI ENG, V20, P10, DOI 10.1109/MCSE.2018.110112927
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI [10.1109/TMAG.2017.2763198, 10.1007/s11263-018-1117-z]
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   NBoSo C, 2017, CHIN STAT YB
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Tiwari U, 2015, MAN MACH INT MAMI 20, P1
   Tu B, 2013, APPL OPTICS, V52, pC37, DOI 10.1364/AO.52.000C37
   Turturici M, 2014, J REAL-TIME IMAGE PR, V9, P463, DOI 10.1007/s11554-013-0330-9
   Victoria BA, 2017, 2017 14 INT C EL ENG, P1
   Vourvoulakis J, 2018, MULTIMED TOOLS APPL, V77, P9393, DOI 10.1007/s11042-017-5042-x
   Vourvoulakis J, 2017, MICROPROCESS MICROSY, V49, P105, DOI 10.1016/j.micpro.2016.11.011
   Wu JH, 2019, MULTIMED TOOLS APPL, V78, P877, DOI 10.1007/s11042-018-5763-5
   Yan WQ, 2017, IEEE T CIRC SYST VID, V27, P1934, DOI 10.1109/TCSVT.2016.2564838
   Yang Z, 2019, MULTIMED TOOLS APPL, V78, P11983, DOI 10.1007/s11042-018-6744-4
   Yeh Yen-Ting., 2014, Asian Conference on Computer Vision, P403
   Yin XL, 2019, MULTIMED TOOLS APPL, V78, P12203, DOI 10.1007/s11042-018-6762-2
   Ying Xiang-Hua, 2003, Chinese Journal of Computers, V26, P1702
   Zeng QH, 2017, OPTIK, V137, P268, DOI 10.1016/j.ijleo.2017.02.091
   Zhang J, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417540064
   Zhang Y N, 2017, J HEALTHCARE ENG, V2017, P2017
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhonglong Xiong, 2011, 2011 International Conference on Multimedia Technology, P456
   Zhou WG, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P204, DOI 10.1109/RCAR.2016.7784026
NR 42
TC 14
Z9 15
U1 3
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27663
EP 27682
DI 10.1007/s11042-019-07890-w
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000040
DA 2024-07-18
ER

PT J
AU Lin, JY
   Chen, Y
   Chang, CC
   Hu, YC
AF Lin, Jiang-Yi
   Chen, Yu
   Chang, Chin-Chen
   Hu, Yu-Chen
TI Dual-image-based reversible data hiding scheme with integrity
   verification using exploiting modification direction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Exploiting modification direction (EMD);
   Dual-image; Shadow; Image quality; Pixel-value differencing (PVD)
ID VQ INDEX TABLE
AB In this paper, a novel dual-image-based reversible data hiding scheme using exploiting modification direction (EMD) is proposed. This scheme embeds two 5-base secret digits into each pixel pair of the cover image simultaneously according to the EMD matrix to generate two stego-pixel pairs. By shifting these stego-pixel pairs to the appropriate locations in some cases, two meaningful shadows are produced. The secret data can be extracted accurately, and the cover image can be reconstructed completely in the data extraction and the image reconstruction procedure, respectively. Experimental results show that our scheme outperforms the comparative methods in terms of image quality and embedding ratio. Pixel-value differencing (PVD) histogram analysis reveals that our scheme achieves a higher security. Moreover, a tampered shadow can effectively be detected through the proposed scheme.
C1 [Lin, Jiang-Yi] Xiamen Univ Technol, Sch Comp & Informat Engn, Xiamen 361024, Fujian, Peoples R China.
   [Lin, Jiang-Yi; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chen, Yu] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Fujian, Peoples R China.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; Fujian University
   of Technology; Providence University - Taiwan
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
EM ychu@pu.edu.tw
RI Hui, Yu/JOZ-3598-2023; Hu, Yu-Chen/AAT-5264-2020; Chang,
   Ching-Chun/JAN-6210-2023
OI Hu, Yu-Chen/0000-0002-5055-3645; 
CR Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   [Anonymous], 2013, P 3 INT C INFORM COM
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang IC, 2015, SIGNAL PROCESS, V108, P376, DOI 10.1016/j.sigpro.2014.09.036
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Hu YC, 2006, PATTERN RECOGN, V39, P1715, DOI 10.1016/j.patcog.2006.02.005
   Jung KH, 2018, MULTIMED TOOLS APPL, V77, P7795, DOI 10.1007/s11042-017-5066-2
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Lee K.-H., 2009, P 3 INT C UB INF MAN, P228, DOI [10.1145/1516241.1516281.11T.-C, DOI 10.1145/1516241.1516281.11T.-C]
   Li F, 2018, MULTIMED TOOLS APPL, V77, P5149, DOI 10.1007/s11042-017-4388-4
   Li SH, 2007, J DATABASE MANAGE, V18, P1, DOI 10.4018/jdm.2007100101
   Liu L, 2017, MULTIMED TOOLS APPL, V75, P11311
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Liu YJ, 2018, MULTIMED TOOLS APPL, V77, P25295, DOI 10.1007/s11042-018-5785-z
   Liu YJ, 2018, DISPLAYS, V51, P51, DOI 10.1016/j.displa.2018.01.004
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Nguyen TS, 2016, MULTIMED TOOLS APPL, V75, P8513, DOI 10.1007/s11042-015-2768-1
   Nguyen TS, 2015, DISPLAYS, V39, P109, DOI 10.1016/j.displa.2015.10.003
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wu NI, 2017, DISPLAYS, V49, P116, DOI 10.1016/j.displa.2017.07.009
   Yu CM, 2011, DISPLAYS, V32, P225, DOI 10.1016/j.displa.2011.02.004
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 29
TC 14
Z9 15
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25855
EP 25872
DI 10.1007/s11042-019-07783-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700028
DA 2024-07-18
ER

PT J
AU Alphonse, AS
   Starvin, MS
AF Alphonse, A. Sherly
   Starvin, M. S.
TI A novel maximum and minimum response-based Gabor (MMRG) feature
   extraction method for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMRG; Emotion; Feature; Classification; ELM
ID EXTREME LEARNING-MACHINE; TEXTURE CLASSIFICATION; NEURAL-NETWORKS; BAT
   ALGORITHM; FACE; PATTERN; OPTIMIZATION; KERNEL; SCALE
AB In facial expression recognition applications, the images are corrupted with random noise, and this affects the classification accuracy. This article proposes a maximum and Minimum Response-based Gabor (MMRG) that can encode the facial texture more discriminatively and eliminate random noise. Two code images are produced from the available Gabor images. Then, after dividing the code images into grids, feature vectors are formed using histograms. A technique based on the bat algorithm is proposed for the optimization of the Gabor filter banks as Bat Algorithm-based Gabor Optimization (BAGO). The MMRG increases the efficiency of Gabor filter-based features by precisely distinguishing the texture frequencies. It also helps in reducing the dimensions of feature vector which is a major problem in Gabor filter-based feature extraction. Radial Basis Function-Extreme Learning Machine (RBF-ELM) classifier is used for a faster and accurate multi-classification. The proposed approach has been evaluated with six datasets namely, Japanese Female Facial Expression (JAFFE), Cohn Kanade (CK+), Multi-media Understanding Group (MUG), Static Facial Expressions in the Wild (SFEW), Oulu-Chinese Academy of Science, Institute of Automation (Oulu-CASIA) and Man-Machine Interaction (MMI) datasets to meet a classification accuracy of 97.2, 97.4, 95.4, 35.4, 87.4 and 82.3% for seven class emotion detection, which is high when compared to other state-of -the-art methods.
C1 [Alphonse, A. Sherly] Anna Univ, Dept CSE, Reg Campus, Tirunelveli 627007, India.
   [Starvin, M. S.] Univ Coll Engn, Dept Mech Engn, Nagercoil 629004, India.
C3 Anna University; Anna University of Technology Tirunelveli; Anna
   University; Anna University of Technology Tirunelveli
RP Alphonse, AS (corresponding author), Anna Univ, Dept CSE, Reg Campus, Tirunelveli 627007, India.
EM sherls82@gmail.com; mstarvin@gmail.com
RI M.S, Starvin/AAK-5377-2021
OI M S, STARVIN/0000-0002-8192-5034; , sherly/0000-0002-0019-9940
CR Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Ahmed F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P265, DOI 10.1109/ICCE.2012.6161859
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Alphonse AS, 2018, MULTIMED TOOLS APPL, V77, P9455, DOI 10.1007/s11042-017-5141-8
   Alphonse AS, 2017, J VIS COMMUN IMAGE R, V49, P459, DOI 10.1016/j.jvcir.2017.10.008
   Alphonse AS, 2017, EXPERT SYST APPL, V90, P127, DOI 10.1016/j.eswa.2017.08.013
   Anisetti M, 2009, STUD COMPUT INTELL, V226, P401
   [Anonymous], ARXIV14083264CS
   [Anonymous], EMOTION RECOGNITION
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], ARXIV170307140
   [Anonymous], INT J BIOL BIOMED EN
   [Anonymous], SIGNAL PROCESS IMAGE
   [Anonymous], ARXIV15040
   [Anonymous], INT C INF SCI APPL I
   [Anonymous], COMP VIS PATT REC WO
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Doerner K, 2004, ANN OPER RES, V131, P79, DOI 10.1023/B:ANOR.0000039513.99038.c6
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Khokher R, 2015, MACROMOL SYMP, V347, P16, DOI 10.1002/masy.201400045
   Konak A, 2006, RELIAB ENG SYST SAFE, V91, P992, DOI 10.1016/j.ress.2005.11.018
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M., 2007, FACE RECOGNITION, P377
   PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394
   Rangayyan R. M., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P170, DOI 10.1109/SIBGRA.2000.883910
   Reyes-Sierra M., 2006, International Journal of Computational Intelligence Research, V2, P287, DOI DOI 10.5019/J.IJCIR.2006.68
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shen W, 2015, PROC CVPR IEEE, P3982, DOI 10.1109/CVPR.2015.7299024
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Valstar MF, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, pJ65
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   Xiao-li Hao, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P419, DOI 10.1007/978-981-10-5041-1_68
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang XS, 2013, INT J BIO-INSPIR COM, V5, P141, DOI 10.1504/IJBIC.2013.055093
   Yang XS, 2011, INT J BIO-INSPIR COM, V3, P267, DOI 10.1504/IJBIC.2011.042259
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7206041
NR 72
TC 10
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23369
EP 23397
DI 10.1007/s11042-019-7646-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400052
DA 2024-07-18
ER

PT J
AU Tang, FH
   Zhang, XY
   Lu, XK
   Hu, SQ
   Zhang, HL
AF Tang, Fuhui
   Zhang, Xiaoyu
   Lu, Xiankai
   Hu, Shiqiang
   Zhang, Huanlong
TI Robust visual tracking based on spatial context pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Convolutional neural network; Discriminative
   correlation filter; Spatial window; Context pyramid
ID OBJECT TRACKING; SET
AB In recent years, discriminative correlation filter (DCF) has gained a lot of popularity in visual tracking, mainly due to its circular sampling from limited training data and computational efficiency in Fourier domain. However, such trackers do not make reasonable use of context information, resulting in limited performance. In this paper, we propose a novel DCF tracking framework based on spatial context pyramid (SCPT) to overcome this problem. Firstly, we take global spatial context into account to exploit the relationship between the target and its context for better tracking. Secondly, we design an effective spatial window to highlight the target while suppressing the background, and thus a robust filter model which has a high response for the target and low response for the background can be learned. Thirdly, we construct a context pyramid representation using multi-level spatial windows for adapting different challenging factors. To validate the compatibility of the proposed algorithm, we implement two versions with the representations from both conventional features and deep convolutional neural network (CNN) features. Extensive experimental results on the OTB-2013 benchmark demonstrate the effectiveness of the proposed tracker in terms of accuracy and robustness.
C1 [Tang, Fuhui; Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
   [Zhang, Xiaoyu] Shanghai Dianji Univ, Sch Elect Engn, Shanghai 201306, Peoples R China.
   [Lu, Xiankai] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.
   [Zhang, Huanlong] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 450002, Henan, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Dianji University; Shanghai Jiao
   Tong University; Zhengzhou University of Light Industry
RP Hu, SQ (corresponding author), Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
EM 419830756@qq.com; hxyzhang@126.com; carrierlxk@sjtu.edu.cn;
   sqhu@sjtu.edu.cn; zhl_lit@163.com
RI xiaoyu, zhang/JXY-7226-2024; LI, XIAO/IQV-9318-2023; Zhang,
   xiaoyu/HTM-3222-2023; Zhang, Xiaoyu/ISV-0984-2023; Wang,
   Zixuan/HZJ-2348-2023; Zhang, xiaoyu/GXA-3206-2022; zhang,
   huanlong/AAE-3160-2020; zhang, xiaoyu/HJI-4374-2023; xiaoyu,
   zhang/GQH-0475-2022
FU National Natural Science Foundation of China [61773262, 61503173]; China
   Aviation Science Foundation [20142057006]
FX This work is supported by the National Natural Science Foundation of
   China (61773262, 61503173), China Aviation Science Foundation
   (20142057006).
CR [Anonymous], ARXIV150104587
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Boddeti VN, 2013, PROC CVPR IEEE, P2291, DOI 10.1109/CVPR.2013.297
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu S, 2016, PROC CVPR IEEE, P4312, DOI 10.1109/CVPR.2016.467
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ni BB, 2008, IEEE T CIRC SYST VID, V18, P1075, DOI 10.1109/TCSVT.2008.927108
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang M, 2017, PROC INT CONF DATA, P21, DOI 10.1109/ICDE.2017.17
   Wang N, 2013, P ADV NEURAL INFORM
   Wang ZP, 2017, MULTIMED TOOLS APPL, V76, P12181, DOI 10.1007/s11042-016-3289-2
   Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang HL, 2018, IEEE ACCESS, V6, P75383, DOI 10.1109/ACCESS.2018.2872524
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou ZP, 2016, MULTIMED TOOLS APPL, V75, P3145, DOI 10.1007/s11042-014-2427-y
NR 47
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21065
EP 21084
DI 10.1007/s11042-019-7416-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400023
DA 2024-07-18
ER

PT J
AU Xia, M
AF Xia, Mu
TI Multimedia based multi-fault diagnosis of satellite sensor based on
   gauss Bayesian algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gauss; Bayesian; Satellite; Sensor; Multiple fault diagnosis
AB A fault diagnosis method based on Gauss Bayesian algorithm is proposed to improve the multi-fault diagnosis accuracy of satellite sensors. Firstly, the working principle and common failure modes of satellite sensors are analyzed, and a multi-fault diagnosis model of satellite sensors is constructed; Secondly, the HONBM algorithm is used to analyze the fault diagnosis and anti-mismatch strategy of the satellite sensor system to improve the performance of the algorithm, the fault diagnosis process of satellite sensor system based on Bayes network and the anti-mismatch strategy are given. Finally, the effectiveness of the proposed algorithm in multi-fault diagnosis of satellite sensors is verified by simulation experiments.
C1 [Xia, Mu] Northwestern Polytech Univ, Sch Automat, Xian, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Xia, M (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian, Shaanxi, Peoples R China.
EM aabzds134@163.com
RI Xia, Mu/JUU-9991-2023
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Babu RS, 2016, IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGICAL TRENDS IN COMPUTING, COMMUNICATIONS AND ELECTRICAL ENGINEERING (ICETT)
   Bolandi H, 2011, INT C CONTR
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Chen Z, 2014, IET INT C INF SCI CO
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   He L, 2010, INT C INT CONTR INF
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Kaur A, 2017, 4 INT C PAR
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Lara M, 2002, ASTRON ASTROPHYS, V389, P692, DOI 10.1051/0004-6361:20020598
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Li WJ, 2015, REMOTE SENS-BASEL, V7, P15494, DOI 10.3390/rs71115494
   Liu J, 2016, J NE U
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Long T, 2010, 7 INT C FUZZ SYST KN
   Ma S, 2013, INT C MECH SCI
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Sathishkumar BR, 2020, NEURAL COMPUT APPL, V32, P11097, DOI 10.1007/s00521-018-3919-x
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
NR 22
TC 4
Z9 4
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22601
EP 22611
DI 10.1007/s11042-019-7611-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400019
DA 2024-07-18
ER

PT J
AU Zhang, F
   Zhang, XH
AF Zhang, Fan
   Zhang, Xinhong
TI Image inverse halftoning and descreening: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Digital halftoning; Inverse halftoning; Descreening; Image quality
   evaluation
ID ALGORITHM; SYSTEM
AB With the development of computer technology and network technology, a large amount of printed documents are converted to the electronic documents and spread on internet. When a halftone image is scanned to an electronic document, the screen patterns will appear, so the inverse halftoning algorithms are needed to remove the screen patterns and improve image quality. In this paper, the halftoning techniques are introduced firstly, then this paper reviews different inverse halftoning algorithms. The inverse halftoning algorithms introduced in this paper include the low-pass filter algorithm, the fast algorithm, the wavelet based algorithm, the maximum posteriori probability algorithm, the LUT algorithm, the vector based algorithm, and the deconvolution based inverse halftoning algorithm. The image quality evaluation of these inverse halftoning algorithms is also discussed. Finally this paper summarizes the shortcomings of current inverse halftoning algorithms and the directions that can be improved in the future.
C1 [Zhang, Fan] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475001, Peoples R China.
   [Zhang, Xinhong] Henan Univ, Sch Software, Kaifeng 475001, Peoples R China.
C3 Henan University; Henan University
RP Zhang, XH (corresponding author), Henan Univ, Sch Software, Kaifeng 475001, Peoples R China.
EM zhangfan@henu.edu.cn; zxh@henu.edu.cn
OI Zhang, Fan/0000-0003-2176-3835
FU National Key Technology Research and Development Program of China
   [2015BAK01B06]; Natural Science Foundation of China [61771006,
   U1504621]; Natural Science Foundation of Henan Province [162300410032]
FX This research was supported by the National Key Technology Research and
   Development Program of China (Grant No. 2015BAK01B06), the Natural
   Science Foundation of China (Grant No. 61771006, and No. U1504621) and
   the Natural Science Foundation of Henan Province (Grant No.
   162300410032).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2004, PROC INT TICSP WORKS
   [Anonymous], 2010, INT C PATT REC
   Au OC, 2002, IEEE INT C AC SPEECH, P3461
   Burger M, 1984, AM J GASTROENTEROL, V79, P861
   Chang PC, 2001, IEEE T IMAGE PROCESS, V10, P95, DOI 10.1109/83.892446
   Cheung S, 1998, ELECT IMAGING, V3648, P1
   Chung KL, 2005, IEEE T IMAGE PROCESS, V14, P1583, DOI 10.1109/TIP.2005.854494
   Contributors W, 2018, DITH
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Damera-Venkata N, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P64, DOI 10.1109/ICIP.1998.723318
   Djebbouri A, 2005, AEU-INT J ELECTRON C, V59, P128, DOI 10.1016/j.aeue.2004.11.039
   FAN ZG, 1994, IEEE IMAGE PROC, P1041, DOI 10.1109/ICIP.1994.413514
   Ferris LW, 2002, IEEE T IMAGE PROCESS, V9, P666
   Floyd RW, 1975, SID DIGEST, V17, P75
   Freitas PG, 2016, SIGNAL PROCESS-IMAGE, V49, P1, DOI 10.1016/j.image.2016.09.008
   GLENN WE, 1985, P SID, V26, P71
   He Z, 2004, J ELECTRON IMAGING, V13, P286, DOI 10.1117/1.1669555
   HEIN S, 1995, IEEE T IMAGE PROCESS, V4, P208, DOI 10.1109/83.342186
   Hou J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2559803
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Johansson K., 2011, GUIDE GRAPHIC PRINT, Vthird
   Katkovnik Vladimir, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P101
   Katkovnik V, 2003, TAMPERE INT CTR SIGN, V19, P21
   Kern RS, 1993, HUMAN VISION VISUAL, P299
   Kite TD, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P799, DOI 10.1109/ICIP.1997.648084
   Kite TD, 2000, IEEE T IMAGE PROCESS, V9, P1583, DOI 10.1109/83.862639
   KNUTH DE, 1987, ACM T GRAPHIC, V6, P245, DOI 10.1145/35039.35040
   Kong Y, 2004, CHINESE J SCI INSTRU, V25, P177
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lau DanielL., 2001, Modern Digital Halftoning
   Lau DL, 2000, NONLINEAR IMAGE PROC, P375
   Mese M., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4663, P278, DOI 10.1117/12.452998
   Mese M, 2002, IEEE T CIRCUITS-I, V49, P790, DOI 10.1109/TCSI.2002.1010034
   Mese M, 2001, IEEE T IMAGE PROCESS, V10, P1566, DOI 10.1109/83.951541
   MESE M, 2000, ACOUST SPEECH SIG PR, P2290
   Metaxas P.T., 1999, P SOC PHOTO-OPT INS, V3648, P485
   Miceli C. M., 1992, Journal of Electronic Imaging, V1, P143, DOI 10.1117/12.57675
   Molina-Garcia J, 2017, PROC SPIE, V10223, DOI 10.1117/12.2262139
   Neelamani R, 2002, INT C IM PROC, V3, P973
   Ostromoukhov V, 1994, ROTATED DISPERSED DI, P123
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pappas TN, 2016, SIGNAL PROCESS MAG I, V20, P14
   Pelcastre F, 2017, IEEE LAT AM T, V15, P488, DOI 10.1109/TLA.2017.7867599
   Safonov IV, 2018, DESCREENING SCANNED
   Sharma G, 2002, J MOL BIOL, V33, P109
   Shen JH, 2009, SIAM REV, V51, P567, DOI 10.1137/060653317
   Shen MY, 2001, J VIS COMMUN IMAGE R, V12, P84, DOI 10.1006/jvci.2000.0464
   Son CH, 2012, ELECTRON LETT, V48, P832, DOI 10.1049/el.2012.0670
   Son CH, 2012, OPT LETT, V37, P2352, DOI 10.1364/OL.37.002352
   Stevenson RL, 1997, IEEE T IMAGE PROCESS, V6, P574, DOI 10.1109/83.563322
   Sun B, 2014, IEEE T IMAGE PROCESS, V23, P3698, DOI 10.1109/TIP.2014.2332394
   Tang LN, 2008, LECT NOTES COMPUT SC, V5041, P382
   Ulichney RA., 1993, IS T SPIES S EL IM S, DOI [DOI 10.1117/12.152707, 10.1117/12.152707]
   Velho Luiz, 1991, P 18 ANN C COMP GRAP, P81, DOI 10.1145/122718.122727
   Wilson R, 2009, FILE HALFTONINGCOLOR
   WONG PW, 1995, IEEE T IMAGE PROCESS, V4, P486, DOI 10.1109/83.370677
   Xiong ZX, 1999, IEEE T IMAGE PROCESS, V8, P1479, DOI 10.1109/83.791977
   Xiong ZX, 1997, P SOC PHOTO-OPT INS, V3018, P89, DOI 10.1117/12.271578
   Yi Y, 2017, MATH PROBL ENG, P1
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Yu-jin Z, 2012, IMAGE ENG
   Zhang C, 2016, NEUROCOMPUTING, V173, P462, DOI 10.1016/j.neucom.2015.01.105
   Zhang F, 2017, PACKAGE ENG, V38, P236
   Zhang F, 2018, LECT NOTES ARTIF INT, V10956, P466, DOI 10.1007/978-3-319-95957-3_49
   Zhong CM, 2010, PATTERN RECOGN, V43, P752, DOI 10.1016/j.patcog.2009.07.010
NR 68
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21021
EP 21039
DI 10.1007/s11042-019-7458-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400021
DA 2024-07-18
ER

PT J
AU Darwish, SM
AF Darwish, Saad Mohamed
TI A modified image selective encryption-compression technique based on 3D
   chaotic maps and arithmetic coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptography; Joint compression encryption; Chaotic maps; Contourlet
   transform; Thresholding; Arithmetic coding
ID CONTOURLET
AB The advances in digital image processing and communications have created a great demand for real-time secure image transmission over the networks. However, the development of effective, fast and secure dependent image compression encryption systems are still a research problem as the intrinsic features of images such as bulk data capacity and high correlation among pixels hinds the use of the traditional joint encryption compression methods. A new approach is suggested in this paper for partial image encryption compression that adopts chaotic 3D cat map to de-correlate relations among pixels in conjunction with an adaptive thresholding technique that is utilized as a lossy compression technique instead of using complex quantization techniques and also as a substitution technique to increase the security of the cipher image. The proposed scheme is based on employing both of lossless compression with encryption on the most significant part of the image after contourlet transform. However the least significant parts are lossy compressed by employing a simple thresholding rule and arithmetic coding to render the image totally unrecognizable. Due to the weakness of 3D cat map to chosen plain text attack, the suggested scheme incorporates a mechanism to generate random key depending on the contents of the image (context key). Several experiments were done on benchmark images to insure the validity of the proposed technique. The compression analysis and security outcomes indicate that the suggested technique is an efficacious and safe for real time image's applications.
C1 [Darwish, Saad Mohamed] Alexandria Univ, Inst Grad Studies & Res, Dept Informat Technol, 163 Horreya Ave,POB 832, Alexandria 21526, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP Darwish, SM (corresponding author), Alexandria Univ, Inst Grad Studies & Res, Dept Informat Technol, 163 Horreya Ave,POB 832, Alexandria 21526, Egypt.
EM Saad.darwish@alexu.edu.eg
RI Darwish, Saad Mohamed/ISB-6375-2023; Darwish, Saad Mohamed/I-9961-2019
OI Darwish, Saad Mohamed/0000-0003-2723-1549
CR Al-ghaib H, 2012, THESIS
   Almalowi SJ, 2012, J APPL MATH, DOI 10.1155/2012/135173
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Brindha M, 2016, APPL SOFT COMPUT, V40, P379, DOI 10.1016/j.asoc.2015.09.055
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   De Cannière C, 2006, P IEEE, V94, P346, DOI 10.1109/JPROC.2005.862300
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE IMAGE PROC, P357
   Durdi VB, 2017, ADV INTELL SYST, V469, P469, DOI 10.1007/978-981-10-1678-3_45
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Eslami R, 2005, INT CONF ACOUST SPEE, P557
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Hamdi M, 2017, SIGNAL PROCESS, V131, P514, DOI 10.1016/j.sigpro.2016.09.011
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Katsigiannis S, 2012, PROC SPIE, V8437, DOI 10.1117/12.924327
   Martin K, 2005, PATTERN RECOGN, V38, P1111, DOI 10.1016/j.patcog.2005.01.002
   Masmoudi A, 2015, MULTIMED TOOLS APPL, V74, P10605, DOI 10.1007/s11042-014-2195-8
   Mohamed NA, 2015, INT CONF SOFT COMPUT, P230, DOI 10.1109/SOCPAR.2015.7492812
   Pande A., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P171, DOI 10.1109/ISM.2011.35
   Rahman S, 2009, J CHEM RES, P1, DOI 10.3184/030823409X393619
   Rekha H, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P396, DOI 10.1109/WiSPNET.2016.7566163
   Seo Y, 2003, P WORLD WIR C WCC 03, P1
   Shuyan Zhang, 2010, 2010 International Conference on Computer, Mechatronics, Control and Electronic Engineering (CMCE 2010), P211, DOI 10.1109/CMCE.2010.5609856
   Song HH, 2005, LECT NOTES COMPUT SC, V3767, P629
   Tan PP, 2012, INT CONF SIGN PROCES, P922, DOI 10.1109/ICoSP.2012.6491730
   Taneja N, 2009, LECT NOTES COMPUT SC, V5909, P426, DOI 10.1007/978-3-642-11164-8_69
   Tong XJ, 2016, NONLINEAR DYNAM, V84, P2333, DOI 10.1007/s11071-016-2648-x
   Tong XJ, 2013, NONLINEAR DYNAM, V72, P229, DOI 10.1007/s11071-012-0707-5
   Veeraswamy K, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & COMMUNICATIONS (NETCOM 2009), P230, DOI 10.1109/NetCoM.2009.26
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Xiang T, 2014, APPL SOFT COMPUT, V21, P159, DOI 10.1016/j.asoc.2014.03.009
   Ye R, 2011, COMMUNICATIONS COMPU, V202
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhang M, 2017, OPT LASER ENG, V90, P254, DOI 10.1016/j.optlaseng.2016.10.025
   Zhang XJ, 2013, SIGNAL PROCESS, V93, P2422, DOI 10.1016/j.sigpro.2013.03.017
NR 37
TC 20
Z9 20
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19229
EP 19252
DI 10.1007/s11042-019-7256-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800014
DA 2024-07-18
ER

PT J
AU Liu, J
   Chen, Y
   Sun, SN
AF Liu, Jin
   Chen, Yue
   Sun, Shengnan
TI A novel local texture feature extraction method called multi-direction
   local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Palmprint recognition; Local feature extraction;
   Multi-direction local binary pattern
ID FACE; RECOGNITION; CLASSIFICATION
AB A novel method named MD-LBP (Multi-Direction Local Binary Pattern) is proposed in this paper to capture the excellent local texture features. Based on LBP (Local Binary Pattern), the proposed method is a local feature extraction method, which optimized the coding scheme by considering the relationship between the center pixel and the weighted pixels in its neighborhood. Furthermore, unlike the original gray scale histogram method, the proposed method used a new way to get the feature vector which not only describes the holistic spatial information of image, but also reduces the image dimension. The proposed method is evaluated by extensive experiments on benchmark databases, such as CMU PIE and Extended Yale B face database, PolyU and CASIA Palmprint database. The experimental results show that the proposed method MD-LBP, can significantly capture the useful local texture features, and improve the recognition rates both in face and palmprint fields.
C1 [Liu, Jin; Chen, Yue; Sun, Shengnan] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM Jinliu@xidian.edu.cn; chenyue@stu.xidian.edu.cn; snsun@stu.xidian.edu.cn
FU National Science Foundation of China [61101246]; Fundamental Research
   Funds for the Central Universities [JB150209]
FX We would like to thank the associate editor and all anonymous reviewers
   for their constructive comments and suggestions. And portions of the
   research in this paper use the CASIA Palmprint Database collected by the
   Chinese Academy of Sciences' Institute of Automation (CASIA). This
   research was partially supported by the National Science Foundation of
   China (Grant No. 61101246) and the Fundamental Research Funds for the
   Central Universities (Grant No. JB150209).
CR Ahmed F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P265, DOI 10.1109/ICCE.2012.6161859
   Alsubari A, 2017, EXTRACTION, V172
   Alsubari A, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P748, DOI 10.1109/NGCT.2016.7877510
   [Anonymous], 2018, CASIA PALMPRINT DATA
   [Anonymous], 2016, YALE B DATASET
   [Anonymous], 2016, CMUPIE DATASET
   [Anonymous], 2018, POLYU MULTISPECTRAL
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen ZH, 2017, IEEE T IND INFORM, V13, P3070, DOI 10.1109/TII.2017.2712746
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding M, 2015, IEEE T CYBERNETICS, V45, P2413, DOI 10.1109/TCYB.2014.2373393
   Fronitasari D, 2017, 2017 15TH INTERNATIONAL CONFERENCE ON QUALITY IN RESEARCH (QIR) - INTERNATIONAL SYMPOSIUM ON ELECTRICAL AND COMPUTER ENGINEERING, P18, DOI 10.1109/QIR.2017.8168444
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Han D, 2008, INT CONF SIGN PROCES, P2075
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Leila M., 2011, International Joint Conference on Biometrics (IJCB), V2011, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu W, 2016, STRUCTURE, V9
   Lunke Fei, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P213, DOI 10.1007/978-3-319-69923-3_23
   Luo YT, 2016, PATTERN RECOGN, V50, P26, DOI 10.1016/j.patcog.2015.08.025
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Petpon A, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P533, DOI 10.1109/ICIG.2009.123
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wagstaff K., 2001, P 18 INT C MACH LEAR, P577, DOI DOI 10.1109/TPAMI.2002.1017616
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhao Y, 2013, NEUROCOMPUTING, V106, P68, DOI 10.1016/j.neucom.2012.10.017
   Zhou D, 2017, MULTIMED TOOLS APPL, P1
NR 39
TC 14
Z9 15
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18735
EP 18750
DI 10.1007/s11042-018-7095-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200062
DA 2024-07-18
ER

PT J
AU Rameshnath, S
   Bora, PK
AF Rameshnath, Sandeep
   Bora, P. K.
TI Perceptual video hashing based on temporal wavelet transform and random
   projections with application to indexing and retrieval of near-identical
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video hashing; Temporal wavelet transform; Achlioptas's
   random matrix; Random projections; Near-identical video indexing and
   retrieval
ID TENSOR DECOMPOSITIONS; JOHNSON-LINDENSTRAUSS; ROBUST
AB A perceptual video hash function extracts a short fixed-length bit string called a perceptual hash on the basis of the visual contents of the video. Such a function should be robust to the content-preserving operations and at the same time, sensitive to the content differences. In this work, the discrete wavelet transform (DWT) along the temporal direction, referred to as the temporal wavelet transform (TWT), is used for generating the temporally informative representative images (TIRIs). The resultant low pass data are projected onto the Achlioptas's random basis to generate the hash. The TWT and the random projection technique not only reduce the dimensions but also retains the important features. Simulation results show that the proposed algorithm performs better for both the content-preserving and the content changing attacks when compared to that of the existing video hashing algorithms with the added advantage of computational efficiency. The proposed algorithm is applied to the indexing and retrieval of near-identical video application and the performance is evaluated using average precision-recall curves.
C1 [Rameshnath, Sandeep] Vidyavardhaka Coll Engn, Dept Elect & Commun Engn, Mysuru 570002, India.
   [Bora, P. K.] Indian Inst Technol, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Vidyavardhaka College of Engineering; Indian Institute of Technology
   System (IIT System); Indian Institute of Technology (IIT) - Guwahati
RP Rameshnath, S (corresponding author), Vidyavardhaka Coll Engn, Dept Elect & Commun Engn, Mysuru 570002, India.
EM sandeep.ece@vvce.ac.in; prabin@iitg.ac.in
RI R, Sandeep/AAT-7289-2020
OI R, Sandeep/0000-0001-8420-1990
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Achlioptas D., 2001, Database-friendly random projections, P274
   Adleman L. M., 1978, 19 ANN S FDN COMPUTE, P75, DOI [DOI 10.1109/SFCS.1978.37, 10.1109/SFCS.1978.37]
   Ailon N., 2006, STOC'06. Proceedings of the 38th Annual ACM Symposium on Theory of Computing, P557, DOI 10.1145/1132516.1132597
   Ailon N, 2009, SIAM J COMPUT, V39, P302, DOI 10.1137/060673096
   [Anonymous], 2016, TEST VIDEO SEQUENCES
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2012, TEST VIDEO SEQUENCES
   [Anonymous], 2013, 2013 4 NAT C COMP VI
   [Anonymous], ARXIV180410563
   Bingham E., 2001, Random projection in dimensionality reduction
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI 10.1002/9780470747278
   Comon P, 2009, J CHEMOMETR, V23, P393, DOI 10.1002/cem.1236
   Coskun B, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P292, DOI 10.1109/SIU.2004.1338317
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Dasgupta S, 2003, RANDOM STRUCT ALGOR, V22, P60, DOI 10.1002/rsa.10073
   Dasgupta S., 1999, 40th Annual Symposium on Foundations of Computer Science (Cat. No.99CB37039), P634, DOI 10.1109/SFFCS.1999.814639
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Dietzfelbinger M, 2004, LNCS, V3000
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fei MJ, 2017, MULTIMED TOOLS APPL, V76, P4617, DOI 10.1007/s11042-016-3723-5
   Fei MJ, 2015, LECT NOTES ARTIF INT, V9246, P331, DOI 10.1007/978-3-319-22873-0_29
   Fei MJ, 2015, NEUROCOMPUTING, V152, P413, DOI 10.1016/j.neucom.2014.09.060
   Gill J., 1974, STOC 74 P 6 ANN ACM, P91
   Hamon K, 2006, HISTOGRAM BASED PERC
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lan XY, 2018, AAAI CONF ARTIF INTE, P7008
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2008, INT CONF ACOUST SPEE, P1237
   Li M., 2011, P IEEE RAD FREQ INT, P1, DOI DOI 10.1109/RFIC.2011.5940608
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Lv X, 2012, IEEE T INF FOREN SEC, P99
   Lv XD, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P729
   Lv Xudong, 2009, FJLT EURASIP J INF S, V2009
   Ma C, 2016, PATTERN RECOGN LETT, V69, P62, DOI 10.1016/j.patrec.2015.09.019
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Monga V., 2005, THESIS
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Oseledets IV, 2008, SIAM J MATRIX ANAL A, V30, P939, DOI 10.1137/060655894
   Roover C. D., 2005, P 12 INT C IM PROC, V3
   Said BAE, 2012, PERCEPTUAL IMAGE HAS, V2
   Saikia N, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P648, DOI 10.1109/ADCOM.2007.115
   Sandeep R, 2016, MULTIMED TOOLS APPL, V75, P7779, DOI 10.1007/s11042-015-2695-1
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   Vaidyanathan P. P., 1993, MULTIRATE SYSTEMS FI
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Zhou B, 2010, J INTELL INF SYST, V34, P227, DOI 10.1007/s10844-009-0096-5
NR 58
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18055
EP 18075
DI 10.1007/s11042-019-7189-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200033
DA 2024-07-18
ER

PT J
AU Dou, JF
   Qin, Q
   Tu, ZM
AF Dou, Jianfang
   Qin, Qin
   Tu, Zimei
TI Background subtraction based on deep convolutional neural networks
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Moving object detection; Deep learning;
   Convolutional neural networks; Graph cut
AB Background modeling and subtraction, the task to detect moving objects in a scene, is a fundamental and critical step for many high level computer vision tasks. However, background subtraction modeling is still an open and challenge problem particularly in practical scenarios with drastic illumination changes and dynamic backgrounds. In this paper, we propose a novel foreground detection method based on CNNs(Convolutional Neural Networks) to deal with challenges confronted with background subtraction. Firstly, given a cleaned background image without moving objects, constructing adjustable neighborhood of each pixel in the background image to form windows; CNN features are extracted with a pre-trained CNN model for each window to form a features based background model. Secondly, for the current frame of a video scene, extracting features with the same operation as the background model. Euclidean distance is adopted to build distance map for current frame and background image with CNN features. Thirdly, the distance map is fed into graph cut algorithm to obtain foreground mask. In order to deal with background changes, the background model is updated with a certain rate. Experimental results verify that the proposed approach is effective to detect foreground objects from complex background environments, and outperforms some state-of-the-art methods.
C1 [Dou, Jianfang; Qin, Qin; Tu, Zimei] Shanghai Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
C3 Shanghai Polytechnic University
RP Dou, JF (corresponding author), Shanghai Polytech Univ, Sch Intelligent Mfg & Control Engn, Dept Automat & Mech & Elect Engn, Shanghai 201209, Peoples R China.
EM specialdays_2010@163.com
RI Dou, Fang Jian/ABR-7700-2022; qin, qin x/GXG-6164-2022; Zhuo,
   Xianglong/HNO-9030-2023
FU Shanghai University Outstanding Teachers Cultivation Fund Program
   [A30DB1524011-21, A01GY15GX48]; Shanghai Second Polytechnic University
   Mechanical Engineering Key Disciplines [XXKZD1603]; Construction of
   University Enterprise Cooperation Automobile Electronic Joint Experiment
   Center [A11NH182016]
FX This work was supported by the by Shanghai University Outstanding
   Teachers Cultivation Fund Program A30DB1524011-21 and 2015 School Fund
   Project A01GY15GX48 and Shanghai Second Polytechnic University
   Mechanical Engineering Key Disciplines XXKZD1603 and the Construction of
   University Enterprise Cooperation Automobile Electronic Joint Experiment
   Center, Grant Number A11NH182016.
CR [Anonymous], 2016, INT C IM AN REC ICIA
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   Balcilar M, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (IEEE INISTA)
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2016, ARXIV161109099
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Camplani M, 2014, J VIS COMMUN IMAGE R, V25, P122, DOI 10.1016/j.jvcir.2013.03.009
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dou JF, 2014, OPTIK, V125, P435, DOI 10.1016/j.ijleo.2013.06.079
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Javed S, 2015, KOR-JPN JT WORKS FR
   Kim J, 2015, I C COMP SYST APPLIC
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ouyang, 2014, ARXIV14093505, DOI [10.1016/j.patcog.2018.02.004, DOI 10.1016/J.PATCOG.2018.02.004]
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 38
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14549
EP 14571
DI 10.1007/s11042-018-6854-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700019
DA 2024-07-18
ER

PT J
AU Kherchaoui, S
   Houacine, A
AF Kherchaoui, Sonia
   Houacine, Amrane
TI Facial expression identification using gradient local phase
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression identification; Local phase quantization; Local
   ternary patterns; Support vector machines (SVM)
AB This paper presents an automatic facial expression recognition (FER) system. The method proposed is based on an adapted gradient local phase quantization (LPQ) descriptor. Two methods for the quantization of the local phase are proposed here to improve the conventional LPQ. These methods are the phase thresholding and the phase LTP coding. An experimental study of these methods is performed for identification of both the six and seven basic expressions: happy, surprised, fear, disgust, sad, anger and neutral state. The FER system consists of three main stages. The first step consists of the detection of the face, selection of a region of interest, and normalization of this region. Then extraction of features is done by the adapted gradient LPQ method. The third step is the classification of the emotional states. The SVM are used for this purpose. Evaluation of the system performance is done on the well-known JAFFE, and Cohn and Kanade, databases, with both six and seven facial expressions.
C1 [Kherchaoui, Sonia; Houacine, Amrane] Univ Sci & Technol Houari Boumediene, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Kherchaoui, S (corresponding author), Univ Sci & Technol Houari Boumediene, Fac Elect & Comp Sci, LCPTS, Algiers, Algeria.
EM ainos04@yahoo.fr; ahouacine@usthb.dz
CR Abbo A. A., 2008, 2008 Second ACM/IEEE International Conference on Distributed Smart Cameras (ICDSC), DOI 10.1109/ICDSC.2008.4635726
   [Anonymous], 2014, Modeling of food waste digestion using ADM1 integrated with Aspen Plus
   [Anonymous], 1994, 1521 AI MIT
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2001, P 2 INT WORKSH STAT
   [Anonymous], 1995, CITESEER
   [Anonymous], LECT NOTES COMPUTER
   Arumugam D, 2011, INT J ADV COMPUT SC, V2, P92
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Ekman P, 1978, FACIAL ACTION CODING
   Heikkila J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P818, DOI 10.1109/ICPR.2010.206
   Holder RP, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0190-5
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Mahaboob Shaik Taj, 2017, INT J APPL ENG RES, V12, P6897
   Ojansivu V., 2008, LECT NOTES COMPUTER
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Ward PAS, 2014, INT CON ADV INFO NET, P441, DOI 10.1109/AINA.2014.55
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
NR 23
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16843
EP 16859
DI 10.1007/s11042-018-7069-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500049
DA 2024-07-18
ER

PT J
AU Kumar, N
   Sardana, HK
   Shome, SN
AF Kumar, Nitin
   Sardana, H. K.
   Shome, S. N.
TI Saliency based shape extraction of objects in unconstrained underwater
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency gradient; Active contours; Saliency gradient based
   morphological geodesic active contours (SMGAC); Saliency gradient based
   morphological active contours without edges (SACWE)
ID RECOGNITION
AB Un-manned underwater exploration in unconstrained environment is a challenging and non-trivial problem. Manual analysis of large volume of images/videos captured by the underwater stations/vehicles is a major bottleneck for the underwater research community. Automated system for analyzing these videos is need of the hour for exploring the underwater space. In this paper, we present a method for extracting the shape of the objects present in the unconstrained underwater environment scenarios. The proposed method extracts the shape of the objects using saliency gradient based morphological active contour models. The uniqueness in the method is that the stopping condition for the active contour models is derived from the combination of saliency gradient with the gradient of the scene. As a result the proposed method is able to work in highly dynamic and unconstrained underwater environments. The results show that the proposed method is able to extract the shapes of the man-made as well as natural objects in these environmental conditions. The proposed method is able to detect shapes of multiple objects present in an underwater scene. The method is successful in extracting the shape of the occluded objects in such conditions. The results show that the proposed saliency gradient based morphological GAC extracts a minimum of 63% and average of 90% of the objects with misclassification rate of 4% whereas the saliency gradient based morphological ACWE extracts a minimum of 62% and average of 85% of the objects with misclassification rate of 4%.
C1 [Kumar, Nitin; Sardana, H. K.; Shome, S. N.] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, India.
   [Sardana, H. K.] CSIR CSIO, Chandigarh 160030, India.
   [Shome, S. N.] CSIR CMERI, Durgapur 713209, W Bengal, India.
C3 Academy of Scientific & Innovative Research (AcSIR); Council of
   Scientific & Industrial Research (CSIR) - India; CSIR - Central
   Scientific Instruments Organisation (CSIO); Council of Scientific &
   Industrial Research (CSIR) - India; CSIR - Central Mechanical
   Engineering Research Institute (CMERI)
RP Sardana, HK (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, India.; Sardana, HK (corresponding author), CSIR CSIO, Chandigarh 160030, India.
EM nitinsk_chd@yahoo.co.in; hk_sardana@csio.res.in; snshome@cmeri.res.in
RI Sardana, Harish Kumar/AAJ-7718-2020
OI Sardana, Harish Kumar/0000-0001-6072-3305
FU CSIR-CSIO, Chandigarh
FX Nitin Kumar is thankful to CSIR-CSIO, Chandigarh for providing the
   funding and opportunity to carry out this work under the grant UnWaR.
   The authors gratefully acknowledge ONC for providing the underwater
   videos for this research work. The authors are also thankful to Neha for
   assisting in generating the ground truth.
CR Alvarez L, 2010, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2010.5539900
   [Anonymous], 2017, P CVPR
   Barat C, 2006, OCEANS, V2006, P1, DOI [DOI 10.1109/OCEANS.2006.306810, 10.1109/OCEANS.2006.306810]
   Barnes CR, 2007, 2007 SYMPOSIUM ON UNDERWATER TECHNOLOGY AND WORKSHOP ON SCIENTIFIC USE OF SUBMARINE CABLES AND RELATED TECHNOLOGIES, VOLS 1 AND 2, P308, DOI 10.1109/UT.2007.370809
   Bazeille S, 2012, INTEL SERV ROBOT, V5, P109, DOI 10.1007/s11370-012-0105-3
   Chaib S, 2016, INT GEOSCI REMOTE SE, P2742, DOI 10.1109/IGARSS.2016.7729708
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Christian B, 2010, EURASIP J ADV SIGNAL, V2010
   Edgington D. R., 2003, Oceans 2003. Celebrating the Past ... Teaming Toward the Future (IEEE Cat. No.03CH37492), pP2749, DOI 10.1109/OCEANS.2003.178344
   Gebali A., 2012, DETECTION SALIENT EV
   Griffiths G., 2002, TECHNOLOGY APPL AUTO, V2
   Ha ML, 2018, IEEE WINT CONF APPL, P1509, DOI 10.1109/WACV.2018.00169
   Han KM, 2011, INT GEOSCI REMOTE SE, P617, DOI 10.1109/IGARSS.2011.6049204
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jaffe JS., 2001, Oceanography, V14, P66, DOI [DOI 10.5670/OCEANOG.2001.24, 10.5670/oceanog.2001.24]
   Jin L., 2017, OCEANS, P1
   Kabatek M, 2009, UNDERWATER TARGET DE
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Leonard I, 2010, SPIE DEFENSE SECURIT
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Márquez-Neila P, 2014, IEEE T PATTERN ANAL, V36, P2, DOI 10.1109/TPAMI.2013.106
   Nitin Kumar, 2019, SALIENCY SUBTRACTION
   Olmos A., 2002, PROC BRIT MACH VIS C, P1, DOI 10.5244/c.16.50
   Palazzo S, 2013, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2013.6738304
   Qi XF, 2012, EVID-BASED COMPL ALT, V2012, P1, DOI 10.1155/2012/617494
   Qin H., 2015, OCEANS 2015 MTS IEEE, P1
   Spampinato C, 2014, COMPUT VIS IMAGE UND, V122, P74, DOI 10.1016/j.cviu.2013.12.003
   Spampinato C, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P514
   Sun XS, 2017, AAAI CONF ARTIF INTE, P274
   Toshev A, 2009, PROC CVPR IEEE, P288, DOI 10.1109/CVPRW.2009.5206803
   Walther D, 2004, PROC CVPR IEEE, P544
   Yuh J, 2000, AUTON ROBOT, V8, P7, DOI 10.1023/A:1008984701078
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhu Y., 2016, INT J AEROSPACE ENG, P1, DOI DOI 10.1109/ICCCHINAW.2016.7586719
   Zingaretti P, 1998, ENG APPL ARTIF INTEL, V11, P257, DOI 10.1016/S0952-1976(97)00001-8
NR 39
TC 8
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15121
EP 15139
DI 10.1007/s11042-018-6849-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700044
DA 2024-07-18
ER

PT J
AU Liu, XM
   Liu, D
   Fu, TY
   Pan, ZF
   Hu, W
   Zhang, K
AF Liu, Xiaoming
   Liu, Dong
   Fu, Tianyu
   Pan, Zhifang
   Hu, Wei
   Zhang, Kai
TI Shortest path with backtracking based automatic layer segmentation in
   pathological retinal optical coherence tomography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical coherence tomography; Layer segmentation; Image segmentation;
   Shortest path; Backtracking
ID NERVE-FIBER LAYER; OCT IMAGES; BOUNDARIES; GRADIENT
AB Optical coherence tomography (OCT) is a high-resolution and non-invasive imaging modality that has become one of the most prevalent techniques for ophthalmic diagnosis. Retinal layer segmentation is crucial for doctors to diagnose and analysis retinal diseases. Manual segmentation is often a time-consuming and subjective process. A number of semi-automatic and automatic methods have been proposed for layer segmentation on retinal OCT images, but very few of them are applicable for retinal pathological OCT images. In this work, we propose a new automatic method for segmenting ILM (Inner Limiting Membrane) and OS-RPE (Outer Segment- Retinal Pigment Epithelium) interfaces on pathological OCT images affected by macular hole disease. The proposed method follows shortest path framework, while is enhanced with backtracking and direction consistency. Backtracking can deal with the shortcut problem which occur when classical shortest path algorithm is used to segment deformed linear structure. Consistency loss is one kind of soft constraint we defined to limit the propagate direction of modified shortest path algorithm. Besides, the image information after Gabor transform can reflect the layer location to an extent. So, it is considered as one new weight in the weight calculation of the method. Another contribution is that the proposed layer segmentation method is suitable for both normal and pathological retinal OCT images. To quantitate the performance of the proposed method, we did comparative experiments with three state-of-the-art segmentation methods. The experimental result shows that proposed method can achieve better result than other methods and can deal with pathological retinal OCT images.
C1 [Liu, Xiaoming; Liu, Dong; Fu, Tianyu; Hu, Wei; Zhang, Kai] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.
   [Liu, Xiaoming; Liu, Dong; Fu, Tianyu; Hu, Wei; Zhang, Kai] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
   [Pan, Zhifang] Wenzhou Med Univ, Sch Informat & Engn, Wenzhou 325035, Peoples R China.
   [Pan, Zhifang] Wenzhou Med Univ, Ctr Informat Technol, Wenzhou 325035, Peoples R China.
C3 Wuhan University of Science & Technology; Wenzhou Medical University;
   Wenzhou Medical University
RP Liu, XM (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Hubei, Peoples R China.; Liu, XM (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Hubei, Peoples R China.
EM lxmspace@gmail.com
RI Pan, Zhifang/ADF-4496-2022; Liu, Xiaoming/AFF-8698-2022; liu,
   dong/GRJ-9115-2022
OI Liu, Xiaoming/0000-0003-3467-5607; Pan, Zhifang/0000-0002-3683-6657
FU National Natural Science Foundation of China [61403287, 61472293,
   61572381]; China Postdoctoral Science Foundation [2014M552039];
   Foundation of Wenzhou Science & Technology Bureau [Y20150086]; Natural
   Science foundation of Zhejiang Province
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61403287, No. 61472293, No. 61572381), China
   Postdoctoral Science Foundation (No. 2014M552039) Foundation of Wenzhou
   Science & Technology Bureau (No. Y20150086), Natural Science foundation
   of Zhejiang Province (No.LY16F030010).
CR [Anonymous], 2017, IN P IEEE C COMPUTER
   [Anonymous], IEEE J BIOMEDICAL HL
   Bandello F, 2014, DIABETIC MACULAR EDE, P989
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chiu SJ, 2015, BIOMED OPT EXPRESS, V6, P1172, DOI 10.1364/BOE.6.001172
   Chiu SJ, 2010, OPT EXPRESS, V18, P19413, DOI 10.1364/OE.18.019413
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Drexler W, 2008, PROG RETIN EYE RES, V27, P45, DOI 10.1016/j.preteyeres.2007.07.005
   Duan J, 2017, PATTERN RECOGN, V72
   Fang LY, 2017, BIOMED OPT EXPRESS, V8, P2732, DOI 10.1364/BOE.8.002732
   Fu DM, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0206-x
   Fuller AR, 2007, IEEE T VIS COMPUT GR, V13, P1719, DOI 10.1109/TVCG.2007.70590
   Ghorbel I, 2011, PATTERN RECOGN, V44, P1590, DOI 10.1016/j.patcog.2011.01.012
   Hageman GS, 1995, AGE RELATED MACULAR, P780
   HEE MR, 1995, ARCH OPHTHALMOL-CHIC, V113, P325, DOI 10.1001/archopht.1995.01100030081025
   Ho AC, 1998, SURV OPHTHALMOL, V42, P393, DOI 10.1016/S0039-6257(97)00132-X
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Hussain MA, 2017, IEEE T BIO-MED ENG, V64, P1638, DOI 10.1109/TBME.2016.2619120
   Ishikawa H, 2005, INVEST OPHTH VIS SCI, V46, P2012, DOI 10.1167/iovs.04-0335
   Ishikawa H, 2002, GRAEF ARCH CLIN EXP, V240, P362, DOI 10.1007/s00417-002-0461-3
   Jin X, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9266-1
   Kajic V, 2010, OPT EXPRESS, V18, P14730, DOI 10.1364/OE.18.014730
   Karri SPK, 2016, BIOMED OPT EXPRESS, V7, P2888, DOI 10.1364/BOE.7.002888
   Keller B, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.7.076015
   Kumar TS, 2018, MULTIMED TOOLS APPL, V77, P10285, DOI 10.1007/s11042-017-5487-y
   Lang A, 2013, BIOMED OPT EXPRESS, V4, P1133, DOI 10.1364/BOE.4.001133
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Li H, 2007, IEEE T MED IMAGING, V26, P1213, DOI 10.1109/TMI.2007.903696
   Liu X, 2016, 8 INT C DIG IM PROC
   Liu XM, 2018, IEEE IMAGE PROC, P2770, DOI 10.1109/ICIP.2018.8451179
   Liu XM, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.1.014002
   Liu XY, 2019, IEEE T CYBERNETICS, V49, P2398, DOI 10.1109/TCYB.2018.2821119
   Medeiros FA, 2005, AM J OPHTHALMOL, V139, P44, DOI 10.1016/j.ajo.2004.08.069
   Mishra A, 2009, OPT EXPRESS, V17, P23719, DOI 10.1364/OE.17.023719
   Na JH, 2012, INVEST OPHTH VIS SCI, V53, P3817, DOI 10.1167/iovs.11-9369
   Niu SJ, 2014, COMPUT BIOL MED, V54, P116, DOI 10.1016/j.compbiomed.2014.08.028
   Novosel J, 2015, MED IMAGE ANAL, V26, P146, DOI 10.1016/j.media.2015.08.008
   Otte S, 2013, IEEE INT WORKSH MACH, P1
   QIAN S, 1993, IEEE T SIGNAL PROCES, V41, P2429, DOI 10.1109/78.224251
   Rossant F, 2015, PATTERN RECOGN, V48, P3857, DOI 10.1016/j.patcog.2015.06.009
   Roy AG, 2017, BIOMED OPT EXPRESS, V8, P3627, DOI 10.1364/BOE.8.003627
   Sahu S, 2019, MULTIMED TOOLS APPL, V78, P4089, DOI 10.1007/s11042-017-5221-9
   Shahidi M, 2005, AM J OPHTHALMOL, V139, P1056, DOI 10.1016/j.ajo.2005.01.012
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Szkulmowski M, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2771569
   Tian J., 2015, PLOS ONE, V10
   Vermeer KA, 2011, BIOMED OPT EXPRESS, V2, P1743, DOI 10.1364/BOE.2.001743
   VERMEER KA, 2010, INVEST OPHTH VIS SCI, V51
   Wei L., 2017, Proceedings of the international conference on underwater networks systems, P1
   Yang Q, 2010, OPT EXPRESS, V18, P21293, DOI 10.1364/OE.18.021293
   Yazdanpanah A, 2009, LECT NOTES COMPUT SC, V5762, P649, DOI 10.1007/978-3-642-04271-3_79
NR 52
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15817
EP 15838
DI 10.1007/s11042-018-6979-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500005
DA 2024-07-18
ER

PT J
AU Rafiq, A
   Khan, M
AF Rafiq, Ayesha
   Khan, Majid
TI Construction of new S-boxes based on triangle groups and its
   applications in copyright protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-boxes; Projective linear groups; Finite fields; Modular group;
   Triangle groups; Algebraic analyses
ID COSET DIAGRAMS; IMAGE; QUOTIENTS
AB Substitution boxes with resilient cryptographic possessions are normally utilized in block ciphers to give the substantial property of nonlinearity. They are important to resist standard attacks such as linear and differential cryptanalysis. A cryptographically robust S-box must be sound with respect to cryptographic properties like nonlinearity, bit independent criteria, strict avalanche criteria, linear and differential approximation probability. In this paper, we have developed an innovative construction scheme of nonlinear component of block cipher based on the action of projective linear groups on the projective line, and the permutation triangle groups. This nonlinear component, namely S-box, is responsible for making the relation between plaintext and ciphertext intractable which is one of the most important requirements of any modern block ciphers. By widening the scope of the proposed S-boxes, we have applied these lightweight nonlinear components in watermarking scheme.
C1 [Rafiq, Ayesha; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Khan, Majid] Inst Space Technol, CISL, Islamabad, Pakistan.
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.; Khan, M (corresponding author), Inst Space Technol, CISL, Islamabad, Pakistan.
EM ayesha_rafiq@live.com; mk.cfd1@gmail.com
RI Rafiq, Ayesha/KOC-3570-2024; Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770; Rafiq, Ayesha/0000-0001-9452-1859
FU Higher Education Commission (HEC) of Pakistan [21-1743/SRGP/RD/HEC/2017]
FX The authors would like to thank the anonymous referees for their helpful
   comments and suggestions, which improved significantly the presentation
   of the paper. The authors are thankful to the Higher Education
   Commission (HEC) of Pakistan for the financial support under-vide No.
   21-1743/SRGP/R&D/HEC/2017.
CR Bahrami S, 2012, ADV MULTIMED, V2012, DOI 10.1155/2012/767364
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Baumslag G, 2006, APPL ALGEBR ENG COMM, V17, P205, DOI 10.1007/s00200-006-0003-z
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Chawla Gaurav, 2012, Int J Comput Appl Inf Technol, V1, P16
   Cid C, 2005, LECT NOTES COMPUT SC, V3557, P145
   CONDER M, 1987, Q J MATH, V38, P427, DOI 10.1093/qmath/38.4.427
   Conder M, PREPRINT
   El-Sheikh HM., 2012, INT J COMPUTER THEOR, V4, P158, DOI [10.7763/IJCTE.2012.V4.442, DOI 10.7763/IJCTE.2012.V4.442]
   Everitt B, 2000, J ALGEBRA, V223, P457, DOI 10.1006/jabr.1999.8014
   Gangadari BR, 2015, INT CONF CONTEMP, P526, DOI 10.1109/IC3.2015.7346738
   Higman G., 1983, ARAB GULF J SCI RES, V1, P159
   Isa H, 2016, NEW GENERAT COMPUT, V34, P221, DOI 10.1007/s00354-016-0302-2
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Khan M, 2015, SIGNAL IMAGE VIDEO P, V9, P1335, DOI 10.1007/s11760-013-0577-4
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   MEIER W, 1990, LECT NOTES COMPUT SC, V434, P549
   Mihajloska H, 2012, 6 INT C EM SEC INF S
   MUSHTAQ Q, 1992, COMMUN ALGEBRA, V20, P1023
   MUSHTAQ Q, 1990, COMMUN ALGEBRA, V18, P3857, DOI 10.1080/00927879008824113
   MUSHTAQ Q, 1987, ARS COMBINATORIA, V23A, P187
   MUSHTAQ Q, 1988, B AUST MATH SOC, V37, P303, DOI 10.1017/S000497270002685X
   Nakahara J, 2009, DAGST SEM P, P1862
   Phan RCW, 2002, CRYPTOLOGIA, V26, P283, DOI 10.1080/0161-110291890948
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   SIEGENTHALER T, 1985, IEEE T COMPUT, V34, P81, DOI 10.1109/TC.1985.1676518
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Steinwandt R, 2001, LECT NOTES COMPUT SC, V1992, P180
   Tom MA, 1976, MODULAR FUNCTIONS DI
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wilson JS, 1999, Q J MATH, V50, P523, DOI 10.1093/qjmath/50.200.523
   Yamamura A, 1999, LECT NOTES COMPUT SC, V1587, P314
   Yamamura A., 1998, Public Key Cryptography. First International Workshop on Practice and Theory in Public Key Cryptography, PKC'98. Proceedings, P203, DOI 10.1007/BFb0054026
NR 39
TC 27
Z9 27
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15527
EP 15544
DI 10.1007/s11042-018-6953-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700060
DA 2024-07-18
ER

PT J
AU Zhang, FF
   Li, SG
   Yu, ZX
AF Zhang, Fangfang
   Li, Shugang
   Yu, Zhaoxu
TI The super user selection for building a sustainable online social
   network marketing community
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online marketing community; Super user selection; Sustainability; Fuzzy
   system dynamic model
ID MODERATING ROLE; SUPPORT; FOCUS
AB Constructing the sustainable Online Social Network Marketing Community (OSNMC) is a particularly effective approach to trumpet the products and enhance the customer experience. Super users are considered as opinion leaders, high influence users, and other active users who play a crucial role in enhancing the sustainability of OSNMC. Recruiting sustainable super users is the essential first step to solve unsustainability issues such as the low participation rates and privacy threats problems in the online community. An integrated Fuzzy System Dynamic Model (FSDM) is proposed for selecting suitable super users to build a sustainable OSNMC. FSDM focuses on the super users' behavioral characteristics of the high-active participation and keen ability to protect privacy. Moreover, the fuzzy analytic hierarchy process method is adopted to obtain the weight of each characteristic, and the growth rate of sustainability is settled with fuzzy Takagi-Sugeno-type fuzzy inference system to address the challenges of the uncertain relationships between super user's characteristic combinations and the OSNMC sustainability. It does not need line feeds here.
   FSDM simulates the fashion marketing community sustainability under super user's different characteristic combinations in four scenarios. The results show that the OSNMC sustainability needs not only an open and active environment but also privacy control.
C1 [Zhang, Fangfang; Li, Shugang] Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
   [Yu, Zhaoxu] East China Univ Sci & Technol, Dept Automat, Shanghai 200237, Peoples R China.
C3 Shanghai University; East China University of Science & Technology
RP Li, SG (corresponding author), Shanghai Univ, Sch Management, Shanghai 200444, Peoples R China.
EM westside_li@163.com
RI Zhang, Fang/HHN-2153-2022
OI Yu, Zhaoxu/0000-0002-2375-0213
FU Chinese National Natural Science Foundation [71271132,71871135];
   Shanghai Pujiang Program [15PJC049]
FX This work was supported by the Chinese National Natural Science
   Foundation (No. 71271132,71871135), and by Shanghai Pujiang Program (No.
   15PJC049).
CR [Anonymous], P 25 INT C SYST DYN
   [Anonymous], SOCIAL COMMUNITIES S
   Gong ZW, 2006, LECT NOTES COMPUT SC, V4223, P334
   Hofacker C.F., 2016, SPAN J MARKET-ESIC, V20, P73
   Hu HB, 2010, PHYSICA A, V389, P1065, DOI 10.1016/j.physa.2009.11.007
   Jafarzadeh M, 2018, MECHATRONICS, V53, P124, DOI 10.1016/j.mechatronics.2018.06.007
   John LK, 2017, J MARKETING RES, V54, P144, DOI 10.1509/jmr.14.0237
   Johnson DS, 2015, J INTERACT MARK, V29, P1, DOI 10.1016/j.intmar.2014.07.002
   Jussila JJ, 2014, COMPUT HUM BEHAV, V30, P606, DOI 10.1016/j.chb.2013.07.047
   Kim HS, 2016, COMPUT HUM BEHAV, V63, P362, DOI 10.1016/j.chb.2016.05.004
   Kim MS, 2017, COMPUT HUM BEHAV, V68, P232, DOI 10.1016/j.chb.2016.11.031
   Kwak H., WWW'10, DOI DOI 10.1145/1772690.1772751
   Li Q, 2018, J STRATEGIC INF SYST, V27, P191, DOI 10.1016/j.jsis.2017.11.001
   Luo N, 2016, INT J INFORM MANAGE, V36, P673, DOI 10.1016/j.ijinfomgt.2016.04.016
   Ma N, 2014, EXPERT SYST APPL, V41, P1357, DOI 10.1016/j.eswa.2013.08.033
   Maar Michael C., 2013
   Malinen S, 2015, COMPUT HUM BEHAV, V46, P228, DOI 10.1016/j.chb.2015.01.004
   Mosteller J, 2017, J INTERACT MARK, V39, P27, DOI 10.1016/j.intmar.2017.02.003
   Orji IJ, 2015, COMPUT IND ENG, V88, P1, DOI 10.1016/j.cie.2015.06.019
   Otto P, 2008, SYST DYNAM REV, V24, P321, DOI 10.1002/sdr.403
   Pensa RG, 2017, EXPERT SYST APPL, V86, P18, DOI 10.1016/j.eswa.2017.05.054
   Ruan YF, 2016, KNOWL-BASED SYST, V106, P150, DOI 10.1016/j.knosys.2016.05.042
   Shire MI, 2018, SAFETY SCI, V106, P104, DOI 10.1016/j.ssci.2018.03.010
   Song H, 2012, INT CONF E BUS ENG, P95, DOI 10.1109/ICEBE.2012.24
   Stelzner M.A., 2010, Social media marketing industry report: How marketers are using social media to grow their businesses
   Tanimoto J, 2016, PHYSICA A, V460, P88, DOI 10.1016/j.physa.2016.04.044
   van Mierlo T, 2012, J MED INTERNET RES, V14, P45, DOI 10.2196/jmir.1854
   Wasko MM, 2000, J STRATEGIC INF SYST, V9, P155, DOI 10.1016/S0963-8687(00)00045-7
   Yang X, 2017, INFORM MANAGE-AMSTER, V54, P154, DOI 10.1016/j.im.2016.05.003
   Yang X, 2016, COMPUT HUM BEHAV, V64, P760, DOI 10.1016/j.chb.2016.08.002
   Young C, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2501
   Zhu DH, 2016, J RETAIL CONSUM SERV, V31, P287, DOI 10.1016/j.jretconser.2016.04.013
   Zhu T, 2012, EXPERT SYST APPL, V39, P4222, DOI 10.1016/j.eswa.2011.09.112
NR 33
TC 2
Z9 2
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14777
EP 14798
DI 10.1007/s11042-018-6829-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700029
DA 2024-07-18
ER

PT J
AU Zhou, LJ
   Wang, H
   Liu, WQ
   Lu, ZM
AF Zhou, Lijian
   Wang, Hui
   Liu, Wanquan
   Lu, Zhe-Ming
TI Face feature extraction and recognition via local binary pattern and
   two-dimensional locality preserving projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face feature extraction; Recognition; Local binary pattern (LBP);
   Two-dimensional locality preserving projections (2DLPP)
ID EIGENFACES
AB In this paper, we propose a novel face feature extraction approach based on Local Binary Pattern (LBP) and Two Dimensional Locality Preserving Projections (2DLPP) to enhance the texture features and preserve the space structure properties of a face image. LBP is firstly used to remove the effect of illumination and noise, which would enhance the detailed texture characteristics of face images. Then 2DLPP is performed to extract some prominent features and decrease the image dimension with space structure information. The Nearest Neighborhood Classifier (NNC) is used to recognize a face image at the end. In addition, the rule for dimension selection is studied from the results of experiments about choosing an appropriate feature dimension by 2DLPP computation. The experimental results on the Yale, the extended Yale B and CMU PIE C09 benchmark datasets showed that the proposed face feature extraction and recognition method achieves a better performance in comparison with similar techniques, and the proposed dimension selection rule can give an appropriate feature dimension in 2DLPP.
C1 [Zhou, Lijian; Wang, Hui] Qingdao Univ Technol, Sch Commun & Elect Engn, Qingdao 2660520, Shandong, Peoples R China.
   [Wang, Hui] Jinan Technician Coll, Jinan 2660520, Shandong, Peoples R China.
   [Liu, Wanquan] Curtin Univ, Dept Comp, Perth, WA 6102, Australia.
   [Lu, Zhe-Ming] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Qingdao University of Technology; Curtin University; Zhejiang University
RP Zhou, LJ (corresponding author), Qingdao Univ Technol, Sch Commun & Elect Engn, Qingdao 2660520, Shandong, Peoples R China.
EM zhoulijian@qut.edu.cn; 972482380@qq.com; W.Liu@curtin.edu.au;
   zheminglu@zju.edu.cn
RI Zhao, YuHan/KIE-0813-2024; Zhou, Lijian/JAC-6504-2023; Huang,
   Liping/KIB-4430-2024; Zhou, Lijian/ABM-3689-2022
OI liu, wanquan/0000-0003-4910-353X
FU Natural Science Foundation of China [61572269]; Key Research and
   Development Programs of Shandong Province Project [2018GGX101040]
FX This work was supported by Natural Science Foundation of China under
   grant 61572269, the Key Research and Development Programs of Shandong
   Province Project: 2018GGX101040.
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen SB, 2007, NEUROCOMPUTING, V70, P912, DOI 10.1016/j.neucom.2006.10.032
   Feng F, 2017, COMPUTER SCI, V44, P267
   Feng F, 2017, COMPUTER SCI, V44, P311
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HONG ZQ, 1991, PATTERN RECOGN, V24, P211, DOI 10.1016/0031-3203(91)90063-B
   Lu C, 2012, NEUROCOMPUTING, V98, P135, DOI 10.1016/j.neucom.2011.08.045
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paisitkriangkrai S, 2017, COMPUT VIS IMAGE UND, V156, P51, DOI 10.1016/j.cviu.2016.10.015
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang AL, 2014, INT CONF INSTR MEAS, P616, DOI 10.1109/IMCCC.2014.131
   Wang B, 2016, P INT COMP SOFTW APP, P58, DOI 10.1109/COMPSAC.2016.111
   Wang XG, 2009, LECT NOTES COMPUT SC, V5553, P423, DOI 10.1007/978-3-642-01513-7_46
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Yan Y, 2013, IEEE IMAGE PROC, P2837
   Yang J, 2015, ACS APPL MATER INTER, V7, P22172, DOI 10.1021/acsami.5b07849
   [张志伟 ZHANG Zhiwei], 2008, [光电子·激光, Journal of Optoelectronics·Laser], V19, P972
   Zhi RC, 2008, NEUROCOMPUTING, V71, P1730, DOI 10.1016/j.neucom.2007.12.002
   Zhou L., 2014, J. Inf. Hiding Multimed. Signal Process, V5, P399
   [祝磊 ZHU Lei], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P2043
NR 24
TC 5
Z9 5
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14971
EP 14987
DI 10.1007/s11042-018-6868-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700037
DA 2024-07-18
ER

PT J
AU Braz, G
   da Rocha, SV
   de Almeida, JDS
   de Paiva, AC
   Silva, AC
   Gattass, M
AF Braz Junior, Geraldo
   da Rocha, Simara V.
   de Almeida, Joao D. S.
   de Paiva, Anselmo C.
   Silva, Aristofanes C.
   Gattass, Marcelo
TI Breast cancer detection in mammography using spatial diversity,
   geostatistics, and concave geometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammography; Detection; False positive reduction; Diversity analysis;
   Geostatistical analysis; Concave geometry; Alpha-shapes
ID AUTOMATIC MASS DETECTION; COMPUTER-AIDED DETECTION; CLASSIFICATION;
   FEATURES; IMAGES
AB Breast cancer is a global health problem which mainly affects the female population. It is known that early detection increases the chances of effective treatment, improving the disease prognosis. It remains a challenge to detect the lesion with high detection rate and ensure, at the same time, low rates of false positives . Aiming this objective, this work proposes an efficient method for detection of mass regions on digitized mammograms though diversity analysis, geostatistical and concave geometry (Alpha Shapes). We evaluate the detection rate for each feature extraction using Support Vector Machine in MIAS and DDSM database, with 74 and 621 mammograms, respectively, all containing at least one mass region. The obtained results are promising, reaching 97.30% of detection rate and 0.89 false positive per image for MIAS database and also 91.63% of detection rate and 0.86 false positive per image for DDSM database. Specifically, in DDSM obtaining high detection rate and low rate of false positives when using concave geometry to extract features in a large database.
C1 [Braz Junior, Geraldo; da Rocha, Simara V.; de Almeida, Joao D. S.; de Paiva, Anselmo C.; Silva, Aristofanes C.] Univ Fed Maranhao, Comp Appl Grp NCA, Ave Portugueses,1996,Campus Bacanga, Sao Luis, Maranhao, Brazil.
   [Gattass, Marcelo] Pontificia Univ Catolica Rio de Janeiro, Tecgraf, Grp Comp Graph Technol, Rua Marques de Sao Vicente 225, BR-22453900 Rio De Janeiro, Brazil.
C3 Universidade Federal do Maranhao
RP Braz, G (corresponding author), Univ Fed Maranhao, Comp Appl Grp NCA, Ave Portugueses,1996,Campus Bacanga, Sao Luis, Maranhao, Brazil.
EM geraldo.braz@ufma.br; simara.rocha@ufma.br; jdallyson@ufma.br;
   anselmo.paiva@ufma.br; ac.silva@ufma.br; mgattass@tecgraf.puc-rio.br
RI Braz, Geraldo/AAW-1827-2021; Paiva, Anselmo/L-2358-2013
OI Braz, Geraldo/0000-0003-3731-6431; Paiva, Anselmo/0000-0003-4921-0626;
   Almeida, Joao Dallyson Sousa de Almeida/0000-0001-7013-9700
FU CNPq; FAPEMA
FX The authors thank CNPq and FAPEMA for the financial support.
CR American Cancer Society A, 2013, LEARN BREAST CANC
   Anitha J, 2017, COMPUT METH PROG BIO, V138, P93, DOI 10.1016/j.cmpb.2016.10.026
   [Anonymous], 2013, INT J RECENT TECHNOL
   Anselin L, 2001, J GEOGRAPHICAL SYSTE, V2, P201
   BIRD RE, 1992, RADIOLOGY, V184, P613, DOI 10.1148/radiology.184.3.1509041
   Braz G, 2013, EXPERT SYST APPL, V40, P7534, DOI 10.1016/j.eswa.2013.07.034
   Braz G, 2009, COMPUT BIOL MED, V39, P1063, DOI 10.1016/j.compbiomed.2009.08.009
   Buzas MA, 1998, J FORAMIN RES, V28, P233
   CAMARGO JA, 1993, J THEOR BIOL, V161, P537, DOI 10.1006/jtbi.1993.1072
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Deepak KS, 2012, PATTERN RECOGN, V45, P3707, DOI 10.1016/j.patcog.2012.03.020
   Dhungel N, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P160
   Ding J, 2009, GRAPHICAL MODELS IMA
   EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635
   Sousa JRFD, 2010, COMPUT METH PROG BIO, V98, P1, DOI 10.1016/j.cmpb.2009.07.006
   Gao XB, 2010, IEEE T INF TECHNOL B, V14, P266, DOI 10.1109/TITB.2009.2036167
   Gonzalez R. C., 2010, PROCESSAMENTO DIGITA
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heath M, 1998, COMP IMAG VIS, V13, P457
   Hong BW, 2010, IEEE T INF TECHNOL B, V14, P129, DOI 10.1109/TITB.2009.2033269
   Jost L., 2010, DIVERSITY-BASEL, V2, P207, DOI DOI 10.3390/d2020207
   Kashyap KL, 2018, MULTIMED TOOLS APPL, V77, P9249, DOI 10.1007/s11042-017-4751-5
   Ke L, 2010, INT CONF BIOMED, P354, DOI 10.1109/BMEI.2010.5639515
   Levine N, 1996, ANALISE ESTATISTICA
   Liu X., 2011, J SHANDONG WOMENS U, V4, P1
   Lladó X, 2009, COMPUT MED IMAG GRAP, V33, P415, DOI 10.1016/j.compmedimag.2009.03.007
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Magurran A. E., 2004, MEASURING BIOL DIVER
   May R.M., 1975, P81
   Moayedi F, 2010, COMPUT BIOL MED, V40, P373, DOI 10.1016/j.compbiomed.2009.12.006
   Montero R.S., 2009, INT MATH FORUM, V4, P1305
   Neto OPS, 2017, MULTIMED TOOLS APPL, V76, P19263, DOI 10.1007/s11042-017-4710-1
   Obenauer S, 2008, ENCY DIAGNOSTIC IMAG, P131
   Oliver A, 2010, ACAD RADIOL, V17, P877, DOI 10.1016/j.acra.2010.04.013
   Pielou E. C., 1975, Ecological diversity
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rahmati P, 2012, MED IMAGE ANAL
   Ramos R, 2012, EXPERT SYSTEMS APPL
   RIPLEY BD, 1977, J ROY STAT SOC B MET, V39, P172
   Sahba F, 2010, IEEE IMAGE PROC, P3629, DOI 10.1109/ICIP.2010.5652047
   Sampaio WB, 2011, COMPUT BIOL MED, V41, P653, DOI 10.1016/j.compbiomed.2011.05.017
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Simpson E, 1949, NATURE, V163, P163, DOI DOI 10.1038/163688A0
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Tai SC, 2014, IEEE J BIOMED HEALTH, V18, P618, DOI 10.1109/JBHI.2013.2279097
   Terada T., 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P1176, DOI 10.1109/ISCIT.2010.5665168
   Tzikopoulos SD, 2011, COMPUT METH PROG BIO, V102, P47, DOI 10.1016/j.cmpb.2010.11.016
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Vikhe PS, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0435-3
   Wang XW, 2012, ACAD RADIOL, V19, P303, DOI 10.1016/j.acra.2011.10.026
   Wei J, 2011, MED PHYS, V38, P1867, DOI 10.1118/1.3560462
   Zheng YF, 2010, ALGORITHMS, V3, P44, DOI 10.3390/a3010044
NR 53
TC 16
Z9 16
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13005
EP 13031
DI 10.1007/s11042-018-6259-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900016
DA 2024-07-18
ER

PT J
AU Firmino, AA
   Baptista, CD
   de Figueirêdo, HF
   Pereira, ET
   Amorim, BDP
AF Firmino, Anderson Almeida
   Baptista, Claudio de Souza
   de Figueiredo, Hugo Feitosa
   Pereira, Eanes Torres
   Pereira Amorim, Brunna de Sousa
TI Automatic and semi-automatic annotation of people in photography using
   shared events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People annotation; Face recognition; Event annotation; Context aware
   multimedia; Personal photo collection
ID PHOTO; RECOGNITION
AB This article proposes an automatic and semi-automatic annotation technique for people in photos using the shared event concept, which consists of many photos captured by different devices of people who attended the same event. The technique uses an algorithm to group photos into personal events and then verifies which of these events are shared. The automatic annotation of people uses techniques of facial recognition and detection, while the semi-automatic annotation uses a pondered sum of estimators based on contextual information and picture content. Experiments showed that using the shared event concept increases the hit rate of automatic and semi-automatic annotations of people in the utilized photo collection.
C1 [Firmino, Anderson Almeida; Baptista, Claudio de Souza; Pereira, Eanes Torres; Pereira Amorim, Brunna de Sousa] Univ Fed Campina Grande, Comp Sci Dept, Ave Aprigio Veloso,882, BR-58109900 Bodocongo Campina Grande, Paraiba, Brazil.
   [de Figueiredo, Hugo Feitosa] Fed Inst Educ Sci & Technol Paraiba, Campus Esperanca, Esperanca, Paraiba, Brazil.
C3 Universidade Federal de Campina Grande; Instituto Federal da Paraiba
   (IFPB)
RP Firmino, AA (corresponding author), Univ Fed Campina Grande, Comp Sci Dept, Ave Aprigio Veloso,882, BR-58109900 Bodocongo Campina Grande, Paraiba, Brazil.
EM andersonalmeida@copin.ufcg.edu.br
RI Pereira, Eanes Torres/ACW-5565-2022; Firmino, Anderson/GQZ-4472-2022
OI Pereira, Eanes Torres/0000-0002-9717-794X; Firmino,
   Anderson/0000-0003-2199-8191
CR Ahmad K, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.060502
   Anderson T.W., 2011, International Encyclopedia of Statistical Science, V1, P52, DOI [10.1007/978-3-642-04898-2_118, DOI 10.1007/978-3-642-04898-2_118]
   Andrade D, 2014, 16 INT C ENT INF SYS
   Andrade DJ, 2016, MANUAL PRATICO ACARO, P1
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2007, P SIGCHI C HUM FACT
   [Anonymous], ICMR 2013 P 3 ACM C
   [Anonymous], ICMR 2013 P 3 ACM C
   [Anonymous], 2014, P 1 INT WORKSH GAM I
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 2 ACM INT C MULT R
   Bouselmi G, 2012, INT J SPEECH TECHNOL, V15, P203, DOI 10.1007/s10772-012-9134-8
   Choi JY, 2011, IEEE T MULTIMEDIA, V13, P14, DOI 10.1109/TMM.2010.2087320
   CHUNG KL, 1946, ANN MATH STAT, V17, P447, DOI 10.1214/aoms/1177730884
   Cohen D, 2012, U. S. Patent, Patent No. [20170046341A1, 20170046341]
   Conci N, 2015, WORK NOT P MEDIAEVAL
   Cooray S, 2006, IET INT C VIS INF EN
   Cooray SH, 2008, ENHANCING PERSON ANN, P2008
   Cooray SH, 2009, 2009 20 INT WORKSH D
   Davis M., 2005, 13th Annual ACM International Conference on Multimedia, P483, DOI 10.1145/1101149.1101257
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   De Figueiredo HF, 2012, P 18 BRAZ S MULT WEB
   de Figueirêdo HF, 2015, EXPERT SYST APPL, V42, P203, DOI 10.1016/j.eswa.2014.07.060
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Feng KY, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P63, DOI 10.1145/2588555.2612173
   Freire TP, 2012, 6 INT WORKSH MULT SI, P43
   Gallagher AC, 2009, IPSJ T COMPUT VIS AP, V1, P15
   Gallagher AC, 2008, P 16 ACM INT C MULT
   Geng Y, 2016, LEARNING CONVOLUTION
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Hamzah R, 2014, IEEE CONF OPEN SYST, P1, DOI 10.1109/ICOS.2014.7042400
   Hanbury A, 2008, J VISUAL LANG COMPUT, V19, P617, DOI 10.1016/j.jvlc.2008.01.002
   Huang SC, 2016, IET COMPUT VIS, V10, P349, DOI 10.1049/iet-cvi.2015.0171
   Hulsebosch RJ, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P397, DOI 10.1109/ARES.2008.45
   Ionescu B, 2016, P 7 INT C MULT SYST
   Ivasic-Kos M, 2015, EXPERT SYST APPL, V42, P9539, DOI 10.1016/j.eswa.2015.07.068
   Jaccard P., 1901, B SOCIETE VAUDOISEDE, V37, P241
   Escalante HJ, 2012, EXPERT SYST APPL, V39, P11011, DOI 10.1016/j.eswa.2012.03.023
   Jang C, 2009, 2009 9 IEEE INT C CO
   Jang C, 2009, P 2009 ACM S APPL CO
   Kim HN, 2012, EXPERT SYST APPL, V39, P6955, DOI 10.1016/j.eswa.2012.01.022
   Kolmogorov A.N., 1933, FDN PROBABILITY
   Lacerda Y. A, 2008, P 14 BRAZ S MULT WEB, P162
   Lacerda YA, 2008, IEEE INT SYM MULTIM, P258, DOI 10.1109/ISM.2008.81
   Lienhart R, 2002, P INT C IM PROC AN I
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Lin DH, 2010, LECT NOTES COMPUT SC, V6311, P243
   Lo Presti L, 2014, MULTIMED TOOLS APPL, V68, P777, DOI 10.1007/s11042-012-1079-z
   Madhumathi K, 2014, INT J ADV RES COMPUT, V3, P7909
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Markus N, 2013, OBJECT DETECTION PIX
   Mezaris V, 2014, MULTIMED TOOLS APPL, V70, P1, DOI 10.1007/s11042-013-1426-8
   Monaghan F, 2007, LECT NOTES COMPUT SC, V4816, P252
   Naaman M, 2005, LEVERAGING GEOREFERE
   Nakaji Y, 2012, IEEE INT CONF MULTI, P272, DOI 10.1109/ICMEW.2012.53
   O'Hare N, 2009, IEEE T MULTIMEDIA, V11, P220, DOI 10.1109/TMM.2008.2009679
   Patel T, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P224, DOI 10.1109/ICIMIA.2017.7975607
   Psallidas F., 2013, IEEE Data Eng. Bull, V36, P42
   Qiu GF, 2013, 2013 2ND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION AND MEASUREMENT, SENSOR NETWORK AND AUTOMATION (IMSNA), P447, DOI 10.1109/IMSNA.2013.6743312
   Rabbath M, 2012, 2 ACM INT C MULT RET, P18
   Rodden K., 2003, P SIGCHI C HUMAN FAC, P409, DOI DOI 10.1145/642611.642682
   Ruocco M, 2015, INFORM PROCESS MANAG, V51, P92, DOI 10.1016/j.ipm.2014.09.001
   Sadlier David A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P215, DOI 10.1109/WIAMIS.2008.16
   Sansone E, 2017, IEEE T MULTIMEDIA, V19, P1285, DOI 10.1109/TMM.2017.2655446
   Shimizu K, 2011, P 1 ACM INT C MULT R
   Stone Z, 2008, 2008 IEEE COMP SOC C
   Varshney LR, 2008, CAMERA CULTURE, V1, P1
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang G, 2010, P 11 EUR C COMP VIS
   Wang S, 2014, IEEE T MULTIMEDIA, V16, P289, DOI 10.1109/TMM.2013.2293060
   Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Xu YS, 2017, INT CONF ACOUST SPEE, P3031, DOI 10.1109/ICASSP.2017.7952713
   Yagnik J., 2007, International Workshop on Multimedia Information Retrieval, P285
   Zhang G, 2018, LECT NOTES ARTIFICIA
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhang W, 2010, 2010 IEEE INT C IM P
   Zhu SH, 2015, PATTERN RECOGN LETT, V65, P103, DOI 10.1016/j.patrec.2015.07.037
   Zigkolis C, 2014, MULTIMED TOOLS APPL, V70, P89, DOI 10.1007/s11042-012-1154-5
NR 79
TC 4
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13841
EP 13875
DI 10.1007/s11042-018-6715-9
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900056
DA 2024-07-18
ER

PT J
AU Teimoori, F
   Razzazi, F
AF Teimoori, Farshad
   Razzazi, Farbod
TI Unsupervised help-trained LS-SVR-based segmentation in speaker
   diarization system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online speech segmentation; Help-training; LS-SVR; Unsupervised
   segmentation; Speaker diarization
ID SPEECH; FUSION
AB In this paper, we propose a new segmentation method for diarization applications. In the proposed method, segmentation is performed using a discriminatively trained support vector regression, while a generative classifier helps it to estimate the probable change points. Since, there is no pre-labeled training samples in segmentation task, the proposed model-based segmentation method tries to suggest a proper solution to bridge this gap. It is assumed that initial applied samples are labeled with the first speaker in an unsupervised manner, while the subsequent training samples are chosen by applying the help-training approach. These samples are estimated to be conducive when both regression and classifier blocks, label positive/negative samples to be advantageous. These samples would be purified in next steps and speakers' models would be updated iteratively. In addition, a new procedure is introduced to estimate deleted and inserted change points that is executed when segmentation is completed. In comparison to similar approaches, experiments have shown performance improvement about 29% in diarization error rate.
C1 [Teimoori, Farshad; Razzazi, Farbod] Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
C3 Islamic Azad University
RP Razzazi, F (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
EM teimoori@iiau.ac.ir; razzazi@srbiau.ac.ir
RI Teimoori, Farshad/AAO-2503-2021; Razzazi, Farbod/AAO-8522-2021
OI Razzazi, Farbod/0000-0003-4970-8117
CR Adankon MM, 2011, PATTERN RECOGN, V44, P2220, DOI 10.1016/j.patcog.2011.02.015
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   Anguera X., 2006, Machine Learning for Multimodal Interaction. Second International Workshop, MLMI 2005. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3869), P402
   [Anonymous], P FALL 2004 RICH TRA
   [Anonymous], INTERSPEECH
   Campbell WM, 2006, COMPUT SPEECH LANG, V20, P210, DOI 10.1016/j.csl.2005.06.003
   Cumani S, 2014, IEEE-ACM T AUDIO SPE, V22, P1590, DOI 10.1109/TASLP.2014.2341914
   Cyrta P, 2018, ADV INTELL SYST COMP, V655, P107, DOI 10.1007/978-3-319-67220-5_10
   Dimitriadis D, 2017, INTERSPEECH, P2739, DOI 10.21437/Interspeech.2017-166
   Frihia H, 2017, INT J SPEECH TECHNOL, V20, P563, DOI 10.1007/s10772-017-9427-z
   Geiger J, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2330
   Gemmeke JF, 2011, COMPUT SPEECH LANG, V25, P462, DOI 10.1016/j.csl.2010.06.004
   Han K, 2013, IEEE T AUDIO SPEECH, V21, P166, DOI 10.1109/TASL.2012.2215596
   Hautamäki V, 2013, IEEE T AUDIO SPEECH, V21, P1622, DOI 10.1109/TASL.2013.2256895
   Hu M, 2015, INT CONF ACOUST SPEE, P5743, DOI 10.1109/ICASSP.2015.7179072
   Hu W., 2017, ARXIV PREPRINT ARXIV
   Huang Y, 2007, TR07004 ICSI
   Phan H, 2015, IEEE-ACM T AUDIO SPE, V23, P20, DOI 10.1109/TASLP.2014.2367814
   India M, 2017, INTERSPEECH, P2834, DOI 10.21437/Interspeech.2017-407
   Kenny P, 2010, IEEE J-STSP, V4, P1059, DOI 10.1109/JSTSP.2010.2081790
   Kinnunen T, 2013, INT CONF ACOUST SPEE, P7229, DOI 10.1109/ICASSP.2013.6639066
   Kotti M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1101, DOI 10.1109/ICME.2006.262727
   Kumar K, 2011, INT CONF ACOUST SPEE, P4784
   Kunesová M, 2017, LECT NOTES ARTIF INT, V10415, P429, DOI 10.1007/978-3-319-64206-2_48
   Li HZ, 2007, IEEE T AUDIO SPEECH, V15, P271, DOI 10.1109/TASL.2006.876860
   Li JY, 2014, IEEE-ACM T AUDIO SPE, V22, P745, DOI 10.1109/TASLP.2014.2304637
   Liu G, 2012, INT CONF ACOUST SPEE, P4233, DOI 10.1109/ICASSP.2012.6288853
   Lopez-Otero P, 2017, MULTIMED TOOLS APPL, V76, P7421, DOI 10.1007/s11042-016-3386-2
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lu L, 2005, MULTIMEDIA SYST, V10, P332, DOI 10.1007/s00530-004-0160-5
   Ma XH, 2017, ADV INTELL SYST, V455, P399, DOI 10.1007/978-3-319-38771-0_39
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Malegaonkar AS, 2007, IEEE T AUDIO SPEECH, V15, P1859, DOI 10.1109/TASL.2007.896665
   Meignier S, 2006, COMPUT SPEECH LANG, V20, P303, DOI 10.1016/j.csl.2005.08.002
   Meignier Sylvain, 2010, P CMU SPUD WORKSH DA
   Mesgarani N, 2006, IEEE T AUDIO SPEECH, V14, P920, DOI 10.1109/TSA.2005.858055
   Minotto Vicente P., 2014, IEEE Transactions on Multimedia, V16, P1032, DOI 10.1109/TMM.2014.2305632
   Moattar MH, 2012, SPEECH COMMUN, V54, P1065, DOI 10.1016/j.specom.2012.05.002
   Naik N, 2018, SMART INNOV SYST TEC, V84, P361, DOI 10.1007/978-3-319-63645-0_40
   Parthasarathi HK, 2013, IEEE T AUDIO SPEECH, V21, P83, DOI 10.1109/TASL.2012.2215588
   Sainath TN, 2011, IEEE T AUDIO SPEECH, V19, P2598, DOI 10.1109/TASL.2011.2155060
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shao Y, 2007, INT CONF ACOUST SPEE, P277
   Shum SH, 2013, IEEE T AUDIO SPEECH, V21, P2015, DOI 10.1109/TASL.2013.2264673
   Silovsky J, 2012, INT CONF ACOUST SPEE, P4193, DOI 10.1109/ICASSP.2012.6288843
   Sinclair M, 2013, INT CONF ACOUST SPEE, P7741, DOI 10.1109/ICASSP.2013.6639170
   Sinha R., 2005, CAMBRIDGE U MARCH 20, P2437
   Soldi G, 2015, EUR SIGNAL PR CONF, P2112, DOI 10.1109/EUSIPCO.2015.7362757
   Stafylakis T, 2010, IEEE J-STSP, V4, P857, DOI 10.1109/JSTSP.2010.2048656
   Stan A, 2016, COMPUT SPEECH LANG, V35, P116, DOI 10.1016/j.csl.2015.06.006
   Suykens J. A. K., 2002, LEAST SQUARES SUPPOR
   Tranter SE, 2004, ODYSSEY04 THE SPEAKE
   Xavier-de-Souza S, 2010, IEEE T SYST MAN CY B, V40, P320, DOI 10.1109/TSMCB.2009.2020435
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Yousafzai J, 2011, IEEE T AUDIO SPEECH, V19, P1396, DOI 10.1109/TASL.2010.2090657
   Yu CZ, 2017, IEEE-ACM T AUDIO SPE, V25, P2188, DOI 10.1109/TASLP.2017.2747097
   Zajíc Z, 2016, LECT NOTES COMPUT SC, V9811, P411, DOI 10.1007/978-3-319-43958-7_49
   Zhang SX, 2013, IEEE T AUDIO SPEECH, V21, P544, DOI 10.1109/TASL.2012.2227734
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
NR 59
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11743
EP 11777
DI 10.1007/s11042-018-6621-1
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900030
DA 2024-07-18
ER

PT J
AU Yang, Z
   Zhao, Y
   Hu, X
   Yin, Y
   Zhou, LH
   Tao, DP
AF Yang, Zhao
   Zhao, Yang
   Hu, Xiao
   Yin, Yi
   Zhou, Lihua
   Tao, Dapeng
TI A flexible vehicle surround view camera system by central-around
   coordinate mapping model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surround view camera system; Fish-eye camera; Bird-eye view;
   Central-around coordinate mapping model
ID CALIBRATION; ALIGNMENT
AB The surround view camera system is an emerging driving assistant technology that can assist drivers in parking by providing top-down view of surrounding situations. Such a system usually consists of four wide-angle or fish-eye cameras that mounted around the vehicle, and a bird-eye view is synthesized from images of these cameras. Commonly there are two fundamental problems for the surround view synthesis, geometric alignment and image synthesis. Geometric alignment performs fish-eye calibration and computes the image perspective transformation between the bird-eye view and images from the surrounding cameras. Image synthesis technique dedicates to seamless stitch between adjacent views and color balancing. In this paper, we propose a flexible central-around coordinate mapping (CACM) model for vehicle surround view synthesis. The CACM model calculates perspective transformation between a top-view central camera coordinate and the around camera coordinates by a marker point based method. With the transformation matrices, we could generate the pixel point mapping relationship between the bird-eye view and images of the surrounding cameras. After geometric alignment, an image fusion method based on distance weighting is adopted for seamless stitch, and an effective overlapping region brightness optimization method is proposed for color balancing. Both the seamless stitch and color balancing can be easily operated by using two types of weight coefficient under the framework of the CACM model. Experimental results show that the proposed approaches could provide a high-performance surround view camera system.
C1 [Yang, Zhao; Hu, Xiao] Guangzhou Univ, Sch Mech & Elect Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Zhao, Yang] Yunnan Open Univ, Sch Media & Informat Engn, Kunming 650023, Yunnan, Peoples R China.
   [Yin, Yi] Kunming Shipborne Equipment Res & Test Ctr, Kunming 650051, Yunnan, Peoples R China.
   [Zhou, Lihua; Tao, Dapeng] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
C3 Guangzhou University; Yunnan University
RP Tao, DP (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
EM dapeng.tao@gmail.com
RI 周, 丽敏/JEO-3613-2023; Zhou, Li/GSE-4531-2022; Tao, Dapeng/E-8649-2013
OI Tao, Dapeng/0000-0003-0783-5273
FU NSFC [61501177, 61772455, U1713213, 61762090]; Guangzhou Key Laboratory
   [201605030014]; Guangzhou University's Training Program for Excellent
   New-recruited Doctors [YB201712]; Yunnan Natural Science Funds
   [2016FB105, 2016FA026]; Program for Excellent Young Talents of Yunnan
   University [WX069051]; Project of Innovative Research Team of Yunnan
   Province
FX This research was supported by NSFC (No. 61501177, No. 61772455, No.
   U1713213, No. 61762090), Guangzhou Key Laboratory (No. 201605030014),
   Guangzhou University's Training Program for Excellent New-recruited
   Doctors (No. YB201712), the Yunnan Natural Science Funds under Grant
   2016FB105 and 2016FA026, the Program for Excellent Young Talents of
   Yunnan University under Grant WX069051, and the Project of Innovative
   Research Team of Yunnan Province.
CR Baftiu I, 2016, 2016 IEEE INTERNATIONAL SYMPOSIUM ON ROBOTICS AND INTELLIGENT SENSORS (IRIS), P190, DOI 10.1109/IRIS.2016.8066089
   BASU A, 1995, PATTERN RECOGN LETT, V16, P433, DOI 10.1016/0167-8655(94)00115-J
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Formentin S, 2015, IEEE-ASME T MECH, V20, P1573, DOI 10.1109/TMECH.2015.2412172
   Gao Y, 2018, IEEE T INTELL TRANSP, V19, P320, DOI 10.1109/TITS.2017.2750087
   Hedi A., 2012, IFAC P, P120
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Lin CC, 2012, SENSORS-BASEL, V12, P4431, DOI 10.3390/s120404431
   Liu YC, 2008, LECT NOTES COMPUT SC, V4931, P207
   Liu YC, 2014, IEEE IMAGE PROC, P1827, DOI 10.1109/ICIP.2014.7025366
   Lo WJ, 2015, LECT NOTES COMPUT SC, V9386, P181, DOI 10.1007/978-3-319-25903-1_16
   Luo L, 2012, INT J DIGITAL CONTEN, V6, P143, DOI [10.4156/jdcta.vol6.issue15.18, DOI 10.4156/JDCTA.VOL6.ISSUE15.18]
   Natroshivili K, 2017, IEEE INT VEH S GOLD, DOI [10.1109/IVS.2017.7995702, DOI 10.1109/IVS.2017.7995702]
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Szeliski R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P251, DOI 10.1145/258734.258861
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   TAO D, 2018, TIP, V27, P325, DOI DOI 10.1109/TIP.2017.2762588
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tseng DC, 2015, INT C MECH MAT CHEM, DOI [10.2991/icmmcce-15.2015.90, DOI 10.2991/ICMMCCE-15.2015.90]
   Yeh YT, 2015, LECT NOTES COMPUT SC, V9009, P403, DOI 10.1007/978-3-319-16631-5_30
   Yu MM, 2014, SAE INT J COMMER VEH, V7, P19, DOI 10.4271/2014-01-0157
   Zhang BY, 2014, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2014.103
   Zhang Zhengyou., 1999, The Proceedings of the Seventh IEEE International Conference on, V1, P666
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 24
TC 3
Z9 4
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11983
EP 12006
DI 10.1007/s11042-018-6744-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900040
DA 2024-07-18
ER

PT J
AU Li, H
   Li, WB
AF Li, Hong
   Li, Weibin
TI RETRACTED: Enhanced artificial bee Colony algorithm and its application
   in multi-threshold image feature retrieval (Retracted article. See SEP,
   2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Artificial bee Colony algorithm; Binary image; Feature search; Griewank;
   Sphere
ID CUCKOO SEARCH ALGORITHM; SEGMENTATION; OPTIMIZATION
AB In human information, visual information accounts for about 60%. Image is the main way for humans to obtain visual information. Image binarization is an important technique in image pre-processing. It has important applications in pattern recognition, optical character recognition, and medical imaging. This paper first introduces the research background, basic principle, elements, algorithm flow, advantages, and disadvantages of bee colony algorithm. To solve the problem that artificial bee colony algorithm is easy to fall into local optimum, this paper proposes an adaptive cauchy mutation artificial bee colony algorithm. This algorithm introduces adaptive factors to expand the search range of bee colony and uses the characteristics of Cauchy distribution to search the global, which improves the universality of bee colony search. Then using stochastic process theory, the adaptive Cauchy mutation artificial bee colony algorithm is analysed theoretically, and the convergence of the algorithm has demonstrated. Finally, we can use Matlab to implement the artificial bee colony algorithm, and we can optimize the Griewank function and Sphere function. In addition, this paper has successfully used in image multi-threshold feature retrieval. Compared with the conventional methods, it shows that the method is more accurate.
C1 [Li, Hong; Li, Weibin] XianYang Normal Univ, Sch Comp Sci, Xianyang, Shaanxi, Peoples R China.
C3 Xianyang Normal University
RP Li, H (corresponding author), XianYang Normal Univ, Sch Comp Sci, Xianyang, Shaanxi, Peoples R China.
EM honglishining@163.com
RI Li, Weibin/I-9619-2018
OI Li, Weibin/0000-0002-6406-1553
FU National Natural Science Foundation of China [81473559]; Science Basic
   Research Program in Shaanxi Province of China [16JK1823]; Natural
   Science Basic Research Plan in Shaanxi Province of China [2017JM6086];
   Science Basic Research Program in Xianyang Normal University of China
   [XSYK17030]; Education Scientific Program of 13th Five-year Plan in
   Shaanxi Province of China [SGH17H196]; Teaching Reform Program in
   Xianyang Normal University of China [2017Z014]
FX The authors would like to thank the anonymous reviewers and the editor
   for suggesting various changes. And this work was supported by the
   National Natural Science Foundation of China (No. 81473559), the Science
   Basic Research Program in Shaanxi Province of China (No. 16JK1823), the
   Natural Science Basic Research Plan in Shaanxi Province of China (No.
   2017JM6086), the Science Basic Research Program in Xianyang Normal
   University of China (No. XSYK17030), the Education Scientific Program of
   13th Five-year Plan in Shaanxi Province of China (no. SGH17H196), the
   Teaching Reform Program in Xianyang Normal University of China (No.
   2017Z014).
CR Akay B, 2015, SIGNAL IMAGE VIDEO P, V9, P967, DOI 10.1007/s11760-015-0758-4
   Akbar H, 2015, INT J SIGNAL IMAGING, V8, P298, DOI 10.1504/IJSISE.2015.071953
   [Anonymous], 2014, J COMPUT INF SYST
   Aparna R, 2017, INT J ROUGH SETS DAT, V3, P21, DOI [10.4018/IJRSDA.2016070102, DOI 10.4018/IJRSDA.2016070102]
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chakraborty S, 2017, MICROSC RES TECHNIQ, V80, P1051, DOI 10.1002/jemt.22900
   Huang YL, 2015, BIOMED SIGNAL PROCES, V18, P195, DOI 10.1016/j.bspc.2015.01.003
   Jiang YZ, 2017, APPL SOFT COMPUT, V52, P1181, DOI 10.1016/j.asoc.2016.09.008
   Kaplan G, 2017, EUR J REMOTE SENS, V50, P137, DOI 10.1080/22797254.2017.1297540
   Kumar S, 2018, INT J MACH LEARN CYB, V9, P163, DOI 10.1007/s13042-015-0360-7
   Ljouad T, 2014, PATTERN RECOGN, V47, P3597, DOI 10.1016/j.patcog.2014.04.003
   Ma Y, 2017, REV FACULTAD INGENIE, V32, P809
   Norouzi A, 2014, IETE TECH REV, V31, P199, DOI 10.1080/02564602.2014.906861
   Oliva D, 2017, EXPERT SYST APPL, V79, P164, DOI 10.1016/j.eswa.2017.02.042
   PANKRATOVA ND, 1930, COMPUTER SCIENCE JOU, V22, P303
   Pant S, 2017, INT J SYST ASSUR ENG, V8, P1858, DOI 10.1007/s13198-017-0623-7
   Ranjani JJ, 2014, COMPUTER VISION LET, V9, P41
   Salgotra R, 2017, EXPERT SYST APPL, V79, P112, DOI 10.1016/j.eswa.2017.02.035
   Saraswat M, 2014, MICRON, V65, P20, DOI 10.1016/j.micron.2014.04.001
   Sudhakar B, 2014, INT J ENG TRENDS TEC, V18, P264, DOI [10.14445/22315381/IJETT-V18P254, DOI 10.14445/22315381/IJETT-V18P254]
   Vashistha S, 2015, INT J ENG COMPUTER S, V4, P12327
   Yao BZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181275
NR 22
TC 7
Z9 7
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8683
EP 8698
DI 10.1007/s11042-018-6066-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800044
DA 2024-07-18
ER

PT J
AU Yao, H
   Liu, XK
   Tang, ZJ
   Qin, C
   Tian, Y
AF Yao, Heng
   Liu, Xiaokai
   Tang, Zhenjun
   Qin, Chuan
   Tian, Ying
TI Adaptive image camouflage using human visual system model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Image watermarking; Image camouflage; Human visual
   system; High capacity
ID ENCRYPTION; WATERMARKING; SCHEME; TRANSFORMATION; ALGORITHM
AB The development of image decryption techniques means that some current encryption techniques that turn a secret image into a meaningless image are no longer safe. Recently, encrypting an image into another meaningful image has opened a new route to transmit the secret image. This paper proposes an improved image encryption approach to camouflage the secret image into another host image. The visual quality of the final camouflage image has been significantly improved by using a human visual system (HVS) model. First, the secret image is pre-encrypted with a specific image encryption method, e.g., chaotic mapping method, then the host image is decomposed by a lifting wavelet transform (LWT) to generate integral wavelet coefficients. The encrypted secret image is then adaptively adjusted to a narrower range to guarantee that the final camouflage image is within a reasonable interval. Next, by using a HVS model, each modified image pixel is embedded into the corresponding detailed coefficients through an adaptive allocation strategy. Specifically, for pixels with extremely high or low intensity or high texture complexity, more bits of the modified secret pixels are allocated to substitute for the corresponding bits of coefficients. Then the modified coefficients are retransformed back to generate the final camouflage image. The secret image can be losslessly recovered through reversal procedures. The experimental results demonstrate the efficacy of the proposed method.
C1 [Yao, Heng; Qin, Chuan; Tian, Ying] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
   [Yao, Heng; Tang, Zhenjun] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Liu, Xiaokai] Univ Shanghai Sci & Technol, Sch Mech Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology; Guangxi Normal
   University; University of Shanghai for Science & Technology
RP Qin, C (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
EM hyao@usst.edu.cn; lxkusst@163.com; zjtang@gxnu.edu.cn; qin@usst.edu.cn;
   tianying@usst.edu.cn
RI Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623
FU National Natural Science Foundation of China [61702332, 61672354,
   61562007]; Research Fund of Guangxi Key Lab of Multi-source Information
   Mining Security [MIMS16-03]; Guangxi Natural Science Foundation
   [2017GXNSFAA198222]; Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing
FX This work was supported in part by the National Natural Science
   Foundation of China (61702332, 61672354, 61562007), Research Fund of
   Guangxi Key Lab of Multi-source Information Mining &
   Security(MIMS16-03), the Guangxi Natural Science Foundation
   (2017GXNSFAA198222), the Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing. The
   authors would like to thank the anonymous reviewers for their helpful
   comments.
CR Abu Dalhoum AL, 2016, MULTIMED TOOLS APPL, V75, P17019, DOI 10.1007/s11042-015-2972-z
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   CHU HK, 2010, ACM T GRAPHIC, V29, P1
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Farri E, 2018, NONLINEAR DYNAM, V93, P1875, DOI 10.1007/s11071-018-4295-x
   FIPS PUB, 1999, DAT ENCR STAND DES
   FIPS PUB, 2001, ANN ADV ENCR STAND A
   HOU D, 2016, IMAGE, V40, P225, DOI DOI 10.1016/j.jvcir.2016.06.018
   Hou DD, 2018, J VIS COMMUN IMAGE R, V53, P134, DOI 10.1016/j.jvcir.2017.11.014
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Lai IJ, 2011, IEEE T INF FOREN SEC, V6, P936, DOI 10.1109/TIFS.2011.2135853
   Lama RK, 2014, MULTIMED TOOLS APPL, V73, P873, DOI 10.1007/s11042-013-1381-4
   Lee YL, 2014, IEEE T CIRC SYST VID, V24, P695, DOI 10.1109/TCSVT.2013.2283431
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rivest R., 1992, Rsa Data Secur Inc Doc No, V20, P86
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang Y, 2018, NEUROCOMPUTING, V275, P1318, DOI 10.1016/j.neucom.2017.09.068
   Yao H, 2018, IEEE ACCESS, V6, P40569, DOI 10.1109/ACCESS.2018.2858858
   Yao H, 2017, J VIS COMMUN IMAGE R, V43, P152, DOI 10.1016/j.jvcir.2017.01.004
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 29
TC 6
Z9 6
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8311
EP 8334
DI 10.1007/s11042-018-6813-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800024
DA 2024-07-18
ER

PT J
AU Zhao, LJ
   Zhang, W
   Tang, P
AF Zhao, Lijun
   Zhang, Wei
   Tang, Ping
TI Analysis of the inter-dataset representation ability of deep features
   for high spatial resolution remote sensing image scene classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing image; Scene classification; Inter-dataset feature
   representation; Deep learning features; Convolutional neural networks
   (CNNs)
ID PIXEL-BASED CLASSIFICATIONS; BAG; FUSION; MODEL
AB Recently, scene based classification has become a new trend for very high spatial resolution remote sensing image interpretation. With the advent of deep learning, the pretrained convolutional neural networks (CNNs) have been proved effective as feature extractors for scene classification tasks in the remote sensing domain, but the potential characteristics and capabilities of such deep features have not been sufficiently analyzed and fully understood. Facing with complex remote sensing scenes with huge intra-class variations, it is still not clear about the limitation of these powerful deep features in exploring essential invariant attributes of remote sensing scenes of the same kind but, in most cases, from separate sources. Therefore, this paper makes an intensive investigation in the feature representation ability of such deep features from the aspect of inter-dataset scene classification of remote sensing images. Four well-known pretrained CNN models and three different commonly used datasets are selected and summarized. Firstly, deep features extracted from various intermediate layers of these models are compared. Then, the inter-dataset feature representation ability is evaluated using cross-classification of different datasets and discussed in terms of imaging spatial resolution, image size, model structure, and time efficiency. Finally, several instructive findings are revealed and conclusions are drawn regarding the strength and weakness of the CNN features in the application of remote sensing image scene classification.
C1 [Zhao, Lijun; Zhang, Wei; Tang, Ping] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100101, Peoples R China.
   [Zhang, Wei] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; The Institute of Remote Sensing & Digital
   Earth, CAS; Chinese Academy of Sciences; University of Chinese Academy
   of Sciences, CAS
RP Zhao, LJ (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100101, Peoples R China.
EM zhaolj01@radi.ac.cn
FU Major Project of High Resolution Earth Observation System of China
   [03-Y20A04-9001-17/18]; National Natural Science Foundation of China
   [41701397]
FX This work was supported in part by the Major Project of High Resolution
   Earth Observation System of China under Grant 03-Y20A04-9001-17/18 and
   in part by the National Natural Science Foundation of China under Grant
   41701397.
CR [Anonymous], 2004 ECCV INT WORKSH
   [Anonymous], 4 NAT C SOC MED PROC
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], NeurIPS
   [Anonymous], 18 ACM SIGSPATIAL IN
   [Anonymous], 2017 ACM C MULT MOUN
   [Anonymous], 2016 ACM C MULT AMST
   [Anonymous], IEEE COMPUT SOC CONF
   [Anonymous], 2014, ACM INT C MULTIMEDIA
   [Anonymous], IEEE INT GEOSC REM S
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cai SS, 2013, REMOTE SENS LETT, V4, P998, DOI 10.1080/2150704X.2013.828180
   Castelluccio M., 2015, Land Use Classification in Remote Sensing Images by Convolutional Neural Networks
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen SZ, 2015, IEEE T GEOSCI REMOTE, V53, P1947, DOI 10.1109/TGRS.2014.2351395
   Cheng G, 2015, IEEE T GEOSCI REMOTE, V53, P4238, DOI 10.1109/TGRS.2015.2393857
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Dai DX, 2011, IEEE GEOSCI REMOTE S, V8, P173, DOI 10.1109/LGRS.2010.2055033
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Lazebnik S., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.68
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Mekhalfi ML, 2015, IEEE GEOSCI REMOTE S, V12, P2155, DOI 10.1109/LGRS.2015.2453130
   Mühling M, 2017, MULTIMED TOOLS APPL, V76, P22169, DOI 10.1007/s11042-017-4962-9
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Oommen T, 2008, MATH GEOSCI, V40, P409, DOI 10.1007/s11004-008-9156-6
   Qi KL, 2015, IEEE GEOSCI REMOTE S, V12, P2403, DOI 10.1109/LGRS.2015.2478966
   Qu T, 2017, MULTIMED TOOLS APPL, V76, P21651, DOI 10.1007/s11042-016-4043-5
   Shahriari M, 2017, MULTIMED TOOLS APPL, V76, P23059, DOI 10.1007/s11042-016-4316-z
   Shao W, 2013, INT J REMOTE SENS, V34, P8588, DOI 10.1080/01431161.2013.845925
   Sheng GF, 2012, INT J REMOTE SENS, V33, P2395, DOI 10.1080/01431161.2011.608740
   Sridharan H, 2015, IEEE GEOSCI REMOTE S, V12, P676, DOI 10.1109/LGRS.2014.2357392
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Weng Q, 2017, IEEE GEOSCI REMOTE S, V14, P704, DOI 10.1109/LGRS.2017.2672643
   Whiteside TG, 2011, INT J APPL EARTH OBS, V13, P884, DOI 10.1016/j.jag.2011.06.008
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zhao B, 2013, REMOTE SENS LETT, V4, P1204, DOI 10.1080/2150704X.2013.858843
   Zhao LJ, 2014, IEEE J-STARS, V7, P4620, DOI 10.1109/JSTARS.2014.2339842
   Zhao LJ, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.035004
   Zhao LJ, 2014, INT J REMOTE SENS, V35, P2296, DOI 10.1080/01431161.2014.890762
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P6207, DOI 10.1109/TGRS.2015.2435801
NR 50
TC 16
Z9 16
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9667
EP 9689
DI 10.1007/s11042-018-6548-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400008
DA 2024-07-18
ER

PT J
AU Chen, XY
   Zhong, HD
   Qiu, AQ
AF Chen, Xianyi
   Zhong, Haidong
   Qiu, Anqi
TI Reversible data hiding scheme in multiple encrypted images based on code
   division multiplexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Code division multiplexing (CDM);
   Encrypted image in cloud
ID WATERMARKING; DIFFERENCE; SEARCH
AB Recently, a reversible data hiding (RDH) scheme based on code division multiplexing (CDM) has been reported, in which secret information and pseudo bits are transformed into spreading sequences. Most sequences may be mutually offset when they are repeatedly embedded, which leads to image quality and embedding capacity improvement. Despite of these advantages, the pseudo bits may cause the image distortion, especially in the low embedding rates. Moreover, it is hard to protect image content when the image is uploaded to cloud server. In order to solve these problems, we propose an RDH scheme based on CDM in multiple encrypted images (RDHMEI) with public key cryptography. The proposed method first encrypted the image using the Paillier homomorphic encryption. Afterwards, the encrypted pixels that have a same coordinate in the multiple images are selected as the elements of the embedding vector. Instead of traditional dual-images based RDH, the proposed method can embed additional bits into the embedding vector while the pixel correlation disappears after encrypting. Experimental results demonstrate the effectiveness and advantages of the proposed method.
C1 [Chen, Xianyi; Zhong, Haidong; Qiu, Anqi] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Chen, XY (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
EM 0204622@163.com; zhhd_2016@163.com; 807066727@qq.com
RI Qiu, Anqi/H-2267-2011
OI Qiu, Anqi/0000-0002-0215-6338
FU National Natural Science Foundation of China [61502242, U1536206,
   U1405254, 61772283, 61602253, 61672294]; National Key R&D Program of
   China [2018YFB1003205]; Jiangsu Basic Research Programs-Natural Science
   Foundation [BK20150925, BK20151530]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD) fund;
   Collaborative Innovation Center of Atmospheric Environment and Equipment
   Technology (CICAEET) fund, China
FX This work is supported by the National Natural Science Foundation of
   China under grant 61502242, U1536206, U1405254, 61772283, 61602253,
   61672294; by the National Key R&D Program of China under grant
   2018YFB1003205; by the Jiangsu Basic Research Programs-Natural Science
   Foundation under grant numbers BK20150925 and BK20151530; by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD) fund; by the Collaborative Innovation Center of
   Atmospheric Environment and Equipment Technology (CICAEET) fund, China.
CR [Anonymous], IEEE TRANS INF FOREN
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Fu ZJ, 2017, IEEE T INF FOREN SEC, V12, P2986, DOI 10.1109/TIFS.2017.2730365
   Fu ZJ, 2017, IEEE T INF FOREN SEC, V12, P1874, DOI 10.1109/TIFS.2017.2692728
   Fujiyoshi M., 2007, P IEEE ICIP, V3
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu YL, 2016, J VIS COMMUN IMAGE R, V39, P51, DOI 10.1016/j.jvcir.2016.05.008
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Qu ZG, 2016, CHINA COMMUN, V13, P108, DOI 10.1109/CC.2016.7559082
   Ren YJ, 2016, J INTERNET TECHNOL, V17, P1125, DOI 10.6138/JIT.2016.17.6.20160714
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang BW, 2017, INT J SENS NETW, V23, P265, DOI 10.1504/IJSNET.2017.083532
   Wu XT, 2016, J VIS COMMUN IMAGE R, V41, P58, DOI 10.1016/j.jvcir.2016.09.005
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xuan G, 2013, LNCS, P368
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zhang J, 2017, INT J SENS NETW, V23, P248, DOI 10.1504/IJSNET.2017.083533
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 34
TC 9
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7499
EP 7516
DI 10.1007/s11042-018-6446-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700048
DA 2024-07-18
ER

PT J
AU Joseph, LMIL
   Rajarajan, S
AF Joseph, L. M. I. Leo
   Rajarajan, S.
TI Reconfigurable hybrid vision enhancement system using tone mapping and
   adaptive gamma correction algorithm for night surveillance robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid vision enhancement (HVE) system; Reconfigurable architecture;
   Night vision images; Optimized tone mapping (OTM); Adaptive gamma
   correction (AGC); Wide dynamic range (WDR) images
ID IMPLEMENTATION; DECOMPOSITION
AB Night vision system has become a critical component of modern warfare and the ability to see in nighttime conditions allows military maneuvers and a potential advantage to the forces equipped with this technology. These night vision systems rely on the very low light levels of night sky illumination to help image the targeted scene and its surroundings. Many research works have been undertaken to overcome issues in hardware implementation. In this paper, we contribute to enhance night vision sources by hybrid vision enhancement (HVE) system without affecting performance of hardware implementation. The proposed hybrid system consists of two algorithms such asoptimizedtone mapping (OTM) and adaptive gamma correction (AGC) algorithm. Normally, hybrid systems are not an area efficient, here we modify the tone mapping algorithm byoptimized filter design with the exponential basis. The differential evolution optimization algorithm is used to enhance the filter design. The proposed HVE system implementation is designed in Verilog language and synthesized with different FPGA device families in Xilinx tool. Simulation result shows that our proposed HVE system is able to enhance vision of wide dynamic range (WDR) images to good visual quality. The synthesis result shows that our proposed HVE system perform very efficient than existing system in terms of hardware utilization, maximum clock frequency, and power.
C1 [Joseph, L. M. I. Leo] Sathyabama Inst Sci & Technol, Chennai, Tamil Nadu, India.
   [Rajarajan, S.] Sri Sairam Inst Technol, Dept Elect & Commun Engn, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Joseph, LMIL (corresponding author), Sathyabama Inst Sci & Technol, Chennai, Tamil Nadu, India.
EM leojoseph0378@gmail.com
RI S, Rajarajan/G-5663-2012; Leo Joseph, Maria Irudaya/AAP-2821-2020;
   joseph, leo/HGC-9880-2022
OI S, Rajarajan/0000-0001-6904-2709; Leo Joseph, Maria
   Irudaya/0000-0003-4269-7670; , Rajarajan/0000-0002-7406-4440
CR Ambalathankandy P., 2016, J REAL TIME IMAGE PR
   [Anonymous], [No title captured]
   Bayani H, 2016, ROBOT AUTON SYST, V75, P187, DOI 10.1016/j.robot.2015.10.002
   Bouzidi I, 2017, MULTIMED TOOLS APPL
   Chen SL, 2016, J DISP TECHNOL, V12, P1494, DOI 10.1109/JDT.2016.2609499
   Cvetkovic S, 2008, IEEE T CONSUM ELECTR, V54, P904, DOI 10.1109/TCE.2008.4560177
   Gu B, 2013, IEEE T IMAGE PROCESS, V22, P70, DOI 10.1109/TIP.2012.2214047
   Guarnieri G, 2011, IEEE T IMAGE PROCESS, V20, P1351, DOI 10.1109/TIP.2010.2092436
   Guo J, 2016, REV TEC ING U ZULIA
   Hassan F, 2007, J REAL-TIME IMAGE PR, V2, P293, DOI 10.1007/s11554-007-0056-7
   Horé A, 2014, INT CONF ACOUST SPEE
   Kim K, 2011, IEEE T CONSUM ELECTR, V57, P1807, DOI 10.1109/TCE.2011.6131157
   Lapray PJ, 2016, J REAL-TIME IMAGE PR, V12, P747, DOI 10.1007/s11554-013-0393-7
   Lee JW, 2010, IEEE T CONSUM ELECTR, V56, P2772, DOI 10.1109/TCE.2010.5681168
   Li ZG, 2014, IEEE T IND ELECTRON, V61, P7076, DOI 10.1109/TIE.2014.2314066
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Cañada PM, 2013, J SYST ARCHITECT, V59, P30, DOI 10.1016/j.sysarc.2012.10.005
   Mikhaylyuk MV, 2015, PROGRAM COMPUT SOFT+, V41, P289, DOI 10.1134/S0361768815050084
   Nnolim UA, 2015, MICROPROCESS MICROSY, V39, P223, DOI 10.1016/j.micpro.2015.04.005
   Ok J, 2017, J VIS COMMUN IMAGE R, V43, P61, DOI 10.1016/j.jvcir.2016.12.008
   Popovic V, 2016, J REAL-TIME IMAGE PR, V12, P697, DOI 10.1007/s11554-014-0444-8
   Popovic V, 2014, IEEE T CIRCUITS-II, V61, P803, DOI 10.1109/TCSII.2014.2345306
   RANADE S, 1981, IEEE T SYST MAN CYB, V11, P370
   Shahnovich U, 2016, 2016 IEEE INT S CIRC
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Ureña R, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-1
   Várkonyi-Kóczy AR, 2008, IEEE T INSTRUM MEAS, V57, P1779, DOI 10.1109/TIM.2008.925715
   Várkonyi-Kóczy AR, 2007, I S INTELL SIG PR, P187
   Vytla L, 2013, J REAL-TIME IMAGE PR, V8, P153, DOI 10.1007/s11554-011-0198-5
   Wang T, 2007, 2007 IEEE INT C IM P
   Wang TH, 2010, IEEE T IMAGE PROCESS, V19, P3089, DOI 10.1109/TIP.2010.2052269
   Warrant E, 2014, P IEEE, V102, P1411, DOI 10.1109/JPROC.2014.2332533
   WU X, 2011, TIP, V20, P1262, DOI DOI 10.1109/TIP.2010.2092438
   Yuan XR, 2006, IEEE T VIS COMPUT GR, V12, P433, DOI 10.1109/TVCG.2006.72
   Zoll C, 2003, LINGUIST INQ, V34, P225, DOI 10.1162/002438903321663398
NR 35
TC 4
Z9 4
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6013
EP 6032
DI 10.1007/s11042-018-6321-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100048
DA 2024-07-18
ER

PT J
AU Khoh, WH
   Pang, YH
   Teoh, ABJ
AF Khoh, Wee How
   Pang, Ying Han
   Teoh, Andrew Beng Jin
TI In-air hand gesture signature recognition system based on 3-dimensional
   imagery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic signature; Hand gesture signature; Biometrics; Motion analysis;
   Gesture recognition
ID VERIFICATION
AB A traditional online handwritten signature recognition system requires direct contact to acquisition device and usually will leave a traceable print on the surface. This made a signature possible and vulnerable to certain attempts of tracking and imitated. Looking into this shortfall, this paper proposes a novel approach to recognise an individual based on his/ her in-air hand motion while signing his/her signature. In this study, a low-cost acquisition device - Microsoft Kinect sensor is adopted to capture an image sequence of hand gesture signature. Palm region is first located and segmented through a predictive palm segmentation algorithm, which are then combined to generate a volume data. The volume data is condensed and reduced into a motion representation image by means of Motion History Image (MHI), which produces rich motion and temporal information. Several features are extracted from the MHI for empirical evaluation. Two classical recognition modes - identification and verification, are testified with an in-house database (HGS database). The proposed system achieves 90.4% identification accuracy and 3.22% equal error rate in verification mode. The experimental results substantiated the potential of the proposed system.
C1 [Khoh, Wee How; Pang, Ying Han] Multimedia Univ, Jalan Ayer Keroh Lama, Bukit Beruang 75450, Melaka, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Seoul, South Korea.
C3 Multimedia University; Yonsei University
RP Khoh, WH (corresponding author), Multimedia Univ, Jalan Ayer Keroh Lama, Bukit Beruang 75450, Melaka, Malaysia.
EM whkhoh@mmu.edu.my; yhpang@mmu.edu.my; bjteoh@yonsei.ac.kr
RI Pang, Ying Han/AGW-5132-2022; Teoh, Andrew Beng Jin/F-4422-2010
OI Khoh, Wee How/0000-0002-7338-8427; PANG, YING HAN/0000-0002-3781-6623
CR Babu RV, 2004, IMAGE VISION COMPUT, V22, P597, DOI 10.1016/j.imavis.2003.11.004
   Chen C.-P., 2011, VISUAL COMMUN-US, P1
   Chen Y, 2013, CANCER CELL INT, V13, DOI 10.1186/1475-2867-13-6
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Fierrez J., 2008, HDB BIOMETRICS, P189, DOI DOI 10.1007/978-0-387-71041-9_10
   Fierrez J, 2007, PATTERN RECOGN LETT, V28, P2325, DOI 10.1016/j.patrec.2007.07.012
   Fischer A, 2015, PROC INT CONF DOC, P241, DOI 10.1109/ICDAR.2015.7333760
   Gruber C, 2010, IEEE T SYST MAN CY B, V40, P1088, DOI 10.1109/TSMCB.2009.2034382
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Iranmanesh V, 2014, SCI WORLD J, DOI 10.1155/2014/381469
   Jaemin L, 2013, KOR-JPN JT WORKS FR, P127, DOI 10.1109/FCV.2013.6485474
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jeon JH, 2012, I C CONT AUTOMAT ROB, P171, DOI 10.1109/ICARCV.2012.6485153
   Ju ZJ, 2016, MULTIMED TOOLS APPL, V75, P11929, DOI 10.1007/s11042-015-2609-2
   Kashi RS, 1997, PROC INT CONF DOC, P253, DOI 10.1109/ICDAR.1997.619851
   Khalil MI, 2009, IEEE IMAGE PROC, P2713, DOI 10.1109/ICIP.2009.5414166
   Khoh W. H., 2014, SUNWAY ACAD J, V11, P11
   Khoh WH, 2014, SECUR COMMUN NETW, V7, P1067, DOI 10.1002/sec.829
   Kholmatov A, 2005, PATTERN RECOGN LETT, V26, P2400, DOI 10.1016/j.patrec.2005.04.017
   Kour J, 2011, INT C IM INF PROC IE, P1, DOI [10.1109/ICIIP.2011.6108923, DOI 10.1109/ICIIP.2011.6108923]
   Ling X, 2010, P 19 ANN WIR OPT COM, P1
   Manabe Hirokazu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P34, DOI 10.1109/IIH-MSP.2009.51
   Mendels O, 2014, IEEE T SYST MAN CY-S, V44, P1461, DOI 10.1109/TSMC.2014.2329652
   Meshoul S., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P314, DOI 10.1109/ISCC.2010.5546760
   Park M., 2012, P INT C IM PROC COMP, V2, P779
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Raheja J. L., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P248, DOI 10.1109/CIMSim.2011.51
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sun ZW, 2016, SECUR COMMUN NETW, V9, P1359, DOI 10.1002/sec.1422
   Van Bang Le, 2014, International Journal of Information and Electronics Engineering, V4, P176, DOI 10.7763/IJIEE.2014.V4.430
   YANG L, 1995, PATTERN RECOGN, V28, P161, DOI 10.1016/0031-3203(94)00092-Z
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 35
TC 9
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6913
EP 6937
DI 10.1007/s11042-018-6458-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700023
DA 2024-07-18
ER

PT J
AU Kim, SJ
   Kim, JM
   Jo, IJ
AF Kim, Seon-Joo
   Kim, Jin-Mook
   Jo, In-June
TI Multimedia image data processing on smartphone for authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; Smartphone authentication information; IMEI;
   Multimedia image data processing
AB The spread of smartphones is rapidly increasing. Such smartphones mainly handle image and video data. In particular, there are many security problems that may occur at this time when there are many accesses to multimedia image data. But most systems use various technologies for user authentication such as identification/password (ID/PW), the certificate, One-Time Password (OTP), fingerprint/iris recognition, etc. When using ID/PW technology, the system is vulnerable, if ID/PW is disclosed to a hacker. The certificate or fingerprint/iris recognition technologies are more secure than ID/PW technology, but they require more cost, and they are complex to build. In this paper, we propose the method for enhancing user authentication. The proposed method improves security at a low cost using the user's authentication information and the user's smartphone IMEI information. In particular, IMEI information can be seen to provide a fast right and secure authentication mechanism to perform user authentication of multimedia image processing. In our research method, it is much safer and superior responsiveness than authentication methods using only user ID / Password on smartphones.
C1 [Kim, Seon-Joo] SW Testing & Certificat Lab TTA, 47 Bungand Ro, Seongnam City 13591, Gyeonggi Do, South Korea.
   [Kim, Jin-Mook] SunMoon Univ, Ind Univ Cooperat Fdn, Dept IT, Educ Fac, 70 Sumnoon Ro 221 Beon Gil, Asan 31460, Chungcheongnam, South Korea.
   [Jo, In-June] Paichai Univ, Dept CyberSecur, 155-40 Baejae Ro, Daejeon 35345, South Korea.
C3 Sun Moon University; Pai Chai University
RP Kim, JM (corresponding author), SunMoon Univ, Ind Univ Cooperat Fdn, Dept IT, Educ Fac, 70 Sumnoon Ro 221 Beon Gil, Asan 31460, Chungcheongnam, South Korea.
EM sunjoo@tta.or.kr; calf0425@surunoon.ac.kr; injune@pcu.ac.kr
CR [Anonymous], 2000, TTAE3G22016
   [Anonymous], 2015, ADV DIS BIOM TECHN P
   [Anonymous], RES DEM
   [Anonymous], 2015, KT DIGIECO REPORT
   Cho S, 2014, ETRI SPECIAL ISSUE S
   Haller N, 1998, 2289 RFC IETF
   Kim S-Y, 2014, J KOREA CONTENTS SOC, V4
   Kim Y, 2001, ETRI ELECT TELECOMMU, V16, P12
   KISA, 2015, REP MOB INT US SURV
   KISA, 2011, RES SEC CRIT EXT EL
   Lee JH, 2013, UTILIZATION PROBLEMS
   Lee S-M, 2012, CURRENT TRENDS AUTHE
   Na S, 2011, REV KOREA I INFORM S
   Song SH, 2012, REV KOREA I INFORM S, V22
NR 14
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5287
EP 5303
DI 10.1007/s11042-017-5600-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100012
DA 2024-07-18
ER

PT J
AU Shreyamsha Kumar, BK
   Swamy, MNS
   Ahmad, MO
AF Shreyamsha Kumar, B. K.
   Swamy, M. N. S.
   Ahmad, M. Omair
TI Visual tracking using structural local DCT sparse appearance model with
   occlusion detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Local DCT sparse appearance model; Holistic image
   reconstruction; Reconstruction error; Occlusion map; Observation model
   update
ID PARTICLE FILTER; FACE RECOGNITION; OBJECT TRACKING
AB In this paper, a structural local DCT sparse appearance model with occlusion detection is proposed for visual tracking in a particle filter framework. The energy compaction property of the 2D-DCT is exploited to reduce the size of the dictionary as well as that of the candidate samples so that the computational cost of l(1)-minimization can be lowered. Further, a holistic image reconstruction procedure is proposed for robust occlusion detection and used for appearance model update, thus avoiding the degradation of the appearance model in the presence of occlusion/outliers. Also, a patch occlusion ratio is introduced in the confidence score computation to enhance the tracking performance. Quantitative and qualitative performance evaluations on two popular benchmark datasets demonstrate that the proposed tracking algorithm generally outperforms several state-of-the-art methods.
C1 [Shreyamsha Kumar, B. K.; Swamy, M. N. S.; Ahmad, M. Omair] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
EM omair@encs.concordia.ca
RI Kumar, B. K. Shreyamsha/F-1624-2010
OI Kumar, B. K. Shreyamsha/0000-0002-3781-0635; Swamy,
   M.N.Srikanta/0000-0002-3989-5476
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Regroupement Strategique en Microsystemes du Quebec (ReSMiQ); Ministere
   de l'Education, de l'Enseignement Superieur et de la Recherche (MEESR)
   du Quebec
FX This work was supported by the Natural Sciences and Engineering Research
   Council (NSERC) of Canada, the Regroupement Strategique en Microsystemes
   du Quebec (ReSMiQ), and Ministere de l'Education, de l'Enseignement
   Superieur et de la Recherche (MEESR) du Quebec.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2017, IEEE TIP, DOI DOI 10.1109/TIP.2017.2656628
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Chen DT, 2008, IEEE T MULTIMEDIA, V10, P268, DOI 10.1109/TMM.2007.911835
   Chen HK, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1614, DOI 10.1109/ROBIO.2014.7090565
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dai PY, 2013, INT CONF ACOUST SPEE, P1803, DOI 10.1109/ICASSP.2013.6637963
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gao JY, 2018, IEEE T IMAGE PROCESS, V27, P3074, DOI 10.1109/TIP.2018.2813166
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   He D, 2009, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2009.5414506
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Krishna MV, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON POWER ELECTRONICS, DRIVES AND ENERGY SYSTEMS (PEDES)
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li X, 2013, IEEE T PATTERN ANAL, V35, P863, DOI 10.1109/TPAMI.2012.166
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Lin C, 2013, ADV INTEL SYS RES, V42, P162
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ou WH, 2018, MULTIMED TOOLS APPL, V77, P10569, DOI 10.1007/s11042-017-4672-3
   Pennerbaker W, 1992, JPEG STILL IMAGE DAT
   Qu P., 2014, INT J SIGNAL PROCESS, V7, P23, DOI DOI 10.14257/ijsip.2014.7.2.03
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shreyamsha Kumar BK, 2016, IEEE INT SYMP CIRC S, P986, DOI 10.1109/ISCAS.2016.7527408
   Shreyamsha Kumar BK, 2015, IEEE INT SYMP CIRC S, P1194, DOI 10.1109/ISCAS.2015.7168853
   Shreyamsha Kumar BK, 2013, CAN CON EL COMP EN, P265, DOI 10.1109/CCECE.2013.6567721
   SHREYAMSHAKUMAR BK, 2016, CANADIAN CONF ELECT, DOI DOI 10.1109/CCECE.2016.7726647
   Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57
   Wang D, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417317
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P5166, DOI 10.1109/TIP.2015.2478399
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang D, 2012, IEEE SIGNAL PROC LET, V19, P711, DOI 10.1109/LSP.2012.2215320
   Wang FL, 2015, COMM COM INF SC, V525, P438, DOI 10.1007/978-3-662-47791-5_49
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   You XH, 2015, SIGNAL PROCESS, V111, P308, DOI 10.1016/j.sigpro.2014.09.019
   Zhang HL, 2015, MULTIMED TOOLS APPL, V74, P1021, DOI 10.1007/s11042-013-1709-0
   Zhang TZ, 2019, IEEE T PATTERN ANAL, V41, P365, DOI 10.1109/TPAMI.2018.2797062
   Zhang TZ, 2018, IEEE T IMAGE PROCESS, V27, P2676, DOI 10.1109/TIP.2017.2781304
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
   Zhuang BH, 2016, NEUROCOMPUTING, V218, P61, DOI 10.1016/j.neucom.2016.08.070
NR 55
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7243
EP 7266
DI 10.1007/s11042-018-6453-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700038
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wu, H
   Bie, RF
   Guo, JQ
   Meng, X
   Wang, SL
AF Wu, Hao
   Bie, Rongfang
   Guo, Junqi
   Meng, Xin
   Wang, Shenling
TI Sparse coding based few learning instances for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Cross-validation sparse coding representation; Sparse
   coding based instance distance; KNN; AP value; AUC value
ID FEATURES
AB Hundreds of thousands of images that are widely used in different fields of modern life have appeared in recent years. The process of retrieving the target images from a big database has become a meaningful problem. As one of the classical techniques of computer vision, image retrieval could effectively solve the problem. However, in most cases, high-quality retrieval results are supported by a large number of learning instances. It not only occupies much computing resources but also wastes much human resource. Moreover, much time is wasted in the process of retrieval. To solve the abovementioned problems, we proposed a sparse coding based few learning instances model for retrieval. Concretely, cross-validation sparse coding representation, sparse coding based instance distance and improved KNN model are combined which directly contributes to build up the previous model. It could reduce the number of learning instances significantly through the selection of optimized learning instances while preserving the retrieval accuracy. At last, a database using a large number of images was set up. The experimental results using the database show our method's superiority in preserving the quality of retrieval with the reduction of learning instances.
C1 [Wu, Hao; Bie, Rongfang; Guo, Junqi; Wang, Shenling] Beijing Normal Univ, Coll Infonnat Sci & Technol, Beijing, Peoples R China.
   [Meng, Xin] Elect Power Planning & Engn Inst, Beijing, Peoples R China.
C3 Beijing Normal University
RP Wang, SL (corresponding author), Beijing Normal Univ, Coll Infonnat Sci & Technol, Beijing, Peoples R China.
EM shenlingwangbnu@163.com
FU Fundamental Research Funds for the Central Universities [2016NT14];
   National Natural Science Foundation of China [61601033]; Beijing
   Advanced Innovation Center for Future Education [BJAICFE2016IR-004]
FX This research is sponsored by Fundamental Research Funds for the Central
   Universities (No.2016NT14), National Natural Science Foundation of China
   (No.61601033) and Beijing Advanced Innovation Center for Future
   Education (BJAICFE2016IR-004).
CR Alham NK, 2011, COMPUT MATH APPL, V62, P2801, DOI 10.1016/j.camwa.2011.07.046
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], IEEE INT C IM PROC 2
   [Anonymous], 2009 16 IEEE INT C I
   [Anonymous], TIP
   [Anonymous], MULTIMEDIA TOOLS AND
   [Anonymous], IMAGE
   [Anonymous], 2011, IMAGE CLASSIFICATION
   [Anonymous], IEEE C EV COMP
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2015, PROC IEEE C COMPUT V
   [Anonymous], 2008, P 25 INT C MACH LEAR
   Arbelaez Pablo., 2007, The Berkeley segmentation dataset and benchmark
   Arora S., 2015, C LEARN THEOR PMLR, V40
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Bulò SR, 2011, PATTERN RECOGN, V44, P2109, DOI 10.1016/j.patcog.2011.03.016
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Cui ZY, 2015, J INTELL ROBOT SYST, V80, pS121, DOI 10.1007/s10846-015-0213-3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dimitrovski I, 2016, INFORM SCIENCES, V329, P851, DOI 10.1016/j.ins.2015.05.012
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kramer O., 2013, Dimensionality Reduction with Unsupervised Nearest Neighbors, P13, DOI DOI 10.1007/978-3-642-38652-72
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2018, IEEE T IMAGE PROCESS, V27, P106, DOI 10.1109/TIP.2017.2755766
   Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058
   Moustakidis S, 2012, IEEE T GEOSCI REMOTE, V50, P149, DOI 10.1109/TGRS.2011.2159726
   Munajat E, 2015, INT C ADV COMP SCI I, P195, DOI 10.1109/ICACSIS.2015.7415163
   Ngiam J., 2011, P 28 INT C MACHINE L, P1105, DOI 10.5555/3104482.3104621
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Pal M, 2010, IEEE T GEOSCI REMOTE, V48, P2297, DOI 10.1109/TGRS.2009.2039484
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Poultney Christopher., 2006, ADV NEURAL INFORM PR
   Qi XJ, 2007, PATTERN RECOGN, V40, P728, DOI 10.1016/j.patcog.2006.04.042
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Salakhutdinov R., 2009, INT C ART INT STAT A, V1
   Simonyan K., 2014, 14091556 ARXIV
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tarabalka Y, 2010, IEEE GEOSCI REMOTE S, V7, P736, DOI 10.1109/LGRS.2010.2047711
   Van Ginneken B, 1999, INT J COMPUT VISION, V31, P169, DOI 10.1023/A:1008018015948
   Wang G, 2010, PROC CVPR IEEE, P3525, DOI 10.1109/CVPR.2010.5539955
   Wu H, 2015, IET COMPUT VIS, V9, P419, DOI 10.1049/iet-cvi.2014.0094
   Wu H, 2015, VISUAL COMPUT, V31, P367, DOI 10.1007/s00371-014-0931-8
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zeiler M.D., European conference on computer vision, P818
NR 55
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6033
EP 6047
DI 10.1007/s11042-018-6301-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100049
DA 2024-07-18
ER

PT J
AU Kim, H
   Kwon, H
   Kim, KK
AF Kim, Hyeob
   Kwon, HyukJun
   Kim, Kyung Kyu
TI Modified cyber kill chain model for multimedia service environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia service environment; Cyber kill chain; Endpoint detection and
   response; Internet of things environment; Multimedia security
ID INTERNET; GAP
AB The sudden rise in the frequency and sophistication of cyber threats has become a hindrance to the steady development of internet of things (IoT)-based multimedia service environments. The framework currently in use for understanding and analyzing cyber threats in the information security (IS) field is the cyber kill chain model. Of these threats, a particular threat that involves advanced and persistent attacks on a designated target (company that provides multimedia services) and causes large-scale damage is referred to as an advanced persistent threat (APT). As there can be numerous threat points in an IoT-based multimedia service environment with networks of various heterogeneous devices connected through multiple routes, an understanding of the potential routes of the threats is crucial. APTs are generally divided into the infiltration stage from the outside into the inside of an organization, and a threat stage that occurs within an organization. The existing kill chain model in the IS field is problematic in that it cannot fully express the actions that occur inside an organization. However, many attacks that occur in today's IoT-based multimedia service environments are performed after infiltration of an insider or the organization. Thus, it is important for actions that occur on the inside to be clearly schematized to secure visibility in the multimedia service environment. This study analyzes the limitations of the existing model, and proposes a revised cyber kill chain model for multimedia security that can explain threats within an organization in addition to external threats.
C1 [Kim, Hyeob; Kim, Kyung Kyu] Yonsei Univ, Grad Sch Informat, Seoul, South Korea.
   [Kwon, HyukJun] Soonchunhyang Univ, Dept IT Finance Management, Asan, South Korea.
C3 Yonsei University; Soonchunhyang University
RP Kwon, H (corresponding author), Soonchunhyang Univ, Dept IT Finance Management, Asan, South Korea.
EM hyubiii@yonsei.ac.kr; gloryever@sch.ac.kr; kyu.kim@yonsei.ac.kr
RI Kim, Hyeob/GQQ-9681-2022; Kim, Hyeob/AAH-2193-2019
OI Kim, Hyeob/0000-0002-8956-3218; Kim, Hyeob/0000-0002-8956-3218
FU Soonchunhyang University Research Fund
FX This research was supported by the Soonchunhyang University Research
   Fund.
CR Alam M, 2017, MULTIMED TOOLS APPL, V76, P22845, DOI 10.1007/s11042-017-4853-0
   [Anonymous], 2010, M-Trends 2010: The Advanced Persistent Threat
   [Anonymous], 2011, LEADING ISSUES INFOR
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bejtlich R, 2010, TAOSECURITY BLOG
   Cloppert M., 2009, SANS COMPUTER FORENS
   Command Five Pty Ltd, 2011, IN PRESS
   FireEye, 2017, M TRENDS 2017 REP
   Firstbrook P., 2017, Market Guide for Endpoint Detection and Response Solutions (ID G00321729)
   Gartner, 2011, GARTNER SAYS INTERNE
   Kim H, 2016, MULTIMED TOOLS APPL, V75, P14795, DOI 10.1007/s11042-015-2638-x
   Kim H, 2016, MULTIMED TOOLS APPL, V75, P12779, DOI 10.1007/s11042-016-3503-2
   Malone S., 2016, Using an expanded cyber kill chain model to increase attack resiliency
   MOORE JF, 1993, HARVARD BUS REV, V71, P75
   Ndibanje B, 2014, SENSORS-BASEL, V14, P14786, DOI 10.3390/s140814786
   Oracevic A, 2017, INT SYM NETWO COMP, DOI 10.1109/ISNCC.2017.8072001
   Ouellet E, 2017, MAGIC QUADRANT ENDPO
   Park W, 2016, MULTIMED TOOLS APPL, V75, P6059, DOI 10.1007/s11042-014-2393-4
   PWC, 2015, KEY FIND 2015 US STA
   Reidy P., 2013, Combating the Insider Threat at the Fbi: Real World Lessons Learned
   Rho S, 2013, J SUPERCOMPUT, V65, P274, DOI 10.1007/s11227-010-0447-6
   Rutherford JR, 2016, P ANN HICSS, P2624, DOI 10.1109/HICSS.2016.329
   Ryan J., 2011, LEADING ISSUES INFOR
   Ryu H, 2014, MAGAZINE IEIE, V41, P16
   SUK JUNG CHAN, 2013, [Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V14, P3032, DOI 10.5762/KAIS.2013.14.6.3032
   Yoo T, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-53
   Zhou L, 2011, IEEE NETWORK, V25, P35, DOI 10.1109/MNET.2011.5772059
NR 27
TC 18
Z9 28
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3153
EP 3170
DI 10.1007/s11042-018-5897-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600025
OA hybrid
DA 2024-07-18
ER

PT J
AU Krismayer, T
   Schedl, M
   Knees, P
   Rabiser, R
AF Krismayer, Thomas
   Schedl, Markus
   Knees, Peter
   Rabiser, Rick
TI Predicting user demographics from music listening information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User trait prediction; Digital user traces; User demographics; Music
   listening habits
ID SMO ALGORITHM; IMPROVEMENTS
AB Online activities such as social networking, online shopping, and consuming multi-media create digital traces, which are often analyzed and used to improve user experience and increase revenue, e. g., through better-fitting recommendations and more targeted marketing. Analyses of digital traces typically aim to find user traits such as age, gender, and nationality to derive common preferences. We investigate to which extent the music listening habits of users of the social music platform Last.fm can be used to predict their age, gender, and nationality. We propose a feature modeling approach building on Term Frequency-Inverse Document Frequency (TF-IDF) for artist listening information and artist tags combined with additionally extracted features. We show that we can substantially outperform a baseline majority voting approach and can compete with existing approaches. Further, regarding prediction accuracy vs. available listening data we show that even one single listening event per user is enough to outperform the baseline in all prediction tasks. We also compare the performance of our algorithm for different user groups and discuss possible prediction errors and how to mitigate them. We conclude that personal information can be derived from music listening information, which indeed can help better tailoring recommendations, as we illustrate with the use case of a music recommender system that can directly utilize the user attributes predicted by our algorithm to increase the quality of it's recommendations.
C1 [Krismayer, Thomas; Rabiser, Rick] Johannes Kepler Univ Linz, Inst Software Syst Engn, Christian Doppler Lab MEVSS, Linz, Austria.
   [Schedl, Markus] Johannes Kepler Univ Linz, Dept Computat Percept, Linz, Austria.
   [Knees, Peter] TU Wien, Fac Informat, Inst Informat Syst Engn, Vienna, Austria.
C3 Johannes Kepler University Linz; Johannes Kepler University Linz;
   Technische Universitat Wien
RP Krismayer, T (corresponding author), Johannes Kepler Univ Linz, Inst Software Syst Engn, Christian Doppler Lab MEVSS, Linz, Austria.
EM thomas.krismayer@jku.at; markus.schedl@jku.at; peter.knees@tuwien.ac.at;
   rick.rabiser@jku.at
RI ; Rabiser, Rick/B-8673-2017
OI Krismayer, Thomas/0000-0001-7463-3976; Rabiser,
   Rick/0000-0003-3862-1112; Knees, Peter/0000-0003-3906-1292; Schedl,
   Markus/0000-0003-1706-3406
FU Johannes Kepler University Linz
FX Open access funding provided by Johannes Kepler University Linz.
CR [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2010, P 19 ACM INT C INFOR, DOI DOI 10.1145/1871437.1871535
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   [Anonymous], NC2TR1998030
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P125, DOI 10.1145/2911451.2911491
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Cheng ZY, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1267, DOI 10.1145/2600428.2611187
   Conover M. D., 2011, 2011 IEEE 3 INT C PR, P192, DOI DOI 10.1109/PASSAT/SOCIALCOM.2011.34
   de Montjoye Yves-Alexandre, 2013, Social Computing, Behavioral-Cultural Modeling and Prediction. 6th International Conference, SBP 2013. Proceedings, P48, DOI 10.1007/978-3-642-37210-0_6
   Fuller J., 2016, P 17 INT SOC MUS INF, P626, DOI DOI 10.5281/ZEN0D0.1415928
   Golbeck J., 2011, P 2011 ANN C HUM FAC, P253, DOI DOI 10.1145/1979742.1979614
   Google, 2016, FREEB DAT DUMPS
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hastie T, 1998, P 1997 C ADV NEUR IN, DOI [10. 1007/978-3-642-30353-1_3, DOI 10.1007/978-3-642-30353-1_3]
   Holmes G, 1999, LECT NOTES ARTIF INT, V1747, P1
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Keerthi SS, 2001, NEURAL COMPUT, V13, P637, DOI 10.1162/089976601300014493
   Kosinski M, 2013, P NATL ACAD SCI USA, V110, P5802, DOI 10.1073/pnas.1218772110
   Krismayer T, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095722
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Liu HF, 2012, PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MANAGING INTEROPERABILITY AND COMPLEXITY IN HEALTH SYSTEMS, P31
   Malmi Eric., 2016, P 10 INT C WEB SOCIA, P635
   Mnih A., 2007, ADV NEURAL INFORM PR, V20
   Ortigosa A, 2014, J COMPUT SYST SCI, V80, P57, DOI 10.1016/j.jcss.2013.03.008
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Platt J, 1998, ADV KERNEL METHODS S, DOI [10. 1023/A:1012474916001, DOI 10.1023/A:1012474916001]
   Quinlan J.R., 1992, P AI 92, P343, DOI DOI 10.1142/9789814536271
   Schedl M, 2015, P 37 EUR C INF RETR, DOI [10. 1007/978-3-319-16354-3_37, DOI 10.1007/978-3-319-16354-3_37]
   Schedl M, 2017, INT J MULTIMED INF R, V6, P71, DOI 10.1007/s13735-017-0118-y
   Schedl M, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P103, DOI 10.1145/2911996.2912004
   Schedl M, 2013, J INTELL INF SYST, V41, P523, DOI 10.1007/s10844-013-0247-6
   Schedl Markus., 2012, ISMIR, P385
   Shevade SK, 2000, IEEE T NEURAL NETWOR, V11, P1188, DOI 10.1109/72.870050
   Su J., 2008, Proceedings of the 25th International Conference on Machine Learning, V307, P1016, DOI DOI 10.1145/1390156.1390284
   Volkova S, 2016, PROCEEDINGS 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (BIGDATASERVICE 2016), P36, DOI 10.1109/BigDataService.2016.28
   Wang Y, 1997, P 9 EUR C MACH LEARN, P128
   Wu M., 2014, P 15 INT SOC MUS INF, P555
   Wu YY, 2015, P NATL ACAD SCI USA, V112, P1036, DOI 10.1073/pnas.1418680112
NR 40
TC 10
Z9 10
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2897
EP 2920
DI 10.1007/s11042-018-5980-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600013
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Liu, M
   Zuo, XD
   Lan, XG
   Xu, MH
AF Liu, Min
   Zuo, Xiaode
   Lan, Xian-Gang
   Xu, Minghui
TI Two-stage supply chain study of deteriorating items considering the
   double effect for multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double effect; Deteriorating items; Two-stage; Supply chain; Multimedia
   systems
ID LOT-SIZE; INTEGRATION; DEMAND; IMPACT; MODEL
AB Considering the ethylene effect and the perspective of learning theory from an interdisciplinary perspective, this paper studies the optimal inventory management of deteriorating items' two-stage supply chain consisting of suppliers and retailers. It is suggested that the inventory level of the two-stage supply chain will affect the dynamic deterioration problem of deterioration degree through the ethylene intensity coefficient. Based on the learning effect theory, the two-stage inventory model of deteriorating items' supply chain is constructed. By analyzing the cost structure under the influence of learning effect of suppliers and retailers, the profit of supply chain is solved by optimization method and optimal price and optimal learning coefficient are derived. The optimal solution of learning coefficient is obtained from various scenarios with theoretical analysis. Meanwhile, the influence of learning effect coefficient on system profit is compared under different ethylene intensity levels. Finally, the paper presents a numerical example to illustrate the rationality and applications of theoretical results. Through this research, it is aimed to reveal the multimedia system could be used to show the data change to help the business decision be more reasonable to attain more profit for managers. Furthermore, the multimedia technology could intensify the learning effect and in return could maximize the system profit of supply chain. This work is mainly modeling analysis, while the research outcomes could be developed into a good system by using multimedia technology.
C1 [Liu, Min; Zuo, Xiaode; Lan, Xian-Gang; Xu, Minghui] Jinan Univ, Sch Management, Guangzhou 510632, Guangdong, Peoples R China.
C3 Jinan University
RP Liu, M (corresponding author), Jinan Univ, Sch Management, Guangzhou 510632, Guangdong, Peoples R China.
EM liumin_wyw@21cn.com
FU National Natural Science Foundation Youth Project [71102146]; Guangdong
   Provincial Natural Science Foundation Project [S2012010010649]
FX This research is supported by:; 1. National Natural Science Foundation
   Youth Project (No. 71102146).; 2. Guangdong Provincial Natural Science
   Foundation Project (No. S2012010010649).
CR ACHABAL DD, 1990, J RETAILING, V66, P383
   Alamri AA, 2007, INT J PROD ECON, V107, P125, DOI 10.1016/j.ijpe.2006.08.004
   [Anonymous], SCIENCES
   [Anonymous], APPL MATH MODEL
   [Anonymous], NEURAL COMPUT APPL
   [Anonymous], J APPL MATH
   [Anonymous], INVENTORY
   [Anonymous], HARV BUS REV
   Balakrishnan A, 2004, MANAGE SCI, V50, P630, DOI 10.1287/mnsc.1040.0228
   Balakrishnan A, 2008, M&SOM-MANUF SERV OP, V10, P218, DOI 10.1287/msom.1070.0171
   Biskup D, 2008, EUR J OPER RES, V188, P315, DOI 10.1016/j.ejor.2007.05.040
   Carbonara Nunzia, 2017, International Journal of Integrated Supply Management, V11, P354
   Chan HL, 2018, INT J PROD RES, V56, P3397, DOI 10.1080/00207543.2016.1278283
   Chang CT, 2010, INT J PROD ECON, V127, P197, DOI 10.1016/j.ijpe.2010.05.014
   Chen CK, 2008, INT J PROD ECON, V113, P459, DOI 10.1016/j.ijpe.2007.03.025
   Chen TH, 2014, INT J PROD ECON, V155, P239, DOI 10.1016/j.ijpe.2014.02.011
   Genovese A, 2017, OMEGA-INT J MANAGE S, V66, P344, DOI 10.1016/j.omega.2015.05.015
   Jaber MY, 2007, INT J PROD ECON, V108, P359, DOI 10.1016/j.ijpe.2006.12.020
   Jaber MY, 2004, EUR J OPER RES, V159, P663, DOI [10.1016/S0377-2217(03)00436-3, 10.1016/s0377-2217(03)00436-3]
   Karimi M, 2017, INT J SYST ASSUR ENG, V8, P704, DOI 10.1007/s13198-016-0557-5
   Keachi E.C., 1966, MANAGEMENT SCI, V13, P102
   Koschat MA, 2008, J RETAILING, V84, P165, DOI 10.1016/j.jretai.2008.04.003
   Lee JH, 2017, IEEE CONSUM ELECTR M, V6, P19, DOI 10.1109/MCE.2017.2684916
   Lee WC, 2009, INFORM SCIENCES, V179, P3885, DOI 10.1016/j.ins.2009.07.011
   Li G, 2015, INT J PROD RES, V53, P1228, DOI 10.1080/00207543.2014.954057
   Michalski M, 2018, SUPPLY CHAIN MANAG, V23, P33, DOI 10.1108/SCM-09-2017-0283
   Petruzzi NC, 1999, OPER RES, V47, P183, DOI 10.1287/opre.47.2.183
   Smunt TL, 2000, PROD OPER MANAG, V9, P158, DOI 10.1111/j.1937-5956.2000.tb00331.x
   Tomás-Barberán F, 2001, J SCI FOOD AGR, V81, P853, DOI 10.1002/jsfa.885
   TRUONGHO, 1965, JOURNAL OF INDUSTRIAL ENGINEERING, V16, P152
   Vanpoucke E, 2017, INT J OPER PROD MAN, V37, P510, DOI 10.1108/IJOPM-07-2015-0441
   Wahab MIM, 2010, COMPUT IND ENG, V58, P186, DOI 10.1016/j.cie.2009.07.007
   Wang JB, 2014, ASIA PAC J OPER RES, V31, DOI 10.1142/S0217595914500365
   WOLFE HB, 1968, IMR-IND MANAG REV, V9, P69
   Yilmaz ÖF, 2017, COMPUT IND ENG, V114, P244, DOI 10.1016/j.cie.2017.10.018
NR 35
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4655
EP 4672
DI 10.1007/s11042-018-6456-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200038
DA 2024-07-18
ER

PT J
AU Manickam, A
   Devarasan, E
   Manogaran, G
   Priyan, MK
   Varatharajan, R
   Hsu, CH
   Krishnamoorthi, R
AF Manickam, Adhiyaman
   Devarasan, Ezhilmaran
   Manogaran, Gunasekaran
   Priyan, Malarvizhi Kumar
   Varatharajan, R.
   Hsu, Ching-Hsien
   Krishnamoorthi, Raja
TI RETRACTED: Score level based latent fingerprint enhancement and matching
   using SIFT feature (Retracted article. See vol. 82, pg. 4775, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Latent fingerprint image; Intuitionistic fuzzy set; Enhancement; SIFT
   feature; Matching
ID CLIMATE-CHANGE; SYSTEM; SEGMENTATION; INTERNET
AB Latent fingerprint identification is such a difficult task to law enforcement agencies and border security in identifying suspects. It is a too complicate due to poor quality images with non-linear distortion and complex background noise. Hence, the image quality is required for matching those latent fingerprints. The current researchers have been working based on minutiae points for fingerprint matching because of their accuracy are acceptable. In an effort to extend technology for fingerprint matching, our model is to propose the enhancementand matching for latent fingerprints using Scale Invariant Feature Transformation (SIFT). It has involved in two phases (i) Latent fingerprint contrast enhancement using intuitionistic type-2 fuzzy set (ii) Extract the SIFTfeature points from the latent fingerprints. Then thematching algorithm is performedwith n- number of images and scoresare calculated by Euclidean distance. We tested our algorithm for matching, usinga public domain fingerprint database such as FVC-2004 and IIIT-latent fingerprint. The experimental consequences indicatethe matching result is obtained satisfactory compare than minutiae points.
C1 [Manickam, Adhiyaman] Saveetha Univ, Saveetha Sch Engn, Dept Sci & Humanities, Chennai, India.
   [Devarasan, Ezhilmaran] VIT Univ, Dept Math, Div Sch Adv Sci, Vellore, Tamil Nadu, India.
   [Manogaran, Gunasekaran; Priyan, Malarvizhi Kumar] Univ Calif Davis, Davis, CA 95616 USA.
   [Varatharajan, R.] Sri Ramanujar Engn Coll, Chennai, India.
   [Hsu, Ching-Hsien] Chung Hua Univ, CSIE Dept, Hsinchu, Taiwan.
   [Krishnamoorthi, Raja] Saveetha Univ, Saveetha Sch Engn, Dept Elect & Commun Engn, Chennai, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering; Vellore Institute of Technology (VIT); VIT Vellore;
   University of California System; University of California Davis; Chung
   Hua University; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering
RP Priyan, MK (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM priyanit085@gmail.com
RI Devarasan, Ezhilmaran/D-4713-2019; KUMAR, PRIYAN
   MALARVIZHI/GYV-1373-2022; MALARVIZHI KUMAR, PRIYAN/U-3908-2018; Hsu,
   Ching-Hsien/AAE-6917-2020; Krishnamoorthy, Raja/GSM-8303-2022;
   Manogaran, Gunasekaran/K-7621-2017
OI Devarasan, Ezhilmaran/0000-0002-8571-447X; MALARVIZHI KUMAR,
   PRIYAN/0000-0001-6149-2705; Manogaran, Gunasekaran/0000-0003-4083-6163
CR [Anonymous], 2013, P 4 INT C COMP COMM
   Arora SS, 2014, IEEE T PATTERN ANAL, V36, P2452, DOI 10.1109/TPAMI.2014.2330609
   Atanassov K. T., 1986, Fuzzy Sets and Systems, V20, P87, DOI 10.1016/S0165-0114(86)80034-3
   Babler W J, 1991, Birth Defects Orig Artic Ser, V27, P95
   Bansal Roli, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P412, DOI 10.1109/FSKD.2009.396
   Bustince H, 2000, FUZZY SET SYST, V114, P485, DOI 10.1016/S0165-0114(98)00279-6
   Cao K, 2014, IEEE T PATTERN ANAL, V36, P1847, DOI 10.1109/TPAMI.2014.2302450
   Chaira T, 2013, NATL CONF COMMUN
   Greenberg S, 2000, INT C PATT RECOG, P322, DOI 10.1109/ICPR.2000.903550
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jain AK, 2011, IEEE T PATTERN ANAL, V33, P88, DOI 10.1109/TPAMI.2010.59
   Jayaram B, 2011, ADV INTEL SYS RES, P311
   Karimi-Ashtiani S, 2008, IEEE IMAGE PROC, P1492, DOI 10.1109/ICIP.2008.4712049
   Keming Mao, 2010, Proceedings of the Third International Joint Conference on Computational Sciences and Optimization (CSO 2010), P222, DOI 10.1109/CSO.2010.76
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Lee K.H., 2006, First Course on Fuzzy Theory and Applications
   Liao X, 2017, COMPUT ELECTR ENG, DOI [10. 1016/j. compel-eceng. 2017. 08. 020, DOI 10.1016/J.C0MPEL-ECENG.2017.08.020]
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lopez D, 2016, INT J INFECT DIS, V45, P23, DOI 10.1016/j.ijid.2016.02.084
   Lopez D, 2017, BIOMED RES, V28, P1
   Lopez D, 2016, HUMAN ELEMENT BIG DA
   Lopez D, 2017, HDB STAT, V37, P301, DOI DOI 10.1590/S0034-76122011000200003
   Lopez D, 2015, ADV INTELL SYST, V415, P195, DOI 10.1007/978-3-319-27212-2_16
   Lopez Daphne, 2014, Proc IEEE Int Conf Big Data, V2014, P19, DOI 10.1109/BigData.2014.7004422
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Malathi S, 2011, 2011 INT C PROC AUT, P1
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Manogaran G., 2016, INT J ADV INTELLIGEN, V9, P1
   Manogaran G., 2017, Big Data Analytics in Healthcare Internet of Things. Innovative Healthcare Systems for the 21st Century, P263, DOI DOI 10.1007/978-3-319-55774-8_10
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Manogaran G, 2018, WIRELESS PERS COMMUN, V102, P2099, DOI 10.1007/s11277-017-5044-z
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Manogaran G, 2018, CLUSTER COMPUT, V21, P189, DOI 10.1007/s10586-017-0982-5
   Manogaran G, 2018, COMPUT ELECTR ENG, V65, P207, DOI 10.1016/j.compeleceng.2017.04.006
   Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Manogaran G, 2017, INT J AMBIENT COMPUT, V8, P88, DOI 10.4018/IJACI.2017040106
   Manogaran Thota., 2018, HCI CHALLENGES PRIVA, P1, DOI DOI 10.4018/978-1-5225-2863-0.CH001
   Park U, 2008, P INT SOC OPT PHOT S
   Paulino AA, 2013, IEEE T INF FOREN SEC, V8, P31, DOI 10.1109/TIFS.2012.2223678
   SHERLOCK BG, 1994, IEE P-VIS IMAGE SIGN, V141, P87, DOI 10.1049/ip-vis:19949924
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Thota C., 2018, Exploring the convergence of big data and the internet of things, P141
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
   Wu CH, 2004, PROC SPIE, V5404, P66, DOI 10.1117/12.542200
   Yoon S., 2011, Proceedings of International Joint Conference on Biometrics, P1, DOI DOI 10.1109/IJCB.2011.6117482
   Yoon S., 2013, IEEE INT C BIOMETRIC, P1, DOI DOI 10.1109/BTAS.2013.6712750
   Youliang Yang, 2010, 2010 Second Pacific-Asia Conference on Circuits,Communications and System (PACCS 2010), P398, DOI 10.1109/PACCS.2010.5626923
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 50
TC 104
Z9 106
U1 0
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3065
EP 3085
DI 10.1007/s11042-018-5633-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600021
DA 2024-07-18
ER

PT J
AU Nazir, F
   Ghazanfar, MA
   Maqsood, M
   Aadil, F
   Rho, S
   Mehmood, I
AF Nazir, Faria
   Ghazanfar, Mustansar Ali
   Maqsood, Muazzam
   Aadil, Farhan
   Rho, Seungmin
   Mehmood, Irfan
TI Social media signal detection using tweets volume, hashtag, and
   sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal detection; Sentiment analysis; Social media analysis; Twitter
ID BIG DATA; NETWORK; SCIENCE
AB Social Media is a well-known platform for users to create, share and check the new information. The world becomes a global village because of the utilization of internet and social media. The data present on Twitter contains information of great importance. There is a strong need to extract valuable information from this huge amount of data. A key research challenge in this area is to analyze and process this huge data and detect the signals or spikes. Existing work includes sentiment analysis for Twitter, hashtag analysis, and event detection but spikes/signal detection from Twitter remains an open research area. From this line of research, we propose a signal detection approach using sentiment analysis from Twitter data (tweets volume, top hashtag and sentiment analysis). In this paper, we propose three algorithms for signal detection in tweets volume, tweets sentiment and top hashtag. The algorithms are the- Average moving threshold algorithm, Gaussian algorithm, and hybrid algorithm. The hybrid algorithm is a combination of the average moving threshold algorithm and Gaussian algorithm. The proposed algorithms are tested over real-time data extracted from Twitter and two large publically available datasets- Saudi Aramco dataset and BP America dataset. Experimental results show that hybrid algorithm outperforms the Gaussian and average moving threshold algorithm and achieve a precision of 89% on real-time tweets data, 88% on Saudi Aramco dataset and 81% on BP America dataset with the recall of 100%.
C1 [Nazir, Faria; Ghazanfar, Mustansar Ali] Univ Engn & Technol Taxila, Dept Software Engn, Taxila, Pakistan.
   [Maqsood, Muazzam; Aadil, Farhan] COMSATS Univ Islamabad, Dept Comp Sci, Attock Campus, Attock, Pakistan.
   [Rho, Seungmin] Sungkyul Univ, Dept Media Software, Anyang, South Korea.
   [Mehmood, Irfan] Sejong Univ, Dept Software, Seoul, South Korea.
C3 University of Engineering & Technology Taxila; COMSATS University
   Islamabad (CUI); Sungkyul University; Sejong University
RP Mehmood, I (corresponding author), Sejong Univ, Dept Software, Seoul, South Korea.
EM irfanmehmood@ieee.org
RI Aadil, Farhan/I-4043-2013; Ghazanfar, Mustansar/ABA-3929-2020; Maqsood,
   Muazzam/AAW-1539-2021; Rho, Seungmin/HTP-6683-2023; Maqsood,
   Muazzam/ABE-1733-2021
OI Aadil, Farhan/0000-0001-8737-2154; Ghazanfar,
   Mustansar/0000-0003-1967-6273; Maqsood, Muazzam/0000-0002-2709-0849
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1A09919551]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A1A09919551).
CR Abdelhaq F, 2013, PROC VLDB ENDOW, V6, P1326, DOI 10.14778/2536274.2536307
   Alag S., 2008, Collective intelligence in action
   [Anonymous], 2021, Proceedings of the International AAAI Conference on Web and Social Media, DOI DOI 10.1609/ICWSM.V9I1.14584
   [Anonymous], 2011, ICWSM
   [Anonymous], 2006, M US INF NEEDS REC S
   [Anonymous], 16 AGILE INT C GEOGR
   [Anonymous], 2010, HLT 10
   [Anonymous], FUTURE GENERATION CO
   [Anonymous], TEXT MINING TWITTER
   [Anonymous], CAN TWITTER REPLACE
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Bagui S, 2015, INT J CLOUD APPL COM, V5, P36, DOI [10.4018/ijcac.2015040103, 10.4018/IJCAC.2015040103]
   Bastos MT, 2015, JOURNALISM STUD, V16, P305, DOI 10.1080/1461670X.2014.891857
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Chen L., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P523
   El Rahman SA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P336, DOI 10.1109/iccisci.2019.8716464
   Ellison N., 2006, SPATIALLY BOUNDED ON, V36
   Fung G.P. C., 2005, VLDB, P181
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   McCormick TH, 2017, SOCIOL METHOD RES, V46, P390, DOI 10.1177/0049124115605339
   Melville Prem., 2009, PROC WIN, V1, P1
   Murphy J, 2014, PUBLIC OPIN QUART, V78, P788, DOI 10.1093/poq/nfu053
   OConnor B., 2010, P INT AAAI C WEBLOGS, P1
   Ouf S, 2015, INT J CLOUD APPL COM, V5, P53, DOI [10.4018/ijcac.2015040104, 10.4018/IJCAC.2015040104]
   Qi He, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P207
   Qualman E., 2010, Socialnomics: How social media transforms the way we live and do business
   Ramya R., 2013, INT J ADV RES COMPUT, V2, P2278
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Small TA, 2011, INFORM COMMUN SOC, V14, P872, DOI 10.1080/1369118X.2011.554572
   Spencer J., 2012, Proc. International Workshop on Sentiment Discovery from Affective Data, P56
   Trusov M, 2009, J MARKETING, V73, P90, DOI 10.1509/jmkg.73.5.90
   Wang X., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM'11, P1031
   Watts DJ, 2004, ANNU REV SOCIOL, V30, P243, DOI 10.1146/annurev.soc.30.020404.104342
   Weng J., 2021, Proc. Int. AAAI Conf. Web Soc. Media, V5, P401, DOI [10.1609/icwsm.v5i1.14102, DOI 10.1609/ICWSM.V5I1.14102]
   Yang Y., 1998, P 21 ANN INT ACM SIG, P28, DOI DOI 10.1145/290941.290953
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zheng LJ, 2018, INT J MACH LEARN CYB, V9, P75, DOI 10.1007/s13042-015-0347-4
NR 41
TC 22
Z9 23
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3553
EP 3586
DI 10.1007/s11042-018-6437-z
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600049
DA 2024-07-18
ER

PT J
AU Raza, A
   Nawaz, T
   Dawood, H
   Dawood, H
AF Raza, Ahmad
   Nawaz, Tabassam
   Dawood, Hassan
   Dawood, Hussain
TI Square texton histogram features for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Square texton histogram (STH); Image retrieval; Content base image
   retrieval (CBIR); Weighted square-chord distance
ID LOCAL BINARY PATTERNS; ROTATION-INVARIANT; TEXTURE CLASSIFICATION;
   COLOR; DESCRIPTOR; SCALE; TRANSFORM
AB A new image feature descriptor for content-based image retrieval is proposed, named as Square Texton Histogram (STH). STH is derived based on the correlation between texture orientation and color information. Based on julesz's texton theory Square Texton' templates are proposed for Image texture analysis. Texture Orientation is computed by using proposed multi texture orientation detector that incorporates horizontal, vertical and diagonal edges information. Features are extracted by correlating texture color and edge orientation by using 4-directional co-occurrence matrix while; the final set of features is obtained by histogram. To find similarity between query and target image, a weighted square-chord distance measure is proposed. The Proposed distance metric integrates the advantages of both bin-by-bin and weighted distance metrics. The proposed STH method is tested on standard dataset's that are extensively used in CBIR domain, such as Coral5K and Coral10K. STH has good discrimination power of primary visual features.
C1 [Raza, Ahmad; Nawaz, Tabassam; Dawood, Hassan] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
   [Dawood, Hussain] Univ Jeddah, Fac Comp & Informat Technol, Jeddah, Saudi Arabia.
C3 University of Engineering & Technology Taxila; University of Jeddah
RP Dawood, H (corresponding author), Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
EM engrr.ahmedraza@gmail.com; tabassam.nawaz@uettaxila.edu.pk;
   hassan.dawood@uettaxila.edu.pk; hussaindawood2002@yahoo.com
RI Raza, Ahmed/AAQ-5757-2020; Dawood, Hassan/AAZ-8114-2021; Dawood,
   Hussain/G-7453-2017
OI Raza, Ahmed/0000-0002-0990-8715; Dawood, Hassan/0000-0003-1355-6457;
   Dawood, Hussain/0000-0003-2653-9541
CR Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmad J, 2015, INT C NETWB INFO, P212, DOI 10.1109/NBiS.2015.36
   Alkhawlani M, 2015, INT J ADV COMPUT SC, V6, P212
   Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   [Anonymous], 2017, ARXIV170902463
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2013, P 5 INT C INT MULT C
   [Anonymous], INT ED RES J
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen YX, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P197, DOI 10.1109/ISSPA.2003.1224674
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dharani T., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P485, DOI 10.1109/ICPRIME.2013.6496719
   Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320
   Gebejes A., 2013, Databases, V9, P375
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Iqbal K, 2012, J COMPUT SYST SCI, V78, P1258, DOI 10.1016/j.jcss.2011.10.013
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jiang F, 2016, NEUROCOMPUTING, V175, P146, DOI 10.1016/j.neucom.2015.10.044
   JULESZ B, 1984, TRENDS NEUROSCI, V7, P41, DOI 10.1016/S0166-2236(84)80275-1
   Jyothi B, 2016, ADV INTELL SYST, V379, P289, DOI 10.1007/978-81-322-2517-1_29
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu PZ, 2017, INFORM SCIENCES, V390, P95, DOI 10.1016/j.ins.2017.01.025
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mezaris V, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P511
   Nan BF, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF), P399, DOI 10.1109/CYBConf.2015.7175967
   Ng J. Y.-H., 2015, arXiv:1504.05133
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Qian XM, 2017, IEEE T MULTIMEDIA, V19, P813, DOI 10.1109/TMM.2016.2638207
   Qian XM, 2015, IEEE T IMAGE PROCESS, V24, P4348, DOI 10.1109/TIP.2015.2462131
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Sajjad M, 2018, MULTIMED TOOLS APPL, V77, P4769, DOI 10.1007/s11042-017-5010-5
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Singh C, 2016, J VIS COMMUN IMAGE R, V41, P225, DOI 10.1016/j.jvcir.2016.10.002
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Uricchio T, 2017, PATTERN RECOGN, V71, P144, DOI 10.1016/j.patcog.2017.05.019
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu J, 2017, J VIS COMMUN IMAGE R, V49, P78, DOI 10.1016/j.jvcir.2017.08.002
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
   Zhi-Chun Huang, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P719, DOI 10.1109/ICMLC.2010.5580566
NR 73
TC 21
Z9 22
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2719
EP 2746
DI 10.1007/s11042-018-5795-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600006
DA 2024-07-18
ER

PT J
AU Song, S
   Park, SO
   Lee, S
   Park, J
AF Song, Seheon
   Park, Sang Oh
   Lee, SangIl
   Park, JaeHyun
TI Mission-oriented service development using capability-based semantic
   recommendation for the internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mission service; Capability-based semantic matching; Recommendation;
   Ontology; IoT
ID IOT
AB This paper presents a mission-oriented service development environment with web-based modeling tool that enable users create workflow-based service composition. This approach utilizes the ontology-based mission service model composed of mission, task, service and resource, and task/service recommendation. During developing the mission-oriented service, capability-based semantic matching and hierarchical relationship-based filtering are used for three types of recommendation. Also, we develop a modeling environment to monitor and execute the mission service application. In experiments, we have conducted on test beds in two domains such as military environment and smart building.
C1 [Song, Seheon] Metabuild Co Ltd, Seoul, South Korea.
   [Park, Sang Oh] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Lee, SangIl; Park, JaeHyun] Agcy Def Dev, Seoul, South Korea.
C3 Chung Ang University; Agency of Defense Development (ADD), Republic of
   Korea
RP Park, SO (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.; Park, J (corresponding author), Agcy Def Dev, Seoul, South Korea.
EM seheon.song@gmail.com; sopark@cau.ac.kr; happyjoy@add.re.kr;
   forehand@add.re.kr
FU Civil-Military Technology Cooperation Program [UM13018RD1]
FX "This work was supported by the Civil-Military Technology Cooperation
   Program" (UM13018RD1)
CR Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   [Anonymous], SPARQL QUERY LANGUAG
   Avilés-López E, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-79
   Barnaghi P, 2012, INT J SEMANT WEB INF, V8, P1, DOI [10.4018/jswis.2012010101, 10.4018/jswis.201201010149]
   Bermudez L, 2006, P ISWC 2006 WORKSH S
   Cassar G, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND COMMUNICATIONS, CONFERENCE ON INTERNET OF THINGS, AND CONFERENCE ON CYBER, PHYSICAL AND SOCIAL COMPUTING (GREENCOM 2012), P210, DOI 10.1109/GreenCom.2012.40
   Choi HS, 2014, SENSORS-BASEL, V14, P22039, DOI 10.3390/s141122039
   Gomez M, 2008, LECT NOTES ARTIF INT, V5268, P347, DOI 10.1007/978-3-540-87696-0_30
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hachem Sara., 2011, Proceedings of the 8th Middleware Doctoral Symposium, p3:1, DOI [10.1145/2093190.2093193, DOI 10.1145/2093190.2093193]
   Han SN, 2014, IEEE T IND INFORM, V10, P752, DOI 10.1109/TII.2013.2252356
   Ko IY, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2835492
   Kotis K, 2013, INT J DISTRIB SYST T, V4, P47, DOI 10.4018/jdst.2013070104
   Levchuk GM, 2002, IEEE T SYST MAN CY A, V32, P346, DOI 10.1109/TSMCA.2002.802819
   McMullen D, 2006, P 2 WORKSH FORM ONT, P655
   Paolucci M, 2002, LECT NOTES COMPUT SC, V2342, P333
   Pease A, 2002, P WORK NOT AAAI 2002
   Robin A, 2006, TECHNICAL REPORT
   Rueda C., 2010, The MMI Device Ontology: Enabling Sensor Integration
   Russomanno DJ, 2005, ICAI '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P637
   Ryu M, 2015, SENSORS-BASEL, V15, P2137, DOI 10.3390/s150102137
   Sheehan J.H., 2003, P INTERSERVICEINDUST, P655
   Song S, 2016, J SUPERCOMPUT, V72, P3646, DOI 10.1007/s11227-016-1765-0
   Song S, 2013, MATH COMPUT MODEL, V58, P261, DOI 10.1016/j.mcm.2012.08.007
   Stavropoulos TG, 2012, 2 INT C WEB INT MIN
   Tzortzis G, 2016, WORKSH ART INT THING
   Wang W, 2013, AUTOMATIKA-UK, V54, P388, DOI 10.7305/automatika.54-4.414
NR 27
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2939
EP 2961
DI 10.1007/s11042-017-4889-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600016
DA 2024-07-18
ER

PT J
AU Bendraou, Y
   Essannouni, F
   Salam, A
AF Bendraou, Youssef
   Essannouni, Fedwa
   Salam, Ahmed
TI From local to global key-frame extraction based on important scenes
   using SVD of centrist features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Static video summary; Key-frame extraction; Singular value
   decomposition; Centrist features
ID SELECTION; SCHEME; VIDEOS
AB The wide spread of multimedia applications and the rapid growth of digital video data require efficient video summarization methods. Extracting brief and pertinent information allows users to quickly browse, recognize and understand a large amount of video content. In this paper, a video summarization method based on important scenes is proposed. A local selection of potential candidate key-frames (PCK) is first performed using only one iteration of the k-means algorithm, where its initialization is achieved using a dictionary selection. Scores of importance are calculated for each PCK to accomplish the global selection. While some approaches remove redundant key-frames to share unique information, this can be used to classify scenes by duration and temporal position. Following such classification, the scene with the longest duration can be considered as the most important one. Therefore, rules of insertion are defined to allow redundancy when the information is considered important. In our contribution, to represent a frame, the singular value decomposition (SVD) of centrist are used as features. The SVD of Centrist allows to better measure the similarity between adjacent frames than other features, and thus to enhance the performance. Experimental results over two different databases show the diversity of our summary and the effectiveness of our method compared to related state of the art methods.
C1 [Bendraou, Youssef; Salam, Ahmed] ULCO, LMPA Lab, Calais, France.
   [Bendraou, Youssef; Essannouni, Fedwa] Univ Mohammed 5, Fac Sci, LRIT Lab, Rabat, Morocco.
C3 Universite du Littoral-Cote-d'Opale; Mohammed V University in Rabat
RP Bendraou, Y (corresponding author), ULCO, LMPA Lab, Calais, France.; Bendraou, Y (corresponding author), Univ Mohammed 5, Fac Sci, LRIT Lab, Rabat, Morocco.
EM youssefbendraou@gmail.com; efedwa@yahoo.fr;
   Ahmed.Salam@lmpa.univ-littoral.fr
CR [Anonymous], D LIB MAG
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chang I. C., 2007, IEEE INT C ON CONS E, P11
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Hadi Y., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1400, DOI 10.1145/1141277.1141601
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Huang C, 2001, IEEE T CIRC SYST TEC, P11
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Ju J, 2016, IEICE T INF SYST, VE99D, P1698, DOI 10.1587/transinf.2015EDL8247
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Ma M, 2017, INT C DIG IM COMP TE
   Ma Mingyang, 2017, IEEE INT C IM PROC I
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nagasaka A, 1991, 2 WORK C VIS DAT SYS, P119
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Panda R, 2016, IEEE IMAGE PROC, P191, DOI 10.1109/ICIP.2016.7532345
   Parry ML, 2011, IEEE T VIS COMPUT GR, V17, P1747, DOI 10.1109/TVCG.2011.208
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2417, P512, DOI 10.1117/12.206078
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 35
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1441
EP 1456
DI 10.1007/s11042-018-6274-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700010
DA 2024-07-18
ER

PT J
AU Jin, YR
   Li, X
AF Jin, Yuran
   Li, Xin
TI Visualizing the Hotspots and Emerging Trends of Multimedia Big Data
   through Scientometrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Visualization; Research hotspots; Emerging trends;
   Scientometrics; CiteSpace
ID CONTEXT; ARCHITECTURE; PATTERNS
AB Multimedia Big Data, known as the biggest big data, is becoming the forefront of big data research. However, a visualization research on the hotspots and trends of Multimedia Big Data through scientometric is still lacking. Based on the references from SCI-EXPANDED(SCIE), SSCI, CPCI-S, CPCI-SSHSI and arXiv databases in 2008-2017, the hotspots and emerging trends of Multimedia Big Data were identified for the first time by visualizing the co-cited references network, co-occurrence keywords network, burst references, burst keywords, Dual-Map Overlays network and Timeline networks with the information visualization software CiteSpaceV, Google Fusion Tables and Carrot(2). The results show that: (1)Multimedia Big Data research has spread across the globe, especially in the United States, China and some European countries; (2)"big data, web application, data mining, virtual screening, cloud service, structure-activity relationship, similarity search problems, concept modeling, etc. are the research hotspots; (3) the research focus evolved mainly from basic security problems and algorithm problems in the early, to technical problems, then to the applications and social impacts, and to mobile internet, cloud, data screening, payment security, etc. till now.(4) The emerging trends mainly include social influence modeling, mobile media cloud, video surveillance system, semantic relations, privacy, internet of thing, precision medicine, parallel massive clustering, etc.; (5) Multimedia Big Data research is developing toward interdisciplinary, of which mathematics and systems is a hot discipline and medicine and clinical is an emerging discipline; (6) the fusion development of multimedia big data with smart city, automotive industry, clothing industry and medical industry will be the trends of the times. The paper aims to promote the development of related theories on Multimedia Big Data and provide reference for researchers to identify relevant research directions.
C1 [Jin, Yuran; Li, Xin] Univ Sci & Technol Liaoning, Sch Business Adm, Anshan 114051, Peoples R China.
C3 University of Science & Technology Liaoning
RP Jin, YR (corresponding author), Univ Sci & Technol Liaoning, Sch Business Adm, Anshan 114051, Peoples R China.
EM jinyuran@163.com; lixiaoxin0322@163.com
RI Jin, Yuran/A-3671-2012
OI Jin, Yuran/0000-0002-6277-6475
FU National Natural Science Foundation of China [71572031, 71472080]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 71572031 and No. 71472080.
CR Agrafiotis DK, 2002, P NATL ACAD SCI USA, V99, P15869, DOI 10.1073/pnas.242424399
   Agrafiotis DK, 2003, J COMPUT CHEM, V24, P1215, DOI 10.1002/jcc.10234
   Aguilar AG, 2012, PROF INFORM, V21, P105, DOI [10. 3145/epi. 2012. ene. 14, DOI 10.3145/EPI.2012.ENE.14]
   [Anonymous], SCI SCI STUDIES
   [Anonymous], 2014, Principles and Applications of Analyzing a Citation Space
   [Anonymous], ARXIV161203639
   Atrey PK, 2012, MULTIMEDIA SYST, V18, P95, DOI 10.1007/s00530-011-0251-z
   Bellini P, 2015, ARXIV150801083
   Bhargava B, 2004, ACM INT C MULT, P81
   Chen C., 2014, Encyclopedia of Information Science and Technology, P271, DOI [DOI 10.4018/978-1-4666-5888-2.CH410, 10.4018/978-1-4666-5888-2.ch410]
   Chen C., 2016, HOW TO USE CITESPACE
   Chen CM, 2014, EXPERT OPIN ORPHAN D, V2, P709, DOI 10.1517/21678707.2014.920251
   Chen CM, 2014, J ASSOC INF SCI TECH, V65, P334, DOI 10.1002/asi.22968
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   Chen SC, 2015, IEEE T MULTIMEDIA, V17, P1401, DOI 10.1109/TMM.2015.2459331
   Dong GZ, 2014, CHINESE J ELECTRON, V23, P695
   GARFIELD E, 1955, SCIENCE, V122, P108, DOI 10.1126/science.122.3159.108
   González-Teruel A, 2015, SCIENTOMETRICS, V103, P687, DOI 10.1007/s11192-015-1548-z
   Guo KH, 2015, J SYST SOFTWARE, V102, P207, DOI 10.1016/j.jss.2014.09.016
   Hu CP, 2014, IEEE T EMERG TOP COM, V2, P376, DOI 10.1109/TETC.2014.2316525
   Jayasena KPN, 2017, NEUROCOMPUTING, V253, P135, DOI 10.1016/j.neucom.2016.11.077
   Jin YR, 2017, J MANUF TECHNOL MANA, V28, P18, DOI 10.1108/JMTM-12-2015-0114
   Kim H. -K., 2014, INT J MULTIMEDIA UBI, V9, P235, DOI [10.14257/ijmue., DOI 10.14257/IJMUE.2014.9.2.23]
   Kim HJ, 2016, J INFORMETR, V10, P954, DOI 10.1016/j.joi.2016.07.007
   Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314
   Krell MM, 2017, ARXIV171209915
   Li S, 2014, P SOC INF SCI TECHNO, V50, P1
   Liang J., 2016, ARXIV PREPRINT ARXIV
   Lifeng Wu, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P26, DOI 10.1109/ICSMC.2010.5642198
   Lin Y, 2015, APPL ELECT TECH, V41, P107
   Liu SB, 2014, SCIENTOMETRICS, V101, P1293, DOI 10.1007/s11192-014-1233-7
   Liu YH, 2011, IEEE T PARALL DISTR, V22, P2100, DOI 10.1109/TPDS.2011.113
   Luo XF, 2011, IEEE T AUTOM SCI ENG, V8, P482, DOI 10.1109/TASE.2010.2094608
   Mylonas P, 2009, IEEE T MULTIMEDIA, V11, P229, DOI 10.1109/TMM.2008.2009681
   Neale J, 2001, IEEE COMMUN MAG, V39, P192, DOI 10.1109/35.910607
   Osiski S, 2004, CONCEPTUAL CLUSTERIN
   Samuel A, 2015, IEEE T MULTIMEDIA, V17, P1484, DOI 10.1109/TMM.2015.2458299
   Sang JT, 2016, MULTIMEDIA SYST, V22, P1, DOI 10.1007/s00530-015-0482-5
   SMALL H, 1980, SCIENTOMETRICS, V2, P277, DOI 10.1007/BF02016349
   Smith JC, 2013, LAW PROPER SOC, P1
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Stefanowski J, 2003, LECT NOTES ARTIF INT, V2663, P240
   Steggink J, 2011, MULTIMEDIA SYST, V17, P367, DOI 10.1007/s00530-010-0220-y
   Su HN, 2010, SCIENTOMETRICS, V85, P65, DOI 10.1007/s11192-010-0259-8
   Tian Y, 2015, IEEE MULTIMEDIA, V22, P93, DOI 10.1109/MMUL.2015.61
   Wang YW, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P128, DOI 10.1109/BigMM.2015.74
   Wong PC, 2011, IEEE COMPUT GRAPH, V31, P18, DOI 10.1109/MCG.2011.72
   Xie K, 2013, 13 INT WORKSH MULT D, P2
   Xu HF, 2003, J CHEM INF COMP SCI, V43, P1186, DOI 10.1021/ci0340557
   Xu Z, 2015, FUTURE GENER COMP SY, V43-44, P40, DOI 10.1016/j.future.2014.04.002
   Zhu WW, 2015, IEEE MULTIMEDIA, V22, P96, DOI 10.1109/MMUL.2015.66
NR 51
TC 24
Z9 25
U1 5
U2 124
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1289
EP 1313
DI 10.1007/s11042-018-6172-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700004
DA 2024-07-18
ER

PT J
AU Liao, HB
AF Liao, Haibin
TI Facial age feature extraction based on deep sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial age estimation; Facial image processing; Feature extraction; Deep
   sparse representation
ID SEPARATING STYLE; REGRESSION
AB In recent years, the research on facial age estimation has attracted more and more interests from the scholars and researchers in the field of psychological, aesthetic, forensic science and computer vision. However, facial age estimation is a challenging work: face age does not suffer from only the influence of intrinsic factors (e.g., genes) but also external factors (e.g., living conditions), so that it is difficult to find accurate features which can describe the change of age. Therefore, this paper proposes a robust face feature extraction method based on dynamic deep sparse representation. Combined with the respective characteristics of Active Appearance Model (AAM), Local Binary Patterns (LBP), Gabor and Bio-Inspired Features (BIF), this method will give sufficient consideration to the thinking way of object recognition of the human, similarity of adjacent ages and the classification principle of signal sparse representation. In addition, in order to reduce the interference of the face identity factor, two factors analysis method is proposed to separate the face identity factor. The experimental results show that the feature extraction method proposed in this paper has strong discrimination and robustness, which outperforms the state-of-the-art age estimation approaches.
C1 [Liao, Haibin] Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning, Peoples R China.
C3 Hubei University of Science & Technology
RP Liao, HB (corresponding author), Hubei Univ Sci & Technol, Sch Comp Sci & Technol, Xianning, Peoples R China.
EM liao_haibing@163.com
RI Liao, Haibin/AAB-6485-2020
OI Liao, Haibin/0000-0002-7984-2811
FU Hubei Provincial Natural Science Foundation of China [2017CFB168]; Hubei
   Provincial Education Office Science and technology research project
   youth talent project [Q20172805]; Hubei Provincial education science
   planning project [2016GB086]; construction of a special scientific
   research project for master's point [2018-19GZ050]
FX We want to thank the helpful comments and suggestions from the anonymous
   reviewers. This work is supported partially by the Hubei Provincial
   Natural Science Foundation of China (No.2017CFB168), the Hubei
   Provincial Education Office Science and technology research project
   youth talent project (No.Q20172805), the Hubei Provincial education
   science planning project (No.2016GB086), the construction of a special
   scientific research project for master's point (No.2018-19GZ050).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], INT J LEGAL MED
   [Anonymous], P INT C COMP VIS PAT
   Cheema MS, 2014, PATTERN RECOGN LETT, V50, P130, DOI 10.1016/j.patrec.2013.09.024
   Chen BC, 2014, ECCV, V2014, P768
   Chen WY, 2015, CELL RES, V25, P574, DOI 10.1038/cr.2015.36
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dayan N, 2008, PERS CARE COSMET TEC, pXV
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng YY, 2017, LECT NOTES COMPUT SC, V10614, P539, DOI 10.1007/978-3-319-68612-7_61
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563041
   Han H, 2013, INT C BIOM MADR SPAI
   Iga R, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P756
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Levi G., 2015, CVPRW, P34
   Liao H., 2016, P IEEE PES GEN M BOS, P1, DOI DOI 10.1109/PESGM.2016.7741337
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Patzelt SBM, 2015, J ESTHET RESTOR DENT, V27, P100, DOI 10.1111/jerd.12125
   Shang LF, 2009, PROC CVPR IEEE, P2090, DOI 10.1109/CVPRW.2009.5206509
   Tang K, 2016, ACCV, V2016, P389
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Wang, 2016, ESANN 2017 P, P589
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2011, PROC CVPR IEEE, P505, DOI 10.1109/CVPR.2011.5995481
   Yi D, 2014, P 12 AS C COMP VIS S, P1
   Zhang D, 2006, LECT NOTES COMPUT SC, V4182, P79
   Zhang GH, 2017, LECT NOTES COMPUT SC, V10585, P1, DOI 10.1007/978-3-319-68935-7_1
   Zhou SHK, 2005, IEEE I CONF COMP VIS, P541
NR 39
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2181
EP 2197
DI 10.1007/s11042-018-6342-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700040
DA 2024-07-18
ER

PT J
AU Long, M
   Peng, F
   Zhu, Y
AF Long, Min
   Peng, Fei
   Zhu, Yin
TI Identifying natural images and computer generated graphics based on
   binary similarity measures of PRNU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image source identification; Binary similarity measures; Photo response
   non-uniformity noise (PRNU)
ID MODEL
AB Aiming at the identification of natural images and computer generated graphics, an image source pipeline forensics method based on binary similarity measures of PRNU (photo response non-uniformity) is proposed. As PRNU is a unique attribute of natural images, binary similarity measures of PRNU are used to represent the differences between natural images and computer generated graphics. Binary Kullback-Leibler distance, binary minimum histogram distance, binary absolute histogram distance and binary mutual entropy are calculated from PRNU in RGB three channels. With a total of 36 dimensions of features, LIBSVM is used for classification. Experimental results and analysis indicate that it can achieve an average identification accuracy of 99.83%, and the capability of identifying natural images and computer generated graphics is balanced. Meanwhile, it is robust against JPEG compression, rotation and additive noise.
C1 [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410014, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410114, Hunan, Peoples R China.
   [Peng, Fei; Zhu, Yin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Changsha University of
   Science & Technology; Hunan University
RP Peng, F (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM caslongm@gmail.com; eepengf@gmail.com; zhuyinyin2009@qq.com
RI Long, Min/AGW-6059-2022; Peng, Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61572182, 61370225]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]; Scientific
   Research Plan of Hunan Provincial Science and Technology Department of
   China [2014FJ4161]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant No. 61572182, 61370225), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No.15JJ2007), supported by the Scientific Research Plan of Hunan
   Provincial Science and Technology Department of China (2014FJ4161).
CR [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   Avcba I, 2015, J ADV APPL SIGNAL PR, V17, P1
   Bayram Sevinc, 2005, 2005 13th European Signal Processing Conference, P1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang TY, 2014, J VIS COMMUN IMAGE R, V25, P1289, DOI 10.1016/j.jvcir.2014.04.010
   Dubois E, 2005, IEEE SIGNAL PROC LET, V12, P847, DOI 10.1109/LSP.2005.859503
   Fan S, 2012, INT J COMPUT INF SCI, V9, P2877
   Gao S, 2013, LNCS, V8398, P303
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li Z., 2013, INT WORKSHOP DIGITAL, P228, DOI 10.1007/978-3-642-40099-519
   Lian NX, 2007, IEEE T IMAGE PROCESS, V16, P2515, DOI 10.1109/TIP.2007.904459
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Losson O, 2013, COMPUT VIS IMAGE UND, V117, P747, DOI 10.1016/j.cviu.2013.03.001
   Lv Y, 2014, P INT C COMP COMM IN, P257
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Özparlak L, 2011, IEEE T INF FOREN SEC, V6, P1418, DOI 10.1109/TIFS.2011.2162830
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Peng F, 2015, J FORENSIC SCI, V60, P435, DOI 10.1111/1556-4029.12680
   Peng F, 2014, DIGIT INVEST, V11, P111, DOI 10.1016/j.diin.2014.04.002
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XF, 2014, COMPUT VIS IMAGE UND, V128, P84, DOI 10.1016/j.cviu.2014.07.007
   Wu R., 2011, IEEE International Conference on Image Processing, P1933
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhang LB, 2017, J VIS COMMUN IMAGE R, V48, P471, DOI 10.1016/j.jvcir.2016.12.013
   Zhang R, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P226, DOI 10.1109/ICECC.2011.6067631
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 37
TC 36
Z9 37
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 489
EP 506
DI 10.1007/s11042-017-5101-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500027
DA 2024-07-18
ER

PT J
AU Ma, YP
   Yang, DB
   Xie, HT
   Yin, J
AF Ma, Yanping
   Yang, Dongbao
   Xie, Hongtao
   Yin, Jian
TI Supervised deep hashing for image content security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image content security; Hashing; Binary codes; Deep learning
ID REPRESENTATION
AB Due to the fast growth of image data on the web, it is necessary to ensure the content security of uploaded images. One of the fundamental problems behind this need is retrieving relevant images from the large-scale databases. Recently, hashing/binary coding algorithms have proved to be effective for large-scale visual information retrieval. Most existing hashing methods usually seek single linear projections to map each sample into a binary vector. In this paper, a supervised deep hashing method is proposed, which seeks multiple non-linear transformations to generate more discriminative binary codes with short bits. We implement a deep Convolutional Neural Network to achieve end-to-end hashing. A loss function is elaborately devised to preserve the similarity relationship between images, meanwhile minimize the quantization error and make hash bits distribute evenly. Extensive experimental comparisons with state-of-the-art hashing algorithms are conducted on CIFAR-10 and NUS-WIDE, the MAP reaches to 87.67% and 77.48% with 48 bits respectively. It shows that the proposed method achieves very competitive results with the state-of-the-arts.
C1 [Ma, Yanping] Ludong Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
   [Yang, Dongbao; Yin, Jian] Shandong Univ, Sch Mech Elect & Informat Engn, Weihai, Shandong, Peoples R China.
   [Yang, Dongbao; Xie, Hongtao] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Anhui, Peoples R China.
C3 Ludong University; Shandong University; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Yang, DB (corresponding author), Shandong Univ, Sch Mech Elect & Informat Engn, Weihai, Shandong, Peoples R China.; Yang, DB; Xie, HT (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Anhui, Peoples R China.
EM yangdongbao0903@163.com; xiehongtao@iie.ac.cn; yinjian@sdu.edu.cn
FU National Nature Science Foundation of China [61771468]; Youth Innovation
   Promotion Association Chinese Academy of Sciences [2017209]
FX This work is supported by the National Nature Science Foundation of
   China (61771468), the Youth Innovation Promotion Association Chinese
   Academy of Sciences (2017209). Thanks to the contributions made by Yan
   Li from Beijing Kuaishou Technology Co., Ltd., who has examined the
   whole manuscript with respect to the usages of verb tense, singular and
   plural forms of nouns, and articles and has also conducted some
   experiments.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], 2014, AAAI
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], CVPR
   [Anonymous], 30 AAAI C ART INT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2467315
   [Anonymous], 2009, NEURIPS
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gu SM, 2013, INT CONF MACH LEARN, P108, DOI 10.1109/ICMLC.2013.6890453
   Jain P, 2008, IEEE C COMPUTER VISI, P1
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang Jun., 2010, ICML, P1127
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Xie HT, 2014, IEEE T MULTIMEDIA, V16, P1104, DOI 10.1109/TMM.2014.2305909
   Xie HT, 2013, J VIS COMMUN IMAGE R, V24, P635, DOI 10.1016/j.jvcir.2013.04.012
   Xie HT, 2011, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2011.6115596
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
NR 48
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 661
EP 676
DI 10.1007/s11042-017-5433-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500037
DA 2024-07-18
ER

PT J
AU Qiang, ZP
   He, LB
   Chen, YQ
   Chen, X
   Xu, D
AF Qiang, Zhenping
   He, Libo
   Chen, Yaqiong
   Chen, Xu
   Xu, Dan
TI Adaptive fast local Laplacian filters and its edge-aware application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laplacian pyramid; Detail enhancement; Detail smoothing; Image editing;
   Local Laplacian filters
ID IMAGES; MODEL
AB We present a new approach for edge-aware image processing, inspired by the principle of local Laplacian filters and fast local Laplacian filters. In contrast to the previous methods that primarily rely on fixed intensity threshold, our method adopts an adaptive parameter selection strategy in different regions of the processing image. This adaptive parameter selection strategy allows different intensity thresholds and different amplitude magnification factors in different pixels, moreover, a different remapping functions are adopted to process each pixel. At the same time, we propose an efficient and flexible method for obtaining the representation of image local variation, and based on the representation to select local Laplacian filters parameters adaptively. Our experiments shows that high-quality results in the detail enhancement and detail smoothing can be produced by our methods.
C1 [Qiang, Zhenping; He, Libo; Xu, Dan] Yunnan Univ, Sch Informat Sci & Engn, 2 Cuihubei Rd, Kunming 650091, Yunnan, Peoples R China.
   [Qiang, Zhenping; Chen, Yaqiong; Chen, Xu] Southwest Forestry Univ, Dept Comp & Informat Sci, 300 Bailong Rd, Kunming 650224, Yunnan, Peoples R China.
C3 Yunnan University; Southwest Forestry University - China
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, 2 Cuihubei Rd, Kunming 650091, Yunnan, Peoples R China.
EM qzp@swfu.edu.cn; 50352591@qq.com; shang911223@qq.com; 362493588@qq.com;
   danxu@ynu.edu.cn
RI Xu, Dan/KPA-7396-2024; Qiang, Zhenping/JEO-7966-2023
OI Xu, Dan/0000-0003-4602-3550; 
FU National Natural Science Foundation of China [11603016, 61540062]; Key
   Project of Yunnan Applied Basic Research [2014fa021]; project of
   Research Center of Kunming Forestry Information Engineering Technology
   [2015FBI06]
FX This work is supported by the projects of National Natural Science
   Foundation of China (11603016, 61540062), the Key Project of Yunnan
   Applied Basic Research(2014fa021) and project of Research Center of
   Kunming Forestry Information Engineering Technology(2015FBI06).
CR [Anonymous], 2006, MATH PROBLEMS IMAGE
   [Anonymous], 1995, P MUSTERERKENNUNG 19
   Arnheim R, 1956, ART VISUAL PERCEPTIO, V16, P425
   Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629645
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1109/SARNOF.2007.4567317, 10.1145/1276377.1276506, 10.1145/1239451.1239554]
   Du H, 2016, VISUAL COMPUT, V32, P1537, DOI 10.1007/s00371-015-1138-3
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu Y, 2015, IEEE T CIRC SYST VID, V25, P261, DOI 10.1109/TCSVT.2014.2333152
   Nie WZ, 2016, J VIS COMMUN IMAGE R, V37, P40, DOI 10.1016/j.jvcir.2015.06.011
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Singh M, 2005, PATTERN RECOGN LETT, V26, P1995, DOI 10.1016/j.patrec.2005.03.015
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Wang QC, 2015, COMPUT GRAPH FORUM, V34, P131, DOI 10.1111/cgf.12625
   Xiaofeng D, 2017, COMPUT ENG APPL, V53, P141
   Xin Y, 2015, COMPUT SCI, V42, P57
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yanxi Z, 2017, COMPUT ENG APPL, V53, P170
   Zhang H, 2013, P 2 ACM INT C MULT, V2013, P33
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhao Y, 2015, 3 WORLD C COMPL SYST, P1
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 42
TC 12
Z9 13
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 619
EP 639
DI 10.1007/s11042-017-5347-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500035
DA 2024-07-18
ER

PT J
AU Raghuwanshi, G
   Tyagi, V
AF Raghuwanshi, Ghanshyam
   Tyagi, Vipin
TI A novel technique for content based image retrieval based on
   region-weight assignment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Curvelet transform; Image search;
   Region-based image retrieval; Region weight assignment
ID DIRECTIONAL LOCAL EXTREMA; COLOR; MECHANISM; PATTERNS; WAVELET
AB This paper presents a novel technique for content based image retrieval (CBIR) that selects and assigns weights to the regions of the image on the basis of their contribution to image contents, using a new region-weight assignment scheme. Assigning the weight to each region ignores the irrelevant regions of the image during retrieval and thus maximizes the retrieval accuracy. The proposed approach performs the feature extraction at both region-level and image-level. Texture and edge features are extracted at region-level whereas shape feature is extracted at image-level. At region-level, the image is divided into non-overlapping regions and texture and edge features are calculated for each region separately. Curvelet transform is used for extracting the texture feature using the curve continuity as well as line continuity in the feature extraction process. Moment invariant is used for extracting the shape features. Integrated Region Matching (IRM) technique is used for retrieving the relevant images. The proposed approach does the best use of the features by balancing the regions and features in the similarity matching of the regions. The performance of the proposed technique is tested on COREL and CIFAR databases. Experimental results show the effectiveness of proposed region weight assignment scheme over the feature weight assignment scheme in image retrieval in comparison to other state-of-the-art techniques.
C1 [Raghuwanshi, Ghanshyam; Tyagi, Vipin] Jaypee Univ Engn & Technol, Guna 473226, MP, India.
RP Tyagi, V (corresponding author), Jaypee Univ Engn & Technol, Guna 473226, MP, India.
EM dr.vipin.tyagi@gmail.com
RI Tyagi, Vipin/I-2451-2013
OI Tyagi, Vipin/0000-0003-4994-3686
CR Candes E.J., 1999, Curvelets - a surprisingly effective nonadaptive representation for objects with edges
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Feng D, 2003, FUNDAMENTALS CONTENT, P1
   Gonde AB, 2013, DIGIT SIGNAL PROCESS, V23, P142, DOI 10.1016/j.dsp.2012.04.019
   Guo JM, 2015, IEEE T INTELL TRANSP, V16
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kimura M, 2006, IEEE T CONSUM ELECTR, V52, P312, DOI 10.1109/TCE.2006.1649643
   Kingsbury N, 1999, PHILOS T R SOC A, V357, P2543, DOI 10.1098/rsta.1999.0447
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kundu MK, 2015, KNOWL-BASED SYST, V73, P254, DOI 10.1016/j.knosys.2014.10.009
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mosbah M, 2014, INT J COMPUT ELECT A, V8
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Raghuwanshi G, 2018, MULTIMED TOOLS APPL, V77, P23389, DOI 10.1007/s11042-018-5628-y
   Raghuwanshi G, 2017, MULTIMED TOOLS APPL, V76, P13741, DOI 10.1007/s11042-016-3747-x
   Raghuwanshi G, 2016, DIGIT SIGNAL PROCESS, V48, P50, DOI 10.1016/j.dsp.2015.09.003
   Reddy AH, 2015, AEU-INT J ELECTRON C, V69, P290, DOI 10.1016/j.aeue.2014.09.015
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Shrivastava N, 2015, ADV INTELL SYST COMP, V328, P509, DOI 10.1007/978-3-319-12012-6_56
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Yildizer E, 2012, KNOWL-BASED SYST, V31, P55, DOI 10.1016/j.knosys.2012.01.013
NR 37
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1889
EP 1911
DI 10.1007/s11042-018-6333-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700029
DA 2024-07-18
ER

PT J
AU Wang, DY
   Tian, JJ
   Whangbo, TK
AF Wang, Dongyue
   Tian, Junjie
   Whangbo, Taeg Keun
TI Method for real-time automatic setting of ultrasonic image parameters
   based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasonic image classification; Convolutional neural network; Deep
   learning
ID NEURAL-NETWORKS
AB We propose a method for the automatic setting of ultrasonic image parameter values based on deep learning of image classification in this paper. The method first classifies ultrasonic images through a convolutional neural network and then sets gray map and Gain parameters correspondingly to acquire high-quality images. In the classification step, we initially tried to classify the images using GoogLeNet. However, as GoogLeNet has a complicated structure and a low operating speed, this paper proposes a new structure for the convolutional neural network to classify the images. The results show that the customized classification method can result in faster recognition without compromising the performance, thus successfully achieving rapid and automatic setting of ultrasonic image parameters.
C1 [Wang, Dongyue; Tian, Junjie; Whangbo, Taeg Keun] Gachon Univ, Dept Comp Sci, Seongnam Si, Gyeonggi Do, South Korea.
C3 Gachon University
RP Whangbo, TK (corresponding author), Gachon Univ, Dept Comp Sci, Seongnam Si, Gyeonggi Do, South Korea.
EM wangdongyue89@126.com; yexiaoxi0922@gmail.com; tkwhangbo@gachon.ac.kr
FU GRRC program of Gyeonggi province [GRRC-Gachon2017]
FX This work was supported by the GRRC program of Gyeonggi province.
   [GRRC-Gachon2017(B03), Development of Personalized Digital Support
   Technology based on Artificial Intelligence].
CR [Anonymous], AC SPEECH SIGN PROC
   [Anonymous], 2017, TECH REP
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 1997, ARTIFICIAL NEURAL NE
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2010, Diagnostic Ultrasound: Physics and Equipment
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2011, P MACHINE LEARNING R
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Chen WS, 2011, COMPUT MATH APPL, V62, P2696, DOI 10.1016/j.camwa.2011.06.051
   Cui K, 2017, CLUSTER COMPUT, V20, P2869, DOI 10.1007/s10586-017-0881-9
   Cui K, 2018, NEURAL COMPUT APPL, V29, P1233, DOI 10.1007/s00521-017-2853-7
   DOUST BD, 1974, RADIOLOGY, V110, P643, DOI 10.1148/110.3.643
   Du J, 2012, IET COMMUN, V6, P2695, DOI 10.1049/iet-com.2012.0029
   FATEMI M, 1980, ULTRASONIC IMAGING, V2, P1, DOI 10.1016/0161-7346(80)90201-1
   Glorot X., 2010, P INT C ARTIFICIAL I, P249
   Hecht-Nielsen R., 1992, Neural Networks for Perception, P65, DOI DOI 10.1016/B978-0-12-741252-8.50010-8
   Hu J., 2017, CoRR
   Luo QL, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-285
   MARSAL K, 1984, ULTRASOUND MED BIOL, V10, P339, DOI 10.1016/0301-5629(84)90168-6
   Peng JS, 2018, COMPLEXITY, DOI 10.1155/2018/1801273
   PETCHESKY RP, 1987, FEMINIST STUD, V13, P263, DOI 10.2307/3177802
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sibi P., 2013, Journal of Theoretical and Applied Information Technology, V47, P1264
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun YG, 2017, J MAR SCI TECH-TAIW, V25, P656, DOI 10.6119/JMST-017-1226-05
   Sun YG, 2018, NEURAL COMPUT APPL, V30, P2003, DOI 10.1007/s00521-017-2983-y
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Yang AM, 2017, RESULTS PHYS, V7, P1046, DOI 10.1016/j.rinp.2017.02.027
   Yang K, 2016, IEEE J SEL AREA COMM, V34, P3208, DOI 10.1109/JSAC.2016.2624078
   Yang K, 2014, IEEE T VEH TECHNOL, V63, P1270, DOI 10.1109/TVT.2013.2284340
NR 34
TC 3
Z9 3
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1067
EP 1080
DI 10.1007/s11042-018-6365-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500060
DA 2024-07-18
ER

PT J
AU Wang, LF
   Dong, X
   Cheng, X
   Lin, SZ
AF Wang, Lifang
   Dong, Xia
   Cheng, Xi
   Lin, Suzhen
TI An improved coupled dictionary and multi-norm constraint fusion method
   for CT/MR medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CT; MR; Image fusion; Improved coupled dictionary; Multi-norm constraint
ID K-SVD; QUALITY ASSESSMENT
AB To solve the problems that a single dictionary is difficult to obtain accurate sparse representation of images, and a single norm as activity level measurement of the source image block does not preserve more details of the image, leading to poor image fusion results, this paper proposes an improved coupled dictionary and multi-norm constraint image fusion method for CT/MR images. In the paper, CT and MR image pairs are used as training set, and the coupled CT dictionary and the MR dictionary are obtained by using the improved K-SVD algorithm respectively. The fusion dictionary is obtained by combining coupled CT dictionary and MR dictionary with the spatial domain method. First, the registered source images are compiled into the column vectors and the means are removed. The exact sparse representation coefficients are calculated by the CoefROMP algorithm under the fusion dictionary. Then the multi-norm constraint of the sparse representation coefficients is taken as activity level measurement of the source image blocks, and the sparse representation coefficients are fused by the rule of choosing the maximum. Finally, the fused images are obtained by reconstruction. The experimental results show that the proposed method in this paper can effectively retain more image details, improve fusion image contrast and clarity, focal prominent, accelerate the running speed of the algorithm and be applied to clinical diagnosis and auxiliary treatment.
C1 [Wang, Lifang; Dong, Xia; Cheng, Xi; Lin, Suzhen] North Univ China, Sch Data Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
C3 North University of China
RP Wang, LF (corresponding author), North Univ China, Sch Data Sci & Technol, Taiyuan 030051, Shanxi, Peoples R China.
EM lifang_wang@aliyun.com
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Angulo JM, 2015, ENTROPY-SWITZ, V17, P5382, DOI 10.3390/e17085382
   Arras B, 2018, IEEE T INFORM THEORY, V64, P1083, DOI 10.1109/TIT.2017.2759279
   Aslantas V, 2015, AEU-INT J ELECTRON C, V69, P160, DOI 10.1016/j.aeue.2015.09.004
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Deng H, 2015, SOL PHYS, V290, P1479, DOI 10.1007/s11207-015-0676-1
   Duan GL, 2016, NEUROCOMPUTING, V208, P117, DOI 10.1016/j.neucom.2015.12.125
   Herskovits J, 2011, STRUCT MULTIDISCIP O, V44, P363, DOI 10.1007/s00158-011-0634-y
   Kafashan M, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074019
   Li WT, 2017, AEU-INT J ELECTRON C, V71, P125, DOI 10.1016/j.aeue.2016.10.011
   [练秋生 Lian Qiusheng], 2015, [自动化学报, Acta Automatica Sinica], V41, P240
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu HY, 2007, INT J WAVELETS MULTI, V5, P567, DOI 10.1142/S0219691307001902
   Madheswari K, 2017, QUANT INFR THERM J, V14, P24, DOI 10.1080/17686733.2016.1229328
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Marcello J, 2013, IEEE GEOSCI REMOTE S, V10, P432, DOI 10.1109/LGRS.2012.2207944
   Mehra I, 2015, OPT COMMUN, V335, P153, DOI 10.1016/j.optcom.2014.09.040
   Ophir B, 2011, IEEE J-STSP, V5, P1014, DOI 10.1109/JSTSP.2011.2155032
   Smith LN, 2012, APPL OPTICS, V51, P3941, DOI 10.1364/AO.51.003941
   Wang JJ, 2015, OPTIK, V126, P2508, DOI 10.1016/j.ijleo.2015.06.019
   Xing L, 2018, SIGNAL PROCESS, V145, P233, DOI 10.1016/j.sigpro.2017.12.013
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yin HT, 2013, INFORM FUSION, V14, P229, DOI 10.1016/j.inffus.2012.01.008
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhen XT, 2013, PATTERN RECOGN LETT, V34, P1899, DOI 10.1016/j.patrec.2012.10.021
   Zhu ZQ, 2016, NEUROCOMPUTING, V214, P471, DOI 10.1016/j.neucom.2016.06.036
NR 27
TC 5
Z9 5
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 929
EP 945
DI 10.1007/s11042-018-5907-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500053
DA 2024-07-18
ER

PT J
AU Ben Slimane, N
   Aouf, N
   Bouallegue, K
   Machhout, M
AF Ben Slimane, Nabil
   Aouf, Nahed
   Bouallegue, Kais
   Machhout, Mohsen
TI A novel chaotic image cryptosystem based on DNA sequence operations and
   single neuron model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logistic-adjusted-Sine map; Single neuron model; Cryptosystem; DNA
   sequence operations; Extended confusion; DNA diffusion; SHA-512
ID ENCRYPTION SCHEME; ALGORITHM; SYSTEM; MAP; CRYPTANALYSIS; EFFICIENT
AB In this paper, a novel image cryptosystem based on DNA sequence operations, Single Neuron Model (SNM) and chaotic map is designed. The initial conditions and system parameters of dynamical systems are generated using 512-bit hash value highly dependent to the plain image. We adopted confusion-diffusion as architecture of the algorithm. The 2D Logistic-adjusted-Sine map (2D-LASM) is employed to confuse the pixels of color components simultaneously, while SNM is employed to generate the key stream, otherwise, the hash value of the plain image are injected additionally in diffusion process. Experimental results and relevant security analysis demonstrated that our proposed encryption scheme has the highest security level because it is more sensitive, and it has a key space sufficiently large. The proposed method is compared to other recent image encryption algorithms including different security analysis properties, such as randomness, sensitivity and correlation of the encrypted-images demonstrated that our cryptosystem is efficient, and can overcomes known attacks.
C1 [Ben Slimane, Nabil; Aouf, Nahed; Bouallegue, Kais; Machhout, Mohsen] Univ Monastir, Elect & Microelect Lab, Dept Phys, Fac Sci Monastir, Monastir, Tunisia.
C3 Universite de Monastir
RP Ben Slimane, N (corresponding author), Univ Monastir, Elect & Microelect Lab, Dept Phys, Fac Sci Monastir, Monastir, Tunisia.
EM nabilbenslimane88@gmail.com; nahedaouf@gmail.com;
   kais_bouallegue@yahoo.fr; machhout@yahoo.fr
OI Ben Slimane, Nabil/0000-0001-9524-0776; Mohsen,
   Machhout/0000-0002-5629-0508
FU ministry of higher education and scientific research of Tunisia
FX This research is supported by ministry of higher education and
   scientific research of Tunisia.
CR Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   [Anonymous], 2009, HINDAWI PUBL CORP MA
   [Anonymous], 2002, FEDERAL INFORM PROCE, V180-2
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Ben Slimane N, 2017, NONLINEAR DYNAM, V88, P1655, DOI 10.1007/s11071-017-3337-0
   Bouallegue K, 2015, CHAOS, V25, DOI 10.1063/1.4923302
   Bouallegue K, 2011, CHAOS SOLITON FRACT, V44, P79, DOI 10.1016/j.chaos.2010.12.005
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen H, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-016-0669-9
   Chen JY, 2011, IEEE T CIRCUITS-II, V58, P110, DOI 10.1109/TCSII.2011.2106316
   Chen JX, 2015, COMMUN NONLINEAR SCI, V23, P294, DOI 10.1016/j.cnsns.2014.11.021
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Elgendy F, 2016, MULTIMED TOOLS APPL, V75, P11529, DOI 10.1007/s11042-015-2883-z
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Furhtand B, 2005, MULTIMEDIA SECURITY
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P7305, DOI 10.1007/s11042-017-4634-9
   Girdhar A, 2018, MULTIMED TOOLS APPL, V77, P27017, DOI 10.1007/s11042-018-5902-z
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li B, 2018, MULTIMED TOOLS APPL, V77, P8911, DOI 10.1007/s11042-017-4786-7
   Li C, 2005, COEXISTING CHAOTIC A, V23, P599
   Li XSW, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI [10.1007/s11042-015-2573-x, DOI 10.1007/S11042-015-2573-X]
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Liu HJ, 2013, J SYST SOFTWARE, V86, P826, DOI 10.1016/j.jss.2012.11.026
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   del Rey AM, 2015, LOG J IGPL, V23, P485, DOI 10.1093/jigpal/jzv013
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P1817, DOI 10.1007/s11042-015-3085-4
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Stinson D., 2002, CRYPTOGRAPHY THEORY, V2nd
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Xue X, 2010, NEURAL NETWORK WORLD
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
NR 65
TC 33
Z9 33
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30993
EP 31019
DI 10.1007/s11042-018-6145-8
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600038
DA 2024-07-18
ER

PT J
AU Choe, G
   Nam, C
   Chu, C
AF Choe, Gwangmin
   Nam, Cholman
   Chu, Changgon
TI An effective temporal error concealment in H.264 video sequences based
   on scene change detection-PCA model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Scene change; H; 264; AVC; PCA; Face recognition;
   Video sequence
AB This paper proposes a new temporal error concealment algorithm in H.264 video sequences based on scene change detection and PCA model. In order to detect scene change, dynamic threshold and image similarity metric are presented using coding prediction mode and DCT AC energy in H.264 baseline. UPCA (Updated PCA) model is presented by combining the scene change feature with Index transformation-Buffer updating approach. The lost images are concealed by Projection onto Convex Sets algorithm with UPCA model. Experimental results show that the proposed algorithm can achieve better error concealment performance for the higher motion and the frequent scene change, compared with the related method.
C1 [Choe, Gwangmin] Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
   [Nam, Cholman; Chu, Changgon] Kim Il Sung Univ, Sch Comp Sci & Technol, Informat & Commun Lab, Pyongyang, North Korea.
RP Choe, G (corresponding author), Kim Il Sung Univ, Sch Comp Sci & Technol, Visual Informat Proc Lab, Pyongyang, North Korea.
EM ryongnam21@yahoo.com
CR Ameigeiras P, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0565-9
   [Anonymous], 2015, ACM T MULTIMEDIA COM
   Behar R, 2015, 7 INT C EV INT, P26
   Brandt J, 2008, INT CONF NEXT GEN, P514, DOI 10.1109/NGMAST.2008.39
   Chen T, 2003, RES EDUC, P55
   Chen TPC, 2002, WIREL COMMUN MOB COM, V2, P607, DOI 10.1002/wcm.83
   De Bruyne S, 2007, LECT NOTES COMPUT SC, V4351, P1
   Dehghani M, 2015, WIRELESS PERS COMMUN, V80, P891, DOI 10.1007/s11277-014-2062-y
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Li HL, 2004, IEEE T MULTIMEDIA, V6, P624, DOI [10.1109/TMM.2004.830812, 10.1109/tmm.2004.830812]
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Nemethova O, 2007, TECHNISCHE U WIEN OS, V3, P77
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yan B, 2004, CCNC 2004: 1ST IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE, PROCEEDINGS, P621, DOI 10.1109/CCNC.2004.1286934
   Yu G, 2010, CHINESE J ELECTRON, V38, P382
   Zeng W, 2005, IEEE INT SYMP CIRC S, P3459
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
NR 18
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31953
EP 31967
DI 10.1007/s11042-018-6184-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000020
DA 2024-07-18
ER

PT J
AU Dutta, A
   Verma, Y
   Jawahar, CV
AF Dutta, Ayushi
   Verma, Yashaswi
   Jawahar, C. V.
TI Automatic image annotation: the quirks and what works
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image tagging; Empirical study; Evaluation metrics; Dataset analysis
ID RELEVANCE
AB Automatic image annotation is one of the fundamental problems in computer vision and machine learning. Given an image, here the goal is to predict a set of textual labels that describe the semantics of that image. During the last decade, a large number of image annotation techniques have been proposed that have been shown to achieve encouraging results on various annotation datasets. However, their scope has mostly remained restricted to quantitative results on the test data, thus ignoring various key aspects related to dataset properties and evaluation metrics that inherently affect the performance to a considerable extent. In this paper, first we evaluate ten state-of-the-art (both deep-learning based as well as non-deep-learning based) approaches for image annotation using the same baseline CNN features. Then we propose new quantitative measures to examine various issues/aspects in the image annotation domain, such as dataset specific biases, per-label versus per-image evaluation criteria, and the impact of changing the number and type of predicted labels. We believe the conclusions derived in this paper through thorough empirical analyzes would be helpful in making systematic advancements in this domain.
C1 [Dutta, Ayushi; Jawahar, C. V.] IIIT, CVIT, Hyderabad, Telangana, India.
   [Verma, Yashaswi] IISc, CDS, Bangalore, Karnataka, India.
C3 International Institute of Information Technology Hyderabad; Indian
   Institute of Science (IISC) - Bangalore
RP Dutta, A (corresponding author), IIIT, CVIT, Hyderabad, Telangana, India.
EM ayushi.dutta@research.iiit.ac.in; yashaswiv@iisc.ac.in;
   jawahar@iiit.ac.in
RI Jawahar, C.V./ACR-3102-2022; Verma, Yashaswi/GXF-3950-2022
OI Jawahar, C.V./0000-0001-6767-7057; Verma, Yashaswi/0000-0003-2317-2641;
   Dutta, Ayushi/0000-0001-6958-5017
FU Department of Science and Technology (India)
FX Yashaswi Verma would like to thank the Department of Science and
   Technology (India) for the INSPIRE Faculty Award 2017.
CR [Anonymous], ACM SIGCHI C HUM FAC
   [Anonymous], 2012, P 50 ANN M ASS COMP
   [Anonymous], BMVC
   [Anonymous], 2015, ICCV
   [Anonymous], CVPR WORKSH
   [Anonymous], ECCV
   [Anonymous], 2016, CVPR
   [Anonymous], ARXIV151206963 CORR
   [Anonymous], ICLR
   [Anonymous], 1999, 1 INT WORKSHOP MULTI
   [Anonymous], 2011, IJCAI
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], CVPR
   [Anonymous], ECCV
   [Anonymous], ICCV
   [Anonymous], 2000, ADV LARGE MARGIN CLA
   [Anonymous], ARXIV160504770 CORR
   [Anonymous], 2015, ACL
   [Anonymous], ICML
   [Anonymous], 2009, ACM CIVR
   [Anonymous], CVPR
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Duygulu Pinar., 2002, ECCV
   Feng S.L., 2004, CVPR
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Grubinger M., 2006, INT WORKSH ONTOIMAGE, V5
   Gupta Ankush., 2012, P AAAI C ART INT
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Moran S, 2014, INT J MULTIMED INF R, V3, P209, DOI 10.1007/s13735-014-0063-y
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Verma Y, 2017, INT J COMPUT VISION, V121, P126, DOI 10.1007/s11263-016-0927-0
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
NR 43
TC 11
Z9 11
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31991
EP 32011
DI 10.1007/s11042-018-6247-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000022
DA 2024-07-18
ER

PT J
AU Kalpana, V
AF Kalpana, V.
TI Analysis of rain fall and the temperature of Coimbatore District using
   land use and land cover change detection by image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Land use; Land cover; Region growing; Segmentation; Remote sensing;
   Multi temporal
AB Image segmentation is a process has done for the classification of high resolution remote sensing images in the present research work. The segmentation results are capable of influencing the subsequent process effects. An image can be partitioned into a number of disjoint segments which is used to represent the image structures. It is found that it is more compact to represent an image and the low level and high structures can be combined. There are different types of methods to segment an image namely, threshold-based, edge-based and region-based. Region growing approach is image segmentation methods in which the neighboring pixels are examined and merged with the class region in case of no edges are detected. The iteration is done for every pixel boundary. Unlike gradient and Laplacian methods, the edges of the region are found by the region growing and it is perfectly their region. The images are determined by the LANDSAT TM satellite data. The remote sensing technique is used for collecting information about the Coimbatore district. The sensed data is a key to many diverse applications. The contribution of this work for Coimbatore district is to find the change of the Land used and Land covered in the entire region and also to find the changes in the green lands, vegetation and Land surface utilized for urban area. The neighboring regions are taken into account and the similarities are checked in the growing process. No single region is allowed to dominate the entire proceedings. A certain number of regions are allowed to grow at a time. Comparable regions will gradually combine into expanding regions. The Control of these methods may be quite complicated but efficient methods have been developed. The directions of growing pixels are easy and efficient to implement on parallel computers. The threshold-based segmentation is completely depending on the gray level images which regards the reflectivity of the featured images. It determines a threshold based on brightness of the ground objects. It is purely from the image background. But it is rapid and its uncertainty is significant. It is not convenient to process multi-spectral images.
C1 [Kalpana, V.] PA Coll Engn & Technol, Dept CSE, Pollachi, India.
RP Kalpana, V (corresponding author), PA Coll Engn & Technol, Dept CSE, Pollachi, India.
EM drybk.pacet@gmail.com
RI Kalpana, Dr.Y Baby/N-2599-2019
CR [Anonymous], 2016, SEASONAL RAINFALL FO
   [Anonymous], 2012, INT J COMPUTER TECHN
   Baby Kalpana Y, 2013, JOKULL J, V1, P32
   Bhatta B., 2011, Remote Sensing and GIS, V2nd
   Bins LS, 1996, J NEUROSCI PSYCHOL E, P677
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Castleman KR, 2010, DIGITAL IMAGE PROCES
   Cipar J, 2007, INT GEOSCI REMOTE SE, P2589, DOI 10.1109/IGARSS.2007.4423374
   Kurosu T, 2001, INT J REMOTE SENS, V22, P595, DOI 10.1080/01431160050505874
   Mathivanan SS, 2012, J ACAD IND RES, V1, P257
   O'Hara CG, 2003, IEEE T GEOSCI REMOTE, V41, P2005, DOI 10.1109/TGRS.2003.816573
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
NR 12
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30487
EP 30504
DI 10.1007/s11042-018-6125-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600016
DA 2024-07-18
ER

PT J
AU Li, Q
   Yan, B
   Li, H
   Chen, N
AF Li, Qi
   Yan, Bin
   Li, Hui
   Chen, Na
TI Separable reversible data hiding in encrypted images with improved
   security and capacity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personal privacy; Image encryption; Reversible data hiding; Stream
   encryption; Block permutation
AB Reversible data hiding (RDH) has to be conducted in the encrypted images when original images are encrypted for privacy protection in some open environments, including the cloud computing. However, the current RDH algorithms in encrypted images with error-free decryption may lead to leakage of image content and low embedding rate. In this paper, a novel RDH algorithm for image in encryption domain is proposed. To improve security, we propose a combined block permutation and a stream cipher into the encryption step, which considers data hiding in later steps. We further increase the embedding rate by proposing bit replacement in prediction error. This scheme has the advantages of built-in embedding flag, error-free decryption and high embedding rate. It can be applied to a wide variety of scenarios: If the recipient has only the data-hiding key, he can extract the hidden data but cannot restore the image; If the recipient has only the image encryption key, he can read the distorted image but cannot extract the hidden data; If the recipient has both keys, he can extract the hidden data and restore the original image completely.
C1 [Li, Qi; Yan, Bin; Li, Hui; Chen, Na] Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Yan, B (corresponding author), Shandong Univ Sci & Technol, Coll Elect Commun & Phys, Qingdao 266590, Peoples R China.
EM yanbinhit@hotmail.com
RI Yan, Bin/Y-7642-2019
OI Chen, Na/0000-0002-5541-8442; Yan, Bin/0000-0003-2929-464X
FU National Natural Science Foundation of China (NSFC) [61272432]; Shandong
   Provincial Natural Science Foundation [ZR2014JL044]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) (No. 61272432) and Shandong Provincial Natural Science
   Foundation (No. ZR2014JL044).
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 20
TC 30
Z9 32
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30749
EP 30768
DI 10.1007/s11042-018-6187-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600028
DA 2024-07-18
ER

PT J
AU Liu, DY
   An, P
   Ma, R
   Shen, LQ
AF Liu, Deyang
   An, Ping
   Ma, Ran
   Shen, Liquan
TI Hybrid linear weighted prediction and intra block copy based light field
   image coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field image; Linear weighted prediction; Intra block copy; Fast
   mode decision; HEVC SCC
ID HEVC
AB Light field imaging can capture both spatial and angular information of a 3D scene and is considered as a prospective acquisition and display solution to supply a more natural and fatigue-free 3D visualization. However, one problem that occupies an important position to deal with the light field data is the sheer size of data volume. In this context, efficient coding schemes for this particular type of image are needed. In this paper, we propose a hybrid linear weighted prediction and intra block copy based light field image codec architecture based on high efficiency video coding screen content coding extensions (HEVC SCC) standard to effectively compress the light field image data. In order to improve the prediction accuracy, a linear weighted prediction method is integrated into HEVC SCC standard, where a locally correction weighted based method is used to derive the weight coefficient vector. However, for the non-homogenous texture area, a best match in linear weighted prediction method does not necessarily lead to a good prediction of the coding block. In order to alleviate such shortcoming, the proposed hybrid codec architecture explores the idea of using the intra block copy scheme to find the best prediction of the coding block based on rate-distortion optimization. For the reason that the used try all then select best intra mode decision method is time-consuming, we further propose a fast mode decision scheme for the hybrid codec architecture to reduce the computation complexity. Experimental results demonstrate the advantage of the proposed hybrid codec architecture in terms of different quality metrics as well as the visual quality of views rendered from decompressed light field content, compared to the HEVC intra-prediction method and several other prediction methods in this field.
C1 [Liu, Deyang] Anqing Normal Univ, Sch Comp & Informat, Anqing, Peoples R China.
   [Liu, Deyang] Univ Key Lab Intelligent Percept & Comp Anhui Pro, Anqing, Peoples R China.
   [An, Ping; Ma, Ran; Shen, Liquan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Anqing Normal University; Shanghai University
RP Liu, DY (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Anqing, Peoples R China.; Liu, DY (corresponding author), Univ Key Lab Intelligent Percept & Comp Anhui Pro, Anqing, Peoples R China.
EM liudeyang@163.com; liudeyang@163.com
RI Shen, Liquan/D-4832-2012; Liu, Deyang/AAB-1184-2020; Liu,
   Deyang/ABG-2705-2020; Liu, Deyang/AAX-5429-2020
OI Liu, Deyang/0000-0001-7991-8735; 
FU National Natural Science Foundation of China [61571285, U1301257];
   Scientific Research Staring Foundation [055-170002004]; Key Project on
   Anhui Provincial Natural Science Study by Colleges and Universities
   [KJ2018A0361]; Foundation of University Research and Innovation Platform
   Team for Intelligent Perception and Computing of Anhui Province
FX This work was supported in part by the National Natural Science
   Foundation of China, under Grants 61571285, U1301257, and Scientific
   Research Staring Foundation 055-170002004, and the Key Project on Anhui
   Provincial Natural Science Study by Colleges and Universities No.
   KJ2018A0361. This work is also supported by the Foundation of University
   Research and Innovation Platform Team for Intelligent Perception and
   Computing of Anhui Province.
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Aggoun A, 2013, IEEE MULTIMEDIA, V20, P28, DOI 10.1109/MMUL.2012.42
   [Anonymous], 2016, MDTV
   [Anonymous], ISO IEC JTC 1SC 29 W
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2016, JCTVCX1015
   Cherigui S, 2013, IEEE T IMAGE PROCESS, V22, P1161, DOI 10.1109/TIP.2012.2227772
   Conti C, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574667
   Conti C, 2016, SIGNAL PROCESS-IMAGE, V42, P59, DOI 10.1016/j.image.2016.01.008
   Dai F, 2015, IEEE IMAGE PROC, P4733, DOI 10.1109/ICIP.2015.7351705
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Lei JJ, 2017, IEEE T BROADCAST, V63, P48, DOI 10.1109/TBC.2016.2623241
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270
   Li L, 2017, IEEE DATA COMPR CONF, P131, DOI 10.1109/DCC.2017.10
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Liu D, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3073784
   Liu DY, 2017, INT CONF ACOUST SPEE, P2002, DOI 10.1109/ICASSP.2017.7952507
   Liu DY, 2016, SIGNAL PROCESS-IMAGE, V47, P438, DOI 10.1016/j.image.2016.08.004
   Liu DY, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P201, DOI 10.1109/ChinaSIP.2015.7230391
   Liu D, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.3.033008
   Liu F, 2017, NEUROCOMPUTING, V252, P3, DOI 10.1016/j.neucom.2016.09.136
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lucas LER, 2014, EUR SIGNAL PR CONF, P11
   Monteiro R, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574670
   Monteiro RJS, 2017, IEEE J-STSP, V11, P1120, DOI 10.1109/JSTSP.2017.2721358
   Podder PK, 2016, NEUROCOMPUTING, V173, P1211, DOI 10.1016/j.neucom.2015.08.079
   Rerabek M., 2016, PROC ICME GRAND CHAL, P1
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tehrani M. P., 2013, JTC1SC29WG11 ISOIEC
   Türkan M, 2012, IEEE T IMAGE PROCESS, V21, P1885, DOI 10.1109/TIP.2011.2170700
   Wang G, 2016, IEEE T IMAGE PROCESS, V25, P5104, DOI 10.1109/TIP.2016.2603602
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Yang R, 2008, IEEE T VIS COMPUT GR, V14, P84, DOI 10.1109/70410
   Zhang QW, 2016, NEUROCOMPUTING, V188, P82, DOI 10.1016/j.neucom.2014.11.103
NR 38
TC 4
Z9 6
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31929
EP 31951
DI 10.1007/s11042-018-6255-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000019
DA 2024-07-18
ER

PT J
AU Meikap, S
   Jana, B
AF Meikap, Sudipta
   Jana, Biswapati
TI Directional PVO for reversible data hiding scheme with image
   interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel-value-ordering; Prediction-error
   expansion; Embedding capacity; Steganalysis; Steganographic attacks
AB Pixel Value Ordering (PVO) is an efficient data hiding scheme where pixels are ranked in ascending order within an image block and then modify minimum and maximum pixel value to embed secret data. The embedding capacity of existing PVO based data hiding schemes were limited to embed only two bits in a row of any block and unable to perform repeated embedding. To solve the existing problem, we have proposed a generalized directional PVO (DPVO) with varying block size. The original image is partitioned into blocks and then enlarged using image interpolation. A new parameter () is introduced and added with maximum pixel value and subtracted from minimum pixel value to maintain the order of the rank which is dependent on the size of the image block. To improve data hiding capacity, overlapped embedding has been considered in three different directions (1) Horizontal, (2) Vertical and (3) Diagonal of each block. Experiments show that the proposed scheme has a good margin of performance compared with the state-of-the-art methods. Several steganographic analysis deemed robust against several attacks.
C1 [Meikap, Sudipta] Hijli Coll, Dept Comp Sci, Paschim Medinipur 721306, W Bengal, India.
   [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Meikap, S (corresponding author), Hijli Coll, Dept Comp Sci, Paschim Medinipur 721306, W Bengal, India.
EM sudiptameikap@gmail.com; biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], USC SIPI IMAGE DATAB
   Balasubramanian C, 2014, MULTIMED TOOLS APPL, V73, P2223, DOI 10.1007/s11042-013-1640-4
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Jana Biswapati, 2016, International Journal of Network Security, V18, P633
   Jana B., 2016, Int. J. Electron. Inf. Eng, V5, P6
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P8805, DOI 10.1007/s11042-017-4775-x
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P763, DOI 10.1007/s11042-016-4230-4
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Jana B, 2016, OPTIK, V127, P3347, DOI 10.1016/j.ijleo.2015.12.055
   Kumar R, 2016, MULTIMED TOOLS APPL, V75, P241, DOI 10.1007/s11042-014-2289-3
   Lee SK, 2004, LECT NOTES COMPUT SC, V3333, P340
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu LC, 2016, INT C PATT RECOG, P1713, DOI 10.1109/ICPR.2016.7899883
   Liu LC, 2017, PATTERN RECOGN, V64, P314, DOI 10.1016/j.patcog.2016.10.034
   Liu LC, 2014, INT C PATT RECOG, P2619, DOI 10.1109/ICPR.2014.452
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Pal P, 2017, INT C COMP INT COMM, P511
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Turner LF, 1989, TURNER LF, V89, P8915
   University of California Berkeley, BERK SEGM DAT BENCHM
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Zhang H, 2016, IEEE INT SYMP SIGNAL, P1, DOI 10.1109/ISSPIT.2016.7885999
NR 37
TC 30
Z9 30
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31281
EP 31311
DI 10.1007/s11042-018-6203-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600051
DA 2024-07-18
ER

PT J
AU Saz, O
   Deena, S
   Doulaty, M
   Hasan, M
   Khaliq, B
   Milner, R
   Ng, RWM
   Olcoz, J
   Hain, T
AF Saz, Oscar
   Deena, Salil
   Doulaty, Mortaza
   Hasan, Madina
   Khaliq, Bilal
   Milner, Rosanna
   Ng, Raymond W. M.
   Olcoz, Julia
   Hain, Thomas
TI Lightly supervised alignment of subtitles on multi-genre broadcasts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multigenre broadcasts; Lightly supervised alignment; Language model
   adaptation; Subtitles
ID DEEP NEURAL-NETWORKS; SPEECH
AB This paper describes a system for performing alignment of subtitles to audio on multigenre broadcasts using a lightly supervised approach. Accurate alignment of subtitles plays a substantial role in the daily work of media companies and currently still requires large human effort. Here, a comprehensive approach to performing this task in an automated way using lightly supervised alignment is proposed. The paper explores the different alternatives to speech segmentation, lightly supervised speech recognition and alignment of text streams. The proposed system uses lightly supervised decoding to improve the alignment accuracy by performing language model adaptation using the target subtitles. The system thus built achieves the third best reported result in the alignment of broadcast subtitles in the Multi-Genre Broadcast (MGB) challenge, with an F1 score of 88.8%. This system is available for research and other non-commercial purposes through webASR, the University of Sheffield's cloud-based speech technology web service. Taking as inputs an audio file and untimed subtitles, webASR can produce timed subtitles in multiple formats, including TTML, WebVTT and SRT.
C1 [Saz, Oscar; Deena, Salil; Doulaty, Mortaza; Hasan, Madina; Khaliq, Bilal; Milner, Rosanna; Ng, Raymond W. M.; Hain, Thomas] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
   [Olcoz, Julia] Univ Zaragoza, Dept Elect Engn & Commun, Zaragoza, Spain.
C3 University of Sheffield; University of Zaragoza
RP Deena, S (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
EM s.deena@sheffield.ac.uk; T.Hain@sheffield.ac.uk
RI Milner, Rosanna/CAG-8026-2022
OI Milner, Rosanna/0000-0001-8924-0593; Hain, Thomas/0000-0003-0939-3464
FU EPSRC Programme Grant [EP/I031022/1]; EPSRC [EP/I031022/1] Funding
   Source: UKRI
FX This work was supported by the EPSRC Programme Grant EP/I031022/1
   (Natural Speech Technology)
CR Alvarez A, 2016, MULTIMED TOOLS APPL, V75, P10823, DOI 10.1007/s11042-015-2794-z
   [Anonymous], 2012, SIGNAL PROCESSING MA
   [Anonymous], 2007, ROBUST SPEECH RECOGN
   Bell P, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P687, DOI 10.1109/ASRU.2015.7404863
   Bell  P., 2015, ASRU 15
   Bordel G, 2012, P 13 ANN C INT SPEEC, P1840
   Braunschweiler N, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2222
   Chen X, 2014, INTERSPEECH, P641
   Chen X, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3511
   Cieri C, 1999, P 1999 DARPA BROADC
   Deena S, 2016, INTERSPEECH 16
   Dines J, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1213
   Federico M, 2014, MULTIMED TOOLS APPL, V72, P21, DOI 10.1007/s11042-012-1318-3
   Galliano S., 2006, LREC, P139
   Hain T, 2016, INTERSPEECH 16
   Hain T, 2016, P 17 ANN C INT SPEEC
   Hain T, 2012, IEEE T AUDIO SPEECH, V20, P486, DOI 10.1109/TASL.2011.2163395
   Hain T, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P504
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Katsamanis A., 2011, P WORKSH NEW TOOLS M, P44
   Klakow D, 1998, P 5 INT C SPOK LANG
   Lanchantin P, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P647, DOI 10.1109/ASRU.2015.7404857
   Larson M, 2013, P MEDIAEVAL 2013 MUL
   Long Y, 2013, P 14 ANN C INT SPEEC, P2187
   Matousek J, 2012, INT CONF ACOUST SPEE, P2385, DOI 10.1109/ICASSP.2012.6288395
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Milner R, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P632, DOI 10.1109/ASRU.2015.7404855
   Moreno P. J., 1998, ICSLP
   Novak Josef R, 2012, P 10 INT WORKSH FIN
   Olcoz J, 2016, P 17 ANN C INT SPEEC
   Pallett D, 1996, P 1996 DARPA SPEECH
   Povey Daniel, 2011, P 2011 IEEE AUT SPEE
   Ramírez J, 2004, SPEECH COMMUN, V42, P271, DOI 10.1016/j.specom.2003.10.002
   Richmond K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P1974
   Ryant N, 2013, INTERSPEECH, P728
   Saz O, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P624, DOI 10.1109/ASRU.2015.7404854
   Stan A, 2016, COMPUT SPEECH LANG, V35, P116, DOI 10.1016/j.csl.2015.06.006
   Stolcke A, 2002, INTERSPEECH, V2002, P2002
   Wen TH, 2013, P INT, P2703
   Williams GF, 2009, TECH REP
   Wrigley SN, 2011, P 12 INT FLOR IT, P3325
   Wrigley SN, 2011, P 12 INT FLOR IT, P3265
   Zelenak M, 2012, EURASIP J AUDIO SPEE, V19, P1
   Zhang PY, 2014, IEEE W SP LANG TECH, P141, DOI 10.1109/SLT.2014.7078564
NR 44
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30533
EP 30550
DI 10.1007/s11042-018-6050-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600018
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Yoganand, AV
   Kavida, AC
   Rukmanidevi
AF Yoganand, A. Vivek
   Kavida, A. Celine
   Rukmanidevi
TI Face detection approach from video with the aid of KPCM and improved
   neural network classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; FCM; Neural network
AB In recent years, the detection of a human face from the video has become an interesting research topic due to the video surveillance and other security issues. Efficient face detection from the video has become an immense need as it can provide various identity measures in the field of defense and other security-related areas. In our proposed method we have developed an efficient method of face detection to index a particular face from different video shots. The proposed method can be divided into Different modules. In the first module, human face from the video is extracted using segmentation technique. In our proposed method, we have used Kernel-based Possibilistic C-Means for segmentation purpose. The second module in our method is the feature extraction process where shape, LBP, and some geometrical features are extracted. The various shape features like area, circularity, and eccentricity are extracted. Once the feature values are extracted we track the particular face using forward tracking process. After the tracking process, we employ the classification technique. The classifier we utilized here is the improved neural network where the weights factors are optimized using the modified cuckoo search algorithm. The performance is compared with some existing works in order to prove the efficiency of our proposed method.
C1 [Yoganand, A. Vivek] Jayam Coll Engn & Technol, Dept Comp Sci & Engn, Dharmapuri, India.
   [Kavida, A. Celine] Veltech Multitech Coll Engn, Dept Phys, Madras, Tamil Nadu, India.
   [Rukmanidevi] RMD Engn Coll, Dept Comp Sci & Engn, Tiruvallur, India.
C3 Vel Tech Multi Tech Dr.Rangarajan Dr.Sakunthala Engineering College
RP Yoganand, AV (corresponding author), Jayam Coll Engn & Technol, Dept Comp Sci & Engn, Dharmapuri, India.
EM vivekyoganand0911@gmail.com
RI A, Celine Kavida/H-6953-2017; Dams, ruks/V-9152-2019
OI A, Celine Kavida/0000-0001-9154-9995; Dams, ruks/0000-0002-0153-6283
CR AL-Allaf O.N.A., 2014, International Journal of Multimedia Its Applications, V6, P1, DOI [10.5121/ijma.2014.6101, DOI 10.5121/IJMA.2014.6101]
   Atan O, 2013, IEEE J SEL TOPICS SI
   Bhatt HS, 2014, IEEE T INF FOREN SEC, V9, P1056, DOI 10.1109/TIFS.2014.2318433
   Chin T-J, 2005, P DIG IM COMP TECHN
   Choi JY, 2010, IEEE T CONSUM ELECTR, V56, P147, DOI 10.1109/TCE.2010.5439138
   Choi JY, 2012, IEEE T SYSTEMS MAN B, V42
   Gou GP, 2014, IET COMPUT VIS, V8, P347, DOI 10.1049/iet-cvi.2013.0025
   Ikeda O, 2005, P IEEE INT C MULT EX
   Kayal S, 2013, P 13 UK WORKSH COMP
   Lu J, 2006, P INT C COMP INT SEC, V2
   Arceda VEM, 2016, ELECTRON NOTES THEOR, V329, P5, DOI 10.1016/j.entcs.2016.12.002
   Ngo TD, 2008, P IEEE INT C SIGN IM
   Pandey S., 2014, International Journal of Computer Science and Information Technologies, V5, P4111
   Patil Shailaja A., 2013, INFORM ENG INT J IEI, V1, P31
   Sankaranarayanan AC, 2014, IEEE T IMAGE PROCESS, V23
   Tao J, 2008, P IEEE INT S CIRC SY
   Tsagkatakis G, 2009, P 16 IEEE INT C IM P
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Yoganand AV, 2015, INT J APPL ENG RES, V10
NR 19
TC 3
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31763
EP 31785
DI 10.1007/s11042-018-6191-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000011
DA 2024-07-18
ER

PT J
AU Zhang, SJ
   Liu, WX
AF Zhang, Shujun
   Liu, Wenxiao
TI Single image3D reconstruction based on control point grid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; Control point grid; Parameterized growing rule;
   Texture mapping
AB In order to construct 3D meshes from a single image quickly and intuitively, this paper presents a 3D reconstruction method based on control point grid. The key idea is to calculate the 2D control point grid of the target area and elevate each control point according to a parameterized 3D growing rule proposed from prior knowledge. First, the contour of the target object is divided into a major component and side components and the skeleton of each component is extracted. 2D control point grid is calculated combining the curvature and geometric feature of the contour and lifted into 3D space with corresponding height defined by parameter mapping. Finally, a complete 3D model is obtained after component combination and texturing. Experimental results show that this method can reasonably and efficiently recover the 3D shape of the target object while maintaining fine curvature and geometric features.
C1 [Zhang, Shujun; Liu, Wenxiao] Qingdao Univ Sci & Technol, Coll Informat Sci & Technol, Qingdao 266061, Peoples R China.
C3 Qingdao University of Science & Technology
RP Zhang, SJ (corresponding author), Qingdao Univ Sci & Technol, Coll Informat Sci & Technol, Qingdao 266061, Peoples R China.
EM lindazsj@163.com
FU Key Research & Development Plan Project of Shandong Province of China
   [2017GGX10127]; National Natural Science Foundations of China [61472196,
   61672305]; Natural Science Foundation of Shandong Province of China
   [ZR2014FM015]
FX This paper is supported by the Key Research & Development Plan Project
   of Shandong Province of China (No.2017GGX10127), National Natural
   Science Foundations of China (No.61472196 and No.61672305) and Natural
   Science Foundation of Shandong Province of China (No.ZR2014FM015).
CR Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   [Anonymous], 2009, P 6 EUR S SKETCH BAS, DOI DOI 10.1145/1572741.1572749]
   [Anonymous], 1998, Visual intelligence
   Baker T., 2001, P 19 INT MESH ROUNDT, P327
   Buchanan P., 2013, Proceedings of the international symposium on sketch-based interfaces and modeling, P5, DOI 10.1145/2487381.2487385
   Changqing Z, 2012, J COM CAD CG, V24, P1585
   Chen T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508378
   Cook MT, 2009, INTERACT COMPUT, V21, P201, DOI 10.1016/j.intcom.2009.05.004
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   Eberly D., 1998, Triangulation by ear clipping. Geometric Tools
   Entem E, 2015, COMPUT GRAPH-UK, V46, P221, DOI 10.1016/j.cag.2014.09.037
   Grosse R, 2010, P ICCV, V30, P2335
   Hershberger J., 1994, P 10 ANN S COMP GEOM, P383
   Ijiri T, 2006, COMPUT GRAPH FORUM, V25, P617, DOI 10.1111/j.1467-8659.2006.00981.x
   Jiang TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766927
   Miao Yongwei, 2015, Journal of Computer Aided Design & Computer Graphics, V27, P1637
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Oswald MR, 2012, PROC CVPR IEEE, P534, DOI 10.1109/CVPR.2012.6247718
   Oswald MR, 2011, P 2011 C INN SHAP AN
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   [束搏 Shu Bo], 2010, [计算机研究与发展, Journal of Computer Research and Development], V47, P549
   Toppe E., 2010, P AS C COMP VIS QUEE
   Wither J, 2009, COMPUT GRAPH FORUM, V28, P541, DOI 10.1111/j.1467-8659.2009.01394.x
   Xuejin C, 2008, THESIS
   Zanni C, 2013, COMPUT GRAPH FORUM, V32, P219, DOI 10.1111/cgf.12199
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zou CQ, 2015, COMPUT GRAPH-UK, V46, P130, DOI 10.1016/j.cag.2014.09.031
NR 28
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31875
EP 31893
DI 10.1007/s11042-018-6193-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000016
DA 2024-07-18
ER

PT J
AU Farajallah, M
   El Assad, S
   Deforges, O
AF Farajallah, Mousa
   El Assad, Safwan
   Deforges, Olivier
TI Cryptanalyzing an image encryption scheme using reverse 2-dimensional
   chaotic map and dependent diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptanalysis; Chosen plain-text attack; Chaos-based cryptosystem;
   Diffusion effect; Brute force attack; Key space
ID SECURITY; TRANSFORM; CIPHERS
AB In the recent literature, many research studies have proven that Known and Chosen plaintext attacks are very efficient tools that are widely used to cryptanalyze partially or completely some chaos-based and non-chaos cryptosystems. In this paper, we addressed some weaknesses in the first Zhang et al., cryptosystem "An image encryption scheme using reverse 2-dimensional chaotic map and dependent diffusion". First, we analyzed the encryption process of Zhang et al., and we found that the non-linear diffusion process can be removed because its argument is present in the ciphered image. Then, based on this observation we derived a partial cryptanalysis equation that removes the effect of the diffusion function and accordingly permits to recover the permuted version of the ciphered image. As a result of the previous operation, the brute-force attack became more suitable. In addition, we mounted a chosen plaintext attack based on a proposed chosen plain image. Consequently, the encryption key space is reduced or recovered for one round, also, the average values of NPCR and UCAI randomness parameters become small compared to the optimal values, and moreover, they are very low for specific pixel position attacks.
C1 [Farajallah, Mousa] Palestine Polytech Univ, Coll Informat Technol & Comp Engn, Hebron, Palestine.
   [El Assad, Safwan] Univ Nantes, Ecole Polytech, Rue Christian Pauc, F-44306 Nantes 3, France.
   [Deforges, Olivier] INSA Rennes, Rennes, France.
C3 Palestine Polytechnic University; Nantes Universite; Institut National
   des Sciences Appliquees de Rennes; Universite de Rennes
RP Farajallah, M (corresponding author), Palestine Polytech Univ, Coll Informat Technol & Comp Engn, Hebron, Palestine.
EM mousa_math@ppu.edu
RI Farajallah, Mousa/N-8399-2017
FU European Celtic-Plus project 4KREPROSYS - 4K ultraHD TV wireless REmote
   PROduction SYStems
FX This work is supported by the European Celtic-Plus project 4KREPROSYS -
   4K ultraHD TV wireless REmote PROduction SYStems.
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2008, Introduction to Modern Cryptography
   [Anonymous], 2001, Security Engineering: A Guide to Building Dependable Distributed Systems
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   El-Wahed M.A., 2008, P WORLD C ENG, V1, P2
   Ge X, 2011, PHYS LETT A, V375, P908, DOI 10.1016/j.physleta.2010.12.065
   Haleem MA, 2007, IEEE T DEPEND SECURE, V4, P313, DOI 10.1109/TDSC.2007.70214
   Healy SJ, 2007, US Patent, Patent No. [7,228,182, 7228182]
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Kadir R., 2010, PROC INT C COMPUT CO, P1
   Kahn D., 1996, The Codebreakers: The comprehensive history of secret communication from ancient times to the internet
   Karim L, 2014, T EMERG TELECOMMUN T, V25, P1028, DOI 10.1002/ett.2801
   Kavitha T., 2010, J INF ASSUR SECUR, V5, P31
   Li CQ, 2014, SIGNAL PROCESS-IMAGE, V29, P914, DOI 10.1016/j.image.2014.06.011
   Li CQ, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500752
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Liu H, 2014, OPT LASER TECHNOL, V56, P313, DOI 10.1016/j.optlastec.2013.09.012
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Nadeem A., 2005, Information and Communication Technologies, ICICT, V2005, P84, DOI DOI 10.1109/ICICT.2005.1598556
   Ngo HuyHoang., 2008, Fourteenth Americas Conference on Information Systems (ACMIS), page, P177
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Petitcolas F., 1883, CRYPTOGRAPHIE MILITA
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Singh S, 2000, CODE BOOK SCI SECREC, P402
   Solak E, 2011, INFORM SCIENCES, V181, P227, DOI 10.1016/j.ins.2010.09.009
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wang XY, 2011, OPT COMMUN, V284, P5804, DOI 10.1016/j.optcom.2011.08.053
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yaseen Q, 2018, MULTIMED TOOLS APPL, V77, P18249, DOI 10.1007/s11042-017-5288-3
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang LY, 2012, J SYST SOFTWARE, V85, P2077, DOI 10.1016/j.jss.2012.04.002
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhang YS, 2014, NONLINEAR DYNAM, V78, P235, DOI 10.1007/s11071-014-1435-9
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhao QC, 2009, APPL OPTICS, V48, P3515, DOI 10.1364/AO.48.003515
NR 56
TC 13
Z9 13
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28225
EP 28248
DI 10.1007/s11042-018-6015-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500020
DA 2024-07-18
ER

PT J
AU Li, X
   Sun, Y
AF Li, Xiang
   Sun, Yi
TI Joint structural similarity and entropy estimation for coded-exposure
   image restoration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coded-exposure; Smear length; Image restoration; Structural similarity;
   Entropy estimation
ID CAMERA
AB We address the image deblurring using coded exposure which can keep image content that may be lost by a traditional shutter. In the restoration of a coded exposure image, the automatic estimation of smear length is the key problem. Because the coded exposure image does not lose high frequency information of the image, the structural similarity compared with the original image is retained. In this paper, we propose a joint coarse to fine estimation method. By comparing structural similarity between the coded-exposure image and its restored image, the smear length can be roughly estimated first. And then the entropy of the restored image is further computed within a small range of the previously estimated smear length. An image that is restored with the wrong smear length will be far from the structure of the coded image that will have high entropy and low structure similarity with the coded exposure image.
C1 [Li, Xiang; Sun, Yi] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.
   [Li, Xiang] Dalian Ocean Univ, Sch Informat Engn, Dalian 116023, Liaoning, Peoples R China.
C3 Dalian University of Technology; Dalian Ocean University
RP Sun, Y (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Liaoning, Peoples R China.
EM lixiang@dlou.edu.cn; lslwf@dlut.edu.cn
CR Agrawal A, 2009, IEEE C COMP VIS PATT
   [Anonymous], 2009, IEEE INT C COMPUTATI
   Cho S, 2009, ACM T GRAPH YOK JAP
   Dai S., 2008, IEEE C COMP VIS PATT, P1
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Ding Y, 2010, EUR C COMP VIS, V6311, DOI [10.1007/978-3-642-15549-9-2, DOI 10.1007/978-3-642-15549-9-2]
   Don ML, 2017, APPL OPTICS, V56, pB142, DOI 10.1364/AO.56.00B142
   Feng W, 2017, APPL OPTICS, V56, P3831, DOI 10.1364/AO.56.003831
   Feng W, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030331
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Harshavardhan S, 2014, IND C MUMB IND 13 15
   Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254
   Holloway J, 2013, IEEE INT C COMP PHOT
   Huang K, 2013, MOTION BLUR IDENTIFI
   Jeon HG, 2017, INT J COMPUT VISION, V123, P269, DOI 10.1007/s11263-016-0976-4
   Jeon HG, 2017, IEEE T IMAGE PROCESS, V26, P2311, DOI 10.1109/TIP.2017.2675202
   Jeon HG, 2013, IEEE I CONF COMP VIS, P1001, DOI 10.1109/ICCV.2013.128
   Jeon HG, 2016, IEEE INT C COMP VIS
   Liu DY, 2014, IEEE T PATTERN ANAL, V36, P248, DOI 10.1109/TPAMI.2013.129
   McCloskey S, 2012, IEEE T PATTERN ANAL, V34, P2071, DOI 10.1109/TPAMI.2012.108
   Michaelides E.E., 2008, Open Thermodynamics Journal, V2, P7, DOI [DOI 10.2174/1874396X00802010007, 10.2174/1874396X00802010007]
   Raskar R, 2006, ACM SIGGR APH BOST M
   Shan Q, 2008, ACM T GRAPH ANG CAL
   Silva EA, 2007, PROC SPIE, V6579, DOI 10.1117/12.720087
   Tendero Y, 2016, RES MATH SCI, V3, DOI 10.1186/s40687-015-0051-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2004, C REC 37 AS C SIGN S
   Zhang J, 2015, BIOM CIRC SYST C ATL
   Zhang J, 2016, OPT EXPRESS, V24, P9013, DOI 10.1364/OE.24.009013
NR 32
TC 3
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29811
EP 29828
DI 10.1007/s11042-018-5773-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800036
DA 2024-07-18
ER

PT J
AU Sridhar, S
   Sudha, GF
AF Sridhar, Srividhya
   Sudha, Gnanou Florence
TI Circular meaningful shares based <i>(k, n)</i> two in one image secret
   sharing scheme for multiple secret images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Visual multiple secret sharing; Randomgrids;
   Polynomial image secret sharing
ID VISUAL CRYPTOGRAPHY; RANDOM GRIDS; CONTRAST; SHADOW
AB Two in One Image Secret Sharing Scheme (TiOISSS) is a cryptographic technique which encrypts a secret image into n shares and the shares are decoded in two different stages to reconstruct the secret image. In this paper, an enhanced (k, n) TiOISSS which uses circular shares instead of rectangular shares based on random grids that shares multiple secret images using noisy and meaningful shares is proposed. In addition, to verify the authenticity of the shared secret images, the proposed scheme shares an additional authentication message along with the secret images. Experimental results and performance analysis with 2 and 3 secret images shared demonstrate the effectiveness of proposed scheme compared to existing scheme.
C1 [Sridhar, Srividhya; Sudha, Gnanou Florence] Pondicheny Engn Coll, Dept Elect & Commun Engn, Puducheny, India.
C3 Pondicherry Engineering College
RP Sridhar, S (corresponding author), Pondicheny Engn Coll, Dept Elect & Commun Engn, Puducheny, India.
EM srividhya2207@gmail.com; gfsudha@pec.edu
RI Sudha, Gnanou Florence/GLU-3814-2022; SRIDHAR, SRIVIDHYA/AAH-6420-2020
OI Sudha, Gnanou Florence/0000-0002-5471-3255; 
CR Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P7865, DOI 10.1007/s11042-017-4680-3
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Feng J-B, 2008, J PATTERN RECOGNIT, V41, P3272
   Gutub Adnan Abdul-Aziz, 2013, IADIS International Conference Applied Computing 2013. Proceedings, P67
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub AA-A, 2012, INT C ADV COMP SCI A, P26
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Li P, 2018, J REAL-TIME IMAGE PR, V14, P41, DOI 10.1007/s11554-016-0621-z
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Sridhar Srividhya, 2015, J MULTIMED TOOLS APP, P1
   Srividhya S, 2016, J VIS COMMUN IMAGE R, V38, P284, DOI 10.1016/j.jvcir.2016.03.012
   Xu J, 2018, J NETW COMPUT APPL, V107, P113, DOI 10.1016/j.jnca.2018.01.014
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 30
TC 4
Z9 4
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28601
EP 28632
DI 10.1007/s11042-018-6019-0
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500034
DA 2024-07-18
ER

PT J
AU Alrjebi, MM
   Liu, WQ
   Li, L
AF Alrjebi, Mustafa M.
   Liu, Wanquan
   Li, Ling
TI Face recognition against illuminations using two directional multi-level
   threshold-LBP and DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Illumination; Local Binary Pattern; Multilevel fusion;
   DCT
ID PATTERN; NORMALIZATION; MODELS; IMAGE
AB In this paper, a new approach named as the Two Directional Multi-level Threshold-LBP Fusion (2D-MTLBP-F) is proposed to solve the problem of face recognition against illuminations. The proposed approach utilizes the Threshold Local Binary Pattern (TLBP) in combination with Discrete Cosine Transform (DCT). The utilization of LBP with different thresholds can produce different levels of information, which in turn can be used to improve performance for face recognition against illuminations. First, all images are normalised using a DCT normalisation technique in order to reduce negative effects of noise, blur or illumination. Secondly, the normalised images are transformed into 61 levels of TLBP with thresholds from -30 to 30 and then the normalised DCT image is fused into these TLBP layers as it contains a different type of information in frequency domain. Thirdly, in the training stage, the 2D-MTLBP-F model is trained by searching for the best combination among these 62 layers (61 TLBP +1 DCT image) based on an idea from two dimensional multiple color fusion (2D-MCF). Fourthly, in testing stage for face recognition, all testing and gallery images are transformed into the 2D-MTLBP-F model, and face recognition is performed using the sparse sensing classifier (SRC). Finally, extensive experimental results on five different databases show that the proposed approach has achieved the highest recognition rates in different lighting conditions as well as in uncontrolled environment for FRGC database. In comparison with TLBP and the recently proposed approach of Multi-Scale Logarithm Difference Edge-maps (MSLDE), the proposed approach also achieves much better results on all used datasets.
C1 [Alrjebi, Mustafa M.; Liu, Wanquan; Li, Ling] Curtin Univ, Dept Comp, Bentley, WA 6102, Australia.
C3 Curtin University
RP Alrjebi, MM (corresponding author), Curtin Univ, Dept Comp, Bentley, WA 6102, Australia.
EM mustafamm.alrjebi@postgrad.curtin.edu.au
RI Huang, Liping/KIB-4430-2024; Zhao, YuHan/KIE-0813-2024; zhu,
   yujie/KBC-4009-2024
OI liu, wanquan/0000-0003-4910-353X; Li, Ling/0000-0001-9722-9503
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   [Anonymous], BAHRIA U J INF COMMU
   [Anonymous], 2016, CHINESE C BIOMETRIC
   [Anonymous], 2008, 2008 3 INT C INF COM, DOI DOI 10.1109/ICTTA.2008.4530124
   [Anonymous], 6 IEEE INT C AUT FAC
   [Anonymous], DISCRETE COSINE TRAN
   [Anonymous], 2014, ARXIV14066947
   [Anonymous], P 27 INT C NEUR INF
   [Anonymous], 2015 INT C COMP COMM
   [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], 2015 INT C DIG IM CO
   [Anonymous], P 1998 IEEE COMP SOC
   [Anonymous], INT J ADV RES ELECT
   [Anonymous], CVPR 2001
   [Anonymous], ARXIV1501
   [Anonymous], 6 INT C IM GRAPH ICI
   [Anonymous], DESTINED BE DEFINITI
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Charfeddine M, 2014, MULTIMED TOOLS APPL, V70, P1521, DOI 10.1007/s11042-012-1167-0
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Faraji MR, 2015, IET COMPUT VIS, V9, P390, DOI 10.1049/iet-cvi.2014.0200
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R, 2008, 8 IEEE INT C AUT FAC, P1
   Haritha Dasari, 2012, International Journal of Modern Education and Computer Science, V4, P21, DOI 10.5815/ijmecs.2012.11.02
   Jeyhoon M, 2017, MULTIMED TOOLS APPL, V76, P3343, DOI 10.1007/s11042-016-3934-9
   Jun Meng, 2010, Proceedings of the 2010 IEEE International Conference on Granular Computing (GrC-2010), P352, DOI 10.1109/GrC.2010.72
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Kondo T, 1999, PATTERN RECOGN, V32, P1707, DOI 10.1016/S0031-3203(98)00176-9
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Li BY, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414560047
   Liu CC, 2007, J MACH LEARN RES, V8, P1165
   Martinez A., 1998, AR FACE DATABASE
   Perez Claudio A., 2009, 2009 International Symposium on Optomechatronic Technologies. ISOT 2009, P322, DOI 10.1109/ISOT.2009.5326048
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roy H, 2016, IEEE T INF FOREN SEC, V11, P1412, DOI 10.1109/TIFS.2016.2530043
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Shrivastava N, 2016, MULTIMED TOOLS APPL, V75, P6569, DOI 10.1007/s11042-015-2589-2
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiaohua Xie PC, 2008, IEEE C COMPUTER VISI, P1
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhao X, 2015, J INF SCI ENG, V31, P1711
   Zhong FJ, 2013, NEUROCOMPUTING, V119, P375, DOI 10.1016/j.neucom.2013.03.020
   Zhou LJ, 2014, J SYST SOFTWARE, V95, P209, DOI 10.1016/j.jss.2014.04.037
NR 51
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25659
EP 25679
DI 10.1007/s11042-018-5812-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400046
DA 2024-07-18
ER

PT J
AU Nguyen, TS
   Chang, CC
   Shih, TH
AF Thai-Son Nguyen
   Chang, Chin-Chen
   Shih, Tso-Hsien
TI Effective reversible image steganography based on rhombus prediction and
   local complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; tamper detection; fragile watermark; reversibility;
   rhombus prediction
ID TAMPER-DETECTION SCHEME; BTC-COMPRESSED IMAGES; DATA HIDING SCHEME;
   AUTHENTICATION SCHEME; FRAGILE WATERMARKING; ALGORITHM; RECOVERY
AB Reversible image steganography attracts much attention of researchers since such technique has ability to reconstruct the original version of the host image losslessly after image steganography. In this paper, we propose a new reversible image steganography based on rhombus prediction and local complexity. To maintain good quality of stego images and to achieve high accuracy of tamper detection, the local complexity of each pixel is first evaluated, then, the prediction error is calculated by using rhombus prediction for embedding the authentication code. Experimental results demonstrated that the proposed scheme has ability to recover the original version of the host images. In addition, the proposed scheme obtains better performance than previous schemes in terms of tamper detection and image quality.
C1 [Thai-Son Nguyen] Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Tra Vinh Provin, Vietnam.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Shih, Tso-Hsien] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 Tra Vinh University; Feng Chia University; National Chung Cheng
   University
RP Nguyen, TS (corresponding author), Tra Vinh Univ, Sch Engn & Technol, Tra Vinh, Tra Vinh Provin, Vietnam.
EM thaison@tvu.edu.vn; ccc@cs.ccu.edu.tw; jokergreem@gmail.com
RI Nguyen, Thai-Son/AGD-3594-2022; Chang, Ching-Chun/JAN-6210-2023
OI Nguyen, Thai-Son/0000-0001-7008-0462; 
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.01-2016.06]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.01-2016.06.
CR Chan CS, 2011, PATTERN RECOGN LETT, V32, P1679, DOI 10.1016/j.patrec.2011.07.023
   Chang CC, 2013, SCI WORLD J, DOI 10.1155/2013/717165
   Chen SY, 2008, IEEE T CIRC SYST VID, V18, P704, DOI 10.1109/TCSVT.2008.918801
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Hu J, 2015, COMPUT ELECTR ENG, V46, P447, DOI 10.1016/j.compeleceng.2015.04.014
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Stalling W., 2003, CRYPTOGRAPHY NETWORK
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Tian WX, 2013, DIGIT SIGNAL PROCESS, V23, P569
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
NR 26
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26449
EP 26467
DI 10.1007/s11042-018-5869-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500011
DA 2024-07-18
ER

PT J
AU Verma, R
   Pandey, R
AF Verma, Rajiv
   Pandey, Rajoo
TI Grey relational analysis based adaptive smoothing parameter for
   non-local means image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Denoising; Non-local means; Grey relational analysis; Smoothing
   parameter
ID MEANS ALGORITHM; SEARCH REGION; SELECTION
AB In non-local means (NLM) algorithm used for suppression of noise in digital images, the choice of smoothing or decay parameter is a critical issue, which affects the performance of NLM algorithm by influencing the amount of smoothing. Generally, the smoothing parameter in NLM algorithm is kept fixed for all pixels in an image, which provides blurring effects near important image details such as edges, textures etc. in an image. This paper presents a grey relational analysis based adaptive non-local means (GRANLM) algorithm to select an adaptive smoothing parameter for each pixel. It considers the grade of relations between reference patch and adjacent patches in a defined region centred at pixel using grey relational analysis (GRA). Experimental results on various standard images for different noise levels show that the proposed algorithm outperforms the traditional NLM algorithm and other NLM variants in terms of peak signal to noise ratio (PSNR), structural similarity index measure (SSIM), visual quality and method noise.
C1 [Verma, Rajiv; Pandey, Rajoo] Natl Inst Technol, Dept Elect & Commun Engn, Kurukshetra 136119, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Verma, R (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Kurukshetra 136119, Haryana, India.
EM rajiv6120043@nitkkr.ac.in; rajoo_pandey@nitkkr.ac.in
RI Verma, Dr. Rajiv/F-1330-2015; Verma, Dr. Rajiv/ADY-3318-2022
OI Verma, Dr. Rajiv/0000-0003-1873-0899; Verma, Dr.
   Rajiv/0000-0003-1873-0899
CR [Anonymous], IMAGE RESTORATION IN
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen QA, 2010, PATTERN RECOGN, V43, P4089, DOI 10.1016/j.patcog.2010.07.002
   Dai T, 2017, SIGNAL PROCESS, V137, P223, DOI 10.1016/j.sigpro.2017.02.005
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Vargas JID, 2016, INT CONF ELECTR COMM, P32, DOI 10.1109/CONIELECOMP.2016.7438548
   DENG JL, 1982, SYST CONTROL LETT, V1, P288, DOI 10.1016/S0167-6911(82)80025-X
   Feng DZ, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1385, DOI 10.1109/ICIA.2006.305956
   Ghosh S, 2017, IET IMAGE PROCESS, V11, P317, DOI 10.1049/iet-ipr.2016.0331
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Hu J, 2013, OPTIK, V124, P5639, DOI 10.1016/j.ijleo.2013.04.009
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   Kuo Y, 2008, COMPUT IND ENG, V55, P80, DOI 10.1016/j.cie.2007.12.002
   Li HJ, 2016, PATTERN RECOGN, V49, P237, DOI 10.1016/j.patcog.2015.05.028
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Nguyen MP, 2017, IEEE T IMAGE PROCESS, V26, P1637, DOI 10.1109/TIP.2017.2658941
   Pardo A, 2009, LECT NOTES COMPUT SC, V5856, P103, DOI 10.1007/978-3-642-10268-4_12
   Plataniotis KN, 1999, P IEEE, V87, P1601, DOI 10.1109/5.784243
   Qiao BM, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P470, DOI [10.1109/CIS.2016.0114, 10.1109/CIS.2016.113]
   Rajpoot N, 2012, PATTERN RECOGN, V45, P2938, DOI 10.1016/j.patcog.2012.01.023
   Salmon J, 2010, IEEE IMAGE PROC, P1929, DOI 10.1109/ICIP.2010.5650780
   Siddeq MM, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0007-6
   Tasdizen T, 2009, IEEE T IMAGE PROCESS, V18, P2649, DOI 10.1109/TIP.2009.2028259
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Verma R, 2015, ANNU IEEE IND CONF
   Verma R, 2018, MULTIMED TOOLS APPL, V77, P549, DOI 10.1007/s11042-016-4227-z
   Verma R, 2017, OPTIK, V147, P151, DOI 10.1016/j.ijleo.2017.08.075
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
   Xiao F, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.749
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zeng WL, 2017, MULTIMED TOOLS APPL, V76, P13239, DOI 10.1007/s11042-016-3753-z
NR 36
TC 7
Z9 9
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25919
EP 25940
DI 10.1007/s11042-018-5828-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400056
DA 2024-07-18
ER

PT J
AU Witwit, W
   Zhao, YF
   Jenkins, K
   Addepalli, S
AF Witwit, Wasnaa
   Zhao, Yifan
   Jenkins, Karl
   Addepalli, Sri
TI Global motion based video super-resolution reconstruction using discrete
   wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Image registration; Image reconstruction
ID HIGH-RESOLUTION IMAGE; EDGE-DIRECTED INTERPOLATION; MANY-CORE
   PROCESSORS; SUPER RESOLUTION; PARALLEL FRAMEWORK; SUBPIXEL MOTION;
   NONLOCAL MEANS; RESTORATION; ENHANCEMENT; ROBUST
AB Different from the existing super-resolution (SR) reconstruction approaches working under either the frequency-domain or the spatial- domain, this paper proposes an improved video SR approach based on both frequency and spatial-domains to improve the spatial resolution and recover the noiseless high-frequency components of the observed noisy low-resolution video sequences with global motion. An iterative planar motion estimation algorithm followed by a structure-adaptive normalised convolution reconstruction method are applied to produce the estimated low-frequency sub-band. The discrete wavelet transform process is employed to decompose the input low-resolution reference frame into four sub-bands, and then the new edge-directed interpolation method is used to interpolate each of the high-frequency sub-bands. The novelty of this algorithm is the introduction and integration of a nonlinear soft thresholding process to filter the estimated high-frequency sub-bands in order to better preserve the edges and remove potential noise. Another novelty of this algorithm is to provide flexibility with various motion levels, noise levels, wavelet functions, and the number of used low-resolution frames. The performance of the proposed method has been tested on three well-known videos. Both visual and quantitative results demonstrate the high performance and improved flexibility of the proposed technique over the conventional interpolation and the state-of-the-art video SR techniques in the wavelet- domain.
C1 [Witwit, Wasnaa] Cranfield Univ, Sch Aerosp Transport & Mfg, Through Life Engn Serv Inst, Cranfield MK43 0AL, Beds, England.
   [Zhao, Yifan; Addepalli, Sri] Cranfield Univ, Sch Aerosp Transport & Mfg, Through Life Engn Serv Ctr, Cranfield MK43 0AL, Beds, England.
   [Jenkins, Karl] Cranfield Univ, Sch Aerosp Transport & Mfg, Ctr Computat Engn Sci, Cranfield MK43 0AL, Beds, England.
C3 Cranfield University; Cranfield University; Cranfield University
RP Zhao, YF (corresponding author), Cranfield Univ, Sch Aerosp Transport & Mfg, Through Life Engn Serv Ctr, Cranfield MK43 0AL, Beds, England.
EM yifan.zhao@cranfield.ac.uk
RI Addepalli, Pavan/AAX-3709-2020; Zhao, Yifan/ADE-5116-2022; Jenkins,
   warren/AAC-5798-2022
OI Addepalli, Pavan/0000-0002-1466-7784; Zhao, Yifan/0000-0003-2383-5724; 
CR Allebach J, P 3 IEEE INT C IM PR, V3, P707
   Anbarjafari G, 2015, SIGNAL IMAGE VIDEO P, V9, P87, DOI 10.1007/s11760-012-0422-1
   Anbarjafari G, 2010, ETRI J, V32, P390, DOI 10.4218/etrij.10.0109.0303
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Bhandari AK, 2014, ISA T, V53, P1286, DOI 10.1016/j.isatra.2014.04.007
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Cui Z, 2014, LECT NOTES COMPUT SC, V8693, P49, DOI 10.1007/978-3-319-10602-1_4
   Demirel H, 2011, IEEE T IMAGE PROCESS, V20, P1458, DOI 10.1109/TIP.2010.2087767
   Demirel H, 2011, IEEE T GEOSCI REMOTE, V49, P1997, DOI 10.1109/TGRS.2010.2100401
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P123, DOI 10.1109/LGRS.2009.2028440
   Dong C, 2014, ECCV, V4, P184
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Eren PE, 1997, IEEE T IMAGE PROCESS, V6, P1446, DOI 10.1109/83.624970
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Iqbal MZ, 2013, IEEE GEOSCI REMOTE S, V10, P451, DOI 10.1109/LGRS.2012.2208616
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Izadpanahi S, 2013, SIGNAL PROCESS, V93, P2076, DOI 10.1016/j.sigpro.2013.01.006
   Izadpanahi S, 2012, IPR 2012, pA9, DOI [10.1049/cp.2012.0447, DOI 10.1049/CP.2012.0447]
   Izadpanahi S, 2013, DWT BASED RESOLUTION
   Jagadeesh P., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P759, DOI 10.1109/ICRTIT.2011.5972260
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2014, MULTIMED TOOLS APPL, V72, P2573, DOI 10.1007/s11042-013-1567-9
   Kamenicky J, 2016, FORENSIC SCI INT, V264, P153, DOI 10.1016/j.forsciint.2016.04.027
   Keren D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P742, DOI 10.1109/CVPR.1988.196317
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Li K, 2016, PATTERN RECOGN, V51, P59, DOI 10.1016/j.patcog.2015.08.008
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Lucchese L, 2000, IEEE T SIGNAL PROCES, V48, P1769, DOI 10.1109/78.845934
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Marcel B., 1997, Traitement du Signal, V14, P135
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   PELEG S, 1987, PATTERN RECOGN LETT, V5, P223, DOI 10.1016/0167-8655(87)90067-5
   Pham TQ, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/83268
   Robinson M.D., 2010, SUPER RESOLUTION IMA, P383
   Satiro J, 2015, INT CONF IMAG PROC, P55, DOI 10.1109/IPTA.2015.7367096
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Temizel A., 2007, P IEEE INT C IM PROC, V5, pV
   Ten Daubechies I., 1992, lecture on wavelets
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   TOM BC, 1994, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.1994.413745
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Witwit W, 2016, GLOBAL J COMP SCI TE, V16, P1
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang LP, 2010, SIGNAL PROCESS, V90, P848, DOI 10.1016/j.sigpro.2009.09.002
   Zhang XP, 2001, IEEE T NEURAL NETWOR, V12, P567, DOI 10.1109/72.925559
   Zhangyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301266
NR 66
TC 9
Z9 9
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27641
EP 27660
DI 10.1007/s11042-018-5941-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500062
OA hybrid
DA 2024-07-18
ER

PT J
AU Bonny, T
   Rabie, T
   Hafez, AHA
AF Bonny, Talal
   Rabie, Tamer
   Hafez, A. H. Abdul
TI Multiple histogram-based face recognition with high speed FPGA
   implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Gamma correction; Performance; Hardware accelerator;
   FPGA
AB Face recognition is an algorithm that is capable of identifying or verifying a query face from multiple faces in the enrollment database. It poses a challenging problem in the field of image analysis and computer vision, especially for applications that deal with video sequences, face re-identification, or operate on intensity images and require fast processing. In this work, we introduce a high speed face recognition technique along with a high speed FPGA implementation. It uses a new similarity measure to estimate the distance between the query face and each of the database face images. The distance metric is the sum of the standard deviations between multiple histograms, which are calculated from each row of the query and database images. The lowest distance score refers to the database face that matches the query. The proposed technique is independent from the ambient illumination and outperforms the well-known face recognition algorithm "Eigenfaces" (it performs the face recognition 16 x faster when both algorithms run on the same platform). Furthermore, we exploit data parallelism in our proposed algorithm to design a hardware accelerator and to implement it on an FPGA prototyping board. The results show 10x execution time improvement in comparison to the software version.
C1 [Bonny, Talal; Rabie, Tamer] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
   [Hafez, A. H. Abdul] Hasan Kalyoncu Univ, Gaziantep, Turkey.
C3 University of Sharjah; Hasan Kalyoncu University
RP Bonny, T (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM tbonny@sharjah.ac.ae; trabie@sharjah.ac.ae; abdul.hafez@hku.edu.tr
RI ABDULHAFIZ, Abdul Hafiz/IZQ-4511-2023; Bonny, Talal/HLX-3107-2023;
   Hafez, A. H. Abdul/AAG-5137-2020
OI Bonny, Talal/0000-0003-1111-0304
CR [Anonymous], 2000, INT CIVIL AVIATION O
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bateux Q, 2017, IEEE ROBOT AUTOM LET, V2, P80, DOI 10.1109/LRA.2016.2535961
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Beheshti I, 2017, J ALZHEIMERS DIS, V55, P1571, DOI 10.3233/JAD-160850
   Cha SH, 2002, PATTERN RECOGN, V35, P1355, DOI 10.1016/S0031-3203(01)00118-2
   Chengzhe Li, 2016, ACM SIGARCH Computer Architecture News, V44, P80, DOI 10.1145/3039902.3039917
   Demirel H, 2008, IEEE SIGNAL PROC LET, V15, P537, DOI 10.1109/LSP.2008.926729
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Georghiades A., 1997, CTR COMPUTATIONAL VI, V2
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Inc X, 2014, 7 SER FPGAS OV
   Kar A, 2017, MULTIMED TOOLS APPL, V76, P19211, DOI 10.1007/s11042-017-4579-z
   Leung HY, 2015, J REAL-TIME IMAGE PR, V10, P135, DOI 10.1007/s11554-012-0263-8
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   PHILLIPS J, 2003, IEEE INT WORKSH AN M
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Salcic Z, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2435227.2435254
   Savvides M, 2004, INT C PATT RECOG, P810
   Senouci B, 2016, J REAL-TIME IMAGE PR, V12, P649, DOI 10.1007/s11554-014-0456-4
   Shan Y, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584659
   Smitha KG, 2015, MED BIOL ENG COMPUT, V53, P1221, DOI 10.1007/s11517-015-1346-z
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Pham TTT, 2017, IMAGE VISION COMPUT, V59, P44, DOI 10.1016/j.imavis.2016.10.010
   Tian L, 2016, MULTIMED TOOLS APPL, V76, P13271
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2490824
   Xilinx, 2016, VIV DES SUIT HLX ED
   Xilinx I, 2012, AXI REF GUID, V14
   Yin D.B. M., P 11 INT C UBIQUITOU, DOI DOI 10.1145/3022227.3022247
NR 32
TC 17
Z9 17
U1 4
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24269
EP 24288
DI 10.1007/s11042-018-5647-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900052
DA 2024-07-18
ER

PT J
AU Malawski, F
   Galka, J
AF Malawski, Filip
   Galka, Jakub
TI System for multimodal data acquisition for human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data acquisition; Data processing; Human-machine interaction; Multimedia
   databases; Multi-sensor systems
ID HUMAN-COMPUTER INTERACTION; GESTURE RECOGNITION; TRACKING; NUMBER
AB Multimodal data is being used more widely for human action recognition nowadays due to the progress of machine learning methods and the development of new types of sensors. The acquisition of the data required by such solutions is often troublesome, and it is difficult to find the proper tools for this process. In this paper, we present a new toolkit for multimodal acquisition. We address and discuss issues concerning the synchronization of data from multiple sensors, the optimization of the initial processing of raw data, and the design of the user interface for efficiently recording large databases. The system was verified in a setup consisting of three types of sensors - a Kinect 2, two PS3Eye cameras, and an accelerometer glove. The accuracy of the synchronization and performance of the initial processing proved to be suitable for human action acquisition and recognition. The system was used for the acquisition of an extensive database of sign language gestures. User feedback indicated the recording process to be efficient, which is also evaluated in the paper. The system is publicly available, both in the form of a standalone application as well as source code, and can be easily customized to any type of sensor setup.
C1 [Malawski, Filip] AGH Univ Sci & Technol, Dept Comp Sci, Krakow, Poland.
   [Galka, Jakub] AGH Univ Sci & Technol, Dept Elect, Krakow, Poland.
C3 AGH University of Krakow; AGH University of Krakow
RP Malawski, F (corresponding author), AGH Univ Sci & Technol, Dept Comp Sci, Krakow, Poland.
EM fmal@agh.edu.pl; jgalka@agh.edu.pl
RI Malawski, Filip/J-3479-2018; ARSLAN, Okan/AAA-3232-2020
FU Polish National Centre for Research and Development Applied Research
   Program [PBS2/B3/21/2013]
FX This work was supported by the Polish National Centre for Research and
   Development Applied Research Program under Grant PBS2/B3/21/2013 titled:
   "Virtual sign language translator."
CR Antonakaki P, 2009, SIGNAL PROCESS, V89, P1723, DOI 10.1016/j.sigpro.2009.03.016
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Chang KI, 2003, 2003 IE INT SOI C P, DOI [10.1109/AMFG.2003.1240842, DOI 10.1109/AMFG.2003.1240842]
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Cheung YM, 2015, IEEE T HUM-MACH SYST, V45, P419, DOI 10.1109/THMS.2015.2400442
   Cholewa M, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P499, DOI 10.1109/ACPR.2015.7486553
   Cholewa M, 2013, PATTERN RECOGN LETT, V34, P574, DOI 10.1016/j.patrec.2012.12.002
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dinh DL, 2016, MULTIMED TOOLS APPL, V75, P1333, DOI 10.1007/s11042-014-2370-y
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   García J, 2013, IEEE T SYST MAN CY-S, V43, P606, DOI 10.1109/TSMCA.2012.2220540
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Hg RI, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P42, DOI 10.1109/SITIS.2012.17
   Hoda M, 2018, MULTIMED TOOLS APPL, V77, P1885, DOI 10.1007/s11042-016-4274-5
   Holte MB, 2012, IEEE J-STSP, V6, P538, DOI 10.1109/JSTSP.2012.2196975
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Hwang BW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P243
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Kepski M, 2012, LECT NOTES ARTIF INT, V7267, P266, DOI 10.1007/978-3-642-29347-4_31
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Lazzeri N, 2014, J HUM-ROBOT INTERACT, V3, P1, DOI 10.5898/JHRI.3.2.Lazzeri
   Li LJ, 2017, MULTIMED TOOLS APPL, V76, P13953, DOI 10.1007/s11042-016-3789-0
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Malawski F, 2014, CHALLENGES MOD TECHN, V5, P12
   Malawski F, 2016, SIG P ALGO ARCH ARR, P51, DOI 10.1109/SPA.2016.7763586
   Malawski F, 2014, LECT NOTES COMPUT SC, V8610, P395, DOI 10.1007/978-3-319-09912-5_33
   Mendels O, 2014, IEEE T SYST MAN CY-S, V44, P1461, DOI 10.1109/TSMC.2014.2329652
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Michel M, 2006, P 4 ACM INT WORKSH V, P3, DOI 10.1145/1178782.1178785
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Plantard P, 2017, MULTIMED TOOLS APPL, V76, P4291, DOI 10.1007/s11042-016-3546-4
   Premaratne P, 2013, NEUROCOMPUTING, V116, P242, DOI 10.1016/j.neucom.2011.11.039
   Sako S, 2016, COMM COM INF SC, V618, P130, DOI 10.1007/978-3-319-40542-1_21
   Sha T, 2011, NEUROCOMPUTING, V74, P2135, DOI 10.1016/j.neucom.2011.01.008
   Song W, 2017, MULTIMED TOOLS APPL, V76, P11159, DOI 10.1007/s11042-015-2986-6
   Tenorth Moritz, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1089, DOI 10.1109/ICCVW.2009.5457583
   Uddin MZ, 2015, MULTIMED TOOLS APPL, V74, P3675, DOI 10.1007/s11042-013-1793-1
   Vadakkepat P, 2008, IEEE T IND ELECTRON, V55, P1385, DOI 10.1109/TIE.2007.903993
   Wu QX, 2013, IEEE T SYST MAN CY-S, V43, P875, DOI 10.1109/TSMCA.2012.2226575
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yang JC, 2016, MULTIMED TOOLS APPL, V75, P17501, DOI 10.1007/s11042-016-3313-6
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
NR 50
TC 7
Z9 7
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23825
EP 23850
DI 10.1007/s11042-018-5696-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900033
DA 2024-07-18
ER

PT J
AU Rajput, AS
   Raman, B
AF Rajput, Amitesh Singh
   Raman, Balasubramanian
TI CryptoCT: towards privacy preserving color transfer and storage over
   cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color transfer; Homomorphic encryption; Encrypted domain processing;
   Cloud computing
ID ENCRYPTION ALGORITHM; PERMUTATION
AB Current trend toward cloud computing coupled with emerging technologies such as high definition images/videos and 360-degree videos, has led the requirement of performing color transfer remotely by third party servers. However, users are always concerned about storing and processing their personal images over the cloud. Addressing this problem, we propose CryptoCT, a novel approach for privacy preserving color transfer and storage over third party cloud infrastructures. Paillier cryptosystem is employed in a manner that secret images can be processed for color transfer without revealing any information. Unlike the previous methods which involve multiple cloud servers, we use a single cloud server to accomplish the task of encrypted domain color transfer. We show that same color transfer effects as of the existing methods in plain domain are achieved in encrypted domain using our approach. To the best of our knowledge, CryptoCT is among the first known ventures to perform the task of color transfer in encrypted domain. Experimental results and security analysis validates the correctness of our approach.
C1 [Rajput, Amitesh Singh; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttarakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Rajput, AS (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttarakhand, India.
EM asr88.dcs2015@iitr.ac.in
FU Information Security Education and Awareness (ISEA) Project (phase II),
   Deity, Government of INDIA
FX This work was supported by Information Security Education and Awareness
   (ISEA) Project (phase II), Deity, Government of INDIA.
CR Aljawarneh Shadi, 2011, Network Security, V2011, P12, DOI 10.1016/S1353-4858(11)70026-5
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   Aljawarneh SA, 2017, FUTURE GENER COMP SY, V74, P385, DOI 10.1016/j.future.2016.10.005
   Aljawarneh SA, 2016, INT J INTELL INF TEC, V12, P12, DOI 10.4018/IJIIT.2016040102
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   [Anonymous], IM PROC SERV DEV
   [Anonymous], THESIS
   [Anonymous], IM VID MAN CLOUD
   [Anonymous], MULTIMEDIA TOOLS APP
   Ayoup AM, 2016, MULTIMED TOOLS APPL, V75, P17171, DOI 10.1007/s11042-015-2985-7
   Chu K.-Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P597
   Finlayson GD, 2015, IEEE T IMAGE PROCESS, V24, P1460, DOI 10.1109/TIP.2015.2405336
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Hu XJ, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886777
   Hwang Y, 2014, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2014.427
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Lathey A, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2656205
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mohanty M, 2013, IEEE INT CON MULTI
   Mohanty M, 2016, MULTIMED TOOLS APPL, V75, P6207, DOI 10.1007/s11042-015-2567-8
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Rabin J, 2014, IEEE IMAGE PROC, P4852, DOI 10.1109/ICIP.2014.7025983
   Rajput Amitesh Singh, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P291, DOI 10.1109/ICMEW.2017.8026304
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Rezai A., 2011, 2011 World Congress on Internet Security (WorldCIS-2011), P192
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Skiljan I., Irfanview
   Song ZC, 2017, IEEE T MULTIMEDIA, V19, P702, DOI 10.1109/TMM.2016.2631123
   Soumya T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, INFORMATICS, COMMUNICATION AND ENERGY SYSTEMS (SPICES)
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wong WK, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P139
   Xiao Y, 2013, IEEE T MULTIMEDIA, V15, P549, DOI 10.1109/TMM.2012.2233725
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202
NR 37
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24223
EP 24245
DI 10.1007/s11042-018-5729-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900050
DA 2024-07-18
ER

PT J
AU Wang, D
   wan, SH
   Guizani, N
AF Wang, Dan
   wan, Shaohua
   Guizani, Nadra
TI Context-based probability neural network classifiers realized by genetic
   optimization for medical decision making
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical decision making; Extraction of features; Probabilistic neural
   network (PNN); Genetic algorithm
ID AIDED DIAGNOSIS SYSTEM; FAULT-DIAGNOSIS; BREAST-CANCER; EXPERT-SYSTEM;
   FUZZY-LOGIC
AB In this paper, we proposed context-based probability neural network (CPNN) classifiers for solving a medical decision making problems. The concept of "contexts" coming from the clustering research area is explored here to construct the second layer of probability neural network classifiers. Furthermore, genetic algorithm is used to optimize the structure parameters when designing the proposed CPNN. In contrast to the known probability neural networks, the proposed CPNN archive a better accuracy classification rate. Several known data sets are utilized to evaluate the performance of CPNN. Experimental results demonstrate that the relationship between the selected features and disease are more apparent in comparison with the conventional neural network models.
C1 [Wang, Dan] Tianjin Univ Sci & Technol, Sch Comp Sci & Informat Engn, Tianjin, Peoples R China.
   [wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Hubei, Peoples R China.
   [Guizani, Nadra] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
C3 Tianjin University Science & Technology; Zhongnan University of
   Economics & Law; Purdue University System; Purdue University
RP wan, SH (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Hubei, Peoples R China.
EM wanghzc@163.com; shaohua.wan@ieee.org; nguizani@purdue.edu
RI Wan, Shaohua/B-9243-2014; Wan, Shaohua/L-8492-2019
OI Wan, Shaohua/0000-0001-7013-9081; 
FU Foundation of Educational Commission of Tianjin City, China [20140803];
   Innovation Foundation for Young Teachers of Tianjin University of
   Science and Technology, China [2014CXLG30]
FX This work was supported by the Foundation of Educational Commission of
   Tianjin City, China (Grant No. 20140803), supported by the Innovation
   Foundation for Young Teachers of Tianjin University of Science and
   Technology, China (Grant No. 2014CXLG30).
CR Miranda GHB, 2015, COMPUT BIOL MED, V64, P334, DOI 10.1016/j.compbiomed.2014.10.006
   Calle-Alonso F, 2013, COMPUT METH PROG BIO, V112, P104, DOI 10.1016/j.cmpb.2013.05.029
   Chen M, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600410CM
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cheung N., 2001, THESIS U QUEENLAND
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Gadewadikar J., 2010, AFRICAN J MATH COMPU, V3, P225
   Ghosh P, 2016, NEUROCOMPUTING, V195, P181, DOI 10.1016/j.neucom.2015.09.123
   Huang W, 2018, IEEE T NEUR NET LEAR, V29, P3452, DOI 10.1109/TNNLS.2017.2729589
   Huang W, 2017, IEEE T FUZZY SYST, V25, P1329, DOI 10.1109/TFUZZ.2016.2612267
   Huang W, 2016, IEEE T INTELL TRANSP, V17, P3194, DOI 10.1109/TITS.2016.2543262
   Huang W, 2012, IEEE T COMMUN, V60, P3376, DOI 10.1109/TCOMM.2012.090512.100570
   Huang W, 2011, IEEE T ENG MANAGE, V58, P377, DOI 10.1109/TEM.2010.2063707
   Karar ME, 2016, COMPUT MED IMAG GRAP, V50, P31, DOI 10.1016/j.compmedimag.2014.09.005
   Mei JP, 2010, PATTERN RECOGN, V43, P1964, DOI 10.1016/j.patcog.2009.12.007
   Ozcift A, 2012, J MED SYST, V36, P2141, DOI 10.1007/s10916-011-9678-1
   Pedrycz W, 1998, IEEE T NEURAL NETWOR, V9, P601, DOI 10.1109/72.701174
   Podgorelec Vili, 2002, J Med Syst, V26, P445, DOI 10.1023/A:1016409317640
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   POGORELOV K, 2017, MULTIMED TOOLS APPL, V76, DOI DOI 10.1007/s11042-017-4989-y
   Polat K., 2015, P TURK S ART INT NEU
   Shi XB, 2016, IEEE ACCESS, V4, P7074, DOI 10.1109/ACCESS.2016.2614541
   Tipping ME, 2000, ADV NEUR IN, V12, P652
   Wu JD, 2008, EXPERT SYST APPL, V34, P2704, DOI 10.1016/j.eswa.2007.05.010
   Wu JD, 2007, EXPERT SYST APPL, V33, P1063, DOI 10.1016/j.eswa.2006.08.011
   Yang BS, 2004, MECH SYST SIGNAL PR, V18, P645, DOI 10.1016/S0888-3270(03)00073-6
   Zarinbal M, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0311-6
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhao QL, 2017, J SYST ARCHITECT, V72, P61, DOI 10.1016/j.sysarc.2016.08.003
NR 31
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21995
EP 22006
DI 10.1007/s11042-018-5631-3
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500011
DA 2024-07-18
ER

PT J
AU Zarepour-Ahmadabadi, J
   Shiri-Ahmadabadi, M
   Latif, A
AF Zarepour-Ahmadabadi, Jamal
   Shiri-Ahmadabadi, MohammadEbrahim
   Latif, Alimohammad
TI A cellular automata-based multi-stage secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Steganograph; Histogram preserving; Visual
   quality; Multi-stage image sharing; Multi-images sharing
ID STEGANOGRAPHY
AB A new Multi-Stage Multi-Secret Image Sharing (MSMSIS) scheme, based on polynomial sharing and cellular automata, is proposed in this paper. The proposed scheme shares multiple secret images among a number of players. The shares and the authentication strings, produced by a cryptographic hash function, are then embedded in cover images by an XOR-based operation in such a way that visual and statistical quality of covers are preserved as much as possible. A particular type of cellular automata is used to guarantee that the secrets are only recovered according to a pre-specified order. The scheme is multiuse, since some parameters are distributed only once and used multiple times. The scheme is verifiable as well, because a cryptographic hash function is used in each stage for each secret image separately. Generality of our scheme also implies that it can be applied on a heterogeneous set of different secret formats, where each secret has its own access structure. Based on our experiments, the PSNR of the proposed method is improved almost 11 percent compared to the average PSNR of the previous similar schemes.
C1 [Zarepour-Ahmadabadi, Jamal; Shiri-Ahmadabadi, MohammadEbrahim] Amirkabir Univ Technol, Fac Math & Comp Sci, Dept Comp Sci, Tehran Polytech, Tehran, Iran.
   [Latif, Alimohammad] Yazd Univ, Dept Comp Engn, Yazd, Iran.
C3 Amirkabir University of Technology; University of Yazd
RP Shiri-Ahmadabadi, M (corresponding author), Amirkabir Univ Technol, Fac Math & Comp Sci, Dept Comp Sci, Tehran Polytech, Tehran, Iran.
EM zarepourjamal@gmail.com; Shiri@aut.ac.ir; alatif@yazd.ac.ir
RI Latif, AliMohammad/AAA-8242-2022
OI Latif, AliMohammad/0000-0002-0697-4952
CR Adamatzky A., 2012, Collision-Based Computing
   Aho AV., 1974, DESIGN ANAL COMPUTER
   [Anonymous], 2002, NEW KIND SCI
   Belfedhal Alaa Eddine, 2015, International Journal of Computer Network and Information Security, V7, P31, DOI 10.5815/ijcnis.2015.06.04
   Brandt SA, 2000, NEUROIMAGE, V11, pS745
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chang CC, 2014, SIGNAL PROCESS, V99, P159, DOI 10.1016/j.sigpro.2013.12.022
   Chen YR, 2016, MULTIMED TOOLS APPL, V75, P13913, DOI 10.1007/s11042-015-2734-y
   da Silva NR, 2016, INFORM SCIENCES, V370, P33, DOI 10.1016/j.ins.2016.07.005
   Deshmukh M, 2016, IEEE 30 INT C ADV IN, P2016
   Di Lena P, 2014, INFORM SCIENCES, V287, P13, DOI 10.1016/j.ins.2014.07.007
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Fatemi M, 2014, IET INFORM SECUR, V8, P224, DOI 10.1049/iet-ifs.2013.0046
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Harn L, 2016, INFORM SCIENCES, V367, P209, DOI 10.1016/j.ins.2016.06.006
   HE J, 1994, ELECTRON LETT, V30, P1591, DOI 10.1049/el:19941076
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hu WT, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/849768
   Hu WT, 2012, SECUR COMMUN NETW, V5, P1267, DOI 10.1002/sec.567
   Hua W, 2017, MULTIMED TOOLS APPL, V76, P7087, DOI 10.1007/s11042-016-3364-8
   Jeon J-C, 2013, ONE WAY HASH FUNCTIO, P21
   Jeyaram B, 2016, SECURITY COMMUNICATI
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Ma Y, 2010, COMPUT VIS IMAGE UND, V114, P981, DOI 10.1016/j.cviu.2010.03.006
   McIntosh H. V, 2009, ONE DIMENSIONAL CELL
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qazanfari K, 2014, INFORM SCIENCES, V277, P90, DOI 10.1016/j.ins.2014.02.007
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tiplea FL, 2016, INFORM SCI
   Uguz S, 2016, APPL MATH MODELLING
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Wuensche A., 1992, Global Dynamics of Cellular Automata: An Atlas of Basin of Attraction Fields of One-Dimensional Cellular Automata
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
NR 43
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24073
EP 24096
DI 10.1007/s11042-018-5717-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900043
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Muhammad, K
   Tang, CS
AF Zhang, Yu-Dong
   Muhammad, Khan
   Tang, Chaosheng
TI Twelve-layer deep convolutional neural network with stochastic pooling
   for tea category classification on GPU platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Stochastic pooling; Data augmentation; Tea
   category classification; Stochastic gradient descent with momentum
ID IDENTIFICATION
AB Automatic tea-category identification is an important topic in factories and supermarkets. Traditional methods need to extract features from tea images manually, which may not be optimal for tea images classification. To avoid the time consuming efforts of handcrafted features extraction, this study proposed a new method combining convolutional neural network (CNN) with stochastic pooling. We collected 900 tea images of Oolong, green, and black teas, with 300 images for each category. The data augmentation method was used over the training set. We employed stochastic gradient descent with momentum (SGDM) to train the CNN. The experiments showed that a 12-layer CNN gives a good result. The sensitivities of Oolong, green, and black tea are 99.5%, 97.5%, and 98.0%, respectively. The overall accuracy of all three-tea categories is 98.33%. The stochastic pooling gives better results than maximum pooling and average pooling. The optimal number of convolutional layer for this task is 5. In addition, GPU has a 175x acceleration in training set and a 122x acceleration in test set, compared to CPU platform.
C1 [Zhang, Yu-Dong] Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.
   [Zhang, Yu-Dong; Tang, Chaosheng] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Muhammad, Khan] Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
C3 University of Leicester; Henan Polytechnic University; Sejong University
RP Zhang, YD (corresponding author), Univ Leicester, Dept Informat, Leicester LE1 7RH, Leics, England.; Zhang, YD; Tang, CS (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.; Muhammad, K (corresponding author), Sejong Univ, Digital Contents Res Inst, Seoul, South Korea.
EM yudongzhang@ieee.org; khanmuhammad@sju.ac.kr; tcs@hpu.edu.cn
RI Tang, Chaosheng/AGX-8816-2022; Khan, Muhammad/IXN-8470-2023; Muhammad,
   Khan/L-9059-2016; Zhang, Yudong/I-7633-2013
OI Tang, Chaosheng/0000-0001-6923-855X; Muhammad, Khan/0000-0003-4055-7412;
   Muhammad, Khan/0000-0002-5302-1150; Zhang, Yudong/0000-0002-4870-1493
FU Open fund of Key Laboratory of Guangxi High Schools Complex System and
   Computational Intelligence [2016CSCI01]; Natural Science Foundation of
   China [61502254, 61602250]; Program of Natural Science Research of
   Jiangsu Higher Education Institutions [15KJB470010, 16KJB520025];
   Natural Science Foundation of Jiangsu Province [BK20150983]
FX This paper is supported by Open fund of Key Laboratory of Guangxi High
   Schools Complex System and Computational Intelligence (2016CSCI01),
   Natural Science Foundation of China (61502254, 61602250), Program of
   Natural Science Research of Jiangsu Higher Education Institutions
   (15KJB470010, 16KJB520025), Natural Science Foundation of Jiangsu
   Province (BK20150983).
CR Altun M, 2017, APPL SOFT COMPUT, V58, P756, DOI 10.1016/j.asoc.2017.04.032
   Barushka A, 2016, LECT NOTES COMPUT SC, V10037, P65, DOI 10.1007/978-3-319-49130-1_6
   Chen Q, 2008, T ASABE, V51, P623, DOI 10.13031/2013.24363
   Chen QS, 2013, J PHARMACEUT BIOMED, V84, P77, DOI 10.1016/j.jpba.2013.05.046
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   de Almeida CRF, 2016, IEEE T INTELL TRANSP, V17, P2262, DOI 10.1109/TITS.2016.2516444
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Ferreira A, 2017, EXPERT SYST APPL, V84, P1, DOI 10.1016/j.eswa.2017.04.053
   Ferreira MD, 2018, EXPERT SYST APPL, V94, P205, DOI 10.1016/j.eswa.2017.10.052
   Gorriz J. M., 2016, FRONT COMPUT NEUROSC, V10
   Gummeson A, 2017, PROC SPIE, V10140, DOI 10.1117/12.2253620
   Jia WJ, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0814-4
   Jian W, 2010, APPL ENG AGRIC, V26, P639
   Kabani A, 2016, LECT NOTES COMPUT SC, V9730, P358, DOI 10.1007/978-3-319-41501-7_41
   Li XL, 2017, SPECTROSC SPECT ANAL, V37, P1081, DOI 10.3964/j.issn.1000-0593(2017)04-1081-05
   Lu SY, 2018, MULTIMED TOOLS APPL, V77, P3715, DOI 10.1007/s11042-016-3559-z
   Martinez-Pabon F, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/8593173
   Pezeshk A, 2017, IEEE T MED IMAGING, V36, P1005, DOI 10.1109/TMI.2016.2640180
   Saha P, 2017, IEEE T INSTRUM MEAS, V66, P1703, DOI 10.1109/TIM.2017.2672458
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Tang Z, 2015, NEUROCOMPUTING, V168, P1011, DOI 10.1016/j.neucom.2015.05.024
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P11, DOI 10.2174/1871527315666161111123024
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2017, IEEE ACCESS, V5, P16576, DOI 10.1109/ACCESS.2017.2736558
   Wang SH, 2017, FUND INFORM, V151, P325, DOI 10.3233/FI-2017-1495
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P637, DOI 10.1177/0037549715623847
   Wang SH, 2016, SIMUL-T SOC MOD SIM, V92, P601, DOI 10.1177/0037549715603481
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wu XY, 2018, MULTIMED TOOLS APPL, V77, P3745, DOI 10.1007/s11042-016-3931-z
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2017, J EXP THEOR ARTIF IN, V29, P299, DOI 10.1080/0952813X.2015.1132274
   Zhou XX, 2016, LECT NOTES COMPUT SC, V9576, P48, DOI 10.1007/978-3-319-32557-6_5
   Zhu SG, 2014, J APPL MATH, DOI 10.1155/2014/828907
NR 35
TC 57
Z9 58
U1 5
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22821
EP 22839
DI 10.1007/s11042-018-5765-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500056
DA 2024-07-18
ER

PT J
AU Han, HY
   Zhang, JP
   Yang, J
   Shen, YR
   Zhang, YS
AF Han, Hongyu
   Zhang, Jianpei
   Yang, Jing
   Shen, Yiran
   Zhang, Yongshi
TI Generate domain-specific sentiment lexicon for review sentiment analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lexicon-based approach; Sentiment analysis; SentiWordNet; Mutual
   information
AB Lexicon-based approaches for review sentiment analysis have attracted significant attention in recent years. Lots of sentiment lexicon generation methods have been proposed. However, the generation of domain-specific lexicon with unlabeled data has not been effectively addressed. In this paper, we propose a new domain-specific sentiment lexicon generation method, mutual information is introduced to assign terms with Part-Of-Speech (POS) tags in the lexicon, the training data are selected from unlabeled corpus according to their sentiment scores which are evaluated by the SentiWordNet (SWN) based sentiment classifier. Then we propose a completed lexicon-based sentiment analysis framework which uses the domain-specific sentiment lexicon generated by the proposed domain-specific sentiment lexicon generation method. The experiment is carried out on publically available datasets. Results show that the proposed lexicon-based sentiment analysis framework using domain-specific lexicons generated by the proposed method gets a good performance.
C1 [Han, Hongyu; Zhang, Jianpei; Yang, Jing; Shen, Yiran; Zhang, Yongshi] Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Han, HY (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, 145 Nantong St, Harbin 150001, Heilongjiang, Peoples R China.
EM hanhongyu@hrbeu.edu.cn
FU National Natural Science Foundation of China [61672179, 61370083,
   61402126]; Specialized Research Fund for the Doctoral Program of Higher
   Education [20122304110012]; Heilongjiang Postdoctoral Science Foundation
   [LBH-Z14071]; Natural Science Foundation for Young Scientists of
   Heilongjiang Province [QC2016083]; Natural Science Foundation of
   Heilongjiang Province [F2015030]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61672179, No. 61370083, No. 61402126), the Specialized
   Research Fund for the Doctoral Program of Higher Education (No.
   20122304110012), the Heilongjiang Postdoctoral Science Foundation
   (LBH-Z14071), the Natural Science Foundation for Young Scientists of
   Heilongjiang Province (QC2016083) and the Natural Science Foundation of
   Heilongjiang Province (F2015030).
CR [Anonymous], 2007, ACL
   [Anonymous], 2010, P ACM INT C INF KNOW
   [Anonymous], 2014, COLING 2014, 25th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, August 23-29, 2014, Dublin, Ireland
   [Anonymous], 2016, COMPUT LINGUISTICS
   [Anonymous], 2010, LREC 10
   [Anonymous], 2005, P EMNLP VANC CAN
   [Anonymous], INDUCING DOMAIN SPEC
   Awwad H, 2016, 2016 THIRD EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2016), P127, DOI [10.1109/ENIC.2016.026, 10.1109/ENIC.2016.25]
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Gatti L, 2012, ARXIV12124315
   Khan FH, 2016, APPL SOFT COMPUT, V39, P140, DOI 10.1016/j.asoc.2015.11.016
   Leopold E, 2002, MACH LEARN, V46, P423, DOI 10.1023/A:1012491419635
   Lochter JV, 2016, EXPERT SYST APPL, V62, P243, DOI 10.1016/j.eswa.2016.06.025
   Maas Andrew, 2011, P 49 ANN M ASS COMP
   Park S, 2015, PATTERN RECOGN LETT, V56, P38, DOI 10.1016/j.patrec.2015.01.004
   Petz G, 2014, INFORM PROCESS MANAG, V50, P899, DOI 10.1016/j.ipm.2014.07.005
   Saif H, 2016, INFORM PROCESS MANAG, V52, P5, DOI 10.1016/j.ipm.2015.01.005
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
NR 19
TC 36
Z9 42
U1 10
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21265
EP 21280
DI 10.1007/s11042-017-5529-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300042
DA 2024-07-18
ER

PT J
AU Hsieh, CW
   Chen, CY
AF Hsieh, Chi-Wen
   Chen, Chih-Yen
TI An adaptive level set method for improving image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Active contour; Level set; Distance regularized level set
   evolution (DRLSE); Edge indicator function
ID GRADIENT VECTOR FLOW; ACTIVE CONTOURS; REGION; EVOLUTION; SNAKES;
   FORMULATION; MODEL
AB Segmentation is one of the most significant techniques in image processing studies. But the major limitations of low contrast, ambiguous boundary and complex morphology of images usually lead to unsatisfactory segmentation, especially in heavily noisy medical images. To address this problem, an attempt by improving Distance Regularized Level Set Evolution (DRLSE) model has been made to build up an effective and accurate active contour model to improve the segmentation ability. In this study, a balance concept between the pushing force and image's contour strength of DRLSE model was adapted for contour segmentations, so the contour convergent/divergent force will be re-defined to make it more feasible for complicated boundaries. The proposed concept integrates the bilateral filtering and Canny contour, and the improved edge indicator function into the DRLSE model. The most important step is to adapt the improved edge indicator function appropriately with the Canny contour. To verify our proposed DRLSE scheme, different testing images are used. The experimental results show that the proposed approach has been examined and tested successfully in most cases. Consequently, the developed algorithm including the DRLSE model combing the Canny contour with an improved g edge indicator, demonstrate the effectiveness and reliability, especially in the testing samples with weak edges and complex topologies.
C1 [Hsieh, Chi-Wen] Natl Chiayi Univ, Dept Elect Engn, 300 Syuefu Rd, Chiayi 60004, Taiwan.
   [Chen, Chih-Yen] Natl Appl Res Labs, Instrument Technol Res Ctr, 20 R&D Rd 6,Hsinchu Sci Pk, Hsinchu 300, Taiwan.
C3 National Chiayi University; National Applied Research Laboratories -
   Taiwan
RP Hsieh, CW (corresponding author), Natl Chiayi Univ, Dept Elect Engn, 300 Syuefu Rd, Chiayi 60004, Taiwan.
EM chihyenorama@gmail.com; chiwen@mail.ncyu.edu.tw
OI Chen, Chih-Yen/0000-0003-2703-0632
FU Ministry of Science and Technology (Taiwan, ROC) [MOST
   103-2221-E-415-008]
FX The authors are grateful to Chun-IWang for assisting in the experiments,
   and the Ministry of Science and Technology (Taiwan, ROC) for the support
   of this research under grant MOST 103-2221-E-415-008.
CR Balla-Arabé S, 2014, IEEE T GEOSCI REMOTE, V52, P5183, DOI 10.1109/TGRS.2013.2287239
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Gao XB, 2011, IEEE T SYST MAN CY B, V41, P518, DOI 10.1109/TSMCB.2010.2065800
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   Hsieh CW, 2012, MEAS SCI REV, V12, P21, DOI 10.2478/v10048-012-0003-z
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P162
   Li CM, 2005, PROC CVPR IEEE, P430
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Mesejo P, 2015, COMPUT MED IMAG GRAP, V43, P167, DOI 10.1016/j.compmedimag.2013.12.005
   Mukherjee S, 2015, IEEE SIGNAL PROC LET, V22, P298, DOI 10.1109/LSP.2014.2346538
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Phung-Van P, 2014, COMPOS PART B-ENG, V60, P227, DOI 10.1016/j.compositesb.2013.12.044
   Rossi R, 2013, INT J NUMER METH FL, V71, P687, DOI 10.1002/fld.3680
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Verma N, 2011, IEEE ENG MED BIO, P2821, DOI 10.1109/IEMBS.2011.6090780
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wang B, 2010, IEEE T SYST MAN CY B, V40, P857, DOI 10.1109/TSMCB.2009.2031090
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P258, DOI 10.1109/TIP.2012.2214046
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 33
TC 6
Z9 6
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 20087
EP 20102
DI 10.1007/s11042-017-5434-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500053
DA 2024-07-18
ER

PT J
AU Seo, J
   Choi, S
   Kim, YA
   Yoo, K
   Han, S
AF Seo, Jiwan
   Choi, Seungjin
   Kim, Yura Alex
   Yoo, Karam
   Han, Sangyong
TI Word embedding-based relation modeling in a heterogeneous information
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous information network; Word embedding; Relation modeling
AB Heterogeneous information networks are widely used in big data applications. These networks consist of multi-type information objects and relations. The appearance of the network can be changed depending on what perspective is used for modeling. Modeling relations between information objects has attracted recent attention. Although many related works have been proposed, they have limitations: they are hard to apply to unstructured data and they require continuous learning; and the results are often sparse. In this paper, we propose a new method based on a word-embedding technique that deduces various relations between information objects. We create viewpoint data that reflects any perspective on information objects and word embedding carried out by using these data. Using the proposed method, the system quantifies the relations between the information objects in heterogeneous information networks. The experiments use real world data to demonstrate the effectiveness of our methodology.
C1 [Seo, Jiwan; Choi, Seungjin; Kim, Yura Alex; Yoo, Karam; Han, Sangyong] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Han, S (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM jwseo@ec.cse.cau.ac.kr; bethemoney@ec.cse.cau.ac.kr;
   alex.k.yura@ec.cse.cau.ac.kr; fka4805@ec.cse.cau.ac.kr; hansy@cau.ac.kr
OI Seo, Jiwan/0000-0003-3463-8822
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Science, ICT and future Planning [NRF -
   2015R1A2 A2A01005304]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT and future Planning (NRF - 2015R1A2 A2A01005304).
CR [Anonymous], 1988, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/57167.57214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Deng H., 2011, PROC ACM SIGKDD C KN, P1271, DOI DOI 10.1145/2020408.2020600
   Huang F., 2009, ACL '09, P495
   Jeh G., 2002, PROC 8 ACM SIGKDD IN, P538
   Jeh Glen, 2003, P 12 INT C WORLD WID, P271, DOI DOI 10.1145/775152.775191
   Jiang Zhuoren., 2015, Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. CIKM'15, P1291, DOI DOI 10.1145/2806416.2806567
   Jung JJ, 2015, MOBILE NETW APPL, V20, P533, DOI 10.1007/s11036-014-0555-2
   Kawale J., 2015, ADV NEURAL INFORM PR, P1297
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Leong HU, 2014, LECT NOTES COMPUT SC, V8485, P38, DOI 10.1007/978-3-319-08010-9_6
   Lin D., 2009, ACL 2009, P1030
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Sohn BS, 2015, MOBILE NETW APPL, V20, P508, DOI 10.1007/s11036-014-0539-2
   Sun Yizhou, 2012, Synthesis Lectures on Data Mining and Knowledge Discovery, V3, P1
   Sunt YZ, 2011, PROC VLDB ENDOW, V4, P992
   Tang D, 2014, BUILDING LARGE SCALE, P172
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Turian J, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P384
   Zhou Y, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1563, DOI 10.1145/2783258.2783328
NR 22
TC 0
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18529
EP 18543
DI 10.1007/s11042-017-5008-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900048
DA 2024-07-18
ER

PT J
AU Varatharajan, R
   Manogaran, G
   Priyan, MK
   Balas, VE
   Barna, C
AF Varatharajan, R.
   Manogaran, Gunasekaran
   Priyan, M. K.
   Balas, Valentina E.
   Barna, Cornel
TI Visual analysis of geospatial habitat suitability model based on inverse
   distance weighting with paired comparison analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual analysis; Geospatial analytical model; Habitat suitability;
   Inverse distance weighting; Spatialmodeling; Paired comparison analysis
ID MULTICRITERIA DECISION-ANALYSIS; FUZZY-LOGIC; HEALTH-CARE; SYSTEM;
   CONSERVATION; VACCINATION
AB Geospatial data analytical model is developed in this paper to model the spatial suitability of malaria outbreak in Vellore, Tamil Nadu, India. In general, Disease control strategies are only the spatial information like landscape, weather and climate, but also spatially explicit information like socioeconomic variable, population density, behavior and natural habits of the people. The spatial multi-criteria decision analysis approach combines the multi-criteria decision analysis and geographic information system (GIS) to model the spatially explicit and implicit information and to make a practical decision under different scenarios and different environment. Malaria is one of the emerging diseases worldwide; the cause of malaria is weather & climate condition of the study area. The climate condition is often called as spatially implicit information, traditional decision-making models do not use the spatially implicit information it most often uses spatially explicit information such as socio-economic, natural habits of the people. There is need to develop an integrated approach that consists of spatially implicit and explicit information. The proposed approach is used to identity an effective control strategy that prevents and control of malaria. Inverse Distance Weighting (IDW) is a type of deterministic method used in this paper to assign the weight values based on the neighborhood locations. ArcGIS software is used to develop the geospatial habitat suitability model.
C1 [Varatharajan, R.] Sri Ramanujar Engn Coll, Dept Elect & Commun Engn, Kolapakkam, India.
   [Manogaran, Gunasekaran; Priyan, M. K.] VIT Univ, Vellore, Tamil Nadu, India.
   [Barna, Cornel] Aurel Vlaicu Univ Arad, Fac Engn, Dept Automat & Appl Software, Arad, Romania.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Aurel Vlaicu
   University of Arad
RP Priyan, MK (corresponding author), VIT Univ, Vellore, Tamil Nadu, India.
EM priyanit085@gmail.com
RI MALARVIZHI KUMAR, PRIYAN/U-3908-2018; KUMAR, PRIYAN
   MALARVIZHI/GYV-1373-2022; Balas, Valentina Emilia/F-4525-2010; Barna,
   Cornel/AAO-9304-2021; Manogaran, Gunasekaran/K-7621-2017
OI MALARVIZHI KUMAR, PRIYAN/0000-0001-6149-2705; Balas, Valentina
   Emilia/0000-0003-0885-1283; Manogaran, Gunasekaran/0000-0003-4083-6163
CR Al-Subhi Al-Harbi K. M., 2001, International Journal of Project Management, V19, P19, DOI 10.1016/S0263-7863(99)00038-1
   [Anonymous], 2016, INT J AMBIENT COMPUT
   [Anonymous], COMPUTERS ELECT ENG
   BELLMAN RE, 1970, MANAGE SCI B-APPL, V17, pB141
   Berke Olaf, 2004, Int J Health Geogr, V3, P18, DOI 10.1186/1476-072X-3-18
   Broekhuizen H, 2015, PHARMACOECONOMICS, V33, P445, DOI 10.1007/s40273-014-0251-x
   Brugger K., 2016, Modeling GIS, Risk Assessment, Economic Impact a Density Map of the Tick-Borne Encephalitis and Lyme Borreliosis Vector Ixodes ricinus (Acari: Ixodidae) for Germany
   Chen FW, 2012, PADDY WATER ENVIRON, V10, P209, DOI 10.1007/s10333-012-0319-1
   Chowell G, 2012, BMC INFECT DIS, V12, DOI 10.1186/1471-2334-12-298
   De SK, 2001, FUZZY SET SYST, V117, P209, DOI 10.1016/S0165-0114(98)00235-8
   Gillenwater D, 2006, ECOL ENG, V28, P311, DOI 10.1016/j.ecoleng.2006.08.003
   Hepinstall JA, 1996, PHOTOGRAMM ENG REM S, V62, P1281
   Hightower JE, 2012, J FISH WILDL MANAG, V3, P184, DOI 10.3996/082011-JFWM-047
   Hongoh V, 2011, INT J HEALTH GEOGR, V10, DOI 10.1186/1476-072X-10-70
   Imtiaz Ahmed Chandio Imtiaz Ahmed Chandio, 2011, International Journal of Environmental Science and Development, V2, P469
   Jato-Espino D, 2014, AUTOMAT CONSTR, V45, P151, DOI 10.1016/j.autcon.2014.05.013
   Johnston KM, 2008, ESRI US C AUG 4 8
   Lauver CL, 2002, ENVIRON MANAGE, V30, P88, DOI 10.1007/s00267-001-2609-z
   Lopez D, 2016, INT J INFECT DIS, V45, P23, DOI 10.1016/j.ijid.2016.02.084
   Lopez D, 2016, HUMAN ELEMENT BIG DA
   Lopez D, 2015, ADV INTELL SYST, V415, P195, DOI 10.1007/978-3-319-27212-2_16
   Lopez Daphne, 2014, Proc IEEE Int Conf Big Data, V2014, P19, DOI 10.1109/BigData.2014.7004422
   Lu GY, 2008, COMPUT GEOSCI-UK, V34, P1044, DOI 10.1016/j.cageo.2007.07.010
   Lu ShihTong., 2 INT C INNOVATIVE C, DOI DOI 10.1109/ICICIC.2007.172
   Macpherson MF, 2016, ANIM CONSERV, V19, P3, DOI 10.1111/acv.12219
   Maharjan B, 2017, GEOSPATIAL ANAL HABI
   Manogaran G, 2017, BIG DATA SECURITY IN
   Manogaran G, 2017, INNOVATIVE HLTH SYST
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Manogaran G, 2017, INT J AMBIENT COMPUT, V8, P88, DOI 10.4018/IJACI.2017040106
   Manogaran G, 2016, PROCEDIA COMPUT SCI, V87, P128, DOI 10.1016/j.procs.2016.05.138
   Massad E, 1999, INT J EPIDEMIOL, V28, P550, DOI 10.1093/ije/28.3.550
   Narouei-Khandan HA, 2016, EUR J PLANT PATHOL, V144, P655, DOI 10.1007/s10658-015-0804-7
   Opricovic S, 2007, EUR J OPER RES, V178, P514, DOI 10.1016/j.ejor.2006.01.020
   Ozbek ME, 2010, J INFRASTRUCT SYST, V16, P21, DOI 10.1061/(ASCE)1076-0342(2010)16:1(21)
   Pavlovskii˘ E., 1966, Natural Nidality of Transmissible Diseases; With Special Reference to the Landscape Epidemiology of Zooanthroponoses
   Phuong NH, 2001, INT J MED INFORM, V62, P165, DOI 10.1016/S1386-5056(01)00160-5
   Rood E, 2010, DIVERS DISTRIB, V16, P975, DOI 10.1111/j.1472-4642.2010.00704.x
   Sarhangzadeh J., 2013, Caspian Journal of Environmental Sciences, V11, P41
   Simsek B, 2013, CHEMOMETR INTELL LAB, V125, P18, DOI 10.1016/j.chemolab.2013.03.012
   Thota Chandu., 2017, Cybersecurity breaches and issues surrounding online threat protection, P288
   Wang J, 2009, INT J PROJ MANAG, V27, P584, DOI 10.1016/j.ijproman.2008.10.003
   Wen J, 2016, IEEE T SIGNAL PROCES
   Wen JM, 2017, IEEE T INFORM THEORY, V63, P631, DOI 10.1109/TIT.2016.2627082
   Xiao H, 2013, CHINESE SCI BULL, V58, P741, DOI 10.1007/s11434-012-5571-7
   Yang M, 2011, INT J ENV RES PUB HE, V8, P1368, DOI 10.3390/ijerph8051368
   Zoccali P, 2017, SAUDI J BIOL SCI, V24, P1045, DOI 10.1016/j.sjbs.2017.01.062
NR 47
TC 110
Z9 116
U1 4
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17573
EP 17593
DI 10.1007/s11042-017-4768-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900004
DA 2024-07-18
ER

PT J
AU Zheng, HT
   Wang, Z
   Ma, NN
   Chen, JY
   Xiao, X
   Sangaiah, AK
AF Zheng, Hai-Tao
   Wang, Zhe
   Ma, Ningning
   Chen, Jinyuan
   Xiao, Xi
   Sangaiah, Arun Kumar
TI Weakly-supervised image captioning based on rich contextual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Weakly-supervised learning; Rich contextual
   information; Encoder-decoder neural networks; Object detection;
   Phrase-based language model
AB Automatically generation of an image description is a challenging task which attracts broad attention in artificial intelligence. Inspired by methods of computer vision and natural language processing, different approaches have been proposed to solve the problem. However, captions generated by the existing approaches have been lack of enough contextual information to describe the corresponding images completely. The labeled captions in the training set only basically describe images and lack of enough contextual annotations. In this paper, we propose a Weakly-supervised Image Captioning Approach (WICA) to generate captions containing rich contextual information, without complete annotations for the contextual information in datasets. We utilize encoder-decoder neural networks to extract basic captioning features and leverage object detection networks to identify contextual features. Then, we encode the two levels of features by a phrase-based language model in order to generate captions with rich contextual information. The comprehensive experimental results reveal that proposed model outperforms the existing baselines in terms of on the richness and reasonability of contextual information for image captioning.
C1 [Zheng, Hai-Tao; Wang, Zhe; Ma, Ningning; Chen, Jinyuan] Tsinghua Univ, Grad Sch Shenzhen, Tsinghua Southampton Web Sci Lab, Shenzhen, Guangdong, Peoples R China.
   [Xiao, Xi] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen, Guangdong, Peoples R China.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Tsinghua Shenzhen International Graduate School; Tsinghua University;
   Vellore Institute of Technology (VIT); VIT Vellore
RP Wang, Z (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Tsinghua Southampton Web Sci Lab, Shenzhen, Guangdong, Peoples R China.
EM wangzhe16@mails.tsinghua.edu.cn
RI Sangaiah, Arun Kumar/U-6785-2019; MA, NINGNING/KQU-7871-2024
OI Sangaiah, Arun Kumar/0000-0002-0229-2460; 
FU National Natural Science Foundation of China [61375054]; Natural Science
   Foundation of Guangdong Province [2014A030313745]; Basic Scientific
   Research Program of Shenzhen City [JCYJ20160331184440545]; Cross Fund of
   Graduate School at Shenzhen, Tsinghua University [JC20140001]
FX This research is supported by National Natural Science Foundation of
   China (Grant No. 61375054), Natural Science Foundation of Guangdong
   Province (Grant No. 2014A030313745), Basic Scientific Research Program
   of Shenzhen City (Grant No. JCYJ20160331184440545), and Cross Fund of
   Graduate School at Shenzhen, Tsinghua University (Grant No. JC20140001).
CR Abadi M, ARXIV, DOI DOI 10.48550/ARXIV.1603.04467
   Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2014, PROC EUR C COMPUT VI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MATH PROBLEMS ENG
   [Anonymous], 2013, P 2013 C EMP METH NA
   [Anonymous], 2014, INT J COMPUT VISION
   [Anonymous], EMNLP
   Bengio Y., 2014, TECHNICAL REPORT
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Karpathy A, 2014, ADV NEUR IN, V27
   Kiros R, 2014, Arxiv, DOI arXiv:1411.2539
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   Mao Junhua, 2014, CoRR
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Sutskever I, 2014, ADV NEUR IN, V27
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu JJ, 2010, SIGNAL PROCESS-IMAGE, V25, P717, DOI 10.1016/j.image.2010.10.003
   Xu K., 2015, COMPUTER SCI, P2048
NR 30
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18583
EP 18599
DI 10.1007/s11042-017-5236-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900051
DA 2024-07-18
ER

PT J
AU Ma, Y
   Liu, ZY
   Wang, XH
   Cao, S
AF Ma, Yue
   Liu, Zhaoyi
   Wang, Xinghua
   Cao, Shan
TI Fast intra coding based on CU size decision and direction mode decision
   for HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC (High Efficiency Video Coding); CU (coding unit) size decision;
   Direction mode decision; Rate-distortion optimization (RDO)
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; VIDEO; ALGORITHM; TERMINATION;
   PREDICTION; STANDARD
AB High Efficiency Video Coding (HEVC) adopts a quad-tree structured coding unit (CU) and more prediction unit (PU) modes are used in all CU depth levels. These improvements bring better coding performance, but the exhaustive search process for optimal CU and PU selection causes higher computational complexity than earlier standards. To speed up the encoder, this paper proposes a fast intra coding algorithm. Firstly, a fast CU size decision method is introduced, which selects different depth decision methods for each largest coding unit. Secondly, a fast direction mode decision method is proposed. It first compares the direction modes of the parent unit and most probable modes (MPMs) list, and then the first direction mode of rate-distortion optimization (RDO) list is used to early terminate the RDO process. Experimental results show that compared with HM 10.0, the proposed algorithm achieves 47% time reduction, whereas the value of BDBR is only 0.7%.
C1 [Ma, Yue; Liu, Zhaoyi; Wang, Xinghua; Cao, Shan] Beijing Inst Technol, Shool Informat & Elect, Beijing 100081, Peoples R China.
   [Cao, Shan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Beijing Institute of Technology; Shanghai University
RP Cao, S (corresponding author), Beijing Inst Technol, Shool Informat & Elect, Beijing 100081, Peoples R China.; Cao, S (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM caoshan@bit.edu.cn
RI Cao, Shan/JOZ-2892-2023; ma, yue/GXE-9897-2022
FU National Natural Science Foundation of China [61271113]; Ph.D Programs
   Foundation of Ministry of Education of China [20131101120028,
   20131101120029]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 61271113) and the Ph.D Programs Foundation of Ministry
   of Education of China (Grant No. 20131101120028 and 20131101120029).
CR [Anonymous], 2016, MOBILE NETW APPL, DOI DOI 10.1007/S11036-018-1136-6
   [Anonymous], EURASIP J WIRELESS C
   Bjontegaard G, 2001, 15 M AUST
   Bossen F., 2013, JCTVCL1100
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Fan T, 2016, IEICE T INF SYST, VE99D, P1953, DOI 10.1587/transinf.2015EDL8231
   Hu J, 2016, J VIS COMMUN IMAGE R, V40, P671, DOI 10.1016/j.jvcir.2016.08.007
   Kim J, 2011, Proceedings of the BioNLP Shared Task 2011 Workshop, P1
   Kokkonis G, 2017, J SUPERCOMPUT, V73, P1044, DOI 10.1007/s11227-016-1769-9
   Kokkonis G, 2016, J REAL-TIME IMAGE PR, V12, P343, DOI 10.1007/s11554-015-0505-7
   Kumar V, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P506, DOI 10.1109/IS3C.2014.138
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Lee JH, 2015, I SYMP CONSUM ELECTR, P270, DOI 10.1109/ICCE.2015.7066409
   Memos VA, 2016, J REAL-TIME IMAGE PR, V12, P473, DOI 10.1007/s11554-015-0509-3
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Park SJ, 2016, SIGNAL PROCESS-IMAGE, V42, P79, DOI 10.1016/j.image.2015.12.006
   Pateux S., 2007, SG16Q6 ITUT
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Psannis K, 2008, IEICE T COMMUN, VE91B, P2692, DOI 10.1093/ietcom/e91-b.8.2692
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Psannis KE, 2016, J REAL-TIME IMAGE PR, V12, P509, DOI 10.1007/s11554-015-0514-6
   Psannis KE, 2009, TELECOMMUN SYST, V41, P65, DOI 10.1007/s11235-009-9151-3
   Ramezanpour M, 2016, J REAL-TIME IMAGE PR, V12, P397, DOI 10.1007/s11554-016-0580-4
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shi W, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P17, DOI 10.1109/APCCAS.2014.7032708
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang H, 2013, IEEE INT SYMP CIRC S, P45, DOI 10.1109/ISCAS.2013.6571778
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhang Y., 2012, IEEE VISUAL COMMUNIC, P1
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhu SP, 2014, C IND ELECT APPL, P936, DOI 10.1109/ICIEA.2014.6931297
NR 40
TC 5
Z9 6
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14907
EP 14929
DI 10.1007/s11042-017-5074-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200021
DA 2024-07-18
ER

PT J
AU Cao, LF
   Gao, LL
   Song, JK
   Shen, FM
   Wang, Y
AF Cao, Liangfu
   Gao, Lianli
   Song, Jingkuan
   Shen, Fumin
   Wang, Yuan
TI Multiple hierarchical deep hashing for large scale image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Deep hashing; Large scale image retrieval; Convolutional
   neural networks
ID QUANTIZATION; SCENE
AB Learning-based hashing methods are becoming the mainstream for large scale visual search. They consist of two main components: hash codes learning for training data and hash functions learning for encoding new data points. The performance of a content-based image retrieval system crucially depends on the feature representation, and currently Convolutional Neural Networks (CNNs) has been proved effective for extracting high-level visual features for large scale image retrieval. In this paper, we propose a Multiple Hierarchical Deep Hashing (MHDH) approach for large scale image retrieval. Moreover, MHDH seeks to integrate multiple hierarchical non-linear transformations with hidden neural network layer for hashing code generation. The learned binary codes represent potential concepts that connect to class labels. In addition, extensive experiments on two popular datasets demonstrate the superiority of our MHDH over both supervised and unsupervised hashing methods.
C1 [Cao, Liangfu; Gao, Lianli; Song, Jingkuan; Shen, Fumin; Wang, Yuan] Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Gao, LL (corresponding author), Univ Elect Sci & Technol China, 2006 Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China.
EM Lianli.gao@uestc.edu.cn
FU Fundamental Research Funds for the Central Universities [ZYGX2014J063];
   National Natural Science Foundation of China [61502080]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions;
   Jiangsu Collaborative Innovation Center on Atmospheric Environment and
   Equipment Technology
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (Grant no. ZYGX2014J063), the National Natural Science
   Foundation of China (Grant no. 61502080) and the Priority Academic
   Program Development of Jiangsu Higher Education Institutions, and
   Jiangsu Collaborative Innovation Center on Atmospheric Environment and
   Equipment Technology.
CR [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], 2016, SURVEY LEARNING HASH
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2009, NIPS
   [Anonymous], EFFECTIVE HASHING LA
   [Anonymous], CONCURR COMPUT PRACT
   [Anonymous], COMPUT SCI
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bradski GaryR., 1998, Computer vision face tracking for use in a perceptual user interface
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Gao LL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P487, DOI 10.1145/2671188.2749309
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Heo JP, 2015, IEEE T PATTERN ANAL, V37, P2304, DOI 10.1109/TPAMI.2015.2408363
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu G, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P839, DOI 10.1145/2733373.2806344
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   LeCun Y, 1998, MNIST DATABASE HANDW
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Norouzi M.E., 2011, ICML
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Song JK, 2016, IMAGE VISION COMPUT, V55, P101, DOI 10.1016/j.imavis.2016.02.005
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Torralba A, 2008, IEEE COMPUTER SOC C, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Xia R., 2014, SUPERVISED HASHING I
   Xie SD, 2014, WIRELESS PERS COMMUN, V78, P231, DOI 10.1007/s11277-014-1748-5
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Xu XZ, 2017, NEURAL COMPUT APPL, V28, pS671, DOI 10.1007/s00521-016-2397-2
NR 50
TC 0
Z9 1
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10471
EP 10484
DI 10.1007/s11042-017-4489-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900006
DA 2024-07-18
ER

PT J
AU Guo, JP
   Sun, LH
   Li, WH
   Yu, T
AF Guo, Junpeng
   Sun, Lihua
   Li, Wenhua
   Yu, Ting
TI Applying uncertainty theory to group recommender systems taking account
   of experts preferences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Group recommendation; Collaborative filtering; Similarity measure;
   Uncertain statistics; Genetic algorithm
ID SIMILARITY; ART
AB This study aims to generate recommendations for a group by weighting the preferences of each group member. We applied uncertain statistics to the preference scores of a panel of experts and a genetic algorithm (GA) to balance the weights of the group members (UGA). A group profile was then designed on the basis of the user ratings and the scores of the experts. A novel similarity measure was then developed based on uncertainty theory to refine the number of K-nearest neighbors (KNN). By integrating uncertain statistics and the novel similarity measure, group profiles were developed from the MovieLens and Gym datasets. Experiments demonstrated that the proposed approach was significantly better than two baseline approaches in generating group recommendations.
C1 [Guo, Junpeng; Sun, Lihua; Li, Wenhua; Yu, Ting] Tianjin Univ, Coll Management Econ, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Sun, LH (corresponding author), Tianjin Univ, Coll Management Econ, Tianjin 300072, Peoples R China.
EM sunlh68@tju.edu.cn
FU National Natural Science Foundation of China [71271147, 71671121]
FX We gratefully acknowledge that this work is financed by the National
   Natural Science Foundation of China (grant numbers 71271147, 71671121).
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Ahn HJ, 2008, INFORM SCIENCES, V178, P37, DOI 10.1016/j.ins.2007.07.024
   Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   An YH, 2016, PHYSICA A, V461, P708, DOI 10.1016/j.physa.2016.06.027
   Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012
   Breese J., 1998, P 14 C UNC ART INT, P43
   Cacheda F, 2011, ACM T WEB, V5, DOI 10.1145/1921591.1921593
   Chen XW, 2012, EUR J OPER RES, V222, P312, DOI 10.1016/j.ejor.2012.05.010
   Chen YL, 2008, EXPERT SYST APPL, V34, P2082, DOI 10.1016/j.eswa.2007.02.008
   Cheng LC, 2014, APPL SOFT COMPUT, V18, P290, DOI 10.1016/j.asoc.2013.09.004
   Christensen IA, 2011, EXPERT SYST APPL, V38, P14127, DOI 10.1016/j.eswa.2011.04.221
   de Campos LM, 2008, FUZZY SET SYST, V159, P1554, DOI 10.1016/j.fss.2008.01.016
   Ding SB, 2013, APPL MATH COMPUT, V223, P139, DOI 10.1016/j.amc.2013.07.083
   Ding SB, 2014, J INTELL FUZZY SYST, V26, P483, DOI 10.3233/IFS-130919
   Gao Y, 2016, IEEE T FUZZY SYST, V24, P981, DOI 10.1109/TFUZZ.2015.2500267
   Gao Y, 2015, INFORM SCIENCES, V296, P61, DOI 10.1016/j.ins.2014.10.048
   Gao Y, 2012, APPL MATH MODEL, V36, P2592, DOI 10.1016/j.apm.2011.09.042
   Gao Y, 2011, COMPUT MATH APPL, V62, P2591, DOI 10.1016/j.camwa.2011.07.058
   Gorla J., 2013, P 22 INT C WORLD WID, P495, DOI DOI 10.1145/2488388.2488432
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Kagita VR, 2015, INFORM SCIENCES, V294, P15, DOI 10.1016/j.ins.2014.08.072
   Liang RZ, 2016, ARXIV160406620
   Liu B., 2007, UNCERTAINTY THEORY, DOI DOI 10.1007/978-3-642-13959-8
   Liu B., 2010, J UNCERTAIN SYST, V4, P83
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Liu W, 2010, INFORMATION-TOKYO, V13, P1693
   Lu J, 2015, DECIS SUPPORT SYST, V74, P12, DOI 10.1016/j.dss.2015.03.008
   Lü LY, 2012, PHYS REP, V519, P1, DOI 10.1016/j.physrep.2012.02.006
   Márquez JOA, 2015, LECT NOTES COMPUT SC, V9297, P20, DOI 10.1007/978-3-319-22668-2_2
   Masthoff J., 2015, recommender systems handbook, P743, DOI 10.1007/978-1-4899-7637-6_22
   Masthoff J, 2011, RECOMMENDER SYSTEMS HANDBOOK, P677, DOI 10.1007/978-0-387-85820-3_21
   Myszkorowski K, 2013, LECT NOTES ARTIF INT, V8083, P671
   O'Connor M, 2001, ECSCW 2001: PROCEEDINGS OF THE SEVENTH EUROPEAN CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P199
   Sangolli S.V., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.17485/ijst/2015/v8i20/83978, DOI 10.17485/ijst/2016/v9i48/107997]
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Sezgin E, 2013, E-HEALTH BIOENG CONF, DOI 10.1109/EHB.2013.6707249
   Son LH, 2014, EXPERT SYST APPL, V41, P6861, DOI 10.1016/j.eswa.2014.05.001
   Valdez AC, 2016, LECT NOTES COMPUT SC, V9605, P391, DOI 10.1007/978-3-319-50478-0_20
   Wang LG, 2010, FIXED POINT THEORY A, DOI 10.1155/2010/283827
   Wang W, 2016, DECIS SUPPORT SYST, V87, P80, DOI 10.1016/j.dss.2016.05.002
   Wang XS, 2012, INFORMATION-TOKYO, V15, P449
   Yao K, 2015, IEEE T FUZZY SYST, V23, P1333, DOI 10.1109/TFUZZ.2014.2360551
   Yao K, 2012, IEEE T FUZZY SYST, V20, P1154, DOI 10.1109/TFUZZ.2012.2194152
NR 44
TC 3
Z9 3
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12901
EP 12918
DI 10.1007/s11042-017-4922-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100055
DA 2024-07-18
ER

PT J
AU Jiang, JY
   Hu, L
   Hao, PT
   Sun, R
   Hu, JJ
   Li, HT
AF Jiang, Jingyan
   Hu, Liang
   Hao, Pingting
   Sun, Rui
   Hu, Jiejun
   Li, Hongtu
TI Q-FDBA: improving QoE fairness for video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dash; Software-defined networking; Machine learning; Dynamic bandwidth
   allocation
AB Multiplayer video streaming scenario can be seen everywhere today as the video traffic is becoming the "killer" traffic over the Internet. The Quality of Experience fairness is critical for not only the users but also the content providers and ISP. Consequently, a QoE fairness adaptive method of multiplayer video streaming is of great importance. Previous studies focus on client-side solutions without network global view or network-assisted solution with extra reaction to client. In this paper, a pure network-based architecture using SDN is designed for monitoring network global performance information. With the flexible programming and network mastery capacity of SDN, we propose an online Q-learning-based dynamic bandwidth allocation algorithm Q-FDBA with the goal of QoE fairness. The results show the Q-FDBA could adaptively react to high frequency of bottleneck bandwidth switches and achieve better QoE fairness within a certain time dimension.
C1 [Jiang, Jingyan; Hu, Liang; Hao, Pingting; Sun, Rui; Hu, Jiejun; Li, Hongtu] Jilin Univ JLU, Coll Comp Sci & Technol, 2699 Qianjin St, Changchun, Jilin, Peoples R China.
RP Li, HT (corresponding author), Jilin Univ JLU, Coll Comp Sci & Technol, 2699 Qianjin St, Changchun, Jilin, Peoples R China.
EM jiangjy14@mails.jlu.edu.cn; lihongtu@jlu.edu.cn
RI Hu, Jiejun/AAP-8555-2020
FU National Sci-Tech Support Plan of China [2014BAH02F03]; Youth Science
   Foundation of Jilin Province of China [20160520011JH]; Youth Sci-Tech
   innovation leader and team project of Jilin Province of China
   [20170519017JH]
FX This work is funded by: National Sci-Tech Support Plan of China under
   Grant No. 2014BAH02F03, and by Youth Science Foundation of Jilin
   Province of China under Grant No. 20160520011JH, and by Youth Sci-Tech
   innovation leader and team project of Jilin Province of China under
   Grant No. 20170519017JH
CR Akhshabi Saamer, 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video-NOSSDAV'13
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], P INT C MULT RETR
   [Anonymous], 2015, ACM T MULTIMEDIA COM
   Bentaleb A, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1296, DOI 10.1145/2964284.2964332
   Bian JW, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P537, DOI 10.1145/2600428.2609616
   Bian JW, 2015, IEEE T MULTIMEDIA, V17, P216, DOI 10.1109/TMM.2014.2384912
   Bouten N, 2014, IN NETWORK QUALITY O
   Chen J, 2016, ACHIEVING QOE FAIRNE
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Georgopoulos P., 2013, Proceedings of the 2013 ACM SIGCOMM Workshop on Future Human-centric Multimedia Networking, FhMN '13, (New York, NY, USA), P15, DOI DOI 10.1145/2491172.2491181
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Kleinrouweler JW, 2016, COMPUT NETW, V109, P234, DOI 10.1016/j.comnet.2016.03.023
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Li BC, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2505805
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Nam H, 2014, IEEE GLOB COMM CONF, P1317, DOI 10.1109/GLOCOM.2014.7036990
   Spiteri K, 2016, IEEE INFOCOM SER, DOI 10.1109/infocom.2016.7524428
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   Sutton R. S., 1998, Adaptive Computation and Machine Learning
   Uzakgider T, 2015, COMPUT NETW, V92, P357, DOI 10.1016/j.comnet.2015.09.027
   Xu X, 2016, IEEE ACCESS, P1, DOI DOI 10.1155/2016/6141838
   Xu X, 2016, NEUROCOMPUTING, V213, P191, DOI 10.1016/j.neucom.2015.11.133
   Yang Y, 2016, INT JOINT CON ARTIFI
   Yang Yang, 2015, IEEE Transactions on Big Data, V1, P162, DOI 10.1109/TBDATA.2016.2516024
   Yang Y, 2013, IEEE T KNOWL DATA EN, V25, P1760, DOI 10.1109/TKDE.2012.118
   Yang Y, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457456
   Yin X, 2016, EFFICIENCY FAIRNESS
   Yin XQ, 2015, ACM SIGCOMM COMP COM, V45, P325, DOI 10.1145/2785956.2787486
NR 31
TC 25
Z9 26
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10787
EP 10806
DI 10.1007/s11042-017-4917-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900024
DA 2024-07-18
ER

PT J
AU Kant, V
   Jhalani, T
   Dwivedi, P
AF Kant, Vibhor
   Jhalani, Tanisha
   Dwivedi, Pragya
TI Enhanced multi-criteria recommender system based on fuzzy Bayesian
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Collaborative filtering; Multi-criteria decision
   making; Fuzzy sets; Naive Bayes classifier
ID COMPUTATIONAL MODELS; TRUST; DISTRUST
AB In the area of recommender systems, collaborative filtering is widely used technique for recommending appropriate items to a user based on the available ratings given by similar users. Most recommender systems (RSs) work only on the single criterion rating i.e., overall rating, however overall rating may not be a good representative of a user preference. Single criterion collaborative filtering (CF) does not generate more reliable recommendations because it suffers from correlation based similarity problems. Moreover, representation of uncertain user preferences is another concern of CF. In our work, we develop a novel fuzzy Bayesian approach to multi-criteria CF for handling uncertain user preferences and correlation based similarity problems. Further, incorporation of multi-criteria ratings into CF would be helpful for generating effective recommendations. Through experiments on Yahoo! Movies dataset, we compare our proposed approach to baseline approaches and demonstrate its effectiveness in terms of accuracy, recall and f-measure.
C1 [Kant, Vibhor] LNMIIT, Dept Comp Sci & Engn, Jaipur 302031, Rajasthan, India.
   [Jhalani, Tanisha] LNMIIT, Jaipur 302031, Rajasthan, India.
   [Dwivedi, Pragya] MNNIT, Allahabad 211004, Uttar Pradesh, India.
C3 LNM Institute of Information Technology; LNM Institute of Information
   Technology; National Institute of Technology (NIT System); Motilal Nehru
   National Institute of Technology
RP Dwivedi, P (corresponding author), MNNIT, Allahabad 211004, Uttar Pradesh, India.
EM vibhor.kant@gmail.com; tanishajhalani75@gmail.com;
   pragya.dwijnu@gmail.com
OI Dwivedi, Pragya/0000-0003-4101-628X
CR Adoinavicius G, 2007, IEEE INTELL SYST, V22, P48, DOI 10.1109/MIS.2007.58
   Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius Gediminas., 2015, Recommender Systems Handbook, VSecond, P847
   Al-Shamri MYH, 2008, EXPERT SYST APPL, V35, P1386, DOI 10.1016/j.eswa.2007.08.016
   Anand D, 2013, SOC NETW ANAL MIN, V3, P65, DOI 10.1007/s13278-012-0049-9
   [Anonymous], INT J ENG RES DEV
   [Anonymous], 2012, Proceedings of the 13th ACM Conference on Electronic Commerce, EC'12, DOI [DOI 10.1145/2229012.2229065, 10.1145/2229012.2229065]
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Bharadwaj KK, 2009, ELECTRON COMMER R A, V8, P37, DOI 10.1016/j.elerap.2008.08.001
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   de Campos LM, 2008, FUZZY SET SYST, V159, P1554, DOI 10.1016/j.fss.2008.01.016
   Dwivedi P, 2015, EXPERT SYST, V32, P264, DOI 10.1111/exsy.12061
   Dwivedi P, 2013, EDUC TECHNOL SOC, V16, P201
   Hofmann T., 1999, IJCAI, V99
   Kant V, 2015, P 17 INT C INF INT W, P75
   Kant V, 2013, INT J INTELL SYST, V28, P1099, DOI 10.1002/int.21619
   Kant V, 2013, INT J INTELL SYST, V28, P332, DOI 10.1002/int.21579
   Katarya R., 2016, MULTIMED TOOLS APPL, P1
   Kim KR, 2012, MULTIMED TOOLS APPL, V61, P87, DOI 10.1007/s11042-011-0728-y
   Lakiotaki K, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P219
   Manouselis N, 2007, WORLD WIDE WEB, V10, P415, DOI 10.1007/s11280-007-0019-8
   Miyahara K., 2000, PRICAI 2000. Topics in Artificial Intelligence. 6th Pacific Rim International Conference on Artificial Intelligence. Proceedings (Lecture Notes in Artificial Intelligence Vol.1886), P679
   Nilashi M, 2015, SOFT COMPUT, V19, P3173, DOI 10.1007/s00500-014-1475-6
   Nilashi M, 2015, INFORM SCIENCES, V293, P235, DOI 10.1016/j.ins.2014.09.012
   Robles V, 2003, LECT NOTES ARTIFICIA
   Roy B., 2013, MULTICRITERIA METHOD, V12
   Yager RR, 2003, FUZZY SET SYST, V136, P133, DOI 10.1016/S0165-0114(02)00223-3
   Toledo RY, 2015, KNOWL-BASED SYST, V76, P96, DOI 10.1016/j.knosys.2014.12.011
   Zenebe A, 2009, FUZZY SET SYST, V160, P76, DOI 10.1016/j.fss.2008.03.017
   Zigoris P., 2006, Proceedings of the 15th ACM Internatioanl Conference on Information and Knowledge Management, P397
NR 30
TC 14
Z9 17
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12935
EP 12953
DI 10.1007/s11042-017-4924-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100057
DA 2024-07-18
ER

PT J
AU Liu, ZB
   Ma, C
   Gao, CY
   Yang, HH
   Lan, RS
   Luo, XN
AF Liu, Zhenbing
   Ma, Chao
   Gao, Chunyang
   Yang, Huihua
   Lan, Rushi
   Luo, Xiaonan
TI Cost-sensitive collaborative representation based classification via
   probability estimation with addressing the class imbalance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collaborative representation; Cost-sensitive learning; Probability
   estimate; Loss function
ID PRINCIPAL COMPONENT ANALYSIS
AB Collaborative representation has been successfully used in pattern recognition and machine learning. However, most existing collaborative representation classification methods are to achieve the highest classification accuracy, assuming the same losses for different misclassifications. This assumption, however, may not hold in many real-word applications as different types of misclassification could lead to different losses. Meanwhile, the class distribution of data is highly imbalanced in real-world applications. To address this problem, a novel Cost-Sensitive Collaborative Representation based Classification (CSCRC) method via Probability Estimation with Addressing the Class Imbalance was proposed. Unlike traditional methods, the class label of test samples is predicted by minimizing the misclassification losses which are obtained via computing the posterior probabilities. In this paper, a Gaussian function was defined as a probability distribution of collaborative representation coefficient vector and the probability distribution was transformed into collaborative representation framework via logarithmic operator. The experiments show that our proposed method performs competitively compared with existing methods.
C1 [Liu, Zhenbing; Ma, Chao; Gao, Chunyang; Yang, Huihua; Lan, Rushi; Luo, Xiaonan] Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, 1 Jinji Rd, Qixing Strict 541000, Guilin, Peoples R China.
C3 Guilin University of Electronic Technology
RP Lan, RS (corresponding author), Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, 1 Jinji Rd, Qixing Strict 541000, Guilin, Peoples R China.
EM machao199271@sina.cn; rslan2016@163.com
RI Yang, Huihua/ABI-3520-2020
OI Yang, Huihua/0000-0001-6334-4044
FU National Natural Science Foundation of China [61562013, 61320106008];
   Guangxi Colleges and Universities Key Laboratory of Intelligent
   Processing of Computer Images and Graphics [LD16096x]; Center for
   Collaborative Innovation in the Technology of IOT and the
   Industrialization [WLW20060610]; Innovation Project of GUET Graduate
   Education; study abroad program for graduate student of Guilin
   University of Electronic Technology
FX The authors want to thank the anonymous reviewers and the associate
   editor for helpful comments and suggestions. This work is supported by
   the National Natural Science Foundation of China (Grant Nos. 61562013,
   61320106008), Guangxi Colleges and Universities Key Laboratory of
   Intelligent Processing of Computer Images and Graphics (Grant No.
   LD16096x), the Center for Collaborative Innovation in the Technology of
   IOT and the Industrialization (Grant No. WLW20060610), Innovation
   Project of GUET Graduate Education, the study abroad program for
   graduate student of Guilin University of Electronic Technology. The
   authors declare that they have no conflict of interest.
CR [Anonymous], IEEE PATTERN ANAL MA
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Blake Catherine, UCI repository of machine learning databases
   Cheng Y, 2016, NEUROCOMPUTING, V215, P250, DOI 10.1016/j.neucom.2015.06.117
   EthemAlpayd, 2011, MACH LEARN, V3, P195
   George Nysia I, 2016, Artif Intell Res, V5, P135, DOI 10.5430/air.v5n1p135
   Jiang LX, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415510040
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P5281, DOI 10.1109/TIP.2016.2605922
   Lan RS, 2012, NEUROCOMPUTING, V86, P184, DOI 10.1016/j.neucom.2012.01.026
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   Liu JK, 2015, BRAIN RES, V1610, P1, DOI 10.1016/j.brainres.2015.03.044
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384
   Polson NG, 2011, BAYESIAN ANAL, V6, P43, DOI 10.1214/11-BA601REJ
   Prince SJD, 2017, IEEE INT C COMPUT VI, V2007, P1
   Sadeghian A, 2016, COMPUT CHEM ENG, V90, P62, DOI 10.1016/j.compchemeng.2016.03.031
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu X, 2016, IEEE ACCESS, P1, DOI DOI 10.1155/2016/6141838
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang XW, 2014, IEEE T KNOWL DATA EN, V26, P2872, DOI 10.1109/TKDE.2014.2312336
   Zhang Y, 2010, IEEE T PATTERN ANAL, V32, P1758, DOI 10.1109/TPAMI.2009.195
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
NR 26
TC 3
Z9 3
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10835
EP 10851
DI 10.1007/s11042-017-5359-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900027
DA 2024-07-18
ER

PT J
AU Wu, ST
   Zhong, SH
   Liu, Y
AF Wu, Songtao
   Zhong, Shenghua
   Liu, Yan
TI Deep residual learning for image steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganalysis; Convolutional neural networks; Residual learning
AB Image steganalysis is to discriminate innocent images and those suspected images with hidden messages. This task is very challenging for modern adaptive steganography, since modifications due to message hiding are extremely small. Recent studies show that Convolutional Neural Networks (CNN) have demonstrated superior performances than traditional steganalytic methods. Following this idea, we propose a novel CNN model for image steganalysis based on residual learning. The proposed Deep Residual learning based Network (DRN) shows two attractive properties than existing CNN based methods. First, the model usually contains a large number of network layers, which proves to be effective to capture the complex statistics of digital images. Second, the residual learning in DRN preserves the stego signal coming from secret messages, which is extremely beneficial for the discrimination of cover images and stego images. Comprehensive experiments on standard dataset show that the DRN model can detect the state of arts steganographic algorithms at a high accuracy. It also outperforms the classical rich model method and several recently proposed CNN based methods.
C1 [Wu, Songtao; Zhong, Shenghua] Shenzhen Univ, Coll Comp Sci & Software Engn, Sheng, Guangdong, Peoples R China.
   [Liu, Yan] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
C3 Shenzhen University; Hong Kong Polytechnic University
RP Zhong, SH (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Sheng, Guangdong, Peoples R China.
EM csstwu@szu.edu.cn; csshzhong@szu.edu.cn; csyliu@comp.polyu.edu.hk
RI liu, yan/HGV-1365-2022
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], SPIE MEDIA WATERMARK
   [Anonymous], 2016, P THE 3 MULT INT SOC, DOI [DOI 10.1145/2955129.2955179, 10.1007/s00438-016-1266-0, DOI 10.1007/S00438-016-1266-0]
   [Anonymous], 2011, P MACHINE LEARNING R
   [Anonymous], ARXIV150201852V1
   [Anonymous], SPIE MEDIA WATERMARK
   [Anonymous], 2011, P 13 INF HID C PRAG
   [Anonymous], CONCURRENCY COMPUTAT
   [Anonymous], 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, DOI [10.1109/APSIPA.2014, 10.1109/APSIPA.2014.7041565]
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen H, 2015, IEEE J BIOMED HEALTH, V19, P1627, DOI 10.1109/JBHI.2015.2425041
   Couchot J F, 2016, ARXIV160507946V3
   Denemark T., 2014, IEEE WORKSH INF FOR
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   He K., 2015, C COMPUTER VISION PA
   Holub V, 2012, IEEE WORKSH INF FOR
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li B, 2009, IEEE T INF FOREN SEC, V4, P369, DOI 10.1109/TIFS.2009.2025841
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lyu S, 2004, PROC SPIE, V5306, P35, DOI 10.1117/12.526012
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   PROVOS N, 2002, P NETW DISTR SYST SE
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Ren TW, 2015, MULTIMEDIA SYST, V21, P189, DOI 10.1007/s00530-014-0384-y
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xu X, 2016, IEEE ACCESS, P1, DOI DOI 10.1155/2016/6141838
   Zhong SH, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957754
   Zhong SH, 2015, EXPERT SYST APPL, V42, P8146, DOI 10.1016/j.eswa.2015.05.034
NR 40
TC 253
Z9 280
U1 4
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10437
EP 10453
DI 10.1007/s11042-017-4440-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Yang, Z
   Zhu, JW
   Teng, L
   Xu, JJ
   Zhu, ZY
AF Yang, Zhou
   Zhu, Junwu
   Teng, Ling
   Xu, Jiajie
   Zhu, Zeyu
TI A double oracle algorithm for allocating resources on nodes in
   graph-based security games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game theory; Double oracle; Minimax equilibria; Distributed artificial
   intelligence; Mixed integer linear programming
AB In the graph-based security game, the defender allocates security resources strategically to protect targets against the adversary. In this paper, firstly, we come up with a new double oracle algorithm for scheduling resources optimally on nodes in graph-based security games. The police scattered on the street can only detect those terrorists on that street, while the police at the intersection place can detect all the terriorists on all the streets crisscrossing the intersection. Secondly, in real world situation, even the police meets the criminals at the same place, criminals still could escape. To match the real world situation, we define a parameter called detection probability, representing the chance the attacker is caught when they are checked by the defenders. Thirdly, we design a double oracle algorithm to find the equilibrium. But the computational complexity of best response oracles are extremely high. We design greedy algorithms and combine them with best response oracles to improve the algorithm efficiency without loss of correctness.
C1 [Yang, Zhou; Zhu, Junwu; Teng, Ling; Xu, Jiajie] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Zhu, Zeyu] Yangzhou Univ, Yangzhou, Jiangsu, Peoples R China.
C3 Yangzhou University; Yangzhou University
RP Zhu, JW (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
EM zhouyang996@foxmail.com; jwzhu@yzu.edu.cn
RI Zhu, Junwu/H-2641-2015
FU National Nature Science Foundation of China [61170201, 61070133,
   61472344]; Six talent peaks project in Jiangsu Province [2011-DZXX-032];
   Jiangsu Science and Technology Project [BY2015061-06, BY2015061-08];
   Yangzhou Science and Technology Project [SXT20140048, SXT20150014,
   SXT201510013]; Natural Science and Technology Project [SXT20140048,
   SXT20150014, SXT201510013]; Natural Science Foundation of the Jiangsu
   Higher Education Institutions [14KJB520041]; Jiangsu Student's Platform
   for Innovation and Entrepreneurship Training Program [201711117017Z]
FX Project supported by the National Nature Science Foundation of China
   (Grant No. 61170201, No. 61070133, No. 61472344), Six talent peaks
   project in Jiangsu Province (Grant No. 2011-DZXX-032), Jiangsu Science
   and Technology Project (Grant No. BY2015061-06, BY2015061-08), Yangzhou
   Science and Technology Project (Grant No. SXT20140048, SXT20150014,
   SXT201510013), Natural Science and Technology Project (Grant No.
   SXT20140048, SXT20150014, SXT201510013), Natural Science Foundation of
   the Jiangsu Higher Education Institutions (Grant No. 14KJB520041),
   Jiangsu Student's Platform for Innovation and Entrepreneurship Training
   Program (Grant No. 201711117017Z).
CR [Anonymous], ADAPTIVE AGENTS MULT
   [Anonymous], INT C AUT AG MULT SY
   Conitzer V., 2006, P 7 ACM C EL COMM, P82, DOI DOI 10.1145/1134707.1134717
   Ge SM, 2014, IEEE INT CON MULTI
   Halvorson E, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P159
   Jain M., 2011, P 10 INT C AUT AG MU, P327
   Jain M., 2013, Proceedings of the Twelfth International Conference on Autonomous Agents and Multi-Agent Systems AAMAS, P215, DOI DOI 10.5555/2484920
   Kiekintveld C., 2009, P 8 INT C AUT AG MUL, P689, DOI DOI 10.1017/CB09780511973031.008
   Lu H, 2017, MOBILE NETW APPL, P1
   McMahan H B, 2003, 20 INT C MACH LEARN, P536
   Pita J, 2009, AI MAG, V30, P43, DOI 10.1609/aimag.v30i1.2173
   Shieh E., 2012, P 11 INT C AUT AG MU, V1, P13
   Vanek Ondrej, 2010, 2010 IEEE Information Theory Workshop (ITW 2010), P9, DOI 10.1109/ITW.2010.5593377
   von Stackelberg H., 1934, Market structure and equilibrium
   WANG FY, 1990, AUTOMATICA, V26, P833, DOI 10.1016/0005-1098(90)90001-X
   Yin Z., 2010, P 9 INT C AUT AG MUL, P1139
NR 16
TC 3
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10961
EP 10977
DI 10.1007/s11042-018-5750-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900034
DA 2024-07-18
ER

PT J
AU Alphonse, AS
   Dharma, D
AF Alphonse, A. Sherly
   Dharma, Dejey
TI Novel directional patterns and a Generalized Supervised Dimension
   Reduction System (GSDRS) for facial emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion; dimension reduction; feature extraction; ELM; classification
ID EXTREME LEARNING-MACHINE; EXPRESSION RECOGNITION; FACE; REGRESSION
AB This paper presents two novel directional patterns, a Maximum Response-based Directional Texture Pattern (MRDTP) and a Maximum Response-based Directional Number Pattern (MRDNP), for recognizing the facial emotions in constrained as well as unconstrained situations. The intensity information obtained from the maximum of the edge responses, after applying eight Kirsch masks, is used for the calculation of facial features in MRDTP. In MRDNP, instead of intensity information, the direction number of the maximum response is used. After dividing MRDNP and MRDTP code images into grids, feature vectors are created from the concatenated histograms obtained from the grids. This paper also proposes an effective Generalized Supervised Dimension Reduction System (GSDRS) and uses Extreme Learning Machine with Radial Basis Function (ELM-RBF) classifier for rapid and efficient classification of emotions. Both the proposed patterns are more effective than the existing ones in removing random noise and providing good structural information using prominent edges which help to achieve high classification accuracy when tested with seven datasets.
C1 [Alphonse, A. Sherly; Dharma, Dejey] Anna Univ, CSE Dept, Reg Campus, Tirunelveli 627007, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Alphonse, AS (corresponding author), Anna Univ, CSE Dept, Reg Campus, Tirunelveli 627007, India.
EM sherls82@gmail.com; dejeytilak@gmail.com
OI Dharma, Dejey/0000-0002-5173-4878; , sherly/0000-0002-0019-9940
CR Abdulrahman M, 2014, SIG PROCESS COMMUN, P2265, DOI 10.1109/SIU.2014.6830717
   Agarwal S, 2018, VISUAL COMPUT, V34, P177, DOI 10.1007/s00371-016-1323-z
   Ahmed Faisal, 2013, Chinese Journal of Engineering, DOI 10.1155/2013/831747
   Ahmed F, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P265, DOI 10.1109/ICCE.2012.6161859
   Aifanti N., 2010, P 11 INT WORKSHOP IM
   Anisetti M, 2009, STUD COMPUT INTELL, V226, P401
   [Anonymous], 2015, 2015 International Joint Conference on Neural Networks (IJCNN)
   [Anonymous], EMOTION RECOGNITION
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, ARXIV170307140
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], AISC
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   Bhat F., 2015, Elastic, V3, DOI [10.11591/ijai.v3.i4.pp177-182, DOI 10.11591/IJAI.V3.I4.PP177-182]
   Bourbakis N, 2011, COGN COMPUT, V3, P436, DOI 10.1007/s12559-010-9072-1
   Calder AJ, 2001, VISION RES, V41, P1179, DOI 10.1016/S0042-6989(01)00002-5
   Castillo JAR, 2012, IEEE IMAGE PROC, P2613, DOI 10.1109/ICIP.2012.6467434
   Chen J, 2014, INT WORKSHOPS ELECT, P884
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 2004, Language, knowledge, and representation, P39, DOI DOI 10.1007/978-1-4020-2783-3_3
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Gupta SK, 1998, J APPL CRYSTALLOGR, V31, P474, DOI 10.1107/S0021889897011047
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Huang GB., 2005, Int J Inf Technol, V11, P16
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Iosifidis A, 2015, PATTERN RECOGN LETT, V54, P11, DOI 10.1016/j.patrec.2014.12.003
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   KIRSCH RA, 1971, COMPUT BIOMED RES, V4, P315, DOI 10.1016/0010-4809(71)90034-6
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mavadati M, 2016, P IEEE C COMPUTER VI, P1
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mavadati SM, 2012, IEEE IMAGE PROC, P1817, DOI 10.1109/ICIP.2012.6467235
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pantic M., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Ramirez Rivera A, 2012, INT C PATT RECOG, P1000
   Rivera AR, 2012, IEEE IMAGE PROC, P2609, DOI 10.1109/ICIP.2012.6467433
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shan CF, 2005, LECT NOTES COMPUT SC, V3766, P221, DOI 10.1007/11573425_22
   Suja P, 2014, ADV INTELL SYST COMP, V264, P299, DOI 10.1007/978-3-319-04960-1_27
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Üstün B, 2006, CHEMOMETR INTELL LAB, V81, P29, DOI 10.1016/j.chemolab.2005.09.003
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2014, UNIVERSAL ACCESS INF, V13, P23, DOI 10.1007/s10209-013-0312-5
   Wen GH, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1945630
   Wu Tingfan., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P42
   Xiao-li Hao, 2017, Advanced Multimedia and Ubiquitous Engineering, MUE/FutureTech 2017. LNEE 448, P419, DOI 10.1007/978-981-10-5041-1_68
   Xie SY, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2016.4328
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhao L, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7206041
   Zia MS, 2015, MULTIMED TOOLS APPL, V74, P3881, DOI 10.1007/s11042-013-1803-3
NR 74
TC 11
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9455
EP 9488
DI 10.1007/s11042-017-5141-8
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200017
DA 2024-07-18
ER

PT J
AU Budikova, P
   Batko, M
   Zezula, P
AF Budikova, Petra
   Batko, Michal
   Zezula, Pavel
TI ConceptRank for search-based image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Search-based image annotation; Content-based image retrieval; kNN
   classification; Biased random walk with restarts; Semantic analysis;
   ConceptRank
ID RETRIEVAL; FEATURES
AB Multimedia information is becoming an ubiquitous part of our lives, which brings an equally ubiquitous need for efficient multimedia retrieval. One of the possible solutions to this problem is to attach text descriptions to multimedia data objects, thus allowing users to utilize traditional text search mechanisms. Search-based annotation techniques attempt to determine the descriptive keywords by analyzing the descriptions of similar, already annotated multimedia objects, which are detected by content-based retrieval techniques. One of the main challenges of this approach is the extraction of semantically connected keywords from the possibly noisy descriptions of similar objects. In this paper, we address this challenge by proposing the ConceptRank, a new keyword ranking algorithm that exploits semantic relationships between candidate keywords and utilizes the random walk mechanism to compute the probability of individual candidates. The effectiveness of the ConceptRank algorithm is evaluated in context of web image annotation. We present a complex image annotation system that includes the ConceptRank component, and compare it to other state-of-the-art annotation techniques.
C1 [Budikova, Petra; Batko, Michal] Masaryk Univ, Fac Informat, Brno, Czech Republic.
   [Zezula, Pavel] Masaryk Univ, Fac Informat, Informat, Brno, Czech Republic.
C3 Masaryk University Brno; Masaryk University Brno
RP Budikova, P (corresponding author), Masaryk Univ, Fac Informat, Brno, Czech Republic.
EM budikova@fi.muni.cz; batko@fi.muni.cz; zezula@fi.muni.cz
RI Batko, Michal/D-9889-2012; Budikova, Petra/H-2004-2013
OI Budikova, Petra/0000-0003-1523-1744
FU Czech Science Foundation [P103/12/G084]
FX This paper is based on research supported by the Czech Science
   Foundation project No. P103/12/G084.
CR [Anonymous], 2004, P VLDB2004
   [Anonymous], P 2 INT WORKSH KEYW
   [Anonymous], INT C MULT RETR ICMR
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], ARXIV14126082 CORR
   [Anonymous], 2014, CLEF
   [Anonymous], P 8 ACM SIGMM INT WO, DOI DOI 10.1145/1178677.1178714
   [Anonymous], 2013, 17 INT DAT ENG APPL
   [Anonymous], CLEF 2014 EV LABS WO
   [Anonymous], 2014, CLEF WORKING NOTES
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], ARXIV14127479 CORR
   Batko M, 2007, LECT NOTES COMPUT SC, V4877, P1
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Budikova P, 2015, LECT NOTES COMPUT SC, V9283, P327, DOI 10.1007/978-3-319-24027-5_36
   Budikova P, 2011, LECT NOTES COMPUT SC, V6966, P130, DOI 10.1007/978-3-642-24469-8_15
   Cai X, 2012, LECT NOTES COMPUT SC, V7577, P823, DOI 10.1007/978-3-642-33783-3_59
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Fu JL, 2015, IEEE T CIRC SYST VID, V25, P1409, DOI 10.1109/TCSVT.2014.2380211
   Gupta MR, 2014, J MACH LEARN RES, V15, P1461
   Hu JW, 2013, PATTERN RECOGN, V46, P936, DOI 10.1016/j.patcog.2012.09.010
   JianSong Yu, 2012, Web Information Systems and Mining. Proceedings International Conference, WISM 2012, P580, DOI 10.1007/978-3-642-33469-6_72
   Ke X, 2013, COMPUT ELECTR ENG, V39, P945, DOI 10.1016/j.compeleceng.2012.09.017
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Li X., 2006, MULTIMEDIA 06, P607, DOI DOI 10.1145/1180639.1180764
   Lican Dai, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P134, DOI 10.1109/ICME.2012.104
   Lin ZJ, 2015, MULTIMED TOOLS APPL, V74, P4091, DOI 10.1007/s11042-013-1811-3
   Lin Zijia., 2012, Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM'12, P1784
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Lokoc Jakub, 2012, Similarity Search and Applications. Proceedings of the 5th International Conference, SISAP 2012, P177, DOI 10.1007/978-3-642-32153-5_13
   Lux M, 2010, FUTURE INTERNET, V2, P341, DOI 10.3390/fi2030341
   Maier O, 2012, J INTELL INF SYST, V39, P651, DOI 10.1007/s10844-012-0207-6
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Naidan B, 2015, PROC VLDB ENDOW, V8, P1618
   Novak D, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1039, DOI 10.1145/2766462.2767868
   Novak D, 2016, LECT NOTES COMPUT SC, V9510, P61, DOI 10.1007/978-3-662-49214-7_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schickel-Zuber V, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P551
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong HH, 2008, KNOWL INF SYST, V14, P327, DOI 10.1007/s10115-007-0094-2
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tousch AM, 2012, PATTERN RECOGN, V45, P333, DOI 10.1016/j.patcog.2011.05.017
   Wang CH, 2008, MULTIMEDIA SYST, V14, P205, DOI 10.1007/s00530-008-0128-y
   Wang XR, 2015, MULTIMED TOOLS APPL, V74, P2055, DOI 10.1007/s11042-013-1742-z
   Wang XJ, 2012, P IEEE, V100, P2705, DOI 10.1109/JPROC.2012.2193109
   Xixi He, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P11, DOI 10.1007/978-3-319-13168-9_2
   Zezula P., 2006, ADV IND CON, V32
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang XM, 2013, MULTIMED TOOLS APPL, V62, P601, DOI 10.1007/s11042-011-0863-5
NR 60
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8847
EP 8882
DI 10.1007/s11042-017-4777-8
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800048
DA 2024-07-18
ER

PT J
AU Kang, D
   Kim, S
   Park, S
AF Kang, Dongwann
   Kim, Sanggeun
   Park, Sangoh
TI Flow-guided hair removal for automated skin lesion identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dermatology; Skin lesion; Hair removal; Line detection
ID BORDER DETECTION; IMAGES; SEGMENTATION
AB In this paper, we propose a method for removing hairs automatically from skin lesion images. To achieve this, we employ an edge-detection technique based on edge-tangent flow. To detect only hair-like structures, rather than contour boundaries, we propose a novel, specialized method for detecting hairs. Regardless of the personal characteristics of the hairs, hairy regions are detected because our method detects coherent thin lines of consistent width. We then restore the hairy regions detected by the proposed method by using the texture synthesis method. Our method restores the regions occluded by hairs with very few remarkable artifacts, because we utilize pixels that actually exist in the source image to restore the occluded areas by searching for the best matching pixels.
C1 [Kang, Dongwann] Bournemouth Univ, Fac Sci & Technol SciTech, Poole, Dorset, England.
   [Kim, Sanggeun] Sungkyul Univ, Dept Comp Sci & Engn, Anyang, South Korea.
   [Park, Sangoh] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Bournemouth University; Sungkyul University; Chung Ang University
RP Park, S (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM sopark@cau.ac.kr
FU Chung-Ang University Research Grant
FX This research was supported by the Chung-Ang University Research Grant
   in 2017.
CR Abbas Q, 2011, COMPUT METH PROG BIO, V104, pE1, DOI 10.1016/j.cmpb.2010.06.016
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Chung DH, 2000, IEEE T MED IMAGING, V19, P763, DOI 10.1109/42.875204
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Fleming MG, 1998, COMPUT MED IMAG GRAP, V22, P375, DOI 10.1016/S0895-6111(98)00048-2
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Grana C, 2003, IEEE T MED IMAGING, V22, P959, DOI 10.1109/TMI.2003.815901
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   Schmid P, 1999, IEEE T MED IMAGING, V18, P164, DOI 10.1109/42.759124
   Schmid-Saugeon P, 2003, COMPUT MED IMAG GRAP, V27, P65, DOI 10.1016/S0895-6111(02)00048-4
   Society AC, KEY STAT MEL SKIN CA
   Taouil K., 2006, INFORM COMMUNICATION, V1, P212, DOI [10.1109/ICTTA.2006.1684373, DOI 10.1109/ICTTA.2006.1684373]
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wighton P, 2008, PROC SPIE, V6914, DOI 10.1117/12.770776
   Xie FY, 2009, COMPUT MED IMAG GRAP, V33, P275, DOI 10.1016/j.compmedimag.2009.01.003
   Zhang Z, 2000, IEEE T MED IMAGING, V19, P1128, DOI 10.1109/42.896789
   Zhou H, 2008, PROC SPIE, V6918, DOI 10.1117/12.770077
NR 19
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9897
EP 9908
DI 10.1007/s11042-018-5672-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200035
DA 2024-07-18
ER

PT J
AU Kumar, TS
   Prabha, KH
AF Kumar, T. Senthil
   Prabha, K. Helen
TI Geometric mean filter with grayscale morphological method to enhance the
   RNFL thickness in the SD-OCT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical coherence tomography; Retinal nerve fiber layer; Alzheimer;
   Segmentation; Feature extraction; Geometric mean filter; Grayscale
   morphological operations
ID COHERENCE TOMOGRAPHY IMAGES; DATA-PROCESSING FRAMEWORK; FIBER LAYER
   THICKNESS; GLAUCOMA; CLASSIFICATION; SECURITY; SYSTEM; MODEL
AB Alzheimer disease plays an important role in day-to-day life. Alzheimer disease is mainly affects the creative thinking, memory and other day-to-day activities. In general, Alzheimer disease influences more on the people who are in the age group of 80-year-90. A recent report from The Hindu states that nearly 50 lakhs of people are affected by Alzheimer disease in India. The essential goal of Optical Coherence Tomography (OCT) imaging technology is to identify the Retinal Nerve Fiber Layer (RNFL) thickness that originally detects the Alzheimer disease status in patients. Spectral-domain (SD) OCT devices have produces OCT images in greater speed; hence, fluctuation of sampling will be high. Open-top hat filter dose not perform well when over fluctuation of sampling of input OCT images. Geometric mean filter is not much affected by fluctuation of sampling. Hence, geometric mean filter with grayscale morphological method is used in this paper to remove the noises as well as enhance the RNFL thickness in the input SD-OCT images. The proposed Geometric mean filter with grayscale morphological operation method is comparatively analyzed with the our other existing approaches proposed earlier namely, various image enhancement approaches such as Otsu's method with Geometric mean filter, Switching Median Filter (SMF) with morphological operation, and Open Top Hat filter with Goldilocks method. The experimental results prove that the proposed geometric mean filter with grayscale morphological performed well when compared other approaches. The proposed algorithm is comparatively analyzed with the help of Sensitivity, Specificity, Accuracy, Mean Square Error (MSE) and Peak Signal to Noise Ratio (PSNR).
C1 [Kumar, T. Senthil] Anna Univ, Chennai, Tamil Nadu, India.
   [Prabha, K. Helen] RMD Engn Coll, ECE Dept, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Kumar, TS (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.
EM senthilkumartphd@gmail.com; helenprabha@yahoo.com
RI T, Senthil kumar/AAJ-8133-2021; K, D/JRX-3613-2023; K,
   Dr.HelenPrabha/V-9407-2019
OI T, Senthil kumar/0000-0002-8933-2145; K,
   Dr.HelenPrabha/0000-0002-4951-5748
CR Anantrasirichai N, 2014, COMPUT MED IMAG GRAP, V38, P526, DOI 10.1016/j.compmedimag.2014.06.012
   [Anonymous], HUMAN ELEMENT BIG DA
   [Anonymous], BIOMED RES
   [Anonymous], 2017, HINDU
   [Anonymous], INNOVATIVE HLTH SYST
   [Anonymous], PLOS ONE, DOI DOI 10.1371/JOURNAL.PONE.0170341
   [Anonymous], EXPLORING CONVERGENC
   Asaoka R, 2017, AM J OPHTHALMOL, V174, P95, DOI 10.1016/j.ajo.2016.11.001
   Banegas SA, 2016, J GLAUCOMA, V25, pE229, DOI 10.1097/IJG.0000000000000280
   Baran U, 2016, J NEUROSCI METH, V270, P132, DOI 10.1016/j.jneumeth.2016.06.014
   Birkeldh U, 2017, ACTA OPHTHALMOL, V95, DOI 10.1111/j.1755-3768.2017.0T027
   Chen CL, 2016, INVEST OPHTH VIS SCI, V57, pOCT475, DOI 10.1167/iovs.15-18909
   Gao ZJ, 2017, COMPUT MED IMAG GRAP, V55, P42, DOI 10.1016/j.compmedimag.2016.07.006
   Goh JP, 2017, J GLAUCOMA, V26, P619, DOI 10.1097/IJG.0000000000000683
   Karri SPK, 2017, BIOMED OPT EXPRESS, V8, P579, DOI 10.1364/BOE.8.000579
   Kromer R, 2016, J MED BIOL ENG, V36, P485, DOI 10.1007/s40846-016-0152-x
   Kulcsar C., 2014, 2014 INT WORKSH COMP, P1
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Lee S, 2017, MED IMAGE ANAL, V35, P570, DOI 10.1016/j.media.2016.08.012
   Lopez D, 2016, INT J INFECT DIS, V45, P23, DOI 10.1016/j.ijid.2016.02.084
   Lopez D, 2017, HDB STAT, V37, P301, DOI DOI 10.1590/S0034-76122011000200003
   Lopez D, 2015, ADV INTELL SYST, V415, P195, DOI 10.1007/978-3-319-27212-2_16
   Lopez Daphne, 2014, Proc IEEE Int Conf Big Data, V2014, P19, DOI 10.1109/BigData.2014.7004422
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Manogaran G, 2018, WIRELESS PERS COMMUN, V102, P2099, DOI 10.1007/s11277-017-5044-z
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Manogaran G, 2018, CLUSTER COMPUT, V21, P189, DOI 10.1007/s10586-017-0982-5
   Manogaran G, 2018, COMPUT ELECTR ENG, V65, P207, DOI 10.1016/j.compeleceng.2017.04.006
   Manogaran G, 2017, INT J BIOMED ENG TEC, V25, P182, DOI 10.1504/IJBET.2017.087722
   Manogaran G, 2017, STUD BIG DATA, V23, P133, DOI 10.1007/978-3-319-49736-5_7
   Manogaran G, 2017, INT J AMBIENT COMPUT, V8, P88, DOI 10.4018/IJACI.2017040106
   Manogaran G, 2016, PROCEDIA COMPUT SCI, V87, P128, DOI 10.1016/j.procs.2016.05.138
   Mwanza JC, 2016, AM J OPHTHALMOL, V161, P12, DOI 10.1016/j.ajo.2015.09.019
   Rao HL, 2014, J GLAUCOMA, V23, P589, DOI 10.1097/IJG.0b013e318286ffa5
   Rasta Seyed Hossein, 2015, J Med Signals Sens, V5, P40
   Sudeep PV, 2016, COMPUT BIOL MED, V71, P97, DOI 10.1016/j.compbiomed.2016.02.003
   Uji A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128512
   Varatharajan R, 2018, COMPUT ELECTR ENG, V70, P447, DOI 10.1016/j.compeleceng.2017.05.035
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P10195, DOI 10.1007/s11042-017-5318-1
   Varatharajan R., 2018, Cluster Computing, V21, P681, DOI 10.1007/s10586-017-0977-2
   Varatharajan R, 2018, MULTIMED TOOLS APPL, V77, P17573, DOI [10.1007/s11042-017-4768-9, 10.1007/s11042-017-5318-1]
NR 41
TC 2
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10285
EP 10301
DI 10.1007/s11042-017-5487-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200058
DA 2024-07-18
ER

PT J
AU Sharma, K
AF Sharma, Kajal
TI Improved visual SLAM: a novel approach to mapping and localization using
   visual landmarks in consecutive frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SLAM; Localization; Landmarks; Video processing
ID VISION; SCALE; EXTRACTION
AB Pathfinding is becoming more and more common in autonomous vehicle navigation, robot localization, and other computer vision applications. In this paper, a novel approach to mapping and localization is presented that extracts visual landmarks from a robot dataset acquired by a Kinect sensor. The visual landmarks are detected and recognized using the improved scale-invariant feature transform (I-SIFT) method. The methodology is based on detecting stable and invariant landmarks in consecutive (red-green-blue depth) RGB-D frames of the robot dataset. These landmarks are then used to determine the robot path, and a map is constructed by using the visual landmarks. A number of experiments were performed on various datasets in an indoor environment. The proposed method performs efficient landmark detection in various environments, which includes changes in rotation and illumination. The experimental results show that the proposed method can solve the simultaneous localization and mapping (SLAM) problem using stable visual landmarks, but with less computation time.
C1 [Sharma, Kajal] Flat 301,Bldg 206,24 Namyang Dong, Chang Won, South Korea.
RP Sharma, K (corresponding author), Flat 301,Bldg 206,24 Namyang Dong, Chang Won, South Korea.
EM kajal175@gmail.com
CR [Anonymous], P ROB SCI SYST RSS
   [Anonymous], 2021, P RGB D WORKSH 3D PE
   [Anonymous], P NAT C ART INT AAAI
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], INT S EXP ROB ISER
   [Anonymous], 2011, P INT S MIX AUGM REA
   [Anonymous], P INT S EXP ROB ISER
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Chen SY, 2005, IEEE T SYST MAN CY B, V35, P894, DOI 10.1109/TSMCB.2005.846907
   Chiang JS, 2013, IEEE SENS J, V13, P1677, DOI 10.1109/JSEN.2013.2240449
   Claraco JLB, 2010, DEVELOPMENT OF SCIEN
   Comport AI, 2010, INT J ROBOT RES, V29, P245, DOI 10.1177/0278364909356601
   Gedik OS, 2013, IEEE T CYBERNETICS, V43, P1395, DOI 10.1109/TCYB.2013.2272735
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486
   Grisetti G, 2009, IEEE T INTELL TRANSP, V10, P428, DOI 10.1109/TITS.2009.2026444
   Jiang CS, 2016, IEEE ROBOT AUTOM LET, V1, P324, DOI 10.1109/LRA.2016.2517207
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Ke Y, 2004, PROC CVPR IEEE, P506
   Koeser K, 2007, GERM C PATT REC
   Konolige K, 2009, P IEEE RSJ INT C INT
   Lee J, 2011, ELECTRON LETT, V47, P1075, DOI 10.1049/el.2011.1832
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Magnusson M, 2009, J FIELD ROBOT, V26, P892, DOI 10.1002/rob.20314
   Manduchi R, 2005, AUTON ROBOT, V18, P81, DOI 10.1023/B:AURO.0000047286.62481.1d
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nistér D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y
   Nüchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209
   Park J, 2015, IEEE T AERO ELEC SYS, V51, P3226, DOI 10.1109/TAES.2015.140222
   Pollefeys M, 2002, COMMUN ACM, V45, P50, DOI 10.1145/514236.514263
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467
   Segal Aleksandr, 2009, ROBOTICS SCI SYSTEMS, V2
   Shao L, 2013, IEEE T CYBERNETICS, V43, P1314, DOI 10.1109/TCYB.2013.2276144
   Sharma K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033017
   Sharma K, 2012, IETE TECH REV, V29, P473, DOI 10.4103/0256-4602.105002
   Sharma K, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.107002
   Stuckler J., 2012, IEEE INT C MULT FUS
   Stuhmer J, 2010, DAGM S PATT REC
   Sturm J., 2011, RGB D WORKSH ADV REA
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085
   Zamora E, 2013, IETE TECH REV, V30, P490, DOI 10.4103/0256-4602.125671
NR 42
TC 4
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7955
EP 7976
DI 10.1007/s11042-017-4694-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800009
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Yuadi, I
AF Tsai, Min-Jen
   Yuadi, Imam
TI Digital forensics of microscopic images for printed source
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microscopic images; Digital image forensics; Feature filters; Support
   vector machines (SVM); Local binary pattern (LBP)
ID SECURITY; CLASSIFICATION; FEATURES; BLACK
AB When trying to identify a printed forged document, examining digital evidence can prove to be a challenge. In this study, microscopic images are used for printed source identification due to their high magnification properties resulting in detailed texture and structure information. Prior research implemented a scanner as a digitizing technique to resolve very fine printed identification, but this technique provided limited information on the resolution and magnification of the sample. In contrast, the performance of microscopy techniques can retrieve the shape and surface texture of a printed document with differing micro structures among printer sources. To explore the relationship between source printers and images obtained by the microscope, the proposed approach utilizes image processing techniques and data exploration methods to calculate many important statistical features, including: Local Binary Pattern (LBP), Gray Level Co-occurrence Matrix (GLCM), Discrete Wavelet Transform (DWT), Spatial filters, the Wiener filter, the Gabor filter, Haralick, and SFTA features. Among the different set of features, the LBP approach achieves the highest identification rate and is significantly superior to other methods. As a result, the proposed technique using microscopic images achieves a high classification accuracy rate, which shows promising applications for real world digital forensics research.
C1 [Tsai, Min-Jen; Yuadi, Imam] Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
   [Yuadi, Imam] Airlangga Univ, Dept Informat & Lib Sci, Jl Airlangga 4-6, Surabaya 60286, East Java, Indonesia.
C3 National Yang Ming Chiao Tung University; Airlangga University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
RI Yuadi/V-3570-2018
FU National Science Council in Taiwan, Republic of China
   [NSC104-2410-H-009-020-MY2]
FX This work was partially supported by the National Science Council in
   Taiwan, Republic of China, under NSC104-2410-H-009-020-MY2.
CR ABRAMOWITZ M., The Concept of Magnification, in
   Ali GN, 2004, IS&T'S NIP20: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, PROCEEDINGS, P301
   Bekhti MA, 2016, LECT NOTES COMPUT SC, V9431, P282, DOI 10.1007/978-3-319-29451-3_23
   Buchanan JDR, 2005, NATURE, V436, P475, DOI 10.1038/436475a
   Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   Chiang PJ, 2009, IEEE SIGNAL PROC MAG, V26, P72, DOI 10.1109/MSP.2008.931082
   Choi JH, 2013, MULTIMED TOOLS APPL, V67, P363, DOI 10.1007/s11042-011-0835-9
   Chu PC, 2013, ANAL CHEM, V85, P4311, DOI 10.1021/ac400378q
   Chun-Lin Liu., 2010, A Tutorial of the wavelet transform
   Costa A. F., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P39, DOI 10.1109/SIBGRAPI.2012.15
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Ferreira A, 2015, FORENSIC SCI INT, V247, P105, DOI 10.1016/j.forsciint.2014.11.030
   Gonzales R. C., 2008, Digital Image Processing
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Herman B., 1993, OPTICAL MICROSCOPY E
   Hewlett- Packard Company, 2002, HP LASERJET 4200 430
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Juric I, 2014, J GRAPHIC ENG DES, V5, P17
   Juuti M, 2007, COLLOID SURFACE A, V299, P101, DOI 10.1016/j.colsurfa.2006.11.039
   Kawasaki M., 2009, TAPPI J, V63, P1362, DOI 10.2524/jtappij.63.1362
   Kim DG, 2014, EUR SIGNAL PR CONF, P795
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Kundur D, 2004, P IEEE, V92, P879, DOI 10.1109/JPROC.2004.827336
   Li QY, 2016, ATMOS MEAS TECH, V9, P753, DOI 10.5194/amt-9-753-2016
   Maenpaa T, 2004, HDB PATTERN RECOGNIT, P115
   Marcella AJ, 2012, WILEY CORP F&A, P1
   Mihlbachler MC, 2012, PALAEONTOL ELECTRON, V15
   Mikkilineni AK, 2005, IS&T'S NIP21: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P223
   Mikkilineni AK, 2005, PROC SPIE, V5681, P430, DOI 10.1117/12.593796
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oravec M, 2015, ACTA CHIM SLOVACA, V8, P191, DOI 10.1515/acs-2015-0031
   Osadchy M, 2007, IEEE T PATTERN ANAL, V29, P98, DOI 10.1109/TPAMI.2007.250602
   Pollard S, 2013, PRINT BIOMETRICS REC
   Pollard SB, 2010, IEEE INT WORKS INFOR
   Ryu SJ, 2010, INT CONF ACOUST SPEE, P1846, DOI 10.1109/ICASSP.2010.5495377
   Say OT, 2013, 2013 IEEE REGIONAL SYMPOSIUM ON MICRO AND NANOELECTRONICS (RSM 2013), P273, DOI 10.1109/RSM.2013.6706528
   Schalkoff Robert J., 1989, Digital image processing and computer vision
   Sharma A, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P99
   Sharma G, 2016, INT CONF COMMUN SYST
   Simske SJ, 2010, INT CONF ACOUST SPEE, P1794, DOI 10.1109/ICASSP.2010.5495416
   Su R, 2005, PHYS PROPERTIES LWC
   Szynkowska MI, 2010, SURF INTERFACE ANAL, V42, P429, DOI 10.1002/sia.3194
   Tsai MJ, 2015, IEEE INT SYMP CIRC S, P2800, DOI 10.1109/ISCAS.2015.7169268
   Tsai MJ, 2014, MULTIMED TOOLS APPL, V73, P2129, DOI 10.1007/s11042-013-1642-2
   Tsai MJ, 2013, IEEE INT SYMP CIRC S, P2347, DOI 10.1109/ISCAS.2013.6572349
   Vega L.R., 2013, A Rapid Introduction to Adaptive Filtering
   Voloshynovskiy S, 2016, INT CONF ACOUST SPEE, P2029, DOI 10.1109/ICASSP.2016.7472033
   Zhu Baoshi., 2003, ACM CCS '03, P145, DOI DOI 10.1145/948109.948131
NR 49
TC 8
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8729
EP 8758
DI 10.1007/s11042-017-4771-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800043
DA 2024-07-18
ER

PT J
AU Ejbali, R
   Zaied, M
AF Ejbali, Ridha
   Zaied, Mourad
TI A dyadic multi-resolution deep convolutional neural wavelet network for
   image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Pattern recognition; Multi-resolution; Deep
   convolutional neural wavelet network; FastWavelet Transform; Adaboost
ID FAST LEARNING ALGORITHM; RECOGNITION; REPRESENTATION; SCENE; SHAPE
AB For almost the past four decades, image classification has gained a lot of attention in the field of pattern recognition due to its application in various fields. Given its importance, several approaches have been proposed up to now. In this paper, we will present a dyadic multi-resolution deep convolutional neural wavelets' network approach for image classification. This approach consists of performing the classification of one class versus all the other classes of the dataset by the reconstruction of a Deep Convolutional Neural Wavelet Network (DCNWN). This network is based on the Neural Network (NN) architecture, the Fast Wavelet Transform (FWT) and the Adaboost algorithm. It consists, first, of extracting features using the FWT based on the Multi-Resolution Analysis (MRA). These features are used to calculate the inputs of the hidden layer. Second, those inputs are filtered by using the Adaboost algorithm to select the best ones corresponding to each image. Third, we create an AutoEncoder (AE) using wavelet networks of all images. Finally, we apply a pooling for each hidden layer of the wavelet network to obtain a DCNWN that permits the classification of one class and rejects all other classes of the dataset. Classification rates given by our approach show a clear improvement compared to those cited in this article.
C1 [Ejbali, Ridha; Zaied, Mourad] Univ Sfax, Res Lab Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ejbali, R (corresponding author), Univ Sfax, Res Lab Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM ridha_ejbali@ieee.org; mourad.zaied@ieee.org
RI Ejbali, Ridha/K-4234-2012
OI Ejbali, Ridha/0000-0002-8148-1621
FU General Direction of Scientific Research (DGRST)
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Al-Jawfi R, 2009, INT ARAB J INF TECHN, V6, P304
   [Anonymous], INT J WAVELETS MULTI
   [Anonymous], INT JOINT C NEUR NET
   [Anonymous], 27 INT C MACH LEARN
   [Anonymous], P INTERSPEECH
   [Anonymous], COMPUTER MODELLING N
   [Anonymous], FDN WAVELETNETWORKS
   [Anonymous], 2010, MOMENTUM
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], J CORR
   [Anonymous], ADV INTEL SYST COMPU
   [Anonymous], COMPUT VIS PATT RECO
   [Anonymous], 2014, IEEE ACM T AUDIO SPE
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bonneau GP, 2008, MATH VIS, P83, DOI 10.1007/978-3-540-33265-7_3
   Chen ZL, 2014, IEEE INT SYMP CIRC S, P1552, DOI 10.1109/ISCAS.2014.6865444
   Daugman J., 2003, INT J WAVELETS MULTI, V1, P1, DOI DOI 10.1142/S0219691303000025
   ElAdel A, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2015), P408, DOI 10.1109/HPCSim.2015.7237069
   ElAdel A, 2015, PROC INT C TOOLS ART, P807, DOI 10.1109/ICTAI.2015.119
   ElAdel A, 2014, LECT NOTES COMPUT SC, V8669, P378, DOI 10.1007/978-3-319-10840-7_46
   Elzobi M, 2013, PROC INT CONF DOC, P945, DOI 10.1109/ICDAR.2013.192
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fernandez Merjildo Diego Alonso, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P527, DOI 10.1007/978-3-642-33275-3_65
   Griffin G., Caltech-256 object category dataset
   Hassairi S, 2015, INT CONF INTELL SYST, P207, DOI 10.1109/ISDA.2015.7489226
   Hassairi S, 2015, PROC INT C TOOLS ART, P265, DOI 10.1109/ICTAI.2015.49
   Hertel L., 2015, 2015 INT JOINT C NEU, P1
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   JAWERTH B, 1994, SIAM REV, V36, P377, DOI 10.1137/1036095
   Jemai O, 2011, INT J PATTERN RECOGN, V25, P1297, DOI 10.1142/S0218001411009111
   Kavukcuoglu K., 2010, Advances in neural information processing systems, P1
   Khalifa M, 2011, COMM COM INF SC, V143, P163
   Krizhevsky A, 2012, Neural Info Proc Syst, V25
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le Q. V., 2011, P 28 INT C INT C MAC, P265
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   LeCun Y, 2012, LECT NOTES COMPUT SC, V7583, P496, DOI 10.1007/978-3-642-33863-2_51
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Liu WF, 2016, NEUROCOMPUTING, V187, P59, DOI 10.1016/j.neucom.2015.07.119
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   PATI YC, 1993, IEEE T NEURAL NETWOR, V4, P73, DOI 10.1109/72.182697
   Plötz T, 2009, INT J DOC ANAL RECOG, V12, P269, DOI 10.1007/s10032-009-0098-4
   Slimane F., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P670, DOI 10.1109/ICFHR.2010.110
   SZU HH, 1992, OPT ENG, V31, P1907, DOI 10.1117/12.59918
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Weibao Zou, 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P151, DOI 10.1109/CGIV.2011.20
   Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   Zhou WY, 1999, IEEE T GEOSCI REMOTE, V37, P771, DOI 10.1109/36.752193
   Zou W., 2012, ADV NEURAL INFORM PR, V25, P3203, DOI DOI 10.5555/2999325.2999492
NR 58
TC 14
Z9 14
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6149
EP 6163
DI 10.1007/s11042-017-4523-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800047
DA 2024-07-18
ER

PT J
AU Liu, H
   Zheng, QH
   Li, ZH
   Qin, T
   Zhu, L
AF Liu, Huan
   Zheng, Qinghua
   Li, Zhihui
   Qin, Tao
   Zhu, Lei
TI An efficient multi-feature SVM solver for complex event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia event detection; Multi-feature learning; SVM solver
AB Multimedia event detection (MED) has become one of the most important visual content analysis tools as the rapid growth of the user generated videos on the Internet. Generally, multimedia data is represented by multiple features and it is difficult to gain better performance for complex event detection with only single feature. However, how to fuse different features effectively is the crucial problem for MED with multiple features. Meanwhile, exploiting multiple features simultaneously in the large-scale scenarios always produces a heavy computational burden. To address these two issues, we propose a self-adaptive multi-feature learning framework with efficient Support Vector Machine (SVM) solver for complex event detection in this paper. Our model is able to utilize multiple features reasonably with an adaptively weighted linear combination manner, which is simple yet effective, according to the various impact that different features on a specific event. In order to mitigate the expensive computational cost, we employ a fast primal SVM solver in the proposed alternating optimization algorithm to obtain the approximate solution with gradient descent method. Extensive experiment results over standard datasets of TRECVID MEDTest 2013 and 2014 demonstrate the effectiveness and superiority of the proposed framework on complex event detection.
C1 [Liu, Huan; Zheng, Qinghua; Qin, Tao] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China.
   [Li, Zhihui] Beijing Etrol Technol Co Ltd, Beijing, Peoples R China.
   [Zhu, Lei] Univ Queensland, Sch Informat Technol & Elect Engn, Brisbane, Qld, Australia.
C3 Xi'an Jiaotong University; University of Queensland
RP Liu, H (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, MOEKLINNS Lab, Xian, Shaanxi, Peoples R China.
EM huanliucs@gmail.com; qhzheng@mail.xjtu.edu.cn; zhihuilics@gmail.com;
   qin.tao@mail.xjtu.edu.cn; l.zhu@uq.edu.au
RI Li, Zhihui/AAB-7394-2020; Zhu, Lei/GQQ-1130-2022
OI Li, Zhihui/0000-0001-9642-8009; Zhu, Lei/0000-0002-5348-7532; Zhu,
   Lei/0000-0002-2993-7142
FU "The Fundamental Theory and Applications of Big Data with Knowledge
   Engineering" under the National Key Research and Development Program of
   China [2016YFB1000903]; Ministry of Education Innovation Research Team
   [IRT 17R86]; Project of China Knowledge Centre for Engineering Science
   and Technology; National Science Foundation of China [61502377]
FX This work is was supported in part by "The Fundamental Theory and
   Applications of Big Data with Knowledge Engineering" under the National
   Key Research and Development Program of China with grant Nos.
   2016YFB1000903; Ministry of Education Innovation Research Team No. IRT
   17R86; Project of China Knowledge Centre for Engineering Science and
   Technology; National Science Foundation of China under Grant Nos.
   61502377.
CR [Anonymous], 2015, ARXIV150301817
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], TRECVID 2013 WORKSH
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], P EUR C COMP VIS ECC
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Cortes C., 2010, Proceedings of the 27th International Conference on Machine Learning, P239
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Farquhar J.D. R., 2005, NIPS
   Gill PE, 2012, COMPUT OPTIM APPL, V51, P1, DOI 10.1007/s10589-010-9339-1
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Hsieh C. J., 2008, P 25 INT C MACH LEAR, P408
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kludas J, 2007, P 5 INT WORKSH AD MU, P147
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lin CJ, 2008, J MACH LEARN RES, V9, P627
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Nie FP, 2014, PR MACH LEARN RES, V32, P505
   Over P., 2014, Proceedings of TRECVID, P52
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335
   Tzelepis Christos, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P3, DOI 10.1007/978-3-319-27671-7_1
   Wang M., 2007, ACM Multi- media, P862
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang Y, 2009, PR ELECTROMAGN RES S, P311, DOI 10.1145/1631272.1631316
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yu SI, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P825, DOI 10.1145/2647868.2654997
   Yu SI, 2012, P NIST TRECVID 2012
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
NR 47
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3509
EP 3532
DI 10.1007/s11042-017-5166-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600033
DA 2024-07-18
ER

PT J
AU Guimaraes, MD
   Dias, DRC
   Mota, JH
   Gnecco, BB
   Durelli, VHS
   Trevelin, LC
AF Guimaraes, Marcelo de Paiva
   Colombo Dias, Diego Roberto
   Mota, Jose Hamilton
   Gnecco, Bruno Barberi
   Serapilha Durelli, Vinicius Humberto
   Trevelin, Luis Carlos
TI Immersive and interactive virtual reality applications based on 3D web
   browsers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; HTML5; JavaScript; WebGL; WebRTC; Computer cluster
ID VISUALIZATION; CAVE
AB This study explores the possibility of effectively using web-standard technologies (i.e., HTML5, JavaScript, WebGL, and WebRTC) to deploy full immersive and interactive virtual reality applications. These applications are based on computer clusters and run in multi-projection environments, such as CAVEs, Panoramas and Power Walls. Until recently, these applications were build using tailored solutions, such low-level libraries to distribute data. We discuss the modern-day web technology which allows these applications meet a multi-platform requirement. This paper also evaluates the communication and synchronization requirements of these applications that are traditionally the main bottleneck. As a proof-of-concept to show the feasibility of our study, we devised and implemented an immersive and interactive virtual reality application employing only web technologies. Our proof-of-concept runs on a miniCAVE environment with three displays and a 6-node cluster.
C1 [Guimaraes, Marcelo de Paiva] Open Univ Brazil UAB, Fed Univ Sao Paulo UNIFESP, Sao Paulo, Brazil.
   [Guimaraes, Marcelo de Paiva; Mota, Jose Hamilton; Serapilha Durelli, Vinicius Humberto] Fac Campo Limpo Paulista Faccamp, Campo Limpo Paulista, Sao Paulo, Brazil.
   [Colombo Dias, Diego Roberto] Fed Univ Sao Joao del Rei UFSJ, Sao Joao Del Rei, Brazil.
   [Gnecco, Bruno Barberi] Corollarium Technol, Sao Paulo, Brazil.
   [Serapilha Durelli, Vinicius Humberto] Univ Sao Paulo, Sao Paulo, Brazil.
   [Trevelin, Luis Carlos] Fed Univ Sao Carlos UFSCar, Sao Carlos, SP, Brazil.
C3 Universidade Federal de Sao Paulo (UNIFESP); Faculdade Campo Limpo
   Paulista; Universidade Federal de Sao Joao del-Rei; Universidade de Sao
   Paulo; Universidade Federal de Sao Carlos
RP Guimaraes, MD (corresponding author), Open Univ Brazil UAB, Fed Univ Sao Paulo UNIFESP, Sao Paulo, Brazil.; Guimaraes, MD (corresponding author), Fac Campo Limpo Paulista Faccamp, Campo Limpo Paulista, Sao Paulo, Brazil.
EM marcelodepaiva@gmail.com; diegocolombo.dias@gmail.com;
   hamiltonmota@gmail.com; brunobg@gmail.com; vinicius.durelli@gmail.com;
   trevelin@dc.ufscar.br
RI Dias, Diego Roberto DRCD Colombo/F-7404-2012; Guimarães, Marcelo
   Paiva/F-7767-2012
OI Dias, Diego Roberto DRCD Colombo/0000-0001-9619-2171; Guimarães, Marcelo
   Paiva/0000-0001-5026-1581
CR Abbasi A, 2012, IEEE MULTIMEDIA, V19, P80, DOI 10.1109/MMUL.2011.77
   [Anonymous], S BRAS REAL VIRT SBC
   [Anonymous], P 9 INT C 3D WEB TEC
   [Anonymous], P 12 ACM SIGGRAPH IN
   [Anonymous], UNITY CLUSTER PACKAG
   [Anonymous], INTRO WEB DEV USING
   [Anonymous], THESIS
   [Anonymous], 2010, OGRE 3D 1 7 BEGINNER
   [Anonymous], P 7 INT C 3D WEB TEC
   [Anonymous], WEBRTC 1 0 IN PRESS
   [Anonymous], JAV 3D LIB
   Anthes C, 2005, COMPUT INFORM, V24, P31
   Boukerche A, 2006, PROC ANNU SIMUL SYMP, P269, DOI 10.1109/ANSS.2006.31
   Bues M, 2001, SPRING EUROGRAP, P165
   Chen L, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P821
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Danchilla B., 2012, Beginning WebGL for HTML5
   DeFanti TA, 2009, FUTURE GENER COMP SY, V25, P114, DOI 10.1016/j.future.2008.06.016
   Drolet F, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P271, DOI 10.1109/VR.2009.4811050
   Finkelstein S, 2011, PRESENCE-TELEOP VIRT, V20, P78, DOI 10.1162/pres_a_00036
   Hall D., 2013, ANSIBLE CONFIGURATIO
   Hemminger Stephen., 2005, Network emulation with netem (lca 2005)
   Hendrix V, 2012, J PHYS CONF SER, V396, DOI 10.1088/1742-6596/396/4/042027
   Humphreys G, 2001, COMP GRAPH, P129, DOI 10.1145/383259.383272
   Humphreys G, 2002, ACM T GRAPHIC, V21, P693, DOI 10.1145/566570.566639
   Jackson S., 2015, UNITY 3D UI ESSENTIA
   Kemeny Andras., 2014, Proceedings of the 2014 Virtual Reality International Conference (VRIC'14), P1
   Kuhlen TW, 2014, IEEE COMPUT GRAPH, V34, P14, DOI 10.1109/MCG.2014.97
   Kuntz S, 2015, P IEEE VIRT REAL ANN, P391, DOI 10.1109/VR.2015.7223460
   Li MN, 2012, ELECTRON COMMER RES, V12, P53, DOI 10.1007/s10660-012-9088-6
   Lv ZH, 2016, IEEE INTERNET THINGS, V3, P1015, DOI 10.1109/JIOT.2016.2546307
   Lv ZH, 2016, IEEE ACCESS, V4, P407, DOI 10.1109/ACCESS.2016.2517076
   MOLNAR S, 1994, IEEE COMPUT GRAPH, V14, P23, DOI 10.1109/38.291528
   Moreau Guillaume, 2013, 2013 26th Conference on Graphics, Patterns and Images - Tutorials (SIBGRAPI-T), P6, DOI 10.1109/SIBGRAPI-T.2013.9
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Pacheco Peter, 2011, Morgan An Introduction to Parallel Programming, V1st
   Schaeffer B, 2003, P IEEE VIRT REAL ANN, P15, DOI 10.1109/VR.2003.1191116
   Steinbach E, 2011, IEEE SIGNAL PROC MAG, V28, P87, DOI 10.1109/MSP.2010.938753
   Tiwari D., 2012, 2012 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS), P221, DOI 10.1109/ISPASS.2012.6189228
   You Y, 2008, IEEE ICC, P1824, DOI 10.1109/ICC.2008.350
   Yunyang Wang, 2011, International Journal of Agricultural and Biological Engineering, V4, P1, DOI 10.3965/j.issn.1934-6344.2011.01.001-019
NR 41
TC 12
Z9 12
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 347
EP 361
DI 10.1007/s11042-016-4256-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400015
DA 2024-07-18
ER

PT J
AU Kumari, S
   Das, AK
   Li, X
   Wu, F
   Khan, MK
   Jiang, Q
   Islam, SKH
AF Kumari, Saru
   Das, Ashok Kumar
   Li, Xiong
   Wu, Fan
   Khan, Muhammad Khurram
   Jiang, Qi
   Islam, S. K. Hafizul
TI A provably secure biometrics-based authenticated key agreement scheme
   for multi-server environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Multi-server; Useranonymity; Forwardsecrecy; Biometrics;
   Fuzzy extractor
ID USER AUTHENTICATION; SMART CARDS; EFFICIENT; ARCHITECTURE;
   CRYPTANALYSIS; PROTOCOL; WEAKNESSES; ANONYMITY; EXCHANGE
AB An authentication scheme handling multiple servers offers a feasible environment to users to conveniently access the rightful services from various servers using one-time registration. The practical realization of distribution of online services efficiently and transparently in multiple-server systems has come true by virtue of multi-server user authentication schemes. Due to distinguished properties like, difficulty to forge or copy, in-feasibility to lose or guess or forget, etc., biometrics have been widely preferred as a third authenticating factor in password and smart card based user authentication protocols. In this paper, we design a new biometrics-based multi-server authentication scheme based on trusted multiple-servers. We harness the concept of fuzzy extractor to provide the proper matching of biometric patterns. We evaluate our scheme through informal discussions on performance and also using Burrows-Abadi-Needham logic (BAN-logic) & random oracle model for formal security analysis. We also compose a comparative assessment of our scheme and the related ones. Outcome of the analysis and assessment shows our scheme an edge above many related and contemporary schemes.
C1 [Kumari, Saru] Chaudhary Charan Singh Univ, Dept Math, C-3, Meerut 282002, Uttar Pradesh, India.
   [Das, Ashok Kumar] Int Inst Informat Technol, Ctr Secur Theory & Algorithm Res, Hyderabad 500032, Andhra Pradesh, India.
   [Li, Xiong] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Wu, Fan] Huaqiao Univ, Xiamen Inst Technol, Dept Comp Sci & Engn, Xiamen 361021, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
   [Jiang, Qi] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Islam, S. K. Hafizul] Birla Inst Technol & Sci, Dept Comp Sci & Informat Syst, Pilani 333031, Rajasthan, India.
C3 Chaudhary Charan Singh University; International Institute of
   Information Technology Hyderabad; Hunan University of Science &
   Technology; Huaqiao University; Xiamen Institute of Technology; King
   Saud University; Xidian University; Birla Institute of Technology &
   Science Pilani (BITS Pilani)
RP Kumari, S (corresponding author), Chaudhary Charan Singh Univ, Dept Math, C-3, Meerut 282002, Uttar Pradesh, India.
EM saryusiirohi@gmail.com; iitkgp.akdas@gmail.com; lixiong84@gmail.com;
   conjurer1981@gmail.com; mkhurram@ksu.edu.sa; jiangqixdu@gmail.com;
   hafi786@gmail.com
RI Wu, Fan/J-9583-2019; Islam, SK Hafizul/K-5724-2017; WU,
   FAN/GRX-1654-2022; Das, Ashok Kumar/U-2790-2019; Kumari,
   Saru/K-2038-2019; Li, Xiong/K-7233-2012; Khan, Muhammad/IXN-8470-2023;
   Nusa, Nuhammad/JXY-5819-2024; KHAN, MUHAMMAD KHURRAM/E-4836-2014; Jiang,
   Qi/K-6325-2014
OI Wu, Fan/0000-0003-3615-1217; Das, Ashok Kumar/0000-0002-5196-9589;
   Kumari, Saru/0000-0003-4929-5383; Li, Xiong/0000-0001-6619-554X; KHAN,
   MUHAMMAD KHURRAM/0000-0001-6636-0533; Jiang, Qi/0000-0002-0894-4992
FU National Natural Science Foundation of China [61300220]
FX The authors would like to acknowledge the anonymous reviewers and the
   Editor for the constructive and helpful suggestions. Dr. Xiong Li is
   supported by the National Natural Science Foundation of China under
   Grant No. 61300220.
CR Abdalla M, 2005, LECT NOTES COMPUT SC, V3386, P65
   Bergamo P, 2005, IEEE T CIRCUITS-I, V52, P1382, DOI 10.1109/TCSI.2005.851701
   Boyko V, 2000, LECT NOTES COMPUT SC, V1807, P156
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chang CC, 2016, IEEE T WIREL COMMUN, V15, P357, DOI 10.1109/TWC.2015.2473165
   Chen TY, 2013, J SUPERCOMPUT, V66, P1008, DOI 10.1007/s11227-013-0966-z
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   El Bakrawy LM, 2011, COMM COM INF SC, V259, P85
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Fu ZJ, 2016, IEEE T PARALL DISTR, V27, P2546, DOI 10.1109/TPDS.2015.2506573
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Gura N, 2004, LECT NOTES COMPUT SC, V3156, P119
   Han S, 2009, CHAOS SOLITON FRACT, V39, P1283, DOI 10.1016/j.chaos.2007.06.030
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   Hong SM, 1996, LECT NOTES COMPUT SC, V1070, P166
   Hongfeng Zhu, 2016, International Journal of Network Security, V18, P803
   Hsiang HC, 2009, COMPUT STAND INTER, V31, P1118, DOI 10.1016/j.csi.2008.11.002
   Juang WS, 2004, IEEE T CONSUM ELECTR, V50, P251, DOI 10.1109/TCE.2004.1277870
   Kaufman C., 2010, INTERNET KEY EXCHANG, DOI DOI 10.17487/RFC4306
   Kim S, 2002, ELECTRON LETT, V38, P1519, DOI 10.1049/el:20020974
   Kocarev L, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P28
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Ku WC, 2005, IEICE T COMMUN, VE88B, P3451, DOI 10.1093/ietcom/e88-b.8.3451
   Ku WC, 2005, IEEE T NEURAL NETWOR, V16, P1002, DOI 10.1109/TNN.2005.849781
   Kumari S, 2014, COMPUT ELECTR ENG, V40, P1997, DOI 10.1016/j.compeleceng.2014.05.007
   Lee CC, 2011, EXPERT SYST APPL, V38, P13863, DOI 10.1016/j.eswa.2011.04.190
   Lee JS, 2008, INT J INNOV COMPUT I, V4, P1357
   Lee WB, 2000, COMPUT SYST SCI ENG, V15, P211
   Leu JS, 2014, IET INFORM SECUR, V8, P104, DOI 10.1049/iet-ifs.2012.0206
   Li CT, 2013, KSII T INTERNET INF, V7, P119, DOI 10.3837/tiis.2013.01.008
   Li LH, 2001, IEEE T NEURAL NETWOR, V12, P1498, DOI 10.1109/72.963786
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Li X, 2011, J NETW COMPUT APPL, V34, P73, DOI 10.1016/j.jnca.2010.09.003
   Liao YP, 2009, COMPUT STAND INTER, V31, P24, DOI 10.1016/j.csi.2007.10.007
   Lin IC, 2003, FUTURE GENER COMP SY, V19, P13, DOI 10.1016/S0167-739X(02)00093-6
   Lin IC, 2008, INT J COMMUN SYST, V21, P435, DOI 10.1002/dac.906
   Martin K.M., 2012, EVERYDAY CRYPTOGRAPH, P495
   Mason J. C., 2003, CHEBYSHEV POLYNOMIAL
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Mitchell C., 2005, Trusted computing, V6
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Shen H, 2015, J AMB INTEL HUM COMP, V6, P825, DOI 10.1007/s12652-015-0305-8
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Tian-Fu Lee, 2018, IEEE Systems Journal, V12, P1499, DOI 10.1109/JSYST.2015.2471095
   Tsai JL, 2008, COMPUT SECUR, V27, P115, DOI 10.1016/j.cose.2008.04.001
   Tsai JL, 2013, WIRELESS PERS COMMUN, V71, P1977, DOI 10.1007/s11277-012-0918-6
   Tsaur WJ, 2005, APPL MATH COMPUT, V170, P258, DOI 10.1016/j.amc.2004.11.033
   Tsaur WJ, 2001, LECT NOTES COMPUT SC, V2093, P174
   Tsaur WJ, 2012, J SYST SOFTWARE, V85, P876, DOI 10.1016/j.jss.2011.10.049
   Wang RC, 2009, IEEE COMMUN LETT, V13, P157, DOI 10.1109/LCOMM.2009.081884
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xue KP, 2014, J COMPUT SYST SCI, V80, P195, DOI 10.1016/j.jcss.2013.07.004
   Yeh KH, 2010, INT J INNOV COMPUT I, V6, P3467
   Yoon EJ, 2013, J SUPERCOMPUT, V63, P235, DOI 10.1007/s11227-010-0512-1
   Zhang LH, 2008, CHAOS SOLITON FRACT, V37, P669, DOI 10.1016/j.chaos.2006.09.047
   Zhang LP, 2016, J NETW COMPUT APPL, V59, P126, DOI 10.1016/j.jnca.2015.06.022
   Zhu H., 2015, J INFORM HIDING MULT, V6, P211
NR 60
TC 44
Z9 45
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2359
EP 2389
DI 10.1007/s11042-017-4390-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400038
DA 2024-07-18
ER

PT J
AU Obaidullah, SM
   Halder, C
   Santosh, KC
   Das, N
   Roy, K
AF Obaidullah, Sk Md
   Halder, Chayan
   Santosh, K. C.
   Das, Nibaran
   Roy, Kaushik
TI PHDIndic_11: page-level handwritten document image dataset of 11
   official Indic scripts for script identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Page-level handwritten dataset; Handwritten document recognition;
   Official Indic scripts; Script identification
ID RECOGNITION; DATABASE
AB Without publicly available dataset, specifically in handwritten document recognition (HDR), we cannot make a fair and/or reliable comparison between the methods. Considering HDR, Indic script's document recognition is still in its early stage compared to others such as Roman and Arabic. In this paper, we present a page-level handwritten document image dataset (PHDIndic_11), of 11 official Indic scripts: Bangla, Devanagari, Roman, Urdu, Oriya, Gurumukhi, Gujarati, Tamil, Telugu, Malayalam and Kannada. PHDIndic_11 is composed of 1458 document text-pages written by 463 individuals from various parts of India. Further, we report the benchmark results for handwritten script identification (HSI). Beside script identification, the dataset can be effectively used in many other applications of document image analysis such as script sentence recognition/understanding, text-line segmentation, word segmentation/recognition, word spotting, handwritten and machine printed texts separation and writer identification.
C1 [Obaidullah, Sk Md] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Halder, Chayan; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Santosh, K. C.] Univ South Dakota, Dept Comp Sci, Vermillion, SD 57069 USA.
   [Das, Nibaran] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Aliah University; West Bengal State University; University of South
   Dakota; Jadavpur University
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM sk.obaidullah@gmail.com; chayan.halderz@gmail.com; santosh.kc@usd.edu;
   nibaranju@gmail.com; kaushik.mrg@gmail.com
RI Santosh, K.C./H-1363-2012; Roy, Kaushik/O-7021-2019; Sk,
   Obaidullah/ABF-9198-2020; Halder, Chayan/ABG-5383-2020
OI Roy, Kaushik/0000-0002-3360-7576; Halder, Chayan/0000-0002-6113-7284;
   Sk, Md Obaidullah/0000-0002-5207-3709
CR Alaei A, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412530011
   [Anonymous], P INT WORKSH FRONT H
   [Anonymous], P INT C COMP COMM TE
   [Anonymous], C NISTIR
   [Anonymous], P INT C DOC ANAL REC
   [Anonymous], J APPL COMPUTATIONAL
   [Anonymous], INT C DOC AN REC BEI
   [Anonymous], P INT C PATT REC
   [Anonymous], P INT C DOC AN REC
   [Anonymous], P INT C FRONT HANDWR
   Busch A, 2005, IEEE T PATTERN ANAL, V27, P1720, DOI 10.1109/TPAMI.2005.227
   Das N, 2015, PATTERN RECOGN, V48, P2054, DOI 10.1016/j.patcog.2014.12.011
   Das N, 2014, INT J DOC ANAL RECOG, V17, P413, DOI 10.1007/s10032-014-0222-y
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Gatos B., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1393, DOI 10.1109/ICDAR.2009.245
   Ghosh D, 2010, IEEE T PATTERN ANAL, V32, P2142, DOI 10.1109/TPAMI.2010.30
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kleber F, 2013, PROC INT CONF DOC, P560, DOI 10.1109/ICDAR.2013.117
   Lakshmi CV, 2004, PATTERN ANAL APPL, V7, P190, DOI 10.1007/s10044-004-0217-2
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Marti U.-V., 2002, International Journal on Document Analysis and Recognition, V5, P39, DOI 10.1007/s100320200071
   Marti U.-V., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P705, DOI 10.1109/ICDAR.1999.791885
   Mulhem P, 2003, MULTIMED TOOLS APPL, V20, P263, DOI 10.1023/A:1024024321994
   Nethravathi B., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P415, DOI 10.1109/ICFHR.2010.71
   Obaidullah SM, 2017, ADV INTELL SYST, V459, P205, DOI 10.1007/978-981-10-2104-6_19
   Obaidullah SM, 2016, INT J INTELL ENG INF, V4, P1, DOI 10.1504/IJIEI.2016.074497
   Obaidullah SM, 2014, APPL COMPUT INTELL S, V2014, DOI 10.1155/2014/896128
   Paul M.Lewis., 2009, Ethnologue : Languages ofthe World, VSixteenth
   Sagheer MW, 2009, LECT NOTES COMPUT SC, V5716, P538, DOI 10.1007/978-3-642-04146-4_58
   Sarkar R, 2012, INT J DOC ANAL RECOG, V15, P71, DOI 10.1007/s10032-011-0148-6
   Singh PK, 2015, P 3 INT C COMPUTER C, P1
   Sklansky J, 1982, PATTERN RECOGN LETT, V1, P79, DOI 10.1016/0167-8655(82)90016-2
   SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477
   Sumner M, 2005, LECT NOTES ARTIF INT, V3721, P675
   Thadchanamoorthy S, 2013, PROC INT CONF DOC, P793, DOI 10.1109/ICDAR.2013.162
NR 36
TC 42
Z9 42
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1643
EP 1678
DI 10.1007/s11042-017-4373-y
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400008
DA 2024-07-18
ER

PT J
AU Kaur, B
   Singh, D
   Roy, PP
AF Kaur, Barjinder
   Singh, Dinesh
   Roy, Partha Pratim
TI A Novel framework of EEG-based user identification by analyzing
   music-listening behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electroencephalography (EEG); User identification; Savtizik-Golay
   filter; Wavelet transform; Hidden Markov Model (HMM); Support Vector
   Machine (SVM)
ID HIDDEN MARKOV-MODELS; NEURONAL ENTRAINMENT; BRAIN; AUTHENTICATION;
   EXTRACTION; BEAT
AB This paper introduces a novel framework for user identification by analyzing neuro-signals. Studies regarding Electroencephalography (EEG) revealed that such bio-signals are sensitive, hard to forge, confidential, and unique which the conventional biometric systems like face, speaker, signature and voice lack. Traditionally, researchers investigated the neuro-signal patterns by asking users to perform various imaginary, visual or calculative tasks. In this work, we have analyzed this neuro-signal pattern using audio as stimuli. The EEG signals are recorded simultaneously while user is listening to music. Four different genres of music are considered as users have their own preference and accordingly they respond with different emotions and interests. The users are also asked to provide music preference which acts as a personal identification mechanism. The framework offers the benefit of uniqueness in neuro-signal pattern even with the same music preference by different users. We used two different classifiers i.e. Hidden Markov Model (HMM) based temporal classifier and Support Vector Machine (SVM) for user identification system. A dataset of 2400 EEG signals while listening to music was collected from 60 users. User identification performance of 97.50 % and 93.83 % have been recorded with HMM and SVM classifiers, respectively. Finally, the performance of the system is also evaluated on various emotional states after showing different emotional videos to users.
C1 [Kaur, Barjinder; Singh, Dinesh] DCRUST, Dept Comp Sci & Engn, Sonipat, India.
   [Roy, Partha Pratim] IIT, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kaur, B (corresponding author), DCRUST, Dept Comp Sci & Engn, Sonipat, India.
EM kaur.barjinder@gmail.com; dinesh.madhav@gmail.com; proy.fcs@iitr.ac.in
RI Roy, Partha Pratim/GPF-4253-2022; Roy, Partha Pratim/AAV-9061-2020; Roy,
   Partha Pratim/AAW-2994-2020; singh, dinesh/AAB-4046-2022
OI Roy, Partha Pratim/0000-0002-5735-5254; singh,
   dinesh/0000-0002-7614-5789; singh, dinesh/0000-0003-0662-5426
CR Abdulkader Sarah N., 2015, Human Aspects of Information Security, Privacy and Trust. Third International Conference, HAS 2015, held as part of HCI International 2015. Proceedings: LNCS 9190, P3, DOI 10.1007/978-3-319-20376-8_1
   Abo-Zahhad M., 2015, PATTERN RECOGN LETT
   Al-Juboori AM, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P52, DOI 10.1109/CSA.2013.19
   Alomari MH, 2014, INT J ADV COMPUT SC, V5, P193
   Alzahrani H, 2014, SPIE DEFENSE SECURIT
   [Anonymous], 2014, P INT C REC ADV INN
   Astigarraga A, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/1435321
   Azami H, 2012, J SIGNAL INFORM PROC
   Badcock NA, 2013, PEERJ, V1, DOI 10.7717/peerj.38
   Breitwieser C, 2012, JOINT INT C PERV COM, P50
   Cabredo R.A., 2012, PROC 13 INT SOC MUSI, P265
   Campbell P, 2011, INT J CULT POLICY, V17, P510, DOI 10.1080/10286632.2010.543461
   Champion C, 2016, COMPUT SPEECH LANG, V36, P347, DOI 10.1016/j.csl.2015.05.001
   Chuang J, 2013, LECT NOTES COMPUT SC, V7862, P1, DOI 10.1007/978-3-642-41320-9_1
   de Mira J, 2015, J SIGNAL PROCESS SYS, V80, P181, DOI 10.1007/s11265-013-0861-0
   Dustor A, 2013, COMM COM INF SC, V370, P456
   Hadjidimitriou SK, 2012, IEEE T BIO-MED ENG, V59, P3498, DOI 10.1109/TBME.2012.2217495
   Hariadi M, 2014, J THEOR APPL INF TEC, V66
   Holzinger Andreas, 2012, Information Technology in Bio- and Medical Informatics. Proceedings of the Third International Conference, ITBAM 2012, P166, DOI 10.1007/978-3-642-32395-9_13
   Iranmanesh V, 2014, SCI WORLD J, DOI 10.1155/2014/381469
   Krishnan SR, 2013, IEEE T SIGNAL PROCES, V61, P380, DOI 10.1109/TSP.2012.2225055
   Kumar AB, 2011, ANESTHESIOLOGY, V114, P964, DOI 10.1097/ALN.0b013e318210f86a
   La Rocca Daria, 2013, Proceedings of the 6th International Conference on Bio-inspired Systems and Signal Processing. BIOSIGNALS 2013, P419
   Lalor EC, 2005, EURASIP J APPL SIG P, V2005, P3156, DOI 10.1155/ASP.2005.3156
   Lee JC, 2012, PATTERN RECOGN LETT, V33, P1520, DOI 10.1016/j.patrec.2012.04.007
   Mahajan K, 2014, INT J COMPUTER SCI M
   Mandal R, 2015, J AM SOC QUESTIONED, V18, P3
   Mao Chengsheng., 2015, Neural Networks (IJCNN), 2015 International Joint Conference on, P1
   Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012
   Nozaradan S, 2012, J NEUROSCI, V32, P17572, DOI 10.1523/JNEUROSCI.3203-12.2012
   Nozaradan S, 2011, J NEUROSCI, V31, P10234, DOI 10.1523/JNEUROSCI.0411-11.2011
   Obermaier B, 2001, PATTERN RECOGN LETT, V22, P1299, DOI 10.1016/S0167-8655(01)00075-7
   Palaniappan R, 2008, INT J NEURAL SYST, V18, P59, DOI 10.1142/S0129065708001373
   Palaniappan R, 2007, IEEE T PATTERN ANAL, V29, P738, DOI 10.1109/TPAMI.2007.1013
   Pleva M, 2016, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA 2016), P386, DOI 10.1109/RADIOELEK.2016.7477360
   Pratim P, 2012, INT CONF FRONT HAND, P225, DOI 10.1109/ICFHR.2012.270
   Rafiee J, 2011, EXPERT SYST APPL, V38, P6190, DOI 10.1016/j.eswa.2010.11.050
   Ramirez R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00354
   Ravi H, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P147, DOI 10.1109/THS.2013.6698991
   Repovs G., 2010, Informatica Medica Slovenica, V15, P18
   Shah PG, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P116, DOI 10.1109/IntelCIS.2015.7397207
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P211, DOI 10.1109/T-AFFC.2011.37
   Stickel C, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P813
   Stytsenko K, 2011, MEI COGSCI C 2011 LI
   Sundararajan A, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P139, DOI 10.1109/ITNG.2015.27
   Swaminathan Raghav., 2016, NEXT GENERATION DNA, P49, DOI DOI 10.1007/978-981-287-670-6_6
   Tatum IV., 2014, Handbook of EEG Interpretation, VSecond
   Wang YJ, 2008, IEEE ENG MED BIOL, V27, P64, DOI 10.1109/MEMB.2008.923958
   Weston J., 1998, Technical report
   Wu T, 2008, MEASUREMENT, V41, P618, DOI 10.1016/j.measurement.2007.07.007
   Wu XQ, 2006, IEEE T SYST MAN CY A, V36, P978, DOI 10.1109/TSMCA.2006.871797
   Yeom SK, 2013, PATTERN RECOGN, V46, P1159, DOI 10.1016/j.patcog.2012.10.023
   Yuan-Pin Lin, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P127, DOI 10.1109/MMSP.2008.4665061
   Zúquete A, 2010, BIOSIGNALS 2010: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P103
NR 54
TC 35
Z9 35
U1 3
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25581
EP 25602
DI 10.1007/s11042-016-4232-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500004
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, SK
AF Kumar, Santosh
   Singh, Sanjay Kumar
TI Automatic identification of cattle using muzzle point pattern: a hybrid
   feature extraction and classification paradigm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animal biometrics; Muzzle point pattern; Cattle recognition; Feature
   extraction; Classification; Texture feature
ID LOCAL BINARY PATTERNS; TEXTURE CLASSIFICATION; IMAGE SEGMENTATION; FACE
   RECOGNITION
AB Animal biometrics is an emerging research field that develops quantified methodologies for representing and detecting the visual appearances of animal based on generic features and primary biometric characteristics. The identification of individual cattle is an important issue for classification of different breads, their registration, traceability, health management, and verification of false insurance claim throughout the world. To solve these major problems, the muzzle (nose) point image pattern of cattle is a suitable and primary biometric characteristic for the recognition of cattle. The recognition of muzzle point images is similar to the recognition of minutiae points in the human fingerprints. In this paper, we propose a hybrid feature extraction approach for the automatic recognition and classification of cattle breeds based on captured muzzle point image pattern features using low- cost camera. The major contributions of this research is based on following aspects: (1) preparation of muzzle point image dataset, (2) extraction of salient set of features and (3) K-nearest neighbour (K-NN), Fuzzy-KNN, Decision Tree (DT), Gaussian Mixture Model (GMM), Probabilistic Neural Network (PNN), Multilayer Perceptron (MLP) and Naive Bayes classification models are applied to recognition, and classification of individual cattle using their muzzle point pattern. This paper, therefore, demonstrates the automatic recognition and classification of livestock using the set of extracted muzzle point image features. The experimental results show that proposed hybrid feature extraction and recognition approach outperforms the current state-of- the art method for the identification of individual cattle using their muzzle point image pattern.
C1 [Kumar, Santosh; Singh, Sanjay Kumar] Banaras Hindu Univ, Dept Comp Sci & Engn, Indian Inst Technol, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu University
   (BHU)
RP Kumar, S; Singh, SK (corresponding author), Banaras Hindu Univ, Dept Comp Sci & Engn, Indian Inst Technol, Varanasi 221005, Uttar Pradesh, India.
EM santosh.rs.cse@iitbhu.ac.in; sks.cse@iitbu.ac.in
RI Singh, Sanjay Kumar/AAC-2031-2022; kumar, Sanjay/ITT-3680-2023; Kumar,
   Sanjay/F-8509-2013; Singh, Sanjay Prithviraj/IQV-1492-2023
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Kumar,
   Sanjay/0000-0003-3659-5387; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762; Kumar, Dr. Santosh/0000-0003-2264-9014
CR Ahmed S, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT NETWORKING AND COLLABORATIVE SYSTEMS IEEE INCOS 2015, P99, DOI 10.1109/INCoS.2015.60
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Allen A, 2008, LIVEST SCI, V116, P42, DOI 10.1016/j.livsci.2007.08.018
   [Anonymous], 1922, J DAIRY SCI
   [Anonymous], Official Journal of the European Union. Animal Health Law, V1
   [Anonymous], ASIAN LIVESTOCK
   [Anonymous], 2013, P AS PAC SIGN INF PR
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Awad AI, 2013, FED CONF COMPUT SCI, P529
   BARANOV AS, 1993, J ANIM BREED GENET, V110, P385, DOI 10.1111/j.1439-0388.1993.tb00751.x
   Barry B, 2007, T ASABE, V50, P1073, DOI 10.13031/2013.23121
   Bishop CM, MACHINE LEARNING
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   [曹莹 Cao Ying], 2013, [自动化学报, Acta Automatica Sinica], V39, P745
   Chen K, 2014, MULTIMED TOOLS APPL, V75, P839
   Corkery GP, 2007, T ASABE, V50, P313, DOI 10.13031/2013.22395
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   Duyck J, 2015, PATTERN RECOGN, V48, P1059, DOI 10.1016/j.patcog.2014.07.017
   Eradus WJ, 1999, COMPUT ELECTRON AGR, V24, P91, DOI 10.1016/S0168-1699(99)00039-3
   Frucci M, 2016, PATTERN RECOGN, V52, P148, DOI 10.1016/j.patcog.2015.08.017
   Gaber T, 2016, COMPUT ELECTRON AGR, V122, P55, DOI 10.1016/j.compag.2015.12.022
   Garcia-Pedrajas N, 2016, IEEE T NEURAL NETWOR, P1
   Goon AM., 1963, FUNDAMENTALS STAT
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Johnston AM, 1996, VET REC, V138, P612, DOI 10.1136/vr.138.25.612
   Kim HT, 2005, ASIAN AUSTRAL J ANIM, V18, P868, DOI 10.5713/ajas.2005.868
   Kim S., 2016, Mediating Peace: Reconciliation Through Visual Art, Music and Film, P1
   Koniar D, 2016, COMPUT METH PROG BIO, V127, P258, DOI 10.1016/j.cmpb.2015.12.009
   Krishnan MMR, 2012, MICRON, V43, P352, DOI 10.1016/j.micron.2011.09.016
   Kühl HS, 2013, TRENDS ECOL EVOL, V28, P432, DOI 10.1016/j.tree.2013.02.013
   Kumar S, 2016, P NATL A SCI INDIA A, V86, P137, DOI 10.1007/s40010-016-0264-2
   Kumar S, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P65, DOI 10.1109/ICIIP.2015.7414742
   Lahiri M., 2011, P 1 ACM INT C MULT R
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Lopatka K, 2016, MULTIMED TOOLS APPL, V75, P10407, DOI 10.1007/s11042-015-3105-4
   Lopes G, 2017, MYCOPATHOLOGIA, V182, P143, DOI 10.1007/s11046-016-0081-9
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Lucena M, 2014, MULTIMED TOOLS APPL, V75, P3677
   Marchant J, COMMUNICATION
   Matiolanski A, 2016, MULTIMED TOOLS APPL, V75, P10513, DOI 10.1007/s11042-015-2697-z
   Mehta R, 2016, IEEE T IMAGE PROCESS, V25, P1604, DOI 10.1109/TIP.2016.2526898
   Minagawa H., 2002, AFITA 2002: Asian agricultural information technology & management. Proceedings of the Third Asian Conference for Information Technology in Agriculture, Beijing, China, 26-28 October, 2002, P596
   Murphy K.P., 2006, Naive bayes classifiers
   Noviyanto A, 2013, COMPUT ELECTRON AGR, V99, P77, DOI 10.1016/j.compag.2013.09.002
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PAL SK, 1992, IEEE T NEURAL NETWOR, V3, P683, DOI 10.1109/72.159058
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Rizzi A, 2014, MULTIMED TOOLS APPL, V75, P3747
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Sun YF, 2014, MULTIMED TOOLS APPL, V73, P2063, DOI 10.1007/s11042-013-1638-y
   Szwoch G, 2014, MULTIMED TOOLS APPL, V75, P761
   Tharwat A, 2014, COMM COM INF SC, V488, P236
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Vlad M., 2012, P 13 WSEAS INT C AUT, P165
   Wang DD, 2016, MULTIMED TOOLS APPL, V75, P3177, DOI 10.1007/s11042-014-2429-9
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wang Z., 2010, P 2010 I E INT C COM, V2, pV2
   Wardrope D, PROBLEMS SUPPURATIN
   Werghi N, 2015, IEEE T IMAGE PROCESS, V24, P220, DOI 10.1109/TIP.2014.2370253
   Xu PF, 2014, MULTIMED TOOLS APPL, V71, P1529, DOI 10.1007/s11042-012-1290-y
   Yang HB, 2015, MULTIMED TOOLS APPL, V74, P6069, DOI 10.1007/s11042-014-1909-2
   Yisu Zhao, 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P861, DOI 10.1109/IMTC.2010.5488048
   Zhang JF, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P192
   Zhao YN, 2016, MULTIMED TOOLS APPL, V75, P4795, DOI 10.1007/s11042-015-2503-y
   Zhu WZ, 2016, MULTIMED TOOLS APPL, V75, P2815, DOI 10.1007/s11042-015-2582-9
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 74
TC 18
Z9 20
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26551
EP 26580
DI 10.1007/s11042-016-4181-9
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500046
DA 2024-07-18
ER

PT J
AU Rossi, S
   Barile, F
   Galdi, C
   Russo, L
AF Rossi, Silvia
   Barile, Francesco
   Galdi, Clemente
   Russo, Luca
TI Recommendation in museums: paths, sequences, and group satisfaction
   maximization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cultural heritage; Group recommendation; Recommendation of a sequence
AB This work addresses the problem of generating and then recommending an artworks sequence for a group of visitors within a museum. Differently from a recommender system for an e-commerce application, the problem, here, is trying to maximize the satisfaction of the proposed recommendations, while taking into account an items' ordering that satisfies each group member during the sequence and the artworks locations in the museum. Moreover, since many visitors may not be able to visit every artwork, the recommender system should provide suggestions while satisfying temporal visit constraints. The problem formulation is discussed together with the characteristics of a feasible solution. An exact search algorithm from the literature is used to efficiently solve the problem and to define the prerequisites for the recommender system. Finally, we evaluate a prototype implementation with both an offline analysis and a pilot study in a simulated museum environment.
C1 [Rossi, Silvia; Galdi, Clemente] Univ Napoli Federico II, Dipartimento Ingn Elettr & Tecnol Informaz, Naples, Italy.
   [Russo, Luca] Univ Napoli Federico II, Dipartimento Ingn Elettr & Tecnol Informaz, Comp Sci, Naples, Italy.
   [Barile, Francesco] Univ Napoli Federico II, Dipartimento Matemat & Applicaz, Naples, Italy.
C3 University of Naples Federico II; University of Naples Federico II;
   University of Naples Federico II
RP Rossi, S (corresponding author), Univ Napoli Federico II, Dipartimento Ingn Elettr & Tecnol Informaz, Naples, Italy.
EM silvia.rossi@unina.it; francesco.barile@unina.it;
   clemente.galdi@unina.it
RI Galdi, Clemente/AAE-4921-2020; Rossi, Silvia/C-2615-2008; GALDI,
   Clemente/U-3737-2019
OI Rossi, Silvia/0000-0002-3379-1756; GALDI, Clemente/0000-0002-2988-700X;
   BARILE, FRANCESCO/0000-0003-4083-8222
CR Amato F, 2013, PROCEDIA COMPUT SCI, V21, P114, DOI 10.1016/j.procs.2013.09.017
   [Anonymous], 2013, USER MODELING ADAPTA
   Baltrunas L., 2010, P 4 ACM C REC SYST, P119, DOI DOI 10.1145/1864708.1864733
   Bohnert F, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2022
   Callaway C, 2014, EAI ENDORSED T AMBIE, V14
   Caso A, 2014, LAT BREAK RES WORKSH, V1181
   Chianese A, 2015, J LOCAT BASED SERV, V9, P209, DOI 10.1080/17489725.2015.1099752
   Cone C.A., 1978, CURATOR, V21/3, P245, DOI DOI 10.1111/J.2151-6952.1978.TB00545.X
   DESROCHERS M, 1988, INFOR, V26, P191
   Desrosiers C, 2011, RECOMMENDER SYSTEMS HANDBOOK, P107, DOI 10.1007/978-0-387-85820-3_4
   Diamond J., 1986, CURATOR, V29, P139, DOI [DOI 10.1111/J.2151-6952.1986.TB01434.X, 10.1111/j.2151-6952.1986.tb01434.x]
   Dumitrescu I, 2003, NETWORKS, V42, P135, DOI 10.1002/net.10090
   Fournier R., 2014, PROCEEDING DIGITAL I
   Galdi C, 2005, PARALLEL PROCESS LET, V15, DOI 10.1142/S0129626405002106
   Glenn JG, 2001, ENTREPRENEURIAL RES
   Irnich Stefan., 2006, COLUMN GENERATION, P33
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Masthoff J, 2004, HUM-COMPUT INT-SPRIN, P93
   Masthoff J, 2006, USER MODEL USER-ADAP, V16, P281, DOI 10.1007/s11257-006-9008-3
   Masthoff J, 2011, RECOMMENDER SYSTEMS HANDBOOK, P677, DOI 10.1007/978-0-387-85820-3_21
   Roes Ivo, 2009, C HUM FACT COMP SYST, P3317
   Rossi S, 2017, CONCURRENCY COMPUTAT
   Rossi S, 2016, 12 INT C SIGN IM TEC
   Rossi S, 2015, ADV INTELL SYST, V372, P151, DOI 10.1007/978-3-319-19629-9_17
   Rossi S, 2016, LECT NOTES BUS INF P, V246, P297, DOI 10.1007/978-3-319-30996-5_15
   Sato H, 2010, NAV RES LOG, V57, P422, DOI 10.1002/nav.20411
   SCHRIJVER A., 2003, COMBINATORIAL OPTIMI, V24, P39
   van Hage WR, 2010, LECT NOTES COMPUT SC, V6088, P46, DOI 10.1007/978-3-642-13486-9_4
NR 29
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26031
EP 26055
DI 10.1007/s11042-017-4869-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500025
DA 2024-07-18
ER

PT J
AU Yang, SB
   Liu, SH
   Li, XF
   Zhong, Y
   He, X
   Wu, C
AF Yang, Shaobo
   Liu, Sihui
   Li, Xingfei
   Zhong, Ying
   He, Xin
   Wu, Chao
TI The short-term forecasting of evaporation duct height (EDH) based on
   ARIMA model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evaporation duct height; Forecasting; ARIMA; Time series
ID TIME-SERIES; PREDICTION
AB The short-term prediction of EDH time series plays an exceedingly important role in several fields such as communications, navigation and so on. In this paper, an application of autoregressive integrated moving average (ARIMA) for short-term forecasting of EDH time series is presented. In order to obtain the EDH, a body of sensors such as air temperature, relative humidity and pressure sensors were installed at different height based on the tower platform. EDH was calculated according to Debye theory and a log-squares curve fit. The comparison showed that the predicted EDH values were in good agreement with the measured values. It also indicates that ARIMA provides promising results for short-term prediction of EDH in the experiment.
C1 [Yang, Shaobo; Li, Xingfei; Zhong, Ying; He, Xin; Wu, Chao] Tianjin Univ, State Key Lab Precis Measuring Technol & Instrume, 92 Weijin Rd, Tianjin 300072, Peoples R China.
   [Liu, Sihui] Zhonghuan TIG CO LTD, Huayuan Ind Area, Tianjin 300384, Peoples R China.
C3 Tianjin University
RP Li, XF (corresponding author), Tianjin Univ, State Key Lab Precis Measuring Technol & Instrume, 92 Weijin Rd, Tianjin 300072, Peoples R China.
EM lixftju@sina.com
FU National Nature Science Foundation of China [41405009]
FX This work was supported by National Nature Science Foundation of China
   (No.41405009)
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   ANDERSON KD, 1989, IEEE T ANTENN PROPAG, V37, P100, DOI 10.1109/8.192171
   [Anonymous], 2002, SYSTEM IDENTIFICATIO
   Babin SM, 1997, J APPL METEOROL, V36, P193, DOI 10.1175/1520-0450(1997)036<0193:ANMOTO>2.0.CO;2
   Benmouiza K, 2016, THEOR APPL CLIMATOL, V124, P945, DOI 10.1007/s00704-015-1469-z
   Brockwell J.P., 2002, Introduction to Time Series and Forecasting, V2nd ed.
   Burk SD, 1997, J APPL METEOROL, V36, P22, DOI 10.1175/1520-0450(1997)036<0022:MMOSRC>2.0.CO;2
   Cheng Y., 2012, CHIN J RADIO SCI, V27, P268
   Hodur RM, 1997, MON WEATHER REV, V125, P1414, DOI 10.1175/1520-0493(1997)125<1414:TNRLSC>2.0.CO;2
   Jiao L, 2009, ACTA METEOROL SIN, V34, P46
   Kuligowski RJ, 1998, MON WEATHER REV, V126, P470, DOI 10.1175/1520-0493(1998)126<0470:EISTPF>2.0.CO;2
   Kumar U, 2010, STOCH ENV RES RISK A, V24, P751, DOI 10.1007/s00477-009-0361-8
   Mellit A, 2013, THEOR APPL CLIMATOL, V111, P297, DOI 10.1007/s00704-012-0661-7
   PAULUS RA, 1985, RADIO SCI, V20, P887, DOI 10.1029/RS020i004p00887
   Shumway R., 2006, Time series analysis and its applications with R examples
   Yardim C, 2006, IEEE T ANTENN PROPAG, V54, P1318, DOI 10.1109/TAP.2006.872673
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zhao XF, 2011, RADIO SCI, V46, DOI 10.1029/2010RS004417
   Zhao XF, 2012, IEEE T ANTENN PROPAG, V60, P1020, DOI 10.1109/TAP.2011.2173115
   Zuo L, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.408
NR 20
TC 6
Z9 6
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 24903
EP 24916
DI 10.1007/s11042-016-4143-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300018
DA 2024-07-18
ER

PT J
AU Tayal, N
   Bansal, R
   Dhal, S
   Gupta, S
AF Tayal, Neha
   Bansal, Ritesh
   Dhal, Sangeeta
   Gupta, Shailender
TI A novel hybrid security mechanism for data communication networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Cryptography; Entropy; Steganography
AB With the growing internet technology over the last decade, the number of intruders trying to steal the confidential information has also risen. As a result, for the protection of secret data from unwanted access, hybrid security mechanisms employing the use of steganography to hide the encrypted data are gaining popularity. These mechanisms provide an extra level of security to the data. This paper proposes a hybrid mechanism that not only aims at providing good security but at the same time has high data embedding capacity and entropy values with low execution time complexity. To enhance the embedding capacity of the overall system, Improved Bit Plane Complex Steganography (IBPCS) along-with Huffman coding is used and for providing randomness, the use of chaos process wherever possible is done. The cryptographic technique employed is hierarchical visual cryptography due to its efficiency over other cryptographic mechanisms. The overall scheme is implemented in MATLAB-10 and the results prove that the proposed mechanism is efficient to other available schemes in literature.
C1 [Tayal, Neha] YMCA Univ Sci & Technol, Field Elect & Commun, Faridabad 121002, India.
   [Bansal, Ritesh] YMCA Univ Sci & Technol, Elect Instrumentat & Control Engn, Faridabad 121002, India.
   [Dhal, Sangeeta; Gupta, Shailender] YMCA Univ Sci & Technol, Elect Engn Dept, Faridabad 121002, India.
C3 J.C. Bose University of Science & Technology, YMCA; J.C. Bose University
   of Science & Technology, YMCA; J.C. Bose University of Science &
   Technology, YMCA
RP Tayal, N (corresponding author), YMCA Univ Sci & Technol, Field Elect & Commun, Faridabad 121002, India.
EM nehatayal2292@gmail.com; ritesh.bansal@hotmail.com;
   sangeeta_dhall@yahoo.co.in; shailender81@gmail.com
RI gupta, shailender/Y-8231-2019; dhall, sangeeta/AAG-2948-2020
OI gupta, shailender/0000-0003-1383-7152; 
CR [Anonymous], 2014, P INT J INN RES ADV
   [Anonymous], 2010, 2010 2 INT C COMPUTI
   [Anonymous], 2012, INT J COMPUTER APPL
   [Anonymous], 2014, INT J COMPUTER ELECT
   [Anonymous], 2012, INT J COMPUTER SCI I
   [Anonymous], 2012, INT J ENG TRENDS TEC
   [Anonymous], P SPIE MULTIMEDIA SY
   [Anonymous], 2014, INT J ELECT COMMUN C
   [Anonymous], 2014, 2014 INT C INFORMATI
   Aung Pye Pye, 2014, INT J INFORM TECHNOL, V2, P55, DOI DOI 10.5121/IJITMC.2014.2105
   Chaudhary D, 2015, INDERSCIENC IN PRESS
   Chavan PV, 2012, P INT C ENG, P1
   Goel S, 2013, P GLOBAL J COMPUTER, V13
   Gupta Shailender, INT J MODERN ED COMP, V4, P27
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Jain Y, 2015, JOURNAL
   Karim S. M. Masud, 2011, P 14 INT C COMP INF, P22
   Kaspersky Lab and INTERPOL, 2014, BMOBILE CYB THREATS, P11
   Kumar Lokesh, 2012, INT J ADV RES COMPUT, V2, P143
   Mohammad A. A., 2012, EUROPEAN J SCI RES, P223
   Pallavi Vijay C, 2014, INT J NET SECUR APPL, V6, P91
   Peipei Shi, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P388, DOI 10.1109/MINES.2010.87
   SCHWARTZ ES, 1964, INFORM CONTROL, V7, P37, DOI 10.1016/S0019-9958(64)90241-4
   Shelke F.M., 2014, International Journal of Application or Innovation in Engineering Management, V3, P171
   Singh S, 2012, IJCSI, V9, P131
   Stallings William., 2005, CRYPTOGRAPHY NETWORK, VFourth
   Usha S., 2011, Proceedings of the 2011 International Conference on Computer Science and Network Technology (ICCSNT), P1017, DOI 10.1109/ICCSNT.2011.6182134
   Vinish A, 2015, INT J ENG TECHNOL SC, V2, P46
NR 28
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 24063
EP 24090
DI 10.1007/s11042-016-4111-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700042
DA 2024-07-18
ER

PT J
AU Liao, X
   Li, KD
   Yin, JJ
AF Liao, Xin
   Li, Kaide
   Yin, Jiaojiao
TI Separable data hiding in encrypted image based on compressive sensing
   and discrete fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted images; Reversible data hiding; Compressive sensing; Discrete
   fourier transform
AB Reversible data hiding in encrypted images has become an effective and popular way to preserve the security and privacy of users' personal images. Recently, Xiao et al. firstly presented reversible data hiding in encrypted images with use of the modern signal processing technique compressive sensing (CS). However, the quality of decrypted image is not great enough. In this paper, a new method of separable data hiding in encrypted images are proposed by using CS and discrete fourier transform, which takes full advantage of both real and imaginary coefficients for ensuring great recovery and providing flexible payload. Compared with the original work, the proposed method can obtain better image quality when concealing the same embedding capacity. Furthermore, image decryption and data extraction are separable in the proposed method, and the secret data can be extracted relatively accurately.
C1 [Liao, Xin; Li, Kaide; Yin, Jiaojiao] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Kaide] Cent South Univ Forestry & Technol, Coll Sci, Changsha 410004, Hunan, Peoples R China.
   [Liao, Xin] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.
   [Liao, Xin] Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
C3 Hunan University; Central South University of Forestry & Technology;
   Chinese Academy of Sciences; Institute of Software, CAS
RP Liao, X (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.; Liao, X (corresponding author), Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China.; Liao, X (corresponding author), Shanghai Key Lab Integrated Adm Technol Informat, Shanghai 200240, Peoples R China.
EM xinliao@hnu.edu.cn
RI Liao, Xin/X-2736-2018; Liao, Xin/ITT-1021-2023
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61402162, 61472131,
   61272546]; Specialized Research Fund for the Doctoral Program of Higher
   Education [20130161120004]; Science and Technology Key Projects of Hunan
   Province [2015TP1004]; Shanghai Key Laboratory of Integrated
   Administration Technologies for Information Security [AGK201605]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61402162, 61472131, 61272546), Specialized Research Fund for
   the Doctoral Program of Higher Education (Grant No. 20130161120004),
   Science and Technology Key Projects of Hunan Province (No. 2015TP1004),
   Opening Project of Shanghai Key Laboratory of Integrated Administration
   Technologies for Information Security (Grant No. AGK201605).
CR Baher H., 1990, SIGNAL PROCESS INTEG, P149
   Bracewell R., 2003, FOURIER ANAL IMAGING, P140
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Li M, 2014, ETRI J, V36, P325, DOI 10.4218/etrij.14.0213.0449
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puech W, 2008, 367 P SEC FOR STEGN, p6819E
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xiao D, 2015, MULTIMED TOOLS APPL, V75, P13779
   Xiao D, 2015, MULTIMED TOOLS APPL, V74, P7729, DOI 10.1007/s11042-014-2017-z
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 24
TC 164
Z9 166
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20739
EP 20753
DI 10.1007/s11042-016-3971-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400016
DA 2024-07-18
ER

PT J
AU Sun, J
   Chen, P
   Bi, CJ
AF Sun, Jian
   Chen, Ping
   Bi, Cunjian
TI 1H-MRS technique and spectroscopic imaging LCModel based adolescent
   obese metabolic syndrome research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 1H-MRS technology; LC Model software; Quantitative analysis; Metabolite
   concentrations
ID MAGNETIC-RESONANCE-SPECTROSCOPY; MR SPECTROSCOPY; RAT-BRAIN; SPECTRA;
   QUANTIFICATION; DISEASE
AB Hydrogen proton magnetic resonance spectroscopy (1H-MRS) was widely used in the auxiliary diagnosis of clinical diseases. However, in the previous study on hippocampal metabolites, the relative ratio of magnetic resonance spectroscopic data common area blow the crest or crest height was used for semi-quantitative or relative quantitative analysis. Although it was convenient to observe the change trend for this method, it could not accurately reflect the specific changes of various metabolites concentrations. So it had a certain limitation. Based on Linear Combination of Model Spectra (LCmodel) processing technology this paper introduced the spectroscopic imaging technology into the analysis procedures. The absolute concentration of brain metabolites was quantitatively detected in the hippocampus of adolescent obese metabolic syndrome. The results showed that the levels of NAA, Cho and MI in bilateral hippocampuses of adolescent metabolic syndrome were significantly decreased, especially in right hippocampus. The application of LCmodel software brought great convenience to realize the absolute quantification of metabolites in vivo.
C1 [Sun, Jian; Bi, Cunjian] Xinjiang Normal Univ, Phys Educ Sch, Urumqi 830017, Peoples R China.
   [Chen, Ping] Beijing Normal Univ, Phys Educ & Sports Sch, Beijing 100875, Peoples R China.
C3 Xinjiang Normal University; Beijing Normal University
RP Sun, J (corresponding author), Xinjiang Normal Univ, Phys Educ Sch, Urumqi 830017, Peoples R China.
EM sunjianmtap@126.com; scsfdxcp@sina.com; qfjian1985@126.com
FU Humanities and Social Sciences Research Fund of Ministry of Education of
   the People's Republic of China (MOE of PRC) [13YJC890032]; General
   Project of Xinjiang Ethnic Sports Culture Research Center
   [XJEDU040613C03]; key discipline of Xinjiang Uighur Autonomous Region,
   Sports Humanistic Sociology
FX The research was founded within the project No. 13YJC890032 entitled:
   "Psychological Evaluation of Cognitive Function and 1H-MRS Study of
   Frontal Lobe and Hippocampus Metabolism before and after the Aerobic
   Exercise Intervention among Obese Adolescents" being one of Youth
   Project supported by Humanities and Social Sciences Research Fund of
   Ministry of Education of the People's Republic of China (MOE of PRC,
   2013). Meanwhile, the research was founded by the General Project of
   Xinjiang Ethnic Sports Culture Research Center (No. XJEDU040613C03).
   Moreover, the research was founded by key discipline of Xinjiang Uighur
   Autonomous Region, Sports Humanistic Sociology.
CR Atwood T, 2007, RADIAT RES, V168, P574, DOI 10.1667/RR0735.1
   Bader Coffer RS, 1991, BIOCHEMISTRY-US, V26, P105
   Baruth JM, 2013, AUTISM RES, V6, P119, DOI 10.1002/aur.1273
   Block W, 2002, ARCH NEUROL-CHICAGO, V59, P828, DOI 10.1001/archneur.59.5.828
   Cao Z, 2008, WORLD J GASTROENTERO, V14, P3891, DOI 10.3748/wjg.14.3891
   Chang LD, 2013, J NEUROIMMUNE PHARM, V8, P576, DOI 10.1007/s11481-013-9460-x
   Chun-yan HE, 2007, CHIN J SCH HLTH, V28, P489
   Cook S, 2008, J PEDIATR, V152, P165, DOI 10.1016/j.jpeds.2007.06.004
   Coplan JD, 2014, NEUROIMAGE-CLIN, V4, P326, DOI 10.1016/j.nicl.2013.12.014
   Fan Guo-guang, 2000, Chinese Journal of Medical Imaging Technology, V16, P535
   Gabor C, 2015, CHINESE J MED IMAGIN, V5, P53
   Grundy SM, 2005, CIRCULATION, V112, P2735, DOI 10.1161/CIRCULATIONAHA.105.169404
   Jansen JFA, 2006, RADIOLOGY, V240, P318, DOI 10.1148/radiol.2402050314
   Jones RS, 2004, NEUROL RES, V26, P488, DOI 10.1179/016164104225017640
   Lin Yan, 2008, Chinese Journal of Radiology, V42, P34
   Mascalchi M, 2002, J MAGN RESON IMAGING, V16, P532, DOI 10.1002/jmri.10189
   Nakajima S, 2015, SCHIZOPHR RES, V164, P164, DOI 10.1016/j.schres.2015.01.043
   Peng H, 2013, CHIN MENT HLTH J, V8, P624
   Pfeuffer J, 1999, J MAGN RESON, V141, P104, DOI 10.1006/jmre.1999.1895
   PROVENCHER SW, 1982, COMPUT PHYS COMMUN, V27, P213, DOI 10.1016/0010-4655(82)90173-4
   Provencher SW, 2001, NMR BIOMED, V14, P260, DOI 10.1002/nbm.698
   PROVENCHER SW, 1993, MAGNET RESON MED, V30, P672, DOI 10.1002/mrm.1910300604
   Provencher SW, 2005, LCMODEL LCMGUI2 USE
   Raven GM, 1998, DIABETES, V37, P1595
   ROSS B, 1994, MAGN RESON QUART, V10, P191
   Sharma KR, 2011, NMR BIOMED, V24, P1270, DOI 10.1002/nbm.1687
   Sun Y, 2006, PSYCHOL EVALUATION C
   Sun Y., 2007, J APPL CLIN PEDIAT, V22, P1471
   Szulc A, 2013, CURR MED CHEM, V20, P414
   Zhao Z, 2008, MED RECAPITULATE, V14, P622
   [周红 ZHOU Hong], 2009, [中国医学影像技术, Chinese Journal of Medical Imaging Technology], V25, P1367
NR 31
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19491
EP 19505
DI 10.1007/s11042-015-3191-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500010
DA 2024-07-18
ER

PT J
AU Adeyemi-Ejeye, A
   Alreshoodi, M
   Walker, SD
AF Adeyemi-Ejeye, A.
   Alreshoodi, M.
   Walker, S. D.
TI Implementation of 4kUHD HEVC-content transmission
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UHDTV; HEVC; Video streaming; MPEG-2 TS; HLS
ID EFFICIENCY
AB The Internet of things (IoT) has received a great deal of attention in recent years, and is still being approached with a wide range of views. At the same time, video data now accounts for over half of the internet traffic. With the current availability of beyond high definition, it is worth understanding the performance effects, especially for real-time applications. High Efficiency Video Coding (HEVC) aims to provide reduction in bandwidth utilisation while maintaining perceived video quality in comparison with its predecessor codecs. Its adoption aims to provide for areas such as television broadcast, multimedia streaming/storage, and mobile communications with significant improvements. Although there have been attempts at HEVC streaming, the literature/implementations offered do not take into consideration changes in the HEVC specifications. Beyond this point, it seems little research exists on real-time HEVC coded content live streaming. Our contribution fills this current gap in enabling compliant and real-time networked HEVC visual applications. This is done implementing a technique for real-time HEVC encapsulation in MPEG-2 Transmission Stream (MPEG-2 TS) and HTTP Live Streaming (HLS), thereby removing the need for multi-platform clients to receive and decode HEVC streams. It is taken further by evaluating the transmission of 4k UHDTV HEVC-coded content in a typical wireless environment using both computers and mobile devices, while considering well-known factors such as obstruction, interference and other unseen factors that affect the network performance and video quality. Our results suggest that 4kUHD can be streamed at 13.5 Mb/s, and can be delivered to multiple devices without loss in perceived quality.
C1 [Adeyemi-Ejeye, A.] Kingston Univ, Wireless Multimedia & Networking Res Grp WMN, London, England.
   [Alreshoodi, M.] Qassim Univ, Buraydah, Saudi Arabia.
   [Walker, S. D.] Univ Essex, Sch Comp Sci & Elect Engn, Access Networks Lab, London, England.
C3 Kingston University; Qassim University; University of Essex
RP Adeyemi-Ejeye, A (corresponding author), Kingston Univ, Wireless Multimedia & Networking Res Grp WMN, London, England.
EM A.Adeyemi-Ejeye@kingston.ac.uk; mo.alreshoodi@qu.edu.sa;
   stuwal@essex.ac.uk
RI Alreshoodi, Mohammed/AAK-4165-2020; Adeyemi-Ejeye, Anthony/AAO-8477-2020
OI Adeyemi-Ejeye, Anthony/0000-0002-8371-7829; Alreshoodi,
   Mohammed/0000-0002-3066-6909
CR 3GPPTS26. 247- V11. 2. 0, 2013, 3GPPTS26 247 V11 2 0
   Adeyemi-Ejeye A., 2014, HEVC MPEG TS DEFINIT
   Adeyemi-Ejeye AO, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (CONTEL 2013), P109
   Adeyemi-Ejeye AO, 2014, J ELECT COMPUT ENG, V2014, P2
   Adhikari VK, 2012, IEEE INFOCOM SER, P2521, DOI 10.1109/INFCOM.2012.6195644
   [Anonymous], HEVC MPEG TS ALLOWIN
   [Anonymous], 2013, 4K TEST SEQ
   [Anonymous], MULT EXP WORKSH ICME
   Apple, 2014, AIRP EXTR 802 11AC
   Bellard F., 2012, FFMPEG
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   BlackMagic- Design, 2011, BLACKM DEV TOOLS
   BlackMagic-Design, 2006, DECKL 4K EXTR
   Blender-Foundation, 2011, SINT 4K
   Bross B., 2012, High Efficiency Video Coding (HEVC) Text Specification Draft 9
   Buitenhuis D, 2014, LIBX265 ENCODER
   Cisco I., 2012, Cisco visual networking index: Forecast and methodology
   Clift L, 2014, DELIVERING LIVE 4K B
   Combs G., 2007, Wireshark, P12
   Ejeye A. O., 2012, 4 COMP SCI EL ENG C
   Fujii T, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P167, DOI 10.1109/ISPACS.2009.5383876
   Guo J, 2008, IEEE T MULTIMEDIA, V10, P153, DOI 10.1109/TMM.2007.911281
   Halák J, 2011, FUTURE GENER COMP SY, V27, P886, DOI 10.1016/j.future.2010.11.014
   Installations T., 1999, NETWORKS, V910, P37
   Irondi I, 2015, IS T SPIE ELECT IMAG
   Irondi I, 2014, SPIE PHOTONICS EUROP
   ISO/ IEC/ 23009- 1: 2014, 2012, 2300912014 ISO IEC
   ITU-T/ ISO/ IEC, 2012, 265 ITU T ISO IEC
   ITU-T/ISO/ IEC, 2014, 265 ITU T ISO IEC
   ITUT, 2014, HIGH EFFICIENCY VIDE
   ITUT, 2011, ADV VID COD GEN AUD
   Kitamura M, 2011, FUTURE GENER COMP SY, V27, P952, DOI 10.1016/j.future.2010.11.025
   Le Feuvre J., 2007, P 15 ACM INT C MULT, P1009, DOI [10.1145/1291233.1291452, DOI 10.1145/1291233.1291452]
   Leppkes H, 2014, LAV FILTERS 0 62
   ManageEngine, 2014, FREE WIF MON PLUS AN
   Margolis T, 2011, FUTURE GENER COMP SY, V27, P924, DOI 10.1016/j.future.2010.11.023
   Matsuura N, 2014, US Patent, Patent No. [8,724,476, 8724476]
   Microsoft, 2014, MICR WIND OP SYST
   Nakasu E, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2011.2179821
   Netgear, 2013, A6200 802 11AC WIFI
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ozer J, 2014, DASH VS HLS REQUEST
   Oztas B, 2014, INT CONF COMPUT NETW, P1006, DOI 10.1109/ICCNC.2014.6785475
   Pantos R, 2010, HTTP LIVE STRE UNPUB
   Plissonneau L., 2012, ACM MMSys'12, P203
   Rao A., 2011, Em: Proceedings of the Seventh COnference on emerging Networking EXperiments and Technologies, P1, DOI DOI 10.1145/2079296.2079321
   Schierl T, 2012, IEEE T CIRC SYST VID, V22, P1871, DOI 10.1109/TCSVT.2012.2223054
   Shimizu T, 2006, FUTURE GENER COMP SY, V22, P929, DOI 10.1016/j.future.2006.04.001
   Shirai D, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1855
   Sony, 2011, SON FDR AX1 4K PROF
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Totusoft, 2013, LAN SPEED TEST LIT V
   Wang Q, 2015, 265 VIDEO STREAMING, P238
   Zinner Thomas, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P29, DOI 10.1109/QOMEX.2010.5518277
NR 55
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18099
EP 18118
DI 10.1007/s11042-016-3807-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800029
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Lim, M
AF Lim, Mingyu
TI CMSNS: a communication middleware for social networking and networked
   multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Communication middleware; Social networking services; Client-server
   model; Content transmission
ID ARCHITECTURE
AB In this paper, we propose a communication middleware for social networking services (CMSNS) in order to reduce the development effort and to support high accessibility to remote social content such as text, image, and video. The main role of CMSNS is to provide a developer with simple application programming interfaces (APIs) and configuration options related to communication among users. With CMSNS, a developer can easily build communication-related functions which are commonly required in SNS and networked multimedia systems such as the management of communication architecture, user registration and authentication, and synchronous / asynchronous sharing of content among users. In addition to the simple development model, CMSNS enables a server to dynamically adjust the amount of SNS content to be downloaded at a client according to current network conditions. With this scheme, a user can access as much content as possible within an acceptable delay, which enhances the accessibility to remote content.
C1 [Lim, Mingyu] Konkuk Univ, Dept Internet & Multimedia Engn, 120 Neungdong Ro, Seoul 05029, South Korea.
C3 Konkuk University
RP Lim, M (corresponding author), Konkuk Univ, Dept Internet & Multimedia Engn, 120 Neungdong Ro, Seoul 05029, South Korea.
EM mlim@konkuk.ac.kr
RI Lim, Mingyu/D-3819-2011
OI Lim, Mingyu/0000-0002-3749-1902
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A01056848]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2015R1D1A1A01056848).
CR Brooker Daniel, 2010, Proceedings of the 21st Australian Software Engineering Conference (ASWEC 2010), P202, DOI 10.1109/ASWEC.2010.13
   Dagher R, 2008, IEEE ACM DIS SIM, P187, DOI 10.1109/DS-RT.2008.52
   Gupta A, 2009, MOBILE NETW APPL, V14, P35, DOI 10.1007/s11036-008-0114-9
   Hoon-Ki Lee, 2010, Proceedings of the Fifth International Conference on Internet and Web Applications and Services (ICIW 2010), P91, DOI 10.1109/ICIW.2010.21
   Karki B.R., 2008, ACM/IFIP/USENIX Middleware '08 Conference Companion, P93
   Kayastha N, 2011, P IEEE, V99, P2130, DOI 10.1109/JPROC.2011.2169033
   Kim JT, 2011, INT C INT TECHN SEC, pL655
   Lim M, 2011, J NETW COMPUT APPL, V34, P172, DOI 10.1016/j.jnca.2010.08.003
   Mokhtar SB, 2009, INT WORKSH MIDDL PER, V2, P6
   Pietiläinen AK, 2009, 2ND ACM SIGCOMM WORKSHOP ON ONLINE SOCIAL NETWORKS (WOSN 09), P49
   Porras J, 2004, 37 ANN HAW INT C SYS, P90306
   Wu CJ, 2013, IEEE T MOBILE COMPUT, V12, P386, DOI 10.1109/TMC.2011.263
   Yao-Jen Chang, 2007, 2007 International Conference on Convergence Information Technology - ICCIT '07, P151, DOI 10.1109/ICCIT.2007.132
NR 13
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 18119
EP 18135
DI 10.1007/s11042-016-3839-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800030
DA 2024-07-18
ER

PT J
AU Pramila, A
   Keskinarkaus, A
   Takala, V
   Seppänen, T
AF Pramila, Anu
   Keskinarkaus, Anja
   Takala, Valtteri
   Seppanen, Tapio
TI Extracting watermarks from printouts captured with wide angles using
   computational photography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Print-cam; Camera phone; Digital watermarking; Computational
   photography; All-in-focus imaging; Focal stack optimization
AB Thus far the research of print-cam robust watermarking methods has focused on finding new methods for embedding and extracting the watermark. However, the capturing process itself, has been neglected in scientific research. In this paper, we propose a solution for the situation when the watermarked image has been captured in a wide angle and the depth of focus of the camera is not deep enough to capture the whole scene in-focus resulting in unfocused areas. The solution proposed here relies on a subfield of computational photography, namely all-in-focus imaging. All-in-focus images are generated by fusing multiple images from the same scene with different focus distances together, so that the object being photographed is fully in focus. Traditionally, the images to be fused are selected by hand from the focal stack or the whole stack is used for building the all-in-focus image. In mobile phone applications, computational resources are limited and using the full focal stack would result in long processing times and the manual selection of images would not be practical. In addition, we propose a method for optimizing the size of the focal stack and automatically selecting appropriate images for fusion. It is shown here that a watermark can still be recovered from the reconstructed all-in-focus image accurately.
C1 [Pramila, Anu; Keskinarkaus, Anja; Takala, Valtteri; Seppanen, Tapio] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
C3 University of Oulu
RP Pramila, A (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
EM anu.pramila@ee.oulu.fi; anja.keskinarkaus@ee.oulu.fi;
   imv.takala@gmail.com; tapio.seppanen@ee.oulu.fi
FU Finnish Cultural Foundation
FX This work was supported in part by Finnish Cultural Foundation.
CR Adams A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778766
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   [Anonymous], 2007, P FINN SIGN PROC S
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Delgado-Guillen LA, 2013, MIDWEST SYMP CIRCUIT, P1363, DOI 10.1109/MWSCAS.2013.6674909
   Eerola T, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.1.010201
   Eerola T, 2009, LECT NOTES COMPUT SC, V5575, P99, DOI 10.1007/978-3-642-02230-2_11
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grewenig S, 2010, LECT NOTES COMPUT SC, V6376, P533
   He DJ, 2005, IEEE IMAGE PROC, P221
   Heckbert P. S., 1997, TECH REP
   Katayama A., 2004, P 3 INT C MOB UB MUL, P109
   Kim W, 2006, LECT NOTES COMPUT SC, V4261, P106
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pramila Anu, 2008, Proceedings of the Fifth IASTED International Conference on Signal Processing, Pattern Recognition, and Applications, P60
   Pramila A, 2012, SIGNAL IMAGE VIDEO P, V6, P211, DOI 10.1007/s11760-011-0211-2
   Sadovnikov A, 2005, LECT NOTES COMPUT SC, V3540, P409
   Sakurikar P, 2014, IEEE COMPUT SOC CONF, P138, DOI 10.1109/CVPRW.2014.26
   Solh M, 2014, P IS T SPIE EL IM
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Vaquero Daniel., 2011, 2011 IEEE Workshop on applications of computer vision (WACV), P511, DOI DOI 10.1109/WACV.2011.5711547.19
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J, 2016, INT J COMPUT VISION, P1
   Yamana T., 2013, Proceedings of the Ninth Symposium of the International Working Group on Plant Viruses with Fungal Vectors, Obihiro, Hokkaido, Japan, 19-22 August 2013, P49
   Zhang C, 2013, IEEE IMAGE PROC, P1272, DOI 10.1109/ICIP.2013.6738262
NR 26
TC 22
Z9 22
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16063
EP 16084
DI 10.1007/s11042-016-3895-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yin, CY
   Zhang, S
AF Yin, Chunyong
   Zhang, Sun
TI Parallel implementing improved k-means applied for image retrieval and
   anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-means; Information entropy; PCA; Cloud computing; Mobile networks;
   Image retrieval
AB Anomaly detection based on data mining is one of the key technologies to be applied to intelligent detection. K-means is a classic clustering algorithm which is efficient for anomaly detection. Traditional K-means is sensitive to the selection of initial clustering centers. Different initial value can cause different clustering results. We combine improved DD algorithm with information entropy to improve the performance of K-means. Improved K-means can optimize the selection of initial clustering centers; automatically decide the number of clusters and output stable clustering results. After the pretreatment of PCA, the adaptability of improved K-means has a distinct progress. To solve the problem of massive data processing time, we adopt the technology of cloud computing and modify the algorithm for parallel processing. We analyze the performance of improved K-means by using different data sets, KDD Cup99 and public mobile malware data set (i.e. MalGenome). The experimental results illustrate that improved K-means has accurate results and can be applied to anomaly detection in mobile networks. This improved K-means also can be applied for image retrieval by calculating the similarity between each image.
C1 [Yin, Chunyong; Zhang, Sun] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Yin, Chunyong] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology
RP Yin, CY (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.; Yin, CY (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.
EM ycycam@163.com
OI Zhang, Sun/0000-0002-4566-7058
FU National Natural Science Foundation of China [61373134]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD); Jiangsu Key Laboratory of Meteorological Observation and
   Information Processing [KDXS1105]; Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology (CICAEET)
FX This work was funded by the National Natural Science Foundation of China
   (No. 61373134). It was also supported by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), Jiangsu Key
   Laboratory of Meteorological Observation and Information Processing (No.
   KDXS1105) and Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology (CICAEET).
CR Anagnostopoulos M, 2015, INT J INF SECUR, V2015, P1
   [Anonymous], MOB NETW APPL
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Laxman S, 2006, SADHANA-ACAD P ENG S, V31, P173, DOI 10.1007/BF02719780
   Lee S, 2011, EXPERT SYST APPL, V38, P14891, DOI 10.1016/j.eswa.2011.05.058
   Narudin FA, 2016, SOFT COMPUT, V20, P343, DOI 10.1007/s00500-014-1511-6
   Shamir O, 2010, MACH LEARN, V80, P213, DOI 10.1007/s10994-010-5177-8
   [仝雪姣 TONG Xuejiao], 2011, [计算机工程与设计, Computer Engineering and Design], V32, P2721
   Villalba SD, 2007, ARTIF INTELL REV, V27, P273, DOI 10.1007/s10462-008-9082-5
   Yin C., 2013, INT J HYBRID INFORM, V6, P291
   Yin C, 2015, J SUPERCOMPUT, V2015, P1, DOI DOI 10.1007/S10845-015-1135-4
   Yin C., 2014, SCI WORLD J, V2014, P425
   Yin CY, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416590138
   Yuan Fu-yong, 2011, Journal of Computer Applications, V31, P1675, DOI 10.3724/SP.J.1087.2011.01675
   Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16
NR 16
TC 13
Z9 15
U1 0
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16911
EP 16927
DI 10.1007/s11042-016-3638-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500003
DA 2024-07-18
ER

PT J
AU Park, JS
   Hyun, DK
   Hou, JU
   Kim, DG
   Lee, HK
AF Park, Jin-Seok
   Hyun, Dai-Kyung
   Hou, Jong-Uk
   Kim, Do-Guk
   Lee, Heung-Kyu
TI Detecting digital image forgery in near-infrared image of CCTV
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Near-infrared image; CCTV; Image splicing; Forged
   near-infrared image
AB The reliability of CCTV digital images is more important than the reliability of many other types of images. However, image editing tools such as Photoshop make this unreliable. CCTV uses two photography modes, the RGB mode and the near-infrared mode. While near-infrared images have different properties, such as a constant level of source light intensity, and a constant direction of the source light, there are no forensic techniques for near-infrared images. In this paper, we propose a forensic technique based on a constant direction of the source light. In order to expose splicing forgery in near-infrared images, we create an ideal near-infrared image model of a plane. We then calculate gradient vectors of the model and objects in images. Depending on the similarity of two vectors, the image is determined forged or not. This forensic technique helps to improve the reliability of near-infrared images.
C1 [Park, Jin-Seok; Hou, Jong-Uk; Kim, Do-Guk; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
   [Hyun, Dai-Kyung] Agcy Def Dev, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Agency of
   Defense Development (ADD), Republic of Korea
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
EM jspark@mmc.kaist.ac.kr; dkhyun@mmc.kaist.ac.kr; juheo@mmc.kaist.ac.kr;
   dgkim@mmc.kaist.ac.kr; hklee@mmc.kaist.ac.kr
RI Kim, DG/AAP-3206-2021
OI Hou, Jong-Uk/0000-0002-7101-0244
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIP) (Fundamental Research on Deep Learning based
   Complex Digital Image Forgery Detection) [B0717-16-0135]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIP)
   (No. B0717-16-0135, Fundamental Research on Deep Learning based Complex
   Digital Image Forgery Detection).
CR [Anonymous], 2013, ISRN SIGNAL PROCESS
   Choi CH, 2013, FORENSIC SCI INT, V226, P94, DOI 10.1016/j.forsciint.2012.12.014
   Dorsey J., 2007, MORGAN KAUFMANN SERI
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Gill M., 2005, HOME OFFICE RES DEV
   He JF, 2006, LECT NOTES COMPUT SC, V3953, P423
   Hyun DK, 2013, SENSORS, V12, P605
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kee E., 2014, ACM T GRAPH IN PRESS
   Kirchner M, 2009, IEEE INT WORKS INFOR, P21, DOI 10.1109/WIFS.2009.5386489
   Lukas J., 2006, INT SOC OPTICS PHOTO, P60
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm MC, 2010, IEEE T INF FOREN SEC, V5, P492, DOI 10.1109/TIFS.2010.2053202
   Taylor Alma., 2000, ILLUMINATION FUNDAME
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
NR 19
TC 1
Z9 1
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15817
EP 15838
DI 10.1007/s11042-016-3871-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900027
DA 2024-07-18
ER

PT J
AU Dias, R
   Gonçalves, D
   Fonseca, MJ
AF Dias, Ricardo
   Goncalves, Daniel
   Fonseca, Manuel J.
TI From manual to assisted playlist creation: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music playlists; Manual creation; Playlist generation; Assisted
   techniques; Survey
ID MUSIC INFORMATION-RETRIEVAL; VISUALIZATION; GENERATION
AB Nowadays, thanks to the popularization of music streaming services, we gained access to millions of songs to listen to. One of the methods employed by these services to support browsing and promote song discovery are playlists. Additionally, creating and sharing playlists over the Internet have become common practices. A playlist can be defined as a "sequence of songs meant to be listened to as a group". Research on playlist creation has been done according to three perspectives: i) manual creation; ii) automatic generation and recommendation; and iii) assisted playlist creation. In this paper we review previous research on these three approaches, which we believe are complementary on the subject of playlist creation. We highlight the importance of combining insights from these three perspectives to better understand the current problems and methods, criteria and techniques, and how they complement each other. Furthermore, we identify promising research directions for the three different approaches of playlist creation.
C1 [Dias, Ricardo; Goncalves, Daniel] Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
   [Fonseca, Manuel J.] Univ Lisbon, LaSIGE, Fac Cincias, Lisbon, Portugal.
C3 Universidade de Lisboa; INESC-ID; Universidade de Lisboa
RP Dias, R (corresponding author), Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
EM ricardo.dias@ist.utl.pt; daniel.goncalves@inesc-id.pt;
   mjfonseca@ciencias.ulisboa.pt
RI Fonseca, Manuel J./D-5120-2011; Goncalves, Daniel/M-6013-2013
OI Fonseca, Manuel J./0000-0002-3559-828X; Goncalves,
   Daniel/0000-0002-5121-6296
FU Fundacao para a Ciencia e Tecnologia [PEst-OE/EEI/LA0021/2013,
   UID/CEC/00408/2013]; FCT [SFRH/BD/70939/2010]; Fundação para a Ciência e
   a Tecnologia [SFRH/BD/70939/2010] Funding Source: FCT
FX This work was supported by national funds through Fundacao para a
   Ciencia e Tecnologia, under INESC-ID multiannual funding -
   PEst-OE/EEI/LA0021/2013 and LaSIGE Strategic Project -
   UID/CEC/00408/2013. Ricardo Dias was supported by FCT, grant reference
   SFRH/BD/70939/2010.
CR Althoff KD, 2001, HDB SOFTWARE ENG KNO, V1
   [Anonymous], 1998, P WORKING C ADV VISU, DOI DOI 10.1145/948496.948514
   [Anonymous], 2010, P 18 ACM INT C MULTI, DOI DOI 10.1145/1873951.1874145
   [Anonymous], 2013, DOING CULTURAL STUDI
   [Anonymous], P INT C MUS INF RETR
   Asante MK, 2008, TS BIGGER HIP HOP RI
   Aucouturier JJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P105, DOI 10.1109/ICME.2002.1035729
   Baccigalupo C, 2007, LECT NOTES COMPUT SC, V4626, P433
   Baccigalupo C, 2006, LECT NOTES ARTIF INT, V4106, P286
   Bakalov Fedor, 2013, P 2013 INT C INTELLI, P49, DOI DOI 10.1145/2449396.2449405
   Barrington L., 2009, Proceedings of the International Conference on Music Information Retrieval, P357
   Baur D, 2010, STREAMS OUR LIVES VI
   Baur D, 2011, P INT C INT US INT
   Bengio IGY, 2016, COURVILLE DEEP UNPUB
   Bennett J., 2007, P KDD CUP WORKSHOP, P35
   Bonnin G, 2013, P INT MUS INF RET C
   Bonnin G., 2013, WORKSH 27 AAAI C ART
   Bonnin G, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2652481
   Bostandjiev Svetlin, 2012, P 6 ACM C REC SYST D, P35, DOI [10.1145/2365952.2365964, DOI 10.1145/2365952.2365964]
   Brewster Bill., 2006, LAST NIGHT DJ SAVED
   Bull M, 2006, COMP SUPP COMP W SER, V35, P131, DOI 10.1007/1-4020-4097-0_7
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Cardoso L, 2011, S INF INFORUM 2011, V124
   Carreira M, 2012, THESIS U LISBOA
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Celma O, 2010, MUSIC RECOMMENDATION AND DISCOVERY, P1, DOI 10.1007/978-3-642-13287-2
   Chen S., 2012, P 18 ACM SIGKDD INT, P714, DOI [DOI 10.1145/2339530.2339643, 10.1145/2339530.2339643]
   Chen Y., 2009, P IUI, P429
   Chen Y, 2010, THESIS LUDWIG MAXIMI
   Cohen WW, 2000, COMPUT NETW, V33, P685, DOI 10.1016/S1389-1286(00)00057-8
   Crampes M., 2007, Proc. of SADPI'07, P15, DOI DOI 10.1145/1283880.1283885
   Cremonesi P, 2011, LECT NOTES COMPUT SC, V6948, P152, DOI 10.1007/978-3-642-23765-2_11
   Cunningham S.J., 2006, P 7 INT C MUSIC INFO, P240
   De Mooij A, 1997, THESIS TU EINDHOVEN
   Dias R, 2012, P INT C ADV VIS INT
   Dias Renata B., 2014, Marine Turtle Newsletter, P14
   Fields B, 2010, INT C MUS INF RET
   Fields B, 2011, THESIS GOLDSMITHS U
   Freire A.M., 2008, The Radio Journal-International Studies in Broadcast and Audio Media, V5, P97
   Golbeck J., 2011, P WORKSH NOV DIV REC, P35
   Goto M., 2005, P ISMIR, P404
   Goussevskaia O, 2008, P 10 INT C HUM COMP, P359
   Gouyon F, 2011, LAT BREAK DEM SESS I
   Hagen AN, 2015, POP MUSIC SOC, P1
   Hariri N., 2012, P 6 ACM C RECOMMENDE, P131, DOI DOI 10.1145/2365952.2365979
   Heise S, 2008, P CONV AUD ENG SOC
   Herrera P, 2010, 1 WORKHS MUS REC DIS, P7
   Hilliges O, 2006, LECT NOTES COMPUT SC, V4073, P82
   Hsu JL, 2011, IEEE SYS MAN CYBERN, P1417, DOI 10.1109/ICSMC.2011.6083868
   Jennings D, 2007, BLOGS ROCK N ROLL DI
   Kamalzadeh M., 2012, Proceedings of the 13th International Society for Music Information Retrieval Conference (ISMIR'12), P373
   Knees P., 2006, MULTIMEDIA 06 P 14 A, P17, DOI 10.1145/1180639.1180652
   Knijnenburg Bart P., 2012, Proceedings of the sixth ACM conference on Recommender systems, P43, DOI DOI 10.1145/2365952.2365966
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126
   Kosara Robert, 2003, P EUROGRAPHICS
   Kremp PA, 2010, SOC FORCES, V88, P1051
   Laplante A., 2006, P 7 INT C MUSIC INFO, P381
   Lehtiniemi  A., 2007, P MOB, P452
   Leitich S., 2007, P ISMIR, P167
   Leong T, 2008, P 26 ANN CHI C HUM F
   Liang D, 2015, INT C MUS INF RETR
   Lillie A., 2008, THESIS MIT
   Marchionini G, 2006, COMMUN ACM, V49, P41, DOI 10.1145/1121949.1121979
   Mazza R., 2009, INTRO INFORM VISUALI
   McFee B., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR, P537
   Miller S., 2010, P ISMIR, P237
   Morchen Fabian., 2005, Proceedings of the 6th International Conference on Music Information Retrieval ISMIR'05, P396
   Neumayer R, 2005, P INT C MUS INF RETR
   Pampalk E., 2002, USING SMOOTHED DATA
   Pampalk E., 2002, Proceedings of the tenth ACM international conference on Multimedia, P570, DOI DOI 10.1145/641007.641121
   Parra D, 2013, THESIS U PITTSBURGH
   Parra Denis., 2012, Proceedings of the sixth ACM conference on Recommender systems, P333, DOI DOI 10.1145/2365952.2366035
   Pauws S, 2008, INFORM SCIENCES, V178, P647, DOI 10.1016/j.ins.2007.08.019
   Schedl M, 2005, P 16 IEEE VIS 2005 C
   Schedl M, 2013, J INTELL INF SYST, V41, P523, DOI 10.1007/s10844-013-0247-6
   Schwartz Barry., 2005, The Paradox of Choice: Why More Is Less
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Siegel D, 2008, MINDSIGHT
   Slaney M, 2007, P INT C MUS INF RETR
   Sneha Antony JJN, 2014, NT J ADV RES COMPUT, V3, P437
   Stumpf S, 2011, 3 INT WORKSH ADV MUS
   Torrens M, 2004, P INT C MULT INF RET
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Verbert Katrien, 2013, P 2013 INT C INT US, P351, DOI DOI 10.1145/2449396.2449442
   Vignoli F, 2004, P INT C MUS INF RETR
   Vignoli Fabio., 2005, PROC INT S MUSIC INF, P272
   Wall Tim., 2007, RADIO J, V5, P35
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang X, 2014, P 22 ACM INT C MULT
   Weigl DM, 2011, P INT C MUS INF RETR
NR 92
TC 12
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 14375
EP 14403
DI 10.1007/s11042-016-3836-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800031
DA 2024-07-18
ER

PT J
AU Liu, L
   Su, Z
   Fu, XD
   Liu, LJ
   Wang, RM
   Luo, XN
AF Liu, Li
   Su, Zhuo
   Fu, Xiaodong
   Liu, Lijun
   Wang, Ruomei
   Luo, Xiaonan
TI A data-driven editing framework for automatic 3D garment modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D garment modeling; Shape analysis; Semantic segmentation; Variation
   synthesis; Mesh merging
ID HIGH-LEVEL FEATURE; MESH SEGMENTATION; RETRIEVAL; DESIGN
AB Exploring shape variations on virtual garments is significant but challenging to the aspect of 3D garment modeling. In this paper, we propose a data-driven editing framework for automatic 3D garment modeling, which includes semantic garment segmentation, probabilistic reasoning for component suggestion, and garment component merging. The key idea in this work is to develop a simple but effective garment synthesis that utilizes a continuous style description, which can be characterized by the ratio of area and boundary length on garment components. First, a semi-supervised learning algorithm is proposed to simultaneously segment and label the components in 3D garments. Second, a set of matchable probability measurement is applied to recommend components that can be regarded as a new 3D garment. Third, a variation synthesis is developed to satisfy the garment style criteria while ensuring the realistic-looking plausibility of the results. As demonstrated by the experiments, our method is able to generate various reasonable garments with material effects to enrich existing 3D garments.
C1 [Liu, Li; Fu, Xiaodong; Liu, Lijun] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Peoples R China.
   [Su, Zhuo; Wang, Ruomei] Sun Yat Sen Univ, Sch Data & Comp Sci, Natl Engn Res Ctr Digital Life, Guangzhou 510006, Guangdong, Peoples R China.
   [Luo, Xiaonan] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Sch Elect & Informat Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Kunming University of Science & Technology; Sun Yat Sen University; Sun
   Yat Sen University
RP Liu, L (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Comp Technol Applicat Key Lab Yunnan Prov, Kunming 650500, Peoples R China.
EM kmust_mary@163.com
RI Liu, Li/JAC-5598-2023; Su, Zhuo/AAO-4506-2020; Liu, Lijun/AAN-3748-2020
OI Liu, Li/0000-0001-9685-6599; Su, Zhuo/0000-0002-6090-0110; 
FU National Natural Science Foundation of China [61462051, 61462056,
   61272192, 61502541, 81560296]; Applied Fundamental Research Project of
   Yunnan Province [2014FB133]; Applied Fundamental Research Key Project of
   Yunnan Province [2014FA028]; Science Research Funded Project of Kunming
   University of Science and Technology [KKSY201403119]
FX This research is supported by the National Natural Science Foundation of
   China (61462051, 61462056, 61272192, 61502541, 81560296), the Applied
   Fundamental Research Project of Yunnan Province (2014FB133), the Applied
   Fundamental Research Key Project of Yunnan Province(2014FA028), the
   Science Research Funded Project of Kunming University of Science and
   Technology (KKSY201403119).
CR Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Berthouzoz F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461975
   Besl P J, 1992, P SENSOR FUSION 4 CO, V1611, P586
   Biermann H, 2002, ACM T GRAPHIC, V21, P312, DOI 10.1145/566570.566583
   Brouet R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185532
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Chaudhuri S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866205
   Chaudhuri S, 2011, SOIL SCI, V176, P110, DOI 10.1097/SS.0b013e31820a0fe2
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Chen XW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818059
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Covey L, 1992, COSTUME DESIGNERS HD
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Floater MS, 2005, COMPUT AIDED GEOM D, V22, P623, DOI 10.1016/j.cagd.2005.06.004
   Fu HB, 2007, COMPUT GRAPH FORUM, V26, P34, DOI 10.1111/j.1467-8659.2007.00940.x
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Gong BQ, 2013, IEEE T MULTIMEDIA, V15, P369, DOI 10.1109/TMM.2012.2231059
   Graphite, 2010, ALICE GEOMETRY LIGHT
   Guo XK, 2014, GRAPH MODELS, V76, P376, DOI 10.1016/j.gmod.2014.03.019
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Huang QX, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024159
   Jain A, 2012, COMPUT GRAPH FORUM, V31, P631, DOI 10.1111/j.1467-8659.2012.03042.x
   Jin XG, 2006, VISUAL COMPUT, V22, P266, DOI 10.1007/s00371-006-0004-8
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Kreavoy A, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P129, DOI 10.1109/PG.2007.40
   Kwok TH, 2016, IEEE T VIS COMPUT GR
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lévy B, 2003, ACM T GRAPHIC, V22, P364, DOI 10.1145/882262.882277
   Li JT, 2014, COMPUT AIDED DESIGN, V49, P28, DOI 10.1016/j.cad.2013.12.005
   Lin JC, 2008, IEEE T VIS COMPUT GR, V14, P653, DOI 10.1109/TVCG.2007.70632
   Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071
   Lv JJ, 2012, COMPUT GRAPH FORUM, V31, P2241, DOI 10.1111/j.1467-8659.2012.03217.x
   MagnenatThalmann N, 2010, MODELING AND SIMULATING BODIES AND GARMENTS, P1
   MayaCloth, 2010, MAYACLOTH
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P721, DOI 10.1016/j.cad.2012.03.006
   Meng YW, 2012, COMPUT AIDED DESIGN, V44, P68, DOI 10.1016/j.cad.2010.11.008
   Ovsjanikov M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964928
   Robson C, 2011, COMPUT GRAPH-UK, V35, P604, DOI 10.1016/j.cag.2011.03.002
   Seidel H.-P, 2004, 2 EUROGRAPHICS S GEO, P175, DOI DOI 10.1145/1057432.1057456
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Sharf A, 2006, VISUAL COMPUT, V22, P835, DOI 10.1007/s00371-006-0068-5
   Sheffer A, 2001, ENG COMPUT-GERMANY, V17, P326, DOI 10.1007/PL00013391
   Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160
   Simari P, 2009, COMPUT GRAPH FORUM, V28, P1415, DOI 10.1111/j.1467-8659.2009.01518.x
   Takayama K, 2011, COMPUT GRAPH FORUM, V30, P613, DOI 10.1111/j.1467-8659.2011.01883.x
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Turquin E, 2007, IEEE COMPUT GRAPH, V27, P72, DOI 10.1109/MCG.2007.1
   Umetani Nobuyuki, 2011, ACM SIGGRAPH 2011 PA, V90, P1, DOI [10.1145/1964921.1964985event-place:Vancouver,BritishColumbia,Canada, DOI 10.1145/1964921.1964985EVENT-PLACE:VANCOUVER,BRITISHCOLUMBIA,CANADA]
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P553, DOI 10.1111/j.1467-8659.2011.01893.x
   Volino P., 2005, Computer-Aided Design and Applications, V2, P645
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang CCL, 2003, COMPUT AIDED DESIGN, V35, P241, DOI 10.1016/S0010-4485(01)00209-3
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Zhang DW, 2015, IEEE GEOSCI REMOTE S, V12, P701, DOI 10.1109/LGRS.2014.2358994
   Zuffi S, 2015, PROC CVPR IEEE, P3537, DOI 10.1109/CVPR.2015.7298976
NR 60
TC 6
Z9 12
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12597
EP 12626
DI 10.1007/s11042-016-3688-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200019
DA 2024-07-18
ER

PT J
AU Song, Y
   Jeong, S
   Kim, H
AF Song, Yeongkil
   Jeong, Seokwon
   Kim, Harksoo
TI Semi-automatic construction of a named entity dictionary for
   entity-based sentiment analysis in social media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Named entity dictionary; Active learning; Information retrieval; Vector
   space model
AB To understand the user experience in social media or to facilitate the design of human-centric services by social media, users' opinions about specific entities in text messages should be captured. A fine-grained named entity recognizer (NER) is an essential module for identifying opinion targets in text messages, and a named-entity (NE) dictionary is a major resource that affects the performance of an NER. However, it is not easy to construct an NE dictionary manually, because human annotation is time-consuming and labor-intensive. To reduce construction time and labor, we propose a semi-automatic system to construct an NE dictionary from the free online resource, Wikipedia. The proposed system constructs a pseudo-document for each Wikipedia NE by using an active-learning technique. It then classifies Wikipedia entries into NE classes based on similarities between the entries and pseudo-documents located in a vector space. In experiments, the proposed system classified 92.3 % of Wikipedia entries into 29 NE classes. It showed a high performance, with a macro-averaging F1-measure of 0.872 and micro-averaging F1-measure of 0.935.
C1 [Song, Yeongkil; Jeong, Seokwon; Kim, Harksoo] Kangwon Natl Univ, Coll IT, Program Comp & Commun Engn, 1 Gangwondaehak Gil, Seoul 121742, Gangwon Do, South Korea.
C3 Kangwon National University
RP Kim, H (corresponding author), Kangwon Natl Univ, Coll IT, Program Comp & Commun Engn, 1 Gangwondaehak Gil, Seoul 121742, Gangwon Do, South Korea.
EM nlpdrkim@kangwon.ac.kr
OI Kim, Harksoo/0000-0002-8286-7198
FU ATC (Advanced Technology Center) Program "Development of Conversational
   Q&A Search Framework Based On Linked Data" [10048448]; Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   - Ministry of Education, Science and Technology [2013R1A1A4A01005074]
FX This work was supported by ATC (Advanced Technology Center) Program
   "Development of Conversational Q&A Search Framework Based On Linked
   Data: Project No. 10048448." This research was also supported by Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education, Science and Technology
   (2013R1A1A4A01005074).
CR Agichtein E., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P85, DOI 10.1145/336597.336644
   [Anonymous], 1995, OV 3 TEXT RETRIEV C
   Collins M, 2003, COMPUT LINGUIST, V29, P589, DOI 10.1162/089120103322753356
   Fleischman M., 2002, P 19 INT C COMP LING, V1, P1, DOI DOI 10.3115/1072228.1072358
   Grishman R., 1996, 16 INT C COMPUTATION, DOI 10.3115/992628.992709
   Hsueh HY, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-7
   Ko M, 2013, J CONVERG, V4, P23
   Kwon AR, 2013, J INF PROCESS SYST, V9, P538
   Nadeau D, 2007, LINGUIST INVESTIG, V30, P3
   이용훈, 2010, [Journal of Korea Academia-Industrial cooperation Society, 한국산학기술학회논문지], V11, P5089
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Sangjoon Bae, 2010, Journal of KISS: Computing Practices, V16, P492
   Sekine S., 2000, LREC, P1977
   Shinzato K., 2006, P WEB CONT MIN HUM L
   SOUZA M. M. O., 2013, Pesquisa qualitativa em geografia: reflexoes teorico-conceituais e aplicadas., P173
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   Tkachenko M., 2010, HPL2010166
NR 18
TC 9
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11319
EP 11329
DI 10.1007/s11042-016-3445-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000011
DA 2024-07-18
ER

PT J
AU Tapu, R
   Mocanu, B
   Zaharia, T
AF Tapu, Ruxandra
   Mocanu, Bogdan
   Zaharia, Titus
TI A computer vision-based perception system for visually impaired
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Obstacle detection; BoVW/VLAD image representation; Relevant interest
   points; A-HOG descriptor; Visually impaired people
AB In this paper, we introduce a novel computer vision-based perception system, dedicated to the autonomous navigation of visually impaired people. A first feature concerns the real-time detection and recognition of obstacles and moving objects present in potentially cluttered urban scenes. To this purpose, a motion-based, real-time object detection and classification method is proposed. The method requires no a priori information about the obstacle type, size, position or location. In order to enhance the navigation/positioning capabilities offered by traditional GPS-based approaches, which are often unreliably in urban environments, a building/landmark recognition approach is also proposed. Finally, for the specific case of indoor applications, the system has the possibility to learn a set of user-defined objects of interest. Here, multi-object identification and tracking is applied in order to guide the user to localize such objects of interest. The feedback is presented to user by audio warnings/alerts/indications. Bone conduction headphones are employed in order to allow visually impaired to hear the systems warnings without obstructing the sounds from the environment. At the hardware level, the system is totally integrated on an android smartphone which makes it easy to wear, non-invasive and low-cost.
C1 [Tapu, Ruxandra; Mocanu, Bogdan; Zaharia, Titus] Telecom SudParis, Inst Mines Telecom, ARTEMIS Dept, UMR CNRS MAP5 8145, 9 Rue Charles Fourier, F-91000 Evry, France.
   [Tapu, Ruxandra; Mocanu, Bogdan] Univ Politehn Bucuresti, Fac ETTI, Telecommun Dept, Splaiul Independentei 313, Bucharest 060042, Romania.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis; Institut Mines-Telecom Business School; Universite Paris Cite;
   National University of Science & Technology POLITEHNICA Bucharest
RP Tapu, R (corresponding author), Telecom SudParis, Inst Mines Telecom, ARTEMIS Dept, UMR CNRS MAP5 8145, 9 Rue Charles Fourier, F-91000 Evry, France.; Tapu, R (corresponding author), Univ Politehn Bucuresti, Fac ETTI, Telecommun Dept, Splaiul Independentei 313, Bucharest 060042, Romania.
EM ruxandra.tapu@telecom-sudparis.eu
FU AAL (Ambient Assisted Living) ALICE project - ANR (Agence Nationale de
   la Recherche) [AAL-2011-4-099]; CNSA (Conseil National pour la
   Solidarite et l'Autonomie); Romanian National Authority for Scientific
   Research and Innovation, CNCS - UEFISCDI [PN-II-RU-TE-2014-4-0202]
FX This work has been partially supported by the AAL (Ambient Assisted
   Living) ALICE project (AAL-2011-4-099), co-financed by ANR (Agence
   Nationale de la Recherche) and CNSA (Conseil National pour la Solidarite
   et l'Autonomie).; This work was supported by a grant of the Romanian
   National Authority for Scientific Research and Innovation, CNCS -
   UEFISCDI, project number PN-II-RU-TE-2014-4-0202.
CR Alahi Ortiz R, 2012, IEEE C COMP VIS PATT
   Ali H, 2007, 5 INT S MOB MAPP TEC, P6
   [Anonymous], 2011, Visual Object Recognition
   [Anonymous], 2003, Int. Sch. Res. Notic., DOI [DOI 10.5402/2013/145031, DOI 10.5402/145031]
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2011, P 2 ANN ACM C MULTIM
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Baatz G, 2010, LECT NOTES COMPUT SC, V6316, P266, DOI 10.1007/978-3-642-15567-3_20
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Black M. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P231, DOI 10.1109/ICCV.1993.378214
   Blasch B., 1997, FDN ORIENTATION MOBI, V2nd
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Brock M., 2013, P ACM C PERV UB COMP
   Chaudhry Chandra R, 2015, DESIGN MOBILE FACE R
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dakopoulos D, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P930
   Dakopoulos D., 2008, P 1 INT C PERVASIVE, P1, DOI DOI 10.1145/1389586.1389619
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Ding C., 2004, P 21 INT C MACH LEAR, P29, DOI DOI 10.1145/1015330.1015408
   El Mobacher A, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/730143
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Golledge R. G., 1997, J VISUAL IMPAIRMENT, V90, P446
   Gronát P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Johnson Lise A, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6289
   Jose J., 2011, INT J DIGIT CONTENT, V5, P362, DOI [DOI 10.4156/jdcta.vol5.issue5.40, 10.4156/jdcta.vol5.issue5.40, DOI 10.4156/JDCTA.VOL5.ISSUE5.40]
   Khan A., 2012, LNCS, P588
   Kuo BC, 2014, IEEE J-STARS, V7, P317, DOI 10.1109/JSTARS.2013.2262926
   Lee JJ, 2007, LECT NOTES COMPUT SC, V4705, P992
   Lepetit CV, 2010, LNCS
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2009, 9 IASTED INT C VIS
   Lin Q, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56715
   Liu CL, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON MECHANICAL, INDUSTRIAL, AND MANUFACTURING TECHNOLOGIES (MIMT 2010), P13, DOI 10.1115/1.859544.paper3
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Manduchi R, 2012, LECT NOTES COMPUT SC, V7383, P9, DOI 10.1007/978-3-642-31534-3_2
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Meers S, 2005, 1 INT C SENS TECHN, P21
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   Pascolini D, 2012, GLOBAL DATA VISUAL I
   Peng E, 2010, LECT NOTES COMPUT SC, V6406, P590, DOI 10.1007/978-3-642-16355-5_45
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Pradeep V, 2010, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2010.5539792
   Rister B, 2013, INT CONF ACOUST SPEE, P2674, DOI 10.1109/ICASSP.2013.6638141
   Rodríguez A, 2012, SENSORS-BASEL, V12, P17476, DOI 10.3390/s121217476
   Rosa S, 2012, PROC SPIE, V8301, DOI 10.1117/12.911991
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saez J.M., 2008, WORKSH COMP VIS APPL
   Saez JuanManuel., 2005, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P23, DOI [DOI 10.1109/CVPR.2005.461, 10.1109/CVPR. 2005.461]
   Sainarayanan G, 2007, APPL SOFT COMPUT, V7, P257, DOI 10.1016/j.asoc.2005.06.005
   Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Takizawa H, 2012, P IEEE INT S SYST IN
   Tian YL, 2010, LECT NOTES COMPUT SC, V6180, P263, DOI 10.1007/978-3-642-14100-3_39
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vinyals A, 2015, INT C COMP VIS PATT
   Wang HC, 2015, IEEE INT C INT ROBOT, P3701, DOI 10.1109/IROS.2015.7353895
   Yu J.H., 2009, P ICROS SICE INT JOI
   Zhang ML, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P718
   Zhang W., 2005, IEEE Workshop on Applications for Visually Impaired, P21
   Zhao CR, 2011, NEUROCOMPUTING, V74, P2929, DOI 10.1016/j.neucom.2011.03.035
NR 73
TC 15
Z9 16
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11771
EP 11807
DI 10.1007/s11042-016-3617-6
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000037
DA 2024-07-18
ER

PT J
AU Vu, VT
   Tran, DT
   Phan, TH
AF Van Tam Vu
   Duc-Tan Tran
   Trong Hanh Phan
TI Data embedding in audio signal using multiple bit marking layers method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple bit marking layers; Embedding signal; Least significant bit;
   Bit marking layers; Sliding window; Embedding error
AB One of the biggest challenges in data embedding is that the confidential data need to be in the 'transparency' after being embedded into the audio signal. Therefore, embedding methods must reduce the influence of embedded data onto the original audio signal. In this paper, the multiple bit marking layers (MBML) method has been proposed to fulfill this requirement. This method reuses the results from the previous embedding time (layer) as the input data to continue embedding it into audio signals (i.e. the next layer). The quality of the proposed method is evaluated through embedding error (EE), signal-to-noise ratio (SNR), embedded capacity (EC) and contribution error (CE). Experimental results have shown that the proposed method provides better quality of EE, and SNR than any other proposed embedding methods such as: LSB (Least Significant Bit), ELS (Embedding Large Sample.), BM (Bit Marking), and the BM/SW (Sliding Window) method with a single layer.
C1 [Van Tam Vu] Univ Technol & Logist, Hanoi, Vietnam.
   [Duc-Tan Tran] VNU Univ Engn & Technol, Hanoi, Vietnam.
   [Trong Hanh Phan] Le Quy Don Tech Univ, Hanoi, Vietnam.
C3 Vietnam National University Hanoi; Le Quy Don Technical University
RP Tran, DT (corresponding author), VNU Univ Engn & Technol, Hanoi, Vietnam.
EM tamt36bca@gmail.com; tantd@vnu.edu.vn; tronghanhmai@yahoo.com
RI Tran, Duc-Tan/S-3941-2019
OI Tran, Duc-Tan/0000-0002-7673-388X
CR Al-Dalah RA, 2012, AM ACAD SCHOLARLY RE, V4
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2009, INT J DATABASE THEOR
   [Anonymous], 2014, J CONVERGENCE
   Babu L., 2013, INT J COMPUT SCI MOB, V2, P54
   Bagade AM, 2014, J INF PROCESS SYST, V10, P256, DOI 10.3745/JIPS.03.0005
   BALUJA Y, 2003, INT J INNOVATIVE RES, V2, P1564
   Bandyopadhyay S.-K., 2012, International Journal of Advanced Research in Computer and Communication Engineering, V1, P1
   Bhattacharyya Debnath, 2009, [Journal of Security Engineering, 보안공학연구논문지], V6, P187
   Gruhl D., 1996, Information Hiding. First International Workshop Proceedings, P295
   Jang BJ, 2015, J INF PROCESS SYST, V11, P280, DOI 10.3745/JIPS.02.0013
   Kekre H. B., 2008, International Journal of Cryptography and Security, V1
   Kekre HB., 2010, INT J COMPUTER APPL, V7, P14
   MALVIYA S, 2012, INT J ELECT COMMUNIC, V2, P219
   PETROVI R, 1999, ELECT ENERGETICS, V12, P103
   Ralf G, 2006, IEEE INT C AC SPEECH
   Saroha K., 2010, INT J COMPUTER APPL, VI I, P12
   VANTAM V, 2014, J ARMY SCI TECHNOLOG, V33, P13
   Verma N, 2013, INT J ADV RES COMPUT, V2, P49
   Vu V. T., 2015, INT J ADV COMPUTING, V7, P67
   Tam VV, 2015, LECT NOTES ELECTR EN, V352, P191, DOI 10.1007/978-3-662-47487-7_29
NR 21
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11391
EP 11406
DI 10.1007/s11042-016-3851-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000016
DA 2024-07-18
ER

PT J
AU Wang, ZP
   Wang, H
   Tan, JQ
   Chen, P
   Xie, CJ
AF Wang, Zhongpei
   Wang, Hao
   Tan, Jieqing
   Chen, Peng
   Xie, Chengjun
TI Robust object tracking via multi-scale patch based sparse coding
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Multi-scale patch; Sparse coding histogram; Appearance
   model
ID VISUAL TRACKING; REPRESENTATION
AB There are many visual tracking algorithms that are based on sparse representation appearance model. Most of them are modeled by local patches with fixed patch scale, which make trackers less effective when objects undergone appearance changes such as illumination variation, pose change or partial occlusion. To solve the problem, a novel appearance representation model is proposed via multi-scale patch based sparse coding histogram for robust visual tracking. In this paper, the appearance of an object is modeled by different scale patches, which are represented by sparse coding histogram with different scale dictionaries. Then a similarity measure is applied to the calculation of the distance between the sparse coding histograms of target candidate and target template. Finally, the similarity score of the target candidate is passed to a particle filter to estimate the target state sequentially in the tracking process. Additionally, in order to decrease the visual drift caused by partial occlusion, an occlusion handling strategy is adopted, which takes the spatial information of multi-scale patches and occlusion into account. Based on the experimental results on some benchmarks of video sequences, our tracker outperforms state-of-the-art tracking methods.
C1 [Wang, Zhongpei; Wang, Hao; Tan, Jieqing; Xie, Chengjun] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Xie, Chengjun] Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.
   [Chen, Peng] Anhui Univ, Inst Hlth Sci, Hefei 230601, Peoples R China.
C3 Hefei University of Technology; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS; Anhui University
RP Xie, CJ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.; Xie, CJ (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Peoples R China.; Chen, P (corresponding author), Anhui Univ, Inst Hlth Sci, Hefei 230601, Peoples R China.
EM bigeagle@mail.ustc.edu.cn; cjxie@iim.ac.cn
RI Tan, Jie/IVV-5250-2023; Chen, Peng/E-4507-2011; chen, peng/HMD-1278-2023
OI Chen, Peng/0000-0002-5810-8159
FU National Natural Science Foundation of China [61070227, 61300058,
   61472282, 31401293, 41302261]; NSFC-Guangdong Joint Foundation Key
   Project [U1135003]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61070227, 61300058, 61472282, 31401293 and 41302261), the
   NSFC-Guangdong Joint Foundation Key Project under Grant (No. U1135003).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai TX, 2012, PATTERN RECOGN, V45, P2390, DOI 10.1016/j.patcog.2011.12.004
   Cabido R, 2012, J VIS COMMUN IMAGE R, V23, P271, DOI 10.1016/j.jvcir.2011.10.005
   Chen F, 2011, IMAGE VISION COMPUT, V29, P787, DOI 10.1016/j.imavis.2011.08.006
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Doucet A, 2001, STAT ENG IN, P3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Huang GH, 2016, MULTIMED TOOLS APPL, V75, P5473, DOI 10.1007/s11042-015-2516-6
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   PARAG T., 2008, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2008.4587556, 10.1109/CVPR.2008.4587556]
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie CJ, 2013, IET COMPUT VIS, V7, P320, DOI 10.1049/iet-cvi.2012.0228
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 38
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12181
EP 12203
DI 10.1007/s11042-016-3289-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200002
DA 2024-07-18
ER

PT J
AU Liu, MF
   Jiang, L
   Hu, HJ
AF Liu, Maofu
   Jiang, Li
   Hu, Huijun
TI Automatic extraction and visualization of semantic relations between
   medical entities from medicine instructions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic relation; Medical entity; Classification model; Extraction
   algorithm; Semantic relation triple; Semantic relationship graph
ID KNOWLEDGE
AB Recent years have witnessed the rapid development and tremendous research interests in healthcare domain. The health and medical knowledge can be acquired from many sources, such as professional health providers, health community generated data and textual descriptions of medicines. This paper explores the classification and extraction of semantic relation between medical entities from the unstructured medicine Chinese instructions. In this paper, three kinds of textual features are extracted from medicine instruction according to the nature of natural language texts. And then, a support vector machine based classification model is proposed to categorize the semantic relations between medical entities into the corresponding semantic relation types. Finally, the extraction algorithm is utilized to obtain the semantic relation triples. This paper also visualizes the semantic relations between medical entities with relationship graph for their future processing. The experimental results show that the approach proposed in this paper is effective and efficient in the classification and extraction of semantic relations between medical entities.
C1 [Liu, Maofu; Jiang, Li; Hu, Huijun] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Peoples R China.
   [Liu, Maofu; Jiang, Li; Hu, Huijun] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
C3 Wuhan University of Science & Technology
RP Liu, MF (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Peoples R China.; Liu, MF (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
EM e_mfliu@163.com; yujianshiguang@gmail.com; huhuijun@wust.edu.cn
FU National Natural Science Foundation of China [61100133]; Major Projects
   of National Social Science Foundation of China [11ZD189]
FX The work presented in this paper is partially supported by the National
   Natural Science Foundation of China under Grant No. 61100133 and the
   Major Projects of National Social Science Foundation of China under
   Grant No. 11&ZD189.
CR Al-Yahya M, 2014, IEEE INT C SEMANT CO, P96, DOI 10.1109/ICSC.2014.42
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], 2009, P 18 INT C WORLD WID, DOI DOI 10.1145/1526709.1526724
   Ben Abacha Asma, 2011, J Biomed Semantics, V2 Suppl 5, pS4, DOI 10.1186/2041-1480-2-S5-S4
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chen ES, 2008, J AM MED INFORM ASSN, V15, P87, DOI 10.1197/jamia.M2401
   Claessen JHT, 2011, IEEE T VIS COMPUT GR, V17, P2310, DOI 10.1109/TVCG.2011.201
   de Bruijn B, 2011, J AM MED INFORM ASSN, V18, P557, DOI 10.1136/amiajnl-2011-000150
   Embarek M, 2008, P 6 INT C LANG RES E
   Kamsu-Foguem B, 2014, INFORM SYST FRONT, V16, P571, DOI 10.1007/s10796-012-9360-2
   Kolb J, 2012, COMM COM INF SC, V284, P237
   Maeda Y, 2013, EDUC PSYCHOL REV, V25, P69, DOI 10.1007/s10648-012-9215-x
   Nie L, 2014, IEEE T KNOWL DATA EN, V27, P2017
   Nie L, 2013, IEEE T KNOWL DATA EN, V27, P396
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Quan CQ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102039
   Rink B, 2011, J AM MED INFORM ASSN, V18, P594, DOI 10.1136/amiajnl-2011-000153
   Roberts Angus., 2008, BioNLP '08: Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, P10, DOI [DOI 10.3115/1572306.1572309, 10.3115/1572306.1572309]
   Song S., 2014, P ACM 8 INT WORKSH D, P29
   Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203
   Venkatesan P., 2014, International Journal of Science and Technology, V3, P127
   Wang Xiaoyan, 2008, AMIA Annu Symp Proc, P783
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   [杨锦锋 Yang Jinfeng], 2014, [自动化学报, Acta Automatica Sinica], V40, P1537
   Yang YH, 2014, APPL POWER ELECT CO, P379, DOI 10.1109/APEC.2014.6803336
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
NR 34
TC 10
Z9 13
U1 1
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10555
EP 10573
DI 10.1007/s11042-015-3093-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400016
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Huang, JW
   Sun, XM
   Qi, CD
AF Liu, Zhenghui
   Huang, Jiwu
   Sun, Xingming
   Qi, Chuanda
TI A security watermark scheme used for digital speech forensics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Speech forensics; Content authentication; Tamper
   location
ID AUDIO WATERMARKING; ROBUST; ENHANCEMENT; BLIND
AB Based on digital watermark, a speech forensics scheme is proposed. The feature coefficients cross-correlation degree of speech signal is defined, and the property is discussed, which demonstrates that the feature is very robust. Then a new watermark embedding method based on the feature is explored, aiming to enlarge the embedding capacity and solve the security issue of watermark schemes based on public features. In this paper, for each fame of speech signal, it is cut into two parts, and each part is divided into some segments. Then frame number is mapped to a sequence of integers, which are embedded into the segments. The integers can be extracted used for forensics and tamper location after watermarked signal being attacked. Theoretical analysis and experimental results show that the scheme proposed is inaudible and robust against desynchronization attacks, enhances the security of watermark system and has a good ability for speech forensics.
C1 [Liu, Zhenghui; Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui; Huang, Jiwu] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui; Qi, Chuanda] Xinyang Normal Univ, Coll Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Shenzhen University; Shenzhen University; Xinyang Normal University;
   Nanjing University of Information Science & Technology
RP Liu, ZH (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Xinyang Normal Univ, Coll Comp & Informat Technol, Xinyang 464000, Peoples R China.
EM zhenghui.liu@163.com
RI huang, jw/KVY-9917-2024; Sun, Xingming/AAD-1866-2019
FU National Natural Science Foundation of China [61332012, 61272465,
   61502409]; Shenzhen RD Program [GJHZ20140418191518323]; Nanhu Scholars
   Program for Young Scholars of XYNU
FX This paper is supported by the National Natural Science Foundation of
   China (Grant No. 61332012, 61272465, 61502409), Shenzhen R&D Program
   (GJHZ20140418191518323), Nanhu Scholars Program for Young Scholars of
   XYNU. We would like to thank the anonymous reviewers for their
   constructive suggestions.
CR Al-Haj A, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0037-2
   Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   Chen OTC, 2007, IEEE T AUDIO SPEECH, V15, P1605, DOI 10.1109/TASL.2007.896658
   Djendi M, 2014, DIGIT SIGNAL PROCESS, V32, P124, DOI 10.1016/j.dsp.2014.05.007
   Herbig T, 2012, COMPUT SPEECH LANG, V26, P210, DOI 10.1016/j.csl.2011.11.002
   Khan LA, 2010, DIGIT INVEST, V7, P65, DOI 10.1016/j.diin.2009.10.001
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu ZH, 2014, MULTIMED TOOLS APPL, V70, P2271, DOI 10.1007/s11042-012-1235-5
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Ming J, 2014, COMPUT SPEECH LANG, V28, P1269, DOI 10.1016/j.csl.2014.04.003
   Ning Chen, 2010, 2010 International Conference on Audio, Language and Image Processing (ICALIP), P367, DOI 10.1109/ICALIP.2010.5684577
   Sahidullah M, 2012, SPEECH COMMUN, V54, P543, DOI 10.1016/j.specom.2011.11.004
   Schwerin B, 2014, SPEECH COMMUN, V58, P49, DOI 10.1016/j.specom.2013.11.001
   Tabibian S, 2015, SIGNAL PROCESS, V106, P184, DOI 10.1016/j.sigpro.2014.06.027
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang XY, 2016, AEU-INT J ELECTRON C, V70, P416, DOI 10.1016/j.aeue.2016.01.002
   Wang XY, 2011, COMPUT ELECTR ENG, V37, P425, DOI 10.1016/j.compeleceng.2011.05.011
   Wang Y., 2010, J ADV SIGNAL PROCESS, V2010, P1, DOI DOI 10.1016/J.PEPTIDES.2010.12.001
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiang SJ, 2006, LECT NOTES COMPUT SC, V4283, P226
NR 21
TC 17
Z9 17
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9297
EP 9317
DI 10.1007/s11042-016-3533-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300008
DA 2024-07-18
ER

PT J
AU Piccialli, F
   Marulli, F
   Chianese, A
AF Piccialli, Francesco
   Marulli, Fiammetta
   Chianese, Angelo
TI A novel approach for automatic text analysis and generation for the
   cultural heritage domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language generation; Cultural heritage; Text generation;
   Knowledge modeling
AB Knowledge is information that has been contextualised in a certain domain, to be used or applied. It represents the basic core of our Cultural Heritage and Natural Language provides us with prime versatile means of construing experience at multiple levels of organization. The natural language generation field consists in the creation of texts providing information contained in other kind of sources (numerical data, graphics, taxonomies and ontologies or even other texts), with the aim of making such texts indistinguishable, as far as possible, from those created by humans. On the other hand, the knowledge extraction, basing on text mining and text analysis tasks, as examples of the many applications born from computational linguistic, provides summarization, categorization, topics extractions from textual resources using linguistic concepts, which deal with the imprecision and ambiguity of human language. This paper presents a research activity focused on exploring and scientifically describing knowledge structure and organization involved in textual resources' generation. Thus, a novel multidimensional model for the representation of conceptual knowledge, is proposed. Furthermore, a real case study in the Cultural Heritage domain is described to demonstrate the effectiveness and the feasibility of the proposed model and approach.
C1 [Piccialli, Francesco; Chianese, Angelo] Univ Naples Federico II, Via Claudio, Naples, Italy.
   [Marulli, Fiammetta] Univ Naples Federico II, Comp Sci, Via Claudio, Naples, Italy.
C3 University of Naples Federico II; University of Naples Federico II
RP Piccialli, F (corresponding author), Univ Naples Federico II, Via Claudio, Naples, Italy.
EM francesco.piccialli@unina.it
RI Piccialli, Francesco/ABC-2457-2020
OI Piccialli, Francesco/0000-0002-5179-2496; MARULLI,
   Fiammetta/0000-0001-5226-2326
CR Amato F, 2013, PROCEDIA COMPUT SCI, V21, P114, DOI 10.1016/j.procs.2013.09.017
   Androutsopoulos I, 2013, J ARTIF INTELL RES, V48, P671, DOI 10.1613/jair.4017
   [Anonymous], P 29 C COMP APPL QUA
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Chianese A, 2016, ELSEVIER, DOI [10.1016/j.future.2016.04.015, DOI 10.1016/J.FUTURE.2016.04.015]
   Chianese A, 2016, COMPUT ELECTR ENG, DOI [10.1016/j.compeleceng.2016.02.008, DOI 10.1016/J.C0MPELECENG.2016.02.008]
   Chianese A, 2015, J LOCAT BASED SERV, V9, P209, DOI 10.1080/17489725.2015.1099752
   EAGLES Project, 1996, NAT LANG GEN
   Feldman Richard., 2002, Epistemology
   Fodor J., 1975, LANGUAGE THOUGHT, P214
   Galanis D, 2008, INSTALL NATURALOWL
   Hobbes T, 1969, ELEMENTS LAW NATURAL, P186
   Hobbes Thomas, 1651, LEVIATHAN
   JYT, 2015, JYTH PYTH JAV PLATF
   LoBue P, 2012, P 49 ANN M ASS COMP, P329
   Malakasiotis P, 2011, THESIS
   Marulli F, 2015, P 1 EAI INT C FUT AC
   Ramirez C, ADV KNOWLEDGE REPRES
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   WDNET, 2015, WORDNET LEX DAT ENGL
NR 20
TC 3
Z9 3
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10389
EP 10406
DI 10.1007/s11042-016-3628-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400005
DA 2024-07-18
ER

PT J
AU Shooroki, HK
   Chahooki, MAZ
AF Shooroki, Hamid Kargar
   Chahooki, Mohammad Ali Zare
TI Selection of effective training instances for scalable automatic image
   annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prototype selection; Multi-label binary dissimilarity measures;
   Large-scale automatic image annotation; Scalability and annotation time
ID PROTOTYPE SELECTION; LABEL PROPAGATION; WEB; RULE
AB Automatic image annotation means employing learning models for describing visual contents of images by using text descriptors. With the fast growth of digital images in the web, large-scale automatic image annotation has started to deal with major challenges. The most important challenges are scalability and annotation performance. In this research, in order to solve scalability and the image annotation time challenge, the prototype selection approach is used. The assumption of the prototype selection is based on single-label instances while, in image annotation, an instance has more than one label. It means that instances are multi-label. Hence, to employ prototype selection algorithms in image annotation, focusing on the concept of multi-label is a critical task. Thus, taking an appropriate measure in these methods to compute the rate of dissimilarity between label vectors has a great importance. The proposed approach in this paper is based on multi-labeling of prototype selection methods by selecting a modifying appropriate binary dissimilarity measure, in comparison two label vectors. The effectiveness of the proposed approach in reducing the number of training instances and selecting effective ones has been shown by experiments on large-scale NUS-WIDE family image sets. The experimental results showed the effectiveness of the proposed approach in reducing the number of instances and improving annotation performance.
C1 [Shooroki, Hamid Kargar; Chahooki, Mohammad Ali Zare] Yazd Univ, Elect & Comp Engn Dept, Yazd, Iran.
C3 University of Yazd
RP Shooroki, HK (corresponding author), Yazd Univ, Elect & Comp Engn Dept, Yazd, Iran.
EM hamidkargar@stu.yazd.ac.ir
RI Zare Chahooki, Mohammad Ali/AAC-1665-2022
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   Angiulli F, 2007, IEEE T KNOWL DATA EN, V19, P1450, DOI 10.1109/TKDE.2007.190645
   [Anonymous], 2010, Proceedings of the Eighteenth ACM International Conference on Multimedia, DOI DOI 10.1145/1873951.1873959
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   Bandyopadhyay S, 2005, FUZZY SET SYST, V152, P5, DOI 10.1016/j.fss.2004.10.011
   Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878
   Cao J, 2015, MATH PROBL ENG, V501, P103
   Charte F, 2014, LECT NOTES COMPUT SC, V8669, P1, DOI 10.1007/978-3-319-10840-7_1
   Choi S.-S., 2010, Systemics, Cybernetics and Informatic, V8, P43
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Deng C, 2015, SIGNAL PROCESS, V112, P137, DOI 10.1016/j.sigpro.2014.07.017
   Devi VS, 2002, PATTERN RECOGN, V35, P505, DOI 10.1016/S0031-3203(00)00184-9
   DEVIJVER PA, 1986, PATTERN RECOGN LETT, V4, P9, DOI 10.1016/0167-8655(86)90066-8
   Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4
   García S, 2008, PATTERN RECOGN, V41, P2693, DOI 10.1016/j.patcog.2008.02.006
   García S, 2012, IEEE T PATTERN ANAL, V34, P417, DOI 10.1109/TPAMI.2011.142
   García-Pedrajas N, 2010, MACH LEARN, V78, P381, DOI 10.1007/s10994-009-5161-3
   GATES GW, 1972, IEEE T INFORM THEORY, V18, P431, DOI 10.1109/TIT.1972.1054809
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kan MN, 2014, IEEE T CIRC SYST VID, V24, P704, DOI 10.1109/TCSVT.2013.2276713
   Ke X, 2013, COMPUT ELECTR ENG, V39, P945, DOI 10.1016/j.compeleceng.2012.09.017
   KUNCHEVA LI, 1995, PATTERN RECOGN LETT, V16, P809, DOI 10.1016/0167-8655(95)00047-K
   Li R, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P576, DOI 10.1109/JCAI.2009.33
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Özgür A, 2005, LECT NOTES COMPUT SC, V3733, P606
   Riquelme JC, 2003, PATTERN RECOGN, V36, P1009, DOI 10.1016/S0031-3203(02)00119-X
   Sanchez JS, 1997, PATTERN RECOGN LETT, V18, P507, DOI 10.1016/S0167-8655(97)00035-4
   Sierra B, 2001, LECT NOTES ARTIF INT, V2101, P20
   Skalak D., 1994, Proceedings of the Eleventh International Conference on Machine Learning, P293, DOI [https://doi.org/10.1016/B978-1-55860-335-6.50043-X, DOI 10.1016/B978-1-55860-335-6.50043-X, 10.1016/B978-1-55860-335-6.50043-X]
   Subramanya A., 2009, Advances in Neural Information Processing Systems 22, P1803
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P448
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang FC, 2011, PROCEDIA ENGINEER, V23, DOI 10.1016/j.proeng.2011.11.2526
   Wang SH, 2012, IEEE T MULTIMEDIA, V14, P1259, DOI 10.1109/TMM.2012.2193120
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yuan Y, 2013, J VIS COMMUN IMAGE R, V24, P95, DOI 10.1016/j.jvcir.2012.02.007
   Zare Chahooki MA, 2015, J COMMUN TECHNOL EL, V2, P1
   Zhang DQ, 2014, AAAI CONF ARTIF INTE, P2177
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   [No title captured]
NR 46
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9643
EP 9666
DI 10.1007/s11042-016-3572-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300024
DA 2024-07-18
ER

PT J
AU Datia, N
   Pires, JM
   Correia, N
AF Datia, Nuno
   Pires, Joao Moura
   Correia, Nuno
TI Time and space for segmenting personal photo sets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Empirical user study; Segmentation algorithm; Formalisation; Personal
   photo collections
ID EPISODIC MEMORY
AB A personal collection of photos shows large variability in the depicted items, making difficult a fully automated solution to cope with sensory and semantic gaps. Emotions and non-visual contextual information can be very important to address those problems. Manual annotations are key, but their time-consuming nature alienate users from doing them. One solution is to lower the annotation effort, building solutions on top of algorithms that prepare a context separation, making possible the reuse of annotations. In this paper we present a segmentation algorithm that uses spatio-temporal information to segment personal photo collections. The algorithm is assessed in a user study, using the participants own photos. The results show users make none or few changes to the proposed segmentations, indicating an acceptance of the algorithm outcome.
C1 [Datia, Nuno] Inst Politecn Lisboa, ISEL, Rua Conselheiro Emidio Navarro, P-1959007 Lisbon, Portugal.
   [Pires, Joao Moura; Correia, Nuno] Univ Nova Lisboa, FCT, P-2829516 Caparica, Portugal.
C3 Polytechnic Institute of Lisbon; Universidade Nova de Lisboa
RP Correia, N (corresponding author), Univ Nova Lisboa, FCT, P-2829516 Caparica, Portugal.
EM datia@isel.pt; jmp@fct.unl.pt; nmc@fct.unl.pt
RI Correia, Natália T. T./D-6699-2013; Datia, Nuno/R-7957-2016; Moura
   Pires, Joao/D-5450-2013; Correia, Nuno/D-2298-2010
OI Datia, Nuno/0000-0003-1600-0227; Moura Pires, Joao/0000-0001-9933-936X;
   Correia, Nuno/0000-0002-8704-6698
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], P ACM MM
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Bruneau P, 2010, LECT NOTES COMPUT SC, V5811, P127
   Cao L, 2008, CVPR, DOI [10.1109/CVPR.2008.4587382, DOI 10.1109/CVPR.2008.4587382]
   Cobley P, 2009, VISUAL COMMUN-US, V8, P123, DOI 10.1177/1470357209102110
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Cohen J., 1988, STAT POWER ANAL BEHA
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cooper Matthew., 2005, ACM T MULTIM COMPUT, V1, P269, DOI [DOI 10.1145/1083314.1083317, 10.1145/1083314.1083317]
   Datia Nuno, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P195, DOI 10.1007/978-3-319-04114-8_17
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Do T. M. T., 2011, P 13 INT C MULT INT, P353, DOI [DOI 10.1145/2070481.2070550, 10.1145/2070481.2070550]
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   Friedman WJ, 2004, SOC COGNITION, V22, P591, DOI 10.1521/soco.22.5.591.50766
   Gargi U, 2003, TECH REP
   Georgescul M, 2006, 7 SIGD WORKSH DISC D, P144
   Gozali JP, 2012, IEEE INT CONF MULTI, P25, DOI 10.1109/ICMEW.2012.12
   Graham A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P326, DOI 10.1145/544220.544301
   Gye L., 2007, Continuum: Journal of Media Cultural Studies, V21, P279, DOI [DOI 10.1080/10304310701269107, 10.1080/10304310701269107]
   Janssen SMJ, 2006, MEM COGNITION, V34, P138, DOI 10.3758/BF03193393
   Johnson J, 2010, DESIGNING WITH THE MIND IN MIND: SIMPLE GUIDE TO UNDERSTANDING USER INTERFACE DESIGN RULES, P1, DOI 10.1016/B978-0-12-375030-3.00001-6
   Kang H, 2007, INT J HUM-COMPUT INT, V23, P315, DOI 10.1080/10447310701702618
   Kellerman Aharon., 1989, Time, Space, and Society: Geographical Societal Perspectives
   Kirk DS, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1806923.1806924
   Kwok SC, 2012, NEUROPSYCHOLOGIA, V50, P2943, DOI 10.1016/j.neuropsychologia.2012.07.025
   Latif K, 2006, LECT NOTES COMPUT SC, V4080, P467
   Lietz P, 2010, INT J MARKET RES, V52, P249, DOI 10.2501/S147078530920120X
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
   Lux M., 2010, P 2010 ACM WORKSHOP, P41, DOI DOI 10.1145/1878061.1878075
   MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Pevzner L, 2002, COMPUT LINGUIST, V28, P19, DOI 10.1162/089120102317341756
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Reeves LM, 2004, COMMUN ACM, V47, P57, DOI 10.1145/962081.962106
   Seltman H.J., 2012, Experimental Design and Analysis
   St Jacques P, 2008, J COGNITIVE NEUROSCI, V20, P1327, DOI 10.1162/jocn.2008.20091
   Sun FM, 2013, NEUROCOMPUTING, V119, P59, DOI 10.1016/j.neucom.2012.03.038
   Sun Y., 2002, Proceedings of the Tenth ACM International Conference on Multimedia, P81, DOI DOI 10.1145/641007.641022
   Tulving E, 2002, ANNU REV PSYCHOL, V53, P1, DOI 10.1146/annurev.psych.53.100901.135114
   Van House NA, 2009, INT J HUM-COMPUT ST, V67, P1073, DOI 10.1016/j.ijhcs.2009.09.003
   Viana W, 2008, J LOCAT BASED SERV, V2, P211, DOI 10.1080/17489720802487956
   von Watzdorf S., 2010, Proceedings of the 3rd International Workshop on Location and the Web, P2
   Whittaker S, 2010, PERS UBIQUIT COMPUT, V14, P31, DOI 10.1007/s00779-009-0218-7
   Zerubavel E., 1981, HIDDEN RHYTHMS
   Zerubavel E., 1996, QUAL SOCIOL, P283, DOI DOI 10.1007/BF02393273
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zuzanek J., 1993, Loisir et Societe, V15, P559
NR 49
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7141
EP 7173
DI 10.1007/s11042-016-3341-2
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400046
DA 2024-07-18
ER

PT J
AU Ghimire, D
   Jeong, S
   Lee, J
   Park, SH
AF Ghimire, Deepak
   Jeong, Sunghwan
   Lee, Joonwhoan
   Park, San Hyun
TI Facial expression recognition based on local region specific features
   and support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expressions; Local representation; Appearance features; Geometric
   features; Support vector machines
ID BINARY PATTERNS; CLASSIFICATION; MODELS
AB Facial expressions are one of the most powerful, natural and immediate means for human being to communicate their emotions and intensions. Recognition of facial expression has many applications including human-computer interaction, cognitive science, human emotion analysis, personality development etc. In this paper, we propose a new method for the recognition of facial expressions from single image frame that uses combination of appearance and geometric features with support vector machines classification. In general, appearance features for the recognition of facial expressions are computed by dividing face region into regular grid (holistic representation). But, in this paper we extracted region specific appearance features by dividing the whole face region into domain specific local regions. Geometric features are also extracted from corresponding domain specific regions. In addition, important local regions are determined by using incremental search approach which results in the reduction of feature dimension and improvement in recognition accuracy. The results of facial expressions recognition using features from domain specific regions are also compared with the results obtained using holistic representation. The performance of the proposed facial expression recognition system has been validated on publicly available extended Cohn-Kanade (CK+) facial expression data sets.
C1 [Ghimire, Deepak; Jeong, Sunghwan] Korea Elect Technol Inst, IT Applicat Res Ctr, Jeonju Si 561844, Jeollabuk Do, South Korea.
   [Park, San Hyun] Korea Elect Technol Inst, Jeonbuk Embedded Syst Res Ctr, Jeonju Si 561844, Jeollabuk Do, South Korea.
   [Lee, Joonwhoan] Jeonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
C3 Jeonbuk National University
RP Lee, J (corresponding author), Jeonbuk Natl Univ, Div Comp Engn, Jeonju Si 561756, Jeollabuk Do, South Korea.
EM deepak@keti.re.kr; shjeong@keti.re.kr; chlee@jbnu.ac.kr;
   shpark@keti.re.kr
RI Ghimire, Deepak/W-2826-2019
OI Ghimire, Deepak/0000-0001-8940-8739
CR Agrawal S, 2015, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3103-6, DOI 10.1007/S11042-015-3103-6]
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2014, ADV HUMAN COMPUTER I
   Bradski G., 2000, DOBBS J SOFTW TOOLS
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YX, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, VOLS 1 AND 2, P158, DOI 10.1109/GRC.2008.4664719
   Chiranjeevi P, 2015, IEEE T IMAGE PROCESS, V24, P2701, DOI 10.1109/TIP.2015.2421437
   Cruz AC, 2014, IEEE T AFFECT COMPUT, V5, P418, DOI 10.1109/TAFFC.2014.2316151
   Danelakis A, 2015, MULTIMED TOOLS APPL, V74, P5577, DOI 10.1007/s11042-014-1869-6
   Ekman P., 1989, Handbook of Social Psychophysiology, P143
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 1978, Facial action coding system
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Hsu C. W., 2010, Technical Report
   Jiang BH, 2014, INT C PATT RECOG, P1776, DOI 10.1109/ICPR.2014.312
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Li YQ, 2013, IEEE T IMAGE PROCESS, V22, P2559, DOI 10.1109/TIP.2013.2253477
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2010, P 3 IEEE WORKSH CVPR, P94
   Poursaberi A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-17
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Schels Martin, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4251, DOI 10.1109/ICPR.2010.1033
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Siddiqi MH, 2013, SENSORS-BASEL, V13, P16682, DOI 10.3390/s131216682
   Soyel H., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P585, DOI 10.1109/FG.2011.5771463
   Susskind J. M., 2008, Affective Computing, P421
   Tu YH, 2012, INT C PATT RECOG, P2391
   Uddin MZ, 2015, MULTIMED TOOLS APPL, V74, P3675, DOI 10.1007/s11042-013-1793-1
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
   Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788
NR 39
TC 70
Z9 71
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7803
EP 7821
DI 10.1007/s11042-016-3418-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800010
DA 2024-07-18
ER

PT J
AU Hu, HT
   Hsu, LY
AF Hu, Hwai-Tsu
   Hsu, Ling-Yuan
TI Collective blind image watermarking in DWT-DCT domain with adaptive
   embedding strength governed by quality metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block-based image watermarking; Discrete wavelet transform; Discrete
   cosine transform; Progressive quantization index modulation; Collective
   embedding strategy
ID QUANTIZATION INDEX MODULATION; DIGITAL WATERMARKING; OWNERSHIP
   VERIFICATION; WAVELET TRANSFORM; STILL IMAGES; ROBUST; ALGORITHM
AB In this paper the merits of block-based blind watermarking in a composite DWTDCT domain are explored. To improve the performance in robustness and imperceptibility, the quantization index modulation (QIM) applied to DWT-DCT coefficients has been formulated in an adaptive manner, where controlling parameters are designed to minimize the bit error rates of extracted watermarks subject to a quality criterion. The targeted coefficients are chosen based upon signal analysis in combination with additional consideration of human visual characteristics. To further enhance watermarking efficiency, two collective strategies are proposed. One takes advantage of multi-bit embedding and the other modifies the norm of a vector constituted by selected coefficients. Experimental results show that, in comparison with other DWT-and/or DCT-related watermarking methods, the proposed collective schemes achieve satisfactory improvements in robustness while the imperceptibility is properly maintained.
C1 [Hu, Hwai-Tsu] Natl Ilan Univ, Dept Elect Engn, 1,Sec 1,Shen Lung Rd, Yi Lan City 26041, Yi Lan, Taiwan.
   [Hsu, Ling-Yuan] St Marys Jr Coll Med Nursing & Management, Dept Informat Management, 100,Lane 265,Sansing Rd,Sec 2, Sansing Township 26644, Yi Lan, Taiwan.
C3 National Ilan University
RP Hu, HT (corresponding author), Natl Ilan Univ, Dept Elect Engn, 1,Sec 1,Shen Lung Rd, Yi Lan City 26041, Yi Lan, Taiwan.
EM hthu@niu.edu.tw
OI Hsu, Ling-Yuan/0000-0002-9543-6872
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   103-2221-E-197-020]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, ROC, under Grant MOST 103-2221-E-197-020.
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   [Anonymous], 2014, MULTIMEDIA TOOLS APP
   [Anonymous], 1968, MATH PHYS MONOGRAPH
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2007, LECT NOTES COMPUT SC, V4614, P82
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen B, 2001, J VLSI SIG PROCESS S, V27, P7, DOI 10.1023/A:1008107127819
   Chen S- T, 2015, MULTIMED TOOLS APPL, P1
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Deb K., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P458, DOI 10.1109/ICECE.2012.6471586
   Dowling J, 2008, LECT NOTES COMPUT SC, V5041, P454
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Gunjal Baisa L., 2011, International Journal of Computer Science, Engineering and Information Technology (IJCSEIT), V1, P36
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Laskar RH, 2011, COMM COM INF SC, V157, P482
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Stankovic RS, 2003, COMPUT ELECTR ENG, V29, P25, DOI 10.1016/S0045-7906(01)00011-8
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Vetterili M., 1985, ICASSP 85. Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No. 85CH2118-8), P1538
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Zhang GN, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2294
   Zhao X, 2010, STUD COMPUT INTELL, V282, P337
   Zheng Dong., 2006, Electrical and Computer Engineering, P2086
NR 41
TC 43
Z9 45
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6575
EP 6594
DI 10.1007/s11042-016-3332-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400022
DA 2024-07-18
ER

PT J
AU Jin, C
   Wang, RD
   Yan, DQ
AF Jin, Chao
   Wang, Rangding
   Yan, Diqun
TI Steganalysis of MP3Stego with low embedding-rate using Markov feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MP3Stego; Steganography; Steganalysis; Lowembedding-rate;
   One-steptransition probability; Feature selection
AB MP3Stego is a typical steganographic tool for MP3 audios, whose embedding behavior disturbs the intrinsic correlation of the quantized MDCT coefficients (refer to as QMDCTs). In this paper, the Markov feature captured this correlation were designed based on the QMDCTs. The feature is sensitive to the subtle alteration caused by MP3stego embedding even at a low embedding-rate. In addition, some work on QMDCT pre-processing, threshold selection and feature optimization were applied to feature construction, which contribute to improving the detection accuracy and reducing the computational complexity of the proposed scheme. Experimental results show that our approach can effectively detect MP3Stego of low embedding-rate and outperforms the prior arts.
C1 [Jin, Chao; Wang, Rangding; Yan, Diqun] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Wang, RD (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM wangrangding@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
CR [Anonymous], 1117231993 ISOIEC
   [Anonymous], MP3STEGZ
   [Anonymous], UNDERMP3COVER
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Mengyu Qiao, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2566, DOI 10.1109/IJCNN.2009.5178971
   Morkel T, 2005, P 5 ANN INF SEC S AF
   Nissar A, 2010, DIGIT SIGNAL PROCESS, V20, P1758, DOI 10.1016/j.dsp.2010.02.003
   Petitcolas F. A. P., 2002, MP3STEGO
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Qiao MY, 2013, INFORM SCIENCES, V231, P123, DOI 10.1016/j.ins.2012.10.013
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Sullivan K, 2006, IEEE T INF FOREN SEC, V1, P275, DOI 10.1109/TIFS.2006.873595
   [万威 Wan Wei], 2012, [中国科学院研究生院学报, Journal of the Graduate School of the Academy of Sciences], V29, P118
   Westfeld A, 2003, LECT NOTES COMPUT SC, V2578, P324
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yan DQ, 2013, DIGIT SIGNAL PROCESS, V23, P1181, DOI 10.1016/j.dsp.2013.02.013
   Yu RS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1483, DOI 10.1109/ICME.2004.1394517
   Zhang HY, 2014, SCI WORLD J, DOI 10.1155/2014/645953
   Zou DK, 2006, P IEEE INT C MULT EX, P1365
NR 22
TC 20
Z9 22
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6143
EP 6158
DI 10.1007/s11042-016-3264-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400003
DA 2024-07-18
ER

PT J
AU Laraqui, A
   Baataoui, A
   Saaidi, A
   Jarrar, A
   Masrar, M
   Satori, K
AF Laraqui, A.
   Baataoui, A.
   Saaidi, A.
   Jarrar, A.
   Masrar, Med
   Satori, K.
TI Image mosaicing using voronoi diagram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Panorama; Mosaic; Voronoi; Sift; Geometric solution; Ransac; Stitching
ID RANSAC; CONSENSUS; FEATURES
AB In this article, we propose a new method of image stitching that computes, in a robust manner, the transformation model applied to creating a panorama that is close to reality. The random selection of matching points used in existing methods, using Random Sample Consensus (RANSAC) or the threshold of the execution process (iteration number) cannot generally provide sufficient precision. Our approach, in this regard, comes to solve this problem. The calculation of the transformation model is based on the VORONOI diagram that divides images into regions to be used in the matching instead of control points. In this case, the transformation estimation will be based on the regions seeds that provide the best correlation score. Among the advantages of our method is solving problems related to outliers that can, in existing methods, affect the reliability of the mosaic. The results obtained are satisfactory in terms of stability, quality, execution time and reduction of the computational complexity.
C1 [Laraqui, A.; Baataoui, A.; Saaidi, A.; Jarrar, A.; Masrar, Med; Satori, K.] Sidi Mohamed Ben Abdellah Univ, LIIAN, Comp Sci Dept, Fac Sci Dhar Mahraz, Atlas Fes 1796, Morocco.
   [Saaidi, A.] Sidi Mohamed Ben Abdellah Univ, LSI, Dept Math Phys & Informat, Polydisciplinary Fac Taza, Taza 1223, Morocco.
   [Jarrar, A.] Sidi Mohamed Ben Abdellah Univ, LSO, Math Dept, Fac Sci Dhar Mahraz, Atlas Fes 1796, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez; Sidi Mohamed Ben Abdellah University of Fez
RP Laraqui, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, LIIAN, Comp Sci Dept, Fac Sci Dhar Mahraz, Atlas Fes 1796, Morocco.
EM a.laraqui@hotmail.com; baataoui.aziz@gmail.com;
   abderrahim.saaidi@usmba.ac.ma; ajarrar1@yahoo.fr; masrar.m@hotmail.com;
   khalidsatorim3i@yahoo.fr
RI satori, khalid/GSE-3077-2022; Saaidi, Abderrahim/R-1916-2019
OI laraqui, abderrahmane/0000-0002-9404-9192; Saaidi,
   Abderrahim/0000-0003-1708-0468; SATORI, khalid/0000-0001-6055-4169
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Allène C, 2008, INT C PATT RECOG, P2539
   [Anonymous], INT SOC OPTICS PHOTO
   [Anonymous], FUT INF COMM TECHN U
   [Anonymous], ISCCSP 2 INT S COMM
   [Anonymous], IEEE C VIS PATT REC
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bevilacqua A, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P511
   Bevilacqua A, 2007, LECT NOTES COMPUT SC, V4633, P501
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Choi YH, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P74, DOI 10.1109/ICCE.2002.1013933
   Fang XY, 2012, SIGNAL IMAGE VIDEO P, V6, P647, DOI 10.1007/s11760-010-0194-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Huang WJ, 2013, LECT NOTES ELECTR EN, V256, P21, DOI 10.1007/978-3-642-38466-0_3
   Jalink A, 1996, IEEE T MED IMAGING, V15, P260, DOI 10.1109/42.500135
   Jiani Hu, 2011, 2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2011), P2442, DOI 10.1109/FSKD.2011.6019993
   Kim BS, 2011, IEEE T CONSUM ELECTR, V57, P1961, DOI 10.1109/TCE.2011.6131177
   Laraqui A, 2014, COLLOQ INF SCI TECH, P340, DOI 10.1109/CIST.2014.7016643
   Laraqui M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0056-5
   Lhuillier M, 2002, LECT NOTES COMPUT SC, V2351, P125
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma XM, 2015, NEUROCOMPUTING, V151, P1430, DOI 10.1016/j.neucom.2014.10.045
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Montijano E, 2015, IEEE T CONTR SYST T, V23, P150, DOI 10.1109/TCST.2014.2317771
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   SALI E, 1992, INT J REMOTE SENS, V13, P3395, DOI 10.1080/01431169208904130
   Sooknanan K, 2012, OCEANS-IEEE
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Wang XN, 2015, COMPUT AIDED DESIGN, V58, P51, DOI 10.1016/j.cad.2014.08.023
   Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 36
TC 17
Z9 20
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8803
EP 8829
DI 10.1007/s11042-016-3478-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800052
DA 2024-07-18
ER

PT J
AU Sheshjavani, AG
   Akbari, B
AF Sheshjavani, Abdollah Ghaffari
   Akbari, Behzad
TI An adaptive buffer-map exchange mechanism for pull-based peer-to-peer
   video-on-demand streaming systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-on-demand; Peer-to-Peer; Buffer-map exchange; Video streaming
AB Unlike P2P live video streaming in which all the peers in a channel watch a video with tiny differences in viewing points, in P2P video on demand (VoD) streaming systems, neighbor peers may watch the same video with more different viewing points; therefore, using push-based approach is not efficient for such systems, and the overhead of the pull-based approaches is challenging due to the periodical exchange of buffer-maps among the peers. In pull-based P2P VoD systems, to achieve better quality of experience it is necessary to use large buffers at the peers that results in more buffer-maps exchange overhead. In this paper, we study buffer-map exchange challenging in pull-based P2P VoD streaming systems and propose an adaptive mechanism for decreasing overhead by sending the buffer-maps with regard to the viewing points of the peers. Bandwidth overhead of the proposed mechanism is independent of the used buffer sizes and is less dependent to the buffer-map exchange period. By using this effective mechanism, better quality of service can be achieved through using large buffers at the peers, without increasing in the overhead. Our simulation based performance evaluation shows the efficiency of the proposed mechanism in decreasing the bandwidth overhead of buffer-map exchange in P2P VoD streaming systems.
C1 [Sheshjavani, Abdollah Ghaffari; Akbari, Behzad] Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Akbari, B (corresponding author), Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
EM abdollah.ghaffari@modares.ac.ir; b.akbari@modares.ac.ir
RI Sheshjavani, Abdollah Ghaffari/U-7585-2019; Akbari, Behzad/KAM-2918-2024
OI Sheshjavani, Abdollah Ghaffari/0000-0003-1553-0605; Akbari,
   Behzad/0000-0002-0077-9611
CR [Anonymous], 2012, OMNET NETWORK SIMULA
   Baumgart I, 2009, IEEE INT CONF PEER, P87, DOI 10.1109/P2P.2009.5284505
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Chang L, 2013, IEEE J SEL AREA COMM, V31, P227, DOI 10.1109/JSAC.2013.SUP.0513020
   Chatzidrossos I, 2010, PEER PEER NETW APPL, V3, P208, DOI 10.1007/s12083-009-0049-3
   Chu YH, 2002, IEEE J SEL AREA COMM, V20, P1456, DOI 10.1109/JSAC.2002.803066
   Dana C., 2005, Multimedia Signal Processing, 2005 IEEE 7th Workshop on, P1, DOI [DOI 10.1109/MMSP.2005.248586, 10.1109/MMSP.2005.248586.]
   Do TT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1467, DOI 10.1109/ICC.2004.1312755
   Feng C, 2009, IEEE INFOCOM SER, P891, DOI 10.1109/INFCOM.2009.5061999
   Goldoni E, 2010, LECT NOTES COMPUT SC, V6003, P171, DOI 10.1007/978-3-642-12365-8_13
   Guangqing Deng, 2010, 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010), P368, DOI 10.1109/CAR.2010.5456711
   Guo Y, 2007, MULTIMED TOOLS APPL, V33, P109, DOI 10.1007/s11042-006-0067-6
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Jahromi N. Tahghigh, 2010, 2010 5th International Symposium on Telecommunications (IST), P706, DOI 10.1109/ISTEL.2010.5734114
   Jannotti J, 2000, P OPER SYST DES IMPL, V4
   Li B, 2008, P 27 INFOCOM
   Li CX, 2014, IEEE T MULTIMEDIA, V16, P1821, DOI 10.1109/TMM.2014.2340795
   Lima L, 2013, IEEE J SEL AREA COMM, V31, P200, DOI 10.1109/JSAC.2013.SUP.0513018
   Liu CY, 2010, 2010 IEEE 21ST INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P2586, DOI 10.1109/PIMRC.2010.5671773
   Liu JC, 2008, P IEEE, V96, P11, DOI 10.1109/JPROC.2007.909921
   Liu Y, 2008, PEER PEER NETW APPL, V1, P18, DOI 10.1007/s12083-007-0006-y
   Luo J, 2010, IEEE INT CON MULTI, P986, DOI 10.1109/ICME.2010.5582931
   Magharei N, 2009, IEEE ACM T NETWORK, V17, P1052, DOI 10.1109/TNET.2008.2007434
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Puttrapornpisut P, 2011, P INT S INT SIGN PRO, P1
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seyyedi S. M. Y., 2011, 2011 International Symposium on Computer Networks and Distributed Systems (CNDS), P175, DOI 10.1109/CNDS.2011.5764567
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Shuai Y, 2011, J SYST ARCHITECT, V57, P392
   Süselbeck R, 2011, IEEE INT CONF PEER, P10, DOI 10.1109/P2P.2011.6038656
   Uedera R, 2013, IEICE T INF SYST, VE96D, P2713, DOI 10.1587/transinf.E96.D.2713
   Vari I, 2012, INET FRAMEWORK OMNET
   Wang F, 2008, P 27 IEEE INFOCOM
   Wang M, 2013, IEEE ACM T NETWORK, V21, P162, DOI 10.1109/TNET.2012.2194165
   Wu D, 2009, IEEE INFOCOM SER, P2726, DOI 10.1109/INFCOM.2009.5062220
   Yu LC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P99, DOI 10.1109/MUE.2009.27
   Zhang JW, 2014, COMPUT COMMUN, V40, P22, DOI 10.1016/j.comcom.2013.12.002
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 39
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7535
EP 7561
DI 10.1007/s11042-016-3425-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400064
DA 2024-07-18
ER

PT J
AU Zhang, XF
   Sun, YJ
   Wang, G
   Guo, Q
   Zhang, CM
   Chen, BJ
AF Zhang, Xiaofeng
   Sun, Yujuan
   Wang, Gang
   Guo, Qiang
   Zhang, Caiming
   Chen, Beijing
TI Improved fuzzy clustering algorithm with non-local information for image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fuzzy clustering; Image segmentation; FLICM; Pixel relevance; Non-local
   information
ID C-MEANS ALGORITHM; LOCAL INFORMATION
AB Fuzzy C-means(FCM) has been adopted to perform image segmentation due to its simplicity and efficiency. Nevertheless it is sensitive to noise and other image artifacts because of not considering spatial information. Up to now, a series of improved FCM algorithms have been proposed, including fuzzy local information C-means clustering algorithm(FLICM). In FLICM, one fuzzy factor is introduced as a fuzzy local similarity measure, which can control the trade-off between noise and details. However, the fuzzy factor in FLICM cannot estimate the damping extent of neighboring pixels accurately, which will result in poor performance in images of high-level noise. Aiming at solving this problem, this paper proposes an improved fuzzy clustering algorithm, which introduces pixel relevance into the fuzzy factor and could estimate the damping extent accurately. As a result, non-local context information can be utilized in the improved algorithm, which can improve the performance in restraining image artifacts. Experimental results on synthetic, medical and natural images show that the proposed algorithm performs better than current improved algorithms.
C1 [Zhang, Xiaofeng; Sun, Yujuan; Wang, Gang] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
   [Guo, Qiang; Zhang, Caiming] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Zhang, Xiaofeng; Guo, Qiang; Zhang, Caiming] Shandong Prov Key Lab Digital Media Technol, Jinan 250014, Peoples R China.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Ludong University; Shandong University of Finance & Economics; Nanjing
   University of Information Science & Technology
RP Zhang, XF (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.; Zhang, XF (corresponding author), Shandong Prov Key Lab Digital Media Technol, Jinan 250014, Peoples R China.
EM iamzxf@126.com; syj-anne@163.com; happy_wg@163.com;
   guoqiang@sdufe.edu.cn; czhang@sdu.edu.cn; 48008543@qq.com
RI Zhang, Caiming/AHD-6558-2022; Guo, Qiang/I-2949-2019
OI Zhang, Caiming/0000-0002-6365-6221; Guo, Qiang/0000-0003-4219-3528
FU NSF of China [61232016, U1405254, 61373078, 61472220, 61502218];
   Priority Academic Program Development of Jiangsu Higer Education
   Institutions; Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology; NSF of Shandong Province
   [ZR2014FM005]; Key Technology Research and Development Program of
   Shandong Province [2015GSF116001, 2015GGX101004]; Shandong Province
   Higher Educational Science and Technology Program [J14LN20]; Doctoral
   Foundation of Ludong University [LY2015035]
FX The authors would like to thank anonymous referees for their valuable
   comments and suggestions which lead to substantial improvements of this
   paper. Also, the authors would like to thank Dr. Krindis and Dr. Maoguo
   GONG for providing the source codes and experimental pictures of FLICM
   and KWFLICM. We would also thank Dr. Weiling CAI for providing the codes
   of FCMS1, FCMS2 and FGFCM. The research was supported by NSF of China
   (61232016, U1405254, 61373078, 61472220, 61502218), the Priority
   Academic Program Development of Jiangsu Higer Education Institutions,
   Jiangsu Collaborative Innovation Center on Atmospheric Environment and
   Equipment Technology, NSF of Shandong Province(ZR2014FM005), Key
   Technology Research and Development Program of Shandong
   Province(2015GSF116001,2015GGX101004), Shandong Province Higher
   Educational Science and Technology Program(J14LN20), and Doctoral
   Foundation of Ludong University(LY2015035).
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 1975, Proc. 8th International Conference on Numerical Taxonomy
   BESSER H, 1990, LIBR TRENDS, V38, P787
   Bezdek J. C., 1973, Journal of Cybernetics, V3, P58, DOI 10.1080/01969727308546047
   Bezdek James C., 1981, PATTERN RECOGN
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Cocosco C.A., BRAINWEB ONLINE INTE
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Ji ZX, 2011, COMPUT MED IMAG GRAP, V35, P383, DOI 10.1016/j.compmedimag.2010.12.001
   Ji ZX, 2011, PATTERN RECOGN, V44, P999, DOI 10.1016/j.patcog.2010.11.017
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Pham DL, 2001, COMPUT VIS IMAGE UND, V84, P285, DOI 10.1006/cviu.2001.0951
   Pham DL, 2001, COMP MED SY, P127, DOI 10.1109/CBMS.2001.941709
   Roy S, 2008, I S BIOMED IMAGING, P452, DOI 10.1109/ISBI.2008.4541030
   Sun YJ, 2015, MULTIMED TOOLS APPL, V74, P3635, DOI 10.1007/s11042-013-1791-3
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Wang G, 2015, MED IMAGE ANAL, V22, P1, DOI 10.1016/j.media.2015.01.005
   Zhang XF, 2017, SOFT COMPUT, V21, P2165, DOI 10.1007/s00500-015-1920-1
   Zhao F, 2013, NEUROCOMPUTING, V106, P115, DOI 10.1016/j.neucom.2012.10.022
   Zhao F, 2011, FRONT COMPUT SCI CHI, V5, P45, DOI 10.1007/s11704-010-0393-8
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 29
TC 37
Z9 43
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7869
EP 7895
DI 10.1007/s11042-016-3399-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800013
DA 2024-07-18
ER

PT J
AU Chang, SE
   Shen, WC
   Yeh, CH
AF Chang, Shuchih Ernest
   Shen, Wei-Cheng
   Yeh, Chun-Hsiu
TI A comparative study of user intention to recommend content on mobile
   social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Technology acceptance model (TAM); Theory of planned behavior (TPB);
   Trust; Recommendation intention; Mobile social networks
ID TECHNOLOGY ACCEPTANCE; INITIAL TRUST; PLS-SEM; CONTINUANCE INTENTION;
   USAGE; PRIVACY; SITES; INFORMATION; SERVICES; FACEBOOK
AB This study aims to explore user intention to recommend multimedia content on mobile social networks. To better understand user behavioral differences in content recommendations, this study utilizes user behavioral responses on social network services to determine heavy and light users. By analyzing data collected from 258 respondents, the findings reveal that the factors that influence intention to recommend vary among heavy and light users. First, trust, subjective norm, perceived ease of use, and perceived usefulness are considered as predictors for heavy users. Second, subjective norm, trust, perceived ease of use, and perceived usefulness are not influencing factors relative to recommendation intention for light users. Third, trust facilitates heavy users to share their content recommendations on mobile social networks. From theoretical perspectives, the results confirm that dynamic trust transfer could be integrated using the theory of planned behavior with a technology acceptance model. Considering practical implications, our findings regarding the prediction of heavy users provide business insights to content recommendation service. Our study highlights trust strategies related to migrating light users to heavy users. Overall, mobile social network providers must consider user technology perception enhancements and reduce trust concerns. Our findings contribute to theoretical applications and provide practical implications for social service providers in relation to social applications on mobile devices.
C1 [Chang, Shuchih Ernest; Shen, Wei-Cheng] Natl Chung Hsing Univ, Inst Technol Management, Taichung, Taiwan.
   [Yeh, Chun-Hsiu] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung, Taiwan.
   [Yeh, Chun-Hsiu] Chung Chou Univ Sci & Technol, Dept Informat Management, Yuanlin City, Taiwan.
C3 National Chung Hsing University; National Chung Hsing University
RP Shen, WC (corresponding author), Natl Chung Hsing Univ, Inst Technol Management, Taichung, Taiwan.
EM iceman.shen@gmail.com
RI Chang, Shuchih Ernest/ABB-8754-2020
CR Adzic V, 2011, MULTIMED TOOLS APPL, V51, P379, DOI 10.1007/s11042-010-0669-x
   AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Ajzen I., 1985, UNDERSTANDING ATTITU, P11, DOI 10.1007/978-3-642-69746-3_2
   Al Mutawa N, 2012, DIGIT INVEST, V9, pS24, DOI 10.1016/j.diin.2012.05.007
   Al-Debei MM, 2013, DECIS SUPPORT SYST, V55, P43, DOI 10.1016/j.dss.2012.12.032
   [Anonymous], 2000, J Interact Marketing, DOI [DOI 10.1002/(SICI)1520-6653(200021)14:2<17::AID-DIR2>3.0.C0;2-E, 10.1002/(SICI)1520-6653(200021)14:2<17::AID-DIR2>3.0.CO;2-E]
   [Anonymous], 2010, CULT SOC NETW SITES
   Boakye KG, 2015, COMPUT HUM BEHAV, V50, P125, DOI 10.1016/j.chb.2015.04.008
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Braun MT, 2013, COMPUT HUM BEHAV, V29, P673, DOI 10.1016/j.chb.2012.12.004
   Casaló LV, 2011, COMPUT HUM BEHAV, V27, P622, DOI 10.1016/j.chb.2010.04.013
   Chang CW, 2014, COMPUT HUM BEHAV, V35, P33, DOI 10.1016/j.chb.2014.02.028
   Chang IC, 2014, INTERNET RES, V24, P21, DOI 10.1108/IntR-02-2012-0025
   Chang SE, 2016, J BUS RES, V69, P4890, DOI 10.1016/j.jbusres.2016.04.048
   Chang SE, 2011, BEHAV INFORM TECHNOL, V30, P659, DOI 10.1080/01449290903377095
   Chang YP, 2011, COMPUT HUM BEHAV, V27, P1840, DOI 10.1016/j.chb.2011.04.006
   Chen YH, 2007, IND MANAGE DATA SYST, V107, P21, DOI 10.1108/02635570710719034
   Cheung CMK, 2010, DECIS SUPPORT SYST, V49, P24, DOI 10.1016/j.dss.2009.12.006
   Chin WW, 2003, INFORM SYST RES, V14, P189, DOI 10.1287/isre.14.2.189.16018
   Chin WW, 1998, QUANT METH SER, P295
   Colomo-Palacios R, 2017, PERVASIVE MOB COMPUT, V38, P505, DOI 10.1016/j.pmcj.2016.03.001
   Costa-Montenegro E, 2012, EXPERT SYST APPL, V39, P9367, DOI 10.1016/j.eswa.2012.02.131
   Cui YQ, 2013, INT J HUM-COMPUT ST, V71, P919, DOI 10.1016/j.ijhcs.2013.03.004
   Curras-Perez R, 2014, IND MANAGE DATA SYST, V114, P1477, DOI 10.1108/IMDS-07-2014-0219
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Gao LL, 2014, ASIA PAC J MARKET LO, V26, P168, DOI 10.1108/APJML-07-2013-0086
   Gefen D, 2003, MIS QUART, V27, P51, DOI 10.2307/30036519
   Gefen D, 2000, Communications of the Association for Information Systems, V4, P7, DOI [10.1016/j.emj.2021.07.010, DOI 10.1016/J.EMJ.2021.07.010, DOI 10.17705/1CAIS.00407]
   Girolami M, 2015, COMPUT NETW, V88, P51, DOI 10.1016/j.comnet.2015.06.006
   Hair JF, 2011, J MARKET THEORY PRAC, V19, P139, DOI 10.2753/MTP1069-6679190202
   Heidemann J, 2012, COMPUT NETW, V56, P3866, DOI 10.1016/j.comnet.2012.08.009
   Holzer A, 2011, TELEMAT INFORM, V28, P22, DOI 10.1016/j.tele.2010.05.006
   Hsiao CH, 2016, TELEMAT INFORM, V33, P342, DOI 10.1016/j.tele.2015.08.014
   Hsu CL, 2008, INFORM MANAGE-AMSTER, V45, P65, DOI 10.1016/j.im.2007.11.001
   Hsu CL, 2016, TECHNOL FORECAST SOC, V108, P42, DOI 10.1016/j.techfore.2016.04.012
   Hsu CL, 2015, ELECTRON COMMER R A, V14, P46, DOI 10.1016/j.elerap.2014.11.003
   Huang YH, 2010, J HOSP MARKET MANAG, V19, P717, DOI 10.1080/19368623.2010.508002
   Jabeur N, 2013, COMMUN ACM, V56, P71, DOI 10.1145/2428556.2428573
   Jang YT, 2015, MULTIMED TOOLS APPL, V74, P159, DOI 10.1007/s11042-013-1430-z
   Joon Koh, 2007, Communications of the ACM, V50, P68, DOI 10.1145/1216016.1216023
   Kock N, 2015, INT J E-COLLAB, V11, P1, DOI 10.4018/ijec.2015100101
   Kwon SJ, 2014, SOC SCI J, V51, P534, DOI 10.1016/j.soscij.2014.04.005
   Lankton NK, 2011, DATA BASE ADV INF SY, V42, P32, DOI 10.1145/1989098.1989101
   Lee MR, 2014, COMPUT HUM BEHAV, V35, P350, DOI 10.1016/j.chb.2014.03.018
   Lee T., 2005, J ELECTRON COMMER RE, V6, P165, DOI [DOI 10.1145/1964921.1964953, 10.1145/1964921.1964953]
   Li X, 2008, J STRATEGIC INF SYST, V17, P39, DOI 10.1016/j.jsis.2008.01.001
   Liao CC, 2011, ELECTRON COMMER R A, V10, P702, DOI 10.1016/j.elerap.2011.07.003
   Lien CH, 2014, COMPUT HUM BEHAV, V41, P104, DOI 10.1016/j.chb.2014.08.013
   Lin XL, 2016, COMPUT HUM BEHAV, V58, P421, DOI 10.1016/j.chb.2016.01.017
   Lippert SK, 2007, IEEE T ENG MANAGE, V54, P468, DOI 10.1109/TEM.2007.900792
   Lu HP, 2009, INTERNET RES, V19, P442, DOI 10.1108/10662240910981399
   Lu J, 2008, INFORM MANAGE-AMSTER, V45, P52, DOI 10.1016/j.im.2007.11.002
   Luo XM, 2002, IND MARKET MANAG, V31, P111, DOI 10.1016/S0019-8501(01)00182-1
   McKnight DH, 2002, J STRATEGIC INF SYST, V11, P297, DOI 10.1016/S0963-8687(02)00020-3
   Naaman M, 2012, MULTIMED TOOLS APPL, V56, P9, DOI 10.1007/s11042-010-0538-7
   Nikou S, 2014, TELEMAT INFORM, V31, P422, DOI 10.1016/j.tele.2013.11.002
   Okazaki S, 2012, COMPUT HUM BEHAV, V28, P78, DOI 10.1016/j.chb.2011.08.013
   Egea JMO, 2011, COMPUT HUM BEHAV, V27, P319, DOI 10.1016/j.chb.2010.08.010
   Ou CX, 2010, INT J HUM-COMPUT ST, V68, P913, DOI 10.1016/j.ijhcs.2010.08.003
   Pavlou PA, 2004, INFORM SYST RES, V15, P37, DOI 10.1287/isre.1040.0015
   Rauniar R, 2014, J ENTERP INF MANAG, V27, P6, DOI 10.1108/JEIM-04-2012-0011
   Ringle CM, 2012, MIS QUART, V36, pIII
   Sanchez F, 2012, MOBILE NETW APPL, V17, P782, DOI 10.1007/s11036-012-0399-6
   Shin DH, 2010, INTERACT COMPUT, V22, P428, DOI 10.1016/j.intcom.2010.05.001
   Suki NM, 2012, J INF TECHNOL RES, V5, P1, DOI 10.4018/jitr.2012040101
   Tan X, 2012, INTERNET RES, V22, P211, DOI 10.1108/10662241211214575
   Taylor S, 1995, MIS QUART, V19, P561, DOI 10.2307/249633
   Tenenhaus M, 2005, COMPUT STAT DATA AN, V48, P159, DOI 10.1016/j.csda.2004.03.005
   THOMPSON RL, 1991, MIS QUART, V15, P125, DOI 10.2307/249443
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Venkatesh V, 2000, MIS QUART, V24, P115, DOI 10.2307/3250981
   Weisberg J, 2011, INTERNET RES, V21, P82, DOI 10.1108/10662241111104893
   Wu IL, 2005, INT J HUM-COMPUT ST, V62, P784, DOI 10.1016/j.ijhcs.2005.03.003
   Xu CY, 2015, DECIS SUPPORT SYST, V79, P171, DOI 10.1016/j.dss.2015.08.008
   Zhao L, 2012, INT J ELECTRON COMM, V16, P53, DOI 10.2753/JEC1086-4415160403
   Zhou T, 2014, COMPUT HUM BEHAV, V37, P283, DOI 10.1016/j.chb.2014.05.008
   Zhou T, 2012, J ELECTRON COMMER RE, V13, P135
   Zhou T, 2011, INTERNET RES, V21, P527, DOI 10.1108/10662241111176353
   Zhou T, 2010, IND MANAGE DATA SYST, V110, P930, DOI 10.1108/02635571011055126
NR 81
TC 13
Z9 15
U1 1
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5399
EP 5417
DI 10.1007/s11042-016-3966-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500032
DA 2024-07-18
ER

PT J
AU Shivani, S
   Rajitha, B
   Agarwal, S
AF Shivani, Shivendra
   Rajitha, B.
   Agarwal, Suneeta
TI XOR based continuous-tone multi secret sharing for store-and-forward
   telemedicine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Multi secret sharing; Meaningful shares; Unexpanded
   shares; Telemedicine; E-health; Medical image security; Telehelth
ID VISUAL CRYPTOGRAPHY
AB Traditional k out of n visual cryptography scheme has been proposed to encrypt single secret image into n shares where only k or more shares can decode the secret image. Many existing schemes on visual cryptography are restricted to consider only binary images as secret which are not appropriate for many important applications. Store-and-Forward telemedicine is one such application where medical images are transmitted from one site to another via electronic medium to analyze the patient's clinical health status. The main objective of Store-and-Forward telemedicine is to provide remote clinical services via two-way communication between the patient and the healthcare provider using electronic medical image, audio and video means. In this paper, a new XOR based Continuous-tone Multi Secret Sharing scheme suitable for store-and-forward telemedicine is proposed to securely transmit the medical images. It also eliminates basic security constraints of VC like pixel expansion in shares/recovered secret images, random pattern of shares, explicit codebook requirement, lossy recovery of secret and limitation on number of secret and shares. Proposed approach is n out of n multi secret sharing scheme which is able to transmit n secret images simultaneously. All secrets could be revealed only after some computations with all n shares and one master share. Master share has been created with the secret key at encoding phase and it can be regenerated at the time of decoding using same secret key. Here all shares are meaningful in continuous-tone which may provide confidentiality to medical images during transmission. Proposed approach not only preserves all basic characteristics of traditional VC but also increases the capacity of secret image sharing. From the experiments we found that irrespective of visible contents of the shares, the probability of getting back the pixel values of respective original secret images at the receiver end is very high.
C1 [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
   [Rajitha, B.; Agarwal, Suneeta] Natl Inst Technol, Allahabad, Uttar Pradesh, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); Motilal Nehru National Institute of Technology
RP Shivani, S (corresponding author), Thapar Univ, Patiala, Punjab, India.
EM shivendrashivani@gmail.com; rajitha@mnnit.ac.in; suneeta@mnnit.ac.in
RI Shivani, Shivendra/AFN-2368-2022; B, Rajitha/HHR-8738-2022
OI Shivani, Shivendra/0000-0002-5931-6603; 
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi NA, 2014, P 3 INT C ADV INF TE, P73
   [Anonymous], 2007, DELIVERING ACCESS SA
   [Anonymous], 1998, THESIS
   [Anonymous], 2014, J INF HIDING MULTIME
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hsu H.-C., 2004, P IEEE INT C NETW SE, P996
   Liu F., 2010, OPTIMAL XOR BASED 2, V545
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Wu X., 2013, P 1 ACM WORKSH INF H, P181, DOI [10.1177/1753193413497191, DOI 10.1145/2482513.2482515]
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yamaguchi Y., 2015, INT J INF COMMUN TEC, V7, P25
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
NR 25
TC 8
Z9 10
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3851
EP 3870
DI 10.1007/s11042-016-4012-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200033
DA 2024-07-18
ER

PT J
AU Zhang, LY
   Han, B
   Dong, HW
   El Saddik, A
AF Zhang, Longyu
   Han, Bote
   Dong, Haiwei
   El Saddik, Abdulmotaleb
TI Development of an automatic 3D human head scanning-printing system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D reconstruction; RGB-D sensor; Motion sensor; Reconstruction accuracy
   evaluation; 3D printing
ID REGISTRATION; FUSION; MODEL
AB Three-dimensional (3D) technologies have been developing rapidly recent years, and have influenced industrial, medical, cultural, and many other fields. In this paper, we introduce an automatic 3D human head scanning-printing system, which provides a complete pipeline to scan, reconstruct, select, and finally print out physical 3D human heads. To enhance the accuracy of our system, we developed a consumer-grade composite sensor (including a gyroscope, an accelerometer, a digital compass, and a Kinect v2 depth sensor) as our sensing device. This sensing device is then mounted on a robot, which automatically rotates around the human subject with approximate 1-meter radius, to capture the full-view information. The data streams are further processed and fused into a 3D model of the subject using a tablet located on the robot. In addition, an automatic selection method, based on our specific system configurations, is proposed to select the head portion. We evaluated the accuracy of the proposed system by comparing our generated 3D head models, from both standard human head model and real human subjects, with the ones reconstructed from FastSCAN and Cyberware commercial laser scanning systems through computing and visualizing Hausdorff distances. Computational cost is also provided to further assess our proposed system.
C1 [Zhang, Longyu; Han, Bote; Dong, Haiwei; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Comp Res Lab, MCRLab, Ottawa, ON, Canada.
C3 University of Ottawa
RP Dong, HW (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Multimedia Comp Res Lab, MCRLab, Ottawa, ON, Canada.
EM lzhan121@uottawa.ca; bhan097@uottawa.ca; hdong@uottawa.ca;
   elsaddik@uottawa.ca
RI Dong, Haiwei/I-1273-2014; /D-4159-2009
OI Dong, Haiwei/0000-0003-1437-7805; /0000-0002-7690-8547
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
FX Longyu Zhang gratefully acknowledges the financial support from Natural
   Sciences and Engineering Research Council of Canada (NSERC) Postgraduate
   Doctoral Scholarship.
CR Abreu-de Souza M, 2006, P INT SOC PHOT REM S
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], 1996, TECHNICAL REPORT
   [Anonymous], INT J COMPUT VIS
   Ball RM, 2008, INNOVATION, P158
   Barmpoutis A, 2013, IEEE T CYBERNETICS, V43, P1347, DOI 10.1109/TCYB.2013.2276430
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cappelletto E, 2016, MULTIMED TOOLS APPL, V75, P3631, DOI 10.1007/s11042-014-2065-4
   Chen C., 2016, P 25 INT JOINT C ART, P3331
   Chen CS, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P242, DOI 10.1109/ICCV.1998.710725
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dickerson M. T., 1994, Proceedings of the Tenth Annual Symposium on Computational Geometry, P211, DOI 10.1145/177424.177649
   Figueroa N, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629673
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Friess M, 2003, TECHNICAL REPORT
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hennessy RJ, 2002, BIOL PSYCHIAT, V51, P507, DOI 10.1016/S0006-3223(01)01327-0
   Hu YL, 2013, MULTIMED TOOLS APPL, V64, P345, DOI 10.1007/s11042-012-1005-4
   Hull C. W., 1986, U.S. Patent, Patent No. [4,575,330, 4575330, US4575330]
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Jian MW, 2011, MULTIMED TOOLS APPL, V53, P237, DOI 10.1007/s11042-010-0509-z
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kan P, 2010, P 14 CENTR EUR SEM C, P191
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Luximon Y, 2009, COMPUT AIDED DESIGN, V44, P40
   Masuda T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P439, DOI 10.1109/TDPVT.2002.1024099
   Merchán P, 2012, SENSORS-BASEL, V12, P6893, DOI 10.3390/s120606893
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454
   Park JH, 2012, SENSORS-BASEL, V12, P8640, DOI 10.3390/s120708640
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Rau JY, 2012, SENSORS-BASEL, V12, P11271, DOI 10.3390/s120811271
   Remondino F, 2014, PHOTOGRAMM REC, V29, P144, DOI 10.1111/phor.12063
   Rockafellar R, 2005, Variational Analysis
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Shum HPH, 2013, IEEE T CYBERNETICS, V43, P1357, DOI 10.1109/TCYB.2013.2275945
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Su XY, 2001, OPT LASER ENG, V35, P263, DOI 10.1016/S0143-8166(01)00023-9
   Sun YJ, 2015, MULTIMED TOOLS APPL, V74, P3635, DOI 10.1007/s11042-013-1791-3
   Weise Thibaut, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1630, DOI 10.1109/ICCVW.2009.5457479
   Yang L., 2016, IEEE Systems Journal, P1
   Yang L, 2015, IEEE SENS J, V15, P4275, DOI 10.1109/JSEN.2015.2416651
   Yang QX, 2012, LECT NOTES COMPUT SC, V7572, P399, DOI 10.1007/978-3-642-33718-5_29
   Zbontar K, 2013, APPL OPTICS, V52, P2750, DOI 10.1364/AO.52.002750
   Zhang B, 2016, IEEE T CIRCUITS SYST
   Zhang BC, 2016, INT J COMPUT VISION, V118, P364, DOI 10.1007/s11263-016-0880-y
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   Zhang L, 2015, ACM T MULTIM COMPUT, V12
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 53
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4381
EP 4403
DI 10.1007/s11042-016-3949-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200058
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kuo, WC
   Chang, SY
   Wang, CC
   Chang, CC
AF Kuo, Wen-Chung
   Chang, Sheng-Yi
   Wang, Chun-Cheng
   Chang, Chin-Chen
TI Secure multi-group data hiding based on gemd map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; General exploiting modification direction(GEMD); Embedding
   capacity; Section-wise strategy
ID IMAGE
AB Numerous data hiding schemes have been recently proposed based on section-wise strategy. The purpose of these approaches is to enhance security by using a unique key to generate a table. But these approaches are not matched between the embedding secret data length for binary bits and the length of the notation system in the section-wise strategy. In order to enhance the security of secret data and increase embedding capacity, we will propose a secure multi-group data hiding scheme based on General Exploiting Modification Direction (GEMD) map in this paper. Three major advantages exist in our scheme. First is flexibility for the number and combination of elements. Second is the removal of spatial redundancy in our method while maintaining embedding capacity above 1 bpp. Lastly, this method avoids the overflow/underflow problem. Experimental results show that our method enhances embedding capacity and maintains good visual stego image quality. In terms of security, the proposed scheme is more secure than LSB replacement method in terms of resisting visual attack and RS testing.
C1 [Kuo, Wen-Chung; Chang, Sheng-Yi] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Yunlin, Taiwan.
   [Wang, Chun-Cheng] Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, Doctoral Program, Yunlin, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Yunlin 41354, Taiwan.
C3 National Yunlin University Science & Technology; National Yunlin
   University Science & Technology; Feng Chia University; Asia University
   Taiwan
RP Kuo, WC (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Yunlin, Taiwan.
EM simonkuo@yuntech.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR Chan CS, 2012, KSII T INTERNET INF, V6, P1718, DOI 10.3837/tiis.2012.06.013
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Kuo WC, 2009, DATA HIDING SCHEME H
   Kuo WC, 2012, THIRD INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND INTELLIGENT CONTROL (ISIC 2012), P286, DOI 10.1109/ISIC.2012.6449762
   Lee CF, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P497
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   TURNER LF, 1989, Patent No. 8908915
   Wang JJ, 2010, SIGNAL PROCESS, V90, P2954, DOI 10.1016/j.sigpro.2010.04.022
   Wang XT, 2012, SIGNAL PROCESS, V92, P1525, DOI 10.1016/j.sigpro.2011.12.013
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Zhang X, 2007, ELECTRON LETT, V43, P482, DOI 10.1049/el:20070248
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 19
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1901
EP 1919
DI 10.1007/s11042-015-3165-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000014
DA 2024-07-18
ER

PT J
AU Seo, JH
   Kim, MH
AF Seo, Jung Hyuk
   Kim, Myoung Ho
TI Efficient processing of video containment queries by using composite
   ordinal features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based video retrieval; Ordinal feature; Video sequence matching;
   Video indexing
ID SEARCH
AB Video containment queries find the videos that have similar sequence of frames to query video clips. Applying sequence matching to all possible subsequences for video containment queries is computationally expensive for large volumes of video data. In this paper, we propose an efficient candidate segment selection scheme, which selects only a small set of subsequences to be matched to the query sequence, by using a cluster of similar frames, called a frame cluster. We also propose a new type of the ordinal feature, called a composite ordinal feature that allows multiple ranks to certain cells. In experiments with large scale video data sets, we show our method improves the query response time by efficiently selecting a set of subsequences for sequence matching.
C1 [Seo, Jung Hyuk; Kim, Myoung Ho] Korea Adv Inst Sci & Technol, Sch Comp, 373-1 Guseong Dong, Daejeon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, MH (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 373-1 Guseong Dong, Daejeon 305701, South Korea.
EM jhseo@dbserver.kaist.ac.kr; mhkim@dbserver.kaist.ac.kr
RI Kim, Myoung Ho/C-1997-2011
FU Bio-Synergy Research Project of the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, through the NRF [NRF-2013M3A9C4078137]; MSIP,
   Korea under the ITRC support program [IITP-2015-H8501-15-1013]
FX This work was supported by the Bio-Synergy Research Project
   (NRF-2013M3A9C4078137) of the MSIP(Ministry of Science, ICT and Future
   Planning), Korea, through the NRF, and by the MSIP, Korea under the ITRC
   support program (IITP-2015-H8501-15-1013) supervised by the IITP.
CR Adjeroh DA, 1999, COMPUT VIS IMAGE UND, V75, P25, DOI 10.1006/cviu.1999.0764
   [Anonymous], 2009, ACM INT C IM VID RET
   [Anonymous], ART PROGRAMMING
   Bertini M, 2006, LECT NOTES COMPUT SC, V4071, P133
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Chiu CY, 2006, INT C PATT RECOG, P228
   Chiu CY, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2516890
   Chiu CY, 2010, IEEE T CIRC SYST VID, V20, P1603, DOI 10.1109/TCSVT.2010.2087471
   Chiu CY, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671966
   Hampapur A., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P194, DOI 10.1117/12.451091
   Hua XS, 2004, IEEE IMAGE PROC, P685
   Huang Z, 2010, IEEE T MULTIMEDIA, V12, P386, DOI 10.1109/TMM.2010.2050737
   Jagadish HV, 2005, ACM T DATABASE SYST, V30, P364, DOI 10.1145/1071610.1071612
   Jie S, 2008, IEEE T MULTIMEDIA, V10, P409, DOI 10.1109/TMM.2008.917339
   Jun W, 2015, MULTIMED TOOLS APPL, P1
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Liu H, 2013, IEEE T KNOWL DATA EN, V25, P1706, DOI 10.1109/TKDE.2012.92
   Liu JJ, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501658
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu H, 2006, IEEE T KNOWL DATA EN, V18, P1544, DOI 10.1109/TKDE.2006.174
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Shen HT, 2009, IEEE T KNOWL DATA EN, V21, P321, DOI 10.1109/TKDE.2008.168
   Sivic J, 2003, PROCEEDING 9 IEEE IN, P1
   Wu A. G., 2007, P ACM MM, P218
   Zhang J. R., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P842, DOI 10.1109/ICME.2012.111
   Zhou XM, 2012, VLDB J, V21, P489, DOI 10.1007/s00778-011-0255-5
NR 28
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2891
EP 2910
DI 10.1007/s11042-016-3270-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000057
DA 2024-07-18
ER

PT J
AU Williem
   Shon, KW
   Park, IK
AF Williem
   Shon, Ki Won
   Park, In Kyu
TI Spatio-angular consistent editing framework for 4D light field images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 4D, light field; Spatio-angular consistent; Edit propagation;
   Segmentation; In-painting
ID PROPAGATION
AB This paper presents a practical framework for various light field editing algorithms, such as segmentation, sparse edit propagation, and inpainting. A novel framework is introduced with its user interface to perform the light field editing algorithms. Unlike single-image algorithms, the coherence between light field subaperture images is fully considered. Instead of processing all light field subaperture images independently, the proposed framework performs editing in the cluster image domain. The edit result in the cluster image is propagated back to each light field subaperture image using 2D-to-4D light field edit propagation. Experimental results on test images captured by a Lytro off-the-shelf light field camera confirm that the proposed method provides robust and consistent results of edited light field subaperture images.
C1 [Williem; Shon, Ki Won; Park, In Kyu] Inha Univ, Dept Informat & Commun Engn, Inchon, South Korea.
C3 Inha University
RP Park, IK (corresponding author), Inha Univ, Dept Informat & Commun Engn, Inchon, South Korea.
EM 22112195@inha.edu; kiwonshon86@gmail.com; pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013; Williem, Williem/O-6205-2019
OI Williem, Williem/0000-0002-2763-7883; Park, In Kyu/0000-0003-4774-7841
FU Inha University Research Grant
FX This work was supported by Inha University Research Grant.
CR An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   Ao HB, 2015, LECT NOTES COMPUT SC, V9314, P601, DOI 10.1007/978-3-319-24075-6_58
   Bie XH, 2011, COMPUT GRAPH FORUM, V30, P2041, DOI 10.1111/j.1467-8659.2011.02059.x
   Bok Y, 2014, LECT NOTES COMPUT SC, V8694, P47, DOI 10.1007/978-3-319-10599-4_4
   Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197
   Chen XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366151
   Cho D, 2013, IEEE I CONF COMP VIS, P3280, DOI 10.1109/ICCV.2013.407
   Cho D, 2014, LECT NOTES COMPUT SC, V8692, P90, DOI 10.1007/978-3-319-10593-2_7
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Criminisi A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857910
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Jarabo A., 2011, Proc. of the V Ibero-American Symposium in Computer Graphics, P75
   Jarabo Adrian, 2014, ACM T GRAPH, V33
   Lang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185530
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li Y, 2010, COMPUT GRAPH FORUM, V29, P2049, DOI 10.1111/j.1467-8659.2010.01791.x
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
NR 27
TC 9
Z9 10
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16615
EP 16631
DI 10.1007/s11042-016-3754-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700077
DA 2024-07-18
ER

PT J
AU Xiong, JP
   Tang, QH
   He, XW
   Cai, LS
   Wang, F
AF Xiong, Jiping
   Tang, Qinghua
   He, Xiaowei
   Cai, Lisang
   Wang, Fei
TI Tracking in multimedia data via robust reweighted local multi-task
   sparse representation for transportation surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target tracking; Sparse representation; Multi-task
ID VISUAL TRACKING; OBJECT TRACKING; ROUTING ALGORITHM; SYSTEM
AB It is of great importance in smart transportation surveillance to track object reliably from multimedia streaming data. Sparse representation based target tracking methods often suffer from tracking failure when target is under occlusions, pose changes or illumination changes conditions. In this paper, we propose a novel robust reweighted local multi-task sparse tracking algorithm. In the algorithm, local patches of all candidate targets are represented as a linear combination of the corresponding local patches from the template dictionary. Furthermore, in order to efficiently capture the frequently emerging outlier tasks, we decompose the sparse coefficient matrix to two collaborative matrices to make sure that the same type of particles share the same sparse structure. Observing that the edge of the candidate object contains background information, this paper gives a lower weight coefficient to the reconstruction error regularization located in the edge of the local patches than the middle local patches. Experimental evaluations on challenging sequences demonstrate the effectiveness, accuracy and robustness of our proposed algorithm in comparison with state-of-the-art algorithms.
C1 [Xiong, Jiping; Tang, Qinghua; He, Xiaowei; Cai, Lisang; Wang, Fei] Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua, Peoples R China.
C3 Zhejiang Normal University
RP Xiong, JP (corresponding author), Zhejiang Normal Univ, Coll Math Phys & Informat Engn, Jinhua, Peoples R China.
EM xjping@zjnu.cn
FU Zhejiang Provincial Natural Science Foundation of China [ZJNSF
   LY14F010008]; NSFC [61572023]
FX This work was supported in part by Zhejiang Provincial Natural Science
   Foundation of China(ZJNSF LY14F010008) and NSFC(61572023).
CR Ali N.H., 2014, INT J COMPUT APPL, V89
   [Anonymous], APPL SOFT COMPUT
   [Anonymous], INT J COMMUN SYST
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], EEE INT C MULT EXP 2, DOI DOI 10.1016/J.OBHDP.2015.07.001
   [Anonymous], 2014, MECH MACH SCI, DOI DOI 10.1109/ICME.2014.6890262
   [Anonymous], 2009, PROGR NATURAL SCI
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], CHAOS SOLITONS FRACT
   [Anonymous], 2007, GRADIENT METHODS MIN
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, COMPUT VIS PATTERN R
   Bai YC, 2014, IEEE SIGNAL PROC LET, V21, P909, DOI 10.1109/LSP.2014.2320291
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bo CJ, 2016, NEUROCOMPUTING, V171, P1175, DOI 10.1016/j.neucom.2015.07.050
   Bucak SS, 2009, PATTERN RECOGN, V42, P788, DOI 10.1016/j.patcog.2008.09.002
   Chen X, 2009, IEEE DATA MINING, P746, DOI 10.1109/ICDM.2009.128
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257
   Gong P, P 18 ACM SIGKDD INT, P895
   Grabner H., 2006, BMVC, P47
   Guo CX, 2015, DISCRETE CONT DYN-S, V8, P1139, DOI 10.3934/dcdss.2015.8.1139
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He L, 2015, INFRARED PHYS TECHN, V71, P424, DOI 10.1016/j.infrared.2015.05.017
   He L, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/439614
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Hua G., 2006, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), V1, P650
   Jiang DD, 2015, J NETW COMPUT APPL, V57, P182, DOI 10.1016/j.jnca.2015.06.010
   Jiang DD, 2015, ANN TELECOMMUN, V70, P427, DOI 10.1007/s12243-015-0465-8
   Jiang DD, 2015, COMPUT NETW, V84, P1, DOI 10.1016/j.comnet.2015.04.003
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Jiang DD, 2015, T EMERG TELECOMMUN T, V26, P308, DOI 10.1002/ett.2619
   Jiang DD, 2014, AEU-INT J ELECTRON C, V68, P915, DOI 10.1016/j.aeue.2014.04.011
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT ELECTR ENG, V37, P1106, DOI 10.1016/j.compeleceng.2011.06.009
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang Dingde., 2015, Telecommunication Systems, P1
   Jiang N, 2011, PROC CVPR IEEE, P1161, DOI 10.1109/CVPR.2011.5995716
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kim H, 2014, ABST APPL ANAL
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li F, 2015, DUAL GROUP STRUCTURE
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Liu YF, 2014, INT C DIGITAL HOME, P8, DOI 10.1109/ICDH.2014.9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu YF, 2011, LECT NOTES COMPUT SC, V6495, P177, DOI 10.1007/978-3-642-19282-1_15
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Ma R., 2015, CHAOS SOLITONS FRACT
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Olfati-Saber R, 2011, P AMER CONTR CONF, P1100
   Qian C, 2014, NEUROCOMPUTING, V136, P327, DOI 10.1016/j.neucom.2013.12.025
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, SIGNAL PROCESS, V93, P1608, DOI 10.1016/j.sigpro.2012.07.015
   Wang K, 2015, IEEE INT C CL COMP, P236, DOI 10.1109/CLUSTER.2015.42
   Wang WX, 2015, LECT NOTES COMPUT SC, V9490, P638, DOI 10.1007/978-3-319-26535-3_73
   Wang Yi, 2015, P 27 INT C SCI STAT
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiong J, 2014, J SENSORS, V1, P1
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Yang TH, 2017, MULTIMED TOOLS APPL, V76, P19411, DOI 10.1007/s11042-015-3139-7
   Yang YH, 2015, NEUROCOMPUTING, V160, P191, DOI 10.1016/j.neucom.2014.12.060
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zarezade A, 2014, IEEE T IMAGE PROCESS, V23, P4496, DOI 10.1109/TIP.2014.2346029
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang S, 2015, ROBUST VISUAL TRACKI
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang Su, 2015, INT C NETW SYST SEC, P405
   Zhang T, 2015, ROBUST VISUAL TRACKI
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang XL, 2015, LECT NOTES COMPUT SC, V9492, P647, DOI 10.1007/978-3-319-26561-2_76
   Zhong B, 2014, PATTERN RECOGN, V47, P1395, DOI 10.1016/j.patcog.2013.10.002
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou S, 2012, INT J ADV COMPUT TEC, V4
NR 98
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17531
EP 17552
DI 10.1007/s11042-016-3464-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600037
DA 2024-07-18
ER

PT J
AU Choi, CH
   Joo, HJ
AF Choi, Chang-Hoon
   Joo, Hae-Jong
TI Motion recognition technology based remote Taekwondo Poomsae evaluation
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion recognition; Remote evaluation system; Taekwondo Poomsae; KINECT
   sensor
AB This paper finally aims to make the public confident, fair and objective Taekwondo evaluation environment through development of publically certified remote Taekwondo Dan( Poom) promotion evaluation platform and, further vitalize Taekwondo and arrange the base for popularization and distribution of remote Taekwondo Poomsae promotion evaluation system. For this, this paper proposed the remote Poomsae evaluation system which may judge and evaluate the accuracy of motion comparing Taekwondo Poomsae motion of the evaluator to that of black belt player using the motion recognition technology which may recognize Taekwondo Poomsae motion through the trace of certain joint regions. In addition, the researcher investigated the accuracy of each algorithm for the date of relatively simple motions trained using the various motion recognition technologies. Also, the final establishment platform was proposed based on the system configuration, module architecture and the entire process according to the remote Taekwondo Poomsae evaluation platform to be implemented in future.
C1 [Choi, Chang-Hoon] Kyungpook Natl Univ, Sch Comp Informat, Daegu, South Korea.
   [Joo, Hae-Jong] Dongguk Univ, Dept Comp Sci Engn, Seoul, South Korea.
C3 Kyungpook National University; Dongguk University
RP Joo, HJ (corresponding author), Dongguk Univ, Dept Comp Sci Engn, Seoul, South Korea.
EM hoon@knu.ac.kr; hjjoo@dongguk.edu
CR [Anonymous], 2014, TAEKW POOMS COMP RUL
   Choi MS, 2001, J DATABASE RES, V17, P3
   Divyakant J. A., 2000, P IEEE 11 INT WORKSH
   Dunham MH, 1999, P INT WORKSH DAT ENG, P14
   Kang BJ, 2000, P LREC 2000
   Kinect Development Introductory, 2012, KIN DEV INTR
   Lauzac SW, 2001, THESIS
   Lee JW, 2001, J DATABASE RES, V2001, P115
   Madria SK, 2001, DISTRIB PARALLEL DAT, V10, P127, DOI 10.1023/A:1019232412740
   Motion Recognition and Classification Using KINECT sensor data, 2012, AUTUMN ACAD J, V39
   Walbom G, 1995, P 14 S REL DISTR SYS
   주해종, 2005, [The KIPS Transactions : Part D, 정보처리학회논문지D], V12, P521
NR 12
TC 7
Z9 7
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13135
EP 13148
DI 10.1007/s11042-015-2901-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800010
DA 2024-07-18
ER

PT J
AU Guo, X
   Wang, J
   Zhao, W
   Zhang, K
   Wang, C
AF Guo, Xin
   Wang, Jie
   Zhao, Wu
   Zhang, Kai
   Wang, Chen
TI Study of medical device innovation design strategy based on demand
   analysis and process case base
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Demand analysis; Process innovation design; Process case; Innovation
   approaches; Medical device
ID PRODUCT
AB Process innovation is of very great significance for a medical device enterprise to improve its ability to solve problems, lower cost and enhance patients' comfort. In order to inspire designers to realize innovation design based on the actual conditions of the medical device enterprise, this paper has proposed a concept of process innovation design oriented Web-based process case base system model based on demand mining and conversion. The system conducts demand mining based on product enterprise competitiveness model and features of existence-presentation model, utilizes TQCSE and 5W2H1E analysis approaches to assist the medical device designers in locking demands, taking QFD iterative construction as an example, constructs a demand conversion model featuring transition from engineering features to process features, takes innovative methods as logic mainline, and utilizes browser/sever to erect process case search and exhibition models through realization technique and application flow. This paper has demonstrated case base backstage realization and management methods, showcased system interface and demonstrated its effectiveness in process design based on actual medical device cases.
C1 [Guo, Xin; Wang, Jie; Zhao, Wu; Zhang, Kai; Wang, Chen] Sichuan Univ, Dept Mfg Sci & Engn, 24 South Sect 1,Yihuan Rd, Chengdu, Peoples R China.
C3 Sichuan University
RP Guo, X; Zhao, W (corresponding author), Sichuan Univ, Dept Mfg Sci & Engn, 24 South Sect 1,Yihuan Rd, Chengdu, Peoples R China.
EM guoxin_scholar@163.com; zhaowu@scu.edu.cn
RI Guo, Xin/ISU-9038-2023
OI Guo, Xin/0000-0001-8494-4516
FU NSFC (Natural Science Foundation of China) [51175357]; NSFC [51435011];
   Project on Innovative Method from the Ministry of Science and Technology
   of China [2013IM030500]
FX This work was supported by NSFC (Natural Science Foundation of China)
   NO.51175357, NSFC NO.51435011 and Project on Innovative Method from the
   Ministry of Science and Technology of China NO.2013IM030500.
CR Che L, 2014, IEEE T SMART GRID, V5, P2517, DOI 10.1109/TSG.2014.2344024
   Chen Z., 2017, Multimedia Tools and Applications, V76, P17669, DOI [DOI 10.1155/2015/749748, DOI 10.1186/S12929-015-0197-0, DOI 10.1007/S11042-015-2882-0]
   Fey VR, 1999, TRIZ J, V1
   Goldie PA, 1996, CLIN BIOMECH, V11, P333, DOI 10.1016/0268-0033(96)00014-9
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Herrmann A, 2000, INT J PROD ECON, V66, P77, DOI 10.1016/S0925-5273(99)00114-0
   Jiang DD, 2016, WIRELESS PERS COMMUN, V86, P901, DOI 10.1007/s11277-015-2961-6
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Jiang DD, 2009, IEEE COMMUN LETT, V13, P52, DOI 10.1109/LCOMM.2008.081271
   Li T., 2015, CONCURR COMPUT PRACT
   Li X, 2015, IEEE INT S CLUST CLO
   Li Xiaomin, 2014, ScientificWorldJournal, V2014, P608231, DOI 10.1155/2014/608231
   Li Yan, 2005, Computer Integrated Manufacturing Systems, V11, P1201
   Li Y, 2007, INT J ADV MANUF TECH, V33, P213, DOI 10.1007/s00170-006-0457-y
   Li YL, 2009, EXPERT SYST APPL, V36, P7045, DOI 10.1016/j.eswa.2008.08.036
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv Z, 2015, IEEE COMPUT INTELL V
   Lv Z, 2015, PERSONAL UBIQUITOUS
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Presley A, 2000, IEEE T ENG MANAGE, V47, P379, DOI 10.1109/17.865906
   Savransky S.D., 2000, Engineering of Creativity: Introduction to TRIZ Methodology of Inventive Problem Solving., P408
   Seliger G, 2001, CIRP ANN-MANUF TECHN, V50, P425, DOI 10.1016/S0007-8506(07)62989-8
   Shuping Dang, 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P736, DOI 10.1109/InfoSEEE.2014.6947763
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Suh NP., 1990, PRINCIPLES DESIGN
   Umeda Y, 1996, AI EDAM, V10, P275, DOI 10.1017/S0890060400001621
   Utter back JM, 1975, OMEGA, P639
   Wang C, 2015, APPL MATH INFORM SCI, V9, P1593
   Wang JJY, 2015, EXPERT SYST APPL, V42, P1278, DOI 10.1016/j.eswa.2014.09.008
   Wang K, 2015, CONCURR COMPUTAT PRA
   Wang Yi, 2015, P 27 INT C SCI STAT
   Xin Z, 2009, P COMP INT SOFTW ENG
   Yang J, 2015, OBJECTIVE EVALUATION
   Yang JC, 2015, SENSORS-BASEL, V15, P19618, DOI 10.3390/s150819618
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
   Zhang X, 2013, IEEE DECIS CONTR P, P6798, DOI 10.1109/CDC.2013.6760966
   Zou R-l, 2015, J MED BIOMECH, V6, P226
NR 39
TC 11
Z9 14
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14351
EP 14365
DI 10.1007/s11042-015-3176-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500020
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Fan, MD
   Ye, DP
   Yang, J
   Wang, L
AF Ren, Yanzhen
   Fan, Mengdi
   Ye, Dengpan
   Yang, Jing
   Wang, Lina
TI Detection of double MP3 compression based on difference of calibration
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio forensics; Double compression; Audio tampering; MP3; DCH
AB In this paper, a new method to detect the presence of double MP3 compression is proposed. The method is based on the Difference of Calibration Histogram (DCH) characteristic. The features are extracted from the difference of the statistics of MDCT coefficients between the test audio and its calibrated audio. The performance of the scheme is tested on a database containing approximately 13,830 audios, a support vector machine (SVM) is applied to the features for detecting the double MP3 compression. Experimental results show that the proposed features are sensitive to double MP3 compression and achieve higher accuracy than the existing state-of-the-art, especially for same-transcoded and down-transcoded MP3 recompression. The method can also be used to estimate the bit-rate of the first-time MP3 encoding from the recompressed MP3 files.
C1 [Ren, Yanzhen; Fan, Mengdi; Ye, Dengpan; Yang, Jing; Wang, Lina] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Ren, Yanzhen; Ye, Dengpan; Wang, Lina] Wuhan Univ, Key Lab Aerosp Informat Secur & Trusted Comp, Minist Educ, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University
RP Ren, YZ (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.; Ren, YZ (corresponding author), Wuhan Univ, Key Lab Aerosp Informat Secur & Trusted Comp, Minist Educ, Wuhan 430072, Peoples R China.
EM renyz@whu.edu.cn; fmd@whu.edu.cn; yedp@whu.edu.cn; abby@whu.edu.cn;
   lnawang@163.com
FU National Natural Science Foundation of China (NSFC) [61332019, 61373169,
   61272451, 61272453]; Foundation of The National Project 973
   [2014CB340600]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under the grant No. 61332019, 61373169, 61272451 and
   61272453, and by the Foundation of The National Project 973 under the
   grant No. 2014CB340600
CR Alan J, 2008, AUD ENG SOC C 33 INT
   [Anonymous], 2003, P DIG FOR RES WORKSH
   Bianchi T., 2013, P 1 ACM WORKSH INF H, P159
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Farid H., 1999, DETECTING DIGITAL FO
   Guang H, 2014, DYNAMIC MATCHING ALG
   Gupta S, 2012, IEEE MULTIMEDIA, V19, P50, DOI 10.1109/MMUL.2011.74
   Kraetzer C, 2012, IS T SPIE ELECT IMAG
   Liu QZ, 2010, COGN COMPUT, V2, P291, DOI 10.1007/s12559-010-9045-4
   Luo D, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2575978
   Ma PF, 2014, LECT NOTES COMPUT SC, V8389, P258, DOI 10.1007/978-3-662-43886-2_19
   Malik H, 2010, INT CONF ACOUST SPEE, P1710, DOI 10.1109/ICASSP.2010.5495479
   Qiao M., 2013, Signal Processing, Communication and Computing (ICSPCC), 2013 IEEE International Conference on, P1
   Qiao M., 2010, P P 18 ACM INT C MUL, P1011
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang R, 2010, IS T SPIE ELECT IMAG
   Yang R, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P21, DOI 10.1145/1411328.1411334
   Zhao H, 2013, AUDIO RECORDING LOCA
NR 18
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13855
EP 13870
DI 10.1007/s11042-015-2758-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800045
DA 2024-07-18
ER

PT J
AU Kim, H
   Park, S
   Chang, H
AF Kim, Hyeri
   Park, Sangho
   Chang, Hangbae
TI A gap analysis study between multimedia security research and education
   by meta data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Meta-analysis; Multimedia security research trends; Security education;
   Social network analysis
ID METAANALYSIS; EFFICACY; MODELS; NEED
AB Studies are increasing on seeking to cultivate multimedia security professional personnel by providing core knowledge necessary for the safe use of multimedia information. Time is needed for such academic studies to be applied to actual education. However, it should be quickly applicable to security professional education according to the characteristics of the security industry that is very sensitive to a fast-changing environment. For the purpose of examining research trends in the area of multimedia security, a network analysis was conducted focusing on keywords to understand the correlation among studies by analyzing well-known academic journals and identifying the directional nature of research. Based on the keywords researched, a meta-analysis was conducted. The result showed that the highest frequency keyword was 'certification' and keywords formed correlations affecting research trends. For consistency between such research and studies, it is important to increase the relative importance of the multimedia information security management area subject through which the business of companies can be understood. It is also necessary to create balanced thinking and a perspective for multimedia security.
C1 [Kim, Hyeri] Chung Ang Univ, Management Technol & Secur Lab, Seoul, South Korea.
   [Park, Sangho] Chung Ang Univ, Grad Sch, Dept Secur Convergence, Seoul, South Korea.
   [Chang, Hangbae] Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, Seoul, South Korea.
C3 Chung Ang University; Chung Ang University; Chung Ang University
RP Chang, H (corresponding author), Chung Ang Univ, Dept Ind Secur, Coll Business & Econ, Seoul, South Korea.
EM hyeriam@hotmail.com; sanghopark@cau.ac.kr; hbchang@cau.ac.kr
FU Human Resources Development of the Korea Institute of Energy Technology
   Evaluation and Planning (KETEP) - Korea Government Ministry of Trade,
   Industry and Energy [20154030200860]; MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the CPRC (Communication Policy Research
   Center) [R0880-15-1007]
FX This work was supported by the Human Resources Development (no.
   20154030200860) of the Korea Institute of Energy Technology Evaluation
   and Planning (KETEP) Grant funded by the Korea Government Ministry of
   Trade, Industry and Energy.; This research was supported by the MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the CPRC
   (Communication Policy Research Center) Support Program (R0880-15-1007)
   supervised by the IITP (Institute for Information & Communication
   Technology Promotion).
CR Allen M, 1999, CRIT STUD MASS COMM, V16, P373, DOI 10.1080/15295039909367102
   Amankwa E, 2014, INT CONF INTERNET, P248, DOI 10.1109/ICITST.2014.7038814
   [Anonymous], INF ASSUR SECUR ED T
   Armstrong CJ, 2007, 2007 IEEE INFORMATION ASSURANCE WORKSHOP, P30, DOI 10.1109/IAW.2007.381910
   Crossler RE, 2013, COMPUT SECUR, V32, P90, DOI 10.1016/j.cose.2012.09.010
   Du WL, 2006, COMPUT SECUR, V25, P190, DOI 10.1016/j.cose.2005.09.011
   Durlak JA, 2011, CHILD DEV, V82, P405, DOI 10.1111/j.1467-8624.2010.01564.x
   Guo KH, 2012, INFORM MANAGE-AMSTER, V49, P320, DOI 10.1016/j.im.2012.08.001
   Higgins JPT, 2002, STAT MED, V21, P1539, DOI 10.1002/sim.1186
   Idziorek J., 2012, 2012 Frontiers in Education Conference Proceedings, P1
   Kolkowska E, 2013, COMPUT SECUR, V33, P3, DOI 10.1016/j.cose.2012.07.001
   Nelson HD, 2006, JAMA-J AM MED ASSOC, V295, P2057, DOI 10.1001/jama.295.17.2057
   Osterholm MT, 2012, LANCET INFECT DIS, V12, P36, DOI 10.1016/S1473-3099(11)70295-X
   Palmerini T, 2012, LANCET, V379, P1393, DOI 10.1016/S0140-6736(12)60324-9
   Posillico T, 2005, J APPL SEC RES, V1, P11, DOI 10.1300/J460v01n02_02
   Ruff CT, 2014, LANCET, V383, P955, DOI 10.1016/S0140-6736(13)62343-0
   Stalvey RH, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P653, DOI 10.1109/IRI.2012.6303071
   Stoica AJ, 2013, IEEE GLOB ENG EDUC C, P44, DOI 10.1109/EduCon.2013.6530085
   Subashini S, 2011, J NETW COMPUT APPL, V34, P1, DOI 10.1016/j.jnca.2010.07.006
   Wallace W., 1992, METATHEORIZING, P53
   Watters PA, 2009, CORP GOV-INT J BUS S, V9, P564, DOI 10.1108/14720700910998139
   Wolf Wolf F. M F. M, Meta-analysis: Quantitative methods for research synthesis
   Wright MA, 2001, COMPUT FRAUD SECUR, P8, DOI 10.1016/S1361-3723(01)00814-4
   Wright MA, 1998, COMPUT FRAUD SECUR, P14, DOI 10.1016/S1361-3723(98)80019-5
   Wu Chunying, 2010, Proceedings 2010 International Forum on Information Technology and Applications (IFITA 2010), P355, DOI 10.1109/IFITA.2010.101
NR 25
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12779
EP 12793
DI 10.1007/s11042-016-3503-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700028
DA 2024-07-18
ER

PT J
AU Wang, X
   Chen, LX
   Jing, JL
   Zheng, HR
AF Wang, Xin
   Chen, Liangxiu
   Jing, Jiali
   Zheng, Herong
TI Human motion capture data retrieval based on semantic thumbnail
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data; Visualized data analysis; Thumbnail; Retrieval
AB We present a method for the efficient retrieval and browsing of immense amounts of realistic 3D human body motion capture data. The proposed method organizes motion capture data based on statistical K-means (SK-means), democratic decision making, unsupervised learning, and visual key frame extraction, thus achieving intuitive retrieval by browsing thumbnails of semantic key frames. We apply three steps for the efficient retrieval of motion capture data. The first is obtaining the basic type clusters by clustering motion capture data using the novel SK-means algorithm, and after which, immediately performing character matching. The second is learning the retrieval information of users during the retrieval process and updating the successful retrieval rate of each data; the search results are then ranked on the basis of successful retrieval rate by democratic decision making to improve accuracy. The last step is generating thumbnails with semantic generalization, which is conducted by using a novel key frame extraction algorithm based on visualized data analysis. The experiment demonstrates that this method can be utilised for the efficient organization and retrieval of enormous motion capture data.
C1 [Wang, Xin; Chen, Liangxiu; Jing, Jiali; Zheng, Herong] Zhejiang Univ Technol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Wang, X (corresponding author), Zhejiang Univ Technol, Hangzhou, Zhejiang, Peoples R China.
EM xinw@zjut.edu.cn; varko.cheng@yahoo.com; muhuanggui@hotmail.com;
   hailiang@zjut.edu.cn
FU National Science Foundation of China [61303142, 60970021, 61173096];
   Natural Science Foundation of Zhejiang Province [Y1110882, Y1110688,
   R1110679]; Higher School Specialized Research Fund for the Doctoral
   Program [20113317110001]
FX This work was supported by National Science Foundation of China(NO.
   61303142, 60970021,61173096), Natural Science Foundation of Zhejiang
   Province(N0. Y1110882, Y1110688, R1110679), Higher School Specialized
   Research Fund for the Doctoral Program.(N0.20113317110001).
CR [Anonymous], 2009, Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games, I3D'09, DOI DOI 10.1145/1507149.1507181
   [Anonymous], 2012, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2011.53
   [Anonymous], 2000, P 2000 ACM WORKSH MU, DOI DOI 10.1145/357744.357942
   Bulut E., 2007, P CASA JUN, P63
   Ioannidis AI, 2014, INT C PATT RECOG, P3463, DOI 10.1109/ICPR.2014.596
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   Loy G, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P66, DOI 10.1109/HLK.2003.1240860
   Miura T, 2014, IEEJ T ELECTR ELECTR, V9, P697, DOI 10.1002/tee.22029
   Numaguchi Naoki, 2011, P 2011 ACM SIGGRAPH, P157
   Tang JKT, 2012, PATTERN RECOGN LETT, V33, P420, DOI 10.1016/j.patrec.2011.06.005
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
   Wu SY, 2009, VISUAL COMPUT, V25, P499, DOI 10.1007/s00371-009-0345-1
   Yang Tao, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P1691
   Zhang Q, 2014, INT J COMPUT INT SYS, V7, P506, DOI 10.1080/18756891.2013.859873
   Zhang Z P, 2008, CONTENT BASED MOTION
NR 17
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11723
EP 11740
DI 10.1007/s11042-015-2705-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200008
DA 2024-07-18
ER

PT J
AU Gao, CQ
   Liu, J
   Feng, Q
   Lv, J
AF Gao, Chenqiang
   Liu, Jun
   Feng, Qi
   Lv, Jing
TI People-flow counting in complex environments by combining depth and
   color information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE People-flow counting; Head detection; SVM; Multi-target tracking
ID ACCURATE
AB People-flow counting is one of the key techniques of intelligence video surveillance systems and the information of people-flow obtained from this technique is an very important evidence for many applications, such as business analysis, staff planning, security, etc. Traditionally, the color image information based methods encounter kinds of challenges, such as shadows, illumination changing, cloth color, etc., while the depth information based methods suffer from lack of texture. In this paper, we propose an effective approach of people-flow counting by combining color and depth information. First, we adopt a background subtraction technique to fast obtain the moving regions on depth images. Second, the water filling algorithm is used to effectively detect head candidates on the moving regions. Then we use the SVM to recognize the real heads from the candidates. Finally, we adopt a weighted K Nearest Neighbor based multi-target tracking method to track each confirmed head and count the people through the surveillance region. Four datasets constructed from two surveillance scenes are used to evaluate the proposed method. Experimental results show that our method outperform the state-of-the-art methods. Our method can work stably on condition of kinds of interruptions and can not only obtain high precisions, but also high recalls on four datasets.
C1 [Gao, Chenqiang] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
   [Liu, Jun; Feng, Qi; Lv, Jing] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Informat & Telecommun Engn, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Gao, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing, Peoples R China.
EM gaocq@cqupt.edu.cn
RI Luo, Jun/JPX-3855-2023; Jun, LIU/HIK-1509-2022
OI Jun, LIU/0000-0001-8122-1443
FU National Natural Science Foundation of China [61571071, 61102131];
   Natural Science Foundation of Chongqing Science and Technology
   Commission [cstc2014jcyjA40048]; Wenfeng innovation and start-up project
   of Chongqing University of Posts and Telecommunications [WF201404]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61571071, 61102131), the Natural Science Foundation of
   Chongqing Science and Technology Commission (No. cstc2014jcyjA40048),
   Wenfeng innovation and start-up project of Chongqing University of Posts
   and Telecommunications (No. WF201404).
CR [Anonymous], J MACH LEARN RES
   [Anonymous], IET DIGEST
   [Anonymous], ACTION2ACTIVITY RECO
   [Anonymous], INT J INFORM ENG
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 3 AS C INF SYST
   [Anonymous], 2013, ARXIV13075800
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Bin Li, 2014, 2014 International Conference on Smart Computing (SMARTCOMP), P136, DOI 10.1109/SMARTCOMP.2014.7043851
   Cai ZB, 2014, C IND ELECT APPL, P1841, DOI 10.1109/ICIEA.2014.6931467
   Chen T. H, 2006, 2006 IEEE C ROBOTICS, P1
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   Ching-Tang Hsieh, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P146, DOI 10.1109/ISPACS.2012.6473470
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dan BK, 2012, IEEE T CONSUM ELECTR, V58, P1013, DOI 10.1109/TCE.2012.6311350
   Evangelio RH, 2014, IEEE T INF FOREN SEC, V9, P863, DOI 10.1109/TIFS.2014.2313919
   Fu HY, 2014, MULTIMED TOOLS APPL, V73, P273, DOI 10.1007/s11042-013-1608-4
   Galcík F, 2013, LECT NOTES COMPUT SC, V8192, P330, DOI 10.1007/978-3-319-02895-8_30
   Lin YJ, 2012, INT C PATT RECOG, P2508
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Rauter M, 2013, IEEE COMPUT SOC CONF, P529, DOI 10.1109/CVPRW.2013.84
   Stahlschmidt C., 2013, Int. Workshop on Multidimensional Syst, P1
   Suresh S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1432, DOI 10.1109/ICCPCT.2014.7054915
   Tan SB, 2005, EXPERT SYST APPL, V28, P667, DOI 10.1016/j.eswa.2004.12.023
   van Oosterhout T, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P620
   Yam KY, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P863, DOI 10.1109/ICCE.2011.5722907
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Zhang XC, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P215, DOI 10.1109/AVSS.2012.82
   Zhao YL, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532439
   Zhu L, 2013, LECT NOTES COMPUT SC, V8034, P582, DOI 10.1007/978-3-642-41939-3_57
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 34
TC 22
Z9 25
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9315
EP 9331
DI 10.1007/s11042-016-3344-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500027
DA 2024-07-18
ER

PT J
AU Ouali, C
   Dumouchel, P
   Gupta, V
AF Ouali, Chahid
   Dumouchel, Pierre
   Gupta, Vishwa
TI A spectrogram-based audio fingerprinting system for content-based copy
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based copy detection; Audio fingerprints; Feature parameters;
   Spectrogram; TRECVID
AB This paper presents a novel audio fingerprinting method that is highly robust to a variety of audio distortions. It is based on an unconventional audio fingerprint generation scheme. The robustness is achieved by generating different versions of the spectrogram matrix of the audio signal by using a threshold based on the average of the spectral values to prune this matrix. We transform each version of this pruned spectrogram matrix into a 2-D binary image. Multiple versions of these 2-D images suppress noise to a varying degree. This varying degree of noise suppression improves likelihood of one of the images matching a reference image. To speed up matching, we convert each image into an n-dimensional vector, and perform a nearest neighbor search based on this n-dimensional vector. We give results with two different feature parameters and their combination. We test this method on TRECVID 2010 content-based copy detection evaluation dataset, and we validate the performance on TRECVID 2009 dataset also. Experimental results show the effectiveness of these features even when the audio is distorted. We compare the proposed method to two state-of-the-art audio copy detection systems, namely NN-based and Shazam systems. Our method by far outperforms Shazam system for all audio transformations (or distortions) in terms of detection performance, number of missed queries and localization accuracy. Compared to NN-based system, our approach reduces minimal Normalized Detection Cost Rate (min NDCR) by 23 % and improves localization accuracy by 24 %.
C1 [Ouali, Chahid] ETS, Montreal, PQ, Canada.
   [Dumouchel, Pierre] Univ Quebec, ETS, Montreal, PQ, Canada.
   [Ouali, Chahid; Gupta, Vishwa] CRIM, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   University of Quebec; Ecole de Technologie Superieure - Canada;
   University of Quebec Montreal; Universite de Montreal
RP Ouali, C (corresponding author), ETS, Montreal, PQ, Canada.; Ouali, C (corresponding author), CRIM, Montreal, PQ, Canada.
EM ouali.chahid@gmail.com; Pierre.Dumouchel@etsmtl.ca; Vishwa.Gupta@crim.ca
RI Ouali, Chahid/X-1371-2019
CR Anguera X., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P455, DOI 10.1109/ICME.2012.137
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], ISMIR
   [Anonymous], 2003, ISMIR
   [Anonymous], 2010, P ACM MM
   Ayari Mohamed, 2011, TRECVID WORKSH
   Baluja S, 2007, INT CONF ACOUST SPEE, P213
   Cano P, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P169
   Ellis Dan., 2009, ROBUST LANDMARK BASE
   Gupta VN, 2012, MULTIMED TOOLS APPL, V60, P371, DOI 10.1007/s11042-010-0608-x
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Heritier Maguelonne, 2009, P TRECVID 2009 GAITH
   Jégou H, 2012, INT CONF ACOUST SPEE, P2369, DOI 10.1109/ICASSP.2012.6288391
   Jiang Menglin, 2011, TRECVID WORKSH
   Ke Y, 2005, PROC CVPR IEEE, P597
   Lebossé J, 2007, PROCEEDINGS OF THE FOURTH IASTED INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, PATTERN RECOGNITION, AND APPLICATIONS, P269
   Lezi Wang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P961, DOI 10.1109/ICME.2012.17
   Ouali C, 2014, INT WORK CONTENT MUL
   Ouali Chahid, 2014, 15 ANN C INT SPEECH
   Saracoglu A, 2009, INT WORK CONTENT MUL, P213, DOI 10.1109/CBMI.2009.12
NR 20
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9145
EP 9165
DI 10.1007/s11042-015-3081-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500017
DA 2024-07-18
ER

PT J
AU Yan, KB
   Li, ZX
   Zhang, CL
AF Yan, Kaobi
   Li, Zhixin
   Zhang, Canlong
TI A New multi-instance multi-label learning approach for image and text
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature learning; Multi-instance multi-label learning; Probabilistic
   latent semantic analysis; Neural networks; Scene classification; Text
   categorization
ID NEURAL-NETWORKS
AB Recently, a reasonable and effectively framework to deal with the classification problem of the polysemy object with complex connotation is multi-instance multi-label (MIML) learning framework in which each example is not only represented by multiple instances but also associated with multiple labels. As we all know, feature expression plays an important role in the classification problems. It determines the accuracy of the classification results from the source. Considering its difficulties for automatically extracting the high-level features which are useful and noiseless for the MIML problem, so in this paper we present a general MIML framework by combining the feature learning technologies with machine learning technologies. Further, based on this framework, a new approach called CPNMIML which combines the probabilistic latent semantic analysis (PLSA) with the neural networks (NN) is proposed. In CPNMIML algorithm, we firstly learn the latent topic allocation of all the training examples by using the PLSA model, it is a feature learning process to get high-level features. Then we utilize the learned latent topic allocation of each training example to train the neural networks. Given a test example, we learn its latent topic distribution. Finally, we send the learned latent topic allocation of the test example to the trained neural networks to get the multiple labels of the test example. Experiments show that the proposed method has superior performance on two real-world MIML tasks.
C1 [Yan, Kaobi; Li, Zhixin; Zhang, Canlong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Li, Zhixin; Zhang, Canlong] Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Li, ZX (corresponding author), Guangxi Expt Ctr Informat Sci, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [61165009, 61262005,
   61363035, 61365009]; National Basic Research Program of China
   [2012CB326403]; Guangxi Natural Science Foundation [2012GXNSFAA053219,
   2013GXNSFAA019345, 2014GXNSFAA118368]; "Bagui Scholar" Project Special
   Funds
FX The author would like to thank the anonymous reviewers for their
   insightful reading and comments which would help much in improving the
   quality of this paper. This work is supported by the National Natural
   Science Foundation of China (Nos. 61165009, 61262005, 61363035,
   61365009), the National Basic Research Program of China (No.
   2012CB326403), the Guangxi Natural Science Foundation (Nos.
   2012GXNSFAA053219, 2013GXNSFAA019345, 2014GXNSFAA118368) and the "Bagui
   Scholar" Project Special Funds.
CR Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], 2001, P ADV NEUR INF PROC
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Csurka G, 2004, GRENOBLE WORKSH PATT, P116
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Han DF, 2008, MULTIMED TOOLS APPL, V39, P169, DOI 10.1007/s11042-008-0203-6
   Haykin S, 2004, NEURAL NETWORK THEOR, P1, DOI Bejing
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Kang F., 2006, CVPR, V2, P1719
   Maron O, 1998, LEARNING AMBIGUITY, P1
   Maron O, 1997, Advances in neural information processing systems, V10, P1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rumelhart DE, 1985, LEARNING INTERNAL RE, V1, P1
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Xie JY, 2011, J COMPUT, V6, P271, DOI 10.4304/jcp.6.2.271-279
   Xu X, 2004, LECT NOTES ARTIF INT, V3056, P272
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zhang M-L, K NEAREST NEIGHBOR B, P1
   Zhang M-L, MULTILABEL LEARNING, P1
   Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338, DOI 10.1109/TKDE.2006.162
   Zhang ML, 2009, NEUROCOMPUTING, V72, P3951, DOI 10.1016/j.neucom.2009.07.008
   Zhou Z.-H., 2002, NEURAL NETWORKS MULT, P1
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
   Zhou Z-H, MULTIPLE INSTANCE LE, P1
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
NR 27
TC 24
Z9 24
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7875
EP 7890
DI 10.1007/s11042-015-2702-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600020
DA 2024-07-18
ER

PT J
AU Afrouzian, R
   Seyedarabi, H
   Kasaei, S
AF Afrouzian, Reza
   Seyedarabi, Hadi
   Kasaei, Shohreh
TI Pose estimation of soccer players using multiple uncalibrated cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape context; 3D human pose estimation; Soccer match; Uncalibrated
   cameras; Silhouette
ID RECOGNITION
AB Fully automatic algorithm for estimating the 3D human pose from multiple uncalibrated cameras is presented. Unlike the state-of-the-art methods which use the estimated pose of previous frames to restrict the candidates of current frame, the proposed method uses the viewpoint of previous frame in order to obtain an accurate pose. This paper also introduces a method to incorporate pose estimation results of several cameras without using the calibration information. The algorithm employs a rich descriptor for matching purposes. The performance of the proposed method is evaluated on a soccer database which is captured by multiple cameras. The dataset of silhouettes, in which the related 3D skeleton poses are known, is also constructed. Experimental results show that the proposed algorithm has a high accuracy rate in estimation of 3D pose of soccer players.
C1 [Afrouzian, Reza; Seyedarabi, Hadi] Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
   [Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 University of Tabriz; Sharif University of Technology
RP Afrouzian, R (corresponding author), Univ Tabriz, Fac Elect & Comp Engn, Tabriz, Iran.
EM afrouzian@tabrizu.ac.ir; seyedarabi@tabrizu.ac.ir; skasaei@sharif.edu
RI Seyedarabi, Hadi/ABD-4603-2021; Kasaei, Shohreh/AAD-5618-2019
OI Seyedarabi, Hadi/0000-0001-6652-2467; Kasaei,
   Shohreh/0000-0002-3831-0878
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Burenius M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1634, DOI 10.1109/ICCVW.2011.6130445
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Burenius M, 2011, LECT NOTES COMPUT SC, V6688, P24, DOI 10.1007/978-3-642-21227-7_3
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Germann M., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P244, DOI 10.1109/3DIMPVT.2011.38
   Germann M, 2010, COMPUT GRAPH FORUM, V29, P585, DOI 10.1111/j.1467-8659.2009.01628.x
   Hofmann M, 2012, INT J COMPUT VISION, V96, P103, DOI 10.1007/s11263-011-0451-1
   Holte MB, 2012, IEEE J-STSP, V6, P538, DOI 10.1109/JSTSP.2012.2196975
   Howe NR, 2007, IMAGE VISION COMPUT, V25, P331, DOI 10.1016/j.imavis.2005.10.006
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Kazemi V, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.6
   Kazemi V, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.48
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moeslund ThomasB., 2011, Visual Analysis of Humans - Looking at People
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Thomas G.A., 2006, P EUROPEAN C VISUAL, P10
   Thomas G, 2007, J REAL-TIME IMAGE PR, V2, P117, DOI 10.1007/s11554-007-0041-1
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
NR 26
TC 11
Z9 11
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6809
EP 6827
DI 10.1007/s11042-015-2611-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400006
DA 2024-07-18
ER

PT J
AU Kim, SJ
   Chae, CB
   Lee, JS
AF Kim, Soo-Jin
   Chae, Chan-Byoung
   Lee, Jong-Seok
TI Subjective and objective quality assessment of videos in error-prone
   network environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subjective quality assessment; Objective quality assessment; Packet
   loss; Paired comparison; Quality of experience
ID PACKET-LOSS
AB Compression and transmission are two fundamental stages involved in wireless video communications, each of which may cause degradation of the quality of experience (QoE) of end users by producing compression artifacts and packet loss artifacts, respectively. They have their own unique perceptual influences. To provide insight for designing QoE-aware content delivery applications, this paper studies subjective and objective quality of videos containing both types of artifacts. First, subjective quality assessment is conducted, from which interaction between the two types of artifacts during quality perception is investigated. Second, using the subjective data, the performance of the state-of-the-art objective quality metrics is evaluated, with the aim of examining suitability of the existing metrics for their use in error-prone video communication applications. Finally, the developed data set is made publicly available for the community.
C1 [Kim, Soo-Jin; Chae, Chan-Byoung; Lee, Jong-Seok] Yonsei Univ, Sch Integrated Technol, 85 Songdogwahak Ro, Inchon 406840, South Korea.
C3 Yonsei University
RP Chae, CB; Lee, JS (corresponding author), Yonsei Univ, Sch Integrated Technol, 85 Songdogwahak Ro, Inchon 406840, South Korea.
EM soojin.kim@yonsei.ac.kr; cbchae@yonsei.ac.kr; jong-seok.lee@yonsei.ac.kr
RI Lee, Jong-Seok/AAF-5197-2020; Chae, Chan-Byoung/AAB-1386-2020
OI Lee, Jong-Seok/0000-0001-5255-4425; Chae,
   Chan-Byoung/0000-0001-9561-3341
FU Students' Association of the Graduate School of Yonsei University -
   Graduate School of Yonsei University; MSIP(Ministry of Science, ICT &
   Future Planning), Korea in the ICT RD Program [KCA-2012-911-01-106]; IT
   Consilience Creative Program [NIPA-2014-H0201-14-1002]
FX This work was supported in part by the Students' Association of the
   Graduate School of Yonsei University funded by the Graduate School of
   Yonsei University, in part by the MSIP(Ministry of Science, ICT & Future
   Planning), Korea in the ICT R&D Program 2013 (KCA-2012-911-01-106) and
   in part by the IT Consilience Creative Program (NIPA-2014-H0201-14-1002)
   supervised by the NIPA (National IT Industry Promotion Agency).
CR [Anonymous], 2011, IVP Subjective Quality Video Database
   [Anonymous], PROOF MEASUREMENT AS
   BAUER DF, 1972, J AM STAT ASSOC, V67, P687, DOI 10.2307/2284469
   Boulos F., 2009, P 4 INT WORKSH VID P, P1
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   De Simone F, 2010, INT CONF ACOUST SPEE, P2430, DOI 10.1109/ICASSP.2010.5496296
   De Simone F, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/190431
   ETSI, 2010, 101154 ETSI TS
   GILBERT EN, 1960, BELL SYST TECH J, V39, P1253, DOI 10.1002/j.1538-7305.1960.tb03959.x
   Glickman ME, 1999, J ROY STAT SOC C-APP, V48, P377, DOI 10.1111/1467-9876.00159
   Hong D., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P146, DOI 10.1109/PCS.2010.5702445
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Justel A, 1997, STAT PROBABIL LETT, V35, P251, DOI 10.1016/S0167-7152(97)00020-5
   Kim SJ, 2012, IEEE GLOBE WORK, P1357, DOI 10.1109/GLOCOMW.2012.6477780
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Liu T, 2009, IEEE J-STSP, V3, P280, DOI 10.1109/JSTSP.2009.2015069
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Ou YS, 2009, P AMER CONTR CONF, P1, DOI 10.1109/ACC.2009.5160491
   Park J, 2013, IEEE T IMAGE PROCESS, V22, P610, DOI 10.1109/TIP.2012.2219551
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Pitrey Y., 2011, QOE MULTIMEDIA CONTE
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tan WT, 2010, INT CONF ACOUST SPEE, P2302, DOI 10.1109/ICASSP.2010.5495975
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wickelmaier F, 2004, BEHAV RES METH INS C, V36, P29, DOI 10.3758/BF03195547
   Winkler Stefan, 2012, IEEE J SEL TOP QUANT, V6, P1
   Wu H.R., 2005, DIGITAL VIDEO IMAGE
   You JY, 2010, INT CONF ACOUST SPEE, P1002, DOI 10.1109/ICASSP.2010.5495313
NR 36
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 12
BP 6849
EP 6870
DI 10.1007/s11042-015-2613-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP8XD
UT WOS:000378780400008
DA 2024-07-18
ER

PT J
AU Zhang, SS
   Klein, DA
   Bauckhage, C
   Cremers, AB
AF Zhang, Shanshan
   Klein, Dominik A.
   Bauckhage, Christian
   Cremers, Armin B.
TI Fast moving pedestrian detection based on motion segmentation and new
   motion features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Motion segmentation; Motion self difference
   features; Histograms of oriented gradients; Support vector machines
AB The detection of moving pedestrians is of major importance for intelligent vehicles, since information about such persons and their tracks should be incorporated into reliable collision avoidance algorithms. In this paper, we propose a new approach to detect moving pedestrians aided by motion analysis. Our main contribution is to use motion information in two ways: on the one hand we localize blobs of moving objects for regions of interest (ROIs) selection by segmentation of an optical flow field in a pre-processing step, so as to significantly reduce the number of detection windows needed to be evaluated by a subsequent people classifier, resulting in a fast method suitable for real-time systems. On the other hand we designed a novel kind of features called Motion Self Difference (MSD) features as a complement to single image appearance features, e.g. Histograms of Oriented Gradients (HOG), to improve distinctness and thus classifier performance. Furthermore, we integrate our novel features in a two-layer classification scheme combining a HOG+Support Vector Machines (SVM) and a MSD+SVM detector. Experimental results on the Daimler mono moving pedestrian detection benchmark show that our approach obtains a log-average miss rate of 36 % in the FPPI range [10(-2), 10(0)], which is a clear improvement with respect to the naive HOG+SVM approach and better than several other state-of-the-art detectors. Moreover, our approach also reduces runtime per frame by an order of magnitude.
C1 [Zhang, Shanshan; Cremers, Armin B.] Univ Bonn, Inst Comp Sci 3, Romerstr 164, D-53117 Bonn, Germany.
   [Klein, Dominik A.] Fraunhofer FKIE, Fraunhoferstr 20, D-53343 Wachtberg, Germany.
   [Bauckhage, Christian] Fraunhofer IAIS, D-53757 Schloss Birlinghoven, Sankt Augustin, Germany.
C3 University of Bonn
RP Zhang, SS (corresponding author), Univ Bonn, Inst Comp Sci 3, Romerstr 164, D-53117 Bonn, Germany.
EM zhangs@iai.uni-bonn.de; kleind@iai.uni-bonn.de;
   christian.bauckhage@iais.fraunhofer.de; abc@iai.uni-bonn.de
RI Zhang, shanshan/HLP-6320-2023; Zhang, Shuo/IUO-8909-2023; Bauckhage,
   Christian/M-7872-2014; Klein, Dominik Alexander/L-9166-2017
OI Bauckhage, Christian/0000-0001-6615-2128; Klein, Dominik
   Alexander/0000-0001-5773-5700
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C INT TRNSP S
   [Anonymous], 2009, P INT C COMP VIS
   [Anonymous], P IEEE INT VEH S
   [Anonymous], P IEEE INT VEH S
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT VEH S
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], P IEEE WORKSH ROB VI
   [Anonymous], P S GERM ASS PATT RE
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT VEH S
   [Anonymous], P IEEE INT VEH S
   [Anonymous], MONOCULAR PEDESTRIAN
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], P INT C PATT REC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], 2006, P EUR C COMP VIS
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], P INT C PATT REC
   Chen K, 1997, INT J PATTERN RECOGN, V11, P417, DOI 10.1142/S0218001497000196
   Curio C, 2000, IEEE T INTELL TRANSP, V1, P155, DOI 10.1109/6979.892152
   Dalal N., CVPR, P886, DOI [DOI 10.1109/CVPR.2005.177, 10.1109/CVPR.2005.177]
   Ding JH, 2013, MULTIMED TOOLS APPL, V63, P791, DOI 10.1007/s11042-011-0896-9
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Franke U, 2002, IEEE T INTELL TRANSP, V3, P173, DOI 10.1109/TITS.2002.802934
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Leibe B, 2007, PROC CVPR IEEE, P1346
   Lim J, 2013, MULTIMED TOOLS APPL, V65, P161, DOI 10.1007/s11042-012-1156-3
   Liu Ce, 2009, THESIS
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 36
TC 13
Z9 16
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6263
EP 6282
DI 10.1007/s11042-015-2571-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700011
DA 2024-07-18
ER

PT J
AU Chen, HS
   Tsai, WJ
AF Chen, Hsuan-Sheng
   Tsai, Wen-Jiin
TI Incorporating frequent pattern analysis into multimodal HMM event
   classification for baseball videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia system; Video semantic analysis; Baseball event
   classification; Interval-based multimodal feature; Temporal sequence
   symbol coding; Co-occurrence symbol coding; HMM; Data mining; Frequent
   pattern analysis; Frequent-pattern trained HMM; Frequent-pattern
   tailored HMM; VOGUE
ID HIDDEN MARKOV MODEL; RECOGNITION; EXTRACTION
AB Data mining and frequent pattern analysis have recently become a popular way of discovering new knowledge from a data set. However, it is rarely applied to video semantic analysis. Therefore, this paper introduces two methods: frequent-pattern trained HMM and frequent-pattern tailored HMM to incorporate frequent pattern analysis into multimodal HMM event classification for baseball videos. Besides, different symbol coding methods including temporal sequence coding and co-occurrence symbol coding for multimodal HMM classification are compared. The results of our experiments on baseball video event classification demonstrate that integration of frequent pattern analysis could help to improve event classification performances.
C1 [Chen, Hsuan-Sheng; Tsai, Wen-Jiin] Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, HS (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM xschen@cs.nctu.edu.tw; wjtsai@cs.nctu.edu.tw
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], P 8 ACM INT WORKSH M
   Assari SM, 2014, P IEEE INT C COMP VI
   Bae TM, 2005, LECT NOTES COMPUT SC, V3568, P113
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P313, DOI 10.1007/s11042-009-0342-4
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Bouqata B, 2006, THESIS RENSSELAER PO
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Brendel W., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3329, DOI 10.1109/CVPR.2011.5995491
   Chai W., 2001, P INT C ART INT
   Chang P, 2002, IEEE IMAGE PROC, P609
   Chen HS, 2014, J VIS COMMUN IMAGE R, V25, P285, DOI 10.1016/j.jvcir.2013.12.001
   Chen HT, 2012, J VIS COMMUN IMAGE R, V23, P767, DOI 10.1016/j.jvcir.2012.03.006
   Chen M, 2006, IEEE SIGNAL PROC MAG, V23, P38, DOI 10.1109/MSP.2006.1621447
   Chen M, 2007, I C DATA ENGIN WORKS, P137, DOI 10.1109/ICDEW.2007.4400983
   Dao MS, 2010, MULTIMED TOOLS APPL, V50, P227, DOI 10.1007/s11042-009-0379-4
   Du YT, 2013, MULTIMED TOOLS APPL, V66, P545, DOI 10.1007/s11042-012-1213-y
   Fleischman M., 2007, Proceedings of the International Workshop on Workshop on Multimedia Information Retrieval, MIR'07, P87
   FLEISCHMAN M, 2007, P 15 INT C MULT, P333
   Gong YH, 2004, COMPUT VIS IMAGE UND, V96, P181, DOI 10.1016/j.cviu.2004.02.002
   Hasan T, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-173
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Karaman S, 2014, MULTIMED TOOLS APPL, V69, P743, DOI 10.1007/s11042-012-1117-x
   Lee H, 2015, P IEEE WINT C APPL C
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mouret M, 2009, INT WORK CONTENT MUL, P169, DOI 10.1109/CBMI.2009.22
   Oskouie P, 2014, ARTIF INTELL REV, V42, P173, DOI 10.1007/s10462-012-9332-4
   Qian XM, 2012, MULTIMED TOOLS APPL, V60, P233, DOI 10.1007/s11042-011-0817-y
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rehman A, 2014, ARTIF INTELL REV, V41, P451, DOI 10.1007/s10462-012-9319-1
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Snoek CGM, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA21
   Talha AM, 2014, IMAGE VISION COMPUT, V32, P1102, DOI 10.1016/j.imavis.2014.08.010
   Wang XF, 2012, MULTIMED TOOLS APPL, V57, P131, DOI 10.1007/s11042-010-0722-9
   Wang ZK, 2014, MULTIMED TOOLS APPL, V73, P519, DOI 10.1007/s11042-013-1619-1
   Wu SY, 2007, IEEE T KNOWL DATA EN, V19, P742, DOI [10.1109/TKDE.2007.190613, 10.1109/TKDE.2007.1032.]
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Yan WQ, 2011, MULTIMED TOOLS APPL, V55, P443, DOI 10.1007/s11042-010-0560-9
   Zaki MJ, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644878
   Zhan Y, 2014, MULTIMEDIA TOOLS APP
   Zhang YM, 2013, IEEE T PATTERN ANAL, V35, P2468, DOI 10.1109/TPAMI.2013.33
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 46
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4913
EP 4932
DI 10.1007/s11042-015-2447-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700005
DA 2024-07-18
ER

PT J
AU Fang, C
   Wang, YJ
AF Fang, Can
   Wang, Yujun
TI Light source imitation by using galvanometer scanner and spot light
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Projector; Display; Galvanometer; Photometry; Collimating optics
ID EMITTING-DIODES
AB In this paper, we present a novel display assembly which is specially designed for the immersive system to enhance the sense of immerse. In particular, we aim at improving the display when a bright object, such as a light source, appears in the field of view. In the proposed assembly, we adopt a spot light to generate a high intensity beam. When the beam hits the screen, a hot spot is formed to imitate the light source displayed on screen. A galvanometer is employed to deflect the beam so we can track the moving of the light source displayed. Based on the basic laws in photometry, we deduct a series of formulas which could calculate the intensity of the beam and to estimate the gain in the contrast and dynamic range.
C1 [Fang, Can; Wang, Yujun] Southwest Univ, Sch Comp & Informat Sci, Chongqing, Peoples R China.
C3 Southwest University - China
RP Fang, C (corresponding author), Southwest Univ, Sch Comp & Informat Sci, Chongqing, Peoples R China.
EM canfang@swu.edu.cn; wangyjun@swu.edu.cn
FU Fundamental Research Funds for the Central Universities [SWU112060]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities SWU112060.
CR Angel E., 2003, INTERACTIVE COMPUTER
   Bass M., 2010, Handbook of optics
   BROSENS P, 1976, OPT ENG, V15, P95, DOI 10.1117/12.7971926
   Byerly KA, 1988, U.S. Patent, Patent No. [4, 762,994, 4762994]
   Duma VF, 2010, OPT ENG, V49, DOI 10.1117/1.3497570
   Jackson FM, 1993, I MATH APPL B UK, V29, P172
   Kendall M. G., 1961, GRIFFINS STAT MONOGR, V8
   Kwak Y, 2000, DISPLAYS, V21, P179, DOI 10.1016/S0141-9382(00)00049-4
   Lim SR, 2011, ENVIRON SCI TECHNOL, V45, P320, DOI 10.1021/es101052q
   McCluney WR, 2014, ARTECH H APPL PHOTON, P1
   NAKAMURA S, 1994, APPL PHYS LETT, V64, P1687, DOI 10.1063/1.111832
NR 11
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5147
EP 5160
DI 10.1007/s11042-015-2942-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700019
DA 2024-07-18
ER

PT J
AU Ceglie, C
   Piro, G
   Striccoli, D
   Camarda, P
AF Ceglie, Cristiano
   Piro, Giuseppe
   Striccoli, Domenico
   Camarda, Pietro
TI <i>3DStreaming</i>: an open-source flexible framework for real-time 3D
   streaming services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D live streaming; Stereoscopy; Open source tool
ID VIDEO; QUALITY
AB The progress of three-dimensional 3D technologies, together with the wide diffusion of both Internet and broadband technologies, is paving the way to emerging live streaming services which have been conceived for delivering 3D video contents in real-time fashion to end users. Nowadays, the only available tools supporting stereoscopic 3D video services cannot be freely downloaded and require the adoption of owner stereoscopic players. Motivated by the lack of an effective solution, we developed a freeware and open source 3D live streaming framework, namely 3DStreaming. It provides stereoscopic 3D live streaming services over the Internet. In particular, it realizes a complete server implementation, offering the support for any transmission protocol and encoding scheme, as well as the full compatibility with any network architecture (i.e., LAN, MAN, Internet, and so on). At the same time, it allows users to use the preferable stereoscopic player and to render the video through any technique available for the chosen player. The overall performances of the proposed tool have been presented by testing its behavior in several network configurations (i.e., by varying network topology, coding technique, 3D representation format, and average encoding rate). All the measured metrics, which include the number of RTP segments that are transmitted and received, the frame loss ratio, and the PSNR, fully demonstrate the right behavior of the implemented tool in all the considered scenarios. We believe that, thanks to its high flexibility, this tool can be exploited by researchers working on stereoscopic-3D related issues to design, test, and evaluate novel and innovative algorithms, protocols, and network architectures.
C1 [Ceglie, Cristiano; Piro, Giuseppe; Striccoli, Domenico; Camarda, Pietro] Politecn Bari DEI, Via Orabona 4, Bari, Italy.
C3 Politecnico di Bari
RP Piro, G (corresponding author), Politecn Bari DEI, Via Orabona 4, Bari, Italy.
EM cristiano.ceglie@poliba.it; giuseppe.piro@poliba.it;
   domenico.striccoli@poliba.it; pietro.camarda@poliba.it
OI Piro, Giuseppe/0000-0003-3783-5565
FU PON projects - Italian MIUR [DSS-01-02499, EURO6-01-02238]; European
   Union (European Social Fund)
FX This work was supported by the PON projects (RES NOVAE, DSS-01-02499 and
   EURO6-01-02238) funded by the Italian MIUR and by the European Union
   (European Social Fund).
CR [Anonymous], 1994, 1003120031INT IEEE
   [Anonymous], P STER DISPL APPL 19
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bourge A, 2006, COMMITTEE DRAFT ISO
   Ceglie C, 2014, WIREL NETW, V20, P2255, DOI 10.1007/s11276-014-0738-6
   Gürler CG, 2011, P IEEE, V99, P694, DOI 10.1109/JPROC.2010.2100010
   Kohler E, 2006, ACM SIGCOMM COMP COM, V36, P27, DOI 10.1145/1151659.1159918
   Kunic S, 2011, ELMAR PROC, P127
   Marín R, 2005, IEEE T IND ELECTRON, V52, P1506, DOI 10.1109/TIE.2005.858733
   Matsuyama T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P234, DOI 10.1109/TDPVT.2002.1024068
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Molineros J, 2001, PROCEEDINGS OF THE 2001 IEEE INTERNATIONAL SYMPOSIUM ON ASSEMBLY AND TASK PLANNING (ISATP2001), P362, DOI 10.1109/ISATP.2001.929052
   Pettersen T, 2003, P ISMAR03, P7
   Piro G, 2011, IEEE T MULTIMEDIA, V13, P1052, DOI 10.1109/TMM.2011.2152381
   Schulzrinne H, 2003, RTP TRANSPORT PROTOC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seeling P, 2012, IEEE COMMUN SURV TUT, V14, P1142, DOI 10.1109/SURV.2011.082911.00067
   Smolic A, 2005, P IEEE, V93, P98, DOI 10.1109/JPROC.2004.839608
   Stelmach L, 2000, IEEE T CIRC SYST VID, V10, P188, DOI 10.1109/76.825717
   Stolberg HJ, 2001, MPEG 4, P33, DOI [10.1109/MPEG.2001.996441, DOI 10.1109/MPEG.2001.996441]
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wolfe J. M., 2006, Sensation & perception
   Yamanoue H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1701, DOI 10.1109/ICME.2006.262877
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   Yun Tang, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P135, DOI 10.1109/CSIE.2009.354
NR 27
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4411
EP 4440
DI 10.1007/s11042-015-2482-z
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700012
DA 2024-07-18
ER

PT J
AU Lucena, M
   Martínez-Carrillo, AL
   Fuertes, JM
   Carrascosa, F
   Ruiz, A
AF Lucena, M.
   Martinez-Carrillo, A. L.
   Fuertes, J. M.
   Carrascosa, F.
   Ruiz, A.
TI Decision support system for classifying archaeological pottery profiles
   based on Mathematical Morphology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pottery profiles; Typologies; Shape matching; Mathematical; Morphology
ID CLASSIFICATION; MORPHOMETRY
AB We present a decision support system to help archaeologists in classifying wheel-made pottery pieces by its profile. A novel shape characterization method, using Mathematical Morphology, is introduced for this purpose. Each profile is represented as a vector, obtained by sampling the so called morphological curves (erosion, dilation, opening and closing), and Euclidean Distance is used as a similarity measure. We show results of our method applied to a profile database of Iberian Pottery from the upper valley of Guadalquivir River (Spain).
C1 [Lucena, M.; Fuertes, J. M.; Carrascosa, F.] Univ Jaen, Dept Comp Sci, Jaen, Spain.
   [Martinez-Carrillo, A. L.; Ruiz, A.] Univ Jaen, Res Univ, Inst Iberian Archaeol, Jaen, Spain.
C3 Universidad de Jaen; Universidad de Jaen
RP Lucena, M (corresponding author), Univ Jaen, Dept Comp Sci, Jaen, Spain.
EM mlucena@ujaen.es; caai@ujaen.es
RI ANIKUZHIYIL, ANISH/Y-8609-2018; Lucena, Manuel/I-6467-2018; Fuertes
   Garcia, Jose Manuel/I-8008-2018
OI Lucena, Manuel/0000-0002-5546-3745; Fuertes Garcia, Jose
   Manuel/0000-0001-6624-4102
FU Excellent Projects Program of CICE (regional government); European Union
   ERDF funds [P07-TIC-02773]; Computer Graphics and Geomatics Research
   Group of the University of Jaen [TIC-144]; Andalusian Economics,
   Innovation, Science and Employment Council [TIC-7278]
FX This work has been supported by the Excellent Projects Program of CICE
   (regional government), the European Union ERDF funds under research
   projects P07-TIC-02773, and the Computer Graphics and Geomatics Research
   Group (TIC-144) of the University of Jaen, and the Andalusian Economics,
   Innovation, Science and Employment Council under project TIC-7278.
CR [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 1996, The Statistical Theory of Shape
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Brande S, 1996, NATO ADV SCI INST SE, V284, P423
   Buchanan B, 2006, J ARCHAEOL SCI, V33, P185, DOI 10.1016/j.jas.2005.07.008
   Buchanan B, 2007, J ANTHROPOL ARCHAEOL, V26, P366, DOI 10.1016/j.jaa.2007.02.005
   Buxeda i Garrigos J, 2011, P 4 INT WORKSH COMP, P1
   Chapa T, 1997, NECROPOLIS IBERICA C
   Forel B, 2009, J ARCHAEOL SCI, V36, P721, DOI 10.1016/j.jas.2008.10.021
   Fuertes J., 2001, 12 SCAND C IM AN SCI, V1, P646
   Fuertes JM, 2003, PROCEEDINGS EC-VIP-MC 2003, VOLS 1 AND 2, P201
   Gilboa A, 2004, J ARCHAEOL SCI, V31, P681, DOI 10.1016/j.jas.2003.10.013
   Halir R, 1997, P CZECH PATT REC WOR, P126
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Kampel M, 2003, J VISUAL COMP ANIMAT, V14, P111, DOI 10.1002/vis.310
   Karasik A, 2011, J ARCHAEOL SCI, V38, P2644, DOI 10.1016/j.jas.2011.05.023
   Lettner M, 2006, P EL IM VIS ART DIG, P83
   Lycett SJ, 2009, SOURCEBOOK OF PALEOLITHIC TRANSITIONS, P79, DOI 10.1007/978-0-387-76487-0_5
   Maaten L, 2009, BAR INT SERIES, V2079, P356
   Matheron G., 1975, Random sets and integral geometry
   Mom V, 2006, ADV DATA ANAL
   Monna F, 2013, J ARCHAEOL SCI, V40, P507, DOI 10.1016/j.jas.2012.06.029
   Nautiyal V., 2006, COMPUTER APPL QUANTI
   Rice PrudenceM., 1987, POTTERY ANAL
   Ruiz A., 1983, Cortes A y F. Cuadernos de Prehistoria de la Universidad de Granada, V8, P251
   Ruiz Rodriguez A, 1984, CUAD PREHIST U GRANA, V9, P195
   Saragusti I, 2005, J ARCHAEOL SCI, V32, P841, DOI 10.1016/j.jas.2005.01.002
   Shennan S., 1975, SCI ARCHAEOL, V15, P17
   Sieso J Pereira, 1989, TRABAJOS PREHIST, V46, P149, DOI DOI 10.3989/TP.1989.V46.I0.592
   Slice DE, 2005, DEV PRIMATOL-PROG PR, P1, DOI 10.1007/0-387-27614-9_1
   Smith N.G., 2012, Journal of Archaeological Method and Theory, P1
   Zelditch ML, 2012, GEOMETRIC MORPHOMETRICS FOR BIOLOGISTS: A PRIMER, 2ND EDITION, P1
NR 32
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3677
EP 3691
DI 10.1007/s11042-014-2063-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200006
DA 2024-07-18
ER

PT J
AU Zhang, YY
   Yi, Q
   Lv, XD
   Ping, Z
AF Zhang Ying-Ying
   Yi, Qin
   Lv Xiao-Dong
   Ping, Zhang
TI Saliency detection via PCA of image patches and ICA-R
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Principal component analysis; Independent component
   analysis with reference
ID INDEPENDENT COMPONENT ANALYSIS; OBJECT DETECTION; INTEGRATION
AB A variety of computational models based on different views for visual saliency detection have emerged in computer vision. In this paper, we combine RGB space and Lab space to represent original features of each image patch in the vector form, and employ principal component analysis (PCA) to select effective features. The saliency cue is obtained by integrating the contrast and distribution of image patches in the reduced dimensional space and supposed to be the reference for saliency foreground. Then we regard saliency map computation as a source signal separation problem in the framework of independent component analysis with reference (ICA-R). Our approach utilizes the common ICA-R to separate the saliency object from the background of the input image with the saliency cue. The main benefits consist of two aspects. On one hand, the combination of Lab and RGB color spaces in both the saliency reference computation and saliency result computation is able to produce better saliency maps than those using only one color space. On the other hand, the input image is assumed to be a mixture of saliency foreground and background, which enables the saliency detection can be embedded into the source separation problem. This source separation problem is solved by ICA-R with the reference for saliency foreground. Extensive experiments on public saliency benchmarks demonstrate that compared with the state-of-the-art algorithms, the proposed method is more effective.
C1 [Zhang Ying-Ying; Yi, Qin; Lv Xiao-Dong; Ping, Zhang] Nanyang Normal Univ, Coll Phys & Elect Engn, Nanyang 473061, Peoples R China.
C3 Nanyang Normal College
RP Zhang, YY (corresponding author), Nanyang Normal Univ, Coll Phys & Elect Engn, Nanyang 473061, Peoples R China.
EM zyyzs226@126.com
RI Wang, zijun/JNS-5435-2023
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   Back AD, 1997, INT J NEURAL SYST, V8, P473, DOI 10.1142/S0129065797000458
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348
   Feng Xin, 2011, Acta Automatica Sinica, V37, P1322, DOI 10.3724/SP.J.1004.2011.01322
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goldstein JS, 1999, INT CONF ACOUST SPEE, P1357, DOI 10.1109/ICASSP.1999.756232
   Gupta R, 2011, LECT NOTES COMPUT SC, V6744, P458, DOI 10.1007/978-3-642-21786-9_74
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hu Zheng-Ping, 2011, Acta Automatica Sinica, V37, P1279, DOI 10.3724/SP.J.1004.2011.01279
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Hyvarinen A, 1998, ADV NEUR IN, V10, P273
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Lin QH, 2004, LECT NOTES COMPUT SC, V3173, P755
   Lin QH, 2007, INFORM SCIENCES, V177, P1265, DOI 10.1016/j.ins.2006.09.011
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rajapakse JC, 1998, HUM BRAIN MAPP, V6, P283, DOI 10.1002/(SICI)1097-0193(1998)6:4<283::AID-HBM7>3.0.CO;2-#
   Sun J, 2012, IEEE IMAGE PROC, P1085, DOI 10.1109/ICIP.2012.6467052
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wei L, 2006, NEUROCOMPUTING, V69, P2244, DOI 10.1016/j.neucom.2005.06.021
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 41
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4527
EP 4542
DI 10.1007/s11042-015-2489-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700017
DA 2024-07-18
ER

PT J
AU Liang, LQ
   Li, D
   Fu, X
   Zhang, WJ
AF Liang, Lie-Quan
   Li, Di
   Fu, Xin
   Zhang, Wu-Jie
TI Touch screen defect inspection based on sparse representation in low
   resolution images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Touch screen; Defect inspection; Redundant dictionary; Sparse
   representation
ID EXPLICIT CONSTRUCTION
AB Defect inspection is one of the most important processes for the touch screen manufacturing. Because the affections of uneven illumination, camera resolution, defect types and the textural background of the touch screen images, the defect inspection problem of touch screen becomes complex and the accuracy of inspection rate is effected significantly. In this paper, the features from defect-free touch screen images are collected to generate an atom pool. Since the normal feature pool is redundant, an optimal subset with small size is selected from the atom pool as training dictionary. According to the l (1) minimization, the coefficients for sparse linear representation of a testing image under the redundancy dictionary can be obtained. Thus, the defect inspection problem can be transferred to the problem that if an image can be sparsely represented under the redundancy dictionary or not. Sparsity ratio of the sparse representation coefficients is proposed as a measurement to determinate whether the testing image is defective or not. Experimental results show that under various illumination conditions, the proposed approach can efficiently and quickly detect the touch screen defects for low resolution images and different defect types.
C1 [Liang, Lie-Quan] Guangdong Univ Finance & Econ, Guangdong Prov Key Lab Elect Commerce Market Appl, Guangzhou 510320, Guangdong, Peoples R China.
   [Liang, Lie-Quan; Li, Di; Zhang, Wu-Jie] S China Univ Technol, Sch Mech & Automot Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Fu, Xin] Univ Houston, Dept Elect & Comp Engn, Houston, TX 77204 USA.
C3 Guangdong University of Finance & Economics; South China University of
   Technology; University of Houston System; University of Houston
RP Liang, LQ (corresponding author), Guangdong Univ Finance & Econ, Guangdong Prov Key Lab Elect Commerce Market Appl, Guangzhou 510320, Guangdong, Peoples R China.
EM lianglq@gdufe.edu.cn
CR [Anonymous], 2011, IM GRAPH ICIG 2011 6
   Cen YG, 2013, J COMPUT APPL MATH, V244, P49, DOI 10.1016/j.cam.2012.11.018
   Cen YG, 2009, APPL MATH COMPUT, V213, P235, DOI 10.1016/j.amc.2009.03.011
   Cen YG, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4855-0
   Cen YG, 2013, J APPL MATH, DOI 10.1155/2013/864132
   [岑翼刚 Cen Yigang], 2011, [电子与信息学报, Journal of Electronics & Information Technology], V33, P326, DOI 10.3724/SP.J.1146.2010.00305
   Chen XH, 2013, THESIS S CHINA U TEC
   Chiou YC, 2009, MEASUREMENT, V42, P989, DOI 10.1016/j.measurement.2009.02.006
   Chiu WY, 2013, IMAGING SCI J, V61, P252, DOI 10.1179/1743131X11Y.0000000016
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Li D, 2014, INT J ADV MANUF TECH, V73, P1605, DOI 10.1007/s00170-014-5871-y
   Liu HG, 2011, INT J ADV MANUF TECH, V56, P1079, DOI 10.1007/s00170-011-3248-z
   Lu CJ, 2005, INT J ADV MANUF TECH, V25, P53, DOI 10.1007/s00170-003-1832-6
   Peng XQ, 2008, INT J ADV MANUF TECH, V39, P1180, DOI 10.1007/s00170-007-1302-7
   Shang HC, 2007, INT J ADV MANUF TECH, V33, P756, DOI 10.1007/s00170-006-0505-7
   Tsai DM, 2002, INT J ADV MANUF TECH, V20, P420, DOI 10.1007/s001700200172
   Tsai DM, 2013, ROBOT CIM-INT MANUF, V29, P312, DOI 10.1016/j.rcim.2013.01.009
   Tsai DM, 2013, IEEE T IND INFORM, V9, P122, DOI 10.1109/TII.2012.2209663
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
NR 20
TC 28
Z9 32
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2655
EP 2666
DI 10.1007/s11042-015-2559-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000016
DA 2024-07-18
ER

PT J
AU Yu, L
   Ong, SK
   Nee, AYC
AF Yu, L.
   Ong, S. K.
   Nee, A. Y. C.
TI A tracking solution for mobile augmented reality based on sensor-aided
   marker-less tracking and panoramic mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; Feature matching; Tracking and registration;
   Panoramic mapping
AB This paper proposes a tracking system for outdoor augmented reality (AR) on handheld devices based on an integration of vision tracking and on-device sensor measurement. To deal with the unpredictable and complex visual information in an outdoor environment, two tracking schemes are proposed for both near-field and far-field tracking scenarios. A sensor-aided binary descriptor is combined with an intensity-based tracking algorithm to deliver a 3D tracking system for fronto-parallel planar surfaces in near-field tracking. In far-field tracking, a sensor-guided panoramic tracking and mapping approach is proposed which allows a creation of the panorama of distant scenes on the fly with camera rotation motion to be tracked at the same time. This implementation allows near real-time creation of panoramic maps on-device; therefore, the users are able to tag information on the training target instantly.
C1 [Yu, L.; Ong, S. K.; Nee, A. Y. C.] Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
C3 National University of Singapore
RP Ong, SK (corresponding author), Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore 117576, Singapore.
EM mpeongsk@nus.edu.sg
RI Ong, SK/AAP-2918-2021
OI Ong, SK/0000-0002-9569-3350; Nee, Andrew/0000-0002-1029-9988
CR Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Benhimane S, 2007, INT J ROBOT RES, V26, P661, DOI 10.1177/0278364907080252
   Bleser G, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P137
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Feiner S, 1997, FIRST INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P74, DOI 10.1109/ISWC.1997.629922
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gammeter S., 2010, CVPR Workshops, P1
   Hwangbo M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1909, DOI 10.1109/IROS.2009.5354093
   Kurz D, 2011, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2011.5995339
   Lin L, 2009, MULTIMED TOOLS APPL, V41, P235, DOI 10.1007/s11042-008-0227-y
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schall G, 2009, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2009.5336489
   Silveira G, 2007, P IEEE COMPUTER VISI, P1
   Ventura J, 2012, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2012.6402531
   Wagner D, 2010, P IEEE VIRT REAL ANN, P211, DOI 10.1109/VR.2010.5444786
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Wonwoo Lee, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P57, DOI 10.1109/ISMAR.2010.5643551
NR 21
TC 17
Z9 20
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3199
EP 3220
DI 10.1007/s11042-014-2430-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600013
DA 2024-07-18
ER

PT J
AU Cao, J
   Zhang, YD
   Ji, RR
   Li, X
AF Cao, Juan
   Zhang, Yongdong
   Ji, Rongrong
   Li, Xin
TI On application-unbiased benchmarking of web videos from a social network
   perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web video benchmark; Social network; Sampling bias; MCG-WEBV 2.0
AB Along with the emerging focus of community-contributed videos on the web, there is a strong demand of a well-designed web video benchmark for the research of social network based video content analysis. The existing video datasets are challenged in two aspects: (1) as the data resource, most of them are narrowed for a specific task, either focusing on one content analysis task with limited scales, or focusing on the pure social network analysis without downloading video content. (2) as the evaluation platform, few of them pay attention to the potential bias introduced by the sampling criteria, therefore cannot fairly measure the task performance. In this paper, we release a large-scale web video benchmark named MCG-WEBV 2.0, which crawls 248,887 YouTube videos and their corresponding social network structure with 123,063 video contributors. MCG-WEBV 2.0 can be used to explore the fusion between content and network for several web video analysis tasks. Based on MCG-WEBV 2.0, we further explore the sampling bias lies in web video benchmark construction. While sampling a completely unbiased video benchmark from million-scale collection is unpractical, we propose a task-dependent measurement of such bias, which minimizes the correlation between the potential video sampling bias and the corresponding content analysis task, if such bias is unavoidable. Following this principle, we have shown several exemplar application scenarios in MCG-WEBV 2.0.
C1 [Cao, Juan; Zhang, Yongdong; Ji, Rongrong] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing, Peoples R China.
   [Li, Xin] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Tsinghua University
RP Zhang, YD (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing, Peoples R China.
EM caojuan@ict.ac.cn; zhyd@ict.ac.cn; rrji@xmu.edu.cn; lx_sy@126.com
FU National High Technology Research and Development Program of China
   [2014AA015202]; National Nature Science Foundation of China [61172153,
   61100087]; National Key Technology Research and Development Program of
   China [2012BAH39B02]; Beijing New Star Project on Science Technology
   [2007B071]
FX This work is supported by the National High Technology Research and
   Development Program of China (2014AA015202), National Nature Science
   Foundation of China (61172153,61100087), National Key Technology
   Research and Development Program of China (2012BAH39B02). the Beijing
   New Star Project on Science & Technology (2007B071).
CR [Anonymous], 2011, ACM INT C MULT RETR
   [Anonymous], 2010, UCF 50 HUMAN ACTION
   Benevenuto F, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596994
   Borghol Y, 2011, IFIP PERFORMANCE
   Cao J, IEEE T CIRCUITS SYST
   Cao J, 2009, TECHNICAL REPORT
   Cha M, 2007, ACM SIGCOMM C INT ME
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Ding Y, 2011, ACM SIGCOMM C INT ME
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22
   Gill P, 2007, ACM SIGCOMM C INT ME
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Huang C, 2007, ACM SIGCOMM COMP COM, V37, P133, DOI 10.1145/1282427.1282396
   Laptev I, 2008, IEEE INT C COMP VIS
   Li HJ, 2014, MULTIMEDIA SYSTEMS
   Liu L., 2008, INT C WORLD WID WEB
   Pang L, 2011, ACM INT C MULT
   Sharma AS, 2009, CLASSIFICATION MULTI
   Smeaton AF, 2006, ACM INT WORKSH MULT
   Song YC, IEEE T MULTIMEDIA
   Song YC, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2533989
   Tang JH, 2009, ACM INT C MULT
   Torralba A, 2011, IEEE INT C COMP VIS
   Wu X, 2007, ACM INT C MULT
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
NR 27
TC 2
Z9 3
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1543
EP 1556
DI 10.1007/s11042-014-2245-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600012
DA 2024-07-18
ER

PT J
AU Huang, W
   Zhang, P
   Shen, MM
AF Huang, Wei
   Zhang, Peng
   Shen, Minmin
TI A novel dementia diagnosis strategy on arterial spin labeling magnetic
   resonance images via pixel-wise partial volume correction and ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Magnetic resonance image; Alzheimer's disease; Ranking
ID POSITRON-EMISSION-TOMOGRAPHY; ALZHEIMERS-DISEASE; INITIAL-EXPERIENCE;
   MRI; BRAIN; PATTERNS
AB Arterial Spin Labeling (ASL) is an emerging magnetic resonance imaging technique attracting increasing attention in dementia diagnosis only beginning from recent years. ASL is capable to provide direct and quantitative measurement of cerebral blood flow (CBF) of scanned patients, so that brain atrophy of demented patients could be revealed by measured low CBF within certain brain regions through ASL. However, partial volume effects (PVE) mainly caused by signal cross-contamination due to pixel heterogeneity and limited spatial resolution of ASL, often prevents CBF from being precisely measured. Inaccurate CBF is prone to mislead and even deteriorate dementia disease diagnosis results, thereafter. In this paper, a novel dementia disease diagnosis strategy based on ASL is proposed for the first time. The diagnosis strategy is composed of two steps: 1) to conduct pixel-wise PVE correction on original ASL images and 2) to predict dementia disease severities based on corrected ASL images via ranking. Extensive experiments and comprehensive statistical analysis are carried out to demonstrate the superiority of the new strategy with comparison to several existing ones. Promising results are reported from the statistical point of view.
C1 [Huang, Wei] Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.
   [Zhang, Peng] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Shen, Minmin] Univ Konstanz, INCIDE Ctr, Constance, Germany.
   [Shen, Minmin] S China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.
C3 Nanchang University; Northwestern Polytechnical University; University
   of Konstanz; South China University of Technology
RP Huang, W (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang, Peoples R China.; Zhang, P (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.; Shen, MM (corresponding author), Univ Konstanz, INCIDE Ctr, Constance, Germany.; Shen, MM (corresponding author), S China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM huangwei@ncu.edu.cn; zh0036ng@nwpu.edu.cn; minmin.shen@uni-konstanz.de
RI zhang, yueqi/JXM-4287-2024; Zhang, Penghui/HGB-7353-2022
OI Zhang, Penghui/0000-0002-9518-7079
FU NWPU [3102014JSJ0014];  [61403182];  [61363046];  [61301194]; 
   [61302121];  [20142BBE50023];  [20142BAB217033]
FX The authors would like to acknowledge national grants 61403182,
   61363046, 61301194 and 61302121 approved by the National Natural Science
   Foundation of China, grants 20142BBE50023 and 20142BAB217033 approved by
   the Jiangxi Provincial Department of Science and Technology, as well as
   the NWPU grant 3102014JSJ0014 for supporting this study.
CR Asllani I, 2008, MAGN RESON MED, V60, P1362, DOI 10.1002/mrm.21670
   BRANTZAWADZKI M, 1992, RADIOLOGY, V182, P769, DOI 10.1148/radiology.182.3.1535892
   Brookmeyer R, 2007, ALZHEIMERS DEMENT, V3, P186, DOI 10.1016/j.jalz.2007.04.381
   Chen Y, 2011, NEUROLOGY, V77, P1977, DOI 10.1212/WNL.0b013e31823a0ef7
   Du Y, 2005, IEEE T MED IMAGING, V24, P969, DOI 10.1109/TMI.2005.850547
   Erlandsson K, 2012, PHYS MED BIOL, V57, pR119, DOI 10.1088/0031-9155/57/21/R119
   FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6
   Galton CJ, 2001, NEUROLOGY, V57, P216, DOI 10.1212/WNL.57.2.216
   Golay Xavier, 2004, Top Magn Reson Imaging, V15, P10, DOI 10.1097/00002142-200402000-00003
   Gold G, 2005, STROKE, V36, P1184, DOI 10.1161/01.STR.0000166052.89772.b5
   Goldstein T, 2008, 0829121 UCLA CAM
   Gunn RN, 2002, J CEREBR BLOOD F MET, V22, P1425, DOI 10.1097/01.wcb.0000045042.03034.42
   Jarvelin K., 2000, SIGIR Forum, V34, P41
   Joachims T., SVM LIGHT IMPLEMENTA
   Johnson NA, 2005, RADIOLOGY, V234, P851, DOI 10.1148/radiol.2343040197
   Keerthi SS, 2002, IEEE T NEURAL NETWOR, V13, P1225, DOI 10.1109/TNN.2002.1031955
   Laakso MP, 1996, NEUROLOGY, V46, P678, DOI 10.1212/WNL.46.3.678
   Liu MH, 2012, NEUROIMAGE, V60, P1106, DOI 10.1016/j.neuroimage.2012.01.055
   Mahendra B, 1987, DEMENTIA, V1, P189
   Malpass K., 2012, NATURE REV NEUROLOGY, V8, P847
   Mioshi E, 2006, INT J GERIATR PSYCH, V21, P1078, DOI 10.1002/gps.1610
   Murphy KJ, 1996, AM J ROENTGENOL, V167, P847, DOI 10.2214/ajr.167.4.8819369
   Musiek ES, 2012, ALZHEIMERS DEMENT, V8, P51, DOI 10.1016/j.jalz.2011.06.003
   Parkes LM, 2004, MAGN RESON MED, V51, P736, DOI 10.1002/mrm.20023
   Rice J, 2007, MATH STAT DATA DNALY
   un, World population prospects
   Wang Z, 2013, NEUROIMAGE-CLIN, V2, P630, DOI 10.1016/j.nicl.2013.04.014
   Wee CY, 2013, HUM BRAIN MAPP, V34, P3411, DOI 10.1002/hbm.22156
   who, TOP 10 CAUS DEATH, DOI DOI 11/44679/INDEX.HTM
   Wright M, 2004, B AM MATH SOC, V42, P1
   Zhou LP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021935
NR 31
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2067
EP 2090
DI 10.1007/s11042-014-2395-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000016
DA 2024-07-18
ER

PT J
AU Chandra, A
   Chattopadhyay, S
AF Chandra, Abhijit
   Chattopadhyay, Sudipta
TI A new strategy of image denoising using multiplier-less FIR filter
   designed with the aid of differential evolution algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential Evolution (DE) algorithm; Image enhancement factor (IEF);
   Image quality index (IQI); Gaussian noise; Multiplier-less low-pass
   filter; Peak signal-to-noise ratio (PSNR); Structural similarity index
   measure (SSIM)
ID 2-D; OPTIMIZATION
AB Due to the rapid development of one-dimensional signal processing in last few decades, it has spread out its wings in the field of multi-dimensional signal processing too. This has mainly been dominated by the proposition and implementation of robust algorithms which have focused on efficient storage and reliable transmission of digital images of various kinds. During the transmission through wired or wireless medium, digital images often encountered different types of channel noise which can significantly distort its appearance. As a matter of fact, filtering operation of digital images forms one of the most important tasks to be performed at the receiving end. In this paper, we have proposed a novel design strategy of two-dimensional (2-D) low-pass filter by means of a powerful evolutionary optimization technique called Differential Evolution (DE) algorithm. Mask coefficients of the proposed filter are constrained to assume values as sum of powers-of-two, thus making the filter hardware friendly. Experimental results have demonstrated the power of the algorithm in reducing the effect of Gaussian noise from digital image in terms of various performance parameters like peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), image enhancement factor (IEF) and image quality index (IQI) and so on. A number of test images have been taken into our consideration for the purpose of establishing our proposition. Simulation results have confirmed the superiority of the proposed DE-based filter over the conventional low-pass filtering method.
C1 [Chandra, Abhijit] Jadavpur Univ, Dept Instrumentat & Elect Engn, Sect 3,Block LB,Plot 8 Salt Lake Bypass, Kolkata 700098, India.
   [Chattopadhyay, Sudipta] Jadavpur Univ, Dept Elect & Telecommun Engn, Kolkata 700032, India.
C3 Jadavpur University; Jadavpur University
RP Chandra, A (corresponding author), Jadavpur Univ, Dept Instrumentat & Elect Engn, Sect 3,Block LB,Plot 8 Salt Lake Bypass, Kolkata 700098, India.
EM abhijit922@yahoo.co.in; sudiptachat@yahoo.com
CR [Anonymous], DIGITAL IMAGE PROCES
   Bhadouria VS, 2014, SIGNAL IMAGE VIDEO P, V8, P71, DOI 10.1007/s11760-013-0487-5
   Boudjelaba K, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P60, DOI 10.1109/PACRIM.2011.6032868
   Das S, 2011, IEEE T EVOLUT COMPUT, V15, P4, DOI 10.1109/TEVC.2010.2059031
   Das S, 2008, STUD COMPUT INTELL, V116, P1, DOI 10.1007/978-3-540-78297-1_1
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Estrada F, 2009, BRIT MACH VIS C
   Hua JY, 2014, MULTIMED TOOLS APPL, V69, P157, DOI 10.1007/s11042-012-1263-1
   Huang HC, 2007, CIRC SYST SIGNAL PR, V26, P671, DOI 10.1007/s00034-006-0104-z
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   Latif A, 2013, J INFORM HIDING MULT, V4, P250
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu JC, 2011, IEEE T CIRCUITS-I, V58, P746, DOI 10.1109/TCSI.2010.2078730
   MCCLELLAN JH, 1977, IEEE T CIRCUITS SYST, V24, P372, DOI 10.1109/TCS.1977.1084354
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Sriranganathan S., 1995, First International Conference on `Genetic Algorithms in Engineering Systems: Innovations and Applications' GALESIA (Conf. Publ. No.414), P282
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Storn Rainer, 1995, TR095012 INT COMP SC
   Thamvichai R, 2001, CONF REC ASILOMAR C, P588, DOI 10.1109/ACSSC.2001.986991
   Thamvichai R, 2002, IEEE T CIRCUITS-I, V49, P878, DOI 10.1109/TCSI.2002.1010045
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tzeng ST, 2007, SIGNAL PROCESS, V87, P2036, DOI 10.1016/j.sigpro.2007.01.034
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Yin H, 2014, J INF HIDING MULTIME, V5
NR 25
TC 12
Z9 12
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1079
EP 1098
DI 10.1007/s11042-014-2358-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700018
DA 2024-07-18
ER

PT J
AU Chang, CC
   Nguyen, TS
   Lin, CC
AF Chang, Chin-Chen
   Thai-Son Nguyen
   Lin, Chia-Chen
TI A new distortion-free data embedding scheme for high-dynamic range
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data embedding; Distortion-free; High-dynamic range image;
   Steganography; High embedding rate
ID STEGANOGRAPHIC METHOD; CAPACITY
AB Distortion-free data embedding enables a cover image to be recovered from its stego-image without any distortion after the secret data have been extracted. This distortion-free property allows the appropriate recovery of highly sensitive images for which even the smallest modification of the cover images cannot be allowed. In this paper, a new distortion-free data embedding scheme is proposed for high-dynamic range (HDR) images. The proposed scheme uses all homogeneous representations of each pixel in an HDR image efficiently and effectively for data embedding to enhance the embedding capacity of the HDR cover image. First, in the embedding phase, all homogeneous representations are used, and each homogeneous representation is used to represent one pattern of secret bits. Then, to conceal the secret bits, the current homogeneous representation of the current processing pixel is modified by the corresponding homogeneous representation of the hidden secret bits. Experimental results confirmed that the proposed scheme has greater embedding capacity than three other existing schemes. In addition, the experimental results indicated that our scheme matched the visual quality of the stego-image by producing a tone-mapped cover image and its stego-image that were exactly the same. In other words, our scheme also provided the desired, distortion-free property.
C1 [Chang, Chin-Chen; Thai-Son Nguyen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
C3 Feng Chia University; Providence University - Taiwan
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
EM ccc@cs.ccu.edu.tw; thaison@tvu.edu.vn; mhlin3@pu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023; Nguyen, Thai-Son/AGD-3594-2022
OI Nguyen, Thai-Son/0000-0001-7008-0462; Lin, Chia-Chen/0000-0003-4480-7351
CR [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], P ACM SIGGRAPH, DOI DOI 10.1145/566570.566574
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2006, J SYST SOFTW, V79, P1754
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cheng YM, 2009, IEEE MULTIMEDIA, V16, P70, DOI 10.1109/MMUL.2009.43
   Chia-Chen Lin, 2010, Journal of Software, V5, P1, DOI 10.4304/jsw.5.2.214-224
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Chin-Chen Chang, 2013, Journal of Electronic Science and Technology, V11, P20, DOI 10.3969/j.issn.1674-862X.2013.01.005
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Guorong Xuan, 2004, Digital Watermarking. Third International Workshop, IWDW 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3304), P115
   Huang NC, 2009, IEEE SIGNAL PROC LET, V16, P802, DOI 10.1109/LSP.2009.2024794
   Larson GregW., 1992, GRAPHICS GEMS 2, P80, DOI [10.1016/B978-0-08-050754-5.50025-6, DOI 10.1016/B978-0-08-050754-5.50025-6]
   Larson GW, 1988, RENDERING RADIANCE
   Li MT, 2011, INT J INNOV COMPUT I, V7
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Solachidis V, 2013, 18 INT C DIG SIGN PR
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang ZH, P 2012 4 INT C DIG H, P33
   Wu HC, 2010, DISPLAYS, V31, P35, DOI 10.1016/j.displa.2009.10.002
   Yu CM, 2011, DISTORTION FREE DATA
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
NR 30
TC 22
Z9 22
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 145
EP 163
DI 10.1007/s11042-014-2279-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500008
DA 2024-07-18
ER

PT J
AU Asghar, MN
   Ghanbari, M
   Fleury, M
   Reed, MJ
AF Asghar, Mamoona N.
   Ghanbari, Mohammed
   Fleury, Martin
   Reed, Martin J.
TI Sufficient encryption based on entropy coding syntax elements of
   H.264/SVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AES-CFB; CABAC; CAVLC; H.264/SVC; Sufficient encryption
ID SELECTIVE ENCRYPTION; VIDEO; SCHEME; PROTECTION; MANAGEMENT; CABAC
AB While much attention has been paid to securing the transmission of single-layer video, multi-layer scalable video also deserves consideration. This paper presents a sufficient encryption (SE) scheme for the H.264 Scalable Video Coding (SVC) extension that maintains the compression efficiency and the decoder format compliancy of the bit-stream, without compromising its confidentiality. SE is achieved by applying encryption of carefully selected codewords or bin-strings of the Context-Adaptive Variable-Length Coding (CAVLC) and Context-Adaptive Binary Arithmetic Coding (CABAC) entropy coders respectively. The selection of exactly what to encrypt is what distinguishes this contribution from that of others. The performance of the scheme is tested on sequences with varying spatial resolutions, thus demonstrating the advantages of the scheme when compared to alternative techniques. These advantages include: minimal computational delay by encrypting partial data; no bit-rate escalation by keeping the compression ratio unchanged; and format compliancy of the bit-stream at the decoder. The detailed security and comparative evaluation of the scheme confirms that it is suitable for commercial, real-time applications. As there is a minimal increase in processing requirements, the scheme is highly suitable for video distribution to users who have subscribed to differing video qualities on end systems ranging from small handheld devices to those capable of high spatial resolutions and frame rates.
C1 [Asghar, Mamoona N.] Islamia Univ Bahawalpur, Dept Comp Sci & IT, Punjab, Pakistan.
   [Asghar, Mamoona N.; Ghanbari, Mohammed; Fleury, Martin; Reed, Martin J.] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Islamia University of Bahawalpur; University of Essex
RP Fleury, M (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
EM mamona.asghar@iub.edu.pk; ghan@essex.ac.uk; fleum@essex.ac.uk;
   mjreed@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Asghar,
   Mamoona/0000-0001-7460-266X
CR Algin GB, 2011, J VIS COMMUN IMAGE R, V22, P353, DOI 10.1016/j.jvcir.2011.02.005
   [Anonymous], FED INF PROC STAND P
   [Anonymous], IEEE REG 10 C TAIP T
   [Anonymous], RFC3830 IETF
   [Anonymous], I STAND TECHN NIST F
   [Anonymous], ART ERROR CORRECTING
   [Anonymous], P SING FRENCH IPAL S
   [Anonymous], DATABASE NETW J
   [Anonymous], P 14 ANN ACM INT C M
   [Anonymous], IEEE T INFO FORENSIC
   [Anonymous], 2006004 ESTREAM
   [Anonymous], EURASIP J INFORM SEC
   [Anonymous], P INT MULT SYST SIGN
   [Anonymous], P ACM MULT SEC WORKS
   [Anonymous], 2009, 2009 2 INT C IMAGE S
   Asghar M. N., 2012, 2012 4th Computer Science and Electronic Engineering Conference (CEEC 2012). Proceedings, P139, DOI 10.1109/CEEC.2012.6375393
   Asghar M. N., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P443, DOI 10.1109/TrustCom.2012.268
   Asghar MN, 2012, J KING SAUD UNIV-COM, V24, P107, DOI 10.1016/j.jksuci.2011.12.002
   Bergeron C., 2005, IEEE Workshop on Multimedia Signal Processing, P1
   Chen TC, 2006, IEEE T CIRCUITS-II, V53, P832, DOI 10.1109/TCSII.2006.880014
   Dubois L, 2011, P IEEE INTERNATIONAL, P1
   Fan Y, 2008, IEICE T FUND ELECTR, VE91A, P12, DOI 10.1093/ietfec/e91-a.1.12
   Fan Y, 2007, LECT NOTES COMPUT SC, V4810, P246
   Fehr G, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P126, DOI 10.1109/WAINA.2013.207
   Ghanbari M., 2011, STANDARD CODECS IMAG, V3rd
   Li CH, 2008, LECT NOTES COMPUT SC, V5353, P496
   Magli E, 2011, SIGNAL PROCESS, V91, P1103, DOI 10.1016/j.sigpro.2010.10.012
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Pande A, 2013, IEEE MULTIMEDIA, V20, P50, DOI 10.1109/MMUL.2012.29
   Park SW, 2009, IEICE T INF SYST, VE92D, P851, DOI 10.1587/transinf.E92.D.851
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Sohn H, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P424, DOI 10.1109/AVSS.2009.48
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   TEUHOLA J, 1978, INFORM PROCESS LETT, V7, P308, DOI 10.1016/0020-0190(78)90024-8
   Wang DY, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P99, DOI 10.1109/MINES.2009.186
   Wang JD, 2007, ASICON 2007: 2007 7TH INTERNATIONAL CONFERENCE ON ASIC, VOLS 1 AND 2, PROCEEDINGS, P802, DOI 10.1109/ICASIC.2007.4415752
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Won YG, 2006, LECT NOTES COMPUT SC, V4283, P407
NR 45
TC 14
Z9 14
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10215
EP 10241
DI 10.1007/s11042-014-2160-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700003
DA 2024-07-18
ER

PT J
AU Biswas, S
   Babu, RV
AF Biswas, Sovan
   Babu, R. Venkatesh
TI Anomaly detection in compressed H.264/AVC video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; H.264; Motion vectors; Compressed domain video
   analysis; Kernel density estimation; Visual surveillance
AB Real time anomaly detection is the need of the hour for any security applications. In this article, we have proposed a real time anomaly detection for H.264 compressed video streams utilizing pre-encoded motion vectors (MVs). The proposed work is principally motivated by the observation that MVs have distinct characteristics during anomaly than usual. Our observation shows that H.264 MV magnitude and orientation contain relevant information which can be used to model the usual behavior (UB) effectively. This is subsequently extended to detect abnormality/anomaly based on the probability of occurrence of a behavior. The performance of the proposed algorithm was evaluated and bench-marked on UMN and Ped anomaly detection video datasets, with a detection rate of 70 frames per sec resulting in 90x and 250x speedup, along with on-par detection accuracy compared to the state-of-the-art algorithms.
C1 [Biswas, Sovan; Babu, R. Venkatesh] Indian Inst Sci, Video Analyt Lab, Supercomp Educ & Res Ctr, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, Video Analyt Lab, Supercomp Educ & Res Ctr, Bangalore 560012, Karnataka, India.
EM venky@serc.iisc.ernet.in
RI Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2013, COMPUTER VISION PATT
   [Anonymous], 2011, P 19 ACM INT C MULTI, DOI DOI 10.1145/2072298.2072042
   [Anonymous], P IND C COMP VIS GRA
   Benezeth Y., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2458, DOI 10.1109/CVPRW.2009.5206686
   Boiman O, 2005, IEEE I CONF COMP VIS, P462
   Chan AB, 2008, IEEE T PATTERN ANAL, V30, P909, DOI 10.1109/TPAMI.2007.70738
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Itti L, 2005, PROC CVPR IEEE, P631
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Moiron S., 2007, P C TEL, P449
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Pourazad M. T., 2010, J IMAGE VIDEO PROCES, V2010
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Remagnino P, 2001, ALGORITHMS, V6, P1
   Ryan D., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P230, DOI 10.1109/AVSS.2011.6027327
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
NR 24
TC 19
Z9 21
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11099
EP 11115
DI 10.1007/s11042-014-2219-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600007
DA 2024-07-18
ER

PT J
AU Borgi, MA
   El'Arbi, M
   Labate, D
   Ben Amar, C
AF Borgi, Mohamed Anouar
   El'Arbi, Maher
   Labate, Demetrio
   Ben Amar, Chokri
TI Regularized directional feature learning for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shearlet; Regularized shearlets network; Face recognition
ID COLLABORATIVE REPRESENTATION; WAVELETS; EIGENFACES
AB This paper presents an improved approach to face recognition, called Regularized Shearlet Network (RSN), which takes advantage of the sparse representation properties of shearlets in biometric applications. One of the novelties of our approach is that directional and anisotropic geometric features are efficiently extracted and used for the recognition step. In addition, our approach is augmented by regularization theory (RSN) in order to control the trade-off between the fidelity to the data (gallery) and the smoothness of the solution (probe). In this work, we address the challenging problem of the single training sample per subject (STSS). We compare our new algorithm against different state-of-the-art methods.
C1 [Borgi, Mohamed Anouar; El'Arbi, Maher; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, ENIS, Sfax 3038, Tunisia.
   [Labate, Demetrio] Univ Houston, Dept Math, Houston, TX 77204 USA.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   University of Houston System; University of Houston
RP Borgi, MA (corresponding author), Univ Sfax, Res Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM anoir.borgi@ieee.org; maher.elarbi@gmail.com; dlabate@math.uh.edu;
   chokri.benamar@ieee.org
RI Chokri, BEN AMAR/K-5237-2012
FU General Direction of scientific Research (DGRST), Tunisia under ARUB
   program; NSF [DMS 1005799, DMS 1008900]
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of scientific Research (DGRST),
   Tunisia, under the ARUB program. D. Labate acknowledges partial support
   by NSF DMS 1005799 and DMS 1008900.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P INT C ART NEUR NET
   [Anonymous], 1996, CONVEX ANAL MINIMIZA, DOI DOI 10.1007/978-3-662-02796-7
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Ben Amar C, 2005, ADV ENG SOFTW, V36, P459, DOI 10.1016/j.advengsoft.2005.01.013
   BERTERO M, 1988, P IEEE, V76, P869, DOI 10.1109/5.5962
   BERTERO M, 1986, INVERSE PROBLEMS
   Bodmann BG, APPL COMPUT IN PRESS
   Borgi Mohamed Anouar, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P514, DOI 10.1109/ICASSP.2014.6853649
   Borgi Mohamed Anouar, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P307, DOI 10.1007/978-3-642-40246-3_38
   Borgi MA, 2013, LECT NOTES COMPUT SC, V8157, P611, DOI 10.1007/978-3-642-41184-7_62
   Cevikalp H, 2010, PATTERN RECOGN LETT, V31, P1285, DOI 10.1016/j.patrec.2010.03.009
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Easley GR, 2014, J MATH IMAGING VIS, V48, P13, DOI 10.1007/s10851-012-0385-4
   Easley GR, 2012, IEEE T IMAGE PROCESS, V21, P550, DOI 10.1109/TIP.2011.2164415
   Easley GR, 2012, HYERBOLIC SHEARLETS
   Guo KH, 2006, APPL NUM HARM ANAL, P231
   Guo KH, 2004, ELECTRON RES ANNOUNC, V10, P78, DOI 10.1090/S1079-6762-04-00132-5
   Hastie T., 2003, SPRINGER SERIES STAT
   Heisele B, 2001, PROC CVPR IEEE, P657
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Kutyniok G, 2009, T AM MATH SOC, V361, P2719
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Li SZ, 1998, P IEEE INT C COMP VI
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Martinez A., 1998, AR FACE DATABASE
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang T., 2012, MULTISTAGE CONVEX RE
   Zhang T, 2010, J MACH LEARN RES, V11, P1081
NR 51
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11281
EP 11295
DI 10.1007/s11042-014-2228-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600015
DA 2024-07-18
ER

PT J
AU Leung, D
   Newsam, S
AF Leung, Daniel
   Newsam, Shawn
TI Land cover classification using geo-referenced photos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Proximate sensing; Land cover classification; Geo-referenced photos
ID WORLD
AB We investigate publicly available geo-referenced photo collections for land cover classification. Mapping land cover is a fundamental task in the geographic sciences and is typically done using remote sensing (overhead) imagery through manual annotation. We here propose a novel alternate approach based on proximate sensing. The goal of proximate sensing is to map what-is-where on the surface of the Earth using ground level images of objects and scenes. It has the potential to map phenomena not observable through remote sensing. We perform an extensive case study on using ground level images for binary land cover classification into developed and undeveloped regions. We investigate visual features and text annotations to label images or sets of images with these two classes. Knowing the location of the images allows us to generate land cover maps which we quantitatively evaluate using ground truth maps. We apply our approach to two photo collections, Flickr, the popular photo sharing website, and the Geograph project, whose goal is to collect geographically informative photos. Comparing these two collections allows us to measure the impact of photographer intent. We utilize a weakly supervised learning framework which eliminates the need for manually labeled training data. We also investigate methods for filtering images that are unlikely to be geographically informative. Our results are promising and validate proximate sensing as a novel alternate approach to geographic discovery.
C1 [Leung, Daniel; Newsam, Shawn] Univ Calif Merced, Elect Engn & Comp Sci, Merced, CA 95343 USA.
C3 University of California System; University of California Merced
RP Leung, D (corresponding author), Univ Calif Merced, Elect Engn & Comp Sci, Merced, CA 95343 USA.
EM cleung3@ucmerced.edu; snewsam@ucmerced.edu
OI Newsam, Shawn/0000-0001-6803-5291
FU National Science Foundation [IIS-1150115]; US Department of Energy Early
   Career Scientist and Engineer/PECASE award; Direct For Computer & Info
   Scie & Enginr [1150115] Funding Source: National Science Foundation; Div
   Of Information & Intelligent Systems [1150115] Funding Source: National
   Science Foundation
FX This work was funded in part by a National Science Foundation CAREER
   grant (IIS-1150115) and a US Department of Energy Early Career Scientist
   and Engineer/PECASE award. We thank the anonymous reviewers for their
   informative feedback.
CR [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], IEEE MULTIMEDIA SPEC
   [Anonymous], P ACM INT C MULT
   [Anonymous], ACM INT C ADV GEOGR
   [Anonymous], STAND LAND US COD MA
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P INT WORKSH LOC WEB
   [Anonymous], 2005, THESIS J GUTENBERG U
   Cao L., 2009, P 17 ACM INT C MULTI, P125
   Cao Liangliang., 2008, COMPUTER VISION PATT, P1
   Cristani M, 2008, P IEEE INT C COMPUTE, P1
   Gallagher Andrew, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P55, DOI 10.1109/CVPR.2009.5204168
   Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hays J, 2008, PROC CVPR IEEE, P3436
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jacobs N, 2007, P IEEE INT C COMPUTE, P1
   Joshi D., 2008, P INT C CONTENT BASE, P37
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Moxley Emily., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, P24
   Naaman M, 2005, ACM-IEEE J CONF DIG, P178, DOI 10.1145/1065385.1065430
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Quack Till., 2008, P 2008 INT C CONTENT, P47
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 30
TC 11
Z9 11
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11741
EP 11761
DI 10.1007/s11042-014-2261-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600034
DA 2024-07-18
ER

PT J
AU Wang, LH
   Hou, CP
   Lei, JJ
   Yan, WQ
AF Wang, Laihua
   Hou, Chunping
   Lei, Jianjun
   Yan, Weiqing
TI View generation with DIBR for 3D display system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View synthesis; 3D image warping; Hole filling; Depth map
ID DEPTH VIDEO
AB DIBR is a promising technology for rendering new views of scenes from a collection of densely sampled images or videos. It has potential application in virtual reality, immersive, advanced visualization, and 3D television systems. However, due to imperfect depth maps and the illumination difference between reference images, annoying artifacts appear in the rendering image. To generate high-quality intermediate virtual viewpoint image, this paper proposes a novel virtual view rendering method based on DIBR. The proposed method consists of four main parts: luminance compensation based on histogram matching, isolated depth pixel removing, 3D warping with depth-based pixel interpolation, and background-based hole filling. Experimental results show that our method can obtain high-quality virtual view images and achieve satisfactory subjective visual effects.
C1 [Wang, Laihua; Hou, Chunping; Lei, Jianjun; Yan, Weiqing] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Lei, JJ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM jjleitg@gmail.com
RI Lei, Jianjun/P-2539-2018
FU National Natural Science Foundation of China [60932007]; National 863
   Program [2012AA03A301]; Ph.D. Programs Foundation of Ministry of
   Education of China [20110032110029]; Key Projects in the Tianjin Science
   & Technology Pillar Program [11ZCKFGX02000]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 60932007, by National 863 Program (No. 2012AA03A301),
   and by Ph.D. Programs Foundation of Ministry of Education of China (No.
   20110032110029) and Key Projects in the Tianjin Science & Technology
   Pillar Program (grant 11ZCKFGX02000).
CR [Anonymous], MPEGM15672 ISOIEC JT
   [Anonymous], THESIS U N CAROLINA
   [Anonymous], EURASIP J ADV SIGNAL
   [Anonymous], 3DTV CON 2008 P IST
   Cadík M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366166
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   De Silva DVSX, 2010, IEEE IMAGE PROC, P4013, DOI 10.1109/ICIP.2010.5653353
   Do L, 2012, IEEE T CONSUM ELECTR, V58, P633, DOI 10.1109/TCE.2012.6227470
   Hannuksela MM, 2013, IEEE T IMAGE PROCESS, V22, P3449, DOI 10.1109/TIP.2013.2269274
   Heo J, 2010, IEEE SIGNAL PROC LET, V17, P835, DOI 10.1109/LSP.2010.2059014
   Lee DS, 2013, OPT COMMUN, V286, P74, DOI 10.1016/j.optcom.2012.08.022
   Lei JJ, 2014, MULTIMED TOOLS APPL, V72, P825, DOI 10.1007/s11042-013-1386-z
   Li S, 2014, IEEE SIGNAL PROC LET, V21, P74, DOI 10.1109/LSP.2013.2291941
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Muller Karsten, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P34, DOI 10.1109/MMSP.2008.4665045
   Oh KJ, 2010, INT J IMAG SYST TECH, V20, P378, DOI 10.1002/ima.20253
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723
   Sundaram M, 2011, APPL SOFT COMPUT, V11, P5809, DOI 10.1016/j.asoc.2011.05.003
   Tanimoto M, 2012, SIGNAL PROCESS-IMAGE, V27, P555, DOI 10.1016/j.image.2012.02.016
   Tauber Z, 2007, IEEE T SYST MAN CY C, V37, P527, DOI 10.1109/TSMCC.2006.886967
   Wang M, 2011, ISPRS J PHOTOGRAMM, V66, P347, DOI 10.1016/j.isprsjprs.2011.01.002
   Yan XS, 2011, OPT ENG, V50, DOI 10.1117/1.3530070
   Zhao M, 2010, PATTERN RECOGN LETT, V31, P686, DOI 10.1016/j.patrec.2009.09.024
   Zinger S, 2012, 3D RES, V3, DOI 10.1007/3DRes.01(2012)4
NR 26
TC 18
Z9 22
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9529
EP 9545
DI 10.1007/s11042-014-2133-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200022
DA 2024-07-18
ER

PT J
AU Wu, ZY
   Zhao, K
   Wu, XX
   Lan, XY
   Meng, HL
AF Wu, Zhiyong
   Zhao, Kai
   Wu, Xixin
   Lan, Xinyu
   Meng, Helen
TI Acoustic to articulatory mapping with deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic to articulatory mapping; Audio-visual mapping; Deep neural
   network (DNN); Speech driven talking avatar
ID MOVEMENTS
AB Synthetic talking avatar has been demonstrated to be very useful in human-computer interactions. In this paper, we discuss the problem of acoustic to articulatory mapping and explore different kinds of models to describe the mapping function. We try general linear model (GLM), Gaussian mixture model (GMM), artificial neural network (ANN) and deep neural network (DNN) for the problem. Taking the advantage of neural network that its prediction stage can be finished in a very short time (e.g. real-time), we develop a real-time speech driven talking avatar system based on DNN. The input of the system is acoustic speech and the output is articulatory movements (that are synchronized with the input speech) on a three-dimensional avatar. Several experiments are conducted to compare the performance of GLM, GMM, ANN and DNN on a well known acoustic-articulatory English speech corpus MNGU0. Experimental results demonstrate that the proposed acoustic to articulatory mapping method with DNN can achieve the best performance.
C1 [Wu, Zhiyong; Zhao, Kai; Wu, Xixin; Lan, Xinyu; Meng, Helen] Tsinghua Univ, Tsinghua CUHK Joint Res Ctr Media Sci Technol & S, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
   [Wu, Zhiyong; Zhao, Kai; Wu, Xixin; Lan, Xinyu; Meng, Helen] Tsinghua Univ, Shenzhen Key Lab Informat Sci & Technol, Grad Sch Shenzhen, Shenzhen 518055, Peoples R China.
   [Wu, Xixin; Meng, Helen] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
   [Wu, Zhiyong; Zhao, Kai; Wu, Xixin; Lan, Xinyu] Tsinghua Univ, TNList, Shenzhen 518055, Peoples R China.
   [Wu, Zhiyong; Zhao, Kai; Wu, Xixin; Lan, Xinyu] Tsinghua Univ, Dept Comp Sci & Technol, Shenzhen 518055, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Chinese University of Hong Kong; Tsinghua University; Tsinghua
   University
RP Wu, XX (corresponding author), Tsinghua Univ, TNList, Shenzhen 518055, Peoples R China.
EM zywu@se.cuhk.edu.hk; zk69052@163.com; xixinwood@gmail.com;
   451250406@qq.com; hmmeng@se.cuhk.edu.hk
RI Meng, Helen M/F-6043-2011
OI Meng, Helen M/0000-0002-4427-3532
FU National Basic Research Program of China [2012CB316401, 2013CB329304];
   Hong Kong SAR Government's Research Grants Council [N-CUHK414/09];
   National Natural Science Foundation of China [61375027, 61370023,
   60805008]; National Social Science Foundation Major Project [13ZD189];
   Guangdong Provincial Science and Technology Program [2012A011100008]
FX This work is supported by the National Basic Research Program of China
   (2012CB316401 and 2013CB329304). This work is also partially supported
   by the Hong Kong SAR Government's Research Grants Council
   (N-CUHK414/09), the National Natural Science Foundation of China
   (61375027, 61370023 and 60805008), the National Social Science
   Foundation Major Project (13&ZD189) and Guangdong Provincial Science and
   Technology Program (2012A011100008).
CR [Anonymous], 2009, NIPS WORKSH DEEP LEA
   [Anonymous], P EUR
   [Anonymous], 2009, ENCY BIOMETRICS
   Cassell J, 2001, AI MAG, V22, P67
   Cosatto E, 2003, P IEEE, V91, P1406, DOI 10.1109/JPROC.2003.817141
   Deng L., 2011, P AS SUMM C APSIPA A, P1
   Ding C, 2015, MULTIMED TOOLS APPL, V74, P9871, DOI 10.1007/s11042-014-2156-2
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hinton GE, 2007, PROG BRAIN RES, V165, P535, DOI 10.1016/S0079-6123(06)65034-6
   Hiroya S, 2002, INT CONF ACOUST SPEE, P437
   Hiroya S., 2002, P ICSLP, P2305
   Jia J, 2014, MULTIMED TOOLS APPL, V73, P439, DOI 10.1007/s11042-013-1604-8
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kawahara H., 2001, P INT WORKSH MOD AN
   Massaro D.W., 1987, Speech perception by ear and eye: A paradigm for psychological inquiry
   MCCULLAGH P, 1984, EUR J OPER RES, V16, P285, DOI 10.1016/0377-2217(84)90282-0
   Meng FB, 2014, MULTIMED TOOLS APPL, V73, P463, DOI 10.1007/s11042-013-1601-y
   Richmond K, 2002, THESIS EDINBURGH U
   Richmond K, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1516
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P318
   Tieleman T., 2009, P 26 ANN INT C MACH, P1033
   Toda T., 2004, INT C SPOKEN LANGUAG, P1129
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Uria B, 2012, P ANN C INT SPEECH C
   Wu ZY, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1802
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Xie L, 2014, MULTIMED TOOLS APPL, V73, P377, DOI 10.1007/s11042-013-1633-3
   Yegnanarayana B., 2006, Artificial Neural Networks"
   Zhang L, 2008, IEEE SIGNAL PROC LET, V15, P245, DOI 10.1109/LSP.2008.917004
   Zhao K, 2013, ASIAPAC SIGN INFO PR
   Zhao TY, 2010, P INT S CHIN SPOK LA, P99
NR 32
TC 18
Z9 18
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9889
EP 9907
DI 10.1007/s11042-014-2183-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400004
DA 2024-07-18
ER

PT J
AU Yang, HW
   Oura, K
   Wang, HY
   Gan, ZY
   Tokuda, K
AF Yang, Hongwu
   Oura, Keiichiro
   Wang, Haiyan
   Gan, Zhenye
   Tokuda, Keiichi
TI Using speaker adaptive training to realize Mandarin-Tibetan
   cross-lingual speech synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HMM-based speech synthesis; Speaker adaptive training; Multi-lingual
   speech synthesis; Tibetan speech synthesis; Mandarin-Tibetan
   cross-lingual speech synthesis; Grapheme-to-phoneme conversion
ID MAPPING APPROACH; ADAPTATION
AB This paper presents a method to realize the hidden Markov model (HMM)-based Mandarin-Tibetan cross-lingual statistical speech synthesis using speaker adaptive training. A set of Speech Assessment Methods Phonetic Alphabet (SAMPA) is designed to label the pronunciation of the initial and the final of Mandarin and Tibetan syllables according to the similarities in pronunciation between Mandarin and Tibetan. A grapheme-to-phoneme conversion method is realized to convert Chinese or Tibetan sentences to SAMPA-based Pinyin sequences. A Mandarin statistical speech synthesis framework is employed to realize Mandarin-Tibetan cross-lingual speech synthesis. A set of context-dependent label format is designed to label the context information of Mandarin and Tibetan sentences. A question set is also realized for context dependent decision tree clustering. The initial and the finalare used as the synthesis units with training using a set of average mixed-lingual models from a large Mandarin multi-speaker-based corpus and a small Tibetan one-speaker-based corpus using speaker adaptive training (SAT). Then, the speaker adaptation transformation is applied to the speaker dependent (SD) training data to obtain a set of speaker dependent Mandarin or Tibetan models from the average mixed-lingual models. The Mandarin speech or Tibetan speech is then synthesized from the speaker dependent Mandarin or Tibetan models. Tests show that this method outperforms the method using only Tibetan SD models when only a small number of Tibetan training utterances are available. When the number of training Tibetan utterances is increased, the performances of the two methods tend to be the same. Mixed Tibetan training sentences have a small effect on the quality of synthesized Mandarin speech.
C1 [Yang, Hongwu; Gan, Zhenye] Northwest Normal Univ, Coll Phys & Elect Engn, Key Lab Atom & Mol Phys & Funct Mat Gansu Prov, Lanzhou 730070, Peoples R China.
   [Oura, Keiichiro; Tokuda, Keiichi] Nagoya Inst Technol, Dept Comp Sci & Engn, Nagoya, Aichi, Japan.
   [Wang, Haiyan] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
C3 Northwest Normal University - China; Nagoya Institute of Technology;
   Northwest Normal University - China
RP Yang, HW (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Key Lab Atom & Mol Phys & Funct Mat Gansu Prov, Lanzhou 730070, Peoples R China.
EM yanghw@nwnu.edu.cn; uratec@sp.nitech.ac.jp; why6715@163.com;
   ganzy@nwnu.edu.cn; tokuda@nitech.ac.jp
RI Yang, Hongwu/AAI-8948-2021
OI Yang, Hongwu/0000-0002-8939-3386
FU National Natural Science Foundation of China [61263036, 61262055]; Gansu
   Science Fund for Distinguished Young Scholars [1210RJDA007]; Core
   Research for Evolutional Science and Technology (CREST) from Japan
   Science and Technology Agency (JST)
FX The research leading to these results was partly funded by the National
   Natural Science Foundation of China (Grant No. 61263036, 61262055),
   Gansu Science Fund for Distinguished Young Scholars (Grant No.
   1210RJDA007) and the Core Research for Evolutional Science and
   Technology (CREST) from Japan Science and Technology Agency (JST).
CR Bourlard H, 2011, SADHANA-ACAD P ENG S, V36, P885, DOI 10.1007/s12046-011-0050-4
   Chen YN, 2009, INT CONF ACOUST SPEE, P4273, DOI 10.1109/ICASSP.2009.4960573
   [高定国 Gao Dingguo], 2005, [中文信息学报, Journal of Chinese Information Processing], V19, P71
   Goldstein MelvynC., 1991, ESSENTIALS MODERN LI
   Handel Z, 2008, LANG LINGUIST COMPAS, V2, DOI 10.1111/j.1749-818x.2008.00061.x
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Latorre J, 2006, SPEECH COMMUN, V48, P1227, DOI 10.1016/j.specom.2006.05.003
   Li Y, 2008, J TSINGHUA U SCI TEC, V48, P621
   Liang H, 2008, INT CONF ACOUST SPEE, P4641
   Lu Gao, 2010, Proceedings of the 2010 International Conference on Information and Automation (ICIA 2010), P817, DOI 10.1109/ICINFA.2010.5512462
   Mirjam  W., 2010, EDIINFRR1388 U ED
   Peng XL, 2010, INT CONF SIGN PROCES, P605, DOI 10.1109/ICOSP.2010.5656849
   Qian Y, 2006, LECT NOTES COMPUT SC, V4274, P223
   Qian Y, 2009, IEEE T AUDIO SPEECH, V17, P1231, DOI 10.1109/TASL.2009.2015708
   Schrder M, 2007, BLIZZARD CHALLENGE 2
   Siohan O, 2002, COMPUT SPEECH LANG, V16, P5, DOI 10.1006/csla.2001.0181
   Wells J. C., 1997, HDB STANDARDS RESOUR
   Wu YJ, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P516
   Wu YJ, 2008, 2008 6TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P9
   Yamagishi J, 2003, IEICE T FUND ELECTR, VE86A, P1956
   Yamagishi J, 2009, IEEE T AUDIO SPEECH, V17, P66, DOI 10.1109/TASL.2008.2006647
   Zen  H., 2010, INTERSPEECH 2010, P186
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
   Zhang Jialu, 2009, Acta Acustica, V34, P81
NR 24
TC 14
Z9 17
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 9927
EP 9942
DI 10.1007/s11042-014-2117-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400006
DA 2024-07-18
ER

PT J
AU Muñoz, FR
   Villalba, LJG
AF Roman Munoz, Fernando
   Garcia Villalba, Luis Javier
TI Web from preprocessor for crawling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Web vulnerability Scanner; Crawling; Web forms; Fields values; Deep web
AB Usually organizations deploy web applications into the production environment with vulnerabilities. To avoid it, organizations need to run a web application vulnerability assessment. The most prevalent kind of vulnerability assessment is when the tester uses a vulnerability scanner. This assessment can be divided into two phases: crawling and testing. The purpose of the first phase is to gather all the access points of the application. In the second phase the tester sends some malformed values to the application, and then analyze the response looking for known vulnerability patterns. The crawling phase is critical because if the tester cannot reach the applications content, he or she couldn't test that content to find vulnerabilities. One of the main challenges of crawling web applications are to fill out web forms with correct values. To face this challenge, web vulnerability scanners used to include a generic list of field value pairs. These scanners also let the tester to add new pairs. This paper presents a novel method for searching candidate web form field values. The challenge is to map more applications content than using the field value pairs included by default. Our method will try to get form fields values executing the client side code and looking for candidate values in an external data source.We have test the proposed method and the experiments show that it can improve the crawling phase of dynamic vulnerability assessment.
C1 [Roman Munoz, Fernando; Garcia Villalba, Luis Javier] Univ Complutense Madrid, Grp Anal Secur & Syst, Dept Software Engn & Artificial Intelligence DISI, Sch Comp Sci, E-28040 Madrid, Spain.
C3 Complutense University of Madrid
RP Villalba, LJG (corresponding author), Univ Complutense Madrid, Grp Anal Secur & Syst, Dept Software Engn & Artificial Intelligence DISI, Sch Comp Sci, Off 431,Calle Prof Jose Garcia Santesmases S-N, E-28040 Madrid, Spain.
EM froman@fdi.ucm.es; javiergv@fdi.ucm.es
RI Garcia Villalba, Luis Javier/N-4631-2014
OI Garcia Villalba, Luis Javier/0000-0001-7573-6272
FU Ministerio de Industria, Turismo y Comercio (MITyC, Spain) through the
   Project Avanza Competitividad I+D+I [TSI-020100-2011-165]; Agencia
   Espanola de Cooperacion Internacional para el Desarrollo (AECID, Spain)
   through Accion Integrada MAEC-AECID MEDITERRANEO [A1/037528/11]
FX This work was supported by the Ministerio de Industria, Turismo y
   Comercio (MITyC, Spain) through the Project Avanza Competitividad I+D+I
   TSI-020100-2011-165 and the Agencia Espanola de Cooperacion
   Internacional para el Desarrollo (AECID, Spain) through Accion Integrada
   MAEC-AECID MEDITERRANEO A1/037528/11.
CR Baral P, 2011, IEEE POTENTIALS, V30, P10, DOI 10.1109/MPOT.2010.939449
   Bau J, 2010, P IEEE S SECUR PRIV, P332, DOI 10.1109/SP.2010.27
   Doupé A, 2010, LECT NOTES COMPUT SC, V6201, P111, DOI 10.1007/978-3-642-14215-4_7
   Gonzalez Hector., 2010, Proceedings of the 2010 ACM SIGMOD International Conference on Management of data, P1061, DOI DOI 10.1145/1807167.1807286
   Huang Yao-Wen, 2003, Proceedings of the 12th International Conference on World Wide Web, P148
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
NR 6
TC 4
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8559
EP 8570
DI 10.1007/s11042-013-1460-6
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600020
DA 2024-07-18
ER

PT J
AU Suh, W
AF Suh, Wonho
TI Mobile computing traffic simulation framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile computing; Online simulation; Optimistic execution; Ad hoc
   network
AB Recent advancements in sensor, mobile computing, and wireless communication technologies have created an opportunity for mobile computing and online traffic simulations. This paper presents a distributed traffic simulation framework where traffic simulation and data processing are performed in a distributed fashion by mobile computing. In this framework, communication middleware and traffic simulation are integrated to manage the distributed network to synchronize traffic predictions among logical processes using a rollback-based optimistic synchronization protocol. The traffic predictions across the multiple logical processes are coordinated by optimistic execution inspired by Time Warp which mitigates the synchronization problem allowing each logical process to execute asynchronously. Invalidated estimates are updated quickly by this mechanism to ensure more robust and reliable estimates. This framework allows each mobile computing based in-vehicle simulation to model a small portion of the overall network and provide detailed traffic state information. Such a system could provide both more up-to-date and robust predictions than that offered by centralized simulations within a single transportation management center. As these systems evolve, the mobile computing online traffic predictions can be used in surface transportation management and travelers will benefit from more accurate and reliable traffic forecast.
C1 Hanyang Univ, Ansan 426791, South Korea.
C3 Hanyang University
RP Suh, W (corresponding author), Hanyang Univ, 55 Hanyangdaehak Ro, Ansan 426791, South Korea.
EM wonhosuh@hanyang.ac.kr
FU Hanyang University [HY-2013-2247]
FX This work was supported by the research fund of Hanyang University
   (HY-2013-2247). The author would like to acknowledge Dr. Richard
   Fujimoto and Dr. Michael Hunter.
CR [Anonymous], 2014, NETWORK ON WHEELS
   [Anonymous], 2014, VEHICLE INFRASTRUCTU
   [Anonymous], 2014, COOPERATIVE VEHICLE
   [Anonymous], 2014, CONNECTED VEHICLE TE
   [Anonymous], 2014, NATL ITS PROGRAM PLA
   [Anonymous], 2014, GLOBAL SYSTEM TELEMA
   Chu L., 2004, Micro-Simulation Modeling Approach to Applications of On-Line Simulation And Data Fusion
   Federal Highway Administration, 2014, HIGHW STAT 2012
   Fujimoto R., 1999, P 1999 WINT SIM C PH
   Gorgorin C, 2007, P IEEE VEH TECHN C D
   Jefferson D, 1985, P ACM T PROGRAMMING, V7
   Katwijk R, 2005, TEST BED MULTIAGENT, P113
   Lee D-H, 2005, INTELLIGENT TRANSPOR, V7, P279
   Lomax T, 2012, 2011 ANN URBAN MOBIL
   Oyama S, 2005, P 2 ACM INT WORKSH V
   Planing Tranpsport Verkehr (PTV), 2012, VISSIM US MAN, P763
   Suh W, 2013, P INT C IT CONV SEC
   Suh W, 2012, THESIS GEORGIA I TEC
   United States Census Bureau, 2014, 2012 STAT ABSTR
   Wang H, 2004, TRANSPORT RES REC, P201
NR 20
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6169
EP 6181
DI 10.1007/s11042-014-2099-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700003
DA 2024-07-18
ER

PT J
AU Anegekuh, L
   Sun, LF
   Ifeachor, E
AF Anegekuh, Louis
   Sun, Lingfen
   Ifeachor, Emmanuel
TI Encoding and video content based HEVC video quality prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE; HEVC; MV; CVQP; Video quality evaluation; Motion amount; Video
   complexity
ID FRAMEWORK
AB Advances in multimedia devices and video compression techniques and the availability of increased network bandwidth in both fixed and mobile networks has increased the proliferation of multimedia applications (e.g. IPTV, video streaming and online gaming). However, this has also posed a real challenge to network and service providers to deliver these applications with an acceptable Quality of Experience (QoE). In these multimedia applications, it is highly desirable to predict and if possible control video quality to meet such QoE and user expectations. Streamed video quality is affected by both encoding and transmission processes. The impacts of these processes are content dependent. This issue has gradually been recognised in video quality modelling research in recent years. In this paper, we carried out objective and subjective tests on video sequences to investigate the impact of video content type and encoding parameter settings on HEVC video quality. Initial results show that varying video content type and encoding parameters impact video quality. Based on the test results, we developed a content-based video quality prediction (CVQP) model that takes into account HEVC encoding parameter such as Quantization Parameter (QP) and video content type (characterised by motion activities and complexity of video sequences). We achieved an accuracy of 92 % for the test dataset when model predicted PSNR values were compared with full reference PSNR measurements. The performance of the model was also evaluated by comparing predicted PSNR with those of Double Stimulus Impairment Scale (DSIS) subjective quality ratings. Results show a good correlation between actual MOS and predicted PSNR. The proposed model could be used by content providers to determine the initial quality of videos based on QP and content type.
C1 [Anegekuh, Louis; Sun, Lingfen; Ifeachor, Emmanuel] Univ Plymouth, Ctr Signal Proc & Multimedia Commun, Plymouth PL4 8AA, Devon, England.
C3 University of Plymouth
RP Anegekuh, L (corresponding author), Univ Plymouth, Ctr Signal Proc & Multimedia Commun, Plymouth PL4 8AA, Devon, England.
EM louis.anegekuh@plymouth.ac.uk; l.sun@plymouth.ac.uk;
   e.ifeachor@plymouth.ac.uk
OI Sun, Lingfen/0000-0002-9921-2817
CR [Anonymous], JCTVCG1200
   [Anonymous], SPMC SUBJ VID TEST
   [Anonymous], 2 INT S WIR PERV COM
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], SUBJ VID QUAL ASS ME
   [Anonymous], INT WORK IMAGE PROCE
   [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], 8 INT WORK NETW OP S
   [Anonymous], P 3 INT WORK VID PRO
   [Anonymous], 2011, J TELECOMMUN INF TEC
   [Anonymous], VQEG REPORT VALIDATI
   [Anonymous], 2009, PAK DEV REV, DOI DOI 10.1109/ICC.2009.5198850
   [Anonymous], IEEE CONSUM ELECT MA
   [Anonymous], IS T SPIE EL IM INT
   [Anonymous], JCTVCA124 ITUT SG16
   [Anonymous], 1 INT C MULT SERV AC
   Argyropoulos S, 2011, INT WORK QUAL MULTIM, P31, DOI 10.1109/QoMEX.2011.6065708
   Avik B., 2009, Institute of Electrical and Electronics Engineers International Conference on Industrial Technology, P1
   Boujut H, 2011, IEEE INT CON MULTI
   Choi H, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P346, DOI 10.1109/PACRIM.2011.6032917
   Hands DS, 2004, IEEE T MULTIMEDIA, V6, P806, DOI 10.1109/TMM.2004.837233
   Hiramatsu K., 2010, 2010 12th IEEE International Conference on Communication Systems (ICCS 2010), P161, DOI 10.1109/ICCS.2010.5686376
   Hu J, 2009, INT WORK QUAL MULTIM, P216, DOI 10.1109/QOMEX.2009.5246950
   Kanwisher N, 2000, NAT REV NEUROSCI, V1, P91, DOI 10.1038/35039043
   Khan Asiya, 2009, Journal of Multimedia, V4, P228, DOI 10.4304/jmm.4.4.228-239
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Kim J., 1975, Statistical package for the social sciences, P398
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Koumaras H, 2010, J VIS COMMUN IMAGE R, V21, P139, DOI 10.1016/j.jvcir.2009.07.005
   Lee B, 2013, IEEE T BROADCAST, V59, P20, DOI 10.1109/TBC.2012.2226533
   Pinson M, 2003, PROC SPIE, V5150, P573, DOI 10.1117/12.509908
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Reibman AR, 2004, IEEE T MULTIMEDIA, V6, P327, DOI 10.1109/TMM.2003.822785
   Ries Michal, 2008, Journal of Communications, V3, P41, DOI 10.4304/jcm.3.1.41-50
   Rosdiana E, 2000, ELECTRON LETT, V36, P521, DOI 10.1049/el:20000424
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Snedecor G.W., 1989, STAT METHODS, P503, DOI [10.1017/S0021859600074104, DOI 10.1017/S0021859600074104]
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Van Wallendael G, 2012, INT WORK QUAL MULTIM, P7, DOI 10.1109/QoMEX.2012.6263845
   Welling M., 2004, Support Vector Regression
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zhai JF, 2005, IEEE INT SYMP CIRC S, P4927
NR 43
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3715
EP 3738
DI 10.1007/s11042-013-1795-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800006
DA 2024-07-18
ER

PT J
AU Pohl, D
   Bouchachia, A
   Hellwagner, H
AF Pohl, Daniela
   Bouchachia, Abdelhamid
   Hellwagner, Hermann
TI Social media for crisis management: clustering approaches for sub-event
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Sub-event detection; Clustering; Information search and
   retrieval; Crisis management
AB Social media is getting increasingly important for crisis management, as it enables the public to provide information in different forms: text, image and video which can be valuable for crisis management. Such information is usually spatial and time-oriented, useful for understanding the emergency needs, performing decision making and supporting learning/training after the emergency. Due to the huge amount of data gathered during a crisis, automatic processing of the data is needed to support crisis management. One way of automating the process is to uncover sub-events (i.e., special hotspots) in the data collected from social media to enable better understanding of the crisis. We propose in the present paper clustering approaches for sub-event detection that operate on Flickr and YouTube data since multimedia data is of particular importance to understand the situation. Different clustering algorithms are assessed using the textual annotations (i.e., title, tags and description) and additional metadata information, like time and location. The empirical study shows in particular that social multimedia combined with clustering in the context of crisis management is worth using for detecting sub-events. It serves to integrate social media into crisis management without cumbersome manual monitoring.
C1 [Pohl, Daniela; Hellwagner, Hermann] Alpen Adria Univ Klagenfurt, Inst Informat Technol ITEC, Multimedia Commun MMC, A-9020 Klagenfurt Am Worthersee, Austria.
   [Bouchachia, Abdelhamid] Bournemouth Univ, Sch Design Engn & Comp, Smart Technol Res Ctr, Fern Barrow Poole BH12 5BB, England.
C3 Bournemouth University
RP Pohl, D (corresponding author), Alpen Adria Univ Klagenfurt, Inst Informat Technol ITEC, Multimedia Commun MMC, Univ Str 65-67, A-9020 Klagenfurt Am Worthersee, Austria.
EM daniela@itec.uni-klu.ac.at; abouchachia@bournemouth.ac.uk;
   hermann.hellwagner@aau.at
OI Bouchachia, Abdelhamid/0000-0002-1980-5517; Hellwagner,
   Hermann/0000-0003-1114-2584
CR [Anonymous], 2006, ELEMNTS INFORM THEOR
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], 2012, BBC NEWS EUROPE
   [Anonymous], 2008, INTRO INFORM RETRIEV
   [Anonymous], 2012, PUBLIC HEALTH EMERGE
   [Anonymous], P SPEC WORKSH INT DI
   Bergstrand F, 2009, PROCEEDINGS OF THE 6
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bouchachia A, 2006, FUZZY SET SYST, V157, P1733, DOI 10.1016/j.fss.2006.02.015
   Choudhary A, 2012, COMMUN ACM, V55, P74, DOI 10.1145/2160718.2160736
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Duda P. O., 2001, PATTERN CLASSIFICATI
   Han DF, 2008, MULTIMED TOOLS APPL, V39, P169, DOI 10.1007/s11042-008-0203-6
   Ireson Neil, 2009, 2009 3rd IEEE International Conference on Digital Ecosystems and Technologies (DEST), P49, DOI 10.1109/DEST.2009.5276763
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Larose D. T., 2005, Discovering knowledge in data
   Liu S, 2008, PROCEEDINGS OF THE I
   Marcus A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P227
   Mathioudakis M., 2010, P 2010 ACM SIGMOD IN, P1155
   Miller G. A, 1998, WORDNET ELECT LEXICA
   Petkos G., 2012, P 2 ACM INT C MULT R, P231, DOI 10. 1145/2324796.2324825.
   Petrovic Sasa, 2010, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, P181
   Pohl D, 2012, FIRST INTERNATIONAL
   Pohl D, 2012, INTERNATIONAL CONFER
   Rattenbury Tye, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P103, DOI 10.1145/1277741.1277762
   Rogstadius J, 2011, PROCEEDINGS CHI WORK
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sagun A, 2010, EFFICIENT DEPLOYMENT, P95
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Slaney M, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.34
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Terpstra T, 2012, PROCEEDINGS OF THE 9
   Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1
   Tucker S, 2012, PROCEEDINGS OF THE 9
   Vesanto J, 2000, TOOLMET 2000 SYMPOSI
   Vieweg S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1079, DOI 10.1145/1753326.1753486
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083
   Yates D, 2011, INT J INFORM MANAGE, V31, P6, DOI 10.1016/j.ijinfomgt.2010.10.001
   Yin J., 2012, IEEE T IND IN PRESS, P1
   Zhou C, 2007, ACM TRANS INF SYST, V25, P65
NR 42
TC 24
Z9 25
U1 2
U2 64
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3901
EP 3932
DI 10.1007/s11042-013-1804-2
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800014
DA 2024-07-18
ER

PT J
AU Song, GH
   Li, ZT
   Zhao, J
   Hu, J
   Tu, H
AF Song, Guanghua
   Li, Zhitang
   Zhao, Juan
   Hu, Jun
   Tu, Hao
TI A reversible video steganography algorithm for MVC based on motion
   vector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible video steganography; Multi-view coding; Motion vector; Inner
   product; Distortion drift
ID DATA HIDING SCHEME; DIFFERENCE EXPANSION; H.264/AVC; WATERMARKING
AB In this paper we present a reversible video steganography scheme for hiding secret data into the motion vector of each block in 3D MVC videos. Under this approach the idea of the inner product is introduced to achieve reversibility. By establishing the inner product between the motion vector and the modulation vector and setting the embedding conditions, we embed 1 bit data into each motion vector and the proposed algorithm is reversible. Moreover, in order to avoid distortion drift, we only embed data into b4-frames with the coding feature of 3D MVC videos. Experimental results also confirm that the proposed scheme can provide expected acceptable video quality of stegovideos and successfully achieve reversibility.
C1 [Song, Guanghua; Zhao, Juan; Hu, Jun; Tu, Hao] Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Li, Zhitang; Tu, Hao] Huazhong Univ Sci & Technol, Network & Comp Ctr, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Li, ZT (corresponding author), Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM ghsong@hust.edu.cn; leeying@mail.hust.edu.cn
FU National Natural Science Foundation of China [61272407]
FX The authors would sincerely like to thank the anonymous reviewers of the
   paper for several insightful comments. They also thank the editor Ms.
   Angie Malanday for her efforts in revising the paper. The work described
   in this paper was supported by the National Natural Science Foundation
   of China under Grant (Name: Research on Steganography for 3D H.264 Video
   Streams without Intra-frame Distortion Drift. No: 61272407).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Barton J. M., 1997, US Patent, Patent No. [6,115,818, 6115818]
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Fallahpour M, 2011, IET IMAGE PROCESS, V5, P190, DOI 10.1049/iet-ipr.2009.0226
   Fallahpour M, 2009, LECT NOTES COMPUT SC, V5450, P52, DOI 10.1007/978-3-642-04438-0_5
   Fang DY, 2006, IEEE INT SYMP CIRC S, P1422
   Hong W, 2010, SIGNAL PROCESS, V90, P2911, DOI 10.1016/j.sigpro.2010.04.012
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   ITU-T and ISO/IEC JTC 1, 2010, 1449610 ISOIEC AVC
   Jing HY, 2012, LECT NOTES ARTIF INT, V7197, P91, DOI 10.1007/978-3-642-28490-8_10
   Kim SM, 2007, LECT NOTES COMPUT SC, V4633, P698
   Kung CH, 2003, P 16 IPPR C COMP VIS, P547
   Kutter M., 1997, M2281 ISOIEC JTCISC2
   Lie W. N., 2005, P IEEE INT C MULT EX, P1174
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Pröfrock D, 2005, PROC SPIE, V5960, P1480, DOI 10.1117/12.632709
   Qin C, 2012, IEEE T CIRCUITS SYST, P1
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P21, DOI 10.1109/IAI.2004.1300937
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang C.-Y., 2011, J INFORM HIDING MULT, V2, P24
   Yo-Sung Ho, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P5
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
   Zhang J, 2007, IEEE T CIRCUITS-II, V54, P205, DOI 10.1109/TCSII.2006.886247
   Zhao Z, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1878
NR 36
TC 14
Z9 18
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3759
EP 3782
DI 10.1007/s11042-013-1798-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800008
DA 2024-07-18
ER

PT J
AU Choi, J
   Min, KW
   Lee, YS
AF Choi, JeongDan
   Min, Kyoung Wook
   Lee, Yang Sun
TI An intelligent parking platform of neighborhood EV for autonomous
   mobility service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent Parking Service (IPS); Video sequences; Moving object
   detection; Roadside server; Autonomous mobility service
ID SYSTEM
AB This paper introduces an Intelligent Parking platform for a neighborhood electric vehicle in intelligent multimedia service environment that automatically maneuvering from a traffic lane to the designated spot guided by roadside servers and mobile device. Three challenging problems are considered: one is to consider both low-speed forward driving and several parking maneuvers at the same time with a few in-vehicle sensors and the second one is to control the various sizes and types of passengers vehicles. And the last one is localization and tracking based on video sequences. With the assumptions of low speed and well installed roadside sensors, the platform to deal with two types of parking missions is proposed in this paper. We conduct a feasibility test for verification of our proposed architecture, and we suggest a possible approach to car-sharing service that autonomous mobility vehicle can drive and valet-charge within the limited area in intelligent multimedia service environment.
C1 [Choi, JeongDan; Min, Kyoung Wook] Elect & Telecommun Res Inst, Dept Car Infra Fus Res Team, Car Ship IT Convergence Technol Dept, Daejon, South Korea.
   [Lee, Yang Sun] Mokwon Univ, Div Comp Engn, Daejeon 302729, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Mokwon University
RP Lee, YS (corresponding author), Mokwon Univ, Div Comp Engn, 800 Doan Dong, Daejeon 302729, South Korea.
EM Jdchoi@etri.re.kr; kwmin92@etri.re.kr; yslee48@gmail.com
RI Min, Kyoung Wook/C-1948-2011; Lee, Yangsun/Q-9948-2019
OI Lee, Yang Sun/0000-0002-1268-2016
FU Industrial Strategic Technology Development Program - Ministry of
   Science ICT and Future Planning (MSIP, Korea) [10035250]
FX This work was supported by the Industrial Strategic Technology
   Development Program(10035250, Development of Spatial Awareness and
   Autonomous Driving Technology for Automatic Valet Parking) funded by the
   Ministry of Science ICT and Future Planning (MSIP, Korea).
CR [Anonymous], INT J INFORM TECHNOL
   Bacha A, 2008, J FIELD ROBOT, V25, P467, DOI 10.1002/rob.20248
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Eberle U, 2010, ROYAL SOC CHEM
   Hsieh M, 2008, P IEEE INT C INT VEH, P1155
   Inouel T, 2004, P SICE ANN C, P1015
   ISO, 2010, ISOTC204
   Kim J, 2009, ETRI J, V31, P463, DOI 10.4218/etrij.09.0209.0087
   Kryvinska Natalia, 2010, International Journal of Information Technology, Communications and Convergence, V1, P77, DOI 10.1504/IJITCC.2010.035228
   Liang W. Y., 2010, J CONVERGENCE, V1, P93
   Manni U, 2010, P IEEE EL C, P1736
   Min K, 2011, ETRI J, V33, P476, DOI 10.4218/etrij.11.1610.0012
   Open Mobile Alliance, 2004, EN REL DEF MOB LOC P
   Wada M, 2003, IEEE T IND ELECTRON, V50, P4, DOI 10.1109/TIE.2002.807690
NR 14
TC 3
Z9 3
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3277
EP 3288
DI 10.1007/s11042-014-1862-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000002
DA 2024-07-18
ER

PT J
AU Yoo, C
   Kang, BT
   Kim, HK
AF Yoo, Changsok
   Kang, Byung-Tak
   Kim, Huy Kang
TI Case study of the vulnerability of OTP implemented in internet banking
   systems of South Korea
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OTP (one time password); Man-in-the-middle attack; Reverse engineering;
   Internet banking
AB The security risk of internet banking has increased rapidly as internet banking services have become commonly used by the public. Among the various security methods, OTP (one time password) is known as one of the strongest methods for enforcing security, and it is now widely used in internet banking services. However, attack methods which can detour OTP have been developed that additional security for OTP is now needed. In this study, we discovered that a new kind of attack through OTP is theoretically possible through an analysis of the currently implemented OTP system and known attack methods. Based on our theory, we tested the new attack method on Korean internet banking services, and empirically proved that it could effectively detour around all of the currently implemented OTP security systems in Korea. To prevent this, we also suggested solutions based on the root cause analysis of the OTP vulnerabilities.
C1 [Yoo, Changsok] Kyung Hee Univ, Dept Culture & Tourism Contents, Seoul, South Korea.
   [Kang, Byung-Tak] Korea Univ, Grad Sch Informat Secur, Seoul, South Korea.
   [Kim, Huy Kang] Korea Univ, Grad Sch Informat Secur, Ctr Informat Secur Technol, Seoul, South Korea.
C3 Kyung Hee University; Korea University; Korea University
RP Kim, HK (corresponding author), Korea Univ, Grad Sch Informat Secur, Ctr Informat Secur Technol, Seoul, South Korea.
EM csyoo@khu.ac.kr; window31@korea.ac.kr; cenda@korea.ac.kr
RI Yoo, Changsok/AAJ-9568-2020; Kim, Huy Kang/R-5779-2016
OI Kim, Huy Kang/0000-0002-0760-8807
FU Kyung Hee University [KHU-2013-0988]
FX This work was supported by a grant from the Kyung Hee University in 2013
   (KHU-2013-0988).
CR Aloul F, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P641, DOI 10.1109/AICCSA.2009.5069395
   [Anonymous], 2005, Phone approval service, Patent No. 11157336
   Bae G, 2008, KOREA I INFORM SECUR, V18, P89
   Chang H, 2011, J SUPERCOMPUT, V55, P228, DOI 10.1007/s11227-010-0412-4
   Christos K, 2007, INF SYST CONTROL J, V3, P1
   de Jong Cornel, ONLINE AUTHENTICATIO
   Guhring P., 2007, CONCEPTS MAN IN THE
   Hallsteinsen S, 2007, INT C SYST NETW COMM, P68
   Hanacek P, 2009, 10 ACIS, P263
   Hiltgen A., 2006, SECURE INTERNET BANK
   Ku WC, 2004, IEICE T COMMUN, VE87B, P2374
   Lee Gi Seong, 2014, INTERNET BANKING SEC
   Maeng Y, 2010, INTERNET INFORM SECU, V1, P101
   Mizuno S, 2005, DIM2005, P54
   NetworkWorld, 2008, NEW TROJ INT ONL BAN
   Oppliger R, 2009, COMPUTER, V42, P27, DOI 10.1109/MC.2009.194
   Paulson LD, 2002, COMPUTER, V35, P27, DOI 10.1109/MC.2002.1009486
   Seo S, 2007, KOREA I INFORM SECUR, V17, P18
   Sherstobitoff R., 2013, Dissecting operation troy: Cyberespionage in South Korea
   Thanh D, 2008, IEEE GLOBECOM, P1
   Wikipedia, MAN IN THE MIDDL ATT
   Wikipedia, ONL BANK
   Wikipedia, ON TIM PASSW
   Wikipedia, 2 FACT AUTH
NR 24
TC 15
Z9 16
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3289
EP 3303
DI 10.1007/s11042-014-1888-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000003
DA 2024-07-18
ER

PT J
AU Li, S
   Wang, LC
   Kong, DH
AF Li, Shuo
   Wang, Lichun
   Kong, Dehui
TI Synthesis of sign language co-articulation based on key frames
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sign language; Sign language synthesis; Co-articulation; Motion edit
AB Co-articulation is a language phenomenon. In sign language (SL), it takes the form of impact among adjacent signs, which results in variations of signs from their standard configurations. Standard configuration is the appearance of a sign when it appears singly, without context. Without co-articulation, SL animation based on virtual character will be a simple concatenation of signs. The movement of virtual character will be mechanical, lacking fluency and realism. This paper presents a key frame based SL co-articulation animation scheme aiming at the three most important elements of co-articulation, i.e. hand shape, hand position and SL speed. To generate co-articulation, motion data of signs which appear sequentially is parsed to identify hand shapes and positions included in these signs. Then, co-articulation will be achieved through some modification to the motion data according to the interaction between adjacent hand shapes and adjacent hand positions. SL Speed acts as an adjusting parameter which dynamically impacts co-articulation. Different expression speed will lead to different degree of co-articulation.
C1 [Li, Shuo; Wang, Lichun; Kong, Dehui] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Li, S (corresponding author), Beijing Univ Technol, Coll Comp Sci & Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM studyboyz@163.com
FU National Natural Science Foundation of China [61170104, 61370119,
   U0935004, 61227004]; Beijing Natural Science Foundation [4112008]
FX The work in this paper was funded by National Natural Science Foundation
   of China (No. 61170104, 61370119, U0935004, 61227004), Beijing Natural
   Science Foundation (4112008).
CR Chi D, 2000, COMP GRAPH, P173, DOI 10.1145/344779.352172
   China Association of the Deaf, 2003, CHIN SIGN LANG
   Conway A, 1994, PEOPLE COMPUTERS, P211
   Dasgupta Tirthankar, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P313, DOI 10.1145/1378773.1378818
   Delorme M, 2009, 2 INT C ADV COMP HUM, P386, DOI [10.1109/ACHI.2009.29, DOI 10.1109/ACHI.2009.29]
   Grosvald Michael., 2008, Proceedings of the 24th Northwest Linguistics Conference (nwlc), P59
   Jerde TE, 2003, J NEUROSCI, V23, P2383
   Jerde TE, 2003, IEEE T BIO-MED ENG, V50, P265, DOI 10.1109/TBME.2002.807640
   Li S, 2012, 15 INT C GEOM GRAPH, P397
   Liddell S.K., 1984, En Papers from the Twentieth Regional Meeting, Chicago Linguistic Society, V20, P257
   Luo W, 2008, THESIS BEIJING NORMA
   Mauk C., 2003, Ph.D. dissertation
   San-Segundo R, 2008, SPEECH COMMUN, V50, P1009, DOI 10.1016/j.specom.2008.02.001
   Segouat J, 2009, 2 INT C ADV COMP HUM, P369, DOI [10.1109/ACHI.2009.25, DOI 10.1109/ACHI.2009.25]
   SHANTZ M, 1982, BEHAV RES METH INSTR, V14, P467, DOI 10.3758/BF03203314
   Sharieh A, 2008, INT WORKSHOP DATABAS, P622, DOI 10.1109/DEXA.2008.129
   Sosnik R, 2004, EXP BRAIN RES, V156, P422, DOI 10.1007/s00221-003-1799-4
   Stokoe W.C., 1978, Sign Language structure: The first linguistic analysis of American sign language
   Stokoe William C, 1976, A Dictionary of American Sign Language on Linguistic Principles
   Sudarsky S, 2000, COMP ANIM CONF PROC, P56, DOI 10.1109/CA.2000.889036
   Ye KJ, 2009, COMPUT ANIMAT VIRT W, V20, P237, DOI 10.1002/cav.307
NR 21
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 1915
EP 1933
DI 10.1007/s11042-013-1724-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500010
DA 2024-07-18
ER

PT J
AU Loghman, M
   Kim, J
AF Loghman, Maziar
   Kim, Joohee
TI Segmentation-based view synthesis for multi-view video plus depth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth image-based rendering; Segmentation; Hole fillings
AB In this paper, we present a novel view synthesis algorithm for three-dimensional video. The proposed algorithm is based on segmentation using multi-level thresholding method. Recently, numerous techniques have been suggested which use a 2-D color image and the per-pixel depth map of the scene to create virtual views of the scene from any viewing position. However, inaccuracy in the depth maps cause annoying visual artifacts in depth-based view synthesis. In the proposed method, the depth maps are first preprocessed to avoid the errors caused by wrong depth values. Then, the color images are segmented according to the depth values and the regions belonging to different segments are warped independently. To further enhance the quality of the synthesized views, a multi-level thresholding based ghost removal algorithm and a novel hole filling algorithm have been proposed. Experimental results show that the proposed methods achieve an average PSNR gain of 0.98 dB for the multi-view test sequences and also improve the subjective quality of the synthesized views.
C1 [Loghman, Maziar; Kim, Joohee] IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
C3 Illinois Institute of Technology
RP Kim, J (corresponding author), IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
EM mloghma1@hawk.iit.edu; joohee@ece.iit.edu
FU Technology Development Program for Commercializing System Semiconductor
   - Ministry of Trade, industry & Energy (MOTIE, Korea) [10041126]
FX This work was supported by the Technology Development Program for
   Commercializing System Semiconductor funded By the Ministry of Trade,
   industry & Energy (MOTIE, Korea). (No. 10041126, Title: International
   Collaborative R&BD Project for System Semiconductor).
CR [Anonymous], 2011, 3DTV C TRUE VIS CAPT
   [Anonymous], M16090 ISOIEC JTC1SC
   Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315
   Dyer CR, 2001, SPRING INT SER ENG C, V628, P469
   Fehn C, 2003, CONF REC ASILOMAR C, P1529
   Feng YM, 2009, IEEE T CONSUM ELECTR, V55, P2349, DOI 10.1109/TCE.2009.5373809
   Kang SB, 1998, PROC SPIE, V3641, P2, DOI 10.1117/12.333774
   Lim H, 2011, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2011.6115615
   Mori Yuji, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P229, DOI 10.1109/3DTV.2008.4547850
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   PAPAMARKOS N, 1994, CVGIP-GRAPH MODEL IM, V56, P357, DOI 10.1006/cgip.1994.1033
   Porter T., 1984, Computers & Graphics, V18, P253
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shade J., 1998, ANN C SERIES ACM SIG, P213
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2004, IEEE IMAGE PROC, P2993
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 20
TC 11
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1611
EP 1625
DI 10.1007/s11042-013-1747-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900006
DA 2024-07-18
ER

PT J
AU Huang, YG
   Huang, HY
   Zhang, J
AF Huang, Yonggang
   Huang, Heyan
   Zhang, Jun
TI A noisy-smoothing relevance feedback method for content-based medical
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Relevance feedback; Noisy elimination; Fuzzy membership function;
   Noisy-smoothing
ID CLASSIFICATION; CLASSIFIERS; FRAMEWORK
AB In this paper, we address a new problem of noisy images which present in the procedure of relevance feedback for medical image retrieval. We concentrate on the noisy images, caused by the users mislabeling some irrelevant images as relevant ones, and a noisy-smoothing relevance feedback (NS-RF) method is proposed. In NS-RF, a two-step strategy is proposed to handle the noisy images. In step 1, a noisy elimination algorithm is adopted to identify and eliminate the noisy images. In step 2, to further alleviate the influence of noisy images, a fuzzy membership function is employed to estimate the relevance probabilities of retained relevant images. After noisy handling, the fuzzy support vector machine, which can take into account different relevant images with different relevance probabilities, is adopted to re-rank the images. The experimental results on the IRMA medical image collection demonstrate that the proposed method can deal with the noisy images effectively.
C1 [Huang, Yonggang; Huang, Heyan] Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Beijing 100081, Peoples R China.
   [Huang, Yonggang; Huang, Heyan] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Zhang, Jun] Deakin Univ, Sch Informat Technol, Geelong, Vic 3217, Australia.
C3 Beijing Institute of Technology; Beijing Institute of Technology; Deakin
   University
RP Huang, YG (corresponding author), Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Beijing 100081, Peoples R China.
EM yonggang.h@gmail.com; jun.zhang@deakin.edu.au
RI huang, yonggang/O-6236-2019; Zhang, Jun/AAJ-6927-2020
OI Zhang, Jun/0000-0002-2189-7801
FU National Natural Science Foundation of China [61300077]; Research Fund
   for the Doctoral Program of Higher Education of China (Query and
   Annotation Translation Using Visual Information for Cross-Language Image
   Retrieval); Basic Research Foundation of Beijing Institute of Technology
   [20120742009]
FX The authors thank courtesy of TM Deserno, Dep. of Medical Informatics,
   RWTH Aachen, Germany, for providing IRMA dataset. This work is supported
   by the National Natural Science Foundation of China (No. 61300077), the
   Research Fund for the Doctoral Program of Higher Education of China
   (Query and Annotation Translation Using Visual Information for
   Cross-Language Image Retrieval), and the Basic Research Foundation of
   Beijing Institute of Technology (No. 20120742009).
CR Arevalillo-Herráez M, 2010, PATTERN RECOGN, V43, P619, DOI 10.1016/j.patcog.2009.08.010
   Belkhatir M, 2005, LECT NOTES COMPUT SC, V3568, P528
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Crucianu M, 2008, INT J IMAG SYST TECH, V18, P150, DOI 10.1002/ima.20151
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Ferreira CD, 2011, PATTERN RECOGN LETT, V32, P27, DOI 10.1016/j.patrec.2010.05.015
   Giacinto G, 2008, STUD COMPUT INTELL, V73, P419
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   Hoi SCH, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508854
   Iakovidis DK, 2009, IEEE T INF TECHNOL B, V13, P442, DOI 10.1109/TITB.2008.923144
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Koenemann Jurgen, 1996, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '96), P205, DOI DOI 10.1145/238386.238487
   Lehmann TM, 2003, PROC SPIE, V5033, P440, DOI 10.1117/12.480677
   Lehmann TM, 2012, IMAGE RETRIEVAL MED
   Lei Z, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P721, DOI 10.1109/ICIP.2001.958595
   Lin CF, 2002, IEEE T NEURAL NETWOR, V13, P464, DOI 10.1109/72.991432
   Liu R, 2008, PATTERN RECOGN, V41, P2645, DOI 10.1016/j.patcog.2008.01.023
   Mildenberger P, 2002, EUR RADIOL, V12, P920, DOI 10.1007/s003300101100
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Muller H, 2002, P 15 INT C PATT REC, P1043
   Rahman MM, 2008, COMPUT MED IMAG GRAP, V32, P95, DOI 10.1016/j.compmedimag.2007.10.001
   Rahman MM, 2007, IEEE T INF TECHNOL B, V11, P58, DOI 10.1109/TITB.2006.884364
   Rahman MM, 2011, IEEE T INF TECHNOL B, V15, P640, DOI 10.1109/TITB.2011.2151258
   Rahman MM, 2011, I S BIOMED IMAGING, P1905, DOI 10.1109/ISBI.2011.5872781
   Rao Y, 2006, LECT NOTES COMPUT SC, V4071, P350
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Salton G., 1971, SMART RETRIEVAL SYST
   Scott G, 2007, IEEE T INF TECHNOL B, V11, P320, DOI 10.1109/TITB.2006.880551
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Wang XY, 2013, ENG APPL ARTIF INTEL, V26, P368, DOI 10.1016/j.engappai.2012.05.008
   Wang XF, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P786, DOI 10.1109/CISP.2012.6469899
   Xu XQ, 2008, IEEE T INF TECHNOL B, V12, P100, DOI 10.1109/TITB.2007.904149
   Ye Lu, 2000, Proceedings ACM Multimedia 2000, P31, DOI 10.1145/354384.354403
   Zhao L., 2012, RECENT ADV COMPUTER, V124, P761
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 40
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1963
EP 1981
DI 10.1007/s11042-013-1685-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200039
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Wang, X
   Zhou, JL
   Wang, XJ
AF Zhu, Haijiang
   Wang, Xuan
   Zhou, Jinglin
   Wang, Xuejing
TI Approximate model of fisheye camera based on the optical refraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical refraction; Approximate model; Parameter estimation; Fisheye
   lens
ID WIDE-ANGLE; LENS; CALIBRATION
AB This paper proposes an approximate model of fisheye camera based on the optical refraction. The model of fisheye lens is firstly derived from the optical refraction and the structure of fisheye lenses. Secondly, a suitable linearization of the fisheye model is developed in order to obtain an approximate model, and the approximate model including two parameters is constructed from the linearization of the fisheye model. Finally, the estimation algorithm on the model parameters is presented using the epipolar constraint between two fisheye images. Furthermore, we provide lots of experiments with synthetic data and real fisheye images. To start with, the feasibility of the approximate model is tested through fitting the five common designed model of fisheye lens with synthetic data. Two groups of experiments with real fisheye image are then performed to estimate the model parameters. In practical situation, this method can automatically establish image correspondences using an improved random sample consensus algorithm without calibration objects.
C1 [Zhu, Haijiang; Wang, Xuan; Zhou, Jinglin; Wang, Xuejing] Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
C3 Beijing University of Chemical Technology
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
EM zhuhj@mail.buct.edu.cn
FU National Natural Science Foundation of China [60875023]; Fundamental
   Research Funds for the Central Universities [ZZ1134, ZZ1013]; Beijing
   Training Programme Foundation for the Talents [2012B009016000004]
FX This work was supported by the National Natural Science Foundation of
   China under grant No.60875023, The Fundamental Research Funds for the
   Central Universities (No.ZZ1134, No.ZZ1013) and Beijing Training
   Programme Foundation for the Talents No.2012B009016000004.
CR BASU A, 1995, PATTERN RECOGN LETT, V16, P433, DOI 10.1016/0167-8655(94)00115-J
   Bräuer-Burchardt C, 2001, IEEE IMAGE PROC, P225, DOI 10.1109/ICIP.2001.958994
   Derpanis K. G., 2010, OVERVIEW RANSAC ALGO
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Hansen P, 2010, INT J ROBOT RES, V29, P267, DOI 10.1177/0278364909356484
   Harris C., 1988, ALVEY VISION C, P147151
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Ho T.H., 2005, P IEEE OMNIVIS WORKS
   Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159
   Hughes C, 2010, APPL OPTICS, V49, P3338, DOI 10.1364/AO.49.003338
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Krüger L, 2011, PATTERN RECOGN LETT, V32, P1428, DOI 10.1016/j.patrec.2011.04.002
   Lefebvre S, 2011, IMAGE VISION COMPUT, V29, P580, DOI 10.1016/j.imavis.2011.05.003
   Li SG, 2011, IEEE T INTELL TRANSP, V12, P232, DOI 10.1109/TITS.2010.2085435
   Li SG, 2008, IEEE T INTELL TRANSP, V9, P589, DOI 10.1109/TITS.2008.2006736
   Li WM, 2011, OPT EXPRESS, V19, P5855, DOI 10.1364/OE.19.005855
   Micusík B, 2003, PROC CVPR IEEE, P485
   Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853
   Ryberg A, 2011, COMPUT VIS IMAGE UND, V115, P1503, DOI 10.1016/j.cviu.2011.06.009
   Schneider D, 2009, ISPRS J PHOTOGRAMM, V64, P259, DOI 10.1016/j.isprsjprs.2009.01.001
   Wang YC, 2007, FISHEYE LENS OPTICS
   [许振辉 XU Zhen-Hui], 2009, [自动化学报, Acta Automatica Sinica], V35, P1159
   Ying XG, 2004, LECT NOTES COMPUT SC, V3021, P442
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 27
TC 6
Z9 8
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1445
EP 1457
DI 10.1007/s11042-013-1641-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200016
DA 2024-07-18
ER

PT J
AU Ahmed, DT
   Hossain, MA
   Shirmohammadi, S
   AlGhamdi, A
   Atrey, PK
   El Saddik, A
AF Ahmed, Dewan Tanvir
   Hossain, M. Anwar
   Shirmohammadi, Shervin
   AlGhamdi, Abdullah
   Atrey, Pradeep K.
   El Saddik, Abdulmotaleb
TI Utility based decision support engine for camera view selection in
   multimedia surveillance systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance system; Decision support engine; Utility; Sensor; Feedback;
   Human-computer interaction
AB Design and implementation of an effective surveillance system is a challenging task. In practice, a large number of CCTV cameras are installed to prevent illegal and unacceptable activities where a human operator observes different camera views and identifies various alarming cases. But reliance on the human operator for real-time response can be expensive as he may be unable to pay full attention to all camera views at the same time. Moreover, the complexity of a situation may not be easily perceivable by the operator for which he might require additional support in response to an adverse situation. In this paper, we present a Decision Support Engine (DSE) to select and schedule most appropriate camera views that can help the operator to take an informed decision. For this purpose, we devise a utility based approach where the utility value changes based on automatically detected events in different surveillance zones, event co-relation, and operator's feedback. In addition to the selected camera views, we propose to synthetically embed extra information around the camera views such as event summary and suggested action plan to globally perceive the current situation. The experimental results show the usefulness of the proposed decision support system.
C1 [Ahmed, Dewan Tanvir; Hossain, M. Anwar; AlGhamdi, Abdullah] King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
   [Shirmohammadi, Shervin; El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
C3 King Saud University; University of Winnipeg; University of Ottawa
RP Ahmed, DT (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM dtahmed@ksu.edu.sa; mahossain@ksu.edu.sa; shervin@discover.uottawa.ca;
   Ghamdi@ksu.edu.sa; p.atrey@uwinnipeg.ca; abed@mcrlab.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012; /D-4159-2009; Hossain, M.
   Anwar/J-9601-2013
OI Shirmohammadi, Shervin/0000-0002-3973-4445; /0000-0002-7690-8547;
   Hossain, M. Anwar/0000-0002-7673-8410
FU NPST program by King Saud University [11-INF1830-02]
FX This research is supported by NPST program by King Saud University
   Project Number 11-INF1830-02.
CR Ahmed DT, 2011, MULT EXP ICME 2011 I, P1
   Atrey PK, 2011, MULTIMED TOOLS APPL, V51, P697, DOI 10.1007/s11042-010-0649-1
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Baumann Matthew A., 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P149, DOI 10.1109/HAPTIC.2010.5444662
   Davis M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P185
   Hossain MA, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870124
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Leykin Alex, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563059
   Liu AA, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1473, DOI 10.1109/ICME.2008.4607724
   Ma YF, 2003, ACM INT C MULT
   Nguyen NT, 2003, PROC CVPR IEEE, P620
   Norris C., 1999, MAXIMUM SURVEILLANCE
   Oates T, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P846
   Peters C, 2003, ATTENTION DRIVEN EYE
   Rath TM, 2003, PROC INT CONF DOC, P218
   Smith G.J., 2004, SURVEILLANCE SOC, V2/, P376
   Vaiapury K, 2008, J MULTIMEDIA, V3, P1
   Wallace E., 1998, CCTV control room ergonomics
NR 18
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 219
EP 240
DI 10.1007/s11042-012-1294-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700011
DA 2024-07-18
ER

PT J
AU Gamboa, H
   Silva, H
   Fred, A
AF Gamboa, Hugo
   Silva, Hugo
   Fred, Ana
TI HiMotion: a new research resource for the study of behavior, cognition,
   and emotion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Physiological data; Multimodal database;
   Affective computing
ID STRESS
AB The HiMotion research project was designed to create a multimodal database and several support tools for the study of human behavior, cognition and emotion, in the context of computer-based tasks designed to elicit cognitive load and specialized affective responses. The database includes both human-computer interaction (HCI) and psychophysiological data, collected through an experimental setup that we devised for synchronized recording of keyboard, mouse, and central/ peripheral nervous system measurements. Currently we provide a battery of five different cognitive tasks, and a video bank for affective elicitation, together with a set of introductory and self-reporting screens. We have conducted two experiments, one involving a population of 27 subjects, which followed the cognitive tasks protocol, and another involving a population of 20 subjects, which followed the video bank visualization protocol. We provide an overview of several studies that have used the HiMotion database to test multiple hypothesis in the behavioral and affective domains, highlighting the usefulness of our contribution.
C1 [Gamboa, Hugo] Fac Ciencia & Tecnol, CEFITEC Ctr Fis & Invest Tecnol, P-2829516 Caparica, Portugal.
   [Silva, Hugo; Fred, Ana] Inst Super Tecn, IT, P-1049001 Lisbon, Portugal.
C3 Universidade de Lisboa; Instituto de Telecomunicacoes
RP Silva, H (corresponding author), Inst Super Tecn, IT, P-1049001 Lisbon, Portugal.
EM hgamboa@fct.unl.pt; hsilva@lx.it.pt; afred@lx.it.pt
RI Plácido da Silva, Hugo/AAA-4845-2022; Fred, Ana/A-7464-2016; Gamboa,
   Hugo/M-8799-2013
OI Plácido da Silva, Hugo/0000-0001-6764-8432; Fred,
   Ana/0000-0003-1320-5024; Gamboa, Hugo/0000-0002-4022-7424
FU National Strategic Reference Framework (NSRF-QREN) programme [3475
   "Affective Mouse"]; PLUX-Wireless Biosignals, S.A.; Fundacao para a
   Ciencia e Tecnologia (FCT) [SFRH/BD/65248/2009]; Fundação para a Ciência
   e a Tecnologia [SFRH/BD/65248/2009] Funding Source: FCT
FX In the context of the HiMotion project there were several entities and
   people that helped or provided their support to the development of the
   project. First of all we express the gratitude to INSTICC in the person
   of Prof. Joaquim Filipe, by the support to the project by providing
   funding resources for scholarships and electrophysiology equipment. Part
   of the data acquisition was performed in the facilities of the Escola
   Superior de Tecnologia de Setubal, where part of the subjects that
   voluntary participated in the projected were recruited. The research was
   preformed in the Pattern and Image Analysis group of Instituto de
   Telecomunicacoes, to which we would also like to thank. Besides the
   researchers, the HiMotion project had collaboration in diverse extents
   of Ricardo Gamboa, David Cordeiro, Joao Almeida, and Filipe Canento; we
   address a special thanks for their involvement and collaboration to the
   project. We would also like to thank to the psychologist, Dr. Hans
   Welling from Student Counseling Center at Instituto Superior Tecnico and
   Dr. Teresa Paiva from the University of Lisbon Medical School which,
   kindly gave advise in preliminary stages of the design of the
   experiments. This work was also partially funded by the National
   Strategic Reference Framework (NSRF-QREN) programme under contract no.
   3475 "Affective Mouse", by PLUX-Wireless Biosignals, S.A., and by the
   Fundacao para a Ciencia e Tecnologia (FCT) under the grant
   SFRH/BD/65248/2009, whose support the authors gratefully acknowledge.
CR Aidos Helena, 2013, Proceedings of the 2nd International Conference on Pattern Recognition Applications and Methods. ICPRAM 2013, P479
   [Anonymous], P 2 INT C AG ART INT
   [Anonymous], CIRCULATION
   [Anonymous], P 2 INT WORKSH COMP
   [Anonymous], P 5 INT C MACH LEARN
   [Anonymous], P 6 INT C BIOINSP SY
   [Anonymous], MENSA GENIUS TEST
   [Anonymous], 5 INT C ENT INF SYST
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], P 2 INT C AFF COMP I
   [Anonymous], P INT EHEALTH TEL HL
   [Anonymous], THESIS U TECNICA LIS
   [Anonymous], SPIE
   [Anonymous], 2007, EMOTION PSYCHOPATHOL, DOI [DOI 10.1037/11562-007, 10.1037/11562-007]
   [Anonymous], P 52 ANN M SOC PSYCH
   Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1
   Bradley M.M., 1999, INT AFFECTIVE DIGITI
   Butcher J.N., 2009, ABNORMAL PSYCHOL, V14th
   Carreiras Carlos, 2013, Proceedings of the 6th International Conference on Bio-inspired Systems and Signal Processing. BIOSIGNALS 2013, P79
   Carvalho S, 2012, APPL PSYCHOPHYS BIOF, V37, P279, DOI 10.1007/s10484-012-9201-6
   FRIDLUND AJ, 1986, PSYCHOPHYSIOLOGY, V23, P567, DOI 10.1111/j.1469-8986.1986.tb00676.x
   Gamboa H, 2007, BIOMETRICS, P1
   Gamboa H., 2008, Ph.D. Thesis
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Herwig U, 2003, BRAIN TOPOGR, V16, P95, DOI 10.1023/B:BRAT.0000006333.93597.9d
   Hewig J, 2005, COGNITION EMOTION, V19, P1095, DOI 10.1080/02699930541000084
   Kaplan R.M., 1997, PSYCHOL TESTING PRIN, V4th
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lang P. J., 2005, A6 U FLOR CTR RES PS
   Lewis M., 2010, HDB EMOTIONS
   Picard R.W., 2000, Affective Computing
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Spreen O., 1998, A Compendium of Neuropsychological Tests
   TOLKMITT FJ, 1986, J EXP PSYCHOL HUMAN, V12, P302, DOI 10.1037/0096-1523.12.3.302
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 36
TC 9
Z9 11
U1 2
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 345
EP 375
DI 10.1007/s11042-013-1602-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700018
DA 2024-07-18
ER

PT J
AU Nam, Y
   Hong, SJ
AF Nam, Yunyoung
   Hong, Sangjin
TI Optimal placement of multiple visual sensors considering space coverage
   and cost constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimal camera placement; Video surveillance; Sensor planning; Sensor
   placement; Multiple cameras
ID OPTIMAL CAMERA PLACEMENT; SYSTEM
AB This paper proposes an optimal camera placement method that analyzes static spatial information in various aspects and calculates priorities of spaces using modeling the moving people pattern and simulation of pedestrian movement. To derive characteristics of space and to cover the space efficiently, an agent-based camera placement method has been developed considering the camera performance as well as the space utility extracted from a path finding algorithm. The simulation shows that the method not only determines the optimal number of cameras, but also coordinates the position and orientation of a camera efficiently considering the installation costs. Experimental results show that our approach achieves a great performance enhancement compared to other existing methods.
C1 [Nam, Yunyoung; Hong, Sangjin] SUNY Stony Brook, Dept Elect & Comp Engn, Mobile Syst Design Lab, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Nam, Y (corresponding author), SUNY Stony Brook, Dept Elect & Comp Engn, Mobile Syst Design Lab, Stony Brook, NY 11794 USA.
EM yynam@ece.sunysb.edu; snjhong@ece.sunysb.edu
RI Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
FU International Collaborative R&D Program of the Ministry of Knowledge
   Economy (MKE), the Korean government [2010-TD-300802-002]
FX This research is supported by the International Collaborative R&D
   Program of the Ministry of Knowledge Economy (MKE), the Korean
   government, as a result of Development of Security Threat Control System
   with Multi-Sensor Integration and Image Analysis Project,
   2010-TD-300802-002.
CR Agarwal PK, 2009, LECT NOTES COMPUT SC, V5516, P301, DOI 10.1007/978-3-642-02085-8_22
   Ai J, 2006, J COMB OPTIM, V11, P21, DOI 10.1007/s10878-006-5975-x
   [Anonymous], 1982, COMBINATORIAL OPTIMI
   [Anonymous], P OMNIVIS WORKSH
   [Anonymous], P 4 ACM INT WORKSH V
   [Anonymous], 1987, Art gallery theorems and algorithms
   Ballard P., 1993, 1993 IEEE INT C ROB, V3, P143, DOI [10.1109/ROBOT.1993.291858, DOI 10.1109/R0B0T.1993.291858]
   Bodor R, 2007, J INTELL ROBOT SYST, V50, P257, DOI 10.1007/s10846-007-9164-7
   Chen SY, 2004, IEEE T SYST MAN CY B, V34, P393, DOI 10.1109/TSMCB.2003.817031
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Erdem UM, 2006, COMPUT VIS IMAGE UND, V103, P156, DOI 10.1016/j.cviu.2006.06.005
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Horster E., 2006, P 4 ACM INT WORKSH V, P111
   Lim FL, 2007, J VLSI SIG PROC SYST, V49, P343, DOI 10.1007/s11265-007-0091-4
   Mittal A, 2004, LECT NOTES COMPUT SC, V3021, P175
   Munishwar V. P., 2010, P 4 ACM IEEE INT C D, P206, DOI DOI 10.1145/1865987.1866020
   Olague G, 1998, INT C PATT RECOG, P8, DOI 10.1109/ICPR.1998.711066
   Petrushin VA, 2005, MACHINE LEARN SIGN P, P349, DOI 10.1109/MLSP.2005.1532927
   Piciarelli C., 2010, ACM/IEEE International Conference on Distributed Smart Cameras, P88, DOI DOI 10.1145/1865987.1866002
   Ryu J, 2009, J UBIQUIT CONV TECHN, V3, P13
   Sivaram GSVS, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556140
   Tarabanis K, 1996, IEEE T PATTERN ANAL, V18, P279, DOI 10.1109/34.485556
   TARABANIS K, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P76, DOI 10.1109/ROBOT.1991.131556
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P72, DOI 10.1109/70.345939
   Topcuoglu HR, 2011, IEEE T SYST MAN CY C, V41, P376, DOI 10.1109/TSMCC.2010.2055850
   Velastin SA, 2005, IEEE T SYST MAN CY A, V35, P164, DOI 10.1109/TSMCA.2004.838461
   Wang J, 2006, J COMB OPTIM, V11, P291, DOI 10.1007/s10878-006-7909-z
   Yao Y., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587515
   YAO YL, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P993, DOI 10.1109/ICSMC.1995.537898
   Yunyoung Nam, 2012, 2012 International Conference on Computing, Networking and Communications (ICNC), P67, DOI 10.1109/ICCNC.2012.6167509
   Zhao J, 2008, IEEE J-STSP, V2, P464, DOI 10.1109/JSTSP.2008.2001430
NR 32
TC 8
Z9 8
U1 1
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 129
EP 150
DI 10.1007/s11042-012-1266-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700007
DA 2024-07-18
ER

PT J
AU Wang, YL
   Velipasalar, S
   Gursoy, MC
AF Wang, Youlu
   Velipasalar, Senem
   Gursoy, Mustafa Cenk
TI Distributed wide-area multi-object tracking with non-overlapping camera
   views
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Object tracking; Multi-camera tracking;
   Non-overlapping camera views; Probabilistic Petri-Nets
ID PETRI NETS; CLASSIFICATION
AB We present a distributed system for wide-area multi-object tracking across disjoint camera views. Every camera in the system performs multi-object tracking, and keeps its own trackers and trajectories. The data from multiple features are exchanged between adjacent cameras for object matching. We employ a probabilistic Petri Net-based approach to account for the uncertainties of the vision algorithms (such as unreliable background subtraction, and tracking failure) and to incorporate the available domain knowledge. We combine appearance features of objects as well as the travel-time evidence for target matching and consistent labeling across disjoint camera views. 3D color histogram, histogram of oriented gradients, local binary patterns, object size and aspect ratio are used as the appearance features. The distribution of the travel time is modeled by a Gaussian mixture model. Multiple features are combined by the weights, which are assigned based on the reliability of the features. By incorporating the domain knowledge about the camera configurations and the information about the received packets from other cameras, certain transitions are fired in the probabilistic Petri net. The system is trained to learn different parameters of the matching process, and updated online. We first present wide-area tracking of vehicles, where we used three non-overlapping cameras. The first and the third cameras are approximately 150 m apart from each other with two intersections in the blind region. We also present an example of applying our method to a people-tracking scenario. The results show the success of the proposed method. A comparison between our work and related work is also presented.
C1 [Wang, Youlu] Univ Nebraska, Dept Elect Engn, Lincoln, NE 68588 USA.
   [Velipasalar, Senem; Gursoy, Mustafa Cenk] Syracuse Univ, Elect Engn & Comp Sci Dept, Syracuse, NY 13210 USA.
C3 University of Nebraska System; University of Nebraska Lincoln; Syracuse
   University
RP Velipasalar, S (corresponding author), Syracuse Univ, Elect Engn & Comp Sci Dept, Syracuse, NY 13210 USA.
EM youlu.wang@huskers.unl.edu; svelipas@syr.edu; mcgursoy@syr.edu
FU NSF [CNS-1205458, CNS-1206291]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [1205458] Funding
   Source: National Science Foundation
FX This work has been funded in part by NSF grant CNS-1205458 and NSF
   CAREER grant CNS-1206291.
CR Albanese M, 2008, IEEE T MULTIMEDIA, V10, P1429, DOI 10.1109/TMM.2008.2010417
   ANJUM N, 2009, P IEEE INT C ADV VID
   [Anonymous], 2008, P INT C PATT REC
   [Anonymous], 2008, P INT C PATT REC
   [Anonymous], 2011, ACM WORKSH HUM GEST
   Black J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P169, DOI 10.1109/MOTION.2002.1182230
   Calderara S, 2005, LECT NOTES COMPUT SC, V3617, P1206, DOI 10.1007/11553595_148
   Cao XB, 2011, IEEE T CIRC SYST VID, V21, P1522, DOI 10.1109/TCSVT.2011.2162274
   Casares M, 2010, COMPUT VIS IMAGE UND, V114, P1223, DOI 10.1016/j.cviu.2010.03.023
   Cheng E, 2006, P IEEE INT C VID SIG
   CHILGUNDE A, 2004, P BRIT MACH VIS C
   Cohen I, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P566, DOI 10.1109/THS.2008.4534515
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   D'Orazio T, 2009, 2009 THIRD ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P365
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAVID R, 1994, AUTOMATICA, V30, P175, DOI 10.1016/0005-1098(94)90024-8
   del-Blanco C, 2008, P 2 ACM IEEE INT C D
   Geismann P, 2010, LECT NOTES COMPUT SC, V6453, P243
   Huang C, 2010, PROC OF THE INTL CON
   Huang T, 1998, ARTIF INTELL, V103, P77, DOI 10.1016/S0004-3702(98)00067-8
   Jacobs RA, 2002, TRENDS COGN SCI, V6, P345, DOI 10.1016/S1364-6613(02)01948-4
   Javed O, 2005, PROC CVPR IEEE, P26
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   KANG J, 2005, P IEEE WORKSH MOT VI
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Madden C, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P188, DOI 10.1109/AVSS.2007.4425308
   MAKRIS D, 2004, P IEEE COMP SOC C CO
   Moller B, 2008, P 19 INT C PATT REC
   Monari E, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P134, DOI 10.1109/AVSS.2009.16
   MURATA T, 1989, P IEEE, V77, P541, DOI 10.1109/5.24143
   Niu C, 2006, P INT C PATT REC
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Porikli F, 2003, P IEEE INT C IM PROC
   Prosser B. J., 2008, P BMVC, VVol. 8
   Rahimi A, 2004, PROC CVPR IEEE, P187
   Triesch J, 2001, NEURAL COMPUT, V13, P2049, DOI 10.1162/089976601750399308
   Velipasalar S, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/542808
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wang Y, 2010, P IEEE INT C MULT EX
NR 41
TC 28
Z9 28
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 7
EP 39
DI 10.1007/s11042-012-1267-x
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700002
DA 2024-07-18
ER

PT J
AU Naderahmadian, Y
   Hosseini-Khayat, S
AF Naderahmadian, Yashar
   Hosseini-Khayat, Saied
TI Fast and robust watermarking in still images based on QR decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR decomposition; Still image; Watermarking
AB A blind watermarking technique based on QR decomposition is proposed on still images. The method is presented in spatial as well as transform domains and its robustness against some well-known image processing attacks is evaluated. It is shown that the QR decomposition offers capacity and robustness comparable to or better than similar watermarking based on the DCT and SVD transformations. Also, an interesting property of QR decomposition, which for the first time has been introduced by our previous paper, is proved and put in practice in more details.
C1 [Naderahmadian, Yashar; Hosseini-Khayat, Saied] Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad 91779, Iran.
C3 Ferdowsi University Mashhad
RP Naderahmadian, Y (corresponding author), Ferdowsi Univ Mashhad, Dept Elect Engn, Mashhad 91779, Iran.
EM ya_na430@alumni.um.ac.ir; skhayat@um.ac.ir
RI Naderahmadian, Yashar/J-1599-2019
OI Naderahmadian, Yashar/0000-0001-5341-8943
CR Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ, 2008, MKS MULTIMED INFORM, P297, DOI 10.1016/B978-012372585-1.50012-7
   Jun Xiao, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P206, DOI 10.1109/PACIIA.2008.167
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Li XJ, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P350, DOI 10.1109/CIS.2008.203
   Liu F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P380, DOI 10.1109/CISP.2008.412
   Lu ZM, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P241
   Ma XH, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1063, DOI 10.1109/ICALIP.2008.4590092
   Mohammad AA, 2012, MULTIMED TOOLS APPL, V59, P851, DOI 10.1007/s11042-011-0772-7
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Navas KA, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P271, DOI 10.1109/COMSWA.2008.4554423
   Stanescu D, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P166, DOI 10.1109/HAVE.2008.4685318
   Sun XY, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P731, DOI 10.1109/IIH-MSP.2008.190
   Tsai MJ, 2000, IEEE T CONSUM ELECTR, V46, P241
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wei Cao, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P381, DOI 10.1109/IST.2009.5071670
   Yavuz E, 2006, LECT NOTES COMPUT SC, V4105, P66
   Yavuz E, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1051, DOI 10.1145/1244002.1244232
   Zhang LJ, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P19, DOI 10.1109/APCIP.2009.141
   Zhao RM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P821, DOI 10.1109/IITA.2008.482
   Zhu XZ, 2006, INT C PATT RECOG, P651
NR 21
TC 37
Z9 39
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2597
EP 2618
DI 10.1007/s11042-013-1559-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300023
DA 2024-07-18
ER

PT J
AU Rani, A
   Raman, B
   Kumar, S
AF Rani, Asha
   Raman, Balasubramanian
   Kumar, Sanjeev
TI A robust watermarking scheme exploiting balanced neural tree for
   rightful ownership protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Neural tree; Semi-blind watermarking;
   Synapses; Watermarking attacks
ID DIGITAL WATERMARKING; IMAGE; AUTHENTICATION; VISIBILITY
AB This paper presents a novel semi-blind watermarking scheme in which a balanced neural tree (BNT) is exploited for embedding and extracting the watermark. The BNT is trained to learn the watermark and the synapses (optimal weights) of the trained BNT are embedded in the host image instead of watermark image. As a result, the proposed scheme is able to embed a large size of watermark in the host image. In the watermark extraction phase, the embedded synapses are extracted from the transmitted image and then watermark is recovered from these extracted synapses. In this way, the original image is not required in the extraction phase. The proposed scheme is tested to withstand various kinds of attacks and found to be robust against various image processing and geometrical attacks.
C1 [Rani, Asha; Raman, Balasubramanian; Kumar, Sanjeev] Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kumar, S (corresponding author), Indian Inst Technol, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM asha0chaudhary@gmail.com; balarfma@iitr.ernet.in; malikdma@gmail.com
RI Kumar, Sanjeev/JTV-5459-2023; Kumar, Sanjeev/HKN-6866-2023
OI Kumar, Sanjeev/0000-0001-7728-3668
FU Council of Scientific and Industrial Research (CSIR), New Delhi
   [CSR-557-MTD]
FX This research work is supported by Council of Scientific and Industrial
   Research (CSIR), New Delhi under the grant number CSR-557-MTD.
CR Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CH, 2005, IEEE T CIRC SYST VID, V15, P65, DOI 10.1109/TCSVT.2004.839992
   Chang CY, 2010, EXPERT SYST APPL, V37, P7639, DOI 10.1016/j.eswa.2010.04.079
   Chen F, 2012, IEEE T INFORM THEORY, V58, P445, DOI 10.1109/TIT.2011.2171534
   Davis KJ, 2001, IEEE IJCNN, P2893, DOI 10.1109/IJCNN.2001.938836
   Foresti G., 1996, PATTERN RECOGNIT LET, V19, P869
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Joo S, 2002, ETRI J, V24, P401, DOI 10.4218/etrij.02.0202.0502
   Liu JL, 2006, COMPUT STAND INTER, V28, P356, DOI 10.1016/j.csi.2005.07.001
   Mei SC, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2430
   Micheloni C, 2012, NEURAL NETWORKS, V27, P81, DOI 10.1016/j.neunet.2011.10.007
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Paquet AH, 2003, SIGNAL PROCESS, V83, P2117, DOI 10.1016/S0165-1684(03)00171-3
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Tseng HW, 2008, ADV COMMUN SYST ELEC, V4, P479
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu GJ, 2003, PATTERN RECOGN, V36, P957, DOI 10.1016/S0031-3203(02)00106-1
   Zhang ZM, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1517
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
   [周波 Zhou Bo], 2004, [中国图象图形学报. A, Journal of image and graphics], V9, P506
NR 22
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2225
EP 2248
DI 10.1007/s11042-013-1528-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300009
DA 2024-07-18
ER

PT J
AU Huo, YR
   He, HJ
   Chen, F
AF Huo, Yaoran
   He, Hongjie
   Chen, Fan
TI A semi-fragile image watermarking algorithm with two-stage detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semi-fragile watermarking; Tamper detection; Two-stage detection;
   Identification parameter
ID AUTHENTICATION; SCHEME
AB The ability against the collage attack of semi-fragile watermarking is improved by embedding the watermark of a block in other blocks, but the tamper detection performance is impaired under general tampering. A two-stage detection method is proposed to improve the tamper detection performance of semi-fragile watermarking. For each 8 x 8 block, six-bit watermark data generated by the significant DCT (Discrete Cosine Transformation) coefficients are divided into two parts with the same length: general tampering watermark (GTW) and collage attack watermark (CAW). The GTW and CAW data of a block are embedded in the quantized DCT coefficients of itself and other blocks, respectively. In the first-stage detection, the general tampered regions are localized by the GTW data. To identify whether the collage attack exists in the received image, the identification parameter is defined by both GTW and CAW data. The selection of the predefined threshold of the identification parameter is derived and verified by the statistical experiments. If the identification parameter is larger than the given threshold, the second stage detection is performed to detect the collaged regions. Experimental results demonstrate that the proposed two-stage detection method is able to identify tampering with high probability under general tampering, collage attack and hybrid attack.
C1 [Huo, Yaoran; He, Hongjie; Chen, Fan] Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
C3 Southwest Jiaotong University
RP He, HJ (corresponding author), Southwest Jiaotong Univ, Sichuan Key Lab Signal & Informat Proc, Chengdu, Sichuan, Peoples R China.
EM hyr_2010@yahoo.cn; hehojie@126.com; fchen@home.swjtu.edu.cn
FU National Natural Science Foundation of China [60970122, 61170226];
   Research Fund for the Doctoral Program of Higher Education
   [20090184120021]; Fundamental Research Funds for the Central
   Universities [SWJTU09CX039, SWJTU10CX09]; Beijing Key Laboratory of
   Advanced Information Science & Network Technology [XDXX1007]; Railway
   Key Laboratory of Information Science Engineering [XDXX1007]; Science
   and Technique Foundation of Tibet Autonomous Region
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 60970122, 61170226), the Research Fund
   for the Doctoral Program of Higher Education (Grant No. 20090184120021),
   the Fundamental Research Funds for the Central Universities (Grant No.
   SWJTU09CX039, SWJTU10CX09), Beijing Key Laboratory of Advanced
   Information Science & Network Technology and Railway Key Laboratory of
   Information Science & Engineering (Grant No. XDXX1007), and by the
   Science and Technique Foundation of Tibet Autonomous Region (2012).
CR Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Che SB, 2007, INT C WAVEL ANAL PAT, P382
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He H, 2009, THESIS SW JIAOTONG U
   Li CT, 2004, IEE P-VIS IMAGE SIGN, V151, P460, DOI 10.1049/ip-vis:20040812
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Liu HM, 2005, IEEE INT SYMP CIRC S, P4014
   Liu H, 2010, EUR J ANAESTH, V27, P740, DOI 10.1097/EJA.0b013e328337bb56
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Yaoran Huo, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P608, DOI 10.1109/ICITIS.2010.5689517
   Yu M, 2007, SCI CHINA SER F, V50, P491, DOI 10.1007/s11432-007-0024-7
   Zhang WY, 2011, OPT COMMUN, V284, P3904, DOI 10.1016/j.optcom.2011.04.004
   Zhou X, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P374
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
NR 20
TC 23
Z9 23
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 123
EP 149
DI 10.1007/s11042-012-1317-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800007
DA 2024-07-18
ER

PT J
AU Tsai, MJ
   Liu, J
   Yin, JS
   Yuadi, I
AF Tsai, Min-Jen
   Liu, Jung
   Yin, Jin-Sheng
   Yuadi, Imam
TI A visible wavelet watermarking technique based on exploiting the
   contrast sensitivity function and noise reduction of human vision system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Contrast Sensitivity Function (CSF); Digital
   watermarking; Human Visual System (HVS); Noise Visibility Function
   (NVF); Wavelet
ID IMAGE QUALITY ASSESSMENT; VISIBILITY; INFORMATION
AB With the widespread use of the Internet and the rapid development of digital technologies, copyright protection of multimedia content has become an important issue. Among the available technologies, digital watermarking techniques are regarded as a solution to the property right protection for multimedia resources. To evaluate the performance of a visible watermarking technique, robustness and perceptual translucence are two essential criteria for the watermark applications. In order to get the best trade-off between the embedding energy of a watermark and perceptual translucence, this study presents a technique named ICOCOA (innovated content and contrast aware) by exploiting the contrast sensitivity function (CSF) and noise reduction of human vision system in the wavelet domain. Another novel idea of this work is to propose the innovated CSF masking (I-CSF) curve which provides better weight perception where a game-theoretic architecture can be leveraged to determine the best I-CSF masking for the watermarked image. The experimental results demonstrate that the proposed approach not only provides a good translucent quality of the watermark but also achieves the robustness against the common image processing operations.
C1 [Tsai, Min-Jen; Liu, Jung; Yin, Jin-Sheng; Yuadi, Imam] Natl Chiao Tung Univ, Inst Informat Management, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, MJ (corresponding author), Natl Chiao Tung Univ, Inst Informat Management, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM mjtsai@cc.nctu.edu.tw
RI Yuadi/V-3570-2018
OI Liu, Jung/0009-0009-7109-823X
FU National Science Council in Taiwan, Republic of China
   [NSC99-2410-H-009-053-MY2, NSC101-2410-H-009-006-MY2]
FX This work was supported by the National Science Council in Taiwan,
   Republic of China, under Grant NSC99-2410-H-009-053-MY2 and
   NSC101-2410-H-009-006-MY2.
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   [Anonymous], 2006, TECHNICAL REPORT
   Beegan AP, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P88, DOI 10.1109/DSPWS.2002.1231082
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen J.-J., 2009, Parallel and Distributed Processing Symposium, International, P1, DOI DOI 10.1109/IPDPS.2009.5161024
   Chen PM, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P910, DOI 10.1109/ICOSP.2000.891668
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Huang CH, 2009, IEEE T INF FOREN SEC, V4, P193, DOI 10.1109/TIFS.2009.2020778
   Huang PS, 2005, IEE P-VIS IMAGE SIGN, V152, P561, DOI 10.1049/ip-vis:20041081
   Levicky D, 2004, RADIOENGINEERING, V13, P38
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Pasti L, 1999, CHEMOMETR INTELL LAB, V48, P21, DOI 10.1016/S0169-7439(99)00002-7
   Pei SC, 2006, IEEE T INF FOREN SEC, V1, P543, DOI 10.1109/TIFS.2006.885031
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tsai HH, 2011, PATTERN RECOGN, V44, P751, DOI 10.1016/j.patcog.2010.10.004
   Tsai MJ, 2011, EXPERT SYST APPL, V38, P5748, DOI 10.1016/j.eswa.2010.10.058
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   Tsai MJ, 2010, P ACM MULT 2010 WORK, P19
   VILLASENOR JD, 1995, IEEE T IMAGE PROCESS, V4, P1053, DOI 10.1109/83.403412
   Voloshynovskiy Sviatoslav., 1999, Third International Workshop on Information Hiding, P211
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
NR 31
TC 8
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1311
EP 1340
DI 10.1007/s11042-013-1423-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300014
DA 2024-07-18
ER

PT J
AU Yin, MQ
   Li, SQ
AF Yin, Mingqiang
   Li, Shiqi
TI Fast BVH construction and refit for ray tracing of dynamic scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Animation; Ray tracing; BVHs; Time complexity; Dynamic scenes
AB As the complexity of virtual environments increases, it becomes a critical issue to ray tracing of dynamic scenes interactively. In this paper, we propose an effective method to address this issue. Firstly, we improve the Surface Area Heuristics (SAH) based bounding volume hierarchies (BVHs) construction algorithm and present a sub-interval search criterion for predicting the optimal split plane position. Compared with the standard SAH approach, our algorithm is much faster but has a little quality degradation. Secondly, we present two new BVH refitting operations, which could run fast and obtain considerable quality of BVHs. The two operations are general and applicable to complex and dynamic scenes including a wide range of deformation. Lastly we use multithread to handle the dynamic scenes during animation, one thread for BVHs rebuilding asynchronously, the others for BVHs refitting and ray tracing. The results of this experiment show that our method is effective. Compared with the previous works, it obtains higher and smoother frame rate.
RP Yin, MQ (corresponding author), Huazhong Univ Sci & Technol, 1037 Luoyu Rd, Wuhan 430074, Peoples R China.
EM ymqeml@yahoo.com
FU National High-tech Research & Development Program of China
   [2010AA804022]
FX This research work has been partially supported by National High-tech
   Research & Development Program of China under Grant NO.2010AA804022.
CR Garanzha K, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P123, DOI 10.1109/RT.2008.4634632
   GUI R, 1995, J STAT PLAN INFER, V48, P215, DOI 10.1016/0378-3758(94)00152-L
   Hapala M, 2011, COMPUT GRAPH FORUM, V30, P199, DOI 10.1111/j.1467-8659.2010.01844.x
   Havran V, 2006, IEEE S INT RAY TRAC, V2006, P71
   Hunt W, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P81
   Hurley J, 2011, INT C GRAPH, V2002, P209
   Lauterbach C, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P39
   Pina JL, 2012, MULTIMED TOOLS APPL, V59, P505, DOI 10.1007/s11042-011-0776-3
   MacDonald JD, 1990, VISUAL COMPUT, V6, P152
   Stoll G, 2005, SIGGRAPH 2005 COURS
   Teschner M, 2005, COMPUT GRAPH FORUM, V24, P61, DOI 10.1111/j.1467-8659.2005.00829.x
   Wachter C, 2006, P 17 EUR S REND, P132
   Wald I, 2008, COMPUT GRAPH-UK, V32, P3, DOI 10.1016/j.cag.2007.11.004
   Wald I, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186650
   Wald I, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P61
   Wald I, 2006, ACM T GRAPHIC, V25, P485, DOI 10.1145/1141911.1141913
   Yoon SE, 2007, P EUR S REND, P31
   Zhao HL, 2011, VISUAL COMPUT, V27, P507, DOI 10.1007/s00371-011-0571-1
   Zhou K., 2010, T VISUALIZATION COMP, V17, P669
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 20
TC 5
Z9 6
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1823
EP 1839
DI 10.1007/s11042-013-1476-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300035
DA 2024-07-18
ER

PT J
AU Zhou, L
   Lu, XB
   Yang, L
AF Zhou, Lu
   Lu, Xiaobo
   Yang, Li
TI A local structure adaptive super-resolution reconstruction method based
   on BTV regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Bilateral Total Variation; Local structure;
   Regularization
ID RESOLUTION IMAGE-RECONSTRUCTION; FRAMES
AB Super-resolution (SR) image reconstruction has been one of the hottest research fields in recent years. The main idea of SR is to utilize complementary information from a set of low resolution (LR) images of the same scene to reconstruct a high-resolution image with more details. Under the framework of the regularization based SR, this paper presents a local structure adaptive BTV regularization based super-resolution reconstruction method to overcome the shortcoming of the Bilateral Total Variation (BTV) super resolution reconstruction model. The proposed method adaptively chooses prior model and regularization parameter according to the local structures. Experimental results show that the proposed method can get better reconstruction results and significantly reduces the manual workload of the regularization parameter selection.
C1 [Zhou, Lu; Lu, Xiaobo; Yang, Li] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2008@yahoo.cn
FU National Natural Science Foundation of China [60972001]; National Key
   Technologies R & D Program of China [2009BAG13A06]
FX This work was supported by National Natural Science Foundation of China
   under grant 60972001 and National Key Technologies R & D Program of
   China under grant 2009BAG13A06.
CR Aguena MLS, 2006, COMPUT VIS IMAGE UND, V102, P178, DOI 10.1016/j.cviu.2006.01.001
   [Anonymous], IMAGING SCI IN PRESS
   Capel D, 2000, INT C PATT RECOG, P600, DOI 10.1109/ICPR.2000.905409
   Chaudhuri S, 2005, IEEE SIGNAL PROC MAG, V22, P16, DOI 10.1109/MSP.2005.1406471
   Fan C, 2006, COMPUTER ENG APPL, V36, P28
   Farsiu S, 2006, IEEE T IMAGE PROCESS, V15, P141, DOI 10.1109/TIP.2005.860336
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Goodman J, 1968, INTRO FOURIER OITICS, V35, P1513
   Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623
   HARRIS JL, 1964, J OPT SOC AM, V54, P931, DOI 10.1364/JOSA.54.000931
   He Y, 2009, IMAGE VISION COMPUT, V27, P364, DOI 10.1016/j.imavis.2008.05.010
   Hong MC, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P474, DOI 10.1109/ICIP.1997.638811
   Hong MC, 1997, P SOC PHOTO-OPT INS, V3024, P1306, DOI 10.1117/12.263211
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Krawczyk-Stando D, 2007, INT J APPL MATH COMP, V17, P157, DOI 10.2478/v10006-007-0014-3
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P1899, DOI 10.1109/TIP.2009.2022440
   Qin FQ, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3091936
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Suresh KV, 2007, IEEE T INTELL TRANSP, V8, P321, DOI 10.1109/TITS.2007.895291
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   Tom BC, 1996, P SOC PHOTO-OPT INS, V2727, P1430, DOI 10.1117/12.233218
   Xie W, 2009, 2009 INTERNATIONAL CONFERENCE ON MEASURING TECHNOLOGY AND MECHATRONICS AUTOMATION, VOL I, P437, DOI 10.1109/ICMTMA.2009.150
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan QQ, 2010, IEEE T IMAGE PROCESS, V19, P3157, DOI 10.1109/TIP.2010.2055571
   Zeng WL, 2012, IEEE T INTELL TRANSP, V13, P828, DOI 10.1109/TITS.2011.2180714
   Zhang X, 2008, LECT NOTES COMPUT SC, V4987, P51
NR 29
TC 11
Z9 15
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1879
EP 1892
DI 10.1007/s11042-012-1311-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000040
DA 2024-07-18
ER

PT J
AU Choi, YH
   Kim, D
   Rho, S
   Hwang, E
AF Choi, Young-Hwan
   Kim, Daehoon
   Rho, Seungmin
   Hwang, Eenjun
TI Converting image to a gateway to an information portal for digital
   signage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital signage; Object recognition; SURF; Local feature; Feature
   descriptor; Steganography; Histogram shifting; Review analyzer
ID SCHEME
AB Digital signage has recently emerged as a new channel for communicating with people in diverse domains such as advertising, shopping mall and public service. In this paper, we propose a novel data fusion method for converting an advertisement image into a gateway to an information portal based on steganography technology for digital signage. We make the information portal very flexible just by changing the link or by organizing the contents dynamically. Typical contents include product information and summary of user evaluation. To implement this scheme, we first register products of interest with their representative features and quick response (QR) code. The representative points are used for detecting products in images and their QR code is embedded into the detected product area using our steganography technique. We implement a prototype system based on our scheme, and show its effectiveness through extensive experiments.
C1 [Choi, Young-Hwan; Kim, Daehoon; Hwang, Eenjun] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Baekseok Univ, Informat & Commun Div, Cheonan, South Korea.
C3 Korea University; Baekseok University
RP Hwang, E (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM work48@korea.ac.kr; kdh812@korea.ac.kr; smrho@bu.ac.kr;
   ehwang04@korea.ac.kr
RI Rho, Seungmin/HTP-6683-2023
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012-0007202]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2012-0007202).
CR Agerri R., 2010, P 7 C INT LANG RES E
   [Anonymous], 2005, P 6 INT C COMP LING
   [Anonymous], 2003, P 12 INT C WORLD WID, DOI DOI 10.1145/775152.775226
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bradley M.M., 1999, PSYCHOLOGY
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Islam MI, 2010, J INF PROCESS SYST, V6, P511, DOI 10.3745/JIPS.2010.6.4.511
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kim D, 2012, ENG APPL ARTIF INTEL, V25, P1373, DOI 10.1016/j.engappai.2012.03.005
   Kudo T, 2004, P 9 C EMP METH NAT L
   Lee W., 2010, VEH TECHN C VTC 2010, P1, DOI DOI 10.1109/VETECS.2010.5493938
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang J., 2010, Patagonia, P26
   Wang Zhi-Hui, 2012, J SYSTEMS S IN PRESS
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yi J., 2003, P 3 IEEE INT C DAT M
NR 24
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 263
EP 278
DI 10.1007/s11042-012-1315-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700015
DA 2024-07-18
ER

PT J
AU Lugmayr, A
   Stockleben, B
   Zou, YN
   Anzenhofer, S
   Jalonen, M
AF Lugmayr, Artur
   Stockleben, Bjoern
   Zou, Yaning
   Anzenhofer, Sonja
   Jalonen, Mika
TI Applying "Design Thinking" in the context of media management education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design thinking; Media management; Innovation management
AB "Design Thinking" - a cross-disciplinary and user centered method - is an approach towards the discovery of solutions and sparks innovative thinking in many ways. It also can be argued, that designers put themselves in the place of the user rather than co-creating with the consumer. Innovation is one of the current keywords across many industries, and many attempt to find new solutions to daily problems. Design Thinking as method allows to understand user needs and understand their principle problems in daily life. The design process uses intensive collaboration in cross-disciplinary settings and is divided into the exploration of the problem space and the solution space to achieve new ways of solving existing problems. Design Thinking has to integrate into the innovation process and into organizational structures right from the beginning. It constitutes a complement to classical analytical processes for problems that require lateral, not linear thinking. This article reviews the practical application of this energetic methodology in the academic context and presents some hands-on examples. The course series has been established by the Entertainment and Media Management Lab. (EMMi Lab.) at the Tampere University of Technology (TUT) and was held in cooperation with students from the University of Tampere (UTA), and the Tampere University of Applied Sciences (TAMK). One course has been held in cooperation with the University of Applied Sciences Magdeburg-Stendal, Germany. This article describes how to train students especially with strong technical background and analytical mind-sets in the development of innovations in the field of media, foster creative thinking, and achieve problem solutions beyond the current state of the art. We present the basic curriculum, course structure, goals & objectives, applied methods, settings, and theoretical aspects of Design Thinking. Our experience and reflections on conducting the courses concludes this article. The article shall be an introductory guide for anyone who intends to organize a similar course in the university context.
C1 [Lugmayr, Artur] Tampere Univ Technol, EMMi Lab, FIN-33101 Tampere, Finland.
   [Stockleben, Bjoern] Magdeburg Stendal Univ Appl Sci, Magdeburg, Germany.
   [Zou, Yaning] Tampere Univ Technol, Dept Commun Engn, FIN-33101 Tampere, Finland.
   [Jalonen, Mika] Tampere Univ Technol, FIN-33101 Tampere, Finland.
   [Anzenhofer, Sonja] Ostfalia Univ Appl Sci, Salzgitter, Germany.
C3 Tampere University; Tampere University; Tampere University
RP Stockleben, B (corresponding author), Magdeburg Stendal Univ Appl Sci, Magdeburg, Germany.
EM lartur@acm.org; bjoern.stockleben@gmail.com; yaning.zou@tut.fi;
   sonja.anzenhofer@gmx.de; mika.jalonen@tut.fi
RI Lugmayr, Artur/AAY-7738-2020; Demir, Fatma/GWZ-5156-2022; Lugmayr,
   Artur/G-4357-2014
OI Lugmayr, Artur/0000-0001-6994-4470
CR Alexander, 1971, DMG NEWSLETTER, V5, P3
   Alexander C, 1964, NOTES SYNTHESIS FORM, V57
   [Anonymous], 1999, MANAG REV
   [Anonymous], 1973, EXPERIENCES VISUAL T
   Asimow Morris., 1962, INTRO DESIGN
   Barab SA, 2004, ANTHROPOL EDUC QUART, V35, P254, DOI 10.1525/aeq.2004.35.2.254
   Bransford J.D., 2000, How People Learn; Brain, Mind, Experience, and School
   BROWN A, 1989, GUIDED COOPERATIVE L, P393
   Brown T., 2010, STANFORD SOCIAL INNO
   Brown T, 2009, HARPERBUSINESS, V31
   Brown T, 2008, HARVARD BUS REV, V86, P84
   Buchanan R, 1992, ENGLISHDESIGN ISSUES, V8, P5
   Buchenau M., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P424, DOI 10.1145/347642.347802
   Buxton B., 2007, SKETCHING USER EXPER
   Domschke M, 2009, 26 ICSID WORLD DES C
   Drucker PF, 2002, HARVARD BUS REV, V80, P95
   Dunne D, ACAD MANAGEMENT LEAR, V5, p[512, 1006]
   Edelman J, 2011, UNDERST INNOV, P61, DOI 10.1007/978-3-642-13757-0_4
   Faste RA, 1994, MECH ENG
   Florida Richard., 2019, RISE CREATIVE CLASS
   Fraser Heather M. A., 2007, Journal of Business Strategy, V28, P68, DOI 10.1108/02756660710760962
   Frederick Mattew., 2007, 101 THINGS I LEARNED
   Holzinger A, 2011, J BIOMED INFORM, V44, P968, DOI 10.1016/j.jbi.2011.07.003
   Hummell L., 2006, The Technology Teacher, V66, P22
   Jaasko V., 2003, Proceedings of 2003 International Conference on Designing Pleasurable Products and Interfaces, P126
   Jones J. C., 1992, DESIGN METHODS, V1
   Jones J-C, 1977, DESIGN METHODS THEOR, V11, P45
   Kim J, 2002, R&D MANAGE, V32, P269, DOI 10.1111/1467-9310.00259
   Lindberg T, 2011, UNDERST INNOV, P3, DOI 10.1007/978-3-642-13757-0_1
   Lugmayr A, 2011, 4 SEM AMB MED EXP SA
   Lugmayr A., 2011, P 15 INT AC MINDTREK, P332, DOI DOI 10.1145/2181037.2181100
   Martin Roger, 2010, Strategy & Leadership, V38, P37, DOI 10.1108/10878571011029046
   Martin R.L, 2009, The design of business: Why design thinking is the next competitive advantage
   Martin RL, 2007, OPPOSABLE MIND SUCCE, V62
   Martin R, 2007, HARVARD BUS REV, V85, P60
   Mattelmaki T., 2002, PDC 2002. Proceedings of the Participatory Design Conference, P266
   Meinel C, 2011, UNDERST INNOV, pXIII
   Moldoveanu M.C., 2008, FUTURE MBA DESIGNING
   Nonaka I, 1995, KNOWLEDGE CREATING C
   Osborn Alex, 2012, Applied imagination-principles and procedures of creative writing
   Owen C., 2007, DESIGN RES Q, V2, P16
   OWEN C.L., 2006, Design thinking: driving innovation
   Pals N, 2008, INT J INNOV MANAG, V12, P275, DOI 10.1142/S1363919608002023
   Piaget J., 1978, Success and understanding
   Pink D. H., 2006, WHOLE NEW MIND WHY R
   Plattner H, 2011, UNDERST INNOV, P1, DOI 10.1007/978-3-642-13757-0
   RITTEL HWJ, 1973, POLICY SCI, V4, P155, DOI 10.1007/BF01405730
   Sato Steve, 2009, Journal of Business Strategy, V30, P40, DOI 10.1108/02756660910942454
   Schon D.A., 1983, The reflective practitioner: How professionals think in action, V1
   Simon HA, 1996, SCI ARTIFICIAL, V4, P3
   Snyder C., 2003, Paper Prototyping: The Fast and Easy Way to Design and Refne User Interfaces, VIllustrated
   Verganti R, 2008, J PROD INNOVAT MANAG, V25, P436, DOI 10.1111/j.1540-5885.2008.00313.x
   Visser F.S., 2008, Proceedings of the Tenth Anniversary Conference on Participatory Design 2008lt;br /gt;, Indiana University, P174
   Vygotsky L, 1986, THOUGHT LANGUAGE, V28
   Wiley J, 1998, MEM COGNITION, V26, P716, DOI 10.3758/BF03211392
   Wright P, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460360
   Zotto C.D., 2008, Management and Innovation in the Media Industry
NR 57
TC 24
Z9 30
U1 2
U2 63
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 1
BP 119
EP 157
DI 10.1007/s11042-013-1361-8
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AK0QX
UT WOS:000338120700007
DA 2024-07-18
ER

PT J
AU Orovic, I
   Orlandic, M
   Stankovic, S
AF Orovic, Irena
   Orlandic, Milica
   Stankovic, Srdjan
TI An image watermarking based on the pdf modeling and quantization effects
   in the wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Wavelet transform; JPEG2000 quantization; Optimal
   detection
ID DIGITAL IMAGE; DCT; FORENSICS; MULTIMEDIA
AB An image watermarking technique based on the concept of JPEG2000 algorithm is proposed. Biorthogonal wavelet 9/7 transform is used to provide a set of coefficients suitable for watermark embedding. The statistical properties of different subbands are analyzed in order to choose the number of decomposition levels and position of subbands, which will assure the best compromise between the watermark transparency and robustness. The JPEG2000 quantization is applied to avoid insignificant wavelet coefficients, while the remaining ones are used for watermarking. The optimal and blind watermark detection is based on the nonlinear score function and appropriate model of coefficients distribution. The performance of the proposed procedure is tested on examples with various images, showing robustness under different attacks, while maintaining high image quality.
C1 [Orovic, Irena; Orlandic, Milica; Stankovic, Srdjan] Univ Montenegro, Fac Elect Engn, Podgorica, Montenegro.
C3 University of Montenegro
RP Orovic, I (corresponding author), Univ Montenegro, Fac Elect Engn, Podgorica, Montenegro.
EM irenao@ac.me; milica@ac.me; srdjan@ac.me
RI Orlandic, Milica/P-6563-2019; Orovic, Irena/U-9175-2018; Stankovic,
   Srdjan/AAH-2804-2019
OI Orovic, Irena/0000-0002-1752-9053; Stankovic,
   Srdjan/0000-0002-4795-494X; Orlandic, Milica/0000-0002-6304-1999
CR Agreste S, 2007, J COMPUT APPL MATH, V210, P13, DOI 10.1016/j.cam.2006.10.087
   [Anonymous], 1992, REGIONAL C SERIES AP
   [Anonymous], 2000, Digital Watermarking
   Battiato S, 2012, IEEE MULTIMEDIA, V19, P17, DOI 10.1109/MMUL.2012.10
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Briassouli A, 2004, IEEE T IMAGE PROCESS, V13, P1604, DOI 10.1109/TIP.2004.837516
   Brown CL, 2000, IEEE T SIGNAL PROCES, V48, P2665, DOI 10.1109/78.863074
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Cox I. J., 2002, Digital Watermarking
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Dia D, 2009, P WORLD C ENG 2009 W, V1
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Joo S, 2002, ETRI J, V24, P401, DOI 10.4218/etrij.02.0202.0502
   Kwitt R., 2009, 17 EUR SIGN PROC C G, P2072
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P460, DOI 10.1109/TIFS.2009.2024715
   Marcellin MW, 2002, SIGNAL PROCESS-IMAGE, V17, P73, DOI 10.1016/S0923-5965(01)00027-3
   Meerwald P, 2001, P SPIE EL IM SEC WAT, V4314, P501
   MEHUL R, 2003, P IEEE REG 10 TECHN
   Mukherjee J, 2004, ICVGIP 2004 KOLK, P320
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Orlandic M, 2009, 53 ETRAN C VRNJACK B
   Seo YH, 2010, J ELECTR COMPUT ENG, V2010, DOI 10.1155/2010/348321
   Seo YS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P530, DOI 10.1109/ICIP.2001.958545
   Stankovic S, 2003, AEU-INT J ELECTRON C, V57, P355, DOI 10.1078/1434-8411-54100185
   Stankovic S, 2001, IEEE T IMAGE PROCESS, V10, P650, DOI 10.1109/83.913599
   Stankovic S, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2981832
   Tay PC, 2005, IEEE INT C IM PROC I, pI
   Vahedi E, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P641
   Vahedi E, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P635
   Veeraswamy K, 2008, INT J COMPUT SCI NET, V8, P170
   Wickens T.D, 2010, Elementary signal detection theory
   Zhou L, 2011, IEEE J SEL AREA COMM, V29, P1358, DOI 10.1109/JSAC.2011.110803
NR 34
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1503
EP 1519
DI 10.1007/s11042-012-1182-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500007
DA 2024-07-18
ER

PT J
AU Kovachev, D
   Cao, YW
   Klamma, R
AF Kovachev, Dejan
   Cao, Yiwei
   Klamma, Ralf
TI Building mobile multimedia services: a hybrid cloud computing approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile multimedia; Cloud computing; Multimedia metadata; XMPP
AB Mobile multimedia services are in high demand, but their development comes at high costs. The emergent computing paradigm cloud computing has great potential to embrace these issues. In fact, we are at the early stage of the coalescence of cloud computing, mobile multimedia and the Web. Motivated by the tremendous success story of the Web based on its simplicity principles, we argue for a comprehensive review on current practices of web and mobile multimedia cloud computing techniques for avoiding frictions. We draw on experience from the development of advanced collaborative multimedia web applications utilizing multimedia metadata standards like MPEG-7 and real-time communication protocols like XMPP. We propose our i5CLoud, a hybrid cloud architecture, which serves as a substrate for scalable and fast time-to-market mobile multimedia services. This paper demonstrates the applicability of emerging cloud computing concepts for mobile multimedia.
C1 [Kovachev, Dejan; Cao, Yiwei; Klamma, Ralf] Rhein Westfal TH Aachen, D-52056 Aachen, Germany.
C3 RWTH Aachen University
RP Kovachev, D (corresponding author), Rhein Westfal TH Aachen, Ahornstr 55, D-52056 Aachen, Germany.
EM kovachev@dbis.rwth-aachen.de; cao@dbis.rwth-aachen.de;
   klamma@dbis.rwth-aachen.de
RI Klamma, Ralf/K-5908-2016
OI Klamma, Ralf/0000-0002-2296-3401
FU Excellence Initiative of German National Science Foundation (DFG) within
   the research cluster Ultra High-Speed Mobile Information and
   Communication (UMIC); NRW State within the B-IT Research School
FX This work is supported by the Excellence Initiative of German National
   Science Foundation (DFG) within the research cluster Ultra High-Speed
   Mobile Information and Communication (UMIC) and in part by NRW State
   within the B-IT Research School. We thank Gokhan Aksakalli and Michael
   Lottko for their prototype implementations.
CR Almeida M., 2010, P 6 INT MOB MULT COM, V10
   [Anonymous], J UCS J UNIVERSAL CO
   [Anonymous], 2011, C INN DAT SYST RES C
   [Anonymous], 2010, PROC 8 INT C MOBILE, DOI [DOI 10.1145/1814433, 10.1145/1814433.1814441, DOI 10.1145/1814433.1814441]
   [Anonymous], 2011, HTML5 VOCABULARY ASS
   Armbrust M., 2009, P 4 BIENN C INN DAT
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Cao Y, 2009, P 10 MULT MET COMM W, V539
   Cao Y, 2009, CEUR WS, V441
   Cao YW, 2010, COMPUT SYST SCI ENG, V25, P251
   Cao YW, 2009, MDM: 2009 10TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT, P102, DOI 10.1109/MDM.2009.21
   Cao Y, 2010, PROCEEDINGS OF THE 2010 COMPUTING FRONTIERS CONFERENCE (CF 2010), P1, DOI 10.1145/1787275.1787277
   Cervino J., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P356, DOI 10.1109/CLOUD.2011.52
   Chang F, 2008, ACM T COMPUT SYST, V26, DOI 10.1145/1365815.1365816
   Chun BG, 2009, P 12 WORKSH  HOT TOP
   Cisco Systems, 2012, 102290212 FLGD CISC
   Dean Jeffrey, 2004, OSDI 04, P10
   Dodson B, 2010, JUNCTION PROTOCOL AD
   Fitzpatrick B, 2007, PREFECT POLICE F PEC
   Garcia A., 2010, Proc. ACM Multimedia Workshop on Mobile Cloud Media Computing (MCMC), P13, DOI DOI 10.1145/1877953.1877959
   Gerlicher ARS, 2007, THESIS U ARTS LONDON
   Gilbert S, 2002, ACM SIGACT NEWS  JUN
   Grigoras R, 2009, P 9 WORKSH MULT MET, V441
   Gustedt J, 2009, PARALLEL PROCESS LET, V19, P399, DOI 10.1142/S0129626409000304
   Hornsby A., 2010, P 14 IEEE INT S CONS
   Kemp R, 2010, P 2 INT ICST C MOB C
   Klamma Ralf, 2008, UPGRADE: The European Journal for the Informatics Professional, V9, P37
   Kosch H., 2003, DISTRIBUTED MULTIMED
   Kovachev D., 2010, P 1 INT WORKSH MOB C
   Kovachev D., 2011, ARXIV11074940
   Kovachev D, 2010, P INT WORKSH MOB COM
   Kristensen MD, 2010, THESIS AARHUS U DENM
   Kumar K, 2010, COMPUTER, V43, P51, DOI 10.1109/MC.2010.98
   Lagesse B. J., 2011, P 1 IEEE PERCOM WORK
   Manyika J, 2011, D91 SECURESCM
   Muldowney T., 2004, XEP 0096 SI FILE TRA
   Ou S, 2007, PERVASIVE MOB COMPUT, V3, P362, DOI 10.1016/j.pmcj.2007.04.004
   Pajak D, 2011, COMPUT GRAPH FORUM, V30, P415, DOI 10.1111/j.1467-8659.2011.01871.x
   Parkvall S, 2011, IEEE COMMUN MAG, V49, P84, DOI 10.1109/MCOM.2011.5706315
   Pearson S, 2009, CLOUD: 2009 ICSE WORKSHOP ON SOFTWARE ENGINEERING CHALLENGES OF CLOUD COMPUTING, P44, DOI 10.1109/CLOUD.2009.5071532
   Pew Research Center, 2010, FUT CLOUD COMP
   Realtime I, 2011, OPENFIRE XMPP SERVER
   Saint-Andre P., 2008, XEP 0045 MULTIUSER C
   Saint-Andre Peter., 2009, XMPP: The Definitive Guide
   Satyanarayanan M, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.82
   Schuster Daniel, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P232, DOI 10.1109/PERCOMW.2010.5470662
   Sun C., 1998, ACM 1998 Conference on Computer Supported Cooperative Work. Proceedings. CSCW 98, P59, DOI 10.1145/289444.289469
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Voigt M, 2009, THESIS U APPL SCI ER
   W3C Video on the Web Activity, 2011, ONT MED RES  1 0
   Wagener J, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-279
   Wenger E., 2009, COMMUNITIES PRACTICE
   Zhang XW, 2011, MOBILE NETW APPL, V16, P270, DOI 10.1007/s11036-011-0305-7
NR 54
TC 17
Z9 17
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 977
EP 1005
DI 10.1007/s11042-012-1100-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900018
DA 2024-07-18
ER

PT J
AU Yang, CL
   Peng, JY
   Feng, XY
   Fan, JP
AF Yang, Chunlei
   Peng, Jinye
   Feng, Xiaoyi
   Fan, Jianping
TI Integrating bilingual search results for automatic junk image filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Junk image filtering; Bilingual image search; Inter-cluster correlation
   analysis
ID RELEVANCE-FEEDBACK; RETRIEVAL
AB Keyword-based image search engines are now very popular for accessing large amounts of Web images on the Internet. Most existing keyword-based image search engines may return large amounts of junk images (which are irrelevant to the given query word), because the text terms that are loosely associated with the Web images are also used for image indexing. The objective of the proposed work is to effectively filter out the junk images from image search results. Therefore, bilingual image search results for the same keyword-based query are integrated to identify the clusters of the junk images and the clusters of the relevant images. Within relevant image clusters, the results are further refined by removing the duplications under a coarse-to-fine structure. Experiments for a large number of bilingual keyword-based queries (5,000 query words) are simultaneously performed on two keyword-based image search engines (Google Images in English and Baidu Images in Chinese), and our experimental results have shown that integrating bilingual image search results can filter out the junk images effectively.
C1 [Yang, Chunlei; Fan, Jianping] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Peng, Jinye; Feng, Xiaoyi] Northwestern Polytech Univ, Xian 710072, Peoples R China.
C3 University of North Carolina; University of North Carolina Charlotte;
   Northwestern Polytechnical University
RP Yang, CL (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM cyang36@uncc.edu; jinyepeng@nwpu.edu.cn; xyfeng@nwpu.edu.cn;
   jfan@uncc.edu
RI Peng, Jin/HZH-6965-2023
FU Program for New Century Excellent Talents in University [NCET-07-0693,
   NCET-08-0458, NCET-10-0071]; Research Fund for the Doctoral Program of
   Higher Education of China [20096102110025];  [NSFC-61075014]; 
   [NSFC-60875016]
FX This work is partly supported by NSFC-61075014 and NSFC-60875016, by the
   Program for New Century Excellent Talents in University under Grant
   NCET-07-0693, NCET-08-0458 and NCET-10-0071 and the Research Fund for
   the Doctoral Program of Higher Education of China (Grant
   No.20096102110025).
CR [Anonymous], CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], P PCM
   [Anonymous], WWW
   [Anonymous], ACM MULT WORKSH LARG
   [Anonymous], IEEE CVPR
   [Anonymous], CVPR
   [Anonymous], ACM MM
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2001, ICDM
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], ACM MULT
   [Anonymous], IEEE ICME
   [Anonymous], P INT C MULT MM 10 A
   [Anonymous], P ECCV HER CRET GREE
   [Anonymous], P IEEE CVPR
   Barnard K, 2001, PROC CVPR IEEE, P434
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Feng S.L., 2004, IEEE CVPR
   Gao Bin., 2005, ACM MULTIMEDIA
   Gao Y, 2008, LECT NOTES COMPUT SC, V4903, P1
   Jiang Y.-G., 2007, ACM CIVR
   Ke Y., 2004, ACM Multimedia
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Loeff N., 2006, P COLINGACL, P547
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Zhang Dong-Qing., 2004, ACM MULTIMEDIA
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou XS, 2001, PROC CVPR IEEE, P11
NR 38
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 661
EP 688
DI 10.1007/s11042-012-1051-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900005
DA 2024-07-18
ER

PT J
AU Yan, YJ
   Liang, XH
   Xie, K
   Zhao, QP
AF Yan, Yajie
   Liang, Xiaohui
   Xie, Ke
   Zhao, Qinping
TI ASEHM: a new transmission control mechanism for remote rendering system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile applications; 3D digital models; Remote rendering systems
ID MOBILE DEVICES
AB Digital 3D models have emerged as a new type of multimedia following sound, image and video. This media type has been distributed and processed widely on desktop PCs. However, processing 3D models on mobile devices is more difficult, mainly due to their physical constraints. Though the remote rendering framework is able to make up for some deficiencies, previous methods based on this framework suffered from high transmission frequency, which just imposes a high power demand on mobile devices' already limited battery life. In this paper, a new transmission control method, Adaptive Splitting and Error Handling Mechanism, is proposed to be integrated with canonical remote rendering system. Our mechanism is able to reduce transmission frequency by trading transmission with splitting operations. According to relevant research findings, reducing frequency will result in a decline in power consumption. Finally, the effectiveness of our method in terms of frequency reduction is validated by comparison with state of the art method.
C1 [Yan, Yajie] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Liang, Xiaohui; Xie, Ke; Zhao, Qinping] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Liang, XH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM yanyajie@vrlab.buaa.edu.cn; lxh@vrlab.buaa.edu.cn;
   xieke@vrlab.buaa.edu.cn; zhaoqp@vrlab.buaa.edu.cn
RI Yan, Yajie/ABP-7888-2022
OI Yan, Yajie/0000-0002-2508-850X; liang, xiaohui/0000-0001-6351-2538
FU Natural Science Foundation of China [61170186]; Beijing Natural Science
   Foundation [4112032]
FX This research was supported by the Natural Science Foundation of China
   (Grant No. 61170186) and the Beijing Natural Science Foundation
   (Researches on Human Body Segmentation Methods in Natural Environment
   based on Computer Vision, Grant No. 4112032).
CR [Anonymous], P EUR WIR
   Duguet F, 2004, IEEE COMPUT GRAPH, V24, P57, DOI 10.1109/MCG.2004.5
   Engel K, 2000, P VIS 2000 OCT
   Feeney LM, 2001, IEEE INFOCOM SER, P1548, DOI 10.1109/INFCOM.2001.916651
   He Z., 2009, P COMP GRAPH INT 200, P45, DOI DOI 10.1145/1629739.1629745
   He ZY, 2004, P ACM 5 C VIRT REAL, DOI [10.1145/1294685.1294687, DOI 10.1145/1294685.1294687]
   Hildebrandt D, 2011, P 2 INT C COMP GEOSP
   Huang JS, 2007, IEEE COMPUT GRAPH, V27, P48, DOI 10.1109/MCG.2007.63
   Kalaiah A, 2005, ACM T GRAPHIC, V24, P348, DOI 10.1145/1061347.1061356
   Lamberti F, 2007, IEEE T VIS COMPUT GR, V13, P247, DOI 10.1109/TVCG.2007.29
   Liang XH, 2009, SCI CHINA SER F, V52, P1335, DOI 10.1007/s11432-009-0144-3
   [刘瑞芳 LIU Rui-fang], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P346
   Noimark Y, 2003, IEEE COMPUT GRAPH, V23, P58, DOI 10.1109/MCG.2003.1159614
   Paravati G, 2010, IEEE T CONSUM ELECTR, V56, P190, DOI 10.1109/TCE.2010.5439144
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Shi WD, 2003, SEVENTEENTH WORKSHOP ON PARALLEL AND DISTRIBUTED SIMULATION (PADS 2003), PROCEEDINGS, P181, DOI 10.1109/PADS.2003.1207434
   SIMUNIC T, 2000, P 6 ANN INT C MOB CO, P11, DOI DOI 10.1145/345910.345914
   Teler E, 2001, COMPUT GRAPH FORUM, V20, pC17, DOI 10.1111/1467-8659.00494
   Yang BL, 2008, J COMPUT SCI TECH-CH, V23, P1015, DOI 10.1007/s11390-008-9195-y
NR 19
TC 1
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 585
EP 603
DI 10.1007/s11042-012-1116-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300002
DA 2024-07-18
ER

PT J
AU Gu, HZ
   Lee, SY
AF Gu, Hui-Zhen
   Lee, Suh-Yin
TI A view-invariant and anti-reflection algorithm for car body extraction
   and color classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View-invariant; Light reflection; Tri-state architecture; Image
   segmentation; Car body extraction; Color classification
AB This study proposes an intelligent algorithm with tri-state architecture for real-time car body extraction and color classification. The algorithm is capable of managing both the difficulties of viewpoint and light reflection. Because the influence of light reflection is significantly different on bright, dark, and colored cars, three different strategies are designed for various color categories to acquire a more intact car body. A SARM (Separating and Re-Merging) algorithm is proposed to separate the car body and the background, and recover the entire car body more completely. A robust selection algorithm is also performed to determine the correct color category and car body. Then, the color type of the vehicle is decided only by the pixels in the extracted car body. The experimental results show that the tri-state method can extract almost 90% of car body pixels from a car image. Over 98% of car images are distinguished correctly in their categories, and the average accuracy of the 10-color-type classification is higher than 93%. Furthermore, the computation load of the proposed method is light; therefore it is applicable for real-time systems.
C1 [Gu, Hui-Zhen; Lee, Suh-Yin] Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Gu, HZ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci & Informat Engn, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM hcku@cs.nctu.edu.tw; sylee@cs.nctu.edu.tw
FU National Science Council [NSC98-2221-E-009-091-MY3]
FX This work was partially supported by National Science Council grant
   NSC98-2221-E-009-091-MY3: Multiview multimedia content analysis,
   indexing and query
CR Al Aghbari Z, 2006, IMAGE VISION COMPUT, V24, P894, DOI 10.1016/j.imavis.2006.02.013
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 1992, Computer and Robot Vision, DOI DOI 10.1109/MRA.2011.941638
   Baek N, 2007, COMM COM INF SC, V2, P1133
   Brown Lisa M., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P91, DOI 10.1109/AVSS.2010.59
   Butzke M, 2008, HIFEN, V32
   Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335
   Chen BS, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1276
   Chen ZZ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P214, DOI 10.1109/ICICISYS.2009.5357707
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kim KJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P134, DOI 10.1109/APSCC.2008.207
   Kim S, 2003, LECT NOTES COMPUT SC, V2728, P39
   Lin S, 2002, LECT NOTES COMPUT SC, V2352, P210
   Ohashi T., 2003, Proceedings of the IASTED International Conference on Signal, Processing, Pattern Recognition, and Applications, P17
   Santos D, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P137, DOI 10.1109/WIAMIS.2009.5031451
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Son JW, 2007, ALPIT 2007: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON ADVANCED LANGUAGE PROCESSING AND WEB INFORMATION TECHNOLOGY, P242, DOI 10.1109/ALPIT.2007.28
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Tan RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P870
   Theodoridis S, 2008, PATTERN RECOGN, P119
   Wu YT, 2010, LECT NOTES COMPUT SC, V6297, P369, DOI 10.1007/978-3-642-15702-8_34
   Xiuzhi Li, 2010, 2010 Third International Symposium on Electronic Commerce and Security (ISECS 2010), P189, DOI 10.1109/ISECS.2010.50
   Zhan Xu, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1503, DOI 10.1109/ICISE.2009.1334
   Zhang DS, 2001, CIRC SYST SIGNAL PR, V20, P143, DOI 10.1007/BF01201137
NR 25
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2013
VL 65
IS 3
BP 387
EP 418
DI 10.1007/s11042-012-0996-1
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 144EO
UT WOS:000318922600004
DA 2024-07-18
ER

PT J
AU Cheng, HJ
   Xiong, NX
   Yang, LT
   Chen, GL
   Zhuang, XF
   Lee, C
AF Cheng, Hongju
   Xiong, Naixue
   Yang, Laurence T.
   Chen, Guolong
   Zhuang, Xiaofang
   Lee, Changhoon
TI Links organization for channel assignment in multi-radio wireless mesh
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless mesh networks; Channel assignment; Links organization;
   Distributed algorithm
AB It is one key issue in the wireless mesh networks to provide various scenarios such as multimedia and applications. Links in the network can be organized and assigned to orthogonal channels so as to minimize the co-channel interference. In this paper we focus on the channel assignment problem for links in the mesh networks and aim at minimizing the overall network interference. The problem is proved to be NP-hard. We have first formulated an approach based on the Particle Swarm Optimization (PSO) algorithm which can be used to find the approximate optimized solution in small-size networks and as a baseline that other algorithms can be compared with. We also have proposed a centralized heuristic as well as a distributed heuristic algorithm for the channel assignment problem. Extensive simulation results have demonstrated that our schemes have good performance in both dense and sparse networks compared with related works.
C1 [Cheng, Hongju; Chen, Guolong; Zhuang, Xiaofang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350002, Peoples R China.
   [Xiong, Naixue] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.
   [Yang, Laurence T.] St Francis Xavier Univ, Dept Comp Sci, Antigonish, NS B2G 1C0, Canada.
   [Lee, Changhoon] Hanshin Univ, Sch Comp Engn, Osan, South Korea.
C3 Fuzhou University; University System of Georgia; Georgia State
   University; Saint Francis Xavier University - Canada; Hanshin University
RP Cheng, HJ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350002, Peoples R China.
EM cscheng@fzu.edu.cn; nxiong@gsu.edu; ltyang@stfx.ca; cgl@fzu.edu.cn;
   xiaofangzhuang@126.com; cryptography1@gmail.com
RI xiong, naixue/M-4277-2019; Chen, Guolong/HDM-8516-2022; Laurence T.
   Yang, FCAE/AAA-1898-2019
OI xiong, naixue/0000-0002-0394-4635; Chen, Guolong/0000-0001-6070-3881;
   Laurence T. Yang, FCAE/0000-0002-7986-4244; Lee,
   Changhoon/0000-0003-4292-5792
FU Key Project Development Foundation of Education Committee of China
   [209062]; Key Project Development Foundation of Education Committee of
   Fujian province [JA08002]; Key Project of Fujian Provincial Natural
   Science Foundation of China [A0820002]; Technology Innovation Platform
   Project of Fujian Province [2009 J1007]
FX This work is supported by the Key Project Development Foundation of
   Education Committee of China under Grand No. 209062, the Key Project
   Development Foundation of Education Committee of Fujian province under
   Grand No. JA08002, the Key Project of Fujian Provincial Natural Science
   Foundation of China under Grant No. A0820002, the Technology Innovation
   Platform Project of Fujian Province under Grant No. 2009 J1007.
CR Akyildiz IF, 2005, COMPUT NETWORKS, V47
   [Anonymous], 4 ANN IEEE COMM SOC
   [Anonymous], 2004, P ACM MOBIHOC
   Arora S., 1992, Proceedings 33rd Annual Symposium on Foundations of Computer Science (Cat. No.92CH3188-0), P14, DOI 10.1109/SFCS.1992.267823
   Chandra R., 2004, P IEEE INFOCOM
   Cheng H, 2010, J COMMUN, V5
   Das AK, 2005, IEEE SENCON
   Das AK, 2006, GLOB TELECOMM CONF
   Gupta P., 2000, IEEE T INFO THEORY
   Kennedy J, 1995, P 6 INT S MICR HUM S
   Kyasanur P, 2006, TECHNICAL REPORT
   Mishra A, 2004, ACMIUSENIX INT MEAS
   Ramachandran Krishna N., 2006, P IEEE INFOCOM
   Raniwala A, 2005, IEEE INFOCOM, V3
   Raniwala A., 2004, ACM SIGMOBILE MOBILE, V8
   Sridha S, 2009, P COMM SYST NETW WOR
   SUBRAMANIAN AP, 2005, 13 INT C NETW PROT I
   Tang J, 2005, P ACM MOBIHOC 05
   Wu S.-L., 2000, ISPAN
NR 19
TC 16
Z9 17
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 239
EP 258
DI 10.1007/s11042-011-0800-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100005
DA 2024-07-18
ER

PT J
AU Varalakshmi, LM
   Florence, SG
AF Varalakshmi, L. M.
   Florence, Sudha G.
TI An enhanced encryption algorithm for video based on multiple Huffman
   tables
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Encryption; Multiple Huffman table; XOR; Chosen
   plaintext attack
ID MULTIMEDIA ENCRYPTION
AB Encryption is one of the fundamental technologies that is used in the security of multimedia data. Unlike ordinary computer applications, multimedia applications generate large amount of data that has to be processed in real time. This work investigates the problem of efficient multimedia data encryption. A scheme known as the Randomized Huffman Table scheme was recently proposed to achieve encryption along with compression. Though this scheme has several advantages it cannot overcome the chosen plaintext attack. An enhancement of this Huffman scheme is proposed in this work which essentially overcomes the attack and improves the security. The proposed encryption approach consists of two modules. The first module is the Randomized Huffman Table module, the output of which is fed to the second XOR module to enhance the performance. Security analysis shows that the proposed scheme can withstand the chosen plaintext attack. The efficiency and security of the proposed scheme makes it an ideal choice for real time secure multimedia applications.
C1 [Varalakshmi, L. M.] Sri Manakula Vinayagar Engn Coll, Dept ECE, Pondicherry, India.
   [Florence, Sudha G.] Pondicherry Engn Coll, Dept ECE, Pondicherry, India.
C3 Pondicherry Engineering College
RP Varalakshmi, LM (corresponding author), Sri Manakula Vinayagar Engn Coll, Dept ECE, Pondicherry, India.
EM varalakshmi_1@yahoo.co.in; gfsudha@pec.edu
RI Sudha, Gnanou Florence/GLU-3814-2022
OI Sudha, Gnanou Florence/0000-0002-5471-3255
CR Agi I, 1996, ISOC SNDSS FEB
   Chu HH, 1999, P SOC PHOTO-OPT INS, V3657, P460, DOI 10.1117/12.344696
   *ISO IEC, 2000, 138182 ISOIEC
   Lei Tang, 1996, Proceedings ACM Multimedia 96, P219, DOI 10.1145/244130.244209
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Qiao, 1997, IEEE INT S CONS EL D
   Qiao L, 1995, 1 INT C IM SCI SYST
   SHI C, 1999, P PDPTA 99
   Spanos G. A., 1995, INT C COMP COMM NETW
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Wu CP, 2001, PROC SPIE, V4314, P128, DOI 10.1117/12.435392
   Wu CP, 2001, PROC SPIE, V4209, P284, DOI 10.1117/12.420829
   Xie DH, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/35262
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
NR 15
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2013
VL 64
IS 3
BP 717
EP 729
DI 10.1007/s11042-011-0963-2
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126IV
UT WOS:000317608600010
DA 2024-07-18
ER

PT J
AU Kim, M
   Park, SO
AF Kim, Mucheol
   Park, Sang Oh
TI Group affinity based social trust model for an intelligent movie
   recommender system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networks; Trust management; Recommender systems; Information
   technology
ID NETWORK; EVOLUTION
AB As many researchers have taken an interest in social networks with the development of the user-generated web, trust management and its application have come into the spotlight. User information that is extracted by behavior patterns and user profiles provides the essential relationship between individuals. In this paper, we propose an intelligent movie recommender system with a social trust model. The proposed system is based on a social network for analyzing social relationships between users and generated group affinity values with user profiles. In experiments, the performance of this system is evaluated with precision-recall and F-measures.
C1 [Kim, Mucheol; Park, Sang Oh] Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
   [Kim, Mucheol] Chung Ang Univ, Sch Comp Sci & Engn, E Commerce & Applicat Lab, Seoul 156756, South Korea.
C3 Chung Ang University; Chung Ang University
RP Park, SO (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, 221 Heuk Seok Dong, Seoul 156756, South Korea.
EM mucheol.kim@gmail.com; sj1st@cs.cau.ackr
FU National Research Foundation of Korea(NRF); Ministry of Education,
   Science and Technology [2011-0024052]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology (2011-0024052).
CR Adar E., 2007, Data Engineering Bulletin, V30, P23
   Al Hasan Mohammad, 2006, SDM06 WORKSH LINK AN
   [Anonymous], 2006, Google's PageRank and beyond: The science of search engine rankings
   Bae J, 2009, 5 INT JOINT C INC IM
   Barabási AL, 2002, PHYSICA A, V311, P590, DOI 10.1016/S0378-4371(02)00736-7
   Borgatti SP, 2009, SCIENCE, V323, P892, DOI 10.1126/science.1165821
   Bourqui R, 2009, ADV SOC NETW AN MIN
   Debnath S, 2008, WORLD WID WEB C
   Dorogovtsev SN, 2002, ADV PHYS, V51, P1079, DOI 10.1080/00018730110112519
   Golbeck J, 2006, IEEE CONS COMM NETW
   Golbeck J, 2009, ACM T WEB, V3, DOI 10.1145/1594173.1594174
   Grandison T, 2000, IEEE Communications Surveys Tutorials, V3, P2, DOI [DOI 10.1109/COMST.2000.5340804, 10.1109/COMST.2000.5340804]
   Huang Z, 2004, 10 AM C INF SYST
   Kim M., 2010, J WIRELESS MOBILE NE, V1, P86
   Kim S, 2009, INT WORKSH MACH INT
   Li C, 2002, IEEE T KNOWL DATA EN, V14, P673, DOI 10.1109/TKDE.2002.1019208
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   McCallum A, 2007, J ARTIF INTELL RES, V30, P249, DOI 10.1613/jair.2229
   Mislove A., 2010, P 3 ACM INT C WEB SE, P251, DOI [DOI 10.1145/1718487.1718519, 10.1145/1718487.1718519]
   Monclar RS, 2009, INT C COMP SUPP COOP, P662, DOI 10.1109/CSCWD.2009.4968134
   Rijke M, 2008, LNCS, V4956
   Saito K, 2007, LNAI, V4694
   Singh L, 2007, IEEE INT CONF INF VI, P672
   Staab S, 2005, IEEE INTELL SYST, V20, P80, DOI 10.1109/MIS.2005.16
   Walter FE, 2008, AUTON AGENT MULTI-AG, V16, P57, DOI 10.1007/s10458-007-9021-x
   Yager RR, 2008, INT IEEE C INT SYST
   Yeh C-F, 2007, 2007 WORKSH LARG SCA
   Yoo S, 2009, KDD 09
NR 28
TC 33
Z9 35
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 505
EP 516
DI 10.1007/s11042-011-0897-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200017
DA 2024-07-18
ER

PT J
AU Messina, A
   Montagnuolo, M
   Di Massa, R
   Borgotallo, R
AF Messina, Alberto
   Montagnuolo, Maurizio
   Di Massa, Riccardo
   Borgotallo, Roberto
TI Hyper Media News: a fully automated platform for large scale analysis,
   production and distribution of multimodal news content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hybrid clustering; Hypermedia graph; News story segmentation; Multimedia
   RSS; Topic Detection and Tracking; News recommendation
ID SEGMENTATION
AB This paper describes Hyper Media News (HMNews), a system for the automated aggregation and consumption of information streams from digital television and the Internet. TV newscasts are automatically segmented, annotated and indexed. Such information is then integrated with those available from Internet blogs, newspapers and press agencies. The end result is a set of innovative information services that supplies retrieval, recommendation and browsing of multi-modal news items across different production paradigms, ranging from traditional professional media, e.g. television and press, to new user-centric media platforms such as social networking sites, internet forums and blogs.
C1 [Messina, Alberto; Montagnuolo, Maurizio; Borgotallo, Roberto] RAI Ctr Res & Technol Innovat, I-10135 Turin, Italy.
   [Di Massa, Riccardo] Politecn Torino, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Montagnuolo, M (corresponding author), RAI Ctr Res & Technol Innovat, Corso E Giambone 68, I-10135 Turin, Italy.
EM a.messina@rai.it; maurizio.montagnuolo@rai.it;
   riccardo.dimassa@gmail.com; r.borgotallo@rai.it
OI Messina, Alberto/0000-0002-8262-2449
CR Allan J., 2002, INTRO TOPIC DETECTIO
   Arlandis J, 2005, LECT NOTES COMPUT SC, V3568, P103
   Bailer W, 2005, TECHNICAL REPORT
   Banerjee Somnath, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P787, DOI 10.1145/1277741.1277909
   BASILI R, 2005, P INT SEM WEB C
   Bekkerman R., 2007, P IEEE C COMP VIS PA
   BRUGNARA F, 2000, P RIAO CONT BAS MULT
   Chua T, 2004, P ACM MM 2004
   De Santo M, 2006, LECT NOTES COMPUT SC, V4105, P273
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DELEGLISE P, 2005, P INT 05
   Deschacht K, 2008, P 30 EUR C INF RETR
   Di Iulio M, 2008, INT WORKSHOP DATABAS, P600, DOI 10.1109/DEXA.2008.65
   Domeniconi C, 2007, DATA MIN KNOWL DISC, V14, P63, DOI 10.1007/s10618-006-0060-8
   Domeniconi C, 2011, KNOWL INF SYST, V28, P99, DOI 10.1007/s10115-010-0318-8
   Farrus M, 2007, P INT C ADV BIOM
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Getahun F, 2009, LECT NOTES COMPUT SC, V5648, P442, DOI 10.1007/978-3-642-02818-2_36
   HAUPTMANN AG, 2003, P TRECVID
   Henzinger Monika, 2003, P 12 INT C WORLD WID, P1, DOI DOI 10.1145/775152.775154
   Hoashi K, 2004, TRECVID 2004
   HUANG W, 2004, ACM SIGIR WORKSH INF, P40
   IJntema W., 2010, P 2010 EDBT ICDT WOR, P1
   Kamahara J, 1999, LECT NOTES COMPUT SC, V1554, P221
   Katakis I, 2009, J INTELL INF SYST, V32, P191, DOI 10.1007/s10844-008-0053-8
   KRAAJ W, 2004, TRECVID 2004
   Laudy C., 2008, 11 INT C INF FUS, P1
   Li X., 2007, World Wide Web, P1309
   Liu J, 2010, IUI 2010, P31
   Mahler R., 2007, STAT MULTISOURCE MUL
   Messina A, 2011, P 2 IT INF RETR WORK
   Messina A, 2011, COMPUTATIONAL ANAL M
   Messina A, 2009, P 18 INT WORLD WID W
   MESSINA A, 2008, INT WORKSH IM AN MUL
   Nakamura Yukihiro, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P143, DOI 10.1109/ICCE.2010.5418741
   Nguyen LD, 2008, 11 INT C INF FUS, P1
   O'Connor N, 2001, P INT C IM PROC, P7
   Paliouras G, 2008, STUD COMPUT INTELL, V104, P175
   Pao HT, 2007, INT WORKSH MULT CONT
   Quenot GM, 2004, TRECVID 2004
   Takama Y, 2009, J ADV COMPUT INTELL, V13, P86, DOI 10.20965/jaciii.2009.p0086
   Volkmer T, 2004, TRECVID 2004
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Zhai Y, 2004, TRECVID 2004
NR 45
TC 1
Z9 1
U1 0
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 427
EP 460
DI 10.1007/s11042-011-0859-1
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200007
DA 2024-07-18
ER

PT J
AU Peng, H
   Wang, J
   Zhang, ZL
AF Peng, Hong
   Wang, Jun
   Zhang, Zulin
TI Audio watermarking scheme robust against desynchronization attacks based
   on kernel clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Kernel clustering; Audio features; Desynchronization
   attacks
ID IMAGE; OPTIMIZATION; INFORMATION
AB In this paper, we propose an adaptive audio watermarking scheme based on kernel fuzzy c-means (KFCM) clustering algorithm, which possesses robust ability against common signal processing and desynchronization attacks. The original audio signal is partitioned into audio frames and then each audio frame is further divided as two sub-frames. In order to resist desynchronization attacks, we embed a synchronization code into first sub-frame of each audio frame by using a mean quantization technique in temporal domain. Moreover, watermark signal is hid into DWT coefficients of second sub-frame of each audio frame by using an energy quantization technique. A local audio feature data set extracted from all audio frames is used to train a KFCM. The well-trained KFCM is used to adaptively control quantization steps in above two quantization techniques. The experimental results show the proposed scheme is robust to common signal processing (such as MP3 lossy compression, noise addition, filtering, re-sampling, re-quantizing) and desynchronization attacks (random cropping, pitch shifting, amplitude variation, time-scale modification, jittering).
C1 [Peng, Hong] Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China.
   [Wang, Jun] Xihua Univ, Sch Elect & Informat Engn, Chengdu 610039, Sichuan, Peoples R China.
   [Zhang, Zulin] Sichuan Univ Nationalities, Dept Comp Sci, Kangding 626001, Sichuan, Peoples R China.
C3 Xihua University; Xihua University; Sichuan Minzu College
RP Peng, H (corresponding author), Xihua Univ, Sch Math & Comp Engn, Chengdu 610039, Sichuan, Peoples R China.
EM ph66@tom.com; wangjun@mail.xhu.edu.cn; zhangzl@scun.edu.cn
RI Peng, Hong/C-8705-2012
FU Sichuan Provincial Key Discipline of Power Electronics and Electric
   Drive, Xihua University [SZD0503-09-0]; Foundation of Sichuan Provincial
   Key Discipline of Computer Software and Theory [SZD0802-09-1]; Sichuan
   Key Laboratory of Intelligent Network Information Processing, China
   [SGXZD1002-10]
FX This work was partially supported by Research Fund of Sichuan Provincial
   Key Discipline of Power Electronics and Electric Drive, Xihua University
   (No. SZD0503-09-0), Foundation of Sichuan Provincial Key Discipline of
   Computer Software and Theory (No. SZD0802-09-1), and Research Fund of
   Sichuan Key Laboratory of Intelligent Network Information Processing
   (SGXZD1002-10), China.
CR Chen LH, 2003, IMAGE VISION COMPUT, V21, P717, DOI 10.1016/S0262-8856(03)00067-2
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   Grin L, 2004, IEEE INT C AC SIGN P, P633
   Huang CH, 2000, P SOC PHOTO-OPT INS, V3971, P516, DOI 10.1117/12.385007
   Huang CH, 2009, INFORM SCIENCES, V179, P791, DOI 10.1016/j.ins.2008.10.035
   Ketcham M, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P1235
   Khan A, 2008, PATTERN RECOGN, V41, P2594, DOI 10.1016/j.patcog.2008.01.007
   Khan A, 2006, INT J KNOWL-BASED IN, V10, P337, DOI 10.3233/KES-2006-10502
   Khan A, 2007, INFORM FUSION, V8, P354, DOI 10.1016/j.inffus.2005.09.007
   Kim DW, 2005, PATTERN RECOGN, V38, P607, DOI 10.1016/j.patcog.2004.09.006
   Kirbiz Serap, 2006, P 2006 IEEE INT C AC, V5, P761
   Kumsawat P, 2005, IEEE T SIGNAL PROCES, V53, P4707, DOI 10.1109/TSP.2005.859323
   Lee HS, 2005, ETRI J, V27, P608, DOI 10.4218/etrij.05.0105.0037
   Li W, 2003, COMPUT MUSIC J, V27, P58, DOI 10.1162/014892603322730505
   Liu JW, 2008, FUZZY SET SYST, V159, P2428, DOI 10.1016/j.fss.2008.03.018
   [孟凡满 MENG Fan-Man], 2009, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V22, P312
   Peng H., 2010, J COMPUT INF SYST, V6, P2675
   [彭宏 Peng Hong], 2010, [计算机研究与发展, Journal of Computer Research and Development], V47, P216
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   Vapnik V., 2001, NATURE STAT LEARNING, VSecond
   [王剑 Wang Jian], 2005, [计算机研究与发展, Journal of Computer Research and Development], V42, P1605, DOI 10.1360/crad20050923
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xu XJ, 2007, LECT NOTES ARTIF INT, V4578, P136
   Yang HJ, 2002, INT CONF ACOUST SPEE, P1029
   Yaslan Y, 2008, MULTIMED TOOLS APPL, V40, P1, DOI 10.1007/s11042-007-0182-z
NR 27
TC 7
Z9 8
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 681
EP 699
DI 10.1007/s11042-011-0868-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500007
DA 2024-07-18
ER

PT J
AU Yamabe, T
   Nakajima, T
AF Yamabe, Tetsuo
   Nakajima, Tatsuo
TI Playful training with augmented reality games: case studies towards
   reality-oriented system design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Gamification; Tangible interaction; Training support;
   Design guideline
AB In this paper, we propose a reality-oriented augmentation approach to support training activities. The approach aims at adding new value and playful features to traditional training environments with keeping their original look-and-feel. For example, a game monitoring service enables to automatically record game events so that players can review a gaming process and strategy for soul-searching, or replay most impressive scenes to share the experience with others after the game finishes. Even several services are running on background, digital devices and services are seamlessly integrated to the game environment in unobtrusive way so that players can concentrate on training as usual. The concept can be applied to both traditional games (e. g., poker and the game of Go) and non-gaming activities (e. g., calligraphy and drumming). We developed four case studies on the concept: Augmented Reality Go, EmoPoker, Augmented Calligraphy and AR Drum Kit. We discuss design issues in the reality-oriented augmentation process based on user study results.
C1 [Yamabe, Tetsuo; Nakajima, Tatsuo] Waseda Univ, Fac Sci & Engn 63 505, Shinjuku Ku, Tokyo, Japan.
   [Yamabe, Tetsuo] Waseda Univ, Distributed & Ubiquitous Comp Lab DCL, Ambient Intelligence Grp, Tokyo, Japan.
C3 Waseda University; Waseda University
RP Yamabe, T (corresponding author), Waseda Univ, Fac Sci & Engn 63 505, Shinjuku Ku, 3-4-1 Okubo, Tokyo, Japan.
EM yamabe@dcl.info.waseda.ac.jp; tatsuo@dcl.info.waseda.ac.jp
CR Al-Shihabi T, 2001, P 5 INT C AUT AG AGE
   [Anonymous], 2009, P 4 INT C PERS TECHN, DOI DOI 10.1145/1541948.1541984
   [Anonymous], P 8 ACM C DES INT SY
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bouchner P., 2011, P 2 INT C CIRC SYST
   Cao Y., 2010, P 2 INT C AUT US INT
   Cooper N, 2004, ACE 04
   Egglestone SR, 2011, LECT NOTES COMPUT SC, V6946, P452, DOI 10.1007/978-3-642-23774-4_38
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Floerkemeier C., 2006, P 3 INT WORKSH PERV, P27
   Froehlich P, 2010, P 1 AUGM HUM INT C A
   GORRY GA, 1971, SLOAN MANAGE REV, V13, P55
   Hetzner S, 2011, LECT NOTES COMPUT SC, V6964, P166, DOI 10.1007/978-3-642-23985-4_14
   Hinske S., 2009, Proceedings of the 3rd International Conference on Tangible and Embedded Interaction, P99, DOI DOI 10.1145/1517664.1517691
   Holland S., 2010, TEI 10
   Huang K., 2008, ISWC 08
   Iimura T, 2002, MILLENN FILM J, V38, P51
   Ishii H., 1999, CHI'99 Proceedings, P394, DOI [10.1145/ 302979.303115, DOI 10.1145/302979.303115]
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   Kallinen K., 2009, IADIS INT C ENT TECH, P35
   Kim S, 2011, P 2011 ANN C HUM FAC
   Kuei-Fang Hsiao, 2011, Edutainment Technologies. Educational Games and Virtual Reality/Augmented Reality Applications. Proceedings 6th International Conference on E-learning and Games, Edutainment 2011, P2, DOI 10.1007/978-3-642-23456-9_2
   Lam H, 2008, IEEE T VIS COMPUT GR, V14, P1149, DOI 10.1109/TVCG.2008.109
   Lee M, 2009, P 8 INT C VIRT REAL
   Lee S, 2011, P 2011 ANN C HUM FAC
   Liu Y, 2011, ACM SPRINGE IN PRESS
   Magerkurth C., 2005, Computer in Entertainment (CIE), V3, P4
   Medenica Z., 2011, P 13 INT C HUM COMP
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Motokawa Yoichi, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P243, DOI 10.1109/ISMAR.2006.297825
   Nacke L, 2008, P 2 INT C FUN GAM
   Nakajima T., 2011, PERS UBIQUIT COMPUT, P1
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Olstam JJ, 2008, ACM T MODEL COMPUT S, V18, DOI 10.1145/1371574.1371575
   Power D. J, 2008, HDB DECISION SUPPORT, V1, P121, DOI [DOI 10.1007/978-3-540-48713-5_7, 10.1007/978-3-540-48713-5_7]
   RASMUSSEN J, 1983, IEEE T SYST MAN CYB, V13, P257, DOI 10.1109/TSMC.1983.6313160
   Sadakata M, 2008, J NEW MUSIC RES, V37, P207, DOI 10.1080/09298210802322401
   Schwarz N, 2000, COGNITION EMOTION, V14, P433, DOI 10.1080/026999300402745
   Shirazi A.S., 2009, P 11 INT C HUM COMP, P1
   Soga Masato, 2011, Knowledge-Based and Intelligent Information and Engineering Systems. Proceedings 15th International Conference (KES 2011), P40, DOI 10.1007/978-3-642-23854-3_5
   Varoudis T, 2011, P 13 IFIP TC 13 INT
   Wilfinger D, 2010, P 2 INT C AUT US INT
NR 42
TC 46
Z9 48
U1 1
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 1
BP 259
EP 286
DI 10.1007/s11042-011-0979-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OL
UT WOS:000313965800012
DA 2024-07-18
ER

PT J
AU Amirante, A
   Castaldi, T
   Miniero, L
   Presta, R
   Romano, SP
AF Amirante, Alessandro
   Castaldi, Tobia
   Miniero, Lorenzo
   Presta, Roberta
   Romano, Simon Pietro
TI Standard multimedia conferencing in the wild: the Meetecho architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conferencing; Multimedia; IETF
ID FRAMEWORK
AB We present a conferencing architecture called Meetecho. To the purpose, we embrace an engineering approach, by describing an actual implementation of an open source centralized video-conferencing system capable to offer advanced communication experience to end-users through the effective exploitation of mechanisms like session management and floor control. Meetecho has been designed to be fully compliant with the latest standard proposals coming from both the IETF and the 3GPP and can be considered as an outstanding example of a real-time application built on top of the grounds paved by the SIP protocol. We will discuss both the design of the overall conferencing framework and the most important issues we had to face during the implementation phase.
C1 [Amirante, Alessandro; Castaldi, Tobia; Miniero, Lorenzo] Meetecho Srl, I-80121 Naples, Italy.
   [Presta, Roberta; Romano, Simon Pietro] Univ Naples Federico II, I-80125 Naples, Italy.
C3 University of Naples Federico II
RP Amirante, A (corresponding author), Meetecho Srl, Via C Poerio 89-A, I-80121 Naples, Italy.
EM alessandro.amirante@unina.it; tobia@meetecho.com; lorenzo@meetecho.com;
   roberta.presta@unina.it; spromano@unina.it
RI Romano, Simon Pietro/R-5244-2016; PRESTA, Roberta/KGL-8348-2024
OI PRESTA, Roberta/0000-0003-3439-3503; Romano, Simon
   Pietro/0000-0002-5876-0382
FU Telecom Italia within the Working Capital initiative
FX The Meetecho project is supported by Telecom Italia within the Working
   Capital initiative.
CR 3GPP2, 2007, TECHNICAL REPORT
   Amirante A, 2008, LECT NOTES COMPUT SC, V5310, P174
   Amirante A, 2007, P 1 INT C PRINC SYST
   Amirante A, 2010, LECT NOTES COMPUT SC, V6157, P63, DOI 10.1007/978-3-642-13789-1_7
   [Anonymous], 2002, RFC3261
   Ayars J, 2004, SYNCHR MULT INT LANG
   Barnes M, 2010, P 4 INT C PRINC SYST
   BARNES M, 2008, RFC5239
   Barnes M, 2011, CENTRALIZED IN PRESS
   Buono A, 2007, IEEE COMMUN MAG, V45, P152, DOI 10.1109/MCOM.2007.344597
   CAMARILLO G, 2006, RFC4582
   Camarillo G, 2006, RFC4583
   MELANCHUK T, 2009, RFC5567
   Novo O., 2011, C INFORM DA IN PRESS
   POSTEL J., 1985, RFC959
   Romano SP, 2011, FRAMEWORK DISTRIBUTE
   Romano SP, 2011, REQUIREMENTS DISTRIB
   Romano SP, 2011, REQUIREMENTS XCON DC
   Saint-Andre P., 2004, RFC3920
NR 19
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2012
VL 61
IS 3
BP 703
EP 720
DI 10.1007/s11042-011-0876-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 021CA
UT WOS:000309861700010
DA 2024-07-18
ER

PT J
AU Park, KH
   Ju, WK
   Kim, YH
AF Park, Ki-Hong
   Ju, Won-Ki
   Kim, Yoon-Ho
TI Implementation of MAC-based RTL module for Inverse DCT in H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Functional Unit; FPGA; H.264/AVC; Inverse DCT
AB In this paper, we implemented the MAC-based RTL module for inverse DCT in H.264/AVC to improve applicability, to reduce processing time and utilize resources. The paper highlights design of FU architecture, its interconnection topology, regular formula of inverse DCT and array processor mapping as well as MAC-based RTL module constructing. Multi-directional FUA and FPGA were presented along with an evaluated performance and simulation result. Hence, the paper encompasses design of single FU that was verified with the performance test at maximum frequency 200 MHz; the designed 4-by-4 FUA operates over 100 MHz. The proposed multi-directional FU can be extended to n-by-n FUA that functionality can be extended to next video coding standard (H.265/HEVC).
C1 [Kim, Yoon-Ho] Mokwon Univ, Dept Comp Engn, Taejon, South Korea.
   [Ju, Won-Ki] Mokwon Univ, Sch IT Engn, Taejon, South Korea.
C3 Mokwon University; Mokwon University
RP Kim, YH (corresponding author), Mokwon Univ, Dept Comp Engn, Taejon, South Korea.
EM khpark@mokwon.ac.kr; wkju@mokwon.ac.kr; yhkim@mokwon.ac.kr
CR [Anonymous], REF SOFTW
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2002, JVTF100
   HALLAPURO A, 2002, JVTB038
   ITU-T, 2010, DOC 1 M JCT VC DRESD
   *JVT, 2003, JVTG050
   Kordasiewicz RC, 2005, IEEE INT C IM PROC I, P1020
   Lee JS, 2001, SIPS 2001: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P80
   Richardson IEG, 2004, H 264 MPEG 4 PART 10
   Texas Instruments, 2008, SPRU610C TEX INSTR
   Texas Instruments, 2006, SPRUEB9 TEX INSTR
   Xilinx Co. doc, 2007, VERTEX4 FAM OV
NR 12
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 213
EP 224
DI 10.1007/s11042-011-0747-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000013
DA 2024-07-18
ER

PT J
AU Park, TJ
   Kim, JK
   Choy, YC
AF Park, Tae-Jin
   Kim, Jae-Kyung
   Choy, Yoon-Chul
TI Creating a clickable TV program by sketching and tracking freeform
   triggers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clickable TV program; Digital data broadcasting; Sketching interface;
   Trigger generation
AB Viewers watching Interactive TV can click on video objects on the screen, connecting them to an advertisement or more detailed content. But this requires an interactive authoring process to attach triggers to clickable objects, which is time-consuming because these objects can appear intermittently, move, and change shape. We facilitate authoring by combining a sketching interface with shot-based object tracking and trigger verification. Experiments involving professional video authors and non-specialist viewers suggest that this approach is an improvement on previous methods.
C1 [Park, Tae-Jin; Kim, Jae-Kyung; Choy, Yoon-Chul] Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
C3 Yonsei University
RP Kim, JK (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul 120749, South Korea.
EM parktj2003@gmail.com; imtc2003@gmail.com; ycchoy@rainbow.yonsei.ac.kr
CR [Anonymous], 1998, Intel Technology Journal, DOI DOI 10.1109/ACV.1998.732882
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Cattelan RG, 2008, ACM T MULTIM COMPUT, V4
   Cesar P, 2009, ACM T MULTIM COMPUT, V5
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Finke M, 2004, COMPUT GRAPH-UK, V28, P179, DOI 10.1016/j.cag.2003.12.005
   Frank S, 2008, ACM T MULTIM COMPUT, V5
   Goldman DB, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P3, DOI 10.1145/1449715.1449719
   HERSHBERGER J, 1992, PROCEEDINGS : 5TH INTERNATIONAL SYMPOSIUM ON SPATIAL DATA HANDLING, VOLS 1 AND 2, P134
   IBM MPEG-4 Technologies, IBM MPEG 4 XMT ED TO
   Lombard M., 2001, J INTERACTIVE ADVERT, V1
   Luo HT, 2002, SIGNAL PROCESS-IMAGE, V17, P559, DOI 10.1016/S0923-5965(02)00036-X
   McGuffin M, 2002, PROC GRAPH INTERF, P35
   Neuschmied Helmut., 2007, MULTIMEDIA'07: Proceedings of the 15th international conference on Multimedia, P158
   Ramos G., 2003, Proceedings of the UIST '03 Symposium on User Interface Software and Technology, P105, DOI DOI 10.1145/964696.964708
   Shneiderman B, 2000, IEEE INFOR VIS, P88, DOI 10.1109/IV.2000.859742
   Trichet R, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P989, DOI 10.1109/ICME.2006.262699
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu-Jin Z., 2006, ADV IMAGE VIDEO SEGM
NR 19
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 833
EP 850
DI 10.1007/s11042-011-0773-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900005
DA 2024-07-18
ER

PT J
AU Mannens, E
   Van Deursen, D
   Troncy, R
   Pfeiffer, S
   Parker, C
   Lafon, Y
   Jansen, J
   Hausenblas, M
   Van de Walle, R
AF Mannens, Erik
   Van Deursen, Davy
   Troncy, Raphael
   Pfeiffer, Silvia
   Parker, Conrad
   Lafon, Yves
   Jansen, Jack
   Hausenblas, Michael
   Van de Walle, Rik
TI A URI-based approach for addressing fragments of media resources on the
   Web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media fragments; W3C standardisation; HTML5
ID H.264/AVC
AB To make media resources a prime citizen on the Web, we have to go beyond simply replicating digital media files. The Web is based on hyperlinks between Web resources, and that includes hyperlinking out of resources (e.g., from a word or an image within a Web page) as well as hyperlinking into resources (e.g., fragment URIs into Web pages). To turn video and audio into hypervideo and hyperaudio, we need to enable hyperlinking into and out of them. The W3C Media Fragments Working Group is taking on the challenge to further embrace W3C's mission to lead the World Wide Web to its full potential by developing a Media Fragment protocol and guidelines that ensure the long-term growth of the Web. The major contribution of this paper is the introduction of Media Fragments as a media-format independent, standard means of addressing media resources using URIs. Moreover, we explain how the HTTP protocol can be used and extended to serve Media Fragments and what the impact is for current Web-enabled media formats.
C1 [Mannens, Erik; Van Deursen, Davy; Van de Walle, Rik] Univ Ghent IBBT, ELIS Multimedia Lab, Ghent, Belgium.
   [Troncy, Raphael] EURECOM, Multimedia Commun Dept, Sophia Antipolis, France.
   [Pfeiffer, Silvia] Vquence, Sydney, NSW, Australia.
   [Parker, Conrad] Kyoto Univ, Kyoto, Japan.
   [Lafon, Yves] W3C ERCIM, Sophia Antipolis, France.
   [Jansen, Jack] CWI, NL-1009 AB Amsterdam, Netherlands.
   [Hausenblas, Michael] Natl Univ Ireland, Digital Enterprise Res Inst LiDRC, Galway, Ireland.
C3 Ghent University; IMT - Institut Mines-Telecom; EURECOM; Kyoto
   University; Ollscoil na Gaillimhe-University of Galway
RP Mannens, E (corresponding author), Univ Ghent IBBT, ELIS Multimedia Lab, Ghent, Belgium.
EM erik.mannens@ugent.be; davy.vandeursen@ugent.be;
   raphael.troncy@eurecom.fr; silviapfeiffer1@gmail.com;
   conrad@metadecks.org; ylafon@w3.org; Jack.Jansen@cwi.nl;
   michael.hausenblas@deri.org; rik.vandewalle@ugent.be
RI Jansen, Jack/KHZ-0382-2024; Troncy, Raphaël/ABE-7222-2021
OI Jansen, Jack/0000-0002-7006-2560; Troncy, Raphaël/0000-0003-0457-1436;
   Mannens, Erik/0000-0001-7946-4884; Hausenblas,
   Michael/0000-0003-0967-5998
FU W3C/ERCIM; Ghent University; Interdisciplinary Institute for Broadband
   Technology (IBBT); Institute for the Promotion of Innovation by Science
   and Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); French Ministry of Industry (Innovative Web call)
   [09.2.93.0966]; EURECOM; CWI; Kyoto University; National University of
   Ireland; Mozilla Corporation; European Union [ICT-2007-214793]
FX The authors would like to thank the other W3C Media Fragments'
   participants: Eric Carlson (Apple, Inc.), Thierry Michel (W3C/ERCIM),
   Guillaume Olivrin (Meraka Institute, South Africa), Soohong Daniel Park
   (Samsung Electronics Co., Ltd.), David Singer (Apple, Inc.), Philip
   Jagenstedt (Opera Software) for their willingness to discuss the
   definition of media fragments and more generally their adequacy within
   the Web architecture. The research activities that have been described
   in this paper were partially funded by W3C/ERCIM, Ghent University,
   Interdisciplinary Institute for Broadband Technology (IBBT), the
   Institute for the Promotion of Innovation by Science and Technology in
   Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), the French Ministry of Industry (Innovative Web call)
   under contract 09.2.93.0966, EURECOM, CWI, Kyoto University, National
   University of Ireland, Mozilla Corporation, and the European Union
   within the 7th framework program (FP7/2007-2013) under agreement
   ICT-2007-214793.
CR [Anonymous], 1449632005 ISOIEC
   [Anonymous], 2003, 14496142003 ISOIEC
   [Anonymous], 2005, 14496122005 ISOIEC
   Bulterman D, 2005, SYNCHRONIZED MULTIME
   De Schriiver D, 2006, P AXMEDIS 2006 LEEDS, P223
   EBU/ETSI, 2008, 10282231 EBUETSI TS
   Ferraiolo J., 2009, SCALABLE VECTOR GRAP
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   Hausenblas M, 2009, P 2 WORKSH LINK DAT
   Hickson I, 2010, HTML5 VOCABULARY ASS
   Internet Engineering Task Force, 2005, 3986 RFC INT ENG TAS
   Internet Engineering Task Force (199), 2616 RFC INT ENG TAS
   ISO, 2002, 1593812002 ISOIEC
   ISO/IEC, 2006, 21000172006 ISOIEC
   ISO/IEC, 2006, 14496172006 ISOIEC
   ITU-T and ISO/IEC, 2003, H264 ITUT ISOIEC
   Lambert P, 2006, LECT NOTES COMPUT SC, V4179, P442
   Mannens E, 2009, USE CASES REQUIREMEN
   Mannens E, 2010, MEDIA FRAGMENTS URI
   Pfeiffer S, 2005, INTERNET DRAFT SPECI
   Pfeiffer S, 2007, P W3C VID WEB WORKSH
   Pfeiffer Silvia, 2003, 3533 RFC
   Raggett D, 1999, HYPERTEXT MARKUP LAN
   Schulzrinne H., 1998, 2326 RFC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Society of Motion Picture and Television Engineers, 2004, 136 SMPTE RP
   The WebM Project, 2010, VP8 DAT FORM DEC GUI
   The WebM Project, 2010, WEBM MULT CONT GUID
   Troncy R, 2007, P W3C VID WEB WORKSH
   Van Deursen D., 2010, Proceedings of the 19th international conference on World wide web (WWW '10), P1361, DOI DOI 10.1145/1772690.1772931
   W3C Media Fragments Working Group, 2010, MED FRAGM WORK GROUP
   Xiph.org Foundation, 2009, THEOR SPEC
   Xiph.org Foundation, 2010, VORB 1 SPEC
NR 33
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 691
EP 715
DI 10.1007/s11042-010-0683-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000014
DA 2024-07-18
ER

PT J
AU Van Rijsselbergen, D
   Poppe, C
   Verwaest, M
   Mannens, E
   Van de Walle, R
AF Van Rijsselbergen, Dieter
   Poppe, Chris
   Verwaest, Maarten
   Mannens, Erik
   Van de Walle, Rik
TI Semantic Mastering: content adaptation in the creative drama production
   workflow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic adaptation; UMA; Universal multimedia experiences;
   Cinematography; Drama production
ID MULTIMEDIA; MPEG-21
AB In order to provide audiences with a proper universal multimedia experience, all classes of media consumption devices, from high definition displays to mobile media players, must receive a product that is not only adapted to their capabilities and usage environments, but also conveys the semantics and cinematography behind the narrative in an optimal way. This paper introduces a semantic video adaptation system that incorporates the media adaptation process in the center of the drama production process. Producers, directors and other creative staff instruct the semantic adaptation system using common cinematographic terminology and vocabulary, thereby seamlessly extending the drama production process into the realm of content adaptation. The multitude of production metadata obtained from various steps in the production process provides a valuable context of narrative semantics that is exploited by the adaptation process. As such, high definition imagery can be intelligently adapted to smaller resolutions while optimally fulfilling the filmmaker's dramatic intentions with respect to the original narrative and obeying various rules of cinematographic grammar.
C1 [Van Rijsselbergen, Dieter; Poppe, Chris; Mannens, Erik; Van de Walle, Rik] Univ Ghent, IBBT, Dept Elect & Informat Syst ELIS, Multimedia Lab, B-9050 Ghent, Belgium.
   [Verwaest, Maarten] VRT Medialab, B-9050 Ghent, Belgium.
C3 Ghent University
RP Van Rijsselbergen, D (corresponding author), Univ Ghent, IBBT, Dept Elect & Informat Syst ELIS, Multimedia Lab, Gaston Crommenlaan 8-201, B-9050 Ghent, Belgium.
EM Dieter.VanRijsselbergen@UGent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University; VRT; IBBT; Institute for the Promotion of Innovation
   by Science and Technology in Flanders (IWT); Fund for Scientific
   Research-Flanders (FWO-Flanders); Belgian Federal Science Policy Office
   (BFSPO); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, VRT, IBBT, the Institute for the Promotion
   of Innovation by Science and Technology in Flanders (IWT), the Fund for
   Scientific Research-Flanders (FWO-Flanders), the Belgian Federal Science
   Policy Office (BFSPO), and the European Union.
CR [Anonymous], 1976, Grammar of the film language
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], P 5 INT C INT AI OR
   [Anonymous], P INT WORKSH IM AN M
   [Anonymous], ACM SIGGRAPH AS 09 I
   [Anonymous], P 4 INT C INT US INT
   [Anonymous], P IBC C
   [Anonymous], P 4 INT C SEM DIG ME
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Bares W., 2000, Proceedings ACM Multimedia 2000, P177, DOI 10.1145/354384.354463
   Bertini M, 2006, IEEE T MULTIMEDIA, V8, P433, DOI 10.1109/TMM.2006.870762
   Catmull E, 1974, inCom-puter Aided Geometric Design, P317, DOI [DOI 10.1016/B978-0-12-079050-0.50020-5, 10.1016/B978-0-12-079050-0.50020-5]
   Chen Fu., 2009, INTRO COLORED GLASS, P81
   Cheng WH, 2007, IEEE T CIRC SYST VID, V17, P43, DOI 10.1109/TCSVT.2006.885717
   Christianson DB, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P148
   Christie M, 2005, LECT NOTES COMPUT SC, V3638, P40
   De Geyter M, 2008, SMPTE MOTION IMAG J, V117, P38, DOI 10.5594/J15016
   Deselaers T, 2008, IEEE COMPUTER SOC C, P1
   Halper N, 2001, COMPUT GRAPH FORUM, V20, pC174, DOI 10.1111/1467-8659.00510
   Hendler J, 2008, FOUND ARTIF INTELL, P821, DOI 10.1016/S1574-6526(07)03021-0
   Jannach D, 2007, J NETW COMPUT APPL, V30, P958, DOI 10.1016/j.jnca.2005.12.007
   Knoche H, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1556134.1556137
   Kopf Stephan., 2009, MM 09, P321
   Kovalick A., 2006, Video systems in an IT environment: The essentials of professional networked media
   Liu Feng., 2006, ACM MULTIMEDIA 2006, P241, DOI DOI 10.1145/1180639.1180702
   Magalhaes J, 2004, SIGNAL PROCESS-IMAGE, V19, P437, DOI 10.1016/j.image.2004.02.004
   Mascelli J., 1998, 5 CS CINEMATOGRAPHY
   Nack F., 2001, IEEE Multimedia, V8, P10, DOI 10.1109/93.959093
   Parr T, 2008, INT C PROGRAM COMPRE, P5, DOI 10.1109/ICPC.2008.36
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Schwitter R, 2002, 13TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P228
   Sco K, 2007, IEEE T CIRC SYST VID, V17, P1395, DOI 10.1109/TCSVT.2007.903775
   Setlur Vidya., 2005, MUM, V154, P59, DOI DOI 10.1145/1149488.1149499
   Sofokleous AA, 2008, MULTIMED TOOLS APPL, V40, P151, DOI 10.1007/s11042-008-0198-z
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   van Beek P, 2003, IEEE SIGNAL PROC MAG, V20, P40, DOI 10.1109/MSP.2003.1184338
   Van Deursen D, 2010, MULTIMED TOOLS APPL, V46, P371, DOI 10.1007/s11042-009-0354-0
   Van Rijsselbergen D, 2009, IEEE INT CON MULTI, P822, DOI 10.1109/ICME.2009.5202621
   Van Rijsselbergen D, 2009, DOCENG'09: PROCEEDINGS OF THE 2009 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P161
   Van Rijsselbergen D, 2008, MULTIMEDIA SYST, V14, P395, DOI 10.1007/s00530-008-0130-4
   Wolf L., 2007, Computer Vision and Pattern Recognition, P1
NR 43
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 307
EP 340
DI 10.1007/s11042-010-0710-0
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800015
OA Green Published
DA 2024-07-18
ER

PT J
AU Andrade, MT
   Dogan, S
   Carreras, A
   Barbosa, V
   Arachchi, HK
   Delgado, J
   Kondoz, AM
AF Andrade, Maria Teresa
   Dogan, Safak
   Carreras, Anna
   Barbosa, Vitor
   Arachchi, Hemantha Kodikara
   Delgado, Jaime
   Kondoz, Ahmet M.
TI Advanced delivery of sensitive multimedia content for better serving
   user expectations in Virtual Collaboration applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context; Adaptation; DRM; Virtual collaborations; Ontology reasoning
ID CONTENT ADAPTATION; MPEG-21; FRAMEWORK
AB A major challenge when accessing protected multimedia content in heterogeneous usage environments is the ability to provide acceptable levels of quality of experience to all involving users. Additionally, different levels of protection should be possible to be addressed when manipulating the content towards the quality of experience maximization. This paper describes the use of a context-aware and Digital Rights Management (DRM)-enabled content adaptation platform towards meeting these challenges. The platform was conceived to deliver advanced content adaptation within different application scenarios, among which Virtual Collaboration (VC) was central. Descriptions of use cases implemented by the platform in heterogeneous VC environments are provided. Conducted experiments have highlighted the benefits to users when compared to an operation without the platform. Results of different adaptations suitable to sensed context conditions are also provided and analyzed. A brief description of the platform functionality is included together with pointers to additional information.
C1 [Andrade, Maria Teresa] Univ Porto, Fac Engn, P-4200465 Oporto, Portugal.
   [Andrade, Maria Teresa; Barbosa, Vitor] INESC Porto, P-4200465 Oporto, Portugal.
   [Dogan, Safak; Arachchi, Hemantha Kodikara; Kondoz, Ahmet M.] Univ Surrey, Fac Engn & Phys Sci, I Lab Multimedia Commun Res, Guildford GU2 7XH, Surrey, England.
   [Carreras, Anna; Delgado, Jaime] Univ Politecn Cataluna, Dept Arquitectura Comp, ES-08034 Barcelona, Spain.
C3 Universidade do Porto; Universidade do Porto; INESC TEC; University of
   Surrey; Universitat Politecnica de Catalunya
RP Andrade, MT (corresponding author), Univ Porto, Fac Engn, Rua Dr Roberto Frias S-N, P-4200465 Oporto, Portugal.
EM mandrade@fe.up.pt; S.Dogan@surrey.ac.uk; annac@ac.upc.edu;
   vhsb@inescporto.pt; H.Kodikaraarachchi@surrey.ac.uk;
   jaime.delgado@ac.upc.edu; A.Kondoz@surrey.ac.uk
RI ANDRADE, MARIA/JGM-7159-2023; Dogan, Safak/JTZ-5976-2023; da Costa
   Andrade, Maria Eduarda/IXN-1199-2023; Delgado, Jaime/AAA-8489-2019;
   Andrade, Maria/HKN-0074-2023; Carreras Coch, Anna/M-3371-2014
OI Dogan, Safak/0000-0002-1465-6495; Delgado, Jaime/0000-0003-1366-663X;
   Carreras Coch, Anna/0000-0002-7257-3081; Andrade, Maria
   Teresa/0000-0002-1363-5027; Kodikara Arachchi,
   Hemantha/0000-0002-5631-3239
FU VISNET II, European Network of Excellence under European Commission IST
FX The work presented was partially developed within VISNET II, a European
   Network of Excellence (http://www.visnet-noe.org), funded under the
   European Commission IST FP6 programme.
CR Andrade MT, 2007, IEEE ICT P 3 INT C C
   Andrade MT, 2007, THESIS U PORTO
   [Anonymous], INF TECHN MULT CON 5
   [Anonymous], 2004, W3C MEMB SUBMISS
   [Anonymous], INF TECHN MULT FRA 1
   [Anonymous], 2010, MPEG 2010
   [Anonymous], 2010, VISNET 2 WIKI
   [Anonymous], 2010, MULTICAO 2010
   [Anonymous], 2007, INF TECHN MULT FRA 7
   [Anonymous], 2005, P 17 M JOINT VID TEA
   Burnett I.S., 2006, MPEG 21 BOOK, V1st
   Carreras A, 2009, P 10 INT WORKSH IM A, P209
   Carreras A, 2010, IEEE MULTIMEDIA, V17, P74, DOI 10.1109/MMUL.2009.61
   Chaari T, 2006, INT J PERVASIVE COMP, V2
   DEY A, 2000, THESIS COLL COMPUTIN
   ISO IEC, 2004, INF TECHN MULT FRA 5
   Jannach D, 2006, APPL INTELL, V24, P109, DOI 10.1007/s10489-006-6933-0
   Kim J-H, 2007, P IEEE INT C MULT UB
   KOFLER I, 2007, P 14 MULT COMP NETW
   Kofler I, 2008, SIGNAL IMAGE VIDEO P, V2, P355, DOI 10.1007/s11760-008-0088-x
   Kosch H, 2009, IEEE COMPUTER SOC CO
   Liu D, 2008, P INT C ADV COMP TEC
   LOPEZ F, 2008, P 9 INT WORKSH IM AN
   López F, 2009, LECT NOTES COMPUT SC, V5887, P114, DOI 10.1007/978-3-642-10543-2_12
   McGuinness D.L., 2004, WEB ONTOLOGY LANGUAG
   OWL, 2004, WEB ONT LANG OWL OV
   Pellet, 2010, PELLET OPEN SOURCE O
   Preuveneers D, 2006, P 4 INT C PERV COMP, P125
   Qin Weijun, 2007, Tsinghua Science and Technology, V12, P707, DOI 10.1016/S1007-0214(07)70179-7
   Serrano JM, 2007, P IEEE INT C COMM 20
   Timmerer C, 2008, ENCY MULTIMEDIA, P457
   Vetro A, 2005, IEEE T MULTIMEDIA, V7, P418, DOI 10.1109/TMM.2005.846795
   W3C, 2010, W3C 2010
   Wang X, 2005, IEEE T MULTIMEDIA, V7, P408, DOI 10.1109/TMM.2005.846788
   Wenger S, 2002, Q15I16R1 ITU T VCEG
NR 35
TC 3
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2012
VL 58
IS 3
BP 633
EP 661
DI 10.1007/s11042-011-0749-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 935GU
UT WOS:000303507900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bustos, B
   Schreck, T
   Walter, M
   Barrios, JM
   Schaefer, M
   Keim, D
AF Bustos, Benjamin
   Schreck, Tobias
   Walter, Michael
   Manuel Barrios, Juan
   Schaefer, Matthias
   Keim, Daniel
TI Improving 3D similarity search by enhancing and combining 3D descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D similarity retrieval; Descriptor combinations; Object partitioning
AB Effective content-based retrieval in 3D model databases is an important problem that has attracted much research attention over the last years. Many individual methods proposed to date rely on calculating global 3D model descriptors based on image, surface, volumetric, or structural model properties. Descriptors such as these are then input for determining the degree of similarity between models. Traditionally, the ability of individual descriptors to perform effective 3D search is decided by benchmarking. However, in practice the data set on which 3D retrieval is to be applied may differ from the characteristics of the respective benchmark. Therefore, statically determining the descriptor to use based on a fixed benchmark may lead to suboptimal results. We propose a generic strategy to improve the retrieval effectiveness in 3D retrieval systems consisting of multiple model descriptors. The specific contribution of this paper is two-fold. First, we propose to adaptively combine multiple descriptors by forming weighted descriptor combinations, where the weight of each descriptor is decided at query time. Second, we enhance the set of global model descriptors to be combined by including partial descriptors of the same kind in the combinations. Partial descriptors are obtained by applying a given descriptor extractor on the set of parts of a model, obtained by a simple model partitioning scheme. Thereby, more model information is exposed to the 3D descriptors, leading to a more complete object description. We give a systematic discussion of the descriptor combination space involving static and query-adaptive weighting schemes, and based on descriptors of different type and focus (model global vs. partial). The combination of both global and partial model descriptors is shown to deliver improved retrieval precision, compared to policies using single descriptors or fixed-weight combinations. The resulting scheme is generic and can accommodate a large class of global 3D model descriptors.
C1 [Bustos, Benjamin; Manuel Barrios, Juan] Univ Chile, Dept Comp Sci, Santiago 8370459, Chile.
   [Schreck, Tobias; Walter, Michael] Tech Univ Darmstadt, Dept Comp Sci, D-64283 Darmstadt, Germany.
   [Schaefer, Matthias; Keim, Daniel] Univ Konstanz, Dept Comp Sci, D-78457 Constance, Germany.
C3 Universidad de Chile; Technical University of Darmstadt; University of
   Konstanz
RP Bustos, B (corresponding author), Univ Chile, Dept Comp Sci, Av Blanco Encalada 2120 3Er Piso, Santiago 8370459, Chile.
EM bebustos@dcc.uchile.cl; tobias.schreck@gris.informatik.tu-darmstadt.de;
   michael.walter@gris.informatik.tu-darmstadt.de; jbarrios@dcc.uchile.cl;
   schaefer@dbvis.inf.uni-konstanz.de; keim@dbvis.inf.uni-konstanz.de
RI Keim, Daniel/X-7749-2019; Bustos, Benjamin/G-1170-2010
OI Keim, Daniel/0000-0001-7966-9740; Bustos, Benjamin/0000-0002-3955-361X;
   Walter, Michael/0000-0003-3186-2482; Schreck, Tobias/0000-0003-0778-8665
FU German Research Foundation DFG [SCHR 1229/2-1]
FX We thank Dejan Vranic and Dietmar Saupe for providing the base 3D
   descriptor extractors used in our work. This work was partially funded
   by the German Research Foundation DFG within the 2010 German-Chile
   research cooperation program, project number SCHR 1229/2-1.
CR Akgul CB, 2008, P 1 EUR C 3D OBJ RET, P41
   [Anonymous], EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR/3DOR08/009-016
   [Anonymous], P EUR WORKSH 3D OBJ
   [Anonymous], 2005, The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling
   [Anonymous], 3DOR 08
   [Anonymous], 2010, P EUR WORKSH 3D OBJ
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   Bustos B., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P514
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Bustos B, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1303, DOI 10.1109/ICME.2004.1394465
   Bustos B, 2006, THESIS U KONSTANZ
   Bustos B., 2006, P 8 ACM SIGMM INT WO, P137
   Bustos B, 2006, INT J DIGIT LIBRARIE, V6, P39, DOI 10.1007/s00799-005-0122-3
   Bustos B, 2007, IEEE COMPUT GRAPH, V27, P22, DOI 10.1109/MCG.2007.80
   Bustos Benjamin., 2005, PROC SAC 05, P1180
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Chen J., 2010, P 9 ACM INT C IM VID, P220, DOI DOI 10.1145/1816041.1816075
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Frakes WB., 1992, Information retrieval: Data structures and algorithms
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Leng B, 2008, MULTIMED TOOLS APPL, V40, P135, DOI 10.1007/s11042-007-0188-6
   Lou K, 2004, PROC INT CONF DATA, P754, DOI 10.1109/ICDE.2004.1320043
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mademlis A., 2007, IEEE ICIP, V2, P517
   Marini S, 2007, IEEE COMPUT GRAPH, V27, P28, DOI 10.1109/MCG.2007.89
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Rahmani R, 2008, IEEE T PATTERN ANAL, V30, P1902, DOI 10.1109/TPAMI.2008.112
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sijbers J, 1997, MAGN RESON IMAGING, V15, P679, DOI 10.1016/S0730-725X(97)00033-7
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   WESSEL R., 2006, proceedings of Vision, Modeling, and Visualization, P365
   Zezula P., 2005, ADV DATABASE SYSTEMS
   [No title captured]
NR 39
TC 9
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 81
EP 108
DI 10.1007/s11042-010-0689-6
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600004
DA 2024-07-18
ER

PT J
AU Pogorelc, B
   Bosnic, Z
   Gams, M
AF Pogorelc, Bogdan
   Bosnic, Zoran
   Gams, Matjaz
TI Automatic recognition of gait-related health problems in the elderly
   using machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Health-problems detection; Human-motion analysis; Gait analysis; Machine
   learning; Data mining; Temporal data mining; Time-series data mining;
   Human locomotion; Elderly care; Ambient assisted living; Ambient media;
   Ambient intelligence; Ubiquitous computing; Pervasive health
ID FALL DETECTION; SENSORS
AB This paper proposes a system for the early automatic recognition of health problems that manifest themselves in distinctive form of gait. Purpose of the system is to prolong the autonomous living of the elderly at home. When the system identifies a health problem, it automatically notifies a physician and provides an explanation of the automatic diagnosis. The gait of the elderly user is captured using a motion-capture system, which consists of body-worn tags and wall-mounted sensors. The positions of the tags are acquired by the sensors and the resulting time series of position coordinates are analyzed with machine-learning algorithms in order to recognize a specific health problem. Novel semantic features based on medical knowledge for training a machine-learning classifier are proposed in this paper. The classifier classifies the user's gait into: 1) normal, 2) with hemiplegia, 3) with Parkinson's disease, 4) with pain in the back and 5) with pain in the leg. The studies of 1) the feasibility of automatic recognition and 2) the impact of tag placement and noise level on the accuracy of the recognition of health problems are presented. The experimental results of the first study (12 tags, no noise) showed that the k-nearest neighbors and neural network algorithms achieved classification accuracies of 100%. The experimental results of the second study showed that classification accuracy of over 99% is achievable using several machine-learning algorithms and 8 or more tags with up to 15 mm standard deviation of noise. The results show that the proposed approach achieves high classification accuracy and can be used as a guide for further studies in the increasingly important area of Ambient Assisted Living. Since the system uses semantic features and an artificial-intelligence approach to interpret the health state, provides a natural explanation of the hypothesis and is embedded in the domestic environment of the elderly person; it is an example of the semantic ambient media for Ambient Assisted Living.
C1 [Pogorelc, Bogdan; Gams, Matjaz] Jozef Stefan Inst, Dept Intelligent Syst, Ljubljana 1000, Slovenia.
   [Pogorelc, Bogdan; Gams, Matjaz] Spica Int Doo, Ljubljana 1231, Slovenia.
   [Bosnic, Zoran] Fac Comp & Informat Sci, Ljubljana 1000, Slovenia.
C3 Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute
RP Pogorelc, B (corresponding author), Jozef Stefan Inst, Dept Intelligent Syst, Jamova Cesta 39, Ljubljana 1000, Slovenia.
EM bogdan.pogorelc@ijs.si; zoran.bosnic@fri.uni-lj.si; matjaz.gams@ijs.si
FU European Union; European Social Fund
FX This work is partially financed by the European Union, the European
   Social Fund. The authors thank Martin Tomsic, Bojan Nemec and Leon
   Zlajpah for their help with data acquisition, Anton Gradisek for his
   medical expertise and Mitja Lustrek, Rok Piltaver and other colleagues
   for helpful feedback.
CR [Anonymous], 2005, P AAMAS 05
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bourke AK, 2008, MED ENG PHYS, V30, P84, DOI 10.1016/j.medengphy.2006.12.001
   Bourke A K., 2006, Proceedings of the 24th IASTED International MultiConference Biomedical Engineering, P156
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Christiannini N., 2000, Support vector machines and other kernel-based learning methods
   Confidence Consortium, 2009, UB CAR SYST SUPP IND
   Craik R.L., 1995, Gait Analysis: Theory and Application
   Dovgan E, 2011, ZDR VESTN, V80, P824
   eMotion, 2009, SMART MOT CAPT SYST
   Harrison RD, 1998, HARRISONS PRINCIPLES
   Jurman D, 2007, INFORM MIDEM, V37, P67
   Kangas M, 2008, GAIT POSTURE, V28, P285, DOI 10.1016/j.gaitpost.2008.01.003
   Kononenko I., 2007, Machine Learning and Data Mining: Introduction to Principles and Algorithms
   Lakany H, 2008, PATTERN RECOGN, V41, P1627, DOI 10.1016/j.patcog.2007.11.004
   Lustrek M, 2009, INFORM-J COMPUT INFO, V33, P197
   Lustrek M, 2009, LECT NOTES COMPUT SC, V5859, P14, DOI 10.1007/978-3-642-05408-2_2
   Maybeck P. S., 1979, Stochastic models, estimation, and control, V141
   McCulloch W.S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Moore ST, 2007, GAIT POSTURE, V26, P200, DOI 10.1016/j.gaitpost.2006.09.011
   Perry J, 2010, GAIT ANALYSIS: NORMAL AND PATHOLOGICAL FUNCTION, SECOND EDITION, P1
   Qian G, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1579
   Ribaric S, 2007, INFORM MIDEM, V37, P98
   Strle D, 2007, INFORM MIDEM, V37, P199
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   United Nations, 2009, WORLD POP AG
   Vishwakarma V, 2007, LECT NOTES COMPUT SC, V4815, P616
   Witten I. H., 2005, DATA MINING PRACTICA
   Zhang T, 2006, LECT NOTES CONTR INF, V345, P858
   Zouba N, 2008, LECT NOTES COMPUT SC, V5329, P37, DOI 10.1007/978-3-540-92781-5_4
NR 30
TC 90
Z9 103
U1 1
U2 77
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 333
EP 354
DI 10.1007/s11042-011-0786-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500003
OA hybrid
DA 2024-07-18
ER

PT J
AU Baek, N
   Lee, H
AF Baek, Nakhoon
   Lee, Hwanyong
TI OpenGL ES 1.1 implementation based on OpenGL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenGL ES; OpenGL; Conformance test; 3D graphics library; De facto
   standard
AB In this paper, we present an efficient way of implementing OpenGL ES 1.1 3D graphics API library for the environments with hardware-supported OpenGL facility, typically as desktop PCs. Although OpenGL ES was started from the existing OpenGL features, it rapidly became the standard 3D graphics library customized for embedded systems through introducing fixed-point arithmetic operations, buffer management with fixed-point data type supports, completely new texture mapping functions and others. Currently, it is the official 3D graphics API for Google Android, Apple iPhone, Sony PlayStation3, etc. In this paper, we achieved improvements on the arithmetic operations for the fixed-point number representation, which is the most characteristic data type for OpenGL ES 1.1. For the conversion of fixed-point data types to the floating-point number representations for the underlying OpenGL, we show the way of efficient conversion processes even with satisfying OpenGL ES standard requirements. We also introduced a specialized memory management scheme to manage the converted data from the buffer containing fixed-point numbers. In the case of texture processing, the requirements in both standards are quite different, and thus we used completely new software-implementations. Our final implementation of OpenGL ES library provides all of more than 200 functions in the standard specification and passed its conformance test, to show its compliance with the standard. From the efficiency point of view, we measured its execution times for several OpenGL ES-specific application programs and achieved remarkable improvements.
C1 [Baek, Nakhoon] Kyungpook Natl Univ, Sch Comp Sci Engn, Taegu 702701, South Korea.
   [Baek, Nakhoon] Mobile Graph Inc, Taegu 706850, South Korea.
   [Lee, Hwanyong] Huone Inc, Taegu 702020, South Korea.
   [Lee, Hwanyong] Kyungpook Natl Univ, Sch EECS, Taegu 702701, South Korea.
C3 Kyungpook National University; Kyungpook National University
RP Baek, N (corresponding author), Kyungpook Natl Univ, Sch Comp Sci Engn, Taegu 702701, South Korea.
EM oceancru@gmail.com; hylee@hu1.com
RI Lee, Hwanyong/Q-3908-2018
OI Lee, Hwanyong/0000-0003-0031-1688; Baek, Nakhoon/0000-0003-2136-843X
CR [Anonymous], DEV SOFTWARE SYMBIAN
   [Anonymous], PLAYSTATION3 API
   [Anonymous], GLEE
   [Anonymous], OPENGL ES COMMON COM
   [Anonymous], SAMSUNG ELECT
   [Anonymous], KHRON GROUP CONF TES
   [Anonymous], MOBILE 3D GRAPHICS
   [Anonymous], IEICE ELECT IN PRESS
   [Anonymous], DGLES
   [Anonymous], KHRON GROUP REF IMPL
   [Anonymous], GAME DEV SERIES
   [Anonymous], APPL IPHONE
   [Anonymous], OPENGL ES COMMON PRO
   [Anonymous], OPENGL ES COMMON COM
   [Anonymous], MOZ WEB BROWS
   [Anonymous], 33 ARM
   [Anonymous], GOOGL ANDR
   [Anonymous], Hybrid
   [Anonymous], IMAGINATION
   Hill S, 2008, INT C CONSUMER ELECT, P1
   HOUGH D, 1981, COMPUTER, V14, P70, DOI 10.1109/C-M.1981.220381
   Pulli K, 2005, IEEE COMPUT GRAPH, V25, P66, DOI 10.1109/MCG.2005.129
   Pulli Kari., 2007, Mobile 3D Graphics: with OpenGL ES and M3G
   Tu CH, 2005, INT C COMP AID DES C, P423
NR 24
TC 8
Z9 9
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 669
EP 685
DI 10.1007/s11042-010-0662-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900011
DA 2024-07-18
ER

PT J
AU Ou, F
   Han, ZC
   Liu, C
   Ou, ZY
AF Ou, Fan
   Han, Zhaocui
   Liu, Chong
   Ou, Zongying
TI Face verification with feature fusion of Gabor based and curvelet based
   representations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature fusion; Face verification; Curvelets; Gabor wavelets
ID RECOGNITION; SETS
AB Face verification has broad potential in varieties of multimedia applications, such as security access control, surveillance monitor, image retrieval and intelligent human machine interface. However, the existence of variable lighting, pose, facial expression, aging and other random factors often causes the occurrence of recognition errors. Further upgrading the performance of face verification systems is not only a challenging but also an urgent task. Information fusion had proved to be one of the promising approaches in upgrading verification performance since more cues and evidences were provided. Gabor feature face representation and Curvelet feature face representation were chosen for fusion processing, since both representations are good at depicting image intrinsic pattern but with different emphases. After calculating the Gabor features and Curvelet features of a face image, the mutually correlated projection pairs of these two individual mode features were first yielded by canonical correlation analysis (CCA) method. Then, an integrate projection set can be built by simply grouping these two mutual correlated projection sequences term by term correspondingly. The integrate projection set possesses most of the information contained in Gabor features and Curvelet features and is optimally reorganized in a correlation sense. To further enhance the discriminant capabilities, a linear discriminant analysis (LDA) post-processing is applied on the integrate projection set to yield the final fusion feature set. The experiment results testing on MBGC data set show that the proposed fusion approach does reduce the error rates significantly as compared with using individual mode feature alone. FRR100 and FAR1000 were reduced about 30% and more.
C1 [Ou, Fan; Han, Zhaocui; Liu, Chong; Ou, Zongying] Dalian Univ Technol, Sch Mech Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Ou, ZY (corresponding author), Dalian Univ Technol, Sch Mech Engn, Dalian 116024, Peoples R China.
EM york_ou@yahoo.com.cn; xiaohan83@163.com; chongl@dlut.edu.cn;
   ouzyg@dlut.edu.cn
FU Dalian University of Technology; Shenyang Institute of Automation,
   Chinese Academy of Science
FX The research work was supported by the joint research funds of Dalian
   University of Technology and Shenyang Institute of Automation, Chinese
   Academy of Science. The authors would like to thank to the MBGC Team and
   Sponsors for providing the MBGC still frontal face version 1.0 data set.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Borga M, 1998, THESIS LINKOPING U S
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès EJ, 2002, SIGNAL PROCESS, V82, P1519, DOI 10.1016/S0165-1684(02)00300-6
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   De la Torre Frade F, 2005, REPRESENTATIONAL ORI, P266
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kittler J, 2003, IEEE T PATTERN ANAL, V25, P110, DOI 10.1109/TPAMI.2003.1159950
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Marcialis G. L, 2002, LNCS, V2359, P30
   Ou Fan, 2010, Application Research of Computers, V27, P399, DOI 10.3969/j.issn.1001-3695.2010.01.120
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, OVERVIEW THEMULTIPLE
   Phillips PJ, 2007, 7408 NISTIR
   Phillips PJ, MBGC STILL FACE CHAL
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235
   Tao Q, 2009, PATTERN RECOGN, V42, P823, DOI 10.1016/j.patcog.2008.09.036
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang WC, 2004, INT C PATT RECOG, P950, DOI 10.1109/ICPR.2004.1334686
NR 27
TC 6
Z9 6
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 549
EP 563
DI 10.1007/s11042-010-0658-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900005
DA 2024-07-18
ER

PT J
AU Sun, HM
   Weng, MW
AF Sun, Huey-Min
   Weng, Mao-Wei
TI Rate-smoothed schedule with tolerable data dropping for video coding
   stream
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-4 FGS framework; Smoothing; Video content
ID BIT-RATE VIDEO; BANDWIDTH ALLOCATION; STORED VIDEO; DELIVERY; NETWORKS;
   STANDARD; QUALITY
AB Most algorithms of smoothing schedule compute the required bit rate of video transmission to satisfy all the transmitted data. In this paper, our proposed tolerable data dropping algorithm can adjust transmitting data to fit available bit rate. MPEG-4 with fine grained scalability (FGS) can support partial data dropping to adapt to available bandwidth network. The algorithm is based on the minimum variance bandwidth allocation (MVBA) algorithm proposed by Salehi et al. to compute the bit rate such that still ensuring that the buffer never underflows and overflows for MPEG-4 FGS streams under the limited bandwidth resource. We prove that our proposed algorithm, named MVBADP, is smoother than the MVBA algorithm. The experimental results show the peak rate, the number of rate changes, and the ratio of total dropping data, and the PSNR for four test sequences with different content characteristics. They are varied by buffer sizes and tolerable dropping ratios. We found that the MVBADP algorithm can reduce the peak rate and the number of changes when the transmitted data are dropped by tolerable dropping ratio, especially on the video sequences with the high motion and complex texture characteristic and larger size change of the consecutive frame.
C1 [Sun, Huey-Min; Weng, Mao-Wei] Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
C3 Chang Jung Christian University
RP Sun, HM (corresponding author), Chang Jung Christian Univ, Dept Informat Management, Tainan 711, Taiwan.
EM prince@mail.cjcu.edu.tw
FU Chang Jung Christian University [Q98002]
FX This work was supported by Chang Jung Christian University under
   Contract Q98002.
CR CHAKARESKI J, 2005, IEEE INT C MULT EXP, P1066
   Feng WC, 1997, MULTIMEDIA SYST, V5, P297, DOI 10.1007/s005300050062
   FENG WC, 1995, COMPUT COMMUN, V18, P709, DOI 10.1016/0140-3664(95)98484-M
   Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Lai HL, 2005, IEEE T CIRC SYST VID, V15, P221, DOI 10.1109/TCSVT.2004.841687
   Lee MJ, 2007, IEEE T CONSUM ELECTR, V53, P454, DOI 10.1109/TCE.2007.381715
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Lin JW, 2006, IEEE T MULTIMEDIA, V8, P996, DOI 10.1109/TMM.2006.879868
   Marshall Albert W., 1979, Inequalities Theory of Majorization and Its Applications, V143
   Microsoft, 2004, 14496 ISO IEC MICR
   Mushtaq M, 2008, CONSUM COMM NETWORK, P447, DOI 10.1109/ccnc08.2007.106
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   REXFORD J, 1997, P INT WORKSH NETW OP, P249
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sen S, 2000, IEEE T MULTIMEDIA, V2, P37, DOI 10.1109/6046.825793
   Stern HI, 2008, SIGNAL PROCESS-IMAGE, V23, P224, DOI 10.1016/j.image.2008.02.001
   Wang ZL, 2010, MULTIMEDIA SYST, V16, P151, DOI 10.1007/s00530-010-0181-1
   Wang ZL, 2009, IEEE T MULTIMEDIA, V11, P998, DOI 10.1109/TMM.2009.2021800
   Wu J, 2007, IEEE SIGNAL PROC LET, V14, P715, DOI 10.1109/LSP.2007.896376
   Zhang JB, 1998, COMPUT COMMUN, V21, P375, DOI 10.1016/S0140-3664(97)00170-9
NR 21
TC 1
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 587
EP 604
DI 10.1007/s11042-010-0659-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900007
DA 2024-07-18
ER

PT J
AU Wang, CJ
   Peng, ZY
   Peng, YW
   Yu, L
   Wang, JZ
   Zhao, QZ
AF Wang, Chuanjian
   Peng, Zhiyong
   Peng, Yuwei
   Yu, Liang
   Wang, Junzhou
   Zhao, Qingzhan
TI Watermarking geographical data on spatial topological relations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geographical data; Watermarking; Spatial topological relation; Watermark
   synchronization; Shape-preserving
AB Geographical data is of great value for data producers. How to protect copyright of geographical data effectively using digital watermarking is a hot research issue. In this paper, spatial topological relation existing between polygons is chosen as cover data, and watermark is embedded by slightly modifying the metric measure of spatial topological relation, and some geographical objects are scaled to derive the watermarked data. Global Main Scaling Distance is introduced to measure the distortions caused by watermark embedding. Experimental results show that the proposed algorithm has a good robustness against geometrical attacks, simplification, interpolation and noise addition attacks, and preserves shape of the watermarked geographical objects. Furthermore, a good tradeoff between robustness and fidelity is acquired in the proposed algorithm.
C1 [Wang, Chuanjian; Peng, Zhiyong; Peng, Yuwei; Yu, Liang; Wang, Junzhou] Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.
   [Wang, Chuanjian; Zhao, Qingzhan] Shihezi Univ, Coll Informat Sci & Technol, Shihezi 832003, Peoples R China.
C3 Wuhan University; Shihezi University
RP Wang, CJ (corresponding author), Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.
EM wangchj@gmail.com; peng@whu.edu.cn; ywpeng@whu.edu.cn;
   yliang84@gmail.com; wangjunzhou@gmail.com; zqz_inf@shzu.edu.cn
FU National Natural Science Foundation of China [90718027]; Key
   Technologies Science and Technology Program [2007BAH12B01,
   2007BAH12B07]; Natural Science Foundation of Hubei Province
   [2008CDA007]; National High Technology Research and Development Program
   [2006AA12Z210]; Independent Research Foundation of Wuhan University
   [6082011]; Open Research Foundation of State Key Laboratory of Aerospace
   Information Security and Trusted Computing
FX This research is funded by National Natural Science Foundation of China
   (Project No. 90718027), and the Key Technologies Science and Technology
   Program (Project No. 2007BAH12B01, 2007BAH12B07), and the Natural
   Science Foundation of Hubei Province (Project No. 2008CDA007), and the
   National High Technology Research and Development Program (Project No.
   2006AA12Z210), and Independent Research Foundation of Wuhan University
   (Project No. 6082011) and Open Research Foundation of State Key
   Laboratory of Aerospace Information Security and Trusted Computing.
CR Agrawal R., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P155
   Allison DCS, 1981, CS81017R VIRG TECH
   [Anonymous], 2007, INTELLIGENT MULTIMED
   [Anonymous], P WORKSH MULT SEC MM
   Collberg CS, 2002, IEEE T SOFTWARE ENG, V28, P735, DOI 10.1109/TSE.2002.1027797
   COX J, 2001, DIGITAL WATERMARKING
   [邓敏 Deng Min], 2002, [测绘学报, Acta Geodetica et Cartographica Sinica], V31, P164
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   Egenhofer M.J., 1994, Categorizing binary topological relations between regions, lines, and points in geographic databases
   Gou HM, 2005, IEEE T SIGNAL PROCES, V53, P3988, DOI 10.1109/TSP.2005.855411
   Huang M, 2007, LECT NOTES COMPUT SC, V4443, P1098
   Kang H, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P234, DOI 10.1109/ITCC.2001.918797
   Lafaye J, 2007, LECT NOTES COMPUT SC, V4605, P312
   Li XJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P947
   Li YY, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P424
   Madelaine J, 2007, ACM S INF COMP COMM, P265
   Ng W, 2005, LECT NOTES COMPUT SC, V3453, P68, DOI 10.1007/11408079_9
   Ohbuchi R, 2002, ICME2002
   Sakamoto M, 2000, S CRYPT INF SEC
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Shariff ARBM, 1998, INT J GEOGR INF SCI, V12, P215
   Shehab M, 2008, IEEE T KNOWL DATA EN, V20, P116, DOI 10.1109/TKDE.2007.190668
   Sion R, 2004, PROC INT CONF DATA, P584, DOI 10.1109/ICDE.2004.1320029
   Sion R, 2004, IEEE T KNOWL DATA EN, V16, P1509, DOI 10.1109/TKDE.2004.94
   Solachidis V, 2000, INT CONF ACOUST SPEE, P1955, DOI 10.1109/ICASSP.2000.859213
   Topkara M, 2005, P SOC PHOTO-OPT INS, V5681, P441, DOI 10.1117/12.593790
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Yu-Chi Pu, 2009, Information Technology Journal, V8, P982, DOI 10.3923/itj.2009.982.989
   Zhao CY, 2006, THESIS WUHAN U
NR 29
TC 23
Z9 27
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 67
EP 89
DI 10.1007/s11042-010-0536-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800005
DA 2024-07-18
ER

PT J
AU Richter, F
   Romberg, S
   Hörster, E
   Lienhart, R
AF Richter, Fabian
   Romberg, Stefan
   Hoerster, Eva
   Lienhart, Rainer
TI Leveraging community metadata for multimodal image ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image ranking; Image retrieval; PageRank; Graph
AB Searching for relevant images given a query term is an important task in nowadays large-scale community databases. The image ranking approach presented in this work represents an image collection as a graph that is built using a multimodal similarity measure based on visual features and user tags. We perform a random walk on this graph to find the most common images. Further we discuss several scalability issues of the proposed approach and show how in this framework queries can be answered fast. Experimental results validate the effectiveness of the presented algorithm.
C1 [Richter, Fabian; Lienhart, Rainer] Univ Augsburg, Multimedia Comp Lab, Dept Comp Sci, D-86159 Augsburg, Germany.
C3 University of Augsburg
RP Richter, F (corresponding author), Univ Augsburg, Multimedia Comp Lab, Dept Comp Sci, D-86159 Augsburg, Germany.
EM richter@informatik.uni-augsburg.de; romberg@informatik.uni-augsburg.de;
   hoerster@informatik.uni-augsburg.de; lienhart@informatik.uni-augsburg.de
OI Lienhart, Rainer/0000-0003-4007-6889
CR BERG TL, 2009, 2 INT VIS WORKSH IEE
   Crandall D, 2009, P 18 INT WORLD WID W
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gang Wang., 2008, Computer Vision and Pattern Recognition, IEEE Computer Society Conference on, P1
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   He XF, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P25
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hsu WinstonH., 2007, ACM MM
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Kamvar Sepandar D., 2003, P 12 INT C WORLD WID, P261, DOI DOI 10.1145/775152.775190
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Langville AN, 2006, SIAM J MATRIX ANAL A, V27, P968, DOI 10.1137/040619028
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Li Xirong., 2008, Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval, MIR '08, P180
   Lienhart R, 2007, INT CONF ACOUST SPEE, P1217
   Lienhart Rainer, 2009, ACM INT C IM VID RET
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nister David, 2006, CVPR
   Page L., 1999, PAGERANK CITATION RA
   Pan Jia-Yu., 2004, CVPRW 04 P 2004 C CO, V9, P146
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Raguram Rahul, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562959
   Romberg S, 2009, IEEE INT CON MULTI, P414, DOI 10.1109/ICME.2009.5202522
   Schroff F, 2007, IEEE I CONF COMP VIS, P2120
   Zheng YT, 2009, P ICCV MIAM FLOR US
NR 26
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 35
EP 62
DI 10.1007/s11042-010-0554-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schierl, T
   de la Fuente, YS
   Globisch, R
   Hellge, C
   Wiegand, T
AF Schierl, Thomas
   de la Fuente, Yago Sanchez
   Globisch, Ralf
   Hellge, Cornelius
   Wiegand, Thomas
TI Priority-based Media Delivery using SVC with RTP and HTTP streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; SVC; Scalable video coding; Adaptive HTTP streaming; Mobile
   channels; Link interruptions; Transmission rate variation; 3GPP PSS
AB Media delivery, especially video delivery over mobile channels may be affected by transmission bitrate variations or temporary link interruptions caused by changes in the channel conditions or the wireless interface. In this paper, we present the use of Priority-based Media Delivery (PMD) for Scalable Video Coding (SVC) to overcome link interruptions and channel bitrate reductions in mobile networks by performing a transmission scheduling algorithm that prioritizes media data according to its importance. The proposed approach comprises a priority-based media pre-buffer to overcome periods under reduced connectivity. The PMD algorithm aims to use the same transmission bitrate and overall buffer size as the traditional streaming approach, yet is more likely to overcome interruptions and reduced bitrate periods. PMD achieves longer continuous playback than the traditional approach, avoiding disruptions in the video playout and therefore improving the video playback quality. We analyze the use of SVC with PMD in the traditional RTP streaming and in the adaptive HTTP streaming context. We show benefits of using SVC in terms of received quality during interruption and re-buffering time, i.e. the time required to fill a desired pre-buffer at the receiver. We present a quality optimization approach for PMD and show results for different interruption/bitrate-reduction scenarios.
C1 [Schierl, Thomas; de la Fuente, Yago Sanchez; Globisch, Ralf; Hellge, Cornelius; Wiegand, Thomas] Fraunhofer HHI, Image Commun Grp, Image Proc Dept, D-10587 Berlin, Germany.
   [Schierl, Thomas; de la Fuente, Yago Sanchez; Hellge, Cornelius; Wiegand, Thomas] Tech Univ Berlin, Dept Telecommun Syst, Image Commun Grp, D-10587 Berlin, Germany.
C3 Technical University of Berlin
RP Schierl, T (corresponding author), Fraunhofer HHI, Image Commun Grp, Image Proc Dept, Einsteinufer 58, D-10587 Berlin, Germany.
EM schierl@hhi.fhg.de
CR *3 GEN PARTN PROJ, 2010, TECHN SPEC GROUP SER
   Amon P, 2007, IEEE T CIRC SYST VID, V17, P1174, DOI 10.1109/TCSVT.2007.905521
   [Anonymous], 2010, H264 ITUT ISOIEC
   Baldo N, 2004, 2004 IEEE 15TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-4, PROCEEDINGS, P1817, DOI 10.1109/PIMRC.2004.1368313
   FARBER N, 2006, J ZHEJIANG UNIV-SC A, V7, P164
   *ISO IEC, 2008, INF TECHN COD AUD VI
   Kritzner J, 2004, LECT NOTES COMPUT SC, V3079, P707
   RENZI D, 2008, INT P WORKSH IM AN M, P97
   SCHIERL T, 2005, P IEEE INT C MULT EX, P868
   Schierl T., 2009, 1381812007AMD3 ISOIE
   SCHIERL T, 2007, P IEEE INT C IM PROC, V6, P497
   SCHIERL T, 2005, P IEEE INT C IM PROC, V3, P696
   Schierl T, 2009, IEEE WIREL COMMUN, V16, P64, DOI 10.1109/MWC.2009.5300304
   SCHWARZ H, 2007, JVT M SAN JOS CA US
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stockhammer T., 2005, P IEEE ICME 2005 JUL, P1396
   Wang B., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P908
   WENGER S, 2009, RTP PAYLOAD FORMAT S
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1227, DOI 10.1109/TCSVT.2007.905519
NR 19
TC 25
Z9 35
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2011
VL 55
IS 2
SI SI
BP 227
EP 246
DI 10.1007/s11042-010-0572-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 808HU
UT WOS:000293969500003
DA 2024-07-18
ER

PT J
AU Zhao, SJ
   Precioso, F
   Cord, M
AF Zhao, Shuji
   Precioso, Frederic
   Cord, Matthieu
TI Spatio-Temporal Tube data representation and Kernel design for SVM-based
   video object retrieval system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kernel design; Object recognition; Video object retrieval;
   Spatio-Temporal Tube Kernel
AB In this article, we propose a new video object retrieval system. Our approach is based on a Spatio-Temporal data representation, a dedicated kernel design and a statistical learning toolbox for video object recognition and retrieval. Using state-of-the-art video object detection algorithms (for faces or cars, for example) we segment video object tracks from real movies video shots. We then extract, from these tracks, sets of spatio-temporally coherent features that we call Spatio-Temporal Tubes. To compare these complex tube objects, we design a Spatio-Temporal Tube Kernel (STTK) function. Based on this kernel similarity we present both supervised and active learning strategies embedded in Support Vector Machine framework. Additionally, we propose a multi-class classification framework dealing with unbalanced data. Our approach is successfully evaluated on two real movies databases, the french movie "L'esquive" and episodes from "Buffy, the Vampire Slayer" TV series. Our method is also tested on a car database (from real movies) and shows promising results for car identification task.
C1 [Zhao, Shuji; Precioso, Frederic] Univ Cergy Pontoise, ETIS Lab, CNRS, ENSEA, F-95000 Cergy Pontoise, France.
   [Cord, Matthieu] Univ Paris 04, UPMC, LIP6, F-75005 Paris, France.
C3 CY Cergy Paris Universite; Centre National de la Recherche Scientifique
   (CNRS); Sorbonne Universite
RP Zhao, SJ (corresponding author), Univ Cergy Pontoise, ETIS Lab, CNRS, ENSEA, 6 Av Ponceau, F-95000 Cergy Pontoise, France.
EM zhao@ensea.fr; precioso@ensea.fr; matthieu.cord@lip6.fr
FU Region Ile-de-France [2007-34HD Digiteo]
FX This work is funded by Region Ile-de-France, project k-VideoScan
   2007-34HD Digiteo.
CR [Anonymous], 2008, ECCV
   [Anonymous], 1998, FAST TRAINING SUPPOR
   [Anonymous], 1997, 1602 AI MIT
   [Anonymous], 2007, ICCV
   [Anonymous], 2001, ICML
   [Anonymous], BMVC
   Apostoloff N. E., 2007, BMVC
   Cour T., 2009, CVPR
   Ekenel HK, 2009, LECT NOTES COMPUT SC, V5558, P299, DOI 10.1007/978-3-642-01793-3_31
   Gosselin PH, 2008, IEEE T IMAGE PROCESS, V17, P1200, DOI 10.1109/TIP.2008.924286
   Guillaumin M., 2008, Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, P1
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LYU S, 2004, TR2004520 DARTM COLL
   Morik K, 1999, MACHINE LEARNING, PROCEEDINGS, P268
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Sivic J., 2009, CVPR
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wu G., 2003, CLASS BOUNDARY ALIGN, DOI 10.1.1.94.9007
   Yan R., 2003, ICCV
   ZHAO S, 2008, EUSIPCO LAUS SWITZ
   Zhao S., 2009, ICIP
NR 24
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2011
VL 55
IS 1
SI SI
BP 105
EP 125
DI 10.1007/s11042-010-0602-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 797PS
UT WOS:000293140400006
DA 2024-07-18
ER

PT J
AU Wakamiya, S
   Kitayama, D
   Sumiya, K
AF Wakamiya, Shoko
   Kitayama, Daisuke
   Sumiya, Kazutoshi
TI Scene extraction system for video clips using attached comment interval
   and pointing region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video sharing; Scene extraction; User comments; Selected
   area; Temporal duration
AB A method was developed to enable users of video sharing websites to easily retrieve video scenes relevant to their interests. The system analyzes both text and non-text aspects of a user's comment and then retrieves and displays relevant scenes along with attached comments. The text analysis works in tandem with non-text features, namely, the selected area and temporal duration associated with user comments. In this way, our system supports a better-organized retrieval of scenes that have been commented on with a higher degree of relevancy than conventional methods, such as using matching keywords. We describe our method and the relation between the scenes and discuss a prototype system.
C1 [Wakamiya, Shoko; Kitayama, Daisuke; Sumiya, Kazutoshi] Univ Hyogo, Himeji, Hyogo, Japan.
C3 University of Hyogo
RP Wakamiya, S (corresponding author), Univ Hyogo, Himeji, Hyogo, Japan.
EM nd09a025@stshse.u-hyogo.ac.jp; ne07p001@stshse.u-hyogo.ac.jp;
   sumiya@shse.u-hyogo.ac.jp
FU Ministry of Education, Culture, Sports, Science, and Technology of Japan
   [20300039]; Grants-in-Aid for Scientific Research [20300039] Funding
   Source: KAKEN
FX This research was supported in part by a Grant-in-Aid for Scientific
   Research (B)(2) 20300039 and Grant-in-Aid for JSPS Fellows 21.197 from
   the Ministry of Education, Culture, Sports, Science, and Technology of
   Japan.
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], P IEEE CS C COMP VIS
   Baluja Shumeet, 2008, P 17 INT C WORLD WID, P895, DOI DOI 10.1145/1367497.1367618
   BRAUDY L, 2004, FILM THEOR CRITICISM
   DAO MS, 2008, P 1 ACM WORKSH AN RE, V26, P33
   FUKINO N, 2003, P 14 DAT ENG WORKSH
   Gong YH, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P850, DOI 10.1109/MMCS.1999.779312
   Karpenko A, 2008, IEEE INT SYM MULTIM, P619, DOI 10.1109/ISM.2008.53
   Kimura T, 2005, IEEE PACIF, P149
   Kitayama D, 2008, 2008 INTERNATIONAL WORKSHOP ON INFORMATION-EXPLOSION AND NEXT GENERATION SEARCH : INGS 2008, PROCEEDINGS, P55, DOI 10.1109/INGS.2008.19
   MASUDA T, 2008, VIDEO SCENE RETRIEVA
   Miura K, 2006, IEEE INT SYM MULTIM, P873
   MIYAMORI H, 2005, P 13 ANN ACM INT C M, P853
   Nakamura S., 2008, P 2 ACM WORKSHOP INF, P59, DOI [10.1145/1458527.1458542, DOI 10.1145/1458527.1458542]
   Pradhan S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P788, DOI 10.1109/MMCS.1999.778586
   SARACENO C, 1997, P INT C IM PROC ICIP, V3, P116
   Shen EdwardYu-Te., 2009, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '09, P809
   Su J.-H., 2008, P 9 INT WORKSH MULT, P36
   Sundaram H., 2000, Proceedings ACM Multimedia 2000, P95, DOI 10.1145/354384.354440
   TAHAGHOGHI SMM, 2005, P 28 AUSTR C COMP SC, P193
   Uehara H, 2005, 2005 SYMPOSIUM ON APPLICATIONS AND THE INTERNET, PROCEEDINGS, P334, DOI 10.1109/SAINT.2005.14
   WANG J, 2008, P 10 ACM INT C MULT, P243
   Wu SY, 2007, IEEE T KNOWL DATA EN, V19, P742, DOI [10.1109/TKDE.2007.190613, 10.1109/TKDE.2007.1032.]
   YAMAMOTO D, 2004, P 3 INT SEM WEB C
   Yamamoto D, 2008, IEEE MULTIMEDIA, V15, P22, DOI 10.1109/MMUL.2008.67
   YOSHITAKA A, 2001, P IEEE INT C MULT EX, V3, P48
   2010, SYNVIE
   2010, SLOTHLIB
NR 28
TC 4
Z9 4
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 7
EP 25
DI 10.1007/s11042-010-0531-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100002
DA 2024-07-18
ER

PT J
AU Cardillo, D
   Rapp, A
   Benini, S
   Console, L
   Simeoni, R
   Guercio, E
   Leonardi, R
AF Cardillo, Daniela
   Rapp, Amon
   Benini, Sergio
   Console, Luca
   Simeoni, Rossana
   Guercio, Elena
   Leonardi, Riccardo
TI The art of video MashUp: supporting creative users with an innovative
   and smart application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video MashUp; Easy-to-use and intuitive interface; Inexpert users;
   Intelligent system
ID TV
AB In this paper, we describe the development of a new and innovative tool of video mashup. This application is an easy to use tool of video editing integrated in a cross-media platform; it works taking the information from a repository of videos and puts into action a process of semi-automatic editing supporting users in the production of video mashup. Doing so it gives vent to their creative side without them being forced to learn how to use a complicated and unlikely new technology. The users will be further helped in building their own editing by the intelligent system working behind the tool: it combines semantic annotation (tags and comments by users), low level features (gradient of color, texture and movements) and high level features (general data distinguishing a movie: actors, director, year of production, etc.) to furnish a pre-elaborated editing users can modify in a very simple way.
C1 [Cardillo, Daniela; Console, Luca] Univ Turin, Dept Comp Sci, Turin, Italy.
   [Rapp, Amon; Guercio, Elena] Univ Turin, Progetto Lagrange Fdn CRT, Telecom Italia, Turin, Italy.
   [Benini, Sergio; Leonardi, Riccardo] Univ Brescia, Brescia, Italy.
   [Simeoni, Rossana] Telecom Italia Lab, Res & Trends, Turin, Italy.
C3 University of Turin; University of Turin; Telecom Italia; University of
   Brescia; Telecom Italia
RP Cardillo, D (corresponding author), Univ Turin, Dept Comp Sci, Turin, Italy.
EM cardillo@di.unito.it; amon.rapp@guest.telecomitalia.it;
   sergio.benini@ing.unibs.it; lconsole@di.unito.it;
   rossana.simeoni@telecomitalia.it; elena.guercio@telecomitalia.it;
   riccardo.leonardi@ing.unibs.it
RI Rapp, Amon/P-8663-2016; Leonardi, Riccardo/F-5666-2010
OI Rapp, Amon/0000-0003-3855-9961; Leonardi, Riccardo/0000-0003-0755-1924
CR Adami N., 1999, Picture Coding Symposium '99, P157
   Aimeri Luca., 2002, Manuale Dei Generi Cinematografici: Hollywood, dalle Origini a Oggi [Handbook of the Film Genres: Hollywood, from its Origins to the Present Days]
   ANDERSON C, 2005, WIRED           0713
   Askwith Ivan, 2007, Master's thesis
   Benini S., 2005, P WIAMIS 05 MONTR SW
   BENINI S, 2008, P ICIP 08 SAN DIEG C
   BENINI S, 2006, P INT C IM PROC ICIP
   BOCCONI S, 2004, P 12 ANN ACM INT C M
   Bordwell D., 2003, FILM ART INTRO, V7th
   Bordwell David., 1997, HIST FILM STYLE
   Bordwell David., 1994, Film History: An Introduction
   Brusilovsky P, 1996, USER MODEL USER-ADAP, V6, P87, DOI 10.1007/BF00143964
   CASARES J, 2002, P ACM C DES INT SYST
   CASETTI F, 1990, ANALISI FILM
   CASSANI D, 2006, MANUALE MONTAGGIO
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   *CTR SOC MED, 2008, REC REFR REC
   DIAKOPOULOS N, 2007, P HYP HYP MANCH UK S
   FORLAI L, 1998, ARCHETIPI MITICI GEN
   Gallagher O., 2008, VIDEO RECUTS REMIX R
   GIEST M, 2007, BBC NEWS
   GIRGENSOHN A, 2000, P UIST 2000
   HANJALIC A, 1999, IEEE T CIRCUITS SYST, V9
   HUA X, 2005, P ACM MULT 2005
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Jenkins Henry, 2006, CONVERGENCE CULTURE
   Kuleshov L., 1974, KULESHOV FILM WRITIN
   KUMANO M, 2002, P MVA 2002, P310
   LEVISTRAUSS C, 1974, SAVAGE MIND LONDON
   Moine R., 2005, I generi del cinema
   MU X, 2003, P SIGIR 2003
   Mu XM, 2003, P ASIST ANNU, V40, P316, DOI 10.1002/meet.1450400139
   PENG WT, 2008, P INT MULT MOD C 200
   Rondolino Gianni., 1995, Manuale del film. Linguaggio, racconto
   SCHWARZ K, 2005, FORMAL ONTOLOGIES ME
   SHAW R, 2006, ACM MULT 2006 OCT 23
   Simeoni R, 2008, LECT NOTES COMPUT SC, V5066, P238, DOI 10.1007/978-3-540-69478-6_32
   Simeoni R, 2007, LECT NOTES COMPUT SC, V4552, P971
   Stefik M., 1995, INTRO KNOWLEDGE SYST
   TOMASI D, 2004, LEZIONI REGIA MODELL
   TOMASINO R, 1998, FIGURE IMMAGINARIO C
   VELLAR A, 2008, P IADIS INT C INT HU
   WANG J, 2005, P ACM MULT 2005
   ZENG W, 2002, P ICIP 2002 ROCH NY, V1, P912
NR 45
TC 5
Z9 5
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 1
EP 23
DI 10.1007/s11042-009-0449-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hou, J
   Qian, JR
   Zhang, WJ
   Zhao, ZZ
   Pan, P
AF Hou, Jie
   Qian, Jiaru
   Zhang, Weijing
   Zhao, Zuozhou
   Pan, Peng
TI Fire detection algorithms for video images of large space structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE NAUTEA; Probability density algorithm; FNN; FGALSSVM; Dempster-Shafer
   (DS); Historical data fusion
AB In large space structures, the latest fire detection methods are based on video image processing and data fusion. But the false positive rate and false negative rate remain unsatisfactory and need improving. The emphases of this paper are target extraction and recognition. A new adaptively updating target extraction algorithm (NAUTEA) is proposed by which the intact target can be extracted in time. In addition, some fire video image recognition algorithms, such as fuzzy neural network (FNN) and FGALSSVM (Fuzzy GALSSVM), are studied and improved. To verify the performance of these algorithms, a prototype system is developed, and a series of algorithm tests on a fire video are conducted. These tests make it clear that, the accurate, robust and real-time fire detection can be realized.
C1 [Hou, Jie; Qian, Jiaru; Zhao, Zuozhou; Pan, Peng] Tsinghua Univ, Dept Civil Engn, Beijing 100084, Peoples R China.
   [Zhang, Weijing] Beijing Univ Technol, Coll Architecture & Civil Engn, Beijing 100124, Peoples R China.
C3 Tsinghua University; Beijing University of Technology
RP Hou, J (corresponding author), Tsinghua Univ, Dept Civil Engn, Beijing 100084, Peoples R China.
EM houj06@mails.tsinghua.edu.cn; qianjr@mail.tsinghua.edu.cn;
   zhangweijing@bjut.edu.cn; zzzhao@mail.tsinghua.edu.cn;
   panpeng@mail.tsinghua.edu.cn
RI PAN, PAN/IWV-1122-2023; Zhang, Weijing/GQA-9455-2022
CR BENMOKHTAR R, 2006, LECT NOTES COMPUTER, P196
   Beynon M, 2000, OMEGA-INT J MANAGE S, V28, P37, DOI 10.1016/S0305-0483(99)00033-X
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Campbell C, 2002, NEUROCOMPUTING, V48, P63, DOI 10.1016/S0925-2312(01)00643-9
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Dempster AP, 2008, STUD FUZZ SOFT COMP, V219, P57
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   HOU J, 2009, P 2 INT C I IN PRESS
   Huseynov JJ, 2008, NEURAL NETWORKS, V21, P398, DOI 10.1016/j.neunet.2007.12.018
   LIAN Q, 2007, CHINA INSTRUM, V6, P65
   Meier T, 1999, IEEE T CIRC SYST VID, V9, P1190, DOI 10.1109/76.809155
   SENTZ K, 2002, THESIS BINGHAMTON U
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wu L. B., 2006, FIRE DETECTION INFOR
   Xiao JM, 2003, IEEE INT CONF FUZZY, P1459
   XU LM, 2005, J COMMUN COMPUT, V2, P18
   Zadeh L. A., 1986, AI magazine, V7, P85, DOI 10.1609/aimag.v7i2.542
NR 21
TC 12
Z9 12
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 45
EP 63
DI 10.1007/s11042-009-0451-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500005
DA 2024-07-18
ER

PT J
AU Su, XQ
   Ji, L
   Li, XA
AF Su, XiuQin
   Ji, Lei
   Li, Xiang
TI A fast and low complexity approach for H.264/AVC intra mode decision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE H,264/AVC; DPD; Intra prediction; Fast algorithm
AB As one of the main features of H.264/AVC, intra prediction coding technique acts as a basis for encoding performance and efficiency. In official reference software Joint Model (JM), it employs the rate distortion optimization (RDO) technique to get to the best encoding performance. By full searching (FS) all of the candidate modes under the rule of RDO, peak-signal-noise-rate (PSNR) decreases to a very low level, but at the same time, the complexity of calculation increases a lot. Many researchers had devoted to searching the fast algorithm which can decrease the complexity, and had designed so many excellent and intelligent fast algorithms. In this paper we introduced a low complexity and fast approach for H.264/AVC intra prediction algorithm. The new approach is based on reducing the number of candidate modes for further RDO calculation, and decreasing the computational complicacy. It can decide the interpolation direction accurately by calculating the directional pixel-value differences (DPD) of target block, and then do statistic with the obtained values to choose the most probable modes. The experimental results demonstrate that the proposed algorithm can achieve more than 70% time saving than JM, but only a tiny degradation of encoding performance is brought in.
C1 [Su, XiuQin; Ji, Lei; Li, Xiang] Chinese Acad Sci, Xian Inst Opt & Precis Mech IOPM, Key Lab Ultrafast Photoelect Diagnost Technol, Xian 710119, Shaanxi, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS
RP Su, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech IOPM, Key Lab Ultrafast Photoelect Diagnost Technol, Xian 710119, Shaanxi, Peoples R China.
EM xqsu@opt.ac.cn
CR Bharanitharan K, 2008, IEEE T MULTIMEDIA, V10, P1250, DOI 10.1109/TMM.2008.2004904
   *ITU T, DRAFT ITU T IN PRESS
   LIU X, 2008, INT S PAR DISTR PROC, P510
   PAN F, 2005, IEEE T CIRCUIT SYSTE, V15, P823
   Sarwer MG, 2008, SIGNAL PROCESS-IMAGE, V23, P571, DOI 10.1016/j.image.2008.05.002
   SU Y, 2005, IEEE INT S CIRC SYST, V2, P1234
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Wang Fengqin, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P245, DOI 10.1049/cp:20080316
   Wang ZN, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1563
   H 264 MPEG 4 10
NR 10
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 65
EP 76
DI 10.1007/s11042-009-0452-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500006
DA 2024-07-18
ER

PT J
AU Canada, BA
   Thomas, GK
   Cheng, KC
   Wang, JZ
AF Canada, Brian A.
   Thomas, Georgia K.
   Cheng, Keith C.
   Wang, James Z.
TI SHIRAZ: an automated histology image annotation system for zebrafish
   phenomics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; High-throughput phenotyping;
   Information-based similarity metrics; Computational symmetry
ID RETRIEVAL; MODEL
AB Histological characterization is used in clinical and research contexts as a highly sensitive method for detecting the morphological features of disease and abnormal gene function. Histology has recently been accepted as a phenotyping method for the forthcoming Zebrafish Phenome Project, a large-scale community effort to characterize the morphological, physiological, and behavioral phenotypes resulting from the mutations in all known genes in the zebrafish genome. In support of this project, we present a novel content-based image retrieval system for the automated annotation of images containing histological abnormalities in the developing eye of the larval zebrafish.
C1 [Canada, Brian A.] Univ S Carolina, Dept Sci & Math, Beaufort, SC USA.
   [Thomas, Georgia K.] SUNY Upstate Med Univ, Sch Med, Syracuse, NY USA.
   [Cheng, Keith C.] Penn State Coll Med, Jake Gittlen Canc Res Fdn, Hershey, PA USA.
   [Wang, James Z.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA 16802 USA.
C3 University of South Carolina System; University of South Carolina
   Columbia; State University of New York (SUNY) System; State University
   of New York (SUNY) Upstate Medical Center; Pennsylvania Commonwealth
   System of Higher Education (PCSHE); Pennsylvania State University; Penn
   State Health; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Canada, BA (corresponding author), Univ S Carolina, Dept Sci & Math, Beaufort, SC USA.
EM brian.canada@gmail.com; gkt612@gmail.com; kcheng76@gmail.com;
   jwang@ist.psu.edu
RI Wang, James/JAD-0675-2023; Cheng, Keith C/B-6506-2011
OI Wang, James/0000-0003-4379-4173; Cheng, Keith/0000-0002-5350-5825
FU Penn State Academic Computing Fellowship; Penn State Clinical and
   Translational Sciences Institute; NIH NCRR [R24 RR01744]; Jake Gittlen
   Cancer Research Foundation; Pennsylvania Tobacco Settlement Funds; Penn
   State Graduate fellowship; NSF [0347148, 0219272, 0821527]; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [0347148] Funding Source: National Science Foundation; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [0219272] Funding Source: National Science Foundation; Office Of
   The Director; EPSCoR [0903795] Funding Source: National Science
   Foundation
FX The work of B. A. Canada was supported by the Penn State Academic
   Computing Fellowship as well as the Penn State Clinical and
   Translational Sciences Institute. This work was also supported by NIH
   NCRR grant R24 RR01744 for the Zebrafish Atlas, as well as by grants
   from the Jake Gittlen Cancer Research Foundation and Pennsylvania
   Tobacco Settlement Funds to K. C. Cheng and a Penn State Graduate
   fellowship to G. K. Thomas. J. Z. Wang is supported by NSF Grant No.
   0347148; in addition, NSF has provided computation infrastructure
   through Grant Nos. 0219272 and 0821527. The authors wish to thank the
   following current and former members of the Jake Gittlen Cancer Research
   Foundation for their invaluable assistance over the course of this
   project: Steven Peckins, for technical support in the processing of very
   high resolution images; Kelsey Bauer, for pre-segmentation hand labeling
   of histological specimens; as well as Jean Copper, Christina Foutz, and
   Lynn Budgeon for their efforts in preparing and digitizing the source
   microscope slides. Finally, the authors thank Yanxi Liu (Penn State
   Department of Computer Science and Engineering) for helpful discussions
   regarding computational symmetry.
CR [Anonymous], 2008, P 2008 INT C CONTENT, DOI DOI 10.1145/1386352.1386436
   [Anonymous], 1983, INTRO MODERN INFORM
   Canada B.a., 2008, PROC 2008 INT C CONT, P581
   CANADA BA, 2007, P 3 IEEE NIH LIF SCI, P245
   Canada BA, 2008, IEEE IMAGE PROC, P1452, DOI 10.1109/ICIP.2008.4712039
   Colquhoun P, 2003, DIS COLON RECTUM, V46, P1332, DOI 10.1007/s10350-004-6744-5
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DAUBECHIES I, 1992, TEN LECTURES WAVELET
   DEMIR C, 2005, TR0509 DEP COMP SCI
   DOYLE S, 2006, P IEEE EMBS, P4759
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   GOU F, 2008, P 34 INT C VER LARG, P1508
   Grunbaum B., 1987, Tilings and Patterns
   GURCAN MN, 2007, OSUBMITR2007N10 OH U
   Hamilton PW, 1997, J PATHOL, V182, P68
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hays J, 2006, LECT NOTES COMPUT SC, V3952, P522
   Lee S.S., 2008, Checklist of fungi of Malaysia. Research pamplet No. 132, P1
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Lin WC, 2007, IEEE T PATTERN ANAL, V29, P777, DOI 10.1109/TPAMI.2007.1053
   Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332
   Lussier Yves A, 2007, Proc Am Thorac Soc, V4, P18, DOI 10.1513/pats.200607-142JG
   Mitra S., 2003, Data mining: multimedia, soft computing, and bioinformatics
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nfisslein-Volhard C., 2002, ZEBRAFISH PRACTICAL
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Petrou Maria., 2006, IMAGE PROCESSING DEA
   PLOTNICK RE, 1993, LANDSCAPE ECOL, V8, P201, DOI 10.1007/BF00125351
   Plummer M, 1997, INT J EPIDEMIOL, V26, P716, DOI 10.1093/ije/26.4.716
   Sabaliauskas NA, 2006, METHODS, V39, P246, DOI 10.1016/j.ymeth.2006.03.001
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tang HL, 2003, IEEE T INF TECHNOL B, V7, P26, DOI 10.1109/TITB.2003.808500
   Tsao-Wu GS, 1998, BIOTECHNIQUES, V25, P614, DOI 10.2144/98254st02
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Weirauch MT, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-463
   ZHAO D, 2005, P IEEE INT C IM PROC, V3, P628
   ZEBR PHEN PROJ 2010
   PENN STATE ZEBRAFISH
   CALTECH 101 IMAGE DA
NR 41
TC 7
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 401
EP 440
DI 10.1007/s11042-010-0638-4
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300002
PM 21461317
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Luo, HZ
   Fan, JP
   Zhou, YJ
AF Luo, Hangzai
   Fan, Jianping
   Zhou, Youjie
TI Multimedia news exploration and retrieval by integrating keywords,
   relations and visual features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia news exploration; Semantic entity-relationship model; Visual
   recommendation
ID IMAGE RETRIEVAL; SEGMENTATION; ACHIEVE
AB Multimedia news may be organized by the keywords and categories for exploration and retrieval applications, but it is very difficult to integrate the relation and visual information into the traditional category browsing and keyword-based search framework. This paper propose a new semantic model that can integrate keyword, relation and visual information in a uniform framework. Based on this semantic representation framework, the news exploration and retrieval applications can be organized by not only keywords and categories but also relations and visual properties. We also proposed a set of algorithms to automatically extract the proposed semantic model automatically from large collection of multimedia news reports.
C1 [Luo, Hangzai] E China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai 200062, Peoples R China.
   [Fan, Jianping; Zhou, Youjie] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 East China Normal University; University of North Carolina; University
   of North Carolina Charlotte
RP Luo, HZ (corresponding author), E China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai 200062, Peoples R China.
EM hzluo@sei.ecnu.edu.cn; jfan@uncc.edu; yzhou18@uncc.edu
FU Shanghai Pujiang Program [08PJ1404600]; NSF-China [60803077]; Shanghai
   leading academic discipline project [B412]; East China Normal
   University; Direct For Computer & Info Scie & Enginr; Div Of Information
   & Intelligent Systems [0946400] Funding Source: National Science
   Foundation
FX This work is supported by Shanghai Pujiang Program under 08PJ1404600,
   NSF-China under 60803077, Shanghai leading academic discipline project
   under B412 and East China Normal University Science Innovation Fund.
CR Barzilay R, 2002, J ARTIF INTELL RES, V17, P35, DOI 10.1613/jair.991
   Bollegala D, 2010, INFORM PROCESS MANAG, V46, P89, DOI 10.1016/j.ipm.2009.07.004
   BOU B, 2005, HYPERBOLIC TREE ENGI
   Carson C., 1999, LECT NOTES COMPUTER, V1614, P509, DOI DOI 10.1007/3-540-48762-X_63
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SF, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P531, DOI 10.1109/ICIP.1998.727321
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fan JP, 2008, IEEE T IMAGE PROCESS, V17, P407, DOI 10.1109/TIP.2008.916999
   Fauqueur J, 2004, J VISUAL LANG COMPUT, V15, P69, DOI 10.1016/j.jvlc.2003.08.002
   Finkel Jenny Rose, 2005, ACL, P363
   Goh K, 2005, ACM T MULTIM COMPUT, V1
   GONG W, 2009, ACM MULTIMEDIA GRAND, P1123
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   HARRIS J, 2004, TENBYTEN
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hetzler B, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P137, DOI 10.1109/INFVIS.1998.729570
   Hoiem D, 2004, PROC CVPR IEEE, P490
   Joachims T., 2002, LEARNING CLASSIFY TE
   KHOSHGOFTAAR TM, 2007, ICML, V227, P935
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lamping J, 1996, J VISUAL LANG COMPUT, V7, P33, DOI 10.1006/jvlc.1996.0003
   Li Beitao., 2003, Proceedings of the Eleventh ACM International Conference on Multimedia, P195
   LOUCHNIKOVA T, 2002, SPIE INTERNET IMAGIN, P203
   LUO H, 2007, IEEE S VIS AN SCI TE
   LUO H, 2004, ACM MULT WORKSH MULT, P213
   Luo HZ, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1324287.1324288
   MADNANI N, 2007, 11 EUR WORKSH NAT LA
   MCCALLUM A, 2003, NATURAL LANGUAGE LEA, P188
   McEnery T., 2004, The Lancaster Corpus of Mandarin Chinese
   Mehler A, 2006, IEEE T VIS COMPUT GR, V12, P765, DOI 10.1109/TVCG.2006.179
   Radev D, 2005, COMMUN ACM, V48, P95, DOI 10.1145/1089107.1089111
   RUBNER Y, 1999, IEEE INT C COMP VIS, P1018
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Snoek CGM, 2006, ACM T MULTIM COMPUT, V2, P91, DOI 10.1145/1142020.1142021
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   Swan R., 2000, ACM SIGKDD 2000 WORK, P73
   WAGSTAFF J, 2005, NEWS VISUALIZATION
   WALTER JA, 2002, ACM SIGKDD
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P85, DOI 10.1109/34.899949
   Weskamp Marcos., 2004, Newsmap
   Wise J., 1995, IEEE Symposium on Information Visualization, V0, P51
   Yuan Jinhui., 2006, P 14 ANN ACM INT C M, P441
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 47
TC 1
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 625
EP 648
DI 10.1007/s11042-010-0639-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300009
DA 2024-07-18
ER

PT J
AU Nahrstedt, K
   Arefin, A
   Rivas, R
   Agarwal, P
   Huang, ZX
   Wu, WM
   Yang, ZY
AF Nahrstedt, Klara
   Arefin, Ahsan
   Rivas, Raoul
   Agarwal, Pooja
   Huang, Zixia
   Wu, Wanmin
   Yang, Zhenyu
TI QoS and resource management in distributed interactive multimedia
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality of service; Resource management; DIME; Bandwidth management;
   Delay management
ID SEARCH ALGORITHM; CONCEALMENT; SCHEME; DELAY
AB Quality of Service (QoS) is becoming an integral part of current ubiquitous Distributed Interactive Multimedia Environments (DIMEs) because of their high resource and real-time interactivity demands. It is highly influenced by the management techniques of available resources in these cyber-physical environments. We consider QoS and resource management influenced by two most important resources; the computing (CPU) and networking resources. In this paper, we survey existing DIME-relevant QoS and resource management techniques for these two resources, present their taxonomy, compare them, and show their impacts on DIMEs. Finally, we discuss appropriateness of those techniques in a sample DIME scenario.
C1 [Nahrstedt, Klara; Arefin, Ahsan; Rivas, Raoul; Agarwal, Pooja; Huang, Zixia; Wu, Wanmin] Univ Illinois, Dept Comp Sci, Urban, IL 61801 USA.
   [Yang, Zhenyu] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign;
   State University System of Florida; Florida International University
RP Nahrstedt, K (corresponding author), Univ Illinois, Dept Comp Sci, 201 N Goodwin Ave, Urban, IL 61801 USA.
EM klara@illinois.edu; marefin2@illinois.edu; trivas@illinois.edu;
   pagarwl@illinois.edu; zhuang21@illinois.edu; wwu23@illinois.edu;
   yangz@cis.fiu.edu
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [0834480] Funding Source: National Science Foundation
CR Agarwal V, 2005, P 12 ANN MULT COMP N
   [Anonymous], 2008, 15882008 IEEE
   [Anonymous], 1997, 2205 RFC
   [Anonymous], 1998, RFC 2474
   ANTONIADES D, 2006, P PASS ACT MEAS PAM
   Baccichet P, 2005, IEEE T CONSUM ELECTR, V51, P227, DOI 10.1109/TCE.2005.1405724
   Baker HH, 2005, ACM T MULTIM COMPUT, V1
   Banachowski SA, 2002, P MULT COMP NETW MMC
   Boutremans C, 2003, IEEE INFOCOM SER, P652
   Brandt SA, 2003, RTSS 2003: 24TH IEEE INTERNATIONAL REAL-TIME SYSTEMS SYMPOSIUM, PROCEEDINGS, P396, DOI 10.1109/REAL.2003.1253287
   Castro M., 2003, Operating Systems Review, V37, P298, DOI 10.1145/1165389.945474
   Castro M, 2002, IEEE J SEL AREA COMM, V20, P1489, DOI 10.1109/JSAC.2002.803069
   CHANG SF, 2001, P IEEE WORKSH CONT B
   Chu H-H, 1999, P IEEE INT C MULT CO, V1
   Chu Y, 2000, P ACM ANN C ACM SPEC
   Daniilidis F, 1999, P ANN C ACM SPEC INT
   Deering S. E., 1988, Computer Communication Review, V18, P55, DOI 10.1145/52325.52331
   Fernandez-Escribano G, 2006, IEEE IMAGE PROC, P869, DOI 10.1109/ICIP.2006.312506
   Gautier L, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P233, DOI 10.1109/MMCS.1998.693647
   Goldenstein S, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P52, DOI 10.1109/CGI.1999.777905
   Hellerstein JL, 1993, IEEE T SOFTW ENG
   Hosseini M, 2003, P 11 ACM INT C MULT
   Huang C-M, 2009, P IEEE INT C COMP SC
   Huang Y-L, 2009, P ACM MULT MM 09
   Huang Z, 2010, P INT WORKSH NETW OP
   HWANG FK, 1992, NETWORKS, V22, P55, DOI 10.1002/net.3230220105
   ITU-G.114, 2003, 114 ITUG
   Jain M, 2002, P 3 PASS ACT MEAS PA
   JAIN M, 2003, IEEE ACM T NETW
   Jeffay K, 1998, P REAL TIM SYST S RT, V0
   Jia XH, 1998, IEEE ACM T NETWORK, V6, P828, DOI 10.1109/90.748092
   Kompella VP, 1993, IEEE ACM T NETW
   Kostic D, 2003, ACM SIGOPS OPERATING, V3
   Kurillo G, 2008, P IEEE INT S MULT IS
   Lee H, 1997, P INT C MULT COMP SY
   Lee X, 1996, IEEE T CIRC SYST VID, V6, P627, DOI 10.1109/76.544734
   Liang YJ, 2003, IEEE T MULTIMEDIA, V5, P532, DOI 10.1109/TMM.2003.819095
   Little T., 1993, Multimedia System, V1, P87
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   Liu HN, 2006, WIREL NETW, V12, P511, DOI 10.1007/s11276-006-6549-7
   Liu J, 2004, 2004 JOINT CONFERENCE OF THE 10TH ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS AND THE 5TH INTERNATIONAL SYMPOSIUM ON MULTI-DIMENSIONAL MOBILE COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P597
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Liu T, 2004, P ACM MULT MM 04
   Liu T., 2004, Proceedings of the 12th annual ACM international conference on Multimedia - MULTIMEDIA '04, P400, DOI DOI 10.1145/1027527.1027622
   Nahrstedt K, 1998, J HIGH SPEED NETW, V7, P229
   NAHRSTEDT K, 1995, COMPUTER, V28, P52, DOI 10.1109/2.384118
   Nahrstedt K, 1997, STABILITY ADAPTATION
   Narbutt M, 2005, IEEE INTERNET COMPUT, V9, P28, DOI 10.1109/MIC.2005.72
   Nguyen H, 2009, P INT ICST C HET NET
   Nieh J, 2003, ACM T COMPUT SYST, V21, P117, DOI 10.1145/762483.762484
   POSIX, 1992, 10034 POSIX
   Rajkumar R., 1998, Proceedings of the SPIE/ACM Conference on Multimedia Computing and Networking, P150
   Ramjee R, 2004, P 13 IEEE ANN JOINT, V2, P680
   Rivas R, 2010, P 4 INT WORKSH VIRT
   Russinovich M, 2007, INSIDE WINDOWS VIS 1
   Saroiu S., 2002, P IEEE INT C COMP CO
   Sat B, 2007, P IEEE INT S MULT IS
   SAVAGE S, 1999, P USENIX S INT TECHN
   Sheppard R, 2008, P ACM INT C MULT MM
   SHIN I, 2003, P 24 IEEE INT REAL T
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   Stoica I., 1995, Earliest Eligible Virtual Deadline First: A Flexible and Accurate Mechanism for Proportional Share Resource Allocation
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tommasi F, 2000, SOME EXTENS IN PRESS
   Vasudevan G.K. R. B. Ramanarayan., 2010, Proceedings of the first annual ACM SIGMM conference on Multimedia systems, MMSys '10, P281
   Vickers BJ, 2000, IEEE ACM T NETWORK, V8, P720, DOI 10.1109/90.893869
   Wah BW, 1999, IEEE T MULTIMEDIA, V1, P342, DOI 10.1109/6046.807954
   WALDSPURGER C, 1995, THESIS MIT
   Wang L, 1999, RSVP REFRESH OVERHEA
   Wu W, 2008, P IEEE INT S MULT IS
   Wu W., 2008, P AACE WORLD C ED MU
   Wu W, 2009, P ACM MULT MM 09
   Xin J, 2004, P PICT COD S
   Yang Z, 2006, P INT WORKSH NETW OP
   Yang Zhenyu, 2005, P IEEE INT S MULT IS
   Yeung A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P334, DOI 10.1109/ICIP.1997.647774
   Zhu Q, 1995, P IEEE INT C COMP CO
   [No title captured]
NR 78
TC 7
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 99
EP 132
DI 10.1007/s11042-010-0627-7
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800005
DA 2024-07-18
ER

PT J
AU Doulamis, A
AF Doulamis, Anastasios
TI Dynamic tracking re-adjustment: a method for automatic tracking recovery
   in complex visual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking recovery; Object detection; Event analysis
ID ROBUST OBJECT TRACKING; FILTER
AB Detection and analysis of events from video sequences is probably one of the most important research issues in computer vision and pattern analysis society. Before, however, applying methods and tools for analyzing actions, behavior or events, we need to implement robust and reliable tracking algorithms able to automatically monitor the movements of many objects in the scene regardless of the complexity of the background, existence of occlusions and illumination changes. Despite the recent research efforts in the field of object tracking, the main limitation of most of the existing algorithms is that they are not enriched with automatic recovery strategies able to re-initialize tracking whenever its performance severely deteriorates. This is addressed in this paper by proposing an automatic tracking recovery tool which improves the performance of any tracking algorithm whenever the results are not acceptable. For the recovery, non-linear object modeling tools are used which probabilistically label image regions to object classes. The models are also time varying. The first property is implemented in our case using concepts from functional analysis which allow parametrization of any arbitrary non-linear function (with some restrictions on its continuity) as a finite series of known functional components but of unknown coefficients. The second property is addressed by proposing an innovative algorithm that optimally estimates the non-linear model at an upcoming time instance based on the current non-linear models that have been already approximated. The architecture is enhanced by a decision mechanism which permits verification of the time instances in which tracking recovery should take place. Experimental results on a set of different video sequences that present complex visual phenomena (full and partial occlusions, illumination variations, complex background, etc) are depicted to demonstrate the efficiency of the proposed scheme in proving tracking in very difficult visual content conditions. Additionally, criteria are proposed to objectively evaluate the tracking performance and compare it with other strategies.
C1 Tech Univ Crete, Khania, Crete, Greece.
C3 Technical University of Crete
RP Doulamis, A (corresponding author), Tech Univ Crete, Polytechnioupolis Campus, Khania, Crete, Greece.
EM adoulam@ergasya.tuc.gr
RI Doulamis, Anastasios/AAL-5972-2021
FU European Union [FP7/2007-2013, 216465]
FX This work is supported by the European Union funded project SCOVIS "Self
   Configurable Cognitive Video Supervsion" supported by the Seventh
   Framework Programme (FP7/2007-2013) under grant agreement no 216465.
CR [Anonymous], 1981, P 7 INT JOINT C ART
   [Anonymous], P 3 IEEE WORKSH WAC
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Chen DT, 2007, IEEE T PATTERN ANAL, V29, P2157, DOI 10.1109/TPAMI.2007.1134
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Davatzikos C, 1996, IEEE T MED IMAGING, V15, P112, DOI 10.1109/42.481446
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Doulamis A, 2003, IEEE T NEURAL NETWOR, V14, P616, DOI 10.1109/TNN.2003.810605
   DOULAMIS A, 2008, ACM WORKSH AN RETR E
   DOULAMIS A, 2004, EUR WORKSH INT KNOWL
   DOULAMIS A, 2008, 16 ACM INT C MULT VA
   GRIMSON WEL, 1999, P INT C COMP VIS PAT, P22
   HEISELE B, 1997, P INT C COMP VIS PAT, P253
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kreyszig E., 1991, Introductory functional analysis with applications, V17
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Medeiros H, 2008, IEEE J-STSP, V2, P448, DOI 10.1109/JSTSP.2008.2001310
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Odobez JM, 2006, IEEE T IMAGE PROCESS, V15, P3514, DOI 10.1109/TIP.2006.877497
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Shahrokni A, 2004, LECT NOTES COMPUT SC, V3022, P566
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith G.J., 2004, SURVEILLANCE SOC, V2/, P376
   STENGER B, 2002, P INT C COMP VIS, P294
   Tekalp M., 1995, DIGITAL VIDEO PROCES
   Tsai DM, 2009, IEEE T IMAGE PROCESS, V18, P158, DOI 10.1109/TIP.2008.2007558
   Wang DM, 1998, IEEE T CIRC SYST VID, V8, P539, DOI 10.1109/76.718501
   Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]
   WANG P, 2005, 7 IEEE WORKSH APPL C, V1, P401
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yonemoto S, 2008, IEEE INT CONF INF VI, P521, DOI 10.1109/IV.2008.43
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P544, DOI 10.1109/34.857008
NR 37
TC 20
Z9 20
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2010
VL 50
IS 1
SI SI
BP 49
EP 73
DI 10.1007/s11042-009-0368-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 616HE
UT WOS:000279198900004
DA 2024-07-18
ER

PT J
AU Chen, SX
   Xiong, NX
   Park, JH
   Chen, M
   Hu, RM
AF Chen, Shuixian
   Xiong, Naixue
   Park, Jong Hyuk
   Chen, Min
   Hu, Ruimin
TI Spatial parameters for audio coding: MDCT domain analysis and synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio coding; MDCT; MDST; Singular value; Spatial parameter
ID FAST ALGORITHM; TRANSFORM; EFFICIENT; STANDARD
AB We use Modified Discrete Cosine Transform (MDCT) to analyze and synthesize spatial parameters. MDCT in itself lacks phase information and energy conservation, which are needed by spatial parameters representation. Completing MDCT with Modified Discrete Sine Transform (MDST) into "MDCT-j*MDST" overcomes this and enables the representation in a form similar to that of DFT. And due to overlap-add in time domain, a MDST spectrum can be built perfectly from MDCT spectra of neighboring frames through matrix-vector multiplication. The matrix is heavily diagonal and keeping only a small number of its sub-diagonals is sufficient for approximation. When using MDCT based core coder in spatial audio coding, like Advanced Audio Coding (AAC), we need no separate transforming for spatial processing, cutting down significantly the computational complexity. Subjective listening tests also show that MDCT domain spatial processing has no quality impairment.
C1 [Park, Jong Hyuk] Kyungnam Univ, Dept Comp Sci & Engn, Masan, South Korea.
   [Chen, Shuixian; Hu, Ruimin] Wuhan Univ, Comp Sch, Wuhan 430072, Peoples R China.
   [Xiong, Naixue] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.
   [Chen, Min] Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151744, South Korea.
C3 Kyungnam University; Wuhan University; University System of Georgia;
   Georgia State University; Seoul National University (SNU)
RP Park, JH (corresponding author), Kyungnam Univ, Dept Comp Sci & Engn, Masan, South Korea.
EM csx792@163.com; nxiong@cs.gsu.edu; parkjonghyuk1@hotmail.com;
   mchen@mmlab.snu.ac.kr
RI Chen, Min/N-9350-2015; xiong, naixue/M-4277-2019
OI Chen, Min/0000-0002-0960-4447; xiong, naixue/0000-0002-0394-4635
FU National Science Foundation of China [60832002]; MKE(Ministry of
   Knowledge Economy), Korea [IITA-2009-C1090-0902-0020]
FX This research was supported by National Science Foundation of China
   (grant 60832002) and MKE(Ministry of Knowledge Economy), Korea, under
   the ITRC(Information Technology Research Center) Support program
   supervised by the IITA(Institute of Information Technology Advancement)
   (IITA-2009-C1090-0902-0020)
CR *3GPP, 2005, 3GPP SPEC SER
   Algazi V. R., 2001, IEEE WORKSH APPL SIG
   Baumgarte F, 2003, IEEE T SPEECH AUDI P, V11, P509, DOI 10.1109/TSA.2003.818109
   Baumgarte F, 2002, INT CONF ACOUST SPEE, P1801
   BAUMGARTE F, 2002, 112 AES CONV MUN GER
   Blauert J., 1983, SPATIAL HEARING PSYC
   Bosi M, 1997, J AUDIO ENG SOC, V45, P789
   BOSI M, 2003, INTRO DIGITAL AUDIO, P333
   Breebaart J, 2005, EURASIP J APPL SIG P, V2005, P1305, DOI 10.1155/ASP.2005.1305
   Breebaart J, 2001, J ACOUST SOC AM, V110, P1074, DOI 10.1121/1.1383297
   BREEBAART J, 2005, 119 AES CONV NEW YOR
   Breebaart J, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/732895
   Breebaart J, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1878
   Breebaart J, 2007, J AUDIO ENG SOC, V55, P331
   CHENG CI, 2004, 116 AES CONV BERL GE
   Cheng MH, 2003, IEEE T SIGNAL PROCES, V51, P221, DOI 10.1109/TSP.2002.806566
   DISCH S, 2004, 117 AES CONV SAN FRA
   ENGDEGARD J, 2004, 116 AES CONV BERL GE
   Faller C, 2006, IEEE T AUDIO SPEECH, V14, P299, DOI 10.1109/TSA.2005.854105
   Faller C, 2003, IEEE T SPEECH AUDI P, V11, P520, DOI 10.1109/TSA.2003.818108
   Faller C, 2002, INT CONF ACOUST SPEE, P1841
   FALLER C, 2002, 11 AES CONV MUN GERM
   FALLER C, 2002, 113 AES CONV LOS ANG
   FALLER C, 2004, THESIS I SYSTEMES CO
   FALLER C, 2001, IEEE WORKSH APPL SIG
   FLIEGE NJ, 1994, INT CONF ACOUST SPEE, P149
   Gilkey R.H., 1997, BINAURAL SPATIAL HEA
   HERRE J, 2004, P 7 INT C DIG AUD EF, P157
   HERRE J, 2005, 118 AES CONV BARC SP
   Herre J, 2008, J AUDIO ENG SOC, V56, P932
   Hotho G, 2008, IEEE T AUDIO SPEECH, V16, P83, DOI 10.1109/TASL.2007.910768
   *ISO IEC JTC1 SC29, 2006, 2300312006FCD ISOIEC
   *ISO IEC JTC1 SC29, 2005, 1381872005E ISOIEC
   *ITU, 2003, ITURBS15341
   Joris P, 2007, TRENDS NEUROSCI, V30, P70, DOI 10.1016/j.tins.2006.12.004
   KARP T, 1995, IEEE INT SYMP CIRC S, P744, DOI 10.1109/ISCAS.1995.521624
   Malvar H., 1992, SIGNAL PROCESSING LA
   MALVAR H, 1999, P IEEE INT C AC SPEE
   MALVAR HS, 1989, IEEE T ACOUST SPEECH, V37, P553, DOI 10.1109/29.17536
   MALVAR HS, 1990, IEEE T ACOUST SPEECH, V38, P969, DOI 10.1109/29.56057
   Malvar HS, 2003, IEEE SIGNAL PROC LET, V10, P8, DOI 10.1109/LSP.2002.806700
   MALVAR HS, 1991, ELECTRON LETT, V27, P775, DOI 10.1049/el:19910482
   McAlpine D, 2001, NAT NEUROSCI, V4, P396, DOI 10.1038/86049
   Munkong R, 2008, IEEE SIGNAL PROC MAG, V25, P98, DOI 10.1109/MSP.2008.918418
   PLOGSTIES J, 2006, 24 TONM VDT INT CONV
   PRINCEN JP, 1986, IEEE T ACOUST SPEECH, V34, P1153, DOI 10.1109/TASSP.1986.1164954
   PRINCEN JP, 1987, P IEEE INT C AC SPEE
   Quackenbush S, 2005, IEEE MULTIMEDIA, V12, P18, DOI 10.1109/MMUL.2005.76
   RODEN J, 2007, 123 AES CONV NEW YOR
   SCHUIJERS E, 2004, 116 AES CONV BERL GE
   SCHUIJERS EGP, 2003, 114 AES CONV AMST NE
   Strutt J.W., 1907, Philosophical Magazine, V13, P214, DOI DOI 10.1080/14786440709463595
   Wang Y, 2003, J AUDIO ENG SOC, V51, P52
NR 53
TC 9
Z9 16
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 225
EP 246
DI 10.1007/s11042-009-0326-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600001
DA 2024-07-18
ER

PT J
AU Quax, P
   Cornelissen, B
   Dierckx, J
   Vansichem, G
   Lamotte, W
AF Quax, Peter
   Cornelissen, Bart
   Dierckx, Jeroen
   Vansichem, Gert
   Lamotte, Wim
TI ALVIC-NG: state management and immersive communication for massively
   multiplayer online games and communities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Networked virtual environments; Scalability; Communication; Conferencing
AB ALVIC-NG is an architecture for networked games based on the classic client/server paradigm. While peer-to-peer and hybrid systems have been extensively researched, the client/server approach provides many advantages that are beneficial or even required from a content, application and service provider's point-of-view. ALVIC-NG consists of an extendable framework which allows for dynamic allocation of server capacity, combined with facilities for player activity management and moderation. This is achieved by introducing an intermediate layer of proxy servers in the architecture to intelligently channel the messages flow. Additionally, ALVIC-NG provides a means for immersive communication by enabling real-time voice chat between participants through an off-the-shelf conferencing system that is closely coupled to the state management facilities and spatial subdivision scheme. Besides a theoretical discussion, we also provide insight into the design of the simulation setup through which we are able to provide actual figures that demonstrate the viability of the proposed solution.
C1 [Quax, Peter; Cornelissen, Bart; Dierckx, Jeroen; Lamotte, Wim] Hasselt Univ, tUL, IBBT, B-3590 Diepenbeek, Belgium.
   [Vansichem, Gert] Androme NV, B-3590 Diepenbeek, Belgium.
C3 Hasselt University
RP Quax, P (corresponding author), Hasselt Univ, tUL, IBBT, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM peter.quax@uhasselt.be; bart.cornelissen@uhasselt.be;
   jeroen.dierckx@uhasselt.be; gert.vansichem@androme.be;
   wim.lamotte@uhasselt.be
RI Quax, Paul/W-8520-2019; Lamotte, Wim/F-1796-2017
OI Lamotte, Wim/0000-0003-1888-6383; QUAX, Peter/0000-0003-4811-0578
FU European Fund for Regional Development (EFRD)
FX Part of this research is funded by the European Fund for Regional
   Development (EFRD). The authors would like to thank the partners
   involved in the IBBT Teleon project.
CR AGGARWAL S, 2006, NETGAMES 06, P5
   ANDROME NV, 2008, INTELLIVIC
   ASSIOTIS M, 2006, NETGAMES 06, P4
   *BLIZZ, 2009, WORLD WARCRAFT
   *CACT, 2009, COMPL RRDTOOL BAS GR
   Capps M, 2000, IEEE COMPUT GRAPH, V20, P12, DOI 10.1109/38.865873
   Greenhalgh C, 1997, LECT NOTES COMPUT SC, V1242, P113, DOI 10.1007/BFb0037348
   Ishibashi Y, 2000, IEEE IC COMP COM NET, P638, DOI 10.1109/ICCCN.2000.885557
   Joslin C, 2004, IEEE COMMUN MAG, V42, P28, DOI 10.1109/MCOM.2004.1284925
   LU F, 2006, NETGAMES 06, P1
   MATIJASEVIC M, 1997, TR9781 U SW LOUIS CT
   OETIKER T, 2008, MULTIROUTER TRAFFIC
   Ogi T, 2001, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2001.913769
   QUAX P, 2003, P 2 WORKSH NETW SYST, P137
   QUAX P, 2004, P IEEE INT C MULT EX
   QUAX P, 2007, THESIS TU LIMBURG
   Quax P, 2008, INT J COMPUT GAMES T, V2008, DOI 10.1155/2008/594313
   Quax Peter., 2004, NETGAMES, P152
   Quax Peter., 2004, VRCAI 04, P88
   Safaei F., 2005, VR 05, P35
   2009, CCP GAMES
NR 21
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 109
EP 131
DI 10.1007/s11042-009-0299-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900006
DA 2024-07-18
ER

PT J
AU Suznjevic, M
   Dobrijevic, O
   Matijasevic, M
AF Suznjevic, Mirko
   Dobrijevic, Ognjen
   Matijasevic, Maja
TI MMORPG Player actions: Network performance, session patterns and latency
   requirements analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMORPG; Networked game; Player activity; Performance; Patterns
AB Providing Massively Multiplayer Online Role-Playing Games (MMORPGs) is a big challenge for future mobile, IP-based networks. Understanding how the players' actions affect the network parameters, the game platform, and the overall perceived quality is highly relevant for the purposes of game design, as well as for the networking infrastructure and network support for games. We break player actions down into discrete categories, and show that each category is distinct in terms of several key metrics. We discuss which categories of actions could be supported on current mobile devices, and present evidence in form of a user survey demonstrating the demand for such services. The starting points into the discussion include the networking, session and latency requirements for particular player actions on one side, and the players' interest on the other. The Blizzard Entertainment's World of Warcraft (WoW) is used as a case study.
C1 [Suznjevic, Mirko; Dobrijevic, Ognjen; Matijasevic, Maja] Univ Zagreb, Fac Elect Engn & Comp, HR-10000 Zagreb, Croatia.
C3 University of Zagreb
RP Suznjevic, M (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Unska 3, HR-10000 Zagreb, Croatia.
EM mirko.suznjevic@fer.hr
RI Matijasevic, Maja/H-3089-2012
OI Matijasevic, Maja/0000-0002-5925-0560
FU Ministry of Science, Education and Sports of the Republic of Croatia
   [036-0362027-1639]; Ericsson Nikola Tesla company, Croatia
FX This work would not have been possible without players that voluntarily
   interrupted their gaming sessions in order to help this research. The
   authors want to thank following characters of the European Bladefist
   realm: Aika, Belisarius, Bothari, Bondocksaint, Bethragor, Grinda,
   Durga, Kekin, Naimed, Othilius, and Vrisanaar. This work was carried out
   within the research project 036-0362027-1639 "Content Delivery and
   Mobility of Users and Services in New Generation Networks," supported by
   the Ministry of Science, Education and Sports of the Republic of Croatia
   and the project " Future Advanced Multimedia Service Enablers" funded by
   Ericsson Nikola Tesla company, Croatia.
CR [Anonymous], 2006, P SIGCHI C HUM FACT, DOI [10.1145/1124772.1124834, DOI 10.1145/1124772.1124834]
   BERGSTRASSER S, 2007, 6 ACM SIGCOMM WORKSH, DOI DOI 10.1145/1326257.1326277
   *BLIZZ ENT INC, WORLD WARCR API WORL
   *BLIZZ ENT INC, 2008, WORLD WARCR SUBSCR B
   *BLIZZ ENT INC, EV API WORLD WARCR W
   BUSSE M, 2004, 3 ACM SIGCOMM WORKSH, DOI DOI 10.1145/1016540.1016543
   Chen K. T., 2006, ACM INT C P SERIES, V266, DOI [10.1145/1178823.1178830, DOI 10.1145/1178823.1178830]
   CHEN KT, 2006, 25 IEEE INT C COMP C, DOI DOI 10.1109/INFOCOM.2006.286
   Chen KT, 2006, COMPUT NETW, V50, P3002, DOI 10.1016/j.comnet.2005.11.005
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   DFC Intelligence, 2007, DIG DISTR KEY ONL GA
   DICK M, 2005, 4 ACM SIGCOMM WORKSH, DOI DOI 10.1145/1103599.110362
   DREDGE S, 2006, MOST AMBITIOUS MOBIL
   ELDER N, 2008, REV QUAKE IPHONE
   FERNANDES S, 2007, 17 INT WORKSH NETW O
   FRITSCH T, 2005, 4 ACM SIGCOMM WORKSH, DOI DOI 10.1145/1103599.1103623
   JOHNSSON F, 2006, MOBILITY GAMING SOCI
   KIM J, 2005, 4 ACM SIGCOMM WORKSH, DOI DOI 10.1145/1103599.1103619
   KOIVISTO EM, 2005, 2005 INT DIG GAM RES
   MASSEY D, 2007, RINGS ONLINE ASK TUR
   *METR 2 0, 2006, MOB GAM TRENDS WEB 2
   ROY D, 2007, THESIS MIT BOSTON
   SUZNJEVIC M, 2008, 7 ACM SIGCOMM WORKSH
   Svoboda P, 2007, IEEE ICC, P1612, DOI 10.1109/ICC.2007.270
   Tarng P.-Y., 2008, 7 ACM SIGCOMM WORKSH, P1
   *TEL RES CTR VIENN, MEAS TRAFF AN WIR NE
   WALLIS J, 2008, N00B WORLD REORDER 1
   *WIK, VIRT EC
   *WIK, MASS MULT ONL ROL PL
   Woodcock B., 2008, ANAL MMOG SUBSCRIPTI
   Zhuang Xinyu., 2007, Player dynamics in massively multiplayer online games
   2002, REV AGE EMPIRES POCK
   2007, LADY VASHJ STRATEGY
   WORLD WARCRAFT ACE3
NR 34
TC 31
Z9 37
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 191
EP 214
DI 10.1007/s11042-009-0300-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900009
DA 2024-07-18
ER

PT J
AU Li, YF
   Ong, K
AF Li, Yongfeng
   Ong, Kenneth
TI Optimized scalable cache management for video streaming system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video streaming; Optimization; Caching strategy; Transmission scheme
AB An important research issue in video streaming is how to efficiently utilize the network resources to provide clients instant access to multiple video objects. Caching strategy and transmission scheme are the two essential points inside the video streaming framework. Recent research efforts on them are not sufficient due to their inflexible support for scalable encoded video streams and heterogeneous requests from clients. In this paper, we propose an optimized caching strategy (OCS) and a scalable transmission scheme (STS) for scalable coded video streaming. By exploring the characteristics of video streaming workload and system design objectives, OCS and STS work efficiently to minimize both network bandwidth cost and user access latency. Firstly, we analyze the caching problem for the proxy-assisted video streaming system and derive a maneuverable caching scenario. Secondly, we develop an efficient transmission scheme for scalable coded videos. Thirdly, we formulate a multi-objective optimization model with closed-form expressions to obtain the optimized caching strategy. Finally, with designed algorithms, an excellent compromise between two competing objectives (minimizing the bandwidth cost and the access latency) is achieved. We start our evaluation by studying the optimized caching strategy for a single video object. Then we apply the strategy to multiple video objects and illustrate the tradeoff between the optimization objectives. Our evaluation results show that compared with other caching strategies, the proposed optimized scalable caching strategy can achieve a significant reduction in bandwidth cost with even a small proxy cache size. Meanwhile, the best performance (in terms of bandwidth cost) is obtained together with the proposed scalable batch-patching transmission scheme.
C1 [Li, Yongfeng; Ong, Kenneth] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Li, YF (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
EM yongfeng@nus.edu.sg; eleongk@nus.edu.sg
RI Li, Yongfeng/AAB-7793-2019
CR Boggia G, 2005, IEEE T MULTIMEDIA, V7, P920, DOI 10.1109/TMM.2005.854383
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   CHEN S, 2003, P NOSSDAV03 JUN 2003
   Cherkasova L, 2004, IEEE ACM T NETWORK, V12, P781, DOI 10.1109/TNET.2004.836125
   DU X, 2006, P IEEE ICC, V3, P1046
   FONSECA NLS, 2002, IEEE T MULTIMEDIA, V4, P114
   Gao LX, 2003, IEEE ACM T NETWORK, V11, P884, DOI 10.1109/TNET.2003.820423
   Gazdar A, 2004, PROCEEDINGS OF THE FOURTH IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P471, DOI 10.1109/ISSPIT.2004.1433820
   GAZDAR A, 2004, P IEEE CONS COMM NET
   Guo M, 2004, IEEE INFOCOM SER, P1501
   HA SJ, 2007, P ICNC AUG 2007, V5, P351
   HYUNG RO, 2006, J VIS COMMUN IMAGE R, V17, P57, DOI DOI 10.1016/J.JVCIR.2005.01.003
   KALAPRIYA K, 2005, 19 INT C ADV INF NET, P229
   Leung YW, 2003, IEEE T MULTIMEDIA, V5, P130, DOI 10.1109/TMM.2003.808818
   LIU J, 2004, P IEEE INF MAR 2004
   LP ATS, 2007, IEEE T PARALL DISTR, V18, P70, DOI DOI 10.1109/TPDS.2007.253282
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   PRABHAKAR S, 2003, INT J IMAGE GRAPH, V3, P95, DOI DOI 10.1142/S0219467803000932
   SATSIOU A, 2004, P 3 IFIP NETW C MAY
   Satsiou Anna, 2006, P 2 INT WORKSH ADV A
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P76
   Sun HF, 2007, WIREL COMMUN MOB COM, V7, P159, DOI 10.1002/wcm.471
   Sun J, 2006, IEEE T CIRC SYST VID, V16, P535, DOI 10.1109/TCSVT.2006.871394
   Wang B, 2004, IEEE T MULTIMEDIA, V6, P366, DOI 10.1109/TMM.2003.822788
   Wu KL, 2004, IEEE T MULTIMEDIA, V6, P770, DOI 10.1109/TMM.2004.834870
   XIA ZI, 2004, P IEEE ICME JUN 2004
   Zhang ZH, 2004, IEEE T CONSUM ELECTR, V50, P139, DOI 10.1109/TCE.2004.1277853
   Zink M, 2005, IEEE T MULTIMEDIA, V7, P75, DOI 10.1109/TMM.2004.840595
NR 29
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 65
EP 86
DI 10.1007/s11042-009-0264-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600004
DA 2024-07-18
ER

PT J
AU Giannetti, F
AF Giannetti, Fabio
TI Mapping strategy for web-driven magazines with personalized
   advertisement and content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variable data print; Template; XSL-FO; SVG; Print; XML; Layout;
   Transactional printing; Content driven pagination; XPS; Personalized
   advertisement; Print on-demand
AB "There will always (I hope) be print books, but just as the advent of photography changed the role of painting or film changed the role of theater in our culture, electronic publishing is changing the world of print media. To look for a one-to-one transposition to the new medium is to miss the future until it has passed you by."aEuro"Tim O'Reilly (2002). It is not hard to envisage that publishers will leverage subscribers' information, interest groups' shared knowledge and others sources to enhance their publications. While this enhances the value of the publication through more accurate and personalized content, it also brings a new set of challenges to the publisher. Content is now driven by web and in a truly automated system, that is, no designer "re-touch" intervention is envisaged. This paper introduces an exploratory mapping strategy to allocate web driven content in a highly graphical publication like a traditional magazine. Two major aspects of the mapping are covered, those enable different level of flexibility and address different content flowing strategies. The last contribution is an evaluation of existing standards, which potentially can leverage this work to incorporate flexible mapping, and subsequently, composition capabilities. The work published here is an extended version of the article presented at the Eight ACM Symposium on Document Engineering in fall 2008 (Giannetti 2008).
C1 Hewlett Packard Labs, Palo Alto, CA 94304 USA.
C3 Hewlett-Packard
RP Giannetti, F (corresponding author), Hewlett Packard Labs, 1501 Page Mill Road,M-S 1161, Palo Alto, CA 94304 USA.
EM fabio.giannetti@hp.com
CR [Anonymous], SCAL VECT GRAPH SVG
   DEWITZ A, PICRM200806 RIT SCH
   GIANNETTI F, 2008, ACM S DOC ENG, P223
   GIANNETTI F, 2007, ACM S DOC ENG, P93
   Jacobs C, 2003, ACM T GRAPHIC, V22, P838, DOI 10.1145/882262.882353
   KAHL W, 1998, LNCS, V1551, P76
   Kingston JH, 2006, FUTURE DOCUMENT FORM
   *MICR, XML PAP SPEC XPS
   OREILLY T, 2002, REPEATED MISCONCEPTI
   *W3C, 2006, EXTENSIBLE MARK LANG
   *W3C, 2007, SCAL VECT GRAPH SV 2
   *W3C, 2007, SCAL VECT GGRAPHICS
   *W3C, 1999, EXTENSIBLE STYL LANG
   *W3C, 2006, EXTENSIBLE STYL LANG
NR 14
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 327
EP 343
DI 10.1007/s11042-009-0269-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800007
DA 2024-07-18
ER

PT J
AU Carvalho, RF
   Chapman, S
   Ciravegna, F
AF Carvalho, Rodrigo F.
   Chapman, Sam
   Ciravegna, Fabio
TI Attributing semantics to personal photographs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photographs; Semantic capture; Information extraction; Clustering;
   Image; Annotation
AB A major bottleneck for the efficient management of personal photographic collections is the large gap between low-level image features and high-level semantic contents of images. This paper proposes and evaluates two methodologies for making appropriate (re)use of natural language photographic annotations for extracting references to people, location and objects and propagating any location references encountered to previously unannotated images. The evaluation identifies the strengths of each approach and shows extraction and propagation results with promising accuracy.
C1 [Carvalho, Rodrigo F.; Chapman, Sam; Ciravegna, Fabio] Univ Sheffield, Dept Comp Sci, Nat Language Proc Grp, Sheffield S1 4DP, S Yorkshire, England.
C3 University of Sheffield
RP Carvalho, RF (corresponding author), Univ Sheffield, Dept Comp Sci, Nat Language Proc Grp, 211 Portobello, Sheffield S1 4DP, S Yorkshire, England.
EM rodrigo@dcs.shef.ac.uk; sam@dcs.shef.ac.uk; fabio@dcs.shef.ac.uk
OI Chapman, Sam/0000-0003-2665-0901; Ciravegna, Fabio/0000-0001-5817-4810
CR AHN LV, 2004, C HUM FACT COMP SYST, P319
   [Anonymous], 2002, CSCW '02, DOI DOI 10.1145/587078.587102
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   [Anonymous], PATTERN CLASSIFICATI
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Aslandogan YA, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P286, DOI 10.1145/278459.258591
   Bang HY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P81
   Barla A, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P566, DOI 10.1109/ICIAP.2003.1234110
   BUDURA A, 2008, 31 ANN INT ACM SIGIR
   COOPER M, 2003, MULTIMEDIA 03, P364
   GREENWOOD M, 2008, LREC 08
   HARE JS, 2005, MULT SEM WEB EUR SEM
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hearst M. A., 1992, Proceedings of the 12th Conference on Computational Linguistics, V2, P539, DOI DOI 10.3115/992133.992154
   IRIA J, 2006, P EACL 2006 MONTR 22
   Keyvanpour M, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P59, DOI 10.1109/DEXA.2007.72
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Miller AD, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P347
   NAAMAN M, 2004, P ACCM MM OCT 2004
   PASTRA K, 2002, APPL INNOVATIONS INT, V10, P121
   Pelleg D., 2000, P 17 INT C MACH LEAR, DOI DOI 10.1007/3-540-44491-2_3
   Spyrou E, 2005, LECT NOTES COMPUT SC, V3697, P847
   SRIHARI RK, 1995, COMPUTER, V28, P49, DOI 10.1109/2.410153
   Stauder J., 2004, EWIMT 2004 EUR WORKS
   VELTKAMP RC, 2000, UUCS200034 DEP COMP
   ZHANG D, 2001, ACM GIS, P88
   Zhang HJ, 2003, WORLD WIDE WEB, V6, P131, DOI 10.1023/A:1023618504691
NR 27
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2009
VL 42
IS 1
SI SI
BP 73
EP 96
DI 10.1007/s11042-008-0249-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 403XX
UT WOS:000263116400005
DA 2024-07-18
ER

PT J
AU Heesch, D
AF Heesch, Daniel
TI A survey of browsing models for content based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image retrieval; CBIR; human-computer interaction; data visualization;
   browsing; networks; clustering; dimensionality reduction
ID SEARCH; SIMILARITY; VISUALIZATION
AB The problem of content based image retrieval (CBIR) has traditionally been investigated within a framework that emphasises the explicit formulation of a query: users initiate an automated search for relevant images by submitting an image or draw a sketch that exemplifies their information need. Often, relevance feedback is incorporated as a post-retrieval step for optimising the way evidence from different visual features is combined. While this sustained methodological focus has helped CBIR to mature, it has also brought out its limitations more clearly: There is often little support for exploratory search and scaling to very large collections is problematic. Moreover, the assumption that users are always able to formulate an appropriate query is questionable. An effective, albeit much less studied, method of accessing image collections based on visual content is that of browsing. The aim of this survey paper is to provide a structured overview of the different models that have been explored over the last one to two decades, to highlight the particular challenges of the browsing approach and to focus attention on a few interesting issues that warrant more intense research.
C1 Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
C3 Imperial College London
RP Heesch, D (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM daniel.heesch@imperial.ac.uk
CR ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3
   [Anonymous], 2002, ADV NEURAL INFORM PR
   [Anonymous], 1989, The psychology of learning and motivation, DOI DOI 10.1016/S0079-7421(08)60539-3
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Berkhin P., 2002, SURVEY CLUSTERING DA
   Beyer K., 1999, Proceedings of the 7th International Conference on Database Theory, ICDT'99, DOI [10.1007/3-540-49257-7_15, DOI 10.1007/3-540-49257-7_15]
   Boucheron LE, 2005, IEEE T GEOSCI REMOTE, V43, P1210, DOI 10.1109/TGRS.2004.841477
   Browne P., 2004, P ACM S APPL COMPUTI, P1084
   CAMPBELL I, 2000, THESIS U GLASGOW
   CARMEL E, 1992, IEEE T SYST MAN CYB, V22, P865, DOI 10.1109/21.179829
   CHEN C, 2000, P INT C INT INF PROC, P206
   Chen CM, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P67, DOI 10.1109/INFVIS.2003.1249010
   Chen CM, 2003, J AM SOC INF SCI TEC, V54, P435, DOI 10.1002/asi.10229
   Chen JY, 1998, P SOC PHOTO-OPT INS, V3299, P563, DOI 10.1117/12.320147
   Chen JY, 2000, IEEE T IMAGE PROCESS, V9, P442, DOI 10.1109/83.826781
   Cheung SCS, 2005, IEEE T MULTIMEDIA, V7, P524, DOI 10.1109/TMM.2005.846906
   CLOUGH P, 2005, P ACM MULT WORKSH SI
   COX K, 1992, P INT C NEW INF TECH
   COX K, 1995, THESIS U CANBERRA
   CROFT WB, 1985, INFORM SYST, V10, P377, DOI 10.1016/0306-4379(85)90042-0
   Crucianu M., 2004, STATE ART AUDIOVISUA
   DATTA R, 2008, ACM T COMPU IN PRESS
   Descampe A, 2007, IEEE T IMAGE PROCESS, V16, P1339, DOI 10.1109/TIP.2007.894258
   Duda R., 2001, Pattern Recognition, V2nd
   Fauqueur J, 2006, MULTIMED TOOLS APPL, V31, P95, DOI 10.1007/s11042-006-0033-3
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Forsyth D. A., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P240, DOI 10.1117/12.451112
   FOWLER R, 1992, 921 U TEX DEP COMP S
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Furnas G. W., 1986, ACM Sigchi Bull., V17, P16, DOI DOI 10.1145/22339.22342
   Gevers T., 2004, EMERGING TOPICS COMP
   Goldberger J, 2006, IEEE T IMAGE PROCESS, V15, P449, DOI 10.1109/TIP.2005.860593
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Guttman A., 1984, SIGMOD Record, V14, P47, DOI 10.1145/971697.602266
   Heesch D, 2004, LECT NOTES COMPUT SC, V2997, P253
   HEESCH D, 2006, SEMANTIC BASED VISUA, P160
   HEESCH D, 2004, P TREC VID
   HEESCH D, 2005, THESIS IMPERIAL COLL
   HEESCH D, 2006, P ACM INT C MULT SIG, P220
   HIROIKE T, 1999, VISUAL INFORM SYSTEM, P155
   Jacobs CE., 1995, FAST MULTIRESOLUTION
   Katayama N., 1997, P ACM SIGMOD, P369
   Keller I, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P102, DOI 10.1109/IVL.2001.990863
   Kohonen T., 2001, SPRINGER SERIES INFO, V30, P1
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Kurniawati R, 1997, AUST COMPUT J, V29, P122
   LAAKSONEN J, 2000, P INT C NEUR INF PRO
   LAVRENKO V, 2003, ADV NEURAL INFORM PR, V16
   Lim S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P328
   Liu TY, 2004, PROGRESS IN ENVIRONMENTAL AND ENGINEERING GEOPHYSICS, P480
   MacCuish J, 1996, P SOC PHOTO-OPT INS, V2656, P104, DOI 10.1117/12.234660
   Milanese R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P859, DOI 10.1109/ICIP.1996.560891
   Minka TP, 1996, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.1996.517110
   Moghaddam B, 2004, INT J COMPUT VISION, V56, P109, DOI 10.1023/B:VISI.0000004834.62090.74
   MUKHOPADHYAY R, 2004, P 6 IEEE INT S MULT, P522
   Musha Y., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P447
   Newell A., 1994, UNIFIED THEORIES COG
   NGUYEN G, 2008, J VIS LANG IN PRESS
   Obdr?zalek S., 2005, PROC 16 BRIT MACHINE, V1, P1
   Pecenovic Z, 2000, LECT NOTES COMPUT SC, V1929, P279
   PLATT JC, 2002, PHOTOTOC AUTOMATIC C
   RODDEN K, 2001, P SIGCHI C HUM FACT, P190, DOI DOI 10.1145/365024.365097
   Rogers Timothy T., 2006, Semantic Cognition: A Parallel Distributed Processing Approach, VRevis
   Roussinov D. G., 1998, CC-AI, The Journal for the Integrated Study of Artificial Intelligence, Cognitive Science and Applied Epistemology, V15, P81
   Roussopoulos N, 1995, P ACM INT C MAN DAT
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rubner L. J., 1997, P ARPA IM UND WORKSH, P661
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Salton G., 1988, SIGIR 88, P147, DOI DOI 10.1145/62437.62447
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   SCHVANEFELDT R, 1990, ABLEX SERIES COMPUTA
   SCLAROFF S, 1997, IMAGEROVER CONTENT B
   Sloutsky VM, 2003, TRENDS COGN SCI, V7, P246, DOI 10.1016/S1364-6613(03)00109-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH J, 1996, P ACM INT C MULT SIG
   Spence R, 1999, INT J HUM-COMPUT ST, V51, P919, DOI 10.1006/ijhc.1999.0265
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009
   Tishby N., 1999, P 37 ANN ALL C COMM, P368
   Urban J., 2003, PROC 3 INT WORKSHOP, P119
   Vendrig J., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P147
   WANG Q, 2006, P IEEE INT S MULT
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   WEBER R, 1997, 24 ETH ZUR
   White DA, 1996, PROC INT CONF DATA, P516, DOI 10.1109/ICDE.1996.492202
   Wolfram S, 2004, NEW KIND SCI
   Yang CC, 2004, J INF SCI, V30, P254, DOI 10.1177/0165551504044670
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Yavlinsky A, 2005, LECT NOTES COMPUT SC, V3568, P507
   YAVLINSKY A, 2007, P ACM INT C MULT SIG, P565
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   ZASS R, 2005, P INT C COMP VIS
   ZHANG H, 1995, P SOC PHOTO-OPT INS, V2420, P36
   Zhang RF, 2005, IEEE I CONF COMP VIS, P846
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 100
TC 72
Z9 80
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 261
EP 284
DI 10.1007/s11042-008-0207-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200005
DA 2024-07-18
ER

PT J
AU Han, DF
   Li, WH
   Li, ZC
AF Han, Dongfeng
   Li, Wenhui
   Li, Zongcheng
TI Semantic image classification using statistical local spatial relations
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE statistical local spatial relations model; semantic image
   classification; variational expectation maximization; invariant local
   regions; graph model
ID RETRIEVAL; SCALE
AB In this paper, a statistical model called statistical local spatial relations (SLSR) is presented as a novel technique of a learning model with spatial and statistical information for semantic image classification. The model is inspired by probabilistic Latent Semantic Analysis (PLSA) for text mining. In text analysis, PLSA is used to discover topics in a corpus using the bag-of-word document representation. In SLSR, we treat image categories as topics, therefore an image containing instances of multiple categories can be modeled as a mixture of topics. More significantly, SLSR introduces spatial relation information as a factor which is not present in PLSA. SLSR has rotation, scale, translation and affine invariant properties and can solve partial occlusion problems. Using the Dirichlet process and variational Expectation-Maximization learning algorithm, SLSR is developed as an implementation of an image classification algorithm. SLSR uses an unsupervised process which can capture both spatial relations and statistical information simultaneously. The experiments are demonstrated on some standard data sets and show that the SLSR model is a promising model for semantic image classification problems.
C1 [Han, Dongfeng; Li, Wenhui] Jilin Univ, Minist Educ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Changchun 130023, Peoples R China.
   [Li, Zongcheng] Shandong Univ Technol, Sch Engn Technol, Zibo, Peoples R China.
C3 Jilin University; Shandong University of Technology
RP Li, WH (corresponding author), Jilin Univ, Minist Educ, Coll Comp Sci & Technol, Key Lab Symbol Computat & Knowledge Engn, Changchun 130023, Peoples R China.
EM handongfeng@gmail.com; liwh@jlu.edu.cn
RI WENHUI, LI/HOH-7881-2023; lin, yuan/JXL-9592-2024
OI WENHUI, LI/0000-0003-0900-8749; 
CR [Anonymous], THESIS CALTECH
   [Anonymous], P 7 EUR C COMP VIS
   [Anonymous], P IEEE INT C COMP VI
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015
   BURL M, 1998, P 5 EUR C COMP VIS 9, V2, P628
   Carneiro G, 2005, PROC CVPR IEEE, P163
   Crandall D, 2005, PROC CVPR IEEE, P10
   DANCE C, 2004, P ECCV INT WORKSH ST, P59
   FAN J, 2005, P 2005 IEEE COMP SOC, V2, P704
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus R, 2003, PROC CVPR IEEE, P264
   FERGUS R, 2005, P ICCV, P1816
   Frey BJ, 2005, IEEE T PATTERN ANAL, V27, P1392, DOI 10.1109/TPAMI.2005.169
   GRIFFIN AHG, 2007, UCBCSD041366 CAL I T
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   Heidemann G, 2006, IEEE T PATTERN ANAL, V28, P822, DOI 10.1109/TPAMI.2006.107
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708
   Lim JH, 2005, PATTERN RECOGN, V38, P847, DOI 10.1016/j.patcog.2004.11.002
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Saha SK, 2007, PATTERN RECOGN LETT, V28, P357, DOI 10.1016/j.patrec.2006.04.005
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Verbeek J, 2006, IEEE T PATTERN ANAL, V28, P1236, DOI 10.1109/TPAMI.2006.166
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   VOGEL J, 2004, P PATT REC S DAGM 04
   Wainwright M.J., 2003, Graphical models, exponential families, and variational inference
   WAINWRIGHT MJ, 2004, ALL C COMM CONTR COM
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Zhang RF, 2005, IEEE I CONF COMP VIS, P846
NR 35
TC 19
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 169
EP 188
DI 10.1007/s11042-008-0203-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400003
DA 2024-07-18
ER

PT J
AU Qamra, A
   Chang, EY
AF Qamra, Arun
   Chang, Edward Y.
TI Scalable landmark recognition using EXTENT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Workshop on Computer Vision Meets Databases
CY JUN 17, 2005
CL Baltimore, MD
DE photo annotation; context; SIFT; scalability
AB We have proposed the EXTENT system for automated photograph annotation using image content and context analysis. A key component of EXTENT is a Landmark recognition system called LandMarker. In this paper, we present the architecture of LandMarker. The content of a query photograph is analyzed and compared against a database of sample landmark images, to recognize any landmarks it contains. An algorithm is presented for comparing a query image with a sample image. Context information may be used to assist landmark recognition. Also, we show how LandMarker deals with scalability to allow recognition of a large number of landmarks. We have implemented a prototype of the system, and present empirical results on a large dataset.
C1 [Qamra, Arun] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
   [Chang, Edward Y.] VIMA Technol, Santa Barbara, CA USA.
C3 University of California System; University of California Santa Barbara
RP Qamra, A (corresponding author), Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
EM arun@cs.ucsb.edu
CR AMORES J, 2005, P INT C COMP VIS PAT
   [Anonymous], 2003, 3 INT WORKSH STAT CO
   [Anonymous], ACM MULTIMEDIA 2004
   [Anonymous], P INT C COMP VIS
   [Anonymous], INT C COMP VIS
   [Anonymous], P 2004 ACM CIKM INT
   BARTOLINI I, 2000, P 4 INT WORKSH QUER
   CARSON C, 1999, P INT C VIS INF SYST
   CHANG EY, 2005, WORKSH COMP VIS M DA
   DATAR M, 2004, P 20 S COMP GEOM
   DAVIS M, 2004, P ACM INT C MULT
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   DIOMIDIS D, 2003, IEEE PERVAS COMPUT, V2, P72
   FRIEDMAN N, 2001, LEARNING BAYESIAN NE
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   GOH KS, 2001, ACM INT C INF KNOWL, P395
   GRAUMAN K, 2005, P INT C COMP VIS PAT
   HECKERMAN D, 1994, MSRTR9411
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   NAAMAN M, 2003, INT C COOP INF SYST
   NAAMAN M, 2004, P ACM INT C MULT
   Novick LR, 2004, PSYCHOL REV, V111, P455, DOI 10.1037/0033-295X.111.2.455
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schmid C., 2005, Handbook of Pattern Recognition and Computer Vision, VThird
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   WEBER R, 2003, P ACM C INF KNOWL MA
NR 26
TC 11
Z9 11
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2008
VL 38
IS 2
BP 187
EP 208
DI 10.1007/s11042-007-0178-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 301NV
UT WOS:000255903800002
DA 2024-07-18
ER

EF