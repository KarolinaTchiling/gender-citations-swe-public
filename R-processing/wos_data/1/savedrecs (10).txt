FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Madhusudhan, R
   Nayak, CS
AF Madhusudhan, R.
   Nayak, Chaitanya S.
TI An improved user authentication scheme for electronic medical record
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EMR; User authentication; Smart card; Biometrics; User anonymity;
   Session key; BAN logic
ID ELLIPTIC CURVE CRYPTOGRAPHY; KEY AGREEMENT SCHEME; SMART CARDS; MUTUAL
   AUTHENTICATION; SECURE; EFFICIENT; ROBUST; ANONYMITY; PRIVACY;
   CRYPTANALYSIS
AB Electronic Medical Record (EMR) systems is a part of e-healthcare system, which is developing rapidly. In this, it is possible to deliver medical services among multiple participants over a network without physical presence. Since sensitive data is transmitted over public channels, it is very much required to maintain the secrecy of that data. This is achieved by mutual authentication between the participants. For this, various schemes for authentication with smart cards have been proposed. Han et al. proposed one such biometrics-based scheme for the same purpose using hash functions along with symmetric key encryption and elliptic curve cryptography. From cryptanalysis of their scheme, we have pointed out weaknesses viz. no user anonymity, user and server impersonation, man-in-the-middle attack. These security issues have been presented in this article. To overcome these attacks, a scheme has been proposed in this article. Since it does not use symmetric key encryption, the proposed scheme reduces the computational complexity as can be seen in the comparison provided. The security analysis of the proposed scheme, along with BAN (Burrows-Abadi-Needham) logic has been explained in detail. Comparison of the proposed scheme with related schemes with respect to computation cost, execution time and performance is demonstrated. This proves that the proposed scheme performs well in terms of security as well as computational efficiency.
C1 [Madhusudhan, R.; Nayak, Chaitanya S.] Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Madhusudhan, R (corresponding author), Natl Inst Technol Karnataka, Dept Math & Computat Sci, Surathkal, Karnataka, India.
EM madhu_nitks@yahoo.com; chaitanyasnayak19@gmail.com
RI R, Madhusudhan/AAV-2720-2021
CR Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0262-y
   [Anonymous], J MED SYST
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Barrows RC, 1996, J AM MED INFORM ASSN, V3, P139, DOI 10.1136/jamia.1996.96236282
   Ben Othman S, 2014, INT WIREL COMMUN, P304, DOI 10.1109/IWCMC.2014.6906374
   Bhattacharyya D, 2009, INT J GRID DISTRIB, V2, P13
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Burt CW, 2005, HEALTH AFFAIR, V24, P1334, DOI 10.1377/hlthaff.24.5.1334
   Callegati F, 2009, IEEE SECUR PRIV, V7, P78, DOI 10.1109/MSP.2009.12
   Cao TJ, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9912-5
   Chang CC, 2017, SMART INNOV SYST TEC, V63, P303, DOI 10.1007/978-3-319-50209-0_37
   Chaturvedi Ankita, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P63, DOI 10.1007/978-3-642-45204-8_5
   Chaturvedi A, 2017, J KING SAUD UNIV-COM, V29, P54, DOI 10.1016/j.jksuci.2014.12.007
   Chen CL, 2012, INT J COMMUN SYST, V25, P585, DOI 10.1002/dac.1277
   Chen HM, 2012, J MED SYST, V36, P3907, DOI 10.1007/s10916-012-9862-y
   Das AK, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0204-8
   Goldsmith J, 2003, HEALTH AFFAIR, V22, P44, DOI 10.1377/hlthaff.22.4.44
   Gunter TD, 2005, J MED INTERNET RES, V7, DOI 10.2196/jmir.7.1.e3
   Han LD, 2018, PEER PEER NETW APPL, V11, P63, DOI 10.1007/s12083-016-0499-3
   He DB, 2012, J MED SYST, V36, P1989, DOI 10.1007/s10916-011-9658-5
   Irshad A, 2017, MULTIMED TOOLS APPL, V76, P16463, DOI 10.1007/s11042-016-3921-1
   Islam SKH, 2013, MATH COMPUT MODEL, V57, P2703, DOI 10.1016/j.mcm.2011.07.001
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Jiang Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9897-0
   Jung J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184232
   Khan MK, 2014, COMPUTING, V96, P793, DOI 10.1007/s00607-013-0308-2
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Lauter K, 2004, IEEE WIREL COMMUN, V11, P62, DOI 10.1109/MWC.2004.1269719
   Lee TF, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9941-8
   Li CT, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0474-9
   Li CT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0322-3
   Li M, 2010, IEEE WIREL COMMUN, V17, P51, DOI 10.1109/MWC.2010.5416350
   Li X, 2018, FUTURE GENER COMP SY, V84, P149, DOI 10.1016/j.future.2017.08.029
   Liu WH, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2018-7
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0221-7
   Madhusudhan R, 2012, J NETW COMPUT APPL, V35, P1235, DOI 10.1016/j.jnca.2012.01.007
   MADHUSUDHAN R, 2018, MULTIMED TOOLS APPL, P1
   MAHAVEERAKANNAN R, 2017, INT C INT INF TECHN, P93
   MAHAVEERAKANNAN R, 2016, INT J COMPUTER TECHN, V9, P543
   Mir O, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0265-8
   MISHRA D, 2015, J MED SYST, V39
   Mishra D, 2014, J MED SYST, V38, DOI [10.1007/s10916-014-0120-3, 10.1007/s10916-014-0024-2]
   Moon J, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0422-0
   Nikooghadam M, 2012, J MED SYST, V36, P3839, DOI 10.1007/s10916-012-9857-8
   Ostad-Sharif A, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1120-5
   Park CS, 2004, COMPUT NETW, V44, P267, DOI 10.1016/j.comnet.2003.09.001
   Qiu SM, 2018, IEEE ACCESS, V6, P7452, DOI 10.1109/ACCESS.2017.2780124
   Rankl W., 2004, Smart Card Handbook
   Siddiqui Z, 2016, PEER PEER NETW APPL, V9, P841, DOI 10.1007/s12083-015-0364-9
   Singh G., 2013, Int. J. Comput. Appl., V67
   Sutrala AK, 2016, COMPUT METH PROG BIO, V135, P167, DOI 10.1016/j.cmpb.2016.07.028
   Tsai SC., 2006, International Journal of Network Security, V2, P101
   WANG HJ, 2013, SHENYANG SHIFAN DAXU, V31, P397, DOI DOI 10.3969/j.issn.1673-5862.2013.03.019
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P4052, DOI 10.1016/j.cnsns.2010.02.014
   Wei JH, 2012, J MED SYST, V36, P3597, DOI 10.1007/s10916-012-9835-1
   Wen FT, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0026-0
   Wen FT, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0042-0
   William S., 1999, CRYPTOGRAPHY NETWORK, P23
   Wu F, 2015, COMPUT ELECTR ENG, V45, P274, DOI 10.1016/j.compeleceng.2015.02.015
   Wu F, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9958-z
   Wu ZY, 2012, J MED SYST, V36, P1529, DOI 10.1007/s10916-010-9614-9
   Wu ZY, 2012, J MED SYST, V36, P631, DOI 10.1007/s10916-010-9527-7
   Xie Q, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9911-6
   Xiong H, 2017, IEEE ACCESS, V5, P5648, DOI 10.1109/ACCESS.2017.2678104
   Xue YG, 2017, EXTREME MECH LETT, V11, P18, DOI 10.1016/j.eml.2016.11.012
   Yeh HL, 2013, IET INFORM SECUR, V7, P247, DOI 10.1049/iet-ifs.2011.0348
   Zhou XB, 2010, PROC SPIE, V7541, DOI 10.1117/12.839165
   Zhu ZA, 2012, J MED SYST, V36, P3833, DOI 10.1007/s10916-012-9856-9
NR 68
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 22007
EP 22026
DI 10.1007/s11042-020-08983-7
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000533058700002
DA 2024-07-18
ER

PT J
AU Qin, FQ
   Fang, S
   Wang, LF
   Yuan, XH
   Elhoseny, M
   Yuan, XJ
AF Qin, Fuqiang
   Fang, Shuai
   Wang, Lifang
   Yuan, Xiaohui
   Elhoseny, Mohamed
   Yuan, Xiaojing
TI Kernel learning for blind image recovery from motion blur
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deconvolution; Motion deblurring; Kernel estimation
AB Restoring image from motion deblur faces great challenges in the estimation of the motion blur kernel that is the key to recover the latent sharp image. In this paper, we present a method to iteratively estimate the structural image and account for the textural component. A scale-aware smoothing operation is developed to remove fine-scale edges with resampling. Our method leverages L-0-norm regularization to enforce the sparsity of the motion blur kernel in both intensity and derivative domains. Experiments are conducted to evaluate the performance of our proposed method using two widely accepted public datasets. We found that our proposed method is insensitive to most hyper-parameters. Both qualitative evaluation and quantitative evaluation confirms that our method effectively restores the sharp image without introducing artifacts. The minimum improvements in terms of average PSNR for both datasets are more than 3.13% for all cases and the improvements in terms of average error rate are 15%. By visually comparing the estimated motion blur kernels, it is clear that the estimated kernel by our method is the closest to the actual kernel used to generate the synthesized blurry images.
C1 [Qin, Fuqiang] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian, Peoples R China.
   [Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian, Peoples R China.
   [Fang, Shuai] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei, Peoples R China.
   [Yuan, Xiaohui] Univ North Texas, Dept Comp Sci & Engn, 3940 N Elm, Denton, TX 76207 USA.
   [Elhoseny, Mohamed] Mansoura Univ, Fac Comp & Informat, Mansoura, Egypt.
   [Yuan, Xiaojing] Univ Houston, Dept Engn Technol, Houston, TX USA.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Hefei University of Technology; University of North Texas
   System; University of North Texas Denton; Egyptian Knowledge Bank (EKB);
   Mansoura University; University of Houston System; University of Houston
RP Yuan, XH (corresponding author), Univ North Texas, Dept Comp Sci & Engn, 3940 N Elm, Denton, TX 76207 USA.
EM xiaohui.yuan@unt.edu
RI Elhoseny, Mohamed/Q-5591-2017
OI Elhoseny, Mohamed/0000-0001-6347-8368; Yuan,
   Xiaohui/0000-0001-6897-4563; Yuan, Xiaojing/0000-0001-9252-7552
FU National Natural Science Foundation of China [61872327, 61472380];
   Fundamental Research Funds for the Central Universities [JD2017JGPY0011,
   JZ2017HGBZ0930, PA2018GDQT0011]
FX The work is partially supported by the National Natural Science
   Foundation of China (No.61872327, 61472380) and Fundamental Research
   Funds for the Central Universities (No. JD2017JGPY0011, JZ2017HGBZ0930,
   PA2018GDQT0011).
CR Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gong D, 2016, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2016.202
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Lai WS, 2015, PROC CVPR IEEE, P64, DOI 10.1109/CVPR.2015.7298601
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Whyte Oliver, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P745
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yuan X, 2010, P SOC PHOTO-OPT INS, V7623, P7623
   Yuan XH, 2018, COMPUT ELECTR ENG, V70, P813, DOI 10.1016/j.compeleceng.2017.12.026
   Yuan XH, 2017, IEEE-CAA J AUTOMATIC, V4, P677, DOI 10.1109/JAS.2017.7510625
   Yue T, 2014, LECT NOTES COMPUT SC, V8695, P79, DOI 10.1007/978-3-319-10584-0_6
NR 24
TC 3
Z9 4
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21873
EP 21887
DI 10.1007/s11042-020-09012-3
EA MAY 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000532672800002
DA 2024-07-18
ER

PT J
AU Weng, L
   Gouet-Brunet, V
   Soheilian, B
AF Weng, Li
   Gouet-Brunet, Valerie
   Soheilian, Bahman
TI Semantic signatures for large-scale visual localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Database search; Information retrieval; Visual localization; Semantic
   feature; Urban computing
AB Visual localization is a useful alternative to standard localization techniques. It works by utilizing cameras. In a typical scenario, features are extracted from captured images and compared with geo-referenced databases. Location information is then inferred from the matching results. Conventional schemes mainly use low-level visual features. These approaches offer good accuracy but suffer from scalability issues. In order to assist localization in large urban areas, this work explores a different path by utilizing high-level semantic information. It is found that object information in a street view can facilitate localization. A novel descriptor scheme called "semantic signature" is proposed to summarize this information. A semantic signature consists of type and angle information of visible objects at a spatial location. Several metrics and protocols are proposed for signature comparison and retrieval. They illustrate different trade-offs between accuracy and complexity. Extensive simulation results confirm the potential of the proposed scheme in large-scale applications. This paper is an extended version of a conference paper in CBMI'18. A more efficient retrieval protocol is presented with additional experiment results.
C1 [Weng, Li] Hangzhou Dianzi Univ, Dept Automat Artificial Intelligence, Hangzhou 310018, Peoples R China.
   [Gouet-Brunet, Valerie; Soheilian, Bahman] Univ Gustave Eiffel, LaSTIG Lab, ENSG, IGN, St Mande 94160, France.
C3 Hangzhou Dianzi University; Universite Gustave-Eiffel
RP Weng, L (corresponding author), Hangzhou Dianzi Univ, Dept Automat Artificial Intelligence, Hangzhou 310018, Peoples R China.
EM lweng@hdu.edu.cn
RI Weng, Li/AFB-9091-2022; Gouet-Brunet, Valérie/GYD-8759-2022
OI Weng, Li/0000-0002-7540-7652; 
FU Zhejiang Provincial Natural Science Foundation of China [LY19F030022];
   National Natural Science Foundation of China [61873077]; European
   project KET ENIAC Things2Do under ENIAC JU grant [621221]
FX This research was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LY19F030022, National Natural
   Science Foundation of China under Grant No. 61873077, and the European
   project KET ENIAC Things2Do under ENIAC JU grant agreement No. 621221.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   [Anonymous], 2009, P 18 INT C WORLD WID
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9006, P188, DOI 10.1007/978-3-319-16817-3_13
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4_39
   ARTH C, 2015, P INT S MIX AUGM REA
   ARYA S, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P271
   Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610
   EAGLEN RH, 1985, AM J PHYS ANTHROPOL, V66, P307, DOI 10.1002/ajpa.1330660308
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Iscen A, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P397, DOI 10.1145/3078971.3079033
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kumar KSA, 2017, MATER RES EXPRESS, V4, DOI 10.1088/2053-1591/aa9d4a
   Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Navarro G, 2001, ACM COMPUT SURV, V33, P31, DOI 10.1145/375360.375365
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Shrivastava A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024188
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Song YF, 2016, IEEE T MULTIMEDIA, V18, P1542, DOI 10.1109/TMM.2016.2568743
   Tola E, 2008, PROC CVPR IEEE, P2578
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vrochidis S, 2019, BIG DATA ANAL LARGE
   WENG L, 2018, INT C CONT BAS MULT, P1
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zhang JG, 2011, 2011 INTERNATIONAL CONFERENCE ON EDUCATION SCIENCE AND MANAGEMENT ENGINEERING (ESME 2011), VOLS 1-5, P677
NR 43
TC 4
Z9 5
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22347
EP 22372
DI 10.1007/s11042-020-08992-6
EA MAY 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000530987700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, S
   Liang, LM
   Ouyang, JQ
   Yuan, Y
AF Chen, Shu
   Liang, Luming
   Ouyang, Jianquan
   Yuan, Yuan
TI Accurate 3D motion tracking by combining image alignment and feature
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Model establishment; Image alignment; Motion tracking
ID POSE; DATABASE; ONLINE
AB We presents a novel method to improve the accuracy of 3D motion tacking. In contrast to the state-of-the-art tracking approaches, where the 3D structure of target is commonly approximated by a CAD model, the proposed method establishes the target model by an online improved Structure-from-Motion technique. Furthermore, the tracking is implemented by three sequential trackers (feature-based tracker, image-alignment-based tracker and Particle Filter), which continually refine the tracking results. This coarse-to-fine method increases the accuracy of tracking. Moreover, our approach uses keyframe strategy to prevent tracking drift, the new keyframe insertion is determined by a criterion which can ensure a correct update. Thorough evaluations are performed on two public databases, the Biwi Head Pose dataset and the UPNA Head Pose Database. Comparisons illustrate that the proposed method achieves better performance with respect to other state-of-the-art tracking approaches.
C1 [Chen, Shu; Ouyang, Jianquan; Yuan, Yuan] Xiangtan Univ, Sch Comp Sci, Xiangtan 411105, Peoples R China.
   [Chen, Shu; Ouyang, Jianquan; Yuan, Yuan] Minist Educ, Key Lab Intelligent Comp & Informat Proc, Xiangtan 411105, Peoples R China.
   [Liang, Luming] Microsoft, Appl Sci Grp, Redmond, WA 98052 USA.
C3 Xiangtan University; Microsoft
RP Liang, LM (corresponding author), Microsoft, Appl Sci Grp, Redmond, WA 98052 USA.
EM llmpass@gmail.com
RI ouyang, jianquan/HTN-9999-2023; Liang, Luming/E-3371-2016
OI ouyang, jianquan/0000-0002-7518-5156; Liang, Luming/0000-0002-1127-2568
FU Natural Science Foundation of Hunan Province [2017JJ2252]
FX This research is supported in part by the Natural Science Foundation of
   Hunan Province (No. 2017JJ2252).
CR Abu Arqub O, 2017, NEURAL COMPUT APPL, V28, P1591, DOI 10.1007/s00521-015-2110-x
   Abu Arqub O, 2016, SOFT COMPUT, V20, P3283, DOI 10.1007/s00500-015-1707-4
   Abu Arqub O, 2014, INFORM SCIENCES, V279, P396, DOI 10.1016/j.ins.2014.03.128
   Alvarez L, 2000, INT J COMPUT VISION, V39, P41, DOI 10.1023/A:1008170101536
   Ariz M, 2016, COMPUT VIS IMAGE UND, V148, P201, DOI 10.1016/j.cviu.2015.04.009
   Baltzakis H, 2012, MACH VISION APPL, V23, P1141, DOI 10.1007/s00138-012-0409-5
   Bregler C, 2004, INT J COMPUT VISION, V56, P179, DOI 10.1023/B:VISI.0000011203.00237.9b
   Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32
   Cagniart C, 2010, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2010.5539814
   Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen S, 2016, IEEE T CIRC SYST VID, V26, P2043, DOI 10.1109/TCSVT.2015.2452782
   Chen S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033005
   Concha A, 2014, IEEE INT CONF ROBOT, P365, DOI 10.1109/ICRA.2014.6906883
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Gibson S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P37, DOI 10.1109/ISMAR.2002.1115068
   Han SC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201399
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hu HN, 2019, IEEE I CONF COMP VIS, P5389, DOI 10.1109/ICCV.2019.00549
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kim J, 2013, PROC CVPR IEEE, P2307, DOI 10.1109/CVPR.2013.299
   Li PL, 2018, LECT NOTES COMPUT SC, V11206, P664, DOI 10.1007/978-3-030-01216-8_40
   Lou HG, 2005, IEEE T IMAGE PROCESS, V14, P1561, DOI 10.1109/TIP.2005.854495
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Morency L., 2008, IEEE International Conference on Automatic Face Gesture Recognition, P1
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Opromolla R, 2017, IEEE T AERO ELEC SYS, V53, P431, DOI 10.1109/TAES.2017.2650785
   Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001
   Pauwels K, 2013, PROC CVPR IEEE, P2347, DOI 10.1109/CVPR.2013.304
   PHAM HX, 2015, ROBUST PERFORMANCE D
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Scheidegger S, 2018, IEEE INT VEH SYM, P433
   Tianye Li, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3130800.3130813
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wan CD, 2019, PROC CVPR IEEE, P10845, DOI 10.1109/CVPR.2019.01111
   Wang YG, 2018, IEEE T VIS COMPUT GR, V24, P1856, DOI 10.1109/TVCG.2017.2693151
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Ye ZJ, 2020, MULTIMED TOOLS APPL, V79, P5053, DOI 10.1007/s11042-018-6307-8
   Zhang G, 2007, AEROSP CONF PROC, P3929
NR 48
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21325
EP 21343
DI 10.1007/s11042-020-08966-8
EA MAY 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530603300001
DA 2024-07-18
ER

PT J
AU Beg, S
   Ahmad, N
   Anjum, A
   Ahmed, M
   Khan, A
   Baig, F
   Khan, A
AF Beg, Saira
   Ahmad, Naveed
   Anjum, Adeel
   Ahmed, Mansoor
   Khan, Abid
   Baig, Fasial
   Khan, Ahmed
TI S-box design based on optimize LFT parameter selection: a practical
   approach in recommendation system domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-box; Cryptography; Galois field; Projective linear group (PGL);
   Chaotic theory; Text-2-image conversion; Recommendation system; NIST
   standard
ID SUBSTITUTION BOX; ENCRYPTION; CRYPTANALYSIS; CONSTRUCTION
AB The strength of cryptography encryption is strongly depended upon the substitution box (S-box), hence highly non-linear S-box is appreciated in cryptography. In this work, we proposed a scheme to select the optimized values for control parameters (a, b, c, d) of linear fractional transform (LFT) to achieve an S-box with non-linearity of 112. For dynamic parameter values, we used location of chaotic sequences. The proposed s-box tested on different criteria such as non-linearity method (NL), probability methods (linear approximation (LP), differential approximation (DP), strictly avalanche criteria (SAC) and bit independence criteria (BIC). Our result shows that proposed s-box achieves better or equal to cryptographic strength as compared with state-of-the-art techniques. Moreover, we tested the proposed s-box based encryption method in recommendation system scenario with the idea of text-to-image conversion. The statistical analysis of this image encryption shows the bright prospects of the proposed method.
C1 [Beg, Saira; Anjum, Adeel; Ahmed, Mansoor; Khan, Abid; Khan, Ahmed] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Ahmad, Naveed] FAST Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
   [Baig, Fasial] Fed Urdu Univ Arts Sci & Technol, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); Federal Urdu University of Arts
   Science & Technology
RP Khan, A (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
EM soft_engr_isb@yahoo.com
RI Anjum, Adeel/L-4391-2013; Ahmed, Mansoor/IVU-8924-2023
OI Anjum, Adeel/0000-0001-5083-0019; Ahmed, Mansoor/0000-0003-2034-1403;
   Khan, Abid/0000-0003-2712-1956
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abd-El-Atty B, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2386-3
   Abdullah S, 2015, NONLINEAR DYNAM, V79, P1679, DOI 10.1007/s11071-014-1767-5
   Aboytes-González JA, 2018, NONLINEAR DYNAM, V94, P2003, DOI 10.1007/s11071-018-4471-z
   Abusukhon A., 2014, INT J COMPUT APPL, V106, P1
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   [Anonymous], 2002, DESIGN RIJNDAEL
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Benrhouma O, 2015, SIGNAL IMAGE VIDEO P, V9, P1281, DOI 10.1007/s11760-013-0570-y
   Bibi N, 2018, PLOS ONE
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Çavusoglu Ü, 2017, NONLINEAR DYNAM, V87, P1081, DOI 10.1007/s11071-016-3099-0
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   El-Latif AAA, 2013, INT SOC OPT PHOTON, V8878, p88781S
   Farwa S, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3298-7
   Hussain I, 2012, Z NATURFORSCH A, V67
   Hussain I, 2018, CHINESE J PHYS, V56, P1609, DOI 10.1016/j.cjph.2018.04.013
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Jhajharia S, 2016, 10 IEEE INT C INT SY, P1
   Khan M.Q., 2019, IEEE Access, P1
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan MA, 2018, IJST-T ELECTR ENG, V42, P219, DOI 10.1007/s40998-018-0061-9
   Kim J, 2009, CRYPTOLOGIA, V33, P246, DOI 10.1080/01611190802653228
   Lam SK, 2006, LECT NOTES COMPUT SC, V3995, P14
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Lambic D, 2014, CHAOS SOLITON FRACT, V58, P16, DOI 10.1016/j.chaos.2013.11.001
   Liu GJ, 2015, NONLINEAR DYNAM, V82, P1867, DOI 10.1007/s11071-015-2283-y
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Özkaynak F, 2017, SIGNAL IMAGE VIDEO P, V11, P659, DOI 10.1007/s11760-016-1007-1
   Peng JL, 2017, INT CONF UBIQ FUTUR, P989
   Picek S, 2014, S BOX SET MATCH TOOL, P140
   Tian Y, 2018, NONLINEAR DYNAM, V94, P2115, DOI 10.1007/s11071-018-4478-5
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P327, DOI 10.4028/www.scientific.net/AMR.981.327
   Tran MT, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P253, DOI 10.1109/CIS.2008.205
   ul Islam F, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0119-x
   Ullah A, 2018, NONLINEAR DYNAM, V91, P359, DOI 10.1007/s11071-017-3874-6
   Wang C, 2018, ENGINEERING-PRC, V4, P21, DOI 10.1016/j.eng.2018.02.005
   Wang Y, 2009, ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS, P125, DOI 10.1109/ECBI.2009.15
   Webster AF, 1985, ON THE DESIGN OF S B, P523
   Xu K, 2016, LECT NOTES COMPUT SC, V10066, P305, DOI 10.1007/978-3-319-49148-6_26
   Yi X, 1997, GLOB TELECOMM CONF, P689, DOI 10.1109/GLOCOM.1997.638418
   Zaghloul A, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064628
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
NR 54
TC 12
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11667
EP 11684
DI 10.1007/s11042-019-08464-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400018
DA 2024-07-18
ER

PT J
AU Birman, R
   Segal, Y
   Hadar, O
AF Birman, Raz
   Segal, Yoram
   Hadar, Ofer
TI Overview of Research in the field of Video Compression using Deep Neural
   Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video Compression; Neural Networks; Deep Learning; Overview
AB Deep Neural Networks (DNN) have emerged in recent year as a best-of-breed alternative for performing various classification, prediction and identification tasks in images and other fields of study. In the last few years, various research groups are exploring the option to harness them to improve video coding with the primary purpose of reducing video compression rates while retaining same video quality. Evolving neural-networks based video coding research efforts are focused on two different directions: (1) improving existing video codecs by performing better predictions that are incorporated within the same codec framework, and (2) holistic methods of end-to-end image/video compression schemes. While some of the results are promising and the prospects are good, no breakthrough has been reported as of yet. This paper provides an overview of state-of-the-art research work, providing examples of few prominent publications that illustrate and further explain the different highlighted topics in the field of using DNNs for video compression. Our conclusion is that the benefits have not been fully explored yet and additional work is expected to accomplish the next generation, neural networks based codecs.
C1 [Birman, Raz; Segal, Yoram; Hadar, Ofer] Ben Gurion Univ Negev, Sch Elect & Comp Engn, Dept Commun Syst Engn, Beer Sheva, Israel.
C3 Ben Gurion University
RP Birman, R (corresponding author), Ben Gurion Univ Negev, Sch Elect & Comp Engn, Dept Commun Syst Engn, Beer Sheva, Israel.
EM birmanr@post.bgu.ac.il
RI Segal, Dr. Yoram/AES-8480-2022; HADAR, OFER/F-2051-2012
OI Segal, Dr. Yoram/0000-0001-8519-1480; Hadar, Ofer/0000-0002-6089-8401
CR [Anonymous], ARXIV160408010
   [Anonymous], 2016, PROC 4 INT C LEARN R
   [Anonymous], 2019, IEEE T CIRCUITS SYST
   [Anonymous], SPIE OPT PHOT C SAN
   [Anonymous], PICT COD S PCS IEEE
   [Anonymous], INT CLEARN REPR ICLR
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], 2018, ARXIV180805734
   [Anonymous], SPIE OPT PHOT C
   [Anonymous], 2017, VIDEO COMPRESSION US
   [Anonymous], COMPUTING RES REPOSI
   [Anonymous], 2018, ARXIV181200101
   Chang QL, 2018, CAN J INFECT DIS MED, V2018, DOI 10.1155/2018/7170416
   Chen T., 2017, P IEEE VCIP DEC, P1, DOI DOI 10.1109/VCIP.2017.8305033
   Chen Zhibo, 2019, IEEE T CIRCUITS SYST
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huo S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351609
   Ibrahim EM, 2018, IEEE INT SYM MULTIM, P110, DOI 10.1109/ISM.2018.00027
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Johnston N., 2017, ArXiv e-prints
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lainema J, 2011, IEEE INT WORKSH MULT
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lee JK, 2018, ASIAPAC SIGN INFO PR, P505, DOI 10.23919/APSIPA.2018.8659611
   Li HG, 2018, NEUROCOMPUTING, V272, P558, DOI 10.1016/j.neucom.2017.07.037
   Li JH, 2017, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2017.8296231
   Li Y., 2017, Discret. Dyn. Nat. Soc., V2017, P1
   Li Y, 2018, IEEE T CIRC SYST VID, V28, P2316, DOI 10.1109/TCSVT.2017.2727682
   Lin JY, 2019, GEOCARTO INT, V34, P1608, DOI 10.1080/10106049.2018.1506505
   Liu D., 2019, ARXIV PREPRINT 19041
   Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P2140, DOI 10.1109/TIP.2018.2882923
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mukherjee D, 2015, PROC SPIE, V9599, DOI 10.1117/12.2191104
   Santurkar S, 2018, PICT COD SYMP, P258, DOI 10.1109/PCS.2018.8456298
   Schiopu I, 2018, PICT COD SYMP, P16, DOI 10.1109/PCS.2018.8456311
   Selimovic A., 2018, IEEE INT WORK C BIOI, P1
   Shen MM, 2011, IEEE T CIRC SYST VID, V21, P755, DOI 10.1109/TCSVT.2011.2130390
   Shi XJ, 2015, ADV NEUR IN, V28
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Su HY, 2014, SCI WORLD J, DOI 10.1155/2014/716020
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Takahashi K, 2011, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2011.6115764
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Wang Y, 2018, MINIM INVASIV THER, V27, P355, DOI 10.1080/13645706.2018.1462833
   Yan N, 2018, IEEE IMAGE PROC, P201, DOI 10.1109/ICIP.2018.8451286
   Zhang HJ, 2018, IEEE T FUZZY SYST, V26, P884, DOI 10.1109/TFUZZ.2017.2697403
   Zhao ZN, 2019, IEEE ACM T COMPUT BI, V16, P1753, DOI 10.1109/TCBB.2017.2706682
NR 50
TC 13
Z9 13
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11699
EP 11722
DI 10.1007/s11042-019-08572-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400020
DA 2024-07-18
ER

PT J
AU Garbin, C
   Zhu, XQ
   Marques, O
AF Garbin, Christian
   Zhu, Xingquan
   Marques, Oge
TI Dropout <i>vs.</i> batch normalization: an empirical study of their
   impact to deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Overfitting; Dropout; Batch normalization; Optimization;
   Regularization
AB Overfitting and long training time are two fundamental challenges in multilayered neural network learning and deep learning in particular. Dropout and batch normalization are two well-recognized approaches to tackle these challenges. While both approaches share overlapping design principles, numerous research results have shown that they have unique strengths to improve deep learning. Many tools simplify these two approaches as a simple function call, allowing flexible stacking to form deep learning architectures. Although their usage guidelines are available, unfortunately no well-defined set of rules or comprehensive studies to investigate them concerning data input, network configurations, learning efficiency, and accuracy. It is not clear when users should consider using dropout and/or batch normalization, and how they should be combined (or used alternatively) to achieve optimized deep learning outcomes. In this paper we conduct an empirical study to investigate the effect of dropout and batch normalization on training deep learning models. We use multilayered dense neural networks and convolutional neural networks (CNN) as the deep learning models, and mix dropout and batch normalization to design different architectures and subsequently observe their performance in terms of training and test CPU time, number of parameters in the model (as a proxy for model size), and classification accuracy. The interplay between network structures, dropout, and batch normalization, allow us to conclude when and how dropout and batch normalization should be considered in deep learning. The empirical study quantified the increase in training time when dropout and batch normalization are used, as well as the increase in prediction time (important for constrained environments, such as smartphones and low-powered IoT devices). It showed that a non-adaptive optimizer (e.g. SGD) can outperform adaptive optimizers, but only at the cost of a significant amount of training times to perform hyperparameter tuning, while an adaptive optimizer (e.g. RMSProp) performs well without much tuning. Finally, it showed that dropout and batch normalization should be used in CNNs only with caution and experimentation (when in doubt and short on time to experiment, use only batch normalization).
C1 [Garbin, Christian; Zhu, Xingquan; Marques, Oge] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Zhu, XQ (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
EM cgarbin@fau.edu; xzhu3@fau.edu; omarques@fau.edu
RI ZOU, Fengcai/ABE-4598-2021
OI ZOU, Fengcai/0000-0002-9613-3734; Zhu, Xingquan/0000-0003-4129-9611;
   Garbin, Christian/0000-0002-4261-5447
CR [Anonymous], US TEST DAT VAL DAT
   [Anonymous], UNDERSTANDING REGULA
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2008, COMPUT SCI
   [Anonymous], 2012, COURSERA NEURAL NETW
   [Anonymous], NEW TYPES DEEP NEURA
   [Anonymous], 2018, UNDERSTANDING DISHAR
   [Anonymous], STANFORD U CS231N CO
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8_26
   Brock Andrew, 2017, ARXIV170604983
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Goodfellow I., 2016, Nature, DOI DOI 10.1038/NATURE14539
   Hinton G.E., 1985, LEARNING INTERNAL RE, DOI [10.21236/ada164453, DOI 10.21236/ADA164453, 10.21236/ADA164453]
   Hinz T, 2018, INT J COMPUT INTELL, V17, DOI 10.1142/S1469026818500086
   Ioffe S., 2015, P INT C LEARN REPR S
   Kohler Jonas, 2018, ARXIV180510694
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky Alex., 2019, THE CIFAR 10 DATASET
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   LeCun Y., 1998, The MNIST database of handwritten digits.
   Lipton Z. C., 2015, ARXIV
   Loh WY, 2014, INT STAT REV, V82, P329, DOI 10.1111/insr.12016
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Morgan N., 1990, Advances in Neural Information Processing Systems
   Nair Vinod, 2010, INT C MACH LEARN, P807
   Perez L., 2017, ARXIV
   Ruder S., 2016, OVERVIEW GRADIENT DE
   Smith L., 2018, DISCIPLINED APPROA 1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
NR 32
TC 212
Z9 227
U1 38
U2 117
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12777
EP 12815
DI 10.1007/s11042-019-08453-9
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700002
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Kanwal, N
   Girdhar, A
   Kaur, L
   Bhullar, JS
AF Kanwal, Navdeep
   Girdhar, Akshay
   Kaur, Lakhwinder
   Bhullar, Jaskaran S.
TI Digital image splicing detection technique using optimal threshold based
   local ternary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery detection; Image splicing; Local ternary pattern; SVM
ID DCT
AB Digital images were considered as authentic proof of evidence some years ago but advancement in technology has made image tampering an easy task for every user. Investigation of the digital images for forgery detection, and authenticate their genuineness is need of the hour. To address this issue, the paper proposes a new block-based technique for image splicing detection. In this technique, first the image is converted to YCbCr format and chrominance component of the image is extracted. This component is segmented in overlapping blocks to extract local features. The paper proposes to use a new texture descriptor named as otsu based enhanced local ternary pattern (OELTP) for feature extraction from these blocks. OELTP uses an optimal threshold value to improve the enhanced local ternary pattern (ELTP) texture descriptor, for better detection of image forgery. Further, the paper proposes to use energy for reducing dimensionality of features, instead of using complex computations as used in earlier techniques. Finally, the features are sorted for speedy classification and fed to support vector machine (SVM) for labelling the images either as authentic or forged. The proposed technique has been tested on varying groups of data from the benchmark dataset(s) and has achieved an accuracy upto 98.25%. To demonstrate the superiority of proposed technique, results are also compared with the state-of-the-art techniques.
C1 [Kanwal, Navdeep] IKG PTU, Kapurthala, India.
   [Girdhar, Akshay] Guru Nanak Dev Engn Coll, Dept IT, Ludhiana, Punjab, India.
   [Kaur, Lakhwinder] Punjabi Univ, Dept Comp Engn, Patiala, Punjab, India.
   [Bhullar, Jaskaran S.] MIMIT, Malout, India.
C3 I. K. Gujral Punjab Technical University; Guru Nanak Dev Engineering
   College Ludhiana; Punjabi University; Malout Institute of Management &
   Information Technology
RP Kanwal, N (corresponding author), IKG PTU, Kapurthala, India.
EM navdeepkanwal@gmail.com; akshay1975@gmail.com
OI Kanwal, Navdeep/0000-0003-3015-2390
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Alahmadi A, 2017, SIGNAL IMAGE VIDEO P, V11, P81, DOI 10.1007/s11760-016-0899-0
   [Anonymous], HYBRID EVOLUTIONARY
   [Anonymous], STUD ENC PAR DIG TEL
   [Anonymous], J ENG SCI TECHNOLOGY
   [Anonymous], IMAGE SPLICING FORGE
   [Anonymous], PHOTOTAMPERING HIST
   Cavazos-Rehg PA, 2018, SUBST ABUS, V39, P21, DOI 10.1080/08897077.2017.1365802
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Farid H., 2006, Significance, V3, P162, DOI [DOI 10.1111/J.1740-9713.2006.00197.X, 10.1111/j.1740-9713.2006.00197.x]
   Hakimi F, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1074, DOI 10.1109/KBEI.2015.7436195
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Li C, 2017, NEUROCOMPUTING, V228, P29, DOI 10.1016/j.neucom.2016.04.068
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mayer O, 2018, IEEE T INF FOREN SEC, V13, P1762, DOI 10.1109/TIFS.2018.2799421
   Moghaddasi Z, 2014, SCI WORLD J, DOI 10.1155/2014/606570
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Shah AP, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P396, DOI 10.1109/ICOPS35962.2018.9575678
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Su B, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Vert J.-P., 2004, A Primer on Kernel Methods, V47, P35
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yuan JH, 2014, LECT NOTES COMPUT SC, V8588, P443, DOI 10.1007/978-3-319-09333-8_48
   Zeng H, 2017, MULTIMED TOOLS APPL, V76, P4783, DOI 10.1007/s11042-016-3712-8
NR 33
TC 22
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 12829
EP 12846
DI 10.1007/s11042-020-08621-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700004
DA 2024-07-18
ER

PT J
AU Zhan, YR
   Zhao, XY
   Lin, X
   Liu, JK
   Liu, MJ
   Niu, DM
AF Zhan, Yaru
   Zhao, Xiuyang
   Lin, Xue
   Liu, Junkai
   Liu, Mingjun
   Niu, Dongmei
TI Graph matching based on local and global information of the graph nodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph matching; Affinity matrix; Global information; Local information;
   Random walks
ID ISOMORPHISM ALGORITHM; TRACKING
AB Graph matching is an essential NP-problem in computer vision and pattern recognition. In this paper, we propose an approximate graph matching method. This method formulates the problem of computing the correspondences between two graphs as a problem of selecting nodes on an association graph. The nodes of the association graph represent candidate correspondences between the two original graphs. Our method first constructs an affinity matrix based on both the global and local information of the original graphs' nodes. Each element of this matrix is used to measure the mutual consistency of a pair of nodes within the association graph. Our method then applies the reweighted random walks technique that preserves the one-to-one matching constraint to simulate random walks on the association graph and to iteratively compute a quasi-stationary distribution. To discretize this distribution, our method finally applies the Hungarian algorithm and obtains an approximate matching between the original two graphs. Experimental results demonstrate the effectiveness of our method for graph matching and the ability of our method for being robust to outlier and deformation noise.
C1 [Zhan, Yaru; Zhao, Xiuyang; Lin, Xue; Liu, Junkai; Liu, Mingjun; Niu, Dongmei] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
C3 University of Jinan
RP Niu, DM (corresponding author), Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250022, Peoples R China.
EM 546674232@qq.com; dniu_ujn@hotmail.com
RI zhang, jt/JVE-1333-2024
CR Albarelli A, 2009, IEEE I CONF COMP VIS, P1319, DOI 10.1109/ICCV.2009.5459312
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], PATTERN RECOGNIT LET
   [Anonymous], 2010, J EXP ALGORITHMICS J
   [Anonymous], C ADV NEUR INF PROC
   [Anonymous], T CIRCUIT SYST VIDEO
   [Anonymous], 2017, COMPUTER VISION PATT
   [Anonymous], 2002, P 11 INT C WORLD WID, DOI DOI 10.1145/511446.511513
   [Anonymous], ARTIFICIAL INTELLIGE
   Berg AC, 2005, PROC CVPR IEEE, P26
   Carletti V, 2019, PATTERN RECOGN LETT, V125, P591, DOI 10.1016/j.patrec.2019.07.001
   Chen HT, 2001, PROC CVPR IEEE, P210
   Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492
   Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75
   Cori M, 2005, LECT NOTES COMPUT SC, V3686, P81
   Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445
   Foggia P, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414500013
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Gori M, 2004, INT C PATT RECOG, P394, DOI 10.1109/ICPR.2004.1334549
   Hu N, 2014, PROC CVPR IEEE, P2313, DOI 10.1109/CVPR.2014.296
   Hu YT, 2016, PROC CVPR IEEE, P346, DOI 10.1109/CVPR.2016.44
   Jiang B, 2019, INT J COMPUT VISION, V127, P1345, DOI 10.1007/s11263-019-01185-1
   Jiang B, 2017, AAAI CONF ARTIF INTE, P4089
   Jiang B, 2015, AAAI CONF ARTIF INTE, P3790
   Jiang B, 2017, PATTERN RECOGN, V61, P255, DOI 10.1016/j.patcog.2016.07.021
   Jiang B, 2014, PATTERN RECOGN, V47, P736, DOI 10.1016/j.patcog.2013.08.024
   LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Leordeanu M., 2009, NIPS, P1114
   Liu MF, 2016, NEUROCOMPUTING, V181, P64, DOI 10.1016/j.neucom.2015.06.099
   Liu M, 2017, IEEE SIGNAL PROC LET, V24, P1168, DOI 10.1109/LSP.2017.2704292
   Liu X, 2018, IEEE ACCESS, V6, P199, DOI 10.1109/ACCESS.2017.2761910
   Liu X, 2017, IEEE ACCESS, V5, P3801, DOI 10.1109/ACCESS.2017.2677976
   Liu ZY, 2014, INT J COMPUT VISION, V109, P169, DOI 10.1007/s11263-014-0707-7
   Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223
   Mills-Tettey G.A., 2007, The dynamic Hungarian algorithm for the assignment problem with changing costs
   Riesen K, 2010, ADV DATABASE SYST, V40, P217, DOI 10.1007/978-1-4419-6045-0_7
   SAHNI S, 1976, J ACM, V23, P555, DOI 10.1145/321958.321975
   Solnon C, 2010, ARTIF INTELL, V174, P850, DOI 10.1016/j.artint.2010.05.002
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Wang T, 2018, IEEE T PATTERN ANAL, V40, P2853, DOI 10.1109/TPAMI.2017.2767591
   Wu J, 2013, PATTERN RECOGN, V46, P2927, DOI 10.1016/j.patcog.2013.04.008
   Wu Y, 2019, NEUROCOMPUTING, V328, P97, DOI 10.1016/j.neucom.2018.02.104
   Yan JC, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P167, DOI 10.1145/2911996.2912035
   Yang X, 2015, PATTERN RECOGN LETT, V55, P8, DOI 10.1016/j.patrec.2014.12.011
   Yu T., 2018, Advances in neural information processing systems, P853
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang LM, 2018, IEEE T MULTIMEDIA, V20, P1462, DOI 10.1109/TMM.2017.2769799
   Zhang Z, 2016, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2016.135
   Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667
NR 50
TC 3
Z9 3
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11567
EP 11590
DI 10.1007/s11042-019-08516-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400014
DA 2024-07-18
ER

PT J
AU Zhang, GS
   Wu, JJ
   Tan, MZ
   Yang, ZJ
   Cheng, QY
   Han, H
AF Zhang, Guoshuai
   Wu, Jiaji
   Tan, Mingzhou
   Yang, Zhongjie
   Cheng, Qingyu
   Han, Hong
TI Learning to Predict US Policy Change Using New York Times Corpus with
   Pre-Trained Language Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Policy change predicting; New York Times Corpus; Pre-trained language
   model; BERT; BPCI
ID MEDIA
AB With the process of economic globalization and political multi-polarization accelerating, it is especially important to predict policy change in the United States. While current research has not taken advantage of the rapid advancement in the natural language processing and the relationship between news media and policy change, we propose a BERT-based model to predict policy change in the United States, using news published by the New York Times. Specifically, we propose a large-scale news corpus from the New York Times covers the period from 2006 to 2018. Then we use the corpus to fine-tune the pre-trained BERT language model to determine whether the news is on the front page, which corresponds to the policy priority. We propose a BERT-based Policy Change Index (BPCI) for the United States to predict the policy change in the future short period of time. Experimental results in the New York Times Corpus demonstrate the validity of the proposed method.
C1 [Zhang, Guoshuai; Wu, Jiaji; Cheng, Qingyu] Xidian Univ, Sch Elect Engn, Xian, Peoples R China.
   [Wu, Jiaji; Tan, Mingzhou; Yang, Zhongjie] Xian Brain Percept Technol Dev Co Ltd, Xian, Peoples R China.
   [Tan, Mingzhou; Yang, Zhongjie; Han, Hong] Xidian Univ, Sch Artificial Intelligence, Xian, Peoples R China.
C3 Xidian University; Xidian University
RP Wu, JJ (corresponding author), Xidian Univ, Sch Elect Engn, Xian, Peoples R China.; Wu, JJ (corresponding author), Xian Brain Percept Technol Dev Co Ltd, Xian, Peoples R China.
EM wujj@mail.xidian.edu.cn
OI Zhang, Guoshuai/0000-0001-7432-3484
FU National Natural Science Foundation of China [61775175, 61771378,
   61601355]; Key Research and Development Program of Shaanxi Province Key
   Industry Innovation Chain (Group) [2019ZDLGY10-06]
FX This work was supported by the National Natural Science Foundation of
   China under 61775175, 61771378 and 61601355, and by the Key Research and
   Development Program of Shaanxi Province Key Industry Innovation Chain
   (Group) -Industrial Field under No.2019ZDLGY10-06.
CR [Anonymous], 2019, ARXIV190505583
   [Anonymous], EC COMMENTARY
   [Anonymous], INT POLITICS
   [Anonymous], IJCAI
   [Anonymous], HEARINGS
   [Anonymous], LDC95T21
   [Anonymous], 2018, OPENAL BLOG
   [Anonymous], 2015, 29 AAAI C ART INT
   [Anonymous], ARXIV14076333
   ANSOLABEHERE S, 1994, PUBLIC OPIN QUART, V58, P335, DOI 10.1086/269431
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Chan Julian TszKin, 2018, AEI EC WORKING PAPER
   DellaVigna S, 2007, Q J ECON, V122, P1187, DOI 10.1162/qjec.122.3.1187
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   Enikolopov R, 2011, AM ECON REV, V101, P3253, DOI 10.1257/aer.101.7.3253
   Gerber AS, 2009, AM ECON J-APPL ECON, V1, P35, DOI 10.1257/app.1.2.35
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI DOI 10.18653/V1/E17-2068
   Katz DM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174698
   Kim Y, 2014, IEEE ASME INT C ADV, P1747, DOI 10.1109/AIM.2014.6878336
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai S., 2015, AAAI C ART INT
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sim Yanchuan, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, P1724
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang AQ, 2016, INT CONF GEOINFORM
   Woon J, 2009, PS-POLIT SCI POLIT, V42, P329, DOI 10.1017/S104909650909043X
   Xiao SY, 2020, IEEE T CYBERNETICS, V50, P1220, DOI 10.1109/TCYB.2019.2900478
   Yano T., 2012, P 2012 C N AM CHAPTE, P793
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
   Zirn Cacilia, 2015, P INT C REC ADV NAT, P747
NR 36
TC 4
Z9 5
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34227
EP 34240
DI 10.1007/s11042-020-08946-y
EA MAY 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000529768400004
DA 2024-07-18
ER

PT J
AU Bathla, G
   Aggarwal, H
   Rani, R
AF Bathla, Gourav
   Aggarwal, Himanshu
   Rani, Rinkle
TI AutoTrustRec: Recommender System with Social Trust and Deep Learning
   using AutoEncoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Big data; Social media; Social recommendation; Social
   trust
AB Deep learning is the most active research topic amongst data scientists and analysts these days. It is because deep learning has provided very high accuracy in various domains such as speech recognition, image processing and natural language processing. Researchers are actively working to deploy deep learning on information retrieval. Due to large-scale data generated by social media and sensor networks, it is quite difficult to train unstructured and highly complex data. Recommender system is intelligent information filtering technique which assists the user to find topic of interest within complex overloaded information. In this paper, our motive is to improve recommendation accuracy for large-scale heterogeneous complex data by integrating deep learning architecture. In our proposed approach ratings, direct and indirect trust values are fed in neural network using shared layer in autoencoder. Comprehensive experiment analysis on three public datasets proves that RMSE and MAE are improved significantly by using our proposed approach.
C1 [Bathla, Gourav] Punjabi Univ, Patiala 147002, Punjab, India.
   [Aggarwal, Himanshu] Punjabi Univ, Dept Comp Engn, Patiala 147002, Punjab, India.
   [Rani, Rinkle] Thapar Univ, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
C3 Punjabi University; Punjabi University; Thapar Institute of Engineering
   & Technology
RP Bathla, G (corresponding author), Punjabi Univ, Patiala 147002, Punjab, India.
EM gouravbathla@gmail.com; himanshu.pup@gmail.com; raggarwal@thapar.edu
RI Aggarwal, Rinkle/AAT-4740-2020; Bathla, Gourav/AAT-4904-2020; Aggarwal,
   Himanshu/GOE-5647-2022; Bathla, Gourav/HQZ-2734-2023
OI Bathla, Gourav/0000-0003-4198-9647; Bathla, Gourav/0000-0003-4198-9647;
   AGGARWAL, HIMANSHU/0000-0003-1782-8376
CR [Anonymous], ARXIV170607845
   [Anonymous], ARXIV170301760
   [Anonymous], ARXIV171207525
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   Chen CC, 2013, INFORM SCIENCES, V224, P19, DOI 10.1016/j.ins.2012.10.037
   Chen M., 2012, P 29 INT C MACHINE L, P1627
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo G, 2016, NOVEL RECOMMENDATION
   Guo GB, 2016, IEEE T KNOWL DATA EN, V28, P1607, DOI 10.1109/TKDE.2016.2528249
   Guo GB, 2015, AAAI CONF ARTIF INTE, P123
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jamali M., 2010, P 4 ACM C REC SYST, P135, DOI DOI 10.1145/1864708.1864736
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu D, 2017, 2017 INTERNATIONAL CONFERENCE ON SENSING, DIAGNOSTICS, PROGNOSTICS, AND CONTROL (SDPC), P387, DOI 10.1109/SDPC.2017.80
   Ma H., 2008, P 17 ACM C INF KNOWL, P931, DOI [DOI 10.1145/1458082.1458205, 10.1145/1458082.1458205]
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ou MD, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1105, DOI 10.1145/2939672.2939751
   Pham MC, 2011, J UNIVERS COMPUT SCI, V17, P583
   Dang QV, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P209, DOI 10.1109/CIC.2017.00036
   Raina R., 2009, ICML, P1
   Salakhutdinov R., 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726
   Strub F., 2016, P 1 WORKSH DEEP LEAR, P11
   Tang JL, 2013, SOC NETW ANAL MIN, V3, P1113, DOI 10.1007/s13278-013-0141-9
   Tran D. H., 2018, ACIS 2018 29 AUSTRAL, P1, DOI [10.5130/acis2018.aj, DOI 10.5130/ACIS2018.AJ]
   Van den Oord A., 2013, ADV NEURAL INFORM PR, P2643, DOI [DOI 10.1109/MMUL.2011.34.VAN, 10.5555/2999792.2999907]
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang H, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1235, DOI 10.1145/2783258.2783273
   Wang H, 2015, AAAI CONF ARTIF INTE, P3052
   Wei J, 2017, EXPERT SYST APPL, V69, P29, DOI 10.1016/j.eswa.2016.09.040
   Yang B, 2017, IEEE T PATTERN ANAL, V39, P1633, DOI 10.1109/TPAMI.2016.2605085
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
   Zhuang FZ, 2017, NEURAL NETWORKS, V90, P83, DOI 10.1016/j.neunet.2017.03.009
NR 41
TC 19
Z9 19
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20845
EP 20860
DI 10.1007/s11042-020-08932-4
EA APR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528990000002
DA 2024-07-18
ER

PT J
AU Hou, GJ
   Li, JM
   Wang, GD
   Pan, ZK
   Zhao, X
AF Hou Guojia
   Li Jingming
   Wang Guodong
   Pan Zhenkuan
   Zhao Xin
TI Underwater image dehazing and denoising via curvature variation
   regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Dehazing and denoising; Image formation model;
   Curvature variation; ADMM
ID ENHANCEMENT; CONTRAST; COEFFICIENT
AB Challenges for underwater captured image processing often lie in images degraded with haze, noise and low contrast, caused by absorption and scattering of the light during propagation. In this paper, we aim to establish a novel total variation and curvature based approach that can properly deal with these problems to achieve dehazing and denoising simultaneously. Integration with the underwater image formation model is successfully realized by formulating the global background light and the transmission map derived from the improved dark channel prior and underwater red channel prior into our variational framework respectively. Moreover, the generated non-smooth optimization problem is solved by the alternating direction method of multipliers (ADMM). Extensive experiments including real underwater image application tests and convergence curves display the significant gains of the proposed variational curvature model and developed ADMM algorithm. Qualitative and quantitative comparisons with several state-of-the-art methods as well as four evaluation metrics are further conducted to quantify the improvements of our fusion approach.
C1 [Hou Guojia; Li Jingming; Wang Guodong; Pan Zhenkuan; Zhao Xin] Qingdao Univ, Coll Comp Sci & Technol, 308 Ningxia Rd, Qingdao, Peoples R China.
   [Hou Guojia] Qingdao Univ, Sch Automat, 308 Ningxia Rd, Qingdao, Peoples R China.
C3 Qingdao University; Qingdao University
RP Hou, GJ (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, 308 Ningxia Rd, Qingdao, Peoples R China.; Hou, GJ (corresponding author), Qingdao Univ, Sch Automat, 308 Ningxia Rd, Qingdao, Peoples R China.
EM hgjouc@126.com
OI Hou, Guojia/0000-0001-6509-6259
FU National Natural Science Foundation of China [61901240]; China
   Scholarship Council [201908370002]; Natural Science Foundation of
   Shandong Province, China [ZR2019BF042]; China Postdoctoral Science
   Foundation [2017M612204]
FX The research work is partially supported by National Natural Science
   Foundation of China (No. 61901240), China Scholarship Council (No.
   201908370002), the Natural Science Foundation of Shandong Province,
   China (No. ZR2019BF042), and the China Postdoctoral Science Foundation
   (No. 2017M612204). The first author would like to thank Lu Tan for doing
   many researches about variational method based on image analysis, also
   thank Xiangjun Du, Yi Zhao, and Xiaopeng Wang, who work in the
   experimental teaching centre for providing us with the experimental
   platform.
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   [Anonymous], 2016, BIOMED RES INT
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chang HB, 2018, SIAM J IMAGING SCI, V11, P24, DOI 10.1137/16M1103270
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Duan JM, 2017, PATTERN RECOGN, V72, P158, DOI 10.1016/j.patcog.2017.07.004
   Duan JM, 2015, J GLOBAL OPTIM, V62, P853, DOI 10.1007/s10898-015-0290-7
   Fang FM, 2014, SIAM J IMAGING SCI, V7, P969, DOI 10.1137/130919696
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   GORDON HR, 1989, LIMNOL OCEANOGR, V34, P1389, DOI 10.4319/lo.1989.34.8.1389
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Guo QW, 2017, J OCEAN U CHINA, V16, P757, DOI 10.1007/s11802-017-3242-7
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou GJ, 2019, NEUROCOMPUTING, V369, P106, DOI 10.1016/j.neucom.2019.08.041
   Hou GJ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051207
   Hou GJ, 2018, IET IMAGE PROCESS, V12, P292, DOI 10.1049/iet-ipr.2017.0359
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kumar N., 2018, MULTIMED TOOLS APPL, P1
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Lu JG, 2017, MULTIMED TOOLS APPL, V76, P10991, DOI 10.1007/s11042-016-3462-7
   Marques TP, 2018, INT C PATT REC
   McGlamery B. L., 1979, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V208, P221
   Panetta K, 2013, IEEE T CONSUM ELECTR, V59, P643, DOI 10.1109/TCE.2013.6626251
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Prasath VBS, 2016, ADV INTELL SYST, V425, P625, DOI 10.1007/978-3-319-28658-7_53
   Rizzini DL, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/60526
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Shu Q, 2018, 9 INT C GRAPH IM PRO, P10615
   Tan L, 2018, APPL MATH MODEL, V61, P280, DOI 10.1016/j.apm.2018.04.017
   Tan L, 2018, J MATH IMAGING VIS, V60, P1, DOI 10.1007/s10851-017-0735-3
   Tikhonov A.N., 1963, SOV MATH DOKL, V4, P1624
   Wang GD, 2019, MULTIMED TOOLS APPL, V78, P29007, DOI 10.1007/s11042-018-6294-9
   Wang GD, 2017, MULTIMED TOOLS APPL, V76, P24515, DOI 10.1007/s11042-016-4136-1
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Wen H, 2013, 2013 IEEE INT S CIRC
   Wu QD, 2017, MULTIMED TOOLS APPL, V76, P17179, DOI 10.1007/s11042-016-3760-0
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang HT, 2018, MULTIMED TOOLS APPL, V77, P9003, DOI 10.1007/s11042-017-4791-x
   Zhang Y, 2007, IEEE T IMAGE PROCESS, V16, P1036, DOI 10.1109/TIP.2007.891787
   Zhu W, 2013, INVERSE PROBL IMAG, V7, P1409, DOI 10.3934/ipi.2013.7.1409
NR 49
TC 18
Z9 18
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20199
EP 20219
DI 10.1007/s11042-020-08759-z
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000526210000002
DA 2024-07-18
ER

PT J
AU Batool, FE
   Attique, M
   Sharif, M
   Javed, K
   Nazir, M
   Abbasi, AA
   Iqbal, Z
   Riaz, N
AF Batool, Faiza Eba
   Attique, Muhammad
   Sharif, Muhammad
   Javed, Kashif
   Nazir, Muhammad
   Abbasi, Aaqif Afzaal
   Iqbal, Zeshan
   Riaz, Naveed
TI Offline signature verification system: a novel technique of fusion of
   GLCM and geometric features using SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric system; Segmentation; Features extraction; Features fusion;
   Classification
ID RECOGNITION; SELECTION; IMAGES
AB In the area of digital biometric systems, the handwritten signature plays a key role in the authentication of a person based on their original samples. In offline signature verification (OSV), several problems exist that are challenging for verification of authentic or forgery signature by the digital system. Correct signature verification improves the security of people, systems, and services. It is applied to uniquely identify an individual based on the motion of pen as up and down, signature speed, and shape of a loop. In this work, the multi-level features fusion and optimal features selection based automatic technique is proposed for OSV. For this purpose, twenty-two Gray Level Co-occurrences Matrix (GLCM) and eight geometric features are calculated from pre-processing signature samples. These features are fused by a new parallel approach which is based on a high-priority index feature (HPFI). A skewness-kurtosis based features selection approach is also proposed name skewness-kurtosis controlled PCA (SKcPCA) and selects the optimal features for final classification into forged and genuine signatures. MCYT, GPDS synthetic, and CEDAR datasets are utilized for validation of the proposed system and show enhancement in terms of Far and FRR as compared to existing methods.
C1 [Batool, Faiza Eba; Sharif, Muhammad] COMSATS Univ Islamabad, Dept CS, Wah Campus, Rawalpindi, Punjab, Pakistan.
   [Attique, Muhammad; Nazir, Muhammad] HITEC Univ, Dept Comp Sci, Museum Rd, Taxila, Pakistan.
   [Javed, Kashif] SMME Nust, Dept Robot, Islamabad, Pakistan.
   [Abbasi, Aaqif Afzaal] Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
   [Iqbal, Zeshan] UET Taxila, Dept Comp Engn, Taxila, Pakistan.
   [Riaz, Naveed] Natl Univ Sci & Technol, SEECS, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI); NITEC University; National
   University of Sciences & Technology - Pakistan; Quaid I Azam University;
   National University of Sciences & Technology - Pakistan
RP Abbasi, AA (corresponding author), Fdn Univ Islamabad, Dept Software Engn, Islamabad, Pakistan.
EM attique@ciitwah.edu.pk
RI khan, sajid/HGE-2406-2022; Khan, Dr. Muhammad Attique/AAX-2644-2021;
   Abbasi, Aaqif Afzaal/AFG-9482-2022; Iqbal, Zeshan/A-1166-2010; Sharif,
   Muhammad/ACD-2598-2022; Sharif, Muhammad/AAB-8376-2022; Iqbal,
   Zeshan/D-8820-2014
OI Khan, Dr. Muhammad Attique/0000-0002-6347-4890; Abbasi, Aaqif
   Afzaal/0000-0002-9982-1321; Sharif, Muhammad/0000-0002-7258-8400; Iqbal,
   Zeshan/0000-0003-4545-4092
CR Abbas N, 2016, 2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2213
   Alajrami E., 2020, Int. J. Acad. Multidiscip. Res, V3, P39, DOI 10.1016/j.patcog.2017.05.012
   Albregtsen F., 2008, STAT TEXTURE MEASURE, DOI [10.5209/ARIS.6586, DOI 10.5209/ARIS.6586]
   [Anonymous], J MED SYSTEMS
   Arshad H, 2019, INT J MACH LEARN CYB, V10, P3601, DOI 10.1007/s13042-019-00947-0
   Bhunia AK, 2019, NEURAL COMPUT APPL, V31, P8737, DOI 10.1007/s00521-019-04220-x
   Biswas Samit, 2010, INT J SMART HOME, V4, P43
   Çalik N, 2019, NEUROCOMPUTING, V359, P1, DOI 10.1016/j.neucom.2019.03.027
   Chandra S, 2016, 2016 3rd International Conference on Recent Advances in Information Technology (RAIT), P410, DOI 10.1109/RAIT.2016.7507937
   Ferrer Marie-Helene, 2013, Instituto Diplomatico, P1, DOI [DOI 10.1109/ICB.2013.6612969, 10.1145/2501907.2501963, 10.1109/ICB.2013.6612969]
   Ghanim TM, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P293, DOI 10.1109/ICCES.2018.8639420
   Gyimah K., 2019, Journal of Advances in Mathematics and Computer Science, V32, P1, DOI [10.9734/jamcs/2019/v32i230141, DOI 10.9734/JAMCS/2019/V32I230141]
   Habiba A, EXPERT SYSTEMS
   Hadjadj I, 2019, LECT NOTES COMPUT SC, V11868, P177, DOI 10.1007/978-3-030-31321-0_16
   Hafemann LG, 2019, IEEE T INF FORENSICS
   Hafemann LG, 2018, INT J DOC ANAL RECOG, V21, P219, DOI 10.1007/s10032-018-0301-6
   Hafemann LG, 2017, PATTERN RECOGN, V70, P163, DOI 10.1016/j.patcog.2017.05.012
   Jadhav T, 2019, INT RES J ENG TECHNO, V6, P579
   Jain Charu, 2017, Image Processing & Communications, V22, P23, DOI 10.1515/ipc-2017-0015
   Jan Z, 2015, ADV INTELL SYST, V353, P653, DOI 10.1007/978-3-319-16486-1_64
   Kalera MK, 2004, INT J PATTERN RECOGN, V18, P1339, DOI 10.1142/S0218001404003630
   Kayaoglu M, 2015, ARXIV150504028
   Kennard DJ, 2012, INT C PATT RECOG, P3733
   Khan MA, 2020, PATTERN RECOGN LETT, V129, P77, DOI 10.1016/j.patrec.2019.11.014
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Kumar MM, 2014, IET BIOMETRICS, V3, P347, DOI 10.1049/iet-bmt.2014.0024
   Kumar R, 2012, PATTERN RECOGN LETT, V33, P301, DOI 10.1016/j.patrec.2011.10.009
   Lantuejoul C, 1977, INT REP CENT MORPH M
   Maergner P, 2019, ARXIV190610401
   Maergner P, 2018, LECT NOTES COMPUT SC, V11004, P470, DOI 10.1007/978-3-319-97785-0_45
   Majid A, 2020, MICROSC RES TECHNIQ, V83, P562, DOI 10.1002/jemt.23447
   Masoudnia S, 2019, EXPERT SYST APPL, V133, P317, DOI 10.1016/j.eswa.2019.03.040
   Miskhat SF, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P940, DOI 10.1109/ICIEV.2012.6317439
   Morales A, 2015, PATTERN RECOGN LETT, V68, P183, DOI 10.1016/j.patrec.2015.09.011
   Neamah K, 2014, 3D RES, V5, DOI 10.1007/s13319-013-0002-3
   Nguyen V, 2011, PROC INT CONF DOC, P339, DOI 10.1109/ICDAR.2011.76
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Ortega-Garcia J, 2003, IEE P-VIS IMAGE SIGN, V150, P395, DOI 10.1049/ip-vis:20031078
   Plataniotis K. N., 2013, Color image processing and applications
   Radhika KS, 2015, PROCEDIA COMPUT SCI, V46, P1593, DOI 10.1016/j.procs.2015.02.089
   Rehman A, 2020, MICROSC RES TECHNIQ, V83, P410, DOI 10.1002/jemt.23429
   Ruiz V, 2020, NEUROCOMPUTING, V374, P30, DOI 10.1016/j.neucom.2019.09.041
   Samuel Daramola, 2010, INT J ENG SCI TECHNO, VED-2, P3137
   Sharif M, 2020, J ORGAN END USER COM, V32, P67, DOI 10.4018/JOEUC.2020040104
   Sharif M, 2020, PATTERN RECOGN LETT, V139, P50, DOI 10.1016/j.patrec.2018.01.021
   Sharif MI, 2020, PATTERN RECOGN LETT, V129, P181, DOI 10.1016/j.patrec.2019.11.019
   Soleimani A, 2016, PATTERN RECOGN LETT, V80, P84, DOI 10.1016/j.patrec.2016.05.023
   Sriwathsan W., 2020, Asian Res J Math, V16, P84
   Stauffer M, 2019, P 2019 3 INT C BIOM, P69
   Takiran M, 2017, 2017 IEEE 15 INT S A
   Thakare BS, 2018, 2018 3 INT C CONV TE, P1
   Vargas JF, 2011, PATTERN RECOGN, V44, P375, DOI 10.1016/j.patcog.2010.07.028
   Zhang ZH, 2016, INT SYM COMPUT INTEL, P103, DOI [10.1109/ISCID.2016.2033, 10.1109/ISCID.2016.138]
   Zois Elias N., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P68, DOI 10.1109/TBIOM.2019.2897802
   Zois EN, 2016, PATTERN RECOGN, V54, P162, DOI 10.1016/j.patcog.2016.01.009
NR 55
TC 36
Z9 37
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14959
EP 14978
DI 10.1007/s11042-020-08851-4
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000523401700001
DA 2024-07-18
ER

PT J
AU Kirubakaran, J
   Venkatesan, GKDP
   Baskar, S
   Kumaresan, M
   Annamalai, S
AF Kirubakaran, J.
   Prasanna Venkatesan, G. K. D.
   Baskar, S.
   Kumaresan, M.
   Annamalai, S.
TI RETRACTED: Prediction of cirrhosis disease from radiologist liver
   medical image using hybrid coupled dictionary pairs on longitudinal
   domain approach (Retracted article. See MAY, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Cirrhosis; Internet of things (IoT); Ultrasound; Region of interest
   PSNR; SSIM
ID CLASSIFICATION; RESECTION; IMPACT
AB This paper presents a novel algorithm for the liver diseases fibrosis called Cirrhosis, which is considered as the most communal diseases in healthcare research. This research work introduced a technique for discriminating the cirrhotic liver from normal liver through adaptive ultrasound (AUS) instead of ultrasound (US) images with Hybrid Coupled Dictionary Pairs on Longitudinal Domain (HCDPLD). The parameters such as region covered and data structure values or variables has been analyzed using heuristic pattern producing classifierfor identifying the sub-bands and edge features. The developed cirrhosis prediction strategy helps to improve the results of image resolution with the accuracy of 99.82%, Average Peak Signal to Noise Ratio (PSNR) of 3.22 dB and Structural Similarity Index (SSIM) of 0.89 through HCDPLD when compared with existing counterparts. Further Ingestible Internet of Things (IoT) sensors with activity tracker helps to monitor the patient health accurately in reliable data transfer.
C1 [Kirubakaran, J.] Muthayammal Engn Coll Autonomous, Dept ECE, Namakkal, Tamil Nadu, India.
   [Prasanna Venkatesan, G. K. D.] Karpagam Acad Higher Educ, Dept Elect & Commun Engn, Coimbatore 641021, Tamil Nadu, India.
   [Baskar, S.] Karpagam Acad Higher Educ, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.
   [Kumaresan, M.; Annamalai, S.] Galgotias Univ, Sch Comp Sci & Engn, Greater Noida, Uttar Pradesh, India.
C3 Muthayammal Engineering College; Karpagam Academy of Higher Education
   (KAHE); Karpagam Academy of Higher Education (KAHE); Galgotias
   University
RP Kirubakaran, J (corresponding author), Muthayammal Engn Coll Autonomous, Dept ECE, Namakkal, Tamil Nadu, India.
EM kirubakaranj.rnd@gmail.com
RI M, Kumaresan/ABG-5635-2021; S, Baskar/R-6346-2017; d, p/GWC-4283-2022;
   VENKATESAN, PRASANNA/V-5828-2018
OI S, Baskar/0000-0003-3570-3059; Selvarajan,
   Annamalai/0000-0001-6336-1194; Dhayanithi, Dr. Prasanna
   Venkatesh/0000-0001-6339-2142; Kumaresan, Dr.
   Kumaresan/0000-0001-6716-7209; VENKATESAN, PRASANNA/0000-0002-0638-1938
CR Acharya UR, 2015, KNOWL-BASED SYST, V75, P66, DOI 10.1016/j.knosys.2014.11.021
   Akinyemiju T, 2017, JAMA ONCOL, V3, P1683, DOI 10.1001/jamaoncol.2017.3055
   Arshad Insha, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P163, DOI 10.1109/ICACCE.2018.8441721
   Chen YF, 2017, KNOWL-BASED SYST, V127, P85, DOI 10.1016/j.knosys.2017.04.008
   Crocetti L, 2018, RADIOLOGY, V287, P473, DOI 10.1148/radiol.2018172822
   Fujimoto K, 2013, ONCOLOGY-BASEL, V84, P3, DOI 10.1159/000345883
   Gane EJ, 2017, LANCET GASTROENTEROL, V2, P805, DOI 10.1016/S2468-1253(17)30159-0
   Gao S, 2014, BIO-MED MATER ENG, V24, P1209, DOI 10.3233/BME-130922
   Guirguis-Blake JM, 2014, ANN INTERN MED, V160, P321, DOI 10.7326/M13-1844
   Gunasundari S, 2013, INT J COMPUTER APPL, V74
   Huguet A, 2018, NUTRITION, V51-52, P73, DOI 10.1016/j.nut.2018.01.008
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Islam SMR, 2015, IEEE ACCESS, V3, P678, DOI 10.1109/ACCESS.2015.2437951
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Labranche R, 2018, RADIOGRAPHICS, V38, P392, DOI 10.1148/rg.2018170079
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee S, 2018, J MAGN RESON IMAGING, V47, P1342, DOI 10.1002/jmri.25841
   Manogaran G, 2019, IEEE ACCESS, V7, P12, DOI 10.1109/ACCESS.2018.2878276
   Preeth S.S.L., 2018, J. Ambient Intell. Human. Comput., P1, DOI [10.1007/s12652-018-1154-z, DOI 10.1007/S12652-018-1154-Z]
   Quesada R, 2017, INT J HYPERTHER, V33, P135, DOI 10.1080/02656736.2016.1231938
   Ricchi P, 2018, BRIT J HAEMATOL, V180, P721, DOI 10.1111/bjh.15083
   Shakeel PM, 2020, HEALTH TECHNOL-GER, V10, P157, DOI 10.1007/s12553-018-0279-6
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Sprague BL, 2015, ANN INTERN MED, V162, P157, DOI 10.7326/M14-0692
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Valerio M, 2015, EUR UROL, V68, P8, DOI 10.1016/j.eururo.2014.10.026
   Wong VWS, 2018, J GASTROEN HEPATOL, V33, P70, DOI 10.1111/jgh.13857
   Wu CC, 2013, IEEE J BIOMED HEALTH, V17, P967, DOI 10.1109/JBHI.2013.2261819
NR 29
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9901
EP 9919
DI 10.1007/s11042-019-7259-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600010
DA 2024-07-18
ER

PT J
AU Kumar, KS
   Bai, MR
AF Kumar, K. Sharath
   Bai, M. Rama
TI Deploying multi layer extraction and complex pattern in fabric pattern
   identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HMAX model; Fabric weave patterns; SVM classifier; Complex pattern
   detection
ID CLASSIFICATION; SEGMENTATION; TEXT
AB Computer aided vision models are convincing so they can be correlated with the traditional classifier models. The prototype obtained serves as a vision for visually impaired by obtaining an outstanding interface platform for user in need. The proposed work focuses on fabric analysis for complex designs and provides audio and text identity guidelines by correlating the images under study. Colour based feature extraction is implemented to obtain global and local features which serves as an input for elaborative analysis of a fabric texture. The obtained image is partitioned to pixelated grains to achieve the above mentioned target. The features are formed as a cluster with the help of SVM classifier and HMAX(Hierarchical model and X) model. In order to improve the efficiency in complex texture fabric identification HMAX solution is combined with the traditional methods. HMAX provides good result on object recognition for methods involved in computer vision. The detail of each pixel is divided to undergo block operations to obtain solid and uniform colour estimation. The estimation identifies the color and further analysis is carried out for complex textures. The block obtained by that outcome is incorporated with the images under study and their respective description is provided for the user. Image enhancement can be achieved through histogram equalization. The methodology adopted proves reliable and effective solution. The pattern can be defined using parameters likes variance, histogram and gray level features. The existing methodology is incompetent due to lack of analysis in complex fabric patterns. The difficulty arises due to scale transforms, occlusions and light intensity. The challenge lies between preference and invariance. Therefore its important to develop a texture recognition system for complex patterns to analyse a fabric for visually challenged.
C1 [Kumar, K. Sharath] Jawaharlal Nehru Technol Univ, Hyderabad, India.
   [Bai, M. Rama] Mahatma Gandhi Inst Technol, Hyderabad, India.
C3 Jawaharlal Nehru Technological University - Hyderabad
RP Kumar, KS (corresponding author), Jawaharlal Nehru Technol Univ, Hyderabad, India.
EM sharathjohn@yahoo.com; vallapu.rama@gmail.com
RI Vallapu, Rama/AAJ-2922-2021
CR [Anonymous], LOW COST COLOUR CLOT
   [Anonymous], IJARECE
   [Anonymous], J MOD OPT
   [Anonymous], INT J ENG COMPUTER S
   [Anonymous], ENG COMPUTER SCI
   [Anonymous], CONT ENG SCI
   [Anonymous], IJSRD INT J SCI RES
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], IND EL 2005 ISIE 200
   [Anonymous], INT J ENG RES TECHNO
   BalaAnand M, 2020, INT J PARALLEL PROG, V48, P329, DOI 10.1007/s10766-018-0598-2
   FAN KC, 1994, PATTERN RECOGN LETT, V15, P1201, DOI 10.1016/0167-8655(94)90110-4
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Harper KE, 2016, ARXIV160205163
   Jain AK, 1996, PATTERN RECOGN, V29, P743, DOI 10.1016/0031-3203(95)00131-X
   Khan B, 2017, ALGORITHMS, V10, DOI 10.3390/a10040117
   Kuan-Yu Chen, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2496, DOI 10.1109/CISP.2010.5647930
   Lam SWC, 1996, INFORMATION INTELLIGENCE AND SYSTEMS, VOLS 1-4, P267
   Lukowicz, 2014, ARCHITECTURE COMPUTI, V8350, P159, DOI [10.1007/978-3-319-04891-8_14, DOI 10.1007/978-3-319-04891-8_14]
   Manian V, 2000, IEEE T IMAGE PROCESS, V9, P1693, DOI 10.1109/83.869181
   Maram B, 2019, SERV ORIENTED COMPUT, V13, P3, DOI 10.1007/s11761-018-0249-x
   Parodi P., 1999, International Journal on Document Analysis and Recognition, V2, P67, DOI 10.1007/s100320050038
   Prasanna S., 2017, ASIAN J APPL SCI TEC, V1, P62
   Savitha R., 2015, Int. J. of Recent and Innovation Trends in Computing and Communication, V3, P1030
   Su F, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/509597
   SUEN M, 1995, P IPPR C COMP VIS GR, P534
   WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4
   WASHBURN DK, 1990, T AM PHILOS SOC, V80, P1
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yang XD, 2014, IEEE T HUM-MACH SYST, V44, P234, DOI 10.1109/THMS.2014.2302814
   ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4
NR 31
TC 6
Z9 6
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10427
EP 10443
DI 10.1007/s11042-019-7421-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600037
DA 2024-07-18
ER

PT J
AU Kushwaha, N
   Pant, M
AF Kushwaha, Neetu
   Pant, Millie
TI Textual data dimensionality reduction-a deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autoencoder; Clustering; Feature extraction; Dimensionality reduction
ID INTEGRATING FEATURE-SELECTION; BPSO
AB The growth of Internet has produced a high volume of natural language textual data. Such data can be sparse and may contain uninformative features which increase the dimensions of the data. This high dimensionality in turn, decreases the efficiency of text mining tasks such as clustering. Transforming the high dimensional data into a lower dimension is an important pre-processing step before applying clustering. In this paper, dimensionality reduction method based on deep Autoencoder neural network named as DRDAE, is proposed to provide optimized and robust features for text clustering. DRDAE selects less correlated and salient feature space from the high dimensional feature space. To evaluate proposed algorithm, k-means is used to cluster text documents. The proposed method is tested on five benchmark text datasets. Simulation results demonstrate that the proposed algorithm clearly outperforms other conventional dimensionality reduction methods in the literature in terms of RI measure.
C1 [Kushwaha, Neetu; Pant, Millie] Indian Inst Technol Roorkee, Dept ASE, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Kushwaha, N (corresponding author), Indian Inst Technol Roorkee, Dept ASE, Roorkee 247667, Uttar Pradesh, India.
EM neetumits@gmail.com; millidma@gmail.com
RI KUSHWAHA, NEETU/CAH-8878-2022; PANT, Millie/C-9911-2018; KUSHWAHA,
   NEETU/CAF-2866-2022
CR Abualigah L.M., 2016, 2016 7 INT C COMPUTE, P12, DOI [DOI 10.1109/CSIT.2016.7549464, DOI 10.1109/CSIT.2016.7549456, 10.1109/CSIT.2016.7549456]
   Agarwal B., 2014, TEXT CLASSIFICATION, P701
   [Anonymous], Pattern Classification
   Arzeno NM, 2015, IEEE T PATTERN ANAL, V37, P1041, DOI 10.1109/TPAMI.2014.2359454
   Bharti KK, 2016, APPL SOFT COMPUT, V43, P20, DOI 10.1016/j.asoc.2016.01.019
   Bharti KK, 2015, EXPERT SYST APPL, V42, P3105, DOI 10.1016/j.eswa.2014.11.038
   Cai D., 2010, KDD, P333
   Chouaib H., 2008, 2008 20 INT C INDIUM, P1
   Cover TM, 1991, WILEY SERIES EXPERT
   Everitt B. S., 2011, CLUSTER ANAL, V5, P71
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Hartigan J. A., 1975, WILEY PUBLICATION AP, P1, DOI [10.1002/0471725382.scard, DOI 10.1002/0471725382.SCARD]
   Hull DA, 2013, J CHEM INF MODEL, V53, P1689, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kant S, 2018, COMPUT ELECTR ENG, V69, P598, DOI 10.1016/j.compeleceng.2017.12.001
   Koller D., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P284
   Kushwaha Neetu, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1053, DOI 10.1007/s12652-018-0941-x
   Kushwaha N, 2018, PATTERN RECOGN LETT, V115, P59, DOI 10.1016/j.patrec.2017.10.031
   Kushwaha N, 2018, FUTURE GENER COMP SY, V82, P190, DOI 10.1016/j.future.2017.12.005
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li YH, CLASSIFICATION TEXT
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu LL, 2012, ASIA-PAC INT SYM ELE, P269, DOI 10.1109/APEMC.2012.6237809
   Ludwig C, 2007, TEXT RETRIEVAL, V24, P1
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zareapoor M, 2019, MULTIMED TOOLS APPL, V78, P23831, DOI 10.1007/s11042-018-5970-0
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
NR 30
TC 5
Z9 5
U1 3
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11039
EP 11050
DI 10.1007/s11042-018-6900-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600070
DA 2024-07-18
ER

PT J
AU Li, Y
   Lu, SJ
AF Li, Yan
   Lu, ShuJian
TI RETRACTED: Research on physical education system model using multimedia
   technology (Retracted Article)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Physical education system; Multimedia technology; Smart multimedia
   environment system; Technological advancement; Theoretical mode
ID TEACHERS
AB At present scenario technology advancement in physical education is not encouraged due to conventional method of education as prevailed as common perspective in teaching. There is a huge scientific gap occur between physical education teachers and students due to traditional conceptual theoretical mode of daily practice. This article mainly focused to provide various tools and practice which has been used to improve present physical education system through technology enhanced innovative scientific approach using integrated multimedia technology in Information and Communication Technology (ICT). In the recent past deficiency in significant nutrients leads to deterioration of organs which creates various health problems, particularly for the sports men/ women which has not been identified by teachers through their traditional way of handling students. Due to the importance of physical education system, children and adolescents physical activities should be continuously monitored for eliminating difficulties in their life using smart multimedia environment system. As physical education teachers are unaware about the various multimedia technologies and its significance in physical education system, this article provides suitable knowledge about the technological advancement in physical education system which helps to learn and apply in to their teaching system. Experimental analysis has been taken on various sports person datasets based on the usage of multimedia technology and its improvement in monitoring sports person has discussed significantly in this research.
C1 [Li, Yan] Anhui Univ Technol, Dept Phys Educ, Maanshan, Peoples R China.
   [Lu, ShuJian] Anhui Univ Technol, Grad Sch, Maanshan, Peoples R China.
C3 Anhui University of Technology; Anhui University of Technology
RP Lu, SJ (corresponding author), Anhui Univ Technol, Grad Sch, Maanshan, Peoples R China.
EM lushujian@ahut.edu.cn; 756907548@qq.com
CR Aslan A, 2018, EDUC SCI-THEOR PRACT, V18, P23, DOI 10.12738/estp.2018.1.0431
   Baek Jun-Hyung, 2018, INTERNATIONAL JOURNAL OF HUMAN MOVEMENT SCIENCE, V12, P27
   Baskar S, 2019, HLTH TECHNOL, P1
   Can S, 2019, BIOMED HUM KINET, V11, P28, DOI 10.2478/bhk-2019-0004
   Carse N, 2018, EUR PHYS EDUC REV, V24, P487, DOI 10.1177/1356336X16688598
   Chau K.T., 2018, Turkish Online Journal of Educational Technology-TOJET, V17, P69
   Cheng XS, 2019, J ADV COMPUT INTELL, V23, P146, DOI 10.20965/jaciii.2019.p0146
   Da-Wei C, 2018, J INTELL FUZZY SYST, V34, P893, DOI 10.3233/JIFS-169383
   Denysova L., 2018, Journal of Physical Education and Sport, V18, P469
   Ensign J, 2018, RES Q EXERCISE SPORT, V89, P66, DOI 10.1080/02701367.2017.1408951
   Escalié G, 2019, SPORT EDUC SOC, V24, P390, DOI 10.1080/13573322.2017.1397507
   Giese M, 2018, SPORT SOC, V21, P152, DOI 10.1080/17430437.2016.1225857
   Gomathi M, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P1, DOI 10.1109/iss1.2019.8908057
   Huang C., 2019, MULTIMED TOOLS APPL, P1
   Hutzler Y, 2019, PHYS EDUC SPORT PEDA, V24, P249, DOI 10.1080/17408989.2019.1571183
   Kashuba VO, 2018, PHYS EDUC STUD, V22, P57, DOI 10.15561/20755279.2018.0201
   Kumar A.A., 2018, Multidisciplinary Higher Education, Research, Dynamics Concepts: Opportunities Challenges for Sustainable Development, V1, P76
   Lleixa T, 2019, SOCIAL INCLUSION IMM, P1
   Pattanayak S, 2019, INNOVATIONS COMPUTER
   Preeth S.S.L., 2018, J. Ambient Intell. Human. Comput., P1, DOI [10.1007/s12652-018-1154-z, DOI 10.1007/S12652-018-1154-Z]
   Ratminingsih NM, 2018, INT J EMERG TECHNOL, V13, P190, DOI 10.3991/ijet.v13i09.8170
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Shi JH, 2012, ENRGY PROCED, V17, P1897, DOI 10.1016/j.egypro.2012.02.329
   Wu D, 2019, ARXIV190610815V1, P1
   Wyant J, 2019, CURRIC STUD HEALTH P, V10, P3, DOI 10.1080/25742981.2018.1514983
   Zhu D, 2018, J ED TECHNOLOGY DEV, V11, P3
NR 26
TC 5
Z9 5
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10461
EP 10474
DI 10.1007/s11042-019-08366-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600039
DA 2024-07-18
ER

PT J
AU Tong, LJ
   Tong, RB
   Chen, L
AF Tong, Lijuan
   Tong, Ruobei
   Chen, Lin
TI Efficient retrieval algorithm for multimedia image information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia image; Retrieval; Optimization
ID PHASE RETRIEVAL; SIMULATION
AB The research on the retrieval of multimedia image data information is of great significance for increasing the retrieval rate of multimedia image information. Due to the certain similar characteristics of massive multimedia image information, the picture information features are confused. The traditional image retrieval method mainly uses the image information feature to classify and retrieve. When the picture information is disordered, it is impossible to classify the mass multimedia image information features, resulting in slow retrieval speed and low accuracy. A new high-efficiency retrieval algorithm for massive multimedia image information is proposed and optimized. Based on the theory of granular computing, an image region similarity measurement method for content retrieval is proposed. The image feature information table is transformed into an ordered matrix form. By studying the ordered matrix, the concept of image feature granules and granule granules is introduced, the importance of image features is analyzed from different granularity levels, and the order relationship between regions in the image feature information table is maintained, and the weight of the theoretical image feature is calculated based on the granularity for implementing the image region similarity measurement method. The example shows that the similarity measure method can measure the degree of similarity between image regions objectively and effectively, and provides a new idea and method for the research of granular computing theory in multimedia image content retrieval.
C1 [Tong, Lijuan] Capital Normal Univ, Sch Management, Beijing 100048, Peoples R China.
   [Tong, Ruobei] Henan Inst Sci & Technol, Xinxiang 453003, Henan, Peoples R China.
   [Chen, Lin] Beijing Language & Culture Univ, Beijing 100083, Peoples R China.
C3 Capital Normal University; Henan Institute of Science & Technology;
   Beijing Language & Culture University
RP Tong, RB (corresponding author), Henan Inst Sci & Technol, Xinxiang 453003, Henan, Peoples R China.
EM tonglijuan@cnu.edu.cn; tongruobei@hist.edu.cn; chenlin@blcu.edu.cn
CR Ahn SH, 2018, ASIA-PAC J ATMOS SCI, V54, P237, DOI 10.1007/s13143-018-0007-1
   Azadeh A, 2018, NEURAL COMPUT APPL, V2018, P1
   Bach H, 2015, INT ARCH PHOTOGRAMM, V47, P1, DOI 10.5194/isprsarchives-XL-7-W3-1-2015
   Baker NR, 2014, J AM SOC INF SCI TEC, V19, P363, DOI [10.1002/asi.5090190402, DOI 10.1002/ASI.5090190402]
   Gao HH, 2017, INT J SOFTW ENG KNOW, V27, P897, DOI 10.1142/S0218194017500334
   Han JW, 2014, IET IMAGE PROCESS, V8, P610, DOI 10.1049/iet-ipr.2013.0514
   Hong SY, 2015, MOD SIMUL ENG, V2015, DOI 10.1155/2015/651428
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P2289, DOI 10.1007/s11042-014-2129-5
   Lee YH, 2015, INTELL AUTOM SOFT CO, V21, P39, DOI 10.1080/10798587.2014.914274
   Lei CD, 2015, ACTA PHOTONICA SIN, V44, P101
   Li G, 2013, IEEE T CIRCUITS SYST, V19, P1566
   Li HS, 2014, INFORM SCIENCES, V273, P212, DOI 10.1016/j.ins.2014.03.035
   Montomoli F, 2016, IEEE J-STARS, V9, P1216, DOI 10.1109/JSTARS.2015.2417999
   Ouellette JD, 2014, IEEE T GEOSCI REMOTE, V52, P5966, DOI 10.1109/TGRS.2013.2294133
   Qian PJ, 2018, IEEE ACCESS, V6, P28594, DOI 10.1109/ACCESS.2018.2825352
   Sanders AFJ, 2015, ATMOS MEAS TECH, V8, P4947, DOI 10.5194/amt-8-4947-2015
   Shao YL, 2015, ADV ENG SOFTW, V90, P138, DOI 10.1016/j.advengsoft.2015.08.002
   Shechtman Y, 2014, IEEE T SIGNAL PROCES, V62, P928, DOI 10.1109/TSP.2013.2297687
   Silva SFD, 2014, J BRAZ COMPUT SOC, V20, P1, DOI [10.1186/1678-4804-20-1, DOI 10.1186/1678-4804-20-1]
   Thilagavathi Shanmugasundaram, 2015, ScientificWorldJournal, V2015, P395256, DOI 10.1155/2015/395256
   Wang FS, 2015, DIGIT SIGNAL PROCESS, V46, P133, DOI 10.1016/j.dsp.2015.07.010
   Wang YQ, 2013, SCI CHINA EARTH SCI, V56, P93, DOI 10.1007/s11430-012-4501-5
   Xia K, 2018, 27 IEEE INT C ROB HU
   Xia KJ, 2018, J MED IMAG HEALTH IN, V8, P1342, DOI 10.1166/jmihi.2018.2472
   Xia L, 2014, SENSORS-BASEL, V14, P21385, DOI 10.3390/s141121385
   Yue L, 2017, IOP CONF SER-MAT SCI, V215, DOI 10.1088/1757-899X/215/1/012002
   Zhao TY, 2015, OPT LASER ENG, V72, P12, DOI 10.1016/j.optlaseng.2015.03.024
   Zheng D, 2018, WORLD J UROL, V2, P1, DOI DOI 10.1109/TGRS.2018.2830100
NR 28
TC 2
Z9 2
U1 6
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9469
EP 9487
DI 10.1007/s11042-019-07886-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600063
DA 2024-07-18
ER

PT J
AU Li, YX
   Pan, ZB
   Du, D
   Li, R
AF Li, Yuxin
   Pan, Zhibin
   Du, Dong
   Li, Rui
TI Adaptive thresholding HOSVD with rearrangement of tensors for image
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Sparse representation; Higher-order singular value
   decomposition; Group sparsity
ID SPARSE REPRESENTATION; SENSING RECOVERY; RESTORATION; TRANSFORM;
   REGULARIZATION; ALGORITHM
AB Image denoising is a widely used approach in the field of image processing, which restores image more accurately. In particular, higher-order singular value decomposition (HOSVD) algorithm is a prominent algorithm for image denoising. However, traditional HOSVD transform utilizes the fixed threshold to truncate the small transform coefficients under the condition of a given tensor. Thus, some intrinsic properties of the tensor are ignored. In this paper, we propose an adaptive thresholding HOSVD with rearrangement of tensors, called ATH-HOSVD. First, the tensor-based HOSVD transform is employed to exploit the nonlocal tensor property. Second, we consider the spatial distribution of elements in the core tensors and adopt the indices of transform coefficients to produce adaptive threshold. Finally, in order to improve the sparsity of tensors, a rearrangement of tensors based on the amplitude sorting and Hilbert space-filling curve is integrated into the scheme of adaptive thresholding HOSVD. Various experiments on natural images are reported to not only demonstrate the effectiveness of the proposed ATH-HOSVD method, but also show its competitive speed.
C1 [Li, Yuxin; Pan, Zhibin; Du, Dong; Li, Rui] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Li, Jiaai/JCO-0168-2023; Li, yuxin/GSD-1668-2022; Pan,
   Zhibin/I-8212-2012; li, Yu/HCI-9086-2022; Tang, Wei/IZQ-1283-2023
FU National Science Foundation of China [U1903213]; Science and Technology
   Program of Xi'an Municipality [GXYD11.1]; Zhejiang Provincial National
   Science Foundation of China [LQY19F010001]
FX This work is supported in part by the National Science Foundation of
   China (Grant No. U1903213), the Science and Technology Program of Xi'an
   Municipality (Grant No. GXYD11.1) and the Zhejiang Provincial National
   Science Foundation of China (Grant No. LQY19F010001).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Azzari L, 2016, IEEE SIGNAL PROC LET, V23, P1086, DOI 10.1109/LSP.2016.2580600
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chambolle A, 2004, ALGORITHM TOTAL VARI
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Cristovao C, 2018, IEEE SIGNAL PROCES L, P1
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Donoho DL, 1992, IEEE T INF THEORY
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elmoataz A, 2008, NONLOCAL DISCRETE RE
   Eslahi N, 2016, IEEE T IMAGE PROCESS, V25, P3126, DOI 10.1109/TIP.2016.2562563
   Feng L, 2016, NEUROCOMPUTING, V216, P45, DOI 10.1016/j.neucom.2016.07.012
   Fu Y, 2016, NEUROCOMPUTING, V195, P30, DOI 10.1016/j.neucom.2015.09.125
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   He N, 2016, MULTIMED TOOLS APPL, V75, P2579, DOI 10.1007/s11042-015-2471-2
   Lai ZY, 2016, MED IMAGE ANAL, V27, P93, DOI 10.1016/j.media.2015.05.012
   Liu HF, 2015, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2015.7298646
   Liu S, 2017, NEUROCOMPUTING, V272
   Luisier F, 2011, IMAGE DENOISING MIXE
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   Peng Y, 2014, PROC CVPR IEEE, P2949, DOI 10.1109/CVPR.2014.377
   Pérez-Demydenko C, 2014, APPL MATH COMPUT, V234, P531, DOI 10.1016/j.amc.2013.12.193
   Peyré G, 2008, MULTISCALE MODEL SIM, V7, P703, DOI 10.1137/07068881X
   Rajwade A, 2013, IEEE T PATTERN ANAL, V35, P849, DOI 10.1109/TPAMI.2012.140
   Remenyi N, 2014, IEEE T IMAGE PROCESS, V23, P5165, DOI 10.1109/TIP.2014.2362058
   Rezghi M, 2017, IEEE T IMAGE PROCESS, P1
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   vHu H, 2015, COMPUTER SCI, V50
   Wang Q, 2017, IEEE T VEH TECHNOL, V66, P8001, DOI 10.1109/TVT.2017.2685526
   Wang X., 2018, COMPUT VIS PATT RECO
   Xiang F, 2012, IEEE INT C AUTOMAT L, P592, DOI 10.1109/ICAL.2012.6308147
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhang J, 2012, IEEE DATA COMPR CONF, P287, DOI 10.1109/DCC.2012.71
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 49
TC 6
Z9 6
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19575
EP 19593
DI 10.1007/s11042-020-08624-z
EA MAR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000521917400001
DA 2024-07-18
ER

PT J
AU Seema, B
   Yao, NM
   Carie, A
   Shah, SBH
AF Seema, Begum
   Yao, Nianmin
   Carie, Anil
   Shah, Syed Bilal Hussain
TI Efficient data transfer in clustered IoT network with cooperative member
   nodes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network; Clustering; IoT; Node cooperation
ID SENSOR NETWORKS; ENERGY; PROTOCOL; DESIGN; MIMO
AB Wireless Sensor Network (WSN) is composed of numerous tiny smart sensors nodes integrated with Internet of Things (IoT) play a crucial role in many applications. The IoT connects physical devices to form a network which consist of software, sensor for exchange of information. Clustering is most common technique for efficient energy utilization in WNS. Sensor nodes when they have data, forwards it to Cluster Head (CH) and CH transfers the received data from the sensor nodes to the sink. When the sink nodes are far away from CH, long-haul transmission consumes higher power. In this paper we propose efficient data transfer mechanism for clustered IoT network through the cooperation of member nodes. First, we use greedy algorithm to select cooperative sensor nodes to act as relay for long distance transmission. Then, to encourage sensor nodes in data forwarding, cluster head uses priority buffers to prioritize assisting sensor nodes data. Simulation results show that, the proposed approach conserves energy and increases the life-time of clustered IoT network.
C1 [Seema, Begum; Yao, Nianmin] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
   [Carie, Anil; Shah, Syed Bilal Hussain] Dalian Univ Technol, Sch Software, Dalian, Peoples R China.
   [Carie, Anil] VIT AP, Sch Comp Sci, Amaravati, India.
C3 Dalian University of Technology; Dalian University of Technology; VIT-AP
   University
RP Seema, B (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
EM seemabilal@yahoo.com; lucos@dlut.edu.cn; carieanil@gmail.com;
   bilalshah@mail.dlut.edu.cn
RI Carie, Anil/AFI-7850-2022; Shah, Syed Bilal Hussain/AAT-2520-2021; Yao,
   Nianmin/JUV-4189-2023
OI Shah, Syed Bilal Hussain/0000-0003-3340-1161; Yao,
   Nianmin/0000-0001-9705-6649
CR Akyildiz IF, 2002, COMPUT NETW, V38, P393, DOI 10.1016/S1389-1286(01)00302-4
   Allirani A, 2009, IEEE INT C ADV COMP
   Booch G., 2007, Object-Oriented Analysis and Design with Applications, Vthird
   Boyinbode O, 2010, IEEE 13 INT C NETW B
   Chong CY, 2003, P IEEE, V91, P1247, DOI 10.1109/JPROC.2003.814918
   Cui SG, 2004, IEEE J SEL AREA COMM, V22, P1089, DOI 10.1109/JSAC.2004.830916
   del Coso A, 2007, IEEE J SEL AREA COMM, V25, P402, DOI 10.1109/JSAC.2007.070215
   Fadel E, 2017, COMPUT COMMUN, V101, P106, DOI 10.1016/j.comcom.2016.12.020
   Faheem M, 2018, COMPUT SCI REV, V30, P1, DOI 10.1016/j.cosrev.2018.08.001
   Faheem M, 2015, J NETW COMPUT APPL, V58, P309, DOI 10.1016/j.jnca.2015.08.002
   Ghosh S, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Heinzelman WB, 2002, IEEE T WIREL COMMUN, V1, P660, DOI 10.1109/TWC.2002.804190
   Hoang DC, 2010, PROC IEEE INT SYMP, P3477, DOI 10.1109/ISIE.2010.5637779
   Jin Y, 2010, IEEE WIR COMM NETW C
   Lee JS, 2016, IEEE INTERNET THINGS, V3, P951, DOI 10.1109/JIOT.2016.2530682
   Pollock KH, 2002, ENVIRONMETRICS, V13, P105, DOI 10.1002/env.514
   Römer K, 2004, IEEE WIREL COMMUN, V11, P54, DOI 10.1109/MWC.2004.1368897
   Ruiz-Garcia L, 2009, SENSORS-BASEL, V9, P4728, DOI 10.3390/s90604728
   Shah J, 2016, PROC TECH, V23, P256, DOI 10.1016/j.protcy.2016.03.025
   Shah Syed Bilal Hussain, 2017, CIT. Journal of Computing and Information Technology, V25, P1, DOI 10.20532/cit.2017.1003259
   Shah SBH, 2017, PEER TO PEER NETW AP
   Shah SB, 2018, SUSTAIN CITIES SOC, V39, P298, DOI 10.1016/j.scs.2018.02.022
   Shah SB, 2018, FUTURE GENER COMP SY, V81, P372, DOI 10.1016/j.future.2017.09.043
   Nguyen TL, 2017, COMPLEXITY, P1, DOI [10.1155/2017/3083745, 10.1109/CLEOE-EQEC.2017.8086935]
   Xu LN, 2017, IEEE INTERNET THINGS, V4, P1229, DOI 10.1109/JIOT.2017.2726014
   Yetgin H, 2017, IEEE COMMUN SURV TUT, V19, P828, DOI 10.1109/COMST.2017.2650979
   Zhang X, 2010, IEEE 16 INT C PAR DI
   Zhou Z, 2008, IEEE T WIREL COMMUN, V7, P3066, DOI 10.1109/TWC.2008.061097
NR 28
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34241
EP 34251
DI 10.1007/s11042-020-08775-z
EA MAR 2020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000562592900002
DA 2024-07-18
ER

PT J
AU Karabulut, D
   Tertychnyi, P
   Arslan, HS
   Ozcinar, C
   Nasrollahi, K
   Valls, J
   Vilaseca, J
   Moeslund, TB
   Anbarjafari, G
AF Karabulut, Dogus
   Tertychnyi, Pavlo
   Arslan, Hasan Sait
   Ozcinar, Cagri
   Nasrollahi, Kamal
   Valls, Joan
   Vilaseca, Joan
   Moeslund, Thomas B.
   Anbarjafari, Gholamreza
TI Cycle-consistent generative adversarial neural networks based low
   quality fingerprint enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cycle-consistent adversarial neural network; Low quality fingerprint;
   Fingerprint quality enhancement; Biometric
ID RECOGNITION SYSTEM; VERIFICATION; ALGORITHM
AB Distortions such as dryness, wetness, blurriness, physical damages and presence of dots in fingerprints are a detriment to a good analysis of them. Even though fingerprint image enhancement is possible through physical solutions such as removing excess grace on the fingerprint or recapturing the fingerprint after some time, these solutions are usually not user-friendly and time consuming. In some cases, the enhancements may not be possible if the cause of the distortion is permanent. In this paper, we are proposing an unpaired image-to-image translation using cycle-consistent adversarial networks for translating images from distorted domain to undistorted domain, namely, dry to not-dry, wet to not-wet, dotted to not-dotted, damaged to not-damaged, blurred to not-blurred. We use a database of low quality fingerprint images containing 11541 samples with dryness, wetness, blurriness, damages and dotted distortions. The database has been prepared by real data from VISA application centres and have been provided for this research by GEYCE Biometrics. For the evaluation of the proposed enhancement technique, we use VGG16 based convolutional neural network to assess the percentage of enhanced fingerprint images which are labelled correctly as undistorted. The proposed quality enhancement technique has achieved the maximum quality improvement for wetness fingerprints in which 94% of the enhanced wet fingerprints were detected as undistorted.
C1 [Karabulut, Dogus; Arslan, Hasan Sait; Ozcinar, Cagri; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Tertychnyi, Pavlo] Univ Tartu, Inst Comp Sci, Tartu, Estonia.
   [Ozcinar, Cagri] Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin 2, Ireland.
   [Nasrollahi, Kamal; Moeslund, Thomas B.] Aalborg Univ, Visual Anal People Lab, Aalborg, Denmark.
   [Nasrollahi, Kamal] Res Dept Milestone Syst, Copenhagen, Denmark.
   [Valls, Joan; Vilaseca, Joan] GEYCE Biometr, Barcelona, Spain.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
C3 University of Tartu; University of Tartu; Trinity College Dublin;
   Aalborg University; Hasan Kalyoncu University
RP Karabulut, D (corresponding author), Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
EM dogus@icv.tuit.ut.ee; Pavlo.Tertychnyi@ut.ee; hasan@icv.tuit.ut.ee;
   ozcinarc@scss.tcd.ie; kn@create.aau.dk; tbm@create.aau.dk;
   shb@icv.tuit.ut.ee
RI Anbarjafari, Gholamreza/A-3845-2010
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Moeslund, Thomas
   B./0000-0001-7584-5209
FU COST Action [CA16101]; Scientific and Technological Research Council of
   Turkey (TUBITAK) 1001 Project [116E097]; Estonian Centre of Excellence
   in IT (EXCITE) - European Regional Development Fund; NVIDIA Corporation
FX This work has been partially supported by the COSTAction CA16101
   Multi-modal Imaging of Forensic Science Evidence -tools for Forensic
   Science, the Scientific and Technological Research Council of Turkey
   (TUBITAK) 1001 Project (116E097), and the Estonian Centre of Excellence
   in IT (EXCITE) funded by the European Regional Development Fund. The
   authors also gratefully acknowledge the support of NVIDIA Corporation
   with the donation of the Titan V Pascal GPU.
CR [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2011, 2011 INT JOINT C BIO
   Barman S, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT), P179, DOI 10.1109/ICIT.2014.46
   Bolotnikova A, 2017, ANALOG INTEGR CIRC S, V92, P467, DOI 10.1007/s10470-017-1006-3
   Cao Kai., 2011, IEEE International Joint Conference on Biometrics (IJCB), P1
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Cappelli R, 2010, I C CONT AUTOMAT ROB, P19, DOI 10.1109/ICARCV.2010.5707958
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Chugh T, 2017, BIOSIG 2017
   Demirel H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/482585
   Dorizzi B, 2009, LECT NOTES COMPUT SC, V5558, P725, DOI 10.1007/978-3-642-01793-3_74
   Haamer RE, 2018, IEEE INT CONF AUTOMA, P621, DOI 10.1109/FG.2018.00098
   Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He ZX, 2015, J OPT SOC AM A, V32, P1171, DOI 10.1364/JOSAA.32.001171
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Ito K., 2005, IEEE INT C IM PROC I, V2, P33
   Jahromi MNS, 2018, IEEE WINT CONF APPL, P28, DOI 10.1109/WACVW.2018.00009
   Ji LP, 2008, PATTERN RECOGN, V41, P1491, DOI 10.1016/j.patcog.2007.09.003
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litvin A, 2019, MULTIMED TOOLS APP
   Loob C, 2017, IEEE INT CONF AUTOMA, P833, DOI 10.1109/FG.2017.106
   Marasco E, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2617756
   Nandakumar K., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P216, DOI 10.1109/ICB.2012.6199811
   Nasrollahi K, 2017, FAC FAC EXPR REC AUD, V10165
   Parziale G, 2004, LECT NOTES COMPUT SC, V3072, P241
   Peralta D, 2015, INFORM SCIENCES, V315, P67, DOI 10.1016/j.ins.2015.04.013
   Radford A., 2015, ARXIV
   Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18
   Ratha N., 2003, Automatic fingerprint recognition systems
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuch P, 2017, BIOSIG 2017
   Song DH, 2019, PATTERN RECOGN, V88, P397, DOI 10.1016/j.patcog.2018.11.018
   Tertychnyi P, 2018, IET BIOMETRICS, V7, P550, DOI 10.1049/iet-bmt.2018.5074
   Tico M, 2003, IEEE T PATTERN ANAL, V25, P1009, DOI 10.1109/TPAMI.2003.1217604
   Willis AJ, 2001, PATTERN RECOGN, V34, P255, DOI 10.1016/S0031-3203(00)00003-0
   Yang JC, 2013, IEEE T HUM-MACH SYST, V43, P235, DOI 10.1109/TSMCC.2011.2174049
   Yao ZG, 2016, IET BIOMETRICS, V5, P243, DOI 10.1049/iet-bmt.2015.0027
   Zhang FD, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P397, DOI 10.1109/BTAS.2017.8272723
   Zhang N, 2016, INT C PATT RECOG, P937, DOI 10.1109/ICPR.2016.7899756
   Zhou J, 2004, IEEE T IMAGE PROCESS, V13, P821, DOI 10.1109/TIP.2003.822608
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 44
TC 8
Z9 8
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18569
EP 18589
DI 10.1007/s11042-020-08750-8
EA MAR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518345200002
DA 2024-07-18
ER

PT J
AU Rousidis, D
   Koukaras, P
   Tjortjis, C
AF Rousidis, Dimitrios
   Koukaras, Paraskevas
   Tjortjis, Christos
TI Social media prediction: a literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Social media prediction; Data prediction models; Social media data; Web
   information systems; Web tools and applications
ID TWITTER; WEB
AB Social Media Prediction (SMP) is an emerging powerful tool attracting the attention of researchers and practitioners alike. Despite its many merits, SMP has also several weaknesses, as it is limited by data issues, like bias and noise, and the lack of confident predictions and generalizable results. The goal of this paper is to survey popular and trending fields of SMP from 2015 and onwards and discuss the predictive models used. We elaborate on results found in the literature, while categorizing the forecasting attempts, based on specific values (source of data, algorithm used, outcome of prediction etc.). Finally, we present our findings and conduct statistical analysis on our dataset and critique the outcome of the attempted prediction reported by the reviewed papers. Our research indicates that results are ambiguous, as not all forecasting models can predict with high accuracy, and prediction seems dependable on the associated field, although some of the documented attempts are promising. More than half (53.1%) of the examined attempts achieved a valid prediction, nearly one fifth (18.8%) did not, while the remaining 28.1% is characterized as plausible or partially validated. By reviewing recent and up-to-date literature and by providing statistics, this paper provides SMP researchers with a guide on methods, algorithms, techniques, prediction success and challenges on three main categories that aid SMP exploration.
C1 [Rousidis, Dimitrios; Koukaras, Paraskevas; Tjortjis, Christos] Int Hellen Univ, Sch Sci & Technol, 14th Km Thessaloniki Moudania, GR-57001 Thermi, Greece.
RP Tjortjis, C (corresponding author), Int Hellen Univ, Sch Sci & Technol, 14th Km Thessaloniki Moudania, GR-57001 Thermi, Greece.
EM d.rousidis@ihu.edu.gr; p.koukaras@ihu.edu.gr; c.tjortjis@ihu.edu.gr
RI Tjortjis, Christos/I-4112-2017; Tjortjis, Christos/P-3009-2019
OI Tjortjis, Christos/0000-0001-8263-9024; Koukaras,
   Paraskevas/0000-0002-1183-9878
CR Abbasi OR, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6050136
   Abdulahi A., 2014, INT J BUSINESS SOCIA, V5, P133
   Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   [Anonymous], 2012, ARXIV12031647
   [Anonymous], 2012, ARXIV12046441
   [Anonymous], 2010, ICIS
   Aquino F, 2017, VACCINE, V35, P4494, DOI 10.1016/j.vaccine.2017.07.029
   Asur S., 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P492, DOI 10.1109/WI-IAT.2010.63
   Baghel N., 2018, ARXIV181200399
   Barakos M., 2015, 5 IBA BACHELOR THESI
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Burnap P, 2016, ELECT STUD, V41, P230, DOI 10.1016/j.electstud.2015.11.017
   Cai YL, 2018, IEEE INT C INT ROBOT, P250, DOI 10.1109/ICRIS.2018.00071
   Cameron MP, 2016, J POLITICAL MARKETIN, V15, P416, DOI 10.1080/15377857.2014.959690
   Candan KS, 2010, DATA MANAGEMENT MULT, P14
   Chaffey D., 2016, GLOBAL SOCIAL MEDIA
   Chen JY, 2017, INFORM SYST, V64, P281, DOI 10.1016/j.is.2016.03.011
   Chen JP, 2019, MULTIMED TOOLS APPL, V78, P2667, DOI 10.1007/s11042-018-5745-7
   Cioffi-Revilla C, 2017, TEXTS COMPUT SCI, P35, DOI 10.1007/978-3-319-50131-4_2
   Cranshaw J., 2012, The Livehoods Project: Utilizing Social Media to Understand the Dynamics of a City
   De Choudhury M, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1157, DOI 10.1145/2818048.2819956
   Dong W., 2016, Leading Effect of Social Media for Financial Fraud Disclosure: A Text Mining Based Analytics
   Doub AE, 2016, APPETITE, V99, P298, DOI 10.1016/j.appet.2016.01.003
   Dredze M, 2016, AM J PREV MED, V50, P550, DOI 10.1016/j.amepre.2015.10.002
   Elshendy M, 2018, J INF SCI, V44, P408, DOI 10.1177/0165551517698298
   ElTayeby O, 2019, HEALTH INFORM J, V25, P1756, DOI 10.1177/1460458218798084
   Felix R, 2017, J BUS RES, V70, P118, DOI 10.1016/j.jbusres.2016.05.001
   Finch KC, 2016, NAT HAZARDS, V83, P729, DOI 10.1007/s11069-016-2327-8
   Gao YF, 2019, AAAI CONF ARTIF INTE, P6415
   Garikar DD, 2015, IND MANAGE DATA SYST, V115, P1604, DOI 10.1108/IMDS-04-2015-0145
   de Zúñiga HG, 2017, SOC SCI COMPUT REV, V35, P3, DOI 10.1177/0894439315619589
   Goswami S, 2018, AIN SHAMS ENG J, V9, P365, DOI 10.1016/j.asej.2016.01.012
   Gruner RL, 2018, J PROD INNOV MANAG
   Guedes Eduardo, 2016, MedicalExpress (São Paulo, online), V3, pM160101
   Guidi M, 2017, THESIS
   Gundecha Pritam., 2012, 2012 TUTORIALS OPERA, P1, DOI [10.1287/educ.1120.0105, DOI 10.1287/EDUC.1120.0105]
   Han J., 2011, DATA MINING CONCEPTS, P32
   He W, 2015, IND MANAGE DATA SYST, V115, P1622, DOI 10.1108/IMDS-03-2015-0098
   Hristidis V, 2010, J SYST SOFTWARE, V83, P1701, DOI 10.1016/j.jss.2010.04.065
   Hudson S, 2016, INT J RES MARK, V33, P27, DOI 10.1016/j.ijresmar.2015.06.004
   HUH JH, 2014, J MULTIMEDIA INF SYS, V1, P133
   Huh JH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040093
   Isotalo V., 2016, DESIGNING NETWORKS I, DOI [10.1007/978-3-319-42697-6_5, DOI 10.1007/978-3-319-42697-6_5]
   Jin F, 2017, LECT NOTES ARTIF INT, V10357, P16, DOI 10.1007/978-3-319-62701-4_2
   Kalmer N.P, 2015, PREDICTIVE POWER SOC
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Karami A., 2018, ARXIV180201786
   Karppi T, 2016, THEOR CULT SOC, V33, P73, DOI 10.1177/0263276415583139
   Kim D, 2014, QUAL QUANT, V48, P2605, DOI 10.1007/s11135-013-9910-9
   Kim J, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.126
   Kim WG, 2016, INT J HOSP MANAG, V55, P41, DOI 10.1016/j.ijhm.2016.03.001
   Koukaras P., 2019, COMPUTING, P1
   Kryvasheyeu Y, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1500779
   Lassen N., 2016, The SAGE Handbook of social media research methods, P328, DOI DOI 10.4135/9781473983847
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin ZP, 2016, TUMOR BIOL, V37, P16305, DOI 10.1007/s13277-016-5424-0
   Matta M, 2015, UMAP WORKSH, P1
   McClellan C, 2017, J AM MED INFORM ASSN, V24, P496, DOI 10.1093/jamia/ocw133
   McDonald R., 2015, FORECASTING 2015 GEN
   McGee J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P459, DOI 10.1145/2505515.2505544
   Nardo M, 2016, J ECON SURV, V30, P356, DOI 10.1111/joes.12102
   Ni M, 2017, IEEE T INTELL TRANSP, V18, P1623, DOI 10.1109/TITS.2016.2611644
   Oikonomou L., 2018, 2018 S E EUR DES AUT, P1, DOI [10.23919/SEEDA-CECNSM.2018.8544919, DOI 10.23919/SEEDA-CECNSM.2018.8544919]
   Ong YX, 2019, INFORMATION AND COMMUNICATION TECHNOLOGIES IN TOURISM 2019, P132, DOI 10.1007/978-3-030-05940-8_11
   Pagolu Venkata Sasank, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P1345, DOI 10.1109/SCOPES.2016.7955659
   Pekar Viktor, 2017, P 8 WORKSH COMP APPR, P92
   Petz Gerald, 2013, Human-Computer Interaction and Knowledge Discovery in Complex, Unstructured, Big Data. Third International Workshop, HCI-KDD 2013. Held at SouthCHI 2013. Proceedings: LNCS 7947, P35, DOI 10.1007/978-3-642-39146-0_4
   Petz Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P618, DOI 10.1007/978-3-642-35236-2_62
   Petz G, 2015, INFORM PROCESS MANAG, V51, P510, DOI 10.1016/j.ipm.2014.07.011
   Pew Research Center September, 2012, OB ROMN MATCH
   Phillips L., 2017, ARXIV170606134
   Radzikowski Jacek, 2016, JMIR Public Health Surveill, V2, pe1, DOI 10.2196/publichealth.5059
   Ricard BJ, 2018, J MED INTERNET RES, V20, DOI 10.2196/11817
   Rossi C, 2018, INT J DISAST RISK RE, V30, P145, DOI 10.1016/j.ijdrr.2018.03.002
   Ruizendaal R, 2016, THESIS
   Sadilek A, 2016, AAAI CONF ARTIF INTE, P3982
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Santillana M, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004513
   Schade L, 2015, THESIS
   Schoen H, 2013, INTERNET RES, V23, P528, DOI 10.1108/IntR-06-2013-0115
   Seabrook EM, 2016, JMIR MENT HEALTH, V3, DOI 10.2196/mental.5842
   Shelton T, 2015, LANDSCAPE URBAN PLAN, V142, P198, DOI 10.1016/j.landurbplan.2015.02.020
   Siddiqui S., 2016, International Journal of Computer Applications Technology and Research, V5, P71, DOI DOI 10.7753/IJCATR0502.1006
   Steinert L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208119
   Subramani S, 2018, LECT NOTES COMPUT SC, V11148, P134, DOI 10.1007/978-3-030-01078-2_12
   Sun A, 2016, INT REV FINANC ANAL, V48, P272, DOI 10.1016/j.irfa.2016.10.009
   Sun Yizhou, 2012, Synthesis Lectures on Data Mining and Knowledge Discovery, V3, P1
   Sunstein CassR., 2018, # Republic: Divided democracy in the age of social media
   Tang JL, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P87, DOI 10.1145/2684822.2685295
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Nguyen TH, 2015, EXPERT SYST APPL, V42, P9603, DOI 10.1016/j.eswa.2015.07.052
   Tomeny TS, 2017, SOC SCI MED, V191, P168, DOI 10.1016/j.socscimed.2017.08.041
   Tsihrintzis GA, 2019, INTEL SYST REF LIBR, V149, P1, DOI 10.1007/978-3-319-94030-4_1
   Vanden Abeele V.A., 2006, CHI 06 EXTENDED ABST, P1469
   Vijayaraghavan R, 2016, U.S. Patent, Patent No. [9,519,936, 9519936]
   Xiaofeng Wang, 2012, Social Computing, Behavioral-Cultural Modeling and Prediction. Proceedings of the 5th International Conference, SBP 2012, P231, DOI 10.1007/978-3-642-29047-3_28
   Yang Y, 2016, ENVIRON RES, V148, P582, DOI 10.1016/j.envres.2015.12.024
   Zafarani R, 2014, SOCIAL MEDIA MINING, P7
   Zamani M., 2017, P 15 C EUROPEAN CHAP, V2, P28, DOI [DOI 10.18653/V1/E17-2005, https://doi.org/10.18653/v1/E17-2005]
   Zhan YC, 2019, J AM MED INFORM ASSN, V26, P9, DOI 10.1093/jamia/ocy140
NR 102
TC 33
Z9 35
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6279
EP 6311
DI 10.1007/s11042-019-08291-9
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900038
DA 2024-07-18
ER

PT J
AU Zaghloul, R
   Hiary, H
   Al-Zoubi, MB
AF Zaghloul, Rawan
   Hiary, Hazem
   Al-Zoubi, Moh'd Belal
TI A multifractal edge detector
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractals; Multifractal analysis; Edge detection; Multiscale filters;
   Frequency domain
ID FRACTAL DIMENSION
AB Significant research has been conducted into image edge detection, usually focusing on gradient and higher order derivative approaches. Recent development in the field suggests the incorporation of scale factor in filter design; this is to increase robustness against noise and to facilitate the process of generating multilevel edge maps. While multifractal analysis technique uses scale factors, few researchers examine the effectiveness of this technique in image edge map generation due to its poor efficiency. Herein, we propose F-MED, a fast multifractal edge detector for grayscale images based on generating an edge map from different low frequency versions of the original image by means of frequency domain Gaussian low pass filters. The quality of results is evaluated subjectively via visual assessment and quantitatively using a set of full-reference and non-reference measures. Results show that the proposed F-MED can be leveraged to support not only high efficiency, but also quality improvement and high robustness against blurring effect and Rayleigh noise.
C1 [Zaghloul, Rawan; Hiary, Hazem; Al-Zoubi, Moh'd Belal] Univ Jordan, Amman 11942, Jordan.
C3 University of Jordan
RP Hiary, H (corresponding author), Univ Jordan, Amman 11942, Jordan.
EM hazemh@ju.edu.jo
RI Zaghloul, Rawan/AAH-1866-2019; Hiary, Hazem/C-8358-2015
OI Zaghloul, Rawan/0000-0002-4793-6717; Hiary, Hazem/0000-0002-0306-5294
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Augustin W, 2008, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '07, P547, DOI 10.1007/978-3-540-74739-0_37
   Bornstein MM, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020202
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CREUTZBURG R, 1989, LECT NOTES COMPUT SC, V399, P42
   Crisan DA, 2006, UNIV POLIT BUCHAR S, V68, P35
   Deng KX, 2019, MEASUREMENT, V133, P77, DOI 10.1016/j.measurement.2018.10.004
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Duda R., 1973, Pattern Classification and Scene Analysis
   Falconer K.J., 1997, TECHNIQUES FRACTAL G
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Florindo JB, 2011, CHAOS SOLITON FRACT, V44, P851, DOI 10.1016/j.chaos.2011.07.008
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   Haykin S., 2004, MODERN WIRELESS COMM
   Hiary H, 2017, SIGNAL IMAGE VIDEO P, V11, P833, DOI 10.1007/s11760-016-1029-8
   Hripcsak G, 2005, J AM MED INFORM ASSN, V12, P296, DOI 10.1197/jamia.M1733
   Lei T, 2014, IET IMAGE PROCESS, V8, P44, DOI 10.1049/iet-ipr.2013.0062
   Levy-Vehel J., 1998, Fractal Image Encoding and Analysis, V159, P299
   Li J, 2006, IEEE IMAGE PROC, P3029, DOI 10.1109/ICIP.2006.313005
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Liu GQ, 2010, J COMPUT SYST SCI, V76, P63, DOI 10.1016/j.jcss.2009.05.006
   Mandelbrot B. B., 1983, The fractal geometry of nature
   Many G, 2019, ESTUAR COAST SHELF S, V219, P1, DOI 10.1016/j.ecss.2019.01.017
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Morgan F., 2009, GEOMETRIC MEASURE TH
   Paskas M., 2011, TELSIKS 2011 - 2011 10th International Conference on Telecommunication in Modern Satellite, Cable and Broadcasting Services, P329, DOI 10.1109/TELSKS.2011.6112063
   Paskas M, 2013, INT CONF SYST SIGNAL, P87, DOI 10.1109/IWSSIP.2013.6623456
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rafajlowicz E, 2007, 2007 INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL SYSTEMS, P69, DOI 10.1109/NDS.2007.4509548
   Rüfenacht D, 2014, IEEE T PATTERN ANAL, V36, P1672, DOI 10.1109/TPAMI.2013.229
   SARKAR N, 1995, SIGNAL PROCESS, V42, P181, DOI 10.1016/0165-1684(94)00126-K
   SARKAR N, 1992, PATTERN RECOGN, V25, P1035, DOI 10.1016/0031-3203(92)90066-R
   Scafetta N, 2003, PHYSICA A, V328, P561, DOI 10.1016/S0378-4371(03)00527-2
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sobel I., 1968, STANF ART PROJ, P271
   Sonka M., 2014, Image processing, analysis, and machine vision
   Uemura K, 2000, COMPUT MED IMAG GRAP, V24, P73, DOI 10.1016/S0895-6111(99)00045-2
   Véhel JL, 1994, FRACTALS, V2, P371, DOI 10.1142/S0218348X94000466
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Zhang BL, 2010, INT CONF BIOMED, P419, DOI 10.1109/BMEI.2010.5639557
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
NR 45
TC 1
Z9 1
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5807
EP 5828
DI 10.1007/s11042-019-08420-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900017
DA 2024-07-18
ER

PT J
AU Asfand-e-yar, M
   Ali, R
   Ahmed, I
   Mushtaq, S
AF Asfand-e-yar, Muhammad
   Ali, Ramis
   Ahmed, Imran
   Mushtaq, Samia
TI Semantic classification of business ontology while migrating business
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Business migration ontology; Legal business migration; Semantic
   classification; Description logic; SPARQL
ID WEB; MODELS
AB An increase in business growth and revenue is the main objective of any business. There are various tactics to answer the problems i.e., about the growth of business and revenue. For example, one has also to answer for revising the company policies, motivational sessions for the employees, increment in salaries, and migration of business to a new place. The difference between a good and great business depends on the place of business. The purpose of migration is to expand the business where infrastructure cost is less, easily achieving business goals and need a comfortable market accordingly. The challenges occurs while migrating a business. Businesspersons can face various issues and problems. For example, how to identify the business challenges and know the basic legal rights to invest in a foreign country? To answer the problem, we have constructed a Business Migration Ontology (BMO) model to integrate information on the web accordingly. Therefore, three training sets used to construct the BMO. The training sets are semantically classified to find similarities and differences during the construction of BMO. The BMO facilitates the businesspersons to select an appropriate jurisdiction for migrating business, according to their requirements and possibilities. The BMO has semantically classified the legal acts defined by a jurisdiction, accordingly. The BMO facilitates to identify the required fields that have significance for businesspersons. The businesspersons can than determine to invest at a certain jurisdiction, accordingly. The BMO provides a complete view of different legal aspects according to various jurisdictions, which is helpful for businesspersons in the better decision while migrating their business.
C1 [Asfand-e-yar, Muhammad; Ali, Ramis; Mushtaq, Samia] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Ahmed, Imran] Intitute Management Sci, Ctr Excellence IT, Peshawar, Pakistan.
RP Asfand-e-yar, M (corresponding author), Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
EM m.asfandeyar@gmail.com; ramisali.buic@bahria.edu.pk;
   imran.ahmed@imsciences.edu.pk; saima@swansea.ac.uk
OI Asfand-e-yar, Muhammad/0000-0001-5695-1399
CR [Anonymous], 1983, The theory of relational databases
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Breslin JG, 2010, COMPUT IND, V61, P729, DOI 10.1016/j.compind.2010.05.002
   Dou DJ, 2015, IEEE INT C SEMANT CO, P244, DOI 10.1109/ICOSC.2015.7050814
   Effendi YA, 2017, INT CONF INFORM COMM, P209, DOI 10.1109/ICTS.2017.8265672
   Ejarque J, 2011, EUROMICRO WORKSHOP P, P47, DOI 10.1109/PDP.2011.24
   Fanesi D, 2015, 2015 INTERNATIONAL CONFERENCE ON ENTERPRISE SYSTEMS (ES), P21, DOI 10.1109/ES.2015.10
   Fauzan A, 2017, INT CONF INFORM COMM, P221, DOI 10.1109/ICTS.2017.8265674
   Feilmayr C, 2016, DATA KNOWL ENG, V101, P1, DOI 10.1016/j.datak.2015.11.003
   Filipowska A, 2009, LECT NOTES BUS INF P, V21, P1
   Ghawi R, 2007, 3 INT WORKSH DAT INT, V91
   Gürbüz Ö, 2017, CONF BUS INFORM, V1, P320, DOI 10.1109/CBI.2017.22
   Hazber M.A., 2016, Appl. Math, V10, P1
   Hoang HH, 2014, ENTERP INF SYST-UK, V8, P648, DOI 10.1080/17517575.2013.767382
   Khorrami F., 2003, POWER SYST
   Ling H., 2013, INT J ENG TECHNOLOGY, V5, P4735
   Martin D, 2005, LECT NOTES COMPUT SC, V3387, P26
   Masse PA, 2016, COLLOQ INF SCI TECH, P216, DOI 10.1109/CIST.2016.7805045
   Milo Tova., 1998, VLDB, V98, P24
   Noy NF, 2001, IEEE INTELL SYST APP, V16, P60, DOI 10.1109/5254.920601
   Persson C, 2017, IEEE INT CON AUTO SC, P864, DOI 10.1109/COASE.2017.8256212
   Samavi R, 2009, INF SYST E-BUS MANAG, V7, P171, DOI 10.1007/s10257-008-0079-z
   Vasilecas O, 2006, INT C COMP SYST TECH, V6
   Veres C, 2010, SPRINGER SER OPTIM A, V41, P21, DOI 10.1007/978-1-4419-1636-5_2
   Wang ZX, 2014, APPL MATH INFORM SCI, V8, P255
   Yu E., 2006, PROCEDINGS 10 IEEE I, P32
   Zhao Q, 2008, FOURTH INTERNATIONAL CONFERENCE ON AUTONOMIC AND AUTONOMOUS SYSTEMS (ICAS 2008), P204, DOI 10.1109/ICAS.2008.12
NR 27
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17903
EP 17921
DI 10.1007/s11042-020-08770-4
EA FEB 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516511300002
DA 2024-07-18
ER

PT J
AU Chaharlang, J
   Mosleh, M
   Rasouli-Heikalabad, S
AF Chaharlang, Javad
   Mosleh, Mohammad
   Rasouli-Heikalabad, Saeed
TI A novel quantum steganography-Steganalysis system for audio signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nano communication; Quantum computing; Quantum circuits; Quantum audio
   steganography; Quantum audio steganalysis
ID HIGH-CAPACITY; ALGORITHM; REPRESENTATION; DECOMPOSITION; TRANSPARENT;
   ENCRYPTION; TRANSFORM; SECURE
AB As a substitute for classical solutions, quantum information hiding techniques have become an essential issue in the field of quantum communications by utilizing the inherent features of quantum mechanics and creating more secured communications for the more reliable exchange of digital media within the context of quantum communications networks. Quantum steganography has been considered as one of these approaches in recent years, but the importance of investigating and discovering these hidden communications within the context of quantum communication networks that require the use of quantum steganalysis methods has not been addressed so far. Therefore, in this paper, a novel quantum steganography-steganalysis system for digital audio signals is proposed, which can accurately detect audio steganography methods in the context of quantum communication networks. The proposed model consists of two separate sections: steganography and steganalysis; in the steganography part, to minimize the impacts of the embedding process and increasing the Signal to Noise Ratio (SNR), the embedding operation is carried out within the Least Significant Fractional Qubit (LSFQ) of the amplitude information of the audio signal samples. Then, a universal steganalyzer in the steganalysis part distinguishes the stego audio signals using the extracted statistical features from the audio signals. The universal steganalyzer consists of a mean feature extraction module to extract features from the audio signal frames and the quantum circuits for implementing the K-Nearest Neighbor (KNN) algorithm and the Hamming distance criterion. The simulation-based quantum circuits of the proposed system tested and evaluated using different audio files. Over 80% accuracy in detecting stego audio signals indicates high accuracy and efficiency of the proposed scheme and its applicability in quantum communication networks. Along with the higher efficiency and security of quantum steganography methods when compared with the classical one, the results show that the proposed quantum steganography-steganalysis scheme is also capable of competing with classical methods in terms of accurately detecting steganography methods.
C1 [Chaharlang, Javad; Mosleh, Mohammad] Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
   [Rasouli-Heikalabad, Saeed] Islamic Azad Univ, Tabriz Branch, Dept Comp Engn, Tabriz, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Mosleh, M (corresponding author), Islamic Azad Univ, Dezful Branch, Dept Comp Engn, Dezful, Iran.
EM Mosleh@iaud.ac.ir
OI Rasouli Heikalabad, Saeed/0000-0001-9926-5153; Mosleh,
   Mohammad/0000-0002-0991-1623
CR Aïmeur E, 2013, MACH LEARN, V90, P261, DOI 10.1007/s10994-012-5316-5
   Ali AH, 2018, MULTIMED TOOLS APPL, V77, P31487, DOI 10.1007/s11042-018-6213-0
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   [Anonymous], The Prisoners' Problem and the Subliminal Channel, DOI 10.1007/978-1-4684-4730-95
   [Anonymous], 1993, DIGITAL IMAGE COMPUT
   [Anonymous], 2019, MULTIMED TOOLS APPL
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bailey K, 2004, IMAGING SCI J, V52, P131, DOI 10.1179/136821904225020249
   Biamonte J, 2017, NATURE, V549, P195, DOI 10.1038/nature23474
   Bohme R., 2010, Advanced Statistical Steganalysis
   CHANDRAMOULI R, 2003, IWDW, P35
   Chen KH, 2018, CHIN CONTR CONF, P3180, DOI 10.23919/ChiCC.2018.8483507
   Chen KH, 2018, INT J THEOR PHYS, V57, P476, DOI 10.1007/s10773-017-3580-7
   DEUTSCH D, 1983, PHYS REV LETT, V50, P631, DOI 10.1103/PhysRevLett.50.631
   Dunjko V, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aab406
   Dunjko V, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.130501
   Ekert A, 2018, NAT PHYS, V14, P114, DOI 10.1038/nphys4346
   El-Khamy SE, 2017, MULTIMED TOOLS APPL, V76, P24091, DOI 10.1007/s11042-016-4113-8
   Gisin N, 2007, NAT PHOTONICS, V1, P165, DOI 10.1038/nphoton.2007.22
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Heidari S, 2017, INT J QUANTUM INF, V15, DOI 10.1142/S0219749917500393
   Huang Hai, 2018, International Journal of High Performance Computing and Networking, V12, P65
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jiang N, 2016, INT J THEOR PHYS, V55, P107, DOI 10.1007/s10773-015-2640-0
   Li PC, 2018, INT J THEOR PHYS, V57, P3242, DOI 10.1007/s10773-018-3841-0
   Li PC, 2018, INT J THEOR PHYS, V57, P1516, DOI 10.1007/s10773-018-3678-6
   LLOYD S, 2013, ARXIV02779
   Long Gui-lu, 2007, Frontiers of Physics in China, V2, P251, DOI 10.1007/s11467-007-0050-3
   Luo GF, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2165-6
   Martin K, 2007, LECT NOTES COMPUT SC, V4567, P32
   Mohsenfar SM, 2015, MULTIMED TOOLS APPL, V74, P759, DOI 10.1007/s11042-013-1694-3
   Mohtasham-zadeh V, 2019, MULTIMED TOOLS APPL, V78, P11369, DOI 10.1007/s11042-018-6702-1
   Mosleh M, 2019, ANALOG INTEGR CIRC S, V100, P513, DOI 10.1007/s10470-019-01464-4
   NEJAD MY, 2019, INT J THEOR PHYS, P1
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Pljonkin AP, 2019, INT J CLOUD APPL COM, V9, P50, DOI 10.4018/IJCAC.2019010104
   Qu ZG, 2018, CHINESE PHYS B, V27, DOI 10.1088/1674-1056/27/1/010306
   Qu ZG, 2019, MULTIMED TOOLS APPL, V78, P7981, DOI 10.1007/s11042-018-6476-5
   Rebentrost P, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.130503
   Ruan Y, 2017, INT J THEOR PHYS, V56, P3496, DOI 10.1007/s10773-017-3514-4
   Ruan Y, 2016, QUANTUM INF PROCESS, V15, P4049, DOI 10.1007/s11128-016-1391-z
   Sahin E, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2092-6
   Schuld M, 2014, LECT NOTES ARTIF INT, V8862, P208, DOI 10.1007/978-3-319-13560-1_17
   Sergienko A.V., 2018, Quantum Communications and Cryptography
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Trugenberger CA, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.067901
   Vedral V, 1996, PHYS REV A, V54, P147, DOI 10.1103/PhysRevA.54.147
   [王冬 Wang Dong], 2012, [计算机科学, Computer Science], V39, P302
   Wang J, 2016, INT J THEOR PHYS, V55, P1622, DOI 10.1007/s10773-015-2800-2
   Wang S, 2015, MEASUREMENT, V73, P352, DOI 10.1016/j.measurement.2015.05.038
   WINIEWSKA J, 2018, VIETNAM J COMPUT SCI, P1
   WOOTTERS WK, 1982, NATURE, V299, P802, DOI 10.1038/299802a0
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xu SJ, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/6/060307
   Xu SJ, 2013, COMMUN THEOR PHYS, V59, P547, DOI 10.1088/0253-6102/59/5/05
   Yan F, 2018, THEOR COMPUT SCI, V752, P71, DOI 10.1016/j.tcs.2017.12.025
   Zhang Y, 2013, QUANTUM INF PROCESS, V12, P2833, DOI 10.1007/s11128-013-0567-z
   Zhou RG, 2018, INT J THEOR PHYS, V57, P1848, DOI 10.1007/s10773-018-3710-x
   Zhou Y, 2019, INT J THEOR PHYS, V58, P950, DOI 10.1007/s10773-018-3987-9
NR 59
TC 15
Z9 15
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17551
EP 17577
DI 10.1007/s11042-020-08694-z
EA FEB 2020
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516442500001
DA 2024-07-18
ER

PT J
AU Kumar, AR
   Sivagami, A
AF Kumar, A. Ranjith
   Sivagami, A.
TI Fuzzy based malicious node detection and security-aware multipath
   routing for wireless multimedia sensor network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks (WMSNs); Malicious node detection;
   Fuzzy logic system; Improved elliptic curve cryptography; Oppositional
   particle swarm optimization
AB Wireless Multimedia Sensor Networks (WMSNs) have drawn tremendous attention because of their potential impact on scientific research and their numerous attractive applications. However, security is one of the main challenges to WMSN. During the data transmission from source to destination, the intermediate nodes may misbehave as a malicious node. So, before reliable data transmission, these malicious nodes are to be detected. In this paper, Fuzzy logic system is presented for malicious node detection. Using this fuzzy system, the trust score is calculated for each sensor node in the network. Depend on the calculated trust score, malicious nodes are detected. For securable data transmission, Improved Elliptic Curve Cryptography (IECC) algorithm is presented. In ECC, Oppositional Particle Swarm Optimization (OPSO) is included for optimal key generation. Simulation results show that the performance of this proposed approach outperforms that of the existing approaches in terms of energy consumption, network lifetime and delay.
C1 [Kumar, A. Ranjith] Agni Coll Technol, OMR, Chennai, Tamil Nadu, India.
   [Sivagami, A.] Aarupadai Veedu Inst Technol, OMR, Chennai 603104, Tamil Nadu, India.
C3 Vinayaka Mission's Research Foundation; Aarupadai Veedu Institute Of
   Technology
RP Kumar, AR (corresponding author), Agni Coll Technol, OMR, Chennai, Tamil Nadu, India.
EM ranjithdr.kumar@gmail.com
RI Anandan, Ranjith Kumar/E-7998-2019
OI Anandan, Ranjith Kumar/0000-0003-4383-9212
CR Abazeed M, 2018, WIREL NETW
   Almalkawi IT, 2010, SENSORS-BASEL, V10, P6662, DOI 10.3390/s100706662
   Aswale S, 2017, WIRELESS PERS COMMUN, V97, P1291, DOI 10.1007/s11277-017-4566-8
   Grieco Luigi Alfredo, 2009, Proceedings of the 2009 Third International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies (UBICOMM 2009), P194, DOI 10.1109/UBICOMM.2009.27
   Hamid Z, 2016, MULTIMED TOOLS APPL, V75, P8195, DOI 10.1007/s11042-015-2737-8
   Harjito B., 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P842, DOI 10.1109/BWCCA.2010.182
   Hwang S, 2014, MULTIMED TOOLS APPL, V68, P297, DOI 10.1007/s11042-012-1064-6
   Khernane N, 2018, COMPUT COMMUN, V124, P1, DOI 10.1016/j.comcom.2018.04.012
   Kumar A, 2019, J NEUROSURG, V130, P1784, DOI [10.3171/2018.11.JNS183191, 10.1007/s12652-019-01419-7]
   Mali G, 2016, IEEE T COMPUT, V65, P1978, DOI 10.1109/TC.2015.2456026
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Mostefaoui A., 2014, 2014 22nd Annual IEEE International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS). Proceedings, P463, DOI 10.1109/MASCOTS.2014.63
   Msolli A, 2018, COMPUT ELECTR ENG, V72, P910, DOI 10.1016/j.compeleceng.2018.01.016
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Ramesh S, 2019, MULTIMED TOOLS APPL, P1
   Shen H, 2014, WIRELESS PERS COMMUN, V75, P1307, DOI 10.1007/s11277-013-1425-0
   Shu L, 2008, MOBILE NETW APPL, V13, P306, DOI 10.1007/s11036-008-0088-7
   Vithya G., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P444, DOI 10.1109/ICRTIT.2011.5972331
NR 19
TC 8
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 14031
EP 14051
DI 10.1007/s11042-020-08631-0
EA FEB 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515931100002
DA 2024-07-18
ER

PT J
AU Sivaraman, R
   Rajagopalan, S
   Amirtharajan, R
AF Sivaraman, R.
   Rajagopalan, Sundararaman
   Amirtharajan, Rengarajan
TI FPGA based generic RO TRNG architecture for image confusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TRNG; FPGA; Ring oscillator; Image encryption
ID RANDOM NUMBER GENERATOR; HIGH-SPEED; RING OSCILLATORS; TRUE; SECURITY;
   ENCRYPTION; DESIGN
AB True Random Number Generator (TRNG) has become a central element of today's secure communication. TRNGs developed through FPGA implementation have a significant role in a number of applications in multimedia communication. Ring Oscillator (RO) has been adopted extensively for developing device-independent TRNG structures. The proposed design is a generic TRNG architecture based on an arrangement of ROs with post-processing. This TRNG was initially tested on Altera Cyclone II FPGA which consumed only 64 inverters to produce good randomness. Also, the device-independent capability of this design has been verified by implementing it on other two FPGA families Xilinx Artix - 7 and Microsemi Smart Fusion2. True randomness was also verified by conducting restart experiment, and the statistical properties of TRNG were evaluated through entropy analysis and NIST SP 800-22 tests. The proposed TRNG yields 26.640650 Mbps as throughput with a sampling clock of 27 MHz. Going beyond the regular key generation utility, the evolving random bits of TRNG were packed suitably to perform confusion of grayscale images producing a near-zero correlation of pixels, thereby extending the application of TRNG to image encryption.
C1 [Sivaraman, R.; Rajagopalan, Sundararaman; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Rajagopalan, S (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM sivaraman77uma@sastra.ac.in; raman@ece.sastra.edu; amir@ece.sastra.edu
RI ., R. Sivaraman/JDM-3125-2023; Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; Rethinam,
   Sivaraman/0000-0001-9292-8524; Sundararaman,
   Rajagopalan/0000-0003-3505-3260
FU SASTRA Deemed University [R&M / 0026 / SEEE - 010 / 2012 - 13]
FX The authors wish to thank SASTRA Deemed University for providing
   infrastructure through the Research & Modernization Fund (Ref.No: R&M /
   0026 / SEEE - 010 / 2012 - 13) to carry out the research work.
CR [Anonymous], 2009, Cryptographic Engineering
   [Anonymous], 2014, Open Problems in Mathematics and Computational Science
   [Anonymous], 2006, TENCON
   Arpaci B, 2020, ENG SCI TECHNOL, V23, P595, DOI 10.1016/j.jestch.2019.09.001
   Artiles JAP, 2019, SIGNAL PROCESS-IMAGE, V79, P24, DOI 10.1016/j.image.2019.08.014
   Badrignans B, 2011, SECURITY TRENDS FOR FPGAS: FROM SECURED TO SECURE RECONFIGURABLE SYSTEMS, P1, DOI 10.1007/978-94-007-1338-3
   Bagini V, 1999, LECT NOTES COMPUT SC, V1717, P204
   Barbareschi M, 2016, MICROPROCESS MICROSY, V47, P3, DOI 10.1016/j.micpro.2016.06.005
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Bica I., 2016, Innovative Security Solutions for Information Technology and Communications
   Biswas Soma, 2011, ENCY CRYPTOGRAPHY SE, P499
   Bowman RL, 1998, CHAOS AND FRACTALS: A COMPUTER GRAPHICAL JOURNEY, P133, DOI 10.1016/B978-044450002-1/50023-0
   Bucci M, 2003, IEEE T COMPUT, V52, P403, DOI 10.1109/TC.2003.1190581
   Bucci M, 2003, IEEE T CIRCUITS-I, V50, P1373, DOI 10.1109/TCSI.2003.818610
   Danger JL, 2009, MICROELECTRON J, V40, P1650, DOI 10.1016/j.mejo.2009.02.004
   Deák N, 2015, I C CONTR SYS COMP S, P453, DOI 10.1109/CSCS.2015.19
   Denis T.S., 2007, CRYPTOGRAPHY DEV, P91
   Dichtl M, 2007, LECT NOTES COMPUT SC, V4727, P45
   Ellis Scott R., 2013, Computer and Information Security Handbook, V2nd, P25
   Epstein M, 2003, LECT NOTES COMPUT SC, V2779, P152, DOI 10.1007/978-3-540-45238-6_13
   Ergün S, 2007, AEU-INT J ELECTRON C, V61, P235, DOI 10.1016/j.aeue.2006.05.006
   Fischer V, 2004, LECT NOTES COMPUT SC, V3203, P555
   Fischer V, 2008, I C FIELD PROG LOGIC, P245, DOI 10.1109/FPL.2008.4629939
   Fischer Viktor, 2003, P CHES, P415
   Güler Ü, 2012, AEU-INT J ELECTRON C, V66, P143, DOI 10.1016/j.aeue.2011.06.001
   Guneysu Tim, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P128, DOI 10.1109/FPT.2009.5377631
   Hasheminejad A, 2019, OPTIK, V184, P205, DOI 10.1016/j.ijleo.2019.03.065
   Hu JK, 2009, J NETW COMPUT APPL, V32, P788, DOI 10.1016/j.jnca.2009.02.009
   Jessa M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P274, DOI 10.1109/ReConFig.2011.35
   Jessa M, 2012, 2012 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS (ICSES)
   Johnson AP, 2017, IEEE T CIRCUITS-II, V64, P452, DOI 10.1109/TCSII.2016.2566262
   Jun B., 1999, INTEL RANDOM NUMBER
   Karmani Rajesh K., 2011, ENCY PARALLEL COMPUT, P71
   Kazumichi H, 2011, IEICE TECH REP, V2011, P1
   Kohlbrenner P., 2004, P 2004 ACM SIGDA 12, P71, DOI DOI 10.1145/968280.968292
   Liao Ning, 2015, Journal of China Universities of Posts and Telecommunications, V22, P1, DOI 10.1016/S1005-8885(15)60661-6
   Loza S, 2015, INT J ELECTRON TELEC, V61, P199, DOI 10.1515/eletel-2015-0026
   Marghescu A, 2016, INT SYM DES TECH ELE, P98, DOI 10.1109/SIITME.2016.7777253
   Marghescu A, 2014, INT SYM DES TECH ELE, P197, DOI 10.1109/SIITME.2014.6967027
   Martin H, 2016, IEEE T IND INFORM, V12, P91, DOI 10.1109/TII.2015.2502183
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Niccol Battezzati MV, 2011, LUCA STERPONE RECONF
   Peeters E, 2005, LECT NOTES COMPUT SC, V3659, P309
   Petrie CS, 2000, IEEE T CIRCUITS-I, V47, P615, DOI 10.1109/81.847868
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ramalingam B, 2018, MULTIMED TOOLS APPL, V77, P11669, DOI 10.1007/s11042-017-4811-x
   Ravichandran D, 2019, J SIGNAL PROCESS SYS, V91, P475, DOI 10.1007/s11265-018-1337-z
   Robert GE, 2002, US PATENT APPL PUBLI
   Robson S, 2014, IEEE T CIRCUITS-II, V61, P937, DOI 10.1109/TCSII.2014.2362715
   Schellekens D, 2006, I C FIELD PROG LOGIC, P139
   Sunar B, 2007, IEEE T COMPUT, V56, P109, DOI 10.1109/TC.2007.250627
   Tkacik TE, 2002, LECT NOTES COMPUT SC, V2523, P450
   Tomassini M., 2001, Applied Soft Computing, V1, P151, DOI 10.1016/S1568-4946(01)00015-1
   Tsoi KH, 2003, ANN IEEE SYM FIELD P, P51
   Valtchanov B., 2009, P 3 INT C SIGN CIRC, P1, DOI DOI 10.1109/ICSCS.2009.5412601
   Varchola M, 2010, LECT NOTES COMPUT SC, V6225, P351, DOI 10.1007/978-3-642-15031-9_24
   Wang XY, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105581
   Wieczorek PZ, 2013, ELECTRON LETT, V49, P744, DOI 10.1049/el.2012.4126
   Wold Knut, 2008, 2008 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P385, DOI 10.1109/ReConFig.2008.17
NR 60
TC 18
Z9 18
U1 8
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13841
EP 13868
DI 10.1007/s11042-019-08592-z
EA FEB 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515805300001
DA 2024-07-18
ER

PT J
AU Qi, HF
   Li, J
   Wu, Q
   Wan, WB
   Sun, JD
AF Qi, Haifeng
   Li, Jing
   Wu, Qiang
   Wan, Wenbo
   Sun, Jiande
TI Hash length: a neglected element
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hash length; Probabilities of collision (PoC); Optimal length
ID ROBUST
AB Hash representation has attracted increasing attentions in recent years, but hash length is still a neglected element in the evaluation of hashing. Hash length is the dimension of hash representation, which is important for the performance of video hash. In this paper, we try to define the optimal hash length according to the probability of collision (PoC) of hash. Based on this definition, we demonstrate that this optimal hash length can be predicted from a small portion of dataset, which could be a reference for practical applications. The verification experiments are performed on several classical hashing methods in the case of video copy detection on different datasets. The experimental results show that each hash method has its own optimal hash length, and the performance can be improved as the length increases.
C1 [Qi, Haifeng; Li, Jing; Wan, Wenbo; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Qi, Haifeng] Shandong Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Li, Jing; Wu, Qiang] Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Peoples R China.
   [Wan, Wenbo; Sun, Jiande] Shandong Normal Univ, Inst Data Sci & Technol, Jinan, Peoples R China.
C3 Shandong Normal University; Shandong University; Shandong Management
   University; Shandong Normal University
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.; Sun, JD (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan, Peoples R China.
EM jiandesun@hotmail.com
RI Zhang, Yuchen/GYI-8858-2022
CR Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hou SJ, 2017, PATTERN RECOGN, V68, P66, DOI 10.1016/j.patcog.2017.03.003
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Kong WH, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P45, DOI 10.1145/2348283.2348293
   Lee S, 2009, IEEE T CIRC SYST VID, V19, P1379, DOI 10.1109/TCSVT.2009.2022801
   Li Z, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2018.2836221
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6323, DOI 10.1109/TNNLS.2018.2829867
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Nie XS, 2018, IEEE T INF FOREN SEC, V13, P1509, DOI 10.1109/TIFS.2018.2790953
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Peng HY, 2013, IEEE IMAGE PROC, P4482, DOI 10.1109/ICIP.2013.6738923
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Su X, 2009, INT CONF ACOUST SPEE, P1525, DOI 10.1109/ICASSP.2009.4959886
   Sun JD, 2016, NEUROCOMPUTING, V213, P84, DOI 10.1016/j.neucom.2016.05.098
   Sun JD, 2012, IEEE SIGNAL PROC LET, V19, P328, DOI 10.1109/LSP.2012.2192271
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Yeow BS, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P1, DOI 10.1109/RCAR.2016.7783991
NR 29
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4763
EP 4782
DI 10.1007/s11042-018-6221-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500030
DA 2024-07-18
ER

PT J
AU Selvi, AS
   Kumar, KPM
   Dhanasekeran, S
   Maheswari, PU
   Ramesh, S
   Pandi, SS
AF Selvi, A. Senthil
   Kumar, K. Pradeep Mohan
   Dhanasekeran, S.
   Maheswari, P. Uma
   Ramesh, S.
   Pandi, S. Senthil
TI De-noising of images from salt and pepper noise using hybrid filter,
   fuzzy logic noise detector and genetic optimization algorithm (HFGOA)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mean filter; Median filter; Fuzzy logic system; Genetic optimization
   algorithm
ID SWITCHING MEDIAN FILTER; HIGH-DENSITY SALT; REMOVAL
AB The main objective of image de-noising is to remove the noise present in the noisy image. Like that, main objective of proposed methodology is to restore the impulse noised standard test image based on hybrid filter, fuzzy logic system and genetic algorithm. The proposed HFGOA method consists of three steps. In the first step noisy image is de-noised using mean filter and median filter, individually. In the second step the difference vector is calculated using two filters output then it is given as input to fuzzy logic system. Fuzzy rules were generated from the difference vector value using triangular membership function. In the third step using genetic optimization algorithm optimal rule will be selected. Fitness value (PSNR) calculated for each population. The new population was repeatedly created using genetic operator until getting best fitness value. The performance of the proposed method was measured using PSNR value. HFGOA method is tested over standard test image (lena image) for different percentage of salt and pepper noise. The Experimental results of HFGOA method is compared with results of different exiting filters. An experimental result shows the HFGOA method rectifies the drawbacks of exiting filters and increases the visual quality of the image by increasing the PSNR value.
C1 [Selvi, A. Senthil; Kumar, K. Pradeep Mohan] SRM Inst Sci & Technol, Dept CSE, Chennai, Tamil Nadu, India.
   [Dhanasekeran, S.] Kalasalingam Univ, Dept CSE, Srivilliputhur, Tamil Nadu, India.
   [Maheswari, P. Uma] Anna Univ, Dept MCA, Reg Campus Madurai, Madurai, Tamil Nadu, India.
   [Ramesh, S.] Velagapudi Ramakrishna Siddhartha Engn Coll, Dept Informat Technol, Vijayawada, Andhra Pradesh, India.
   [Pandi, S. Senthil] Sethu Inst Technol, Dept Informat Technol, Pulloor, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai; Kalasalingam Academy of
   Research & Education; Anna University; Anna University of Technology
   Madurai; Velagapudi Ramakrishna Siddhartha Engineering College
RP Ramesh, S (corresponding author), Velagapudi Ramakrishna Siddhartha Engn Coll, Dept Informat Technol, Vijayawada, Andhra Pradesh, India.
EM mailmeselvi@yahoo.co.in; k.pradeep.kumar15@gmail.com;
   srividhans@gmail.com; dharshukiran@gmail.com; rameshcse@autmdu.ac.in;
   mailtosenthil.ks@gmail.com
RI Subbiah, Dhanasekaran/ACE-3140-2022; Senthilselvi, A/AAY-1907-2020;
   Sekaran, Dr. Ramesh/AAQ-8876-2020; Dr.S.Ramesh, Dr. S./B-2239-2014; s,
   sp/HJG-4651-2022; P, Uma Maheswari/AAA-3767-2022; S, senthil
   pandi/CAI-9163-2022
OI Subbiah, Dhanasekaran/0000-0002-5409-2057; Senthilselvi,
   A/0000-0002-0280-9773; Sekaran, Dr. Ramesh/0000-0002-6668-2142;
   Dr.S.Ramesh, Dr. S./0000-0001-5232-8479; P, Uma
   Maheswari/0000-0001-6880-1769; S, senthil pandi/0000-0003-0267-1740
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   [Anonymous], 2011, DIGITAL IMAGE PROCES
   [Anonymous], 2014, INT J EMERGING ENG R
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Deivalakshmi S, 2016, AEU-INT J ELECTRON C, V70, P757, DOI 10.1016/j.aeue.2016.03.002
   Fuller R, 1996, ABO ABOAKADEMI, Vxxvii, P275
   Habib M, 2016, AEU-INT J ELECTRON C, V70, P689, DOI 10.1016/j.aeue.2016.02.005
   HARRIS JL, 1966, J OPT SOC AM, V56, P569, DOI 10.1364/JOSA.56.000569
   Kaehler S.D., 1998, FUZZY LOGIC TUTORIAL
   Li YY, 2014, NEUROCOMPUTING, V127, P190, DOI 10.1016/j.neucom.2013.08.015
   Lin CH, 2010, IEEE T IMAGE PROCESS, V19, P2307, DOI 10.1109/TIP.2010.2047906
   Liu LC, 2015, INFORM SCIENCES, V315, P1, DOI 10.1016/j.ins.2015.03.067
   MCGLAMER.BL, 1967, J OPT SOC AM, V57, P293, DOI 10.1364/JOSA.57.000293
   Nadernejad E, 2013, SIGNAL PROCESS-IMAGE, V28, P222, DOI 10.1016/j.image.2012.12.001
   RAMESH S, 2013, ASIAN J SCI RES, V6, P736, DOI DOI 10.3923/ajsr.2013.736.744
   Ramesh T, 2014, INT CONF CONTEMP, P1, DOI 10.1109/IC3.2014.6897138
   Ross TJ, 2010, FUZZY LOGIC ENG APPL, P275
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Selvi AS, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4501
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang L-X, 1994, ADAPTIVE FUZZY SYSTE, P275
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhou Z, 2012, IEEE T IMAGE PROCESS, V21, P3157, DOI 10.1109/TIP.2012.2189577
   Zuo ZY, 2013, OPTIK, V124, P3503, DOI 10.1016/j.ijleo.2012.10.014
NR 28
TC 13
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4115
EP 4131
DI 10.1007/s11042-019-7727-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700057
DA 2024-07-18
ER

PT J
AU Wang, TC
   Tong, CS
   Xu, BL
AF Wang, Ti-chun
   Tong, Chang-sheng
   Xu, Ben-ling
TI AGV navigation analysis based on multi-sensor data fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AGV; Navigation; Multi-sensor; Data fusion; Kalman filter
AB For the navigation problem of differential AGV, its motion model was established, and the inertial guidance method based on multi-sensor was adopted. The encoder, gyro, acceleration sensor, ultrasonic sensor and infrared sensor were selected to establish the Kalman filter multi-sensor. And the models and algorithms of the data fusion navigation and the obstacle avoidance were proposed. Further, the simulation calculation was conducted. The research results show that the navigation accuracy of AGV and navigation performance were improved by the method discussed in the paper.
C1 [Wang, Ti-chun; Tong, Chang-sheng; Xu, Ben-ling] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wang, TC (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
EM wangtichun2010@nuaa.edu.cn
OI WANG, Ti-chun/0000-0002-5701-2446
CR Almasri M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010024
   [Anonymous], 2015, 2015 INT C IND POS I
   Cardarelli E, 2014, INT C INTELL COMP CO, P221, DOI 10.1109/ICCP.2014.6937000
   De Cecco M, 2002, IEEE IMTC P, P1513, DOI 10.1109/IMTC.2002.1007183
   Demesure G, 2016, J INTELL ROBOT SYST, V82, P495, DOI 10.1007/s10846-015-0273-4
   Jung K, 2014, ROBOT AUTON SYST, V62, P1241, DOI 10.1016/j.robot.2014.03.016
   김재용, 2013, International Journal of Fuzzy Logic and Intelligent systems, V13, P307
   Lee IS, 2012, ADV MAT RES, V488, P1818, DOI 10.4028/www.scientific.net/AMR.488-489.1818
   Lee SY, 2012, ROBOT CIM-INT MANUF, V28, P425, DOI 10.1016/j.rcim.2011.11.005
   Pei L, 2015, J HUAZHONG U SCI TEC, P224
   [王一强 Wang Yiqiang], 2011, [计算机应用与软件, Computer Applications and Software], V28, P49
   Xiao Ben-xian, 2005, Journal of System Simulation, V17, P1939
   Ye Jin-hua, 2013, Electric Machines and Control, V17, P111
   Yoon SW., 2015, J Sens, V2015, P1
   Yuan PJ, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P900, DOI 10.1109/IS3C.2014.237
   Zaifang Z, 2005, MECH ENG, V1, P43
   [朱从民 Zhu Congmin], 2009, [农业机械学报, Transactions of the Chinese Society of Agricultural Machinery], V40, P40
   Zhu Congmin, 2008, Chinese Journal of Scientific Instrument, V29, P2419
   Zou Bo, 2014, Application Research of Computers, V31, P1035, DOI 10.3969/j.issn.1001-3695.2014.04.019
NR 19
TC 17
Z9 19
U1 21
U2 121
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5109
EP 5124
DI 10.1007/s11042-018-6336-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500050
DA 2024-07-18
ER

PT J
AU Atal, DK
   Singh, M
AF Atal, Dinesh Kumar
   Singh, Mukhtiar
TI A dictionary matrix generation based compression and bitwise embedding
   mechanisms for ECG signal classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram (ECG) signal; Dictionary matrix generation; Bitwise
   embedding; Modified dynamic classification (MDC)
ID AUTOMATED DETECTION; QRS COMPLEX; STEGANOGRAPHY; INFORMATION; MODEL
AB The Electrocardiogram (ECG) signal processing is one of the exciting research areas in recent days. Ensuring security to the patient's confidential information is a demanding critical task in many healthcare systems. So, the traditional works developed the security mechanisms for embedding the original ECG signal with the image, audio, or video. But, it does not focus on reducing the size of the original message before transmitting it to others. Also, it has significant limitations of inefficient security, increased complexity, and reduced classification accuracy. To rectify this issue, our research proposed the new embedding mechanism to improve the security of patient's health information. In this system, the original ECG signals compressed at the initial stage by using the proposed Dictionary Matrix Generation (DMG) algorithm. Then, the compressed signals embedded within the cover image by using the Bitwise Embedding (BE) mechanism. At the receiver side, the bedded goal is de-embedded and decompressed by using the DMG and BE algorithms. The features such as spectral and peak values of the signal are extracted for increasing the efficiency of classification. Classification and detection of abnormality present in ECG signal of patient is the most essential part. To achieve this, we proposed the Modified Dynamic Classification (MDC) algorithm based on the features. In this work, the novelty is implemented in the compression, embedding, and classification stages. The proposed system reduces the data loss during transmission, memory storage and time complexity. The overall process evaluated by using PTB diagnostic ECG database. In experiments, the proposed classification technique provides the accuracy of 98.39% and it proved that the proposed method had highest performances than existing methods such as PNN, SVM and RF classification.
C1 [Atal, Dinesh Kumar; Singh, Mukhtiar] Delhi Technol Univ, Dept Elect Engn, Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University
RP Singh, M (corresponding author), Delhi Technol Univ, Dept Elect Engn, Bawana Rd, Delhi 110042, India.
EM smukhtiar_79@yahoo.co.in
RI SINGH, MUKHTIAR/AAE-8636-2022; Atal, Dr. Dinesh Kumar/AAK-2916-2020
OI Atal, Dr. Dinesh Kumar/0000-0003-2247-5632; Singh,
   Mukhtiar/0000-0003-0101-2698
CR Abdulla A. A., 2015, EXPLOITING SIMILARIT
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   [Anonymous], 2017, PTB DIAGNOSTIC ECG D
   [Anonymous], IEEE T INFORM FORENS
   Ardan AN, 2019, J PHYS CONF SER, V1204, DOI 10.1088/1742-6596/1204/1/012071
   Awasthi D, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P559, DOI 10.1109/ICCSP.2015.7322548
   Awasthi D, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P718, DOI 10.1109/ECS.2015.7125005
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cheng L-T, 2018, INT J COMPUT INF SCI, V12, P509
   Chowdhury R, 2018, MEN AND FEMINISM IN INDIA, P1
   Cuadros J, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/6371871
   Feng ND, 2019, IEEE ACCESS, V7, P50431, DOI 10.1109/ACCESS.2019.2910880
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Haddadi R, 2019, 3 INT C COMP WIR COM
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Hu YH, 2019, J INTERNET TECHNOL, V20, P975, DOI 10.3966/160792642019052003029
   Ibaida A, 2013, IEEE T BIO-MED ENG, V60, P3322, DOI 10.1109/TBME.2013.2264539
   Jero SE, 2016, ELECTRON LETT, V52, P283, DOI 10.1049/el.2015.3218
   Jha C., 2017, INT J TELEMEDICINE C, V2, P31, DOI [10.1504/IJTMCP.2017.082106, DOI 10.1504/IJTMCP.2017.082106]
   Jha CK, 2019, IET SCI MEAS TECHNOL, V13, P500, DOI 10.1049/iet-smt.2018.5217
   Jovanovic B, 2015, FACTA UNIV-SER ELECT, V28, P571, DOI 10.2298/FUEE1504571J
   Li HQ, 2016, CIRC SYST SIGNAL PR, V35, P1187, DOI 10.1007/s00034-015-0108-3
   Liji CA, 2016, PROC TECH, V24, P1039, DOI 10.1016/j.protcy.2016.05.230
   Marakarkandy B, 2015, INT J APPL INNOVATIO, V4, P94
   Mathivanan P, 2018, AUSTRALAS PHYS ENG S, V41, P1057, DOI 10.1007/s13246-018-0695-y
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Meng R., 2019, J INFORM HIDING PRIV, V1, P43
   Mohagheghi E, 2017, ENERGIES, V10, DOI 10.3390/en10040535
   Pasolli E, 2015, BIOMED SIGNAL PROCES, V19, P130, DOI 10.1016/j.bspc.2014.10.013
   Patil V, 2018, L N COMPUT VIS BIOME, V28, P238, DOI 10.1007/978-3-319-71767-8_20
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Rani R, 2015, INT J COMPUT SCI NET, V15, P1
   Reddy KG, 2017, INT RES J ENG TECHNO, V4, P1212
   Sankari V., 2014, INF COMM EMB SYST IC, P1, DOI DOI 10.1109/ICICES.2014.7033925
   Stergiou C., 2018, Journal of Multimedia Information System, V5, P27
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Sulam J, 2017, SIGNAL PROCESS, V130, P403, DOI 10.1016/j.sigpro.2016.07.026
   Swierkosz A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103401
   Tsai TH, 2018, IEEE ACCESS, V6, P42207, DOI 10.1109/ACCESS.2018.2858857
   Wang ZH, 2020, COGN SYST RES, V59, P15, DOI 10.1016/j.cogsys.2019.09.001
   Wu F, 2017, NEURAL PROCESS LETT, V45, P649, DOI 10.1007/s11063-016-9545-7
   Wu F, 2016, PATTERN RECOGN, V50, P143, DOI 10.1016/j.patcog.2015.08.012
   Wu W., 2015, 2015 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2015.7156675
   Yildirim O, 2018, COGN SYST RES, V52, P198, DOI 10.1016/j.cogsys.2018.07.004
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang KF, 2017, CHIN CONTR CONF, P1069, DOI 10.23919/ChiCC.2017.8027488
   Zhang SD, 2020, VISUAL COMPUT, V36, P305, DOI 10.1007/s00371-018-1612-9
NR 50
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13139
EP 13159
DI 10.1007/s11042-020-08671-6
EA JAN 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515608600003
DA 2024-07-18
ER

PT J
AU Wang, RL
   He, N
   Wang, YX
   Lu, K
AF Wang, Ruolin
   He, Ning
   Wang, Yixue
   Lu, Ke
TI Adaptively weighted nonlocal means and TV minimization for speckle
   reduction in SAR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic aperture radar (SAR); Speckle reduction; TV minimization;
   Nonlocal means (NLM); Polarimetric synthetic aperture radar (PolSAR)
ID ALGORITHMS
AB Speckle noise reduction is an important issue in synthetic aperture radar (SAR) imaging. Because SAR images are distinct in being complex valued and susceptible to corruption owing to multiplicative fluctuations, specialized methods for speckle reduction are needed. Techniques based on nonlocal means perform denoising by exploiting the natural redundancy of patterns within an image. They calculate a weighted average of pixels whose neighborhoods are close to one another, where this significantly reduces noise while preserving most image content. While this method performs well on flat areas and textures, its results are excessively smooth in low-contrast areas, and leave residual noise around edges and singular structures. Another variational denoising method uses total variation (TV) minimization to restore regular images but is prone to excessively smooth textures, the staircasing effect, and contrast losses. Our proposed model is intended for the logarithmic domain of SAR data, and combines the above two methods by minimizing an adaptive TV using a nonlocal data fidelity term. In the variational functionals developed here, weighted parameters of nonlocal regularization are adaptively tuned based on local heterogeneity information and noise in the images. A fast iterative shrinkage/thresholding algorithm (FISTA) is then used to solve the optimization problem. The results of experiments on real SAR images verify the effectiveness of the proposed method in terms of speckle reduction.
C1 [Wang, Ruolin] Logist Dept Beijing Mil Reg, Beijing 100042, Peoples R China.
   [He, Ning] Beijing Union Univ, Beijing 100101, Peoples R China.
   [Wang, Yixue] Shenyang Inst Engn, Shenyang 110136, Liaoning, Peoples R China.
   [Lu, Ke] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Beijing Union University; Shenyang Institute of Engineering; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS
RP He, N (corresponding author), Beijing Union Univ, Beijing 100101, Peoples R China.
EM 992759523@qq.com; xxthening@buu.edu.cn; wyx123624@163.com;
   luk@ucas.ac.uk
RI Huang, Yu/KDM-9182-2024; chen, yanhong/JVE-0289-2024
FU National Natural Science Foundation of China [61572077, 61872042]; Key
   Projects of the Beijing Education Commission [KZ201911417048]; Project
   of Oriented Characteristic Disciplines [KYDE40201701]
FX This work was supported by the National Natural Science Foundation of
   China (61572077, 61872042); Key Projects of the Beijing Education
   Commission (KZ201911417048); The Project of Oriented Characteristic
   Disciplines (KYDE40201701).
CR ARSENAULT HH, 1984, APPL OPTICS, V23, P845, DOI 10.1364/AO.23.000845
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chen JO, 2011, IEEE T GEOSCI REMOTE, V49, P1744, DOI 10.1109/TGRS.2010.2087763
   Coupé P, 2008, I S BIOMED IMAGING, P1291, DOI 10.1109/ISBI.2008.4541240
   Cozzolino D, 2014, IEEE GEOSCI REMOTE S, V11, P524, DOI 10.1109/LGRS.2013.2271650
   Deledalle CA, 2017, IEEE T IMAGE PROCESS, V26, P4389, DOI 10.1109/TIP.2017.2713946
   Deledalle CA, 2015, IEEE T GEOSCI REMOTE, V53, P2021, DOI 10.1109/TGRS.2014.2352555
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Erer I, 2019, SIVIP, P1
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Hua Zhong, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7495, DOI 10.1117/12.832169
   Huang YM, 2012, IEEE T IMAGE PROCESS, V21, P4534, DOI 10.1109/TIP.2012.2205007
   Liu X, 2017, COMPUT VIS IMAGE UND, V162, P23, DOI 10.1016/j.cviu.2017.08.002
   Ma XS, 2018, IEEE J-STARS, V11, P743, DOI 10.1109/JSTARS.2017.2768059
   Ma XS, 2016, IEEE T GEOSCI REMOTE, V54, P3421, DOI 10.1109/TGRS.2016.2517627
   Nie XL, 2016, IEEE T IMAGE PROCESS, V25, P2620, DOI 10.1109/TIP.2016.2552402
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Peyré G, 2011, INVERSE PROBL IMAG, V5, P511, DOI 10.3934/ipi.2011.5.511
   Ping Fan Yan, 1986, Traitement du Signal, V3, P91
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Tang YY, 2003, IEEE T PATTERN ANAL, V25, P1118, DOI 10.1109/TPAMI.2003.1227987
   Vasile G, 2006, IEEE T GEOSCI REMOTE, V44, P1609, DOI 10.1109/TGRS.2005.864142
   Xue BD, 2013, IEEE GEOSCI REMOTE S, V10, P1309, DOI 10.1109/LGRS.2013.2238603
   Yun S, 2012, IEEE T IMAGE PROCESS, V21, P2523, DOI 10.1109/TIP.2012.2185942
NR 27
TC 12
Z9 13
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7633
EP 7647
DI 10.1007/s11042-019-08377-4
EA JAN 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600008
DA 2024-07-18
ER

PT J
AU Raees, M
   Ullah, S
AF Raees, Muhammad
   Ullah, Sehat
TI THE-3DI: Tracing head and eyes for 3D interactions: An interaction
   technique for virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D interactions; Eyes recognition; Virtual environment; Head gestures
   for interaction
ID GAZE; TRACKING; MOVEMENTS; NAVIGATION; INTERFACE; SYSTEM
AB Gesture-based interfaces offer a suitable platform for interactions in Virtual Environments (VE). However, the difficulties involved in learning and making of distinct gestures affect the performance of an interactive system. By incorporating computer vision in Virtual Reality (VR), this paper presents an intuitive interaction technique where the states and positions of eyes are traced for interaction. With comparatively low cognitive load, the technique offers an easy to use interaction solution for VR applications. Unlike other gestural interfaces, interactions are performed in distinct phases where transition from one phase to another is enacted with simple blink of eyes. In an attained phase, interaction along an arbitrary axis is performed by a perceptive gesture of head; rolling, pitching or yawing. To follow the trajectory of eyes in real time, coordinates mapping is performed dynamically. The proposed technique is implemented in a case-study project; EBI (Eyes Blinking based Interaction). In the EBI project, real time detection and tracking of eyes are performed at the back-end. At the front-end, virtual scene is rendered accordingly by using the OpenGL library. To assess accuracy, usability and cognitive load of the proposed technique, the EBI project is evaluated 280 times in three different evaluation sessions. With an ordinary camera, an average accuracy of 81.4% is achieved. However, assessment made by using a high-quality camera revealed that accuracy of the system could be raised to a higher level. As a whole, findings of the evaluations support applicability of the technique in the emerging domains of VR.
C1 [Raees, Muhammad; Ullah, Sehat] Univ Malakand, Dept Comp Sci & IT, Dir Lower, Pakistan.
C3 University of Malakand
RP Raees, M (corresponding author), Univ Malakand, Dept Comp Sci & IT, Dir Lower, Pakistan.
EM visitrais@yahoo.com
RI Raees, Muhammmad/J-3526-2019; ullah, sehat/HTT-4581-2023
OI Raees, Muhammmad/0000-0001-6887-6883; ullah, sehat/0000-0002-1193-9350
CR Ackad C., 2014, P SIGCHI C HUM FACT, V49, P57, DOI 10.1002/rwm3.20180
   Alqahtani A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01980
   Alt F., 2014, Proceedings of the 19th international conference on Intelligent User Interfaces, P267, DOI DOI 10.1145/2557500.2557518
   [Anonymous], 2014, INT C HUM COMP INT
   [Anonymous], 2013, P 2013 INT C BIOM IC, DOI DOI 10.1109/ICB.2013.6612953
   [Anonymous], 2010, P 17 ACM S VIRTUAL R
   [Anonymous], 2002, INT C IM PROC
   [Anonymous], 2014, 2014 11 INT S EL TEL
   Atienza R, 2016, IEEE REGION 10 SYMP, P110, DOI 10.1109/TENCONSpring.2016.7519387
   Bellarbi B., 2015, EL ENG ICEE 2015 4 I, P1, DOI 10.1109/INTEE.2015.7416813
   Benko H., 2009, P 17 ACM INT C MULT, P935, DOI DOI 10.1145/1631272.1631462
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Bolte B, 2015, IEEE T VIS COMPUT GR, V21, P545, DOI 10.1109/TVCG.2015.2391851
   Bott NT, 2017, FRONT NEUROSCI-SWITZ, V11, P1, DOI 10.3389/fnins.2017.00370
   Card SK, 2014, GESTURE BASED INTERA
   Cashion J, 2012, IEEE T VIS COMPUT GR, V18, P634, DOI 10.1109/TVCG.2012.40
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Chapoulie E, 2014, THESIS
   Chatterjee I, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P131, DOI 10.1145/2818346.2820752
   Choi I., 2011, P 20 INT C COMP COMM, P1
   Dargham JA, 2012, ADV INTEL SOFT COMPU, V151, P565
   De Luca Alexander., 2007, P 19 AUSTRALASIAN C, P199, DOI [10.1145/1324892.1324932, 10.1145/1324892.1324932doi.org/10.1145/1324892.1324932, DOI 10.1145/1324892.1324932DOI.ORG/10.1145/1324892.1324932]
   De Smedt Q., 2017, THESIS
   Deng S, 2018, THESIS
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Duguleana M, 2014, PROCEDIA ENGINEER, V69, P333, DOI 10.1016/j.proeng.2014.02.240
   Esteves A, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P457, DOI 10.1145/2807442.2807499
   Fono D., 2005, Proceedings of the SIGCHI conference on Human factors in computing systems, P151, DOI 10.1145/1054972.1054994
   Foulsham T, 2015, EYE, V29, P196, DOI 10.1038/eye.2014.275
   Granholm E, 2004, INT J PSYCHOPHYSIOL, V52, P1, DOI 10.1016/j.ijpsycho.2003.12.001
   Hales J., 2013, P 3 INT WORKSH PERV, V6
   Han P, 2013, J VISION, V13, DOI 10.1167/13.8.27
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hilsendeger A., 2009, 6 WORKSH VIRT AUGM R
   Holland Corey, 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117536, 10.1109/IJCB.2011.6117536.]
   Hou WJ, 2018, LECT NOTES COMPUT SC, V10911, P18, DOI 10.1007/978-3-319-92141-9_2
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Jacob R.J., 1990, P SIGCHI C HUM FACT, P11, DOI DOI 10.1145/97243.97246
   Joakim K, 2017, EYE TRACKING IS VIRT
   Kaaman A., 2017, GAZE SUPPORTED INTER
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Khamis M, 2018, P 2018 INT C ADV VIS, V7, P18
   Khamis M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P155, DOI 10.1145/3126594.3126630
   Khamis M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P274, DOI 10.1145/2971648.2971679
   Kim K, 2015, SENSORS-BASEL, V15, P1022, DOI 10.3390/s150101022
   Kim M, 2016, MULTIMED TOOLS APPL, V75, P16529, DOI 10.1007/s11042-016-3355-9
   Kinnunen T, 2010, P S EYE TRACK RES AP, P187
   Komogortsev Oleg, 2010, P 2010 S EYE TRACK R, P57, DOI [DOI 10.1145/1743666.1743679, 10.1145/1743666.1743679]
   Kowalczyk P, 2019, MULTIMED TOOLS APPL, V78, P13749, DOI 10.1007/s11042-018-6554-8
   Kumar A, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P2002
   Laddi A, 2019, MULTIMED TOOLS APPL, V78, P31215, DOI 10.1007/s11042-019-07940-3
   Leigh R.J., 1999, NEUROLOGY EYE MOVEME
   Li CY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194475
   Linn Andreas., 2017, Gaze Teleportation in Virtual Reality
   Long A.C., 2001, Quill: a gesture design tool for pen-based user interfaces
   Di Stasi LL, 2011, APPL ERGON, V42, P807, DOI 10.1016/j.apergo.2011.01.003
   Maheswari S, 2017, BIOMED RES, V28, P29
   Majaranta P, 2011, IGI GLOBAL, DOI 10: 978-1
   Mardanbegi  Diako, 2011, P NOV GAZ CONTR APPL, P2, DOI 10.1145/1983302.1983304
   Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680
   Memo A, 2018, MULTIMED TOOLS APPL, V77, P27, DOI 10.1007/s11042-016-4223-3
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Mousas C, 2017, COMPUT GRAPH-UK, V65, P1, DOI 10.1016/j.cag.2017.03.001
   Oh Uran., 2013, P SIGCHI C HUMAN FAC, P1129, DOI DOI 10.1145/2470654.2466145
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Padilla R., 2012, World Academy of Science, Engineering and Technology, V64, P362
   Padmanaban Nitish, 2017, P NATL ACAD SCI USA
   Pfeiffer T., 2008, J VIRTUAL REALITY BR, V5, P1660
   Pham HA, 2018, CHALLENGE HAND GESTU
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Porta M, 2015, J ASSIST TECHNOL, V9, P48, DOI 10.1108/JAT-12-2013-0037
   Prabhakar Gowdham, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2010001
   Pratibha Adkar., 2013, International Journal of Computer Science Information and Engineering Technology (IJCSIET), V2, P1
   Punpongsanon P, 2017, IEEE T VIS COMPUT GR, V23, P1952, DOI 10.1109/TVCG.2016.2586071
   Raees M., 2017, PAKISTAN J SCI, V69, P85
   Raees M, 2019, INT J INTERACT MULTI, V5, P115, DOI 10.9781/ijimai.2019.01.002
   Raees M, 2016, J ENG RES-KUWAIT, V4, P22
   Rahman S. U., 2018, INT J INTERACTIVE DE, P1
   Reale MJ, 2011, IEEE T MULTIMEDIA, V13, P474, DOI 10.1109/TMM.2011.2120600
   Rodriguez JD, 2013, CLIN OPHTHALMOL, V7, P337, DOI 10.2147/OPTH.S39356
   Rubio-Tamayo Jose Luis, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040021
   Sayers H, 2004, INTERACT COMPUT, V16, P939, DOI 10.1016/j.intcom.2004.05.003
   Schultheis H, 2004, LECT NOTES COMPUT SC, V3137, P225
   Sofia Jennifer J., 2018, MULTIMED TOOLS APPL, V2, P1
   Sorgalla J, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P102, DOI 10.5220/0006621301020107
   Stellmach S., 2012, Proc. CHI, P2981, DOI DOI 10.1145/2207676.2208709
   Stellmach Sophie., 2012, P S EYE TRACKING RES, P131, DOI [https://doi.org/10.1145/2168556.2168577, DOI 10.1145/2168556.2168577]
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Triesch J., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P95, DOI 10.1145/507072.507092
   Vafadar M, 2015, MULTIMED TOOLS APPL, V74, P7515, DOI 10.1007/s11042-014-1989-z
   Vanacken D., 2014, WORKSH GEST BAS INT
   Velloso Eduardo, 2017, ACM Transactions on Computer-Human Interaction, V24, DOI 10.1145/3064937
   Velloso E, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P812, DOI 10.1145/2901790.2901867
   Velloso E, 2015, LECT NOTES COMPUT SC, V9297, P315, DOI 10.1007/978-3-319-22668-2_25
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Vidal M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P439, DOI 10.1145/2493432.2493477
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu HY, 2016, VISUAL COMPUT, V32, P123, DOI 10.1007/s00371-014-1060-0
   Zhang YX, 2015, LECT NOTES COMPUT SC, V9298, P570, DOI 10.1007/978-3-319-22698-9_39
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 102
TC 0
Z9 1
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1311
EP 1337
DI 10.1007/s11042-019-08305-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600053
DA 2024-07-18
ER

PT J
AU Sharma, M
AF Sharma, Madhu
TI Image encryption based on a new 2D logistic adjusted logistic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; New 2D chaotic map; Logistic map; Lyapunov exponent
ID ALGORITHM; SCHEME; CRYPTANALYSIS; ENTROPY; CIPHERS
AB This paper proposes an encryption scheme based on a new 2-dimensional chaotic map. The new 2D chaotic map is derived from the idea of giving the two outputs of a 2D logistic map to two separate 1-dimensional logistic maps. The resulting 2D chaos based pseudo-random number generator is demonstrated to have significantly better randomness and unpredictability characteristics in terms of Lyapunov exponents as well as trajectory plots, in comparison to some recently proposed schemes based on other 2D chaotic maps. This new 2D chaotic map is then used to implement encryption of images. The proposed encryption scheme is demonstrated to be significantly better in terms of the required computational effort. For the proposed scheme, the commonly used measures of security, unpredictability and sensitivity to initial states are successfully established with the help of a set of standard simulation results.
C1 [Sharma, Madhu] DIT Univ, Dehra Dun 248001, Uttarakhand, India.
C3 DIT University
RP Sharma, M (corresponding author), DIT Univ, Dehra Dun 248001, Uttarakhand, India.
EM madhuashishsharma@gmail.com
RI Sharma, Madhu/ABC-0334-2022
OI Sharma, Madhu/0000-0002-3303-5651
CR Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bellini P, 2018, MULTIMED TOOLS APPL, V77, P2083, DOI 10.1007/s11042-017-4382-x
   BENETTIN G, 1976, PHYS REV A, V14, P2338, DOI 10.1103/PhysRevA.14.2338
   Bhardwaj R, 2019, OPTIK, V181, P1099, DOI 10.1016/j.ijleo.2018.12.130
   BROWN R, 1991, PHYS REV A, V43, P2787, DOI 10.1103/PhysRevA.43.2787
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chandrika BK, 2017, J VIS COMMUN IMAGE R, V46, P23, DOI 10.1016/j.jvcir.2017.03.006
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Çokal C, 2009, PHYS LETT A, V373, P1357, DOI 10.1016/j.physleta.2009.02.030
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hsiao HI, 2015, SIGNAL PROCESS, V117, P281, DOI 10.1016/j.sigpro.2015.06.007
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kindt EJ, 2018, COMPUT LAW SECUR REV, V34, P523, DOI 10.1016/j.clsr.2017.11.004
   Li CQ, 2011, SIGNAL PROCESS, V91, P949, DOI 10.1016/j.sigpro.2010.09.014
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Villena S, 2018, COMPUT IND, V98, P34, DOI 10.1016/j.compind.2018.02.004
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 37
TC 19
Z9 21
U1 2
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 355
EP 374
DI 10.1007/s11042-019-08079-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600015
DA 2024-07-18
ER

PT J
AU Wang, SW
   Lan, L
   Zhang, X
   Dong, GH
   Luo, ZG
AF Wang, Shiwei
   Lan, Long
   Zhang, Xiang
   Dong, Guohua
   Luo, Zhigang
TI Object-aware semantics of attention for image captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High-level semantic concepts; Semantic attention; Image captioning
AB In image captioning, exploring the advanced semantic concepts is very important for boosting captioning performance. Although much progress has been made in this regard, most existing image captioning models usually neglect the interrelationships between objects in an image, which is a key factor of accurately understanding image content. In this paper, we propose the object-aware semantic attention object-aware semantic attention (OSA) based captioning model to address this issue. Specifically, our attention model allows the explicit associations between the objects by coupling the attention mechanism with three types of semantic concepts, i.e., the category information, relative sizes of the objects, and relative distances between objects. In reality, they are easily built up and seamlessly coupled with the well-known encoder-decoder captioning framework. In our empirical analysis, these semantic concepts favor different aspects of the image content like the number of the objects belonging to each category, the main focus of an image, and the closeness between the objects. Importantly, they are cooperated with visual features to help the attention model effectively highlight the image regions of interest for significant performance gains. By leveraging three types of semantic concepts, we derive four semantic attention models for image captioning. Extensive experiments on MSCOCO dataset show our attention models within the encoder-decoder image captioning framework perform favorably as compared to representative captioning models.
C1 [Wang, Shiwei; Dong, Guohua; Luo, Zhigang] Natl Univ Def Technol, Sci & Technol Parallel & Distributed Proc, Changsha 410073, Peoples R China.
   [Lan, Long; Zhang, Xiang] Natl Univ Def Technol, Inst Quantum Informat, State Key Lab High Performance Comp, Changsha 410073, Peoples R China.
   [Wang, Shiwei; Lan, Long; Zhang, Xiang; Dong, Guohua; Luo, Zhigang] Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China; National University of Defense Technology
   - China
RP Lan, L (corresponding author), Natl Univ Def Technol, Inst Quantum Informat, State Key Lab High Performance Comp, Changsha 410073, Peoples R China.; Lan, L (corresponding author), Natl Univ Def Technol, Coll Comp, Changsha 410073, Peoples R China.
EM long.lan@nudt.edu.cn; zhangxiang08@nudt.edu.cn; zgluo@nudt.edu.cn
RI Zhang, Xiangyu/ABC-2896-2021
OI Zhang, Xiangyu/0000-0003-3716-4722; Lan, Long/0000-0002-4238-8985
FU National Natural Science Foundation of China [61806213, U1435222]
FX This work was supported by the National Natural Science Foundation of
   China [61806213, U1435222].
CR [Anonymous], 2015, ARXIV150904942
   [Anonymous], 2017, ARXIV170205658
   [Anonymous], 2017, INT C MACH LEARN
   [Anonymous], 2018, ARXIV180703514
   [Anonymous], 2016, ARXIV161201033
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2018, P IEEE C COMP VIS PA
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   [Anonymous], 2017, ARXIV170407333
   [Anonymous], 2004, P ANN M ASS COMP LIN
   Bengio Y., 2014, TECHNICAL REPORT
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822
   Hu H, 2017, ARXIV171111575S
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu A, 2018, P 27 INT JOINT C ART, P821, DOI DOI 10.24963/IJCAI.2018/114
   Liu AA, 2017, COMPUT VIS IMAGE UND, V163, P113, DOI 10.1016/j.cviu.2017.04.013
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mao Junhua, 2014, CoRR
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qiu ZF, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P225, DOI 10.1145/3077136.3080842
   Ren S, 2015, NIPS, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sutskever I, 2014, ADV NEUR IN, V27
   Vaswani A., 2017, P ADV NEUR INF PROC, V2017, P5998
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yao T, 2017, PROC CVPR IEEE, P5263, DOI 10.1109/CVPR.2017.559
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhou LW, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P305, DOI 10.1145/3126686.3126717
NR 46
TC 10
Z9 10
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2013
EP 2030
DI 10.1007/s11042-019-08209-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2LC
UT WOS:000571393200001
DA 2024-07-18
ER

PT J
AU Abdallah, HA
   Amoon, M
   Hadhoud, MM
   Shaalan, AA
   Alshebeili, SA
   Abd El-Samie, FE
AF Abdallah, Hanaa A.
   Amoon, Mohammed
   Hadhoud, Mohiy M.
   Shaalan, Abdalhameed A.
   Alshebeili, Saleh A.
   Abd El-Samie, Fathi E.
TI An embedding approach using orthogonal matrices of the singular value
   decomposition for image steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Data Hiding; Singular Value Decomposition; Visual Image
   Fidelity
ID DIGITAL IMAGES
AB This paper aims to reduce the embedding errors, maintain the image fidelity, and reduce the errors, when detecting the embedded messages in images. An embedding approach is proposed that depends on using the orthogonal matrices of the Singular Value Decomposition (SVD) as a vessel for embedding information instead of embedding in the singular values of the images. Three ways are suggested to reduce the embedding errors and maintain the image fidelity, when detecting the embedded message. These ways are increasing the number of columns protected without embedding, choosing the suitable block size to embed in and adjusting the singular values in order to give a high quality of the stego image. Results show that utilization of the orthogonal matrices of the SVD for information hiding can be as effective as using transform-based techniques, and it gives better results than those obtained with the Least Significant Bit (LSB) technique.
C1 [Abdallah, Hanaa A.; Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh, Saudi Arabia.
   [Abdallah, Hanaa A.; Shaalan, Abdalhameed A.] Zagazig Univ, Fac Engn, Zagazig, Egypt.
   [Amoon, Mohammed] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [Amoon, Mohammed] King Saud Univ, Community Coll, Dept Comp Sci, Riyadh 2809511437, Saudi Arabia.
   [Hadhoud, Mohiy M.] Menoufia Univ, Fac Comp & Informat, Shibin Al Kawm, Egypt.
   [Alshebeili, Saleh A.] King Saud Univ, Dept Elect Engn, Riyadh 11421, Saudi Arabia.
   [Alshebeili, Saleh A.] King Saud Univ, KACST TIC Radio Frequency & Photon & Soc, Riyadh 11421, Saudi Arabia.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Zagazig University; Egyptian Knowledge Bank (EKB); Menofia
   University; King Saud University; Egyptian Knowledge Bank (EKB); Menofia
   University; King Saud University; King Saud University; Egyptian
   Knowledge Bank (EKB); Menofia University
RP Amoon, M (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.; Amoon, M (corresponding author), King Saud Univ, Community Coll, Dept Comp Sci, Riyadh 2809511437, Saudi Arabia.
EM haabdullah@pnu.edu.sa; mamoon@ksu.edu.sa; mmhadhoud@yahoo.com;
   shaalan_zag2010@yahoo.com; dsaleh@ksu.edu.sa; fathi_sayed@yahoo.com
RI abdalaziz, hanaa/GLQ-8305-2022; El-Khamy, Said E./AAE-6748-2020;
   Alshebeili, Saleh/GZB-2540-2022; Sayed, Fathi/HRA-4752-2023; Amoon,
   Mohammed/AAM-8540-2020
OI Alshebeili, Saleh/0000-0003-4157-9277; Sayed, Fathi/0000-0001-8749-9518;
   Amoon, Mohammed/0000-0003-1704-7211; abdallah, Hanaa A.
   Abdallah/0000-0003-0307-1384
FU Deanship of Scientific Research at Princess Nourah bint Abdulrahman
   University through the Fast-track Research Funding program; Deanship of
   Scientific Research at King Saud University [RG-1440-039]
FX This research was funded by the Deanship of Scientific Research at
   Princess Nourah bint Abdulrahman University through the Fast-track
   Research Funding program. The authors extend their appreciation to the
   Deanship of Scientific Research at King Saud University for funding this
   work through research group No (RG-1440-039).
CR Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 1997, 13 INT C DIG SIGN PR, V1
   Cary Huffman., 2003, Fundamentals of Error-Correcting Codes
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Cox I. J., 2002, Digital Watermarking
   Crandall R., 1998, SOME NOTES STEGANOGR
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Lay David., 2000, LINEAR ALGEBRA ITS A
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2018, COMPUT ELECTR ENG, V67, P320, DOI 10.1016/j.compeleceng.2017.08.020
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Min-Jen Tsai, 2000, IEEE Transactions on Consumer Electronics, V46, DOI 10.1109/30.826405
   Schneier B., 2015, APPL CRYPTOGRAPHY, VSecond
   Sun R, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1592, DOI 10.1109/ICOSP.2002.1180102
   Zhu XZ, 2006, INT C PATT RECOG, P651
NR 20
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7175
EP 7191
DI 10.1007/s11042-019-7657-6
EA DEC 2019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664300004
DA 2024-07-18
ER

PT J
AU Wang, YH
   Zhang, HH
   Wang, NN
   Ning, XJ
   Zhao, YN
   Wang, LJ
   Lv, K
AF Wang, Yinghui
   Zhang, Huanhuan
   Wang, Ningna
   Ning, Xiaojuan
   Zhao, Yanni
   Wang, Lijuan
   Lv, Ke
TI Rotational-guided optimal cutting-plane extraction from point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rotational-guided; Point cloud; Optimal cutting-plane; Rotation axis
ID SLICING PROCEDURE; RECONSTRUCTION
AB This paper presents a simple yet powerful rotational-guided optimal cutting-plane extraction method which can provide an effective way for skeleton extraction, simplification, surface reconstruction and boundary extraction. The optimal cutting-planes can be obtained by several steps: calculating the cutting-points and initial cutting-plane, rotating reference cutting-plane on each cutting-point along the given rotation axis to generate a group of cutting-planes, calculating the area of these planes and selecting the plane with the smallest projected area. The primary advantage of the proposed method is that it does neither place strong requirements on the quality of input point cloud nor on the geometry of captured shapes. The experimental results demonstrate that our method can extract the optimal cutting-planes effectively for an unoriented raw point cloud model, even in the presence of noise and missing data.
C1 [Wang, Yinghui; Zhang, Huanhuan; Ning, Xiaojuan; Zhao, Yanni; Wang, Lijuan] Xian Univ Technol, Inst Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Wang, Yinghui; Ning, Xiaojuan] Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Shaanxi, Peoples R China.
   [Zhang, Huanhuan] Xian Polytech Univ, Inst Elect & Informat, Xian 710048, Shaanxi, Peoples R China.
   [Wang, Ningna] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75080 USA.
   [Lv, Ke] Univ Chinese Acad Sci, 19 Beijing Yuquan Rd, Beijing 100049, Peoples R China.
C3 Xi'an University of Technology; Xi'an Polytechnic University; University
   of Texas System; University of Texas Dallas; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Zhang, HH (corresponding author), Xian Univ Technol, Inst Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.; Zhang, HH (corresponding author), Xian Polytech Univ, Inst Elect & Informat, Xian 710048, Shaanxi, Peoples R China.
EM zhanghuanhuan0557@163.com
RI wang, yinghui/GWV-7334-2022
OI Zhang, Huanhuan/0000-0001-5745-1775
FU National Key R&D Program of China [2018YFB1004905]; National Natural
   Science Foundation of China [61872291, 61902302, 61871320]; Shaanxi
   Natural Science Foundation [2017JQ6023]; Shaanxi Provincial Education
   Department [18JS077]
FX This work is supported in part by National Key R&D Program of China
   under Grant No. 2018YFB1004905; in part by National Natural Science
   Foundation of China under Grant No.61872291, No.61902302, No.61871320;
   in part by Shaanxi Natural Science Foundation under Grant No.
   2017JQ6023; in part by Scientific Research Program Funded by Shaanxi
   Provincial Education Department under Grant No. 18JS077. We would like
   to thank the author (Huang H [31]) to share their scanned models in this
   paper.
CR Adhikary N, 2016, COMPUT AIDED DES APP, V13, P587, DOI [10.1080/16864360.2016.1150703, DOI 10.1080/16864360.2016.1150703]
   Ding DH, 2016, ROBOT CIM-INT MANUF, V37, P139, DOI 10.1016/j.rcim.2015.09.002
   Fang Fang, 2013, Geomatics and Information Science of Wuhan University, V38, P1353
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   [官亚勤 Guan Yaqin], 2016, [计算机应用, Journal of Computer Applications], V36, P1793
   Heng Liu, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P224, DOI 10.1109/ICCRD.2011.5763900
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Huang KW, 2006, J SYST SIMUL, V18, P52
   Javidrad F, 2011, ROBOT CIM-INT MANUF, V27, P397, DOI 10.1016/j.rcim.2010.08.008
   Kulkarni P, 1996, COMPUT AIDED DESIGN, V28, P683, DOI 10.1016/0010-4485(95)00083-6
   Li M, 2010, IEEE INT C COMP AID, P919
   Lin HW, 2005, VISUAL COMPUT, V21, P418, DOI 10.1007/s00371-005-0304-4
   Liu GH, 2003, J MATER PROCESS TECH, V138, P53, DOI 10.1016/S0924-0136(03)00048-7
   Nagai Y, 2015, COMPUT GRAPH-UK, V46, P55, DOI 10.1016/j.cag.2014.09.034
   Oropallo W, 2017, COMP AIDED DES APPL, V4, P1
   Park HT, 2007, P 2007 SUMM COMP SIM, P24
   Sareen KK, 2010, SCI TECHNOL HUM, P6
   Sui W, 2016, IEEE T VIS COMPUT GR, V22, P1261, DOI 10.1109/TVCG.2015.2505296
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Timmerman M.E., 2003, Journal of the American Statistical Association, V98, P1082
   Wang GL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1717, DOI 10.1109/ROBIO.2015.7419019
   Wang YH, 2018, IEEE ACCESS, V6, P18299, DOI 10.1109/ACCESS.2018.2798640
   Wang YH, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.12.123111
   Wu YF, 2004, COMPUT AIDED DESIGN, V36, P231, DOI 10.1016/S0010-4485(03)00097-6
   Xiao W., 2014, SENS TRANS, V173, P197
   [杨振清 Yang Zhenqing], 2014, [计算机应用与软件, Computer Applications and Software], V31, P222
   Zeng L, 2011, COMPUT AIDED DESIGN, V43, P1577, DOI 10.1016/j.cad.2011.06.007
   Zhang S, 2009, J JIANGSU U SCI TECH, V23, P403
   Zhang YF, 2003, J MATER PROCESS TECH, V140, P105, DOI 10.1016/S0924-0136(03)00824-0
   Zhong S., 2014, COMPUT AIDED DES APP, V11, P20
NR 30
TC 2
Z9 2
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7135
EP 7157
DI 10.1007/s11042-019-08339-w
EA DEC 2019
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000503664300005
DA 2024-07-18
ER

PT J
AU Anusha, R
   Jaidhar, CD
AF Anusha, R.
   Jaidhar, C. D.
TI Clothing invariant human gait recognition using modified local optimal
   oriented pattern binary descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature extraction; Gait recognition; Human
   identification
ID IDENTIFICATION; REPRESENTATION; TEMPLATE; IMAGE
AB Human gait is a behavioral characteristic which has received a large amount of consideration in recent times as a biometric identifier. The clothing variance is one of the most common covariate influences which can influence the performance of gait recognition approach in real-world scenarios. This paper proposes a gait recognition approach proficient in choosing information characteristics for individual identification under different clothing conditions. The proposed method constitutes of addressing the feature extraction technique by introducing a binary descriptor called as Modified Local Optimal Oriented Pattern (MLOOP). In the proposed approach, initially, the feature vectors such as histogram and horizontal width vector are extracted from MLOOP descriptor, and then the dimensionality of the feature vector is reduced to remove the irrelevant features. The performance of MLOOP was accessed against its predecessors. Obtained experimental results demonstrate that the MLOOP descriptor performs better than the previous binary descriptors. Furthermore, the performance analysis of the proposed approach was assessed on OU-ISIR B treadmill gait database and CASIA B gait database. Broad investigations demonstrate the viability of the proposed technique.
C1 [Anusha, R.; Jaidhar, C. D.] Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Anusha, R (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Surathkal 575025, India.
EM it16fv01.anusha@nitk.edu.in; jaidharcd@nitk.edu.in
FU Visvesvaraya PhD Scheme, MeitY, Government of India
FX We convey our genuine gratitude to Prof Yasushi Yagi, Osaka University
   Japan and his whole research group for providing us, OU-ISIR Treadmill
   Gait database [26]. We thank the team behind The Institute of
   Automation, Chinese Academy of Sciences (CASIA) for sharing CASIA gait
   database [44], in the absence of which the experiments might not have
   been done. This work is supported by Visvesvaraya PhD Scheme, MeitY,
   Government of India.
CR Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   [Anonymous], INT C INF EL VIS ICI
   [Anonymous], 2006, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI DOI 10.1109/TPAMI.2006.38
   [Anonymous], CASIA GAIT DATABASE
   Bashir K., 2009, BMVC, P1
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Boulgouris NV, 2007, IEEE T IMAGE PROCESS, V16, P731, DOI 10.1109/TIP.2007.891157
   Boulgouris NV, 2006, PATTERN RECOGN, V39, P969, DOI 10.1016/j.patcog.2005.10.013
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Cuntoor N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P113
   Das Choudhury S, 2016, PATTERN RECOGN LETT, V80, P1, DOI 10.1016/j.patrec.2016.05.009
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   Deng M, 2018, IEEE CAA J AUTOMATIC
   Ding T., 2008, P IEEE C COMPUTER VI, P1
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   El Gayar N, 2006, LECT NOTES ARTIF INT, V4087, P67
   Ghebleh A, 2018, MULTIMED TOOLS APPL, P1
   Isaac ERHP, 2017, IEEE SIGNAL PROC LET, V24, P1188, DOI 10.1109/LSP.2017.2715179
   Islam MS, 2013, 2013 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL ENGINEERING (ICAEE 2013), P411, DOI 10.1109/ICAEE.2013.6750373
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lishani AO, 2018, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-016-4205-5
   Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Lo Presti Liliana, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P26, DOI 10.1109/CVPRW.2015.7301351
   Lublinerman R, 2006, INT C PATT RECOG, P347
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   Nandy A, 2017, MULTIMED TOOLS APPL, V76, P9133, DOI 10.1007/s11042-016-3505-0
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Prakash C, 2015, INT CONF CONTEMP, P190, DOI 10.1109/IC3.2015.7346677
   Rida I, 2016, IEEE SIGNAL PROC LET, V23, P154, DOI 10.1109/LSP.2015.2507200
   Rida I, 2016, SIGNAL IMAGE VIDEO P, V10, P463, DOI 10.1007/s11760-015-0766-4
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Shiraga Kohei, 2016, ICB, P1, DOI DOI 10.1109/ICB.2016.7550060
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Yuanyuan Zhang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P256
   Zhang SW, 2018, MULTIMED TOOLS APPL, V77, P12331, DOI 10.1007/s11042-017-4884-6
NR 44
TC 20
Z9 21
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2873
EP 2896
DI 10.1007/s11042-019-08400-8
EA DEC 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500319500003
DA 2024-07-18
ER

PT J
AU Wang, XH
   Zhang, JJ
AF Wang, Xiuhui
   Zhang, Jiajia
TI Gait feature extraction and gait classification using two-branch CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait classification; Deep learning; Convolution neural network (CNN);
   Support vector machine (SVM); Gait energy image (GEI); Multi-frequency
   gait energy image (MF-GEI)
ID RECOGNITION; PERFORMANCE
AB As a promising biometric identification method, gait recognition has many advantages, such as suitable for human identification at a long distance, requiring no contact and hard to imitate. However, due to the complex external factors in the gait data sampling process and the clothing changes of the person to be identified, gait recognition still faces numerous challenges in practical applications. In this paper, we present a novel solution for gait feature extraction and gait classification. Firstly, two kinds of Two-branch Convolution Neural Network (TCNN), i.e., middle-fusion TCNN and last-fusion TCNN, to improve the correct recognition rate of gait recognition are presented. Secondly, we construct Multi-Frequency Gait Energy Images (MF-GEIs) to train the proposed TCNNs networks and then extract refined gait features using the trained TCNNs. Finally, the output of each TCNN is utilized to train an SVM gait classifier separately which will be used for gait classification and recognition. In addition, the proposed solution is measured on CASIA dataset B and OU-ISIR LP dataset. Both experimental results show that our solution outperforms various existing methods.
C1 [Wang, Xiuhui; Zhang, Jiajia] China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Wang, XH (corresponding author), China Jiliang Univ, Coll Informat Engn, Key Lab Electromagnet Wave Informat Technol & Met, 258 Xueyuan St, Hangzhou 310018, Zhejiang, Peoples R China.
EM wangxiuhui@cjlu.edu.cn
OI Wang, Xiuhui/0000-0003-1773-9760
FU National Natural Science Foundation of China [61303146, 61602431]
FX This work is supported by the National Natural Science Foundation of
   China under grants No. 61303146 and No. 61602431.
CR Abdulsattar F, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA), DOI 10.1109/ISBA.2016.7477229
   Ariyanto G, 2011, INTERNATIONAL CONFER
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Connie T, 2017, IEEE T CYBERNETICS, V47, P1395, DOI 10.1109/TCYB.2016.2545693
   DELONG ER, 1988, BIOMETRICS, V44, P837, DOI 10.2307/2531595
   Gaur S., 2012, INT J ADV RES ELECT, V1, P282
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hinton G. E., 2012, 12070580 ARXIV
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jia N, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P774, DOI 10.1109/BTAS.2017.8272769
   Kusakunniran Worapan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1058, DOI 10.1109/ICCVW.2009.5457587
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XL, 2018, IEEE T NEUR NET LEAR, V29, P1454, DOI 10.1109/TNNLS.2017.2672978
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Mahfouf Z, 2018, NEUROCOMPUTING, V283, P140, DOI 10.1016/j.neucom.2017.12.040
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mengdie Chu, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P605, DOI 10.1007/978-3-319-69923-3_65
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Theekhanont P., 2012, Proceedings of the 2012 International Symposium on Information Technology in Medicine and Education (ITME 2012), P936, DOI 10.1109/ITiME.2012.6291457
   Uddin MS, 2018, FRONT AGING NEUROSCI, V10, DOI 10.3389/fnagi.2018.00004
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
   Wang X, 2019, MATTER, V1, P1, DOI DOI 10.1016/J.NEUROBIOLAGING.2018.11.025
   Wang XH, 2018, MULTIMED TOOLS APPL, V77, P12545, DOI 10.1007/s11042-017-4903-7
   [王修晖 Wang Xiuhui], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P709
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu S, 2020, IEEE T CIRC SYST VID, V30, P2057, DOI 10.1109/TCSVT.2019.2905373
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang R, 2012, IEEE T NEUR NET LEAR, V23, P330, DOI 10.1109/TNNLS.2011.2178315
NR 43
TC 11
Z9 12
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2917
EP 2930
DI 10.1007/s11042-019-08509-w
EA DEC 2019
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000500319500001
DA 2024-07-18
ER

PT J
AU Bost, X
   Gueye, S
   Labatut, V
   Larson, M
   Linares, G
   Malinas, D
   Roth, R
AF Bost, Xavier
   Gueye, Serigne
   Labatut, Vincent
   Larson, Martha
   Linares, Georges
   Malinas, Damien
   Roth, Raphael
TI Remembering winter was coming Character-oriented video summaries of TV
   series
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Extractive summarization; TV series; Plot analysis; Dynamic social
   network
ID SEGMENTATION; ALGORITHM
AB Today's popular TV series tend to develop continuous, complex plots spanning several seasons, but are often viewed in controlled and discontinuous conditions. Consequently, most viewers need to be re-immersed in the story before watching a new season. Although discussions with friends and family can help, we observe that most viewers make extensive use of summaries to re-engage with the plot. Automatic generation of video summaries of TV series' complex stories requires, first, modeling the dynamics of the plot and, second, extracting relevant sequences. In this paper, we tackle plot modeling by considering the social network of interactions between the characters involved in the narrative: substantial, durable changes in a major character's social environment suggest a new development relevant for the summary. Once identified, these major stages in each character's storyline can be used as a basis for completing the summary with related sequences. Our algorithm combines such social network analysis with filmmaking grammar to automatically generate character-oriented video summaries of TV series from partially annotated data. We carry out evaluation with a user study in a real-world scenario: a large sample of viewers were asked to rank video summaries centered on five characters of the popular TV series Game of Thrones, a few weeks before the new, sixth season was released. Our results reveal the ability of character-oriented summaries to re-engage viewers in television series and confirm the contributions of modeling the plot content and exploiting stylistic patterns to identify salient sequences.
C1 [Bost, Xavier] Orkis, SAS, F-13290 Aix En Provence, France.
   [Bost, Xavier; Gueye, Serigne; Labatut, Vincent; Linares, Georges] Avignon Univ, Lab Informat Avignon, F-84000 Avignon, France.
   [Larson, Martha] Delft Univ Technol, Intelligent Syst Dept, Delft, Netherlands.
   [Larson, Martha] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.
   [Larson, Martha] Radboud Univ Nijmegen, Inst Comp & Informat Sci, Nijmegen, Netherlands.
   [Malinas, Damien; Roth, Raphael] Avignon Univ, Ctr Norbert Elias, F-84000 Avignon, France.
C3 Avignon Universite; Delft University of Technology; Radboud University
   Nijmegen; Radboud University Nijmegen; Avignon Universite
RP Bost, X (corresponding author), Orkis, SAS, F-13290 Aix En Provence, France.; Bost, X (corresponding author), Avignon Univ, Lab Informat Avignon, F-84000 Avignon, France.
EM xbost@orkis.com; serigne.gueye@univ-avignon.fr;
   vincent.labatut@univ-avignon.fr; m.a.larson@tudelft.nl;
   georges.linaress@univ-avignon.fr; damien.malinas@univ-avignon.fr;
   raphael.roth@univ-avignon.fr
RI Labatut, Vincent/F-9873-2010; Larson, Martha/E-9983-2014
OI Labatut, Vincent/0000-0002-2619-2835; Bost, Xavier/0000-0002-5624-8721;
   Gueye, Serigne Abdoulaye/0000-0001-7217-8543; ROTH,
   Raphael/0000-0003-4256-0105
FU Research Federation Agorantic, Avignon University
FX This work was supported by the Research Federation Agorantic, Avignon
   University.
CR [Anonymous], 2016, THESIS
   [Anonymous], 2012, P 10 INT WORKSHOP CO
   [Anonymous], 2010, P 18 ACM INT C MULTI
   [Anonymous], P 6 ACM SIGMM INT WO, DOI [10.1145/1026711.1026752, DOI 10.1145/1026711.1026752]
   BALAS E, 1980, OPER RES, V28, P1130, DOI 10.1287/opre.28.5.1130
   Bost X, 2018, LECT NOTES SOC NETW, P55, DOI 10.1007/978-3-319-78196-9_3
   Bost X, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1111, DOI 10.1109/ASONAM.2016.7752379
   Bredin Herve, 2016, ACM MULTIMEDIA, P157
   Daskin M.S., 1995, Network and Discrete Location, Network and Discrete Location, DOI [DOI 10.1002/9781118032343, 10.1002/9781118032343.]
   FAYARD D, 1982, COMPUTING, V28, P269, DOI 10.1007/BF02241754
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Friedland G, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P511, DOI 10.1109/ISM.2009.20
   Giannakopoulos T, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P954
   Gillick Dan, 2009, Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing, P10
   Guha T, 2015, INT CONF ACOUST SPEE, P2264, DOI 10.1109/ICASSP.2015.7178374
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Lartillot O, 2008, ST CLASS DAT ANAL, P261, DOI 10.1007/978-3-540-78246-9_31
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   Smeaton A. F., 2006, P 8 ACM INT WORKSHOP, P231
   Smith JR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1799, DOI 10.1145/3123266.3127906
   Tapaswi M, 2014, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2014.111
   Tsoneva T, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P169, DOI 10.1109/ICSC.2007.42
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
NR 27
TC 10
Z9 10
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35373
EP 35399
DI 10.1007/s11042-019-07969-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800051
DA 2024-07-18
ER

PT J
AU Calefato, F
   Castellano, G
   Rossano, V
AF Calefato, Fabio
   Castellano, Giovanna
   Rossano, Veronica
TI RECODE: revision control for digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia design; Image editing; Revision control; Collaborative
   design; Digital painting
AB Revision control is a vital component in the collaborative development of artifacts such as software code and multimedia. While revision control has been widely deployed for text files, very few attempts to control the versioning of binary files can be found in the literature. This can be inconvenient for multimedia applications that use a significant amount of binary data, such as images, videos, meshes, and animations. Existing strategies such as storing whole files for individual revisions or simple binary deltas, respectively consume significant storage and complex semantic information. To overcome these limitations, in this paper we present RECODE, a revision control system for digital images. It stores revisions in the form of a DAG (directed acyclic graph) where nodes represent editing operations, and edges describe the spatial and temporal relationships between operations. Being integrated with GitHub, the largest project hosting platform, RECODE also facilitates the artistic creation process of distributed teams with different workflows that include image editing and digital painting. A preliminary user study was performed to assess the perceived usability of the proposed system.
C1 [Calefato, Fabio; Castellano, Giovanna; Rossano, Veronica] Univ Bari, Comp Sci Dept, Via Orabona 4, I-70125 Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP Castellano, G (corresponding author), Univ Bari, Comp Sci Dept, Via Orabona 4, I-70125 Bari, Italy.
EM fabio.calefato@uniba.it; giovanna.castellano@uniba.it;
   veronica.rossano@uniba.it
RI Calefato, Fabio/H-4177-2014; Castellano, Giovanna/J-5877-2012; rossano,
   veronica/AAQ-2433-2020
OI Calefato, Fabio/0000-0003-2654-1588; Castellano,
   Giovanna/0000-0002-6489-8628; rossano, veronica/0000-0002-4079-9641
FU project "Creative Cultural Collaboration" (C3) under the Apulian
   INNONETWORK programme, Italy
FX This work is partially funded by the project "Creative Cultural
   Collaboration" (C3) under the Apulian INNONETWORK programme, Italy.
CR [Anonymous], 2018, LIN GUID DES SERV WE
   [Anonymous], GRAPHS THEORY ALGORI
   Bang-Jensen J, 2009, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-1-84800-998-1_1
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bonanni L, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P571
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Calefato F, 2018, IEEE INT CON INF VIS, P512, DOI 10.1109/iV.2018.00095
   Chen CW, 2018, LECT NOTES COMPUT SC, V10705, P386, DOI 10.1007/978-3-319-73600-6_38
   Chen HT, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1965000
   Claman TH, 2018, us patent, Patent No. 9864973
   da Silva JR, 2016, SOFTWARE PRACT EXPER, V46, P1011, DOI 10.1002/spe.2340
   Dobos J, 2012, EUROGRAPHICS
   Dobos J, 2012, WEB3D 2012, P121
   Grisaffe D.B., 2007, Journal of Consumer Satisfaction, Dissatisfaction and Complaining Behavior, V20, P36
   Hunt JJ, 1998, ACM T SOFTW ENG METH, V7, P449
   Kleine M, 2012, ABSTRACTION VERSION
   Nielsen JV, 2012, DIABETOL METAB SYNDR, V4, DOI 10.1186/1758-5996-4-23
   O'Sullivan B., 2009, Queue, V7, P30, DOI DOI 10.1145/1600000/1595636/P30OSULLIVAN.PDF?KEY1=1595636&KEY2=01447086!26COLL=GUIDE&DL=GUIDE&CFID=81018117&CFTOKEN=10948435
   Ruparelia N.B., 2010, SIGSOFT SOFTW ENG NO, V35, P5, DOI DOI 10.1145/1668862.1668876
   Schuler D., 1993, Participatory Design: Principles and Practices
   Slaughter DS, 2018, EDUC COMMUN TECHNOL, P253, DOI 10.1007/978-3-319-61780-0_18
   Wang ZH, 2014, I C VIRTUAL REALITY, P73, DOI 10.1109/ICVRV.2014.53
   Zhao ZP, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1235, DOI 10.1145/2556288.2557394
NR 23
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33169
EP 33188
DI 10.1007/s11042-019-7735-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600025
DA 2024-07-18
ER

PT J
AU Deb, S
   Biswas, B
   Bhuyan, B
AF Deb, Subhrajyoti
   Biswas, Bhaskar
   Bhuyan, Bubu
TI Secure image encryption scheme using high efficiency word-oriented
   feedback shift register over finite field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; wfsr; NPCR; UACI; ECDH; NIST randomness test
ID CHAOTIC SYSTEM; ELLIPTIC CURVE; ALGORITHM; CRYPTANALYSIS; MAP
AB Image encryption is an evolving technique in the arena of data communication. In the last decade, many encryption schemes have been suggested. Unfortunately, most of the current schemes are unable to maintain a balance between security and computational complexity. To overcome this challenge, this paper introduces a novel encryption scheme that effectively maintains the trade-off between security and computational complexity. Initially, the plain image is randomized and scrambled by the Logistic map and Arnold's scrambling technique. The intermediate image found above, is then encrypted by the special word-oriented feedback shift register (wfsr) to get the final cipher image. Wfsr is inherently suitable for high-quality pseudorandom number generation with good statistical properties. It usually posses high throughput. Further, the elliptic curve Diffie-Hellman (ECDH) is used for sharing the keys required for encryption and decryption process. The performance of the proposed cryptosystem is evaluated based on several statistical properties of the cipher image, the resistance of the cipher image to various attacks, and time required for encryption and key sharing process. The statistical properties of the encrypted image are found out through histogram analysis, correlation and entropy finding, key sensitivity analysis, chi-square test, and NIST randomness test. The resistance of the encrypted image to various attacks is either found out experimentally or indirectly by using metrics like Unified Average Changing Intensity (UACI), Number of Pixel Changing Rate (NPCR). The proposed encryption method compares favorably with similar image encryption schemes.
C1 [Deb, Subhrajyoti; Bhuyan, Bubu] NE Hill Univ, Dept Informat Technol, Shillong, Meghalaya, India.
   [Biswas, Bhaskar] Tripura Univ, Dept Informat Technol, Suryamaninagar, India.
C3 North Eastern Hill University; Tripura University
RP Deb, S (corresponding author), NE Hill Univ, Dept Informat Technol, Shillong, Meghalaya, India.
EM subhrajyotideb1@gmail.com
RI Deb, Dr. Subhrajyoti/AAX-8520-2021
OI Deb, Dr. Subhrajyoti/0000-0001-6939-0113
CR Abd El-Latif AA, 2019, OPT LASER TECHNOL, V116, P92, DOI 10.1016/j.optlastec.2019.03.005
   Abd El-Latif AA, 2013, PROC SPIE, V8878, DOI 10.1117/12.2031074
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Aissa B, 2013, NEW TRENDS MATH SCI, V1, P10
   Akhavan A, 2015, OPT COMMUN, V350, P77, DOI 10.1016/j.optcom.2015.03.079
   [Anonymous], 1883, Journal des sciences militaires
   [Anonymous], 2013, IACR CRYPTOLOGY EPRI
   [Anonymous], 2007, IACR CRYPTOLOGY EPRI
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2017, OPT LASER ENG, V88, P37, DOI 10.1016/j.optlaseng.2016.07.010
   Benrhouma O, 2015, SIGNAL IMAGE VIDEO P, V9, P1281, DOI 10.1007/s11760-013-0570-y
   Bishoi SK, 2017, DISCRETE APPL MATH, V222, P67, DOI 10.1016/j.dam.2017.01.033
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Das P, 2015, PROCEDIA COMPUT SCI, V46, P604, DOI 10.1016/j.procs.2015.02.103
   Deb Subhrajyoti, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P631, DOI 10.1007/978-981-10-6890-4_61
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar P, 2016, OPTIK, V127, P2341, DOI 10.1016/j.ijleo.2015.11.188
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Lauter KE, 2008, 2008099 CRYPT EPRINT
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Meenpal T, 2017, J REAL-TIME IMAGE PR, V13, P363, DOI 10.1007/s11554-014-0409-y
   Praveenkumar P, 2018, MULTIMED TOOLS APPL, V77, P8393, DOI 10.1007/s11042-017-4741-7
   Praveenkumar P, 2015, COMPUT BIOL MED, V62, P264, DOI 10.1016/j.compbiomed.2015.04.031
   Roy S, 2018, WIRELESS PERS COMMUN, V98, P2223, DOI 10.1007/s11277-017-4971-z
   Rukhin A., 2001, TECHNICAL REPORT
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SHI ZF, 2012, RES J APPL SCI ENG T, V4, P2887
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P327, DOI 10.4028/www.scientific.net/AMR.981.327
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P372, DOI 10.4028/www.scientific.net/AMR.981.372
   Ul Hasan S, 2018, CRYPTOGR COMMUN, V10, P1075, DOI 10.1007/s12095-017-0265-2
   Wang LM, 2019, APPL MATH COMPUT, V347, P293, DOI 10.1016/j.amc.2018.11.017
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   YE CH, 2012, INT J ADV COMPUTING, V4, P239, DOI DOI 10.1166/SAM.2012.1279
   Zaghloul A, 2014, INT J SECUR APPL, V8, P89, DOI 10.14257/ijsia.2014.8.4.09
   Zaghloul A, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064628
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhao TY, 2015, OPT COMMUN, V338, P64, DOI 10.1016/j.optcom.2014.09.083
NR 47
TC 19
Z9 19
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34901
EP 34925
DI 10.1007/s11042-019-08086-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800030
DA 2024-07-18
ER

PT J
AU Hajarian, M
   Bastanfard, A
   Mohammadzadeh, J
   Khalilian, M
AF Hajarian, Mohammad
   Bastanfard, Azam
   Mohammadzadeh, Javad
   Khalilian, Madjid
TI SNEFL: Social network explicit fuzzy like dataset and its application
   for Incel detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dataset; Social network; Fuzzy like; Social media; Incel detection;
   Involuntary celibate
ID LONELINESS
AB In this paper, with respect to reviewing and comparing existing social networks' datasets, we introduce SNEFL dataset: the first social network dataset that includes the level of users' likes (fuzzy like) data in addition to the likes between users. With users' privacy in mind, the data has been collected from a social network. It includes several additional features including age, gender, marital status, height, weight, educational level and religiosity of the users. We have described its structure, analysed its features and evaluated its advantages in comparison with other social network datasets. On top of that, using unique feature of SNEFL dataset (fuzzy like) for the first time a rule-based algorithm has been developed to detect involuntary celibates (Incels) in social networks. Despite Incels activities in online social networks, until now no study on computer science has been performed to identify them. This study is the first step to address this challenge that society is facing today. Experimental results show that the accuracy of the proposed algorithm in identifying Incels among all social network users is 23.21% and among users who have fuzzy like data is 68.75%. In addition to the Incel detection, SNEFL dataset can be used by researchers in different fields to produce more accurate results. Some study areas that SNEFL dataset can be used in are network analysis, frequent pattern mining, classification and clustering.
C1 [Hajarian, Mohammad; Bastanfard, Azam; Mohammadzadeh, Javad; Khalilian, Madjid] Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
C3 Islamic Azad University
RP Hajarian, M; Bastanfard, A (corresponding author), Islamic Azad Univ, Karaj Branch, Dept Comp Engn, Karaj, Iran.
EM MainSystem@yahoo.com; bastanfard@kiau.ac.ir
RI Mohammadzadeh, Javad/AEJ-7749-2022; Hajarian, Mohammad/AAF-4215-2021;
   Bastanfard, Azam/AAX-8571-2020; Mohammadzadeh, Javad/AAN-5691-2021;
   khalilian, madjid/AAD-3267-2021; khalilian, madjid/AAM-9725-2020
OI Hajarian, Mohammad/0000-0001-9863-2679; Bastanfard,
   Azam/0000-0002-7935-819X; Mohammadzadeh, Javad/0000-0003-1889-0294;
   khalilian, madjid/0000-0001-5479-7033
CR Althoff T, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P34, DOI 10.1145/2736277.2741120
   Anderson A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P66, DOI 10.1145/2736277.2741672
   [Anonymous], 2008, Time
   [Anonymous], 2018, ARXIV180203997
   [Anonymous], 2018, NBC News
   [Anonymous], 2018, NEW SCI
   Bachrach Y, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1649
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bi B., 2013, P 22 INT C WORLD WID, P131, DOI DOI 10.1145/2488388.2488401
   Blommaert J., 2017, Online-Offline Modes of Identity and Community: Elliot Rodger's Twisted World of Masculine Victimhood
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Buccafurri F, 2013, ANN CONF PRIV SECUR, P36, DOI 10.1109/PST.2013.6596034
   Burke M, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1909
   Burrow AL, 2017, J EXP SOC PSYCHOL, V69, P232, DOI 10.1016/j.jesp.2016.09.005
   Cacioppo S, 2015, PERSPECT PSYCHOL SCI, V10, P238, DOI 10.1177/1745691615570616
   Cheng J., 2015, ARXIV150400680
   Correa T, 2010, COMPUT HUM BEHAV, V26, P247, DOI 10.1016/j.chb.2009.09.003
   Domènech-Abella J, 2017, SOC PSYCH PSYCH EPID, V52, P381, DOI 10.1007/s00127-017-1339-3
   Erlandsson F, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120686
   Erlandsson F, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18050164
   Erlandsson F, 2015, SECOND EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC 2015), P9, DOI 10.1109/ENIC.2015.10
   Evoli C, 2014, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2014/11/024
   Fortna VP, 2015, INT ORGAN, V69, P519, DOI 10.1017/S0020818315000089
   Ging D, 2019, MEN MASC, V22, P638, DOI 10.1177/1097184X17706401
   Hajarian M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0589-3
   Hajarian M, 2017, COMPUT HUM BEHAV, V77, P282, DOI 10.1016/j.chb.2017.08.046
   Hallac D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P387, DOI 10.1145/2783258.2783313
   Jin X, 2018, MULTIMED TOOLS APPL, P1
   Khandelwal A, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1149, DOI 10.1145/3035918.3064012
   Kim AY, 2015, J STAT EDUC, V23, DOI 10.1080/10691898.2015.11889737
   Kunegis J., 2009, P 18 INT C WORLD WID, P741, DOI DOI 10.1145/1526709.1526809
   Leskovec J., 2010, P 19 INT C WORLD WID, P641
   Leskovec J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1361
   Matz S. C., 2017, P NAT ACAD SCI
   McAuley J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2783258.2783381
   Meyffret S, 2012, THESIS
   Nagle A., 2016, BAFFLER, V30, P64
   Narayanan A, 2009, P IEEE S SECUR PRIV, P173, DOI 10.1109/SP.2009.22
   Nazir F, 2018, MULTIMED TOOLS APPL, P1
   Nia R, 2012, PROCEEDINGS OF THE 2012 ASE INTERNATIONAL CONFERENCE ON SOCIAL INFORMATICS (SOCIALINFORMATICS 2012), P205, DOI 10.1109/SocialInformatics.2012.29
   Parand FA, 2016, COMBINING FUZZY LOGI
   Pittman M, 2016, COMPUT HUM BEHAV, V62, P155, DOI 10.1016/j.chb.2016.03.084
   Pizzato L, 2013, USER MODEL USER-ADAP, V23, P447, DOI 10.1007/s11257-012-9125-0
   Popescu A, 2015, AMST PRIV C, P23
   Raj ED, 2017, NEUROCOMPUTING, V219, P412, DOI 10.1016/j.neucom.2016.09.036
   Ruan ZC, 2018, MULTIMED TOOLS APPL, V77, P11459, DOI 10.1007/s11042-017-5495-y
   Stillwell D. J., 2012, AM PSYCHOL, V59, P93
   Subbian K, 2016, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2815625
   Tiwari A, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3115433
   West R, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1242, DOI 10.1145/2736277.2741666
   Wu YY, 2015, P NATL ACAD SCI USA, V112, P1036, DOI 10.1073/pnas.1418680112
   Yang J, 2015, KNOWL INF SYST, V42, P181, DOI 10.1007/s10115-013-0693-z
   Zhao QY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1513, DOI 10.1145/2783258.2783401
NR 53
TC 12
Z9 12
U1 2
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33457
EP 33486
DI 10.1007/s11042-019-08057-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600041
DA 2024-07-18
ER

PT J
AU Ma, M
   Song, HB
AF Ma, Ming
   Song, Houbing
TI Effective moving object detection in H.264/AVC compressed domain for
   video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion segmentation; Compressed domain; H.264/ AVC; Video surveillance
ID SEGMENTATION
AB In this paper a novel approach is presented to detect moving object in H.264/AVC compressed domain for video surveillance applications. The proposed algorithm utilizes the information from the H.264 compressed bit stream to reduce the computational complexity and memory requirements. In order to exploit the spatial and temporal consistency of moving object, a Markov Random Field (MRF) model is employed to detect and segment moving object based on motion vectors and quantization parameters (QP). The size of the blocks (in bits) are also used to improve the detection result. Experiments show good performance achieved by the algorithm, and the moving object can be detected effectively from the compressed video sequence.
C1 [Ma, Ming] Inner Mongolia Univ, Coll Comp Sci, Hohhot 010012, Peoples R China.
   [Song, Houbing] Embry Riddle Aeronaut Univ, Dept Elect Comp Software & Syst Engn, Daytona Beach, FL 32114 USA.
C3 Inner Mongolia University; Embry-Riddle Aeronautical University
RP Song, HB (corresponding author), Embry Riddle Aeronaut Univ, Dept Elect Comp Software & Syst Engn, Daytona Beach, FL 32114 USA.
EM csmaming@imu.edu.cn; h.song@ieee.org
RI song, hu/JVO-3838-2024; Song, Houbing Herbert/E-3628-2010
OI Song, Houbing Herbert/0000-0003-2631-9223
FU Natural Science Foundation of Inner Mongolia of China [2014BS0602];
   Program of High-Level Talents of Inner Mongolia University (SPH-IMU)
FX The research is supported by the Natural Science Foundation of Inner
   Mongolia of China (No. 2014BS0602) and the Program of High-Level Talents
   of Inner Mongolia University (SPH-IMU).
CR [Anonymous], 2001, COMP SCI W
   Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Biswas S, 2015, MULTIMED TOOLS APPL, V74, P11099, DOI 10.1007/s11042-014-2219-4
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Cuevas C, 2015, I SYMP CONSUM ELECTR, P15, DOI 10.1109/ICCE.2015.7066301
   De Praeter Johan, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P135, DOI 10.1109/ICCE.2017.7889258
   Kapotas S. K., 2010, 2010 IEEE INT C IMAG, P325
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Konda KR, 2017, IEEE INT S BROADB MU, P1
   Laumer M, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P282, DOI 10.1109/PCS.2015.7170091
   LIU L, 2008, IM SIGN PROC CISP 08, V3, P605
   LIU S, 2017, FRACTALS, V25, P12
   Mak CM, 2009, IET IMAGE PROCESS, V3, P272, DOI 10.1049/iet-ipr.2008.0093
   Moridani Ahad Karimi, 2015, International Journal of Imaging & Robotics, V15, P45
   Moriyama M, 2015, I S INTELL SIG PROC, P48, DOI 10.1109/ISPACS.2015.7432735
   Pan Z., 2017, MULTIMED TOOLS APPL, V76, P1
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P428, DOI 10.1016/j.jvcir.2009.05.001
   Szczerba K, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P478, DOI 10.1109/AVSS.2009.78
   Tom M., 2013, 2013 4 NATL C COMPUT, P1
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
   Zhao L, 2018, IEEE T SYST MAN CY-S, V48, P2003, DOI 10.1109/TSMC.2017.2743696
NR 23
TC 6
Z9 7
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35195
EP 35209
DI 10.1007/s11042-019-08145-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800043
DA 2024-07-18
ER

PT J
AU Sabbane, F
   Tairi, H
AF Sabbane, Fadoua
   Tairi, Hamid
TI Medical image watermarking technique based on polynomial decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Watermarking; Robustness; Polynomial transform; Texture
   extraction; Structure extraction
ID HIGH-CAPACITY; REVERSIBLE WATERMARKING; SCHEME; RECOGNITION; TRANSFORM;
   MOMENTS
AB To date, the exchange and storage of medical data on electronic format are subject to potential risks. Hence, considerations of security and copyright protection of medical images are necessary and unavoidable. In such a situation, a watermarking scheme is proposed as one of the most promising methods to provide security, reliability, and authenticity of medical information. In this work, we propose a new region based medical image watermarking, which consists of embedding numerical information, called a watermark, into the original image. The main originality of this scheme is the use of the polynomial transform to decompose an image into two parts: the structure and the texture components. This mathematical model is used to extract the most relevant embedding areas, containing less information required for diagnosis. The texture component is selected for embedding the watermark so as to preserve fidelity to the original medical image. Compared with the state-of-the-art schemes, experimental results reveal that the proposed scheme can achieve a good compromise with regard to the invisibility and robustness of the watermark.
C1 [Sabbane, Fadoua; Tairi, Hamid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LIIAN Lab, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Sabbane, F (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, LIIAN Lab, Fes, Morocco.
EM sabbane.fadoua@gmail.com; htairi@yahoo.fr
OI Tairi, Hamid/0000-0002-5445-0037
CR Aherrahrou N, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0101-x
   Amakdouf H, 2018, PROCEDIA COMPUT SCI, V127, P226, DOI 10.1016/j.procs.2018.01.118
   Bennett K, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1468
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Da FP, 2010, IMAGE VISION COMPUT, V28, P1645, DOI 10.1016/j.imavis.2010.05.003
   Favorskaya M, 2017, PROCEDIA COMPUT SCI, V112, P1460, DOI 10.1016/j.procs.2017.08.019
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Gangadhar Y, 2018, BIOMED SIGNAL PROCES, V43, P31, DOI 10.1016/j.bspc.2018.02.007
   Ghadi M, ROBUST WATERMARKING, V6
   Gomez-Coronel SL, 2015, CARTAGENA INDIAS
   Kekre DHB, COLUMN ROW DCT WAVEL, V3, P15
   Maalouf A, 2009, IEEE IMAGE PROC, P5, DOI 10.1109/ICIP.2009.5413933
   Moubtahij RE, SPATIAL IMAGE POLYNO, V29
   Mousavi SM, 2015, J DIGIT IMAGING, V28, P417, DOI 10.1007/s10278-015-9770-z
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Murali P, 2018, OPTIK, V170, P242, DOI 10.1016/j.ijleo.2018.04.050
   Pan W, 2018, COMPUT METH PROG BIO, V160, P119, DOI 10.1016/j.cmpb.2018.03.011
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Prasad R, SCALING TRANSLATION, V7
   Sabbane F, 2019, P NEW CHALL DAT SCI, P1
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh A, 2017, INT J MED INFORM, V108, P110, DOI 10.1016/j.ijmedinf.2017.10.010
   Sun YX, 2015, BIOMED SIGNAL PROCES, V18, P80, DOI 10.1016/j.bspc.2014.10.008
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Turuk M, 2018, J DIGIT IMAGING, V31, P167, DOI 10.1007/s10278-017-0024-0
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Wu HY, 2016, NEUROCOMPUTING, V215, P110, DOI 10.1016/j.neucom.2015.05.147
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Zhang H, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030045
NR 34
TC 13
Z9 13
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34129
EP 34155
DI 10.1007/s11042-019-08134-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600068
DA 2024-07-18
ER

PT J
AU Shakiba, A
AF Shakiba, Ali
TI A novel randomized one-dimensional chaotic Chebyshev mapping for chosen
   plaintext attack secure image encryption with a novel chaotic breadth
   first traversal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chebyshev; Chaotic breadth-first search; Chaos
ID SCHEME; MAP; SYSTEM; DESIGN
AB We construct a novel randomized chaotic image encryption algorithm based on the one-dimensional chaotic Chebyshev mappings. We first define a novel chaotic breadth-first search algorithm and then use it to apply the permutation to image pixels. We also use a novel approach to construct the diffusion matrix using a chaotic sequence. Using a one-dimensional chaotic mapping in constructing image encryption algorithm has the advantage of lower computational and space complexities compared to hyper-chaotic encryption schemes. Moreover, our design favors brute-force search attack resistance because of a sufficiently large key space, as well as providing CPA-security and robustness against noise and data loss scenarios. Finally, the security performance of our proposed method is investigated against statistical analysis, key-sensitivity analysis, and differential attack analysis which shows acceptable security.
C1 [Shakiba, Ali] Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
C3 Vali-e-Asr University of Rafsanjan
RP Shakiba, A (corresponding author), Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
EM a.shakiba.iran@gmail.com
RI Shakiba, Ali/J-6420-2016
OI Shakiba, Ali/0000-0002-2253-1166
CR [Anonymous], 2003, P IEEE INT S CIRC SY
   [Anonymous], J KING SAUD U COMPUT
   Bergamo P, 2005, IEEE T CIRCUITS-I, V52, P1382, DOI 10.1109/TCSI.2005.851701
   BRIGGS K, 1990, PHYS LETT A, V151, P27, DOI 10.1016/0375-9601(90)90841-B
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng PG, 2015, NONLINEAR DYNAM, V79, P2121, DOI 10.1007/s11071-014-1798-y
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Gupta K, 2012, ADV ENG SOFTW, V49, P29, DOI 10.1016/j.advengsoft.2012.03.001
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Katz J., 2014, Introduction to modern cryptography
   Khan M, 2015, NONLINEAR DYNAM, V82, P527, DOI 10.1007/s11071-015-2173-3
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li XW, 2015, OPT EXPRESS, V23, P3035, DOI 10.1364/OE.23.003035
   Liao X, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1982, DOI 10.1109/ICASSP.2018.8462384
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HS, 2009, ACTA PHYS SIN-CH ED, V58, P2231, DOI 10.7498/aps.58.2231
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mason J. C., 2003, CHEBYSHEV POLYNOMIAL
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Shakiba A, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501121
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wong KW, 2002, PHYS LETT A, V298, P238, DOI 10.1016/S0375-9601(02)00431-0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XG, 2004, CHAOS SOLITON FRACT, V22, P359, DOI 10.1016/j.chaos.2004.02.008
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2016, INFORM SCIENCES, V349, P137, DOI 10.1016/j.ins.2016.02.041
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
NR 63
TC 21
Z9 23
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34773
EP 34799
DI 10.1007/s11042-019-08071-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800025
DA 2024-07-18
ER

PT J
AU Soliman, RF
   Amin, M
   Abd El-Samie, FE
AF Soliman, Randa F.
   Amin, Mohamed
   Abd El-Samie, Fathi E.
TI Cancelable Iris recognition system based on comb filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Privacy; Iris recognition; Random projection;
   Comb filter
ID BIOMETRICS SCHEME; SECURITY
AB This paper presents a novel scheme for cancelable iris recognition based on comb filtering. This scheme begins with a coarse-to-fine iris localization stage. After that, Gabor filtering is applied for feature extraction. The two-dimensional phase pattern of features generated with the LogGabor filter is distorted through comb filtering. The objective of this distortion process is to generate a cancelable feature pattern that represents the iris. The ability to reinitiate a new cancelable pattern is guaranteed through the variation of the comb filter order. The proposed scheme is compared with a cancelable random projection scheme for iris recognition. Experimental results are conducted on CASIA-IrisV3-Interval database for both random projection and comb filtering schemes. Moreover, evaluation metrics are estimated for different comb filter orders of 6, 8, 10, and 12 in addition to the case of original iris features. Hamming distance and Receiver Operating Characteristic (ROC) curve are estimated for both random projection and comb filtering schemes to check robustness and stability. The experimental results show a significant gain in both privacy and performance. Also, the comb filtering scheme achieves a superior performance for all orders compared to the random projection scheme. The proposed comb filtering scheme achieves the highest accuracy of 99.75% for order 6 and a promising Equal Error Rate (EER) of 0.36% for order 10.
C1 [Soliman, Randa F.; Amin, Mohamed] Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm 32511, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University
RP Soliman, RF (corresponding author), Menoufia Univ, Fac Sci, Math & Comp Sci Dept, Shibin Al Kawm 32511, Egypt.
EM randafouad2010@yahoo.com; mohamed_amin110@yahoo.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; Amin, Mohammed/E-9820-2018
OI Sayed, Fathi/0000-0001-8749-9518; Amin, Mohammed/0000-0001-5091-0641
CR [Anonymous], 2018, 30136 ISOIEC
   [Anonymous], 2017, CASIA IRISV3 DATABAS
   [Anonymous], 2013, Handbook of iris recognition
   [Anonymous], 2008, IEEE 19 INT C PATT R
   Arpit D, 2014, P 31 INT C MACH LEAR, V32
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Choudhury B, 2016, IEEE ST CONF RES DEV
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dwivedi R, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P785, DOI 10.1109/SPIN.2015.7095296
   Evans N, 2015, IEEE SIGNAL PROC MAG, V32, P17, DOI 10.1109/MSP.2015.2443271
   Ferreira JL, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/7901502
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5735, P135, DOI 10.1007/978-3-642-04474-8_11
   Hermand Jean-Pierre, 2014, OCEANS 2014, DOI 10.1109/OCEANS-TAIPEI.2014.6964569
   Jenisch S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3213, DOI 10.1109/ICIP.2011.6116352
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Kuo SM, 2006, REAL TIME SIGNAL PRO
   Lacharme P., 2012, Int. J. Comput. Sci. Softw. Eng. (IJCSSE 2012), V6, P315
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Masek L., 2003, THESIS CITESEER
   Ouda O, 2011, IEICE T INF SYST, VE94D, P1768, DOI 10.1587/transinf.E94.D.1768
   Ouda O, 2010, IEICE T INF SYST, VE93D, P1878, DOI 10.1587/transinf.E93.D.1878
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Punithavathi P., 2017, Biometric Technology Today, V2017, P8, DOI 10.1016/S0969-4765(17)30138-8
   Rahulkar AD, 2012, IEEE T INF FOREN SEC, V7, P230, DOI 10.1109/TIFS.2011.2166069
   Rashid RA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P898, DOI 10.1109/ICCCE.2008.4580735
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathageb C, 2011, EURASIP J INF SECUR, V2011, p3)
   Rathgeb C, 2015, INT CONF BIOMETR, P422, DOI 10.1109/ICB.2015.7139105
   Rathgeb C, 2014, IET BIOMETRICS, V3, P207, DOI 10.1049/iet-bmt.2013.0049
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Soliman NF, 2017, OPTIK, V140, P469, DOI 10.1016/j.ijleo.2016.11.150
   Syarif MA, 2014, LECT NOTES COMPUT SC, V8836, P644, DOI 10.1007/978-3-319-12643-2_78
   Tarek Mayada, 2017, International Journal of Network Security, V19, P498, DOI 10.6633/IJNS.201707.19(4).02
   Tarek M, 2016, IET BIOMETRICS, V5, P220, DOI 10.1049/iet-bmt.2015.0045
   Toplak ME, 2005, BEHAV BRAIN FUNCT, V1, DOI 10.1186/1744-9081-1-8
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wan MH, 2017, MULTIMED TOOLS APPL, V76, P355, DOI 10.1007/s11042-015-3057-8
   Wan MH, 2014, INFORM SCIENCES, V274, P55, DOI 10.1016/j.ins.2014.02.145
NR 45
TC 13
Z9 13
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2521
EP 2541
DI 10.1007/s11042-019-08163-2
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000502127000002
DA 2024-07-18
ER

PT J
AU Tian, LH
   Dai, HT
   Li, C
AF Tian, Lihua
   Dai, Hangtao
   Li, Chen
TI A Semi-fragile Video Watermarking Algorithm Based On Chromatic Residual
   DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H; 264; Chromatic DCT; Video watermark; Prediction mode; Tamper
   detection
ID SCHEME
AB In this paper, a semi fragile video watermarking scheme based on chromatic DCT is proposed, which can protect copyright and tamper detection simultaneously. Firstly, through the experiment, it is found that the chroma block has a more stable prediction mode relative to the luminance block, which can effectively reduce the asynchronous probability brought by the change of the prediction mode. At the same time, blocks contains more the number of nonzero (NNZ) coefficients, the less the prediction mode changes. Therefore, for each macroblock, the algorithm sort its 4 x 4 sub macroblock according to the NNZ of chroma DCT coefficients, then select the sub block which has most NNZ residual coefficients. According to the secret key K and medium frequency stability of Intra 4 x 4 coefficients, modulate the relationship of three DCT coefficients near medium frequency. Secondly, the sensitivity of the prediction mode to malicious attacks and recompression operations is different. Therefore, the algorithm classifies the prediction mode of the macroblock and generates the authentication code using the prediction mode. The experimental results show that the video quality is negligible affected after watermark embedding, and the change of video bit rate is basically constant. At the same time, the chromatic DCT algorithm can also use the authentication code of the prediction mode to detect and locate the tampering at the 4 x 4 sub block level with good robustness.
C1 [Tian, Lihua; Dai, Hangtao; Li, Chen] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Tian, LH (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Shaanxi, Peoples R China.
EM lhtian@mail.xjtu.edu.cn
RI Tian, li/HQY-8623-2023
OI Li, Chen/0000-0003-0527-0547
FU National Natural Science Foundation of China [61901356]; HPC Platform of
   Xi'an Jiaotong University
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61901356 and the HPC Platform of Xi'an Jiaotong
   University.
CR Afanasyeva A, 2014, INT C IMAGE PROCESSI, P1
   Bhattacharya A, 2013, INT CONF IMAG VIS, P489, DOI 10.1109/IVCNZ.2013.6727063
   Chen Xiaoling, 2012, Proceedings of the 2012 Second International Conference on Intelligent System Design and Engineering Application (ISDEA), P134, DOI 10.1109/ISdea.2012.413
   DUTTA T, 2013, NAT C COMM NCC, P1
   Fallahpour M, 2014, IEEE T INSTRUM MEAS, V63, P1057, DOI 10.1109/TIM.2014.2299371
   Farfoura M, 2016, MULTIMED TOOLS APPL, V75, P7465, DOI 10.1007/s11042-015-2672-8
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Jadhav Anita, 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P140, DOI 10.1109/ICESC.2014.29
   Li Q, 2013, J COMPUT, V8, P3126, DOI 10.4304/jcp.8.12.3126-3133
   Li X, 2016, IEEE INT CONF ELECTR, P257, DOI 10.1109/ICEIEC.2016.7589733
   MAIRGIOTIS AK, 2015, 2 IET INT C INT SIGN, P1
   Manikandan VM, 2016, IEEE STUDENT TECHNOL, P266, DOI 10.1109/TechSym.2016.7872694
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   SHEN J, 2013, ADV IMAGE GRAPHICS T, V363, P109, DOI DOI 10.1007/978-3-642-37149-3_14
   SHUZHI L, 2016, COMPUTER APPL RES, V33, P521
   Stankowski J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P265, DOI 10.1109/PCS.2012.6213343
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang DY, 2012, MULTIMED TOOLS APPL, V60, P537, DOI 10.1007/s11042-011-0830-1
NR 20
TC 16
Z9 17
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 1759
EP 1779
DI 10.1007/s11042-019-08256-y
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000495297000001
DA 2024-07-18
ER

PT J
AU Golabi, S
   Helfroush, MS
   Danyali, H
AF Golabi, Sasan
   Helfroush, Mohammad Sadegh
   Danyali, Habibollah
TI Reversible robust data hiding based on wavelet filters modification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Steganography; Digital wavelet transform; Jpeg2000;
   Scalable data hiding
ID IMAGE WATERMARKING
AB In this paper, a new robust reversible data hiding method is proposed. The method is designed based on wavelet modifications which result in a scalable data hiding scheme. The well-known biorthogonal wavelets are modified according to the watermarking bits. This is done in a way that the embedded bit can easily be interpreted based on the wavelet coefficients of the watermarked image and regardless of its resolution. Following such an algorithm would result in both reversibility and robustness. The proposed method is especially robust against wavelet resolution changing attacks and DWT based compressions. This can be of high value when dealing with low bandwidth communication situations. The practical results show high robustness against signal processing attacks and high PSNR and capacity in lossless scenarios.
C1 [Golabi, Sasan; Helfroush, Mohammad Sadegh; Danyali, Habibollah] Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
C3 Shiraz University of Technology
RP Helfroush, MS (corresponding author), Shiraz Univ Technol, Dept Elect & Elect Engn, Shiraz, Iran.
EM s.golabi@sutech.ac.ir; ms_helfroush@sutech.ac.ir
RI Helfroush, Sadegh/ABE-9961-2021
CR [Anonymous], 1992, SOC IND APPL MATH
   Borah A, 2015, INT J COMPUT APPL, V129, P28
   Celik M, 2002, REVERSIBLE DATA HIDI
   Cherian J., 2016, INT J RES COMPUT APP, V4, P27
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Egiazarian K., 2016, Blind image deconvolution: theory and applications
   Feng HC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2384273
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Goljan M, 2001, INT WORKSH INF HID 2
   HONSINGER CW, 2001, Patent No. 20016278791
   Katzenbeisser S, 2016, INFORM HIDING TECHNI
   Kozhemiakina N, 2016, ELECT IMAGING, V2016, P1, DOI 10.2352/ISSN.2470-1173.2016.15.IPAS-196
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liu F, 2017, DAT COMPR C DCC 2017
   Mallat S., 2008, WAV TOUR SIGN PROC, P3
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Newtson KA, 2017, PROC SPIE, V10203, DOI 10.1117/12.2262919
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Oraintara S, 2002, IEEE T SIGNAL PROCES, V50, P607, DOI 10.1109/78.984749
   Pathak S, 2016, FUTURISTIC TRENDS EN, V16, P108
   Pla OG, 2004, PROC SPIE, V5306, P571, DOI 10.1117/12.531459
   Prakasa R. S., 2017, GLOBAL J COMPUTER SC, V17
   Rabbani Majid., 2002, J ELECTRON IMAGING, V11
   Reddy MR, 2017, 2017 INT C NETW ADV
   Smith M, 2017, U.S. Patent, Patent No. [9,749,659. 29, 974965929]
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Tian HW, 2013, IEEE T CYBERNETICS, V43, P2190, DOI 10.1109/TCYB.2013.2245415
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Vaishnav M, 2017, MED IM COMPR US DUAL
   Wiseman Y., 2015, ENCY INFORM SCI TECH, P295, DOI [10.4018/978-1-4666-5888-2.ch028, DOI 10.4018/978-1-4666-5888-2.CH028]
   Xin CHEN, 2015, INFORM TECHNOLOGY, V4, P37
   Xuan G, 2006, INT WORKSH DIG WAT
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zhu WW, 1999, IEEE T CIRC SYST VID, V9, P545, DOI 10.1109/76.767121
NR 39
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31847
EP 31865
DI 10.1007/s11042-019-07992-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000039
DA 2024-07-18
ER

PT J
AU Lee, JY
AF Lee, Jin Young
TI Deep multimodal embedding for video captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep embedding; LSTM network; Multimodal features; Video captioning
AB Automatically generating natural language descriptions from videos, which is simply called video captioning, is very challenging work in computer vision. Thanks to the success of image captioning, in recent years, there has been rapid progress in the video captioning. Unlike images, videos have a variety of modality information, such as frames, motion, audio, and so on. However, since each modality has different characteristic, how they are embedded in a multimodal video captioning network is very important. This paper proposes a deep multimodal embedding network based on analysis of the multimodal features. The experimental results show that the captioning performance of the proposed network is very competitive in comparison with conventional networks.
C1 [Lee, Jin Young] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
C3 Sejong University
RP Lee, JY (corresponding author), Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
EM jinyounglee@sejong.ac.kr
CR [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2004, TSBO
   [Anonymous], INT C COMP LING
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], AAAI C ART INT
   [Anonymous], 2015, C N AM CHAPT ASS COM
   [Anonymous], AAAI C ART INT
   [Anonymous], ARXIV171209532V1
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], NEUR INF PROC SYST C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, P IEEE C COMPUTER VI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, INT C AC SPEECH SIGN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, ACM MULTIMEDIA
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2014, ADV NEUR IN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2015, ICML
   [Anonymous], INT C COMP VIS
   [Anonymous], C EMP METH NAT LANG
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], ACM MULTIMEDIA
   Bahdanau D., 2015, 3 INT C LEARN REPR I
   Carreira Joao, 2017, IEEE C COMP VIS PATT
   Chen S, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/6359248
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Denkowski M., 2014, Meteor Universal: Lan-
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Papineni K., 2002, P ACL, P311
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., 2017, AAAI C ART INT
   Xiang SJ, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8492672
   Yu H, 2016, IEEE INT CONF COMMUN
NR 39
TC 9
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31793
EP 31805
DI 10.1007/s11042-019-08011-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000036
DA 2024-07-18
ER

PT J
AU Li, Q
   You, JN
AF Li, Qin
   You, Jane
TI Two-dimensional locality adaptive discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2DLDA; Dimensionality reduction; Local geometric structure
ID DIMENSIONALITY REDUCTION; RECOGNITION; ILLUMINATION; EIGENFACES; MODELS;
   PCA
AB Two-dimensional Linear Discriminant Analysis (2DLDA), which is supervised and extracts the most discriminating features, has been widely used in face image representation and recognition. However, 2DLDA is inapplicable to many real-world situations because it assumes that the input data obeys the Gaussian distribution and emphasizes the global relationship of data merely. To handle this problem, we present a Two-dimensional Locality Adaptive Discriminant Analysis (2DLADA). Compared to 2DLDA, our method has two salient advantages: (1) it does not depend on any assumptions on the data distribution and is more suitable in real world applications; (2) it adaptively exploits the intrinsic local structure of data manifold. Performance on artificial dataset and real-world datasets demonstrate the superiority of our proposed method.
C1 [Li, Qin] Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen, Guangdong, Peoples R China.
   [You, Jane] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Shenzhen Institute of Information Technology; Hong Kong Polytechnic
   University
RP Li, Q (corresponding author), Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen, Guangdong, Peoples R China.
EM qlinshenz@163.com
FU Collaborative Innovation Platform of shenzhen institute of information
   technology [JCYJ20160530141902978]; National Natural Science Foundation
   of China [61773302]; Natural Science Foundation of Ningbo [2018A610049]
FX This work is supported by the Collaborative Innovation Platform of
   shenzhen institute of information technology, theShenzhen Fundamental
   Research fund under Grant JCYJ20160530141902978, the National Natural
   Science Foundation of China under Grant 61773302, and the Natural
   Science Foundation of Ningbo: 2018A610049. We thank Yinfeng Wang and
   Xiaojun Yang for their language editing, thank Deyan Xie for her writing
   assistance.
CR Abou-Moustafa KT, 2015, PATTERN RECOGN, V48, P1863, DOI 10.1016/j.patcog.2014.11.008
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189
   Calzada A, 2013, INT CONF MACH LEARN, P1836, DOI 10.1109/ICMLC.2013.6890895
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   Gao QX, 2019, IEEE T CYBERNETICS, V49, P1212, DOI 10.1109/TCYB.2018.2796642
   Gao QX, 2018, IEEE T CYBERNETICS, V48, P1672, DOI 10.1109/TCYB.2017.2712740
   Gao QX, 2013, IEEE T IMAGE PROCESS, V22, P3807, DOI 10.1109/TIP.2013.2262286
   Gao QX, 2012, PATTERN RECOGN, V45, P3717, DOI 10.1016/j.patcog.2012.03.024
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Ghassabeh YA, 2015, PATTERN RECOGN, V48, P1999, DOI 10.1016/j.patcog.2014.12.012
   Gu ZH, 2012, INT C PATT RECOG, P1213
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Ke QF, 2005, PROC CVPR IEEE, P739
   Li BN, 2016, IEEE T CYBERNETICS, V46, P2543, DOI 10.1109/TCYB.2015.2479645
   Li CN, 2015, NEURAL NETWORKS, V65, P92, DOI 10.1016/j.neunet.2015.01.003
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li MY, 2017, NEUROCOMPUTING, V266, P216, DOI 10.1016/j.neucom.2017.05.037
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liu Y, 2017, IEEE T IMAGE PROCESS, V26, P684, DOI 10.1109/TIP.2016.2621667
   Lu M, 2016, PATTERN RECOGN, V60, P681, DOI 10.1016/j.patcog.2016.05.024
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Nie FP, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P993
   Oh J, 2016, PATTERN RECOGN, V54, P116, DOI 10.1016/j.patcog.2016.01.002
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shao GW, 2017, PATTERN RECOGN, V66, P353, DOI 10.1016/j.patcog.2016.12.030
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang QQ, 2018, IEEE T NEUR NET LEAR, V29, P738, DOI 10.1109/TNNLS.2016.2636130
   Wang QQ, 2018, IEEE T IMAGE PROCESS, V27, P1336, DOI 10.1109/TIP.2017.2777184
   Wang S, 2016, PATTERN RECOGN, V57, P179, DOI 10.1016/j.patcog.2016.02.019
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang R, 2003, INT J PATTERN RECOGN, V17, P1325, DOI 10.1142/S0218001403002903
   Ye HS, 2017, PATTERN RECOGN, V72, P82, DOI 10.1016/j.patcog.2017.06.029
   Zhang W, 2017, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON GREEN MANAGEMENT AND LOCAL GOVERNMENT'S RESPONSIBILITY, 2017, P120
   Zheng W., 2017, IEEE T CYBERN, V44, P828
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 40
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30397
EP 30418
DI 10.1007/s11042-019-07861-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200043
DA 2024-07-18
ER

PT J
AU Sanches, SRR
   Sementille, AC
   Tori, R
   Nakamura, R
   Freire, V
AF Sanches, Silvio R. R.
   Sementille, Antonio C.
   Tori, Romero
   Nakamura, Ricardo
   Freire, Valdinei
TI PAD: a perceptual application-dependent metric for quality assessment of
   segmentation algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Objective metric; Segmentation quality; Segmentation evaluation;
   Videoconference
ID BACKGROUND SUBTRACTION; OBJECTIVE EVALUATION; EVALUATION CRITERIA; VIDEO
   SEGMENTATION; MODEL
AB Extracting elements of interest from video frames is a necessary task in many applications, such as those that require replacing the original background. Quality assessment of foreground extraction algorithms is essential to find the best algorithm for a particular application. This paper presents an application-dependent objective metric capable of evaluating the quality of those algorithms by considering user perception. Our metric identifies types of errors that cause the greatest annoyance based on regions of the scene where users tend to keep their attention during videoconference sessions. We demonstrate the efficiency of our metric by evaluating bilayer segmentation algorithms. The results showed that metric is effective compared to others used to evaluate algorithms for videoconferencing systems.
C1 [Sanches, Silvio R. R.] Univ Tecnol Fed Parana, Cornelio Procopio, PR, Brazil.
   [Sementille, Antonio C.] Univ Estadual Paulista, Bauru, Brazil.
   [Tori, Romero; Nakamura, Ricardo] Univ Sao Paulo, Escola Politecn, Sao Paulo, Brazil.
   [Freire, Valdinei] Univ Sao Paulo, Sao Paulo, Brazil.
C3 Universidade Tecnologica Federal do Parana; Universidade Estadual
   Paulista; Universidade de Sao Paulo; Universidade de Sao Paulo
RP Sanches, SRR (corresponding author), Univ Tecnol Fed Parana, Cornelio Procopio, PR, Brazil.
EM silviosanches@utfpr.edu.br; semente@fc.unesp.br; tori@usp.br;
   ricardonakamura@usp.br; valdinei.freire@usp.br
RI Tori, Romero/F-7801-2012; Silva, Valdinei F/C-8663-2014; Sanches, Silvio
   RR/J-6357-2013
OI Tori, Romero/0000-0001-9381-9565; Sementille, Antonio
   Carlos/0000-0002-4337-514X; Sanches, Silvio/0000-0003-3635-7477
CR [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   [Anonymous], 3 INT WORKSH IM MED
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Baron R, 2016, BACKGROUND REPLACEME
   Bohannon LS, 2013, DISPLAYS, V34, P177, DOI 10.1016/j.displa.2012.10.009
   Correia PL, 2003, IEEE T IMAGE PROCESS, V12, P186, DOI 10.1109/TIP.2002.807355
   El Baf F, 2008, LECT NOTES COMPUT SC, V5358, P772, DOI 10.1007/978-3-540-89639-5_74
   Erdem C. E., 2000, P EUR SIGN PROC C EU P EUR SIGN PROC C EU, P1
   Gelasca ED, 2009, IEEE J-STSP, V3, P319, DOI 10.1109/JSTSP.2009.2015067
   Godbehere AB, 2012, P AMER CONTR CONF, P4305
   Goncalves Vagner M., 2017, Journal of the Brazilian Computer Society, V23, DOI 10.1186/s13173-016-0050-7
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Huang GH, 2018, MULTIMED TOOLS APPL, V77, P31313, DOI 10.1007/s11042-018-6208-x
   Huang X, 2017, J VIS COMMUN IMAGE R, V43, P173, DOI 10.1016/j.jvcir.2017.01.002
   Isik S, 2019, SWCD SLIDING WINDOW
   Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002
   ITU-R, 2019, INT TEL UN COMM CONN
   Kim W, 2018, MULTIMED TOOLS APPL, V77, P19439, DOI 10.1007/s11042-017-5410-6
   Kozamernik F, 2005, SMPTE MOTION IMAG J, V114, P152, DOI 10.5594/J11535
   Lacassagne L, 2009, IEEE IMAGE PROC, P3265, DOI 10.1109/ICIP.2009.5413946
   Lee S, 2010, J VIS COMMUN IMAGE R, V21, P665, DOI 10.1016/j.jvcir.2010.04.005
   Li QH, 2016, J COMPUT SCI TECH-CH, V31, P225, DOI 10.1007/s11390-016-1623-9
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Mech R, 2002, EURASIP J APPL SIG P, V2002, P401, DOI 10.1155/S1110865702000732
   Ou XY, 2017, J COMPUT SCI TECH-CH, V32, P683, DOI 10.1007/s11390-017-1751-x
   Qian R. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P143, DOI 10.1109/ICIP.1999.819566
   Sanches SRR, 2012, LECT NOTES COMPUT SC, V7334, P699, DOI 10.1007/978-3-642-31075-1_52
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Salioni DV, 2015, SYMP VIRTUAL AUGMENT, P212, DOI 10.1109/SVR.2015.38
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Sanchez-Gordon S., 2013, Proceedings of the International Conference on Information Technology Based Higher Education and Training ITHET, P1
   Shi R, 2015, IEEE T IMAGE PROCESS, V24, P5033, DOI 10.1109/TIP.2015.2473099
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Universite de Sherbrooke, 2018, CHANGEDETECTION NET
   Villegas P, 2004, IEEE T IMAGE PROCESS, V13, P1092, DOI 10.1109/TIP.2004.828433
   Villegas P., 1999, Proc. Workshop Image Analysis for Multimedia Interactive Services, V99, P85
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vojodi H, 2013, IMAGE VISION COMPUT, V31, P877, DOI 10.1016/j.imavis.2013.08.002
   Yin P, 2011, IEEE T PATTERN ANAL, V33, P30, DOI 10.1109/TPAMI.2010.65
   Zhao ZJ, 2012, COMM COM INF SC, V346, P177
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
NR 46
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32393
EP 32417
DI 10.1007/s11042-019-07958-7
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000059
DA 2024-07-18
ER

PT J
AU Singh, SK
   Sachan, MK
AF Singh, Shailendra Kumar
   Sachan, Manoj Kumar
TI SentiVerb system: classification of social media text using sentiment
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Social media text; Opinion mining; Sentiment analysis;
   Spell checker; Sentiment score
ID BEHAVIOR
AB This article proposes novel frameworks of SentiVerb and Spell Checker system, which extracts the reaction, mood, and opinion of users from social media text (SMT). The opinion of users is extracted from their written text on social media such as comments, tweets, blogs, feedbacks etc. and are classified as positive or negative opinion based on sentiment score of SMT using dictionary-based approach and a binary classifier. The dictionary-based approach uses opinion verb dictionary (OVD) to extract the sentiment of opinion verbs present in SMT. This OVD contain only opinion verbs along with their sentiment score. The various steps of the framework such as lower-case conversion, tokenization, spell checker, Part-of-Speech tagging, stop word elimination, stemming, sentiment score calculation, and classification of SMT has been discussed. A new concept of threshold negative parameter is first time introduced in this article. In the experiment, the proposed SentiVerb system's performance is evaluated on three datasets such as Facebook comments on goods and services tax (GST) implementation in India, tweets on the debate between former president of USA Mr. Barack Obama and Mr. John McCain, and the movie reviews. Consequently, the implementation of the proposed SentiVerb system using rule-based classifier (RBC) gives the best performance result in term of accuracy with 82.5% on GST comments and 79.18% on Obama-McCain debate, which is better than the existing algorithms on the social issues related domain dataset(s). Also, system performance (accuracy of 71.3%) is better than others results on standard movie dataset.
C1 [Singh, Shailendra Kumar; Sachan, Manoj Kumar] St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Sangrur 148106, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET)
RP Singh, SK (corresponding author), St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Sangrur 148106, Punjab, India.
EM Sks.it2012@gmail.com; manojsachan@gmail.com
RI Sachan, Manoj Kumar/Y-4259-2019; SINGH, SHAILENDRA KUMAR/T-1882-2017
OI Sachan, Manoj Kumar/0000-0003-3942-8330; SINGH, SHAILENDRA
   KUMAR/0000-0001-9658-1441
CR [Anonymous], 2007, ACL
   [Anonymous], 2004, P 42 ANN M ASS COMPU
   [Anonymous], 2006, P 5 INT C LANG RES E
   [Anonymous], 2012, SENTIMENT ANAL OPINI
   [Anonymous], 2007, ICWSM
   [Anonymous], 2001, P APFA
   [Anonymous], J INFORM KNOWLEDGE R
   [Anonymous], 2003, P 12 INT C WORLD WID, DOI DOI 10.1145/775152.775226
   [Anonymous], 2010, LREC 10
   Asghar MZ, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2809-x
   Binali H, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1-3, P887
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Clark E, 2011, PROCD SOC BEHV, V27, P2, DOI 10.1016/j.sbspro.2011.10.577
   Cruz L, 2017, COMM COM INF SC, V656, P57, DOI 10.1007/978-3-319-55209-5_5
   Davies Mark., WORD FREQUENCY DATA
   Doyle D., STOPWORDS
   Dutta S, 2015, 2015 IEEE 2ND INTERNATIONAL CONFERENCE ON RECENT TRENDS IN INFORMATION SYSTEMS (RETIS), P378, DOI 10.1109/ReTIS.2015.7232908
   Fernández-Gavilanes M, 2016, EXPERT SYST APPL, V58, P57, DOI 10.1016/j.eswa.2016.03.031
   Guan T, 2018, COMPUT HUM BEHAV, V81, P137, DOI 10.1016/j.chb.2017.12.023
   Guellil I, 2015, 2015 12TH IEEE INTERNATIONAL CONFERENCE ON PROGRAMMING AND SYSTEMS (ISPS), P132
   Han B, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2414425.2414430
   Hang Li, 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P443
   Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640
   HEARST MA, 1992, TEXT-BASED INTELLIGENT SYSTEMS : CURRENT RESEARCH AND PRACTICE IN INFORMATION EXTRACTION AND RETRIEVAL, P257
   Hu M., 2004, P 10 ACM SIGKDD INT, P168, DOI DOI 10.1145/1014052.1014073
   Hu NJ, 2013, ADV INTEL SYS RES, P476
   Hu X., 2013, P 22 INT C WORLD WID, P607, DOI DOI 10.1145/2488388.2488442
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   Jivani A.G., 2011, Int. J. Comp. Tech. Appl, V2, P1930
   Kapko M, 2015, CIO FROM IDG
   Karamibekr M, 2012, PROCEEDINGS OF THE 2012 ASE INTERNATIONAL CONFERENCE ON SOCIAL INFORMATICS (SOCIALINFORMATICS 2012), P215, DOI 10.1109/SocialInformatics.2012.49
   Karamibekr M, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P327, DOI 10.1109/WI-IAT.2012.122
   Kim S., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220555
   Leong LY, 2018, COMPUT HUM BEHAV, V78, P160, DOI 10.1016/j.chb.2017.09.033
   Liu F., 2012, Proc 50th Annu Meet Assoc Comput Linguist, V1, P1035
   Liu Fei, 2011, P 49 ANN M ASS COMPU, P71
   Lu YJ, 2011, LET'S TALK ORE DEPOSITS, VOLS I AND II, P347
   Luo NL, 2018, COMPUT HUM BEHAV, V81, P84, DOI 10.1016/j.chb.2017.12.004
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Modi SN, 2017, FACEBOOK
   Morinaga S., 2002, P 8 ACM SIGKDD INT C, P341, DOI [DOI 10.1145/775047.775098, 10.1145/775047.775098]
   Mou J, 2018, COMPUT HUM BEHAV, V78, P74, DOI 10.1016/j.chb.2017.08.049
   Nasukawa T., 2003, P 2 INT C KNOWLEDGE, P70, DOI DOI 10.1145/945645.945658
   Ortega Bueno R, 2015, P 8 INT WORKSH SEM E, P773
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Peng L., 2014, What do seller manipulations of online product reviews mean to consumers?
   Polanyi L, 2006, INFORM RETRIEVAL SER, V20, P1
   Press Trust Of India, 2013, BUS STAND
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   SACK W, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1488
   Saif H, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P810
   Saif H, 2014, LECT NOTES COMPUT SC, V8798, P54, DOI 10.1007/978-3-319-11955-7_5
   Schmidbauer H, 2018, COMPUT HUM BEHAV, V81, P148, DOI 10.1016/j.chb.2017.11.021
   Serrano-Guerrero J, 2015, INFORM SCIENCES, V311, P18, DOI 10.1016/j.ins.2015.03.040
   Singh P. K., 2015, INT J ENG TECHNOLOGY, V7, P1443
   Singh S.K., 2014, International Journal of Database Theory and Application, V7, P39, DOI [10.14257/ijdta.2014.7.5.04, DOI 10.14257/IJDTA.2014.7.5.04]
   Singh SK, 2014, INT J APPL ENG RES, V9, P13925
   Singh SK, 2017, INT J ADV RES COMPUT, V8, P831, DOI [10.26483/ijarcs.v8i3.3108, DOI 10.26483/IJARCS.V8I3.3108]
   Singh SK., 2015, International Journal of Applied Engineering Research, V10, P1694
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Somasundaran Swapna, 2010, P NAACL HLT 2010 WOR, P116
   Subasic P, 2001, IEEE T FUZZY SYST, V9, P483, DOI 10.1109/91.940962
   Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tong RichardM., 2001, WORKING NOTES ACM SI, P1
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Vilnai-Yavetz I, 2018, COMPUT HUM BEHAV, V79, P181, DOI 10.1016/j.chb.2017.10.034
   Washenko A, 2015, SPROUTSOCIAL BLOG
   Whissell C., 1989, Emotion: Theory, Research and Experience: vol. 4, V4
   Wiebe J. M., 1994, Computational Linguistics, V20, P233
   Wiebe J.M., 1990, Proceedings of the 13th Conference on Computational Linguistics, V2, P401
   Wiebe J. M., 1999, Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, P246, DOI [DOI 10.3115/1034678.1034721, 10.3115/1034678.1034721]
   Wiebe JM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P735
   XPO6, 2009, LIST ENGL STOP WORDS
   Yi JH, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P427, DOI 10.1109/ICDM.2003.1250949
NR 75
TC 11
Z9 12
U1 6
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32109
EP 32136
DI 10.1007/s11042-019-07995-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000049
DA 2024-07-18
ER

PT J
AU Tariq, J
AF Tariq, Junaid
TI Intra mode selection using classical secretary problem (CSP) in high
   efficiency video coding (HEVC)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video coding; Image coding; HEVC; Fast intra mode; Optimal stopping
   theory
ID DECISION; PREDICTION; ALGORITHM; COST
AB In order to support fast distribution of multimedia contents on social media and internet, a fast intra mode decision strategy is proposed in this article to reduce the encoding time of multimedia contents by removing the brute force intra mode selection procedure of HEVC. This article, firstly, improves the performance of the rough-mode-decision (RMD) component of HEVC by constructing the candidate intra mode list by employing a new measure that is fusion of the Hadamard-cost and the statistical-inference formed using spatial/ temporal information. Later, an optimal stopping point prediction model is constructed that outperforms the existing optimal stopping models proposed for HEVC by giving promising balance between the increase in bit-rate and the decrease in complexity. Finally, an early intra mode termination is predicted using the proposed optimal stopping model. Simulation results demonstrate that the proposed model has a wide application and provides early termination for a generic class of decision problems.
C1 [Tariq, Junaid] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
C3 NITEC University
RP Tariq, J (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
EM jtariq2-c@my.cityu.edu.hk
CR [Anonymous], 2016, BIOMED RES INT
   [Anonymous], CIRC SYST SIGNAL PRO
   [Anonymous], HEVC TEST MOD
   [Anonymous], 1973, THEORY PROBAB APPL, DOI DOI 10.1137/1117078
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   [Anonymous], P AMS IMS SIAM JOINT
   [Anonymous], 2011, JCTVCF900
   [Anonymous], JCTVCH0166 ISOIEC MP
   [Anonymous], 2017, MULTIMED TOOLS APPL, DOI DOI 10.1057/S41278-017-0070-Z
   Bjontegaard G., 2001, Document VCEG-M33
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Gwon D, 2019, KSII T INTERNET INF, V13, P385, DOI 10.3837/tiis.2019.01.022
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   Huang B, 2020, IEEE T CIRC SYST VID, V30, P795, DOI 10.1109/TCSVT.2019.2893396
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ramezanpour M, 2016, J REAL-TIME IMAGE PR, V12, P397, DOI 10.1007/s11554-016-0580-4
   Ruiz D, 2017, MULTIMED TOOLS APPL, V76, P861, DOI 10.1007/s11042-015-3014-6
   Shi W, 2018, J REAL-TIME IMAGE PR, V15, P57, DOI 10.1007/s11554-017-0677-4
   Song Y, 2017, MULTIMED TOOLS APPL, V76, P2001, DOI 10.1007/s11042-015-3155-7
   Sun XM, 2017, J INEQUAL APPL, DOI 10.1186/s13660-017-1424-x
   TARIQ J, 2019, MULTIMED TOOLS APPL, V78, P1, DOI DOI 10.1007/S11042-018-6670-5
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1782, DOI 10.1109/SMC.2015.312
   Tian R, 2019, MULTIMED TOOLS APPL, V78, P289, DOI 10.1007/s11042-018-6001-x
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Yan ZG, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON IMAGE, VIDEO AND SIGNAL PROCESSING (IVSP 2019), P45, DOI 10.1145/3317640.3317645
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
   Zhu J, 2013, IEEE IMAGE PROC, P1977, DOI 10.1109/ICIP.2013.6738407
NR 42
TC 7
Z9 7
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31533
EP 31555
DI 10.1007/s11042-019-07989-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000025
DA 2024-07-18
ER

PT J
AU Xiong, LZ
   Xia, ZH
   Chen, XY
   Shim, HJ
AF Xiong, Lizhi
   Xia, Zhihua
   Chen, Xianyi
   Shim, Hiuk Jae
TI Secure multimedia distribution in cloud computing using re-encryption
   and fingerprinting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-encryption; Fingerprint; Cloud computing; Multimedia distribution
ID SOCIAL NETWORKS; SCHEME; EFFICIENT
AB Recently, cloud computing becomes a main platform for the distribution of multimedia content. The paradigm of multimedia distribution has been shifted from the models in traditional ways to the one in cloud computing. Security and privacy are two most important issues in multimedia distribution. The new model in cloud computing concerns the following issues. Firstly, outsourced content should be confidential except a data owner (DO). Secondly, the CSP is semi-trusted in the public cloud computing environment. A malicious data user (DU) may collude with the CSP to harm the DO's rights and interests. Thirdly, the rights and interests of DU, including anonymity and unlinkability, should be protected. Based on the above problems, we propose and analyze a Multimedia Distribution based Re-encryption and Fingerprinting (MDRF) scheme in cloud computing. The proposed scheme 1) allows efficient distribution of the content while preserving security and privacy of copyright holders and end users, 2) resolve the problems of piracy tracing, collusion resistance, and dispute resolution, and 3) protect the rights and interests of DU, including anonymity and unlinkability. The analysis part demonstrates that the security of DO and DU are well provided in the proposed scheme. The experimental results evaluate the performance of our framework in terms of collusion resistance of the fingerprint and imperceptibility of fingerprint embedding.
C1 [Xiong, Lizhi; Xia, Zhihua; Chen, Xianyi; Shim, Hiuk Jae] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Xiong, Lizhi; Xia, Zhihua; Chen, Xianyi; Shim, Hiuk Jae] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
   [Xiong, Lizhi] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Xiong, LZ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.; Xiong, LZ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.; Xiong, LZ (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Jiangsu, Peoples R China.
EM lzxiong16@163.com; xia_zhihua@163.com; 0204622@163.com;
   waitnual@gmail.com
RI Xia, Zhihua/C-8581-2011; Xiong, Lizhi/KCK-1464-2024
OI Xia, Zhihua/0000-0001-6860-647X
FU National Natural Science Foundation of China [61702276, 61672294,
   61502242]; Startup Foundation for Introducing Talent of Nanjing
   University of Information Science and Technology [2016r055]; Priority
   Academic Program Development (PAPD) of Jiangsu Higher Education
   Institutions
FX The authors are grateful for the anonymous reviewers who made
   constructive comments and improvements. This work was supported by the
   National Natural Science Foundation of China (No. 61702276, 61672294,
   61502242), the Startup Foundation for Introducing Talent of Nanjing
   University of Information Science and Technology under Grant 2016r055,
   and the Priority Academic Program Development (PAPD) of Jiangsu Higher
   Education Institutions.
CR Boneh D, 1995, LECT NOTES COMPUT SC, V963, P452
   Camenisch J, 2000, LECT NOTES COMPUT SC, V1976, P415
   Cao Y, 2018, CMC-COMPUT MATER CON, V54, P197, DOI 10.3970/cmc.2018.054.197
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Domingo-Ferrer J, 2013, COMPUT COMMUN, V36, P542, DOI 10.1016/j.comcom.2012.12.005
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   He S, 2006, IEEE T INF FOREN SEC, V1, P231, DOI 10.1109/TIFS.2006.873597
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   KURIBAYASHI M, 2010, EURASIP J INF SECUR, V2010, p1:1
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Megías D, 2015, IEEE T DEPEND SECURE, V12, P179, DOI 10.1109/TDSC.2014.2320712
   Megías D, 2014, MULTIMEDIA SYST, V20, P105, DOI 10.1007/s00530-013-0307-3
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Murillo-Escobar MA, 2015, EXPERT SYST APPL, V42, P8198, DOI 10.1016/j.eswa.2015.06.035
   Pfitzmann B., 1997, Advances in Cryptology - EUROCRYPT '97. International Conference on the Theory and Application of Cryptographic Techniques Proceedings, P88
   Prins Jeroen P., 2007, EURASIP J INF SECUR, V2007, P20
   Xiong LZ, 2018, CMC-COMPUT MATER CON, V55, P523, DOI 10.3970/cmc.2018.01791
   Xiong LZ, 2018, MULTIDIM SYST SIGN P, V29, P1191, DOI 10.1007/s11045-017-0497-5
   Xu YY, 2014, J VIS COMMUN IMAGE R, V25, P805, DOI 10.1016/j.jvcir.2014.01.005
   Ye CH, 2014, IEEE INT CONF TRUST, P616, DOI 10.1109/TrustCom.2014.79
   Zhang K, 2014, IEEE COMMUN MAG, V52, P58, DOI 10.1109/MCOM.2014.6766086
NR 21
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30297
EP 30313
DI 10.1007/s11042-018-6981-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200037
DA 2024-07-18
ER

PT J
AU Zhang, Z
AF Zhang, Zhen
TI Visualization analysis of the development trajectory of knowledge
   sharing in virtual communities based on CiteSpace
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge sharing; Virtual communities; Development trajectory;
   Visualization analysis; CiteSpace
ID INTENTION; NETWORKS
AB Studies on knowledge sharing (KS) in virtual communities (VCs) have indicated several limitations, such as chaotic literature information, interdisciplinarity complexity, and evolution vagueness. In this study, literature on KS in VCs is obtained from the database of Web of Science (WoS) Core Collection during 2002 to 2017. CiteSpace technology based on Java platform is applied to develop the visualization analysis of the development trajectory, and summarize the research distribution, intellectual base and evolution path of how KS in VCs has been studied. Results show that the quantitative development of literature on KS in VCs has undergone three stages, and China, USA, South Korea have led the research of this area. Moreover, the intellectual base is social capital, social cognitive theory, and behavior, motivation, quantity and quality of KS. In addition, the evolution path has gone through two stages: Firstly, the trajectory of development during 2002 to 2014 is concept definition, VCs platform, and factors influencing KS. Secondly, from the perspective of individuals, teams and organizations, the factors including social capital, trust, and self-efficiency have been stressed during 2015 to 2017. It provides the research trajectories and future research directions for authors.
C1 [Zhang, Zhen] Wuhan Univ Technol, Sch Management, Wuhan 430070, Hubei, Peoples R China.
C3 Wuhan University of Technology
RP Zhang, Z (corresponding author), Wuhan Univ Technol, Sch Management, Wuhan 430070, Hubei, Peoples R China.
EM zhangzhenquanquan@whut.edu.cn
FU Research Project of Hubei Provincial Education Department [B2017300]
FX This work was supported by Research Project of Hubei Provincial
   Education Department under Grant No. B2017300.
CR Chang HH, 2011, INFORM MANAGE-AMSTER, V48, P9, DOI 10.1016/j.im.2010.11.001
   Chen CJ, 2010, INFORM MANAGE-AMSTER, V47, P226, DOI 10.1016/j.im.2010.03.001
   Chen CM, 2006, J AM SOC INF SCI TEC, V57, P359, DOI 10.1002/asi.20317
   Chiu CM, 2006, DECIS SUPPORT SYST, V42, P1872, DOI 10.1016/j.dss.2006.04.001
   Dickinson JE, 2017, J SUSTAIN TOUR, V25, P163, DOI 10.1080/09669582.2016.1182538
   Hsu CL, 2008, INFORM MANAGE-AMSTER, V45, P65, DOI 10.1016/j.im.2007.11.001
   Hsu MH, 2007, INT J HUM-COMPUT ST, V65, P153, DOI 10.1016/j.ijhcs.2006.09.003
   Hung SY, 2015, J ASSOC INF SCI TECH, V66, P2494, DOI 10.1002/asi.23339
   Jiang LY, 2012, OPTIK, V123, P1834, DOI 10.1016/j.ijleo.2012.02.045
   Kankanhalli A, 2005, MIS QUART, V29, P113, DOI 10.2307/25148670
   Kleinberg J, 2003, DATA MIN KNOWL DISC, V7, P373, DOI 10.1023/A:1024940629314
   Lee S, 2016, INT J TECHNOL MANAGE, V70, P58, DOI 10.1504/IJTM.2016.074675
   Liao TH, 2017, UNIVERSAL ACCESS INF, V16, P215, DOI 10.1007/s10209-016-0452-5
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lin MJJ, 2009, COMPUT HUM BEHAV, V25, P929, DOI 10.1016/j.chb.2009.03.008
   Marshall GJ, 2000, CYBERNET SYST, V31, P397, DOI 10.1080/019697200124766
   Munar AM, 2014, TOURISM MANAGE, V43, P46, DOI 10.1016/j.tourman.2014.01.012
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Scannell L, 2010, J ENVIRON PSYCHOL, V30, P1, DOI 10.1016/j.jenvp.2009.09.006
   Wasko MM, 2005, MIS QUART, V29, P35, DOI 10.2307/25148667
   Xu S, 2016, J INTERNET TECHNOL, V17, P1151, DOI 10.6138/JIT.2016.17.6.20161007
   Yao CY, 2015, TOTAL QUAL MANAG BUS, V26, P619, DOI 10.1080/14783363.2013.865918
NR 22
TC 8
Z9 8
U1 2
U2 95
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29643
EP 29657
DI 10.1007/s11042-018-6061-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200002
DA 2024-07-18
ER

PT J
AU Zhao, P
   Liu, Y
   Lu, YJ
   Xu, BP
AF Zhao, Peng
   Liu, Yang
   Lu, Yijuan
   Xu, Benpeng
TI A sketch recognition method based on transfer deep learning with the
   fusion of multi-granular sketches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch recognition; Deep learning; Transfer learning
AB Most of existing sketch recognition methods focus on the contour/shape of whole sketches. They ignore different granularities of sketches during sketching. Stroke sequences of sketches often demonstrate the change of various granularities. In the progress of sketching, a coarser-grained contour gradually changes to a finer-grained object. Different granularities of sketch imply different levels of semantic information and play different roles in sketch recognition. In this paper, a transfer-deep-learning-based sketch recognition method-"sketch-transfer-net" is proposed. Sketch-transfer-net designs a novel fine-tuning strategy to use different granular sketches to fine-tune different layers of neural network. The extensive comparative experiments show that the proposed sketch-transfer-net can capture descriptive information of various granular sketches and therefore improve the performance of sketch recognition. In addition, the novel fine-turning strategy could weaken the negative effect in transfer learning and enable CNNs to be well trained on small sketch datasets.
C1 [Zhao, Peng; Liu, Yang; Xu, Benpeng] Anhui Univ, Sch Comp Sci & Technol, Hefei 230039, Peoples R China.
   [Zhao, Peng] Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
   [Lu, Yijuan] Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
C3 Anhui University; Anhui University; Texas State University System; Texas
   State University San Marcos
RP Zhao, P (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei 230039, Peoples R China.; Zhao, P (corresponding author), Anhui Univ, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230601, Peoples R China.
EM zhaopeng_ad@163.com
RI LU, YIJUAN/GNM-8769-2022; yu, zhang/JWO-7724-2024; Li,
   Shuya/JHT-2171-2023
OI LU, YIJUAN/0000-0002-9855-8365; Li, Shuya/0000-0001-5320-8452
FU National Natural Science Foundation of China [61602004]; Natural Science
   Foundation of the Education Department of Anhui Province [KJ2016A041,
   KJ2017A011]; NSF [CNS-1305302]; Texas State Research Enhancement Program
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61602004) to Dr. Zhao, Natural Science Foundation of the
   Education Department of Anhui Province (Grant No. KJ2016A041,
   KJ2017A011), and in part supported by NSF CNS-1305302 and Texas State
   Research Enhancement Program grant to Dr. Lu.
CR [Anonymous], 2007, C NEUR INF PROC SYST
   [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], 2017, VERY DEEP CONVOLUTIO
   [Anonymous], HUMAN LANGUAGE TECHN
   [Anonymous], MAXOUT NETWORKS OL
   [Anonymous], 2017, SKETCH NET BEATS HUM
   [Anonymous], ACM SIGGRAPH
   [Anonymous], P SIAM INT C DAT MIN
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2012, AAAI
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], P 14 INT C ART INT S
   Cao XC, 2013, IEEE I CONF COMP VIS, P313, DOI 10.1109/ICCV.2013.46
   Carneiro G, 2004, INT C PATT RECOG, P16, DOI 10.1109/ICPR.2004.1334458
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Seddati Omar, 2015, CONT BAS MULT IND CB, P1, DOI DOI 10.1109/CBMI.2015.7153606
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   YANG Yongxin, 2015, ARXIV150107873
   Yesilbek Kemal Tugrul, 2015, P WORKSH SKETCH BAS, P117
NR 28
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35179
EP 35193
DI 10.1007/s11042-019-08216-6
EA OCT 2019
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000488903300001
DA 2024-07-18
ER

PT J
AU AjithaGladis, KP
AF AjithaGladis, K. P.
TI Gravitational search algorithm based data scheduling for peer to peer
   video on demand system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer to peer video streaming systems; Video on demand (VoD);
   Gravitational search algorithm; Data scheduling; Priority function
ID VOD SYSTEM; P2P; REPLICATION; OPTIMIZATION
AB In peer to peer (P2P) video streaming systems, peers in network assist to forward the data to other peers without the interference of central servers. Video on Demand (VoD) is widely using internet service, which offers video to users with effective control when they need it. The major significant problem in developing a P2P VoD system is data scheduling, which concentrates on dealing with transmitting and dispatching data segments within a system efficiently. So a Gravitational Search Algorithm based data Scheduling (GSAS) is presented in this paper. Initially, the network is developed in the form of hierarchical topology. Video file is cached as data segments in each peer in the top layer of the network. Using the priority function, these data segments are sorted or prioritized. Using the proposed GSA algorithm, optimal or suitable peers which cache the requested data segments in the top layer are selected. Then the prioritized data segments from the selected peers are scheduled to the peer which has requested for video sequences. The video file "Grandmother" with the size 53 MB is examined in this approach. This proposed approach is simulated in the network simulator. Simulation results show that the performance of this proposed approach is superior to that of the existing work in terms of throughput and scheduling time.
C1 [AjithaGladis, K. P.] CSI Inst Technol, Dept IT, Thovalai, India.
RP AjithaGladis, KP (corresponding author), CSI Inst Technol, Dept IT, Thovalai, India.
EM kpajithagladis1503@gmail.com
CR Abdulaziz S, 2017, ADV SOFT COMPUTING M, P477
   Bhuiyan MZA, 2017, IEEE T IND INFORM, V13, P572, DOI 10.1109/TII.2017.2665463
   Brij G., 2016, Handbook of Research on Modern Cryptographic Solutions for Computer and Cyber Security
   Chang CL, 2014, IEEE SYST J, V8, P304, DOI 10.1109/JSYST.2013.2258199
   Cheng B, 2008, J SYST ARCHITECT, V54, P651, DOI 10.1016/j.sysarc.2007.11.003
   de Pinho LB, 2006, J NETW COMPUT APPL, V29, P25, DOI 10.1016/j.jnca.2004.10.009
   Deltouzos K, 2017, COMPUT NETW, V113, P58, DOI 10.1016/j.comnet.2016.12.002
   Demirci S, 2017, COMPUT STAND INTER, V49, P44, DOI 10.1016/j.csi.2016.08.002
   Elhoseny M, 2018, EXPERT SYST APPL, V92, P142, DOI 10.1016/j.eswa.2017.09.008
   Elhoseny M, 2017, WIRELESS PERS COMMUN, V95, P3733, DOI 10.1007/s11277-017-4023-8
   Eunsam K, 2017, J NETW COMPUT APPL, V88, P112
   Fan LS, 2016, IEEE J-STSP, V10, P1494, DOI 10.1109/JSTSP.2016.2607692
   He Y, 2012, J NETW COMPUT APPL, V35, P1568, DOI 10.1016/j.jnca.2012.02.004
   Hwang KW, 2016, COMPUT NETW, V106, P226, DOI 10.1016/j.comnet.2016.06.006
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Liao XF, 2012, FUTURE GENER COMP SY, V28, P930, DOI 10.1016/j.future.2011.10.006
   Mohammad AA, 2016, J REAL-TIME IMAGE PR, V13, P527
   Ramzan N, 2012, SIGNAL PROCESS-IMAGE, V27, P401, DOI 10.1016/j.image.2012.02.004
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rohmer T, 2016, IFAC PAPERSONLINE, V49, P775, DOI 10.1016/j.ifacol.2016.07.868
   Tauhiduzzaman M, 2015, COMPUT NETW, V79, P39, DOI 10.1016/j.comnet.2014.12.009
   Wójcik R, 2016, AEU-INT J ELECTRON C, V70, P162, DOI 10.1016/j.aeue.2015.11.001
   Wu WJ, 2014, IEEE T PARALL DISTR, V25, P612, DOI 10.1109/TPDS.2013.94
   Yang XY, 2010, J PARALLEL DISTR COM, V70, P1175, DOI 10.1016/j.jpdc.2010.07.007
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu Q, 2012, IET COMMUN, V6, P1625, DOI 10.1049/iet-com.2011.0190
   Zhou YP, 2015, IEEE ACM T NETWORK, V23, P1163, DOI 10.1109/TNET.2014.2321422
   Zhou YP, 2013, IEEE ACM T NETWORK, V21, P233, DOI 10.1109/TNET.2012.2196444
NR 28
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27291
EP 27307
DI 10.1007/s11042-019-7644-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000023
DA 2024-07-18
ER

PT J
AU Hu, T
   Zhu, XY
   Guo, W
   Wang, SH
   Zhu, JF
AF Hu, Tao
   Zhu, Xinyan
   Guo, Wei
   Wang, Shaohua
   Zhu, Jianfeng
TI Human action recognition based on scene semantics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Depth sensor; Semantic context; Trajectory
   clustering
AB Like outdoors, indoor security is also a critical problem and human action recognition in indoor area is still a hot topic. Most studies on human action recognition ignored the semantic information of a scene, whereas indoors contains varieties of semantics. Meanwhile, the depth sensor with color and depth data is more suitable for extracting the semantics context in human actions. Hence, this paper proposed an indoor action recognition method using Kinect based on the semantics of a scene. First, we proposed a trajectory clustering algorithm for a three-dimensional (3D) scene by combining the different characteristics of people such as the spatial location, movement direction, and speed. Based on the clustering results and scene context, it concludes a region of interest (ROI) extraction method for indoors, and dynamic time warping (DTW) is used to study the abnormal action sequences. Finally, the color and depth-data-based 3D motion history image (3D-MHI) features and the semantics context of the scene were combined to recognize human action. In the experiment, two datasets were tested and the results demonstrate that our semantics-based method performs better than other methods.
C1 [Hu, Tao; Zhu, Xinyan; Guo, Wei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430070, Peoples R China.
   [Hu, Tao; Zhu, Xinyan; Guo, Wei] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430070, Peoples R China.
   [Hu, Tao] Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430070, Peoples R China.
   [Hu, Tao] Kent State Univ, Sch Informat, Kent, OH 44240 USA.
   [Wang, Shaohua] Wuhan Univ, Int Sch Software, Wuhan 430070, Peoples R China.
   [Zhu, Jianfeng] Kent State Univ, Sch Digital Sci, Kent, OH 44240 USA.
C3 Wuhan University; Wuhan University; Wuhan University; University System
   of Ohio; Kent State University; Kent State University Salem; Kent State
   University Kent; Wuhan University; University System of Ohio; Kent State
   University; Kent State University Kent; Kent State University Salem
RP Guo, W (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430070, Peoples R China.; Guo, W (corresponding author), Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430070, Peoples R China.
EM guowei-lmars@whu.edu.cn
RI zhu, y x/IVU-7833-2023; zhu, xin/JXN-3188-2024; 朱, 欣妍/JZD-6639-2024; Hu,
   Tao/JOZ-6744-2023; shaohua, wang/AAB-7904-2022
FU National Key Research and Development Program of China [2016YFB0502204];
   National Natural Science Foundation of China [41301517]; Funds for the
   Central Universities [413000010]; State Laboratory of Information
   Engineering in Surveying, Mapping and Remote Sensing, Wuhan University
   [16(03)]; National Key Technology Research and Development Program
   [2012BAH35B03]
FX This research is supported by the National Key Research and Development
   Program of China (No. 2016YFB0502204), the National Natural Science
   Foundation of China (No. 41301517), the Funds for the Central
   Universities (No. 413000010), the Open Found of State Laboratory of
   Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan
   University (No.16(03)), the National Key Technology Research and
   Development Program (No. 2012BAH35B03).
CR Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   [Anonymous], P 4 IEEE INT C MULT
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   Atev S., 2006, 2006 IEEE RSJ INT C
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Brand M, 1997, P 1997 IE COMP SOC C
   Brandle N, 2006, IEEE C INT TRANSP SY
   Brendel W, 2011, 2011 IE INT C COMP V
   Cao LB, 2012, IEEE T KNOWL DATA EN, V24, P1378, DOI 10.1109/TKDE.2011.129
   Chakraborty B, 2011, 2011 IE INT C COMP V
   Chen C, 2016, IEEE SENS J, V16, P773, DOI 10.1109/JSEN.2015.2487358
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   DAVIS JW, 2001, MACWORLD         FEB, P100
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Guo P, 2012, IEEE T CIRC SYST VID, V22, P1306, DOI 10.1109/TCSVT.2012.2199390
   Guo W, 2012, IEEE INT SYMP CIRC S, P1275
   Han Lei, 2010, Chinese Journal of Computers, V33, P776, DOI 10.3724/SP.J.1016.2010.00776
   [胡加佩 Hu Jiapei], 2014, [地球信息科学学报, Journal of Geo-Information Science], V16, P545
   Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359
   Liu CD, 2010, IEEE T INF TECHNOL B, V14, P1236, DOI 10.1109/TITB.2010.2052061
   Lu N, 2011, J INEQUAL APPL, DOI 10.1186/1029-242X-2011-4
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652
   Masood SZ, 2011, 2011 IE INT C COMP V
   Masoud O, 2003, IMAGE VISION COMPUT, V21, P729, DOI 10.1016/S0262-8856(03)00068-4
   Meng ZL, 2010, 2010 INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION AND 2010 ASIA-PACIFIC CONFERENCE ON INFORMATION TECHNOLOGY AND OCEAN ENGINEERING: CICC-ITOE 2010, PROCEEDINGS, P3, DOI 10.1109/CICC-ITOE.2010.8
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Naftel A., 2006, IEEE INT C COMP VIS
   Naftel A, 2006, MULTIMEDIA SYST, V12, P227, DOI [10.1007/s00530-006-0058-5, 10.1007/S00530-006-0058-5]
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Nguyen NT, 2005, IEEE COMP SOC C COMP
   Nowozin S, 2012, MSRTR201268 MICR RES
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Ren X, 2012, 2012 IE C COMP VIS P
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Shin H-K, 2005, INT C INT COMP
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Song Y, 2012, IEEE IJCNN
   Tao H, 2013, MATH PROBL ENG
   Vieira Antonio W, 2012, IB C PATT REC
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang Y, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2012, VOL 3, PTS A AND B, P1201
   Watanabe K, 2008, ECSIS S BIOINSP LEAR
   Weinland D, 2005, WORKSH MOD PEOPL HUM
   Xia L, 2012, 2012 IE COMP SOC C C
   Yan W, 2005, 7 IEEE WORKSH APPL C, V1
   Yang RD, 2009, COMPUT VIS IMAGE UND, V113, P663, DOI 10.1016/j.cviu.2008.09.005
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yu Z., 2012, Liquid redox electrolytes for dye-sensitized solar cells Ze Yu
NR 53
TC 5
Z9 6
U1 2
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28515
EP 28536
DI 10.1007/s11042-017-5496-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700010
DA 2024-07-18
ER

PT J
AU Liu, F
   Yang, AZ
AF Liu, Fang
   Yang, Anzhe
TI Application of gcForest to visual tracking using UAV image sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Unmanned aerial vehicles; gcForest; Multi-scale
   transformation
ID ROBUST OBJECT TRACKING
AB Visual object tracking is a core technology and challenging research in computer vision. With the rapid development of unmanned aerial vehicle (UAV), more and more UAVs are equipped with video cameras to conduct object tracking. Researching object tracking of UAV image sequences is of great help for practical applications. Recent trackers based on deep networks have a great success by learning an effective representation of targets, however, the offline training is time-consuming, and the complex network may reduce its efficiency. In this paper, to effectively decrease the training time and handle the problem of network complexity, an effective tracking algorithm called multi-scale gcForest tracking (MSGCF) is proposed. First, to enrich the sample information and overcome the problem of scale variations, the multi-scale transformation is used for helping network to obtain the stronger representation of target samples. Then, gcForest that is a decision tree ensemble approach is utilized in tracking task to extract the target features, and gcForest is much easier to train and works well in small-scale training data. Most importantly, we make improvements to the gcForest by adding three channels at the top of network to adapt to multi-scale images and improve the representation ability of network. Furthermore, computation speed can be increased greatly through the method of reducing feature dimension based on compressive sensing (CS) theory, and the power of features can also be reserved. Finally, a support vector machine (SVM) classifier is employed to effectively separate targets and backgrounds. Extensive experimental results on UAV image sequences and challenging benchmark data sets demonstrate that the proposed MSGCF algorithm is effective.
C1 [Liu, Fang; Yang, Anzhe] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Yang, AZ (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM anzheyang@emails.bjut.edu.cn
FU National Natural Science Foundation of China [61171119]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61171119). The authors greatly appreciate the financial
   support.
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen T, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013003
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang WY, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023012
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu N, 2019, MULTIMED TOOLS APPL, V78, P3689, DOI 10.1007/s11042-017-5538-4
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Schuck PW, 2005, ASTROPHYS J, V632, pL53, DOI 10.1086/497633
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang HX, 2019, MULTIMED TOOLS APPL, V78, P257, DOI 10.1007/s11042-017-5533-9
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang H, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023008
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
NR 50
TC 10
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27933
EP 27956
DI 10.1007/s11042-019-07864-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000052
DA 2024-07-18
ER

PT J
AU Panchal, G
   Samanta, D
   Barman, S
AF Panchal, Gaurang
   Samanta, Debasis
   Barman, Subhas
TI Biometric-based cryptography for digital content protection without any
   key storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cryptographic key generation; Biometric-based security; Data security;
   Bio-crypto system; Information forensics security
ID RIDGE FEATURES; FINGERPRINT
AB The traditional digital data security mechanisms follow either cryptography or authentication. The primary point of contention with these mechanisms remains either memorizing or securely storing the user's credentials. The proposed work addresses this critical issue by presenting a fingerprint biometric-based mechanism to protect users' digitized documents. In our approach, biometric features are extracted from the user's fingerprint captured with a fingerprint biometric sensor. The extracted features are then used to generate a unique code utilizing the convolution coding principle. This unique code is further used to generate a cryptographic key for encryption and decryption of the user's document. A sedulous investigation to our approach which includes experimentation with a variety of standard fingerprint images as the database starkly reveals a staggering 95.12 % true positive and 0 % as false negative. Further, the advantages of our approach are that it generates a unique key for each user and eliminates the storage of any biometric template or key. In addition, it is faster and accurate enough to develop any robust data storage security system.
C1 [Panchal, Gaurang; Samanta, Debasis] Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
   [Barman, Subhas] Jalpaiguri Govt Engn Coll, Jalpaiguri, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Jalpaiguri Government Engineering College
RP Panchal, G (corresponding author), Indian Inst Technol Kharagpur, Kharagpur, W Bengal, India.
EM gp.citc@gmail.com; debasis.samanta.iitkgp@gmail.com;
   subhas.barman@gmail.com
RI Barman, Subhas/AAH-5244-2019
OI Barman, Subhas/0000-0002-3206-1110; Samanta, Debasis/0000-0002-6104-3771
CR Abn FH, 2006, IEEE T COMPUT, V55, P1081, DOI [10.1109/TC.2006.138, DOI 10.1109/TC.2006.138]
   [Anonymous], 2013, NIST SPECIAL DATABAS
   [Anonymous], 2006, Handbook of Multibiometrics
   Beng A, 2008, 3 IEEE C IND EL APPL, V5, P2145
   Chang YJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2203, DOI 10.1109/ICME.2004.1394707
   Choi H, 2011, IEEE T INF FOREN SEC, V6, P338, DOI 10.1109/TIFS.2010.2103940
   Condurache A, 2011, IEEE 2011 INT C DIG, P487
   Dahake P, 2015, 2015 INT C PERV COMP, P1
   Feng JJ, 2008, PATTERN RECOGN, V41, P342, DOI 10.1016/j.patcog.2007.04.016
   Gaddam S, 2010, INT J NETWORK SECURI, V11, P9
   Gaddam SV., 2010, IJ NETWORK SECURITY, V11, P61
   Gottschlich C, 2014, IET BIOMETRICS, V3, P291, DOI 10.1049/iet-bmt.2013.0065
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Hao F, 2006, IEEE T COMPUT, V55, P1081, DOI 10.1109/TC.2006.138
   Jaganathan P, 2011, 2011 INT C LOG INF C, P281
   Jain A., 2005, EUR SIGN P C, V5, P168
   Jianjiang F, 2011, 2011 INT C BAS BIOM, P1
   Johannesson R., 1999, FUNDAMENTALS CONVOLU
   Kanade S, 2008, P 6 BIOM S BSYM 2008, P59
   Kanade S., 2009, BTAS 09 P 3 IEEE INT, P1
   Kanade S., BTAS 2010 P 4 IEEE I, P1
   Kaur M, 2010, INT J COMPUT APPL, V4
   Lalithamani KSN, 2009, IEEE INT C ADV REC T, V9, P47
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Li P, 2012, EXPERT SYST APPL, V39, P6562, DOI 10.1016/j.eswa.2011.12.048
   Li S, 2013, IEEE T INF FOREN SEC, V8, P350, DOI 10.1109/TIFS.2012.2234740
   Maheshwari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P1247
   Msiza I, 2011, INT J MACHINE LEARNI, V1, P8
   Murillo-Escobar MA, 2015, EXPERT SYST APPL, V42, P8198, DOI 10.1016/j.eswa.2015.06.035
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Nguyen TH, 2013, J INF SECUR APPL, V18, P206, DOI 10.1016/j.jisa.2013.11.001
   Patil S, 2015, 2015 INT C VLSI SYST, P1
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Saggaf A, 2012, IEEE NAT WORKSH INF, P1
   Short NJ, 2012, IET BIOMETRICS, V1, P82, DOI 10.1049/iet-bmt.2011.0010
   Sousedik C, 2014, IET BIOMETRICS, V3, P219, DOI 10.1049/iet-bmt.2013.0020
   Stallings W., 2008, Cryptography and Network Security, V5th
   Stinson D., 1995, CRYPTO THEORY PRACTI
   Stoianov A, 2010, ANN CONF PRIV SECUR, P231, DOI 10.1109/PST.2010.5593246
   Nguyen TH, 2015, IET BIOMETRICS, V4, P29, DOI 10.1049/iet-bmt.2014.0026
   Upmanyu M, 2010, IEEE T INF FOREN SEC, V5, P255, DOI 10.1109/TIFS.2010.2043188
   Wicker SB., 1994, Reed-Solomon Codes and Their Applications
   Yang WC, 2014, PATTERN RECOGN, V47, P1309, DOI 10.1016/j.patcog.2013.10.001
   Zhang B, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P664, DOI 10.1109/ICBNMT.2011.6156019
NR 44
TC 18
Z9 18
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26979
EP 27000
DI 10.1007/s11042-017-4528-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000009
DA 2024-07-18
ER

PT J
AU Wang, X
   Zhan, YZ
AF Wang, Xinyn
   Zhan, Yongzhao
TI A zero-watermarking scheme for three-dimensional mesh models based on
   multi-features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh model; Copyright protection; Watermark; Zero-watermarking
ID 3D; ROBUST; FUSION; CUES
AB The aim of this study is to devise a zero-watermarking algorithm, the main challenge of which is the selection and construction of resilient features of three-dimensional(3D) models while improving the resilience of the zero-watermarking algorithm to common attacks. A novel zero-watermarking scheme for 3D mesh models based on multi-features is proposed in this paper. Using the Ordered Statistics Vertex Extraction and Tracing Algorithm, the stable vertices of a 3D model are determined. Then, the skewness measure of the shape diameter function values and vertex norms of the stable vertices are determined. Combined with the distribution feature of the number of stable vertices, a resilient watermark is applied. Experimental results show that the proposed scheme is not affected by a similarity transformation (such as translation, rotation, or uniform scaling) or vertex reordering. The scheme is also sufficiently resilient to noise, simplification, smoothing, and subdivision attacks. In addition, the scheme can resist cropping to a certain extent. The scheme proposed in this paper is suitable for applications that require 3D models with a higher accuracy and that cannot be embedded with a watermark that would modify the data of those models.
C1 [Wang, Xinyn; Zhan, Yongzhao] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Wang, X; Zhan, YZ (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
EM xywang@ujs.edu.cn; yzzhan@ujs.edu.cn
RI jin, li/IWU-4648-2023
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20113227110021]; Graduate Student Research and Innovation Foundation of
   Jiangsu Province of China [CX10B_273Z]
FX This work was supported by the Specialized Research Fund for the
   Doctoral Program of Higher Education(Grant No. 20113227110021) and the
   Graduate Student Research and Innovation Foundation of Jiangsu Province
   of China(Grant No. CX10B_273Z).
CR Abdallah Alaa E., 2015, International Journal of Security and Networks, V10, P1, DOI 10.1504/IJSN.2015.068390
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Agarwal P, 2009, IEEE T INF FOREN SEC, V4, P36, DOI 10.1109/TIFS.2008.2011081
   [Anonymous], INT J DIGIT CONTENT
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], 3 INT C ED REF MOD
   Benedens O, 1999, IEEE COMPUT GRAPH, V19, P46, DOI 10.1109/38.736468
   Benedens O., 1999, P MULT SEC WORKSH AC, V99, P95
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Bors AG, 2006, IEEE T IMAGE PROCESS, V15, P687, DOI 10.1109/TIP.2005.863116
   Chen Z, 2006, P 2006 IEEE INT C AC, P2
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   [杜顺 Du Shun], 2013, [计算机辅助设计与图形学学报, Journal of Compute-Aided Design and Graphics], V25, P653
   Eskizara Omer, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P932, DOI 10.1109/SIU.2009.5136550
   [冯小青 FENG Xiao-qing], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1534
   Garg H, 2013, ROM J INF SCI TECH, V16, P287
   Gu XG, 2013, SIGNAL PROCESS, V93, P2244, DOI 10.1016/j.sigpro.2012.07.014
   Hu Min, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P390
   Jin Jian-Qiu, 2004, J Zhejiang Univ Sci, V5, P251, DOI 10.1631/jzus.2004.0251
   Kanai S., 1998, IFIP WG, P296
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kim MS, 2005, LECT NOTES COMPUT SC, V3710, P313
   Kwon KR, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P499
   Lee GW, 2005, IEICE T FUND ELECTR, VE88A, P1512, DOI 10.1093/ietfec/e88-a.6.1512
   Lee SH, 2007, DIGIT SIGNAL PROCESS, V17, P396, DOI 10.1016/j.dsp.2005.04.014
   Lee SH, 2014, MULTIMED TOOLS APPL, V73, P1723, DOI 10.1007/s11042-013-1643-1
   Lee SH, 2013, DIGIT SIGNAL PROCESS, V23, P1505, DOI 10.1016/j.dsp.2013.04.012
   Lee SH, 2012, DIGIT SIGNAL PROCESS, V22, P744, DOI 10.1016/j.dsp.2012.04.015
   Lin CH, 2010, VISUAL COMPUT, V26, P1101, DOI [10.1007/s00371-010-0461-y, 10.1007/s00371-010-0461]
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Liu Y, 2016, ARXIV161009462CSCY
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2015, P 24 INT JOINT C ART, P117
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Matei B, 2006, IEEE T PATTERN ANAL, V28, P1111, DOI 10.1109/TPAMI.2006.148
   Mun SM, 2015, P 2015 INT C 3D IM
   Ohbuchi R, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P261, DOI 10.1145/266180.266377
   Ohbuchi R, 1998, COMPUT COMMUN, V21, P1344, DOI 10.1016/S0140-3664(98)00202-3
   Qin Y, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTERNET OF THINGS, P85, DOI 10.1109/ICAIOT.2015.7111544
   Sehgal A, 2003, PATTERN RECOGN, V36, P765, DOI 10.1016/S0031-3203(02)00102-4
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Soliman MM, 2016, ADV INTELL SYST, V427, P617, DOI 10.1007/978-3-319-29504-6_57
   Soliman MM, 2015, ADV INTELL SYST COMP, V323, P731, DOI 10.1007/978-3-319-11310-4_64
   Soliman MM, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P99, DOI 10.1109/ICCES.2013.6707181
   Sun SS, 2005, P 2005 IE WORKSH MUL
   Vasic B, 2012, ADV ELECTR COMPUT EN, V12, P25, DOI 10.4316/AECE.2012.04004
   Wang JR, 2012, VISUAL COMPUT, V28, P1049, DOI 10.1007/s00371-011-0650-3
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang Rui, 2013, Journal of Shanghai Jiaotong University, V47, P1863
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Wibowo SA, 2014, INT J FUZZY LOGIC IN, V14, P249
   Xiuhu Tan, 2013, Journal of Theoretical and Applied Information Technology, V51, P175
   [徐涛 XU Tao], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P1819
   Xu Tao, 2007, Journal of Jilin University (Engineering and Technology Edition), V37, P901
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yin Kang-Kang, 2001, Journal of Computer Aided Design & Computer Graphics, V13, P102
   Yu ZQ, 2003, PATTERN RECOGN, V36, P2603, DOI 10.1016/S0031-3203(03)00086-4
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zaid AO, 2015, MULTIMED TOOLS APPL, V74, P5897, DOI 10.1007/s11042-014-1896-3
   Zhang JW, 2009, I C COMP GRAPH IM VI, P510, DOI 10.1109/CGIV.2009.49
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
NR 74
TC 11
Z9 12
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27001
EP 27028
DI 10.1007/s11042-017-4666-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000010
DA 2024-07-18
ER

PT J
AU Zhang, LN
   Wei, DY
AF Zhang, Lina
   Wei, Deyun
TI Dual DCT-DWT-SVD digital watermarking algorithm based on particle swarm
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Particle swarm optimization; Generalized Arnold
   transform; Discrete cosine transform; Discrete wavelet transform;
   Singular value decomposition
ID IMAGE WATERMARKING; SCHEME; ROBUST; PROTECTION
AB Robust invisible watermarking plays an important role in copyright protection. Such watermarking has high requirements for robustness and security, and transparency and capacity cannot be ignored. Although there are many algorithms using singular value decomposition, most algorithms do not take security and reliability into account. Moreover, a meaningful watermark cannot be extracted under some attacks, resulting in the failure of copyright protection. In this paper, combined with particle swarm optimization (PSO), a secure and robust dual-embedded watermarking algorithm is proposed. First, the watermark image is encrypted by the generalized Arnold transform, then the original host image and the encrypted watermark image are processed by discrete cosine transform and multi-level discrete wavelet transform, and the singular values of the watermark image are embedded into the low-frequency and high-frequency regions of the host image, respectively. In addition, the embedding factor matrices are optimized by PSO. The simulation results based on the normal and medical host and watermark images show that the algorithm can meet the four basic characteristics of the watermarking algorithm. Moreover, the proposed watermarking algorithm has high capacity and good robustness, and can extract watermark with good visual effect under most attacks, so it can be used in copyright protection.
C1 [Zhang, Lina; Wei, Deyun] Xidian Univ, Sch Math & Stat, Xian 710126, Shaanxi, Peoples R China.
C3 Xidian University
RP Zhang, LN (corresponding author), Xidian Univ, Sch Math & Stat, Xian 710126, Shaanxi, Peoples R China.
EM linazhang2017@126.com
OI Zhang, Lina/0000-0002-5529-7118
FU National Natural Science Foundation of China [11601406]; Natural Science
   Foundation of Shaanxi Province [2018JM6044, 2018JQ1024]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 11601406, the Natural Science Foundation
   of Shaanxi Province under Grants 2018JM6044 and 2018JQ1024.
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Beheshti Z, 2015, APPL SOFT COMPUT, V28, P345, DOI 10.1016/j.asoc.2014.12.015
   Bekkouch S, 2015, J INF PROCESS SYST, V11, P406, DOI 10.3745/JIPS.02.0021
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Divecha N, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P204, DOI 10.1109/ISSP.2013.6526903
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Furqan A, 2015, 2015 IEEE INT C COMP
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Handito KW, 2018, J PHYS CONF SER, V971, DOI 10.1088/1742-6596/971/1/012006
   Harjito B, 2017, AIP CONF PROC, V1813, DOI 10.1063/1.4975968
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Joseph A, 2013, INT J SIGNAL IMAGE P, V1
   Kasana G, 2017, OPTIK, V142, P191, DOI 10.1016/j.ijleo.2017.05.027
   Kaur R, 2015, INT J LATEST TRENDS, V5, P459
   Li CH, 2012, IEEE T SYST MAN CY B, V42, P627, DOI 10.1109/TSMCB.2011.2171946
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Maloo S, 2017, INFORM COMMUNICATION, V1, P509
   Mehto A, 2016, PROCEDIA COMPUT SCI, V78, P88, DOI 10.1016/j.procs.2016.02.015
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Muthumanickam S, 2018, MICROSYST TECHNOL, V24, P1565, DOI 10.1007/s00542-017-3578-3
   Nandi S, 2016, ADV INTELL SYST, V394, P69, DOI 10.1007/978-81-322-2656-7_7
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Niu YY, 2016, LECT NOTES ELECTR EN, V369, P303, DOI 10.1007/978-981-10-0072-0_39
   Pandey P, 2014, MULTIMED TOOLS APPL, V72, P723, DOI 10.1007/s11042-013-1375-2
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Saikrishna N, 2016, PROCEDIA COMPUT SCI, V93, P808, DOI 10.1016/j.procs.2016.07.299
   Saxena P, 2012, 2 INT C COMP SCI INF, P138
   Saxena S, INT J ELECT COMPUT S, V4
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2014, P NATL A SCI INDIA A, V84, P345, DOI 10.1007/s40010-014-0140-x
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Wang CY, 2017, J INF PROCESS SYST, V13, P1585, DOI 10.3745/JIPS.03.0086
   Wang YB, 2012, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE - 2011, VOL 6, PTS A AND B, P911
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Yadav B, 2018, SOFT COMPUTING THEOR
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang Z, 2016, INT CONF SIGN PROCES, P805, DOI 10.1109/ICSP.2016.7877942
NR 48
TC 42
Z9 46
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 28003
EP 28023
DI 10.1007/s11042-019-07902-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000055
DA 2024-07-18
ER

PT J
AU Zhou, XP
   Wang, J
   Guo, M
   Gao, Z
AF Zhou, Xiaoping
   Wang, Jia
   Guo, Ming
   Gao, Zhe
TI Cross-platform online visualization system for open BIM based on WebGL
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-platform; Open BIM; Online visualization system; WebGL
ID DELAUNAY TRIANGULATION; MODEL
AB Online BIM visualization system is the first and primary task for building web applications of BIM. Light-weighted, cross-platform and open are three basic rules when building online BIM visualization systems. Currently, some efforts have been made on BIM visualization. However, most of them are designed for local BIM, and the online ones neglect the network load (without light-weighted) or are platform dependent (without cross-platform). This study develops a novel online BIM visualization system based on IFC and WebGL, termed as WebBIM. WebBIM firstly converts the raw IFC geometry data into triangles, light-weights the BIM geometry data by sharing the geometry data among the object instances generated from the same facility component, compresses the geometry, and directly renders the decompressed triangular BIM data in web browsers. Finally, empirical studies from extensive real projects' BIM data show that WebBIM is efficient, capable of visualization of large BIM files and compatible with mainstream devices.
C1 [Zhou, Xiaoping; Wang, Jia; Gao, Zhe] Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 100044, Peoples R China.
   [Guo, Ming] Beijing Univ Civil Engn & Architecture, Inst Mapping & Urban Spatial Informat, Beijing 100044, Peoples R China.
C3 Beijing University of Civil Engineering & Architecture; Beijing
   University of Civil Engineering & Architecture
RP Zhou, XP; Wang, J (corresponding author), Beijing Univ Civil Engn & Architecture, Beijing Key Lab Intelligent Proc Bldg Big Data, Beijing 100044, Peoples R China.; Guo, M (corresponding author), Beijing Univ Civil Engn & Architecture, Inst Mapping & Urban Spatial Informat, Beijing 100044, Peoples R China.
EM lukefchou@gmail.com; wangjia@bucea.edu.cn; guoming@bucea.edu.cn
FU Beijing Natural Science Foundation [4174087]; Scientific Research
   Project of Beijing Educational Committee [SQKM201710016002]; Natural
   Science Foundation of China [71601013, 71531012]
FX This work was supported by the Beijing Natural Science Foundation under
   grant no. 4174087, the Scientific Research Project of Beijing
   Educational Committee under grand no. SQKM201710016002, and the Natural
   Science Foundation of China under grant nos. 71601013 and 71531012.
CR Afsari K, 2017, AUTOMAT CONSTR, V77, P24, DOI 10.1016/j.autcon.2017.01.011
   [Anonymous], 2012, WEBGL RUNNING
   [Anonymous], INT ALLIANCE INTEROP
   Azhar S., 2011, LEADERSHIP MANAGEMEN, V11, P241, DOI [10.1061/(ASCE)LM.1943-5630.0000127, DOI 10.1061/(ASCE)LM.1943-5630.0000127]
   Deutsch P., 1996, document RFC 1952, P1
   Eastman CM, 2011, BOOK BIM HDB GUIDE B
   Hammad A, 2006, COMPUT-AIDED CIV INF, V21, P530, DOI 10.1111/j.1467-8667.2006.00456.x
   Hu Z., 2008, Tsinghua Science and Technology, V13, P266, DOI DOI 10.1016/S1007-0214(08)70160-3
   Kim MK, 2016, AUTOMAT CONSTR, V72, P102, DOI 10.1016/j.autcon.2016.08.035
   Liu XJ, 2016, GRAPH MODELS, V88, P40, DOI 10.1016/j.gmod.2016.06.001
   RAJAN VT, 1994, DISCRETE COMPUT GEOM, V12, P189, DOI 10.1007/BF02574375
   REBAY S, 1993, J COMPUT PHYS, V106, P125, DOI 10.1006/jcph.1993.1097
   Teo TA, 2016, ADV ENG INFORM, V30, P268, DOI 10.1016/j.aei.2016.04.007
   Zhang JP, 2011, AUTOMAT CONSTR, V20, P155, DOI 10.1016/j.autcon.2010.09.013
NR 14
TC 34
Z9 43
U1 9
U2 144
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28575
EP 28590
DI 10.1007/s11042-018-5820-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700013
DA 2024-07-18
ER

PT J
AU Banerjee, A
   Jana, B
AF Banerjee, Ananya
   Jana, Biswapati
TI A robust reversible data hiding scheme for color image using
   reed-solomon code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Reed-solomon code; Image encryption; Color image; Image
   recovery; Reversible data hiding; BM; Forney; Chien-search
ID WATERMARKING TECHNIQUE
AB This article encompasses an effective scheme regarding reversible data hiding methodology that is achieved as an objective when Reed-Solomon (RS) codes are employed on a color image. Insertion of two additional pixels is done within the block of 5 pixels through linear interpolation with a view to carry the remainder of encoding polynomial epsilon(x) when divided by generating polynomial psi(x). The task of data embedding is done within the additional two pixels after the aforesaid color image is partitioned into R, G, B components. The secret data bits are positioned through error creation adjusting with the last three bits(LSB) of each pixel of the block to ensure almost exact quality of the image. The said hidden data can be extricated successfully by the intended receiver without any distortion whereas reconstruction of original cover image can be done. Indeed, better results in terms of quality is experienced after having compared the proposed methodology with similar schemes in vogue. Finally some standard steganographic analysis is employed to test the robustness of the obtained stego image. The intended outcome brought into limelight some remarkable sublime characteristics in the field of image authentication, tamper detection and digital forgery detection without which the technological life is stunted. Innumerable government and private sector facet including health care, commercial security, defence, intellectual property rights gets immensely benefited from this scheme.
C1 [Banerjee, Ananya] Basanti Devi Coll, Kolkata 700029, India.
   [Jana, Biswapati] Vidyasagar Univ Midnapore, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Banerjee, A (corresponding author), Basanti Devi Coll, Kolkata 700029, India.
EM anaanya.2011@gmail.com; biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
CR [Anonymous], 2014, ARXIV14114790
   Banerjee Ananya, 2017, Communication, Devices, and Computing. ICCDC 2017. Proceedings: LNEE 470, P127, DOI 10.1007/978-981-10-8585-7_12
   Banerjee A, 2018, ADV INTELL SYST, V672, P356, DOI 10.1007/978-981-10-7512-4_36
   Chaari Lamia, 2009, WSEAS Transactions on Circuits and Systems, V8, P729
   Chang CJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/526806
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Diop I., 2012, INT J DISTRIBUTED PA, V3, P81, DOI DOI 10.5121/ijdps.2012.3207
   Hill T, 2013, REED SOLOMON CODES E
   Huang YH, 2014, MULTIMED TOOLS APPL, V70, P1439, DOI 10.1007/s11042-012-1176-z
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P8805, DOI 10.1007/s11042-017-4775-x
   Jana B, 2018, MULTIMED TOOLS APPL, V77, P763, DOI 10.1007/s11042-016-4230-4
   Jana B, 2017, MULTIMED TOOLS APPL, V76, P21691, DOI 10.1007/s11042-016-3990-1
   Kim C, 2014, LECT NOTES ELECTR EN, V301, P697, DOI 10.1007/978-94-017-8798-7_80
   Kim S, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9050061
   Kim T, 2015, 2015 3RD INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD) AND INTERNATIONAL CONFERENCE ON OPEN AND BIG (OBD), P765, DOI 10.1109/FiCloud.2015.31
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Liu L, 2016, MULTIMED TOOLS APPL, V75, P11311, DOI 10.1007/s11042-015-2855-3
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meikap S, 2018, MULTIMED TOOLS APPL, V77, P31281, DOI 10.1007/s11042-018-6203-2
   Parah SA, 2017, INTEL SYST REF LIBR, V115, P223, DOI 10.1007/978-3-319-44270-9_10
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2015, SECUR COMMUN NETW, V8, P899, DOI 10.1002/sec.1046
   Rapajic PB, 2002, 2002 WSEAS INT C EL, P451
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Song ML, 2013, NEUROCOMPUTING, V119, P222, DOI 10.1016/j.neucom.2013.03.037
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   University of Southern California, 2015, USC SIPI IMAGE DATAB
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang H, 2015, IEEE PHOTONIC TECH L, V27, P15, DOI 10.1109/LPT.2014.2359654
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 36
TC 6
Z9 6
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24903
EP 24922
DI 10.1007/s11042-019-7626-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900056
DA 2024-07-18
ER

PT J
AU He, YD
   Zhou, JF
   Yuen, SY
AF He, Yaodong
   Zhou, Jianfeng
   Yuen, Shiu Yin
TI Composing photomosaic images using clustering based evolutionary
   programming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photomosaic; Evolutionary algorithm; Evolutionary programming;
   Combinatorial optimization
ID ALGORITHM
AB Photomosaic images are a type of images consisting of various tiny images. In the past, many approaches have been proposed trying to automatically compose photomosaic images. To obtain a better visual sense and satisfy some commercial requirements, a constraint that a tiny image should not be repeatedly used many times is usually added. With the constraint, algorithms using greedy mechanism fail to solve it. In this paper, we present an approach called clustering based evolutionary programming to deal with the problem. Our new approach has a similar mechanism to that of evolutionary programming (we adopt mutation, selection and fitness evaluation) and uses the normalized color histogram information as the prior information. The two characteristics make our approach converges fast and performs well. In our experiment, the proposed algorithm is compared with the state of the art algorithms and software. The results indicate that our algorithm is able to generate higher quality photomosaic images.
C1 [He, Yaodong; Zhou, Jianfeng; Yuen, Shiu Yin] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yuen, SY (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM yaodonghe2-c@my.cityu.edu.hk; jfzhou2-c@my.cityu.edu.hk;
   kelviny.ee@cityu.edu.hk
OI YUEN, Shiu Yin Kelvin/0000-0002-5889-8808; ZHOU,
   Jianfeng/0000-0002-5916-6457; He, Yaodong/0000-0002-2364-746X
FU CityU Strategic Grant [7004610]; City University of Hong Kong
FX The work described in this paper was supported by a CityU Strategic
   Grant (Project No. 7004610). Yaodong He and Jianfeng Zhou acknowledge
   the Institutional Postgraduate Studentship from City University of Hong
   Kong. The authors would like to thank Dr. Yang Lou for his valuable
   comments.
CR [Anonymous], 2012, Genetic Algorithms: Concepts and Designs
   Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, P3, DOI 10.1109/4235.585888
   Back T., 1996, EVOLUTIONARY ALGORIT
   Battiato S, 2007, COMPUT GRAPH FORUM, V26, P794, DOI 10.1111/j.1467-8659.2007.01021.x
   Blasi GD, 2005, P INT C CENTR EUR CO, P1
   Ijaz S, 2018, APPL INTELL, V48, P1086, DOI 10.1007/s10489-017-1026-9
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lama RK, 2014, MULTIMED TOOLS APPL, V73, P873, DOI 10.1007/s11042-013-1381-4
   Lee HY, 2017, MULTIMED TOOLS APPL, V76, P24281, DOI 10.1007/s11042-016-4175-7
   Li CJ, 2017, 2017 2ND ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS), P345, DOI 10.1109/ACIRS.2017.7986121
   Ruiz IL, 2018, MULTIMED TOOLS APPL, V77, P15291, DOI 10.1007/s11042-017-5115-x
   Marcelino CG, 2018, APPL INTELL, V48, P3672, DOI 10.1007/s10489-018-1167-5
   Narasimhan H, 2009, WOR CONG NAT BIOL, P776
   Plant W, 2013, MULTIMED TOOLS APPL, V64, P695, DOI 10.1007/s11042-011-0951-6
   Sah SBM, 2008, LECT NOTES COMPUT SC, V5361, P259
   Seo S, 2016, MULTIMED TOOLS APPL, V75, P12831, DOI 10.1007/s11042-015-2867-z
   Silvers R., 1997, Photomosaics
   Wei H, 2015, APPL INTELL, V43, P112, DOI 10.1007/s10489-014-0633-y
NR 18
TC 3
Z9 4
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25919
EP 25936
DI 10.1007/s11042-019-07798-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700031
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, A
   Sachdeva, N
AF Kumar, Akshi
   Sachdeva, Nitin
TI Cyberbullying detection on social multimedia using soft computing
   techniques: a meta-analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyberbullying; Social multimedia; Soft computing; Machine learning;
   Meta-analysis
AB Cyberbullying is to bully someone in the digital realm. It has become extremely detrimental as the social media and the internet have become more popular and omnipresent. People use the internet services to viciously attack others from behind a screen. The substantial growth in the dimensionality, heterogeneity, subjectivity and multimodality of social media and the pressing need to timely curtail the damage instigated through cyberbullying, has fostered the need to devise automated mechanisms which detect such unfavorable activities. The use of soft computing techniques to handle such pernicious issue has been studied invariably and widely in literature. This study is to understand the viability, scope and significance of this alliance of using soft computing techniques for cyberbullying detection on social multimedia. This work is a systematic literature review to gather, explore, comprehend and analyze the research trends, gaps and prospects of this pairing in a well-organized way. The contribution of this study is noteworthy as it focuses on the use and application of soft computing techniques for cyberbullying detection on social multimedia utilizing a meta-analytic approach in order to integrate, interpret and critically analyze the findings in the original studies for expounding novel approaches to achieve comparable and effectual results pertaining to the defined research domain. Published studies starting April 2003, accessed from six digital portals (ACM, IEEE, Elsevier, Wiley, Springer and Taylor and Francis) have been reviewed to expound the state-of-art within the domain to give insightsand finally identify the directions of future research.
C1 [Kumar, Akshi; Sachdeva, Nitin] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Delhi Technological University
RP Kumar, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM akshikumar@dce.ac.in; nits.usit@gmail.com
RI Kumar, Akshi/Y-9314-2019
OI Kumar, Akshi/0000-0003-4263-7168
CR Agrawal S, 2018, LECT NOTES COMPUT SC, V10772, P141, DOI 10.1007/978-3-319-76941-7_11
   Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   [Anonymous], 2009, Proceedings of the Content Analysis in the WEB
   [Anonymous], 2016, P ACM INT C AUTOMATI, DOI DOI 10.1145/2833312.2849567
   [Anonymous], 2018, NEURAL NETWORKS DEEP, DOI DOI 10.1007/978-3-319-94463-0
   [Anonymous], 2013, P 5 ANN ACM WEB SCI
   Ashktorab Z, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P3, DOI 10.1145/3091478.3091499
   Balakrishnan V, 2015, COMPUT HUM BEHAV, V46, P149, DOI 10.1016/j.chb.2015.01.021
   Balci K, 2015, COMPUT HUM BEHAV, V53, P517, DOI 10.1016/j.chb.2014.10.025
   Bourgonje P., 2017, INT C GERMAN SOC COM, P180
   Bu SJ, 2018, LECT NOTES ARTIF INT, V10870, P561, DOI 10.1007/978-3-319-92639-1_47
   Byrne S, 2014, J COMPUT-MEDIAT COMM, V19, P215, DOI 10.1111/jcc4.12040
   Campbell M.A., 2005, Australian Journal of Guidance and Counselling, V15, P68, DOI [10.1375/ajgc.15.1.68, DOI 10.1375/AJGC.15.1.68]
   Chatzakou D, 2017, PROCEEDINGS OF THE 28TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT'17), P65, DOI 10.1145/3078714.3078721
   Chatzakou D, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P13, DOI 10.1145/3091478.3091487
   Chatzakou D, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P767, DOI 10.1145/3041021.3054211
   Chavan VS, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2354, DOI 10.1109/ICACCI.2015.7275970
   Chen JY, 2020, NEURAL COMPUT APPL, V32, P10809, DOI 10.1007/s00521-018-3442-0
   Coletto M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1465, DOI 10.1145/3184558.3191594
   Dadvar Maral, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P693, DOI 10.1007/978-3-642-36973-5_62
   Dadvar M, 2014, LECT NOTES COMPUT SC, V8436, P275, DOI 10.1007/978-3-319-06483-3_25
   Garcia-Recuero A., 2017, Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017, P1132, DOI [10.1145/3110025, DOI 10.1145/3110025]
   Gordeev D, 2016, PROCD SOC BEHV, V236, P71, DOI 10.1016/j.sbspro.2016.12.022
   Gordeev D, 2016, LECT NOTES COMPUT SC, V9811, P240, DOI 10.1007/978-3-319-43958-7_28
   Haidar Azzam., 2017, Investigating half precision arithmetic to accelerate dense linear system solvers, P1
   Hammer H.L., 2016, IND NETWORKS INTELLI, P164
   Holt TJ, 2014, J CRIM JUST, V42, P347, DOI 10.1016/j.jcrimjus.2014.04.004
   Hosseinmardi H, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P186, DOI 10.1109/ASONAM.2016.7752233
   Ibn Rafiq R, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0398-x
   Ibn Rafiq R, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P617, DOI 10.1145/2808797.2809381
   Kitchenham B., 2007, 2007001 EBSE
   Koban K, 2018, COMPUT HUM BEHAV, V79, P9, DOI 10.1016/j.chb.2017.10.015
   Michalopoulos D, 2014, COMPUT SECUR, V42, P177, DOI 10.1016/j.cose.2013.12.004
   Nahar Vinita, 2012, Web Technologies and Applications. Proceedings of the 14th Asia-Pacific Web Conference, APWeb 2012, P767, DOI 10.1007/978-3-642-29253-8_75
   Nahar V, 2014, LECT NOTES COMPUT SC, V8506, P160
   Nandhini BS, 2015, PROCEDIA COMPUT SCI, V45, P485, DOI 10.1016/j.procs.2015.03.085
   Papegnies Etienne, 2017, Statistical Language and Speech Processing. 5th International Conference, SLSP. Proceedings: LNAI 10583, P70, DOI 10.1007/978-3-319-68456-7_6
   Parime S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1541, DOI 10.1109/ICCPCT.2014.7054943
   Potha N, 2016, KNOWL-BASED SYST, V96, P134, DOI 10.1016/j.knosys.2015.12.021
   Thu PP, 2017, 2017 18TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNDP 2017), P149, DOI 10.1109/SNPD.2017.8022715
   Raisi Elaheh, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P409, DOI 10.1145/3110025.3110049
   Rakib TBA, 2018, LECT NOTES ARTIF INT, V10751, P180, DOI 10.1007/978-3-319-75417-8_17
   Reynolds K., 2011, Proceedings of the 2011 Tenth International Conference on Machine Learning and Applications (ICMLA 2011), P241, DOI 10.1109/ICMLA.2011.152
   Salawu S, 2020, IEEE T AFFECT COMPUT, V11, P3, DOI 10.1109/TAFFC.2017.2761757
   Sarna G, 2017, INT J MACH LEARN CYB, V8, P677, DOI 10.1007/s13042-015-0463-1
   Sedano CR, 2017, LECT NOTES ARTIF INT, V10245, P315, DOI 10.1007/978-3-319-59063-9_28
   Sharma H, 2018, 3RD INTERNATIONAL CONFERENCE ON INNOVATIVE APPLICATIONS OF COMPUTATIONAL INTELLIGENCE ON POWER, ENERGY AND CONTROLS WITH THEIR IMPACT ON HUMANITY (CIPECH-18), P26
   Sheeba JI, 2013, P IEEE INT C COMP IN, P1
   Wint ZZ, 2017, 2017 TWELFTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P209, DOI 10.1109/ICDIM.2017.8244677
   Xu J. M., 2012, P 2012 C N AM CHAPT, P656
   Ybarra M., 2010, NAT SUMM INT VIOL AB
   Zhang X, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P740, DOI [10.1109/ICMLA.2016.0132, 10.1109/ICMLA.2016.71]
   Zhao R, 2017, IEEE T AFFECT COMPUT, V8, P328, DOI 10.1109/TAFFC.2016.2531682
NR 53
TC 29
Z9 29
U1 1
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 23973
EP 24010
DI 10.1007/s11042-019-7234-z
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900010
DA 2024-07-18
ER

PT J
AU Kumar, A
   Sangwan, SR
   Nayyar, A
AF Kumar, Akshi
   Sangwan, Saurabh Raj
   Nayyar, Anand
TI Rumour veracity detection on twitter using particle swarm optimized
   shallow classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rumour; Classifier; Veracity; Feature selection; Swarm
AB Information overload on Web has been a well-identified challenge which has amplified with the advent of social web. Good, bad, true, false, useful, useless all kinds of information disseminates through the social web platforms. It becomes exceedingly imperative to pro-actively resolve rumours and inhibit them from spreading among the Internet users as it can jeopardize the well-being of the citizens. The task for rumour analysis intends to identify & classify a rumour either as true (factual), false (nonfactual) or unresolved. Determining the accuracy of a rumourous story, a.k.a. rumour veracity is hard owing to the noisy, ambiguous and heterogeneous use of natural language. This necessitates automation of the predictive task which classifies the questionable veracity of rumour accurately. The research presented in this paper, is an empirical study to put forward an optimized learning model which classifies real-time tweets on the basis of truth value, facilitating rumour analysis. The study is conducted on a collection of nearly 14 k tweets pertaining to the recent mob lynching fuelled by rumours on suspected child-lifters in the Indian sub-continent (#moblynching) and run on five classical shallow classifiers to categorize tweets into true, false and unspecified using 13 attributes (features). Subsequently, the use of an optimal feature selection method, particle swarm algorithm is proposed to improve the classifier's performance. The empirical analysis validates that the proposed implementation of particle swarm optimization (PSO) for feature subset selection in rumour veracity classification outperforms the baseline supervised learning algorithms. An average 11.28% improvement in accuracy and approximately 31% average reduction in features are demonstrated using PSO. The highest accuracy with optimization of 96.15% is achieved by decision tree.
C1 [Kumar, Akshi; Sangwan, Saurabh Raj] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
C3 Delhi Technological University; Duy Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang, Vietnam.
EM akshikumar@dce.ac.in; saurabhsangwan2610@gmail.com;
   anandnayyar@duytan.edu.vn
RI Kumar, Akshi/Y-9314-2019; Nayyar, Anand/F-3732-2015
OI Kumar, Akshi/0000-0003-4263-7168; Nayyar, Anand/0000-0002-9821-6146;
   Sangwan, Saurabh/0000-0002-0832-0362
CR Aggarwal A, 2018, P SAC 2018 S APPL CO, V8
   Aghdam MH, 2015, J ARTIF INTELL SOFT, V5, P231, DOI 10.1515/jaiscr-2015-0031
   Alzubi J, 2018, J PHYS CONF SER, V1142, DOI 10.1088/1742-6596/1142/1/012012
   [Anonymous], 2015, THESIS
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/IJST/2015/V8I1/105286
   [Anonymous], 2011, P ESWC 11
   Ben Veyseh AP, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2335, DOI 10.1145/3132847.3133116
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Cheng Chang, 2016, Advanced Data Mining and Applications. 12th International Conference, ADMA 2016. Proceedings: LNAI 10086, P751, DOI 10.1007/978-3-319-49586-6_54
   Chua Alton YK, 2016, P INT MULT ENG COMP, V1
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Enayet O, 2017, P SEMEVAL ACL
   Giasemidis Georgios, 2016, Social Informatics. 8th International Conference, SocInfo 2016. Proceedings: LNCS 10046, P185, DOI 10.1007/978-3-319-47880-7_12
   Gorrell G, 2019, DETERMINING RUMOUR V
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KUMAR A, 2015, INT CONF CONTEMP, P285
   Kumar A., 2018, INT J COMPUTER SCI E, V6, P642, DOI [10.26438/ijcse/v6i6.642651, DOI 10.26438/IJCSE/V6I6.642651]
   Kumar A., 2018, LECT NOTES NETWORKS
   Kumar A, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5107
   Kumar A, 2018, P NATL A SCI INDIA A, V88, P95, DOI 10.1007/s40010-017-0369-2
   Kwon S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168344
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Liu X., 2015, P 24 ACM INT C INF K, P1867, DOI [10.1145/2806416.2806651, DOI 10.1145/2806416.2806651]
   Loper E, 2002, ETMTNLP 02 P ACL 02, P63, DOI [10.3115/1225403.1225421, DOI 10.3115/1225403.1225421, DOI 10.3115/1118108.1118117]
   Ma B, 2017, ADV INTELL SYST, V513, P245, DOI 10.1007/978-3-319-46562-3_16
   Ma J., 2015, P 24 ACM INT C INF K, P1751, DOI DOI 10.1145/2806416.2806607
   Omar N., 2013, Journal of Information System Research and Innovation, V3, P64
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Serrano E, 2015, LECT NOTES ARTIF INT, V9329, P113, DOI 10.1007/978-3-319-24069-5_11
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang SH, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2709, DOI 10.1109/BigData.2015.7364071
   Wang XY, 2007, PATTERN RECOGN LETT, V28, P459, DOI 10.1016/j.patrec.2006.09.003
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Yang F., 2012, P ACM SIGKDD WORKSH, V13
   Zhang ZL, 2015, HEALTH INFO LIBR J, V32, P195, DOI 10.1111/hir.12115
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 38
TC 30
Z9 30
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24083
EP 24101
DI 10.1007/s11042-019-7398-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900016
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Gao, ED
AF Pan, Zhibin
   Gao, Erdun
TI Reversible data hiding based on novel embedding structure PVO and
   adaptive block-merging strategy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Pixel-value-ordering (PVO); Three-pixel
   embedding structure (TPES); Adaptive block-merging strategy
ID PREDICTION-ERROR EXPANSION; WATERMARKING; SCHEME; ALGORITHM
AB In data hiding field, pixel-value-ordering (PVO)-based methods yield excellent performances by taking full advantage of correlation in a fixed block. In PVO-based methods, the maximum and minimum of each block are utilized to embed data. The maximal embedding capacity (EC) is achieved by setting embedding block size smaller to generate more basic embedding blocks. In this light, a new three-pixel embedding structure is proposed to improve the maximal EC by reducing the number of pixels in each basic block. Meanwhile, unlike conventional algorithms which take the noise level of current block as complexity, we utilize the correlation information among neighboring blocks to get a better classification on embedding blocks. Moreover, dynamic block partition method is further investigated and an adaptive block-merging strategy is proposed in this paper. In this strategy, a more rational way is provided to exploit the embedding potential than the top-down partition method and the performance is significantly enhanced. With these three new improvements, our scheme exhibits better performance than the state-of-the-art PVO-based methods.
C1 [Pan, Zhibin; Gao, Erdun] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Jiangxi, Peoples R China.
C3 Xi'an Jiaotong University; Nanchang Hangkong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.; Pan, ZB (corresponding author), Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Jiangxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of Key Laboratory of Jiangxi Province for Image
   Processing and Pattern Recognition, Nanchang Hangkong University
   [TX2014001]
FX This work is supported by the Open Project Program of Key Laboratory of
   Jiangxi Province for Image Processing and Pattern Recognition, Nanchang
   Hangkong University (Grant No. TX2014001).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2017, IEEE T INF FORENSICS
   [Anonymous], 2017, IEEE T INFORM FORENS
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/104835
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wan WB, 2020, MULTIMED TOOLS APPL, V79, P4907, DOI 10.1007/s11042-018-6860-1
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang C, 2010, IEEE IMAGE PROC, P3673, DOI 10.1109/ICIP.2010.5652508
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2018, MULTIMED TOOLS APPL, V77, P13419, DOI 10.1007/s11042-017-4959-4
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 46
TC 9
Z9 9
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26047
EP 26071
DI 10.1007/s11042-019-7692-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700036
DA 2024-07-18
ER

PT J
AU Saliha, M
   Ali, B
   Rachid, S
AF Saliha, Mezzoudj
   Ali, Behloul
   Rachid, Seghir
TI Towards large-scale face-based race classification on spark framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Race classification; Logistic regression; Local Binary Pattern; Spark;
   Large-scale face images
ID GENDER; PATTERNS; DATABASE; ATTACKS
AB Recently, the identification of an individual race has become an important research topic in face recognition systems, especially in large-scale face images. In this paper, we propose a new large-scale race classification method which combines Local Binary Pattern (LBP) and Logistic Regression (LR) on Spark framework. LBP is used to extract features from facial images, while spark's logistic regression is used as a classifier to improve the accuracy and speedup the classification system. The race recognition method is performed on Spark framework to process, in a parallel way, a large scale of data. The evaluation of our proposed method has been performed on two large face image datasets CAS-PEAL and Color FERET. Two major races were considered for this work, including Asian and Non-Asian races. As a result, we achieve the highest race classification accuracy (99.99%) compared to Linear SVM, Naive Bayesian (NB), Random Forest(RF), and Decision Tree (DT) Spark's classifiers. Our method is compared against different state-of-the-art methods on race classification, the obtained results show that our approach is more efficient in terms of accuracy and processing time.
C1 [Saliha, Mezzoudj; Ali, Behloul; Rachid, Seghir] Univ Batna 2, LaSTIC Lab, Batna, Algeria.
C3 University of Batna 2
RP Saliha, M (corresponding author), Univ Batna 2, LaSTIC Lab, Batna, Algeria.
EM saliha.mezzoudj@yahoo.com; a.behloul@univ-batna2.dz;
   r.seghir@univ-batna2.dz
RI Seghir, Rachid/AAE-5095-2019
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], APPL MATH INFORM SCI
   [Anonymous], 2013, P WORLD ACAD SCI ENG
   [Anonymous], IJCNN 99
   [Anonymous], P 5 INT ICST MOB MUL
   [Anonymous], 2005, IEEE INT C INFORM AC
   [Anonymous], INT J COMPUT SCI INF
   Anwar I, 2017, CYBERN INF TECHNOL, V17, P152, DOI 10.1515/cait-2017-0036
   Chen CJ, 2013, PROC SPIE, V8712, DOI 10.1117/12.2018230
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Harnie D, 2017, FUTURE GENER COMP SY, V67, P409, DOI 10.1016/j.future.2016.04.023
   Huh JH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082693
   Ibrahim DS, 2017, INT J ADV COMPUT SC, V8, P425
   Karau H., 2015, Learning Spark: Lightning-Fast Big Data Analysis
   Lahdenoja O., 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C), DOI 10.1109/ISCAS.2006.1693438
   Lee S, 2019, J SUPERCOMPUT, V75, P4267, DOI 10.1007/s11227-018-2440-4
   Li J, 2012, PROCEEDINGS OF THE XI'AN 2012 INTERNATIONAL CONFERENCE OF SPORT SCIENCE & PHYSICAL EDUCATION, VOL I: SCIENCE AND INNOVATION IN SPORTS, P143
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   Manesh FS, 2010, I C CONT AUTOMAT ROB, P1644, DOI 10.1109/ICARCV.2010.5707882
   Masood Sarfaraz, 2018, ADV INTELL SYST COMP, P217
   Meng X., 2016, J. Mach. Learn. Res., V17, P1, DOI DOI 10.1145/2882903.2912565
   Muhammad G, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012500194
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Roomi S. M. M., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P54, DOI 10.1109/NCVPRIPG.2011.19
   Shafer J, 2010, INT SYM PERFORM ANAL, P122, DOI 10.1109/ISPASS.2010.5452045
   Verschae R, 2006, LECT NOTES COMPUT SC, V4225, P68
   Wu LF, 2014, IEEE COMMUN MAG, V52, P80, DOI 10.1109/MCOM.2014.6766089
   Zaharia Matei., 2012, NSDI 12
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
NR 37
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26729
EP 26746
DI 10.1007/s11042-019-7672-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700064
DA 2024-07-18
ER

PT J
AU Subudhi, BN
   Rout, DK
   Ghosh, A
AF Subudhi, Badri Narayan
   Rout, Deepak Kumar
   Ghosh, Ashish
TI Big data analytics for video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Big Data; Data Science; Big Data Analytics for video
ID MARKOV RANDOM-FIELD; OBJECT DETECTION; INTELLIGENT SURVEILLANCE;
   TRACKING; CHALLENGES; MODEL; ALGORITHM; FEATURES; NETWORK; SYSTEM
AB This article addresses the usage and scope of Big Data Analytics in video surveillance and its potential application areas. The current age of technology provides the users, ample opportunity to generate data at every instant of time. Thus in general, a tremendous amount of data is generated every instant throughout the world. Among them, amount of video data generated is having a major share. Education, healthcare, tours and travels, food and culture, geographical exploration, agriculture, safety and security, entertainment etc., are the key areas where a tremendous amount of video data is generated every day. A major share among it are taken by the daily used surveillance data captured from the security purpose camera and are recorded everyday. Storage, retrieval, processing, and analysis of such gigantic data require some specific platform. Big Data Analytics is such a platform, which eases this analysis task. The aim of this article is to investigate the current trends in video surveillance and its applications using Big Data Analytics. It also aims to focus on the research opportunities for visual surveillance in Big Data frameworks. We have reported here the state-of-the-art surveillance schemes for four different imaging modalities: conventional video scene, remotely sensed video, medical diagnostics, and underwater surveillance. Several works were reported in this research field over recent years and are categorized based on the challenges solved by the researchers. A list of tools used for video surveillance using Big Data framework is presented. Finally, research gaps in this domain are discussed.
C1 [Subudhi, Badri Narayan] Indian Inst Technol Jammu, Dept Elect Engn, Nagrota, Jammu & Kashmir, India.
   [Rout, Deepak Kumar] Natl Inst Technol Goa, Dept Elect & Commun Engn, Ponda, Goa, India.
   [Ghosh, Ashish] Indian Stat Inst, Ctr Soft Comp Res, 203 BT Rd, Kolkata 700108, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) Jammu; National Institute of Technology (NIT System);
   National Institute of Technology Goa; Indian Statistical Institute;
   Indian Statistical Institute Kolkata
RP Ghosh, A (corresponding author), Indian Stat Inst, Ctr Soft Comp Res, 203 BT Rd, Kolkata 700108, W Bengal, India.
EM ash@isical.ac.in
RI SUBUDHI, BADRI N/B-6830-2013; Rout, Deepak/N-1550-2018
OI SUBUDHI, BADRI N/0000-0002-4378-0065; Rout, Deepak/0000-0001-5692-5385;
   GHOSH, ASHISH/0000-0003-1548-5576
CR Ahmad J, 2018, IEEE T IND INFORM, V14, P3205, DOI 10.1109/TII.2018.2800163
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Alharbi A, 2014, IEEE INT SYMP SIGNAL, P161, DOI 10.1109/ISSPIT.2014.7300581
   Ali Heba Hamdy, 2018, Future Computing and Informatics Journal, V3, P51, DOI 10.1016/j.fcij.2017.11.002
   [Anonymous], BIOMED INFOR INSIGHT
   [Anonymous], 2016, CONSULTING AHEAD
   [Anonymous], WHITEPAPER CISCO VNI
   [Anonymous], NEU COMP APP
   [Anonymous], TUTORIALS OPERATIONS
   [Anonymous], 22ND USENIX CONF ON
   [Anonymous], P SPIE
   [Anonymous], 4 IEEE INT C IM INF
   [Anonymous], IEEE 14 SIG P COM AP
   [Anonymous], IEEE T CIR SYS TECH
   [Anonymous], 2009, IN VITRO FERTILIZATI
   [Anonymous], BIG DAT SOL
   [Anonymous], 2011, CIDR
   [Anonymous], 2006, REMOTE SENSING DIGIT
   [Anonymous], PAT RECOG BIG DATA
   [Anonymous], UCSD PEDESTRIAN DATA
   [Anonymous], EURO TRANS CONF
   [Anonymous], BIG DATA WHAT IS NAS
   [Anonymous], SIGKDD EXPLORATIONS
   [Anonymous], IJCSN INT J COMPUTER
   [Anonymous], ASS PRECLIN ORG DAM
   [Anonymous], BIG DATA COMPUTING U
   Assunçao MD, 2015, J PARALLEL DISTR COM, V79-80, P3, DOI 10.1016/j.jpdc.2014.08.003
   Babar M, 2019, FUTURE GENER COMP SY, V96, P398, DOI 10.1016/j.future.2019.02.035
   Bansal S, 2016, J INFECT DIS, V214, pS375, DOI 10.1093/infdis/jiw400
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Behrad A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-23
   Belle A, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/370194
   Ben Ayed A, 2015, PROCEDIA COMPUT SCI, V53, P216, DOI 10.1016/j.procs.2015.07.297
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Blat J, 2016, P IEEE, V104, P2085, DOI 10.1109/JPROC.2015.2496111
   Campbell J. B., 2011, INTRO REMOTE SENSING
   Cavallaro G, 2015, IEEE J-STARS, V8, P4634, DOI 10.1109/JSTARS.2015.2458855
   Chakraborty D, 2019, PATTERN RECOGN, V89, P161, DOI 10.1016/j.patcog.2019.01.002
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen ZZ, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P276, DOI 10.1109/BigMM.2015.53
   Cheng X, 2014, CHINA COMMUN, V11, P26, DOI 10.1109/CC.2014.7019837
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Chuang MC, 2017, IEEE T SYST MAN CY-S, V47, P2467, DOI 10.1109/TSMC.2016.2523943
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dean J, 2014, WILEY SAS BUS SER, P1, DOI 10.1002/9781118691786
   Dubuisson S, 2016, MACH VISION APPL, V27, P23, DOI 10.1007/s00138-015-0713-y
   Eberhardt R, 2007, AM J RESP CRIT CARE, V176, P36, DOI 10.1164/rccm.200612-1866OC
   Ezaki N, 2004, INT C PATT RECOG, P683, DOI 10.1109/ICPR.2004.1334351
   Fan JQ, 2014, NATL SCI REV, V1, P293, DOI 10.1093/nsr/nwt032
   Fang RG, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932707
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Foresti GL, 2000, INT J PATTERN RECOGN, V14, P167, DOI 10.1142/S021800140000012X
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2018, IEEE ACCESS, V6, P68989, DOI 10.1109/ACCESS.2018.2878313
   Ghosh A, 2007, J INTELL FUZZY SYST, V18, P525
   Ghosh A, 2018, CAAI T INTELL TECHNO, V3, P208, DOI 10.1049/trit.2018.1008
   Ghosh A, 2012, IEEE T CIRC SYST VID, V22, P1127, DOI 10.1109/TCSVT.2012.2190476
   Guo SY, 2015, PROCEDIA ENGINEER, V123, P190, DOI 10.1016/j.proeng.2015.10.077
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Heidemann J, 2012, COMPUT NETW, V56, P3866, DOI 10.1016/j.comnet.2012.08.009
   Helbing D., 2019, DIGITAL ENLIGHTENMEN, P47
   Hore S., 2018, Computer Vision: Concepts, Methodologies, Tools, and Applications, P601
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Kajo I, 2018, MULTIMED TOOLS APPL, V77, P1783, DOI 10.1007/s11042-016-4327-9
   Kambatla K, 2014, J PARALLEL DISTR COM, V74, P2561, DOI 10.1016/j.jpdc.2014.01.003
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Ko T, 2008, IEEE APP IMG PAT, P84
   Kwon O, 2014, INT J INFORM MANAGE, V34, P387, DOI 10.1016/j.ijinfomgt.2014.02.002
   Labrinidis A, 2012, PROC VLDB ENDOW, V5, P2032, DOI 10.14778/2367502.2367572
   Lebart K, 2003, IEEE J OCEANIC ENG, V28, P673, DOI 10.1109/JOE.2003.819314
   Lee CH, 2017, KIDNEY RES CLIN PRAC, V36, P3, DOI 10.23876/j.krcp.2017.36.1.3
   Lenhart D., 2008, Pattern Recognition and Image Analysis, V18, P400, DOI 10.1134/S1054661808030061
   Li Baiping, 2018, 2018 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P690, DOI 10.1109/ICITBS.2018.00179
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873
   Lin WG, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON INTELLIGENT MECHATRONICS AND AUTOMATION, P644
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu J, 2013, J AM MED INFORM ASSN, V20, P1021, DOI 10.1136/amiajnl-2012-001336
   Louridas P, 2013, IEEE SOFTWARE, V30, P33, DOI 10.1109/MS.2013.125
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lyon D, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714541861
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Mandal B, 2018, IEEE IMAGE PROC, P938, DOI 10.1109/ICIP.2018.8451190
   Meggitt DJ, 1999, OCEANS '99 MTS/IEEE : RIDING THE CREST INTO THE 21ST CENTURY, VOLS 1-3, P289, DOI 10.1109/OCEANS.1999.799755
   Meng LF, 2012, IEEE J-STARS, V5, P146, DOI 10.1109/JSTARS.2011.2179639
   Menze BH, 2010, LECT NOTES COMPUT SC, V6362, P151
   Minami M, 1999, IND ROBOT, V26, P278, DOI 10.1108/01439919910277549
   Mondal A, 2017, INT J COMPUT VISION, V122, P116, DOI 10.1007/s11263-016-0959-5
   Oliveira SF, 2012, IEEE I C EMBED SOFTW, P572, DOI 10.1109/HPCC.2012.83
   Opitz M, 2014, 2014 11TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS 2014), P186, DOI 10.1109/DAS.2014.29
   Palaniappan K., 2010, INFORM FUSION FUSION, P1, DOI DOI 10.1109/ICIF.2010.5711891
   Palaniappan K, 2011, DISTRIBUTED VIDEO SENSOR NETWORKS, P349, DOI 10.1007/978-0-85729-127-1_24
   Palazzo S, 2014, EUROMICRO WORKSHOP P, P312, DOI 10.1109/PDP.2014.80
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Pouyanfar S, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3150226
   Pradhan R, 2018, IEEE T IMAGE PROCESS, V27, P692, DOI 10.1109/TIP.2017.2766358
   Presnar MD, 2010, PROC SPIE, V7672, DOI 10.1117/12.849469
   Rangayyan R.M., 2004, Biomedical image analysis
   Rathore MMU, 2015, IEEE J-STARS, V8, P4610, DOI 10.1109/JSTARS.2015.2424683
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Rout DK, 2018, EXPERT SYST APPL, V97, P117, DOI 10.1016/j.eswa.2017.12.009
   Ruhé MHO, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P760
   Ruiz M, 2016, COMPUT COMMUN, V84, P1, DOI 10.1016/j.comcom.2016.03.026
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sehgal A, 2004, 2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P455
   Selmi Z, 2017, PROC INT CONF DOC, P1132, DOI 10.1109/ICDAR.2017.187
   Shamsolmoali P, 2018, MULTITOOLS APP, P1
   Shao ZF, 2018, IEEE T BIG DATA, V4, P105, DOI 10.1109/TBDATA.2017.2715815
   Sheng M, 2015, IEEE WIREL COMMUN, V22, P14, DOI 10.1109/MWC.2015.7143322
   Shivakumara P, 2018, CAAI T INTELL TECHNO, V3, P169, DOI 10.1049/trit.2018.1015
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Subudhi BN, 2017, MULTIMED TOOLS APPL, V76, P13511, DOI 10.1007/s11042-016-3698-2
   Subudhi BN, 2016, INFORM SCIENCES, V366, P31, DOI 10.1016/j.ins.2016.04.049
   Subudhi BN, 2016, INFORM SCIENCES, V331, P15, DOI 10.1016/j.ins.2015.10.031
   Subudhi BN, 2015, SOFT COMPUT, V19, P2769, DOI 10.1007/s00500-014-1440-4
   Subudhi BN, 2014, OPT LASER TECHNOL, V57, P284, DOI 10.1016/j.optlastec.2013.10.003
   Subudhi BN, 2011, PATTERN RECOGN LETT, V32, P2097, DOI 10.1016/j.patrec.2011.07.028
   Subudhi BN, 2011, IEEE T CIRC SYST VID, V21, P993, DOI 10.1109/TCSVT.2011.2133870
   Suinesiaputra A, 2015, IEEE J BIOMED HEALTH, V19, P1283, DOI 10.1109/JBHI.2014.2370952
   Taj M, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940281
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P520, DOI 10.1109/JOE.2004.839933
   Turki H, 2017, PROC INT CONF DOC, P949, DOI 10.1109/ICDAR.2017.159
   Vallières M, 2015, PHYS MED BIOL, V60, P5471, DOI 10.1088/0031-9155/60/14/5471
   Verma Jai Prakash., 2016, International Journal on Soft Computing, Artificial Intelligence and Applications, V5, P41, DOI [10.5121/ijscai.2016.5105, DOI 10.5121/IJSCAI.2016.5105]
   Vincent N, 2019, PATTERN RECOGN, V86, P281, DOI 10.1016/j.patcog.2018.09.010
   Wu J, 2015, IEEE NETWORK, V29, P35, DOI 10.1109/MNET.2015.7018201
   Xiang W, 2016, IEEE NETWORK, V30, P30, DOI 10.1109/MNET.2016.7474341
   Xiang XB, 2018, INT J FUZZY SYST, V20, P572, DOI 10.1007/s40815-017-0401-3
   Xiao JJ, 2010, PROC CVPR IEEE, P679, DOI 10.1109/CVPR.2010.5540151
   Xu YZ, 2019, MOD RHEUMATOL, V29, P984, DOI 10.1080/14397595.2018.1519148
   Young AA, 2009, EXP PHYSIOL, V94, P578, DOI 10.1113/expphysiol.2008.044081
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhang XG, 2018, IEEE ACCESS, V6, P66816, DOI 10.1109/ACCESS.2018.2878733
   Zitouni MS, 2015, IEEE SYS MAN CYBERN, P1827, DOI 10.1109/SMC.2015.320
NR 143
TC 28
Z9 30
U1 5
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26129
EP 26162
DI 10.1007/s11042-019-07793-w
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700040
DA 2024-07-18
ER

PT J
AU Xu, C
   Makihara, Y
   Li, X
   Yagi, Y
   Lu, JF
AF Xu, Chi
   Makihara, Yasushi
   Li, Xiang
   Yagi, Yasushi
   Lu, Jianfeng
TI Speed-Invariant Gait Recognition Using Single-Support Gait Energy Image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Single-support phase; Speed invariance; Morphing
ID DISCRIMINANT-ANALYSIS; WALKING; IDENTIFICATION; REPRESENTATION;
   PERFORMANCE; FEATURES
AB Gait is one of the most popular behavioral biometrics because it can be authenticated at a distance from a camera without subject cooperation. Speed differences between matching pairs, however, cause significant performance drops in gait recognition, and gait mode difference (i.e., walking versus running) makes gait recognition further challenging. We therefore propose a speed-invariant gait representation called single-support GEI (SSGEI), which realizes a good trade-off between speed invariance and stability by aggregating multiple frames around single-support phases. In addition, to mitigate the pose differences between walking and running modes at single-support phases, we morph walking and running SSGEIs into intermediate SSGEIs between walking and running mode, where we exploit a free-form deformation field from the walking or running modes to the intermediate mode obtained by training data. We finally apply Gabor filtering and spatial metric learning as postprocessing for further accuracy improvement. Experiments on two publicly available datasets, the OU-ISIR Treadmill Dataset A and the CASIA-C Dataset demonstrate that the proposed method yields the state-of-the-art accuracies in both identification and verification scenarios with a low computational cost.
C1 [Xu, Chi; Li, Xiang; Lu, Jianfeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Xu, Chi; Makihara, Yasushi; Li, Xiang; Yagi, Yasushi] Osaka Univ, Inst Sci & Ind Res, Dept Intelligent Media, Osaka 5670047, Japan.
C3 Nanjing University of Science & Technology; Osaka University
RP Xu, C (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.; Xu, C (corresponding author), Osaka Univ, Inst Sci & Ind Res, Dept Intelligent Media, Osaka 5670047, Japan.
EM xuchisherry@gmail.com; makihara@am.sanken.osaka-u.ac.jp;
   lixiangmzlx@gmail.com; yagi@am.sanken.osaka-u.ac.jp; lujf@njust.edu.cn
RI Li, Xiang/HNQ-3047-2023; Xu, Chi/ABJ-0303-2022
OI Li, Xiang/0000-0002-8044-7050; Xu, Chi/0000-0001-6036-5763
FU JSPS [JP18H04115]; Jiangsu Provincial Science and Technology Support
   Program [BE2014714]; 111 Project [B13022]; Priority Academic Program
   Development of Jiangsu Higher Education Institutions
FX This work was supported by JSPS Grants-in-Aid for Scientific Research
   (A) JP18H04115, by Jiangsu Provincial Science and Technology Support
   Program (No. BE2014714), by the 111 Project (No. B13022), and by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR [Anonymous], RECOGNIZING HUMAN GA
   [Anonymous], P 2005 INT C COMM CI
   [Anonymous], P 10 AS C COMP VIS Q
   [Anonymous], 2010, P IEEE COMP SOC C CO
   [Anonymous], P 23 IEEE C COMP VIS
   Bouchrika I., 2008, 8th IEEE International Conference on Automatic Face Gesture Recognition, P1, DOI [10.1109/AFGR.2008.4813395., DOI 10.1109/AFGR.2008.4813395]
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Cheng FX, 2002, INT C PATT RECOG, P1017, DOI 10.1109/ICPR.2002.1048478
   Guan Y, 2013, INT CONF BIOMETR
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Iosifidis A, 2012, IEEE T INF FOREN SEC, V7, P530, DOI 10.1109/TIFS.2011.2175921
   Iwama H, 2013, Information and Media Technologies, V5, P163
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Iwashita Yumi, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2273, DOI 10.1109/ICRA.2017.7989261
   Iwashita Y, 2015, LECT NOTES COMPUT SC, V9279, P141, DOI 10.1007/978-3-319-23231-7_13
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Kusakunniran W, 2012, IEEE T SYST MAN CY B, V42, P1654, DOI 10.1109/TSMCB.2012.2197823
   Kusakunniran W, 2011, IEEE IMAGE PROC, P545, DOI 10.1109/ICIP.2011.6116403
   Kusakunniran W, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P49, DOI 10.1109/AVSS.2009.44
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Leow A, 2005, LECT NOTES COMPUT SC, V3565, P493
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li Z., 2008, Proceedings of the 16th ACM international conference on Multimedia, P671
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Lynnerup N, 2014, IET BIOMETRICS, V3, P47, DOI 10.1049/iet-bmt.2013.0090
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y., 2008, P 19 INT C PATT REC
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Nakajima H, 2012, INT C PATT RECOG, P3803
   Nixon Mark S., 2005, INT SERIES BIOMETRIC, P1
   Phillips P. J., 2002, FACE RECOGNITION VEN
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Shiraga K, 2016, INT CONF BIOMETR
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tan DL, 2007, IEEE IMAGE PROC, P337
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P673
   Tan DL, 2006, INT C PATT RECOG, P1000
   Tanawongsuwan R, 2004, PROC CVPR IEEE, P783
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wolf T, 2016, IEEE IMAGE PROC, P4165, DOI 10.1109/ICIP.2016.7533144
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Wu ZF, 2015, IEEE T MULTIMEDIA, V17, P1960, DOI 10.1109/TMM.2015.2477681
   Xu C, 2016, P AS C COMP VIS, P52
   Xu D, 2012, IEEE T IMAGE PROCESS, V21, P316, DOI 10.1109/TIP.2011.2160956
   Yam CY, 2002, INT C PATT RECOG, P287, DOI 10.1109/ICPR.2002.1044691
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang C, 2016, INT CONF ACOUST SPEE, P2832, DOI 10.1109/ICASSP.2016.7472194
NR 51
TC 10
Z9 10
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26509
EP 26536
DI 10.1007/s11042-019-7712-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700055
OA hybrid
DA 2024-07-18
ER

PT J
AU Bejaoui, H
   Ghazouani, H
   Barhoumi, W
AF Bejaoui, Hela
   Ghazouani, Haythem
   Barhoumi, Walid
TI Sparse coding-based representation of LBP difference for 3D/4D facial
   expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D; 4D facial expression recognition; Covariance; Mesh-LBP; Sparse
   coding; Riemannian optimization
ID FACE RECOGNITION; ALGORITHM; SEQUENCES; ADABOOST; TIME
AB This paper presents an effective method for automated 3D/4D facial expression recognition based on Mesh-Local Binary Pattern Difference (mesh-LBPD). In contrast to most of existing methods, the proposed mesh-LBPD is based on a unified set of geometric and appearance features of different facial regions. Indeed, multiple features are combined into a compact form using covariance matrices, namely Cov - 3D - LBP. Then, the Cov - 3D - LBP atoms are represented as sparse data combinations. To that end, a Riemannian optimization objective for dictionary learning and sparse coding is used, in order to reduce the complexity of the problem, and the representation loss is characterized via an affine invariant Riemannian metric. In order to prove the effectiveness of the proposed compact combination of geometric and appearance features, we conducted extensive experimental validations on real-world datasets. In fact, obtained results show the capability of the proposed method to significantly outperform, or achieve comparable performances with, the state-of-the-art methods.
C1 [Bejaoui, Hela; Ghazouani, Haythem; Barhoumi, Walid] Univ Tunis El Manar, Inst Super Informat Res, Res Team Intelligent Syst Imaging & Artificial Vi, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.
   [Ghazouani, Haythem; Barhoumi, Walid] Univ Carthage, Ecole Natl Ingn Carthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
C3 Universite de Tunis-El-Manar; Universite de Carthage
RP Barhoumi, W (corresponding author), Univ Tunis El Manar, Inst Super Informat Res, Res Team Intelligent Syst Imaging & Artificial Vi, LR16ES06 Lab Rech Informat Modelisat & Traitement, 2 Rue Abou Rayhane Bayrouni, Ariana 2080, Tunisia.; Barhoumi, W (corresponding author), Univ Carthage, Ecole Natl Ingn Carthage, 45 Rue Entrepreneurs, Tunis 2035, Tunisia.
EM hella_bejaoui@yahoo.fr; haythem.ghazouani@enicar.u-carthage.tn;
   walid.barhoumi@enicarthage.rnu.tn
RI Barhoumi, Walid/C-6576-2014; Ghazouani, Haythem/N-1013-2014
OI Barhoumi, Walid/0000-0003-2123-4992; Ghazouani,
   Haythem/0000-0002-6521-5024
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IMAGE ANAL RECOGNITI
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], EU WORKSH 3D OBJ RET
   [Anonymous], P FDN INT SYST
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2011, P ACM WORKSH HUM GES
   [Anonymous], 2013, 2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)
   Bejaoui H, 2017, LECT NOTES COMPUT SC, V10617, P39, DOI 10.1007/978-3-319-70353-4_4
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Berretti S, 2013, VISUAL COMPUT, V29, P1333, DOI 10.1007/s00371-013-0869-2
   Birgin EG, 2001, ACM T MATH SOFTWARE, V27, P340, DOI 10.1145/502800.502803
   Cherian A, 2017, IEEE T NEUR NET LEAR, V28, P2859, DOI 10.1109/TNNLS.2016.2601307
   Chetty K, 2010, IEEE RAD CONF, P188, DOI 10.1109/RADAR.2010.5494627
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Harandi MT, 2012, LECT NOTES COMPUT SC, V7573, P216, DOI 10.1007/978-3-642-33709-3_16
   Hariri W, 2017, ENG APPL ARTIF INTEL, V64, P25, DOI 10.1016/j.engappai.2017.05.009
   Hegde Ganapatikrishna, 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P47, DOI 10.1007/978-3-319-26832-3_6
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Hong XP, 2009, PROC CVPR IEEE, P1802, DOI 10.1109/CVPRW.2009.5206742
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Kopaczka M, 2018, IEEE INT INSTRUMENTA, P1
   Li HB, 2011, LECT NOTES COMPUT SC, V6915, P483, DOI 10.1007/978-3-642-23687-7_44
   Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202
   Li WJ, 2018, IEEE INT CONF AUTOMA, P24, DOI 10.1109/FG.2018.00014
   Li XL, 2015, SIGNAL PROCESS, V108, P297, DOI 10.1016/j.sigpro.2014.09.033
   Li YS, 2014, INFORM SCIENCES, V281, P559, DOI 10.1016/j.ins.2013.12.022
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lisai Li, 2015, Applied Mechanics and Materials, V742, P257, DOI 10.4028/www.scientific.net/AMM.742.257
   Luo Y, 2016, OPTIK, V127, P718, DOI 10.1016/j.ijleo.2015.10.147
   Ma D, 2015, J COMPUT METHODS SCI, V15, P537, DOI 10.3233/JCM-150566
   Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058
   Nugrahaeni RA, 2016, 2016 1ST INTERNATIONAL SEMINAR ON APPLICATION FOR TECHNOLOGY OF INFORMATION AND COMMUNICATION (ISEMANTIC): SCIENCE AND TECHNOLOGY FOR A BETTER FUTURE, P163, DOI 10.1109/ISEMANTIC.2016.7873831
   Phillips PJ, 2014, IMAGE VISION COMPUT, V32, P74, DOI 10.1016/j.imavis.2013.12.002
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reale M, 2013, IEEE INT CONF AUTOMA
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Shao J, 2015, PATTERN RECOGN LETT, V65, P157, DOI 10.1016/j.patrec.2015.07.039
   Shiyang Cheng, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163161
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Szeptycki P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P32, DOI 10.1109/BTAS.2009.5339052
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Wang HJ, 2018, IEEE ACCESS, V6, P6001, DOI 10.1109/ACCESS.2017.2784842
   Wang QW, 2014, APPL MECH MATER, V511-512, P433, DOI 10.4028/www.scientific.net/AMM.511-512.433
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wang Z, 2016, NEUROCOMPUTING, V174, P756, DOI 10.1016/j.neucom.2015.09.083
   Wei XF, 2018, IEEE INT CONF AUTOMA, P31, DOI 10.1109/FG.2018.00015
   Werghi N, 2016, IEEE T INF FOREN SEC, V11, P964, DOI 10.1109/TIFS.2016.2515505
   Xue ML, 2015, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2015.34
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yin LJ, 2008, IEEE INT CONF AUTOMA, P116
   Zhang FF, 2018, PROC CVPR IEEE, P3359, DOI 10.1109/CVPR.2018.00354
   Zhang W, 2015, PATTERN RECOGN, V48, P3191, DOI 10.1016/j.patcog.2015.04.012
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhao SY, 2019, INT J PHYTOREMEDIAT, V21, P1296, DOI 10.1080/15226514.2019.1586036
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
NR 67
TC 19
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22773
EP 22796
DI 10.1007/s11042-019-7632-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400027
DA 2024-07-18
ER

PT J
AU de Souza, JM
   Gonzaga, A
AF de Souza, Jones Mendonca
   Gonzaga, Adilson
TI Human iris feature extraction under pupil size variation using local
   texture descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture recognition; Iris recognition; Median-local-mapped-pattern
ID PERIOCULAR RECOGNITION; IMAGES; MOVE
AB The human iris texture is one of the most reliable biometric traits because it is unique, and the iris pattern remains stable for years. However, iris images acquired under uncontrolled illumination is one source of difficulties for iris recognition systems, mainly in applications at a distance and in non-cooperative environments. Different levels of light cause iris texture modifications due to pupil size variation. The iris contains 02 groups of muscles: the sphincter pupillae and the dilator pupillae. When the sphincter pupillae contracts the iris reduces the size of the pupil and its texture changes. It is well known in the biometric literature that pupil dilation degrades iris biometric performance. We propose in this paper to evaluate some local texture descriptors for iris recognition, considering pupil contraction and dilation. Furthermore, we propose 02 new texture descriptors called Median-Local-Mapped-Pattern (Median-LMP) and Modified Median-Local-Mapped-Pattern (MM-LMP) and compare their performances to the original Local Mapped Pattern (LMP), the Completed Modeling of Local Binary Pattern (CLBP), the Median Binary Pattern (MBP), the Weber Local Descriptor (WLD) and the Daugman's method. Our results show that our methodology is more robust when we compare iris samples with different levels of pupil sizes (dilated vs contracted). Besides this, our descriptor performs better than all the compared methods, primarily if one iris with a contracted pupil is used for searching another iris with a dilated pupil.
C1 [de Souza, Jones Mendonca; Gonzaga, Adilson] Univ Sao Paulo, Dept Elect & Comp Engn EESC, Ave Trabalhador Sao Carlense 400, BR-13560590 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Gonzaga, A (corresponding author), Univ Sao Paulo, Dept Elect & Comp Engn EESC, Ave Trabalhador Sao Carlense 400, BR-13560590 Sao Carlos, SP, Brazil.
EM jones_souza@usp.br; agonzaga@sc.usp.br
RI Gonzaga, Adilson/B-4883-2010
OI Gonzaga, Adilson/0000-0003-2193-9394
FU Sao Paulo Research Foundation (FAPESP) [2015/20812-5]; Fundacao de
   Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [15/20812-5] Funding
   Source: FAPESP
FX The authors would like to thank the Sao Paulo Research Foundation
   (FAPESP), grant #2015/20812-5.
CR [Anonymous], IJCAI
   [Anonymous], CASIA IR IM DAT CASI
   [Anonymous], 9 WVC WORKSH VISAO C
   [Anonymous], 2 INT C SIGN PROC SY
   [Anonymous], 10 WORKSH VISAO COMP
   [Anonymous], 2013, ELECT LETT COMPUT VI
   [Anonymous], 10 WORKSH VISAO COMP
   [Anonymous], IEEE 6 INT C BIOM TH
   Bashir F, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P426, DOI 10.1109/THS.2008.4534490
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Cassin B., 1990, DICT EYE TERMINOLOGY
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   da Costa RM, 2012, IEEE T SYST MAN CY B, V42, P1072, DOI 10.1109/TSMCB.2012.2186125
   Daugman J, 2002, IEEE IMAGE PROC, P33
   De Villar JA, 2010, CONF REC ASILOMAR C, P1770, DOI 10.1109/ACSSC.2010.5757845
   Dong Wenbo., 2009, CHINESE C PATTERN RE, P1
   Fancourt C, 2005, LECT NOTES COMPUT SC, V3546, P1
   Ferraz CT, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414550106
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Hanna K.J., 1996, MVA, P200
   He YQ, 2006, INT C PATT RECOG, P557
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu Y, 2016, Multimedia Tools and Applications, P1
   Martin A., 1997, PROC EURO SPEECH 97, V4, P1895
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   Nappi M, 2012, PATTERN RECOGN LETT, V33, P1820, DOI 10.1016/j.patrec.2012.02.005
   Nguyen K, 2017, PATTERN RECOGN, V72, P123, DOI 10.1016/j.patcog.2017.05.021
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2011, IEEE T INF FOREN SEC, V6, P82, DOI 10.1109/TIFS.2010.2086446
   Proença H, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P9
   Proença H, 2008, LECT NOTES COMPUT SC, V5358, P731, DOI 10.1007/978-3-540-89639-5_70
   Rashad M. Z., 2011, International Journal of Computer Science & Information Technology, V3, P67, DOI 10.5121/ijcsit.2011.3506
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P121, DOI 10.1109/ACV.1994.341298
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
NR 41
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20557
EP 20584
DI 10.1007/s11042-019-7371-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400001
DA 2024-07-18
ER

PT J
AU Xue, XZ
   Li, Y
AF Xue, Xizhe
   Li, Ying
TI Robust particle tracking via spatio-temporal context learning and
   multi-task joint local sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Local sparse representation; Spatio-temporal context;
   Multi-task learning
ID VISUAL TRACKING; OBJECT TRACKING; MODELS
AB Particle filters have been proven very successful for non-linear and non-Gaussian estimation problems and extensively used in object tracking. However, high computational costs and particle decadency problem limit its practical application. In this paper, we present a robust particle tracking approach based on spatio-temporal context learning and multi-task joint local sparse representation. The proposed tracker samples particles according to the confidence map constructed by the spatio-temporal context information of the target. This sampling strategy can ameliorate problems of sample impoverishment and particle degeneracy, target state distribution to obtain robust tracking performance. In order to locate the target more accurately and be less sensitive to occlusion, the local sparse appearance model is adopted to capture the local and structural information of the target. Finally, the multi-task learning where the representations of particles are learned jointly is employed to further improve tracking performance and reduce overall computational complexity. Both qualitative and quantitative evaluations on challenging benchmark image sequences have demonstrated that the proposed tracking algorithm performs favorably against several state-of-the-art methods.
C1 [Xue, Xizhe; Li, Ying] Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710129, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Li, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710129, Shaanxi, Peoples R China.
EM lybyp@nwpu.edu.cn
FU National Key Research and Development Program of China [2016YFB0502502];
   National Natural Science Foundation of China [61871460, 61876152];
   Foundation Project for Advanced Research Field of China
   [614023804016HK03002]
FX This work was supported by the National Key Research and Development
   Program of China (2016YFB0502502), the National Natural Science
   Foundation of China (61871460, 61876152) and the Foundation Project for
   Advanced Research Field of China (614023804016HK03002). The authors
   would like to thank the editors and the anonymous referees for their
   constructive comments which have been very helpful in revising this
   paper. We would like also to appreciate Prof. Jonathan C-Wfor his
   assistance in English writing and Mr. Bin Lin for his thoughtful
   suggestions on experiments.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], ARXIV170704021
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen X, 2009, IEEE DATA MINING, P746, DOI 10.1109/ICDM.2009.128
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Ji Z, 2019, NEUROCOMPUTING, V329, P339, DOI 10.1016/j.neucom.2018.10.069
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang N, 2011, PROC CVPR IEEE, P1161, DOI 10.1109/CVPR.2011.5995716
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leistner C, 2010, LECT NOTES COMPUT SC, V6376, P493
   Li X, 2011, IEEE I CONF COMP VIS, P1156, DOI 10.1109/ICCV.2011.6126364
   Liu BY, 2013, IEEE T PATTERN ANAL, V35, P2968, DOI 10.1109/TPAMI.2012.215
   Liu R, 2009, IEEE I CONF COMP VIS, P1459, DOI 10.1109/ICCV.2009.5459285
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51
   Wu SL, 2016, MULTIMED TOOLS APPL, V75, P12137, DOI 10.1007/s11042-016-3320-7
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2203, DOI 10.1007/s11042-014-2402-7
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
   Zhu GB, 2015, IEEE T IMAGE PROCESS, V24, P5140, DOI 10.1109/TIP.2015.2479460
NR 42
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21187
EP 21204
DI 10.1007/s11042-019-7246-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400029
DA 2024-07-18
ER

PT J
AU Yang, B
   Li, QZ
AF Yang, Bo
   Li, Qian-zhong
TI Local binary pattern-based discriminant graph construction for
   dimensionality reduction with application to face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern; Dimensionality reduction; Face recognition; Graph
   embedding
ID TEXTURE CLASSIFICATION; PRESERVING PROJECTIONS; LAPLACIAN EIGENMAPS;
   FEATURE-EXTRACTION; APPEARANCE
AB Graph construction has attracted increasing interest in recent years due to its key role in many dimensionality reduction (DR) algorithms. On the other hand, our previous study shows that the Local-Binary-Pattern Image (LBPI) representation is a more powerful discriminant and is invariant to monotonic gray level changes. Here, we attempt to construct a discriminant graph for DR in the LBPI representation space. We call the graph the Local-Binary-Image Discriminant (LBID) graph and further incorporate the LBID graph into the Locality Preserving Projection (LPP) to develop an enhanced algorithm - Local Binary Image Discriminant Preserving Projection (LBIDPP). Meanwhile, we also construct a Local-Binary-Histogram (LBH) graph in LBP histogram space and obtain the Local Binary Histogram Preserving Projection (LBHPP) algorithm and compare these to the LBID graph and LBIDPP. It is worth noting that LBIDPP is not a simple combination of the two feature extractions LBP and LPP, i.e., LBP + LPP. LBIDPP inherits the attractive properties of the LBP and LPP. The experiments on face recognition validate the effectiveness and feasibility of the LBID graph and LBIDPP.
C1 [Yang, Bo] Inner Mongolia Univ, Coll Comp Sci, Hohhot 010021, Peoples R China.
   [Yang, Bo; Li, Qian-zhong] Sch Phys Sci & Technol, Hohhot 010021, Peoples R China.
   [Yang, Bo] Inner Mongolia Key Lab Data Min & Knowledge Engn, Hohhot 010021, Peoples R China.
C3 Inner Mongolia University
RP Yang, B (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Hohhot 010021, Peoples R China.; Yang, B (corresponding author), Sch Phys Sci & Technol, Hohhot 010021, Peoples R China.; Yang, B (corresponding author), Inner Mongolia Key Lab Data Min & Knowledge Engn, Hohhot 010021, Peoples R China.
EM csyb@imu.edu.cn
RI Yang, Bo/D-2691-2012
FU National Natural Science Foundation of China [61363051]; China
   Postdoctoral Science Foundation [2013 M540217]; Program of Higher-Level
   Talents of Inner Mongolia University [115118, 135113]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61363051), China Postdoctoral Science Foundation (Nos.
   2013 M540217), Program of Higher-Level Talents of Inner Mongolia
   University (Nos. 115118, 135113).
CR Ahonen T, 2004, INT C PATT RECOG, P153, DOI 10.1109/ICPR.2004.1334491
   Ahonen T, 2004, LNCS, V3021, P69
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2007, ICCV
   [Anonymous], 2008, SEMISUPERVISED LEARN
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], 2001, ADV NEURAL INFORM PR
   [Anonymous], 2011, P 17 ACM SIGKDD INT, DOI DOI 10.1145/2020408.2020576
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], TECHNICAL REPORT
   Argyriou A., 2005, Advances in Neural Information Processing Systems, P67
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   García MA, 2007, IMAGE VISION COMPUT, V25, P1091, DOI 10.1016/j.imavis.2006.05.023
   Golub G.H., 1989, MATRIX COMPUTATIONS
   He X., 2004, P ADV NEURAL INFORM, P153
   Jebara Tony, 2009, P 26 INT C MACH LEAR
   Levin K, 2017, IEEE T SIGNAL PROCES, V65, P1988, DOI 10.1109/TSP.2016.2645517
   Liu JY, 2017, IEICE T INF SYST, VE100D, P1325, DOI 10.1587/transinf.2016EDP7422
   Martinez A., 1998, AR FACE DATABASE
   Moses Y., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P286
   Nanni L, 2012, PATTERN RECOGN, V45, P3844, DOI 10.1016/j.patcog.2012.04.007
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sun YB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050506
   Torre B, 2011, GIT IMAGING MICROSC, V13, P26
   Wang J, 2012, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2012.6247790
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Woo S, 2018, PATTERN RECOGN, V77, P65, DOI 10.1016/j.patcog.2017.12.010
   Wu X., 2015, 2015 IEEE C IEEE COM, V4
   Xiao YL, 2016, MULTIMED TOOLS APPL, V75, P13041, DOI 10.1007/s11042-015-2569-6
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yan Y, 2013, NEUROCOMPUTING, V119, P201, DOI 10.1016/j.neucom.2013.03.039
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang B, 2010, NEUROCOMPUTING, V74, P301, DOI 10.1016/j.neucom.2010.03.019
   Yang B, 2010, INT J PATTERN RECOGN, V24, P1011, DOI 10.1142/S0218001410008275
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yun F, 2013, GRAPH EMBEDDING PATT
   Zhang LM, 2012, PATTERN RECOGN, V45, P1205, DOI 10.1016/j.patcog.2011.08.015
NR 43
TC 1
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22445
EP 22462
DI 10.1007/s11042-019-7518-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400012
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Gupta, R
   Son, LH
   Kumar, R
AF Kapoor, Rajiv
   Gupta, Rashmi
   Le Hoang Son
   Kumar, Raghvendra
TI Iris localization for direction and deformation independence based on
   polynomial curve fitting and singleton expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Canny edge detection; Gaussian smoothing; Iris localization; Polynomial
   curve fitting; Singleton expansion
ID CLUSTERING-ALGORITHM; RECOGNITION; SEGMENTATION; TRANSFORM
AB In an authentic biometric system, iris recognition aims to detect the iris pattern of a person. The single unique pattern of the human iris may be extracted from the image and encoded, such that a given code may be compared to several others, and then validating if the patterns belong to a particular eye or not. Iris localization is an important aspect of iris recognition since accuracy in iris localization affects iris recognition. The previous iris localization methods were less efficient owing to slow processing time and inefficiency in handling non-straight faces in imperfect conditions. In this paper, we propose a new iris localization method with direction and deformation independence. It is based on the idea that the iris is localized from the side face and from distance. A novel approach of curve fitting using polynomial along with singleton expansion is adopted to efficiently and accurately localize the iris in any distance and direction from the camera. We validate the method by experimental analysis on the basis of accuracy, segmentation error and execution time. The method is suggested to be significant for diagnosing several eye-related disorders as well as for biometric authentication processes.
C1 [Kapoor, Rajiv] Delhi Technol Univ, ECE Dept, Delhi, India.
   [Gupta, Rashmi] GGSIPU, AIACT&R, ECE Dept, Delhi, India.
   [Le Hoang Son] Vietnam Natl Univ, VNU Informat Technol Inst, 144 Xuan Thuy, Hanoi, Vietnam.
   [Kumar, Raghvendra] LNCT Coll, Comp Sci & Engn Dept, Jabalpur, Madhya Pradesh, India.
C3 Delhi Technological University; GGS Indraprastha University; Netaji
   Subhas University of Technology; Netaji Subhas University of Technology
   (East Campus); Vietnam National University Hanoi
RP Son, LH (corresponding author), Vietnam Natl Univ, VNU Informat Technol Inst, 144 Xuan Thuy, Hanoi, Vietnam.
EM rajivkapoor@dce.ac.in; rashmig71@yahoo.com; sonlh@vnu.edu.vn;
   raghvendraagrawal7@gmail.com
RI Gupta, Rashmi/HLH-0461-2023; Kapoor, Rajiv/AAA-2011-2022; Gupta,
   Rashmi/KMY-3135-2024
OI Kapoor, Rajiv/0000-0003-3020-1455; Gupta, Rashmi/0000-0003-3983-4638;
   Hoang Son, Le/0000-0001-6356-0046
CR Abate AF, 2015, PATTERN RECOGN LETT, V57, P43, DOI 10.1016/j.patrec.2014.10.017
   [Anonymous], 2017, MATH PROB ENG
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2018, MACH VIS APPL
   Ayvali E, 2015, ANN BIOMED ENG, V43, P1828, DOI 10.1007/s10439-014-1208-0
   Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34
   Cament LA, 2014, PATTERN RECOGN, V47, P568, DOI 10.1016/j.patcog.2013.09.003
   Cao LY, 2014, INT CONF INSTR MEAS, P826, DOI 10.1109/IMCCC.2014.174
   Cheah W, 2013, 2013 INTERNATIONAL CONFERENCE ON INFORMATICS AND CREATIVE MULTIMEDIA (ICICM), P168, DOI 10.1109/ICICM.2013.65
   Chinese Academy of Sciences, 2016, CASIA IR IM DAT
   Hai DT, 2017, APPL SOFT COMPUT, V54, P141, DOI 10.1016/j.asoc.2017.01.021
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dey S., 2007, INT J BIOMED BIOL EN, V1, P293
   Dora L, 2017, ENG APPL ARTIF INTEL, V62, P286, DOI 10.1016/j.engappai.2017.04.011
   Elrefaei LA, 2017, MULTIMED TOOLS APPL, P1
   Frucci M, 2016, PATTERN RECOGN, P78
   Gaikwad PP, 2017, INT J ENG SCI, V13, P176
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galdia C, 2016, PATTERN RECOGN LETT, V82, P157
   Govindaraju V, 2010, INT C PATT REC, P1
   Gupta R, 2016, INT J IMAGE DATA FUS, V7, P325, DOI 10.1080/19479832.2014.961973
   Gupta R, 2015, INT J SIGNAL IMAGING, V8, P205, DOI 10.1504/IJSISE.2015.070541
   Gupta R, 2012, INT J SIGNAL IMAGING, V5, P101, DOI 10.1504/IJSISE.2012.047783
   Haindl M, 2015, PATTERN RECOGN LETT, V57, P60, DOI 10.1016/j.patrec.2015.02.012
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Long HV, 2019, COMPUT IND ENG, V127, P687, DOI 10.1016/j.cie.2018.11.007
   Hofbauer H, 2014, INT C PATT RECOG, P527, DOI 10.1109/ICPR.2014.101
   Hollingsworth KP, 2009, IEEE T PATTERN ANAL, V31, P964, DOI 10.1109/TPAMI.2008.185
   Hu Y, 2017, IMAGE VISION COMPUT, V58, P168, DOI 10.1016/j.imavis.2016.05.003
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Hu Y, 2015, PATTERN RECOGN LETT, V57, P24, DOI 10.1016/j.patrec.2014.12.012
   Jan F, 2018, MULTIMED TOOLS APPL, V77, P1041, DOI 10.1007/s11042-016-4334-x
   Jillela RR, 2015, PATTERN RECOGN LETT, V57, P4, DOI 10.1016/j.patrec.2014.09.014
   Kang BJ, 2007, IEEE T SYST MAN CY B, V37, P1555, DOI 10.1109/TSMCB.2007.907042
   Kapoor R, 2015, IET COMPUT VIS, V9, P226, DOI 10.1049/iet-cvi.2013.0316
   Kapoor R, 2013, IET COMPUT VIS, V7, P201, DOI 10.1049/iet-cvi.2012.0097
   Kaur H, 2017, INT J ADV RES COMPUT, P267
   Kim D, 2016, EXPERT SYST APPL, V54, P328, DOI 10.1016/j.eswa.2016.01.050
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Laddi A, 2017, MULTIMED TOOLS APPL, V76, P7129, DOI 10.1007/s11042-016-3361-y
   Son LH, 2017, INT J FUZZY SYST, V19, P1585, DOI 10.1007/s40815-016-0260-3
   Son LH, 2017, ENG APPL ARTIF INTEL, V59, P186, DOI 10.1016/j.engappai.2017.01.003
   Son LH, 2017, APPL INTELL, V46, P1, DOI 10.1007/s10489-016-0811-1
   Son LH, 2016, INT J FUZZY SYST, V18, P894, DOI 10.1007/s40815-015-0117-1
   Son LH, 2016, APPL SOFT COMPUT, V46, P284, DOI 10.1016/j.asoc.2016.05.009
   Son LH, 2016, EXPERT SYST APPL, V46, P380, DOI 10.1016/j.eswa.2015.11.001
   Son LH, 2015, INFORM SCIENCES, V317, P202, DOI 10.1016/j.ins.2015.04.050
   Li MM, 2016, EXPERT SYST APPL, V45, P161, DOI 10.1016/j.eswa.2015.09.033
   Liu Y, 2016, SENSOR BASED ACTIVIT, V181, P89
   Liu YN, 2015, J BIONIC ENG, V12, P504, DOI 10.1016/S1672-6529(14)60141-4
   Lv Yinzhi, 2018, Asian Journal of Ecotoxicology, V13, P11, DOI 10.7524/AJE.1673-5897.20171103001
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Thanh ND, 2017, COGN COMPUT, V9, P526, DOI 10.1007/s12559-017-9462-8
   Tam NT, 2018, WIREL NETW, V24, P1477, DOI 10.1007/s11276-016-1412-y
   Thong PH, 2016, ENG APPL ARTIF INTEL, V56, P121, DOI 10.1016/j.engappai.2016.08.009
   Thong PH, 2016, SOFT COMPUT, V20, P3549, DOI 10.1007/s00500-015-1712-7
   Thong PH, 2016, KNOWL-BASED SYST, V109, P48, DOI 10.1016/j.knosys.2016.06.023
   Phuong P.T.M., 2018, J COMPUT SCI CYBERN, V34, P17, DOI [10.15625/1813-9663/34/1/12725, DOI 10.15625/1813-9663/34/1/12725]
   Poornima S, 2010, PROCEDIA COMPUT SCI, V2, P127, DOI 10.1016/j.procs.2010.11.016
   Rai H, 2014, EXPERT SYST APPL, V41, P588, DOI 10.1016/j.eswa.2013.07.083
   Ritter N, 2013, P INT C IM AN PROC
   Sarode NS., 2014, INT J INNOVATIVE SCI, V2, P34
   Shah S., 2011, IEEE T INF FOREN SEC, V4, P824
   Sibai FN, 2011, EXPERT SYST APPL, V38, P5940, DOI 10.1016/j.eswa.2010.11.029
   Soliman N, 2016, OPTIK INT J LIGHT EL, P2
   Sundaram R. M., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P89, DOI 10.1109/EAIT.2011.18
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tan TN, 2012, PATTERN RECOGN LETT, V33, P970, DOI 10.1016/j.patrec.2011.08.009
   Tomeo-Reyes I, 2016, PATTERN RECOGN, V60, P306, DOI 10.1016/j.patcog.2016.05.022
   Tuan TM, 2016, APPL INTELL, V45, P402, DOI 10.1007/s10489-016-0763-5
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Wildes R. P., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P121, DOI 10.1109/ACV.1994.341298
   Yahiaoui M, 2016, PATTERN RECOGN LETT, V82, P116, DOI 10.1016/j.patrec.2016.05.025
NR 74
TC 11
Z9 11
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19279
EP 19303
DI 10.1007/s11042-019-7314-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800016
DA 2024-07-18
ER

PT J
AU Li, YT
   Ge, GF
AF Li, Yantao
   Ge, Guangfu
TI Cryptographic and parallel hash function based on cross coupled map
   lattices suitable for multimedia communication security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication security; Chaos; Cryptographic hash function;
   Cross coupled map lattices
ID GENETIC ALGORITHM; CRYPTANALYSIS; SCHEME
AB Cryptographic hash functions can map data of arbitrary size to data of fixed size (hash values), which can be used in a wide range of multimedia applications for communication security, such as integrity protection, message authentication and digital signature. In this paper, we present a cryptographic and parallel chaotic hash function based on the cross coupled map lattices for multimedia communication security. More specifically, we first utilize the piecewise linear chaotic map with secret keys to generate initial parameter sequence for the cross coupled map lattices and an initial hash value. Then, we extend the original message into a message matrix to enhance the correlation of message characters. Next, we process each of the message blocks in the matrix in parallel as the space domain input of the cross coupled map lattices and the initial parameters as the time domain input to generate intermediate hash values. After all message blocks are processed in parallel, the final h-bit hash value is obtained by logical operations with the initial and intermediate hash values. Finally, we evaluate the performance of the proposed hash function in terms of uniform distribution of hash values, sensitivity of the hash value to subtle changes of the original message, secret keys, and images, confusion and diffusion properties, collision tests, efficiency of computation speed. The cryptanalytic results demonstrate that the proposed hash algorithm has statistical properties with B=64.0022 and P =50.0017%, collision resistance with d =85.3944, average computation speed of 132.0 Mbps, and better statistical performance compared with existing chaotic hash functions, which are suitable for multimedia communication security.
C1 [Li, Yantao] Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
   [Ge, Guangfu] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
C3 Chongqing University; Southwest University - China
RP Li, YT (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400044, Peoples R China.
EM yantaoli@foxmail.com
OI Li, Yantao/0000-0001-7648-5671
FU National Natural Science Foundation of China [61672119, 61528206,
   61402380]; Natural Science Foundation of CQ CSTC [cstc2015jcyjA40044,
   cstc2014jcyjA40030]; Fundamental Research Funds for the Central
   Universities [XDJK2015B030]; U.S. National Science Foundation
   [CNS-1253506, CNS-1618300]; Opening Project of State Key Laboratory for
   Novel Software Technology [KFKT2016B13]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant nos. 61672119, 61528206 and 61402380), the
   Natural Science Foundation of CQ CSTC (Grant nos. cstc2015jcyjA40044,
   and cstc2014jcyjA40030), the Fundamental Research Funds for the Central
   Universities (Grant no. XDJK2015B030), U.S. National Science Foundation
   (Grant nos. CNS-1253506 (CAREER) and CNS-1618300), and the Opening
   Project of State Key Laboratory for Novel Software Technology (Grant No.
   KFKT2016B13).
CR Ahmad M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0123-1
   Akhavan A, 2009, CHAOS SOLITON FRACT, V42, P1046, DOI 10.1016/j.chaos.2009.02.044
   Akhavan A, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-126
   Amin M, 2009, CHAOS SOLITON FRACT, V42, P767, DOI 10.1016/j.chaos.2009.02.001
   [Anonymous], 2005, TECHNICAL REPORT
   [Anonymous], 2018, ARXIV180801956
   [Anonymous], 2004, Cryptol. ePrint Arch., Tech. Rep. 2004/199
   Bakhtiari S, 1996, LECT NOTES COMPUT SC, V1029, P201, DOI 10.1007/BFb0032359
   Deng SJ, 2011, COMMUN NONLINEAR SCI, V16, P3269, DOI 10.1016/j.cnsns.2010.12.016
   Deng SJ, 2010, COMMUN NONLINEAR SCI, V15, P1338, DOI 10.1016/j.cnsns.2009.05.065
   Deng SJ, 2009, COMMUN NONLINEAR SCI, V14, P3889, DOI 10.1016/j.cnsns.2009.02.020
   Elhoseny M, 2018, J COMPUT SCI-NETH, V25, P339, DOI 10.1016/j.jocs.2017.08.004
   Elhoseny M, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2724846
   Elhoseny M, 2018, EXPERT SYST APPL, V92, P142, DOI 10.1016/j.eswa.2017.09.008
   Elhoseny M, 2017, J INTELL FUZZY SYST, V33, P2305, DOI 10.3233/JIFS-17348
   Elhoseny M, 2017, WIRELESS PERS COMMUN, V95, P3733, DOI 10.1007/s11277-017-4023-8
   Elhoseny M, 2016, SECUR COMMUN NETW, V9, P2024, DOI 10.1002/sec.1459
   Elhoseny M, 2016, J KING SAUD UNIV-COM, V28, P262, DOI 10.1016/j.jksuci.2015.11.001
   Elsayed W, 2018, COMPUT ELECTR ENG, V70, P799, DOI 10.1016/j.compeleceng.2017.12.022
   Farouk A, 2018, FRONT PHYS-BEIJING, V13, DOI 10.1007/s11467-017-0717-3
   Guo W, 2009, PHYS LETT A, V373, P3201, DOI 10.1016/j.physleta.2009.07.016
   Guo XF, 2006, ACTA PHYS SIN-CH ED, V55, P4442, DOI 10.7498/aps.55.4442
   Hong D, 2016, MULTIMED TOOLS APPL, V75, P14525, DOI 10.1007/s11042-015-2769-0
   Jiteurtragool N, 2013, INT CONF ADV COMMUN, P1089
   Kanso A, 2015, NONLINEAR DYNAM, V81, P27, DOI 10.1007/s11071-015-1970-z
   Kanso A, 2013, COMMUN NONLINEAR SCI, V18, P109, DOI 10.1016/j.cnsns.2012.06.019
   Kim BK, 2017, MULTIMED TOOLS APPL, V76, P19649, DOI 10.1007/s11042-016-3373-7
   Kim H, 2019, MULTIMED TOOLS APPL, V78, P3107, DOI 10.1007/s11042-018-5630-4
   Kwok HS, 2005, INT J BIFURCAT CHAOS, V15, P4043, DOI 10.1142/S0218127405014489
   Li YT, 2016, CHAOS SOLITON FRACT, V91, P639, DOI 10.1016/j.chaos.2016.08.014
   Li YT, 2016, NONLINEAR DYNAM, V84, P2387, DOI 10.1007/s11071-016-2652-1
   Li YT, 2016, OPTIK, V127, P4484, DOI 10.1016/j.ijleo.2016.01.176
   Li YT, 2012, INFORM SCIENCES, V214, P56, DOI 10.1016/j.ins.2012.06.001
   Li YT, 2011, NEURAL COMPUT APPL, V20, P1305, DOI 10.1007/s00521-011-0543-4
   Li YT, 2011, NEURAL COMPUT APPL, V20, P133, DOI 10.1007/s00521-010-0432-2
   Li YL, 2012, OPT FIBER TECHNOL, V18, P7, DOI 10.1016/j.yofte.2011.09.004
   Lin ZS, 2019, CLUSTER COMPUT, V22, P905, DOI 10.1007/s10586-017-1062-6
   Lin ZS, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501061
   Liu HJ, 2018, MULTIMED TOOLS APPL, V77, P1391, DOI 10.1007/s11042-016-4288-z
   Liu JD, 2012, J COMPUT, V7, P1671, DOI 10.4304/jcp.7.7.1671-1680
   Luo YL, 2012, CHINESE PHYS B, V21, DOI 10.1088/1674-1056/21/6/060503
   Mendel F, 2013, LECT NOTES COMPUT SC, V7881, P262, DOI 10.1007/978-3-642-38348-9_16
   Mihçak MK, 2005, MULTIMEDIA SYST, V11, P185, DOI 10.1007/s00530-005-0201-8
   NIST, 2001, SECURE HASH STANDARD
   Nouri M, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1044, DOI 10.1109/ISTEL.2012.6483140
   Ren HJ, 2009, CHAOS SOLITON FRACT, V42, P2014, DOI 10.1016/j.chaos.2009.03.168
   Rivest R., 1992, MD5 MESSAGE DIGEST A
   ROMPEL J, 1990, PROCEEDINGS OF THE TWENTY SECOND ANNUAL ACM SYMPOSIUM ON THEORY OF COMPUTING, P387, DOI 10.1145/100216.100269
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Stevens M, 2013, LECT NOTES COMPUT SC, V7881, P245, DOI 10.1007/978-3-642-38348-9_15
   Tang KW, 2007, INT J BIFURCAT CHAOS, V17, P923, DOI 10.1142/S021812740701763X
   Teh JS, 2015, NONLINEAR DYNAM, V81, P1067, DOI 10.1007/s11071-015-2049-6
   Tharwat A, 2019, CLUSTER COMPUT, V22, pS4745, DOI 10.1007/s10586-018-2360-3
   Tsudik G., 1992, Computer Communication Review, V22, P29, DOI 10.1145/141809.141812
   Wang QX, 2016, IEEE T CIRCUITS-I, V63, P401, DOI 10.1109/TCSI.2016.2515398
   Wang SH, 2011, CHINESE PHYS B, V20, DOI 10.1088/1674-1056/20/9/090504
   Wang SH, 2012, COMMUN NONLINEAR SCI, V17, P780, DOI 10.1016/j.cnsns.2011.06.017
   Wang XY, 2005, LECT NOTES COMPUT SC, V3621, P17
   Wang Y, 2007, CIS WORKSHOPS 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY WORKSHOPS, P791, DOI 10.1109/CIS.Workshops.2007.16
   Wang Y, 2008, INFORM SCIENCES, V178, P1391, DOI 10.1016/j.ins.2007.10.008
   Wang Y, 2011, COMMUN NONLINEAR SCI, V16, P2810, DOI 10.1016/j.cnsns.2010.10.001
   Wong KW, 2003, PHYS LETT A, V307, P292, DOI 10.1016/S0375-9601(02)01770-X
   Xiao D, 2008, PHYS LETT A, V372, P4682, DOI 10.1016/j.physleta.2008.04.060
   Xiao D, 2010, COMMUN NONLINEAR SCI, V15, P2254, DOI 10.1016/j.cnsns.2009.10.012
   Xiao D, 2010, PHYS LETT A, V374, P1228, DOI 10.1016/j.physleta.2010.01.006
   Xiao D, 2009, PHYS LETT A, V373, P4346, DOI 10.1016/j.physleta.2009.09.059
   Xiao D, 2009, NEUROCOMPUTING, V72, P2288, DOI 10.1016/j.neucom.2008.12.031
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Yi X, 2005, IEEE T CIRCUITS-II, V52, P354, DOI 10.1109/TCSII.2005.848992
   Yuan XH, 2017, J NETW SYST MANAG, V25, P21, DOI 10.1007/s10922-016-9379-7
   Zhang H, 2005, ACTA PHYS SIN-CH ED, V54, P4006, DOI 10.7498/aps.54.4006
   Zhang J, 2010, PHYS LETT A, V362, P439
   Zhang P, 2017, WIRELESS PERS COMMUN, V96, P2289, DOI 10.1007/s11277-017-4298-9
NR 74
TC 29
Z9 29
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17973
EP 17994
DI 10.1007/s11042-018-7122-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200029
DA 2024-07-18
ER

PT J
AU Mei, JH
   Wu, ZM
   Chen, X
   Qiao, Y
   Ding, HH
   Jiang, XD
AF Mei, Jianhan
   Wu, Ziming
   Chen, Xiang
   Qiao, Yu
   Ding, Henghui
   Jiang, Xudong
TI DeepDeblur: text image recovery from blur to sharp
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text Deblurring; Convolutional Neural Network (CNN); Blind
   deconvolution; Short connection
AB Digital images could be degraded by a variety of blur during the image acquisition (i.e. relative motion of cameras, electronic noise, capturing defocus, and so on). Blurring images can be computationally modeled as the result of a convolution process with the corresponding blur kernel and thus, image deblurring can be regarded as a deconvolution operation. In this paper, we explore to deblur images by approximating blind deconvolutions using a deep neural network. Different deep neural network structures are investigated to evaluate their deblurring capabilities, which contributes to the optimal design of a network architecture. It is found that shallow and narrow networks are not capable of handling complex motion blur. We thus, present a deep network with 20 layers to cope with text image blur. In addition, a novel network structure with Sequential Highway Connections (SHC) is leveraged to gain superior convergence. The experiment results demonstrate the state-of-the-art performance of the proposed framework with the higher visual quality of the delurred images.
C1 [Mei, Jianhan; Jiang, Xudong] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
   [Ding, Henghui] Nanyang Technol Univ, Sch Elect & Elect Engn, Rapid Rich Object Search Lab, Singapore, Singapore.
   [Wu, Ziming] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Chen, Xiang] Tech Univ Darmstadt, Fachbereich Informat, Darmstadt, Germany.
   [Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Nanyang Technological University; Nanyang Technological University; Hong
   Kong University of Science & Technology; Technical University of
   Darmstadt; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS
RP Jiang, XD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
EM jianhan001@e.ntu.edu.sg; zwual@connect.ust.hk;
   xiang.chen@visinf.tu-darmstadt.de; yu.qiao@siat.ac.cn;
   ding0093@e.ntu.edu.sg; exdjiang@ntu.edu.sg
RI Yu, Qiao/IAP-6999-2023; Mei, Jianhan/K-7294-2014; Ding,
   Henghui/C-7486-2019; Qiao, Yu/ABD-5787-2021; Jiang, Xudong/B-1555-2008
OI Mei, Jianhan/0000-0002-3510-2897; Ding, Henghui/0000-0003-4868-6526;
   Jiang, Xudong/0000-0002-9104-2315
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2012, IEEE T IMAGE PROCESS
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], 2014, ACM INT C MULTIMEDIA
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], C WORKSH NEUR INF PR
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], C WORKSH NEUR INF PR
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], ACM T GRAPHICS TOG
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], INT C COMP VIS PATT
   [Anonymous], ACM T GRAPHICS TOG
   [Anonymous], 2015, ARXIV150203167
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Kaiming H., 2016, P IEEECVF C COMPUTER
   Kupyn Orest, 2017, ARXIV E PRINTS
   Lee CY, 2015, INT CONF ADV ROBOT
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Noroozi M, 2017, LECT NOTES COMPUT SC, V10496, P65, DOI 10.1007/978-3-319-66709-6_6
   Ramakrishnan S, 2017, IEEE INT CONF COMP V, P2993, DOI 10.1109/ICCVW.2017.353
NR 28
TC 14
Z9 14
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18869
EP 18885
DI 10.1007/s11042-019-7251-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200068
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Sanyal, G
AF Mukherjee, Srilekha
   Sanyal, Goutam
TI A multi level image steganography methodology based on adaptive PMS and
   block based pixel swapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Adaptive power Modulus scrambling; Block based pixel
   swapping; Peak signal to noise ratio; Cross correlation coefficient
AB The practice of information exchange through global media like internet extensively entails a security concern. This paper consists of a proposed approach that braces the security concern in the realm of image steganography. The adaptive technique of the Power Modulus Scrambling (PMS) has been preliminarily used so as to disturb the normal pixel orientation of the original carrier. A second layer of encryption is enforced with the implementation of the Block Based Pixel Swapping technique. These steps ensure a two tier secured shield. Next, the embedding procedure is facilitated depending on a comparative key based permutation combination methodology. This approach caters the need of security during communication. The proposed approach is evaluated with respect to substantial performance metrics. The commendable results obtained shows that the foothold of imperceptibility is well maintained.
C1 [Mukherjee, Srilekha; Sanyal, Goutam] Natl Inst Technol, Comp Sci & Engn Dept, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Mukherjee, S (corresponding author), Natl Inst Technol, Comp Sci & Engn Dept, Durgapur, India.
EM srilekha.mukherjee3@gmail.com; nitgsanyal@gmail.com
RI SANYAL, GOUTAM/AAI-6613-2020; Mukherjee, Srilekha/ABA-7026-2020
CR Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Al-Taani AT, 2009, INT J COMPUT INF SCI, V3, P574
   Almohammad A., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P215, DOI 10.1109/IPTA.2010.5586786
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2004, IEEE INT C IND INF B
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Banerjee I, 2015, INT J ELECTRON SECUR, V7, P345
   Bhattacharya S, 2010, INT J COMPUTER ELECT, V4, P1243
   Chandramouli R., 2003, International Workshop on Digital Watermarking, P35
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Chang KC, 2008, J MULTIMED, V3, P37, DOI DOI 10.4304/JMM.3.3.26-33
   Das S, 2019, PATTERN RECOGN LETT, V126, P102, DOI 10.1016/j.patrec.2018.06.026
   Dukkipati A, 2012, APPL MATH COMPUT, V218, P11674, DOI 10.1016/j.amc.2012.05.052
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Ferzli R, 2010, P IM PROC ALG SYST 8, V7532
   Gurav J., 2015, INT J RECENT INNOV T, V3, P1836
   Joshi R, 2013, INT J ADV RES COMPUT, V2, P228
   Lan T, 2000, INT C IM PROC ICIP V
   Lundin R, 2012, INT CONF COMPU ASPEC, P238, DOI 10.1109/CASoN.2012.6412409
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo X, 2012, COMPUT J, V55
   Maheswari SU, 2017, MULTIMED TOOLS APPL, V76, P415, DOI 10.1007/s11042-015-3035-1
   Mukherjee Srilekha, 2017, International Journal of Computers and Applications, V39, P59, DOI 10.1080/1206212X.2016.1273624
   MUKHERJEE S, 2015, TENCON IEEE REGION, pN1582
   Mukherjee S, 2016, PROGR INTELLIGENT CO, P157
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V77, P27851, DOI 10.1007/s11042-018-5996-3
   Safarpour M., 2016, ABS160100299 CORR
   Sanchetti A., 2012, INT J INNOV TECHNOL, V2, P2278
   Sheisi H., 2012, Int. J. Comput. Electr. Eng., V4, P458
   Shojanazeri H, 2017, MULTIMED TOOLS APPL, V76, P577, DOI 10.1007/s11042-015-3018-2
   Singh K. U., 2014, INT J COMPUT APPL, V97, P10
   Su Q, 2015, MULTIMED TOOLS APPL, V76, P707
   Nguyen TS, 2018, MULTIMED TOOLS APPL, V77, P26449, DOI 10.1007/s11042-018-5869-9
   Wang D., 2015, INT J NETWORK SECURI, V17, P322
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 36
TC 3
Z9 4
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17607
EP 17622
DI 10.1007/s11042-018-7127-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200014
DA 2024-07-18
ER

PT J
AU Priya, RV
AF Priya, R. Vishnu
TI Emotion recognition from geometric fuzzy membership functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric features; Primitive shape; Emotion recognition; Fuzzy
   membership function; Fuzzy-shape
ID FACIAL EXPRESSION RECOGNITION; FACE RECOGNITION; FEATURES;
   CLASSIFICATION; EIGENFACES; LBP
AB The posterity challenging task in the Machine Intelligence field is to design a smarter system to identify the human emotions. Facial Emotion Recognition (FER) is a significant visual based tool to construct a smarter system that can recognize human emotions. The existing methods in FER are based on Action Units (AU), appearance and geometrical parameters. Nearly 7000 different combinations of AUs are used in AU to discriminate the emotions, which can be very expensive and increase processing time. Generalize appearance features across the universe is another challenging task. In this paper, a novel geometrical fuzzy based approach is presented to accurately recognize the emotions. The four corner features from eyes and mouth regions are extracted without considering reference face. The extracted features are used to define the quadrilateral shape that failed to match with the shapes in geometry. The degree of impreciseness exists in the quadrilateral is measured by the proposed Mixed Quadratic Shape Model (MQSM) using fuzzy membership functions. Finally, twelve fuzzy features are extracted from the membership functions and used by the classifier for validation. The CK, JAFFE and ISED datasets are used in the experiment to evaluate the performance of the MSQM. It is observed the proposed method performed better than the contemporary methods using twelve fuzzy features without reference image.
C1 [Priya, R. Vishnu] Maulana Azad Natl Inst Technol, Dept Comp Applicat, Bhopal, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Priya, RV (corresponding author), Maulana Azad Natl Inst Technol, Dept Comp Applicat, Bhopal, Madhya Pradesh, India.
EM vishnupriya.r@vit.ac.in
CR Agarwal S, 2017, MULTIMED TOOLS APPL, V76, P1073, DOI 10.1007/s11042-015-3103-6
   Aifanti N, 2014, SIGNAL PROCESS-IMAGE, V29, P177, DOI 10.1016/j.image.2013.10.004
   Anderson K, 2006, IEEE T SYST MAN CY B, V36, P96, DOI 10.1109/TSMCB.2005.854502
   Anderson K, 2004, COMPUT VIS IMAGE UND, V95, P184, DOI 10.1016/j.cviu.2004.01.001
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], NIPS
   [Anonymous], ICM
   [Anonymous], ICMI 2016
   [Anonymous], ACTION2ACTIVITY RECO
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], IEEE ACCESS
   [Anonymous], P INT C WEB INT
   [Anonymous], IEEE ACCESS
   [Anonymous], P ICSP
   [Anonymous], ENCY INFORM SCI TECH
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2017, INT C COMP SCI ICCS
   [Anonymous], P BRIT MACH C
   [Anonymous], 2015, 2015 21 KOR JAP JOIN
   [Anonymous], 2005, Int. J. Inf. Technol.
   Barros P, 2017, NEUROCOMPUTING, V253, P104, DOI 10.1016/j.neucom.2017.01.096
   Barthomeuf L, 2012, BRIT J DEV PSYCHOL, V30, P253, DOI 10.1111/j.2044-835X.2011.02033.x
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Cruz AC, 2014, IEEE T AFFECT COMPUT, V5, P418, DOI 10.1109/TAFFC.2014.2316151
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Vo DM, 2016, 2016 3RD NATIONAL FOUNDATION FOR SCIENCE AND TECHNOLOGY DEVELOPMENT CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P80, DOI 10.1109/NICS.2016.7725672
   Ekman Paul, 1978, Action coding system: a technique for the measurement of facial movement
   Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006
   Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546
   Feng XY, 2004, LECT NOTES COMPUT SC, V3212, P668
   Gaidhane VH, 2016, SADHANA-ACAD P ENG S, V41, P415, DOI 10.1007/s12046-016-0479-6
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7921, DOI 10.1007/s11042-016-3428-9
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Gu WF, 2010, SOFT COMPUT, V14, P113, DOI 10.1007/s00500-009-0441-1
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Gupta S. K., 2011, Proceedings of the Seventh International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2011), P422, DOI 10.1109/SITIS.2011.64
   Happy SL, 2017, IEEE T AFFECT COMPUT, V8, P131, DOI 10.1109/TAFFC.2015.2498174
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He LH, 2005, P ANN INT IEEE EMBS, P3300
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Hsu FS, 2014, MULTIMED TOOLS APPL, V73, P309, DOI 10.1007/s11042-013-1616-4
   Huang Y., 2016, P 18 ACM INT C MULT
   Ilbeygi M, 2012, ENG APPL ARTIF INTEL, V25, P130, DOI 10.1016/j.engappai.2011.07.004
   Jain S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1642, DOI 10.1109/ICCVW.2011.6130446
   Kazmi SB, 2012, SOFT COMPUT, V16, P369, DOI 10.1007/s00500-011-0721-4
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kharat GU, 2009, ADV INTEL SOFT COMPU, V60, P207
   Kim D, 2017, COMPUT VIS IMAGE UND, V160, P114, DOI 10.1016/j.cviu.2017.04.008
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Kotsia I, 2008, IMAGE VISION COMPUT, V26, P1052, DOI 10.1016/j.imavis.2007.11.004
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Li J., 2015, PROC IEEE INT C IMAG, P1
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu WF, 2009, 2009 WASE INTERNATIONAL CONFERENCE ON INFORMATION ENGINEERING, ICIE 2009, VOL I, P197, DOI 10.1109/ICIE.2009.36
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lo Presti L, 2017, COMPUT VIS IMAGE UND, V156, P19, DOI 10.1016/j.cviu.2016.10.007
   Luo RC, 2011, IEEE ASME INT C ADV, P1058, DOI 10.1109/AIM.2011.6027077
   Luo Y, 2013, OPTIK, V124, P2767, DOI 10.1016/j.ijleo.2012.08.040
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Mollaeian Aida, 2016, 2016 IEEE Conference on Electromagnetic Field Computation (CEFC), DOI 10.1109/CEFC.2016.7816397
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Nielsen JA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071275
   Perez-Gaspar LA, 2016, EXPERT SYST APPL, V66, P42, DOI 10.1016/j.eswa.2016.08.047
   Poursaberi A, 2012, EURASIP J IMAGE VIDE, P1, DOI 10.1186/1687-5281-2012-17
   Pu XR, 2015, NEUROCOMPUTING, V168, P1173, DOI 10.1016/j.neucom.2015.05.005
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Rosenblum M, 1996, IEEE T NEURAL NETWOR, V7, P1121, DOI 10.1109/72.536309
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Saeed A, 2014, ADV HUM-COMPUT INTER, V2014, DOI 10.1155/2014/408953
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P445, DOI 10.1142/S0218001408006284
   Shiqing Zhang, 2012, WSEAS Transactions on Signal Processing, V8, P21
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Sohail ASM, 2011, INT J PATTERN RECOGN, V25, P835, DOI 10.1142/S0218001411008762
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P779, DOI 10.1109/TSMCB.2009.2029076
   Tsai HH, 2018, SOFT COMPUT, V22, P4389, DOI 10.1007/s00500-017-2634-3
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uddin MZ, 2009, IEEE T CONSUM ELECTR, V55, P2216, DOI 10.1109/TCE.2009.5373791
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Wang H, 2014, UNIVERSAL ACCESS INF, V13, P23, DOI 10.1007/s10209-013-0312-5
   Wu Tingfan., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P42
   Xiang C, 2006, IEEE T IMAGE PROCESS, V15, P2097, DOI 10.1109/TIP.2006.875225
   Xie XD, 2009, PATTERN RECOGN, V42, P1003, DOI 10.1016/j.patcog.2008.08.034
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Yu H, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON ELECTRIC UTILITY DEREGULATION AND RESTRUCTURING AND POWER TECHNOLOGIES (DRPT 2015), P1617, DOI 10.1109/DRPT.2015.7432501
   Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
   Zhang L, 2015, COMPUT VIS IMAGE UND, V140, P93, DOI 10.1016/j.cviu.2015.07.007
   Zhang L, 2013, EXPERT SYST APPL, V40, P5160, DOI 10.1016/j.eswa.2013.03.016
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhang SQ, 2012, SENSORS-BASEL, V12, P3747, DOI 10.3390/s120303747
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 111
TC 12
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17847
EP 17878
DI 10.1007/s11042-018-6954-9
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200024
DA 2024-07-18
ER

PT J
AU Priyanka, S
   Sudhakar, MS
AF Priyanka, S.
   Sudhakar, M. S.
TI An effective image retrieval framework in invariant feature space
   merging GeoSOM with modified inverted indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Codebook; Clustering; GeoSOM; Invariant Zernike moment descriptor;
   Inverted indexing; Precision-Recall
ID COLOR; REPRESENTATION; RECOGNITION; DESCRIPTOR
AB The complexity in retrieving diverse images with different affine transformations poses a challenging issue to researchers. Hence, this paper offers one such framework targeting the aforesaid concern. Accordingly, a three step retrieval framework is proposed that initially extracts Invariant Zernike Moment Descriptor (IZMD) features from the query database. The attained features are then vector quantized by the Geodesic Self-Organizing Map (GeoSOM) to produce the feature codebook. Finally, a slight variant of the inverted indexing scheme operates on the GeoSOM codebook to produce the closely related images. This enforces a weighting and matching strategy that reduces the search space and time. Simulation analysis of the presented framework is performed on color and medical datasets using the standard evaluation measures. Relative analysis with the state-of-the-art schemes show betterment in terms of Precision-Recall (P-R) and other performance parameters.
C1 [Priyanka, S.; Sudhakar, M. S.] VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Priyanka, S (corresponding author), VIT, Sch Elect Engn, Vellore, Tamil Nadu, India.
EM priyanka.s2014@vit.ac.in
RI M S, Sudhakar/AGS-2597-2022
OI M S, Sudhakar/0000-0003-4243-9006
CR Agrawal D, 2013, INF SYST COMP NETW I
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   Anuar FM, 2013, EXPERT SYST APPL, V40, P105, DOI 10.1016/j.eswa.2012.07.031
   BacAo F, 2005, P WORKSH SELF ORG MA
   BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066
   Bhunia A. K., 2018, ARXIV180100879
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Chen Z, 2010, IEEE T IMAGE PROCESS, V19, P205, DOI 10.1109/TIP.2009.2032890
   DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272
   Flusser J, 2006, PROC WRLD ACAD SCI E, V11, P196
   Houjeij A, 2013, IEEE ICC
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kohonen T., 2001, SPRINGER SERIES INFO, V30, P1
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Mokhtarian F, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P515
   Patel T., 2015, INT J COMPUT APPL, V132, P22
   Rahman M, 2011, SELF ORG MAPS APPL N
   Rao LK, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0044-z
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Rui Y, 1998, SER SOFTW ENGN KNOWL, V8, P165
   SHENG Y, 1986, J OPT SOC AM A, V3, P885, DOI 10.1364/JOSAA.3.000885
   Squire D, 1999, 10 SCAND C IM AN SCI
   Sudhakar MS, 2014, APPL SOFT COMPUT, V22, P492, DOI 10.1016/j.asoc.2014.04.029
   Taubin G, 1991, SPIE C GEOM METH COM
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang YP, 1999, IEEE T IMAGE PROCESS, V8, P1586, DOI 10.1109/83.799886
   Wu J, 2017, J VIS COMMUN IMAGE R, V49, P78, DOI 10.1016/j.jvcir.2017.08.002
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   ZHANG D, 2002, 5 AS C COMP VIS ACCV
NR 39
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19961
EP 19977
DI 10.1007/s11042-019-7355-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800047
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Zhou, L
   Zhang, T
   Zhang, DH
AF Zhang, Qiu-yu
   Zhou, Liang
   Zhang, Tao
   Zhang, Deng-hai
TI A retrieval algorithm of encrypted speech based on short-term
   cross-correlation and perceptual hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Short-term cross-correlation coefficient;
   Perceptual hashing; Scrambling encryption; Feature extraction of
   encrypted speech
AB In order to achieve extraction perceptual features from the encryption speech as a search digest for the content-based encryption speech retrieval, we present a retrieval algorithm of encrypted speech based on short-term cross-correlation and perceptual hashing in this paper. Firstly, the study encrypts the speech file and uploads the encrypted speech data to the encryption speech database in cloud server. Secondly, the sample speech clips are obtained by the cutting operation from the speech file for scrambling encryption. The perceptual hashing sequence of the encrypted speech is constructed by extracting the short-term cross-correlation of the encrypted speech signals as the search digest. These perceptual hashing sequences are uploaded into the hashing index table of cloud server. Finally, the Hamming distance algorithm is used for the matching retrieval operation during the search. The experimental results show that the proposed algorithm of encrypted speech perceptual hashing has a better discrimination, robustness and compactness, and the perceptual hashing sequences can be extracted directly from the encrypted sample speech. Meanwhile, the encryption speech signal has high recall and precision ratios after various content preserving operations. In the whole retrieval process, the downloading and decrypting operations of speech data are not necessary.
C1 [Zhang, Qiu-yu; Zhou, Liang; Zhang, Tao; Zhang, Deng-hai] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Gansu, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Gansu, Peoples R China.
EM zhangqylz@163.com; 874415993@qq.com; 1090408922@qq.com; zdhler@sina.com
RI Zhang, Qiu-yu/V-9223-2019; zhang, denghai/KGK-7709-2024
OI Zhang, Qiu-yu/0000-0003-1488-388X; liang, Zhou/0000-0002-9825-0387
FU National Natural Science Foundation of China [61862041, 61363078];
   Research Project in Universities of Education Department of Gansu
   Province [2017B-16, 2018A-187]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, No. 61363078), the Research Project in Universities
   of Education Department of Gansu Province (2017B-16, 2018A-187). The
   authors would like to thank the anonymous reviewers for their helpful
   comments and suggestions.
CR Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   de Carvalho CAB, 2017, IEEE ACM INT SYMP, P715, DOI 10.1109/CCGRID.2017.19
   Chen DQ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P531
   Ding D, 2012, INT C MULT RETR ICMR, DOI 10.1145/2324796.2324799
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   Habib Z, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC ENGINEERING (ICEEE 2017), P246, DOI 10.1109/ICEEE2.2017.7935827
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Hu PF, 2014, PATTERN RECOGN, V47, P1138, DOI 10.1016/j.patcog.2013.06.010
   Kalker T, 2001, PROC SPIE, V4518, P189, DOI 10.1117/12.448203
   Lv X, 2018, FUTURE GENER COMP SY, V82, P41, DOI 10.1016/j.future.2017.11.046
   Mäkinen T, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-23
   Mitani K, 2016, INT SIGN PROC COMM S, P1, DOI [10.1109/ISPACS.2016.7824729, DOI 10.1109/ISPACS.2016.7824729]
   Roy A, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11808-x
   Sadr A, 2015, MULTIMED TOOLS APPL, V74, P9715, DOI 10.1007/s11042-014-2147-3
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Tahir S, 2017, 2017 31ST INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P242, DOI 10.1109/ICOIN.2017.7899512
   Thangavel M, 2016, 2016 INT C REC TREND, P1, DOI DOI 10.1109/ICRTIT.2016.7569581
   Wang HX, 2015, China patent, Patent No. [CN104835499A, 104835499A]
   Wang K, 2013, SIXTH INTERNATIONAL CONFERENCE ON NONLINEAR MECHANICS (ICNM-VI), P423
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Xu Y, 2017, IEEE-ACM T AUDIO SPE, V25, P1230, DOI 10.1109/TASLP.2017.2690563
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zhang QY, 2018, MULTIMED TOOLS APPL, V77, P21653, DOI 10.1007/s11042-018-5613-5
   Zhang R, 2018, TRAC-TREND ANAL CHEM, V99, P1, DOI 10.1016/j.trac.2017.11.015
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
   Zhu XF, 2017, IEEE T MULTIMEDIA, V19, P2033, DOI 10.1109/TMM.2017.2703636
   Zou FH, 2018, MULTIMED TOOLS APPL, V77, P3677, DOI 10.1007/s11042-017-5219-3
NR 32
TC 22
Z9 23
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17825
EP 17846
DI 10.1007/s11042-019-7180-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200023
DA 2024-07-18
ER

PT J
AU Akter, LA
   Moon, I
   Kwon, GR
AF Akter, Lata Ayesha
   Moon, Inkyu
   Kwon, Goo-Rak
TI Double random phase encoding with a Poisson-multinomial distribution for
   efficient colorful image authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical security and encryption; Pattern recognition;
   Poisson-multinomial distribution; Photon-counting imaging; Double
   randomphase encryption; Probability density function; Nonlinear
   correlations; Color image authentication
ID OPTICAL ENCRYPTION; TRANSFORM; SYSTEM
AB In this paper, a new integrated approach is proposed for authenticating digital color image. Here, a new technique, Poisson-Multinomial Distribution (PMD) is introduced for the first time in image processing. It is used for Photon Counting Imaging (PCI) which is integrated with Double Random Phase Encoding (DRPE) scheme in this system. The main goal of this proposal is to establish an image authentication architecture which will only work for 3D digital color images. It is a simplified way for applying PCI scheme on three channels of a 3D image simultaneously. The system will generate a stationary white noise as a final output, which will be difficult to decode for a third party attacker. This proposed scheme works directly with the original digital RGB image. At first, the system encrypts those three channels of the image individually with DRPE method without separating them and the amplitude part of the encrypted image is photon counted using PMD. Finally, to obtain an optimal result, a probability density function is used. On the authentication part, the reference digital image is encrypted by the same keys as the original image and then both of the encrypted images are compared with a statistical nonlinear correlation method. The numerical experiments say that, this proposed PMD based method is proven to be a good and simplified one that can be used to encrypt digital color images. In addition, even if the number of photons is really low, this new system can successfully differentiate between true class and false class images. To prove its efficiency we have also shown some experimental results under different situations.
C1 [Akter, Lata Ayesha] Chosun Univ, Dept Comp Engn, 309 Pilmun Daero, Gwangju 61452, South Korea.
   [Moon, Inkyu] DGIST, Dept Robot Engn, 333 Techno Jungang Daero, Daegu 42988, South Korea.
   [Kwon, Goo-Rak] Chosun Univ, Sch Informat Commun Engn, 309 Pilmun Daero, Gwangju 61452, South Korea.
C3 Chosun University; Daegu Gyeongbuk Institute of Science & Technology
   (DGIST); Chosun University
RP Kwon, GR (corresponding author), Chosun Univ, Sch Informat Commun Engn, 309 Pilmun Daero, Gwangju 61452, South Korea.
EM grkwon@chosun.ac.kr
OI Lata, Ayesha Akter/0000-0003-4041-0920; Kwon,
   Goo-Rak/0000-0003-3486-8812
CR Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Abuturab MR, 2012, APPL OPTICS, V51, P3006, DOI 10.1364/AO.51.003006
   [Anonymous], 2013, REP AN PRIV SEC ONL
   Bernier M, 2009, OPT EXPRESS, V17, P3285, DOI 10.1364/OE.17.003285
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Inkyu Moon, 2013, Journal of Display Technology, V9, P51, DOI 10.1109/JDT.2012.2227938
   Javidi B, 1997, OPT ENG, V36, P992, DOI 10.1117/1.601144
   JAVIDI B, 1989, APPL OPTICS, V28, P2358, DOI 10.1364/AO.28.002358
   Lee IH, 2013, J OPT SOC KOREA, V17, P494, DOI 10.3807/JOSK.2013.17.6.494
   Li XW, 2014, OPTIK, V125, P2983, DOI 10.1016/j.ijleo.2013.12.036
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   MENDLOVIC D, 1995, APPL OPTICS, V34, P7538, DOI 10.1364/AO.34.007538
   Monaghan DS, 2009, J OPT SOC AM A, V26, P2033, DOI 10.1364/JOSAA.26.002033
   Moon I, 2009, OPT LETT, V34, P731, DOI 10.1364/OL.34.000731
   Muniraj I, 2015, OPT EXPRESS, V23, P15907, DOI 10.1364/OE.23.015907
   Pérez-Cabré E, 2012, J OPTICS-UK, V14, DOI 10.1088/2040-8978/14/9/094001
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Sang J, 2012, SENSORS-BASEL, V12, P13441, DOI 10.3390/s121013441
   Suzuki H, 2006, OPT EXPRESS, V14, P1755, DOI 10.1364/OE.14.001755
   Tan XD, 2001, APPL OPTICS, V40, P2310, DOI 10.1364/AO.40.002310
   Webster JG, SERIES MED PHYS BIOM
   Yi F, 2014, SENSORS-BASEL, V14, P8877, DOI 10.3390/s140508877
NR 25
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14613
EP 14632
DI 10.1007/s11042-018-6844-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700022
DA 2024-07-18
ER

PT J
AU Fati, SM
   Sumari, P
AF Fati, Suliman Mohamed
   Sumari, Putra
TI A survey on content awareness challenges in IPTV delivery networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Delivery networks; Replica placement; Content status; Load
   balancing; IPTV delivery networks
ID REQUEST DISTRIBUTION; OPTIMAL ALLOCATION; REPLICA PLACEMENT; FILE
   PLACEMENT; VOD SERVERS; VIDEO; PERFORMANCE; CLUSTER; OPTIMIZATION;
   ARCHITECTURE
AB Nowadays, with the evolution of digital video broadcasting, as well as, the advent of high speed broadband networks, a new era of TV services has emerged known as IPTV. IPTV is a system that exploits the high speed broadband networks to deliver TV services to the subscribers. From the service provider viewpoint, the challenge in IPTV systems is how to build delivery networks that exploits the resources efficiently and reduces the service cost, as well. However, designing such delivery networks are affected by many factors including choosing the suitable network architecture, load balancing, resources waste, and cost reduction. Furthermore, IPTV contents characteristics; particularly size, popularity, and interactivity play an important role in balancing the load and avoiding the resources waste for delivery networks. Ignoring the content status in solving delivery networks issues particularly replica placement, request distribution, and resource allocation problems leads to load imbalance, which in turn, leads to performance degradation in IPTV system. In this survey paper, we introduce IPTV delivery networks terminology and taxonomy. Upon that, we investigate the challenges related to the contents' awareness in those delivery networks. At the end of the paper, we propose a content-awareness in ITV delivery networks and CDN as the future direction and discuss its importance in different aspects as request redirection, resource allocation, and replica placement.
C1 [Fati, Suliman Mohamed] Prince Sultan Univ, Dept Informat Syst, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
   [Sumari, Putra] Univ Sains Malaysia, Multimedia Res Grp, Sch Comp Sci, George Town 11800, Malaysia.
C3 Prince Sultan University; Universiti Sains Malaysia
RP Fati, SM (corresponding author), Prince Sultan Univ, Dept Informat Syst, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
EM smfati@yahoo.com; putra@cs.usm.my
RI Sumari, Putra/I-1070-2016; Fati, Suliman Mohamed/W-9547-2018
OI Fati, Suliman/0000-0002-6969-2338
CR Aldana Diaz ME, 2011, P 5 ACM INT C UB INF, P114
   Alemany J, 1997, TR970202 U WASH DEP
   [Anonymous], HPL2002
   [Anonymous], 2011, TECHNICAL REPORT
   [Anonymous], THESIS
   [Anonymous], 2007, TECHNICAL REPORT
   [Anonymous], 2010, P ACM MM WORKSH SOC
   Belbekkouche A, 2012, IEEE COMMUN SURV TUT, V14, P1114, DOI 10.1109/SURV.2011.122811.00060
   Bikfalvi A, 2011, COMPUT NETW, V55, P1310, DOI 10.1016/j.comnet.2010.12.020
   Bisdikian CC, 1996, IEEE MULTIMEDIA, V3, P62, DOI 10.1109/93.556540
   Bolosky WJ, 1996, MSRTR9609
   Borzemski L, 2008, LECT NOTES ARTIF INT, V5178, P117, DOI 10.1007/978-3-540-85565-1_15
   Cardellini V, 1999, IEEE INTERNET COMPUT, V3, P28, DOI 10.1109/4236.769420
   Casalicchio E., 2002, Cluster Computing, V5, P65, DOI 10.1023/A:1012796706047
   Chang Soo Kim, 2006, 8th International Conference on Advanced Communication Technology (IEEE Cat. No.06EX1209C)
   Cherkasova L, 2000, 8TH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P492, DOI 10.1109/MASCOT.2000.876576
   Cho DH, 2008, J SYST ARCHITECT, V54, P335, DOI 10.1016/j.sysarc.2007.08.001
   Choe Y.R., 2007, MULTIMEDIA 07 P 15 I, P117
   Cidon I, 2002, COMPUT NETW, V40, P205, DOI 10.1016/S1389-1286(02)00251-7
   CRANOR CD, 2003, P 13 INT WORKSH NETW, P4, DOI DOI 10.1145/776322.776326
   Dakshayini M, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL IV, PROCEEDINGS, P162, DOI 10.1109/ICCIMA.2007.170
   Davies C, 2005, TECHNICAL REPORT
   Dees E, 2007, THESIS
   Du ZH, 2011, J SYST SOFTWARE, V84, P1224, DOI 10.1016/j.jss.2011.02.038
   Dukes J, 2004, LECT NOTES COMPUT SC, V3311, P194
   Ebara H, 2005, IEICE T COMMUN, VE88B, P4598, DOI 10.1093/ietcom/e88-b.12.4598
   Fan QL, 2018, COMPUT ELECTR ENG, V66, P332, DOI 10.1016/j.compeleceng.2017.04.011
   Fati SM, 2014, P 8 INT C UB INF MAN, P106
   Fati SM, 2018, IPTV DELIV NETW NEXT, P93
   Fati SM, 2017, PROC INT CONF COMP, P282
   Figueiredo Flavio, 2011, P 4 ACM INT C WEB SE, P745, DOI DOI 10.1145/1935826.1935925
   Fleury J, 2006, ITU T IPTV GLOB TECH
   Gaber SMA, 2012, MULTIMED TOOLS APPL, P1
   Gaber SMA, 2012, J INF COMMUN TECHNOL, V11, P131
   Gafsi J, 2000, IEEE T PARALL DISTR, V11, P412, DOI 10.1109/71.850836
   Ganger G. R., 1993, Proceeding of the Twenty-Sixth Hawaii International Conference on System Sciences (Cat. No.93TH0501-7), P40, DOI 10.1109/HICSS.1993.270759
   García R, 2009, COMPUT NETW, V53, P2038, DOI 10.1016/j.comnet.2009.03.011
   GlobeComm, 2006, IPTV REV NEW OPP NEW
   Golubchik L, 2001, IEEE T PARALL DISTR, V12, P363, DOI 10.1109/71.920587
   Guo J, 2008, IEEE T KNOWL DATA EN, V20, P836, DOI 10.1109/TKDE.2007.190742
   Guruprasad HS, 2008, INT J COMPUT SCI SEC, V2, P14
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Hongliang Yu, 2006, Operating Systems Review, V40, P333, DOI 10.1145/1218063.1217968
   Houidi I, 2011, COMPUT NETW, V55, P1011, DOI 10.1016/j.comnet.2010.12.011
   Huang C, 2007, ACM SIGCOMM COMP COM, V37, P133, DOI 10.1145/1282427.1282396
   Huang YF, 2004, INFORM SCIENCES, V164, P113, DOI 10.1016/j.ins.2003.10.005
   ITU-T Focus Group IPTV I. P. T. V, 2006, SERV REQ
   Jacqui C, 2007, ARS TECHNICA
   Joe I, 2011, COMM COM INF SC, V262, P28
   Karantanis S, 2009, THESIS
   Khan SU, 2008, J PARALLEL DISTR COM, V68, P113, DOI 10.1016/j.jpdc.2007.06.009
   Kim J, 2010, INT J SECUR APPL, V4, P1
   Kitjongthawonkul S., 2011, Proceedings of the 2011 13th International Conference on Advanced Communication Technology (ICACT). Smart Service Innovation through Mobile Interactivity, P1031
   Kulatunga C, 2011, P INT C COMM ICC 11, P1
   Laoutaris N, 2005, COMPUT NETW, V47, P409, DOI 10.1016/j.comnet.2004.07.020
   Lee JYB, 2000, IEEE T PARALL DISTR, V11, P1217, DOI 10.1109/71.895790
   Lee SB, 2009, IEEE T BROADCAST, V55, P516, DOI 10.1109/TBC.2009.2015985
   Li MF, 2010, COMPUT COMMUN, V33, P83, DOI 10.1016/j.comcom.2009.08.003
   Lie PWK, 2000, MULTIMED TOOLS APPL, V11, P35, DOI 10.1023/A:1009673332611
   Little T., 1993, LECT NOTES COMPUTER, P204
   Loukopoulos T, 2004, J PARALLEL DISTR COM, V64, P1270, DOI 10.1016/j.jpdc.2004.04.005
   Mahmood A, 2010, INFORM PROCESS MANAG, V46, P170, DOI 10.1016/j.ipm.2009.06.006
   Mikoczy E, 2009, STUD COMPUT INTELL, V231, P315
   Mir NF, 2011, PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON NETWORKS (ICN 2011), P430
   Mohamed Fati S., 2018, IPTV DELIVERY NETWOR, P1
   Moon J, 2010, LECT NOTES COMPUT SC, V6018, P269, DOI 10.1007/978-3-642-12179-1_24
   MRG, 2012, IPTV MARK LEAD REP
   Nair TR, 2010, J COMPUT, V2, P14
   Nakaniwa A, 2007, IASTED INT CONF INTE, P15
   Neves T.A., 2010, ELECT NOTES DISCRETE, V36, P89
   Nguyen TV, 2005, COMPUT NETW, V49, P103, DOI 10.1016/j.comnet.2005.04.001
   Nishimura H., 2012, 2012 16th International Conference on Intelligence in Next Generation Networks (ICIN 2012): Realising the Power of the Network, P1, DOI 10.1109/ICIN.2012.6376026
   Niu Di, 2013, THESIS
   Nordstrom E., 2009, TECHNICAL REPORT, P2009
   Open IPTV Forum, 2009, TECHNICAL REPORT
   Organization for Economics Development (OECD), 2007, DSTIICCPCISP20072FIN
   Pai VS, 1998, ACM SIGPLAN NOTICES, V33, P205, DOI 10.1145/291006.291048
   Pandey S, 2011, INT J NETW MANAG, V21, P455, DOI 10.1002/nem.769
   Passarella A, 2012, COMPUT COMMUN, V35, P1, DOI 10.1016/j.comcom.2011.10.005
   Pathan M, 2009, MULTIAGENT GRID SYST, V5, P165, DOI 10.3233/MGS-2009-0127
   Pathan M, 2008, LECT NOTES ELECTR EN, V9, P3
   Plagemann T, 2006, COMPUT COMMUN, V29, P551, DOI 10.1016/j.comcom.2005.06.006
   Sabella R, 2007, 3 EURONGI C NEXT GEN, pxviii
   Scheuermann P, 1998, VLDB J, V7, P48, DOI 10.1007/s007780050053
   Sharifian S, 2008, FUTURE GENER COMP SY, V24, P775, DOI 10.1016/j.future.2008.03.005
   Sharifian S, 2011, APPL SOFT COMPUT, V11, P970, DOI 10.1016/j.asoc.2010.01.017
   Shicong Meng, 2010, 2010 IEEE International Conference on Web Services (ICWS), P179, DOI 10.1109/ICWS.2010.26
   Sierra-LLamazares KG, 2009, THESIS
   Sujatha DN, 2008, 9 INT C DISTR COMP N, P478
   Takayanagi K, 2003, BROADCAST TECHNOLOGY
   Tang KS, 2001, IEEE T IND ELECTRON, V48, P891, DOI 10.1109/41.954552
   Tay YC, 2000, IEEE T KNOWL DATA EN, V12, P410, DOI 10.1109/69.846293
   Tenzakhti F, 2004, J SYST ARCHITECT, V50, P591, DOI 10.1016/j.sysarc.2003.12.003
   Teo YM, 2001, SIMULATION, V77, P185, DOI 10.1177/003754970107700504
   Thouin F, 2007, THESIS
   Thouin F, 2007, IEEE NETWORK, V21, P42, DOI 10.1109/MNET.2007.334311
   Valentin R, 2004, DIGITAL TV BROADCAST
   Vicari C, 2008, THESIS
   Vinay A, 2011, P INT C ICWET, P344
   WAH BW, 1984, COMPUTER, V17, P23, DOI 10.1109/MC.1984.1658928
   WANG JQ, 2001, WUHAN SHIP BUILDING, V3, P1
   Wang YW, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P102, DOI 10.1109/MMCS.1997.609580
   Wauters T, 2006, COMPUT COMMUN, V29, P3313, DOI 10.1016/j.comcom.2006.05.008
   WOLF J, 1989, PERF E R SI, V17, P1, DOI 10.1145/75372.75373
   Xu S., 2009, THESIS
   Yarali A., 2005, INTERNET PROTOCOL TE, P1
   Zaman S, 2011, IEEE T PARALL DISTR, V22, P1455, DOI 10.1109/TPDS.2011.27
   ZHOU X, 2002, P INT C IPDPS, P127
   Zhou XB, 2007, J NETW COMPUT APPL, V30, P515, DOI 10.1016/j.jnca.2006.03.001
NR 109
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16817
EP 16842
DI 10.1007/s11042-018-7057-3
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500048
DA 2024-07-18
ER

PT J
AU Lakshmi, KD
   Rajappa, M
   Krithivasan, K
   Roy, DS
AF Lakshmi, Divya K.
   Rajappa, Muthaiah
   Krithivasan, Kannan
   Roy, Diptendu Sinha
TI Helly hypergraph based matching framework using deterministic sampling
   techniques for spatially improved point feature based image matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypergraph matching; Helly property; Point correspondence; Image
   matching
ID ALGORITHM
AB Hypergraphs are tools for matching of point-features incorporating spatial relationships in the form of hyperedges exhibiting topological and geometric features between the points of images to be matched. Considering all possible hyperedges is computationally expensive and are randomly chosen in the state of the art techniques. A Helly Hypergraph based Matching Framework (HHMF) is proposed for the matching of images using point-features with effective hyperedges. The framework includes proposed algorithms such as Construction of Hyperedges using Point-features by Random (CHPR), Combinatorial (CHPC), and Exhaustive (CHPE) sampling techniques with and without Helly selection. The resultant hyperedges are treated with Adaptive Block Co-ordinate Ascent Graph Matching with Integer Projected Fixed Point algorithm. The performance of the proposed framework is evaluated in terms of Accuracy, Matching score, Execution time and Tensor Size for synthetic point sets and Willow wine image dataset. Based on the experimental studies carried out against existing framework, CHPC, and CHPE with Helly selection, exhibited better performance with 73.88% & 81% accuracy for 53.64 & 14.8% reduced tensor size respectively, in deformation noise tests, and 98% & 96% accuracy for 97% & 70% reduced tensor size in outlier tests. In the implicit experimental comparisons within sampling techniques, CHPR, and CHPE provided better performance with 81.37%, and 76% accuracy. In general, HHMF framework has reduced the tensor size and execution time for deterministic sampling cases during point sets matching. The framework can be extended in the near future by incorporating learning schemes for automated hypergraph based point sets matching.
C1 [Lakshmi, Divya K.; Rajappa, Muthaiah] SASTRA Univ, Sch Comp, Thirumalaisamudram 613401, Thanjavur, India.
   [Krithivasan, Kannan] SASTRA Univ, Sch Humanities & Sci, Thirumalaisamudram 613401, Thanjavur, India.
   [Roy, Diptendu Sinha] NIT Meghalaya, Comp Sci & Engn Dept, Shillong 793003, Meghalaya, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   National Institute of Technology (NIT System); National Institute of
   Technology Meghalaya
RP Lakshmi, KD (corresponding author), SASTRA Univ, Sch Comp, Thirumalaisamudram 613401, Thanjavur, India.
EM divyalakshmi8188@gmail.com
RI k, k/KFC-0221-2024; k, k/HZK-4476-2023; k, k/KFT-2541-2024; su,
   haobo/JPK-2362-2023; K, Kannan/GPK-0744-2022; Krishnan,
   Divya/AAQ-6599-2021
OI Rajappa, Muthaiah/0000-0002-6659-1961
FU Council of Scientific and Industrial Research
   [09/1095/(0009)/2015-EMR-I]; Department of Science & Technology -
   Science and Engineering Research Board [SR/FST/MSI-107/2015]
FX This work was supported by the Council of Scientific and Industrial
   Research, the premier research and development organization in India,
   under the Senior Research Fellowship Scheme. (grant number
   09/1095/(0009)/2015-EMR-I). The second author wishes to thank Department
   of Science & Technology - Science and Engineering Research Board for the
   financial support through FIST No.: SR/FST/MSI-107/2015 and TATA Realty
   IT city-SASTRA Srinivasan Ramanujan Research Cell.
CR Ali-Sisto D, 2017, IEEE J-STARS, V10, P1197, DOI 10.1109/JSTARS.2016.2615099
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Bretto A, 2002, INFORM PROCESS LETT, V81, P55, DOI 10.1016/S0020-0190(01)00186-7
   Bretto A, 1997, GRAPH MODEL IM PROC, V59, P265, DOI 10.1006/gmip.1997.0437
   Bretto A., 2001, Electron Notes Theoretic Comput Sci, V46, P181, DOI [DOI 10.1016/S1571-0661(04)80985-X, 10.1016/S1571-0661(04)80985-X]
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Dharmarajan R, 2016, THESIS
   Dongxiang Zhou, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P4020, DOI 10.1109/WCICA.2004.1342254
   Dourado M.C., 2006, J BRAZ COMPUT SOC, V12, P7, DOI DOI 10.1007/BF03192385
   Dourado MC, 2008, INFORM PROCESS LETT, V108, P247, DOI 10.1016/j.ipl.2008.05.013
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Kahaki SMM, 2016, NEUROCOMPUTING, V175, P1009, DOI 10.1016/j.neucom.2015.09.106
   Kannan K, 2010, IMAGE VISION COMPUT, V28, P1329, DOI 10.1016/j.imavis.2010.01.013
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Lin MC, 2007, INFORM PROCESS LETT, V103, P40, DOI 10.1016/j.ipl.2007.02.017
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ng ES, 2012, IEEE T IMAGE PROCESS, V21, P3429, DOI 10.1109/TIP.2012.2195012
   Nguyen Q, 2017, IEEE T PATTERN ANAL, V39, P1054, DOI 10.1109/TPAMI.2016.2574706
   Rajesh Khanna B, 2012, THESIS
   Somu N, 2017, FUTURE GENER COMP SY, V68, P14, DOI 10.1016/j.future.2016.08.014
   Yan JC, 2018, IEEE T CYBERNETICS, V48, P765, DOI 10.1109/TCYB.2017.2655538
   Yan JC, 2015, PROC CVPR IEEE, P1520, DOI 10.1109/CVPR.2015.7298759
   Zass R, 2008, PROC CVPR IEEE, P1221
   Zhang H, 2017, PATTERN RECOGN LETT, V87, P87, DOI 10.1016/j.patrec.2016.07.011
   Zisserman, 2004, MULTIPLE VIEW GEOMET, P673, DOI [10.1017/CBO9780511811685, DOI 10.1017/CBO9780511811685]
NR 30
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14657
EP 14681
DI 10.1007/s11042-018-6852-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700024
DA 2024-07-18
ER

PT J
AU Noura, HN
   Noura, M
   Chehab, A
   Mansour, MM
   Couturier, R
AF Noura, Hassan N.
   Noura, Mohamad
   Chehab, Ali
   Mansour, Mohammad M.
   Couturier, Raphael
TI Efficient and secure cipher scheme for multimedia contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Parallel image cipher scheme; Error propagation; Visual degradation;
   Balance between security level and performance
ID IMAGE; PERFORMANCE; CHAOS
AB The impact of confidentiality and privacy breaches are more pronounced when dealing with multimedia contents. One of the obvious techniques to counter these threats is the use of encryption. A number of algorithms for robust image encryption, targeted for real-time applications with tight resource constraints, has been proposed in the literature. In this paper, first, we analyze two recent cipher schemes for image contents, which are based on two rounds. We show that the schemes are designed to ensure maximum avalanche effect in the whole image by employing the chaining block code mode (CBC) in forward and backward directions. However, they do not lend themselves to parallel implementation and they have a problem with error propagation, which is not desirable for wireless multimedia transmission. As such, we propose to redesign the underlying algorithm to make it practical when used with applications that either suffer from a high error percentage or from real-time constraints. The modified cipher employs the counter mode to eliminate the chaining process (forward and backward), which allows for parallel computations and minimizes the effect of error propagation. According to the security and performance results, the proposed scheme can respond better to the applications and/or system requirements and limitations by ensuring a better performance and an equally high level of security compared to both ciphers in addition to minimum error propagation. To the best of our knowledge, the proposed scheme is the first dynamic key-dependent stream cipher scheme with a pseudo-random key-stream generation for re-ordering of sub-matrices.
C1 [Noura, Hassan N.; Chehab, Ali; Mansour, Mohammad M.] Amer Univ Beirut, Maroun Semaan Fac Engn & Architecture, Dept Elect & Comp, Beirut, Lebanon.
   [Noura, Mohamad; Couturier, Raphael] UBFC, FEMTO ST Inst, CNRS, Besancon, France.
C3 American University of Beirut; Universite de Franche-Comte; Universite
   de Technologie de Belfort-Montbeliard (UTBM); Centre National de la
   Recherche Scientifique (CNRS)
RP Couturier, R (corresponding author), UBFC, FEMTO ST Inst, CNRS, Besancon, France.
EM hn49@aub.edu.lb; mohamad.noura@univ-fcomte.fr; chehab@aub.edu.lb;
   mm14@aub.edu.lb; raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Noura, Hassan/U-8729-2018
OI Couturier, Raphaël/0000-0003-1490-9592; Noura,
   Hassan/0000-0002-2589-5053; Noura, Hassan/0000-0003-1768-9193; Chehab,
   Ali/0000-0002-1939-2740
FU Maroun Semaan Faculty of Engineering and Architecture at the American
   University of Beirut; EIPHI Graduate School [ANR-17-EURE-0002]
FX This paper is partially funded from the Maroun Semaan Faculty of
   Engineering and Architecture at the American University of Beirut and by
   the EIPHI Graduate School (contract "ANR-17-EURE-0002").
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   Akhshani A, 2010, OPT COMMUN, V283, P3259, DOI 10.1016/j.optcom.2010.04.056
   Alajel KM, 2010, 2010 4 INT C SIGN PR, P1
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   [Anonymous], COMP COMM NETW ICCCN
   [Anonymous], 2017, NISTIR8114
   [Anonymous], 2014, IACR CRYPTOLOGY EPRI
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2015, IACR CRYPTOLOGY EPRI
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Barker EB, 2011, RECOMMENDATION RANDO
   Biham E, 1993, DIFFERENTIAL CRYPTAN, V28
   Borghoff J, 2012, LECT NOTES COMPUT SC, V7658, P208, DOI 10.1007/978-3-642-34961-4_14
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Cho JS, 2011, COMPUT COMMUN, V34, P391, DOI 10.1016/j.comcom.2010.02.029
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Dong F, 2010, MED PHYS, V37, DOI 10.1118/1.3468041
   Dworkin M., 2001, RECOMMENDATION BLOCK
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Feng Huang, 2009, Frontiers of Electrical and Electronic Engineering in China, V4, P5, DOI 10.1007/s11460-009-0016-z
   Flayh NA, 2009, 2009 INTERNATIONAL CONFERENCE ON MULTIMEDIA, SIGNAL PROCESSING AND COMMUNICATION TECHNOLOGIES, P32, DOI 10.1109/MSPCT.2009.5164167
   Gamal T.E., 1984, P WORKSH THEOR APPL, V196, P10, DOI DOI 10.1007/3-540-39568-7_2
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Gross H, 2017, LECT NOTES COMPUT SC, V10159, P95, DOI 10.1007/978-3-319-52153-4_6
   Gueron S, 2009, LECT NOTES COMPUT SC, V5665, P51, DOI 10.1007/978-3-642-03317-9_4
   Guo J, 2011, LECT NOTES COMPUT SC, V6917, P326, DOI 10.1007/978-3-642-23951-9_22
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Hu Y, 2014, SCI WORLD J, V2014, P7
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Janakiraman S, 2018, MICROPROCESS MICROSY, V56, P1, DOI 10.1016/j.micpro.2017.10.013
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Laiphrakpam DS, 2018, MULTIMED TOOLS APPL, V77, P8629, DOI 10.1007/s11042-017-4755-1
   Li CQ, 2011, INT J BIFURCAT CHAOS, V21, P2067, DOI 10.1142/S0218127411029641
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mondal B, 2017, J KING SAUD UNIV-COM, V29, P499, DOI 10.1016/j.jksuci.2016.02.003
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Noura H, 2015, IEEE WCNC, P2103, DOI 10.1109/WCNC.2015.7127792
   Noura H, 2014, IEEE WCNC, P2635, DOI 10.1109/WCNC.2014.6952824
   NYBERG K, 1995, J CRYPTOL, V8, P27, DOI 10.1007/BF00204800
   O'Melia S, 2010, IEEE T VLSI SYST, V18, P1505, DOI 10.1109/TVLSI.2009.2025171
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Shibutani K, 2011, LECT NOTES COMPUT SC, V6917, P342, DOI 10.1007/978-3-642-23951-9_23
   Shujiang Xu, 2008, 2008 International Conference on Computational Intelligence and Security, P433, DOI 10.1109/CIS.2008.146
   Suzaki T., 2013, P INT C SEL ARE CRYP, V7707, P339
   Tong XJ, 2009, OPT COMMUN, V282, P2722, DOI 10.1016/j.optcom.2009.03.075
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu WL, 2011, LECT NOTES COMPUT SC, V6715, P327, DOI 10.1007/978-3-642-21554-4_19
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
NR 57
TC 14
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14837
EP 14866
DI 10.1007/s11042-018-6845-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700032
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zheng, HD
   Liu, D
   Wang, JF
   Liang, J
AF Zheng, Hongdi
   Liu, Dong
   Wang, Junfeng
   Liang, Jie
TI A QoE-perceived screen updates transmission scheme in desktop
   virtualization environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Desktop virtualization; QoE-perceived model; Partially reliable;
   Transmission scheme
ID CONGESTION CONTROL; PERFORMANCE; QUALITY; EXPERIENCE; PROTOCOL
AB As a solution for cloud computing, desktop virtualization realizes the remote execution of applications and feeds back execution results in the form of screen updates through network, aiming to offer users the same experience as operating in local systems. It is challenging to achieve this goal since timeliness and reliability should be both guaranteed during the process of screen updates transmission, but the two requirements tend to be difficult to be satisfied simultaneously. Reliable transmission will induce more latency to perform reliable mechanisms, which can influence the timely delivery of screen updates. Timely transmission just provides a best-effort data delivery service, failing to react well to unfavorable network conditions. In order to cope with this problem, we propose a Partially Reliable Transmission Scheme (PRTS) for screen updates transmission in desktop virtualization environment. It tries to make trade-offs between timeliness and reliability and employs a QoE-perceived model to sense the visual quality experienced by users. Distinguished with existing transmission schemes, PRTS adjusts its sending strategy not only according to current network conditions, but also according to users' QoE. The experimental results show that PRTS can improve the transmission efficiency of screen updates and also the visual quality in desktop virtualization environment under different network conditions.
C1 [Zheng, Hongdi; Wang, Junfeng] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
   [Liu, Dong] Nucl Power Inst China, Chengdu 610200, Sichuan, Peoples R China.
   [Wang, Junfeng] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Sichuan, Peoples R China.
   [Liang, Jie] China Informat Technol Secur Evaluat Ctr, Beijing 100085, Peoples R China.
C3 Sichuan University; Sichuan University
RP Wang, JF (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.; Wang, JF (corresponding author), Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610065, Sichuan, Peoples R China.
EM zhdscu@126.com; liudong73@yahoo.com; wangjf@scu.edu.cn;
   liangj@itsec.gov.cn
FU National Natural Science Foundation of China [91338107, U1836103];
   Development Program of Sichuan, China [2017GZDZX0002, 18ZDYF3867,
   19ZDZX0024]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 91338107 and U1836103, and in part by
   the Development Program of Sichuan, China under Grants 2017GZDZX0002,
   18ZDYF3867 and 19ZDZX0024.
CR Ahmad S, 2010, IEEE T CIRC SYST VID, V20, P275, DOI 10.1109/TCSVT.2009.2031545
   [Anonymous], 2011, P 20 IEEE INT C COMP
   BANSAL D, 2000, MITLCSTR806
   Borri M, 2004, IEEE COMMUN LETT, V8, P541, DOI 10.1109/LCOMM.2004.833835
   Cai L, 2005, IEEE T MULTIMEDIA, V7, P339, DOI 10.1109/TMM.2005.843360
   Carlucci G, 2017, IEEE ACM T NETWORK, V25, P2629, DOI 10.1109/TNET.2017.2703615
   Chen KB, 2017, MULTIMED TOOLS APPL, V76, P19557, DOI 10.1007/s11042-016-3247-z
   Claeys M, 2016, INT CONF NETW SER, P100, DOI 10.1109/CNSM.2016.7818405
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Jiang Y, 2014, INT J GRID DISTRIB C, V7
   Lázaro F, 2017, IEEE T COMMUN, V65, P4114, DOI 10.1109/TCOMM.2017.2715805
   Li ZL, 2017, MULTIMED TOOLS APPL, V76, P10893, DOI 10.1007/s11042-016-4038-2
   Liotou E, 2015, IEEE COMMUN MAG, V53, P145, DOI 10.1109/MCOM.2015.7158278
   Luo Q, 2018, IEEE J SEL AREA COMM, V36, P257, DOI 10.1109/JSAC.2018.2804099
   McQuistin S, 2016, 2016 IFIP NETWORKING CONFERENCE (IFIP NETWORKING) AND WORKSHOPS, P422, DOI 10.1109/IFIPNetworking.2016.7497221
   Mukherjee B, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P165, DOI 10.1109/ICNP.2000.896301
   Nieh J, 2003, ACM T COMPUT SYST, V21, P87, DOI 10.1145/592637.592640
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Oludele A., 2014, J COMPUTER SCI APPL, V2, P40, DOI [DOI 10.12691/JCSA-2-3-1, 10.12691/jcsa-2-3-1]
   Ngo QT, 2017, MULTIMED TOOLS APPL, V76, P22217, DOI 10.1007/s11042-017-4692-z
   Saini M, 2017, MULTIMED TOOLS APPL, V76, P11621, DOI 10.1007/s11042-015-3158-4
   Sangtae Ha, 2008, Operating Systems Review, V42, P64, DOI 10.1145/1400097.1400105
   Sgardoni V, 2015, IEEE T MOBILE COMPUT, V14, P401, DOI 10.1109/TMC.2014.2331967
   Shen ZH, 2017, INT J MODEL SIMUL SC, V8, DOI 10.1142/S1793962317500453
   Soltanian A, 2018, IEEE ACCESS, V6, P9792, DOI 10.1109/ACCESS.2018.2794258
   Vankeirsbilck B, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P385, DOI 10.1109/ATNAC.2008.4783355
   Vankeirsbilck B, 2012, J NETW COMPUT APPL, V35, P1620, DOI 10.1016/j.jnca.2012.03.007
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie HH, 2016, IEEE T VEH TECHNOL, V65, P923, DOI 10.1109/TVT.2015.2397862
   Zhao L, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 3, P43, DOI 10.1109/ICICISYS.2009.5358230
NR 31
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16755
EP 16781
DI 10.1007/s11042-018-7058-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500045
DA 2024-07-18
ER

PT J
AU Barra, S
   Bisogni, C
   Nappi, M
   Ricciardi, S
AF Barra, Silvio
   Bisogni, Carmen
   Nappi, Michele
   Ricciardi, Stefano
TI F-FID: fast fuzzy-based iris de-noising for mobile security applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iris segmentation; Noise removal; Fuzzy controller; Gini index
ID RECOGNITION; SEGMENTATION
AB Once confined to indoor biometric applications depending on dedicated acquisition devices, recently the iris has proved to be a suitable biometric for in-the-wild ubiquitous person authentication, thanks to continuously improving image capturing/processing performances provided by last generations of smartphones. In this mobile context, the efficiency of the whole processing pipeline represents a crucial aspect of any practical application and the segmentation task, that is deeply affected by noisy iris images may become a serious bottleneck. This work presents F-FID, an effective and time-wise efficient approach to de-noising of iris images by means of a fuzzy controller without sacrificing their resolution and saliency. The experiments, specifically conducted on the MICHE dataset, confirm that the proposed method provides segmentation accuracy comparable to that achieved by state of the art algorithms, while requiring less than twenty percent of their average computing time.
C1 [Barra, Silvio] Univ Cagliari, Dept Math & Comp Sci, Cagliari, Italy.
   [Bisogni, Carmen; Nappi, Michele] Univ Salerno, Dept Comp Sci, Salerno, Italy.
   [Ricciardi, Stefano] Univ Molise, Dept Biosci & Terr, Molise, Italy.
C3 University of Cagliari; University of Salerno; University of Molise
RP Barra, S (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Cagliari, Italy.
EM silvio.barra@unica.it; cbisogni@unisa.it; mnappi@unisa.it;
   stefano.ricciardi@unimol.it
RI Barra, Silvio/J-8577-2019; Bisogni, Carmen/GXG-4181-2022
OI Barra, Silvio/0000-0003-4042-3000; Bisogni, Carmen/0000-0003-1358-006X
CR Abate Andrea F., 2018, Cyberspace Safety and Security. 10th International Symposium, CSS 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11161), P270, DOI 10.1007/978-3-030-01689-0_21
   Abate A, 2016, INT C PATT RECOG, P155, DOI 10.1109/ICPR.2016.7899625
   Abate AF, 2019, IEEE T SYST MAN CY-S, V49, P469, DOI 10.1109/TSMC.2017.2698258
   Abate AF, 2017, PATTERN RECOGN LETT, V91, P37, DOI 10.1016/j.patrec.2017.02.002
   Abate AF, 2017, LECT NOTES ARTIF INT, V10147, P260, DOI 10.1007/978-3-319-52962-2_23
   Abate AF, 2017, LECT NOTES COMPUT SC, V10485, P93, DOI 10.1007/978-3-319-68548-9_9
   [Anonymous], 2014, INT C LEARN REPR
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Barra S, 2014, LECT NOTES COMPUT SC, V8897, P28, DOI 10.1007/978-3-319-13386-7_3
   Barra S, 2015, PATTERN RECOGN LETT, V57, P66, DOI 10.1016/j.patrec.2014.10.011
   Barra S, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414600039
   Bowyer K.W., 2013, Handbook of Iris Recognition, P15, DOI [10.1007/978-1-4471-4402-1_2, DOI 10.1007/978-1-4471-4402-1_2, DOI 10.1007/978-1-4471-4402-12]
   Chaskar U, 2012, IRIS IMAGE QUALITY A
   Clarke NL, 2007, COMPUT SECUR, V26, P109, DOI 10.1016/j.cose.2006.08.008
   Daugman J, 2001, INT J COMPUT VISION, V45, P25, DOI 10.1023/A:1012365806338
   Daugman J, 2009, IRIS RECOGNITION WOR, DOI [10. 1016/B978-0-12-374457-9. 00025-1, DOI 10.1016/B978-0-12-374457-9.00025-1]
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   De Marsico M, 2018, PATTERN RECOGN, V74, P286, DOI 10.1016/j.patcog.2017.08.028
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   Du YZ, 2011, IEEE T SYST MAN CY B, V41, P64, DOI 10.1109/TSMCB.2010.2045371
   El-Zaart Ali, 2010, J COMPUTER SCI, V6, P217
   Elrefaei LA, 2018, MULTIMED TOOLS APPL, V77, P14579, DOI 10.1007/s11042-017-5049-3
   Haindl M, 2015, PATTERN RECOGN LETT, V57, P60, DOI 10.1016/j.patrec.2015.02.012
   Hofbauer H, 2014, INT C PATT RECOG, P527, DOI 10.1109/ICPR.2014.101
   Jarjes A. A., 2011, Proceedings of the 2011 3rd International Conference on Advanced Computer Control (ICACC 2011), P515, DOI 10.1109/ICACC.2011.6016466
   Jayalakshmi S, 2013, 2013 INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, INFORMATICS AND MEDICAL ENGINEERING (PRIME)
   Jeong DS, 2010, IMAGE VISION COMPUT, V28, P254, DOI 10.1016/j.imavis.2009.04.001
   Kumar V., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P56, DOI 10.1070/pu1997v040n05abeh000236.www.ijetae.com
   Labati RD, 2012, IRIS SEGMENTATION ST, P151
   LERMAN RI, 1984, ECON LETT, V15, P363, DOI 10.1016/0165-1765(84)90126-5
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Makinana S, 2014, LECT NOTES COMPUT SC, V8397, P571, DOI 10.1007/978-3-319-05476-6_58
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1502, DOI 10.1109/TPAMI.2009.140
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Rad RM., 2013, Int J Signal Process Image Process Pattern Recog, V6, P37
   Ross A, 2006, SEGMENTING NONIDEAL, DOI [10. 1109/BCC. 2006. 4341625., DOI 10.1109/BCC.2006.4341625]
   SHESHINSKI E, 1972, J ECON THEORY, V4, P98, DOI 10.1016/0022-0531(72)90167-6
   Tian QC, 2004, FAST ALGORITHM APPL
   Vatsa M, 2008, IEEE T SYST MAN CY B, V38, P1021, DOI 10.1109/TSMCB.2008.922059
   Wan Y, 2015, FOREST POLICY ECON, V50, P118, DOI 10.1016/j.forpol.2014.06.002
   Wang N, 2014, MULTIMED TOOLS APPL, V71, P1411, DOI 10.1007/s11042-012-1278-7
NR 43
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 14045
EP 14065
DI 10.1007/s11042-019-7156-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900065
DA 2024-07-18
ER

PT J
AU Choudhury, SK
   Padhy, RP
   Sa, PK
   Bakshi, S
AF Choudhury, Suman Kumar
   Padhy, Ram Prasad
   Sa, Pankaj Kumar
   Bakshi, Sambit
TI Human detection using orientation shape histogram and coocurrence
   textures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Stereo geometry; Disparity estimation; Feature
   extraction; Classification
ID PEDESTRIAN DETECTION; SEGMENTATION; OCCLUSION; MULTIPLE; FEATURES;
   TRACKING; IMAGE; MODEL
AB In this article, we present a framework to detect pedestrians in presence of various real world challenges. The depth-level occlusion is addressed by a stereo-aided triangulation mechanism, where the ORB (Oriented FAST and Rotated BRIEF) descriptor is used to speed up the disparity estimation. An empirical formulation has been made to compute the maximum feasible window size during region proposals generation. The variation of unusual articulated postures is tackled with a shape-histogram representation that uses a set of oriented, high-frequency kernels to compute the gradient details; a set of co-occurrence texture cues is further taken into consideration to strengthen the resulting descriptor. We validate the efficacy of our method on three benchmark pedestrian datasets, where the obtained results are expressed in terms of five performance metric.
C1 [Choudhury, Suman Kumar; Padhy, Ram Prasad; Sa, Pankaj Kumar; Bakshi, Sambit] Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, OD, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Choudhury, SK (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci & Engn, Rourkela 769008, OD, India.
EM sumanchoudhury.nitr@gmail.com; ramprasad.nitr@gmail.com;
   pankajksa@nitrkl.ac.in; bakshisambit@nitrkl.ac.in
RI Gandhiraman, Ram P./B-7004-2013; K, Pankaj/A-9362-2017; Bakshi,
   Sambit/JDC-3355-2023
OI Bakshi, Sambit/0000-0002-6107-114X; PATURI, RAM
   PRASAD/0000-0002-1233-6930
CR [Anonymous], INT C COMP VIS SYST
   [Anonymous], 2013, ADV MECH ENG
   [Anonymous], 2007, SOC IND APPL MATH
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], IEEE T INTELL TRANSP
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Brown LM, 2014, INT C PATT RECOG, P2239, DOI 10.1109/ICPR.2014.389
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Errami M, 2016, I C COMP GRAPH IM VI, P156, DOI 10.1109/CGiV.2016.38
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Feidie Liang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P811, DOI 10.1007/978-3-642-34778-8_76
   Gavrila DM, 2007, IEEE T PATTERN ANAL, V29, P1408, DOI 10.1109/TPAMI.2007.1062
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gürbüz SZ, 2012, IEEE T AERO ELEC SYS, V48, P1306, DOI 10.1109/TAES.2012.6178063
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lin Z, 2008, LECT NOTES COMPUT SC, V5305, P423, DOI 10.1007/978-3-540-88693-8_31
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Liu YZ, 2016, NEUROCOMPUTING, V184, P55, DOI 10.1016/j.neucom.2015.07.143
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Maji S, 2008, PROC CVPR IEEE, P2245
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645
   Ouyang WL, 2013, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR.2013.414
   Ouyang WL, 2012, PROC CVPR IEEE, P3258, DOI 10.1109/CVPR.2012.6248062
   Rittscher J, 2005, PROC CVPR IEEE, P486
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Yao SH, 2015, NEUROCOMPUTING, V151, P1006, DOI 10.1016/j.neucom.2014.08.080
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang XW, 2015, NEUROCOMPUTING, V168, P861, DOI 10.1016/j.neucom.2015.05.038
   Zhao T, 2008, IEEE T PATTERN ANAL, V30, P1198, DOI 10.1109/TPAMI.2007.70770
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 46
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13949
EP 13969
DI 10.1007/s11042-018-6866-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900060
DA 2024-07-18
ER

PT J
AU Jahid, T
   Karmouni, H
   Hmimid, A
   Sayyouri, M
   Qjidaa, H
AF Jahid, Tarik
   Karmouni, Hicham
   Hmimid, Abdeslam
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Fast computation of Charlier moments and its inverses using Clenshaw's
   recurrence formula for image analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moments; Image; Reconstruction; Charlier; Clenshaw; Fast computation
ID PARALLEL FRAMEWORK; INVARIANT MOMENTS
AB In this paper, we propose a new fast way to compute both the image Charlier moments and its inverses using Clenshaw's recurrence formula. Firstly, we present recursive polynomials of Charlier with respect to the order n and with respect to the variable x and then we define Clenshaw's recurrence formula to improve the consuming time of the proposed algorithm. So, to show the robustness of the proposed method, a comparative study with the classical method is carried out. In fact, the results of the simulations carried out on binary and gray-scale images show the effectiveness of the proposed method in terms of the calculation time of Charlier moments and in terms of image reconstruction capacity with respect to Krawtchouk moments.
C1 [Jahid, Tarik; Karmouni, Hicham; Hmimid, Abdeslam; Qjidaa, Hassan] Univ Sidi Mohamed Ben Abdellah Fez, Fac Sci Dhar El Mahrez, LESSI, CED ST,STIC, Fes, Morocco.
   [Sayyouri, Mhamed] Univ Chouaib Doukkali, Ecole Natl Sci Appl Jadida, Lab Sci Ingn Energie, BP 1166, El Jadida Plateau 24004, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Chouaib Doukkali University
   of El Jadida
RP Jahid, T (corresponding author), Univ Sidi Mohamed Ben Abdellah Fez, Fac Sci Dhar El Mahrez, LESSI, CED ST,STIC, Fes, Morocco.
EM jahidtarik@gmail.com; hicham.karmouni@usmba.ac.ma;
   abdeslam.hmimid@usmba.ac.ma; mhamed.sayyouri@usmba.ac.ma;
   qjidah@yahoo.fr
RI Sayyouri, Mhamed/AAB-5496-2020; Karmouni, Hicham/ACB-0232-2022
OI Sayyouri, Mhamed/0000-0002-1615-419X; Karmouni,
   Hicham/0000-0001-9225-8380; Hassan, qjidaa/0000-0003-4505-5243
CR [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], 2017, 2017 INT C EL INF TE
   [Anonymous], 1992, ART SCI COMPUTING
   [Anonymous], 2017, 2017 INT C ADV TECHN
   [Anonymous], TIP
   [Anonymous], WSEAS T SIGNAL PROCE
   [Anonymous], 2015, J THEORETICAL APPL C
   [Anonymous], TPAMI
   [Anonymous], 2014, MOMENTS MOMENT INVAR
   Hmimid A, 2015, PATTERN RECOGN, V48, P509, DOI 10.1016/j.patcog.2014.08.020
   Hmimid A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013026
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Karmouni H, 2018, CIRC SYST SIGNAL PR, V37, P4015, DOI 10.1007/s00034-018-0755-2
   Karmouni H, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov AF, 1991, CLASSICAL ORTHOGONAL
   Sayyouri M, 2016, MULTIMED TOOLS APPL, V75, P547, DOI 10.1007/s11042-014-2307-5
   Sayyouri M, 2015, CIRC SYST SIGNAL PR, V34, P875, DOI 10.1007/s00034-014-9881-7
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang GB, 2006, PATTERN RECOGN, V39, P47, DOI 10.1016/j.patcog.2005.05.015
   Yan C, 2018, IEEE Transactions on Multimedia
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
   Zhu HQ, 2011, INT J PATTERN RECOGN, V25, P37, DOI 10.1142/S0218001411008506
   Zhu HQ, 2007, SIGNAL PROCESS, V87, P687, DOI 10.1016/j.sigpro.2006.07.007
NR 30
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12183
EP 12201
DI 10.1007/s11042-018-6757-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900050
DA 2024-07-18
ER

PT J
AU Kaur, J
   Jindal, N
AF Kaur, Jobanpreet
   Jindal, Neeru
TI A secure image encryption algorithm based on fractional transforms and
   scrambling in combination with multimodal biometric keys
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric keys; Image encryption; Security analysis; Differential
   attacks; Spoofing attacks
ID FOURIER-TRANSFORM; IRIS
AB In today's digital world, security is a preeminent element in the transmission of digital images. In this paper, image encryption algorithm is proposed using fractional transform and scrambling along with multimodal biometric keys. For unauthorized persons, it is very difficult to retrieve the biometric keys. Firstly, both iris and fingerprint binary codes are XORed and given to the original image. This randomized image is secured using fractional order as a key. The significant feature of fractional transforms benefits from its extra degree of freedom that is provided by its fractional orders. The fractional order is calculated from the iris key. To make the encryption more confusing, scrambling is used to shuffle the position of pixels. Experimental results like histogram analysis, correlation analysis, peak signal-to-noise ratio, mean square error, structural similarity index measure, spectral distortion, information entropy, key sensitivity analysis, differential attacks and spoofing attacks verify the efficacy of proposed algorithm.
C1 [Kaur, Jobanpreet; Jindal, Neeru] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Jindal, N (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM neeru.jindal@thapar.edu
CR Acharya Bibhudendra, 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P77, DOI 10.1109/ICETET.2008.110
   Bhatnagar G, 2014, IEEE T SYST MAN CY-S, V44, P1234, DOI 10.1109/TSMC.2014.2303789
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Chandra S, 2014, 2014 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATION AND COMPUTATIONAL ENGINEERING (ICECCE), P83, DOI 10.1109/ICECCE.2014.7086640
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Huijuan X, 2007, 1 INT S DATA PRIV E
   Jain AK, 2007, Handbook of biometrics, DOI DOI 10.1007/978-0-387-71041-9
   Jindal N, 2014, SIGNAL IMAGE VIDEO P, V8, P1543, DOI 10.1007/s11760-012-0391-4
   Jindal N, 2013, J ELECTR ENG-SLOVAK, V64, P250, DOI 10.2478/jee-2013-0036
   Khashan OA, 2014, J ZHEJIANG U-SCI C, V15, P435, DOI 10.1631/jzus.C1300262
   Lima JB, 2014, SIGNAL PROCESS, V94, P521, DOI 10.1016/j.sigpro.2013.07.020
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Naik K., 2015, INT J COMPUT VISION, V5, P335, DOI DOI 10.1504/IJCVR.2015.071337
   Narayanan VA, 2003, MICROPROCESS MICROSY, V27, P511, DOI 10.1016/S0141-9331(03)00113-3
   Pan SM, 2017, MULTIMED TOOLS APPL, V76, P2933, DOI 10.1007/s11042-015-3209-x
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Qiudong Sun, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1669, DOI 10.1109/FSKD.2012.6233963
   Rao BR, 2012, INT J ENG RES APPL I
   Singh H, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0110-y
   Sui LS, 2015, OPT COMMUN, V343, P140, DOI 10.1016/j.optcom.2015.01.021
   Takeda M, 2012, J OPTICS-UK, V14, DOI 10.1088/2040-8978/14/9/094003
   Venter J, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.4.044001
   Vilardy Juan M., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012047
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wu JH, 2013, J COMPUT, V8, P2816, DOI 10.4304/jcp.8.11.2816-2822
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhao DM, 2008, OPT COMMUN, V281, P5326, DOI 10.1016/j.optcom.2008.07.049
   Zhao QJ, 2010, PATTERN RECOGN, V43, P1050, DOI 10.1016/j.patcog.2009.08.004
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 35
TC 13
Z9 15
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11585
EP 11606
DI 10.1007/s11042-018-6701-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900022
DA 2024-07-18
ER

PT J
AU Relan, D
   Ballerini, L
   Trucco, E
   MacGillivray, T
AF Relan, Devanjali
   Ballerini, Lucia
   Trucco, Emanuele
   MacGillivray, Tom
TI Using orthogonal locality preserving projections to find dominant
   features for classifying retinal blood vessels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retina; Fundus images; Vessel classification; Feature extraction;
   Orthogonal locality preserving projections (OLPP)
ID ARTERIES; CLASSIFICATION; SEGMENTATION; DIAGNOSIS; VEINS
AB Automatically classifying retinal blood vessels appearing in fundus camera imaging into arterioles and venules can be problematic due to variations between people as well as in image quality, contrast and brightness. Using the most dominant features for retinal vessel types in each image rather than predefining the set of characteristic features prior to classification may achieve better performance. In this paper, we present a novel approach to classifying retinal vessels extracted from fundus camera images which combines an Orthogonal Locality Preserving Projections for feature extraction and a Gaussian Mixture Model with Expectation-Maximization unsupervised classifier. The classification rate with 47 features (the largest dimension tested) using OLPP on our own ORCADES dataset and the publicly available DRIVE dataset was 90.56% and 86.7% respectively.
C1 [Relan, Devanjali; Ballerini, Lucia; MacGillivray, Tom] Univ Edinburgh, Ctr Clin Brain Sci, Edinburgh, Midlothian, Scotland.
   [Trucco, Emanuele] Univ Dundee, Sch Sci & Engn, Comp, Dundee, Scotland.
C3 University of Edinburgh; University of Dundee
RP Relan, D (corresponding author), Univ Edinburgh, Ctr Clin Brain Sci, Edinburgh, Midlothian, Scotland.
EM devanjali_relan@ed-alumni.net; lucia.ballerini@ed.ac.uk;
   E.Trucco@dundee.ac.uk; T.J.MacGillivray@ed.ac.uk
RI Relan, Devanjali/AAF-6555-2019; Ballerini, Lucia/AAY-6629-2021;
   BALLERINI, LUCIA/GQP-7330-2022
OI Relan, Devanjali/0000-0002-8946-7437; Trucco,
   Emanuele/0000-0002-5055-0794; MacGillivray, Tom/0000-0001-5120-0086
FU Leverhulme Trust [RPG-419]; NHS Lothian RD; Edinburgh Clinical Research
   Imaging Centre
FX This work was supported by Leverhulme Trust grant RPG-419 "Discovery of
   retinal biomarkers for genetics with large cross-linked datasets".
   Support from NHS Lothian R&D and the Edinburgh Clinical Research Imaging
   Centre is gratefully acknowledged.
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Adlakha A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1122, DOI 10.1109/CCAA.2016.7813884
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alharthi N., 2017, Scientific Modelling and Research, V2, P9, DOI 10.20448/808.2.1.9.18
   Aly S., 2018, NED University Journal of Research, V15, P17
   [Anonymous], 2016, INDIAN J SCI TECHNOL, DOI DOI 10.17485/ijst/2016/v9i28/98382
   [Anonymous], 2016, ARXIV160500763
   [Anonymous], IM VIS COMP C
   [Anonymous], 2018, J Inf Secur Cybercrimes Res (JISCR), DOI DOI 10.26735/16587790.2018.006
   [Anonymous], 2014, J COMPUTER SCI, DOI DOI 10.3844/JCSSP.2014.2088.2094
   [Anonymous], J COMPUTER HARDWARE
   [Anonymous], ARXIV13070995
   [Anonymous], P 32 ANN HAW INT C S
   [Anonymous], 16 SCI HAJJ RES FOR
   [Anonymous], MED IMAGING IMAGE PR
   [Anonymous], 2009, SPIE MED IMAGING
   [Anonymous], DIMENSIONALITY REDUC
   Baker ML, 2008, STROKE, V39, P1371, DOI 10.1161/STROKEAHA.107.496091
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cai D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P3, DOI 10.1145/1076034.1076039
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Chrástek R, 2005, MED IMAGE ANAL, V9, P297, DOI 10.1016/j.media.2004.12.004
   Dashtbozorg B, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2263809
   Frost S, 2013, TRANSL PSYCHIAT, V3, DOI 10.1038/tp.2012.150
   Giachetti A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2145, DOI 10.1109/ICIP.2011.6116035
   Grisan E, 2003, P ANN INT IEEE EMBS, V25, P890, DOI 10.1109/IEMBS.2003.1279908
   Gutub A., 2017, Multimed. Tools Appl., P1
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hamednejad G, 2015, 2015 22ND IRANIAN CONFERENCE ON BIOMEDICAL ENGINEERING (ICBME), P257, DOI 10.1109/ICBME.2015.7404152
   Jordan KC, 2017, EXPERT REV OPHTHALMO, V12, P207, DOI 10.1080/17469899.2017.1307105
   Joshi VS, 2012, PROC SPIE, V8315, DOI 10.1117/12.911490
   Kim S, 2015, VISUAL COMPUT, V31, P541, DOI 10.1007/s00371-014-0946-1
   Li CM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P376, DOI 10.1109/IITA.2008.71
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   McQuillan R, 2008, AM J HUM GENET, V83, P359, DOI 10.1016/j.ajhg.2008.08.007
   Miri Maliheh, 2017, J Med Signals Sens, V7, P59
   Mirsharif Q, 2013, COMPUT MED IMAG GRAP, V37, P607, DOI 10.1016/j.compmedimag.2013.06.003
   Muramatsu C, 2011, COMPUT MED IMAG GRAP, V35, P472, DOI 10.1016/j.compmedimag.2011.03.002
   Niemeijer M, 2011, IEEE T MED IMAGING, V30, P1941, DOI 10.1109/TMI.2011.2159619
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Ong EP, 2016, IEEE ENG MED BIO, P3252, DOI 10.1109/EMBC.2016.7591422
   Ong EP, 2015, IEEE IMAGE PROC, P2720, DOI 10.1109/ICIP.2015.7351297
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Relan D, 2013, IEEE ENG MED BIO, P7396, DOI 10.1109/EMBC.2013.6611267
   Saez M, 2012, COMPUT METH PROG BIO, V108, P367, DOI 10.1016/j.cmpb.2012.02.008
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tang BP, 2011, CHIN J MECH ENG-EN, V24, P891, DOI 10.3901/CJME.2011.05.891
   Vazquez S. G., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P599, DOI 10.1109/DICTA.2010.106
   Vijayakumar V, 2016, IEEE ENG MED BIO, P1320, DOI 10.1109/EMBC.2016.7590950
   Xiaofei He, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P96
   Xu XY, 2017, COMPUT METH PROG BIO, V141, P3, DOI 10.1016/j.cmpb.2017.01.007
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang CF, 2017, PR INT CONF DATA SC, P514, DOI 10.1109/DSAA.2017.53
   Zamperini A, 2012, COMP MED SY
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
NR 57
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12783
EP 12803
DI 10.1007/s11042-018-6474-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900007
DA 2024-07-18
ER

PT J
AU Spampinato, G
   Bruna, A
   Naccari, F
   Tomaselli, V
AF Spampinato, Giuseppe
   Bruna, Arcangelo
   Naccari, Filippo
   Tomaselli, Valeria
TI Adaptive low cost algorithm for video stabilization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video stabilization; Characteristics curves; IIR filters; FIR filters;
   Curves matching
AB Video stabilization is a technique used to compensate user hand shaking. It avoids grabbing the unintentional motion in a video sequence, which causes unpleasant effects for the final user. In this paper we present a very simple but effective low power consumption solution, suitable for cheap and small video cameras, running at 31 fps for a VGA sequence with a simple ARM926EJ-S. The proposed solution is robust to common difficult conditions, like noise perturbations, illumination changes, motion blurring and rolling shutter distortions.
C1 [Spampinato, Giuseppe; Bruna, Arcangelo; Naccari, Filippo; Tomaselli, Valeria] ST Microelect, Adv Syst Technol, Imaging Grp, Stradale Primosole 50, I-95100 Catania, Italy.
C3 STMicroelectronics
RP Spampinato, G (corresponding author), ST Microelect, Adv Syst Technol, Imaging Grp, Stradale Primosole 50, I-95100 Catania, Italy.
EM giuseppe.spampinato@st.com; arcangelo.bruna@st.com;
   filippo.naccari@st.com; valeria.tomaselli@st.com
RI Tomaselli, Valeria/JXX-3008-2024
OI Tomaselli, Valeria/0009-0003-4234-9454; Spampinato,
   Giuseppe/0000-0001-7037-5092
CR Adams A, 2008, COMPUT GRAPH FORUM, V27, P597, DOI 10.1111/j.1467-8659.2008.01157.x
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Bhujbal D, 2016, INT J ADV RES SCI EN, V3
   Bosco A, 2008, IEEE T CONSUM ELECTR, V54, P220, DOI 10.1109/TCE.2008.4560078
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldstein A., 2012, ACM T GRAPH, V32, P5
   Kim MK, 1997, IEEE T CONSUM ELECTR, V43, P1010, DOI 10.1109/30.642366
   Koo Y, 1999, IEEE T CONSUM ELECTR, V45, P118, DOI 10.1109/30.754426
   Kovacevic VB, 2016, J SIGNAL PROCESS SYS, V84, P283, DOI 10.1007/s11265-015-1063-8
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Litwin L, 2000, IEEE POTENTIALS, V19, P28, DOI 10.1109/45.877863
   Liu SC, 2014, PROC CVPR IEEE, P4209, DOI 10.1109/CVPR.2014.536
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Rawat P., 2011, INT J SIGNAL IMAGE P, V2, P159, DOI DOI 10.5121/sipij.2011.2213
   Salunkhe A, 2015, INT J ADV RES ELECT, V4
   Spampinato G., 2016, IEEE ICCE
   Wang YiYan Wang YiYan, 2013, Chinese Journal of Hygienic Insecticides & Equipments, V19, P8
NR 17
TC 2
Z9 2
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13787
EP 13804
DI 10.1007/s11042-018-6571-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900053
DA 2024-07-18
ER

PT J
AU Wang, YL
   Zhao, Y
AF Wang, Yalin
   Zhao, Yue
TI Paracatadioptric camera calibration based on the projecting relationship
   of the relative position between two spheres
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine vision; Calibration; Paracatadioptric camera; Imaged circular
   points; Vanishing point
ID IMAGES
AB We discuss how the projecting relationship of the relative position between two spheres in space can be used to calibrate paracatadioptric cameras. The projections of two spheres under a paracatadioptric camera are classified into three cases: Intersection, tangency, and separation. Methods for obtaining the principal point are proposed for each case. When the principal point is known, an analysis of the geometric relationship of the two spheres on the unit viewing sphere model shows that their tangent lines at the antipodal points are parallel. Based on this geometric relationship, the vanishing line of the plane containing the projection circle can be determined to yield the imaged circular points and obtain the remaining intrinsic camera parameters. When the principal point is unknown, the intersection points of two groups of parallel projection circles of the two spheres on the unit viewing sphere model combine with their corresponding antipodal points to form a rectangle; hence, the vanishing point in the orthogonal directions can be determined. Finally, the intrinsic camera parameters can be obtained by applying the constraints of the vanishing points in orthogonal directions to the absolute conic. Simulation results and real image data demonstrate the effectiveness of our methods.
C1 [Wang, Yalin; Zhao, Yue] Yunnan Univ, Inst Math & Stat, Kunming 650091, Yunnan, Peoples R China.
   [Wang, Yalin] Xian Res Inst High Technol, Math & OR Sect, Hongqing Town 710025, Shanxi, Peoples R China.
C3 Yunnan University; Rocket Force University of Engineering
RP Zhao, Y (corresponding author), Yunnan Univ, Inst Math & Stat, Kunming 650091, Yunnan, Peoples R China.
EM zhao6685@yeah.net
OI Yue, Zhao/0000-0002-4896-2247
FU National Natural Science Foundation of China [61663048, 11361074]
FX This work was supported in part by a grant from the National Natural
   Science Foundation of China (No. 61663048 and No. 11361074).
CR Agrawal M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P782
   [Anonymous], 2004, Technical Report
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163
   Daucher N., 1994, P ECCV, P447
   Deng XM, 2011, IEEE IMAGE PROC, P637, DOI 10.1109/ICIP.2011.6116632
   Duan HX, 2012, PATTERN RECOGN LETT, V33, P677, DOI 10.1016/j.patrec.2011.12.012
   Evelyn J, 1974, 7 CIRCLES THEOREM OT
   Gasparini S, 2009, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2009.5459336
   Ge DY, 2016, MULTIMED TOOLS APPL, V75, P15635, DOI 10.1007/s11042-015-2845-5
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Jeng SW, 2008, IMAGE VISION COMPUT, V26, P690, DOI 10.1016/j.imavis.2007.08.005
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Li YZ, 2017, APPL OPTICS, V56, P2230, DOI 10.1364/AO.56.002230
   Lu Y, 2010, COMPUT VIS IMAGE UND, V114, P8, DOI 10.1016/j.cviu.2009.09.001
   Nalwa V. S., 1996, TECHNICAL REPORT
   Nene SA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1087, DOI 10.1109/ICCV.1998.710852
   PENNA MA, 1991, IEEE T PATTERN ANAL, V13, P1240, DOI 10.1109/34.107007
   Puig L, 2011, INT J COMPUT VISION, V93, P101, DOI 10.1007/s11263-010-0411-1
   Schnieders D, 2013, COMPUT VIS IMAGE UND, V117, P1536, DOI 10.1016/j.cviu.2013.06.004
   Su LJ, 2016, OPT LASER ENG, V82, P22, DOI 10.1016/j.optlaseng.2016.01.018
   Sun JH, 2015, OPT LASER TECHNOL, V65, P83, DOI 10.1016/j.optlastec.2014.07.009
   Teramoto H., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P499
   WONG KY, 2016, TIP, V20, P305, DOI DOI 10.1109/TIP.2010.2063035
   Wu FC, 2008, PATTERN RECOGN, V41, P3166, DOI 10.1016/j.patcog.2008.03.010
   Wu YH, 2004, LECT NOTES COMPUT SC, V3021, P190
   Ying X., 2005, 6 WORKSH OMN VIS CAM, P28
   Ying XH, 2004, IEEE T PATTERN ANAL, V26, P1260, DOI 10.1109/TPAMI.2004.79
   Ying XH, 2005, IEEE I CONF COMP VIS, P596
   Ying XH, 2008, INT J COMPUT VISION, V78, P89, DOI 10.1007/s11263-007-0082-8
   Zhang F, 2011, MULTIMED TOOLS APPL, V52, P77, DOI 10.1007/s11042-009-0453-y
   Zhang H, 2007, IEEE T PATTERN ANAL, V29, P499, DOI 10.1109/TPAMI.2007.45
   Zhao Y, 2016, MULTIMED TOOLS APPL, V75, P7981, DOI 10.1007/s11042-015-2716-0
   Zhao Y, 2015, J OPT SOC AM A, V32, P2201, DOI 10.1364/JOSAA.32.002201
NR 36
TC 5
Z9 5
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12223
EP 12249
DI 10.1007/s11042-018-6763-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900052
DA 2024-07-18
ER

PT J
AU Yu, HP
   He, FZ
   Pan, YT
AF Yu, Haiping
   He, Fazhi
   Pan, Yiteng
TI A novel segmentation model for medical images with intensity
   inhomogeneity based on adaptive perturbation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intensity inhomogeneity; Adaptive perturbation; Medical image
   segmentation; Computer vision
ID LEVEL SET METHOD; ACTIVE CONTOUR MODEL; MEANS ALGORITHM; ROBUST;
   OPTIMIZATION; COMPUTE
AB In medical field, it remains challenging to accurately segment medical images due to low contrast, complex noises and intensity inhomogeneity. To overcome these obstacles, this paper provides a novel edge-based active contour model (ACM) for medical image segmentation. Specifically, an accurate regularization approach is presented to maintain the level set function with a signed distance property, which guarantees the stability of the evolution curve and the accuracy of the numerical computation. More significantly, an adaptive perturbation is integrated into the framework of the edge-based ACM. The perturbation technique can balance the stability of curve evolution and the accuracy of segmentation, which is key for segmenting medical images with intensity inhomogeneity. A number of experiments on both artificial and real medical images demonstrate that the proposed segmentation model outperforms state-of-the-art methods in terms of robustness to noise and segmentation accuracy.
C1 [Yu, Haiping; Pan, Yiteng] Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [He, Fazhi] Wuhan Univ, Sch Comp Sci, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
EM seaping@whu.edu.cn; fzhe@whu.edu.cn; panyiteng@whu.edu.cn
RI Pan, Yi/AAJ-2341-2021; He, Fazhi/Q-3691-2018
OI , Haiping/0000-0001-9643-9568
FU National Natural Science Foundation of China [61472289, 61502356];
   National Key Research and Development Project [2016YFC0106305]
FX We would like to thank all the anonymous reviewers for their valuable
   comments. This work is supported by the National Natural Science
   Foundation of China(Grant No. 61472289 and No. 61502356) and the
   National Key Research and Development Project(Grant No. 2016YFC0106305).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Ali H, 2016, PATTERN RECOGN, V51, P27, DOI 10.1016/j.patcog.2015.08.022
   Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Becker M, 2016, INT J COMPUT ASS RAD, V11, P695, DOI 10.1007/s11548-015-1241-y
   Boutiche Y, 2017, IET IMAGE PROCESS, V11, P200, DOI 10.1049/iet-ipr.2016.0648
   Cencini M, 2003, LECT NOTES PHYS, V636, P187
   Chae SH, 2016, MULTIMED TOOLS APPL, V75, P15347, DOI 10.1007/s11042-014-2201-1
   Chen JT, 2016, SPEECH COMMUN, V78, P1, DOI 10.1016/j.specom.2015.12.006
   Chen XJ, 2012, IEEE T IMAGE PROCESS, V21, P2035, DOI 10.1109/TIP.2012.2186306
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Chitsaz M, 2011, J COMPUT SCI TECH-CH, V26, P247, DOI 10.1007/s11390-011-9431-8
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Cunliang Liu, 2013, Journal of Software, V8, P2305, DOI 10.4304/jsw.8.9.2305-2312
   Dai LZ, 2015, PATTERN RECOGN, V48, P2513, DOI 10.1016/j.patcog.2015.03.001
   Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920
   Du Y, 2005, IEEE T MED IMAGING, V24, P969, DOI 10.1109/TMI.2005.850547
   Feng J, 2013, SIGNAL PROCESS, V93, P487, DOI 10.1016/j.sigpro.2012.08.024
   Ge Q, 2012, PATTERN RECOGN, V45, P1578, DOI 10.1016/j.patcog.2011.09.008
   GONG M, 1955, INFORMATION, V293, P351, DOI DOI 10.1016/J.INS.2014.09.023
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Grosgeorge D, 2011, INT J COMPUT ASS RAD, V6, P573, DOI 10.1007/s11548-010-0532-6
   Howard J, 2011, NAT REV MOL CELL BIO, V12, P392, DOI 10.1038/nrm3120
   Ivanovska T, 2016, COMPUT MED IMAG GRAP, V48, P9, DOI 10.1016/j.compmedimag.2015.11.005
   Ji SY, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/747549
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim JU, 2017, IEEE ENG MED BIO, P685, DOI 10.1109/EMBC.2017.8036917
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Liu YL, 2008, J COMPUT SCI TECH-CH, V23, P270, DOI 10.1007/s11390-008-9129-8
   Liu Y, 2012, INT C PATT RECOG, P898
   Loh P., 2011, ADV NEURAL INFORM PR, P2726
   Lu T, 2017, IEEE INT CON MULTI, P1362, DOI 10.1109/ICME.2017.8019298
   Luo YM, 2017, IEEE GEOSCI REMOTE S, V14, P2398, DOI 10.1109/LGRS.2017.2766204
   Min H, 2015, PATTERN RECOGN, V48, P1547, DOI 10.1016/j.patcog.2014.10.018
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni B, 2016, APPL MATH SER B, V31, P37, DOI 10.1007/s11766-016-3340-0
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Rad AE, 2017, MULTIMED TOOLS APPL, V76, P2185, DOI 10.1007/s11042-015-3196-y
   Ren ZM, 2015, SIGNAL PROCESS, V117, P138, DOI 10.1016/j.sigpro.2015.05.009
   ROBERTS JD, 1980, INT J CONTROL, V32, P677, DOI 10.1080/00207178008922881
   Ros G., 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, P3234, DOI DOI 10.1109/CVPR.2016.352
   Shang YF, 2011, IEEE T BIO-MED ENG, V58, P1023, DOI 10.1109/TBME.2010.2097596
   Shao L, 2017, INFORM SCIENCES, V385, P266, DOI 10.1016/j.ins.2017.01.013
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   VESE LA, 2012, VISION, V50, P271
   Wang B, 2014, IEEE T CYBERNETICS, V44, P418, DOI 10.1109/TCYB.2013.2256891
   Wang B, 2010, IEEE T SYST MAN CY B, V40, P857, DOI 10.1109/TSMCB.2009.2031090
   Wang H, 2014, INFORM SCIENCES, V263, P43, DOI 10.1016/j.ins.2013.10.033
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3
   XU C, 1969, IEEE TRANS IMAGE PRO, V7, P359
   Xue DX, 2017, PROC SPIE, V10420, DOI 10.1117/12.2282000
   Yan C, 2017, IEEE SIGNAL PROCESS, V21, P573
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan PK, 2013, COMPUT VIS IMAGE UND, V117, P1017, DOI 10.1016/j.cviu.2013.03.006
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang L, 2005, IEEE T INF TECHNOL B, V9, P475, DOI 10.1109/TITB.2005.847515
   Yang X, 2014, IEEE T IMAGE PROCESS, V23, P2854, DOI 10.1109/TIP.2014.2321506
   Yang XJ, 2011, J COMPUT SCI TECH-CH, V26, P344, DOI 10.1007/s02011-011-1137-8
   Yang ZY, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P277, DOI 10.1109/CLOUD.2018.00042
   Yu HP, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0100
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang N, 2011, COMPUT VIS IMAGE UND, V115, P256, DOI 10.1016/j.cviu.2010.09.007
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhao YT, 2015, IEEE T MED IMAGING, V34, P1797, DOI 10.1109/TMI.2015.2409024
   Zhou SP, 2017, NEUROCOMPUTING, V234, P216, DOI 10.1016/j.neucom.2017.01.013
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou YF, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0102
NR 88
TC 91
Z9 92
U1 2
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11779
EP 11798
DI 10.1007/s11042-018-6735-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900031
DA 2024-07-18
ER

PT J
AU Chen, GR
AF Chen, Guorui
TI Channel estimation with Bayesian framework based on compressed sensing
   algorithm in multimedia transmission system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia transmission system; Channel estimation; Compressed sensing;
   Matching pursuit; Bayesian framework; Support set
ID RECONSTRUCTION; INFORMATION
AB With the emergence of Wireless multimedia transmission system, the distribution of multimedia contents has now become a reality. To solve the problem of stability in the process of transmission, this paper proposes an improved channel estimation with Bayesian framework based on compressed sensing algorithm in multimedia transmission system. The algorithm uses the sparse characteristics of the channel and can reduce the pilot sequence length under the same conditions. Due to the high complexity of the support agnostic Bayesian matching pursuit algorithm, our algorithm improves the support set, which proposed Expectation Prune Matching Pursuit algorithm in the paper. At each sparsity level of the channel, an expanded support set is given by adding some positions corresponding to the atoms that have a larger inner product value with the current residual signal. Then the best support set is obtained by removing the wrong positions and adopting the idea of Bayesian estimation algorithm in the expanded support set. The estimated channel and the relative probability of the best support set at each sparse level are calculated. Finally, the expectation of the channel is calculated and regarded as the estimation of the channel. Compared with comparison algorithm in the error and bit error rate under different SNR conditions, our proposed algorithm can reduce the computational complexity while maintaining the estimation accuracy.
C1 [Chen, Guorui] Yangtze Univ, Coll Comp Sci, 1 Nanhu Rd, Jingzhou 434000, Hubei, Peoples R China.
C3 Yangtze University
RP Chen, GR (corresponding author), Yangtze Univ, Coll Comp Sci, 1 Nanhu Rd, Jingzhou 434000, Hubei, Peoples R China.
EM guoruichenl@163.com
CR Arjav B, 2018, J COMMUN INFO NETW, V3, P84, DOI [10.1007/s41650-018-0011-8, DOI 10.1007/S41650-018-0011-8]
   Byun SH, 2013, IEEE J OCEANIC ENG, V38, P718, DOI 10.1109/JOE.2013.2258222
   Chen Z, 2016, MULTIMED TOOLS APPL, V75, P2565, DOI 10.1007/s11042-015-2578-5
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Gao Z, 2016, IEEE T COMMUN, V64, P601, DOI 10.1109/TCOMM.2015.2508809
   Gui G, 2015, IET COMMUN, V9, P2168, DOI 10.1049/iet-com.2014.0979
   Hao Huang, 2016, 2016 IEEE International Workshop on Electromagnetics (iWEM): Applications and Student Innovation Competition, P1, DOI 10.1109/iWEM.2016.7504919
   Jakubczak S., 2011, PROC MOBICOM, P289
   Katabi D., 2009, MITCSAILTR2009005
   Kivinien, 2002, P 2002 IEEE ANT PROP, P206
   Lv ZG, 2016, IEEE COMMUN LETT, V20, P1461, DOI 10.1109/LCOMM.2016.2557788
   Masood M, 2013, IEEE T SIGNAL PROCES, V61, P5298, DOI 10.1109/TSP.2013.2278814
   Méndez-Rial R, 2015, 2015 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA), P90, DOI 10.1109/ITA.2015.7308971
   Quan Lei, 2017, Journal of Xidian University, V44, P106, DOI 10.3969/j.issn.1001-2400.2017.01.019
   Rusu C, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417853
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shi K, 2010, SIGNAL PROCESS, V90, P3289, DOI 10.1016/j.sigpro.2010.05.015
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Song XD, 2015, IEEE T CIRC SYST VID, V25, P1926, DOI 10.1109/TCSVT.2015.2416562
   Stenumgaard P, 2013, IEEE COMMUN MAG, V51, P186, DOI 10.1109/MCOM.2013.6515064
   SU G, 2012, TSP, V60, P2223, DOI DOI 10.1109/TSP.2012.2184537
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Takahashi N, 2009, IEEE T SIGNAL PROCES, V57, P3361, DOI 10.1109/TSP.2009.2020747
   Tang ZH, 2017, J PHYS CONF SER, V787, DOI 10.1088/1742-6596/787/1/012008
   Wen YG, 2014, IEEE T MULTIMEDIA, V16, P885, DOI 10.1109/TMM.2014.2315596
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhang YX, 2008, IEEE T MULTIMEDIA, V10, P1648, DOI 10.1109/TMM.2008.2007324
NR 27
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8813
EP 8825
DI 10.1007/s11042-018-6443-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800050
DA 2024-07-18
ER

PT J
AU Feng, L
   Gong, DF
   Liu, FL
   Lu, HY
AF Feng, Liu
   Gong, Daofu
   Liu, Fenlin
   Lu, Haoyu
TI Affine invariant image watermarking scheme based on ASIFT and Delaunay
   tessellation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affine transformation; ASIFT feature; Robust watermarking
ID RESISTANT; DOMAIN
AB Watermarking algorithms that resist geometric combination attacks is currently a trend of research in this field. This paper proposed a geometrically invariant watermarking scheme based on the feature points of resistance to affine transformation. The scheme used Affine Scale Invariant Feature Transform (ASIFT) to detect the feature points of the carrier image and filtrated the established feature points group depending on anti-affine properties. The obtained feature points set obtained better robustness against multiple attacks. As for robustness, we utilized the feature points set to construct the Delaunay tessellation and embedded the watermark information in the histogram of each triangle. Because of the stability of Delaunay tessellation and the basic characteristics of affine transformation, the geometric robustness of the proposed scheme achieved a good effect as was verified in experiments.
C1 [Feng, Liu; Gong, Daofu; Liu, Fenlin] Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
   [Lu, Haoyu] Zhengzhou Sci & Technol Inst, Informat Secur, Zhengzhou 450001, Henan, Peoples R China.
   [Feng, Liu] Zhengzhou Univ Light Ind, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University; Zhengzhou University of Light Industry
RP Gong, DF (corresponding author), Zhengzhou Sci & Technol Inst, Zhengzhou 450001, Henan, Peoples R China.
EM gongdf@aliyun.com
RI Lu, Hao/GQH-3203-2022; lu, haojie/HOA-7748-2023; lu, hao/HZH-4458-2023
FU National Nature Science Foundation of China [U1636219, U1736119,
   61572052, 61772549, U1736214, 61401512, 61601517]; National Key R&D
   Program of China [2016YFB0801303, 2016QY 01W0105]; Plan for Scientific
   Innovation Talent of Henan Province [2018JR0018]; Key Technologies R&D
   Program of Henan Province [162102210032]
FX This work was supported in part by the National Nature Science
   Foundation of China (Grant No. U1636219, U1736119, 61572052, 61772549,
   U1736214, 61401512, and 61601517), the National Key R&D Program of China
   (Grant No. 2016YFB0801303 and 2016QY 01W0105), Plan for Scientific
   Innovation Talent of Henan Province (Grant No. 2018JR0018) and the Key
   Technologies R&D Program of Henan Province (Grant No. 162102210032)).
CR [Anonymous], 2003, INT WORKSH DIG WAT
   Jia XL, 2016, 2016 IEEE INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P1120, DOI 10.1109/ITNEC.2016.7560539
   Kuo LH, 2013, CMC-COMPUT MATER CON, V33, P213
   Liu CS, 2008, CMC-COMPUT MATER CON, V8, P53
   Lu W, 2010, COMPUT ELECTR ENG, V36, P2, DOI 10.1016/j.compeleceng.2009.04.002
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Lyu WL, 2014, KSII T INTERNET INF, V8, P3591, DOI 10.3837/tiis.2014.10.018
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Oujun Lou, 2015, Advanced Materials Research, V1061-1062, P1118, DOI 10.4028/www.scientific.net/AMR.1061-1062.1118
   Pun CM, 2015, MULTIMED TOOLS APPL, V74, P7821, DOI 10.1007/s11042-014-2025-z
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Sun JG, 2010, 2010 INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING AND COMMUNICATION AND 2010 ASIA-PACIFIC CONFERENCE ON INFORMATION TECHNOLOGY AND OCEAN ENGINEERING: CICC-ITOE 2010, PROCEEDINGS, P98, DOI 10.1109/CICC-ITOE.2010.33
   Thanh TM, 2017, MULTIMED TOOLS APPL, V77, P1
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Yang CY, 2017, MULTIMED TOOLS APPL, V76, P1455, DOI 10.1007/s11042-015-3065-8
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Ye X, 2015, INT C IM SIGN PROC, P323
   Yu G., 2011, IMAGE PROCESSING LIN, V1, P2105
   Yuan WG, 2007, INT C SIGNAL PROCESS, V4, P2632
   Zhang XJ, 2013, FRONT COMPUT SCI-CHI, V7, P145, DOI 10.1007/s11704-013-2174-7
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhao Y, 2012, SCI CHINA INFORM SCI, V55, P650, DOI 10.1007/s11432-011-4470-x
   Zheng D, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2098
NR 28
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8133
EP 8149
DI 10.1007/s11042-018-6717-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800014
DA 2024-07-18
ER

PT J
AU Hussin, WMSB
   Noordin, MNMJ
   Isa, NAM
AF Hussin, Wan Muhammad Syahrir Bin Wan
   Noordin, Mohd Naim Mohd Jain
   Isa, Nor Ashidi Mat
TI Nonlinear local-pixel-shifting color constancy algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color correction; Color constancy; Nonlinear pixel shifting; Contrast
   Enhancement; Adaptive limit
ID IMAGE QUALITY ENHANCEMENT; UNDERWATER IMAGE; MODEL
AB Most color constancy algorithms implement a color correction process that performs globally for the entire input pixel image. This process leads to a saturation problem and overcorrected images, especially in overexposed regions, thereby resulting in contrast inconsistency and incorrect true-color image objects. Each pixel in an input image should have a different correction range value. Pixels with high probability to be saturated or overcorrected should not be treated similarly as pixels with low probability. Thus, this study proposes a new color correction algorithm that aims to reduce the effects of the saturation phenomenon and overcorrected color images while enhancing the image contrast. To achieve this objective, the proposed algorithm consists of two main processes, namely, color correction and contrast enhancement. A shifting process is nonlinearly applied to each pixel in a 2D two-channel CIELAB color space. Each pixel has a different corrected rate depending on the adaptive limit value and the reference point. Subsequently, the global and local contrast corrections are executed on the L channel to enhance the image contrast. Qualitative and quantitative results on 653 outdoor; 818 indoor; and 1394 underwater images show that the proposed algorithm outperforms several state-of-the-art algorithms in producing enhanced color constancy and contrast. The proposed algorithm also reduces noise effects and improves the details of an image without creating unnatural and inaccurate color constancy.
C1 [Hussin, Wan Muhammad Syahrir Bin Wan; Noordin, Mohd Naim Mohd Jain; Isa, Nor Ashidi Mat] Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
   [Hussin, Wan Muhammad Syahrir Bin Wan] Univ Malaysia Pahang, Fac Comp Syst & Software Engn, Kuantan 26300, Pahang, Malaysia.
C3 Universiti Sains Malaysia; Universiti Malaysia Pahang Al-Sultan Abdullah
   (UMPSA)
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM wmsyahrir@ump.edu.my; naim.jain@gmail.com; ashidi@usm.my
RI Mat Isa, Nor Ashidi/I-7826-2017
OI Mat Isa, Nor Ashidi/0000-0002-2675-4914
FU Ministry of Higher Education of Malaysia
FX The authors are grateful to the anonymous reviewers for their valuable
   comments and suggestions toward the improvement of this paper. The
   authors would also like to thank the Ministry of Higher Education of
   Malaysia for providing financial support under the Fundamental Research
   Grant Scheme for the study titled "Formulation of a Robust Framework of
   Image Enhancement for Non-uniform Illumination and Low-Contrast Images."
CR Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Agarwal V, 2007, NEURAL NETWORKS, V20, P559, DOI 10.1016/j.neunet.2007.02.004
   [Anonymous], 2017, ARXIV
   [Anonymous], TIP
   [Anonymous], 2014, INT J COMPUT APPL, DOI [DOI 10.5120/17735-8849, 10.5120/17735-8849]
   [Anonymous], TIP
   [Anonymous], 2009 3 INT S INT INF
   [Anonymous], INT J ENG ED
   [Anonymous], 2005, PROC INT C IMAGE PRO, DOI DOI 10.1109/ICIP.2005.1530157
   [Anonymous], 2014, INT J ADV COMPUT SCI
   [Anonymous], 2013, Int. J. Comput. Appl, DOI DOI 10.5120/13766-1620
   [Anonymous], TIP
   Bai XD, 2013, COMPUT ELECTRON AGR, V99, P21, DOI 10.1016/j.compag.2013.08.022
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049
   Bianco Simone, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P81, DOI 10.1109/CVPRW.2015.7301275
   Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007
   Bianco S, 2008, LECT NOTES COMPUT SC, V5188, P104, DOI 10.1007/978-3-540-85891-1_14
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374
   Cepeda-Negrete J, 2015, APPL SOFT COMPUT, V28, P1, DOI 10.1016/j.asoc.2014.11.034
   Faghih MM, 2014, APPL SOFT COMPUT, V17, P52, DOI 10.1016/j.asoc.2013.11.016
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Funt B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P445, DOI 10.1007/BFb0055683
   Gasparini F, 2004, PATTERN RECOGN, V37, P1201, DOI 10.1016/j.patcog.2003.12.007
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Ghani ASA, 2014, SPRINGERPLUS, V3, DOI 10.1186/2193-1801-3-757
   Ghani ASA, 2015, APPL SOFT COMPUT, V27, P219, DOI 10.1016/j.asoc.2014.11.020
   Gijsenij A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P171, DOI 10.1109/ICIAPW.2007.16
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   Hitam Muhammad Suzuri, 2013, 2013 INT C COMPUTER
   Hou LK, 2013, SIAM J IMAGING SCI, V6, P2213, DOI 10.1137/120888302
   Hunt R. G. W., 2004, REPROD COLOUR, DOI [10. 1002/0470024275, DOI 10.1002/0470024275, 10.1002/0470024275]
   Kwok NM, 2013, ENG APPL ARTIF INTEL, V26, P2356, DOI 10.1016/j.engappai.2013.07.023
   Kwok N. M., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P994, DOI 10.1109/CISP.2011.6100336
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Manikandan S, 2011, J PHARMACOL PHARMACO, V2, P214, DOI 10.4103/0976-500X.83300
   McGreevy KM, 2009, CLIN CHEM, V55, P165, DOI 10.1373/clinchem.2008.106260
   Montenegro J, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P313, DOI 10.1109/ICEEE.2013.6676048
   Naim MJNM, 2015, 2015 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA), P213, DOI 10.1109/ISITIA.2015.7219981
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Noordin MNMJ, 2017, MULTIMED TOOLS APPL, V76, P10279, DOI 10.1007/s11042-016-3620-y
   Recky Michal, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P356, DOI 10.1109/ICPR.2010.96
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Stanikunas R, 2004, NEURAL NETWORKS, V17, P327, DOI 10.1016/j.neunet.2003.12.002
   Syahrir WM, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P276, DOI 10.1109/ICCSIT.2009.5234497
   Wirth Michael, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P79, DOI 10.1109/CRV.2010.17
   Wu J, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATIONS, VOLS 1-4, CONFERENCE PROCEEDINGS, P1817
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 56
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10401
EP 10448
DI 10.1007/s11042-018-6566-4
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400040
DA 2024-07-18
ER

PT J
AU Shi, MH
   Zhao, XQ
   Qiao, DD
   Xu, BG
   Li, CM
AF Shi, Meihong
   Zhao, Xueqing
   Qiao, Dongdong
   Xu, Bugao
   Li, Chunmei
TI Conformal monogenic phase congruency model-based edge detection in color
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Phase congruency; Conformal monogenic signal; Poisson kernel; Edge
   detection
AB To enhance the precision of edge localization and noise suppression in a color image, we propose a conformal monogenic phase congruency model-based (CMPCM) edge detection algorithm that has a good analytical capability in a spatial domain for local structural features to exploit points of the maximum phase congruency in two-dimensional images, and employ Pratt's Figure of Merit (PFOM) evaluation metrics to measure the performance of its edge detection. Comprehensive experiments were conducted on synthetic color images and natural color images from BSDS500 and LPAICI standard image datasets. The experimental results demonstrated that the proposed CMPCM algorithm outperforms other algorithms, such as viz. Canny, LOG, VPMM, PC and MPC, and has smaller computational time consumption as well.
C1 [Shi, Meihong; Zhao, Xueqing] Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
   [Qiao, Dongdong; Xu, Bugao; Li, Chunmei] Xian Polytech Univ, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
   [Xu, Bugao] Univ North Texas, Dept Comp Sci & Engn, 3940 N Elm,Room F201, Denton, TX 76207 USA.
C3 Xi'an Polytechnic University; Xi'an Polytechnic University; University
   of North Texas System; University of North Texas Denton
RP Shi, MH (corresponding author), Xian Polytech Univ, Sch Comp Sci, Shaanxi Key Lab Clothing Intelligence, 19 Jinhua South Rd, Xian 710048, Shaanxi, Peoples R China.
EM meihong_shi@163.com
RI L, Chun/HKW-1738-2023
FU Special Scientific Research Project of Education Department of Shaanxi
   Provincial Government [16JK1328]; Natural Science Research Plan in
   Shaanxi Province of China [2017JQ6071]
FX This work was supported by the Special Scientific Research Project of
   Education Department of Shaanxi Provincial Government (No. 16JK1328),
   and the Natural Science Research Plan in Shaanxi Province of China(Youth
   Programs, No. 2017JQ6071).
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Chen X, 2010, INT CONF SIGN PROCES, P793, DOI 10.1109/ICOSP.2010.5655926
   Delanghe R., 2001, Computational Methods and Function Theory, V1, P107
   Felsberg M, 2004, J MATH IMAGING VIS, V21, P5, DOI 10.1023/B:JMIV.0000026554.79537.35
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844
   Fleischmann O, 2011, J MATH IMAGING VIS, V40, P305, DOI 10.1007/s10851-011-0263-5
   Geetha MK, 2009, INT J COMPUT INT SYS, V2, P39, DOI 10.2991/jnmp.2009.2.1.5
   [贾迪 Jia Di], 2014, [电子学报, Acta Electronica Sinica], V42, P257
   Kovesi P., 1999, Fifth International/National Biennial Conference on Digital Image Computing, Techniques, and Applications. DICTA99, P212
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Lei T., 2013, ACTA ELECTRON SIN, V41, P1903
   Li Ming, 2015, Geomatics and Information Science of Wuhan University, V40, P64, DOI 10.13203/j.whugis20140066
   Lijuan W, 2014, 26 CHIN CONTR DEC C, P2033
   Liu DL, 2014, SIGNAL PROCESS-IMAGE, V29, P844, DOI 10.1016/j.image.2014.06.007
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   NEVATIA R, 1977, IEEE T SYST MAN CYB, V7, P820
   Novak CL., 1987, P DARPA IMAGE UNDERS, V1, P35
   Shi M., 2008, Basic Sci. J. Text. Univ, V21, P351, DOI [10.3969/j.issn.1006-8341.2008.03.023, DOI 10.3969/J.ISSN.1006-8341.2008.03.023]
   Shojaeilangari S, 2014, PATTERN RECOGN LETT, V49, P55, DOI 10.1016/j.patrec.2014.06.009
   Tang H, 2013, J IMAGE GRAPHICS
   Wang K, 2013, J INFRARED MILLIM W, V32, P73, DOI 10.3724/SP.J.1010.2013.00073
   Wang L, 2012, PROCEEDINGS OF 2012 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2012), P2211, DOI 10.1109/ICCSNT.2012.6526357
   Wietzke L, 2008, JOINT PATT REC S, P527
   Wietzke L, 2008, INT WORKSH ROB VIS, P454
   [肖志涛 Xiao Zhitao], 2004, [天津大学学报. 自然科学与工程技术版, Journal of Tianjin University], V37, P695
   Xu H, 2012, PROCEEDINGS OF 2012 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2012), P2112, DOI 10.1109/ICCSNT.2012.6526335
   Zhang L, 2012, PATTERN RECOGN, V45, P2522, DOI 10.1016/j.patcog.2012.01.017
NR 30
TC 10
Z9 11
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10701
EP 10716
DI 10.1007/s11042-018-6617-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400052
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Xu, SJ
   Yao, H
   Qin, C
   Zhang, XQ
AF Tang, Zhenjun
   Xu, Shijie
   Yao, Heng
   Qin, Chuan
   Zhang, Xianquan
TI Reversible data hiding with differential compression in encrypted image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Image encryption; Differential compression;
   Huffman coding
ID RING PARTITION
AB This paper proposes a novel reversible data hiding (RDH) algorithm with differential compression (DC) in encrypted image, which has high embedding capacity. The key contributions are two sides. (1) An efficient block-based encryption scheme is developed for encrypting image. It can transfer spatial correlation between neighboring pixels of plaintext image into encrypted image. (2) The DC scheme is proposed to conduct compression of encrypted image. It can efficiently compress encrypted image by exploiting pixel correlation and vacate a large room for data embedding. Many experiments are conducted to evaluate the performance of our RDH algorithm. Comparisons illustrate that our RDH algorithm outperforms some state-of-the-art algorithms in embedding capacity and computational time.
C1 [Tang, Zhenjun; Xu, Shijie; Zhang, Xianquan] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Tang, Zhenjun; Xu, Shijie; Zhang, Xianquan] Guangxi Normal Univ, Dept Comp Sci, Guilin 541004, Peoples R China.
   [Tang, Zhenjun; Zhang, Xianquan] Guangxi Normal Univ, Guangxi Collaborat Innovat Ctr Multisource Inform, Guilin 541004, Peoples R China.
   [Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Minist Educ, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Yao, Heng; Qin, Chuan] Univ Shanghai Sci & Technol, Minist Educ, Engn Res Ctr Opt Instrument & Syst, Shanghai 200093, Peoples R China.
C3 Guangxi Normal University; Guangxi Normal University; Guangxi Normal
   University; University of Shanghai for Science & Technology; University
   of Shanghai for Science & Technology
RP Tang, ZJ (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Tang, ZJ (corresponding author), Guangxi Normal Univ, Dept Comp Sci, Guilin 541004, Peoples R China.; Tang, ZJ (corresponding author), Guangxi Normal Univ, Guangxi Collaborat Innovat Ctr Multisource Inform, Guilin 541004, Peoples R China.
EM tangzj230@163.com
RI xu, shijie/IVH-2089-2023; Yao, Heng/J-9457-2019; Qin, Chuan/C-1106-2017
OI Yao, Heng/0000-0002-3784-4157; Qin, Chuan/0000-0002-0370-4623; Tang,
   Zhenjun/0000-0003-3664-1363; Xu, Shi-Jie/0000-0002-7671-2368
FU National Natural Science Foundation of China [61562007, 61762017,
   61702332, 61672354]; Guangxi "Bagui Scholar" Teams for Innovation and
   Research; Guangxi Natural Science Foundation [2017GXNSFAA198222,
   2015GXNSFDA139040]; Project of Guangxi Science and Technology
   [GuiKeAD17195062]; Guangxi Key Lab of Multi-source Information Mining
   Security [16-A-02-02, 15-A-02-02]; Innovation Project of Guangxi
   Graduate Education [XYCSZ 2018076]
FX This work is partially supported by the National Natural Science
   Foundation of China (61562007, 61762017, 61702332, 61672354), Guangxi
   "Bagui Scholar" Teams for Innovation and Research, the Guangxi Natural
   Science Foundation (2017GXNSFAA198222, 2015GXNSFDA139040), the Project
   of Guangxi Science and Technology (GuiKeAD17195062), the Project of the
   Guangxi Key Lab of Multi-source Information Mining & Security
   (16-A-02-02, 15-A-02-02), and the Innovation Project of Guangxi Graduate
   Education (XYCSZ 2018076). The authors would like to thank the anonymous
   referees for their valuable comments and suggestions.
CR Agrawal S, 2017, OPTIK, V130, P922, DOI 10.1016/j.ijleo.2016.11.059
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Guorong Xuan, 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P264
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Huang JW, 1998, ELECTRON LETT, V34, P748, DOI 10.1049/el:19980545
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Ni ZC, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P912
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qin C, 2018, SIGNAL PROCESS-IMAGE, V60, P160, DOI 10.1016/j.image.2017.10.003
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Rivest RonaldL., 1992, The RC4 encryption algorithm
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Skretting K, 1999, P NORSIG 1999 C, P9
   Tang ZJ, 2018, OPTIK, V157, P750, DOI 10.1016/j.ijleo.2017.11.154
   Tang ZJ, 2017, MULTIMED TOOLS APPL, V76, P8257, DOI 10.1007/s11042-016-3476-1
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian J., 2002, Proceedings of workshop on multimedia and security p, P19
   van Leest A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P731
   Weng SW, 2016, J VIS COMMUN IMAGE R, V41, P185, DOI 10.1016/j.jvcir.2016.09.016
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang X, 2012, LECT NOTES COMPUT SC, V7669, P247, DOI [10.1007/978-3-642-35236-2_25, DOI 10.1007/978-3-642-35236-2_25]
   Zhang XQ, 2017, MULTIMED TOOLS APPL, V76, P9195, DOI 10.1007/s11042-016-3521-0
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zheng SL, 2016, MULTIMED TOOLS APPL, V75, P13765, DOI 10.1007/s11042-015-2920-y
NR 45
TC 41
Z9 44
U1 3
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9691
EP 9715
DI 10.1007/s11042-018-6567-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400009
DA 2024-07-18
ER

PT J
AU Zeng, XM
   Feng, GR
   Zhang, XP
AF Zeng, Ximei
   Feng, Guorui
   Zhang, Xinpeng
TI Detection of double JPEG compression using modified DenseNet model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Double JPEG compression; DenseNet; Filtering layer; F-LDA; Residual
   noises
AB With the increasing tendency of the tempering of JPEG images, development of methods detecting image forgery is of great importance. In many cases, JPEG image forgery is usually accompanied with double JPEG compression, leaving no visual traces. In this paper, a modified version of DenseNet (densely connected convolutional networks) is proposed to accomplish the detection task of primary JPEG compression among double compressed images. A special filtering layer in the front of the network contains typically selected filtering kernels that can help the network following to discriminating the images more easily. As shown in the results, the network has achieved great improvement compared to the-state-of-the-art method especially on the classification accuracy among images with lower quality factors.
C1 [Zeng, Ximei; Feng, Guorui; Zhang, Xinpeng] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Zeng, Ximei; Feng, Guorui; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Feng, GR (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Feng, GR (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM fgr2082@aliyun.com
FU National Natural Science Foundation of China [U1536109, U1636206,
   61525203, 61373151, 61472235]
FX This work was supported by the National Natural Science Foundation of
   China under Grants (U1536109, U1636206, 61525203, 61373151, 61472235).
CR Amerini I., 2017, 2017 IEEE WORKSH INF, P1
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], THE 4TH ACM WORKSHOP
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE INT C AC
   [Anonymous], ARXIV180601571V1
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], PROC CVPR IEEE
   Chen C., 2008, IEEE INT C PATTERN R, P1
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Huang FJ, 2010, IEEE T INF FOREN SEC, V5, P848, DOI 10.1109/TIFS.2010.2072921
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang GL, 2017, IEEE ICC
   LeCun Y., 1990, NeurIPS, P396
   Li B., 2017, ARXIV
   Liu QZ, 2011, LECT NOTES COMPUT SC, V6676, P466, DOI 10.1007/978-3-642-21090-7_55
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Srivastava RK, 2015, ARXIV150500387
   Verma V, 2018, SIGNAL PROCESS-IMAGE, V67, P22, DOI 10.1016/j.image.2018.04.014
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Yao H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120313
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 27
TC 13
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8183
EP 8196
DI 10.1007/s11042-018-6737-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800017
DA 2024-07-18
ER

PT J
AU Avola, D
   Bernardi, M
   Foresti, GL
AF Avola, Danilo
   Bernardi, Marco
   Foresti, Gian Luca
TI Fusing depth and colour information for human action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Decision level fusion; Bag-of-visual-word;
   Naive bayes combination; Support vector machine; RGB-D
ID ACTION CLASSIFICATION; DISCRIMINANT-ANALYSIS; GESTURE RECOGNITION;
   FEATURES; LEVEL; VIDEO
AB In recent years, human action recognition systems have been increasingly developed to support a wide range of application areas, such as surveillance, behaviour analysis, security, and many others. In particular, data fusion approaches that use depth and colour information (i.e., RGB-D data) seem to be particularly promising for recognizing large classes of human actions with a high level of accuracy. Anyway, existing data fusion approaches are mainly based on feature fusion strategies, which tend to suffer of some limitations, including the difficult of combining different feature types and the management of missing information. To address the two problems just reported, we propose an RGB-D data based human action recognition system supported by a decision fusion strategy. The system, starting from the well-known Joint Directors of Laboratories (JDL) data fusion model, analyses human actions separately for each channel (i.e., depth and colour). The actions are modelled as a sum of visual words by using the traditional Bag-of-Visual-Words (BoVW) model. Subsequently, on each channel, these actions are classified by using a multi-class Support Vector Machine (SVM) classifier. Finally, the classification results are fused by a Naive Bayes Combination (NBC) method. The effectiveness of the proposed system has been proven on the basis of three public datasets: UTKinect-Action3D, CAD-60, and LIRIS Human Activities. Experimental results, compared with key works of the current state-of-the-art, have shown that what we propose can be considered a concrete contribute to the action recognition field.
C1 [Avola, Danilo; Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
   [Avola, Danilo; Bernardi, Marco] Sapienza Univ, Dept Comp, Rome, Italy.
C3 University of Udine; Sapienza University Rome
RP Avola, D (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.; Avola, D (corresponding author), Sapienza Univ, Dept Comp, Rome, Italy.
EM avola@di.uniroma1.it; bernardi@di.uniroma1.it; gianluca.foresti@uniud.it
OI Bernardi, Marco/0000-0001-5477-1423
FU MIUR under grant "Departments of Excellence 2018-2022" of the Department
   of Computer Science of Sapienza University
FX This work was supported in part by the MIUR under grant "Departments of
   Excellence 2018-2022" of the Department of Computer Science of Sapienza
   University.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], TPAMI
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], 2006, P 18 INT C NEURAL IN
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], TIP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACCESS
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Avola D, 2018, INTEL SYST REF LIBR, V145, P7, DOI 10.1007/978-3-319-73891-8_2
   Avola D, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P638, DOI 10.5220/0006722506380645
   Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   Avola D, 2013, LECT NOTES COMPUT SC, V8158, P465, DOI 10.1007/978-3-642-41190-8_50
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Bhavsar A., 2016, P IEEE C COMP VIS PA, P38
   Cámara-Chávez G, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P153, DOI 10.1109/ISM.2009.116
   Canal G, 2016, COMPUT VIS IMAGE UND, V149, P65, DOI 10.1016/j.cviu.2016.03.004
   Chathuramali KGM, 2012, INT CONF ADV ICT, P197, DOI 10.1109/ICTer.2012.6421415
   Correa NM, 2010, IEEE SIGNAL PROC MAG, V27, P39, DOI 10.1109/MSP.2010.936725
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Das S, 2017, P IEEE INT C ADV VID, P1
   Duta IC, 2017, MULTIMED TOOLS APPL, V76, P22445, DOI 10.1007/s11042-017-4795-6
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Foggia P, 2013, IEEE SYS MAN CYBERN, P2910, DOI 10.1109/SMC.2013.496
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He CK, 2018, MULTIMED TOOLS APPL, V77, P29573, DOI 10.1007/s11042-017-5255-z
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Jia CC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P87, DOI 10.1145/2647868.2654928
   Jia CC, 2014, AAAI CONF ARTIF INTE, P1228
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001
   Kim TY, 2005, IEEE SIGNAL PROC LET, V12, P871, DOI 10.1109/LSP.2005.859494
   Klein L. A., 2019, SENSOR DATA FUSION I
   Koperski M, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P44, DOI 10.1109/AVSS.2016.7738023
   Koperski M, 2014, IEEE IMAGE PROC, P4176, DOI 10.1109/ICIP.2014.7025848
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kosmopoulos Dimitrios I., 2013, Distributed, Ambient, and Pervasive Interactions. First International Conference, DAPI 2013. Held as Part of HCI International 2013. Proceedings: LNCS 8028, P42, DOI 10.1007/978-3-642-39351-8_5
   Kumar P, 2006, LECT NOTES COMPUT SC, V4338, P528
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miranda L, 2014, PATTERN RECOGN LETT, V39, P65, DOI 10.1016/j.patrec.2013.10.005
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   Ni BB, 2012, INT CONF ACOUST SPEE, P1405, DOI 10.1109/ICASSP.2012.6287947
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Piyathilaka L, 2015, SPRINGER TRAC ADV RO, V105, P395, DOI 10.1007/978-3-319-07488-7_27
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Raman N, 2015, NEUROCOMPUTING, V154, P149, DOI 10.1016/j.neucom.2014.12.009
   Ross A, 2005, PROC SPIE, V5779, P196, DOI 10.1117/12.606093
   Sanchez-Riera J, 2016, PATTERN RECOGN LETT, V73, P1, DOI 10.1016/j.patrec.2015.12.006
   Scholkopf B, 1997, IEEE T SIGNAL PROCES, V45, P2758, DOI 10.1109/78.650102
   Shahzad A, 2015, INT J THERMOPHYS, V36, P2565, DOI 10.1007/s10765-014-1671-8
   Sung J., 2011, PROC AAAI C ARTIF IN, P47
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Sykora P, 2014, AASRI PROC, V9, P19, DOI 10.1016/j.aasri.2014.09.005
   Tripathi RK, 2018, ARTIF INTELL REV, V50, P283, DOI 10.1007/s10462-017-9545-7
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wolf C, 2014, COMPUT VIS IMAGE UND, V127, P14, DOI 10.1016/j.cviu.2014.06.014
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xian Y, 2017, IEEE T CIRC SYST VID, V27, P624, DOI 10.1109/TCSVT.2016.2589838
   Yan SC, 2005, PROC CVPR IEEE, P526
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Zhong GQ, 2014, NEURAL COMPUT, V26, P761, DOI 10.1162/NECO_a_00570
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 77
TC 26
Z9 26
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5919
EP 5939
DI 10.1007/s11042-018-6875-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100044
DA 2024-07-18
ER

PT J
AU Moura, N
   Veras, R
   Aires, K
   Machado, V
   Silva, R
   Araújo, F
   Claro, M
AF Moura, Nayara
   Veras, Rodrigo
   Aires, Kelson
   Machado, Vinicius
   Silva, Romuere
   Araujo, Flavio
   Claro, Maila
TI ABCD rule and pre-trained CNNs for melanoma diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image classification; ABCD rule; Pre-trained CNNs; Attribute
   selection; Multilayer perceptron
ID CONVOLUTIONAL NEURAL-NETWORKS; PIGMENTED SKIN-LESIONS; TEXTURAL
   FEATURES; CLASSIFICATION; AGREEMENT
AB Skin cancer is the most common type of cancer and represents more than half of cancer diagnoses. Melanoma is the least frequent among skin cancers, but it is the most serious, with high potential for metastasis and can lead to death. However, melanoma is almost always curable if discovered in the early stages. In this context, computational methods for processing and analysis of skin lesion images have been studied and developed. This work proposes a computational approach to assist dermatologists in the diagnosis of skin lesions in melanoma or non-melanoma by means of dermoscopic images. The proposed methodology classifies skin lesions using a descriptor formed by the combination of the ABCD rule (Asymmetry, Border, Color, and Diameter) and pre-trained Convolutional Neural Networks (CNNs) features. The features were selected according to their gain ratios and used as input to the MultiLayer Perceptron classifier. We built a new database joining two distinct databases presented in the literature to validate the proposed methodology. The proposed method achieved an accuracy rate of 94.9% and Kappa index of 89.2%, which is considered excellent.
C1 [Moura, Nayara; Veras, Rodrigo; Aires, Kelson; Machado, Vinicius; Claro, Maila] Univ Fed Piaui, Teresina, PI, Brazil.
   [Silva, Romuere; Araujo, Flavio] Univ Fed Piaui, Picos, PI, Brazil.
C3 Universidade Federal do Piaui; Universidade Federal do Piaui
RP Moura, N (corresponding author), Univ Fed Piaui, Teresina, PI, Brazil.
EM naayaraholanda@gmail.com
RI Silva, Romuere/AFW-0349-2022; Veras, Rodrigo M S/D-7358-2015; de Araújo,
   Flávio H Duarte/C-9541-2015
OI Silva, Romuere/0000-0002-7163-7469; Veras, Rodrigo M
   S/0000-0001-8180-4032; Araujo, Flavio/0000-0003-2824-2645; Machado,
   Vinicius Ponte/0000-0003-3391-8443
CR Al-Akaidi M., 2004, Fractal speech processing
   [Anonymous], 2018, CANC FACTS FIG 2018
   [Anonymous], TECH REP
   [Anonymous], 2013, J HLTH INFORM
   Gutiérrez PA, 2011, IEEE T NEURAL NETWOR, V22, P246, DOI 10.1109/TNN.2010.2093537
   Barcelos CAZ, 2003, IEEE T IMAGE PROCESS, V12, P751, DOI 10.1109/TIP.2003.814242
   Bhati P, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P181, DOI 10.1109/CCIntelS.2015.7437904
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Campbell J.L., 2012, Dermnet, Skin Disease Atlas
   Cavalcanti PG, 2013, EXPERT SYST APPL, V40, P4054, DOI 10.1016/j.eswa.2013.01.002
   Cavalcanti PG, 2011, COMPUT MED IMAG GRAP, V35, P481, DOI 10.1016/j.compmedimag.2011.02.007
   Chang WY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0076212
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Codella Noel, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P118, DOI 10.1007/978-3-319-24888-2_15
   Cohen BA, 2012, J HOPKINS U DERMATLA
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   DASARATHY BV, 1991, PATTERN RECOGN LETT, V12, P497, DOI 10.1016/0167-8655(91)80014-2
   Diepgen TL, 2016, DERMATOLOGY INFORM S
   Fix E., 1951, TECH REP
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Guide SC, 2012, MELANOMA
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S., 2009, NEURAL NETWORKS LEAR
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kasmi R, 2016, IET IMAGE PROCESS, V10, P448, DOI 10.1049/iet-ipr.2015.0385
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Lacy K, 2013, Medicine, V41, P402, DOI DOI 10.1016/J.MPMED.2013.04.008
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li S. Z., 2009, Markov random field modeling in image analysis
   Melton JL, 2012, LOYOLA U DERMATOLOGY
   Mendonça T, 2013, IEEE ENG MED BIO, P5437
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oliveira RB, 2016, EXPERT SYST APPL, V61, P53, DOI 10.1016/j.eswa.2016.05.017
   Powers D.M.W., 2007, Technical Report, V2, P37
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Sánchez-Monedero J, 2016, LECT NOTES ARTIF INT, V9648, P427, DOI 10.1007/978-3-319-32034-2_36
   SCF, 2017, SKIN CANC FACTS STAT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soyer HP, 2000, Interactive atlas of dermoscopy
   Suzumura Y., 2012, YSP Dermatology Image Database
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Total S, 2012, CANC PELE FOTOPROTEC
   UK CR, 2017, SKIN CANC
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Wang SH, 2018, J REAL-TIME IMAGE PR, V15, P631, DOI 10.1007/s11554-017-0717-0
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
NR 53
TC 18
Z9 18
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6869
EP 6888
DI 10.1007/s11042-018-6404-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700021
DA 2024-07-18
ER

PT J
AU Zhang, H
   Zhang, T
   Chen, HJ
AF Zhang, Hao
   Zhang, Tao
   Chen, Huajin
TI Revisiting weighted Stego-image Steganalysis for PVD steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Steganography; Weighted stego-image; Pixel-value
   difference; Embedding rate estimation
AB Weighted stego-image (WS) method is famous for estimating embedding rate of steganography using least significant bit (LSB) scheme. This paper investigates its feasibility of analyzing pixel-value differencing (PVD) steganography, an algorithm without using LSB strategy. Theoretical analysis demonstrates that, although PVD embedding scheme is quite different from LSB, the stego noise in sum value image behaviors like that of LSB replacement (LSBR) steganography. Thus, several sum value image based WS estimators are proposed and the effectiveness is verified via experiments. The results indicate that the estimators are sensitive to sample size and relative embedding rate, and combing non-adaptive and adaptive methods can make the estimation more accurate.
C1 [Zhang, Hao; Zhang, Tao; Chen, Huajin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Zhang, H (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM haozhang78@126.com
OI Zhang, Hao/0000-0002-6310-0493
FU National Natural Science Foundation of China [61572518]; China
   Postdoctoral Science Foundation [2016M603035]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61572518, No.u1636202) and China Postdoctoral Science
   Foundation (No. 2016M603035). The authors would like to thank the
   reviewers for their insightful comments and helpful suggestions.
CR Anjum A, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P636
   [Anonymous], P SPIE SEC FOR STEG
   Böhme R, 2008, LECT NOTES COMPUT SC, V5284, P178
   Fillatre L, 2014, IEEE IMAGE PROC, P4201, DOI 10.1109/ICIP.2014.7025853
   Filler T., 2010, BOSS BREAK OUR STEGA
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Gulve Avinash K., 2015, International Journal of Image, Graphics and Signal Processing, V7, P66, DOI 10.5815/ijigsp.2015.05.08
   Huang Hsiao-Shan, 2014, INT J SCI ENG, V4, P141
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P27, DOI 10.1145/1411328.1411335
   Luo Y, 2011, P IEEE INT C MULT EX
   Schöttle P, 2012, IEEE INT WORKS INFOR, P193, DOI 10.1109/WIFS.2012.6412648
   Shen SY, 2015, COMPUT SECUR, V48, P131, DOI 10.1016/j.cose.2014.07.008
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Yang C, 2011, P INT C SEC CRYPT
   YU X, 2005, P IEEE INT C IM PROC, V2, P1102
   Yu XY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P265, DOI 10.1109/ICME.2008.4607422
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 17
TC 2
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7479
EP 7497
DI 10.1007/s11042-018-6473-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700047
DA 2024-07-18
ER

PT J
AU Chen, F
   Fu, ZG
   Zhen, L
AF Chen, Fei
   Fu, Zhongguang
   Zhen, Ling
TI RETRACTED: Thermal power generation fault diagnosis and prediction model
   based on deep learning and multimedia systems (Retracted article. See
   SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Multimedia system; Thermal power; Generation fault diagnosis; Deep
   neural network; Fuzzy prediction scenario
ID ENERGY STORAGE; FUZZY APPROACH; RECOGNITION; DESIGN; PLANTS; COSTS
AB In this research, we propose the thermal power generation fault diagnosis and prediction model based on deep learning and multimedia systems. The application of multimedia technology in the power dispatching communication system not only greatly enhances the stability and reliability of the power system, but also enriches the application of science and technology in the power system. It is one of the main directions for the development of power communication and information processing systems. The paper's novelty and contribution are major reflected from the three aspects. First, we optimize the traditional neural network model to fix it more suitable for multimedia applications. We improve the forecasting accuracy; and then for each type of sample of B-neural network model, the up-front of meteorological data. Second, the deep neural network is optimized for better evaluation efficiency. The number of convolution kernels in each convolutional layer in the network is different. The more the number of the post-convolution kernels, the more efficient the model will be. Therefore, the multi-kernel structure is proposed. Third, we integrate the multimedia into the prediction scenario to visualize the data and results. The experiment result is conducted to validate the performance of the proposed method. Results compared with the other state-of-the-art models demonstrate the robustness of our method.
C1 [Chen, Fei; Fu, Zhongguang; Zhen, Ling] North China Elect Power Univ, Beijing 102206, Peoples R China.
C3 North China Electric Power University
RP Chen, F (corresponding author), North China Elect Power Univ, Beijing 102206, Peoples R China.
EM chenfeincepu@yahoo.com
CR Abbas NI, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0464-5
   Akram Muhammad, 2017, Case Studies in Engineering Failure Analysis, V8, P21, DOI 10.1016/j.csefa.2017.01.001
   Berrhazi S, 2018, IET RENEW POWER GEN, V12, P37, DOI 10.1049/iet-rpg.2016.0848
   Boru D, 2015, CLUSTER COMPUT, V18, P385, DOI 10.1007/s10586-014-0404-x
   Bottrell Nathaniel, 2017, CIRED - Open Access Proceedings Journal, V2017, P1567, DOI 10.1049/oap-cired.2017.0648
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Chen H, 2017, ENERG POLICY, V104, P23, DOI 10.1016/j.enpol.2017.01.022
   Chen Q, 2018, MULTIMED TOOLS APPL, V77, P18601, DOI 10.1007/s11042-017-5299-0
   Conrado LS, 2017, RENEW SUST ENERG REV, V67, P1345, DOI 10.1016/j.rser.2016.09.071
   Delavar AG, 2014, CLUSTER COMPUT, V17, P129, DOI 10.1007/s10586-013-0275-6
   Fateh MF, 2017, NEURAL COMPUT APPL, V28, P2165, DOI 10.1007/s00521-016-2185-z
   Feng Y, 2017, NEURAL COMPUT APPL, V28, P1619, DOI 10.1007/s00521-015-2135-1
   González-Roubaud E, 2017, RENEW SUST ENERG REV, V80, P133, DOI 10.1016/j.rser.2017.05.084
   Huang Z, 2017, PATTERN RECOGN LETT, V98, P1, DOI 10.1016/j.patrec.2017.08.001
   Javed K, 2015, IEEE T CYBERNETICS, V45, P2626, DOI 10.1109/TCYB.2014.2378056
   Jiao JT, 2015, IEEE T INFORM THEORY, V61, P2835, DOI [10.1109/TIT.2015.2412945, 10.1109/tit.2015.2412945]
   Khankari G, 2017, TENCON IEEE REGION, P93, DOI 10.1109/TENCON.2017.8227843
   Kumaresan G, 2017, RENEW SUST ENERG REV, V77, P1363, DOI 10.1016/j.rser.2017.01.171
   Lawan SM, 2017, J CLEAN PROD, V143, P1246, DOI 10.1016/j.jclepro.2016.11.157
   Li ZR, 2017, J MED IMAG HEALTH IN, V7, P639, DOI 10.1166/jmihi.2017.2082
   Liu L, 2017, NAT ENERGY, V2, DOI 10.1038/nenergy.2017.109
   LIU M, 2017, TVCG, V23, P91, DOI DOI 10.1109/TVCG.2016.2598831
   Lu T, 2018, MULTIMED TOOLS APPL, V77, P11219, DOI 10.1007/s11042-017-5475-2
   Mansouri I, 2018, NEURAL COMPUT APPL, V29, P873, DOI 10.1007/s00521-016-2492-4
   Meng L, 2017, INT J HYDROGEN ENERG, V42, P17275, DOI 10.1016/j.ijhydene.2017.05.147
   Miyake M, 2017, J POWER SOURCES, V340, P319, DOI 10.1016/j.jpowsour.2016.11.080
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Olatomiwa L, 2015, RENEW SUST ENERG REV, V51, P1784, DOI 10.1016/j.rser.2015.05.068
   Ouaarab A, 2014, NEURAL COMPUT APPL, V24, P1659, DOI 10.1007/s00521-013-1402-2
   Pang MY, 2017, J CLEAN PROD, V144, P279, DOI 10.1016/j.jclepro.2017.01.034
   Pathak N, 2018, IEEE T POWER SYST, V33, P2040, DOI 10.1109/TPWRS.2017.2734923
   Pettinau A, 2017, APPL ENERG, V193, P426, DOI 10.1016/j.apenergy.2017.02.056
   Raju M, 2017, POWER ADV COMPUTING, P1
   Saba T, 2014, NEURAL COMPUT APPL, V25, P1337, DOI 10.1007/s00521-014-1618-9
   Saini P, 2018, ENERGY ENV SUSTAIN, P163, DOI 10.1007/978-981-10-7206-2_9
   Siar H, 2015, CLUSTER COMPUT, V18, P1609, DOI 10.1007/s10586-015-0486-0
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Sun C, 2017, IOP C SERIES MAT SCI, V199
   Sundar LS, 2017, RENEW SUST ENERG REV, V68, P185, DOI 10.1016/j.rser.2016.09.108
   Valencia F, 2016, IEEE T SMART GRID, V7, P1486, DOI 10.1109/TSG.2015.2463079
   Wang XS, 2017, IEEE WINT CONF APPL, P998, DOI 10.1109/WACV.2017.116
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Wulandhari LA, 2015, NEURAL COMPUT APPL, V26, P57, DOI 10.1007/s00521-014-1698-6
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang SW, 2017, CLUSTER COMPUT, V20, P1517, DOI 10.1007/s10586-017-0859-7
   Zhao BC, 2017, APPL ENERG, V195, P761, DOI 10.1016/j.apenergy.2017.03.110
NR 46
TC 8
Z9 8
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4673
EP 4692
DI 10.1007/s11042-018-6601-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200039
DA 2024-07-18
ER

PT J
AU Portaz, M
   Kohl, M
   Chevallet, JP
   Quénot, G
   Mulhem, P
AF Portaz, Maxime
   Kohl, Matthias
   Chevallet, Jean-Pierre
   Quenot, Georges
   Mulhem, Philippe
TI Object instance identification with fully convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fully convolutional network; Triplet loss; Siamese network; Instance
   search; Image retrieval
AB This paper presents a novel approach for instance search and object detection, applied to museum visits. This approach relies on fully convolutional networks (FCN) to obtain region proposals and object representation. Our proposal consists in four steps: a classical convolutional network is first fined-tuned as classifier over the dataset, next we build from this network a second one, fully convolutional, trained as classifier, that focuses on all regions of the corpus images, this network is used in a third step to define image global descriptors in a siamese architecture using triplets of images, and eventually these descriptors are then used for retrieval using classical scalar product between vectors. Our framework has the following features: i) it is well suited for small datasets with low objects variability as we use transfer learning, ii) it does not require any additional component in the network as we rely on classical (i.e. not fully convolutional) and fully convolutional networks, and iii) it does not need region annotations in the dataset as it deals with regions in a unsupervised way. Through multiple experiments on two image datasets taken from museum visits, we detail the effect of each parameter, and we show that the descriptors obtained using our proposed network outperform those from previous state-of-the-art approaches.
C1 [Portaz, Maxime; Kohl, Matthias; Chevallet, Jean-Pierre; Quenot, Georges; Mulhem, Philippe] Univ Grenoble Alpes, CNRS, Grenoble INP, LIG, F-38000 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Portaz, M (corresponding author), Univ Grenoble Alpes, CNRS, Grenoble INP, LIG, F-38000 Grenoble, France.
EM maxime.portaz@gmail.com
CR [Anonymous], ARXIV151105879CS
   [Anonymous], 2014, CoRR
   [Anonymous], ARXIV160408893CS
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, PROC 14 FRENCH INF R
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, ARXIV161007940
   [Anonymous], 2014, ARXIV14126537
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 1994, ADV NEURAL INFORM PR
   [Anonymous], 2016, J MACH LEARN RES
   [Anonymous], ARXIV14111792CS
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2711011
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Barroso LA, 2003, IEEE MICRO, V23, P22, DOI 10.1109/MM.2003.1196112
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Perronnin F., 2007, IEEE C COMPUTER VISI
   PHILBIN J., 2008, IEEE C COMPUTER VISI, P1
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
NR 31
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2747
EP 2764
DI 10.1007/s11042-018-5798-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600007
DA 2024-07-18
ER

PT J
AU Sahu, S
   Singh, HV
   Kumar, B
   Singh, AK
AF Sahu, Sima
   Singh, Harsh Vikram
   Kumar, Basant
   Singh, Amit Kumar
TI De-noising of ultrasound image using Bayesian approached heavy-tailed
   Cauchy distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speckle noise; Cauchy prior; MAP estimator; Statistical modeling of
   wavelet coefficients
ID SPECKLE REDUCTION; WAVELET; FILTER; SHRINKAGE; REMOVAL
AB Medical ultrasound images are used in clinical diagnosis and generally degraded by speckle noise. This makes difficulty in automatic interpretation of diseases in ultrasound images. This paper presents a speckle removal algorithm by modeling the wavelet coefficients. A Bayesian approach is implemented to find the noise free coefficients. Cauchy prior and Gaussian Probability Density Function (PDF) are used to model the true wavelet coefficients and noisy coefficients respectively. A Maximum a Posteriori (MAP) estimator is used to estimate the noise free wavelet coefficients. A Median Absolute Deviation (MAD) estimator is used to find the variance of affected wavelet coefficients in finest scale. The proposed method is compared with existing denoising methods. The experimental results show that the method offer up to 21.48% enhancement in Peak Signal to Noise Ratio (PSNR), 1.82% enhancement in Structural Similarity Index (SSIM), 1% enhancement in Correlation coefficient () and 7.68% enhancement in Edge Preserving Index (EPI) than best existing wavelet modeling method. The results indicate that the proposed method outperforms over existing methods, both in noise reduction and edge preservation.
C1 [Sahu, Sima] Dr APJ Abdul Kalam Tech Univ, Image Proc, Lucknow, Uttar Pradesh, India.
   [Singh, Harsh Vikram] KNIT, Dept Elect Engn, Sultanpur, Uttar Pradesh, India.
   [Kumar, Basant] Motilal Nehru Natl Inst Technol, Dept Elect & Commun Engn, Allahabad, Uttar Pradesh, India.
   [Singh, Amit Kumar] Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Kamla Nehru
   Institute of Technology Sultanpur; National Institute of Technology (NIT
   System); Motilal Nehru National Institute of Technology; Jaypee
   University of Information Technology
RP Singh, AK (corresponding author), Jaypee Univ Informat Technol, Dept Comp Sci & Engn, Solan, Himachal Prades, India.
EM simahal@rediffmail.com; harshvikram@gmail.com; singhbasant@mnnit.ac.in;
   amit_245singh@yahoo.com
RI sahu, sima/AAO-8685-2021; Singh, Harsh Vikram/Q-9457-2019; KUMAR,
   BASANT/AAD-8650-2021; Singh, Amit Kumar/D-1300-2015
OI sahu, sima/0000-0002-0606-8140; Singh, Harsh Vikram/0000-0002-8904-862X;
   Singh, Amit Kumar/0000-0001-7359-2068
CR Achim A, 2003, IEEE T GEOSCI REMOTE, V41, P1773, DOI 10.1109/TGRS.2003.813488
   Achim A, 2001, IEEE T MED IMAGING, V20, P772, DOI 10.1109/42.938245
   Amirmazlaghani M, 2012, IET IMAGE PROCESS, V6, P580, DOI 10.1049/iet-ipr.2009.0110
   ATLAS L, 2004, ACOUST SPEECH SIG PR, P761
   Bhuiyan MIH, 2008, IET IMAGE PROCESS, V2, P203, DOI 10.1049/iet-ipr:20070035
   Bhuiyan MIH, 2007, IEEE T CIRC SYST VID, V17, P500, DOI 10.1109/TCSVT.2006.888020
   Bhuiyan M.I.H., 2006, IEEE N E WORKSHOP CI, P33
   Bhuiyan MIH, 2005, IEEE INT SYMP CIRC S, P4935, DOI 10.1109/ISCAS.2005.1465740
   Bhutada GG, 2011, IET IMAGE PROCESS, V5, P573, DOI 10.1049/iet-ipr.2010.0014
   Bibalan MH, 2016, EURASIP J IMAGE VIDE, V48, P1
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   CHEN Y, 1975, INF PROCESS, V7, P629, DOI DOI 10.1142/S0219691309003136
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   EI-Said SA, 2012, J MED IMAG RADIANT S, V43, P200, DOI [10.1016/j.jmir.2012.06.001, DOI 10.1016/J.JMIR.2012.06.001]
   Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704
   Forouzanfar M, 2008, INT J WAVELETS MULTI, V6, P653, DOI 10.1142/S0219691308002562
   Gagnon L, 1997, P SOC PHOTO-OPT INS, V3169, P80, DOI 10.1117/12.279681
   GUO H, 1994, IEEE IMAGE PROC, P75, DOI 10.1109/ICIP.1994.413278
   Hansen M, 2000, IEEE T INFORM THEORY, V46, P1778, DOI 10.1109/18.857790
   Hyvärinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214
   Jafari Saeed, 2017, JOUNAL ADV COMPUTER, V8, P53
   Jain A., 1989, Fundamental of digital image processing
   Lee MS, 2012, IET IMAGE PROCESS, V6, P813, DOI 10.1049/iet-ipr.2011.0366
   Li HY, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-017-0336-9
   Lu YX, 2016, NEUROCOMPUTING, V173, P633, DOI 10.1016/j.neucom.2015.08.010
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Press W. H., 1999, NUMERICAL RECIPES C
   Rabbani H, 2008, IEEE T BIO-MED ENG, V55, P2152, DOI 10.1109/TBME.2008.923140
   Rabbani H, 2006, 2006 IEEE 12TH DIGITAL SIGNAL PROCESSING WORKSHOP & 4TH IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, P203, DOI 10.1109/DSPWS.2006.265407
   Ramos-Llordén G, 2015, IEEE T IMAGE PROCESS, V24, P345, DOI 10.1109/TIP.2014.2371244
   Ranjani JJ, 2015, IET IMAGE PROCESS, V9, P338, DOI 10.1049/iet-ipr.2013.0863
   Sadreazami H, 2016, IEEE INT SYMP CIRC S, P33, DOI 10.1109/ISCAS.2016.7527163
   Sudeep PV, 2016, BIOMED SIGNAL PROCES, V28, P1, DOI 10.1016/j.bspc.2016.03.001
   Vidakovic B., 2009, STAT MODELING WAVELE
NR 37
TC 22
Z9 23
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4089
EP 4106
DI 10.1007/s11042-017-5221-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200012
DA 2024-07-18
ER

PT J
AU Zeng, YN
   Mao, H
   Peng, DZ
   Yi, Z
AF Zeng, Yuni
   Mao, Hua
   Peng, Dezhong
   Yi, Zhang
TI Spectrogram based multi-task audio classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-task learning; Convolutional neural networks; Deep residual
   networks; Audio classification
ID RECOGNITION; ACCENT
AB Audio classification is regarded as a great challenge in pattern recognition. Although audio classification tasks are always treated as independent tasks, tasks are essentially related to each other such as speakers' accent and speakers' identification. In this paper, we propose a Deep Neural Network (DNN)-based multi-task model that exploits such relationships and deals with multiple audio classification tasks simultaneously. We term our model as the gated Residual Networks (GResNets) model since it integrates Deep Residual Networks (ResNets) with a gate mechanism, which extract better representations between tasks compared with Convolutional Neural Networks (CNNs). Specifically, two multiplied convolutional layers are used to replace two feed-forward convolution layers in the ResNets. We tested our model on multiple audio classification tasks and found that our multi-task model achieves higher accuracy than task-specific models which train the models separately.
C1 [Zeng, Yuni; Mao, Hua; Peng, Dezhong; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Mao, H (corresponding author), Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Sichuan, Peoples R China.
EM huamao@scu.edu.cn
OI Mao, Hua/0000-0003-3198-6282
FU National Natural Science Foundation of China [61402306, 61432012]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61402306, 61432012]
CR Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2007, MIR MATLAB
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], NEURAL NETW
   [Anonymous], ARXIV170306697
   [Anonymous], 2012, ANN M CAN SOC BRAIN
   [Anonymous], 2015, Recent Advances in Convolutional Neural Networks
   [Anonymous], CONV NEUR NETW LEN
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Chen T., 2015, P NEUR INF PROC SYST
   Gong Pinghua, 2012, KDD, V2012, P895
   Grosse R, 2007, P 23 C UNC ART INT, P149
   Han Y, 2017, IEEE-ACM T AUDIO SPE, V25, P208, DOI 10.1109/TASLP.2016.2632307
   Hannun A, 2014, ARXIV14125567V2CSCL
   Hansen JHL, 2016, SPEECH COMMUN, V78, P19, DOI 10.1016/j.specom.2015.12.004
   Hashimoto Kazuma, 2016, ARXIV161101587
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li C., 2017, ARXIV170502304
   Livingstone SR, 2015, Q J EXP PSYCHOL, V68, P952, DOI 10.1080/17470218.2014.971034
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Pedersen C, 2007, 6TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, PROCEEDINGS, P444, DOI 10.1109/ICIS.2007.47
   Phapatanaburi K, 2016, MULTIMED TOOLS APPL, V75, P5109, DOI 10.1007/s11042-015-2935-4
   Rao P, 2008, STUD COMPUT INTELL, V83, P169, DOI 10.1007/978-3-540-75398-8_8
   Shegokar P., 2016, 10 INT C SIGNAL PROC, P1
   Simonyan K., 2014, 14091556 ARXIV
   Wu B, 2016, IEEE INT C MULTIMEDI, P1
   Zhang BQ, 2016, INT CONF ACOUST SPEE, P5805, DOI 10.1109/ICASSP.2016.7472790
   Zhang BQ, 2015, INT CONF AFFECT, P139, DOI 10.1109/ACII.2015.7344563
   Zhu XF, 2017, MED IMAGE ANAL, V38, P205, DOI 10.1016/j.media.2015.10.008
   Zhu XF, 2014, LECT NOTES COMPUT SC, V8675, P401, DOI 10.1007/978-3-319-10443-0_51
   Zhu Yingying, 2016, Med Image Comput Comput Assist Interv, V9900, P264, DOI 10.1007/978-3-319-46720-7_31
   Zhu YY, 2015, IEEE T PATTERN ANAL, V37, P529, DOI 10.1109/TPAMI.2013.2295311
NR 38
TC 90
Z9 96
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3705
EP 3722
DI 10.1007/s11042-017-5539-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600057
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jiang, XL
   Yang, XJ
   Ying, ZG
   Zhang, LW
   Pan, J
   Chen, SJ
AF Jiang, Xiaoliang
   Yang, Xiaojun
   Ying, Zhengen
   Zhang, Liwen
   Pan, Jie
   Chen, Shaojie
TI Segmentation of shallow scratches image using an improved multi-scale
   line detection approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical element; Shallow scratches; Multi-scale line detection;
   Morphological operations
ID SURFACE DEFECT DETECTION; VESSEL SEGMENTATION; INSPECTION SYSTEM;
   BLOOD-VESSELS; OPTIC DISC; MORPHOLOGY; DESIGN
AB Along with developing modern technology, the demands for optical element surface develop towards the characteristics of large scale and high precision. However, it is challenging to evaluate the surface defects since some shallow scratches in optical element surface images are usually characterized by low contrast and blurry outlines. This property makes the machine vision inspection extremely difficult. So, this paper proposes a novel multi-scale line detection method that can efficiently extract shallow scratches. Firstly, to decrease the influence of the surrounding region, a new multi-scale line detector combines all the responses at different scales by setting different weights for each scale. Then, based on the scratches features, we utilize morphological operations to get the full continuum of the scratches area. Experimental results show that our model can ideally extract the contours of shallow scratches that are very close to the optical microscope results observed by specialists.
C1 [Jiang, Xiaoliang; Yang, Xiaojun; Ying, Zhengen; Zhang, Liwen; Pan, Jie] Quzhou Univ, Coll Mech Engn, Quzhou 324000, Zhejiang, Peoples R China.
   [Jiang, Xiaoliang; Chen, Shaojie] Southwest Jiaotong Univ, Coll Mech Engn, Chengdu 610031, Sichuan, Peoples R China.
C3 Quzhou University; Southwest Jiaotong University
RP Jiang, XL (corresponding author), Quzhou Univ, Coll Mech Engn, Quzhou 324000, Zhejiang, Peoples R China.; Jiang, XL (corresponding author), Southwest Jiaotong Univ, Coll Mech Engn, Chengdu 610031, Sichuan, Peoples R China.
EM jxl_qzu@163.com
RI Zhang, Liqun/JDN-3523-2023; Zhang, Li/GWM-7501-2022
OI Jiang, Xiaoliang/0000-0003-2695-8586; Yang, Xiaojun/0000-0002-9489-9314
FU National Natural Science Foundation of China [51275272, 51605252,
   51605253]; Zhejiang Provincial Natural Science Foundation of China
   [LQ17C160001, LQ18F010007]; Provincial public-benefit technology
   application research of Zhejiang [2016C31127]; Key Laboratory of
   Air-driven Equipment Technology of Zhejiang Province [2018E10011]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve this paper. Besides, this
   work is supported by the National Natural Science Foundation of China
   (No. 51275272, 51605252, 51605253), Zhejiang Provincial Natural Science
   Foundation of China (No. LQ17C160001, LQ18F010007), Provincial
   public-benefit technology application research of Zhejiang (No.
   2016C31127), Key Laboratory of Air-driven Equipment Technology of
   Zhejiang Province (No. 2018E10011).
CR [Anonymous], 2018, PATTERN ANAL APPL
   Bai XL, 2014, IEEE T IND INFORM, V10, P2135, DOI 10.1109/TII.2014.2359416
   Biswal B, 2018, IET IMAGE PROCESS, V12, P389, DOI 10.1049/iet-ipr.2017.0329
   Ding WD, 2017, INT J AUTOM COMPUT, V14, P420, DOI 10.1007/s11633-017-1079-6
   Eldada L, 2004, REV SCI INSTRUM, V75, P575, DOI 10.1063/1.1647701
   Gaidhane VH, 2018, PATTERN ANAL APPL, V21, P277, DOI 10.1007/s10044-017-0640-9
   Gao XJ, 2013, INT J BIOMED ENG TEC, V13, P240, DOI 10.1504/IJBET.2013.058445
   Guo LY, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540162
   Jayaswal RK, 2015, OPTIK, V126, P1700, DOI 10.1016/j.ijleo.2015.05.043
   Jian CX, 2017, APPL SOFT COMPUT, V52, P348, DOI 10.1016/j.asoc.2016.10.030
   Khonina SN, 2016, J MOD OPTIC, V63, P1239, DOI 10.1080/09500340.2015.1137368
   Kuo CF, 2013, INT J PROD RES, V51, P1464, DOI 10.1080/00207543.2012.695877
   Lei J, 2018, NEUROCOMPUTING, V294, P72, DOI 10.1016/j.neucom.2018.03.013
   Li C, 2017, CHIN OPT LETT, V15, P53, DOI [10.1016/j.cplett.2017.03.048, DOI 10.1016/J.CPLETT.2017.03.048]
   Liu K, 2017, IEEE T INSTRUM MEAS, V66, P2585, DOI 10.1109/TIM.2017.2712838
   Liu Y, 2014, OPT LASER ENG, V55, P243, DOI 10.1016/j.optlaseng.2013.11.013
   Min YZ, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0241-y
   Movafeghi A, 2018, J NONDESTRUCT EVAL, V37, DOI 10.1007/s10921-017-0458-9
   Nazari A, 2015, J TEKNOL, V77, P47
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Qu M, 2017, PERVASIVE MOB COMPUT, V41, P490, DOI 10.1016/j.pmcj.2017.04.003
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Richard N, 2016, OPT ENG, V55
   Rodrigues LC, 2017, BIOMED SIGNAL PROCES, V36, P39, DOI 10.1016/j.bspc.2017.03.014
   Rodil SS, 2010, INT J ADV MANUF TECH, V49, P133, DOI 10.1007/s00170-009-2395-y
   Shen YP, 2013, P I MECH ENG B-J ENG, V227, P1504, DOI 10.1177/0954405413489293
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tao X, 2017, OPT COMMUN, V387, P390, DOI 10.1016/j.optcom.2016.10.062
   Tao X, 2015, IEEE T INSTRUM MEAS, V64, P2530, DOI 10.1109/TIM.2015.2415092
   Tsai DM, 2006, PATTERN RECOGN, V39, P1679, DOI 10.1016/j.patcog.2006.03.005
   Wang J, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1968
   Wang WH, 2018, J MED IMAG HEALTH IN, V8, P262, DOI 10.1166/jmihi.2018.2288
   Wei JH, 2018, INT J THEOR PHYS, V57, P1479, DOI 10.1007/s10773-018-3675-9
   Yanli Hou, 2014, Journal of Computing Science and Engineering, V8, P119, DOI 10.5626/JCSE.2014.8.2.119
   Zhang J, 2014, COMPUT MED IMAG GRAP, V38, P517, DOI 10.1016/j.compmedimag.2014.05.010
   Zhao YJ, 2018, ADV ENG SOFTW, V115, P17, DOI 10.1016/j.advengsoft.2017.08.008
NR 36
TC 5
Z9 5
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 1053
EP 1066
DI 10.1007/s11042-018-6222-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500059
DA 2024-07-18
ER

PT J
AU Das, TK
AF Das, Tanmoy Kanti
TI Anti-forensics of JPEG compression detection schemes using approximation
   of DCT coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG compression detection; Anti-forensics; Approximation
ID CRYPTANALYSIS
AB Here we propose a unique anti-forensics method using the approximation of DCT coefficients for security analysis of forensics schemes that are dependent on the distortions produced by JPEG compression to detect forgery. Approximation process first builds a model of the AC component of DCT coefficients. Then it uses that model to restore the values of the DCT coefficients. The beauty of the proposed anti-forensics technique is that one can specify any distortion measure and it is capable of minimizing that distortion as long as the specified distortion is produced by JPEG compression or the distortion is measurable in the DCT domain. We specifically mount our anti-forensics technique on three leading JPEG compression detection schemes (Fan and de Queiroz, IEEE Trans Image Process 12(2): 230-235, 2003; Lai and Bohme 2011) to highlight their weaknesses. Though these schemes are based on three different distortions metrics, still we could achieve 100% missed detection rate for JPEG images having quality factor more than equal to 60%. Our analysis raises a serious question regarding the robustness and security of JPEG artifact based forgery detection schemes.
C1 [Das, Tanmoy Kanti] Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Das, TK (corresponding author), Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, Madhya Pradesh, India.
EM tkdas.mca@nitrr.ac.in
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bohme R., 2012, DIGITAL IMAGE FORENS, P327, DOI [DOI 10.1007/978-1-4614-0757-7_12, 10.1007/978-1-4614-0757-7_12]
   Chakravarti L, 1967, ROY HDB METHODS APPL, VI
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Das TK, 2004, IEEE SIGNAL PROC LET, V11, P446, DOI 10.1109/LSP.2004.824028
   Das TK, 2005, IEEE T SIGNAL PROCES, V53, P768, DOI 10.1109/TSP.2004.839930
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Iuliani M, 2017, J VIS COMMUN IMAGE R, V42, P65, DOI 10.1016/j.jvcir.2016.11.010
   Khan M. E., 2017, APPROACH CRACK DETEC
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Sutthiwan Patchara, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P411, DOI 10.1007/978-3-642-32205-1_33
   Ullerich C, 2008, IWDW 2007, P127
   Valenzise G., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1949, DOI 10.1109/ICIP.2011.6115854
   Zakariah M, 2018, MULTIMED TOOLS APPL, V77, P1009, DOI 10.1007/s11042-016-4277-2
NR 27
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31835
EP 31854
DI 10.1007/s11042-018-6170-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000014
DA 2024-07-18
ER

PT J
AU Jiang, L
AF Jiang, Li
TI The identical operands commutative encryption and watermarking based on
   homomorphism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia information security; Homomorphism; Commutative encryption
   and watermarking
ID KEY
AB Aiming at the requirement of comprehensive security protection for multimedia information, this paper proposes a new algorithm to realize the combination of encryption and watermarking based on the homomorphism. Under the proposed algorithm scheme, the plaintext watermark embedding operations are mapped to the ciphertext domain by homomorphism to achieve the plaintext watermark embedding in the ciphertext domain; at the same time, the embedded plaintext watermarks are also mapped to the ciphertext domain by homomorphism to achieve the ciphertext watermarking embedding. According to the experimental results, by the proposed algorithm, the order of watermark embedding and data encrypting does not affect the production of the same encrypted-watermarked data, meanwhile, whether the encrypted-watermarked data being decrypted or not does not affect the extraction of embedded watermark. For the operands of encryption and watermarking being the same data, the proposed algorithm has higher security compared with the existing mainstream independent operands based communicative encryption and watermarking.
C1 [Jiang, Li] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Henan, Peoples R China.
C3 Zhengzhou University
RP Jiang, L (corresponding author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Henan, Peoples R China.
EM ieljiang@zzu.edu.cn
FU National Natural Science Foundation of China [61402421, 61331021]
FX The authors would like to acknowledge the help of Dr. Zhi Quan in
   editing of the paper. And this work was supported by the National
   Natural Science Foundation of China under Grant 61402421, 61331021.
CR [Anonymous], 1978, Found. Sec. Comput
   Battisti F, 2009, EURASIP J ADV SIG PR, V2009, P1
   Bender W., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P164, DOI 10.1117/12.205315
   Boato G, 2008, ELECTRON LETT, V44, P601, DOI 10.1049/el:20080492
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Chang F, 2005, ADV MULTIMED INFO PR, V3333, P356
   Chang FC, 2005, IEEE INT SYMP CIRC S, P4983
   Chauhan D. S., 2017, Quantization based multiple medical information watermarking for secure e- health,'' M u l t i m e d i a T o o l s A p p l ., P1
   Gentry C, 2011, ANN IEEE SYMP FOUND, P107, DOI 10.1109/FOCS.2011.94
   Gentry Craig, 2009, FULLY HOMOMORPHIC EN, V20
   Jiang L, 2014, MULTIMED TOOLS APPL, V70, P1617, DOI 10.1007/s11042-012-1181-2
   Kalker T, 2005, P 43 ANN ALL C COMM, P1511
   Li Jiang, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P625, DOI 10.1109/MINES.2010.136
   Li Z, 2007, MULTIMED EXPO, P627
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Otto-von-Guericke University at Magdeburg (GAUSS), 2005, IST2002507932 GAUSS
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Park SW, 2008, STUD COMPUT INTELL, V142, P351
   Puech W., 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1481
   Puech W, 2007, J REAL-TIME IMAGE PR, V2, P55, DOI 10.1007/s11554-007-0045-x
   Puech W, 2008, P OF SPIE
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Singh AK, 2016, MULTIMED TOOLS APPL, V75, P8381, DOI 10.1007/s11042-015-2754-7
   Smart NP, 2010, LECT NOTES COMPUT SC, V6056, P420
   Stinson D. R., 2018, Cryptography Theory and Practice
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Xu Y, 2012, J APPL REMOTE SENS, V6, P1, DOI [10.1117/1.JRS.12.016031, DOI 10.1117/1.JRS.12.016031]
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
NR 34
TC 11
Z9 13
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30575
EP 30594
DI 10.1007/s11042-018-6142-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600020
DA 2024-07-18
ER

PT J
AU Li, HL
   Guan, QX
   Wang, HD
   Dong, J
AF Li, Hailiang
   Guan, Qingxiao
   Wang, Haidong
   Dong, Jing
TI Deep-MATEM: TEM query image based cross-modal retrieval for material
   science literature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-Modal; Document retrieval; Convolutional network; Material science
ID SCALE
AB With the rapid increasing of published material science literatures, an effective literature retrieving system is important for researchers to obtain relevant information. In this paper we propose a cross-modal material science literatures retrieval method using transmission electron microscopy(TEM) image as query information, which provide a access of using material experiment generated TEM image data to retrieve literatures. In this method, terminologies are extracted and topic distribution are inferred from text part of literatures by using LDA, and we design a multi-task Convolutional Neuron Network(CNN) mapping query TEM image to the relevant terminologies and topic distribution predictions. The ranking score is calculated from output for query image and text data. Experimental results shows our method achieves better performance than multi-label CCA, Deep Semantic Matching(Deep SM) and Modality-Specific Deep Structure(MSDS).
C1 [Li, Hailiang; Wang, Haidong] Cent South Univ, Sch Minerals Proc & Bioengn, Changsha 410083, Hunan, Peoples R China.
   [Li, Hailiang; Guan, Qingxiao; Dong, Jing] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Guan, Qingxiao] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
   [Dong, Jing] Chinese Acad Sci, Inst Automat, Ctr Res Intelligent Percept & Comp, Beijing 100190, Peoples R China.
C3 Central South University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Guan, QX (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Guan, QX (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM assed321@csu.edu.cn; 258817567@qq.com
FU National Natural Science Foundation of China [U1536105, 51474237,
   U1536120, U1636201]; National Key Research and Development Program of
   China [2016YFB1001003]
FX This work was supported by the National Natural Science Foundation of
   China under U1536105, NO.51474237, U1536120, U1636201, the National Key
   Research and Development Program of China(No. 2016YFB1001003)
CR [Anonymous], 2014, ARXIV14065726 CORR
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Callister W., 2013, Materials Science and Engineering- An Introduction, V9th ed.
   Cao G, 2018, IEEE T CYBERNETICS, V99, P1
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jiang XY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P69, DOI 10.1145/2733373.2806240
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, INT C COMM SIGN PROC
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang D, 2016, IEEE T IMAGE PROCESS, V25, P4540, DOI 10.1109/TIP.2016.2592800
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang YF, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P307, DOI 10.1145/2647868.2654901
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   You XG, 2014, IEEE T CIRC SYST VID, V24, P1265, DOI 10.1109/TCSVT.2014.2306031
NR 31
TC 0
Z9 0
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30269
EP 30290
DI 10.1007/s11042-018-6043-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600006
DA 2024-07-18
ER

PT J
AU Noura, M
   Noura, H
   Chehab, A
   Mansour, MM
   Sleem, L
   Couturier, R
AF Noura, Mohammad
   Noura, Hassan
   Chehab, Ali
   Mansour, Mohammad M.
   Sleem, Lama
   Couturier, Raphael
TI A dynamic approach for a lightweight and secure cipher for medical
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Selective or partial encryption algorithm; Full encryption algorithm;
   Permutation and substitution primitives; Cryptographic analysis
ID ENCRYPTED IMAGES; COMPRESSION; CHAOS; SCHEME; CRYPTANALYSIS; PROTECTION;
   EFFICIENT; ALGORITHM
AB Protecting the contents of medical records is of paramount importance when it comes to preserving patients' privacy. Most existing cryptographic-based solutions rely on traditional encryption algorithms having a multi-round structure, which introduces processing latency and requires increased resources. Medical images possess special characteristics compared to other types of images. The main goal of this paper is to leverage these characteristics to design and implement an efficient and secure encryption algorithm for such images. The proposed solution defines three variants of encryption algorithms: (a) full, (b) middle-full, and (c) selective. The full approach encrypts all sub-matrices of an image, while the middle-full variant is a middle solution between the selective and full algorithms and its goal is to just hide the type of the medical image. Selective encryption identifies a set of sub-matrices of an image according to a statistical average test, known as region of interest (ROI). In the three approaches, a high security level is ensured since each image is encrypted independently of the previous and next images. Also, all primitives of the proposed cipher, such as permutation and substitution, depend on a dynamic key. Furthermore, the encryption scheme is efficient since the proposed round function is lightweight and applied for only one round. This reduces the latency and the required resources as compared to traditional cryptographic schemes. The proposed approach is flexible as it can be applied in either selective, middle-full, or full mode. Also, the size of a sub-matrix is variable and can be changed according to the available memory size. Several security and performance tests are conducted to evaluate the effectiveness of the proposed solution. The results validate the robustness of the proposed scheme against almost all considered types of attacks and show an improvement in terms of latency and resources compared to current image-encryption schemes. Also, the results confirm the robustness of the proposed algorithm in protecting the contents of medical images.
C1 [Noura, Mohammad; Sleem, Lama; Couturier, Raphael] UBFC, FEMTO ST Inst, Belfort, France.
   [Noura, Hassan; Chehab, Ali; Mansour, Mohammad M.] Amer Univ Beirut, Elect & Comp Engn, Beirut, Lebanon.
C3 Universite de Franche-Comte; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Centre National de la Recherche Scientifique
   (CNRS); American University of Beirut
RP Couturier, R (corresponding author), UBFC, FEMTO ST Inst, Belfort, France.
EM mohamad.noura@univ-fcomte.fr; hn49@aub.edu.lb; chehab@aub.edu.lb;
   mm14@aub.edu.lb; lama.sleem@univ-fcomte.fr;
   raphael.couturier@univ-fcomte.fr
RI Couturier, Raphaël/C-1095-2013; Mansour, Mohammad M/D-2809-2018; Noura,
   Hassan/U-8729-2018
OI Couturier, Raphaël/0000-0003-1490-9592; Chehab, Ali/0000-0002-1939-2740;
   Noura, Hassan/0000-0002-2589-5053; Noura, Hassan/0000-0003-1768-9193
FU Lebanese National Council for Scientific Research; Labex ACTION program
   [ANR-11-LABX-01-01]
FX This paper is partially funded by the Lebanese National Council for
   Scientific Research and by the Labex ACTION program (contract
   ANR-11-LABX-01-01).
CR Abdmouleh MK, 2013, INT C SYST CONTR SIG, P16
   Ali S., 2015, J INFORM SCI COMPUTI, V1, P78
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Ashtiyani M, 2008, 3 INT C INF COMM TEC, P1
   Babel M., 2012, Advances in Reasoning-Based Image Processing Intelligent Systems: Conventional and Intelligent Paradigms, P91
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Biham E., 2012, DIFFERENTIAL CRYPTAN
   Brahimi Zahia, 2008, WSEAS Transactions on Circuits and Systems, V7, P718
   Bruckmann A, 2000, COMPUT BIOL MED, V30, P153, DOI 10.1016/S0010-4825(00)00004-4
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Daemen J., 2013, DESIGN RIJNDAEL AES
   Dai Y, 2012, PROCEEDING OF THE IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P210, DOI 10.1109/ICInfA.2012.6246810
   Digital imaging and communications in medicine (DICOM), 2004, SEC SYST MAN PROF 15
   Feng Huang, 2009, Frontiers of Electrical and Electronic Engineering in China, V4, P5, DOI 10.1007/s11460-009-0016-z
   Fornazin M, 2008, ADVANCES IN COMPUTER AND INFORMATIOM SCIENCES AND ENGINEERING, P284, DOI 10.1007/978-1-4020-8741-7_52
   Fu C, 2015, INT SYM MED INFORM, P103, DOI 10.1109/ISMICT.2015.7107507
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Heys HM, 2002, CRYPTOLOGIA, V26, P189, DOI 10.1080/0161-110291890885
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Jian XU, 2018, J NETWORK COMPUTER A
   Kanso A, 2015, COMMUN NONLINEAR SCI, V24, P98, DOI 10.1016/j.cnsns.2014.12.005
   Kester QA, 2015, 2015 15TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS (ICCSA), P8, DOI 10.1109/ICCSA.2015.8
   Li JZ, 2018, SOFT COMPUT, V22, P47, DOI 10.1007/s00500-016-2320-x
   Li P, 2017, SOFT COMPUT, V21, P4349, DOI 10.1007/s00500-016-2066-5
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Lima JB, 2015, SIGNAL PROCESS-IMAGE, V35, P1, DOI 10.1016/j.image.2015.03.005
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Mahmood A. B., 2011, 2011 6th International Conference for Internet Technology and Secured Transactions (ICITST), P596
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mostefaoui A, 2015, AD HOC NETW, V32, P81, DOI 10.1016/j.adhoc.2015.01.007
   Ou Y, FRONTIERS ALGORITHMI, P62
   Paar C., 2009, UNDERSTANDING CRYPTO
   Panduranga H.T., 2013, INT J ENG TECHNOLOGY, V5, P115
   Puech W., 2005, PROC EUR SIGNAL PROC, P1
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   SCHNEIER B, 1993, DR DOBBS J, V18, P50
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   Shi ZJ, 2004, BIT PERMUTATION INST
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Som S, 2013, PROC TECH, V10, P663, DOI 10.1016/j.protcy.2013.12.408
   Usman K, 2007, HEALTHCOM 2007: UBIQUITOUS HEALTHCARE IN AGING SOCIETIES, P244, DOI 10.1109/HEALTH.2007.381640
   Wang XY, 2013, NONLINEAR DYNAM, V73, P795, DOI 10.1007/s11071-013-0832-9
   Wang Y-G, 2018, TRANSPORTATION SPHER
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Zeng L, 2015, OPTIK, V126, P5022, DOI 10.1016/j.ijleo.2015.09.219
   Zhang L-B, 2015, INT J SIGNAL PROCESS, V8, P327
   Zhang L-B, 2015, MATH PROBL ENG, V2015, P13951
   Zhang XP, 2014, IEEE T MULTIMEDIA, V16, P1327, DOI 10.1109/TMM.2014.2315974
   Zhang XP, 2014, MULTIMED TOOLS APPL, V72, P489, DOI 10.1007/s11042-013-1392-1
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhou JT, 2013, INT CONF ACOUST SPEE, P2872, DOI 10.1109/ICASSP.2013.6638182
   Zhou YC, 2009, IEEE ENG MED BIO, P3707, DOI 10.1109/IEMBS.2009.5334799
NR 54
TC 16
Z9 16
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31397
EP 31426
DI 10.1007/s11042-018-6051-0
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600056
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, Y
   Luo, XB
   Ding, L
   Hu, SQ
AF Wang, Yong
   Luo, Xinbin
   Ding, Lu
   Hu, Shiqiang
TI Visual tracking via robust multi-task multi-feature joint sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Multi-task sparse learning; Decomposition model;
   Alternating direction method of multipliers
ID OBJECT TRACKING; ONLINE
AB Multiple feature object representation has been proved as a robust approach for visual tracking. Different types of situations such as occlusion, rotation and illumination may occur during tracking, especially long sequences. Robust tracking could be obtained as multiple features could complement each other. In this paper, we cast visual tracking as a novel multi-task sparse learning problem and exploit various types of visual features, such as intensity, color, texture and edge, where each feature can be sparsely represented by a linear combination of atoms from an adaptive feature template. We use an on-line feature selection mechanism based on the two-class variance ratio measure, applied to log likelihood distributions computed with respect to a given feature from samples of object and background pixels. The proposed method is integrated in a particle filtering framework. We jointly consider the underlying relationship across different particles, and tackle it in a unified robust multi-task formulation. In addition, to capture the frequently emerging outlier tasks, we make fully use of a decomposition model which enables a more robust and accurate approximation. We show that the proposed model can be efficiently solved using the Alternating direction method of multipliers (ADMM) with a small number of closed-form updates. Four types of features are implemented and tested on numerous benchmark video sequences. Both the qualitative and quantitative results demonstrate the superior performance of the proposed approach compared to 9 state of-the-art trackers.
C1 [Wang, Yong] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Luo, Xinbin] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Ding, Lu; Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
C3 University of Ottawa; Shanghai Jiao Tong University; Shanghai Jiao Tong
   University
RP Luo, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM losinbin@sjtu.edu.cn
RI TIAN, YI/KHU-9704-2024; Ding, Lu/AAJ-2179-2020; Wang,
   Zejun/KBB-8454-2024
FU National Natural Science Foundation of China [61374161]; China Aviation
   Science Foundation [20142057006]
FX This paper is jointly supported by the National Natural Science
   Foundation of China No. 61374161, China Aviation Science Foundation
   20142057006. Part of the research conducted when the first author were
   in CRCV at UCF.
CR [Anonymous], 2017, PROC HARDW ARCHIT SU
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 2015, HIGH SPEED TRACKING
   [Anonymous], PASCAL VISUAL OBJECT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, P BMVC
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2013, P 27 ANN C NEUR INF
   [Anonymous], SCALE ADAPTIVE KERNE
   [Anonymous], 2005, P IEEE C CVPR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen DT, 2007, IEEE T PATTERN ANAL, V29, P2157, DOI 10.1109/TPAMI.2007.1134
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Han ZJ, 2011, COMPUT VIS IMAGE UND, V115, P69, DOI 10.1016/j.cviu.2010.09.004
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Moreno-Noguer F, 2008, IEEE T PATTERN ANAL, V30, P670, DOI 10.1109/TPAMI.2007.70727
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang JY, 2005, PROC CVPR IEEE, P1037
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang L, 2009, IEEE INT C EMERG
   Zhang T., 2012, IEEE C COMPUTER VISI, P1
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
NR 42
TC 8
Z9 9
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31447
EP 31467
DI 10.1007/s11042-018-6198-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600058
DA 2024-07-18
ER

PT J
AU Chatbri, H
   Kameyama, K
   Kwan, P
   Little, S
   O'Connor, NE
AF Chatbri, Houssem
   Kameyama, Keisuke
   Kwan, Paul
   Little, Suzanne
   O'Connor, Noel E.
TI A novel shape descriptor based on salient keypoints detection for binary
   image matching and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape descriptors; Salient keypoints; Image matching; Sketch-based
   retrieval
AB We introduce a shape descriptor that extracts keypoints from binary images and automatically detects the salient ones among them. The proposed descriptor operates as follows: First, the contours of the image are detected and an image transformation is used to generate background information. Next, pixels of the transformed image that have specific characteristics in their local areas are used to extract keypoints. Afterwards, the most salient keypoints are automatically detected by filtering out redundant and sensitive ones. Finally, a feature vector is calculated for each keypoint by using the distribution of contour points in its local area. The proposed descriptor is evaluated using public datasets of silhouette images, handwritten math expressions, hand-drawn diagram sketches, and noisy scanned logos. Experimental results show that the proposed descriptor compares strongly against state of the art methods, and that it is reliable when applied on challenging images such as fluctuated handwriting and noisy scanned images. Furthermore, we integrate our descriptor in a content-based document image retrieval system using sketch queries as a step for query and candidate occurrence matching, and we show that it leads to a significant boost in retrieval performances.
C1 [Chatbri, Houssem; Little, Suzanne; O'Connor, Noel E.] Dublin City Univ, Insight Ctr Data Analyt, Dublin, Ireland.
   [Kameyama, Keisuke] Univ Tsukuba, Fac Engn Informat & Syst, Tsukuba, Ibaraki, Japan.
   [Kwan, Paul] Univ New England, Sch Sci & Technol, Armidale, NSW, Australia.
C3 Dublin City University; University of Tsukuba; University of New England
RP Chatbri, H (corresponding author), Dublin City Univ, Insight Ctr Data Analyt, Dublin, Ireland.
EM houssem.chatbri@dcu.ie; keisuke.kameyama@cs.tsukuba.ac.jp;
   paul.kwan@une.edu.au; suzanne.little@dcu.ie; noel.oconnor@dcu.ie
RI Kwan, Wing Hing Paul/JQV-6054-2023
OI Kwan, Wing Hing Paul/0000-0002-4959-5274; Little,
   Suzanne/0000-0003-3281-3471; O'Connor, Noel/0000-0002-4033-9135
FU Japanese Government; Irish Research Council (IRC) [GOIPD/2016/61];
   Science Foundation Ireland (SFI) [SFI/12/RC/2289]
FX This work has emanated from a research grant in part from the
   Monbukagakusho Scholarship sponsored by the Japanese Government, in part
   from the Irish Research Council (IRC) under Grant Number GOIPD/2016/61,
   and in part from Science Foundation Ireland (SFI) under Grant Number
   SFI/12/RC/2289 (Insight Centre for Data Analytics). The authors would
   also like to thank Dr. Richard Zanibbi for providing his dataset [56],
   Dr. Mathieu Delalandre and Dr. Alireza Alaei for their assistance with
   extracting logos from the Tobacco 800 dataset, and Dr. Shuang Liang for
   her assistance with her dataset [28].
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   [Anonymous], 2010, P 18 ACM INT C MULT
   [Anonymous], 1999, MODERN INFORM RETRIE
   [Anonymous], INT J COMPUT VIS
   [Anonymous], 2008, PATTERN RECOGNIT
   [Anonymous], INT C DIG IM COMP TE
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Breuss M, 2013, INNOVATIONS SHAPE AN
   Bunke H, 2012, PATTERN RECOGN LETT, V33, P811, DOI 10.1016/j.patrec.2011.04.017
   Cao T.T., 2010, P 2010 ACM SIGGRAPH, P83, DOI 10.1145/1730804.1730818
   Chalechale A, 2005, IEEE T SYSTEMS
   Chatbri H, 2015, PATTERN RECOGNITION
   Chatbri H, 2015, AS C PATT REC ACPR I
   Chatbri H, 2015, INT CONF IMAG PROC, P205, DOI 10.1109/IPTA.2015.7367128
   Demirci MF, 2008, COMPUT VIS IMAGE UND, V110, P312, DOI 10.1016/j.cviu.2007.09.012
   Donoser M, 2010, EFFICIENT PARTIAL SH, P281
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Harris C., 1988, ALVEY VISION C, P147151
   Kopf S, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P478, DOI 10.1109/ICME.2005.1521464
   Laiche N, 2014, SIGNAL PROCESS-IMAGE, V29, P556, DOI 10.1016/j.image.2014.01.009
   Lee S, 2013, IMAGE VISION COMPUT, V31, P357, DOI 10.1016/j.imavis.2013.02.003
   Liang S, 2008, PATTERN RECOGN LETT, V29, P1733, DOI 10.1016/j.patrec.2008.05.004
   Liang S, 2015, IEEE T PATTERN ANAL, V37, P1723, DOI 10.1109/TPAMI.2014.2369031
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Mokhtarian F, 1996, BRIT MACH VIS C BMVC, V96
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pedrosa GV, 2010, PATTERN RECOGN LETT, V31, P1658, DOI 10.1016/j.patrec.2010.05.013
   Pedrosa GV, 2013, NEUROCOMPUTING
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   RICHARDS W, 1985, COMPUT VISION GRAPH, V31, P265, DOI 10.1016/0734-189X(85)90031-3
   Roman-Rangel E, 2015, PATTERN RECOGN, V48, P1161, DOI 10.1016/j.patcog.2014.06.009
   Roman-Rangel E, 2014, LECT NOTES COMPUT SC, V8495, P172, DOI 10.1007/978-3-319-07491-7_18
   ROSENFEL.A, 1966, J ACM, V13, P471
   Roy Davies E, 2004, MACHINE VISION THEOR
   Saha P. K., 2015, PATTERN RECOGNITION
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Sebe N, 2003, IMAGE VISION COMPUT, V21, P1087, DOI 10.1016/j.imavis.2003.08.012
   Sezgin TM, 2007, ACM SIGGRAPH 2007 CO, P36
   Shafait F, 2008, PROC SPIE, V6815, DOI 10.1117/12.767755
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Shuang Liang, 2011, 2011 10th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI-CC 2011), P340, DOI 10.1109/COGINF.2011.6016163
   Song J, 2016, BRIT MACH VIS C BMVC, V3
   Sundar H, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P130, DOI 10.1109/smi.2003.1199609
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Tyler C.W., 2002, HUMAN SYMMETRY PERCE
   Wang Q, 2013, NEUROCOMPUTING, V101, P181, DOI 10.1016/j.neucom.2012.08.012
   Witkin A., 1984, Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP '84, VVolume 9, P150, DOI DOI 10.1109/ICASSP.1984.1172729
   Yang XW, 2012, PATTERN RECOGN, V45, P1927, DOI 10.1016/j.patcog.2011.11.010
   Yu Qian, 2015, ARXIV150107873
   Zanibbi R, 2011, INT C DOC AN REC ICD
   Zhang DH, 2002, LECT NOTES COMPUT SC, V2287, P646
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhao P, 2016, NEUROCOMPUTING, V213, P66, DOI 10.1016/j.neucom.2016.03.098
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
   Zhu G, 2007, PROC INT CONF DOC, P864
NR 61
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28925
EP 28948
DI 10.1007/s11042-018-6054-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500048
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Huang, QH
   Zhang, F
   Li, XL
AF Huang, Qinghua
   Zhang, Fan
   Li, Xuelong
TI Few-shot decision tree for diagnosis of ultrasound breast tumor using
   BI-RADS features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast tumors CAD system; Few-shot learning; BI-RADS; Decision tree
ID COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION; CANCER; MODELS
AB This paper proposes an ultrasound breast tumor CAD system based on BI-RADS features scoring and decision tree algorithm. Because of the difficulty of biopsy label collection, the proposed system adopts a few-shot learning method. The SVM classifier is employed to preliminarily mark the unlabeled cases firstly. Then these unlabeled cases with the pseudo labels are combined with the few real-labeled cases to train the decision tree. To test the performance of the proposed method, 1208 ultrasound breast images were collected, and three well-experienced clinicians and three interns evaluated these images according to the BI-RADS scoring scheme. All of the images are transformed into vectors such that the algorithm can process. The experimental results show that the system performance improves significantly with the help of pseudo-labeled data. Compared to the decision tree trained by the real-labeled cases only, when the number of real-labeled cases was 40, the accuracy, specificity, sensitivity of the proposed system were increased by 2.05%, 2.47% and 1.81%, respectively; the positive predictive value (PPV) and the negative predictive value (NVP) were increased by 1.29% and 3.05%, respectively. Meanwhile, the performance of the proposed method was the same as the method using sufficient samples. When the number of the labeled cases reached 100, the accuracy, specificity, sensitivity, PPV and NVP of the proposed method were 90.03%, 87.02%, 91.68%, 93.07%, and 85.03%, respectively. The results demonstrate that our method can efficiently distinguish the breast tumor although the labeled data is not sufficient.
C1 [Huang, Qinghua] Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.
   [Huang, Qinghua; Zhang, Fan] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Huang, Qinghua] Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China.
   [Huang, Qinghua] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
   [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
C3 Shenzhen University; South China University of Technology; Northwestern
   Polytechnical University; Northwestern Polytechnical University; Chinese
   Academy of Sciences; Xi'an Institute of Optics & Precision Mechanics,
   CAS
RP Huang, QH (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen 518060, Peoples R China.; Huang, QH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.; Huang, QH (corresponding author), Northwestern Polytech Univ, Sch Mech Engn, Xian 710072, Shaanxi, Peoples R China.; Huang, QH (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
EM enicarwhw@qq.com
RI li, xiang/GWM-6319-2022; Li, Xuelong/Z-3785-2019; Li,
   Xuelong/ABF-3381-2020
OI Li, Xuelong/0000-0002-0019-4197
FU National Natural Science Foundation of China [61372007, 61571193];
   Guangzhou Key Lab of Body Data Science [201605030011]; Natural Science
   Foundation of Guangdong Province, China [2017A030312006,
   2015A030313210]; Fundamental Research Funds for the Central Universities
   [2015ZM138]; Project of Science and Technology Department of Guangdong
   province [2014A050503020, 2016A010101021, 2016A010101022,
   2016A010101023]; Science and Technology Program of Guangzhou
   [201704020134]
FX This work was partially supported by National Natural Science Foundation
   of China (Nos. 61372007 and 61571193), Guangzhou Key Lab of Body Data
   Science (No. 201605030011), Natural Science Foundation of Guangdong
   Province, China (Nos. 2017A030312006 and 2015A030313210), Fundamental
   Research Funds for the Central Universities (NO. 2015ZM138), Project of
   Science and Technology Department of Guangdong province (2014A050503020,
   2016A010101021, 2016A010101022 and 2016A010101023), Science and
   Technology Program of Guangzhou (no. 201704020134).
CR Aminikhanghahi S, 2017, MULTIMED TOOLS APPL, V76, P10191, DOI 10.1007/s11042-016-3605-x
   DeSantis C, 2014, CA-CANCER J CLIN, V64, P52, DOI 10.3322/caac.21203
   Feng XF, 2017, APPL SCI-BASEL, V7, DOI [10.3390/app7010037, 10.3390/atmos7030037]
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Han JW, 2015, IEEE T CYBERNETICS, V45, P1692, DOI 10.1109/TCYB.2014.2358647
   Huang Q, 2017, COMPUT METH PROG BIO, V156, P73
   Huang QH, 2017, INT J COMPUT ASS RAD, V12, P493, DOI 10.1007/s11548-016-1513-1
   Huang QH, 2015, INFORM SCIENCES, V314, P293, DOI 10.1016/j.ins.2014.08.021
   Jesneck JL, 2007, RADIOLOGY, V244, P390, DOI 10.1148/radiol.2442060712
   Kim J, 2013, J AM MED INFORM ASSN, V20, P613, DOI 10.1136/amiajnl-2012-001570
   Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3
   Liu JW, 2017, MULTIMED TOOLS APPL, V76, P6595, DOI 10.1007/s11042-016-3342-1
   Liu X, 2014, IEEE ENG MED BIO, P4679, DOI 10.1109/EMBC.2014.6944668
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Luo YZ, 2017, BIOMED RES INT-UK, V2017, DOI 10.1155/2017/9157341
   Nothacker M, 2009, BMC CANCER, V9, DOI 10.1186/1471-2407-9-335
   Prabusankarlal KM, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0029-y
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Shan J, 2016, ULTRASOUND MED BIOL, V42, P980, DOI 10.1016/j.ultrasmedbio.2015.11.016
   Shen WC, 2007, ACAD RADIOL, V14, P928, DOI 10.1016/j.acra.2007.04.016
   Shi J, 2016, NEUROCOMPUTING, V194, P87, DOI 10.1016/j.neucom.2016.01.074
   Su Y, 2010, C PHD RES MICR EL 18, P1
   Tang J, 2014, COMPUT VIS IMAGE UND, V124, P91, DOI 10.1016/j.cviu.2014.02.007
   Tu EM, 2015, NEUROCOMPUTING, V157, P173, DOI 10.1016/j.neucom.2015.01.020
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang GS, 2015, MULTIMED TOOLS APPL, V74, P3783, DOI 10.1007/s11042-013-1799-8
   Zhang Q, 2016, ULTRASONICS, V72, P150, DOI 10.1016/j.ultras.2016.08.004
   Zhang R, 2017, INT CONF ACOUST SPEE, P2417, DOI 10.1109/ICASSP.2017.7952590
   Zhou SC, 2013, BIOMED SIGNAL PROCES, V8, P688, DOI 10.1016/j.bspc.2013.06.011
NR 32
TC 12
Z9 13
U1 3
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29905
EP 29918
DI 10.1007/s11042-018-6026-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800041
DA 2024-07-18
ER

PT J
AU Li, XL
   Yuan, AH
   Lu, XQ
AF Li, Xuelong
   Yuan, Aihong
   Lu, Xiaoqiang
TI Multi-modal gated recurrent units for image description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image description; Gated recurrent unit; Convolutional neural network;
   Multi-modal embedding
ID BACKPROPAGATION; RETRIEVAL
AB Using a natural language sentence to describe the content of an image is a challenging but very important task. It is challenging because a description must not only capture objects contained in the image and the relationships among them, but also be relevant and grammatically correct. In this paper a multi-modal embedding model based on gated recur-rent units (GRU) which can generate variable-length description for a given image. In the training step, we apply the convolutional neural network (CNN) to extract the image feature. Then the feature is imported into the multi-modal GRU as well as the corresponding sentence representations. The multi-modal GRU learns the inter-modal relations between image and sentence. And in the testing step, when an image is imported to our multi-modal GRU model, a sentence which describes the image content is generated. The experimental results demonstrate that our multi-modal GRU model obtains the state-of-the-art performance on Flickr8K, Flickr30K and MS COCO datasets.
C1 [Li, Xuelong; Yuan, Aihong; Lu, Xiaoqiang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710119, Shaanxi, Peoples R China.
   [Li, Xuelong; Yuan, Aihong] Univ Chinese Acad Sci, 19A Yuquanlu, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710119, Shaanxi, Peoples R China.
EM xuelong_li@opt.ac.cn; ahyuan@opt.ac.cn; luxq666666@gmail.com
RI Li, Xuelong/ABF-3381-2020; li, xiang/GWM-6319-2022; Li,
   Xuelong/Z-3785-2019
OI Lu, Xiaoqiang/0000-0002-7037-5188; Li, Xuelong/0000-0002-0019-4197
FU National Natural Science Foundation of China [61772510, 61761130079,
   61472413]; Key Research Program of Frontier Sciences, CAS
   [QYZDY-SSW-JSC044]; Young Top-notch Talent Program of Chinese Academy of
   Sciences [QYZDB-SSW-JSC015]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61761130079, in part by the Key Research
   Program of Frontier Sciences, CAS under Grant QYZDY-SSW-JSC044, in part
   by the National Natural Science Foundation of China under Grant
   61472413, in part by the National Natural Science Foundation of China
   under Grant 61772510, and in part by the Young Top-notch Talent Program
   of Chinese Academy of Sciences under Grant QYZDB-SSW-JSC015.
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], 2012, P INT C NEUR INF PRO
   [Anonymous], STAT ANAL MANAGEMENT
   [Anonymous], IEEE GEOSCI REMOTE S
   [Anonymous], COMPUT RES REPOS COR
   [Anonymous], T ASS COMPUT LINGUIS
   [Anonymous], P INT C LEARN REPR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2017, CORR
   [Anonymous], 2017, P IEEE, DOI DOI 10.1109/JPROC.2017.2675998
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], P ANN C INT SPEECH C
   [Anonymous], 2004, P 20 INT C COMP LING
   [Anonymous], P INT C ART INT STAT
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chen WZ, 2017, IEEE IJCNN, P1403, DOI 10.1109/IJCNN.2017.7966017
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Chung J., 2015, CoRR, Vabs/1506.02216
   Chung Junyoung, 2014, ARXIV14123555
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fairbank M, 2013, IEEE T NEUR NET LEAR, V24, P2088, DOI 10.1109/TNNLS.2013.2271778
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Greff K., 2015, ARXIV150304069
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jia YQ, 2011, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2011.6126524
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301
   Mao Junhua, 2015, P INT C LEARN REPR
   Mikolov T., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P196, DOI 10.1109/ASRU.2011.6163930
   Mnih A., 2007, P 24 INT C MACH LEAR, P641, DOI [DOI 10.1145/1273496.1273577, 10.1145/1273496.1273577]
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salakhutdinov R., 2009, AISTATS
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Socher R., 2011, NIPS'11 Proceedings of the 24th International Conference on Neural Information Processing Systems, V24, P801
   Sutskever I, 2014, ADV NEUR IN, V27
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhang Linguang., 2017, CoRR
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zitnick C.L., 2014, ARXIV14115654
NR 71
TC 16
Z9 17
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29847
EP 29869
DI 10.1007/s11042-018-5856-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800038
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, HN
   Miao, YQ
AF Wang, Hainan
   Miao, Yunqi
TI The random boosting ensemble classifier for land-use image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boosting; Ensemble learning; Classifier; Few-shot learning
ID EXTREME LEARNING-MACHINE; SCENE CLASSIFICATION; TEXTURE; RECOGNITION
AB This paper presents a random boosting ensemble (RBE) classifier for remote sensing image classification, which introduces the random projection feature selection and bootstrap methods to obtain base classifiers for classifier ensemble. The RBE method is built based on an improved boosting framework, which is quite efficient for the few-shot problem due to the bootstrap in use. In RBE, kernel extreme machine (KELM) is applied to design base classifiers, which actually make RBE quite efficient due to feature reduction. The experimental results on the remote scene image classification demonstrate that RBE can effectively improve the classification performance, and resulting into a better generalization ability on the 21-class land-use dataset and the India pine satellite scene dataset.
C1 [Wang, Hainan; Miao, Yunqi] Beihang Univ, Sch Automat Sci & Elect Engn, 37 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Wang, Hainan] Guizhou Univ, Sch Mech Engn, Guiyang 550025, Guizhou, Peoples R China.
C3 Beihang University; Guizhou University
RP Wang, HN (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, 37 Xueyuan Rd, Beijing 100083, Peoples R China.; Wang, HN (corresponding author), Guizhou Univ, Sch Mech Engn, Guiyang 550025, Guizhou, Peoples R China.
EM 350715910@qq.com
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Aksoy S, 2005, IEEE T GEOSCI REMOTE, V43, P581, DOI 10.1109/TGRS.2004.839547
   [Anonymous], ISPRS J PHOTOGRAMMET
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen C, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P324, DOI 10.1109/BigMM.2015.23
   Chunhua Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2585, DOI 10.1109/CVPR.2011.5995554
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Ding GG, 2018, IEEE T INTELL TRANSP, V19, P140, DOI 10.1109/TITS.2017.2774778
   Dos Santos Jefersson Alex, 2013, 2013 26th Conference on Graphics, Patterns and Images - Tutorials (SIBGRAPI-T), P23, DOI 10.1109/SIBGRAPI-T.2013.11
   dos Santos JA, 2012, INT C PATT RECOG, P3090
   dos Santos JA, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P203
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang L., 2017, MULTIMEDIA TOOLS APP
   Huang LH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060483
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Yu Q, 2006, PHOTOGRAMM ENG REM S, V72, P799, DOI 10.14358/PERS.72.7.799
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang BC, 2017, IEEE T SYST MAN CY-S, V47, P693, DOI 10.1109/TSMC.2016.2629509
   Zhang BC, 2017, IEEE T CIRC SYST VID, V27, P1515, DOI 10.1109/TCSVT.2016.2540978
   Zhang BC, 2016, INT J COMPUT VISION, V118, P364, DOI 10.1007/s11263-016-0880-y
   Zhang JP, 2015, INT GEOSCI REMOTE SE, P1012, DOI 10.1109/IGARSS.2015.7325940
   Zhao SD, 2016, NEUROCOMPUTING, V173, P1943, DOI 10.1016/j.neucom.2015.09.066
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao YD, 2007, IEEE T GEOSCI REMOTE, V45, P1458, DOI 10.1109/TGRS.2007.892602
NR 32
TC 2
Z9 2
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29933
EP 29947
DI 10.1007/s11042-018-6085-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800043
DA 2024-07-18
ER

PT J
AU Zheng, YH
   Li, M
   Zhang, JW
   Wang, J
AF Zheng, Yuhui
   Li, Min
   Zhang, Jianwei
   Wang, Jin
TI Selection of regularization parameter in GMM based image denoising
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Gaussian mixture model; Regularization parameter
   selection; Lagrange multiplier method
ID TOTAL VARIATION MODEL; SPARSE
AB Currently, the image denoising methods using Gaussian mixture model to learn image prior have received much attention. Among these methods, expected patch log likelihood based image denoising approach has been shown to be surprisingly competitive in image restoration. However, recent related works generally utilize global regularization parameter that influences the performance of denoising algorithm. In this paper, with the consideration that the Gaussian mixture model has the capability of clustering, we propose an adaptive estimation method of regularization parameter for expected patch log likelihood based image denoising. Our method jointly employs the Lagrange multiplier technique and entropy concept to select regularization parameter for each underlying cluster. Experimental results illustrate the relatively good performance of our image denoising method in terms of visual improvement and peak signal to noise ratio.
C1 [Zheng, Yuhui; Li, Min] Nanjing Univ Informat Sci &Technol, Coll Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhang, Jianwei] Nanjing Univ Informat Sci & Technol, Coll Math & Stat, Nanjing 210044, Jiangsu, Peoples R China.
   [Wang, Jin] Yangzhou Univ, Coll Informat Engn, Yangzhou 215127, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Yangzhou University
RP Wang, J (corresponding author), Yangzhou Univ, Coll Informat Engn, Yangzhou 215127, Jiangsu, Peoples R China.
EM zheng_yuhui@nuist.edu.cn; limin_513@126.com; zhangjw@nuist.edu.cn;
   jinwang@yzu.edu.cn
RI Wang, Jin/AAI-7009-2020; Zheng, Yuhui/AAF-2420-2019
OI Wang, Jin/0000-0001-5473-8738; 
FU National Natural Science Foundation of China [61572257, 61672295];
   Natural Science Fund for Colleges and Universities in Jiangsu Province
   [15KJB520025]; PAPD - (priority academic program development of Jiangsu
   Higher Education Institutions)
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61572257 and 61672295, the Natural Science Fund for
   Colleges and Universities in Jiangsu Province (15KJB520025), and the
   PAPD (a project funded by the priority academic program development of
   Jiangsu Higher Education Institutions).
CR Buades A, 2009, IEEE T IMAGE PROCESS, V18, P1192, DOI 10.1109/TIP.2009.2017171
   Chen K, 2014, NUMER ALGORITHMS, V67, P73, DOI 10.1007/s11075-013-9775-y
   Dong YQ, 2011, J MATH IMAGING VIS, V40, P82, DOI 10.1007/s10851-010-0248-9
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2281, DOI 10.1109/TIP.2006.875247
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Izmailov AF, 2015, MATH PROGRAM, V152, P33, DOI 10.1007/s10107-014-0777-x
   Jeong S, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0122-5
   Koo KM, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0114-5
   Lee I, 2017, J INF PROCESS SYST, V13, P256, DOI 10.3745/JIPS.02.0057
   Lou YF, 2010, J SCI COMPUT, V42, P185, DOI 10.1007/s10915-009-9320-2
   Lu X, 2015, IEEE T IMAGE PROCESS, V24, P5469, DOI 10.1109/TIP.2015.2473098
   González-de-Suso JL, 2014, IEEE T CIRC SYST VID, V24, P452, DOI 10.1109/TCSVT.2013.2276857
   Niknejad M, 2015, IEEE T IMAGE PROCESS, V24, P3624, DOI 10.1109/TIP.2015.2447836
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Park JH, 2017, J INF PROCESS SYST, V13, P1431, DOI 10.3745/JIPS.00.0008
   Ren J, 2013, IEEE T IMAGE PROCESS, V22, P1454, DOI 10.1109/TIP.2012.2231690
   Rezghi M, 2009, J COMPUT APPL MATH, V231, P914, DOI 10.1016/j.cam.2009.05.016
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Su ZM, 2017, ELECTRON LETT, V53, P717, DOI 10.1049/el.2016.3515
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P1770, DOI 10.1109/TIP.2011.2181401
   Xiao F, 2018, IEEE T VEH TECHNOL, V67, P2409, DOI 10.1109/TVT.2017.2771805
   Yan RM, 2013, IEEE T IMAGE PROCESS, V22, P4689, DOI 10.1109/TIP.2013.2277813
   Yang ZL, 2013, IEEE T IMAGE PROCESS, V22, P3192, DOI 10.1109/TIP.2012.2216278
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yuan QQ, 2010, IEEE T IMAGE PROCESS, V19, P3157, DOI 10.1109/TIP.2010.2055571
   Zeng Y.-H., 2016, J INEQUAL APPL, V2016, P1, DOI DOI 10.1016/J.EXER.2016.05.002
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang JW, 2017, MULTIMED TOOLS APPL, V76, P11471, DOI 10.1007/s11042-016-4214-4
   Zhang JW, 2016, J INTERNET TECHNOL, V17, P1117, DOI 10.6138/JIT.2016.17.6.20160603
   Zheng YH, 2018, IEEE T CIRC SYST VID, V28, P2586, DOI 10.1109/TCSVT.2017.2724940
   Zheng YH, 2017, J INTERNET TECHNOL, V18, P1553, DOI 10.6138/JIT.2017.18.7.20161120
   Zheng YH, 2017, J INF PROCESS SYST, V13, P1168, DOI 10.3745/JIPS.02.0072
   Zheng YH, 2015, ELECTRON LETT, V51, P144, DOI 10.1049/el.2014.3494
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 36
TC 5
Z9 5
U1 1
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 30121
EP 30134
DI 10.1007/s11042-018-6360-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800054
DA 2024-07-18
ER

PT J
AU Akbari, M
   Liang, J
   Cheng, H
AF Akbari, Mohammad
   Liang, Jie
   Cheng, Howard
TI A real-time system for online learning-based visual transcription of
   piano music
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music information retrieval; Real-time piano music transcription; Image
   and video processing; Convolutional neural networks; Support vector
   machines; Online learning
ID FUNDAMENTAL-FREQUENCY ESTIMATION; HARMONICITY; MODEL
AB In order to deal with the challenges arising from acoustic-based music information retrieval such as automatic music transcription, the video of the musical performances can be utilized. In this paper, a new real-time learning-based system for visually transcribing piano music using the CNN-SVM classification of the pressed black and white keys is presented. The whole process in this technique is based on visual analysis of the piano keyboard and the pianist's hands and fingers. A high accuracy with an average F-1 score of 0.95 even under non-ideal camera view, hand coverage, and lighting conditions is achieved. The proposed system has a low latency (about 20 ms) in real-time music transcription. In addition, a new dataset for visual transcription of piano music is created and made available to researchers in this area. Since not all possible varying patterns of the data used in our work are available, an online learning approach is applied to efficiently update the original model based on the new data added to the training dataset.
C1 [Akbari, Mohammad; Liang, Jie] Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Burnaby, BC, Canada.
   [Cheng, Howard] Univ Lethbridge, Dept Math & Comp Sci, 4401 Univ Dr, Lethbridge, AB, Canada.
C3 Simon Fraser University; University of Lethbridge
RP Akbari, M (corresponding author), Simon Fraser Univ, Sch Engn Sci, 8888 Univ Dr, Burnaby, BC, Canada.
EM akbari@sfu.ca; jiel@sfu.ca; howard.cheng@uleth.ca
RI akbari, mohammad/ADF-5801-2022
OI Liang, Jie/0000-0003-3003-4343
FU Natural Sciences and Engineering Research Council (NSERC) of Canada
   [RGPIN312262, STPGP447223, RGPAS478109, RGPIN288300]
FX This work was supported by the Natural Sciences and Engineering Research
   Council (NSERC) of Canada under grant RGPIN312262, STPGP447223,
   RGPAS478109, and RGPIN288300.
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   Akbari M., 2014, THESIS U LETHBRIDGE
   Akbari M, 2016, US Patent, Patent No. [9,418,637, 9418637]
   Akbari M, 2015, P INT C NEW INT MUS, P313
   Akbari M, 2015, IEEE T MULTIMEDIA, V17, P2113, DOI 10.1109/TMM.2015.2473702
   Baniya BK, 2016, MULTIMED TOOLS APPL, V75, P3013, DOI 10.1007/s11042-014-2418-z
   Baur D, 2010, IEEE T VIS COMPUT GR, V16, P1119, DOI 10.1109/TVCG.2010.206
   Bazzica A, 2016, COMPUT VIS IMAGE UND, V144, P188, DOI 10.1016/j.cviu.2015.09.009
   Ben-Hur A, 2010, METHODS MOL BIOL, V609, P223, DOI 10.1007/978-1-60327-241-4_13
   Benetos E, 2013, J INTELL INF SYST, V41, P407, DOI 10.1007/s10844-013-0258-3
   Benetos E, 2012, COMPUT MUSIC J, V36, P81, DOI 10.1162/COMJ_a_00146
   Benetos Emmanouil., 2015, Proc. International Computer Music Conference, P701
   Bertin N, 2010, IEEE T AUDIO SPEECH, V18, P538, DOI 10.1109/TASL.2010.2041381
   Böck S, 2012, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2012.6287832
   Borjian N, 2018, MULTIMED TOOLS APPL, V77, P6165, DOI 10.1007/s11042-017-4524-1
   Brown S, 2006, J CONSCIOUSNESS STUD, V13, P43
   Cao XZ, 2015, MULTIMED TOOLS APPL, V74, P9097, DOI 10.1007/s11042-014-2057-4
   Cemgil AT, 2006, IEEE T AUDIO SPEECH, V14, P679, DOI 10.1109/TSA.2005.852985
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang HY, 2017, MULTIMED TOOLS APPL, V76, P19523, DOI 10.1007/s11042-015-3202-4
   Corrêa DC, 2016, EXPERT SYST APPL, V60, P190, DOI 10.1016/j.eswa.2016.04.008
   DANNENBERG RB, 1993, COMPUT MUSIC J, V17, P20, DOI 10.2307/3680940
   Davy M, 2003, BAYESIAN STATISTICS 7, P105
   Downie JS, 2003, ANNU REV INFORM SCI, V37, P295, DOI 10.1002/aris.1440370108
   Duan ZY, 2010, IEEE T AUDIO SPEECH, V18, P2121, DOI 10.1109/TASL.2010.2042119
   Farquad MAH, 2012, DECIS SUPPORT SYST, V53, P226, DOI 10.1016/j.dss.2012.01.016
   Frisson Christian., 2009, QPSR NUMEDIART RES P, V2, P67
   Geng MY, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P186, DOI 10.1109/BigMM.2016.19
   Gorodnichy D.O., 2006, The 3rd Canadian Conference on Computer and Robot Vision, P63
   Gutiérrez S, 2016, MULTIMED TOOLS APPL, V75, P16905, DOI 10.1007/s11042-015-2963-0
   Karpathy A., 2016, CONVNETSHARP
   Katarya R, 2018, MULTIMED TOOLS APPL, V77, P2673, DOI 10.1007/s11042-017-4447-x
   Klapuri AP, 2004, J NEW MUSIC RES, V33, P269, DOI 10.1080/0929821042000317840
   Klapuri AP, 2003, IEEE T SPEECH AUDI P, V11, P804, DOI 10.1109/TSA.2003.815516
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Laskov P, 2006, J MACH LEARN RES, V7, P1909
   Lin CJ, 2008, J MACH LEARN RES, V9, P627
   Maler Anabel., 2013, Music Theory Online, V19, P1, DOI [10.30535/mto.19.1.4, DOI 10.30535/MTO.19.1.4]
   Nanni L, 2016, EXPERT SYST APPL, V45, P108, DOI 10.1016/j.eswa.2015.09.018
   Oka A, 2013, KOR-JPN JT WORKS FR, P1, DOI 10.1109/FCV.2013.6485449
   Paleari M, 2008, IEEE IMAGE PROC, P93, DOI 10.1109/ICIP.2008.4711699
   Peeling PH, 2011, IEEE J-STSP, V5, P1133, DOI 10.1109/JSTSP.2011.2158804
   Pertusa A, 2005, PATTERN RECOGN LETT, V26, P1809, DOI 10.1016/j.patrec.2005.03.001
   Poast M, 2000, LEONARDO, V33, P215, DOI 10.1162/002409400552531
   Quested G, 2008, P INT COMP MUS C ICM
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reboursiere L, 2010, P NEW INT MUS EXPR N
   Scarr J., 2010, 25th International Conference of Image and Vision Computing New Zealand (IVCNZ), P1
   Schindler A., 2016, ACM T INTEL SYST TEC, V8, P20
   Seger RA, 2014, EXPERT SYST APPL, V41, P2098, DOI 10.1016/j.eswa.2013.09.009
   Sigtia S, 2016, IEEE-ACM T AUDIO SPE, V24, P927, DOI 10.1109/TASLP.2016.2533858
   Sigtia S, 2015, INT CONF ACOUST SPEE, P2061, DOI 10.1109/ICASSP.2015.7178333
   Sotirios M., 2008, Proceedings of the 10th International Conference on Information Integration and Web-based Applications Services, iiWAS '08, P604
   Stober S, 2013, MULTIMED TOOLS APPL, V65, P467, DOI 10.1007/s11042-012-1042-z
   Suteparuk P, 2014, TECH REP
   Tavares T. Fernandes, 2013, J BRAZ COMPUT SOC, V19, P589, DOI DOI 10.1007/s13173-013-0118-6
   Tavares TF, 2012, IEEE INT WORKSH MULT, P215, DOI 10.1109/MMSP.2012.6343443
   Taweewat P, 2013, EXPERT SYST APPL, V40, P575, DOI 10.1016/j.eswa.2012.07.063
   Thompson WF, 2005, SEMIOTICA, V156, P203, DOI 10.1515/semi.2005.2005.156.203
   Tsai CH, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P343, DOI 10.1145/2623330.2623661
   Yoshii K, 2012, IEEE T AUDIO SPEECH, V20, P717, DOI 10.1109/TASL.2011.2164530
   Zhang B, 2009, TRA709 NAT U SING SC
   Zhang Bingjun., 2007, P ACM INT C MULT, P521
NR 63
TC 7
Z9 7
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25513
EP 25535
DI 10.1007/s11042-018-5803-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400040
DA 2024-07-18
ER

PT J
AU Cabañas-Molero, P
   Lucena, M
   Fuertes, JM
   Vera-Candeas, P
   Ruiz-Reyes, N
AF Cabanas-Molero, P.
   Lucena, M.
   Fuertes, J. M.
   Vera-Candeas, P.
   Ruiz-Reyes, N.
TI Multimodal speaker diarization for meetings using volume-evaluated
   SRP-PHAT and video analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker diarization; Meeting rooms; SRP-PHAT; Multimodal processing
ID SOUND SOURCE LOCALIZATION; VOICE ACTIVITY DETECTION; MICROPHONE ARRAYS
AB Speaker diarization is traditionally defined as the problem of determining "who speaks when" given an audio or video stream. This is an important task in many applications for meeting rooms, including automatic transcription of conversations, camera steering or content summarization. When the room is equipped with microphone arrays and cameras, speakers can be distinguished according to their location and the problem can be addressed through localization techniques. This article proposes a multimodal speaker diarization system for meeting environments based on a modified SRP-PHAT function evaluated on space volumes rather than discrete points. In our system, this function is used in combination with a circular array, enabling audio-based localization based on the selection of local maxima. Voicing detection is used to detect speech frames, whereas video analysis is introduced to aid in the decision when users move or simultaneously speak. The approach is evaluated on the well-known AMI dataset with approximately 100 hours of realistic meeting recordings and shows an average diarization error rate of 21% - 25%.
C1 [Cabanas-Molero, P.; Vera-Candeas, P.; Ruiz-Reyes, N.] Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
   [Lucena, M.; Fuertes, J. M.] Univ Jaen, Dept Comp Sci, Jaen, Spain.
C3 Universidad de Jaen; Universidad de Jaen
RP Cabañas-Molero, P (corresponding author), Univ Jaen, Dept Telecommun Engn, Jaen, Spain.
EM pcabanas@ujaen.es; mlucena@ujaen.es; jmf@ujaen.es; pvera@ujaen.es;
   nicolas@ujaen.es
RI Vera-Candeas, Pedro/L-3428-2014; Lucena, Manuel/I-6467-2018; Fuertes
   Garcia, Jose Manuel/I-8008-2018; Cabanas-Molero, Pablo/I-1844-2015; Ruiz
   Reyes, Nicolas/R-5878-2018
OI Vera-Candeas, Pedro/0000-0003-0866-703X; Lucena,
   Manuel/0000-0002-5546-3745; Fuertes Garcia, Jose
   Manuel/0000-0001-6624-4102; Cabanas-Molero, Pablo/0000-0002-2452-6037;
   Ruiz Reyes, Nicolas/0000-0003-4631-5326
FU Andalusian Economy and Knowledge Council [2010-TIC6762]; Spanish
   Ministry of Economy and Competitiveness [TEC2015-67387-C4-2-R]
FX This work was supported by the Andalusian Economy and Knowledge Council
   under project 2010-TIC6762, and the Spanish Ministry of Economy and
   Competitiveness under project TEC2015-67387-C4-2-R.
CR Ajmera J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P605
   Miro XA, 2012, IEEE T AUDIO SPEECH, V20, P356, DOI 10.1109/TASL.2011.2125954
   [Anonymous], P INTERSPEECH
   [Anonymous], IEEE T COMPUTERS
   [Anonymous], P INTERSPEECH
   Araki S, 2016, INT CONF ACOUST SPEE, P385, DOI 10.1109/ICASSP.2016.7471702
   Araki S, 2010, CONF REC ASILOMAR C, P1697, DOI 10.1109/ACSSC.2010.5757829
   Aubrey Andrew, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2409
   Biagetti G, 2016, ROBUST SPEAKER IDENT, P465
   Blauth DA, 2012, PATTERN RECOGN LETT, V33, P373, DOI 10.1016/j.patrec.2011.09.002
   Carletta J, 2005, LECT NOTES COMPUT SC, V3869, P28
   Cha Z, 2008, IEEE T MULTIMEDIA, V10, P538, DOI 10.1109/TMM.2008.917406
   Cobos M, 2011, IEEE SIGNAL PROC LET, V18, P71, DOI 10.1109/LSP.2010.2091502
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   DiBiase J. H., 2000, Ph.D. thesis
   Do H, 2007, INT CONF ACOUST SPEE, P121
   Fredouille C, 2009, RT 09 NIST RICH TRAN, V15, P17
   Friedland G, 2012, IEEE T AUDIO SPEECH, V20, P371, DOI 10.1109/TASL.2011.2158419
   Friedland G, 2009, INT CONF ACOUST SPEE, P4069, DOI 10.1109/ICASSP.2009.4960522
   Fujimoto M, 2009, P INT 2009, P1235
   Gebru ID, 2018, IEEE T PATTERN ANAL, V40, P1086, DOI 10.1109/TPAMI.2017.2648793
   Ghaemmaghami H, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P3118
   Gonzalez S, 2014, IEEE-ACM T AUDIO SPE, V22, P518, DOI 10.1109/TASLP.2013.2295918
   Hori T, 2012, IEEE T AUDIO SPEECH, V20, P499, DOI 10.1109/TASL.2011.2164527
   Hung H, 2008, WORKSH MULT CAM MULT
   Liu Q., 2011, SENSOR SIGNAL PROCES, P1
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Marti A, 2011, INT CONF ACOUST SPEE, P2592
   McCowan Iain, 2005, Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, V88
   Minotto VP, 2014, IEEE T MULTIMEDIA, V16, P1032, DOI 10.1109/TMM.2014.2305632
   Minotto VP, 2013, IEEE J-STSP, V7, P147, DOI 10.1109/JSTSP.2012.2237379
   Minotto VP, 2015, IEEE T MULTIMEDIA, V17, P1694, DOI 10.1109/TMM.2015.2463722
   Noulas A, 2012, IEEE T PATTERN ANAL, V34, P79, DOI 10.1109/TPAMI.2011.47
   Rozgic Viktor, 2010, Journal of Multimedia, V5, P322, DOI 10.4304/jmm.5.4.322-331
   Sarafianos N, 2016, MULTIMED TOOLS APPL, V75, P115, DOI 10.1007/s11042-014-2274-x
   Scott D, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P80, DOI 10.1109/ISM.2009.41
   Soldi G, 2015, EUR SIGNAL PR CONF, P2112, DOI 10.1109/EUSIPCO.2015.7362757
   Tiawongsombat P, 2012, PATTERN RECOGN, V45, P783, DOI 10.1016/j.patcog.2011.07.011
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wellner Pierre., 2004, International Workshop on Machine Learning for Multimodal Interaction, P12
   Wooters C, 2008, LECT NOTES COMPUT SC, V4625, P509
   Zhang C, 2007, INT CONF ACOUST SPEE, P125
   Zhang C, 2006, 2006 IEEE Workshop on Multimedia Signal Processing, P86, DOI 10.1109/MMSP.2006.285274
NR 44
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27685
EP 27707
DI 10.1007/s11042-018-5944-2
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500064
DA 2024-07-18
ER

PT J
AU Liu, JW
   Gu, YL
   Kamijo, S
AF Liu, Jingwen
   Gu, Yanlei
   Kamijo, Shunsuke
TI Integral customer pose estimation using body orientation and visibility
   mask
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pose estimation; Body orientation; Visibility mask; Deep neural network;
   Surveillance camera
AB The analysis of customer pose is one of the most important topics for marketing. Using the customer pose information, the retailers can evaluate the customer interest level to the merchandise. However, the pose estimation is not easy because of the problems of occlusion and left-right similarity. To address these two problems, we propose an Integral Pose Network (IntePoseNet) which incorporates the body orientation and visibility mask. Firstly, benefiting from the simple gaits in retail store, the body orientation can give the global information of pose configuration. For example, if a person is facing to right, the body orientation indicates the occlusion of his or her left body. Similarly, if a person is facing to the camera, his or her right shoulder is probably at the left side of image. The body orientation is fused with local joint connections by a set of novel Orientational Message Passing (OMP) layers in Deep Neural Network. Secondly, the visibility mask models the occlusion state of each joint. It is tightly related to the body orientation because the body orientation is the main reason of self-occlusion. In addition, occluding object (e.g. shopping basket in retail store environment) detection can also give the clues of visibility mask prediction. Furthermore, the system models the temporal consistency by introducing the optical flow and Bi-directional Recurrent Neural Network. Therefore, the global body orientation, local joint connections, customer motion, occluding objects and temporal consistency are integrally considered in our system. At last, we conduct a series of comparison experiments to show the effectiveness of our system.
C1 [Liu, Jingwen] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Gu, Yanlei; Kamijo, Shunsuke] Univ Tokyo, Inst Ind Sci, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo
RP Liu, JW (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
EM ljwqq0@kmj.iis.u-tokyo.ac.jp; guyanlei@kmj.iis.u-tokyo.ac.jp;
   kamijo@iis.u-tokyo.ac.jp
RI jingwen, liu/B-5167-2014; Gu, Yanlei/GSJ-3642-2022
CR Achilles Felix, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P491, DOI 10.1007/978-3-319-46720-7_57
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], P WORKSH MULT US AUT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ARXIV170310898
   [Anonymous], P INT C COMP GRAPH V
   [Anonymous], 1995, CONVOLUTIONAL NETWOR
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2014, AS C COMP VIS SING N
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], 2014, P ADV NEUR INF PROC
   Azizpour H, 2012, LECT NOTES COMPUT SC, V7572, P836, DOI 10.1007/978-3-642-33718-5_60
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Chen XJ, 2015, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2015.7299020
   Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eichner M., 2012, P ACCV, P138
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Haque A, 2016, LECT NOTES COMPUT SC, V9905, P160, DOI 10.1007/978-3-319-46448-0_10
   Iqbal U, 2017, IEEE INT CONF AUTOMA, P438, DOI 10.1109/FG.2017.61
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Johnson S., 2010, BMVC
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Liu JW, 2017, MULTIMED TOOLS APPL, V76, P6595, DOI 10.1007/s11042-016-3342-1
   Liu ZK, 2017, MULTIMED TOOLS APPL, V76, P26675, DOI 10.1007/s11042-016-4193-5
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   Park Dennis, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P58, DOI 10.1109/CVPRW.2015.7301337
   Pfister T, 2015, IEEE I CONF COMP VIS, P1913, DOI 10.1109/ICCV.2015.222
   Pishchulin L, 2013, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2013.82
   Rafi Umer, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P67, DOI 10.1109/CVPRW.2015.7301338
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yao J, 2007, P IEEE INT C COMPUTE, P1
NR 48
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26107
EP 26134
DI 10.1007/s11042-018-5839-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400064
DA 2024-07-18
ER

PT J
AU Ouni, A
   Urruty, T
   Visani, M
AF Ouni, Achref
   Urruty, Thierry
   Visani, Muriel
TI A robust CBIR framework in between bags of visual words and phrases
   models for specific image datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image representation; CBIR; Bag of visual words; Visual phrases; Expert
   dataset
AB One objective of the Content Based Image Retrieval research field is to propose new methodologies and tools to manage the increasing number of images available. Linked to a specific context of small expert datasets without prior knowledge, our research work focuses on improving the discriminative power of the image representation while keeping the same efficiency for retrieval. Based on the well-known bag of visual words model, we propose three different methodologies inspired by the visual phrase model effectiveness and a compression technique which ensures the same effectiveness for retrieval than the BoVW model. Our experimental results study the performance of our proposals on different well known benchmark datasets and show its good performance compared to other recent approaches.
C1 [Ouni, Achref; Urruty, Thierry] Univ Poitiers, CNRS, XLIM, UMR 7252, Poitiers, France.
   [Visani, Muriel] Univ La Rochelle, Lab L3i, Rochelle, France.
   [Visani, Muriel] Univ Sci & Technol Hanoi, Vietnam France ICT Lab, Hanoi, Vietnam.
   [Visani, Muriel] Univ Bordeaux, Lab LaBRI, Bordeaux, France.
C3 Universite de Poitiers; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS); La
   Rochelle Universite; Vietnam Academy of Science & Technology (VAST);
   University of Science & Technology of Hanoi (USTH); Universite de
   Bordeaux
RP Urruty, T (corresponding author), Univ Poitiers, CNRS, XLIM, UMR 7252, Poitiers, France.
EM achref.el.ouni@outlook.fr; thierry.urruty@xlim.fr;
   muriel.visani@univ-lr.fr
RI Ouni, Achref/GLT-3092-2022
OI Ouni, Achref/0000-0002-1197-253X; Urruty, Thierry/0000-0003-1339-1920
FU Poitou-Charentes Regional Founds for Research activities; European
   Regional Development Founds (ERDF) inside the e-Patrimoine project from
   the ax 1 of the NUMERIC Program
FX This research is supported by the Poitou-Charentes Regional Founds for
   Research activities and the European Regional Development Founds (ERDF)
   inside the e-Patrimoine project from the ax 1 of the NUMERIC Program.
CR Alqasrawi Y, 2013, SIGNAL IMAGE VIDEO P, V7, P759, DOI 10.1007/s11760-011-0266-0
   [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], 2015, Data mining: the textbook
   [Anonymous], ARXIV15020316 CORR
   [Anonymous], ARXIV16070621 CORR
   [Anonymous], 2007, 2007 IEEE COMP SOC C
   [Anonymous], ARXIV16020726 CORR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], ARXIV15120338 CORR
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2007, CVPR
   [Anonymous], ARXIV16030502 CORR
   [Anonymous], ARXIV15020185 CORR
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Chatoux H, 2016, INT C PATT RECOG, P1988, DOI 10.1109/ICPR.2016.7899928
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang WH, 2016, MULTIMED TOOLS APPL, V75, P9095, DOI 10.1007/s11042-015-2939-0
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Nister David, 2006, CVPR
   Ouni A, 2017, LECT NOTES COMPUT SC, V10133, P245, DOI 10.1007/978-3-319-51814-5_21
   Pedrosa Glauco V., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P304, DOI 10.1109/SIBGRAPI.2013.49
   Ren YX, 2014, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-43432-1_1
   Simonyan K., 2014, 14091556 ARXIV
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403
   Yeganli F, 2015, SIGNAL IMAGE VIDEO P, V9, P285, DOI 10.1007/s11760-015-0816-y
NR 39
TC 7
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26173
EP 26189
DI 10.1007/s11042-018-5841-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500001
DA 2024-07-18
ER

PT J
AU Wazarkar, S
   Keshavamurthy, BN
AF Wazarkar, Seema
   Keshavamurthy, Bettahally N.
TI Fashion image classification using matching points with linear
   convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Linear Convolution; Matching Points; Classification; Fashion images
AB Social image data related to fashion is flowing through the social networks in huge amount. Analysis of this data is a challenging task due to its characteristics like voluminous, unstructured, etc. Classification provides an easy and efficient way to deal with such data. In this paper, we proposed a new approach for classification of fashion images by incorporating the concepts of linear convolution and matching points using local features. Linear convolution is used to get the representative images with important features. Then, matching points between given image and class representative images are obtained. Maximum matching points are considered while assigning a class label to the given image. Proposed approach is useful further for various applications related to fashion such as fashion recommendation, fashion trend analysis, etc.
C1 [Wazarkar, Seema; Keshavamurthy, Bettahally N.] Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Goa
RP Wazarkar, S (corresponding author), Natl Inst Technol Goa, Dept Comp Sci & Engn, Ponda, India.
EM wazarkarseema@nitgoa.ac.in; bnkeshav.fcse@nitgoa.ac.in
RI Wazarkar, Seema/Y-3371-2019; Wazarkar, Seema/G-8541-2018
OI Bettahally nanjaiah, Keshavamurthy/0000-0002-6680-8462
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, P INT C MULT RETR
   [Anonymous], INT J WEB SERVICES R
   [Anonymous], AUTOPATH HARNESSING
   Bhimani J, 2017, IEEE HIGH PERF EXTR
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Dahl JJ, 2017, IEEE INT ULTRA SYM
   Hori K, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P359, DOI 10.1145/3012709.3016075
   Inoue N, 2017, IEEE INT CONF COMP V, P2261, DOI 10.1109/ICCVW.2017.265
   Islam S. M. S., 2017, Advances in Technology Innovation, V2, P119
   Jagadeesh V, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1925, DOI 10.1145/2623330.2623332
   Kim EundeokAnn Marie Fiore Hyejeong Kim., 2013, Fashion Trends: Analysis and Forecasting
   Lin M., 2013, P 2 INT C LEARNING R
   Liu ZW, 2016, LECT NOTES COMPUT SC, V9906, P229, DOI 10.1007/978-3-319-46475-6_15
   Loni B, 2014, P 5 ACM MULT SYST C, P41
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miura S, 2013, 2013 INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P784, DOI 10.1109/SITIS.2013.127
   Nguyen Hai Thanh, 2014, Mining Intelligence and Knowledge Exploration. Second International Conference, MIKE 2014. Proceedings: LNCS 8891, P51, DOI 10.1007/978-3-319-13817-6_6
   Pawening RE, 2015, INT CONF INFORM COMM, P119, DOI 10.1109/ICTS.2015.7379883
   Riegler M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P397, DOI 10.1145/2647868.2654894
   Rubio A, 2017, IEEE INT CONF COMP V, P2236, DOI 10.1109/ICCVW.2017.261
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang F, 2016, IET IMAGE PROCESS, V10, P456, DOI 10.1049/iet-ipr.2015.0507
   Wang FL, 2016, MULTIMEDIA SYST, V22, P63, DOI 10.1007/s00530-014-0393-x
   Wu Q, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2890104
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yamaguchi K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P773, DOI 10.1145/2647868.2654958
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
   Zafarani R., 2014, Social media mining an introduction, P382, DOI DOI 10.1017/CBO9781139088510
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P3218, DOI 10.1109/TCYB.2017.2762344
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2016, MULTIMED TOOLS APPL, V75, P8921, DOI 10.1007/s11042-014-2342-2
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 39
TC 3
Z9 3
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25941
EP 25958
DI 10.1007/s11042-018-5829-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400057
DA 2024-07-18
ER

PT J
AU Wójtowicz, A
   Wojciechowski, R
   Ruminski, D
   Walczak, K
AF Wojtowicz, Adam
   Wojciechowski, Rafal
   Ruminski, Dariusz
   Walczak, Krzysztof
TI Securing ubiquitous AR services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access control; Security protocol; User privacy; Augmented reality;
   Semantic web; Mobile applications; Ubiquitous applications
AB This article describes a new approach to creating and securing ubiquitous augmented reality (AR) systems. Creation of AR presentations in distributed environments, where AR presentation can be dynamically composed at runtime based on distributed data sources and the usage context, and where new services can be dynamically added by various service providers, raises security concerns related to both service access control and users' privacy. To address this challenge, a generic architecture for deployment of ubiquitous AR services and an application-layer security protocol, which enforces usage of AR content according to semantically described usage policies, are proposed.
C1 [Wojtowicz, Adam; Wojciechowski, Rafal; Ruminski, Dariusz; Walczak, Krzysztof] Poznan Univ Econ & Business, Dept Informat Technol, Al Niepodleglosci 10, PL-61875 Poznan, Poland.
C3 Poznan University of Economics & Business
RP Wójtowicz, A (corresponding author), Poznan Univ Econ & Business, Dept Informat Technol, Al Niepodleglosci 10, PL-61875 Poznan, Poland.
EM awojtow@kti.ue.poznan.pl
RI Wójtowicz, Adam/AAA-9256-2019; Walczak, Krzysztof/AAF-9685-2021;
   Rumiński, Dariusz/J-7983-2019
OI Wójtowicz, Adam/0000-0003-1276-0915; Walczak,
   Krzysztof/0000-0001-8170-7910; Rumiński, Dariusz/0000-0001-8179-9894
FU Polish National Science Centre (NCN) [DEC-2012/07/B/ST6/01523,
   DEC-2016/20/T/ST6/00590]
FX This research work has been supported by the Polish National Science
   Centre (NCN) Grants No. DEC-2012/07/B/ST6/01523 and
   DEC-2016/20/T/ST6/00590.
CR [Anonymous], HOTOS
   [Anonymous], 2013, OPEN GEOSPATIAL CONS
   Apache Software Foundation, 2017, AP JEN DOC
   Aryan A., 2010, 2010 International Conference on Computer and Communication Technology (ICCCT 2010), P119, DOI 10.1109/ICCCT.2010.5640424
   Bertino Elisa., 2005, SACMAT 05, P29
   Cai S, 2014, COMPUT HUM BEHAV, V37, P31, DOI 10.1016/j.chb.2014.04.018
   Cantor S., 2005, ASSERTIONS PROTOCOLS
   Hardt D, 2012, OAUTH 2 0 FRAMEWORK
   Haugstvedt AC, 2012, INT SYM MIX AUGMENT, P247, DOI 10.1109/ISMAR.2012.6402563
   Hegde V, 2010, W3C WORKSH AUGM REAL, V1
   Hervás R, 2011, LECT NOTES COMPUT SC, V6693, P17, DOI 10.1007/978-3-642-21303-8_3
   Jana S, 2013, P IEEE S SECUR PRIV, P349, DOI 10.1109/SP.2013.31
   Koutromanos G., 2015, 6th International Conference on Information, Intelligence, Systems and Applications (IISA), July 2015, P1, DOI DOI 10.1109/IISA.2015.7388031
   Kugelmann D, 2018, ANN ANAT, V215, P71, DOI 10.1016/j.aanat.2017.09.011
   LeBlanc AG, 2017, PREV MED, V101, P235, DOI 10.1016/j.ypmed.2016.11.012
   Lee G.A., 2013, Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry, P207
   MacIntyre B., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P65, DOI 10.1109/ISMAR.2011.6092371
   Madsen JB, 2016, ACM J COMPUT CULT HE, V9, DOI 10.1145/2822899
   Matuszka T., 2014, 6 INT C VAMR 2014 PA, P375, DOI [10.1007/978-3-319-07458-0_35., DOI 10.1007/978-3-319-07458-0-35]
   Matuszka T., 2013, 5 INT C VAMR 2013 HE, P202, DOI [10.1007/978-3-642-39405-8_24, DOI 10.1007/978-3-642-39405-8-24]
   Moses Tim., 2005, EXTENSIBLE ACCESS CO
   Navab N, 2010, IEEE T MED IMAGING, V29, P1412, DOI 10.1109/TMI.2009.2021947
   Nixon Lyndon JB, 2012, I SEMANTICS POSTERS, P48
   PTC Inc, 2012, VUF AUGM REAL SDK
   Roesner F, 2014, COMMUN ACM, V57, P88, DOI 10.1145/2580723.2580730
   Ruminski D, 2017, WEB3D 2017, DOI 10.1145/3055624.3077121
   Ruminski D, 2014, INT SYM MIX AUGMENT, P401
   Ruminski D, 2013, LECT NOTES BUS INF P, V160, P258
   Schmalstieg Dieter, 2007, Location Based Services and TeleCartography, P369, DOI [10.1007/978-3-540-36728-4_28, DOI 10.1007/978-3-540-36728-4_28]
   Speiginer G, 2015, 17 INT C HCI INT 201, P112
   Stefan Philipp, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P540, DOI 10.1007/978-3-319-66185-8_61
   van Aart C, 2010, LECT NOTES ARTIF INT, V6317, P257, DOI 10.1007/978-3-642-16438-5_18
   Walczak K, 2017, LECT NOTES COMPUT SC, V10324, P415, DOI 10.1007/978-3-319-60922-5_32
   Walczak K, 2015, ADV INTELL SYST, V369, P595, DOI 10.1007/978-3-319-19713-5_52
   Walczak K, 2014, P I CON VIR SYS MULT, P353, DOI 10.1109/VSMM.2014.7136656
   Wang X, 2005, IEEE T MULTIMEDIA, V7, P408, DOI 10.1109/TMM.2005.846788
   Wojciechowski R, 2013, COMPUT EDUC, V68, P570, DOI 10.1016/j.compedu.2013.02.014
NR 37
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26881
EP 26899
DI 10.1007/s11042-018-5892-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500029
DA 2024-07-18
ER

PT J
AU Xue, LX
   Zhong, X
   Wang, RG
   Yang, J
   Hu, M
AF Xue, Lixia
   Zhong, Xin
   Wang, Ronggui
   Yang, Juan
   Hu, Min
TI Low - resolution vehicle recognition based on deep feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Feature fusion; Sparseness; Low
   resolution; Vehicle recognition
ID CLASSIFICATION
AB Recently, convolutional neural networks have achieved great success in image classification. However, the traditional convolutional neural network lacks the ability to distinguish image features, especially for the low resolution images with less feature information. In the vehicle recognition task, it is inevitable to lose some feature information by convolution during the process of the low-level feature is abstracted into the high-level semantic feature. In this paper, an improved convolutional neural network model with higher robustness is proposed, we call it feature fusion convolutional neural network (FFCNN), which can not only produce more discriminative features, but also can avoid interference caused by environmental factors to some extent. Firstly, the strategy of feature fusion is used to fuse the different low-level features in the convolution neural network. Secondly, in order to prevent overfitting, we combine with the network model of sparse and data augmentation to optimize the structure of the network model. The results of the experiment show that the model proposed in this paper has higher recognition accuracy compared with the traditional vehicle recognition methods and the original convolutional neural network models.
C1 [Xue, Lixia; Zhong, Xin; Wang, Ronggui; Yang, Juan; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM xlxzzm@163.com; m13329016380@163.com; wangrgui@foxmail.com;
   yangjuan@hfut.edu.cn; jsjxhumin@hfut.edu.cn
RI Hu, Min/HLH-2112-2023; Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]
FX We express our sincere thanks to the anonymous reviewers for their
   useful comments and suggestions to raise the standard of the paper. This
   study was supported by the National Natural Science Foundation of China
   under Grant No. 61672202.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2009, BRIT MACH VIS C
   Arora S, 2014, PR MACH LEARN RES, V32
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Hasegawa O, 2005, MACH VISION APPL, V16, P116, DOI 10.1007/s00138-004-0163-4
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Huang KQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2449081
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Peng XC, 2016, IEEE IMAGE PROC, P3683
   Salvador J, 2015, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2015.45
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Wang ZH, 2016, PROCEEDINGS OF THE 4TH INTERNATIONAL WORKSHOP ON ENERGY HARVESTING AND ENERGY-NEUTRAL SENSING SYSTEMS (ENSSYS'16), P1, DOI [10.1109/ICAUMS.2016.8479999, 10.1145/2996884.2996885]
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C., 2006, P 2006 IEEE INT WORK, P17
NR 32
TC 5
Z9 5
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27617
EP 27639
DI 10.1007/s11042-018-5940-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500061
DA 2024-07-18
ER

PT J
AU Jeyabharathi, D
   Dejey
AF Jeyabharathi, D.
   Dejey
TI Efficient background subtraction for thermal images using reflectional
   symmetry pattern (RSP)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector product; Vector direction; Reflectional symmetrical patterns
ID OBJECT DETECTION; DYNAMIC TEXTURE; SURVEILLANCE; TRACKING; VIDEO; MODEL
AB Nowadays, thermal image processing has gained more attention. Thermal camera's cost is decreasing, and so many real-time applications use thermal cameras since they have an ability to detect objects in darkness and track objects in the video. A background subtraction approach using Reflectional Symmetry Pattern (RSP) for thermal image background subtraction is proposed based on the assumption that the geometric reflectional symmetrical pattern of each of the objects (person) is much lower than the surrounding background. Reflectional symmetrical texture pattern can be used to create a subspace from the result of frame differencing approach. Statistical parameters such as VP (Vector Product), VD (Vector Direction) can be used to create an accurate background model. As a result, the proposed scheme can provide a high precision and less error rate to meet the requirements of object detection from real-time thermal videos.
C1 [Jeyabharathi, D.] Sri Krishna Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Dejey] Anna Univ Reg Campus Tirunelveli, Dept Comp Sci & Engn, Tirunelveli, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Jeyabharathi, D (corresponding author), Sri Krishna Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM bharathi.durai@gmail.com
RI bharathi, Jeya/T-6437-2019
OI Dharma, Dejey/0000-0002-5173-4878
CR [Anonymous], 2014, AS C COMP VIS SPRING
   Cheng L, 2009, IEEE I CONF COMP VIS, P2066, DOI 10.1109/ICCV.2009.5459454
   Conaire CO, 2006, IEEE IMAGE PROC, P2381, DOI 10.1109/ICIP.2006.312905
   Davis JamesW., 2005, CVPR 05 P 2005 IEEE, P11
   Jeyabharathi D, 2017, ADV COMPU INTELL ROB, P267, DOI 10.4018/978-1-5225-2053-5.ch013
   Jeyabharathi D, 2016, MULTIMED TOOLS APPL, V75, P17617, DOI 10.1007/s11042-016-3772-9
   Jeyabharathi D, 2016, J VIS COMMUN IMAGE R, V40, P816, DOI 10.1016/j.jvcir.2016.08.011
   Jeyabharathi D, 2018, COMPUT ELECT ENG
   Kesavaraja D, 2018, J PARALLEL DISTR COM, V118, P267, DOI 10.1016/j.jpdc.2017.08.015
   Li LH, 2016, IEEE T CIRC SYST VID, V26, P278, DOI 10.1109/TCSVT.2014.2380195
   Li W, 2012, 8 ICNC IEEE, P82
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   OConaire C., 2006, 9 INT C INF FUS IEEE, P1, DOI [10.1109/ICIF.2006.301618, DOI 10.1109/ICIF.2006.301618]
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Peijiang C, 2009, COMPUT NETW MULTIMED
   San M, 2012, ISCCSP
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Singh S, 2006, IEEE LCIR S
   Sobral A, 2014, LECT NOTES COMPUT SC, V8814, P94, DOI 10.1007/978-3-319-11758-4_11
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stocker A, 2002, P IEEE INT S CIRC SY, V2
   Valizadeh S, 2016, CONS EL ICCE 2016 IE
   Valizadeh S, 2018, MULTIMED TOOLS APPL, V77, P22985, DOI 10.1007/s11042-017-5486-z
   Venkataraman AB, 2005, CURR SCI INDIA, V88, P1827
   Wang Q, 2008, IEEE 2008
   Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099
   Xu Z, 2017, CONTRL DEC C CCDC 20
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 33
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22567
EP 22586
DI 10.1007/s11042-018-6220-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500042
DA 2024-07-18
ER

PT J
AU Yan, H
   Wang, ZF
   Lin, TH
   Li, Y
   Jin, DP
AF Yan, Huan
   Wang, Zifeng
   Lin, Tzu-Heng
   Li, Yong
   Jin, Depeng
TI Profiling users by online shopping behaviors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; User behavior analytics; Data analysis
AB Online shopping has been prevalent in our daily life. Profiling users and understanding their browsing behaviors are critical for enhancing shopping experience and maximizing sales revenue. In this paper, based on a one-month dataset recording 2 million users' 67 million online shopping and browsing logs, we seek to understand how users browse and shop products, and how distinct these behaviors are. We find that there exist dedicate groups of users that prefer certain product categories corresponding to similar demands. Moreover, distinct differences of behaviors exist in categories, where repetitive and targeted browsing are two major prevalent patterns.
C1 [Yan, Huan; Wang, Zifeng; Lin, Tzu-Heng; Li, Yong; Jin, Depeng] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Li, Y (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM yanh14@mails.tsinghua.edu.cn; wangzf14@mails.tsinghua.edu.cn;
   linzh14@mails.tsinghua.edu.cn; liyong07@tsinghua.edu.cn;
   jindp@tsinghua.edu.cn
RI li, yong/HDN-3885-2022; jin, du/G-4747-2012; Lin, Tzu-Heng/T-2969-2019
OI Lin, Tzu-Heng/0000-0002-0760-1592
CR Anderson A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P419, DOI 10.1145/2566486.2568018
   [Anonymous], IEEE T INF THEORY
   Benson AR, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P519, DOI 10.1145/2872427.2883025
   Chen M, 2017, BIG DATA COGNITIVE C, V1
   Chen M, 2017, IEEE ACCESS, V4, P1242
   Chen M, 2017, IEEE COMMUN MAG, V55, P54, DOI 10.1109/MCOM.2017.1600410CM
   Chen M, 2016, MOBILE NETW APPL, V21, P825, DOI 10.1007/s11036-016-0745-1
   eMarketer, 2016, WORLDW RET EC SAL EM, P2
   Keralapura R, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P341
   Li JY, 2012, J PARALLEL DISTR COM, V72, P666, DOI 10.1016/j.jpdc.2012.02.002
   Li Y, 2015, IEEE ACCESS, V3, P2542, DOI 10.1109/ACCESS.2015.2499271
   Liu CH, 2017, IEEE SYST J, V11, P106, DOI 10.1109/JSYST.2015.2440431
   Qiu MK, 2015, IEEE T COMPUT, V64, P3528, DOI 10.1109/TC.2015.2409857
   Qiu MK, 2009, ACM T DES AUTOMAT EL, V14, DOI 10.1145/1497561.1497568
   Tian DX, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2422144
   Zhang Y, 2016, IEEE T SERV COMPUT, V9, P786, DOI 10.1109/TSC.2016.2592520
   Zhang Y, 2017, FUTURE GENER COMP SY, V66, P30, DOI 10.1016/j.future.2015.12.001
   Zhang Y, 2015, MOBILE NETW APPL, V20, P348, DOI 10.1007/s11036-014-0537-4
   Zheng K, 2016, IEEE NETWORK, V30, P44, DOI 10.1109/MNET.2016.7389830
NR 19
TC 4
Z9 6
U1 1
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21935
EP 21945
DI 10.1007/s11042-017-5365-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500008
DA 2024-07-18
ER

PT J
AU Yang, LC
   Jiang, PL
   Wang, F
   Wang, X
AF Yang, Longchao
   Jiang, Peilin
   Wang, Fei
   Wang, Xuan
TI Robust real-time visual object tracking via multi-scale fully
   convolutional Siamese networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Region-based; Fully convolutional; Siamese-network;
   Deep learning
AB Robust visual object tracking against occlusions and deformations is still very challenging task. To tackle these issues, existing Convolutional Neural Networks (CNNs) based trackers either fail to handle them or can just run in low speed. In this paper, we present a realtime tracker which is robust to occlusions and deformations based on a Region-based, Multi-Scale Fully Convolutional Siamese Network (R-MSFCN). In the proposed R-MSFCN, the information of regions is extracted separately by the proposition of position-sensitive score maps on multiple convolutional layers. Combining these score maps via adaptive weights leads to accurate location of the target on a new frame. The experiments illustrate that our method outperforms state-of-the-art approaches, and can handle the cases of object deformation and occlusion at about 31 FPS.
C1 [Yang, Longchao; Wang, Fei; Wang, Xuan] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, 28 Xianning Rd, Xian, Shaanxi, Peoples R China.
   [Jiang, Peilin] Xi An Jiao Tong Univ, Sch Software Engn, 28 Xianning Rd, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Yang, LC (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, 28 Xianning Rd, Xian, Shaanxi, Peoples R China.
EM yanglongchao@stu.mail.edu.cn; pljiang@mail.xjtu.edu.cn;
   wfx@mail.xjtu.edu.cn; xwang.cv@gmail.com
RI Wang, Fei/ITV-5151-2023
OI Wang, Fei/0000-0003-3462-8472
FU Natural Science Foundation of China [61231018]; National Science and
   Technology Support Program [2015BAH31F01]; Program of Introducing
   Talents of Discipline to University [B13043]
FX This work was supported in part by Natural Science Foundation of China
   (No.61231018), National Science and Technology Support Program
   (2015BAH31F01) and Program of Introducing Talents of Discipline to
   University under grant B13043.
CR Bertinetto L., 2016, COMPUTER SCI, V38, P311
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Caseiro Rui, 2015, TPAMI
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jifeng Dai, 2016, ARXIV160506409
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Yi, 2016, ARXIV161107709
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nam H., 2016, CORR
   Nam H., 2015, Learning multi-domain convolutional neural networks for visual tracking
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pinheiro P.O., 2015, NEURIPS, P1990
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   XIANG W, 2014, ICONIP, V8834, P594
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhao H., 2016, ARXIV161201105
NR 33
TC 6
Z9 6
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22131
EP 22143
DI 10.1007/s11042-018-5664-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500020
DA 2024-07-18
ER

PT J
AU Wang, Y
   He, Y
   Boushey, CJ
   Zhu, FQ
   Delp, EJ
AF Wang, Yu
   He, Ye
   Boushey, Carol J.
   Zhu, Fengqing
   Delp, Edward J.
TI Context based image analysis with application in dietary assessment and
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image analysis; Image segmentation; Object classification; Context
   information; Dietary assessment
ID SEGMENTATION; PERCEPTION; COLOR
AB Dietary assessment is essential for understanding the link between diet and health. We develop a context based image analysis system for dietary assessment to automatically segment, identify and quantify food items from images. In this paper, we describe image segmentation and object classification methods used in our system to detect and identify food items. We then use context information to refine the classification results. We define contextual dietary information as the data that is not directly produced by the visual appearance of an object in the image, but yields information about a user's diet or can be used for diet planning. We integrate contextual dietary information that a user supplies to the system either explicitly or implicitly to correct potential misclassifications. We evaluate our models using food image datasets collected during dietary assessment studies from natural eating events.
C1 [Wang, Yu; Zhu, Fengqing] Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Delp, Edward J.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Delp, Edward J.] Purdue Univ, Sch Biomed Engn, W Lafayette, IN 47907 USA.
   [He, Ye] Google Inc, Mountain View, CA 94043 USA.
   [Boushey, Carol J.] Univ Hawaii, Ctr Canc, Program Epidemiol, Honolulu, HI 96822 USA.
C3 Purdue University System; Purdue University; Purdue University System;
   Purdue University; Purdue University System; Purdue University; Google
   Incorporated; Cancer Research Center of Hawaii; University of Hawaii
   System
RP He, Y (corresponding author), Google Inc, Mountain View, CA 94043 USA.
EM yehe@google.com
RI Delp, Edward J/C-3616-2013
OI Zhu, Fengqing/0000-0002-3863-3220; Delp, Edward/0000-0002-2909-7323
FU US National Institutes of Health [NIH/NCI 1U01CA130784-01, NIH/NIDDK
   2R56DK073711-04, 1R01-DK073711-01A1]
FX This work was sponsored by the US National Institutes of Health under
   grant NIH/NCI 1U01CA130784-01 and NIH/NIDDK
   2R56DK073711-04,1R01-DK073711-01A1. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the US
   National Institutes of Health.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 2009, MMWR-MORBID MORTAL W
   [Anonymous], 2004, Int. J. Comput. Vis., DOI [DOI 10.1023/B:VISI.0000029664.99615.94, 10.1023/B:VISI.0000029664.99615.94]
   [Anonymous], 2009, P ACM MULTIMEDIA 200
   [Anonymous], 2003, NIPS
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BIEDERMAN I, 1982, COGNITIVE PSYCHOL, V14, P143, DOI 10.1016/0010-0285(82)90007-X
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Boushey CJ, 2009, EUR J CLIN NUTR, V63, pS50, DOI 10.1038/ejcn.2008.65
   Choi T, 2013, INT J MULTIMEDIA UBI, V8, P207
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fang SB, 2015, IEEE INT SYM MULTIM, P385, DOI 10.1109/ISM.2015.67
   Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He Y, 2013, ISSCS 2013 (2013), V2013, DOI 10.1109/ISSCS.2013.6651268
   He Y, 2014, IEEE IMAGE PROC, P2744, DOI 10.1109/ICIP.2014.7025555
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Joutou T, 2009, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2009.5413400
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kelkar S, 2010, P IFT ANN M FOOD EXP
   Kenney C, 2001, IEEE T IMAGE PROCESS, V10, P326, DOI 10.1109/83.902298
   Kong FY, 2015, PERVASIVE MOB COMPUT, V19, P108, DOI 10.1016/j.pmcj.2014.05.012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Livingstone MBE, 2004, BRIT J NUTR, V92, pS213, DOI 10.1079/BJN20041169
   Ma WY, 1997, P SOC PHOTO-OPT INS, V3016, P496, DOI 10.1117/12.274547
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Martinel N., 2016, ARXIV161206543
   McFee B, 2011, IEEE T IMAGE PROCESS, V20, P570, DOI 10.1109/TIP.2010.2068556
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Peddi VB, 2017, FUTURE GENER COMP SY, V66, P71, DOI 10.1016/j.future.2016.03.019
   Rabinovich A, 2007, IEEE I CONF COMP VIS, P1237, DOI 10.1109/iccv.2007.4408986
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarkka S., 2013, Bayesian filtering and smoothing
   Schap TE, 2014, J HUM NUTR DIET, V27, P82, DOI 10.1111/jhn.12071
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stella S, 2010, P IFT ANN M FOOD EXP
   Thompson FE, 2010, J AM DIET ASSOC, V110, P48, DOI 10.1016/j.jada.2009.10.008
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wang Y, 2015, LECT NOTES COMPUT SC, V9281, P317, DOI 10.1007/978-3-319-23222-5_39
   Zhu FQ, 2015, IEEE J BIOMED HEALTH, V19, P377, DOI 10.1109/JBHI.2014.2304925
   Zhu FQ, 2010, IEEE J-STSP, V4, P756, DOI 10.1109/JSTSP.2010.2051471
NR 56
TC 18
Z9 21
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19769
EP 19794
DI 10.1007/s11042-017-5346-x
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500040
PM 30202237
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Tao, SQ
AF Tao, Songqiao
TI 3D CAD model retrieval based on the softassign quadratic assignment
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model retrieval; Softassign quadratic assignment algorithm; Face
   adjacency graph
ID GRAPH; RECOGNITION; SIMILARITY; FEATURES
AB A retrieval method for 3D CAD models based on the softassign quadratic assignment algorithm is presented in this paper. Firstly, retrieval models and target models are expressed as face adjacency graphs (FAGs) and thus 3D CAD model retrieval is turned to a graph matching problem. Secondly, vertex and edge compatibility matrices between the FAGs of a retrieval model and a target model are calculated. Then, an optimization objective function is created from compatibility matrices of a retrieval model and a target model, which serves as the similar metric for choosing vertex mapping matrix M of two models. Finally, the softassign quadratic assignment algorithm is introduced to find the optimal vertex mapping matrix M. Experimental results have shown that the proposed method supports 3D CAD model retrieval, and it is promising to meet the requirement of engineering applications.
C1 [Tao, Songqiao] Wuhan Tech Coll Commun, Dept Mech & Elect Engn, Wuhan 430065, Hubei, Peoples R China.
RP Tao, SQ (corresponding author), Wuhan Tech Coll Commun, Dept Mech & Elect Engn, Wuhan 430065, Hubei, Peoples R China.
EM taosongqiao@163.com
RI Tao, Songqiao/GSD-8971-2022
OI Tao, Songqiao/0000-0002-5799-4670
CR Auwatanamongkol S, 2007, PATTERN RECOGN LETT, V28, P1428, DOI 10.1016/j.patrec.2007.02.013
   Bai J, 2010, COMPUT AIDED DESIGN, V42, P1069, DOI 10.1016/j.cad.2010.07.002
   Bespalov D., 2005, Proceedings of the 2005 ACM Symposium on Solid and Physical Modeling-SPM '05, V1, P275
   Bespalov D, 2006, COMPUT AIDED DESIGN, V38, P1020, DOI 10.1016/j.cad.2006.07.005
   Biasotti S, 2016, COMPUT GRAPH FORUM, V35, P87, DOI 10.1111/cgf.12734
   Cardone A, 2006, COMPUT AIDED DESIGN, V38, P954, DOI 10.1016/j.cad.2006.08.001
   Chen Q, 2015, MULTIMED TOOLS APPL, V74, P4907, DOI 10.1007/s11042-013-1850-9
   CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565
   Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9
   El-Mehalawi M, 2003, COMPUT AIDED DESIGN, V35, P95, DOI 10.1016/S0010-4485(01)00178-6
   Gao S, 1998, COMPUT AIDED DESIGN, V30, P727, DOI 10.1016/S0010-4485(98)00033-5
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   HARALICK RM, 1980, ARTIF INTELL, V14, P263, DOI 10.1016/0004-3702(80)90051-X
   Huang MC, 2016, PROC CIRP, V56, P590, DOI 10.1016/j.procir.2016.10.116
   Huang R, 2015, COMPUT IND, V67, P38, DOI 10.1016/j.compind.2014.12.001
   Huangfu ZM, 2017, MULTIMED TOOLS APPL, V76, P8145, DOI 10.1007/s11042-016-3456-5
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Jeon SM, 2016, COMPUT IND, V77, P29, DOI 10.1016/j.compind.2016.01.002
   Kim H, 2017, MULTIMED TOOLS APPL, V76, P15867, DOI 10.1007/s11042-016-3881-5
   KIM WY, 1991, IEEE T PATTERN ANAL, V13, P224, DOI 10.1109/34.75511
   Lee YL, 2002, PATTERN RECOGN, V35, P299, DOI 10.1016/S0031-3203(01)00022-X
   Li B, 2013, MULTIMED TOOLS APPL, V62, P821, DOI 10.1007/s11042-011-0873-3
   Li M, 2009, J MECH DESIGN, V131, DOI 10.1115/1.4000253
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Li Z, 2015, COMPUT AIDED DESIGN, V62, P190, DOI 10.1016/j.cad.2014.05.008
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu ZB, 2013, J COMPUT SCI TECH-CH, V28, P836, DOI 10.1007/s11390-013-1382-9
   Ma LJ, 2010, COMPUT GRAPH-UK, V34, P545, DOI 10.1016/j.cag.2010.06.002
   Qin FW, 2016, ADV ENG INFORM, V30, P751, DOI 10.1016/j.aei.2016.10.001
   SUGANTHAN PN, 1995, PATTERN RECOGN, V28, P997, DOI 10.1016/0031-3203(94)00166-J
   Tao SQ, 2013, COMPUT AIDED DESIGN, V45, P1239, DOI 10.1016/j.cad.2013.05.008
   Tao SQ, 2012, PATTERN RECOGN, V45, P1721, DOI 10.1016/j.patcog.2011.09.017
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Xu CH, 2017, COMPUT IND, V90, P1, DOI 10.1016/j.compind.2017.04.006
   Xu D, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1326, DOI 10.1145/2964284.2964329
   Yang YB, 2007, IEEE T SYST MAN CY C, V37, P1081, DOI 10.1109/TSMCC.2007.905756
   You CF, 2010, INT J ADV MANUF TECH, V46, P649, DOI 10.1007/s00170-009-2113-9
   Zhang J, 2013, COMPUT AIDED DESIGN, V45, P1138, DOI 10.1016/j.cad.2013.04.003
   Zhu KP, 2012, COMPUT IND, V63, P1, DOI 10.1016/j.compind.2011.09.003
   Zhuang T, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/6049750
NR 42
TC 3
Z9 5
U1 3
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16249
EP 16265
DI 10.1007/s11042-017-5197-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300012
DA 2024-07-18
ER

PT J
AU Wang, P
   Li, K
AF Wang, Ping
   Li, Kai
TI A fast intra mode decision algorithm combining neighboring information
   for H.264/AVC high profile
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H. 264/AVC; Intra prediction; Mode decision; Most probable mode; Sum of
   absolute transformed difference
ID VIDEO CODING STANDARD; TRANSFORM-DOMAIN; BLOCK SIZE; PREDICTION;
   SELECTION
AB Intra coding in H.264/AVC can significantly improve the coding efficiency but at the cost of high computational complexity due to the use of rich prediction modes and rate-distortion optimization technique. To reduce the complexity, this paper proposes a fast mode decision algorithm for intra prediction in H.264/AVC high profile. The best prediction mode not only relies on the content of current block but also depends on the neighboring blocks because of the spatial continuity. Based on the reconstructed neighboring pixels, different prediction mode leads to different residual block which is the difference between the original block and predicted block. Since small residual block is advantageous to get good coding including the small distortion and few bit numbers, the feature from the residual block will be used to help do mode decision. Besides the neighboring pixels, the best modes of encoded neighboring blocks are also used to select the candidate modes. The proposed algorithm uses the sum of absolute transformed difference (SATD) to measure the residual block and uses the most probable mode to indicate the influence of the prediction modes of the neighboring blocks. Based on the statistic on mode decision accuracy, the most probable mode and the modes with the smallest residual block are considered as the candidate modes. Meanwhile, the early termination rules which can directly select only one mode are given in the proposed algorithm. Experimental results show that the proposed algorithm effectively reduces the complexity of intra prediction with slight coding performance degradation compared with the full search algorithm.
C1 [Wang, Ping; Li, Kai] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Wang, P (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM ping.fu@xjtu.edu.cn
FU National Natural Science Foundation of China [61202180]
FX The authors would like to thank the editors and the reviewers for their
   hard work and their helpful suggestions. This work was supported by the
   National Natural Science Foundation of China under Project No. 61202180.
CR [Anonymous], ISO IEC MPEG ITU T V
   [Anonymous], 2001, 13 VCEG M AUST TEX U
   Bharanitharan K, 2008, IEEE T MULTIMEDIA, V10, P1250, DOI 10.1109/TMM.2008.2004904
   Chen CN, 2014, MULTIMED TOOLS APPL, V72, P687, DOI 10.1007/s11042-013-1388-x
   Chen CN, 2013, MULTIMED TOOLS APPL, V62, P719, DOI 10.1007/s11042-011-0862-6
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   Kau LJ, 2015, IEEE T CIRC SYST VID, V25, P944, DOI 10.1109/TCSVT.2014.2369691
   Kim C, 2006, J VIS COMMUN IMAGE R, V17, P291, DOI 10.1016/j.jvcir.2005.05.002
   Kim H, 2015, MULTIMED TOOLS APPL, V74, P4641, DOI 10.1007/s11042-013-1827-8
   Kuo YH, 2014, MULTIMED TOOLS APPL, V72, P1803, DOI 10.1007/s11042-013-1480-2
   Kwon SK, 2012, IEEE T BROADCAST, V58, P125, DOI 10.1109/TBC.2011.2174894
   Lee YM, 2010, IEEE T CIRC SYST VID, V20, P463, DOI 10.1109/TCSVT.2009.2035853
   Li HL, 2008, IEEE T CIRC SYST VID, V18, P756, DOI 10.1109/TCSVT.2008.918778
   Lim K, 2012, IEEE T CONSUM ELECTR, V58, P654, DOI 10.1109/TCE.2012.6227473
   Lin YY, 2010, IEEE T CIRC SYST VID, V20, P1367, DOI 10.1109/TCSVT.2010.2077482
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Pejman H, 2012, IEEE T CONSUM ELECTR, V58, P1345
   Sarwer MG, 2008, SIGNAL PROCESS-IMAGE, V23, P571, DOI 10.1016/j.image.2008.05.002
   Sarwer M, 2013, SIGNAL IMAGE VIDEO P, V7, P777, DOI 10.1007/s11760-011-0267-z
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Su YP, 2005, IEEE INT SYMP CIRC S, P1234
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P975, DOI 10.1109/TCSVT.2008.920742
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Wang P, 2012, MULTIMED TOOLS APPL, V60, P139, DOI 10.1007/s11042-011-0807-0
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CY, 2013, IEEE T MULTIMEDIA, V15, P1083, DOI 10.1109/TMM.2013.2247033
   Yu AC, 2006, J VIS COMMUN IMAGE R, V17, P322, DOI 10.1016/j.jvcir.2005.05.006
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zhang TR, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P1292, DOI 10.1109/APCCAS.2008.4746264
NR 30
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17157
EP 17180
DI 10.1007/s11042-017-5283-8
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300052
DA 2024-07-18
ER

PT J
AU Baran, R
   Dziech, A
   Zeja, A
AF Baran, Remigiusz
   Dziech, Andrzej
   Zeja, Andrzej
TI A capable multimedia content discovery platform based on visual content
   analysis and intelligent data enrichment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content discovery and delivery; Recommender engines; Visual analysis;
   Data enrichment; Multimedia indexing; Complex multimedia objects
AB A new capable content discovery platform based on multimedia data enrichment is presented in this paper. The platform, known as the IMCOP system, refers to the concept of intelligent discovery and delivery of multimedia content. Relevant state-of-the-art solutions are described in detail in the background section. The overall architecture and the main components of the IMCOP system are presented next. An original concept of Complex Multimedia Objects which extend the MPEG-7 standard to hold the processed data and bind it into content related collections is introduced. Selected results of tests illustrating how the IMCOP system performs in terms of responsiveness and stability under a particular workload are reported. Finally, IMCOP's advantages in reference to other content discovery platforms are discussed and summed up.
C1 [Baran, Remigiusz] Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
   [Dziech, Andrzej] AGH Univ Sci & Technol, Al Mickiewicza 30, PL-30059 Krakow, Poland.
   [Zeja, Andrzej] Univ Comp Engn & Telecommun, Ul Toporowskiego 98, PL-25553 Kielce, Poland.
C3 Kielce University of Technology; AGH University of Krakow
RP Baran, R (corresponding author), Kielce Univ Technol, Fac Elect Engn Automat & Comp Sci, Al 1000 Lecia PP 7, PL-25314 Kielce, Poland.
EM r.baran@tu.kielce.pl; dziech@kt.agh.edu.pl; a.zeja@wstkt.pl
RI Baran, Remigiusz/E-5457-2014
OI Baran, Remigiusz/0000-0002-3643-5642
FU Polish National Centre for Research and Development (NCBR), EUREKA
   Projects [E! II/PL-IL/10/02A/2012, E!II/PL-IL/10/03A/2012]
FX This work was supported by the Polish National Centre for Research and
   Development (NCBR), as a part of the EUREKA Projects no. E!
   II/PL-IL/10/02A/2012 and E!II/PL-IL/10/03A/2012.
CR Baran R, 2000, MMET 2000: INTERNATIONAL CONFERENCE ON MATHEMATICAL METHODS IN ELECTROMAGNETIC THEORY, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P218, DOI 10.1109/MMET.2000.888560
   Baran R, 2015, COMM COM INF SC, V566, P3, DOI 10.1007/978-3-319-26404-2_1
   Baran R, 2014, COMM COM INF SC, V429, P1
   Blanco-Fernández Y, 2008, IEEE T CONSUM ELECTR, V54, P727, DOI 10.1109/TCE.2008.4560154
   Bleschke M, 2009, MIXDES 2009: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, P635
   Cerqueira E, 2009, LECT NOTES COMPUT SC, V5630, P242, DOI 10.1007/978-3-642-02472-6_26
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Eshkol A, 2014, COMM COM INF SC, V429, P73
   Howlett RJ, 2003, INTERNET BASED INTEL, V3
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Romaniak P, 2012, CONSUM COMM NETWORK, P597, DOI 10.1109/CCNC.2012.6181021
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   Salter J, 2006, IEEE INTELL SYST, V21, P35, DOI 10.1109/MIS.2006.4
   Slusarczyk P, 2016, MULTIMED TOOLS APPL, V75, P10649, DOI 10.1007/s11042-014-2173-1
   Su X, 2009, ADVANCES IN ARTIFICI
NR 16
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14077
EP 14091
DI 10.1007/s11042-017-5014-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900043
OA hybrid
DA 2024-07-18
ER

PT J
AU Feng, Q
   Wang, TJ
   Liu, F
   Lin, HF
AF Feng Qi
   Wang Tianjiang
   Liu Fang
   Lin HeFei
TI Research on multi-camera information fusion method for intelligent
   perception
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual perception; Information fusion; Wavelet transform; Feature
   extraction; Matching and recognition
AB In this paper, the Gaussian Mixture Model and Mean Shift algorithm are used to detect and track moving objects in the visual perception network composed of multiple cameras. And on this basis, a target matching method based on wavelet transform, which is applied in a visual perception network composed by multiple camera, fusing visual information from different cameras is proposed. This method takes local features as basis of target matching, and applies wavelet transformation to detect the feature points that represent important information of the target image, and then extracts the color of the neighborhood of feature points as its salient features. The method of classification and clustering is applied by calculating the distance of salient features vector space to measure similarities of the target features and thus realize target recognition. The test result shows that the method can realize the matching and recognition of moving object with the cooperation among multiple cameras.
C1 [Feng Qi; Wang Tianjiang; Liu Fang; Lin HeFei] HUST, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, TJ (corresponding author), HUST, Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
EM fengqi@hust.edu.cn; tjwang@hust.edu.cn
FU State Key Program of National Natural Science Foundation of China
   [U1536203]; National Natural Science Foundation of China [61572214];
   independent innovation research foundation of Huazhong University of
   Science and Technology [2016YXMS089]
FX The work was supported in part by the State Key Program of National
   Natural Science Foundation of China (Grant No. U1536203), and the
   National Natural Science Foundation of China (Grant No. 61572214), and
   the independent innovation research foundation of Huazhong University of
   Science and Technology (Grant No. 2016YXMS089).
CR Ali MMN, 2014, INFORM SCIENCES, V278, P448, DOI 10.1016/j.ins.2014.03.064
   Burdescu DD, 2009, LECT NOTES COMPUT SC, V5807, P606
   Chen R., 2015, INT C ADV MECH ENG I, P723
   Craglia M, 2012, INT J DIGIT EARTH, V5, P4, DOI 10.1080/17538947.2011.638500
   Draisma J, 2016, FOUND COMPUT MATH, V16, P99, DOI 10.1007/s10208-014-9240-x
   Forbes C., 2010, NORMAL GAUSSIAN DIST, P143
   Girone G., 2016, APPL MATH, V7, P1504
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   Gu HZ, 2013, MULTIMED TOOLS APPL, V65, P387, DOI 10.1007/s11042-012-0996-1
   Hashem IAT, 2016, INT J INFORM MANAGE, V36, P748, DOI 10.1016/j.ijinfomgt.2016.05.002
   Hu MD, 2015, COMM COM INF SC, V525, P142, DOI 10.1007/978-3-662-47791-5_17
   Hu X., 2016, OPEN J APPL SCI, V6, P449
   Kannappan S, 2016, ADV VIS COMPUT, V2016, P33
   Karney CFF, 2016, ACM T MATH SOFTWARE, V42, DOI 10.1145/2710016
   Liao W, 2016, COMPUT INF TECHNOL
   Liberti L, 2012, QUANTITATIVE BIOL, V56, P3
   Mishchenko Y, 2015, SIGNAL IMAGE VIDEO P, V9, P19, DOI 10.1007/s11760-012-0419-9
   Neirotti P, 2014, CITIES, V38, P25, DOI 10.1016/j.cities.2013.12.010
   Pan Z, 2017, MULTIMED TOOLS APPL, V76, P16989, DOI 10.1007/s11042-016-3647-0
   Pasupa K, 2015, ARTIF LIFE ROBOT, V20, P320, DOI 10.1007/s10015-015-0233-x
   Pathak RS, 2016, P NATL A SCI INDIA A, V86, P273, DOI 10.1007/s40010-015-0225-1
   Priambodo B, 2016, INT RES J COMP SCI, V3
   Rahman MM, 2011, J PHY SCI, V15, P149
   Ratanasanya S, 2015, ADV INTELLIGENT SYST, V361, P9
   Riou L, 2000, PATT REC INT C, V3, P3425
   Saravanan G, 2016, INT C COMM SIGN PROC
   Sattar F, 2016, INT J INTELL TRANSP, V14, P1, DOI 10.1007/s13177-014-0097-9
   Sindhuja G, 2015, C POW CONTR COMM COM, P283
   Skoneczny S, 2012, PRZ ELEKTROTECHNICZN, V2012, P140
   Sriharsha KV, 2015, 2015 6 INT C COMP CO, P1
   Sun Y, 2012, LECT NOTES ELECT ENG, V124, P711
   Surkutlawar S, 2013, INT J ADV COMPUT SC, V4, P164
   Utomo FS, 2016, AM J APPL SCI, V13, P1407
   Vogler N, 2010, J OPT SOC AM A, V27, P1361, DOI 10.1364/JOSAA.27.001361
   Wang DJ, 2016, MULTIMED TOOLS APPL, V75, P10271, DOI 10.1007/s11042-015-3078-3
   Xiong TS, 2016, J VIS COMMUN IMAGE R, V34, P135, DOI 10.1016/j.jvcir.2015.10.018
   Yadav DK, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P943, DOI 10.1109/ICACCI.2014.6968502
   Yager RR, 2016, STUD FUZZ SOFT COMP, V336, P199, DOI 10.1007/978-3-319-28808-6_12
   Yang X, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P518, DOI 10.1109/IWECA.2014.6845672
   Zhang Yi, 2016, Journal of Beijing University of Aeronautics and Astronautics, V42, P2683, DOI 10.13700/j.bh.1001-5965.2015.0858
   Zheng Y, 2016, INT CONF MEAS, P467, DOI 10.1109/ICMTMA.2016.117
   Zhou ZP, 2016, MULTIMED TOOLS APPL, V75, P3145, DOI 10.1007/s11042-014-2427-y
NR 42
TC 7
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15003
EP 15026
DI 10.1007/s11042-017-5085-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200025
DA 2024-07-18
ER

PT J
AU Islam, M
   Laskar, RH
AF Islam, Mohiul
   Laskar, Rabul Hussain
TI Geometric distortion correction based robust watermarking scheme in
   LWT-SVD domain with digital watermark extraction using SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Lifting wavelet transform(LWT); Singular value
   decomposition(SVD); Support vector machine(SVM); Invariant centroid;
   Radon transform
ID DISCRETE WAVELET TRANSFORM; IMAGE WATERMARKING; DWT-SVD; DCT; INVARIANT;
   SCALE
AB With the advent of technology, digital image watermarking turns to be an effective technique to protect digital images from illegal usages and manipulation. In digital image watermarking, one of the major challenges is to provide robustness against geometrical attack maintaining adequate level of imperceptibility and security. In this work, a robust digital image watermarking scheme is proposed based on the combination of lifting wavelet transform(LWT) and singular value decomposition(SVD). To achieve better correlation between the extracted and original watermark, SVM-based binary classification approach is integrated in watermark extraction. In the proposed technique, geometric distortion correction based approach is incorporated with SVM based binary watermark detection to achieve improved robustness against de-synchronization attack. The 3-level LWT is performed on the cover image where horizontal (HL) sub-band is chosen for binary watermark insertion. The training and testing patterns are formed using an optimized set of features along with the singular values of corresponding blocks. In case of de-synchronization attacks, geometrical distortion correction is required before performing watermark extraction. In the detection process, the geometric distortion parameters of the attacked watermarked image are estimated by the geometric correction method. This algorithm provides high robustness against both the geometrical and non-geometrical attacks. It has been observed that the algorithm gives average imperceptibility of similar to 42.27 dB with the watermark capacity of 512 bits. Experimental results suggest that the proposed watermarking scheme provides significant improvement in terms of robustness and security of the watermark. The subjective analysis also suggests that proposed scheme provides improved performance over some of the recent existing techniques.
C1 [Islam, Mohiul; Laskar, Rabul Hussain] NIT Silchar, Dept ECE, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Islam, M (corresponding author), NIT Silchar, Dept ECE, Silchar 788010, Assam, India.
EM mohiul292@gmail.com
RI Islam, Mohiul/AAE-9713-2021; Laskar, Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Islam,
   Mohiul/0000-0003-2780-1652
FU Speech and Image Processing Laboratory, Department of Electronics and
   Communication Engineering, National Institute of Technology Silchar,
   India
FX The authors would like to acknowledge Speech and Image Processing
   Laboratory, Department of Electronics and Communication Engineering,
   National Institute of Technology Silchar, India for providing support
   and necessary facilities for carrying out this work. Moreover, the
   authors would like to thank Mr. Amarjit Roy, Asst. Professor, School of
   Engineering and Technology, BML Munjal University, Gurgaon, Haryana,
   India for his valuable suggestions.
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Al-Otaibi NA, 2014, P 2014 INT C ADV ENG, P243
   [Anonymous], 2015, 12 LEARN TECHN C WEA
   [Anonymous], WOSPA 2008 5 IEEE IN
   [Anonymous], 4 IEEE GCC C EXH
   [Anonymous], ARXIV160908417
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Cox I. J., 2002, Digital Watermarking
   Deng C, 2010, SIGNAL PROCESS, V90, P3256, DOI 10.1016/j.sigpro.2010.05.032
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Gutub AAA, 2012, INT CONF ADV COMPUT, P116, DOI 10.1109/ACSAT.2012.44
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Kasana G, 2017, OPTIK, V142, P191, DOI 10.1016/j.ijleo.2017.05.027
   Kim BS, 2003, REAL-TIME IMAGING, V9, P139, DOI 10.1016/S1077-2014(03)00020-2
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li JZ, 2010, INT CONF COMP SCI, P367, DOI 10.1109/ICCSIT.2010.5564713
   Li QF, 2018, NEURAL COMPUT APPL, V30, P463, DOI 10.1007/s00521-016-2680-2
   Liang RZ, 2016, ARXIV160406620
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lutovac B, 2017, MULTIMED TOOLS APPL, V76, P23333, DOI 10.1007/s11042-016-4127-2
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mehta R, 2017, INT J MACH LEARN CYB, V8, P379, DOI 10.1007/s13042-015-0331-z
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1322, DOI 10.1109/APSCC.2008.105
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Ramanjaneyulu K, 2012, IET IMAGE PROCESS, V6, P364, DOI 10.1049/iet-ipr.2010.0347
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Singh C, 2013, OPT LASER TECHNOL, V54, P176, DOI 10.1016/j.optlastec.2013.05.016
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh P, 2013, IEEE INT ADV COMPUT, P1213
   Singha J, 2015, IETE J RES, V61, P597, DOI 10.1080/03772063.2015.1054900
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wang XY, 2008, SIGNAL PROCESS, V88, P2193, DOI 10.1016/j.sigpro.2008.03.005
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
   Zhu HQ, 2010, DIGIT SIGNAL PROCESS, V20, P1612, DOI 10.1016/j.dsp.2010.01.010
NR 54
TC 37
Z9 38
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14407
EP 14434
DI 10.1007/s11042-017-5035-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900058
DA 2024-07-18
ER

PT J
AU Rusiñol, M
   Chazalon, J
   Diaz-Chito, K
AF Rusinol, Marcal
   Chazalon, Joseph
   Diaz-Chito, Katerine
TI Augmented songbook: an augmented reality educational application for
   raising music awareness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Document image matching; Educational applications
AB This paper presents the development of an Augmented Reality mobile application which aims at sensibilizing young children to abstract concepts of music. Such concepts are, for instance, the musical notation or the idea of rhythm. Recent studies in Augmented Reality for education suggest that such technologies have multiple benefits for students, including younger ones. As mobile document image acquisition and processing gains maturity on mobile platforms, we explore how it is possible to build a markerless and real-time application to augment the physical documents with didactic animations and interactive virtual content. Given a standard image processing pipeline, we compare the performance of different local descriptors at two key stages of the process. Results suggest alternatives to the SIFT local descriptors, regarding result quality and computational efficiency, both for document model identification and perspective transform estimation. All experiments are performed on an original and public dataset we introduce here.
C1 [Rusinol, Marcal; Diaz-Chito, Katerine] Univ Autonoma Barcelona, Dept Ciencies Comp, Comp Vis Ctr, Edifici O, Barcelona 08193, Spain.
   [Chazalon, Joseph] Univ La Rochelle, L3i Lab, Ave Michel Crepeau, F-17042 La Rochelle 1, France.
   [Chazalon, Joseph] EPITA Res & Dev Lab LRDE, 14-16 Rue Voltaire, F-94270 Le Kremlin Bicetre, France.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); La Rochelle Universite
RP Rusiñol, M (corresponding author), Univ Autonoma Barcelona, Dept Ciencies Comp, Comp Vis Ctr, Edifici O, Barcelona 08193, Spain.
EM marcal@cvc.uab.es; joseph.chazalon@univ-lr.fr; kdiaz@cvc.uab.es
RI Katerine, Diaz-Chito/M-1676-2014; Rusinol, Marcal/M-1419-2014
OI Katerine, Diaz-Chito/0000-0002-8860-8082; Rusinol,
   Marcal/0000-0002-1734-2205
FU People Programme (Marie Curie Actions) of the Seventh Framework
   Programme of the European Union (FP7) under REA [600388]; Agency of
   Competitiveness for Companies of the Government of Catalonia, ACCIO;
   CERCA Programme / Generalitat de Catalunya; MOBIDEM project, part of the
   "Systematic Paris-Region" and "Images & Network" Clusters - French
   Government and its economic development agencies; NVIDIA Corporation; 
   [TIN2014-52072-P]
FX This work was supported by the Spanish project TIN2014-52072-P, by the
   People Programme (Marie Curie Actions) of the Seventh Framework
   Programme of the European Union (FP7/2007-2013) under REA grant
   agreement no. 600388, by the Agency of Competitiveness for Companies of
   the Government of Catalonia, ACCIO, by the CERCA Programme / Generalitat
   de Catalunya, and by the MOBIDEM project, part of the "Systematic
   Paris-Region" and "Images & Network" Clusters, funded by the French
   Government and its economic development agencies. We gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   Titan X Pascal GPU used for this research.
CR González NAA, 2015, PROCEDIA COMPUT SCI, V75, P250, DOI 10.1016/j.procs.2015.12.245
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   Bacca J, 2014, EDUC TECHNOL SOC, V17, P133
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Burie JC, 2015, PROC INT CONF DOC, P1161, DOI 10.1109/ICDAR.2015.7333943
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Cascales A, 2013, PROCEDIA COMPUT SCI, V25, P420, DOI 10.1016/j.procs.2013.11.053
   Chazalon J, 2015, PROC INT CONF DOC, P621, DOI 10.1109/ICDAR.2015.7333836
   Chazalon J, 2015, PROC INT CONF DOC, P1216, DOI 10.1109/ICDAR.2015.7333957
   Diaz C, 2015, PROCEDIA COMPUT SCI, V75, P205, DOI 10.1016/j.procs.2015.12.239
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Feng Huang, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P47, DOI 10.1109/IHMSC.2011.82
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goodwin A, 2013, P INT C IM VIS COMP
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Jain R, 2013, P DOC REC RETR 21
   Karatzas D, P 12 IAPR WORKSH DOC, P369
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Zarzuela MM, 2013, PROCEDIA COMPUT SCI, V25, P375, DOI 10.1016/j.procs.2013.11.046
   Moraleda Jorge, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3424, DOI 10.1109/ICPR.2010.836
   Moraleda J, 2012, PATTERN RECOGN LETT, V33, P863, DOI 10.1016/j.patrec.2011.10.013
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nakai T, 2006, LECT NOTES COMPUT SC, V3872, P541
   Nayef N, 2015, P INT C DOC AN REC
   Pra YD, 2014, P ICMC
   Quintero E, 2015, PROCEDIA COMPUT SCI, V75, P301, DOI 10.1016/j.procs.2015.12.251
   Rambli DRA, 2013, PROCEDIA COMPUT SCI, V25, P211, DOI 10.1016/j.procs.2013.11.026
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Takeda K., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P225, DOI 10.1109/DAS.2012.71
   Takeda K, 2011, PROC INT CONF DOC, P1054, DOI 10.1109/ICDAR.2011.213
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tomi AB, 2013, PROCEDIA COMPUT SCI, V25, P123, DOI 10.1016/j.procs.2013.11.015
   Wu C, 2016, VIRTUAL REALITY, P1
   Yilmaz RM, 2016, COMPUT HUM BEHAV, V54, P240, DOI 10.1016/j.chb.2015.07.040
NR 36
TC 15
Z9 17
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13773
EP 13798
DI 10.1007/s11042-017-4991-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900032
DA 2024-07-18
ER

PT J
AU Vezzetti, E
   Marcolin, F
   Tornincasa, S
   Ulrich, L
   Dagnes, N
AF Vezzetti, Enrico
   Marcolin, Federica
   Tornincasa, Stefano
   Ulrich, Luca
   Dagnes, Nicole
TI 3D geometry-based automatic landmark localization in presence of facial
   occlusions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face; Face analysis; Landmark localization; Differential geometry;
   Feature extraction
ID FACE RECOGNITION; FORMALIZATION; DESCRIPTORS; FEATURES; SHAPE
AB This study proposes a novel automatic method for facial landmark localization relying on geometrical properties of 3D facial surface working both on complete faces displaying different emotions and in presence of occlusions. In particular, 12 descriptors coming from Differential Geometry including the coefficients of the fundamental forms, Gaussian, mean, principal curvatures, shape index and curvedness are extracted as facial features and their local geometric properties are exploited to localize 13 soft-tissue landmarks from eye and nose areas. The method is deterministic and is backboned by a thresholding technique designed by studying the behaviour of each geometrical descriptor in correspondence to the locus of each landmark. Occlusions are managed by a detection algorithm based on geometrical properties which allows to proceed with the landmark localization avoiding the covered areas. Experimentations were carried out on 3132 faces of the Bosphorus database and of a 230-sized internal database, including expressive and occluded ones (mouth, eye, and eyeglasses occlusions), obtaining 4.75 mm mean localization error.
C1 [Vezzetti, Enrico; Marcolin, Federica; Tornincasa, Stefano; Ulrich, Luca; Dagnes, Nicole] Politecn Torino, Dept Management & Prod Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Marcolin, F (corresponding author), Politecn Torino, Dept Management & Prod Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM federica.marcolin@polito.it
RI Tornincasa, Stefano/IXW-6673-2023; Tornincasa, Stefano/IXW-6240-2023
OI Ulrich, Luca/0000-0001-8407-0660; Marcolin,
   Federica/0000-0002-4360-6905; Dagnes, Nicole/0000-0003-4690-7567
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   [Anonymous], 2015, WORLD S COMP NETW IN
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   Bagchi P, 2012, PROC INT CONF EMERG, P311, DOI 10.1109/EAIT.2012.6407931
   Canavan S, 2015, BIOM THEOR APPL SYST, P1
   Canavan S, 2015, COMPUT VIS IMAGE UND, V139, P136, DOI 10.1016/j.cviu.2015.06.006
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Creusot Clement., 2012, COMPUTER VISION PATT, P57
   De Giorgis N, 2015, LECT NOTES COMPUT SC, V9279, P421, DOI 10.1007/978-3-319-23231-7_38
   Dibeklioglu H, 2010, ROBUST LANDMARK LOCA
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Gilani SZ, 2015, PROC CVPR IEEE, P4639, DOI 10.1109/CVPR.2015.7299095
   Kakadiaris IA, 2012, SPIE NEWSROOM, DOI [10.1117/2.1201205.004214, DOI 10.1117/2.1201205.004214]
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lei JJ, 2016, IEEE T SYST MAN CY-S, V46, P165, DOI 10.1109/TSMC.2015.2452892
   Leslie G., 1994, ANTHROPOMETRY HEAD F
   Leslie G, 1981, FARKAS ANTHROPOMETRY
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Li Y, 2015, IET COMPUT VIS, V9, P75, DOI 10.1049/iet-cvi.2014.0070
   Perakis P, 2014, PATTERN RECOGN, V47, P2783, DOI 10.1016/j.patcog.2014.03.007
   Perakis P, 2013, IEEE T PATTERN ANAL, V35, P1552, DOI 10.1109/TPAMI.2012.247
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sukno FM, 2015, IEEE T CYBERNETICS, V45, P1717, DOI 10.1109/TCYB.2014.2359056
   Swennen G., 2005, 3 DIMENSIONAL CEPHAL, DOI DOI 10.1007/3-540-29011-7
   Szeptycki P, 2012, BIOMETRICS SPECIAL I, P1
   Vezzetti E, 2016, INT J BIOMETRICS, V8, P216
   Vezzetti E, 2016, IMAGE ANAL STEREOL, V35, P53, DOI 10.5566/ias.1339
   Vezzetti E, 2014, IMAGE ANAL STEREOL, V33, P167, DOI 10.5566/ias.1100
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Vezzetti E, 2014, AESTHET PLAST SURG, V38, P796, DOI 10.1007/s00266-014-0334-2
   Vezzetti E, 2014, MULTIMED TOOLS APPL, V68, P895, DOI 10.1007/s11042-012-1091-3
   Vezzetti E, 2012, COMPUT METH PROG BIO, V108, P1078, DOI 10.1016/j.cmpb.2012.07.008
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
NR 33
TC 44
Z9 44
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14177
EP 14205
DI 10.1007/s11042-017-5025-y
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900048
DA 2024-07-18
ER

PT J
AU Brodic, D
   Amelio, A
   Jankovic, R
AF Brodic, Darko
   Amelio, Alessia
   Jankovic, Radmila
TI Exploring the influence of CAPTCHA types to the users response time by
   statistical analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CAPTCHA; Web; Response time; Usability; Statistical analysis; Internet
   user
AB CAPTCHA stands for Completely Automated Public Turing Test to Tell Computers and Humans Apart. It is a test program that solves a given task for preventing the attacks made by automatic programs. If the response to CAPTCHA is correct, then the program classifies the user as a human. This paper introduces a new analysis of the impact of different CAPTCHAs to the Internet user's response time. It overcomes the limitations of the previous approaches in the state-of-the-art. In this sense, different types of CAPTCHAs are presented and described. Furthermore, an experiment is conducted, which is based on two populations of Internet users for text and image-based CAPTCHA types, differentiated by demographic features, such as age, gender, education level and Internet experience. Each user is required to solve the different types of CAPTCHA, and the response time to solve the CAPTCHAs is registered. The obtained results are statistically processed by Mann-Whitney U and Pearson's correlation coefficient tests. They analyze 7 different hypotheses which evaluate the response time in dependence of gender, age, education level and Internet experience, for the different CAPTCHA types. It represents an invaluable study in the literature to predict the best use of a given CAPTCHA for specific types of Internet users.
C1 [Brodic, Darko; Jankovic, Radmila] Univ Belgrade, Tech Fac Bor, Vojske Jugoslavije 12, Bor 19210, Serbia.
   [Amelio, Alessia] Univ Calabria, DIMES, Via P Bucci Cube 44, I-87036 Arcavacata Di Rende, Cs, Italy.
C3 University of Belgrade; University of Calabria
RP Brodic, D (corresponding author), Univ Belgrade, Tech Fac Bor, Vojske Jugoslavije 12, Bor 19210, Serbia.
EM dbrodic@tfbor.bg.ac.rs; aamelio@dimes.unical.it
RI Brodic, Darko T/C-3905-2011; Amelio, Alessia/AAI-4601-2021; Janković
   Babić, Radmila/AAD-4059-2020
OI Janković Babić, Radmila/0000-0003-3424-134X
FU Ministry of Education, Science and Technological Development of the
   Republic of Serbia [TR33037]
FX This study was partially funded by the Grant of the Ministry of
   Education, Science and Technological Development of the Republic of
   Serbia, as a part of the project TR33037 within the framework of the
   Technological development program. The receiver of the funding is Dr.
   Darko Brodic.
CR [Anonymous], 1950, MIND, DOI 10.1093/mind/LIX.236.433
   [Anonymous], 2005, P SIGCHI C HUM FACT
   [Anonymous], ANN M ASS COMP LING
   [Anonymous], 2011, Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis
   Baecher P., 2010, LNI, P353
   Baird HS, 2005, PROC SPIE, V5676, P197, DOI 10.1117/12.587811
   Belk Marios, 2013, Human Aspects of Information Security, Privacy, and Trust. First International Conference, HAS 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8030, P71, DOI 10.1007/978-3-642-39345-7_8
   Belk M, 2015, INT J HUM-COMPUT ST, V84, P1, DOI 10.1016/j.ijhcs.2015.07.002
   Brodic D, 2017, LECT NOTES COMPUT SC, V9961, P38, DOI 10.1007/978-3-319-57753-1_4
   Brodic D, 2016, LECT NOTES ARTIF INT, V9883, P78, DOI 10.1007/978-3-319-44748-3_8
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dhamija R, 2005, LECT NOTES COMPUT SC, V3517, P127
   Field A., 2009, Discovering statistics with SPSS, V3rd
   Goswami G, 2014, FUTURE GENER COMP SY, V31, P59, DOI 10.1016/j.future.2012.08.013
   Hubbard R, 2004, THEOR PSYCHOL, V14, P295, DOI 10.1177/0959354304043638
   Hernandez-Castro CJ, 2010, COMPUT SECUR, V29, P141, DOI 10.1016/j.cose.2009.06.006
   Kalsoom S, 2012, KSII T INTERNET INF, V6, P734, DOI 10.3837/tiis.2012.02.017
   Khan M, 2016, SIGNAL IMAGE VIDEO P, V10, P293, DOI 10.1007/s11760-014-0741-5
   Kim JW, 2010, VISUAL COMPUT, V26, P1135, DOI 10.1007/s00371-010-0469-3
   Kim J, 2014, KSII T INTERNET INF, V8, P1071, DOI 10.3837/tiis.2014.03.021
   Lee YL, 2011, DISPLAYS, V32, P81, DOI 10.1016/j.displa.2010.12.004
   Li QJ, 2015, MULTIMED TOOLS APPL, V74, P4583, DOI 10.1007/s11042-013-1823-z
   Lillibridges M, 2001, US Patent, Patent No. 6195698
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, Delving into transferable adversarial examples and black-box attacks"
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Madathil K.C., 2010, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V54, P1249, DOI DOI 10.1177/154193121005401603
   MORAN TP, 1981, INT J MAN MACH STUD, V15, P3, DOI 10.1016/S0020-7373(81)80022-3
   Rui Y, 2004, MULTIMEDIA SYST, V9, P493, DOI 10.1007/s00530-003-0122-3
   Rusu A, 2005, LECT NOTES COMPUT SC, V3517, P42
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   2002, 1 WORKSH HUM INT PRO
NR 38
TC 7
Z9 7
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12293
EP 12329
DI 10.1007/s11042-017-4883-7
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100030
DA 2024-07-18
ER

PT J
AU Ji, YL
   Li, HX
   Yang, Y
   Li, SY
AF Ji, Yanli
   Li, Haoxin
   Yang, Yang
   Li, Shuying
TI Hierarchical topology based hand pose estimation from a single depth
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand pose estimation; Regression forest; Hierarchical topology; Pose
   refinement
AB Hand pose estimation benefits large human computer interaction applications. The hand pose has high dimensions of freedom (dof) for joints, and various hand poses are flexible. Hand pose estimation is still a challenge problem. Since hand joints on the hand skeleton topology model have strict relationships between each other, we propose a hierarchical topology based approach to estimate 3D hand poses. First, we determine palm positions and palm orientations by detecting hand fingertips and calculating their directions in depth images. It is the global topology of hand poses. Moreover, we define connection relationships of finger joints as the local topology of hand model. Based on hierarchical topology, we extract angle features to describe hand poses, and adopt the regression forest algorithm to estimate 3D coordinates of hand joints. We further use freedom forrest algorithm to refine ambiguous poses in estimation to solve error accumulation problem. The hierarchical topology based approach ensures estimated hand poses in a reasonable topology, and improves estimation accuracy. We evaluate our approach on two public databases, and experiments illustrate its efficiency. Compared with state-of-the-art approaches, our approach improves estimation accuracy.
C1 [Ji, Yanli; Li, Haoxin] Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu, Sichuan, Peoples R China.
   [Yang, Yang] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Sichuan, Peoples R China.
   [Li, Shuying] China Aerosp Sci & Technol Corp, Inst 16, Xian, Shaanxi, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; China Aerospace Science &
   Technology Corporation (CASC)
RP Ji, YL (corresponding author), Univ Elect Sci & Technol China, Sch Automat Engn, Chengdu, Sichuan, Peoples R China.
EM yanliji@uestc.edu.cn; dlyyang@gmail.com
RI yang, yang/HGT-7999-2022; Lang, Ming/HIK-0758-2022; yang,
   yang/GVT-5210-2022
FU Natural Science Foundation of China (NSFC) [61305043, 61673088,
   61572108]
FX This research is supported by the Natural Science Foundation of China
   (NSFC) under grant No. 61305043 and grant No. 61673088. It is also
   supported by the Natural Science Foundation of China (NSFC) under grant
   No. 61572108.
CR Albrecht I., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P98
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], ICCV WORKSH
   [Anonymous], 2015, P IEEE INT C COMP VI
   Braort A, 2001, GEST WORKSH
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brown JA, 2012, IEEE T VIS COMPUT GR, V18, P68, DOI 10.1109/TVCG.2011.34
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Chi X, 2013, ICCV
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Liang H, 2013, VISUAL COMPUT, V29, P837, DOI 10.1007/s00371-013-0822-4
   Lien CC, 2005, MACH VISION APPL, V16, P157, DOI [10.1007/s00138-004-0167-0, 10.1007/S00138-004-0167-0]
   Lu S., 2003, CVPR
   Luo YD, 2018, PATTERN RECOGN, V75, P128, DOI 10.1016/j.patcog.2017.02.034
   Nakagawa Y, 2016, INT C PAR DISTRIB SY, P1237, DOI [10.1109/ICPADS.2016.0168, 10.1109/ICPADS.2016.166]
   Oberweger M., 2015, COMPUTER SCI
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Oikonomidis Iason, 2014, CVPR
   Qian Chen., 2014, CVPR
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sato Y, 2001, IEEE VIRT REAL C
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Shotton J, 2013, Commun. ACM, V56, P119, DOI [DOI 10.1145/2398356.2398381, 10.1145/2398356.2398381]
   Sridhar S, 2014, IEEE INT C 3D VIS
   Srinath S, 2013, ICCV
   Srinath S, 2015, CVPR
   Suarez J., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P411, DOI 10.1109/ROMAN.2012.6343787
   Sudderth A, 2004, CVPRW
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tompson J., 2014, ACM T GRAPHIC, V33, P1935
   Yang Y, 2015, IEEE T CYBERNETICS, V45, P1069, DOI 10.1109/TCYB.2014.2344015
NR 36
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10553
EP 10568
DI 10.1007/s11042-017-4651-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900011
DA 2024-07-18
ER

PT J
AU Kanmani, M
   Narasimhan, V
AF Kanmani, Madheswari
   Narasimhan, Venkateswaran
TI Swarm intelligent based contrast enhancement algorithm with improved
   visual perception for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE l alpha beta color space; Gamma correction approach; Particle swarm
   optimization; Entropy; Edge content
ID BI-HISTOGRAM EQUALIZATION; ADAPTIVE GAMMA CORRECTION; BRIGHTNESS;
   OPTIMIZATION
AB In this paper, we propose an optimized contrast enhancement algorithm for color images that improves visual perception of information. As color plays an important cue in many application areas, to prevent unwanted artifacts on color, our proposed method translates the color image into de-correlated l alpha beta color space based on the statistics of cone response to natural images. A color is defined in the l alpha beta space by an achromatic channel (brightness l), the red, green chrominance channel (alpha) and the yellow-blue chrominance channel (beta). In order to avoid over saturation and annoying artifacts, our method is applied to the luminance component of the image and alpha and beta are kept as constants. The key work of this paper is to use an adaptive gamma correction factor chosen by particle swarm optimization (PSO) to improve the entropy and enhance the details of the image. Gamma correction is a well-established technique that preserves the mean brightness of an image and produces more natural looking images by the choice of an optimal gamma factor. In the proposed method, the edge content and entropy are used as an objective function for each particle since a color image with good visual contrast includes many intensive edges. Since edges play a primary role in image understanding, one good way to enhance the contrast is to enhance the edges. Simulation results indicate that the proposed PSO optimized contrast enhancement improves overall image contrast and enriches the information present in the image. The proposed method is suitable for many real-time image processing applications.
C1 [Kanmani, Madheswari] SSN Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
   [Narasimhan, Venkateswaran] SSN Coll Engn, Dept Elect & Commun Engn, Madras, Tamil Nadu, India.
C3 SSN College of Engineering; SSN College of Engineering
RP Kanmani, M (corresponding author), SSN Coll Engn, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
EM madheswarik@ssn.edu.in; venkateswarann@ssn.edu.in
RI N, Venkateswaran/AGR-2157-2022
OI N, Venkateswaran/0000-0002-6789-4112
CR AGHAGOLZADEH S, 1992, OPT ENG, V31, P614, DOI 10.1117/12.56095
   [Anonymous], 2011, INT J ELECT COMMUN T
   [Anonymous], ENG OPTIMIZATION THE
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Behera SK, 2015, INT J ENG RES TECHNO, Vl4, P1049
   Bianco G, 2015, INT ARCH PHOTOGRAMME, VXL-5/W5
   Caselles V, 1999, IEEE T IMAGE PROCESS, V8, P220, DOI 10.1109/83.743856
   Chen Q, 2010, SIGNAL PROCESS, V90, P44, DOI 10.1016/j.sigpro.2009.05.015
   Chen SD, 2004, DIGIT SIGNAL PROCESS, V14, P413, DOI 10.1016/j.dsp.2004.04.001
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chiu YS, 2011, IEEE SYS MAN CYBERN, P2946, DOI 10.1109/ICSMC.2011.6084119
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Fonseca L, IMAGE FUSION REMOTE, P153
   Gao QQ, 2011, C IND ELECT APPL, P234, DOI 10.1109/ICIEA.2011.5975586
   GAUCH J, 1992, P SOC PHOTO-OPT INS, V1818, P1168, DOI 10.1117/12.131388
   Gorai A, 2009, WOR CONG NAT BIOL, P72, DOI 10.1109/NABIC.2009.5393603
   Gupta B, 2014, INT J ADV RES COMMUN, V3, P7585
   Gupta S., 2014, International Journal of Computer Applications, V100, P18
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Jidesh P, 2014, ARAB J SCI ENG, V39, P3691, DOI 10.1007/s13369-014-0983-0
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kwok NM, 2013, ENG APPL ARTIF INTEL, V26, P2356, DOI 10.1016/j.engappai.2013.07.023
   Liangchen Liu, 2012, 2012 19th IEEE International Conference on Image Processing (ICIP 2012), P1849, DOI 10.1109/ICIP.2012.6467243
   Nickfarjam AM, 2014, ARAB J SCI ENG, V39, P753, DOI 10.1007/s13369-013-0638-6
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2552, DOI 10.1109/TCE.2010.5681140
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Puiono Pulung NA, 2013, P 7 ICTS BAL
   Radman A, 2014, ARAB J SCI ENG, V39, P3039, DOI 10.1007/s13369-013-0924-3
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Shanmugavadivu P, 2014, OPT LASER TECHNOL, V57, P243, DOI 10.1016/j.optlastec.2013.07.013
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Shi WZ, 2005, INT J APPL EARTH OBS, V6, P241, DOI 10.1016/j.jag.2004.10.010
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Subhashdas SK, P SPIE IS T, V9395
   Travis D., 1991, EFFECTIVE COLOR DISP
   Vishwakarma A.K., 2012, Indian J. Comput. Sci. Eng, V3, P39
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Y., 2013, J CHINA U POSTS TELE, V20, P20, DOI DOI 10.3760/CMAJ.ISSN.1008-6706.2013.11.038
   Wei Zhenggang, 1999, Acta Electronica Sinica, V27, P79
   Welsh Tomihisa., Transferring Color to Greyscale Images
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
   Zuiderveld K., 1994, CONTRAST LTD ADAPTIV, P474
NR 47
TC 21
Z9 21
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12701
EP 12724
DI 10.1007/s11042-017-4911-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100047
DA 2024-07-18
ER

PT J
AU Li, JJ
   Wang, CY
   Chen, X
   Tang, Z
   Hui, GB
   Chang, CC
AF Li, Jianjun
   Wang, Chenyan
   Chen, Xie
   Tang, Zheng
   Hui, Guobao
   Chang, Chin-Chen
TI A selective encryption scheme of CABAC based on video context in high
   efficiency video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Selective encryption; CABAC; Remaining absolute level; Truncated
   rice code; EGk code
ID H.264/AVC; STANDARD
AB In this paper, we propose a selective encryption scheme with a chaotic encryption system for the High Efficiency Video Coding (HEVC) standard in which Context Adaptive Binary Arithmetic Coding (CABAC) is the only entropy coder for transform coefficient coding. Our method focuses on the binstrings of truncated rice with a context "p" (TRp) code suffix and kth order Exp-Golomb (k = p + 1) code suffix before Binary Arithmetic Coding (BAC) for the remaining absolute level coding, which is coded by the bypass mode in the entropy coding stage. The probability of symbols does not change and CABAC decoding has no effect after encryption. Several different YUV sequences are used for experimental evaluation of the proposed algorithm. Compared to previous researches, our approach has good protection for video information, which keeps a constant bitrate and format compatibility, and meantime it has a negligible impact on encoding performance.
C1 [Li, Jianjun; Wang, Chenyan; Chen, Xie] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Jianggan Dist, Peoples R China.
   [Tang, Zheng; Hui, Guobao] CETC, Key Lab Data Link Technol, Xian, Shaanxi, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
C3 Hangzhou Dianzi University; China Electronics Technology Group; Feng
   Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
EM lijjcan@gmail.com; adamtangzheng@163.com; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Key Laboratory of Data Link Technology of CETC, Xi'An, China
FX This work was supported by Key Laboratory of Data Link Technology of
   CETC, Xi'An, China
CR Ahn J, 2004, LECT NOTES COMPUT SC, V3333, P386
   Hofbauer Heinz, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1986, DOI 10.1109/ICASSP.2014.6853946
   Kwon SG, 2005, LECT NOTES COMPUT SC, V3656, P207, DOI 10.1007/11559573_26
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Liang L., 2005, P 5 INT C INF COMM S, P1121
   Ouamri M, 2015, J MULTIMEDIA PROCESS, V6
   Sabino CC, 2013, IEEE SYS MAN CYBERN, P1578, DOI 10.1109/SMC.2013.272
   Shahid Z., 2009, IEEE INT C IM PROC I, P1265
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Van Wallendael G, 2013, IEEE IMAGE PROC, P4583, DOI 10.1109/ICIP.2013.6738944
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Wang YS, 2012, EUR SIGNAL PR CONF, P1752
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yeung SKA, 2009, IEEE SIGNAL PROC LET, V16, P893, DOI 10.1109/LSP.2009.2026109
NR 15
TC 19
Z9 20
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12837
EP 12851
DI 10.1007/s11042-017-4916-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100052
DA 2024-07-18
ER

PT J
AU Lv, GH
   Teng, SW
   Lu, GJ
AF Lv, Guohua
   Teng, Shyh Wei
   Lu, Guojun
TI COREG: a corner based registration technique for multimodal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal image registration; Content difference; Scale difference;
   Corner; Curvature
ID POINT DISTANCE ACCUMULATION; PERFORMANCE; CURVATURE
AB This paper presents a COrner based REGistration technique for multimodal images (referred to as COREG). The proposed technique focuses on addressing large content and scale differences in multimodal images. Unlike traditional multimodal image registration techniques that rely on intensities or gradients for feature representation, we propose to use contour-based corners. First, curvature similarity between corners are for the first time explored for the purpose of multimodal image registration. Second, a novel local descriptor called Distribution of Edge Pixels Along Contour (DEPAC) is proposed to represent the edges in the neighborhood of corners. Third, a simple yet effective way of estimating scale difference is proposed by making use of geometric relationships between corner triplets from the reference and target images. Using a set of benchmark multimodal images and multimodal microscopic images, we will demonstrate that our proposed technique outperforms a state-of-the-art multimodal image registration technique.
C1 [Lv, Guohua] Qilu Univ Technol, Sch Informat, Jinan, Shandong, Peoples R China.
   [Teng, Shyh Wei; Lu, Guojun] Federat Univ Australia, Fac Sci & Technol, Ballarat, Vic, Australia.
C3 Qilu University of Technology; Federation University Australia
RP Lv, GH (corresponding author), Qilu Univ Technol, Sch Informat, Jinan, Shandong, Peoples R China.
EM drguohualv@163.com
OI Lu, Guojun/0000-0003-2523-7576; Teng, Shyh Wei/0000-0003-0347-3797; Lv,
   Guohua/0000-0003-3550-8026
CR Aguilera C, 2012, SENSORS-BASEL, V12, P12661, DOI 10.3390/s120912661
   [Anonymous], 2014, COMPUTERENCE
   [Anonymous], THESIS
   [Anonymous], 2012, THESIS
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Awrangjeb M, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P519, DOI 10.1109/DICTA.2009.91
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Bentoutou Y, 2005, IEEE T GEOSCI REMOTE, V43, P2127, DOI 10.1109/TGRS.2005.853187
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen JA, 2010, IEEE T BIO-MED ENG, V57, P1707, DOI 10.1109/TBME.2010.2042169
   Chen J, 2009, PROG NAT SCI-MATER, V19, P643, DOI 10.1016/j.pnsc.2008.06.029
   Choi BS, 2011, IEEE T IND ELECTRON, V58, P2226, DOI 10.1109/TIE.2011.2109330
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ghassabi Z., 2013, Eurasip Journal on Image and Video Processing, V2013, P1
   Han JH, 2001, PATTERN RECOGN LETT, V22, P1133, DOI 10.1016/S0167-8655(01)00063-0
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Hopp T, 2013, MED IMAGE ANAL, V17, P209, DOI 10.1016/j.media.2012.10.003
   Hossain M. T., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P197, DOI 10.1109/DICTA.2011.40
   Kelman A., 2007, INT C COMP VIS PATT, P1
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Lee JA, 2015, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR.2015.7298707
   Li Y, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023013
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu YX, 2014, MED IMAGE ANAL, V18, P555, DOI 10.1016/j.media.2014.02.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv G, 2013, INT C DIG IM COMP TE, P1
   Lv G., 2014, P INT C DIG IM COMP, P1
   Lv GH, 2016, PATTERN RECOGN LETT, V84, P156, DOI 10.1016/j.patrec.2016.09.011
   Myronenko A, 2010, IEEE T MED IMAGING, V29, P1882, DOI 10.1109/TMI.2010.2053043
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Pan MS, 2014, MULTIMED TOOLS APPL, V70, P1585, DOI 10.1007/s11042-012-1180-3
   Saleem S, 2014, IEEE SIGNAL PROC LET, V21, P400, DOI 10.1109/LSP.2014.2304073
   Sedaghat A, 2015, IEEE T GEOSCI REMOTE, V53, P5283, DOI 10.1109/TGRS.2015.2420659
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Staring M, 2009, IEEE T MED IMAGING, V28, P1412, DOI 10.1109/TMI.2009.2016560
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   Teng SW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013013
   Tsai CL, 2010, IEEE T MED IMAGING, V29, P636, DOI 10.1109/TMI.2009.2030324
   Wachinger C, 2012, MED IMAGE ANAL, V16, P1, DOI 10.1016/j.media.2011.03.001
   Woo J, 2015, IEEE T IMAGE PROCESS, V24, P757, DOI 10.1109/TIP.2014.2387019
   Xia MH, 2004, IEEE T IMAGE PROCESS, V13, P720, DOI 10.1109/TIP.2003.822611
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu DJ, 2007, INT J PATTERN RECOGN, V21, P573, DOI 10.1142/S0218001407005508
   Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]
   Yi Z, 2008, ELECTRON LETT, V44, P107, DOI 10.1049/el:20082477
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 52
TC 9
Z9 9
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12607
EP 12634
DI 10.1007/s11042-017-4907-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100043
DA 2024-07-18
ER

PT J
AU Pun, CM
   Yan, CP
   Yuan, XC
AF Pun, Chi-Man
   Yan, Cai-Ping
   Yuan, Xiao-Chen
TI Robust image hashing using progressive feature selection for tampering
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust image hashing; Progressive feature point selection; Tampering
   detection; Image authentication; Horizontal location-context hashing
   (HLCH); Vertical location-context hashing (VLCH)
ID SECURE; QUANTIZATION; MOMENTS
AB The main problem addressed in this paper is the robust tamper detection of the image received in a transmission under various content-preserving attacks. To this aim the progressive feature point selection method is proposed to extract the feature points of high robustness; with which, the local feature and color feature are then generated for each feature point. Afterwards, the robust image hashing construction method is proposed by using the location-context information of the features. The constructed hash is attached to the image before transmission and it can be used for analyzing at destination to filter out the geometric transformations occurred in the received image. After image restoration, the similarity of the global hashes between the source image and restored image is calculated to determine whether the received image has the same contents as the trusted one or has been maliciously tampered. When the received image being judged as a tampered image, the hashes calculated with the proposed Horizontal Location-Context Hashing (HLCH) and Vertical Location-Context Hashing (VLCH) methods will be used to locate the tampered regions. Experimental results on different images with tampering of arbitrary size and location demonstrate that our image authentication and tampering localization scheme are superior to the state-of-the-art methods under various attacks.
C1 [Pun, Chi-Man; Yuan, Xiao-Chen] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; yb47428@umac.mo; xiaochen_yuan@ieee.org
RI Yuan, Xiaochen/ABH-5255-2020; Pun, Chi Man/GRJ-3703-2022
OI Yuan, Xiaochen/0000-0002-7490-6695; Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (093-2014-A2).
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Cheung YM, 2007, IEEE T CIRC SYST VID, V17, P1007, DOI 10.1109/TCSVT.2007.903553
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lefebvre F, 2003, 2003 INT C P IM PROC, V493
   Liang R-Z, 2016, PATTERN RECOGNITION
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lu W, 2010, PROC SPIE, V7541, DOI 10.1117/12.838745
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Manish Mishra Manish Mishra, 2013, International Research Journal of Biological Sciences, V2, P1
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Monga V, 2007, IEEE T INF FOREN SEC, V2, P376, DOI 10.1109/TIFS.2007.902670
   Monga V, 2006, IEEE T IMAGE PROCESS, V15, P3452, DOI 10.1109/TIP.2006.881948
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Weinberger K., 2009, P 26 ANN INT C MACH, P1113, DOI DOI 10.1145/1553374.1553516
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Zhang W, 2008, PERVASIVE MOB COMPUT, V4, P658, DOI 10.1016/j.pmcj.2008.05.005
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zhuang DY, 2015, INFORM SCIENCES, V302, P94, DOI 10.1016/j.ins.2014.08.064
NR 30
TC 19
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11609
EP 11633
DI 10.1007/s11042-017-4809-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100002
DA 2024-07-18
ER

PT J
AU Ren, YZ
   Wu, HX
   Wang, LN
AF Ren, Yanzhen
   Wu, Hongxia
   Wang, Lina
TI An AMR adaptive steganography algorithm based on minimizing distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMR; Adaptive steganography; Fixed codebook; STC; Minimum embedding
   distortion
ID STEGANALYSIS; INFORMATION
AB To improve the concealment and statistics security, the paper proposed an AMR (Adaptive Multi-Rate) FCB (Fixed CodeBook) Adaptive steganography scheme (AFA), which is based on the search principle of AMR FCB and the correlation of non-zero pulse positions. The key contribution of the scheme is the design of the cost function and the additive distortion function. The optimal probability of pulse and the pulse correlation in the same track were introduced to cost function to improve the statistics security of the proposed algorithm. The hit function b(n) which is used to search for optimal pulse position was added to additive distortion function to improve the concealment of the algorithm. The experiment results show that the proposed scheme has better hearing concealment and security performance to resist the detecting of the existing steganalysis algorithms than the other steganography schemes.
C1 [Ren, Yanzhen; Wu, Hongxia; Wang, Lina] Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.
   [Ren, Yanzhen; Wang, Lina] State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
   [Ren, Yanzhen; Wang, Lina] Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Ren, YZ (corresponding author), Wuhan Univ, Comp Sch, Wuhan, Hubei, Peoples R China.; Ren, YZ (corresponding author), State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.; Ren, YZ (corresponding author), Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan 430072, Hubei, Peoples R China.
EM renyz@whu.edu.cn; 13027150492@163.com; lnawang@163.com
RI Wang, Li-Na/T-7047-2018
FU National Natural Science Foundation of China (NSFC) [U1536114, U1536204,
   61373169]; China Scholarship Council
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under the grant NO. U1536114, NO. U1536204, NO. 61373169,
   and China Scholarship Council.
CR [Anonymous], MANDATORY SPEECH COD
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], ADOBE AUDITION CS6
   [Anonymous], INT WORKSH DIG WAT
   [Anonymous], COMPUT ENG
   [Anonymous], SPIE IS T EL IM
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 26V6 3GPP TS
   [Anonymous], WIRELESS COMMUNICATI, DOI DOI 10.1109/WICOM.2010.5600125
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], ACTA ELECT SINICA
   [Anonymous], AUD DAT
   Bilal I, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P402, DOI 10.1109/PDGC.2014.7030779
   BURNS EM, 1981, J ACOUST SOC AM, V70, P1655, DOI 10.1121/1.387220
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Geiser B, 2008, INT CONF ACOUST SPEE, P4005, DOI 10.1109/ICASSP.2008.4518532
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Li SB, 2012, J ZHEJIANG U-SCI C, V13, P624, DOI 10.1631/jzus.C1100374
   Liu PD, 2016, INT J MACH LEARN CYB, V7, P1057, DOI 10.1007/s13042-015-0430-x
   Miao HB, 2012, COMPUT ELECTR ENG, V38, P1490, DOI 10.1016/j.compeleceng.2012.05.003
   Miao R, 2011, P 46 IEEE INT C COMM, P1, DOI DOI 10.1109/ICC.2011.5962657
   Nishimura Akira, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P483, DOI 10.1109/IIH-MSP.2009.83
   Paulin C, 2016, INT J SPEECH TECHNOL, V19, P585, DOI 10.1007/s10772-016-9352-6
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Ren YZ, 2015, IEEE T INF FOREN SEC, V10, P1801, DOI 10.1109/TIFS.2015.2421322
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Wang CY, 2007, IEEE INT SYM MULTIM, P255, DOI 10.1109/ISM.2007.33
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wilson A, 2016, Electron. Imag., V2016, P1
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xiao B, 2008, IEEE GLOBECOM 200820, P1
   Yu Chi, 2012, Journal of Chinese Computer Systems, V33, P1445
NR 36
TC 24
Z9 26
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12095
EP 12110
DI 10.1007/s11042-017-4860-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100022
DA 2024-07-18
ER

PT J
AU Wang, SK
   Yu, CY
   Sun, YJ
   Gao, F
   Dong, JY
AF Wang, Shengke
   Yu, Changyin
   Sun, Yujuan
   Gao, Feng
   Dong, Junyu
TI Specular reflection removal of ocean surface remote sensing images from
   UAVs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE UAVs; Remote sensing; Specular reflection; Ocean surface
ID SUN GLINT; COMPONENTS; COASTAL
AB Images captured by UAVs above the sea surface often contain lots of highlight regions due to the specular reflection of solar radiation on the non-flat sea surface. The existence of a great deal of specular highlight components may cover the objects under the water which is negative to those applications based on the UAV remote sensing images. In this paper, we present a method to remove the specular reflection on the RGB images of ocean surface. The intensity of specular highlight components is much larger than that of diffuse components in the images, simply subtracting the highlight component form the original image will leave a lot of holes. So our method contains two main steps: highlight regions detection and restoration of those regions. We use the method based on the intensity ratio to extract the regions affected by the specular reflection. Then we use the local information around those highlight regions to restore the intensity of those pixels. The experimental results indicate that the proposed method can effectively remove the specular reflection and keep details of ocean surface images.
C1 [Wang, Shengke; Yu, Changyin; Gao, Feng; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Sun, Yujuan] Ludong Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
C3 Ocean University of China; Ludong University
RP Wang, SK (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
EM neverme@ouc.edu.cn
FU National Natural Science Foundation of China(NSFC) [61301241, 61602229,
   41606198, 61501417, 41706010]; Natural Science Foundation of Shandong
   Provincial [ZR2016FM13, ZR2016FB02]; Guangzhou Education Science
   "Twelfth Five Year Plan" program [1201553242]
FX This work is supported by the National Natural Science Foundation of
   China(NSFC) Grants 61301241, 61602229, 41606198, 61501417 and 41706010,
   Natural Science Foundation of Shandong Provincial ZR2016FM13,
   ZR2016FB02, and Guangzhou Education Science "Twelfth Five Year Plan"
   2014 program grant 1201553242.
CR Alsmirat MA, 2017, J REAL-TIME IMAGE PR, V13, P527, DOI 10.1007/s11554-016-0631-x
   [Anonymous], 2001, P INT C VIS IM IM PR
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Doxani G., 2013, Thales, P329
   Drew MS, 2014, COMPUT VIS IMAGE UND, V127, P1, DOI 10.1016/j.cviu.2014.07.002
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hedley JD, 2005, INT J REMOTE SENS, V26, P2107, DOI 10.1080/01431160500034086
   Kay S, 2009, REMOTE SENS-BASEL, V1, P697, DOI 10.3390/rs1040697
   Kutser T, 2013, REMOTE SENS ENVIRON, V133, P85, DOI 10.1016/j.rse.2013.02.011
   Kutser T, 2009, REMOTE SENS ENVIRON, V113, P2267, DOI 10.1016/j.rse.2009.06.016
   Martin J, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010037
   Nayar S. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P583, DOI 10.1109/CVPR.1993.341071
   Overstreet BT, 2017, EARTH SURF PROC LAND, V42, P318, DOI 10.1002/esp.4063
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Radford A., 2015, ARXIV
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   Shen HL, 2013, APPL OPTICS, V52, P4483, DOI 10.1364/AO.52.004483
   Sodhro AH, 2017, MULTIMED TOOLS APPL, V76, P20001, DOI [10.1007/s11042-017-4452-0, 10.1007/s11042-016-4084-9]
   Suo JL, 2016, IEEE T IMAGE PROCESS, V25, P5441, DOI 10.1109/TIP.2016.2605002
   Tan RobbyT., 2003, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), V1, pI
   Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Umeyama S, 2004, IEEE T PATTERN ANAL, V26, P639, DOI 10.1109/TPAMI.2004.1273960
   Wang F, 2016, IEEE IMAGE PROC, P1983, DOI 10.1109/ICIP.2016.7532705
   Wolff L.B., 1989, Computer Vision and Pattern Recognition, 1989. Proceedings CVPR '89., P363
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Yang C., 2016, High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
NR 36
TC 12
Z9 15
U1 1
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11363
EP 11379
DI 10.1007/s11042-017-5551-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900054
DA 2024-07-18
ER

PT J
AU Svelto, C
   Matteucci, M
   Pniov, A
   Pedotti, L
AF Svelto, Cesare
   Matteucci, Matteo
   Pniov, Alexey
   Pedotti, Lorenzo
TI Skin prick test digital imaging system with manual, semiautomatic, and
   automatic wheal edge detection and area measurement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical image analysis; Skin Prick Test; Digital exams; wheal
   measurement; Image reconstruction; Allergy
AB A novel biomedical instrument for supporting the physician in Skin Prick Test analysis was designed, developed, characterized, and is now ready for clinical trials. Skin Prick Test is the gold standard front-end analysis for diagnosis of allergies in human subjects. The forearm skin is punctured with different allergens and the resulting reaction wheals are analyzed and compared to standard reaction, with larger areas corresponding to stronger allergy to the specific allergen. The wheals inspection and allergy diagnosis are performed, visually and subjectively, by the Medical Doctor. This procedure is laborious and somehow unreliable, being subject to variability both intra- and inter-operator because the doctor subjectivity in detecting and measuring the wheals is significant. Registration of the exam result is rarely available in a digital format, useful for data saving, transmission, retrieval and comparative analyses. Many of the above criticalities of the actual Prick Test manual practice are addressed and resolved by the proposed biomedical instrumentation that makes use of digital image-processing and data storage. In this work, we present a prototype of wheal measurement system, designed, developed and characterized to specifically measure geometry and areas of the allergic reaction wheals in Prick Test clinical exams. After software developments from previous version of the instrument, the wheal-meter now allows manual, semi-automatic, automatic, and fully-automatic operating conditions always providing digital exams output.
C1 [Svelto, Cesare; Matteucci, Matteo] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.
   [Pniov, Alexey] Bauman Moscow State Tech Univ, 2 Ya Baumanskaya Ul 5, Moscow 105005, Russia.
   [Pedotti, Lorenzo] CD Pharma Grp Srl, Piazza Angeli 7, I-20146 Milan, Italy.
C3 Polytechnic University of Milan; Bauman Moscow State Technical
   University
RP Svelto, C (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza Leonardo da Vinci 32, I-20133 Milan, Italy.
EM cesare.svelto@polimi.it; matteo.matteucci@polimi.it; apniov@gmail.com;
   l.pedotti@restech.it
OI SVELTO, CESARE/0000-0002-1910-7575
CR Australasian Society of Clinical Immunology and Allergy, 2006, SKIN PRICK TEST DIAG, P21
   Australian Standard, 2016, SUPPLEMENTARY CEMENT, P21
   Bousquet J, 2012, ALLERGY, V67, P18, DOI 10.1111/j.1398-9995.2011.02728.x
   Bulan O, 2014, P IMAGE PROCESS MACH, V7
   EBRUSTER H, 1959, Wien Klin Wochenschr, V71, P551
   Heinzerling Lucie, 2013, Clin Transl Allergy, V3, P3, DOI 10.1186/2045-7022-3-3
   Justo X, 2016, ALLERGY, V71, P1095, DOI 10.1111/all.12921
   Morris A, 2006, CURR ALLERGY CLIN IM, V19, P22
   Pepys J., 1975, BR J HOSP MED, P413
   Pepys J., 1975, Br J Hosp Med, V14, P412
   Prinz M., 2005, STUD HEALT TECHNOL I, V15, P441
   Svelto C, 2016, IEEE CONF IMAGING SY, P482, DOI 10.1109/IST.2016.7738274
   Wöhrl S, 2006, EXP DERMATOL, V15, P119, DOI 10.1111/j.1600-0625.2006.00388.x
NR 13
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9779
EP 9797
DI 10.1007/s11042-018-5823-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200028
DA 2024-07-18
ER

PT J
AU Banerjee, A
   Basu, S
   Basu, S
   Nasipuri, M
AF Banerjee, Anupam
   Basu, Sumana
   Basu, Subhadip
   Nasipuri, Mita
TI ARTeM: a new system for human authentication using finger vein images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vascular biometrics; Finger vein identification; Fuzzy contrast
   enhancement; Image registration
ID FEATURE-EXTRACTION; ROI LOCALIZATION; RECOGNITION; PATTERNS; PALMPRINT
AB A new system (ARTeM) for human authentication using finger vein images is described here. The developed algorithm combines 1) a fuzzy contrast enhancement algorithm with 2) a mutual information and affine transformation based registration technique and 3) a correlation coefficient based template matching algorithm, to detect the identity of a person based on the match-scores with finger vein images stored in the database. For performance assessment of the ARTeM algorithm, the benchmark SDUMLA multimodal biometric database containing 3816 images of 106 persons is used. On the complete database, up to 95.28% classification accuracy is achieved with single finger images; while up to 98.11% accuracy is observed with a consensus of two fingers. On a reduced subset of 86 persons' database, 98.84% accuracy is achieved with single finger classification and cent percent classification is obtained using a consensus of two fingers. Comparative analyses with other works also validate the effectiveness of the developed methodology.
C1 [Banerjee, Anupam; Basu, Sumana; Basu, Subhadip; Nasipuri, Mita] Jadavpur Univ, Comp Sci & Engn Dept, Kolkata 700032, India.
C3 Jadavpur University
RP Basu, S (corresponding author), Jadavpur Univ, Comp Sci & Engn Dept, Kolkata 700032, India.
EM subhadip@cse.jdvu.ac.in
RI Banerjee, Anupam/HLG-0690-2023
OI Banerjee, Anupam/0000-0002-2859-7705
FU CMATER research laboratory of the Computer Science and Engineering
   Department, Jadavpur University, India; PURSE-II and UPEII project;
   FASTTRACK grant of DST [SR/FTP/ETA-04/2012]; UGC, Government of India
   [F.30-31/2016(SA-II)]
FX This project is partially supported by the CMATER research laboratory of
   the Computer Science and Engineering Department, Jadavpur University,
   India, PURSE-II and UPEII project, FASTTRACK grant (SR/FTP/ETA-04/2012)
   of DST and Research Award (F.30-31/2016(SA-II)) from UGC, Government of
   India.
CR Abaza A, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431221
   [Anonymous], 2013, INT J COMPUT TRENDS
   [Anonymous], ENCY BIOMETRICS I Z
   [Anonymous], INT C OPT INSTR TECH
   [Anonymous], J KOREA I COMMUN SCI
   [Anonymous], 1965, THESIS
   [Anonymous], THESIS
   [Anonymous], INF CONTROL
   [Anonymous], SDUMLA HMT MULTIMOD
   Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI 10.1023/A:1015059928466
   Campbell JP, 1997, P IEEE, V85, P1437, DOI 10.1109/5.628714
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHEN Y, 2016, MATH PROBL ENG, V2016, P1, DOI DOI 10.1155/2016/6564202
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Fan HY, 2017, MULTIMED TOOLS APPL, V76, P3505, DOI 10.1007/s11042-016-3761-z
   Gaens T, 1998, LECT NOTES COMPUT SC, V1496, P1099, DOI 10.1007/BFb0056299
   Hanmandlu M, 2011, PATTERN RECOGN LETT, V32, P1843, DOI 10.1016/j.patrec.2011.06.029
   Honarpisheh Zahra, 2013, IAES International Journal of Electrical and Computer Engineering, V3, P30
   Hoshyar A. N., 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P1020, DOI 10.1109/ITSIM.2010.5561595
   Jain A.K., 2011, HDB FACE RECOGNITION, V1
   Jain A. K., 2006, Biometrics: personal identification in networked society, V479
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Karnan M, 2011, APPL SOFT COMPUT, V11, P1565, DOI 10.1016/j.asoc.2010.08.003
   Kim HG, 2012, LECT NOTES COMPUT SC, V7432, P21, DOI 10.1007/978-3-642-33191-6_3
   Kumar A, 2012, IEEE T IMAGE PROCESS, V21, P2228, DOI 10.1109/TIP.2011.2171697
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Ladoux PO, 2009, LECT NOTES COMPUT SC, V5558, P1290, DOI 10.1007/978-3-642-01793-3_130
   Lee EC, 2011, SENSORS-BASEL, V11, P2319, DOI 10.3390/s110302319
   Liu Y, 2016, SIGNAL PROCESS, V125, P237, DOI 10.1016/j.sigpro.2016.01.019
   Lu Y, 2013, SENSORS-BASEL, V13, P14339, DOI 10.3390/s131114339
   Lv ZH, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P149, DOI 10.1109/ICVR.2015.7358623
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Mattes D, 2001, PROC SPIE, V4322, P1609, DOI 10.1117/12.431046
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   Miura N, 2007, IEICE T INF SYST, VE90D, P1185, DOI 10.1093/ietisy/e90-d.8.1185
   Mulyono D, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P134
   PAL SK, 1981, IEEE T SYST MAN CYB, V11, P494
   Park KR, 2011, COMPUT INFORM, V30, P295
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Rashid RA, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P898, DOI 10.1109/ICCCE.2008.4580735
   Rosdi BA, 2011, SENSORS-BASEL, V11, P11357, DOI 10.3390/s111211357
   Saadat F, 2015, SECOND INTERNATIONAL CONGRESS ON TECHNOLOGY, COMMUNICATION AND KNOWLEDGE (ICTCK 2015), P501, DOI 10.1109/ICTCK.2015.7582719
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Teoh Saw Beng, 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P530, DOI 10.1109/ICSIPA.2011.6144093
   Tome P., 2014, P INT C BIOM SPEC IN, P1
   Trabelsi R., 2013, Int. J. Eng. Technol., V5, P3175
   TRAURING M, 1963, NATURE, V197, P938, DOI 10.1038/197938a0
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Vanoni M, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P30, DOI 10.1109/BIOMS.2014.6951532
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Wang L, 2008, PATTERN RECOGN, V41, P920, DOI 10.1016/j.patcog.2007.07.012
   Watanabe M, 2008, ACTA HORTIC, P75, DOI 10.1007/978-1-84628-921-7_5
   Wu JD, 2009, EXPERT SYST APPL, V36, P5793, DOI 10.1016/j.eswa.2008.07.042
   Xian R, 2015, INT CONF BIOMETR, P85, DOI 10.1109/ICB.2015.7139080
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yanagawa T., 2007, MHF PREPR SER, V12, P1
   Yang JC, 2016, INFORM SCIENCES, V373, P251, DOI 10.1016/j.ins.2016.09.004
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P1569, DOI 10.1016/j.patrec.2012.04.018
   Yang JF, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P87, DOI 10.1109/ICIG.2009.170
   Yang W, 2011, HAND BAS BIOM ICHB 2, P1
   Yang WM, 2013, IEICE T INF SYST, VE96D, P1227, DOI 10.1587/transinf.E96.D.1227
   Yu CB, 2009, INTERDISCIP SCI, V1, P280, DOI 10.1007/s12539-009-0046-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang ZB, 2006, INT C PATT RECOG, P145
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 69
TC 30
Z9 30
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5857
EP 5884
DI 10.1007/s11042-017-4501-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800033
DA 2024-07-18
ER

PT J
AU Brito, PQ
   Stoyanova, J
   Coelho, A
AF Brito, Pedro Quelhas
   Stoyanova, Jasmina
   Coelho, Antonio
TI Augmented reality versus conventional interface: Is there any difference
   in effectiveness?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Effectiveness; Emotion; Brand evaluation; Online
   shopping; Experimental design
ID SPREADING ACTIVATION THEORY; PERCEIVED RISK; E-COMMERCE; PRODUCT
   KNOWLEDGE; ONLINE; IMPACT; WEB; BEHAVIOR; MEDIA; INTANGIBILITY
AB The moment immediately before the "add to cart" decision is very critical in online shopping. Drawing on theories of transfer, spreading activation and human-computer interaction, the superiority of markerless Augmented Reality (AR) and Marker-based augmented reality (M) over Conventional Interactive (CI) is hypothesized. Although those multimedia tools are not part of the product/brand motivating the consumer interest they interfere in the interactive performance of the ecommerce. 150 consumers in a lab experiment showed higher emotional response, interactive response and brand evaluation in M and AR than CI. Contrary to what was expected the usability results were the inverse. That is, usability of CI outperforms M and AR. Considering only AR and M interfaces their effect on psychological variables was not statistically significant. A sophisticated or a simple interface had no impact on intention to buy the target brand, but the brand recommendation improved from M to AR. The differing effect of those three interface systems was mediated by brand familiarity, perceived risk, opinion leadership and positive emotional traits.
C1 [Brito, Pedro Quelhas] Univ Porto, Fac Econ, LIAAD INESC Tec, Rua Dr Roberto Frias, P-4200464 Porto, Portugal.
   [Stoyanova, Jasmina; Coelho, Antonio] Univ Porto, Fac Engn, Rua Dr Roberto Frias S-N, P-4200464 Porto, Portugal.
C3 Universidade do Porto; INESC TEC; Universidade do Porto
RP Brito, PQ (corresponding author), Univ Porto, Fac Econ, LIAAD INESC Tec, Rua Dr Roberto Frias, P-4200464 Porto, Portugal.
EM pbrito@fep.up.pt; jasmina_mail@mail.bg; acoelho@fe.up.pt
RI Coelho, Antonio/G-2216-2011; Quelhas-Brito, Pedro/C-5900-2015
OI Coelho, Antonio/0000-0001-7949-2877; Quelhas-Brito,
   Pedro/0000-0003-2672-5950
CR Aaker JL, 1997, J MARKETING RES, V34, P347, DOI 10.2307/3151897
   ANDERSON JR, 1983, J VERB LEARN VERB BE, V22, P261, DOI 10.1016/S0022-5371(83)90201-3
   [Anonymous], J NIELSENS ALERTBOX
   [Anonymous], 1987, PSYCHOL MARK, V4, P225
   [Anonymous], 2007, METAPHORIK
   [Anonymous], ACTA U AGR SILVIC ME
   Arafsha F, 2015, MULTIMED TOOLS APPL, V74, P3035, DOI 10.1007/s11042-013-1767-3
   Azoulay Audrey., 2003, BRAND MANAGEMENT, V11, P143, DOI DOI 10.1057/PALGRAVE.BM.2540162
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BACHOROWSKI JA, 1994, PERS INDIV DIFFER, V17, P191, DOI 10.1016/0191-8869(94)90025-6
   Baños RM, 2012, INTERACT COMPUT, V24, P131, DOI 10.1016/j.intcom.2012.04.002
   Bartels J, 2011, J BUS RES, V64, P601, DOI 10.1016/j.jbusres.2010.05.002
   Batra R, 2004, J CONSUM PSYCHOL, V14, P318, DOI 10.1207/s15327663jcp1403_12
   Belleau B.D., 2007, Clothing and Textiles Research Journal, V25, P244, DOI DOI 10.1177/0887302X07302768
   Beukeboom CJ, 2015, J INTERACT MARK, V32, P26, DOI 10.1016/j.intmar.2015.09.003
   Bosse T, 2008, CONSCIOUS COGN, V17, P94, DOI 10.1016/j.concog.2007.06.006
   Botella C, 2011, COMPUT HUM BEHAV, V27, P217, DOI 10.1016/j.chb.2010.07.043
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Bryman A., 2009, SOCIAL RES METHODS
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10
   Chen LSL, 2012, BEHAV INFORM TECHNOL, V31, P1021, DOI 10.1080/0144929X.2011.624640
   Choi HH, 2016, MULTIMED TOOLS APPL, V75, P15311, DOI 10.1007/s11042-014-2272-z
   Chung N, 2015, COMPUT HUM BEHAV, V50, P588, DOI 10.1016/j.chb.2015.02.068
   COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407
   Coovert MD, 2014, COMPUT HUM BEHAV, V34, P241, DOI 10.1016/j.chb.2014.02.001
   COX DF, 1964, J MARKETING RES, V1, P32, DOI 10.2307/3150375
   Cozby P.C., 2009, Methods in Behavioral Research, V10th
   Deng LQ, 2012, ELECTRON COMMER R A, V11, P420, DOI 10.1016/j.elerap.2012.06.004
   Ding CG, 2012, ELECTRON COMMER R A, V11, P299, DOI 10.1016/j.elerap.2011.10.002
   Eisenbeiss M, 2012, J INTERACT MARK, V26, P4, DOI 10.1016/j.intmar.2011.06.002
   Ewoldsen DR, 2015, MEDIA PSYCHOL, V18, P312, DOI 10.1080/15213269.2014.937440
   Fang H, 2014, ELECTRON COMMER R A, V13, P409, DOI 10.1016/j.elerap.2014.08.002
   Fonseca D, 2014, COMPUT HUM BEHAV, V31, P434, DOI 10.1016/j.chb.2013.03.006
   Forsythe S, 2006, J INTERACT MARK, V20, P55, DOI 10.1002/dir.20061
   Gamboa H, 2014, MULTIMED TOOLS APPL, V73, P345, DOI 10.1007/s11042-013-1602-x
   Goldsmith R.E., 1991, Journal of the Academy of Marketing Science, V19, P209, DOI [DOI 10.1007/BF02726497, 10.1007/bf02726497, 10.1007/BF02726497]
   Goldsmith R.E., 2003, The international handbook on innovation, P321, DOI DOI 10.1016/B978-008044198-6/50022-X
   Goto K., 2002, Web redesign: Workflow that works
   Hair JF, 2010, Multivariate data analysis
   Hassenzahl M, 2010, INTERACT COMPUT, V22, P353, DOI 10.1016/j.intcom.2010.04.002
   He Y, 2016, MARKET LETT, V27, P103, DOI 10.1007/s11002-014-9317-y
   Hsu JSC, 2015, ELECTRON COMMER R A, V14, P418, DOI 10.1016/j.elerap.2015.06.003
   HUMPHREYS MS, 1984, PSYCHOL REV, V91, P153, DOI 10.1037/0033-295X.91.2.153
   Iyengar R, 2011, MARKET SCI, V30, P195, DOI 10.1287/mksc.1100.0566
   Janiszewski C, 2000, J MARKETING RES, V37, P331, DOI 10.1509/jmkr.37.3.331.18780
   Jarrier E, 2012, INT J ARTS MANAG, V15, P18
   Jung T, 2015, TOURISM MANAGE, V49, P75, DOI 10.1016/j.tourman.2015.02.013
   Kim DJ, 2009, INFORM SYST RES, V20, P237, DOI 10.1287/isre.1080.0188
   Kim HJ, 2014, MULTIMED TOOLS APPL, V68, P355, DOI 10.1007/s11042-012-1157-2
   Kim J., 2004, Seoul Journal of Business, V10
   Kim KK, 2011, ELECTRON COMMER R A, V10, P408, DOI 10.1016/j.elerap.2010.11.004
   Kim SY, 2014, COMPUT HUM BEHAV, V36, P376, DOI 10.1016/j.chb.2014.03.067
   Kock N, 2016, COGN TECHNOL WORK, V18, P105, DOI 10.1007/s10111-015-0349-8
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   Kwon SJ, 2010, ELECTRON COMMER R A, V9, P522, DOI 10.1016/j.elerap.2010.04.004
   Landau MJ, 2010, PSYCHOL BULL, V136, P1045, DOI 10.1037/a0020970
   LARSEN RJ, 1987, J RES PERS, V21, P1, DOI 10.1016/0092-6566(87)90023-7
   Lavie T, 2004, INT J HUM-COMPUT ST, V60, P269, DOI 10.1016/j.ijhcs.2003.09.002
   Lee KC, 2008, COMPUT HUM BEHAV, V24, P88, DOI 10.1016/j.chb.2007.01.018
   Lee S, 2011, J BUS RES, V64, P1195, DOI 10.1016/j.jbusres.2011.06.022
   Lee Y, 2012, DECIS SUPPORT SYST, V52, P450, DOI 10.1016/j.dss.2011.10.004
   Li HR, 2002, J ADVERTISING, V31, P43, DOI 10.1080/00913367.2002.10673675
   Li T, 2013, ELECTRON COMMER R A, V12, P449, DOI 10.1016/j.elerap.2013.07.001
   Liikkanen LA, 2015, INTERACTING COMPUTER
   Lin A, 2008, J INTERACT MARK, V22, P40, DOI 10.1002/dir.20120
   López I, 2011, ELECTRON COMMER R A, V10, P49, DOI 10.1016/j.elerap.2010.04.003
   Lv ZH, 2016, NEUROCOMPUTING, V208, P290, DOI 10.1016/j.neucom.2015.12.128
   Lv ZH, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0475-8
   Mandler JM, 2014, LANG COGN, V6, P510, DOI 10.1017/langcog.2014.14
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   MEYERSLEVY J, 1989, J CONSUM RES, V16, P197, DOI 10.1086/209208
   MORELAND RL, 1982, J EXP SOC PSYCHOL, V18, P395, DOI 10.1016/0022-1031(82)90062-2
   Nepomuceno MV, 2014, J RETAIL CONSUM SERV, V21, P619, DOI 10.1016/j.jretconser.2013.11.006
   Ng S, 2009, J MARKETING RES, V46, P279, DOI 10.1509/jmkr.46.2.279
   Nickerson R., 1997, Handbook of Human-Computer Interaction, V2nd
   Nielsen J., 1994, Usability inspection methods, P25, DOI [10.5555/189200.189209, DOI 10.5555/189200.189209, DOI 10.1089/TMJ.2010.0114]
   Norman D., 1988, PSYCHOL EVERYDAY THI
   Olsson T, 2012, J AMB INTEL SMART EN, V4, P29, DOI 10.3233/AIS-2011-0127
   Pantin-Sohier G, 2009, RECH APPL MARKET-ENG, V24, P53, DOI 10.1177/205157070902400203
   Partala T, 2012, INTERACT COMPUT, V24, P25, DOI 10.1016/j.intcom.2011.10.001
   Raney AA, 2003, J INTERACT MARK, V17, P38, DOI 10.1002/dir.10064
   REYNOLDS FD, 1971, J MARKETING RES, V8, P449, DOI 10.2307/3150235
   ROLLAND JP, 1994, P SOC PHOTO-OPT INS, V2351, P293
   Ryu HS, 2016, MULTIMED TOOLS APPL, V75, P3375, DOI 10.1007/s11042-014-2439-7
   Scheaffer R., 1996, ELEMENTARY SURVEY SA, V5th
   Shneiderman B, 1998, COMPUT EDUC, V31, P25, DOI 10.1016/S0360-1315(98)00014-1
   Siltanen S., 2012, Theory and applications of marker-based augmented reality
   Song PJ, 2011, ELECTRON COMMER R A, V10, P288, DOI 10.1016/j.elerap.2010.09.003
   Stefanucci JK, 2009, J EXP PSYCHOL GEN, V138, P131, DOI 10.1037/a0014797
   Stevens J., 1999, APPL MULTIVARIATE ST
   Tabachnick B.G., 2012, Using multivariate statistics, V6th
   Teichert TA, 2010, PSYCHOL MARKET, V27, P369, DOI 10.1002/mar.20332
   Van Krevelen D. W. F., 2010, Int. J. Virtual Real., V9, P1, DOI [10.20870/IJVR.2010.9.2.2767, DOI 10.20870/IJVR.2010.9.2.2767]
   van Noort G, 2012, J INTERACT MARK, V26, P223, DOI 10.1016/j.intmar.2011.11.002
   Verhagen T, 2011, INFORM MANAGE-AMSTER, V48, P320, DOI 10.1016/j.im.2011.08.001
   Verhellen Y, 2016, MARKET LETT, V27, P461, DOI 10.1007/s11002-015-9347-0
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P1863, DOI 10.1007/s11042-013-1722-3
   Wang SF, 2014, MULTIMED TOOLS APPL, V72, P1257, DOI 10.1007/s11042-013-1450-8
   Wang YB, 2016, COMPUT HUM BEHAV, V56, P34, DOI 10.1016/j.chb.2015.11.011
   Wathen CN, 2002, J AM SOC INF SCI TEC, V53, P134, DOI 10.1002/asi.10016
   WHISSELL C, 1986, PERCEPT MOTOR SKILL, V62, P875, DOI 10.2466/pms.1986.62.3.875
   Wood L.E., 1998, USER INTERFACE DESIG
   Wu HY, 2016, MULTIMED TOOLS APPL, V75, P733, DOI 10.1007/s11042-014-2323-5
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Yang MT, 2014, INTERACT COMPUT, V26, P321, DOI 10.1093/iwc/iwu015
   Zhang KZK, 2016, ELECTRON COMMER R A, V15, P14, DOI 10.1016/j.elerap.2015.12.001
   Zlatanova Sikya, 2002, GIST REPORT, V17, P1
NR 108
TC 12
Z9 13
U1 3
U2 91
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7487
EP 7516
DI 10.1007/s11042-017-4658-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700049
DA 2024-07-18
ER

PT J
AU Chen, YD
   Hao, CY
   Wu, W
   Wu, EH
AF Chen, Yadang
   Hao, Chuanyan
   Wu, Wen
   Wu, Enhua
TI Efficient frame-sequential label propagation for video object
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video segmentation; Label propagation; Supervised; Range-adaptive
ID EXTRACTION; TRACKING
AB In this work, we present an approach for segmenting objects in videos taken in complex scenes. It propagates initial object label through the entire video by a frame-sequential manner where the initial label is usually given by the user. The proposed method has several contributions which make the propagation much more robust and accurate than other methods. First, a novel supervised motion estimation algorithm is employed between each pair of neighboring frames, by which a predicted shape model can be warped in order to segment the similar color around object boundary. Second, unlike previous methods with fixed modeling range, we design a novel range-adaptive appearance model to handle the tough problem of occlusion. Last, the paper gives a reasonable framework based on GraphCut algorithm for obtaining the final label of the object by combining the clues from both appearance and motion. In the experiments, the proposed approach is evaluated qualitatively and quantitatively with some recent methods to show it achieves state-of-art results on multiple videos from benchmark data sets.
C1 [Chen, Yadang] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Chen, Yadang] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
   [Hao, Chuanyan] Nanjing Univ Posts & Telecommun, Sch Educ Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Wu, Wen; Wu, Enhua] Univ Macau, Fac Sci & Technol, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Posts & Telecommunications; University of Macau
RP Chen, YD (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.; Chen, YD (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing, Jiangsu, Peoples R China.
EM cyd4511632@126.com; hcy@njupt.edu.cn; wenwu@umac.mo; ehwu@umac.mo
RI Liu, xuefeng/IUP-1483-2023
FU National Natural Science Foundation of China [61602252]; Natural Science
   Foundation of Jiangsu Province of China [BK20160964, BK20160902,
   BK20160967]; Priority Academic Program Development(PAPD) of Jiangsu
   Higher Education Institutions; Startup Foundation for Introducing Talent
   of Nanjing University of Information Science and Technology(NUIST)
   [2243141601013]
FX We thank the anonymous reviewers for their valuable comments. This paper
   is supported by National Natural Science Foundation of China (No.
   61602252), Natural Science Foundation of Jiangsu Province of China (No.
   BK20160964, BK20160902, BK20160967), Project through the Priority
   Academic Program Development(PAPD) of Jiangsu Higher Education
   Institutions, Startup Foundation for Introducing Talent of Nanjing
   University of Information Science and Technology(NUIST) (No.
   2243141601013).
CR [Anonymous], 1986, DENSITY ESTIMATION S
   Avinash Ramakanth S, 2014, P 2014 IEEE C COMP V
   Bai X., 2009, ACM SIGGRAPH, P70
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Faktor A., 2014, P 2014 BRIT MACH VIS
   Fan QN, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818105
   Giordano D, 2015, PROC CVPR IEEE, P4814, DOI 10.1109/CVPR.2015.7299114
   Grundmann M, 2010, P 2010 IEEE C COMP V
   Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43
   Jang WD, 2016, P 2016 IEEE C COMP V
   Jiang HQ, 2015, IEEE T MULTIMEDIA, V17, P3, DOI 10.1109/TMM.2014.2368273
   Khoreva A, 2015, PROC CVPR IEEE, P951, DOI 10.1109/CVPR.2015.7298697
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Maerki N, 2016, P 2016 IEEE C COMP V
   Nagaraja N, 2015, P 2015 IEEE INT C CO
   Pan S., 2016, MULTIMED TOOLS APPL, P1
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Perazzi Federico, 2016, 2016 IEEE C COMP VIS
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sun DQ, 2013, PROC CVPR IEEE, P2451, DOI 10.1109/CVPR.2013.317
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Tsai YH, 2016, IEEE INT CONF MULTI
   Varas D, 2014, P 2014 IEEE C COMP V
   Vijayanarasimhan S, 2012, LECT NOTES COMPUT SC, V7576, P496, DOI 10.1007/978-3-642-33715-4_36
   Wang JW, 2017, MULTIMED TOOLS APPL, V76, P23721, DOI 10.1007/s11042-016-4153-0
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao L, 2016, IEEE CONF COMPUT
   Xu CL, 2016, INT J COMPUT VISION, V119, P272, DOI 10.1007/s11263-016-0906-5
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhang Y, 2015, J COMPUT SCI TECH-CH, V30, P467, DOI 10.1007/s11390-015-1537-y
   Zhong F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661281
   Zhong F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366194
NR 40
TC 7
Z9 11
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6117
EP 6133
DI 10.1007/s11042-017-4520-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800045
DA 2024-07-18
ER

PT J
AU Kumar, K
   Shrimankar, DD
   Singh, N
AF Kumar, Krishan
   Shrimankar, Deepti D.
   Singh, Navjot
TI Eratosthenes sieve based key-frame extraction technique for event
   summarization in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event; Video summarization; K-means clustering; Multimedia analysis;
   Eratosthenes sieve; Davies bouldin index
ID SPORTS VIDEO; HIGHLIGHTS
AB The rapid growth of video data demands both effective and efficient video summarization methods so that users are empowered to quickly browse and comprehend a large amount of video content. It is a herculean task to manage access to video content in real time where humongous amount of audiovisual recorded data is generated every second. In this paper we propose an Eratosthenes Sieve based key-frame extraction approach for video summarization (VS) which can work better for real-time applications. Here, Eratosthenes Sieve is used to generate sets of all Prime number frames and nonprime number frames up to total N frames of a video. k-means clustering procedure is employed on these sets to extract the key-frames quickly. Here, the challenge is to find the optimal set of clusters, achieved by employing Davies-Bouldin Index (DBI). DBI a cluster validation technique which allows users with free parameter based VS approach to choose the desired number of key-frames without incurring additional computational costs. Moreover, our proposed approach includes likes of both local and global perspective videos. The method strongly enhances clustering procedure performance trough engagement of Eratosthenes Sieve. Qualitative and quantitative evaluation and complexity computation are done in order to compare the performances of the proposed model and state-of-the-art models. Experimental results on two benchmark datasets with various types of videos exhibit that the proposed methods outperform the state-of-the-art models on F-measure.
C1 [Kumar, Krishan; Shrimankar, Deepti D.] Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.
   [Kumar, Krishan; Singh, Navjot] Natl Inst Technol Uttarakhand, Srinagar, Garhwal, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; National Institute of Technology (NIT
   System); National Institute of Technology Uttarakhand
RP Kumar, K (corresponding author), Visvesvaraya Natl Inst Technol, Nagpur, Maharashtra, India.; Kumar, K (corresponding author), Natl Inst Technol Uttarakhand, Srinagar, Garhwal, India.
EM kkberwal@nituk.ac.in; dshrimankar@cse.vnit.ac.in;
   navjot.singh.09@gmail.com
RI Berwal, Krishan/AAC-3473-2020; Kumar, Dr. Krishan/N-9846-2018; Kumar,
   Krishan/AAE-1656-2021; Singh, Navjot/I-5444-2017
OI Berwal, Krishan/0000-0002-7068-6541; Kumar, Dr.
   Krishan/0000-0002-7068-6541; Singh, Navjot/0000-0003-0409-8482
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Chang P, 2002, IEEE IMAGE PROC, P609
   Chen F, 2014, IEEE T MULTIMEDIA, V16, P455, DOI 10.1109/TMM.2013.2291967
   Chowdhury AS, 2012, INT C PATT RECOG, P3108
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dagtas S, 2004, MULTIMEDIA SYST, V9, P586, DOI 10.1007/s00530-003-0130-3
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gao L, 2016, 14 EUR C COMP VIS
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Gu L, 1999, P EUR WORKSH MULT MU, P3
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Guo Z, 2016, NEUROCOMPUTING, V208, P299, DOI 10.1016/j.neucom.2016.03.083
   John PJP, 1996, BIOPSYCHOLOGY, P170
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nagasaka A, 1991, 2 WORK C VIS DAT SYS, P119
   Ouyang JQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2800, DOI 10.1109/ICMLC.2003.1260028
   Pan H, 2001, INT CONF ACOUST SPEE, P1649, DOI 10.1109/ICASSP.2001.941253
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Ricardo B-Y, 1999, MODERN INFORM RETRIE, P463
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2417, P512, DOI 10.1117/12.206078
   Singh N, 2017, MULTIMED TOOLS APPL, V76, P10521, DOI 10.1007/s11042-016-3676-8
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vermaak Jaco, 2002, BMVC, P1
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1951, DOI 10.1109/ICME.2004.1394643
   Wang SF, 2015, IEEE T AFFECT COMPUT, V6, P410, DOI 10.1109/TAFFC.2015.2432791
   Weisstein EW, 2016, SIEVE ERATOSTHENES
   Xiong Z., 2005, UNIFIED FRAMEWORK VI
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P421, DOI 10.1109/TMM.2008.917346
   Yue Gao, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P269, DOI 10.1007/978-3-319-14445-0_24
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
   Ziyou Xiong, 2004, 2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763), P1947, DOI 10.1109/ICME.2004.1394642
NR 51
TC 57
Z9 58
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7383
EP 7404
DI 10.1007/s11042-017-4642-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700044
DA 2024-07-18
ER

PT J
AU Mirloo, M
   Ebrahimnezhad, H
AF Mirloo, Mahsa
   Ebrahimnezhad, Hossein
TI Non-rigid 3D object retrieval using directional graph representation of
   wave kernel signature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-rigid 3D model; Object retrieval; Directional graph; Wave kernel
   signature
ID SHAPE RETRIEVAL
AB Extensive use of three dimensional models in various areas indicates the importance of 3D data retrieval accuracy. In this paper, a directional graph, is introduced for 3D model retrieval. The proposed directional graph is isometric invariant and extracts the features of 3D model vertices in a way that both provides a sample of the features of each salient part and illustrates how various parts are linked and connected with each other. Directionality of the graph does not refer to a certain physical direction, but it shows the arrangement of different points in the graph. The proposed method commences with determining the salient points and continues with constructing a directional graph. Each branch of the graph starts from one salient point in the 3D model and ends in another salient point of that model. The points between the beginning and end of each branch are the vertices of 3D model from which the shortest geodesic path between these two salient points crosses. The whole graph of each model is constructed out of the accumulation of multiple branches, each of which is associated with a pair of salient points. After constructing of the directional graph, WKS is calculated in the path of graph points as the geometric feature of the model. In fact, the points of the directional graph do not provide any information on the object features and they only specify the location where the features should be calculated. The features are calculated and placed in the graph points so, the final graph is built. After completing the feature extraction process, the difference between various models is estimated using Munkres Assignment problem. The experimental results indicate the effectiveness of the directional graph in object description for non-rigid 3D model retrieval. Comparing the proposed method with other approaches by computing the evaluation parameters as well as investigating the computational complexity substantiates the superior performance of it.
C1 [Mirloo, Mahsa; Ebrahimnezhad, Hossein] Sahand Univ Technol, Fac Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Fac Elect Engn, Comp Vis Res Lab, Tabriz, Iran.
EM m_mirloo@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Agathos A, 2010, VISUAL COMPUT, V26, P1301, DOI 10.1007/s00371-010-0523-1
   Agathos A, 2010, VISUAL COMPUT, V26, P63, DOI 10.1007/s00371-009-0383-8
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019
   Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Cao Yi., 2008, Munkres Assignment Algorithm
   Del Bimbo A, 2006, ACM T MULTIM COMPUT, V2, P20
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Kazmi Ismail Khalid, 2013, 2013 10th International Conference on Computer Graphics, Imaging and Visualization (CGIV), P1, DOI 10.1109/CGIV.2013.11
   Kuang ZZ, 2015, MULTIMED TOOLS APPL, V74, P10335, DOI 10.1007/s11042-014-2170-4
   Kuang ZZ, 2015, COMPUT GRAPH-UK, V46, P209, DOI 10.1016/j.cag.2014.09.033
   Kuang ZZ, 2015, COMPUT AIDED DESIGN, V58, P13, DOI 10.1016/j.cad.2014.08.004
   Li CY, 2014, MULTIMEDIA SYST, V20, P253, DOI 10.1007/s00530-013-0318-0
   Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3
   Li ZM, 2016, COMPUT GRAPH-UK, V54, P8, DOI 10.1016/j.cag.2015.07.002
   Lian Z, 2010, SHREC 10 TRACK NONRI
   Lian ZH, 2013, MACH VISION APPL, V24, P1685, DOI 10.1007/s00138-013-0501-5
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Liu ZB, 2015, NEUROCOMPUTING, V151, P583, DOI 10.1016/j.neucom.2014.06.090
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Mademlis A, 2009, PATTERN RECOGN, V42, P2447, DOI 10.1016/j.patcog.2009.04.024
   Masoumi M, 2016, PATTERN RECOGN LETT, V83, P339, DOI 10.1016/j.patrec.2016.04.009
   Mohamed HH, 2015, NEUROCOMPUTING, V168, P790, DOI 10.1016/j.neucom.2015.05.045
   Mohamed W., 2016, APPL INTELL, V45, P1
   Novotni M, 2004, COMPUT AIDED DESIGN, V36, P1047, DOI 10.1016/j.cad.2004.01.005
   Peyré G, 2011, COMPUT SCI ENG, V13, P94, DOI 10.1109/MCSE.2011.71
   Pickup D, 2015, PATTERN RECOGN, V48, P2500, DOI 10.1016/j.patcog.2015.02.021
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Savelonas MA, 2016, PATTERN RECOGN, V55, P114, DOI 10.1016/j.patcog.2016.02.003
   Sfikas K, 2012, VISUAL COMPUT, V28, P943, DOI 10.1007/s00371-012-0714-z
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Smeets D, 2009, LECT NOTES COMPUT SC, V5702, P757, DOI 10.1007/978-3-642-03767-2_92
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tabia H, 2015, IEEE T MULTIMEDIA, V17, P1591, DOI 10.1109/TMM.2015.2457676
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Toldo R, 2010, VISUAL COMPUT, V26, P1257, DOI 10.1007/s00371-010-0519-x
   Yang YB, 2007, IEEE T SYST MAN CY C, V37, P1081, DOI 10.1109/TSMCC.2007.905756
   Zhang Y, 2016, NEUROCOMPUTING, V195, P40, DOI 10.1016/j.neucom.2015.09.118
   Zhouhui Lian, 2010, Proceedings of the Shape Modeling International (SMI 2010), P25, DOI 10.1109/SMI.2010.20
NR 44
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6987
EP 7011
DI 10.1007/s11042-017-4617-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700026
DA 2024-07-18
ER

PT J
AU Zhang, XM
   Zhang, X
   Li, X
   Li, ZJ
   Wang, SZ
AF Zhang, Xiaoming
   Zhang, Xu
   Li, Xiong
   Li, Zhoujun
   Wang, Senzhang
TI Classify social image by integrating multi-modal content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Multi-modal classification; Social image analysis
ID MATRIX
AB There is a growing volume of social images with the development of social networks and digital cameras. Usually, these images are annotated with textual tags besides the visual content. It is quite urgent to automatically organize and manage this large number of social images. Image classification is the basic task of these applications and has attracted great research efforts. Though there are many researches on image classification, it is of considerable challenge to integrate the multi-modal content of social images simultaneously for classification, since the textual content and visual content are represented in two heterogeneous feature spaces. In this paper, we proposed a multi-modal learning method to integrate multi-modal features through their correlation seamlessly. Specifically, we learn two linear classification modules for the two types of features, and then they are integrated by the l (2) normalization method via a joint model. Each classier is normalized with l (2,1) to reduce the effect of the noisy features by selecting a subset of more important features. With the joint model, the classification based on visual features can be reinforced by the classification based on textual features, and vice verse. Then, the test image is classified based on both the textual features and visual features by combing the results of the two classifiers. Experiments conducted on real-world social image datasets demonstrate the superiority of our proposed method compared with the representative baselines.
C1 [Zhang, Xiaoming] Beihang Univ, Beijing Key Lab Network Technol, Beijing, Peoples R China.
   [Zhang, Xu; Li, Xiong] Natl Comp Network Emergency Response Tech Team Ch, Beijing, Peoples R China.
   [Li, Zhoujun] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China.
   [Wang, Senzhang] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
C3 Beihang University; Beihang University; Nanjing University of
   Aeronautics & Astronautics
RP Zhang, X (corresponding author), Natl Comp Network Emergency Response Tech Team Ch, Beijing, Peoples R China.
EM yolixs@buaa.edu.cn; zhangxu@cert.org.cn
RI Li, Kexin/KAO-2519-2024
OI Li, Zhoujun/0000-0002-9603-9713
FU National Natural Science Foundation of China [61202239, U1636210,
   U163610106, 61403090]; Fundamental Research Funds for the Central
   Universities [YWF-14-JSJXY-16]; Fund of the State Key Laboratory of
   Software Development Environment [SKLSDE-2015ZX-11]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61202239, No. U1636210, U163610106, and No.
   61403090), in part by the Fundamental Research Funds for the Central
   Universities (No. YWF-14-JSJXY-16), and in part by the Fund of the State
   Key Laboratory of Software Development Environment (No.
   SKLSDE-2015ZX-11)
CR [Anonymous], INT LNAI 06 C
   [Anonymous], SEMIAUTOMATIC PHOTO
   [Anonymous], GRAPH EMBEDDING EXTE
   [Anonymous], 2005, INT JOINT C ART INT
   [Anonymous], 2002, THESIS STANFORD U
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ADV NEURAL INF PROCE
   [Anonymous], IEEE T GEOSCI REMOTE
   [Anonymous], ARXIV160406620
   [Anonymous], 2007, P 6 ACM INT C IM VID
   [Anonymous], P INT CLA C
   [Anonymous], PERSONALIZED SOCIAL
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], LEARN COMPUT SCI
   [Anonymous], P ACM INT C MULT RET
   [Anonymous], IEEE TVCG
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Brefeld U., 2006, Proceedings of the 23rd international conference on Machine learning, P137, DOI [10.1145/1143844.1143862, DOI 10.1145/1143844.1143862]
   Brefeld U, 2004, P 21 INT C MACH LEAR, P16
   Cabral R, 2015, IEEE T PATTERN ANAL, V37, P121, DOI 10.1109/TPAMI.2014.2343234
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Farquhar J.D. R., 2005, NIPS
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Kloft M, 2011, J MACH LEARN RES, V12, P953
   Krishnapuram B., 2004, Advances in Neural Information Processing Systems, V17, P721
   Lanckriet Gert, 2002, ICML'02: Proceedings of the Nineteenth International Conference on Machine Learning, V5, P323, DOI 10.1023/B:JODS.0000012018.62090.a7
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Liu NN, 2013, COMPUT VIS IMAGE UND, V117, P493, DOI 10.1016/j.cviu.2012.10.009
   Liu Y, 2011, PATTERN RECOGN, V44, P2287, DOI 10.1016/j.patcog.2010.12.012
   Lu Zhongqi, 2014, P 28 AAAI C ART INT
   Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Tao DP, 2015, INFORM SCIENCES, V320, P383, DOI 10.1016/j.ins.2015.03.031
   Tollari S., 2007, CIVR 07, P65
   van Noord N, 2017, PATTERN RECOGN, V61, P583, DOI 10.1016/j.patcog.2016.06.005
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang LQ, 2016, NEUROCOMPUTING, V171, P242, DOI 10.1016/j.neucom.2015.06.064
   Wang X., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P236, DOI 10.1145/1148170.1148214
   Wozniak M, 2009, LECT NOTES ARTIF INT, V5572, P541, DOI 10.1007/978-3-642-02319-4_65
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Zhou SS, 2013, NEURAL PROCESS LETT, V38, P17, DOI 10.1007/s11063-012-9260-y
NR 54
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7469
EP 7485
DI 10.1007/s11042-017-4657-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700048
DA 2024-07-18
ER

PT J
AU Cheng, D
   Gong, YH
   Shi, WW
   Zhang, SZ
AF Cheng, De
   Gong, Yihong
   Shi, Weiwei
   Zhang, Shizhou
TI Person re-identification by the asymmetric triplet and identification
   loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Triplet loss; Joint; Identification
ID DEEP
AB Person re-identification(re-id) aims to match the same individuals across different non-overlapping camera views. In this paper, we analyze the effectiveness of two widely used triplet loss and softmax loss on person re-id task. We conclude that the triplet loss function is suitable for the relatively small datasets with the shallow neural network, while the softmax loss works better on larger datasts with relatively deeper network architecture. Both of them are essential to the person re-id task. Moreover, we present a convolutional neural network (CNN) model under the joint supervision of the triplet loss and softmax loss for person re-id. This method can get a slightly better performance than either of them. The triplet loss makes the distance of the same individual's images closer, and pushes the instances of different individuals far apart from each other, which can effectively reduce the intra-personal variations. Meanwhile, the person identification cost, which is implemented by the softmax loss with the "center loss" embedded, can discriminatively learn some identity-related feature representations (i.e. features with large inter-personal variations). Extensive experimental results demonstrate the effectiveness of our proposed method, and we have obtained promising performance on the challenging i-LIDS, PRID2011 and CUHK03 datasets.
C1 [Cheng, De; Gong, Yihong; Shi, Weiwei; Zhang, Shizhou] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Sch Elect & Informat Engn, Xian Ning West Rd 28, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Cheng, D (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Sch Elect & Informat Engn, Xian Ning West Rd 28, Xian 710049, Shaanxi, Peoples R China.
EM chengdexjtu@qq.com
FU National Basic Research Program of China [2015CB351705]; State Key
   Program of National Natural Science Foundation of China [61332018]
FX This work was supported by the National Basic Research Program of China
   (Grant No. 2015CB351705), the State Key Program of National Natural
   Science Foundation of China (Grant No. 61332018).
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2012, BRIT MACH VIS C
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], IEEE T CYBERN
   [Anonymous], PROC CVPR IEEE
   [Anonymous], HOM OFF I LIDS MULT
   [Anonymous], 2011, BRIT MACH VIS C DUND
   [Anonymous], ARXIV161106026
   [Anonymous], ARXIV150301543
   [Anonymous], ARXIV150303832
   [Anonymous], ARXIV161105666
   [Anonymous], DIFFERENCES
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Davis J. V., 2007, ICML, P209
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Doll ar, 2007, CVPR, P1
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Globerson A., 2005, ADV NEURAL INFORM PR
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Park U, 2006, INT C PATT RECOG, P1204
   Roth PM, 2014, ADV COMPUT VIS PATT, P247, DOI 10.1007/978-1-4471-6296-4_12
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Sun Y, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng N, 2017, P 26 INT JOINT C ART, P964
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
NR 59
TC 12
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3533
EP 3550
DI 10.1007/s11042-017-5182-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600034
DA 2024-07-18
ER

PT J
AU Hong, HS
   Sun, ZX
AF Hong, Hanshu
   Sun, Zhixin
TI Achieving secure data access control and efficient key updating in
   mobile multimedia sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMSN; Security; Access control; Encryption
ID ENCRYPTION; SCHEME
AB MMSN is a new type of wireless sensor networks, which can satisfy the demands of capturing various structures of multimedia data. Due to its better performance in monitoring the target environment, MMSN has already been applied to many fields and scenarios. However, MMSN also faces with various security threatens and data privacy is one issue urgently to be solved. In this paper, we propose an attribute based encryption scheme to guarantee the secure data sharing in MMSN. In our scheme, a user can only get access to the encrypted multimedia data if his private key satisfies with the access structure. We divide the system lifetime of MMSN into discrete time periods and embed the current time period information into user's private key. When time evolves, only part of the private key has to be updated and the system public parameters remain unchanged. This can reduce the key-updating computation cost and minimize the energy consumption for system parameter transmission when attribute revocation or private key exposure happens. By security proof and efficiency analysis, we prove our scheme is confidential and of higher efficiency, which makes it more appropriate for secure data protection in MMSN.
C1 [Hong, Hanshu; Sun, Zhixin] Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Networ, Minist Educ, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Hong, HS (corresponding author), Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Networ, Minist Educ, Nanjing, Jiangsu, Peoples R China.
EM hhskaka@163.com
FU National Natural Science Foundation of China [61373135, 61672299]
FX This research is supported by the National Natural Science Foundation of
   China (61373135, 61672299). The authors thank the sponsors for their
   support and the reviewers for helpful comments.
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   [Anonymous], 2011, PROC INT WORKSHOP PU
   [Anonymous], 2012, ADV COMPUTER SCI INF
   Attrapadung N, 2011, LECT NOTES COMPUT SC, V6571, P90, DOI 10.1007/978-3-642-19379-8_6
   Baek J, 2008, PROCEEDINGS OF THE IFIP TC 11/ 23RD INTERNATIONAL INFORMATION SECURITY CONFERENCE, P95
   Bertoni G, 2005, P CHES 05 WORKSH CRY
   Chen L, 2007, INT J INF SECUR, V6, P213, DOI 10.1007/s10207-006-0011-9
   Chen M, 2011, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2011-159
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Guerrero-Zapata M, 2010, TELECOMMUN SYST, V45, P77, DOI 10.1007/s11235-009-9235-0
   Hu CQ, 2013, IEEE J SEL AREA COMM, V31, P37, DOI 10.1109/JSAC.2013.SUP.0513004
   Lewko A, 2010, LECT NOTES COMPUT SC, V6110, P62, DOI 10.1007/978-3-642-13190-5_4
   Lopez J, 2009, LECT NOTES COMPUT SC, V5705, P289, DOI 10.1007/978-3-642-03829-7_10
   Melodia T, 2011, DISTRIBUTED VIDEO SENSOR NETWORKS, P233, DOI 10.1007/978-0-85729-127-1_16
   Ruj S., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P352, DOI 10.1109/IPDPS.2011.42
   Sahai A, 2005, LECT NOTES COMPUT SC, V3494, P457, DOI 10.1007/11426639_27
   Sharif A, 2009, IEEE INTL CONF IND I, P606, DOI 10.1109/INDIN.2009.5195872
   Sun Q, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 2, WORKSHOPS, P651, DOI 10.1109/EUC.2008.37
   Tan CC, 2009, IEEE T INF TECHNOL B, V13, P926, DOI 10.1109/TITB.2009.2033055
   Tan YL, 2011, COMM COM INF SC, V251, P238
   Tian Y, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/259798
   Varalakshmi LM, 2014, TELECOMMUN SYST, V56, P357, DOI 10.1007/s11235-013-9849-0
   Wander AS, 2005, Third IEEE International Conference on Pervasive Computing and Communications, Proceedings, P324, DOI 10.1109/PERCOM.2005.18
   Xie L. F., 2010, WIR MOB NETW C WMNC, P1
   Yu SC, 2011, IEEE T PARALL DISTR, V22, P673, DOI 10.1109/TPDS.2010.130
NR 25
TC 12
Z9 12
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4477
EP 4490
DI 10.1007/s11042-017-4804-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500025
DA 2024-07-18
ER

PT J
AU Wang, HN
   Lv, YD
   Chen, H
   Li, YJ
   Zhang, Y
   Lu, ZH
AF Wang, Hainan
   Lv, Yiding
   Chen, Hong
   Li, Yujie
   Zhang, Yin
   Lu, Zhihai
TI Smart pathological brain detection system by predator-prey particle
   swarm optimization and single-hidden layer neural-network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Predator-prey particle swarm optimization; Computer-aided diagnosis;
   Magnetic resonance imaging; Single-hidden layer neural-network
ID IMAGE CLASSIFICATION; ALZHEIMERS-DISEASE; WAVELET ENTROPY; DECISION
   TREE; MACHINE; TRANSFORM; INVARIANT
AB In order to develop an artificial intelligence and computer-aided diagnosis system that assists neuroradiologists to interpret magnetic resonance (MR) images. This paper employed Hu moment invariant (HMI) as the brain image features, and we proposed a novel predator-prey particle swarm optimization (PP-PSO) algorithm used to train the weights of single-hidden layer neural-network (SLN). We used five-fold stratified cross validation (FFSCV) for statistical analysis. Our proposed HMI + SLN + PP-PSO method achieved a sensitivity of 96.00 +/- 5.16%, a specificity of 98.57 +/- 0.75%, and an accuracy of 98.25 +/- 0.65% for the DA-160 dataset, and yields a sensitivity of 97.14 +/- 2.33%, a specificity of 97.00 +/- 0.34%, and an accuracy of 97.02 +/- 0.33% for the DA-255 dataset. Our method performs better than six state-of-the-art approaches.
C1 [Wang, Hainan; Lv, Yiding; Lu, Zhihai] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Wang, Hainan; Lv, Yiding; Lu, Zhihai] Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.
   [Chen, Hong] Nanjing Med Univ, Affiliated Hosp 1, Dept Neurol, Nanjing 210029, Jiangsu, Peoples R China.
   [Li, Yujie] Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
C3 Nanjing Normal University; Nanjing Normal University; Nanjing Medical
   University; Yangzhou University; Zhongnan University of Economics & Law
RP Lu, ZH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Lu, ZH (corresponding author), Nanjing Normal Univ, Sch Educ Sci, Nanjing 210023, Jiangsu, Peoples R China.; Li, YJ (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Jiangsu, Peoples R China.; Zhang, Y (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
EM liyujie@yzu.edu.cn; yin.zhang.cn@ieee.org; luzhihai@njnu.edu.cn
RI Li, YuJie/JAC-4451-2023; Li, Yujie/AAH-3298-2019; Li,
   YuJie/HGT-8657-2022; Zhang, Yin/K-2414-2019; Zhang, Yin/O-2149-2015
OI Li, Yujie/0000-0002-0275-2797; Zhang, Yin/0000-0002-8103-8937; Zhang,
   Yin/0000-0002-1772-0763
CR Agarwal  P., 2014, SCI WORLD J
   Agarwal P, 2016, MATH PROBL ENG
   Alweshah M, 2015, APPL SOFT COMPUT, V35, P513, DOI 10.1016/j.asoc.2015.06.018
   Awan AU, 2016, INT J PRECIS ENG MAN, V17, P409, DOI 10.1007/s12541-016-0051-7
   Banerjee S, 2016, INT J ELEC POWER, V81, P275, DOI 10.1016/j.ijepes.2016.01.031
   Bansod PV, 2016, APPL ACOUST, V112, P41, DOI 10.1016/j.apacoust.2016.05.011
   Buyukada M, 2016, BIORESOURCE TECHNOL, V216, P280, DOI 10.1016/j.biortech.2016.05.091
   Chen XY, 2016, WATER RESOUR MANAG, V30, P2179, DOI 10.1007/s11269-016-1281-2
   Chen Y, 2008, J MATH IMAGING VIS, V30, P133, DOI 10.1007/s10851-007-0042-5
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Das S, 2013, PROG ELECTROMAGN RES, V137, P1, DOI 10.2528/PIER13010105
   Duan HB, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4754-9
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   Fu MY, 2014, CHIN CONTR CONF, P670, DOI 10.1109/ChiCC.2014.6896705
   Gorriz J. M., 2016, FRONT COMPUT NEUROSC, V10
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jang WS, 2007, COMM COM INF SC, V2, P370
   Jia SM, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P1581, DOI 10.1109/ICMA.2014.6885936
   Kumar M, 2016, APPL COMPUT INTELL S, V2016, DOI 10.1155/2016/6304915
   Liu G., 2016, ENTROPY, V8, P11
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Lu ZH, 2016, J MED IMAG HEALTH IN, V6, P1218, DOI 10.1166/jmihi.2016.1901
   Mallick S, 2016, INT J NUMER MODEL EL, V29, P943, DOI 10.1002/jnm.2155
   Oyedotun OK, 2016, APPL INTELL, V45, P198, DOI 10.1007/s10489-015-0753-z
   Shan R, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060175
   Sharma MK, 2016, NEURAL COMPUT APPL, V27, P1369, DOI 10.1007/s00521-015-1940-x
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang SH, 2015, ENTROPY-SWITZ, V17, P8278, DOI 10.3390/e17127877
   Wang SH, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/454076
   Wang SH, 2015, ENTROPY-SWITZ, V17, P6663, DOI 10.3390/e17106663
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Yang JC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0145800
   Zeng R, 2016, NEUROCOMPUTING, V216, P416, DOI 10.1016/j.neucom.2016.08.006
   Zhang GS, 2015, AER ADV ENG RES, V8, P683
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YD, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1523-4
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2013, SCI WORLD J, DOI 10.1155/2013/528069
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, TECHNOL HEALTH CARE, V24, pS641, DOI 10.3233/THC-161191
   Zhang YD, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0525-2
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, PROG ELECTROMAGN RES, V152, P41, DOI 10.2528/PIER15040602
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2014, KNOWL-BASED SYST, V64, P22, DOI 10.1016/j.knosys.2014.03.015
   Zhang YD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/840491
   Zhang YD, 2014, PROG ELECTROMAGN RES, V144, P171, DOI 10.2528/PIER13121310
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zhang YD, 2011, SENSORS-BASEL, V11, P4721, DOI 10.3390/s110504721
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhang YD, 2009, SCI CHINA SER F, V52, P914, DOI 10.1007/s11432-009-0019-7
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
   Zunic J, 2016, MACH VISION APPL, V27, P129, DOI 10.1007/s00138-015-0730-x
NR 61
TC 12
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3871
EP 3885
DI 10.1007/s11042-016-4242-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600054
DA 2024-07-18
ER

PT J
AU Zhang, MJ
   Ma, Z
   Zhang, Y
   Wang, YB
AF Zhang, Manjun
   Ma, Zheng
   Zhang, Yan
   Wang, Yongbin
TI RETRACTED: An identity authentication scheme based on cloud computing
   environment (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Cloud computing; Identity authentication; Dynamic key
ID KEYSTROKE DYNAMICS
AB In order to solve the shortcomings of traditional identity authentication technology, such as low security, low efficiency, a mobile terminal identity authentication scheme based on cloud computing environment is proposed in this paper. In addition, the two-dimensional code technology is used for identity authentication in the cloud computing environment, and the QR coding technology is also used. The dynamic authentication of the mobile terminal is realized by using the two-dimensional code as the information transmission carrier. According to the security analysis, the scheme has simple structure and no need to use the third party equipment, which has high security and adaptability. Finally, the two fusion of two-dimensional code proposed in this paper provides a new way of thinking for the identity authentication based on the cloud environment, and also promotes the development of the Internet of things.
C1 [Zhang, Manjun] China Unicom, Network Technol Res Inst, Beijing 100000, Peoples R China.
   [Ma, Zheng] Beijing Univ Posts & Telecommun, Inst Network Technol, Beijing, Peoples R China.
   [Zhang, Yan; Wang, Yongbin] China Unicom, Dept Technol, Beijing, Peoples R China.
C3 China United Network Communications Limited; Beijing University of Posts
   & Telecommunications; China United Network Communications Limited
RP Zhang, MJ (corresponding author), China Unicom, Network Technol Res Inst, Beijing 100000, Peoples R China.
EM jukenhan541624@yeah.net
RI ma, zheng/IRY-8826-2023
FU Mobile Communication Network and Intelligent Terminal Security Situation
   Awareness Research Project, Network Technology Research Institute of
   China Unicom [NT12-9301-2017-000132]
FX The study was supported by "Mobile Communication Network and Intelligent
   Terminal Security Situation Awareness Research Project, Network
   Technology Research Institute of China Unicom (Grant No.
   NT12-9301-2017-000132)".
CR Cao J, 2013, OPTICAL PRECISION EN, V21, P1598
   Cho S, 2000, J ORG COMP ELECT COM, V10, P295, DOI 10.1207/S15327744JOCE1004_07
   Gui Zhenwen, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P34
   Karnan M, 2011, APPL SOFT COMPUT, V11, P1565, DOI 10.1016/j.asoc.2010.08.003
   Ke J, 2014, MICROELECTRONICS COM, V31, P89
   Lee Shirly, 2010, Journal of Information and Communication Convergence Engineering, V8, P427
   Li L, 2011, COMPUTER INTEGRATED, V17, P55
   Lin Wei, 2010, Computer Engineering, V36, P154
   Ma Wen-jian, 2008, Computer Integrated Manufacturing Systems, V14, P630
   Oliveira LB, 2011, COMPUT COMMUN, V34, P485, DOI 10.1016/j.comcom.2010.05.013
   Sood SK, 2011, J NETW COMPUT APPL, V34, P609, DOI 10.1016/j.jnca.2010.11.011
   Wang W, 2006, VQ J CHINESE SOC INS, V27, P2155
   Wang Zhi-liang, 2006, Computer Integrated Manufacturing Systems, V12, P947
   Xiao D, 2007, INFORM SCIENCES, V177, P1136, DOI 10.1016/j.ins.2006.07.026
   Xu Duo, 2006, Chinese Journal of Mechanical Engineering, V42, P23, DOI 10.3901/JME.2006.01.023
   Xu Z, 2012, SYSTEM ENG ELECT TEC, V34, P1412
   Xue K, 2011, SCI TECHNOLOGY ENG, V11, P20
NR 17
TC 6
Z9 6
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4283
EP 4294
DI 10.1007/s11042-017-4552-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500013
DA 2024-07-18
ER

PT J
AU Limna, T
   Tandayya, P
AF Limna, Thanathip
   Tandayya, Pichaya
TI Workload scheduling for Nokkhum video surveillance as a service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance system; Video surveillance as a service; Scheduling;
   Workload analysis
AB Video Surveillance Systems (VSS) on the Internet as known as Video Surveillance as a Service (VSaaS) or Cloud based Video Surveillance (CVS) systems. Video processing workload analysis has usually employed only one category of static video processing attribute, such as a frame rate with a single frame size on the same computing node specification, but VSaaS must handle a variety of video processing attributes. Also, in a static workload, it is difficult to identify the resource consumption of video processing attributes, especially involving a combination of frame rates and sizes on different computing nodes on virtual or physical machines. Consequently, it is difficult to place a task on a computing node if the resource usage information is unknown to the scheduler. In this paper, the video processing workload characteristics utilize various parameters, such as the type of video processing task, frame rate, frame size, and compute node specification. The analysis results have helped us to design a scheduler that supports different computing node specifications. We explore video processing workload for testing resource usage capacity in several computing nodes, and collect information for the scheduler's estimation. This paper also proposes a resource estimation module for predicting the video processing resource usage for a new video processing task when there is no matching or close estimation. Furthermore, we suggest scheduler criteria for optimizing system resource usage.
C1 [Limna, Thanathip; Tandayya, Pichaya] Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Songkhla, Thailand.
C3 Prince of Songkla University
RP Tandayya, P (corresponding author), Prince Songkla Univ, Fac Engn, Dept Comp Engn, Hat Yai, Songkhla, Thailand.
EM thanathip.limna@gmail.com; pichaya@coe.psu.ac.th
RI Tandayya, Pichaya/AAH-6051-2021
FU Thailand Research Fund; Prince of Songkla University through Royal
   Golden Jubilee Ph.D. Program [PHD/0047/2552]
FX The authors are grateful for financial support from the Thailand
   Research Fund and Prince of Songkla University through the Royal Golden
   Jubilee Ph.D. Program (Grant No. PHD/0047/2552).
CR Alam A., 2015, MOSS FLORA INDIA UPD, P1
   Crockford D., 2006, P XML, V2006
   Fielding R. T, 2002, ACM Transactions on Internet Technology (TOIT), V2, P115, DOI [DOI 10.1145/514183.514185, 10.1145/514183.514185]
   Hossain MA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/135257
   Hossain MS, 2014, MULTIMED TOOLS APPL, V73, P169, DOI 10.1007/s11042-012-1312-9
   Hossain MS, 2012, IEEE INT CONF MULTI, P408, DOI 10.1109/ICMEW.2012.77
   JongHyuk Lee, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P147, DOI 10.1109/CLOUD.2012.141
   Karimaa A, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON DEPENDABILITY (DEPEND 2011), P92
   Kivity A., 2007, P LIN S DTTAW DNTOR, V1, P225
   Limna T, 2016, MULTIMED TOOLS APPL, V75, P1765, DOI 10.1007/s11042-014-2373-8
   Lin CF, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P655, DOI 10.1109/UIC-ATC.2012.72
   Miao Dan., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1237
   Nan XM, 2011, IEEE INT WORKSH MULT
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Prat Andrea., 2013, The Political Economy of Mass Media, P1
   Vinoski S, 2006, IEEE INTERNET COMPUT, V10, P87, DOI 10.1109/MIC.2006.116
   Wu YS, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS INTELLIGENCE & COMPUTING AND 9TH INTERNATIONAL CONFERENCE ON AUTONOMIC & TRUSTED COMPUTING (UIC/ATC), P661, DOI 10.1109/UIC-ATC.2012.43
NR 17
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1363
EP 1389
DI 10.1007/s11042-016-4225-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400056
DA 2024-07-18
ER

PT J
AU Park, MW
   Kim, JI
   Lee, YJ
   Park, J
   Suh, W
AF Park, Man-Woo
   Kim, Jung In
   Lee, Young-Joo
   Park, Jinwoo
   Suh, Wonho
TI Vision-based surveillance system for monitoring traffic conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Vehicle detection; Vehicle tracking; Image processing
ID RAPID OBJECT DETECTION; VEHICLE DETECTION; TRACKING; CLASSIFICATION;
   FEATURES; SEGMENTATION
AB With the rapid advancement of sensing technologies, it has been feasible to collect various types of traffic data such as traffic volume and travel times. Vision-based approach is one of the major scheme actively used for the automated traffic data collection, and continues to gain traction to a broader utilization. It collects video streams from cameras installed near roads, and processes the video streams frame by frame using image processing algorithms. The widely used algorithms include vehicle detection and vehicle tracking which recognize every vehicle in the camera view and track it in the consecutive frames. Vehicle counts and speed can be estimated from the detection and tracking results. Continuous efforts have been made for the performance improvement of the algorithms and for their effective applications. However, little research has been found on the application to the various view settings of highway CCTV cameras as well as the reliability of the speed estimation. This paper proposes a vision-based system that integrates vehicle detection, vehicle tracking, and field of view calibration algorithms to obtain vehicle counting data and to estimate individual vehicle speed. The proposed system is customized for the video streams collected from highway CCTVs which have various settings in terms of focus and view angles. The system detects and tracks every vehicle in the view unless it is occluded by other vehicles. It is also capable of handling occlusions that occurs frequently depending on the view angles. The system has been tested on the several different views including congested scenes. Vehicle counts and speed estimation results are compared to the manual counting and GPS data, respectively. The comparison signifies that the system has a high potential to extract reliable information about highway traffic conditions from highway CCTVs.
C1 [Park, Man-Woo] Myongji Univ, 116 Myongji Ro, Yongin 17058, Gyeonggi Do, South Korea.
   [Kim, Jung In] Stanford Univ, Dept Civil & Environm Engn, 473 Via Ortega, Stanford, CA 94305 USA.
   [Lee, Young-Joo] UNIST, Sch Urban & Environm Engn, 50 UNIST Gil, Ulsan 44919, South Korea.
   [Park, Jinwoo; Suh, Wonho] Hanyang Univ, Dept Transportat & Logist Engn, 55 Hanyangdaehak Ro, Ansan 15588, South Korea.
C3 Myongji University; Stanford University; Ulsan National Institute of
   Science & Technology (UNIST); Hanyang University
RP Suh, W (corresponding author), Hanyang Univ, Dept Transportat & Logist Engn, 55 Hanyangdaehak Ro, Ansan 15588, South Korea.
EM mwpark@mju.ac.kr; jikim07@stanford.edu; ylee@unist.ac.kr;
   parkchuy10@hanyang.ac.kr; wonhosuh@hanyang.ac.kr
RI Park, Jin-Hong/F-1829-2014; Kim, Jung In/AAE-7483-2022; Lee, Young
   Joo/V-3932-2018
OI Kim, Jung In/0000-0003-0583-0348; 
FU Transportation & Logistics Research Program [ID-97344]; 
   [NRF-2014R1A1A2054793]
FX This work was supported by NRF-2014R1A1A2054793 and Transportation &
   Logistics Research Program ID-97344.
CR [Anonymous], 2006, Next generation simulation
   Bas E, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1085
   Bouttefroy PLM, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P61, DOI 10.1109/ITSC.2008.4732659
   Chaiyawatana N., 2011, Proceedings of the Eighth International Joint Conference on Computer Science and Software Engineering (JCSSE 2011), P149, DOI 10.1109/JCSSE.2011.5930111
   Ervin R., 2000, System for Assessment of the Vehicle Motion Environment (SAVME)
   Feris R., 2011, Proc. 2011 IEEE Workshop on Applications of Computer Vision (WACV), P527
   Gokule R, 2014, INT J ADV FDN RES CO, V1, P93
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Huang LL, 2010, INT ASIA CONF INFORM, P324, DOI 10.1109/CAR.2010.5456534
   Kanheer NK., 2008, VISION BASED DETECTI
   Kanhere NK, 2008, IEEE T INTELL TRANSP, V9, P148, DOI 10.1109/TITS.2007.911357
   Kanhere NK, 2007, TRANSPORT RES REC, P155, DOI 10.3141/1993-21
   Kanhere NK, 2010, IEEE T INTELL TRANSP, V11, P441, DOI 10.1109/TITS.2010.2045500
   Kim Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P524
   Kim Z., 2005, P 12 WORLD C INT TRA
   Kim Z, 2010, 13 INT IEEE ANN C IN, P99
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu T, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P124
   Malinovskiy Y, 2009, TRANSPORT RES REC, P81, DOI 10.3141/2121-09
   MCFARLANE NJB, 1995, MACH VISION APPL, V8, P187, DOI 10.1007/BF01215814
   Melo J, 2006, IEEE T INTELL TRANSP, V7, P188, DOI 10.1109/TITS.2006.874706
   Miovision, 2016, MIOV TRAFF DAT
   Mu KN, 2016, J INF PROCESS SYST, V12, P183, DOI 10.3745/JIPS.02.0040
   Rodríguez T, 2010, MACH VISION APPL, V21, P555, DOI 10.1007/s00138-009-0185-z
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Scharcanski J, 2011, IEEE T VEH TECHNOL, V60, P381, DOI 10.1109/TVT.2010.2099676
   Skimson E, 2016, EVOLUTION DATA DRIVE
   Sri Harsha S., 2016, INT J APPL ENG RES, V11, P3733
   Tamersoy B, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P529, DOI 10.1109/AVSS.2009.57
   TrafficVision, VID AN DET KC SCOUT
   Tsai Li-Wu., 2011, Energy Procedia, V13, P3174
   Tsuchiya M, 2006, INT C PATT RECOG, P978
   Uzkent B, 2016, IEEE COMPUT SOC CONF, P1443, DOI 10.1109/CVPRW.2016.181
   Vargas M, 2010, IEEE T VEH TECHNOL, V59, P3694, DOI 10.1109/TVT.2010.2058134
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xiong C-Z, 2009, P ICCTP 2009 CRIT IS, P486
   Yabo A, 2016, P AADECA 2016 SEM CO
   Zhang L, 2007, PROC CVPR IEEE, P3766
   Zhang ZX, 2008, INT C PATT RECOG, P3918
NR 39
TC 9
Z9 9
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25343
EP 25367
DI 10.1007/s11042-017-4521-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300044
DA 2024-07-18
ER

PT J
AU Sheu, JS
   Tsai, WH
AF Sheu, Jia-Shing
   Tsai, Wei-Hsiu
TI Implementation of a following wheel robot featuring stereoscopic vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robot vision; Image tracking; PID feedback control
ID SELF-CALIBRATION; SYSTEMS
AB This paper describes how two cameras were used to implement stereoscopic visual imaging through a robot vision system. Image processing was applied to construct a real-time stereoscopic image tracking system for use in robots. The target object was sought by image preprocessing. The deviation of the target object from the optical center of the two cameras was measured to calculate the stereoscopic image depth of the target object, and the target object was instantly locked for real-time tracking. This system consists of two parts. The first part uses depth calculation to determine the distance between the target object and robot platform and applies image processing to simplify the image. The deviation angles of the left and right images are subsequently measured to calculate the target object distance. The second part uses real-time image tracking so that the platform can lock the image of the target object into an overlapping image. Proportional-integral-derivative (PID) feedback controls the robot movement and instantly obtains the target object and offset direction. The signal is exported to dc servo motors to drive the rotation of the two cameras and the movement of the platform. The image of the target object is locked in the image center of the stereoscopic visual system for real-time tracking.
C1 [Sheu, Jia-Shing; Tsai, Wei-Hsiu] Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
C3 National Taipei University of Education
RP Sheu, JS (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM jiashing@tea.ntue.edu.tw; showsweetnow@yahoo.com.tw
OI Sheu, Jia-Shing/0000-0002-9498-3110
CR Ang KH, 2005, IEEE T CONTR SYST T, V13, P559, DOI 10.1109/TCST.2005.847331
   [Anonymous], 2011, THESIS
   BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032
   Christensen H. I., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P69, DOI 10.1142/S0218001493000054
   KASE H, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1791, DOI 10.1109/IECON.1993.339345
   Li Z., 2010, THESIS
   LIANG P, 1989, IEEE T SYST MAN CYB, V19, P811, DOI 10.1109/21.35344
   Lu MC, 2006, IEEE SENS J, V6, P495, DOI 10.1109/JSEN.2005.858434
   Okuyama Y, 2007, PROCEEDINGS OF SICE ANNUAL CONFERENCE, VOLS 1-8, P116
   Ren Y., 2008, THESIS
   Shish SM, 2008, IEEE INT C ADV ROB S, P23
   Sung-Hyun Han, 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P1762, DOI 10.1109/IROS.1999.811733
   TIRUMALAI AP, 1992, IEEE T PATTERN ANAL, V14, P1184, DOI 10.1109/34.177383
   Wei LX, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P683
   Wei S.K., 2010, THESIS
NR 15
TC 2
Z9 2
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25161
EP 25177
DI 10.1007/s11042-016-4297-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300034
DA 2024-07-18
ER

PT J
AU Shrivastava, S
   Singh, SK
   Hooda, DS
AF Shrivastava, Sourabh
   Singh, Satish Kumar
   Hooda, D. S.
TI Soybean plant foliar disease detection using image retrieval approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Disease analysis; Disease retrieval; Disease segmentation; Image
   retrieval
ID COLOR; TEXTURE; CLASSIFICATION; SEVERITY; FEATURES; RUST
AB A research to solve the soybean foliar disease detection problem is proposed through the image retrieval method. We explore the suitability of image retrieval methods to categorize the diseases of the soybean plants. To solve this problem we present two feature descriptors HIST and WDH, also explore several other colors and texture based feature descriptors such as BIC, CCV, CDH, LBP, SSLBP, LAP and SEH. Research presents an efficient method for soybean disease retrieval and classification method using background subtraction. This research helps to identify the infected lesion pattern which is fully automated and does not require human intervention at any stage. The robustness of the segmentation approach is also verified over six types of the soybean plant diseases. We analyze the statistical and spectral information of the infected portion to model the descriptors. Research test several colors and texture based visual feature descriptors using retrieval based approaches to solve the stated problem.
C1 [Shrivastava, Sourabh] Indian Inst Informat Technol, Pune 412109, Maharashtra, India.
   [Singh, Satish Kumar] Indian Inst Informat Technol, Allahabad 211012, Uttar Pradesh, India.
   [Hooda, D. S.] Jaypee Univ Engn & Technol, Guna, MP, India.
C3 Indian Institute of Information Technology Allahabad
RP Shrivastava, S (corresponding author), Indian Inst Informat Technol, Pune 412109, Maharashtra, India.
EM sourabh.juet@gmail.com
RI singh, satish/U-7158-2018; Singh, Dr Satish Kumar/JMP-6186-2023
OI singh, satish/0000-0002-8536-4991; Singh, Dr Satish
   Kumar/0000-0003-1991-7727
CR [Anonymous], 2010, COMPUT ELECTRON AGR, DOI DOI 10.1016/j.compag.2009.09.002
   [Anonymous], FOOD AGR ORG UN
   [Anonymous], BR J MATMETICS COMPU
   [Anonymous], BP 68 W DOWNY MILDEW
   Cui D, 2010, BIOSYST ENG, V107, P186, DOI 10.1016/j.biosystemseng.2010.06.004
   Di Cui, 2009, Sensing and Instrumentation for Food Quality and Safety, V3, P49, DOI 10.1007/s11694-009-9070-8
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, SIGNAL IMAGE VIDEO P, V10, P819, DOI 10.1007/s11760-015-0821-1
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2013, INT J APPL PATTERN R, V1, P108, DOI 10.1504/IJAPR.2013.052343
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Dubey SR, 2012, PROCEDIA ENGINEER, V38, P3449, DOI 10.1016/j.proeng.2012.06.398
   HARTMAN GL, 1991, PLANT DIS, V75, P596, DOI 10.1094/PD-75-0596
   Lee WS, 2010, COMPUT ELECTRON AGR, V74, P2, DOI 10.1016/j.compag.2010.08.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pass G., 1996, Proceedings ACM Multimedia 96, P65, DOI 10.1145/244130.244148
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Shi ZP, 2012, MULTIMED TOOLS APPL, V61, P263, DOI 10.1007/s11042-011-0836-8
   Shrivastava S, 2015, MULTIMED TOOLS APPL, V74, P11467, DOI 10.1007/s11042-014-2239-0
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Tan WX, 2016, MULTIMED TOOLS APPL, V75, P16741, DOI 10.1007/s11042-015-2940-7
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Ziou D, 2014, PATTERN ANAL APPL, V17, P279, DOI 10.1007/s10044-012-0303-9
NR 31
TC 27
Z9 29
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26647
EP 26674
DI 10.1007/s11042-016-4191-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500050
DA 2024-07-18
ER

PT J
AU Tashiro, S
   Tatsuma, A
   Aono, M
AF Tashiro, Shoki
   Tatsuma, Atsushi
   Aono, Masaki
TI Super-vector coding features extracted from both depth buffer and
   view-normal-angle images for part-based 3D shape retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View-normal-angle image; Range scan; Part-based 3D shape retrieval;
   Super-vector coding; Re-ranking
ID OBJECT; REGISTRATION
AB We have witnessed 3D shape models abundant in many application fields including 3D CAD/CAM, augmented/mixed reality (AR/MR), and entertainment. Creating 3D shape models from scratch is still very expensive. Efficient and accurate methods for shape retrieval is essential for 3D shape models to be reused. To retrieve similar 3D shape models, one must provide an arbitrary 3D shape as a query. Most of the research on 3D shape retrieval has been conducted with a "whole" shape as a query (aka whole-to-whole shape retrieval), while a "part" shape (aka part-to-whole shape retrieval) is more practically requested as a query especially by mechanical engineering with 3D CAD/CAM applications. A "part" shape is naturally constructed by a 3D range scanner as an input device. In this paper, we focus on the efficient method for part-to-whole shape retrieval where the "part" shape is assumed to be given by a 3D range scanner. Specifically, we propose a Super-Vector coding feature with SURF local features extracted from the View-Normal-Angle image, or the image synthesized by taking account of the angle between the view vector and the surface normal vector, together with the depth-buffered image, for part-to-whole shape retrieval. In addition, we propose a weighted whole-to-whole re-ranking method taking advantage of global information based on the result of part-to-whole shape retrieval. Through experiments we demonstrate that our proposed method outperforms the previous methods with or without re-ranking.
C1 [Tashiro, Shoki; Tatsuma, Atsushi] Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.
   [Aono, Masaki] Toyohashi Univ Technol, Dept Comp Sci & Engn, Grad Sch, Toyohashi, Aichi, Japan.
C3 Toyohashi University of Technology; Toyohashi University of Technology
RP Tashiro, S (corresponding author), Toyohashi Univ Technol, Dept Comp Sci & Engn, Toyohashi, Aichi, Japan.
EM tashiro@kde.cs.tut.ac.jp; tatsuma@cs.tut.ac.jp; aono@tut.jp
FU Kayamori Foundation of Information Science Advancement; Toukai
   Foundation for Technology; JSPS KAKENHI Grant [JP26280038, JP15K15992];
   Grants-in-Aid for Scientific Research [15K12027, 17H01746] Funding
   Source: KAKEN
FX This work was supported by Kayamori Foundation of Information Science
   Advancement, Toukai Foundation for Technology, and JSPS KAKENHI Grant
   Numbers JP26280038, JP15K15992. We are indebted to Dr. Michalis
   Savelonas for providing the evaluation scripts and SHREC 2013 ground
   truth data.
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], EUR WORKSH 3D OBJ RE
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Feng J., 2016, 2016 IEEE Winter Conference on Applications of Computer Vision (WACV), P1, DOI DOI 10.1109/WACV.2016.7477652
   Furuya T., 2015, P 2015 EUR WORKSH 3D, P15
   Furuya T, 2015, MULTIMED TOOLS APPL, V74, P10367, DOI 10.1007/s11042-014-2171-3
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Jancsary J, 2012, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2012.6247950
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li B, 2013, MULTIMED TOOLS APPL, V65, P363, DOI 10.1007/s11042-012-1009-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moriyama A, P 2015 EUR WORKSH 3D, P153, DOI [10.2312/3dor.20151069, DOI 10.2312/3DOR.20151069]
   Ohbuchi Ryutarou, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P63, DOI 10.1109/ICCVW.2009.5457716
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Papadakis P, 2010, INT J COMPUT VISION, V89, P177, DOI 10.1007/s11263-009-0281-6
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pratikakis I, 2016, EUR WORKSH 3D OBJ RE, P10, DOI [10.2312/3DOR.20161091, DOI 10.2312/3DOR.20161091]
   Quan LL, 2015, COMPUT AIDED DESIGN, V59, P119, DOI 10.1016/j.cad.2014.09.005
   Savelonas MA, 2016, PATTERN RECOGN, V55, P114, DOI 10.1016/j.patcog.2016.02.003
   Serra G, 2015, COMPUT VIS IMAGE UND, V134, P22, DOI 10.1016/j.cviu.2015.01.005
   Sfikas K, 2016, MULTIMED TOOLS APPL, V75, P3693, DOI 10.1007/s11042-014-2069-0
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Shilane P., 2004, Shape Modeling International
   Sipiran I., 2013, 3DOR, P81
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tao SQ, 2013, COMPUT AIDED DESIGN, V45, P1239, DOI 10.1016/j.cad.2013.05.008
   Tatsuma A, 2009, VISUAL COMPUT, V25, P785, DOI 10.1007/s00371-008-0304-2
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang Y, 2014, LOW COST DEPTH SENSO, P489, DOI [10.1007/978-3-319-10590-1_32, DOI 10.1007/978-3-319-10590-1_32]
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   Zhu CZ, 2013, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2013.214
NR 43
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22059
EP 22076
DI 10.1007/s11042-017-4801-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200011
DA 2024-07-18
ER

PT J
AU He, C
   Ran, LQ
   Wang, L
   Li, XQ
AF He, Chen
   Ran, Lingqiang
   Wang, Lei
   Li, Xueqing
TI Point set surface compression based on shape pattern analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Point-based model; Surface segmentation; Encoding
ID SELF-SIMILARITY; REPRESENTATION; SCHEME; SYSTEM; 3D
AB In this work we propose an efficient algorithm for progressive point set surface compression based on shape pattern analysis. The algorithm proceeds as follows. First, the model surface is segmented into square patches according to the principal directions of the surfel. Then, the square patch is parameterized into a 2D domain and regularly resampled. After the resampling, each patch can be described as a height map. Using the height maps, we do the similarity analysis between patches. The patches which have the similar shape are classified into the same cluster, called a shape pattern. For patches in the same shape pattern, a representative patch is computed; then each patch can be represented as the representative patch plus an error correction. When decoding, the profile of the model can be quickly reconstructed using the representative patches and transformation parameters. Then with the decoding of the error image, the model can be gradually refined, implementing progressive compression of 3D point-based models.
C1 [He, Chen; Wang, Lei] Weifang Univ, Coll Comp Engn, Weifang 261061, Shandong, Peoples R China.
   [Ran, Lingqiang] Shandong Univ, Geotech & Struct Engn Res Ctr, Jinan 250061, Shandong, Peoples R China.
   [Li, Xueqing] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
C3 Weifang University; Shandong University; Shandong University
RP He, C (corresponding author), Weifang Univ, Coll Comp Engn, Weifang 261061, Shandong, Peoples R China.
EM imhechen@163.com; ranlingqiang@mail.sdu.edu.cn
RI He, Chen/JLM-5059-2023; Ran, Ling-Qiang/F-9796-2010
FU Science and Technology Development Plan Project of Shandong Province
   [2012G0020127]; Science and Technology Development Plan Project of
   Weifang City [2015GX009]; Doctoral Research Foundation of Weifang
   University [2015BS12]
FX We thank the workgroup of Pointshop3D for providing software and
   point-based models. This work is supported by the Science and Technology
   Development Plan Project of Shandong Province (2012G0020127), the
   Science and Technology Development Plan Project of Weifang City
   (2015GX009) and Doctoral Research Foundation of Weifang University
   (2015BS12).
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Alexander M, 2001, INTERNETWEEK, P21
   [Anonymous], P IEEE APPL IM PATT, DOI [10.1109/AIPR.2011.6176359, DOI 10.1109/AIPR.2011.6176359]
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   Botsch M., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P53
   Chen CQ, 2004, IEEE SIGNAL PROC LET, V11, P167, DOI 10.1109/LSP.2003.819869
   Chen D., 2005, PROC PACIFIC GRAPHIC, P124
   Chen He, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P217, DOI 10.1109/ICIG.2013.49
   Deselaers T, 2010, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2010.5539775
   Dong J, 2005, P INT WORKSH TEXT AN, V6, P209
   Fleishman S, 2003, ACM T GRAPHIC, V22, P997, DOI 10.1145/944020.944023
   Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134
   Gumhold S, 2005, ACM, V137
   Huang J., 2012, COMP VIS PATT REC WO, P41, DOI [DOI 10.1109/CVPRW.2012.6238913, 10.1109/CVPRW.2012.6238913]
   Huang Y., 2006, EUROGRAPHICS S POINT, P103, DOI DOI 10.2312/SPBG/SPBG06/103-110
   Huang Y, 2008, IEEE T VIS COMPUT GR, V14, P440, DOI 10.1109/TVCG.2007.70441
   Hubo E, 2008, COMPUT GRAPH-UK, V32, P221, DOI 10.1016/j.cag.2008.01.012
   Hubo E, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P105
   Ioannis K, 1995, IS T SPIES S EL IM S, P76
   Junejo I. N., 2010, IEEE T PATTERN ANAL, V99
   Kalaiah A, 2005, ACM T GRAPHIC, V24, P348, DOI 10.1145/1061347.1061356
   Kim S, 2014, IEEE IMAGE PROC, P5746, DOI 10.1109/ICIP.2014.7026162
   Kim Y, 2013, J ELECTRON IMAGING, V22, P381
   Kruger J., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P99, DOI 10.1109/PBG.2005.194070
   Li J, 2014, PROC CVPR IEEE, P3374, DOI 10.1109/CVPR.2014.431
   Liang M, 2015, MULTIMED TOOLS APPL, P1
   Merry B, 2006, COMPUT GRAPH FORUM, V25, P709, DOI 10.1111/j.1467-8659.2006.00993.x
   Ochotta T., 2004, EUROGRAPHICS S POINT, P103
   Ochotta T, 2008, COMPUT GRAPH FORUM, V27, P1647, DOI 10.1111/j.1467-8659.2008.01178.x
   Pajarola R., 2003, P IASTED COMPUTER GR, P141
   Park SB, 2009, IEEE T MULTIMEDIA, V11, P177, DOI 10.1109/TMM.2008.2008868
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Razdan A, 2005, COMPUT AIDED DESIGN, V37, P1481, DOI 10.1016/j.cad.2005.03.003
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Schnabel R., 2006, S POINT BAS GRAPH 20, P111
   Schnabel R, 2008, COMPUT GRAPH-UK, V32, P246, DOI 10.1016/j.cag.2008.01.014
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Smith J, 2012, COMPUT GRAPH-UK, V36, P341, DOI 10.1016/j.cag.2012.03.032
   Sun C, 2015, IEEE T IMAGE PROCESS, V24, P2488, DOI 10.1109/TIP.2015.2424316
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   WASCHBUSCH M., 2004, Proceedings of Eurographics Symposium on Point-Based Graphics 2004, P95
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 45
TC 5
Z9 6
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20545
EP 20565
DI 10.1007/s11042-016-3991-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400008
DA 2024-07-18
ER

PT J
AU Shin, Y
   Koo, D
   Hur, J
   Yun, J
AF Shin, Youngjoo
   Koo, Dongyoung
   Hur, Junbeom
   Yun, Joobeom
TI Secure proof of storage with deduplication for cloud storage systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Multimedia content security; Cloud storage; Proof of
   data possession; Proof of retrievability; Proof of ownership; Data
   deduplication
ID RETRIEVABILITY
AB Explosion of multimedia content brings forth the needs of efficient resource utilization using the state of the arts cloud computing technologies such as data deduplication. In the cloud computing environments, achieving both data privacy and integrity is the challenging issue for data outsourcing service. Proof of Storage with Deduplication (POSD) is a promising solution that addresses the issue for the cloud storage systems with deduplication enabled. However, the validity of the current POSD scheme stands on the strong assumption that all clients are honest in terms of generating their keys. We present insecurity of this approach under new attack model that malicious clients exploit dishonestly manipulated keys. We also propose an improved POSD scheme to mitigate our attack.
C1 [Shin, Youngjoo] ETRI, Affiliated Inst, Daejeon, South Korea.
   [Koo, Dongyoung] Korea Adv Inst Sci & Technol, Dept Comp Sci, Daedeok Innopolis, South Korea.
   [Hur, Junbeom] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
   [Yun, Joobeom] Sejong Univ, Dept Comp & Informat Secur, Seoul, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Korea Advanced Institute of Science & Technology (KAIST); Korea
   University; Sejong University
RP Hur, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.; Yun, J (corresponding author), Sejong Univ, Dept Comp & Informat Secur, Seoul, South Korea.
EM yjshin@nsr.re.kr; dykoo@kaist.ac.kr; jbhur@korea.ac.kr;
   jbyun@sejong.ac.kr
RI Shin, Youngjoo/AAL-2127-2020
OI Shin, Youngjoo/0000-0003-4831-7392
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP) [2013R1A2A2A01005559, 2015R1C1A1A02036511]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No.
   2013R1A2A2A01005559, No. 2015R1C1A1A02036511)
CR [Anonymous], 2012, CISCO VISUAL NETWORK
   Ateniese G., 2008, P 4 INT C SEC PRIV C, P9
   Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Blasco J, 2014, IEEE CONF COMM NETW, P481, DOI 10.1109/CNS.2014.6997518
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Bowers KevinD., 2009, Proc. of ACM-CCSW '09, P43, DOI DOI 10.1145/1655008.1655015
   Cui H, 2015, IET INFORM SECUR, V9, P43, DOI 10.1049/iet-ifs.2013.0322
   Dodis Y, 2009, LECT NOTES COMPUT SC, V5444, P109
   Erway CC, 2015, ACM T INFORM SYST SE, V17, DOI 10.1145/2699909
   González-Manzano L, 2015, J NETW COMPUT APPL, V50, P49, DOI 10.1016/j.jnca.2014.12.004
   Halevi S, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P491, DOI 10.1145/2046707.2046765
   Harnik D, 2010, IEEE SECUR PRIV, V8, P40, DOI 10.1109/MSP.2010.187
   Jia X, 2011, 2011538 IACR CRYPT E
   Joux A, 2002, LECT NOTES COMPUT SC, V2369, P20
   Li J, 2015, IEEE T COMPUT, V64, P3569, DOI 10.1109/TC.2015.2401017
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2014, IEEE T PARALL DISTR, V25, P1615, DOI 10.1109/TPDS.2013.284
   Mulazzani M, 2011, P USENIX C SEC SEC 1
   Paulo J, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2611778
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shacham H, 2008, LECT NOTES COMPUT SC, V5350, P90, DOI 10.1007/978-3-540-89255-7_7
   Shi E., 2013, P ACM CCS, P325
   Shin Y, 2012, 2012554 IACR CRYPT E
   Soohak M, 2015, ACM COMPUT SURV, V47
   Wang HQ, 2015, IEEE T SERV COMPUT, V8, P328, DOI 10.1109/TSC.2014.1
   Zheng Qingji., 2012, CODASPY '12: ACM conference on Data and Application Security and Privacy, P1
   Zheng X., 2015, P 10 ACM S INF COMP, P63
NR 27
TC 5
Z9 6
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19363
EP 19378
DI 10.1007/s11042-015-2956-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500002
DA 2024-07-18
ER

PT J
AU Zhao, RY
   Li, CL
   Tian, XK
AF Zhao, Rongyong
   Li, Cuiling
   Tian, Xiangke
TI A novel industrial multimedia: rough set based fault diagnosis system
   used in CNC grinding machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fault diagnosis system; Rough set theory; Decision support model; CNC
   grinding machine
AB Multimedia technologies are increasingly used in design of CNC grinding machines. The self-diagnosis system is a necessary part. To make use of multimedia and solve the problem about the lack of diagnosis knowledge included in the self-diagnosis module used in CNC grinding machines, this paper addresses the fault diagnosis knowledge discovery and the decision support model for fault diagnosis designed in a CNC grinding machine based on on-line vibration monitoring. The fault diagnosis characteristics of CNC grinding machine are analyzed first. Then the rough set theory is introduced to reduce the redundant information affecting fault diagnosis, thereby discover the fault diagnosis knowledge in the form of rules. Further, this paper proposes a decision support model of fault diagnosis module for modern CNC grinding machine, based on the theory advantages of redundant information reduction supported by rough set, being easy to find the diagnosis knowledge in the maintenance and fault diagnosis records. The model is applied into an engineering example of fault diagnosis for a given type of grinding machine. Useful knowledge of fault diagnosis is discovered with the engineering interpretation of fault diagnosis process. The performance comparison with other typical diagnosis methods verifies the validity and advantage of the proposed decision support model based on rough set theory. This paper provides a multimedia solution integrated with rough set theory and information technology for diagnosis module developed in modern CNC grinding machines, and can be a theoretical and technical reference to build fault diagnosis systems used in other modern machines.
C1 [Zhao, Rongyong; Tian, Xiangke] Tongji Univ, CIMS Res Ctr, Caoan Rd 4800, Shanghai 201804, Peoples R China.
   [Zhao, Rongyong; Li, Cuiling] Tongji Univ, Coll Elect & Informat Engn, Caoan Rd 4800, Shanghai 201804, Peoples R China.
C3 Tongji University; Tongji University
RP Zhao, RY (corresponding author), Tongji Univ, CIMS Res Ctr, Caoan Rd 4800, Shanghai 201804, Peoples R China.; Zhao, RY (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Caoan Rd 4800, Shanghai 201804, Peoples R China.
EM zhaorongyong@tongji.edu.cn; 16666501@tongji.edu.cn; tianxk-312@163.com
RI Zhao, RongYong/AAV-4427-2021
OI Zhao, RongYong/0000-0003-1225-1643
FU National Natural Science Foundation of China [71373178]; Natural Science
   Foundation of Shanghai, China [13ZR1444700, 15ZR1420100]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 71373178) and Natural Science Foundation of Shanghai,
   China (Grant No. 13ZR1444700 and 15ZR1420100).
CR Daigle MJ, 2010, IEEE T SYST MAN CY A, V40, P917, DOI 10.1109/TSMCA.2010.2052038
   Feng ZP, 2015, MECH SYST SIGNAL PR, V62-63, P54, DOI 10.1016/j.ymssp.2015.03.014
   Jiang F, 2015, KNOWL-BASED SYST, V73, P324, DOI 10.1016/j.knosys.2014.10.014
   Kamel T, 2015, ELECTR POW SYST RES, V126, P68, DOI 10.1016/j.epsr.2015.05.001
   Keliris C, 2015, INT J CONTROL, V88, P1472, DOI 10.1080/00207179.2015.1007395
   Krysander M, 2008, IEEE T SYST MAN CY A, V38, P197, DOI 10.1109/TSMCA.2007.909555
   Lazo-Cortés MS, 2015, INFORM SCIENCES, V294, P152, DOI 10.1016/j.ins.2014.09.045
   Lee J, 2006, COMPUT IND, V57, P476, DOI 10.1016/j.compind.2006.02.014
   Li H, 2015, J VIB CONTROL, V21, P2416, DOI 10.1177/1077546313487242
   Liu Q., 2001, ROUGH SET ROUGH REAS
   Mafarja M, 2015, INT J SYST SCI, V46, P503, DOI 10.1080/00207721.2013.791000
   de Oca SM, 2012, INT J AP MAT COM-POL, V22, P161, DOI 10.2478/v10006-012-0012-y
   Moosavi SS, 2015, J MAGN MAGN MATER, V391, P203, DOI 10.1016/j.jmmm.2015.04.062
   Wang TY, 2015, MECH SYST SIGNAL PR, V62-63, P30, DOI 10.1016/j.ymssp.2015.03.005
   Xia X, 2015, INT J ELEC POWER, V71, P60, DOI 10.1016/j.ijepes.2015.02.022
   Zhao RY, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P187, DOI 10.1109/ICCIAS.2006.294119
   Zhao RY, 2005, RES ROUGH SET THEORY
   Zheng Z, 2015, MECH MACH THEORY, V91, P151, DOI 10.1016/j.mechmachtheory.2015.04.009
NR 18
TC 10
Z9 11
U1 3
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19913
EP 19926
DI 10.1007/s11042-016-3878-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500035
DA 2024-07-18
ER

PT J
AU Meng, XY
   Che, L
   Liu, ZH
   Che, N
   Ji, XN
AF Meng, Xian-Yong
   Che, Lei
   Liu, Zhi-Hui
   Che, Ning
   Ji, Xiao-Nan
TI Towards a partial differential equation remote sensing image method
   based on adaptive degradation diffusion parameter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Total variation; Partial differential equations; Remote sensing image
   denoising; Upwind scheme
ID GENERALIZED M-SET; ENHANCEMENT
AB For the anisotropy diffusion feature, Partial Differential Equation (PDE) methods keep edge detail characters well in case of denoising, thus being widely applied in remote sense image denoising, smoothing, filtering and reconstruction. A PDE remote sensing image denoising method based on Adaptive Degradation Diffusion Parameter (ADDP) was proposed in the paper to deal with fuzzy detail problem caused by increasing iteration number. The PDE denoising method with ADDP enlarged diffusion size in the plat region of remote sensing image without affecting the remote sensing image edge, thus avoiding loss of remote sensing image detail and intersections caused by Gaussian convolution smoothing in the PDE filtering model based on curvature-based movement (CM) and image denoising model based on total variation (TV). In the region where gradation value changes little, the method executed isotropic diffusion to remove isolated noise. The upwind scheme was applied for model numerical realization. Experimental in remote sensing image denoising results proved its feasibility and effectiveness.
C1 [Meng, Xian-Yong; Liu, Zhi-Hui] Xinjiang Univ, Sch Resources & Environm Sci, Urumqi 830046, Peoples R China.
   [Meng, Xian-Yong; Ji, Xiao-Nan] Chinese Acad Sci, Xinjiang Inst Ecol & Geog, Urumqi 830011, Peoples R China.
   [Che, Lei] Xinjiang Uygur Autonomous Reg Res Inst Measuremen, Urumqi 830011, Peoples R China.
   [Che, Lei] Xinjiang Univ, Sch Mech Engn, Urumqi 830046, Peoples R China.
   [Che, Ning] Chinese Acad Sci, Inst Chem, Beijing 100190, Peoples R China.
C3 Xinjiang University; Chinese Academy of Sciences; Xinjiang Institute of
   Ecology & Geography, CAS; Xinjiang University; Chinese Academy of
   Sciences; Institute of Chemistry, CAS
RP Che, L (corresponding author), Xinjiang Uygur Autonomous Reg Res Inst Measuremen, Urumqi 830011, Peoples R China.; Che, L (corresponding author), Xinjiang Univ, Sch Mech Engn, Urumqi 830046, Peoples R China.
EM xjdxjx@yeah.net
FU MWR public sector research and special funds [201301103]; Ministry of
   Education Key Laboratory of Eco-Oasis Open Topic, China
   [XJDX0201-2013-07]
FX This research was financially supported by the MWR public sector
   research and special funds (201301103) and Ministry of Education Key
   Laboratory of Eco-Oasis Open Topic, China (XJDX0201-2013-07). This
   financial support is gratefully acknowledged and appreciated. We would
   also happy to thank the anonymous reviewers and editor for their review
   and excellent contributions towards the improvement of this manuscript.
CR [Anonymous], APPL MATH INF SCI
   [Anonymous], P 6 INT C EL ENG COM
   Badulescu P., 1999, CAS '99 Proceedings. 1999 International Semiconductor Conference (Cat. No.99TH8389), P301, DOI 10.1109/SMICND.1999.810523
   Carmona RA, 1998, IEEE T IMAGE PROCESS, V7, P353, DOI 10.1109/83.661185
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Chen WL, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/829589
   Chen Y, 2000, P SPIE MATH MODELING, P148
   Chen YM, 2000, COMPUT MATH APPL, V39, P131, DOI 10.1016/S0898-1221(00)00050-X
   Fritsch D.S., 1992, VISUALIZATION BIOMED, V1808, P105
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Hoon LY, 1991, IEEE T CIRCUITS SYST, V38, P984
   HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6
   Jansen M, 1999, IEEE T IMAGE PROCESS, V8, P947, DOI 10.1109/83.772237
   JEONG BJ, 1994, IEEE T SIGNAL PROCES, V42, P3264, DOI 10.1109/78.330393
   Johnstone IM, 1997, J R STAT SOC B, V59, P319, DOI 10.1111/1467-9868.00071
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Krim H, 1999, IEEE T INFORM THEORY, V45, P898, DOI 10.1109/18.761331
   KUAN DT, 1987, IEEE T ACOUST SPEECH, V35, P373, DOI 10.1109/TASSP.1987.1165131
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lin ZX, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2979, DOI 10.1109/ICMLC.2003.1260085
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Liu W, 2006, 2006 IMACS: MULTICONFERENCE ON COMPUTATIONAL ENGINEERING IN SYSTEMS APPLICATIONS, VOLS 1 AND 2, P72, DOI 10.1109/CIMCA.2006.48
   Malfait M, 1997, IEEE T IMAGE PROCESS, V6, P549, DOI 10.1109/83.563320
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Shah J, 1996, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.1996.517065
   Song B, 2003, TOPICS VARIATION PDE
   Weickert J., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P230
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   WHITAKER RT, 1993, CVGIP-IMAG UNDERSTAN, V57, P99, DOI 10.1006/ciun.1993.1006
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Zhu Xuan, 2008, Acta Photonica Sinica, V37, P609
NR 33
TC 5
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17651
EP 17667
DI 10.1007/s11042-015-2881-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800003
DA 2024-07-18
ER

PT J
AU Dehshibi, MM
   Sourizaei, M
   Fazlali, M
   Talaee, O
   Samadyar, H
   Shanbehzadeh, J
AF Dehshibi, Mohammad Mahdi
   Sourizaei, Mohamad
   Fazlali, Mahmood
   Talaee, Omid
   Samadyar, Hossein
   Shanbehzadeh, Jamshid
TI A hybrid bio-inspired learning algorithm for image segmentation using
   multilevel thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Imagesegmentation; Hybridoptimization; Kapur
   function; Otsu function
ID OPTIMIZATION; ENTROPY; MODEL
AB In the field of image analysis, segmentation is one of the most important preprocessing steps. One way to achieve segmentation is the use of threshold selection, where each pixel that belongs to a determined class, based on the mutual visual characteristics, is labeled according to the selected threshold. In this work, a combination of two pioneer methods, namely Otsu and Kapur, are investigated to solve the threshold selection problem. Optimum parameters of these objective functions are calculated using Bacterial Foraging (BF) optimization algorithm, for its accuracy, and Harmony Search (HS), for its speed. However, the biggest problem of soft computing family algorithms is catching into a local optimum. To resolve this critical issue, we investigate the power of Learning Automata (LA) which works as a controller to make switching between these two optimization methods. LA is a heuristic method which can solve complex optimization problems with interesting results in parameter estimation. Despite other techniques commonly seek through the parameter map, LA explores in the probability space, providing appropriate convergence properties and robustness. The proposed method is tested on benchmark images and shows fast convergence avoiding the typical sensitivity to initial conditions such as the Expectation-Maximization (EM) algorithm or the complex, and time-consuming computations which are commonly found in gradient methods. Experimental results demonstrate the algorithm's ability to perform automatic multithreshold selection and show interesting advantages as it is compared to other algorithms solving the same task.
C1 [Dehshibi, Mohammad Mahdi; Samadyar, Hossein] Islamic Azad Univ, Dept Comp Engn, Fac Engn, Sci & Res Branch, Tehran, Iran.
   [Sourizaei, Mohamad] Islamic Azad Univ, Zahedan Branch, Young Researchers & Elite Club, Zahedan, Iran.
   [Fazlali, Mahmood] Shahid Beheshti Univ, Fac Math, Dept Comp Sci, Tehran, Iran.
   [Talaee, Omid] Shiraz Univ, Dept Med Engn, Fac Engn, Shiraz, Iran.
   [Shanbehzadeh, Jamshid] Kharazmi Univ, Dept Comp Sci, Fac Engn, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University; Shahid Beheshti
   University; Shiraz University; Kharazmi University
RP Dehshibi, MM (corresponding author), Islamic Azad Univ, Dept Comp Engn, Fac Engn, Sci & Res Branch, Tehran, Iran.; Sourizaei, M (corresponding author), Islamic Azad Univ, Zahedan Branch, Young Researchers & Elite Club, Zahedan, Iran.
EM dehshibi@iranprc.org; sourizaei.m@gmail.com
RI Dehshibi, Mohammad Mahdi/S-9946-2017; Fazlali, Mahmood/JCP-3157-2023
OI Dehshibi, Mohammad Mahdi/0000-0001-8112-5419; Fazlali,
   Mahmood/0000-0002-1701-5562
CR Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   [Anonymous], 1994, LEARNING AUTOMATA TH
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Brownlee J, 2011, CLEVER ALGORITHMS NA
   Chen JQ, 2005, IEEE T IMAGE PROCESS, V14, P1524, DOI 10.1109/TIP.2005.852204
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hill PR, 2003, IEEE T IMAGE PROCESS, V12, P1618, DOI 10.1109/TIP.2003.819311
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Morand C, 2010, SIGNAL PROCESS-IMAGE, V25, P450, DOI 10.1016/j.image.2010.04.004
   NARENDRA KS, 1974, IEEE T SYST MAN CYB, VSMC4, P323, DOI 10.1109/TSMC.1974.5408453
   Osuna-Enciso V, 2013, EXPERT SYST APPL, V40, P1213, DOI 10.1016/j.eswa.2012.08.017
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Tao WB, 2007, PATTERN RECOGN LETT, V28, P788, DOI 10.1016/j.patrec.2006.11.007
   van der Merwe D, 2003, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2003.1299577
   Vantaram SR, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040901
   Wang J, 2009, IEEE T IMAGE PROCESS, V18, P1844, DOI 10.1109/TIP.2009.2021087
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yazdani D, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P137, DOI 10.1109/HIS.2012.6421323
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   YU XM, 1994, IEEE T PATTERN ANAL, V16, P530, DOI 10.1109/34.291443
   Zahara E, 2005, PATTERN RECOGN LETT, V26, P1082, DOI 10.1016/j.patrec.2004.10.003
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zuva T, 2011, CANADIAN J IMAGE PRO, V2, P20
NR 35
TC 21
Z9 22
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15951
EP 15986
DI 10.1007/s11042-016-3891-3
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900032
DA 2024-07-18
ER

PT J
AU Hu, YC
   Choo, KKR
   Chen, WL
AF Hu, Yu-Chen
   Choo, Kim-Kwang Raymond
   Chen, Wu-Lin
TI Tamper detection and image recovery for BTC-compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Image recovery; Block truncation coding; Image
   authentication; Fragile watermarking
ID DIGITAL IMAGES; RESTORATION CAPABILITY; AUTHENTICATION SCHEME; FRAGILE
   WATERMARKING
AB To ensure the integrity of images compressed using block truncation coding (BTC), a tamper detection and image recovery scheme is proposed in this paper. In this scheme, the size of the authentication data can be adaptively selected according to the user's requirement. The authentication data is embedded in the value differences of the quantization levels in each BTC-compressed image block. Multiple copies of the recovery data are embedded into the bit maps of the smooth blocks. Experimental results show that the proposed scheme performs well in terms of detection precision and the embedded image quality. Meanwhile, the tampered areas can be roughly recovered by using the proposed scheme.
C1 [Hu, Yu-Chen; Chen, Wu-Lin] Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX USA.
   [Choo, Kim-Kwang Raymond] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
C3 Providence University - Taiwan; University of Texas System; University
   of Texas at San Antonio (UTSA); University of South Australia
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM ychu@pu.edu.tw; raymond.choo@fulbrightmail.org; wlchen@pu.edu.tw
RI Hui, Yu/JOZ-3598-2023; Choo, Kim-Kwang Raymond/A-3634-2009; Hu,
   Yu-Chen/AAT-5264-2020
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; Hu,
   Yu-Chen/0000-0002-5055-3645
FU Providence University, Taichung, Taiwan under the National Science
   Council, Taipei, R.O.C. [MOST 103-2410-H-126-009-MY3,
   MOST-103-2632-E-126-001MY3]
FX This research was supported by Providence University, Taichung, Taiwan
   under contract the National Science Council, Taipei, R.O.C. under
   contract MOST 103-2410-H-126-009-MY3 and MOST-103-2632-E-126-001MY3.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chuang JC, 2013, INT J SECUR APPL, V7, P209, DOI 10.14257/ijsia.2013.7.6.22
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu Y. C., 2013, INT J SECURITY ITS A, V7, P11
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Lee CW, 2013, SIGNAL PROCESS, V93, P2010, DOI 10.1016/j.sigpro.2013.01.009
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lo CC, 2014, SIGNAL PROCESS, V98, P174, DOI 10.1016/j.sigpro.2013.11.028
   Lo CC, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033003
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Tsai P, 2003, SIGNAL PROCESS-IMAGE, V18, P813, DOI 10.1016/j.image.2003.06.001
   Wang SS, 2008, PATTERN RECOGN, V41, P701, DOI 10.1016/j.patcog.2007.05.012
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu CM., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P13, DOI [10.14257/ijsip.2014.7.5.02, DOI 10.14257/IJSIP.2014.7.5.02]
   Yang Q, MULTIMED TOOLS APPL, DOI [10.1007/s11042-015-3079-2, DOI 10.1007/S11042-015-3079-2]
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 24
TC 13
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15435
EP 15463
DI 10.1007/s11042-016-3847-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900011
DA 2024-07-18
ER

PT J
AU Varish, N
   Pradhan, J
   Pal, AK
AF Varish, Naushad
   Pradhan, Jitesh
   Pal, Arup Kumar
TI Image retrieval based on non-uniform bins of color histogram and dual
   tree complex wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Color histogram; Dual tree complex
   wavelet transform; Principal texture direction; Statistical parameters
ID TEXTURE FEATURES; NEURAL-NETWORKS; SHAPE; SIMILARITY; EXTRACTION; FUSION
AB Traditional Content-Based Image Retrieval (CBIR) systems were developed for retrieving similar kinds of images from a whole image database based on the given query image. In this paper, the authors have proposed a hierarchical approach for designing a CBIR scheme based on the color and texture features of an image. Initially, a color based approach is adopted and the intermediate results produced by using these color features is appropriate to discard a significant number of non-relevant images from the database. The intermediate database will be the input for the second stage. At this stage, a texture based approach is adopted for retrieving images from the intermediate database. The color features are extracted by computing the statistical parameters of non-uniform quantized histograms of HSV color space while a rotation invariant multi-resolution texture based approach is accomplished on value(V) component of HSV color space for extracting texture features. These texture features are extracted based on the principal texture direction and by taking the energies from various sub-bands of a dual tree complex wavelet transform (DT-CWT). Furthermore, the proposed scheme is suitable to handle mirror images during the retrieval process. The presented scheme has reduced the processing cost due to the consideration of a hierarchical approach. The proposed scheme is tested on the two well-known Corel-1K and GHIM-10K image databases respectively and satisfactory results were achieved in terms of precision, recall and F-score. The proposed scheme is compared with some other existing state of art CBIR schemes and the experimental results validate the improvement over other schemes in most of the instances.
C1 [Varish, Naushad; Pradhan, Jitesh; Pal, Arup Kumar] Indian Sch Mines Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Jharkand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Varish, N (corresponding author), Indian Sch Mines Dhanbad, Dept Comp Sci & Engn, Dhanbad 826004, Jharkand, India.
EM naushad.cs88@gmail.com; jitpradhan02@gmail.com; arupkrpal@gmail.com
RI Varish, Naushad/R-4371-2019; Pal, Arup Kumar/I-2496-2016
OI Varish, Naushad/0000-0002-0088-2213; Pradhan,
   Jitesh/0000-0002-6264-4093; Pal, Arup Kumar/0000-0003-4229-0715
CR [Anonymous], 1998, IEEE DIG SIGN PROC W
   [Anonymous], 2014, ADV INTELL SYST COMP, DOI DOI 10.1007/978-3-319-07692-8
   Ashraf R, 2015, ENTROPY-SWITZ, V17, P3552, DOI 10.3390/e17063552
   Çelik T, 2011, COMPUT ELECTR ENG, V37, P729, DOI 10.1016/j.compeleceng.2011.06.008
   Chahooki MAZ, 2012, IET IMAGE PROCESS, V6, P327, DOI 10.1049/iet-ipr.2010.0548
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Krishnamoorthy R, 2013, DIGIT SIGNAL PROCESS, V23, P555, DOI 10.1016/j.dsp.2012.09.018
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Malik F, 2013, J KING SAUD UNIV-COM, V25, P207, DOI 10.1016/j.jksuci.2012.11.004
   Manthalkar R, 2003, PATTERN RECOGN LETT, V24, P2455, DOI 10.1016/S0167-8655(03)00090-4
   Mustaffa MR, 2008, MALAYS J COMPUT SCI, V21, P1
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Rahimi M, SIVIP, V9, P691
   Rahimi M, 2011, IEEE INT SYMP SIGNAL, P415
   Rakvongthai Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1494, DOI 10.1016/j.image.2013.06.005
   Rao M.B., 2011, INT J COMPUT APPL, V18, P40, DOI [10.5120/2285-2961, DOI 10.5120/2285-2961]
   Reddy P. Gangadhara, 2010, 2010 Recent Advances in Space Technology Services and Climate Change (RSTSCC), P138, DOI 10.1109/RSTSCC.2010.5712832
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Walia E, 2014, J VIS COMMUN IMAGE R, V25, P1335, DOI 10.1016/j.jvcir.2014.05.005
   Wang Shengjiu., 2001, A Robust CBIR Approach Using Local Color Histograms
   Wang XY, 2010, MULTIMED TOOLS APPL, V49, P323, DOI 10.1007/s11042-009-0362-0
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zeng S, 2016, NEUROCOMPUTING, V171, P673, DOI 10.1016/j.neucom.2015.07.008
NR 45
TC 22
Z9 22
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15885
EP 15921
DI 10.1007/s11042-016-3882-4
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900030
DA 2024-07-18
ER

PT J
AU Yu, J
   Li, LY
   Zou, J
AF Yu, Jun
   Li, Lingyan
   Zou, Jie
TI Realistic emotion visualization by combining facial animation and
   hairstyle synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual emotion synthesis; Facial animation; Hair animation
ID HAIR; VIDEO; CAPTURE
AB Facial expressions are one of most intuitive way for expressing emotions, and can facilitate human-computer interaction by enabling users to communicate with computers using more natural ways. Besides, the hair can be designed to enhance the expression of emotions particularly. To visualize the emotions in multiple aspects for completeness, we propose a realistic visual emotional synthesis system based on the combination of facial expression and hairstyle in this paper. Firstly, facial expression is synthesized by the anatomical model and parameterized model. Secondly, cartoonish hairstyle is synthesized to describe emotion implicitly by the mass-spring model and cantilever beam model. Finally, the synthesis results of facial expression and hairstyle are combined to produce a complete visual emotion synthesis result. Experiment results demonstrate the proposed system can synthesize realistic animation, and the emotion expressiveness by combining of face and hair outperform that by face or hair alone.
C1 [Yu, Jun; Li, Lingyan] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
   [Zou, Jie] Wuhan Technol & Business Univ, Dept Comp Sci & Technol, Wuhan 430065, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.; Zou, J (corresponding author), Wuhan Technol & Business Univ, Dept Comp Sci & Technol, Wuhan 430065, Peoples R China.
EM harryjun@ustc.edu.cn; qvbso0724@163.com
RI zhan, xiao/JEZ-3810-2023
FU National Natural Science Foundation of China [61572450, 61303150]; Open
   Project Program of the State KeyLab of CAD&CG, Zhejiang University
   [A1501]; Fundamental Research Funds for the Central Universities
   [WK2350000002]; State Key Laboratory of Virtual Reality Technology and
   Systems, Beihang University [BUAA-VR-16KF-12]; State Key Laboratory of
   Novel Software Technology, Nanjing University [KFKT2016B08]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61572450, No. 61303150), the Open Project Program of the
   State KeyLab of CAD&CG, Zhejiang University (No. A1501), the Fundamental
   Research Funds for the Central Universities (WK2350000002), the Open
   Funding Project of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University (No. BUAA-VR-16KF-12), the Open Funding
   Project of State Key Laboratory of Novel Software Technology, Nanjing
   University (No. KFKT2016B08).
CR ANJYO K, 1992, COMP GRAPH, V26, P111, DOI 10.1145/142920.134021
   [Anonymous], 2015, ACM T GRAPHIC
   Bando Y, 2003, COMP GRAPH FOR EUR P
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Bonneel N, 2009, COMPUT GRAPH FORUM, V28, P1171, DOI 10.1111/j.1467-8659.2009.01494.x
   Bro-Nielsen M, 1998, P IEEE, V86, P490, DOI 10.1109/5.662874
   Chai ML, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601211
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Eisert P, 2003, INT J IMAG SYST TECH, V13, P245, DOI 10.1002/ima.10072
   Feng WW, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778845
   Jun Y., 2014, SCI CHINA INFORM SCI, V57, P274
   Koch R. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P421, DOI 10.1145/237170.237281
   Marcos S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3810, DOI 10.1109/IROS.2008.4650814
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Paris S, 2004, ACM T GRAPHIC, V23, P712, DOI 10.1145/1015706.1015784
   Parke F., 1996, COMPUTER FACIAL ANIM
   Pighing F., 1998, SIGGRAPH, P75
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sifakis E., 2006, ACM SIGGRAPHEUROGRAP, P261
   Wang WM, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P521, DOI 10.1109/ICIG.2009.26
   Waters K., 1987, COMPUTER GRAPHICS, V22, P17
   Wei YC, 2005, ACM T GRAPHIC, V24, P816, DOI 10.1145/1073204.1073267
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Yu J, 2016, MULTIMED TOOLS APPL, V75, P12021, DOI 10.1007/s11042-016-3368-4
   Yu J, 2015, IEEE T CYBERNETICS, V45, P977, DOI 10.1109/TCYB.2014.2341737
   Yuencheng Lee, 1995, Computer Graphics Proceedings. SIGGRAPH 95, P55
NR 31
TC 1
Z9 2
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14905
EP 14919
DI 10.1007/s11042-016-4239-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400020
DA 2024-07-18
ER

PT J
AU Marcolin, F
   Vezzetti, E
AF Marcolin, Federica
   Vezzetti, Enrico
TI Novel descriptors for geometrical 3D face analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face; Face analysis; Landmarks; Geometry; Face recognition; Face
   expression recognition
ID MORPHOLOGICAL ANALYSIS; RECOGNITION; DESIGN; SHAPE
AB 3D face was recently investigated for various applications, including biometrics and diagnosis. Describing facial surface, i.e. how it bends and which kinds of patches is composed by, is the aim of studies of Face Analysis, whose ultimate goal is to identify which features could be extracted from three-dimensional faces depending on the application. In this study, we propose 105 novel geometrical descriptors for Face Analysis. They are generated by composing primary geometrical descriptors such as mean, Gaussian, principal curvatures, shape index, curvedness, and the coefficients of the fundamental forms, and by applying standard functions such as sine, cosine, and logarithm to them. The new descriptors were mapped on 217 facial depth maps and analysed in terms of descriptiveness of facial shape and exploitability for localizing landmark points. Automatic landmark extraction stands as the final aim of this analysis. Results showed that some newly generated descriptors were sounder than the primary ones, meaning that their local behaviours in correspondence to a landmark position is thoroughly specific and can be registered with high similarity on every face of our dataset.
C1 [Marcolin, Federica; Vezzetti, Enrico] Politecn Torino, Dept Management & Prod Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
C3 Polytechnic University of Turin
RP Marcolin, F (corresponding author), Politecn Torino, Dept Management & Prod Engn, Corso Duca Abruzzi 24, I-10129 Turin, Italy.
EM federica.marcolin@polito.it; enrico.vezzetti@polito.it
OI Marcolin, Federica/0000-0002-4360-6905
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Abbas H, 2015, PROCEDIA COMPUT SCI, V60, P1649, DOI 10.1016/j.procs.2015.08.275
   [Anonymous], 2005, 3 DIMENSIONAL CEPHAL
   Bagchi P, 2012, PROC INT CONF EMERG, P311, DOI 10.1109/EAIT.2012.6407931
   Bennamoun M., 2015, WILEY ENCY ELECT ELE
   Canavan S, 2015, COMPUT VIS IMAGE UND, V139, P136, DOI 10.1016/j.cviu.2015.06.006
   Creusot C., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P204, DOI 10.1109/3DIMPVT.2011.33
   Creusot Clement., 2012, COMPUTER VISION PATT, P57
   Daoudi M, 2013, 3D FACE MODELING, ANALYSIS AND RECOGNITION, pIX
   Do Carmo M., 1976, Differential Geometry of Curves and Surfaces
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Gray A, 2006, MODERN DIFFERENTIAL
   Hadid A., 2008, Handbook of Texture Analysis, P347
   Hiremath P., 2013, International Journal of Signal Processing, Image Processing and Pattern Recognition, V6, P1
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Inan T, 2012, IEEE T INF FOREN SEC, V7, P577, DOI 10.1109/TIFS.2012.2186293
   Kakadiaris I, 2012, 3 DIMENSION FACE REC, DOI [10.1117/2.1201205.004214, DOI 10.1117/2.1201205.004214]
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lanz Cornelia, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P556
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Li HB, 2011, LECT NOTES COMPUT SC, V6915, P483, DOI 10.1007/978-3-642-23687-7_44
   Li Y, 2011, ABSTR APPL ANAL, V22, P1
   Liu Y, 2013, INT SYM COMPUT INTEL, P313, DOI 10.1109/ISCID.2013.192
   Di Martino JM, 2014, IEEE IMAGE PROC, P3818, DOI 10.1109/ICIP.2014.7025775
   Meethongjan K., 2007, SUMMARY LIT REV FACE
   Mirmehdi Majid., 2008, Handbook of Texture Analysis
   Moosavi SeyedAhmad., 2014, 2014 Iranian Conference on Intelligent Systems (ICIS), P1, DOI DOI 10.1109/IRANIANCIS.2014.6802552
   Nerendra Kumar K., 2016, HDB RES EMERGING PER
   Pears N, 2010, INT J COMPUT VISION, V89, P152, DOI 10.1007/s11263-009-0297-y
   Perakis P, 2014, PATTERN RECOGN, V47, P2783, DOI 10.1016/j.patcog.2014.03.007
   Qingkai Zhen, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015, January 5-7, 2015, Proceedings: LNCS 8935, P522, DOI 10.1007/978-3-319-14445-0_45
   Rabiu H, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P237, DOI 10.1109/ICSIPA.2013.6708010
   Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Szeptycki P, 2012, BIOMETRICS SPECIAL I, P1
   Tang HL, 2013, SIGNAL PROCESS, V93, P2190, DOI 10.1016/j.sigpro.2012.04.002
   Vezzetti E, 2009, INT J ADV MANUF TECH, V42, P780, DOI 10.1007/s00170-008-1625-z
   Vezzetti E., 2011, P INT 2011 BAD BAD G
   Vezzetti E, 2012, MULTIMED TOOLS APPL, V68, P1
   Vezzetti E, 2014, IMAGE ANAL STEREOL, V33, P167, DOI 10.5566/ias.1100
   Vezzetti E, 2014, ROBOT AUTON SYST, V62, P1768, DOI 10.1016/j.robot.2014.07.009
   Vezzetti E, 2014, AESTHET PLAST SURG, V38, P796, DOI 10.1007/s00266-014-0334-2
   Vezzetti E, 2013, COMPUT IND, V64, P1326, DOI 10.1016/j.compind.2013.04.006
   Vezzetti E, 2012, COMPUT METH PROG BIO, V108, P1078, DOI 10.1016/j.cmpb.2012.07.008
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Vezzetti E, 2012, ROBOT AUTON SYST, V60, P928, DOI 10.1016/j.robot.2012.01.003
   Vezzetti E, 2010, J PLAST RECONSTR AES, V63, P218, DOI 10.1016/j.bjps.2008.09.031
   Vezzetti E, 2009, INT J ADV MANUF TECH, V41, P1140, DOI 10.1007/s00170-008-1562-x
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Wei J, 2013, IEEE ICCE, P1, DOI 10.1109/ICCE.2013.6486769
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Zhang GP, 2011, PATTERN RECOGN LETT, V32, P1009, DOI 10.1016/j.patrec.2011.02.004
   Zhao X, 2011, 3D FACE ANAL LANDMAR
NR 55
TC 44
Z9 46
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13805
EP 13834
DI 10.1007/s11042-016-3741-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mohammad, N
   Sun, XM
   Yang, HF
   Yin, JP
   Yang, GB
   Jiang, MF
AF Mohammad, Nur
   Sun, Xingming
   Yang, Hengfu
   Yin, Jianping
   Yang, Gaobo
   Jiang, Mingfang
TI Lossless visible watermarking based on adaptive circular shift operation
   for BTC-compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lossless visible watermarking; Absolute moment block truncation coding;
   Circular shift operation
ID REVERSIBLE STEGANOGRAPHY
AB Most existing BTC (Block Truncation Coding) based watermarking algorithms do not fully exploit visual perception of the host images. These schemes cannot obtain visual quality of stego-images and recover original images without distortion. To solve this issue, a new reversible visible watermarking scheme based on AMBTC (Absolute Moment Block Truncation Coding) domain is proposed. First, the proposed scheme uses adaptive pixel circular shift operation that adapts to local properties of the image to embed the visible watermark into two level (one-bit) nonparametric quantization levels of AMBTC according to the parity of the bit plane of AMBTC triple. The watermark signal can be extracted according to the parity of the Bit plane. The experimental results prove that the algorithm can achieve high visual quality of stego-images and recover original BTC-compressed image losslessly. Moreover, it is robust against common signal processing attacks. The visible watermarking algorithm can be applied to copyright of digital images in real-time environment because of the low time consumption due to the simplicity of AMBTC.
C1 [Mohammad, Nur; Sun, Xingming; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Yang, Hengfu; Jiang, Mingfang] Hunan First Normal Univ, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Yang, Hengfu; Yin, Jianping] Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China.
C3 Hunan University; Hunan First Normal University; Nanjing University of
   Information Science & Technology; National University of Defense
   Technology - China
RP Yang, HF (corresponding author), Hunan First Normal Univ, Dept Informat Sci & Engn, Changsha 410205, Hunan, Peoples R China.; Yang, HF (corresponding author), Natl Univ Def Technol, Sch Comp, Changsha 410073, Hunan, Peoples R China.
EM longsenmd@yahoo.com; sunnudt@163.com; hengfuyang@hotmail.com
RI Yang, Hengfu/S-6738-2019; Sun, Xingming/AAD-1866-2019
FU Hunan Provincial Natural Science Foundation of China [2016JJ6022];
   National Natural Science Foundation of China [61232016, 61073191,
   61070196]; National Basic Research Program 973 [2009CB326202,
   2010CB334706]; Key laboratory of informationization technology for basic
   education in Hunan province [02015TP1017]
FX This work is supported by Hunan Provincial Natural Science Foundation of
   China (2016JJ6022), National Natural Science Foundation of China
   (61232016, 61073191, 61070196), National Basic Research Program 973
   (2009CB326202, 2010CB334706), Key laboratory of informationization
   technology for basic education in Hunan province (02015TP1017).
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, IEICE T INF SYST, VE90D, P1422, DOI 10.1093/ietisy/e90-d.9.1422
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2011, FUND INFORM, V109, P121, DOI 10.3233/FI-2011-500
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Guo JM, 2009, SIGNAL PROCESS, V89, P1864, DOI 10.1016/j.sigpro.2009.03.013
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hong W, P 2008 IE C IM SIGN
   Luo H, INF TECHNOL J, V10, P681
   Mohammad Nur, 2014, Information Technology Journal, V13, P536, DOI 10.3923/itj.2014.536.541
   Pasi F, 1995, IEEE T COMMUN, V43, P1677
   Shi Minghui, 2012, INT J COMPUTER SCI I, V9, P466
   Wei S, 2006, IEEE T IND APPL, V16, P354
   Wien Hong, 2010, Information Technology Journal, V9, P179, DOI 10.3923/itj.2010.179.183
   Yang HF, 2015, MULTIMED TOOLS APPL, V74, P1725, DOI 10.1007/s11042-013-1714-3
NR 15
TC 15
Z9 16
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13301
EP 13313
DI 10.1007/s11042-016-3757-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900017
DA 2024-07-18
ER

PT J
AU Huang, GH
   Pun, CM
   Lin, C
AF Huang, Guoheng
   Pun, Chi-Man
   Lin, Cong
TI Unsupervised video co-segmentation based on superpixel co-saliency and
   region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Co-saliency; Co-segmentation; Region merging; Superpixel; Unsupervised
ID ALGORITHM; SHIFT
AB Nowadays, fully unsupervised video object segmentation is still a challenge in computer vision. Furthermore, it is more difficult to segment the object from a set of clips. In this paper, we propose an unsupervised and on-line method that efficiently segments common objects from a set of video clips. Our approach is based on the hypothesis, that common or similar objects in multiple video clips are salient, and they share similar features. At first, we try to find out the regions in every clip which are salient and share similar features by proposing a new co-saliency scheme based on superpixels. Then, the most salient superpixels are chosen as the initial object marker superpixels. Starting from these superpixels, we merge neighboring and similar regions, and segment out the final object parts. The experimental results demonstrate that the proposed method can efficiently segment the common objects from a group of video clips with generally lower error rate than some state-of-the-art video co-segmentation methods.
C1 [Huang, Guoheng; Pun, Chi-Man; Lin, Cong] Univ Macau, Dept Comp & Informat Sci, Taipa, Macau Sar, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Taipa, Macau Sar, Peoples R China.
EM yb27405@umac.mo; cmpun@umac.mo; yb17403@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Badrinarayanan V, 2013, IEEE T PATTERN ANAL, V35, P2751, DOI 10.1109/TPAMI.2013.54
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Cao XC, 2014, IEEE T IMAGE PROCESS, V23, P4175, DOI 10.1109/TIP.2014.2332399
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chiu WC, 2013, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.2013.48
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Fu HZ, 2014, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2014.405
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Golland P, 1997, COMPUT VIS IMAGE UND, V68, P346, DOI 10.1006/cviu.1997.0553
   Guo JM, 2013, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2013.278
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Manen S, 2013, P 2013 IE INT C COMP
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Tang K, 2014, PROC CVPR IEEE, P1464, DOI 10.1109/CVPR.2014.190
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wang TH, 2014, COMPUT VIS IMAGE UND, V120, P14, DOI 10.1016/j.cviu.2013.10.013
   Willert V, 2005, LECT NOTES COMPUT SC, V3663, P9
   Zhang D, 2013, P 2013 IE C COMP VIS
   Zhang D, 2014, LECT NOTES COMPUT SC, V8695, P551, DOI 10.1007/978-3-319-10584-0_36
NR 36
TC 6
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12941
EP 12964
DI 10.1007/s11042-016-3709-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200034
DA 2024-07-18
ER

PT J
AU Kim, H
   Han, S
AF Kim, Hyungki
   Han, Soonhung
TI Geo-registration of wide-baseline panoramic image sequences using a
   digital map reference
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital map; Geo-registration; Panoramic image sequence
AB This paper describes a method of geo-registering a sequence of panoramic images to a digital map by matching pixel information from the images with information on the building footprint contained in a digital map. Recently, images captured at the ground level using a Mobile Mapping System (MMS), such as the panoramic images displayed by Google Street View, have been considered as a valuable resource for three-dimensional (3D) building modeling. However, the wide intervals between these panoramic images, as well as locational and directional error from the related sensors, make it difficult to analyze the image data. This paper demonstrates a formulation method for connecting pixels in panoramic images with information on footprint vertices and building lines contained in a digital map. To allow both pixel and footprint information consistent in 3D space, each panoramic image is tilt-corrected in pre-processing to upright the image using the estimated pitch and roll of a vehicle and removing the pitch and roll effects from the panoramic image pixels. Through the proposed formulation, a single panoramic image can be easily geo-registered with simple user-provided constraints, and adjacent sequential images can then be automatically geo-registered using point feature matching. Experimental results showed a significant reduction in the locational and directional error of sequential panoramic images, and the proposed vanishing point (VP) based validation process was found to successfully detect failure cases.
C1 [Kim, Hyungki] Korea Inst Machinery & Mat, 171 Jang Dong, Daejeon 305343, South Korea.
   [Han, Soonhung] Korea Adv Inst Sci & Technol, 291 Daehak Ro, Daejeon 305701, South Korea.
C3 Korea Institute of Machinery & Materials (KIMM); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Kim, H (corresponding author), Korea Inst Machinery & Mat, 171 Jang Dong, Daejeon 305343, South Korea.
EM diskhkme@gmail.com; shhan@kaist.ac.kr
RI Han, Soonhung/C-2030-2011; han, soonhung/AAA-5745-2021
OI han, soonhung/0000-0001-5676-8121
FU Korea Institute of Machinery and Materials [NK190C]; Korea National
   Research Council of Science & Technology, Development of Integration and
   Automation Technology for Nuclear Plant Life-cycle Management - Korea
   government Ministry of Knowledge Economy [2011 T100200145]; Human
   Resources Development program of the Korea Institute of Energy
   Technology Evaluation and Planning(KETEP) - Korea government Ministry of
   Trade, Industry and Energy [20134030200300]
FX This research was supported by the Basic Research Project of Korea
   Institute of Machinery and Materials (Project Code : NK190C) supported
   by a grant from Korea National Research Council of Science & Technology,
   Development of Integration and Automation Technology for Nuclear Plant
   Life-cycle Management grant funded by the Korea government Ministry of
   Knowledge Economy (2011 T100200145) and Human Resources Development
   program(No. 20134030200300) of the Korea Institute of Energy Technology
   Evaluation and Planning(KETEP) grant funded by the Korea government
   Ministry of Trade, Industry and Energy.
CR Al-Shahri M, 2014, IEEE T IMAGE PROCESS, V23, P4199, DOI 10.1109/TIP.2014.2331147
   Al-Tairi ZH, 2014, J INF PROCESS SYST, V10, P283, DOI 10.3745/JIPS.02.0002
   [Anonymous], INT J COMPUT VISION
   [Anonymous], J CONVERGENCE
   Bazin JC, 2012, INT J ROBOT RES, V31, P63, DOI 10.1177/0278364911421954
   Cham T, 2010, ESTIMATING CAMERA PO
   Chang SM, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-14
   Cipolla R, 2004, P INT C VIRT SYST MU, P22
   David P, 2011, IEEE INT C INT ROBOT, P494, DOI 10.1109/IROS.2011.6048164
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Goswami K, 2014, J CONVERG, V4, P20
   Guowei Wan, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1214, DOI 10.1109/CISP.2011.6100448
   Hernandez J, 2009, P 16 IEEE INT C IM P, P3977
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Huang ZY, 2011, SCI CHINA INFORM SCI, V54, P1207, DOI 10.1007/s11432-011-4263-2
   Khongkraphan K, 2014, J INF PROCESS SYST, V10, P589, DOI 10.3745/JIPS.02.0010
   Kim DN, 2007, LECT NOTES COMPUT SC, V4681, P1192
   Kim H, 2014, MATH PROBL ENG
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Liew LH, 2014, J CONVERG, V4, P15
   Liu H, 2013, IEEE INT SYMP CIRC S, P721, DOI 10.1109/ISCAS.2013.6571948
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Shahabi C, 2014, J INF PROCESS SYST, V10, P1, DOI 10.3745/JIPS.2014.10.1.001
   Taneja A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P479, DOI 10.1109/3DIMPVT.2012.45
   Torii A, 2009, ICCV WORKSH
   Ventura J, 2013, VIRTUAL REAL-LONDON, V17, P147, DOI 10.1007/s10055-012-0208-3
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang GH, 2005, PATTERN RECOGN LETT, V26, P207, DOI 10.1016/j.patrec.2004.08.024
   Xiao JX, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618460
   Zheng X, 2011, P 10 INT C VIRT REAL, P225
NR 31
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11215
EP 11233
DI 10.1007/s11042-016-3298-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000005
DA 2024-07-18
ER

PT J
AU Shin, D
   Shin, D
   Shin, D
AF Shin, Dongmin
   Shin, Dongil
   Shin, Dongkyoo
TI Development of emotion recognition interface using complex EEG/ECG
   bio-signal for interactive contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive contents; Natural user Interface; Emotion recognition; Human
   computer interaction
ID BRAIN-COMPUTER INTERFACE; EEG; STRESS
AB With the changes in the interface paradigm, a user may not be satisfied using only a behavior-based interface such as a mouse and keyboard. In this paper, we propose a real-time user interface with emotion recognition that depends on the need for skill development to support a change in the interface paradigm to one that is more human centered. The proposed emotion recognition technology may provide services to meet the need to recognize emotions when using contents. Until now, most studies on an emotion recognition interface have used a single signal, which was difficult to apply because of low accuracy. In this study, we developed a complex biological signal emotion recognition system that blends the ratio of an ECG for the autonomic nervous system and the relative power value of an EEG (theta, alpha, beta, and gamma) to improve the low accuracy. The system creates a data map that stores user-specific probabilities to recognize six kinds of feelings (amusement, fear, sadness, joy, anger, and disgust). It updates the weights to improve the accuracy of the emotion corresponding to the brain waves of each channel. In addition, we compared the results of the complex biological signal data set and EEG data set to verify the accuracy of the complex biological signal, and found that the accuracy had increased by 35.78%. The proposed system will be utilized as an interface for controlling a game and smart space for a user with high accuracy.
C1 [Shin, Dongmin; Shin, Dongil; Shin, Dongkyoo] Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
C3 Sejong University
RP Shin, D (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM dmshin1988@gmail.com; dshin@sejong.ac.kr; shindk@sejong.ac.kr
RI Shin, Dongil/AAB-3750-2021
OI Shin, Dongmin/0009-0002-6167-4327
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2015R1D1A1A01059253]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2015R1D1A1A01059253).
CR [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   Cai J, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P497, DOI 10.1109/ITCS.2009.108
   Christie IC, 2004, INT J PSYCHOPHYSIOL, V51, P143, DOI 10.1016/j.ijpsycho.2003.08.002
   Ekman P., 1999, Handbook of cognition and emotion, V53, P226
   Elmir Y, 2014, J INF PROCESS SYST, V10, P555, DOI 10.3745/JIPS.02.0007
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P589, DOI 10.1109/TITB.2010.2041553
   HARTER S, 1981, DEV PSYCHOL, V17, P300, DOI 10.1037/0012-1649.17.3.300
   Healey J, 2000, INT C PATT RECOG, P218, DOI 10.1109/ICPR.2000.902898
   Khosrowabadi Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4242, DOI 10.1109/ICPR.2010.1031
   Kim Kyung Sik, 2015, [Journal of Korea Game Society, 한국게임학회 논문지], V15, P145, DOI 10.7583/JKGS.2015.15.1.145
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   이지형, 2010, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V15, P19
   Lee D, 2006, KOREA INTELLIGENT SY, V16, P172, DOI [10.5391/JKIIS.2006.16.3.372, DOI 10.5391/JKIIS.2006.16.3.372]
   Lee LT, 2015, HUM-CENTRIC COMPUT I, V5, DOI 10.1186/s13673-015-0024-3
   Liu Y, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P262, DOI 10.1109/CW.2010.37
   Oh J-S, 2014, J CONVERGENCE, V5, P2
   편해걸, 2015, [Journal of Korea Game Society, 한국게임학회 논문지], V15, P27, DOI 10.7583/JKGS.2015.15.1.27
   Petrantonakis PanagiotisC., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Rosalind P, 1995, AFFECTIVE COMPUTING
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Shon JG, 2014, J INF PROCESS SYST, V10, P543, DOI 10.3745/JIPS.04.0010
   Shusterman V, 2005, IEEE ENG MED BIOL, V24, P52, DOI 10.1109/MEMB.2005.1411349
   Stipek D., 1993, Motivation to learn: From theory to practice, VSecond
   Takayuki H, 2003, TECHNICAL REPORT IEI, P35
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   WOESTENBURG JC, 1983, BIOL PSYCHOL, V16, P127, DOI 10.1016/0301-0511(83)90059-5
   Wolpaw JR, 2004, P NATL ACAD SCI USA, V101, P17849, DOI 10.1073/pnas.0403504101
   WOLPAW JR, 1991, ELECTROEN CLIN NEURO, V78, P252, DOI 10.1016/0013-4694(91)90040-B
   Zhao QB, 2009, CHINESE SCI BULL, V54, P78, DOI 10.1007/s11434-008-0547-3
NR 30
TC 35
Z9 37
U1 1
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11449
EP 11470
DI 10.1007/s11042-016-4203-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000019
DA 2024-07-18
ER

PT J
AU Liu, J
   Liu, YL
   Ge, QQ
AF Liu, Jin
   Liu, Yanli
   Ge, Qianqian
TI Infrared image segmentation based on gray-scale adaptive fuzzy
   clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive fuzzy clustering; Infrared image segmentation; Multi-threshold
   segmentation; Gray level histogram; Pseudo-peak removal
AB Since the infrared detector itself is subject to various external disturbances when collecting information, infrared images are characterized by of low SNR, low contrast and blur edge, which greatly increases the difficulty of detection and recognition. Contraposing the problems that a fuzzy clustering algorithm cannot find the reasonable clustering number adaptively, it will have a low infrared image segmentation rate when the gray-scale between object region and background region are of great difference. A gray-scale adaptive fuzzy clustering algorithm (GAFC) is proposed in this work. The methodology uses a coarse-fine concept to reduce the computational burden required for the fuzzy clustering and to improve the accuracy of segmentation that a single fuzzy clustering cannot reach. The coarse segmentation attempts to segment coarsely based on gray level histogram. Firstly, the pseudo peaks in the gray level histogram are removed by introducing a control factor of peak areas and a control factor of peak widths, then in order to find a finer segmentation result, the coarse segmentation result is clustered by an improved fuzzy clustering algorithm that introduces an adaptive function to get the most reasonable cluster number and that defines a logarithmic function as a measurement of distance. The results of experimental data show that not only the GAFC mentioned in this paper preserves the advantages in multi-threshold segmentation method which is fast and easy, and behaves well in segmenting infrared images in complex environments.
C1 [Liu, Jin; Liu, Yanli; Ge, Qianqian] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, J (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM Jinliu@xidian.edu.cn; ylliu@stu.xidian.edu.cn; geqianqina_ex@163.com
FU National Natural Science Foundation of China [61101246]; Fundamental
   Research Funds for the Central Universities [JB150209]
FX This research was supported in part by the National Natural Science
   Foundation of China (Grant No. 61101246) and the Fundamental Research
   Funds for the Central Universities (Grant No. JB150209).
CR [Anonymous], RES METHODS INFRARED
   [Anonymous], PHOTOELECTRIC ENG
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], RES IMAGE TARGET SEG
   [Anonymous], TELKOMNIKA INDONESIA
   [Anonymous], THRESHOLD SEGMENTATI
   [Anonymous], 2009, INFRARED IMAGE PROCE
   [Anonymous], OTCBVS BENCHMARK DAT
   [Anonymous], EUR SIGN PROC C
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Chen HC, 2015, MED TEACH, V37, P1090, DOI 10.3109/0142159X.2015.1009431
   Cui Zhao-hua, 2014, Control and Decision, V29, P1130
   [杜晓晨 Du Xiaochen], 2005, [红外技术, Infrared Technology], V27, P66
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kubassova O, 2008, IEEE IMAGE PROC, P3036, DOI 10.1109/ICIP.2008.4712435
   Li Jianping, 2010, Journal of Projectiles, Rockets, Missiles and Guidance, V30, P197
   Li Y, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL I, P462, DOI 10.1109/CINC.2009.100
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   Lopes NV, 2010, IEEE T IMAGE PROCESS, V19, P199, DOI 10.1109/TIP.2009.2032349
   Medina-Carnicer R, 2010, IEEE T IMAGE PROCESS, V19, P165, DOI 10.1109/TIP.2009.2032942
   Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607
   [谭洪波 Tan Hongbo], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P1352
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wang L, 2010, IEEE T INTELL TRANSP, V11, P40, DOI 10.1109/TITS.2009.2026674
   Witkin A., 1984, Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP '84, VVolume 9, P150, DOI DOI 10.1109/ICASSP.1984.1172729
   Wu KL, 2002, PATTERN RECOGN, V35, P2267, DOI 10.1016/S0031-3203(01)00197-2
   [吴锐 Wu Rui], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P2460
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
NR 28
TC 5
Z9 6
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11111
EP 11125
DI 10.1007/s11042-016-3657-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400046
DA 2024-07-18
ER

PT J
AU Piotrowski, Z
   Lenarczyk, P
AF Piotrowski, Zbigniew
   Lenarczyk, Piotr
TI Blind image counterwatermarking - hidden data filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hidden data filter; Watermarking; Image watermarking; Counter
   watermarking
AB Watermarking is a dynamically developing method of copyright protection used for media (sounds, images, films, or 3D objects) that employs signal processing in order to hide additional, invisible information about the owner or author. However, studies until now have not widely considered the problem of attempting to blind removal of hidden data in a manner that allows the watermarked signal to be returned to the original signal. Current considerations of authors of leading articles in the watemarking field focus on the robustness of the method - security system against intentional attacks of removal of the additional information, without taking into account the aspect of simultaneous degradation of the quality and form of the watermarked picture. As has been shown in the article, it is possible to design a perfect filter (same as reversible operations) that allows the removal of additional information from the watermarked picture in a way that makes it possible to return to the form of the host image. This paper describes an ideal filter used for removal of additional, invisible information in forms of an eliminating function and a signal masking function. Their effectiveness has been demonstrated for practical implementations of this type of eliminating and masking filters for watermarking methods in the cepstrum domain.
C1 [Piotrowski, Zbigniew; Lenarczyk, Piotr] Mil Univ Technol, Gen S Kaliskiego 2 St, PL-00908 Warsaw, Poland.
C3 Military University of Technology in Warsaw
RP Piotrowski, Z (corresponding author), Mil Univ Technol, Gen S Kaliskiego 2 St, PL-00908 Warsaw, Poland.
EM zpiotrowski@wat.edu.pl
RI Piotrowski, Zbigniew Marek/JUU-2802-2023
OI Piotrowski, Zbigniew Marek/0000-0003-3556-0297
CR [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   Bartolini F, 2004, WATERMARKING SYSTEMS
   Bogert B.P., 1963, P S TIM SER AN, V15, P209
   Cole Eric, 2003, Hiding in Plain Sight: Steganography and the Art of Covert Communication
   Cox I.J., 2001, Digital watermarking
   Cox IJ, 1998, IEEE J SEL AREA COMM, V16, P587, DOI 10.1109/49.668980
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Fabien A, 1988, LNCS, V1525, P219
   Fridrich J, 1998, ISPACS 98 C MELB
   Hsu TC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P29, DOI 10.1109/IIH-MSP.2008.349
   Kalker T, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P425, DOI 10.1109/ICIP.1998.723516
   LANGELAAR GC, 1998, 9 EUR SIGN PROC C IS, P2281
   Lee CH, 1999, IEEE T CONSUM ELECTR, V45, P1005, DOI 10.1109/30.809176
   Lenarczyk Piotr, 2010, 2010 INT C MULT INF, P356
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Seitz J., DIGITAL WATERMARKING
   Sencar HT, DATA HIDING FUNDAMEN
NR 17
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10119
EP 10131
DI 10.1007/s11042-016-3601-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300046
OA hybrid
DA 2024-07-18
ER

PT J
AU Rizzi, A
   Fogli, D
   Barricelli, BR
AF Rizzi, Alessandro
   Fogli, Daniela
   Barricelli, Barbara Rita
TI A new approach to perceptual assessment of human-computer interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human vision system; Visual interface assessment; Color correction;
   Image perception
ID AUTOMATIC COLOR EQUALIZATION; RETINEX; ALGORITHM; AESTHETICS; ISSUES
AB This paper proposes a new approach and a tool to assess user interfaces by applying the ACE (Automatic Color Equalization) algorithm for computing the alternative distribution of color and contrast for the interface under design. The way humans perceive digital images or interfaces is influenced by their chromatic and spatial composition. The output of the ACE tool suggests changes in the visual composition of the interface that the designer can decide to consider or not in its final version. This semi-automatic approach to visual assessment, where the designer expertise may supervise the results and the following design decisions, allows to add a low-level perceptual testing point of view during the design phase, nowadays not always considered. The paper presents the results of a user test that involved 50 participants and regarded the evaluation of 16 different interfaces (and their alternatives). Results report the effectiveness of this innovative interfaces visual assessment approach and tool.
C1 [Rizzi, Alessandro; Barricelli, Barbara Rita] Univ Milan, Dept Comp Sci, Via Comelico 39-41, I-20135 Milan, Italy.
   [Fogli, Daniela] Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.
C3 University of Milan; University of Brescia
RP Barricelli, BR (corresponding author), Univ Milan, Dept Comp Sci, Via Comelico 39-41, I-20135 Milan, Italy.
EM alessandro.rizzi@unimi.it; daniela.fogli@unibs.it;
   barricelli@di.unimi.it
RI Barricelli, Barbara Rita/AAT-2374-2020
OI Barricelli, Barbara Rita/0000-0001-9575-5542
CR Albers J., 2013, Interaction of color : 50th anniversary edition, V4th
   [Anonymous], 2012, INFORM VISUAL
   Artusi A, 2006, COMPUT GRAPH FORUM, V25, P5, DOI 10.1111/j.1467-8659.2006.00914.x
   Banic N, 2013, IEEE SIGNAL PROC LET, V20, P1240, DOI 10.1109/LSP.2013.2285960
   Barnard P., 2000, ACM Transactions on Computer-Human Interaction, V7, P222, DOI 10.1145/353485.353490
   Bertalmío M, 2009, J PHYSIOL-PARIS, V103, P69, DOI 10.1016/j.jphysparis.2009.05.001
   Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Bottoni P, 1997, IEEE T SYST MAN CY A, V27, P773, DOI 10.1109/3468.634641
   Bottoni P, 1999, ACM T PROGR LANG SYS, V21, P1077, DOI 10.1145/330643.330644
   Chambah M, 2007, ELECT IMAGING IMAGE
   Fairchild MD, 2004, J ELECTRON IMAGING, V13, P126, DOI 10.1117/1.1635368
   Fierro Massimo, 2009, 2009 International Symposium on Optomechatronic Technologies. ISOT 2009, P316, DOI 10.1109/ISOT.2009.5326047
   Fogli D, 2014, UNIVERSAL ACCESS INF, V13, P205, DOI 10.1007/s10209-013-0291-6
   Gatta C, 2006, IEE P-VIS IMAGE SIGN, V153, P357, DOI 10.1049/ip-vis:20050279
   Gatta C, 2007, INT J IMAG SYST TECH, V17, P285, DOI 10.1002/ima.20118
   Gianini G, 2015, INFORM SCI UNPUB
   Gianini G, 2014, J OPT SOC AM A, V31, P2663, DOI 10.1364/JOSAA.31.002663
   Hartmann J, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460357
   Hussain F, 1968, THESIS
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   KINCHLA RA, 1979, PERCEPT PSYCHOPHYS, V25, P225, DOI 10.3758/BF03202991
   Kolås O, 2011, J IMAGING SCI TECHN, V55, DOI 10.2352/J.ImagingSci.Technol.2011.55.4.040503
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lavie T, 2004, INT J HUM-COMPUT ST, V60, P269, DOI 10.1016/j.ijhcs.2003.09.002
   Lindgaard G, 2003, WHAT IS THIS EVASIVE, V15
   McCann JJ, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P51
   McCann JJ, 2004, J ELECTRON IMAGING, V13, P6, DOI 10.1117/1.1645250
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Monk A, 2004, HUM-COMPUT INTERACT, V19, P371, DOI 10.1207/s15327051hci1904_6
   Moroney N., 2002, P COL IM C, P23
   Nasar JL, 1999, DIRECTIONS PERSON EN, P229
   Ouni S, 2008, P SPIE, V6808
   Parraman C, 2007, P IS T SPIE EL IM, P1
   Parraman C., 2006, PRINTING TECHNOLOGY
   Petersen MG, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1453152.1453153
   Preece J, 2004, HUMAN COMPUTER INTER
   Provenzi E, 2008, IEEE T PATTERN ANAL, V30, P1757, DOI 10.1109/TPAMI.2007.70827
   Provenzi E, 2007, IEEE T IMAGE PROCESS, V16, P162, DOI 10.1109/TIP.2006.884946
   Provenzi E, 2014, INT J COMPUT VISION, V106, P153, DOI 10.1007/s11263-013-0651-y
   Rizzi A, 2004, J ELECTRON IMAGING, V13, P75, DOI 10.1117/1.1635366
   Rizzi A, 2003, PATTERN RECOGN LETT, V24, P1663, DOI 10.1016/S0167-8655(02)00323-9
   RIZZI A, 2007, P IS T SPIE EL IM 20
   Schenkman BN, 2000, BEHAV INFORM TECHNOL, V19, P367, DOI 10.1080/014492900750000063
   Sekuler R., 1994, PERCEPTION, V3rd
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Tractinsky N, 2006, INT J HUM-COMPUT ST, V64, P1071, DOI 10.1016/j.ijhcs.2006.06.009
   van der Heijden H, 2003, INFORM MANAGE-AMSTER, V40, P541, DOI 10.1016/S0378-7206(02)00079-4
   Vonikakis V, 2008, IET IMAGE PROCESS, V2, P19, DOI 10.1049/iet-ipr:20070012
   WCAG.: World Wide Web Consortium, 2008, WEB CONT ACC GUID 2
   Zhang P, 2005, COMMUN ACM, V48, P105, DOI 10.1145/1081992.1081997
   Zosso D, 2015, SIAM J IMAGING SCI, V8, P787, DOI 10.1137/140972664
   Zuffi S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P241, DOI 10.1109/ICIAP.2007.4362786
NR 52
TC 6
Z9 6
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7381
EP 7399
DI 10.1007/s11042-016-3400-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400057
DA 2024-07-18
ER

PT J
AU Cremonesi, P
   Elahi, M
   Garzotto, F
AF Cremonesi, Paolo
   Elahi, Mehdi
   Garzotto, Franca
TI User interface patterns in recommendation-empowered content intensive
   multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Recommender Systems; Design Patterns; Human Factors; HCI;
   Standardization
ID DESIGN PATTERNS; SYSTEMS
AB Design Patterns (DPs) are acknowledged as powerful conceptual tools to improve design quality and to reduce time and cost of the development process by effect of the reuse of "good" design solutions. In many fields (e.g., software engineering, web engineering, interface design) patterns are widely used by practitioners and are also investigated from a research perspective. Still, they have been seldom explored in the arena of Recommender Systems (RSs). RSs provide suggestions ("recommendations") for items that are likely to be appropriate for the user profile, and are increasingly adopted in content-intensive multimedia applications to complement traditional forms of search in large information spaces. This paper explores RSs through the lens of User Interface (UI) Design Patterns. We have performed a systematic analysis of 54 recommendation-empowered content-intensive multimedia applications, in order to: (i) discover the occurrences of existing domain independent UI patterns; (ii) identify frequently adopted UI solutions that are not modelled by existing patterns, and define a set of new UI patterns, some of which are specific of the interfaces for recommendation features while others can be useful also in a broader context. The results of our inspection have been discussed with and evaluated by a team of experts, leading to a consolidated set of 14 new patterns that are reported in the paper. Reusing pattern-based design solutions instead of building new solutions from scratch enables novice and expert designers to build good UIs for Recommendation-empowered content intensive multimedia applications more effectively, and ultimately can improve the UX experience in this class of systems. From a broader perspective, our work can stimulate future research bridging Recommender Systems, Web Engineering and Interface Design by means of Design Patterns, and highlights new research directions also discussed in the paper.
C1 [Cremonesi, Paolo; Elahi, Mehdi; Garzotto, Franca] Politecnico Milano, Dept Elect Informat & Bioengn, Via Ponzio 34-5, I-20133 Milan, Italy.
C3 Polytechnic University of Milan
RP Elahi, M (corresponding author), Politecnico Milano, Dept Elect Informat & Bioengn, Via Ponzio 34-5, I-20133 Milan, Italy.
EM paolo.cremonesi@polimi.it; mehdi.elahi@polimi.it;
   franca.garzotto@polimi.it
RI Garzotto, Franca/AAQ-7886-2020; Elahi, Mehdi/O-4221-2015; Elahi,
   Mehdi/S-2348-2019; Cremonesi, Paolo/I-8699-2012
OI Elahi, Mehdi/0000-0003-2203-9195; Elahi, Mehdi/0000-0003-2203-9195;
   Cremonesi, Paolo/0000-0002-1253-8081
FU European Institute of Technology (EIT) - grant EIT DIGITAL [15008 -
   2015]
FX This work has been partially supported by the European Institute of
   Technology (EIT) - grant EIT DIGITAL # 15008 - 2015.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius Gediminas., 2015, Recommender Systems Handbook, VSecond, P847
   Aggarwal C C., 2016, Recommender Systems, P139
   Aggarwal C. C., 2016, Recommender Systems, P71
   Aggarwal Charu C., 2016, Recommender systems, V1
   Alexander C., 1979, The timeless way of building, V1
   Amatriain Xavier, 2015, Handbook, P385, DOI [10.1007/978-1-4899-7637-611, DOI 10.1007/978-1-4899-7637-6_11]
   [Anonymous], 1996, Pattern oriented software architecture: a system of patters
   [Anonymous], RECOMMENDER SYSTEMS
   [Anonymous], 2016, Neighborhood-Based Collaborative Filtering, DOI DOI 10.1007/978-3-319-29659-3_2
   [Anonymous], COMPUTER SCI REV
   [Anonymous], 2010, DESIGNING INTERFACES
   [Anonymous], 2016, P CHI C EXTENDED ABS
   Arvola M, 2006, INT J COMPUT APPL T, V25, P128, DOI 10.1504/IJCAT.2006.009063
   Balabanovic M, 1997, COMMUN ACM, V40, P66, DOI 10.1145/245108.245124
   Blas ND, 2002, PALAZZO CONGRESSI BI
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Borchers J. O., 2001, AI & Society, V15, P359, DOI 10.1007/BF01206115
   Bottoni P, 2010, INFORM SOFTWARE TECH, V52, P821, DOI 10.1016/j.infsof.2010.03.005
   Bouassida N., 2011, Proceedings 2011 IEEE 2nd International Conference on Software Engineering and Service Science (ICSESS 2011), P590, DOI 10.1109/ICSESS.2011.5982389
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R., 2000, Knowledge-based Recommender Systems
   COPLIEN JO, 1995, PATTERN LANGUAGES OF PROGRAM DESIGN, P183
   Cosley Dan, 2003, P SIGCHI C HUM FACT, P585
   Cremonesi P, 2015, P 11 BIANN C IT SIGC, P66, DOI [10.1145/2808435.2808442., DOI 10.1145/2808435.2808442]
   Cremonesi P., 2012, Proceedings of the Sixth ACM Conference on Recommender Systems, P27, DOI DOI 10.1145/2365952.2365963
   Cremonesi P., 2011, CHI'11 extended abstracts on human factors in computing systems, P1927
   Cremonesi P, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2209310.2209314
   Cremonesi P, 2013, LECT NOTES COMPUT SC, V8119, P334
   Cremonesi P, 2011, LECT NOTES COMPUT SC, V6948, P152, DOI 10.1007/978-3-642-23765-2_11
   Cremonesi Paolo., 2010, P 8 EUROPEAN C INTER, P105, DOI DOI 10.1145/1809777.1809801
   de Gemmis M., 2015, RECOMMENDER SYSTEMS, P119, DOI [DOI 10.1007/978-1-4899-7637-6_4, 10.1007/978-1-4899-7637-6_4]
   Dearden A, 2006, HUM-COMPUT INTERACT, V21, P49, DOI 10.1207/s15327051hci2101_3
   Deldjoo Y, 2016, J DATA SEMANTICS, P1
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Desrosiers C, 2011, RECOMMENDER SYSTEMS HANDBOOK, P107, DOI 10.1007/978-0-387-85820-3_4
   Di Blas N, 2009, WORLD WIDE WEB, V12, P345, DOI 10.1007/s11280-009-0065-5
   Dong J, 2009, INT J SOFTW ENG KNOW, V19, P823, DOI 10.1142/S021819400900443X
   Duyne D.K.V., 2002, DESIGN SITES PATTERN
   Felfernig A., 2015, RECOMMENDER SYSTEMS, P161, DOI DOI 10.1007/978-1-4899-7637-6_5
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Gamma Erich., 1994, DESIGN PATTERNS
   Garzotto F, 1999, INT C CONC MOD, P293, DOI [10.1007/3-540-48054-4_24, DOI 10.1007/3-540-48054-4_24]
   Garzotto F, 1998, P MUS WEB INT C TOR, V1998
   Garzotto F, 2004, EDMEDIA 2004
   Goodyear P., 2004, Proceedings of Networked Learning Conference, P449
   Gueheneuc YG, 2007, P 1 EUROLO FOC GROUP
   Harrison R., 2013, J INTERACTION SCI, V1, P1, DOI [10.1186/2194-0827-1-1, DOI 10.1186/2194-0827-1-1]
   Jameson A., 2015, Recommender systems handbook, P611
   Jezequel Jean-Marc., 1999, Design Patterns with Contracts
   Kantor P.B., 2011, RECOMMENDER SYSTEMS
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Liikkanen LA, 2015, COMPUT HUM BEHAV, V50, P108, DOI 10.1016/j.chb.2015.01.067
   Lockyer L., 2009, Handbook of research on learning design and learning objects: Issues, applications, and technologies
   Manzato DAG, 2013, IEEE COMMUN MAG, V51, P120, DOI 10.1109/MCOM.2013.6576349
   MARTIN D, 2002, POINTER PATTERNS INT
   McNee SM, 2006, CHI 06 HUM FACT COMP, P1097, DOI DOI 10.1145/1125451.1125659
   Palma F., 2012, 2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE), P1, DOI 10.1109/RSSE.2012.6233399
   Rao K., 2010, DESIDOC J LIB INFORM, V28, P17
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Richardson JH, 2014, ENTERTAINMENT LAW RE, V22
   Rossi G., 1997, Eighth ACM Conference on Hypertext, Hypertext '97, P57, DOI 10.1145/267437.267444
   Rubens N., 2015, Active Learning in Recommender Systems, P809, DOI [DOI 10.1007/978-1-4899-7637-624, DOI 10.1007/978-1-4899-7637-6_24]
   Schedl M., 2015, Recommender Systems Handbook, V2nd, P453, DOI DOI 10.1007/978-1-4899-7637-6_13
   Schummer T, 2003, EUROPLOP, P53
   Schummer T., 2013, PATTERNS COMPUTER ME
   SCHUMMER T, 2005, PATTERN APPROACH END
   Shvets A, 2016, PROXY DESIGN PATTERN
   Swearingen K., 2001, P ACM SIGIR WORKSH R, V13, P1
   VAN WELIE M., 2003, Proceedings of interact, P1
   Van Welie M, 2008, DESIGN PATTERNS WEB
   Véras D, 2015, EXPERT SYST APPL, V42, P9046, DOI 10.1016/j.eswa.2015.06.052
   [No title captured]
   [No title captured]
NR 76
TC 20
Z9 24
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5275
EP 5309
DI 10.1007/s11042-016-3946-5
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500026
DA 2024-07-18
ER

PT J
AU Kaur, H
   Khanna, P
AF Kaur, Harkeerat
   Khanna, Pritee
TI Cancelable features using log-Gabor filters for biometric authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Biometric salting; Log-Gabor transform;
   Non-invertiblity; Random projection; Revocability
ID BINARY PATTERN LBP; RANDOM PROJECTION; FACE; FINGERPRINT; PRIVACY;
   HISTOGRAM
AB Wide spread use of biometric based authentication requires security of biometric data against identity thefts. Cancelable biometrics is a recent approach to address the concerns regarding privacy of biometric data, public confidence, and acceptance of biometric systems. This work proposes a template protection approach which generates revocable binary features from phase and magnitude patterns of log-Gabor filters. Multi-level transformations are applied at signal and feature level to distort the biometric data using user specific tokenized variables which are observed to provide better performance and security against information leakage under correlation attacks. A thorough analysis is performed to study the performance, non-invertibility, and changeability of the proposed approach under stolen token scenario on multiple biometric modalities. It is revealed that generated templates are non-invertible, easy to revoke, and also deliver good performance.
C1 [Kaur, Harkeerat; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
EM harkeerat.kaur@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019
OI Khanna, Pritee/0000-0003-0518-2133
CR Amayeh G, 2009, LECT NOTES COMPUT SC, V5875, P243, DOI 10.1007/978-3-642-10331-5_23
   [Anonymous], 2007, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2007.383110
   [Anonymous], INT C SEC CRYPT SECR
   Areekul V, 2004, LECT NOTES COMPUT SC, V3072, P403
   Aykut M, 2015, IMAGE VISION COMPUT, V40, P65, DOI 10.1016/j.imavis.2015.05.002
   Beveridge R., 2003, CSU FACE IDENTIFICAT
   Bingham E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P245, DOI 10.1145/502512.502546
   Bolle RM, 2002, PATTERN RECOGN, V35, P2727, DOI 10.1016/S0031-3203(01)00247-3
   Chin YJ, 2014, INFORM FUSION, V18, P161, DOI 10.1016/j.inffus.2013.09.001
   Chu RF, 2007, LECT NOTES COMPUT SC, V4844, P22
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Dasgupta Sanjoy, 2000, P16 C UNC ART INT, P143
   Farooq F., 2007, Conference Proceedings presented in Signal Processing and Its Applications, P1
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Filipe S, 2014, PATTERN ANAL APPL, V17, P823, DOI 10.1007/s10044-013-0354-6
   FRANKL P, 1988, J COMB THEORY B, V44, P355, DOI 10.1016/0095-8956(88)90043-3
   Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Hirata S, 2009, LECT NOTES COMPUT SC, V5558, P868, DOI 10.1007/978-3-642-01793-3_88
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Teoh AndrewBeng., 2006, 9th International Conference on Control, Automation, Robotics and Vision, (ICARCV'06), P1, DOI DOI 10.1109/ICARCV.2006.345404
   Jun Yi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P519, DOI 10.1109/ICASSP.2014.6853650
   Kaski S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P413, DOI 10.1109/IJCNN.1998.682302
   Kaur H, 2016, MULTIMED TOOLS APPL, V75, P16333, DOI 10.1007/s11042-015-2933-6
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Lee C, 2010, J NETW COMPUT APPL, V33, P236, DOI 10.1016/j.jnca.2009.12.011
   Lee Y, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P92
   Leng L, 2010, SCI RES ESSAYS, V6, P784
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li JP, 2014, CURR CHIN ECON REPOR, P541, DOI 10.1007/978-3-642-54678-5_75
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Lin CS, 2001, PATTERN RECOGN, V34, P1271, DOI 10.1016/S0031-3203(00)00075-3
   Liu K, 2006, IEEE T KNOWL DATA EN, V18, P92, DOI 10.1109/TKDE.2006.14
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Maiorana E, 2011, ANN IEEE SYST CONF, P495
   Mulyono D, 2008, TECHN 2008 ISBAST 20, P1
   Ngo DCL, 2006, IEEE T CIRC SYST VID, V16, P771, DOI 10.1109/TCSVT.2006.873780
   Ratha N, 2006, INT C PATT RECOG, P370
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Soutar C, 1998, P SOC PHOTO-OPT INS, V3314, P178, DOI 10.1117/12.304705
   Struc V, 2009, INFORMATICA-LITHUAN, V20, P115
   Sutcu Y., 2005, P 7 WORKSHOP MULTIME, P111
   Teoh A, 2006, INFORM PROCESS LETT, V100, P145, DOI 10.1016/j.ipl.2006.06.010
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   truc, 2010, EURASIP J. Adv. Signal Process. - Spec. Issue Adv. Image Process. Def. Secur. Appl, V1, P31
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Wang XX, 2010, IEEE INT SYMP CIRC S, P373, DOI 10.1109/ICMLA.2010.62
   Wang Y, 2010, IEEE T SYST MAN CY B, V40, P1280, DOI 10.1109/TSMCB.2009.2037131
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang W., 2013, CYBERSPACE SAFETY SE, P81, DOI DOI 10.1007/978-3-319-03584-0_7
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
NR 62
TC 28
Z9 30
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4673
EP 4694
DI 10.1007/s11042-016-3652-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500002
DA 2024-07-18
ER

PT J
AU Riess, C
   Unberath, M
   Naderi, F
   Pfaller, S
   Stamminger, M
   Angelopoulou, E
AF Riess, Christian
   Unberath, Mathias
   Naderi, Farzad
   Pfaller, Sven
   Stamminger, Marc
   Angelopoulou, Elli
TI Handling multiple materials for exposure of digital forgeries using 2-D
   lighting environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; 2-D lighting environment; Illuminant direction;
   Reflectance normalization
AB The distribution of incident light is an important physics-based cue for exposing image manipulations. If an image has been composed from multiple sources, it is likely that the illumination environments of the spliced objects differ. Johnson and Farid introduced a proof-of-principle algorithm for a forensic comparison of lighting environments. However, this baseline approach suffers from relatively strict assumptions that limit its practical applicability. In this work, we address one of the biggest limitations, namely the need to compute a lighting environment from patches of homogeneous material. To compute a lighting environment from multiple-color surfaces, we propose a method that we call "intrinsic contour estimation" (ICE). ICE is able to integrate reflectances from multiple materials into one lighting environment, as long as surfaces of different materials share at least two similar normal vectors. We validate the proposed method in a controlled ground-truth experiment on two datasets, with light from three different directions. These experiments show that using ICE can improve the median estimation error by almost 50 %, and the mean error by almost 30 %.
C1 [Riess, Christian; Unberath, Mathias; Naderi, Farzad; Pfaller, Sven; Angelopoulou, Elli] Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, Martensstr 3, D-91058 Erlangen, Germany.
   [Stamminger, Marc] Comp Graph Lab, Cauerstr 11, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Riess, C (corresponding author), Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, Martensstr 3, D-91058 Erlangen, Germany.
EM christian.riess@fau.de
OI Riess, Christian/0000-0002-5556-5338; Unberath,
   Mathias/0000-0002-0055-9950
FU Research Training Group 1773 "Heterogeneous Image Systems"; German
   Research Foundation (DFG)
FX This work was supported by the Research Training Group 1773
   "Heterogeneous Image Systems", funded by the German Research Foundation
   (DFG).
CR Brian V, 2005, EUR C COMP VIS, P124
   Conotter V, 2012, IEEE T INF FOREN SEC, V7, P283, DOI 10.1109/TIFS.2011.2165843
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Fan W, 2012, EUR SIGNAL PR CONF, P1777
   Farid H., 2011, DIGITAL IMAGE FORENS
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Gehler P., 2011, P ADV NEUR INF PROC, P765
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kee E, 2010, P 2 IEEE INT WORKSH, P2010
   Kee E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629646
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Ostrovsky Y, 2005, PERCEPTION, V34, P1301, DOI 10.1068/p5418
   Peng B, 2015, P 7 IEEE INT WORKSH, P2015
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Riess C, 2015, LECT NOTES COMPUT SC, V9281, P3, DOI [10.1007/978-3-319-23222-5_1, 10.1007/978-3-319-23222-5]
   Riess C, 2010, LECT NOTES COMPUT SC, V6387, P66, DOI 10.1007/978-3-642-16435-4_6
   Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
NR 19
TC 9
Z9 9
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4747
EP 4764
DI 10.1007/s11042-016-3655-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500005
DA 2024-07-18
ER

PT J
AU Venkatachalam, N
   Anitha, R
AF Venkatachalam, Natarajan
   Anitha, R.
TI A multi-feature approach to detect Stegobot: a covert multimedia social
   network botnet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia Social Network; Botnet; Stegobot traffic; Image
   steganography; Malicious profile; Botnet detection
AB Online Multimedia Social Networks(OSNs) are popular and efficient medium for millions of users. Unfortunately, in wrong hands, they are also effective medium for spreading social malware and propagation of social botnet. A newly proposed multimedia social network threat, Stegobot masks crucial information in a digital image by using a technique known as steganography. Stegobot works by first infecting a computer and then communicates the stolen information, which could be login passwords, bank account details or credit card numbers. Also it efficiently utilizes the advantage of image steganography to hide the presence of communication within the image sharing behavior of OSNs. Since these social bots exhibit unobservable communication channels, existing botnet detection mechanisms cannot be applied to such botnets. In this paper, we present a novel host based method for detecting and differentiating Stegobot profiles. Also the proposed method shows the ability to detect Stegobot network traffic which is inherently different from legitimate multimedia social network traffic. The best performance of our detection system is demonstrated on different social networks data set with different evaluation metrics. Multiple aspects of multimedia attributes proposed in this study help to explore the hidden communication structure of botnet. Stegobot profiles mimic genuine users and compromise other vulnerable users in social network. By using single view features alone it is very difficult to detect bot profiles as well as Stegobot communications and hence in this work a multi-feature approach is considered. Also, this work attempts to help network security experts and forensic analysts to understand the Stegobot communication and the key profiles inside the malicious network.
C1 [Venkatachalam, Natarajan; Anitha, R.] PSG Coll Technol, Dept Appl Math & Computat Sci, Coimbatore 641004, Tamil Nadu, India.
C3 PSG College Technology
RP Venkatachalam, N (corresponding author), PSG Coll Technol, Dept Appl Math & Computat Sci, Coimbatore 641004, Tamil Nadu, India.
EM Natarajan.V.IN@ieee.org
RI Venkatachalam, Natarajan/AAF-9767-2019
OI Venkatachalam, Natarajan/0000-0002-8926-4146; Rajagopal Usha, Dr
   Anitha/0000-0002-4248-3229
CR [Anonymous], 2010, P 11 ANN C CONV TEL
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], ADV COMPUTER SCI ENG
   [Anonymous], COMPUTER J
   [Anonymous], 2010, NDSS
   [Anonymous], 2004, ELECT IMAGING
   [Anonymous], 2010, P 17 ACM C COMP COMM
   [Anonymous], 1994, SOCIAL NETWORK ANAL
   [Anonymous], 2011, WE SUCCEED DEVELOPIN
   [Anonymous], ID THEFT COMPUTER FO
   [Anonymous], 2012, PROC 1 INT C SECURIT
   Benevenuto F, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P620, DOI 10.1145/1571941.1572047
   Boshmaf Y, 2013, COMPUT NETW, V57, P556, DOI 10.1016/j.comnet.2012.06.006
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Buscarino A, 2012, IEEE SYST J, V6, P531, DOI 10.1109/JSYST.2012.2192054
   Cao Q., 2012, P 9 USENIX C NETW SY, P15
   Castillo Carlos, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P423, DOI 10.1145/1277741.1277814
   Fedynyshyn Gregory, 2011, Autonomic and Trusted Computing. Proceedings 8th International Conference (ATC 2011), P228, DOI 10.1007/978-3-642-23496-5_17
   Fire M., 2012, HUMAN J, V1, P26
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Gowacz A, 2010, ANN TELECOMMUN, V65, P3, DOI 10.1007/s12243-009-0146-6
   Gu G., 2008, BOTMINER CLUSTERING, P139
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hughes D, 2008, LECT NOTES COMPUT SC, V5158, P122
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Mislove Alan E., 2009
   Mondal M, 2011, ACM SIGCOMM COMP COM, V41, P398, DOI 10.1145/2043164.2018487
   Nagaraja Shishir, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P299, DOI 10.1007/978-3-642-24178-9_21
   Nagaraja S., 2010, USENIX SECURITY 2010, P95
   Nagaraja Shishir., 2009, SNOOPING DRAGON SOCI
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Shafiq MZ, 2008, LECT NOTES COMPUT SC, V5137, P88, DOI 10.1007/978-3-540-70542-0_5
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
   Stringhini G, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P1
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
NR 37
TC 7
Z9 11
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6079
EP 6096
DI 10.1007/s11042-016-3555-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500066
DA 2024-07-18
ER

PT J
AU Almuashi, M
   Hashim, SZM
   Mohamad, D
   Alkawaz, MH
   Ali, A
AF Almuashi, Mohammed
   Hashim, Siti Zaiton Mohd
   Mohamad, Dzulkifli
   Alkawaz, Mohammed Hazim
   Ali, Aida
TI Automated kinship verification and identification through human facial
   images: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinship verification; Kinship recognition; Discriminative features
   (resemblance); Kinship problems and challenges; Deep learning
ID FACE RECOGNITION; KIN RECOGNITION; FAMILY
AB Face is the most considerable constituent that people use to recognize one another. Humans can quickly and easily identify each other by their faces and since facial features are unobtrusive to lighting condition and pose, face remains as a dynamic recognition approach to human. Kinship recognition refers to the task of training a machine to recognize the blood relation between a pair of kin and non-kin faces (verification) based on features extracted from facial images, and to determine the exact type or degree of that relation (identification). Automatic kinship verification and identification is an interesting areas for investigation, and it has a significant impact in many real world applications, for instance, forensic, finding missing family members, and historical and genealogical research. However, kinship recognition is still not largely explored due to insufficient database availability. In this paper we present a survey on issues and challenges in kinship verification and identification, related previous works, current trends and advancements in kinship recognition, and potential applications and research direction for the future. We also found that Deep Learning (DL) has mostly outperformed numerous methods using manually designed features by automatically learning and extracting important information from facial features, and enable significant visual recognition functions by improving accuracy in most applications.
C1 [Almuashi, Mohammed; Mohamad, Dzulkifli] Univ Teknol Malaysia, Fac Comp, Johor Baharu, Malaysia.
   [Hashim, Siti Zaiton Mohd] Univ Teknol Malaysia, UTM Big Data Ctr, Smart Digital Community Res Alliance, Johor Baharu, Malaysia.
   [Ali, Aida] Univ Teknol Malaysia, UTM Big Data Ctr, Johor Baharu, Malaysia.
   [Alkawaz, Mohammed Hazim] Management & Sci Univ, Fac Informat Sci & Engn, Dept Informat Sci & Comp, Selangor, Malaysia.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; Universiti
   Teknologi Malaysia; Management Science University
RP Almuashi, M (corresponding author), Univ Teknol Malaysia, Fac Comp, Johor Baharu, Malaysia.
EM almuashi2000@gmail.com; sitizaiton@utm.my; dzulkifli@utm.my;
   hamohammed5@live.utm.my; aida@utm.my
RI mohamad, dzulkifli/F-9091-2011; Alkawaz, Mohammed Hazim/KOC-6843-2024;
   ali, aida/HHM-9276-2022; Hashim, Siti Zaiton Mohd/AAE-5401-2020
OI Alkawaz, Mohammed Hazim/0000-0001-9715-8477; 
CR [Anonymous], 2006, J VIS
   [Anonymous], KINSHIP BRIEF ESSAY
   [Anonymous], ARXIV150402351
   [Anonymous], EFFECT GENDER RECALL
   [Anonymous], P ROYAL SOC B
   [Anonymous], 2010, EFFECTS AGING FACIAL
   [Anonymous], 2012, C PATT REC APPL METH
   [Anonymous], THESIS
   [Anonymous], RES OFFERS OPPORTUNI
   [Anonymous], 2002, KLUWER INT SER ENG C
   [Anonymous], VIS COMPUT
   [Anonymous], 2014, INT J HUMANITIES SOC
   [Anonymous], 2011, 2011 19 IRANIAN C EL
   [Anonymous], 2013, FOUND TRENDS SIGNAL, DOI DOI 10.1561/2000000039
   [Anonymous], 2009, Reliable Face Recognition Methods: System Design, Implementation and Evaluation
   [Anonymous], IDENTIFYING KINSHIP
   [Anonymous], 2014, ARXIV14066947
   [Anonymous], 2014, INT J ENG RES TECHNO
   [Anonymous], ROBUST FACE RECOGNIT
   [Anonymous], WHO I LOOK DETERMINI
   [Anonymous], 3 CLASSES DEEP LEARN
   [Anonymous], TINY IMAGENET CLASSI
   [Anonymous], AUTOMATIC VERIFICATI
   [Anonymous], HUMAN CTR SOCIAL MED
   [Anonymous], ARXIV12101916
   [Anonymous], 2010, INT J BIOINFORMATICS
   [Anonymous], J VIS
   [Anonymous], J STAT ED
   [Anonymous], 1968, INT ENCY SOCIAL SCI
   [Anonymous], 2014, ARXIV14117766
   [Anonymous], 22 INT C PATT REC IC
   [Anonymous], KINSHIP
   [Anonymous], 2008, International Encyclopedia of the Social Sciences
   [Anonymous], DISCRIMINATIVE MULTI
   [Anonymous], WHO YOU LOOK DNA FAM
   [Anonymous], 2014, ARXIV14032802
   Biswas S., 2011, Proc. IEEE International Workshop on Information Forensics and Security (WIFS), P1, DOI DOI 10.1109/WIFS.2011.6123126
   BLAUSTEIN AR, 1981, NATURE, V290, P246, DOI 10.1038/290246a0
   Dantcheva A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P391, DOI 10.1109/BTAS.2012.6374605
   DeBruine LM, 2009, VISION RES, V49, P38, DOI 10.1016/j.visres.2008.09.025
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Feng Jiao, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P188
   Ghahramani M, 2014, MACH VISION APPL, V25, P919, DOI 10.1007/s00138-013-0566-1
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jha M., 1994, INTRO INDIAN ANTHR
   Jung K, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1525, DOI 10.1145/2740908.2741982
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Lamba H., 2011, IEEE International Joint Conference on Biometrics (IJCB), P1, DOI [DOI 10.1109/IJCB.2011.6117520, 10.1109/IJCB.2011.6117520]
   Lieberman D, 2007, NATURE, V445, P727, DOI 10.1038/nature05510
   Lin SK, 2000, INTERNET J CHEM, V3, part. no.
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2012, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2012.6247978
   Mo D., 2012, A survey on deep learning: one small step toward AI
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Park JH, 2008, REV GEN PSYCHOL, V12, P215, DOI 10.1037/1089-2680.12.3.215
   Plomin R, 2011, INT J EPIDEMIOL, V40, P563, DOI 10.1093/ije/dyq148
   Reis H.T., 2009, Encyclopedia of human relationships, V1
   Sadr J, 2003, PERCEPTION, V32, P285, DOI 10.1068/p5027
   Scott J., 2005, Oxford dictionary of sociology, V3rd
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Somanath G, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130517
   Song Y, 2006, LECT NOTES COMPUT SC, V3953, P382, DOI 10.1007/11744078_30
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Sun Y, 2014, ADV NEUR IN, V27
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TANAKA JW, 1993, Q J EXP PSYCHOL-A, V46, P225, DOI 10.1080/14640749308401045
   Tang Y, 2013, ARXIV
   Wang Y., 2014, INT J DISTRIB SENS N, V2014, P9, DOI DOI 10.1155/2014/756240
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, INT C PATT RECOG, P549
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Yang BQ, 2015, J SENSORS, V2015, DOI 10.1155/2015/470905
   YOUNG AW, 1985, PERCEPTION, V14, P737, DOI 10.1068/p140737
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao W., 2011, FACE PROCESSING ADV
   Zhou X., 2011, ACM Multimedia, P953
   Zhu ZY, 2013, IEEE I CONF COMP VIS, P113, DOI 10.1109/ICCV.2013.21
NR 85
TC 25
Z9 27
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 265
EP 307
DI 10.1007/s11042-015-3007-5
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000013
DA 2024-07-18
ER

PT J
AU Iwan, LH
   Thom, JA
AF Iwan, Lukman H.
   Thom, James A.
TI Temporal video segmentation: detecting the end-of-act in circus
   performance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video temporal segmentation; Audio classification; Sound detection;
   Image sequence analysis; Image comparison; Machine learning; Performing
   arts
ID AUDIO CLASSIFICATION
AB The segmentation into acts of a circus performance video is challenging as the content has similar characteristics to other performance videos but is quite different from movies, TV programs, and home videos. Segmentation is useful as a long duration circus show usually contains several shorter segments that are acts. We propose a new method for detecting end-of-act within circus performance videos. Unlike other temporal video segmentation methods, this method does not rely on shot detection techniques and uses audio and video content analysis separately. First is audio content analysis, for detecting applause on the circus audio stream. Second is image analysis. The applause is further analyzed to test whether this applause occurs at the end-of-act. An end-of-act is detected, if the image(s) before and after the applause are different or there are black frames just after the applause. Otherwise, it is not the end-of-act. The experiment to detect end-of-act on Circus Oz performance videos achieved a 92.27 % recall and 49.05 % precision, providing useful clues that assist human annotators to segment circus video into acts.
C1 [Iwan, Lukman H.; Thom, James A.] RMIT Univ, Sch Comp Sci & Informat Technol, Melbourne, Vic, Australia.
C3 Royal Melbourne Institute of Technology (RMIT)
RP Iwan, LH (corresponding author), RMIT Univ, Sch Comp Sci & Informat Technol, Melbourne, Vic, Australia.
EM lukman.iwan@rmit.edu.au; james.thom@rmit.edu.au
FU Australian Research Council [LP100200118]; Australian Research Council
   [LP100200118] Funding Source: Australian Research Council
FX This research was supported under Australian Research Council's Linkage
   Projects funding scheme (project number LP100200118). We would like to
   thank our partners on the project: Australia Research Council, RMIT
   University, LaTrobe University, Circus Australia Ltd, Australia Council
   for the Arts, and Victoria Arts Centre Trust. We thank the anonymous
   referees for their helpful feedback and suggestion improvements to the
   paper.
CR Briggs F, 2009, IEEE DATA MINING, P51, DOI 10.1109/ICDM.2009.65
   Cai R, 2006, IEEE T AUDIO SPEECH, V14, P1026, DOI 10.1109/TSA.2005.857575
   Cao Y, 2003, LECT NOTES COMPUT SC, V2728, P446
   Chasanis V., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, p35:1, DOI DOI 10.1145/1646396.1646439
   Chen LH, 2008, PATTERN RECOGN, V41, P1056, DOI 10.1016/j.patcog.2007.07.024
   Covell M, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P461, DOI 10.1109/MMSP.2006.285351
   Duan L., 2006, International Multimedia Conference, P201
   Günsel B, 1998, J ELECTRON IMAGING, V7, P592, DOI 10.1117/1.482613
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hanjalic A., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P229
   Harb H, 2007, MULTIMED TOOLS APPL, V34, P375, DOI 10.1007/s11042-007-0108-9
   Jarina R, 2007, 8 INT WORKSH IM AN M
   Kijak E, 2006, MULTIMED TOOLS APPL, V30, P289, DOI 10.1007/s11042-006-0031-5
   Kiranyaz S, 2006, IEEE T AUDIO SPEECH, V14, P1062, DOI 10.1109/TSA.2005.857573
   Lesser N, 2005, INT CONF ACOUST SPEE, P37
   Li YX, 2009, SIGNAL PROCESS, V89, P1625, DOI 10.1016/j.sigpro.2009.03.001
   Lienhart R, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P509, DOI 10.1109/MMCS.1997.609763
   Lienhart R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P685, DOI 10.1109/MMCS.1999.779282
   Liu CL, 2013, IEEE T MULTIMEDIA, V15, P884, DOI 10.1109/TMM.2013.2238522
   Liu N, 2011, IEEE T MULTIMEDIA, V13, P961, DOI 10.1109/TMM.2011.2160334
   Liu N, 2010, LECT NOTES COMPUT SC, V6297, P296, DOI 10.1007/978-3-642-15702-8_27
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   Manoj C., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P182, DOI 10.1109/ICECTECH.2011.5941827
   McEnnis D, 2005, P INT C MUS INF RETR, P600
   MCKAY Cory, 2010, THESIS MCGILL U CANA
   Olajec J, 2006, NEUREL 2006: EIGHT SEMINAR ON NEURAL NETWORK APPLICATIONS IN ELECTRICAL ENGINEERING, PROCEEDINGS, P21
   SADLIER D, 2001, P 1 INT WORKSH PATT, P14
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Silva P, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P369, DOI 10.1109/ICMLA.2012.172
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Subashini K, 2012, J COMPUT APPL, V53, P43
   THEODOROU T., 2012, INT J SIGNAL PROCESS, V5, P37
   Yuan JH, 2007, IEEE T CIRC SYST VID, V17, P168, DOI 10.1109/TCSVT.2006.888023
   Zhang T, 1999, INT CONF ACOUST SPEE, P3001, DOI 10.1109/ICASSP.1999.757472
NR 34
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1379
EP 1401
DI 10.1007/s11042-015-3130-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000060
DA 2024-07-18
ER

PT J
AU Lee, JS
   Chen, YR
AF Lee, Jung-San
   Chen, You-Ren
TI Selective scalable secret image sharing with verification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable secret image sharing; Salient map; Meaningful shadow;
   Verification; ROI
ID STEGANOGRAPHY
AB Scalable secret image sharing (SSIS) is a new secret image sharing technique. The feature of scalability refers to the fact that the revealed secret information is proportional to the number of gathered shadows. Once all of the valid shadows are collected, the complete secret can be revealed easily. The kernel of secret information, however, may be leaked out with a few shadows collected in the existing SSIS mechanisms. This is because researchers seldom concerned about secret distribution. Thus, we introduce the Salient map to develop a new method, in which the ROIs (region of interesting) of secret image can be revealed progressively. Additionally, we introduce the concepts of meaningful shadow and verification to SSIS. To the best of our knowledge, this is the first SSIS that employs a meaningful shadow. The leading adoption can greatly help reduce the attention of attackers in order to enhance the security, while the second concept can avoid malicious behaviors from outside attackers or dishonest members.
C1 [Lee, Jung-San; Chen, You-Ren] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Feng Chia University
RP Lee, JS (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM leejs@fcu.edu.tw
CR Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Lin PY, 2011, IET INFORM SECUR, V5, P81, DOI 10.1049/iet-ifs.2008.0043
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Rao TRN, 2006, CIRC SYST SIGNAL PR, V25, P1, DOI 10.1007/s00034-005-1123-6
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2010, J VIS COMMUN IMAGE R, V21, P751, DOI 10.1016/j.jvcir.2010.06.001
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 17
TC 20
Z9 22
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1
EP 11
DI 10.1007/s11042-015-3011-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000001
DA 2024-07-18
ER

PT J
AU Jin, D
   Cho, S
   Sung, Y
   Cho, K
   Um, K
AF Jin, Daxing
   Cho, Seoungjae
   Sung, Yunsick
   Cho, Kyungeun
   Um, Kyhyun
TI Reactive virtual agent learning for NUI-based HRI applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural user interface; Natural user experience; Human-robot
   interaction; Virtual agent learning
AB The natural user interface (NUI) has been investigated in a variety of fields in application software. This paper proposes an approach to generate virtual agents that can support users for NUI-based applications through human-robot interaction (HRI) learning in a virtual environment. Conventional human-robot interaction (HRI) learning is carried out by repeating processes that are time-consuming, complicated and dangerous because of certain features of robots. Therefore, a method is needed to train virtual agents that interact with virtual humans imitating human movements in a virtual environment. Then the result of this virtual agent can be applied to NUI-based interactive applications after the interaction learning is completed. The proposed method was applied to a model of a typical house in virtual environment with virtual human performing daily-life activities such as washing, eating, and watching TV. The results show that the virtual agent can predict a human's intent, identify actions that are helpful to the human, and can provide services 16 % faster than a virtual agent trained using traditional Q-learning.
C1 [Jin, Daxing] NCSoft Corp, Daewangpangyo Ro 644beon Gil, Seongnam Si 463400, Gyeonggi Do, South Korea.
   [Cho, Seoungjae; Cho, Kyungeun; Um, Kyhyun] Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
   [Sung, Yunsick] Keimyung Univ, Dept Game Mobile Contents, 1095 Dalgubeol Daero, Daegu 704701, South Korea.
C3 Dongguk University; Keimyung University
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3 Ga, Seoul 100715, South Korea.
EM cke@dongguk.edu
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [NIPA-2014-H0301-14-1021]; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology [2011-0011266]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (NIPA-2014-H0301-14-1021) supervised by the NIPA
   (National IT Industry Promotion Agency). And this work was supported by
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) funded by the Ministry of Education, Science and
   Technology (2011-0011266). And this paper is extended and improved from
   accepted paper of KCIC-2013/FCC-2014 conferences.
CR [Anonymous], 2013, J CONVERGENCE
   Berger E, 2008, P INT C SIMULATION M
   Bicho E, 2009, P 2009 INT S NEW FRO
   Calinon S, 2010, P 2010 IEEE RSJ INT
   Lim M, 2013, J INF PROCESS SYST, V9, P489, DOI 10.3745/JIPS.2013.9.3.489
   Mason M, 2011, P 6 ACM IEEE INT C H
   Mozgovoy M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-5
   Sung Y, 2012, IEEE INTELL SYST, V27, P14, DOI 10.1109/MIS.2012.28
   Thurau C, 2005, P GAME ON NOV 24 25
   Yamaguchi Y, 1996, P INT C EV COMP MAY
NR 10
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15157
EP 15170
DI 10.1007/s11042-014-2048-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700002
DA 2024-07-18
ER

PT J
AU Khan, MA
   Moinuddin, AA
   Khan, E
   Ghanbari, M
AF Khan, Mohd Ayyub
   Moinuddin, Athar Ali
   Khan, Ekram
   Ghanbari, Mohammad
TI Optimized unequal error protection of embedded video bitstream using
   adaptive-hierarchical QAM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Embedded video bitstream; Error resilient; Hierarchical QAM; Physical
   layer; Unequal error protection; Wavelet based video coding
ID H.264/AVC VIDEO; TRANSMISSION; ALGORITHM; SCHEME; WIMAX
AB In this paper, a reliable video communication system using adaptive Hierarchical QAM (HQAM) is designed to provide optimized unequal error protection (UEP) to embedded video bitstreams. Based on the relative importance of bits, video bitstream is partitioned into two priorities, namely High Priority (HP) and Low Priority (LP) substreams. Then, the optimal value of modulation (or hierarchical) parameter (alpha) of HQAM, which controls the relative error protection of these substreams, is selected from a pre-designed look-up table. The proposed system adapts itself by adapting the optimal alpha according to the varying channel condition, without changing the modulation level. This is in contrast to conventional WiMAX and LTE systems, in which dynamic switching among multiple modulations is used to adapt the varying channel conditions. This paper proposes HQAM with adaptive alpha as an alternative to the multiple modulation schemes. Moreover, for fixed average transmission power, receiver demodulates symbols without the knowledge of alpha. In order to further improve the video quality and to reduce the effects of erroneously received LP bits, the proposed system uses another level of adaptation, in which received LP bits are adaptively considered or discarded, before decoding the video, depending on the channel conditions (or optimized alpha). Simulation results show that proposed system can achieve significant improvement in the video quality compared to QAM based EEP scheme and non-adaptive HQAM.
C1 [Khan, Mohd Ayyub; Moinuddin, Athar Ali; Khan, Ekram] Aligarh Muslim Univ, Dept Elect Engn, Aligarh, Uttar Pradesh, India.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 Aligarh Muslim University; University of Essex
RP Khan, MA (corresponding author), Aligarh Muslim Univ, Dept Elect Engn, Aligarh, Uttar Pradesh, India.
EM ayyub.alig@gmail.com; atharamoin@gmail.com; ekhan67@gmail.com;
   ghan@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Khan, Mohd
   Ayyub/0000-0003-0930-9349; Khan, Ekram/0000-0001-8983-7584
CR Ahmadi S, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5116805
   [Anonymous], DIG VID BRAODC DVB D
   [Anonymous], DIG VID BROADC DVB F
   [Anonymous], IET TELECOMMUNICATIO
   [Anonymous], ARXIV11124944
   [Anonymous], IET INT C VIS INF EN
   Barmada B, 2006, SIGNAL PROCESS-IMAGE, V21, P390, DOI 10.1016/j.image.2006.01.001
   Barmada B, 2005, IEEE SIGNAL PROC LET, V12, P577, DOI 10.1109/LSP.2005.851261
   Cao L, 2007, IEEE T IMAGE PROCESS, V16, P2384, DOI 10.1109/TIP.2007.903262
   Chang SH, 2012, IEEE T INFORM THEORY, V58, P5816, DOI 10.1109/TIT.2011.2173613
   Chang YC, 2006, IEEE T CONSUM ELECTR, V52, P1153, DOI 10.1109/TCE.2006.273127
   Chang YC, 2009, IEEE T CONSUM ELECTR, V55, P1089, DOI 10.1109/TCE.2009.5277961
   Chari MR, 2007, IEEE T BROADCAST, V53, P145, DOI 10.1109/TBC.2007.891696
   COVER TM, 1972, IEEE T INFORM THEORY, V18, P2, DOI 10.1109/TIT.1972.1054727
   Deb K., 2004, Optimization for engineering design: algorithms and examples
   Ghandi MM, 2006, J VIS COMMUN IMAGE R, V17, P451, DOI 10.1016/j.jvcir.2005.05.005
   Ghosh A, 2010, IEEE WIREL COMMUN, V17, P10, DOI 10.1109/MWC.2010.5490974
   Goldsmith A., 2005, WIRELESS COMMUNICATI
   Hasan T, 2011, ANNU IEEE IND CONF, DOI 10.1109/CLEOE.2011.5943668
   Hellge C., 2009, P IEEE BMSB MAY, P1
   Khan Mohd Ayyub, 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P328, DOI 10.1109/MSPCT.2011.6150506
   Khan M. A., 2010, 2010 IEEE Symposium on Industrial Electronics and Applications (ISIEA 2010), P217, DOI 10.1109/ISIEA.2010.5679468
   Li J, 1999, IEEE T IMAGE PROCESS, V8, P913, DOI 10.1109/83.772232
   Li P, 2010, IEEE T CONSUM ELECTR, V56, P2741, DOI 10.1109/TCE.2010.5681164
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Moinuddin AA, 2008, IET IMAGE PROCESS, V2, P59, DOI 10.1049/iet-ipr:20070162
   Mukhtar H, 2012, IEEE T COMMUN, V60, P2275, DOI 10.1109/TCOMM.2012.061412.110507
   Proakis J.G., 2001, McGraw-Hill series in electrical and computer engineering : communications and signal processing
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   Vitthaladevuni PK, 2001, IEEE T BROADCAST, V47, P228, DOI 10.1109/11.969372
   Wong W., 1996, Principles of color design
   Zyren J., 2007, Overview of the 3gpp long term evolution physical layer
NR 33
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15729
EP 15762
DI 10.1007/s11042-015-2886-9
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700038
DA 2024-07-18
ER

PT J
AU Kim, C
   Yang, CN
AF Kim, Cheonshik
   Yang, Ching-Nung
TI Data hiding based on overlapped pixels using hamming code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data Hiding; Steganography; Matrix Encoding; Hamming codes
ID INFORMATION; SCHEME
AB Most data hiding schemes change the least significant bits to conceal messages in the cover images. Matrix encoding scheme is a well known scheme in this field. The matrix encoding proposed by Crandall can be used in steganographic data hiding methods. Hamming codes are kinds of cover codes. "Hamming + 1" proposed by Zhang et al. is an improved version of matrix encoding steganography. The embedding efficiency of "Hamming + 1" is very high for data hiding, but the embedding rate is low. Our proposed "Hamming + 3" scheme has a slightly reduced embedding efficiency, but improve the embedding rate and image quality. "Hamming + 3" is applied to overlapped blocks, which are composed of 2 (k) +3 pixels, where k=3. We therefore propose verifying the embedding rate during the embedding and extracting phases. Experimental results show that the reconstructed secret messages are the same as the original secret message, and the proposed scheme exhibits a good embedding rate compared to those of previous schemes.
C1 [Kim, Cheonshik] Anyang Univ, Digital Media Engn, 708-113 Anyang 5 Dong, Anyang 430714, Kyonggi Do, South Korea.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien 9701, Taiwan.
C3 Anyang University; National Dong Hwa University
RP Kim, C (corresponding author), Anyang Univ, Digital Media Engn, 708-113 Anyang 5 Dong, Anyang 430714, Kyonggi Do, South Korea.
EM mipsan@paran.com; cnyang@mail.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU Basic Science Research Program Through the National Research Foundation
   of Korea (NRF) by the Ministry of Education, Science and Technology
   [20120192]
FX This paper was extended and improved from an accepted paper of the
   KCIC-2013/FCC-2014 conferences. This research was supported by the Basic
   Science Research Program Through the National Research Foundation of
   Korea (NRF) by the Ministry of Education, Science and Technology
   (20120192).
CR [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Chang CC, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P16, DOI 10.1109/ISECS.2008.222
   Chen C. W., 2012, JOC J CONVERGENCE, V3, P29
   Crandall R., 1998, SOME NOTES STEGANOGR
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Gnanaraj JWK, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-16
   Juneja M, 2013, J INF PROCESS SYST, V9, P405, DOI 10.3745/JIPS.2013.9.3.405
   Kim C, 2012, LECT NOTES ARTIF INT, V7197, P129, DOI 10.1007/978-3-642-28490-8_14
   Kim C, 2011, LECT NOTES ARTIF INT, V6592, P372, DOI 10.1007/978-3-642-20042-7_38
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Panduranga HT, 2013, J INF PROCESS SYST, V9, P499, DOI 10.3745/JIPS.2013.9.3.499
   Truong T.-T., 2012, J CONVERGENCE, V3, P25
   Tseng FH, 2011, HUM-CENTRIC COMPUT I, V1, DOI 10.1186/2192-1962-1-4
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Willems FMJ, 2005, IEEE T INFORM THEORY, V51, P1209, DOI 10.1109/TIT.2004.842707
   Yang CN, 2011, KSII T INTERNET INF, V5, P457, DOI 10.3837/tiis.2011.02.013
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 18
TC 15
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15651
EP 15663
DI 10.1007/s11042-014-2355-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700033
DA 2024-07-18
ER

PT J
AU Liu, RJ
   Chen, Y
   Zhu, XB
   Hou, K
AF Liu, Ruijun
   Chen, Yi
   Zhu, Xiaobin
   Hou, Kun
TI Image classification using label constrained sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Label consistent; Sparse coding; Image classification; Local feature
   encoding
ID FEATURES
AB Sparse coding has been widely used for feature encoding in recent years. However, the encoded parameters' similarity is ignored with sparse coding. Besides, the label information from which class the local feature is extracted is also ignored. To solve this problem, in this paper, we propose a novel feature encoding method called label constrained sparse coding (LCSC) for visual representation. The visual similarities between local features are jointly considered with the corresponding label information of local features. This is achieved by combining the label constraints with the encoding of local features. In this way, we can ensure that similar local features with the same label are encoded with similar parameters. Local features with different labels are encoded with dissimilar parameters to increase the discriminative power of encoded parameters. Besides, instead of optimizing for the coding parameter of each local feature separately, we jointly encode the local features within one sub-region in the spatial pyramid way to combine the spatial and contextual information of local features. We apply this label constrained sparse coding technique for classification tasks on several public image datasets to evaluate its effectiveness. The experimental results shows the effectiveness of the proposed method.
C1 [Liu, Ruijun; Chen, Yi; Zhu, Xiaobin; Hou, Kun] Beijing Technol & Business Univ, Beijing, Peoples R China.
C3 Beijing Technology & Business University
RP Liu, RJ (corresponding author), Beijing Technol & Business Univ, Beijing, Peoples R China.
EM liuruijun@btbu.edu.cn; chenyi@btbu.edu.cn; zhuxiaobin@btbu.edu.cn;
   houkun@btbu.edu.cn
RI Liu, Ruijun/AAA-4250-2020
OI Liu, Ruijun/0000-0003-4871-8989
FU "TwelfthFive Year Plan" National Science and technology support program
   [2012BAD29B01-2]; National Natural Science Foundation of China
   [61402023]; State Key Laboratory of Virtual Reality Technology and
   Systems at Beihang University [BUAA-VR-14KF-04]; Collaborative
   Innovation Centre for State-owned Assets Administration of Beijing
   Technology and Business University [GZ20131102]
FX This work is supported by "TwelfthFive Year Plan" National Science and
   technology support program (No. 2012BAD29B01-2), National Natural
   Science Foundation of China (NO. 61402023), the open funding project of
   State Key Laboratory of Virtual Reality Technology and Systems at
   Beihang University (No. BUAA-VR-14KF-04), Collaborative Innovation
   Centre for State-owned Assets Administration of Beijing Technology and
   Business University (No. GZ20131102).
CR Agarwal J, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-014-0020-z
   [Anonymous], 2007, ICCV
   [Anonymous], ICCV
   [Anonymous], 2008, CVPR
   [Anonymous], J CONVERGENCE
   [Anonymous], 2010, P CVPR
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2014, CVPR
   [Anonymous], 2010, CVPR
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Benlamri R, 2014, HUM-CENT COMPUT INFO, V4, DOI 10.1186/s13673-014-0012-z
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gehler Peter., 2009, ICCV
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Griffin G., 2006, CALTECH 256 DATASET
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Huang YZ, 2011, PROC CVPR IEEE, P1753, DOI 10.1109/CVPR.2011.5995682
   Manh HT, 2013, J INF PROCESS SYST, V9, P592, DOI 10.3745/JIPS.2013.9.4.592
   Inoue N, 2013, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2013.156
   Ji RR, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168758
   Kim J.S., 2013, J CONVERG, V4, P31
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee S, 2014, EVID-BASED COMPL ALT, V2014, DOI 10.1155/2014/967462
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Patil PB, 2013, J INF PROCESS SYST, V9, P349, DOI 10.3745/JIPS.2013.9.3.349
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Ramirez I., 2010, P CVPR
   Rueda A, 2014, IEEE T MED IMAGING, V33, P1262, DOI 10.1109/TMI.2014.2308999
   Russakovsky O, 2012, LECT NOTES COMPUT SC, V7573, P1, DOI 10.1007/978-3-642-33709-3_1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song Z, 2011, PROC CVPR IEEE, P1585, DOI 10.1109/CVPR.2011.5995330
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Wang C., 2009, CVPR
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang CJ, 2014, COMPUT VIS IMAGE UND, V123, P14, DOI 10.1016/j.cviu.2014.02.013
   Zhang CJ, 2013, NEUROCOMPUTING, V120, P318, DOI 10.1016/j.neucom.2012.07.056
   Zhang CJ, 2013, PATTERN RECOGN LETT, V34, P1046, DOI 10.1016/j.patrec.2013.02.013
   Zhang CJ, 2013, SIGNAL PROCESS, V93, P2111, DOI 10.1016/j.sigpro.2012.09.007
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zhou N., 2012, P CVPR
NR 46
TC 17
Z9 17
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15619
EP 15633
DI 10.1007/s11042-015-2626-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700031
DA 2024-07-18
ER

PT J
AU Pan, X
   Cen, Y
   Ma, YB
   Yan, WH
   Gao, XJ
   Liu, X
   Liu, GX
AF Pan, Xin
   Cen, Yao
   Ma, Yubao
   Yan, Weihong
   Gao, Xiaojing
   Liu, Xia
   Liu, Guixiang
TI Identification of gramineous grass seeds using Gabor and locality
   preserving projections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forage identification; Seed image; Local preserving projections; Gabor
   filters; Gramineous grass
ID RECOGNITION; VEGETATION; FUSION; COLOR; WHEAT
AB Forage identification is primarily realized by human experts at a low efficiency, which does not meet the requirements of a digital grassland management. In this study, we propose an automatic identification system for gramineous grass seed, an important category of forage in grassland, based on seed images using Gabor filters and local preserving projections (LPP). The system includes four modules: image acquisition, image preprocessing, feature extraction, and feature matching. Seed images are first captured by a common digital camera, and then preprocessed by a morphological operation to obtain the ROI. In the feature extraction module, the integration of Gabor filters and LPP can provide robust features for varying brightness and image contrast while preserving the manifold structure of the images for efficient dimensionality reduction. The nearest neighbor classifier and linear discriminant analysis (LDA) classifier are used for classification. The novelty of the system lies in two aspects; one is that gramineous grass seeds in the study is automatically identified as valuable resources in grassland, instead of the certain species of weed to be distinguished from crops in the previous weed classification. The other is that Gabor filter and LPP are applied to extract the textural manifold features for the identification of gramineous grass, rather than the geometric features of appearance of gray-scale images, for more robust performance. The experimental results demonstrate the effectiveness of the seed identification system.
C1 [Pan, Xin; Cen, Yao; Gao, Xiaojing; Liu, Xia] Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010018, Inner Mongolia, Peoples R China.
   [Ma, Yubao; Yan, Weihong; Liu, Guixiang] Grassland Res Inst Chinese Acad Agr Sci, Hohhot 010010, Inner Mongolia, Peoples R China.
C3 Inner Mongolia Agricultural University; Chinese Academy of Agricultural
   Sciences; Institute of Grassland Research, CAAS
RP Pan, X (corresponding author), Inner Mongolia Agr Univ, Coll Comp & Informat Engn, Hohhot 010018, Inner Mongolia, Peoples R China.; Liu, GX (corresponding author), Grassland Res Inst Chinese Acad Agr Sci, Hohhot 010010, Inner Mongolia, Peoples R China.
EM xinpan@yahoo.com; liugx804@163.com
RI Zhang, Kai/KBD-3312-2024
FU National Natural Science Foundation of China [61582067, 31302017];
   Postdoctoral Science Foundation of China [20100480370, 201104179];
   National Scientific and Technological Research Project [2013BAK05B01];
   Ministry of water Resources Industry Special Project [201201008-022];
   Basic Scientific Research Foundation for Central Public Research
   Institutes [1610332015007]; Foundations of Inner Mongolia Agricultural
   University [NDPYTD 210-9, BJ09-43]
FX This work is dedicated to Researcher Zhu Xu and Dr. Feng Hao for their
   great contributions. This work was supported partly by the National
   Natural Science Foundation of China under Grant No. 61582067 and No.
   31302017, the Postdoctoral Science Foundation of China No. 20100480370
   and No. 201104179, the National Scientific and Technological Research
   Project 2013BAK05B01, the Ministry of water Resources Industry Special
   Project 201201008-022, the Basic Scientific Research Foundation for
   Central Public Research Institutes No. 1610332015007, and the
   Foundations of Inner Mongolia Agricultural University NDPYTD 210-9, and
   BJ09-43.
CR [Anonymous], 7 INT C KNOWL SYST E
   [Anonymous], 2011, P 4 INT C PERVASIVE
   [Anonymous], LECT NOTES ELECT ENG
   Burgos-Artizzu XP, 2010, IMAGE VISION COMPUT, V28, P138, DOI 10.1016/j.imavis.2009.05.009
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cui JR, 2014, NEURAL COMPUT APPL, V24, P497, DOI 10.1007/s00521-012-1265-y
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Gerhards R, 2003, WEED RES, V43, P385, DOI 10.1046/j.1365-3180.2003.00349.x
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Granitto PM, 2005, COMPUT ELECTRON AGR, V47, P15, DOI 10.1016/j.compag.2004.10.003
   Granitto PM, 2002, COMPUT ELECTRON AGR, V33, P91, DOI 10.1016/S0168-1699(02)00004-2
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ishak AJ, 2009, COMPUT ELECTRON AGR, V66, P53, DOI 10.1016/j.compag.2008.12.003
   Lausch A, 2013, ENVIRON MONIT ASSESS, V185, P1215, DOI 10.1007/s10661-012-2627-8
   Li Q, 2014, J ARID LAND, V6, P478, DOI 10.1007/s40333-013-0207-6
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009
   Onyango CM, 2003, COMPUT ELECTRON AGR, V39, P141, DOI 10.1016/S0168-1699(03)00023-1
   Ou F, 2012, MULTIMED TOOLS APPL, V57, P549, DOI 10.1007/s11042-010-0658-0
   Pan X, 2008, IMAGE VISION COMPUT, V26, P1261, DOI 10.1016/j.imavis.2008.03.001
   Potter C, 2014, J COAST CONSERV, V18, P213, DOI 10.1007/s11852-014-0308-1
   Pourreza A, 2012, COMPUT ELECTRON AGR, V83, P102, DOI 10.1016/j.compag.2012.02.005
   Shi C, 2009, P INT WORKSHOP INTEL, P1
   Tellaeche A, 2011, APPL SOFT COMPUT, V11, P908, DOI 10.1016/j.asoc.2010.01.011
   van Evert FK, 2009, WEED RES, V49, P164, DOI 10.1111/j.1365-3180.2008.00682.x
   Vanamburg LK, 2006, INT J REMOTE SENS, V27, P939, DOI 10.1080/01431160500114789
   Wang JL, 2013, COMPUT ELECTRON AGR, V96, P23, DOI 10.1016/j.compag.2013.04.014
   Wang JingXuan Wang JingXuan, 2010, Acta Agrestia Sinica, V18, P37, DOI 10.1007/s10409-009-0313-z
   [王明亚 Wang Mingya], 2012, [种子, Seed], V31, P55
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Yanikoglu B, 2014, MACH VISION APPL, V25, P1369, DOI 10.1007/s00138-014-0612-7
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
NR 31
TC 1
Z9 1
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16551
EP 16576
DI 10.1007/s11042-016-3424-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700074
DA 2024-07-18
ER

PT J
AU Choi, J
   Seok, S
   Seo, H
   Kim, H
AF Choi, Jongseok
   Seok, Seonhee
   Seo, Hwajeong
   Kim, Howon
TI A fast ARX model-based image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic encryption; ARX
ID CHAOTIC MAPS
AB This paper proposes a novel ARX model-based image encryption scheme that uses addition, rotation, and XOR as its confusion and diffusion mechanism instead of S-Box and permutation as in SP networks. The confusion property of the proposed scheme is satisfied by rotation and XOR with chaotic sequences generated from two logistic maps. Unlike classical image encryption schemes that adopt S-Box or permutation of the entire plain image, the diffusion property is satisfied using addition operations. The proposed scheme exhibits good performance on correlation coefficients (horizontal, vertical and diagonal), Shannon's entropy and NPCR (Number of Pixels Change Rate). Furthermore, simulation results indicate that its time complexity is 9.2 times more efficient than the fastest algorithm(Yang's algorithm).
C1 [Choi, Jongseok; Seok, Seonhee; Seo, Hwajeong; Kim, Howon] Pusan Natl Univ, Room 6512,6 Engn Bldg,Jangjeon 2 I Dong, Busan 609735, South Korea.
C3 Pusan National University
RP Kim, H (corresponding author), Pusan Natl Univ, Room 6512,6 Engn Bldg,Jangjeon 2 I Dong, Busan 609735, South Korea.
EM js.choi.85@gmail.com; seokseonhee@gmail.com; hwajeong84@gmail.com;
   howonkim@gmail.com
RI seo, hwajeong/AAG-9052-2019
FU Institute for Information & communications Technology Promotion(IITP) -
   Korea government(MSIP) [10043907]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIP)
   (No.10043907, Development of high performance IoT device and Open
   Platform with Intelligent Software)
CR [Anonymous], 1987, SIGPLAN Notices, V22, P9, DOI 10.1145/24686.24687
   Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Ashtiyani M, 2008, 3 INT C INF COMM TEC, P1
   Bakhshandeh A, 2013, OPT LASER ENG, V51, P665, DOI 10.1016/j.optlaseng.2013.01.001
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Enayatifar R, 2013, OPT LASER ENG, V51, P1066, DOI 10.1016/j.optlaseng.2013.03.010
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Gupta K, 2009, 2009 1ST INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS(CICSYN 2009), P342, DOI 10.1109/CICSYN.2009.33
   Hong D, 2014, LECT NOTES COMPUT SC, V8267, P3, DOI 10.1007/978-3-319-05149-9_1
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Li HJ, 2011, OPT LASER ENG, V49, P753, DOI 10.1016/j.optlaseng.2011.03.017
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu ZJ, 2007, OPT COMMUN, V275, P324, DOI 10.1016/j.optcom.2007.03.039
   Liu ZJ, 2013, OPT LASER TECHNOL, V47, P152, DOI 10.1016/j.optlastec.2012.09.007
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Srividya G., 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P266, DOI 10.1109/ICCSP.2011.5739316
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
   Zeghid M., 2007, INT J COMPUT SCI ENG, V1, P70
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   ZHAO G, 2010, 2010 2 INT C SIGN PR, V0002, P00002
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 31
TC 20
Z9 20
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14685
EP 14706
DI 10.1007/s11042-016-3274-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500040
OA hybrid
DA 2024-07-18
ER

PT J
AU Kim, A
   Lee, J
   Kim, M
AF Kim, Ahyoung
   Lee, Junwoo
   Kim, Mucheol
TI Context-Aware Recommendation Model based on Mobile Application Analysis
   Platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-aware; Recommendation system; Collaborative filtering; Log
   analysis
ID SYSTEM
AB Recently, various types of log data have been collected and used due to the explosive increase of mobile devices. In mobile environment with high portability and mobility, in addition, the user context information is an important factor for recommendation process. This study attempted to analyze usability log data collected from the mobile device through an application analysis platform. We suggested a context-aware recommendation model to recommend mobile applications or contents by recognizing users' context data. The usability data of applications consist of activities which were active during the use of a mobile device. The features of these activities are related with time, location and device information. A model proposed in this study has a flexible structure which can be selectively used depending on user circumstances and performs a usability patterns of the applications based on the collaborative filtering method.
C1 [Kim, Ahyoung; Lee, Junwoo] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon, South Korea.
   [Kim, Mucheol] Sungkyul Univ, Dept Multimedia, 53 Sungkyuldaehak Ro, Anyang, Gyeonggi Do, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Sungkyul University
RP Kim, M (corresponding author), Sungkyul Univ, Dept Multimedia, 53 Sungkyuldaehak Ro, Anyang, Gyeonggi Do, South Korea.
EM kimay@etri.re.kr; leejw@etri.re.kr; mucheol.kim@gmail.com
FU Ministry of Science, ICT and Future Planning (MSIP, Korea)
FX This work was supported by the Ministry of Science, ICT and Future
   Planning (MSIP, Korea).
CR Agrawal Agrawal D. D., 14 INT C EXT DAT TEC, P530, DOI DOI 10.1145/1951365.1951432
   Ali K., 2012, KDD 12 P 18 ACM SIGK, P204
   [Anonymous], 2010, P 12 INT C HUMAN COM
   Bauer G., 2010, 2 WORKSH CONT AW REC
   Bohmer M., 2013, Proceedings of the 2013 international conference on Intelligent user interfaces, P267
   Buyya R, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P5, DOI 10.1109/HPCC.2008.172
   Davidsson Christoffer., 2011, P 2011 WORKSHOP CONT, P19
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Debnath S., 2008, Proceedings of the 17th international conference on World Wide Web, P1041
   Fontan J., 2008, OP SOURC GRID CLUST
   Foster I., 2008, GRID COMPUTING ENV W, P1
   Kakousis K, 2010, ENTERP INF SYST-UK, V4, P355, DOI 10.1080/17517575.2010.509814
   Kang JM, 2011, AS PAC NETW OP MAN S
   Karatzoglou Alexandros., 2012, Proceedings of ACM International Con- ference on Information and Knowledge Management, P2527, DOI [10.1145/2396761.2398683, DOI 10.1145/2396761.2398683]
   Lee DJ, 2009, KOREA COMPUT C, V36, P123
   Lee JS, 2006, LECT NOTES COMPUT SC, V4272, P190
   Lee KH, 2011, SIGMOD REC, V40, P11, DOI 10.1145/2094114.2094118
   Madden S, 2012, IEEE INTERNET COMPUT, V16, P4, DOI 10.1109/MIC.2012.50
   Padhy R. P., 2011, INT J ADV ENG SCI TE, V11, P15
   Seo HS, 2011, KOREA COMPUT C, V38, P101
   Verkasalo H, 2010, IEEE INT C MOB BUS 2
   Woerndl W, 2007, I C DATA ENGIN WORKS, P871, DOI 10.1109/ICDEW.2007.4401078
   Xu Q., 2011, P 2011 ACM SIGCOMM C, P329, DOI [10.1145/2068816.2068847, DOI 10.1145/2068816.2068847]
   Yan Bo., 2011, P 9 INT C MOBILE SYS, P113
   이세일, 2011, [Journal of Korean Institute of Intelligent Systems, 한국지능시스템학회 논문지], V21, P224
   Younge Andrew J., 2010, 2010 International Conference on Green Computing (Green Comp), P357, DOI 10.1109/GREENCOMP.2010.5598294
NR 26
TC 6
Z9 6
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14783
EP 14794
DI 10.1007/s11042-015-3146-8
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500045
DA 2024-07-18
ER

PT J
AU Lee, H
   Park, S
   Seo, C
   Shin, SU
AF Lee, Hyejoo
   Park, Suwan
   Seo, Changho
   Shin, Sang Uk
TI DRM cloud framework to support heterogeneous digital rights management
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Cloud computing; Content protection
AB The DRM(digital rights management) techniques have been rapidly developed to protect the digital media contents. The growth of smart device and cloud computing makes the environment in which various services can be provided anywhere and anytime, so the DRM technologies have to react to such changes. From this aspect, we previously proposed the architecture of DRM-as-a-Service that provides various functionalities of DRM as some services on the cloud environment, and we referred to it as the DRM Cloud. In this paper, we define a reference model of DRM Cloud to represent some DRM functions that are provided by the DRM Cloud, and several service scenarios are proposed on the DRM Cloud. Also we simulate the DRM Cloud on the testbed and then discuss some security issues and how to handle the interoperability in the DRM Cloud. We conclude that the DRM Cloud allows the content consumers to use many contents with various smart devices, also let the DRM developers and the content service providers reduce the costs of development and business.
C1 [Shin, Sang Uk] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Busan, South Korea.
   [Lee, Hyejoo; Seo, Changho] Kongju Natl Univ, Dept Appl Math, Kong Ju, Chungnam, South Korea.
   [Park, Suwan] ETRI, Cyber Secur Res Dept, Daejeon, South Korea.
C3 Pukyong National University; Kongju National University; Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Shin, SU (corresponding author), Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Busan, South Korea.
EM hyejoo2010@gmail.com; parksw10@etri.re.kr; chseo@kongju.ac.kr;
   shinsu@pknu.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [2011-0029927]
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of
   Korea(NRF) funded by the Ministry of Science, ICT & Future Planning (No.
   2011-0029927).
CR [Anonymous], 2012, MARLIN BROADBAND ARC
   [Anonymous], 2008, MICROSOFT PLAYREADY
   [Anonymous], J CONVERGENCE
   [Anonymous], J CONVERGENCE
   Augusto JC, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-12
   Berena AJ, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-6
   Bocharov JA, 2010, PORTABLE ENCODING AU
   Díaz-Sánchez D, 2011, IEEE T CONSUM ELECTR, V57, P970, DOI 10.1109/TCE.2011.5955247
   Diehl E., 2012, Securing Digital Video: Techniques for DRM and Content Protection
   Dworkin Morris., 2004, NIST SPECIAL PUBLICA
   Heileman GL, 2005, DRM INTEROPERABILITY
   Hyejoo L, 2013, P 3 INT C CONV TECHN, P287
   Jamkhedkar PA, 2009, COMPUT ELECTR ENG, V35, P376, DOI 10.1016/j.compeleceng.2008.06.012
   Jonsson J., 2003, Public-key cryptography standards (pkcs) #1: Rsa cryptography speci cations version 2.1
   Juneja M, 2013, J INF PROCESS SYST, V9, P405, DOI 10.3745/JIPS.2013.9.3.405
   Kalker T, 2007, CORAL DRM INTEROPERA
   Kalker T, 2012, IEEE MULTIMEDIA, V19, P7, DOI 10.1109/MMUL.2012.14
   Kim J.S., 2013, J CONVERG, V4, P31
   Kim PS, 2013, J INF PROCESS SYST, V9, P425, DOI 10.3745/JIPS.2013.9.3.425
   Koenen RH, 2004, P IEEE, V92, P883, DOI 10.1109/JPROC.2004.827357
   Konstantinos C, 2013, SCIENCES, V3, P1
   Lee H., 2013, Journal of Internet Services and Information Security (JISIS), V3, P94
   Mingfeng Tan, 2011, Proceedings of the 2011 IEEE 6th International Symposium on Service Oriented System Engineering (SOSE 2011), P251, DOI 10.1109/SOSE.2011.6139114
   Panduranga HT, 2013, J INF PROCESS SYST, V9, P499, DOI 10.3745/JIPS.2013.9.3.499
   Peng Zou, 2010, Proceedings of the 12th Asia Pacific Web Conference (APWEB 2010), P459, DOI 10.1109/APWeb.2010.43
   Petrlic R., 2012, 2012 IEEE Workshops of International Conference on Advanced Information Networking and Applications (WAINA), P1286, DOI 10.1109/WAINA.2012.92
   Simmons JC, 2013, INTEROPERABILITY DIG
   Trusted Computing Group, 2011, TPM Main Specification Level 2 version 1.2
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 29
TC 4
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14089
EP 14109
DI 10.1007/s11042-015-2662-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500006
DA 2024-07-18
ER

PT J
AU Lee, J
   Lee, CM
   Park, NK
AF Lee, Julak
   Lee, Chang-Moo
   Park, Nam-Kwun
TI Application of sensor network system to prevent suicide from the bridge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor network system; Industrial security; Social safety net; Suicide
   prevention; Bridge
AB Recently suicides have been on the rise and become social issues around the world. Seoul, the capital of South Korea, has been no exception. Hence, to detect and respond early, Seoul Metropolitan Government has installed the suicide corresponding sensor system at two locations of Han-River bridges where suicide occurs frequently. This study analyzed the pilot system's performance of past 1 year and presented the following results. First, rescued people who attempted to suicide have increased in relation of the sensor system and it's determined to be verified based on early discovery, and prompt action of rescue operation. Second, after a pilot test for 1 year, surveillance cameras installed at blind spots have contributed to improve the effectiveness of the security system. Finally, as a result of the analyzing the death leap types, there are three following types of people who attempted to suicide: (1) a form of falling directly from the bridge rail, (2) a form of sitting on the bridge rail and jumping away, (3) a form of standing outside of the bridge rail and jumping away. Based on these results, it was implied that the proactive measures such as utilizing sensors are very effective in suicide prevention and they can be expanded to prevention of death leap in other places such as high-rise buildings.
C1 [Lee, Julak] Kyonggi Univ, Dept Secur Management, 154-42 Gwanggyosan Ro, Suwon 443760, Gyeonggi Do, South Korea.
   [Lee, Chang-Moo] Chung Ang Univ, Dept Ind Secur, 84 Heukseok Ro, Seoul, South Korea.
   [Park, Nam-Kwun] Seoul Metropolitan Council, Publ Safety & Construct Comm, 15 Deoksugung Gil, Seoul, South Korea.
C3 Kyonggi University; Chung Ang University
RP Lee, CM (corresponding author), Chung Ang Univ, Dept Ind Secur, 84 Heukseok Ro, Seoul, South Korea.
EM julaklee@hanmail.net; jbalanced@gmail.com; park9616@naver.com
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) support program
   [IITP-2015-H8501-15-1018]
FX "This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2015-H8501-15-1018) supervised by the
   IITP(Institute for Information & communications Technology Promotion)"
CR Gore-Jones V, 2012, AUSTRALAS PSYCHIATRY, V20, P309, DOI 10.1177/1039856212449672
   Kang LY, 2010, STUD LIFE CULT, V18, P305
   Kim DY, 2012, KOR J HLTH PSYCHOL, V17, P323
   Kim J, 2013, COLLECT SOC WELF THE, V33, P513
   Kim Jong-Oh, 2009, [korean Journal of Public Safety and Criminal Justice, 한국공안행정학회보], V18, P59
   Kim K, 2014, INT J MENT HEALTH SY, V8, DOI 10.1186/1752-4458-8-17
   Kim M, 2011, KOR J POLICY ANAL EV, V21, P273
   Lee D, 2013, BUSAN NATL U LAW REV, V54, P1
   Lee H, 2011, GLOBAL SOCIAL WELFAR, V1, P7
   주정관, 2014, [Korea Reformed Journal, 개혁논총], V31, P289
   김정연, 2012, [Journal of Digital Convergence, 디지털융복합연구], V10, P525
   이순성, 2010, [Studies on Life and Culture, 생명연구], V18, P77
   이윤주, 2008, [Korea Journal of Counseling, 상담학연구], V9, P659
NR 13
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 14557
EP 14568
DI 10.1007/s11042-015-3134-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500033
DA 2024-07-18
ER

PT J
AU Ye, DP
   Mei, Y
   Shang, YY
   Zhu, JX
   Ouyang, K
AF Ye, Dengpan
   Mei, Yuan
   Shang, Yueyun
   Zhu, Jixiang
   Ouyang, Kun
TI Mobile crowd-sensing context aware based fine-grained access control
   mode
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile crowd sensing; Context aware; Access control
ID CLASSIFICATION
AB The present of smart mobile devices have provided unprecedented flexibility to humankind, with which people are able to access kinds of system resource through internet everywhere, including confidential data, nevertheless. While the traditional computing environment is always considered to be static and security-guarded, the context of mobile computing is much more variable, complex, and risk-hidden. To provide appropriate protection on mobile devices, we proposed a context-aware model combined with crowd-sensing paradigm to achieve fine-grained measurement of user's current context. Corresponding to the context-aware model, we categorize the context by kinds of attributes and proposed Attribute-tree based Context-Aware Access Control model to protect user's privacy and confidential information. The experimental result indicates that our proposed model is fine-grained, efficient and flexible to apply to different mobile platforms.
C1 [Ye, Dengpan; Mei, Yuan; Zhu, Jixiang; Ouyang, Kun] Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
   [Shang, Yueyun] South Cent Univ Nationalities, Sch Math & Stat, Wuhan 430074, Peoples R China.
C3 Wuhan University; South Central Minzu University
RP Ye, DP (corresponding author), Wuhan Univ, Sch Comp, Wuhan 430072, Peoples R China.
EM yedp2001@163.com
RI lu, yuan/JZD-0832-2024
FU National Natural Science Foundation of China [61272453]; Natural Science
   Foundation of Hubei Province [2014CFB379]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61272453, by the Natural Science
   Foundation of Hubei Province under Grant 2014CFB379.
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Aich S, 2007, LECT NOTES COMPUT SC, V4804, P1567
   [Anonymous], 2010, P IEEE INFOCOM
   [Anonymous], USING MOBILE TECHNOL
   Azizyan M, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P261
   Bauer L., 2007, SOUPS 07, P64
   Bertino E., 2001, ACM Transactions on Information and Systems Security, V4, P191, DOI 10.1145/501978.501979
   Bertino Elisa., 2005, SACMAT 05, P29
   Burges CristopherJ. C., 1998, DATA MIN KNOWL DISC
   Cai CZ, 2004, PROTEINS, V55, P66, DOI 10.1002/prot.20045
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Damiani ML, 2007, ACM T INFORM SYST SE, V10, DOI 10.1145/1210263.1210265
   Eisenman SB, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P87
   El-Maleh K, 1999, INT CONF ACOUST SPEE, P237, DOI 10.1109/ICASSP.1999.758106
   Guo B, 2014, INT CONF PERVAS COMP, P593, DOI 10.1109/PerComW.2014.6815273
   Himberg J, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P127, DOI 10.1109/MFI.2001.1013520
   Joshi J., 2002, P 7 ACM S ACCESS CON, P74
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Long S, 1996, 2 ACM INT C MOB COMP, P10
   Mohan P, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P323
   Poslad S, 2001, IEE CONF PUBL, P28, DOI 10.1049/cp:20010006
   Press WilliamH., 2007, NUMERICAL RECIPES AR, V3rd, P883
   Ray I, 2006, LECT NOTES COMPUT SC, V4332, P147
   Salam F. M., 1999, Proceedings. 1999 IEEE/SICE/RSJ. International Conference on Multisensor Fusion and Integration for Intelligent Systems. MFI'99 (Cat. No.99TH8480), P211, DOI 10.1109/MFI.1999.815991
   van Diggelen F, 2009, ARTECH HSE GNSS TECH, P1
   Van Laerhoven K, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P115, DOI 10.1109/ISWC.2001.962112
   VANSETTEN M, 2004, LNCS, V3137
   Vapnik VN, 1996, NATURE STAT LEARNING, V38, P400
   Venanzi M, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P155, DOI 10.1145/2566486.2567989
   Wang K, 2014, IEEE SYS MAN CYBERN, P3755, DOI 10.1109/SMC.2014.6974515
   Wang ZB, 2015, IEEE T MOBILE COMPUT, V14, P538, DOI 10.1109/TMC.2014.2322373
   Zhou Q, 2012, J COMPUTATIONAL INFO, V8, P8471
NR 32
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13977
EP 13993
DI 10.1007/s11042-015-2693-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800051
DA 2024-07-18
ER

PT J
AU Cai, LJ
   Huang, L
   Liu, CP
AF Cai, Lijun
   Huang, Lei
   Liu, Changping
TI Age estimation based on improved discriminative Gaussian process latent
   variable model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Discriminative Gaussian process latent variable model;
   Kernel fisher discriminant analysis; Gaussian process regression
AB Affected by various factors (genes, living habits and so on), different people present distinct aging patterns. To discover the underlying trend of aging patterns, we propose an effective age estimation method based on DGPLVM (Discriminative Gaussian Process Latent Variable Model). DGPLVM is a kind of discriminative latent variable method for manifold learning. It discovers the low-dimensional manifold by employing a discriminative prior distribution over the latent space. DGPLVM with KFDA (Kernel Fisher Discriminant Analysis) prior has been studied and successfully applied to face verification. Different with face verification which is a two-class problem, age estimation is a linearly inseparable multi-class problem. In this paper, DGPLVM with KFDA is reformulated to get the low-dimensional representations for age estimation. After low-dimensional representations are obtained, Gaussian process regression model is adopted to find the age regressor mapping low-dimensional representations to ages. Experimental results on two widely used databases FG-NET and MORPH show that reformulated DGPLVM with KFDA is a good application in age estimation and achieves comparable results to state-of-the arts.
C1 [Cai, Lijun; Huang, Lei; Liu, Changping] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Cai, LJ (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM cailijun2013@ia.ac.cn
RI huang, lei/GQP-8739-2022
CR [Anonymous], 2011, P 22 BRIT MACH VIS C
   [Anonymous], 29 AAAI C ART INT AA
   [Anonymous], 2007, P IEEE 11 INT C COMP
   [Anonymous], 2007, P 24 INT C MACHINE L
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1383
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guo G., 2010, IEEE COMP SOC C COMP, P71, DOI DOI 10.1109/CVPRW.2010.5543609
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563041
   Kim S.-J., 2006, ICML 06, P465
   Kuang-Yu Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3396, DOI 10.1109/ICPR.2010.829
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lawrence ND, 2004, ADV NEUR IN, V16, P329
   Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Peng Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3404, DOI 10.1109/ICPR.2010.831
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Ren HY, 2015, LECT NOTES COMPUT SC, V9003, P115, DOI 10.1007/978-3-319-16865-4_8
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wenhua Ma, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P958, DOI 10.1109/PACIIA.2008.258
   Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853
   Yan SC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P96
   Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975
NR 33
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11977
EP 11994
DI 10.1007/s11042-015-2668-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200022
DA 2024-07-18
ER

PT J
AU Kim, T
   Kim, EJ
AF Kim, Taekook
   Kim, Eui-Jik
TI View pattern-based adaptive streaming strategy for mobile content
   delivery services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive streaming; Content delivery service; Progressive download; View
   pattern; YouTube
AB This study contributes towards a new streaming strategy for mobile multimedia content such as audio/video delivered to mobile access devices. In general, users often watch the first part of a video clip and then switch to some other content. In this regard, this paper presents a view pattern-based adaptive streaming (abbreviated VPAS) strategy for mobile content delivery services that considers mobile network environments characterized by limited available bandwidth. VPAS offers a distinction by requesting smaller data chunk sizes in the remaining parts of the video content, which are not as frequently referenced as the first parts. VPAS offers several benefits, including the less wasting of network resources and less network traffic.
C1 [Kim, Taekook] Korea Univ, Dept Elect Engn, 145 Anam Ro, Seoul 02855, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
C3 Korea University; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
EM euijik.kim@gmail.com
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2014R1A1A2057641]; Hallym
   University Research Fund [HRF-201506-005]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2014R1A1A2057641). This research was also supported by
   Hallym University Research Fund, 2015 (HRF-201506-005).
CR [Anonymous], 2013, CISC VIS NETW IND FO
   Forouzan BA, 2010, TCP IP PROTOCOL SUIT, P728
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Huang YS, 2015, MULTIMED TOOLS APPL, V74, P4927, DOI 10.1007/s11042-014-1856-y
   Ji XY, 2015, J SUPERCOMPUT, V71, P2138, DOI 10.1007/s11227-014-1340-5
   Kim S, 2015, J SUPERCOMPUT, V71, P2177, DOI 10.1007/s11227-015-1393-0
   Kim T, 2015, MULTIMED TOOLS APPL, V74, P1697, DOI 10.1007/s11042-014-2215-8
   Kurose J, 2013, COMPUTER NETWORKING, P593
   Ma KJ, 2011, IEEE COMMUN MAG, V49, P166, DOI 10.1109/MCOM.2011.5741161
   Ma KJ, 2011, J NETW COMPUT APPL, V34, P1572, DOI 10.1016/j.jnca.2011.02.001
   Sandvine, 2014, 1H2014 SANDV
   Yu HF, 2015, MULTIMED TOOLS APPL, V74, P5811, DOI 10.1007/s11042-014-1889-2
NR 12
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12693
EP 12704
DI 10.1007/s11042-015-3077-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700023
DA 2024-07-18
ER

PT J
AU Wang, YL
   Ding, WJ
   Chen, YX
AF Wang, Yulin
   Ding, Wenjia
   Chen, Yixin
TI Positioning corners of human mouth based on local gradient operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature points positioning; Local gradient operator;
   Chain code tracing
ID FACE DETECTION
AB Face recognition has widespread applications in monitoring system, public security and home entertainment etc.. However, in practical application, there are many problems needed to be solved in face recognition technology. This paper presents a method to detect and locate accurately facial feature points based on local gradient operator. With Adaboost algorithm, we first detect roughly the mouth area in the face image, and then extract contours of mouth using local gradient operator. Finally, we use Ostu threshold to extract the binary contour around mouth corners according to the precise location of chain code tracing. Experimental results show that local gradient operator can detect and locate rapidly and accurately human mouth, and it is relatively robust against change of facial expressions as well as noise, which helps to improve face recognition rate.
C1 [Wang, Yulin; Chen, Yixin] Wuhan Univ, Int Sch Software, Wuhan, Peoples R China.
   [Ding, Wenjia] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Wuhan University; National University of Singapore
RP Chen, YX (corresponding author), Wuhan Univ, Int Sch Software, Wuhan, Peoples R China.
EM blairchen@126.com
RI chen, yu-cheng/IQT-1648-2023; Chen, Yi/JBR-7728-2023; Chen,
   Yi/HPD-0595-2023; Chen, Yu/Y-3292-2019; Yulin, Wang/AAL-3345-2021; Chen,
   Yukun/KGK-4521-2024; Chen, Yi/HIR-2608-2022
OI Yulin, Wang/0000-0002-9899-7712; 
FU Applied Basic Research Programs of Wuhan City [2014060101010029];
   Natural Science Foundation of Hubei Province of China [2011CDB449]
FX This work is sponsored by Applied Basic Research Programs of Wuhan City
   (Grant No. 2014060101010029), and Natural Science Foundation of Hubei
   Province of China (Grant No. 2011CDB449).
CR [Anonymous], BRIT MACH VIS C
   Bichsel M, 1991, THESIS
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Feris RS, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P125, DOI 10.1109/AFGR.2002.1004143
   Fu HC, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P507, DOI 10.1109/NNSP.2000.890128
   Heisele B, 2001, PROC CVPR IEEE, P657
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Kafai M, 2014, IEEE T INF FOREN SEC, V9, P2132, DOI 10.1109/TIFS.2014.2359548
   Kanade Takeo, 1973, Picture processing system by computer complex and recognition of human faces
   Kruger V, 2002, J OPT SOC AM
   Kumar Sunil, 2013, Biomed Res Int, V2013, P382063, DOI 10.1155/2013/382063
   Li D. H., 2002, P 2002 2 IEEE INT C, P76
   Nguyen MH, 2008, P 2008 8 IEEE INT C, P376
   Phung SL, 2001, P 7 AUSTR NZ INT INF, P171
   Reinders MJT, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P230, DOI 10.1109/AFGR.1996.557269
   REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978
   REISFELD D, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P117, DOI 10.1109/ICPR.1992.201521
   WAITE J, 1992, BT TECHNOL J, V10, P20
   Wan KW, 2005, PATTERN RECOGN LETT, V26, P2409, DOI 10.1016/j.patrec.2005.04.015
   Yan SC, 2003, IMAGE VISION COMPUT, V21, P69, DOI 10.1016/S0262-8856(02)00136-1
   YANG GZ, 1994, PATTERN RECOGN, V27, P53, DOI 10.1016/0031-3203(94)90017-5
   Yow KC, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P16, DOI 10.1109/AFGR.1996.557238
   Zhang LM, 2000, KES'2000: FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ENGINEERING SYSTEMS & ALLIED TECHNOLOGIES, VOLS 1 AND 2, PROCEEDINGS, P117, DOI 10.1109/KES.2000.885772
   Zhang Wencong, 2008, Journal of Electronics, V25, P337, DOI 10.1007/s11767-006-0199-x
NR 25
TC 1
Z9 1
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11815
EP 11829
DI 10.1007/s11042-015-2627-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200013
DA 2024-07-18
ER

PT J
AU Guo, C
   Zhang, H
   Song, QQ
   Li, MC
AF Guo, Cheng
   Zhang, Huan
   Song, Qiongqiong
   Li, Mingchu
TI A multi-threshold secret image sharing scheme based on the generalized
   Chinese reminder theorem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Access structure; Multi-threshold secret sharing; Secret image sharing;
   Chinese remainder theorem
ID AUTHENTICATION; STEGANOGRAPHY; DECRYPTIONS
AB In a multi-secret image sharing scheme, participants are able to share multiple secret images such the way that each secret image can be reconstructed according to the corresponding access structure. In this paper, employing Chan and Chang's multi-secret sharing, we propose a new multi-threshold secret image sharing scheme. In the secret image sharing process, based on the generalized CRT, secret values are produced according to the associated access structures. The shadow images can be generated by embedding the secret values into a cover image using the quantization operation. The new scheme allows a qualified subset of participants to retrieve the related secret image. Moreover, any monotone access structure can be realized with a deletion procedure. The experiments demonstrate that secret images can be recovered without distortion. Besides, the quality of the shadow images is satisfactory and the capacity of embedded secret values is acceptable especially under binary images.
C1 [Guo, Cheng; Zhang, Huan; Song, Qiongqiong; Li, Mingchu] Dalian Univ Technol, Sch Software Technol, 8 Rd, Dalian 116620, Peoples R China.
C3 Dalian University of Technology
RP Guo, C (corresponding author), Dalian Univ Technol, Sch Software Technol, 8 Rd, Dalian 116620, Peoples R China.
EM guo8016@gmail.com; zhanghuan0211@126.com; qiongq.song@gmail.com;
   li_minqchu@yahoo.com
FU National Science Foundation of China [61272173, 61100194, 61401060];
   general program of Liaoning Provincial Department of Education Science
   Research [L2014017]
FX This paper is supported by the National Science Foundation of China
   under grant No. 61272173, 61100194, 61401060 and the general program of
   Liaoning Provincial Department of Education Science Research under
   grants L2014017.
CR Barwick SG, 2005, DESIGN CODE CRYPTOGR, V37, P367, DOI 10.1007/s10623-004-4031-z
   BENALOH J, 1990, LECT NOTES COMPUT SC, V403, P27
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chan CW, 2005, APPL MATH COMPUT, V166, P1, DOI 10.1016/j.amc.2004.04.081
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Ito M., 1989, Electronics and Communications in Japan, Part 3 (Fundamental Electronic Science), V72, P56, DOI 10.1002/ecjc.4430720906
   Kumar S, 2014, SECUR COMMUN NETW, V7, P653, DOI 10.1002/sec.769
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Sasaki Manami, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7391, DOI 10.1109/ICASSP.2014.6855036
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   STINSON DR, 1994, IEEE T INFORM THEORY, V40, P118, DOI 10.1109/18.272461
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
NR 19
TC 22
Z9 22
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11577
EP 11594
DI 10.1007/s11042-015-2885-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900035
DA 2024-07-18
ER

PT J
AU Hu, LY
   Guo, GD
   Ma, CF
AF Hu, Liying
   Guo, Gongde
   Ma, Changfeng
TI Combined new nonnegative matrix factorization algorithms with
   two-dimensional nonnegative matrix factorization for image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nonnegative matrix factorization (NMF); Two-dimensional nonnegative
   matrix factorization (2DNMF); Rank-one residue iteration (RRI);
   Element-wisely residue iteration (ERI); Image processing; Compression
   ratio
ID REPRESENTATION; DISCOVERY; FRAMEWORK; PARTS
AB In recent years, nonnegative matrix factorization (NMF) has attracted significant amount of attentions in image processing, text mining, speech processing and related fields. Although NMF has been applied in several application successfully, its simple application on image processing has a few caveats. For example, NMF costs considerable computational resources when performing on large databases. In this paper, we propose two enhanced NMF algorithms for image processing to save the computational costs. One is modified rank-one residue iteration (MRRI) algorithm, the other is element-wisely residue iteration (ERI) algorithm. Here we combine CAPG (a NMF algorithm proposed by Lin), MRRI and ERI with two-dimensional nonnegative matrix factorization (2DNMF) for image processing. The main difference between NMF and 2DNMF is that the former first aligns images into one-dimensional (1D) vectors and then represents them with a set of 1D bases, while the latter regards images as 2D matrices and represents them with a set of 2D bases. The three combined algorithms are named CAPG-2DNMF, MRRI-2DNMF and ERI-2DNMF. The computational complexity and convergence analyses of proposed algorithms are also presented in this paper. Three public databases are used to test the three NMF algorithms and the three combinations, the results of which show the enhancement performance of our proposed algorithms (MRRI and ERI algorithms) over the CAPG algorithm. MRRI and ERI have similar performance. The three combined algorithms have better image reconstruction quality and less running time than their corresponding 1DNMF algorithms under the same compression ratio. We also do some experiments on a real-captured image database and get similar conclusions.
C1 [Hu, Liying; Guo, Gongde; Ma, Changfeng] Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou 350007, Peoples R China.
C3 Fujian Normal University
RP Hu, LY (corresponding author), Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou 350007, Peoples R China.
EM hlyxyz@fjnu.edu.cn
FU National Natural Science Foundation of China [61175123]
FX We would like to thank the anonymous editors and reviewers for their
   helpful suggestions and comments. This work is supported by National
   Natural Science Foundation of China (Grant No.61175123).
CR [Anonymous], P EUROSPEECH
   Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Brunet JP, 2004, P NATL ACAD SCI USA, V101, P4164, DOI 10.1073/pnas.0308531101
   Chu M., 2005, IMAGE, Bulletin of the International Linear Algebra Society, V34, P2
   Eches O, 2014, IEEE GEOSCI REMOTE S, V11, P778, DOI 10.1109/LGRS.2013.2278993
   Gao Y, 2005, BIOINFORMATICS, V21, P3970, DOI 10.1093/bioinformatics/bti653
   Guillamet D, 2002, LECT NOTES ARTIF INT, V2504, P336
   Ho ND, 2008, NON NEGATIVE MATRIX
   Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134
   Kumar BGV, 2012, IMAGE VISION COMPUT, V30, P279, DOI 10.1016/j.imavis.2012.02.010
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li SZ, 2001, PROC CVPR IEEE, P207
   Lin L, 2011, APPL MATH COMPUT, V217, P9997, DOI 10.1016/j.amc.2011.04.070
   Lin L, 2010, APPL MATH COMPUT, V216, P1763, DOI 10.1016/j.amc.2009.12.028
   McCann MT, 2014, IEEE T IMAGE PROCESS, V23, P2033, DOI 10.1109/TIP.2014.2307475
   Nikitidis S, 2012, PATTERN RECOGN, V45, P4080, DOI 10.1016/j.patcog.2012.04.030
   Pauca VP, 2006, LINEAR ALGEBRA APPL, V416, P29, DOI 10.1016/j.laa.2005.06.025
   Pauca VP, 2004, SIAM PROC S, P452
   Ptucha R, 2013, IMAGE VISION COMPUT, V31, P365, DOI 10.1016/j.imavis.2013.03.003
   Sajda P, 2004, IEEE T MED IMAGING, V23, P1453, DOI 10.1109/TMI.2004.834626
   Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005
   Smaragdis P, 2003, 2003 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS PROCEEDINGS, P177, DOI 10.1109/ASPAA.2003.1285860
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Wang Y, 2005, INT J PATTERN RECOGN, V19, P495, DOI 10.1142/S0218001405004198
   Zhang DQ, 2005, LECT NOTES COMPUT SC, V3723, P350
   Zheng WS, 2012, PATTERN RECOGN, V45, P2912, DOI 10.1016/j.patcog.2012.01.022
NR 26
TC 4
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11127
EP 11155
DI 10.1007/s11042-015-2837-5
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900014
DA 2024-07-18
ER

PT J
AU Gao, LL
   Pan, HW
   Xie, XQ
   Zhang, ZQ
   Li, Q
   Han, QL
AF Gao, Linlin
   Pan, Haiwei
   Xie, Xiaoqin
   Zhang, Zhiqiang
   Li, Qing
   Han, Qilong
TI Graph modeling and mining methods for brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain images; Graph model; Graph edit distance; Frequent approximate
   subgraph mining
ID CT; RETRIEVAL; ALGORITHM; SYMMETRY; PATTERNS; PLANE
AB Brain disease is a top cause of death. Currently, its main diagonosis is to take advantage of medical brain images to analyse patients' condition. In medical big data analysis field, it has been a research hotspot that how to effectively represent medical images and discover significant information hidden in them to further assist doctors to achieve a better diagnosis. Graphs, as one of the most general forms of data representation, can easily represent entities, their attributes and their relationships well. However, the existing medical image graph models do not exploit the specific relationships of brain images very well so that some essential information is lost. Therefore, aiming at brain images, we firstly construct a domain knowledge-oriented graph about the Topological Relationships among Ventricles and Lesions (TRVL) to represent a brain image, and give the algorithm of modeling a brain Image to a TRVL Graph (denoted as I2G). Then we propose a method named Frequent Approximate Subgraph Mining based on Graph Edit Distance (FASMGED) to exactly discover meaningful patterns hidden in brain images. This method employs a strong error-tolerant graph matching strategy which is accordant with ubiquitous noise in practice. Moreover, an approximate method of frequent approximate subgraph mining is proposed based on the greedy strategy. We have evaluated our algorithms on real and simulated data. Results show that I2G is computationally scalable, FASMGED can discover more significant patterns than other state-of-the-art frequent subgraph mining methods, and the approximate method of frequent approximate subgraph mining outperforms FASMGED.
C1 [Gao, Linlin; Pan, Haiwei; Xie, Xiaoqin; Zhang, Zhiqiang; Han, Qilong] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Li, Qing] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Harbin Engineering University; City University of Hong Kong
RP Pan, HW (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.
EM gll_89@hrbeu.edu.cn; panhaiwei2006@hotmail.com; xiexiaoqin@hrbeu.edu.cn;
   zqzhang@hrbeu.edu.cn; itqli@cityu.edu.hk; hanqilong@hrbeu.edu.cn
RI Li, Qing/JMH-1365-2023; Gao, Lin/JNF-0375-2023; zhang,
   zhiqiang/R-8991-2016
OI Li, Qing/0000-0003-3370-471X; 
FU National Natural Science Foundation of China [61370084, 61272184,
   61202090]; Fundamental Research Funds for the Central Universities
   [HEUCF100602, HEUCFT1202]
FX The paper is partly supported by the National Natural Science Foundation
   of China under Grant No.61370084, 61272184, 61202090; The Fundamental
   Research Funds for the Central Universities under grant No.HEUCF100602,
   HEUCFT1202.
CR Acosta-Mendoza N, 2012, KNOWL-BASED SYST, V27, P381, DOI 10.1016/j.knosys.2011.12.002
   [Anonymous], IEEE T PATTERN ANAL
   Atif J, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P224
   Bahadir A, 2010, P 20 INT C PATT REC, P1112
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen C, 2007, IEEE DATA MINING, P445, DOI 10.1109/ICDM.2007.36
   Conte D, 2004, IJPRAI, V520, P5833
   Cook D.J., 2007, Mining graph data
   Elsayed A, 2010, KNOWL-BASED SYST, V23, P330, DOI 10.1016/j.knosys.2009.11.008
   Euripides GM, 2002, IEEE T KNOWL DATA EN, V14, P979
   Flores-Garrido M, 2014, KNOWL-BASED SYST, V66, P166, DOI 10.1016/j.knosys.2014.04.040
   Gao LL, 2015, IEEE INT C BIOINFORM, P1004, DOI 10.1109/BIBM.2015.7359821
   Gao XB, 2008, PATTERN RECOGN, V41, P3179, DOI 10.1016/j.patcog.2008.03.025
   Gillebert CR, 2014, NEUROIMAGE-CLIN, V4, P540, DOI 10.1016/j.nicl.2014.03.009
   Gu XS, 2006, HUMAN ANATOMY
   Haiwei P, 2005, P ANN INT IEEE EMBS, P3308
   HOLDER LB, 1992, MACHINE LEARNING /, P218
   Hossain M.S. Angryk., 2007, IEEE ICDM Workshop on Mining Graphs and Complex Structures, USA, P417, DOI DOI 10.1109/ICDMW.2007.104
   Hu QM, 2003, NEUROIMAGE, V20, P2153, DOI 10.1016/j.neuroimage.2003.08.009
   Jia Y, 2011, KNOWL INF SYST, V28, P423, DOI 10.1007/s10115-010-0376-y
   Kumar A, 2014, MED IMAGE ANAL, V18, P330, DOI 10.1016/j.media.2013.11.003
   Liao CC, 2010, COMPUT BIOL MED, V40, P331, DOI 10.1016/j.compbiomed.2010.01.004
   Morales-González A, 2014, PATTERN RECOGN, V47, P169, DOI 10.1016/j.patcog.2013.07.004
   Nowozin S., 2007, Computer Vision and Pattern Recognition 2007. CVPR '07, P1, DOI DOI 10.1109/CVPR.2007.383171
   Pan HW, 2014, IEEE J BIOMED HEALTH, V18, P574, DOI 10.1109/JBHI.2013.2274798
   Prima S, 2002, IEEE T MED IMAGING, V21, P122, DOI 10.1109/42.993131
   Rafael C.G, 2010, DIGITAL IMAGE PROCES
   Rong JS, 2016, J MED IMAG HEALTH IN, V6, P22, DOI 10.1166/jmihi.2016.1596
   Rorden C, 2012, NEUROIMAGE, V61, P957, DOI 10.1016/j.neuroimage.2012.03.020
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Song YL, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING, P337
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   Vos PC, 2013, MED IMAGING IMAGE PR, V8669, P598
   Xiao YH, 2008, LECT NOTES COMPUT SC, V4947, P452, DOI 10.1007/978-3-540-78568-2_34
   Yan XF, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P721, DOI 10.1109/ICDM.2002.1184038
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   Zhang SJ, 2007, PROC INT CONF DATA, P1222
   Zou Z, 2009, FREQUENT SUBGRAPH PA, P583
   Zou ZN, 2010, IEEE T KNOWL DATA EN, V22, P1203, DOI 10.1109/TKDE.2010.80
   Zou Zhaonian., 2010, KDD, P633
NR 42
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9333
EP 9369
DI 10.1007/s11042-016-3482-3
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500028
DA 2024-07-18
ER

PT J
AU Hsia, CH
   Chiang, JS
   Hsieh, CF
AF Hsia, Chih-Hsien
   Chiang, Jen-Shiun
   Hsieh, Chi-Fang
TI Low-complexity range tree for video synopsis system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Video retrieval system; Gaussian mixture model;
   Low-complexity range tree; Video synopsis system
ID SEGMENTATION; TRACKING; IDENTIFICATION
AB This work proposes an efficient video retrieval technique for video synopsis. In a video system, the Region of Interest (ROI) should be extracted in a long video effectively such that users can browse it quickly and easily. Focusing on the characteristics of objects in the foreground of real-world video sequences, this work employs the Gaussian Mixture Model (GMM) and color-histograms for object detection. In order to reduce the search time, a new video synopsis search approach, a low-complexity range tree algorithm, is proposed to improve the effectiveness of searches for objects of interest matching pre-set conditions. With the time and space redundancy-reducing techniques of video synopsis, the objects of interest can be displayed within a short time. Objects and events can be found and displayed quickly without allocating time to watching non-ROIs. For the test video sequences, the results show an accuracy rate of 97 % and a processing speed of 32 FPS (frames per second) in the online phase, and the time complexity of object searching is reduced from O(N) to O(log (D-1) N).
C1 [Hsia, Chih-Hsien] Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
   [Chiang, Jen-Shiun; Hsieh, Chi-Fang] Tamkang Univ, Dept Elect Engn, New Taipei, Taiwan.
C3 Chinese Culture University; Tamkang University
RP Chiang, JS (corresponding author), Tamkang Univ, Dept Elect Engn, New Taipei, Taiwan.
EM chhsia625@gmail.com; chhsia@ee.tku.edu.tw; hardman761110@gmail.com
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU National Science Council of Taiwan [NSC-100-2221-E-032-046]
FX This research work was partially supported by the National Science
   Council of Taiwan, under grant number NSC-100-2221-E-032-046.
CR [Anonymous], 2011 IEEE INT S INT
   [Anonymous], P 2006 IEEE COMP SOC
   Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Chien SY, 2004, IEEE T MULTIMEDIA, V6, P732, DOI 10.1109/TMM.2004.834868
   Gong YH, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P362, DOI 10.1109/ICIP.2001.958126
   Guo JM, 2011, IEEE T CIRC SYST VID, V21, P804, DOI 10.1109/TCSVT.2011.2133270
   Hsia CH, 2013, I S INTELL SIG PROC, P163, DOI 10.1109/ISPACS.2013.6704540
   Hsia CH, 2012, INT J INNOV COMPUT I, V8, P4451
   Kim KK, 2005, 7TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P817
   Lin C-H, 2011, IPPR C COMP VIS GRAP
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mitiche A, 2006, IEEE T PATTERN ANAL, V28, P1818, DOI 10.1109/TPAMI.2006.232
   Pal C., 2005, IEEE C COMP VIS PATT, V2, P20
   Petrovic N, 2005, MULTIMED TOOLS APPL, V26, P327, DOI 10.1007/s11042-005-0895-9
   Pope A, 1998, CONF REC ASILOMAR C, P915, DOI 10.1109/ACSSC.1998.751015
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Pyun KP, 2007, IEEE T IMAGE PROCESS, V16, P1902, DOI 10.1109/TIP.2007.899612
   Ribaric S, 2004, IEEE MEDITERR ELECT, P231, DOI 10.1109/MELCON.2004.1346816
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sugandi B, 2007, INT C INN COMP INF C, P5
   Sugandi B, 2009, INT J INNOV COMPUT I, V5, P1179
   Xiao BX, 2008, Proceedings of the 27th Chinese Control Conference, Vol 4, P578, DOI 10.1109/CHICC.2008.4605713
   Yamada H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P222, DOI 10.1109/FPT.2003.1275751
   Yanjun Li, 2006, 2006 International Symposium on Communications and Information Technologies (IEEE Cat No. 06EX1447C), P697
   Zarka N, 2008, 3 INT C ICTTA, P1
   Zhan CH, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P519, DOI 10.1109/ICIG.2007.153
   Zhang LF, 2008, IEEE INT SYM MULTIM, P667, DOI 10.1109/ISM.2008.117
NR 28
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9885
EP 9902
DI 10.1007/s11042-015-2714-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500021
DA 2024-07-18
ER

PT J
AU Mironica, I
   Duta, IC
   Ionescu, B
   Sebe, N
AF Mironica, Ionut
   Duta, Ionut Cosmin
   Ionescu, Bogdan
   Sebe, Nicu
TI A modified vector of locally aggregated descriptors approach for fast
   video classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Capturing content variation in time in video; Modified vector of locally
   aggregated descriptor; Random forests; Video classification
AB In order to reduce the computational complexity, most of the video classification approaches represent video data at frame level. In this paper we investigate a novel perspective that combines frame features to create a global descriptor. The main contributions are: (i) a fast algorithm to densely extract global frame features which are easier and faster to compute than spatio-temporal local features; (ii) replacing the traditional k-means visual vocabulary from Bag-of-Words with a Random Forest approach allowing a significant speedup; (iii) the use of a modified Vector of Locally Aggregated Descriptor(VLAD) combined with a Fisher kernel approach that replace the classic Bag-of-Words approach, allowing us to achieve high accuracy. By doing so, the proposed approach combines the frame-based features effectively capturing video content variation in time. We show that our framework is highly general and is not dependent on a particular type of descriptors. Experiments performed on four different scenarios: movie genre classification, human action recognition, daily activity recognition and violence scene classification, show the superiority of the proposed approach compared to the state of the art.
C1 [Mironica, Ionut; Ionescu, Bogdan] Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
   [Duta, Ionut Cosmin] Univ Trento, MHUG Grp, Comp Sci, Trento, Italy.
   [Sebe, Nicu] Univ Trento, Trento, Italy.
C3 National University of Science & Technology POLITEHNICA Bucharest;
   University of Trento; University of Trento
RP Mironica, I (corresponding author), Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
EM imironica@imag.pub.ro; duta@disi.unitn.it; bionescu@imag.pub.ro;
   sebe@disi.unitn.it
RI Sebe, Niculae/KEC-2000-2024; Ionescu, Bogdan/IWU-7778-2023
OI Sebe, Niculae/0000-0002-6597-7248; 
FU Sectoral Operational Programme Human Resources Development of the
   Ministry of European Funds through the Financial Agreement
   [POS-DRU/159/1.5/S/132395]
FX The work has been funded by the Sectoral Operational Programme Human
   Resources Development 2007-2013 of the Ministry of European Funds
   through the Financial Agreement POS-DRU/159/1.5/S/132395.
CR Almeida J, 2014, LECT NOTES COMPUT SC, V8827, P604, DOI 10.1007/978-3-319-12568-8_74
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2013, ICCV WORKSHOP ACTION
   [Anonymous], P TRECVID 2013
   [Anonymous], 2014, CoRR
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P MEDIAEVAL 2012 WOR
   [Anonymous], INT MULTIMED INF RET
   [Anonymous], CORR
   [Anonymous], 2009, ICCV
   [Anonymous], ARXIV12064620
   Bilinski P, 2013, IEEE INT CONF AUTOMA
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bouckaert R.R., 2013, WEKA Manual for Version 3-6-10
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Ciresan DC, 2011, IJCAI, P1238
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   De Herrera A.G.S., 2013, CLEF Working Notes
   Demarty C-H, 2013, WORKING NOTES P
   Demarty C-H, 2013, MEDIA TOOLS APPL
   Demarty CH, 2014, INT WORK CONTENT MUL
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Gold K., 2010, 2010 IEEE 9th International Conference on Development and Learning (ICDL 2010), P58, DOI 10.1109/DEVLRN.2010.5578864
   Goto S, 2013, WORKING NOTES P
   Ikizler-Cinbis N., 2011, P EUR C COMP VIS ECC, V6311, P494, DOI [http://dx.doi.org/10.1007/978-3-642-15549-9_36, DOI 10.1007/978-3-642-15549-9_36]
   Imre C., 2011, INFORM THEORY CODING, DOI DOI 10.1017/CBO9780511921889
   Ionescu B, 2012, MEDIEVAL WORKSH
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang Y-G, 2013, ICCV WORKSH ACT REC
   Karaman S., 2013, ICCV WORKSH ACT REC
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ludwig O, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P432
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Marín J, 2013, IEEE I CONF COMP VIS, P2592, DOI 10.1109/ICCV.2013.322
   Mathieu B., 2010, P 11 INT C MUS INF R, P441
   Nakayama H., 2012, P NIPS 2012 WORKSH L
   Penet C, 2013, WORKING NOTES P
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Picard D, 2011, IEEE IM PROC ICIP 20
   Quoc V, 2013, IEEE INT C AC SPEECH
   Raptis M, 2011, EUR C COMP VIS ECCV, P577
   Rohrbach M, 2012, INT C COMP VIS PATT
   Rostamzadeh N, 2013, IEEE INT C IM AN PRO
   Schmiedeke S., 2012, MEDIAEVAL WORKSH
   Schmiedeke S, 2013, ACM MULT SYST C OSL, V1
   Semela T., 2012, MEDIAEVAL WORKSH
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Simonyan K., 2014, CORR
   Sjoberg M, 2013, MEDIAEVAL 2014 WORKS
   Solmaz B, 2013, MACH VISION APPL, V24, P1473, DOI 10.1007/s00138-012-0449-x
   Uijlings JRR, 2010, IEEE T MULTIMEDIA, V12, P665, DOI 10.1109/TMM.2010.2052027
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang Jiang., 2011, CVPR
   WorkshopLarson M, 2013, COLOCATED ACM MULTIM, V1043
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
NR 66
TC 19
Z9 21
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9045
EP 9072
DI 10.1007/s11042-015-2819-7
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500013
DA 2024-07-18
ER

PT J
AU Lei, B
   Mak, MW
AF Lei, Baiying
   Mak, Man-Wai
TI Robust scream sound detection via sound event partitioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scream sound detection; Regularized PCA-whitening; Feature
   normalization; Sound event partitioning
ID IMAGE FEATURE; CLASSIFICATION; RECOGNITION; FEATURES; NOISE
AB This paper proposes a robust scream-sound detection scheme for acoustic surveillance applications. To enhance the discriminability between scream and non-scream sounds, a sound-event partitioning (SEP) method that facilitates the extraction of multiple acoustic vectors from a single sound event is developed. Regularized principal component analysis (PCA) and normalization are applied to the acoustic vectors, which are then classified by support vector machines (SVMs). Experimental results based on 1000 sound events show that the proposed scheme is effective even if there are severe mismatches between the training and testing conditions. The experimental results also show that the proposed scheme can reduce the equal error rate (EER) by up to 60 % when compared to a classical approach that uses mel-frequency cepstral coefficients (MFCC) as features. Extensive analyses on different processing stages of the proposed sound detection scheme also suggest that sound partitioning and feature normalization play important roles in boosting the detection performance.
C1 [Lei, Baiying] Shenzhen Univ, Sch Med, Dept Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Shenzhen 518060, Guangdong, Peoples R China.
   [Lei, Baiying] Shenzhen Univ, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen 518060, Guangdong, Peoples R China.
   [Mak, Man-Wai] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Shenzhen University; Shenzhen University; Hong Kong Polytechnic
   University
RP Lei, B (corresponding author), Shenzhen Univ, Sch Med, Dept Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Shenzhen 518060, Guangdong, Peoples R China.; Lei, B (corresponding author), Shenzhen Univ, Guangdong Key Lab Biomed Measurements & Ultrasoun, Shenzhen 518060, Guangdong, Peoples R China.
EM leiby@szu.edu.cn
RI Lei, Baiying/GRE-9741-2022; Lei, Baiying/GQO-8422-2022; Lei,
   Baiying/AAY-5515-2020; Mak, Man-Wai/C-3750-2014
OI Lei, Baiying/0000-0002-3087-2550; Lei, Baiying/0000-0002-3087-2550; Lei,
   Baiying/0000-0002-3087-2550; Mak, Man-Wai/0000-0001-8854-3760
FU National Natural Science Foundation of China [61402296]; Motorola
   Solutions Foundation [7186445]; Hong Kong Polytechnic University
   [G-YL78]
FX The work was supported partly by National Natural Science Foundation of
   China (No. 61402296), Motorola Solutions Foundation (ID: 7186445) and
   the Hong Kong Polytechnic University Grant No. G-YL78. The authors would
   like to thank Wing-Lung Leung for developing the sound recording system
   and part of the Android App.
CR Ali S, 2006, LECT NOTES COMPUT SC, V4304, P362
   [Anonymous], 2006, PROC IEEE INT C ACOU
   [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   [Anonymous], P NIST 2011 WORKSH
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   Clavel C, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1307
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dennis J, 2013, PATTERN RECOGN LETT, V34, P1085, DOI 10.1016/j.patrec.2013.02.015
   Dennis J, 2013, IEEE T AUDIO SPEECH, V21, P367, DOI 10.1109/TASL.2012.2226160
   Dennis J, 2011, IEEE SIGNAL PROC LET, V18, P130, DOI 10.1109/LSP.2010.2100380
   Ghoraani B, 2011, IEEE T AUDIO SPEECH, V19, P2197, DOI 10.1109/TASL.2011.2118753
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Hautamäki V, 2013, IEEE T AUDIO SPEECH, V21, P1622, DOI 10.1109/TASL.2013.2256895
   Herbrich R, 2002, IEEE T INFORM THEORY, V48, P3140, DOI 10.1109/TIT.2002.805090
   Tran HD, 2011, IEEE T AUDIO SPEECH, V19, P1556, DOI 10.1109/TASL.2010.2093519
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Lei BY, 2014, NEUROCOMPUTING, V141, P139, DOI 10.1016/j.neucom.2014.04.002
   Liao WH, 2009, IEEE SYS MAN CYBERN, P2695, DOI 10.1109/ICSMC.2009.5346556
   Mak MW, 2014, COMPUT SPEECH LANG, V28, P295, DOI 10.1016/j.csl.2013.07.003
   Mak MW, 2012, INT CONF ACOUST SPEE, P1985, DOI 10.1109/ICASSP.2012.6288296
   Mak MW, 2011, SPEECH COMMUN, V53, P119, DOI 10.1016/j.specom.2010.06.011
   Martin A., 1997, PROC EURO SPEECH 97, V4, P1895
   Myung Jong Kim, 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P205, DOI 10.1109/CBMI.2011.5972546
   Ntalampiras S, 2009, INT CONF ACOUST SPEE, P165, DOI 10.1109/ICASSP.2009.4959546
   Penet C, 2014, MULTIMED TOOLS APPL, P1
   Rao W, 2013, IEEE T AUDIO SPEECH, V21, P1012, DOI 10.1109/TASL.2013.2243436
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Valenzise G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P21, DOI 10.1109/AVSS.2007.4425280
   VARGA A, 1993, SPEECH COMMUN, V12, P247, DOI 10.1016/0167-6393(93)90095-3
   Wang YX, 2013, IEEE T AUDIO SPEECH, V21, P270, DOI 10.1109/TASL.2012.2221459
   Weimin Huang, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P2115, DOI 10.1109/ICIEA.2010.5515397
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
NR 36
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6071
EP 6089
DI 10.1007/s11042-015-2555-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700002
DA 2024-07-18
ER

PT J
AU He, W
   Chen, JX
   Zhang, WH
AF He, Wu
   Chen, Jim X.
   Zhang, Weihua
TI Crowd simulation using DC model and density information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd simulation; Discrete choice model; Density information;
   Collision-free; Intra-group; Inter-group
ID FLOW
AB Realistic crowd simulation is an important issue for the production of virtual worlds for games, crowd management, public space design, education, entertainment or architectural and urban planning. In this paper, crowd simulation is considered from two aspects: intra-group simulation and inter-group simulation. We propose a unified framework for crowd simulation in real-time virtual environment. Based on this framework, for intra-group simulation, we propose a novel density-based information crowd simulation to collision-free. For inter-group simulation, we propose a novel discrete choice (DC) model to realistic simulation of crowds and path planning. Meanwhile, we also propose a variable bounding box method for intra-group/inter-groups intersection problem. The simulation results show that the developed framework allows different group structures to be easily modeled. And the proposed framework could be used for real-time navigation of many moving crowd in complicated virtual environments.
C1 [He, Wu] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [He, Wu] Sichuan Normal Univ, Digital Media Coll, Chengdu 610068, Sichuan, Peoples R China.
   [Chen, Jim X.] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
   [Zhang, Weihua] Southwest Jiaotong Univ, State Key Lab Tract Power, Chengdu 610031, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Sichuan Normal University; George Mason
   University; Southwest Jiaotong University
RP He, W (corresponding author), Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.; He, W (corresponding author), Sichuan Normal Univ, Digital Media Coll, Chengdu 610068, Sichuan, Peoples R China.
EM wuhe83@163.com; jchen@gmu.edu; tpl@home.swjtu.edu.cn
RI zheng, wei/IQT-9639-2023; zhang, weihua/GXV-1334-2022; WU,
   ZHEN/GRN-7688-2022
OI WU, ZHEN/0000-0001-8719-057X
FU Sichuan provincial education department [13ZB0154]
FX We would like to thank the anonymous reviewers for helpful comments.
   This work was supported by scientific research fund of Sichuan
   provincial education department (Grant No: 13ZB0154)
CR [Anonymous], 2009, P 4 INT C FDN DIGITA, DOI DOI 10.1145/1536513.1536540
   [Anonymous], 1999, P GAM DEV C
   [Anonymous], TRANSPORTATION RES C
   Charalambous P, 2014, COMPUTER GRAPHICS FO
   Chen D, 2012, FUTURE GENER COMP SY, P132
   Chraibi M., 2012, MODELING DESIRED DIR
   Daamen W., 2004, MODELLING PASSENGER
   DAAMEN W., 2002, C P EUROSIW, P24
   Funge J, 1999, COMP GRAPH, P29, DOI 10.1145/311535.311538
   Hart P, 2008, IEEE T SYST SCI CYB, V4, P100
   Heliövaara S, 2012, BUILD ENVIRON, V48, P89, DOI 10.1016/j.buildenv.2011.08.020
   Hocker M., 2010, EWORK EBUSINESS ARCH, P389, DOI DOI 10.1201/B10527-65
   Hoogendoorn SP, 2004, TRANSPORT RES B-METH, V38, P169, DOI 10.1016/S0191-2615(03)00007-9
   Huang L, 2009, TRANSPORT RES B-METH, V43, P127, DOI 10.1016/j.trb.2008.06.003
   Hughes RL, 2003, ANNU REV FLUID MECH, V35, P169, DOI 10.1146/annurev.fluid.35.101101.161136
   Jund T, 2012, COMPUT ANIMAT VIRT W, V23, P311, DOI 10.1002/cav.1449
   Lemercier S, 2012, EUROGRAPHICS P CIGNO, V31
   Liu WX, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P3, DOI 10.1109/VR.2012.6180866
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Rao YB, 2011, MULTIMED TOOLS APPL, V54, P397, DOI 10.1007/s11042-010-0542-y
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   Robin T, 2010, T RES B, V43, P36
   Roland G., 2008, Comput. Animation Social Agents, P64
   Stephen Guy J, 2010, EUR ACM SIGGRAPH S C, P13
   Thalmann D., 2007, Wiley Encyclopedia of Computer Science and Engineering
   Train K., 2003, DISCRETE CHOICE METH
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   van Toll W, 2011, IEEE INT C INT ROBOT, P3526, DOI 10.1109/IROS.2011.6048397
   van Toll WG, 2012, COMPUT ANIMAT VIRT W, V23, P59, DOI 10.1002/cav.1424
   Wein R, 2007, COMP GEOM-THEOR APPL, V36, P66, DOI 10.1016/j.comgeo.2005.11.007
   Wijermans N., 2011, THESIS U GRONINGEN
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
NR 32
TC 3
Z9 3
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5981
EP 5998
DI 10.1007/s11042-015-2561-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600029
DA 2024-07-18
ER

PT J
AU Li, F
   Li, N
AF Li, Fan
   Li, Na
TI Region-of-interest based rate control algorithm for H.264/AVC video
   coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; Rate-distortion optimization; HVS; H.264/AVC; ROI
ID RATE-CONTROL SCHEME; COMMUNICATION; MODE
AB Conventional rate control algorithms allocate bits for every macroblock (MB) without consider whether it needs encoding, and they choose encoding mode only from the set provided by H.264/AVC standard. While, according to the human visual system (HVS) research, human eyes can only focus on one area in a frame, which is called region-of-interest (ROI). This phenomenon gives a chance to code all MBs unequally, especially for NROI MB, we may do not need encoded. In this paper, a ROI-based rate control algorithm for H.264/AVC video coding is proposed to improve the coding efficiency. After the ROI segmentation, the target bits are unequally allocated for each MB. For non-region-of-interest (NROI) MB coding, we proposed the Active MB Concealment (AMC) Mode in rate-distortion optimization (RDO). The AMC gives a tradeoff between the rate and distortion and improve the quality of the ROI MBs at the cost of the quality decreasing of the NROI MBs. Compared with the conventional rate control algorithms, the experimental results demonstrate that the proposed algorithm gives the better performance in terms of the average peak signal-to-noise ratio (PSNR) and the subjective evaluations, and maintains the smoothness of video quality.
C1 [Li, Fan; Li, Na] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, F (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM lifan@mail.xjtu.edu.cn
FU National Science Foundation of China [61372091]; Natural Science Basic
   Research Plan in Shaanxi Province of China [2014JM8318]; Fundamental
   Research Funds for the Central Universities
FX This study was supported in part by National Science Foundation of China
   61372091, Natural Science Basic Research Plan in Shaanxi Province of
   China 2014JM8318, and the Fundamental Research Funds for the Central
   Universities.
CR Bahri N, 2012, IEEE MEDITERR ELECT, P848, DOI 10.1109/MELCON.2012.6196562
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chen-Hsien Miao, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P623, DOI 10.1109/ICSPCC.2012.6335597
   Chiang JC, 2010, IEEE INT CON MULTI, P238, DOI 10.1109/ICME.2010.5583354
   Guan-Lin Wu, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P509, DOI 10.1109/ICME.2012.180
   Hrarti M., 2010, 5th International Symposium on I/V Communications and Mobile Network (ISVC), P1
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Hu HM, 2011, J VIS COMMUN IMAGE R, V22, P615, DOI 10.1016/j.jvcir.2011.07.002
   Jin R, 2009, P INT S COMP NETW MU, P1
   Kamaci N, 2011, IEEE IMAGE PROC, P1409, DOI 10.1109/ICIP.2011.6115704
   Lee JY, 2012, IEEE T CIRC SYST VID, V22, P393, DOI 10.1109/TCSVT.2011.2163460
   Li H, 2006, 8 INT C SIGN PROC 2, V2
   Li ZG, 2002, INT CONF ACOUST SPEE, P2065
   Li ZG, 2003, 7 JVT M PATT 2 JVT G
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Ma S, 2003, 8 JVT M, P20
   Meng Q, 2010, P INT WORKSH INT SYS, P1
   Ou TS, 2011, IEEE T CIRC SYST VID, V21, P682, DOI 10.1109/TCSVT.2011.2129890
   Shi YH, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P77, DOI 10.1109/ICYCS.2008.174
   Sun Y, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P109
   Wang DY, 2008, 2008 INTERNATIONAL CONFERENCE ON APPERCEIVING COMPUTING AND INTELLIGENCE ANALYSIS (ICACIA 2008), P147, DOI 10.1109/ICACIA.2008.4769992
   Wu G. L., 2012, IEEE VIS COMMUN IMAG, P1
   Wu GL, 2013, IEEE T IMAGE PROCESS, V22, P2247, DOI 10.1109/TIP.2013.2247409
   Yunhui Shi, 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P634, DOI 10.1049/cp:20080390
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 27
TC 3
Z9 5
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4163
EP 4186
DI 10.1007/s11042-015-2465-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700001
DA 2024-07-18
ER

PT J
AU Liu, SG
   Chen, D
AF Liu, Shiguang
   Chen, Di
TI A computational approach to digital hand-painted printing patterns on
   cloth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand-painted printing patterns; Cloth; Dye diffusion; Physically based
   simulation
AB This paper presented a novel computational approach to simulating hand-painted printing patterns on cloth, according to the real process of this ancient folk handicraft. A contour grid based method was specially designed so as to generate the contours of the printing patterns by inputting a contour image or a color image. Considering both the anisotropic structure of cloth and the influence from user's strokes, we proposed the main direction guided anisotropic diffusion model (MDGADM) to compute the diffusion of dyes on cloth. Other interactions between dyes and cloth including the adsorption and evaporation were also incorporated to improve the accuracy and the realism. The algorithms of the boundary restriction and the contour enhancement were further developed to optimize the method. Various experiment results showed that our method can produce vivid hand-painted printing patterns on cloth of different woven structures. Our method provides users with a flexible artistic designing tool, and has great potential to protect and inherit this traditional handicraft.
C1 [Liu, Shiguang; Chen, Di] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Liu, Shiguang] Tianjin Key Lab Cognit Comp & Applicat, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM lsg@tju.edu.cn
CR Auer S, 2012, COMPUT GRAPH FORUM, V31, P1909, DOI 10.1111/j.1467-8659.2012.03071.x
   Burgess J, 2005, COMPUTER GRAPHICS INTERNATIONAL 2005, PROCEEDINGS, P234
   Curtis C. J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P421, DOI 10.1145/258734.258896
   Djado K, 2012, COMPUT ANIMAT VIRT W, V23, P301, DOI 10.1002/cav.1446
   Jeong S, 2013, COMPUT GRAPH FORUM, V32, P225, DOI 10.1111/cgf.12230
   Kunii T. L., 2001, International Journal of Shape Modeling, V7, P45, DOI 10.1142/S0218654301000047
   Liu SG, 2011, VISUAL COMPUT, V27, P241, DOI 10.1007/s00371-010-0531-1
   Liu Shiguang, 2008, Journal of Computer Aided Design & Computer Graphics, V20, P1110
   Luft T, 2006, J COMPUT SCI TECH-CH, V21, P159, DOI 10.1007/s11390-006-0159-9
   Lum EB, 2001, NINTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P322, DOI 10.1109/PCCGA.2001.962888
   Morimoto Y, 2011, NATURAL DYES
   Stam J., 2003, P GAM DEV C
   Van Laerhoven T, 2005, COMPUT ANIMAT VIRT W, V16, P429, DOI 10.1002/cav.95
   Van Laerhoven T, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P640, DOI 10.1109/CGI.2004.1309281
   Wang CM, 2007, IEEE T VIS COMPUT GR, V13, P235, DOI 10.1109/TVCG.2007.41
   Wilson Brett., 2004, NPAR 04, P129
   Zong M, 2007, SHAPE APPEARANCE FIB
NR 17
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4577
EP 4591
DI 10.1007/s11042-015-2492-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700020
DA 2024-07-18
ER

PT J
AU Lombardo, V
   Pizzo, A
AF Lombardo, Vincenzo
   Pizzo, Antonio
TI Multimedia tool suite for the visualization of drama heritage metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drama ontology; Interactive visualization; Metadata annotation
AB This paper presents a multimedia tool suite for, on the one hand, the annotation of metadata that encode the dramatic qualities of cultural heritage items, and, on the other, the visualization of such metadata for drama analysis and didactics. The tool suite relies upon an ontology of drama to devise an annotation schema for the metadata concerning the dramatic qualities. The two major modules of the tool suite are a web-based platform, that allows for the insertion of the annotation metadata, and a visualization program for the interactive exploration of such metadata, respectively. The tool suite was tested on the cross-media studies of drama analysis and teaching of drama structure through the application to classical examples.
C1 [Lombardo, Vincenzo; Pizzo, Antonio] Univ Turin, CIRMA, Corso Svizzera 185, Turin, Italy.
   [Lombardo, Vincenzo; Pizzo, Antonio] Univ Turin, Dipartimento Informat, Corso Svizzera 185, Turin, Italy.
C3 University of Turin; University of Turin
RP Lombardo, V (corresponding author), Univ Turin, CIRMA, Corso Svizzera 185, Turin, Italy.; Lombardo, V (corresponding author), Univ Turin, Dipartimento Informat, Corso Svizzera 185, Turin, Italy.
EM vincenzo@di.unito.it; antonio.pizzo@unito.it
RI Lombardo, Vincenzo/ABE-2078-2021; Pizzo, Antonio/HHN-6598-2022
OI Pizzo, Antonio/0000-0002-2096-5649; Lombardo,
   Vincenzo/0000-0002-8166-9827
CR Addison AC, 2013, 2013 DIG HER INT C, V2
   Agirre E, 2012, P 8 INT C LANG RES E
   [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], 2004, P AUSTR WORKSH INT E
   [Anonymous], NEW TRENDS RES ONTOL
   [Anonymous], LA DRAMATURGIE
   [Anonymous], ESTHETICS PHILOS ESS
   [Anonymous], 2002, AAAI 2002 WORKSH ONT
   [Anonymous], 17 INT C DISTR MULT
   Aristotele, 2008, Poetica
   Aristotle, 2013, POETICS
   Baikadi A, 2011, AIIDE 2011 AAAI WORK, P2
   Baker C.F., 1998, P 36 ANN M ASS COMP, P86, DOI [DOI 10.3115/980845.980860, DOI 10.3115/980451.980860]
   Bordwell D., 2006, Film art: An introduction, V8th
   Bratman M.E., 1987, Intention, Plans, and Practical Reason
   Brooks Cleanth., 1946, Understanding Drama
   BRUNER J, 1991, CRIT INQUIRY, V18, P1, DOI 10.1086/448619
   Card SK, 2006, IEEE S VIS AN SCI TE
   Carlson Marvin., 1984, Theories of the Theatre: A Historical and Critical Survey from the Greeks to the Present
   Carson C., 1997, Literary & Linguistic Computing, V12, P269, DOI 10.1093/llc/12.4.269
   de Melo G, 2008, PROC INT C TOOLS ART, P190, DOI 10.1109/ICTAI.2008.34
   Diderot D., 1966, Classics in the history of thought: Diderot's selected writings
   Egri L., 1946, ART DRAMATIC WRITING
   Elam Keir., 1980, SEMIOTICS THEATRE DR
   Elson DK, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2813
   Esslin M., 1988, The Field of Drama
   Field S, 2003, DEFINITE GUIDE SCREE
   Fisher D, 2008, P IEEE S VIS AN SCI, V01
   Freytag G., 2004, TECHNIQUE DRAMA EXPO
   Gangemi A., 2009, Handbook on ontologies, P221, DOI DOI 10.1007/978-3-540-92673-3
   Genette Gerard, 1980, Narrative discourse: An essay in method
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Guarino N., 2009, HDB ONTOLOGIES, P1, DOI [DOI 10.1007/978-3-540-92673-30, 10.1007/978-3-540-92673-3_0, DOI 10.1007/978-3-540-92673-3_0]
   Hatcher Jeffrey., 1996, The Art Craft of Playwriting
   Heath  T., 2011, SYNTHESIS LECT SEMAN, DOI [10.2200/S00334ED1V01Y201102WBE001, DOI 10.2200/S00334ED1V01Y201102WBE001, 10.2200/s00334ed1v01y201102wbe001]
   Hegel G, 1885, HEGELS AESTHETICS
   KIPPER K, 2005, THESIS U PENNSYLVANI
   Kurin R, 2004, MUSEUM INT, V56, P66, DOI 10.1111/j.1350-0775.2004.00459.x
   Lessing G.E., 1962, Hamburg Dramaturgy
   Lombardo V., 2013, DIGITAL HERITAGE
   Lombardo V, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P78, DOI 10.1109/ISM.2012.23
   Mamber Stephen., 2003, NEW MEDIA, P145
   Mamet D, 1998, COLUMBIA LECT AM CUL
   McKee R., 1997, Story
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Ortony A., 1988, COGNITIVE STRUCTURE
   Peinado F, 2008, P ICIDIS08 ERF GERM
   Pfister M, 1991, EUROPEAN STUDIES ENG
   Pianta E, 2002, 1 INT C GLOB WORDNET, P293
   Polti Georges., 1895, Les trente-six situations dramatiques
   Propp V., 1968, Morphology of the Folktale, V2nd ed.
   Rimmon-Kenan Shlomith, 1983, NARRATIVE FICTION CO
   Ryan Marie-Laure., 2006, Avatars of Story
   Ryngaert J, 2008, COLLECTION CURSUS L
   Smith GregM., 2003, FILM STRUCTURE EMOTI
   Smith Laurajane., 2009, INTANGIBLE HERITAGE
   Spencer S., 2002, The playwright's guidebook: An insightful primer on the art of dramatic writing
   Strauss A.L., 1990, BASICS QUALITATIVE R
   SUCHANEK Fabian M., 2007, 16 INT WORLD WID WEB, V16, P697, DOI DOI 10.1145/1242572.1242667
   SZONDI P, 1983, BOUNDARY TWO, V11, P191, DOI 10.2307/303010
   van Riemsdijk M, 2008, P AAMAS 08
   Vecco M, 2010, J CULT HERIT, V11, P321, DOI 10.1016/j.culher.2010.01.006
NR 63
TC 3
Z9 4
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 7
BP 3901
EP 3932
DI 10.1007/s11042-014-2066-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering
GA DI0GB
UT WOS:000373172200016
DA 2024-07-18
ER

PT J
AU Gaj, S
   Patel, AS
   Sur, A
AF Gaj, Sibaji
   Patel, Ashish Singh
   Sur, Arijit
TI Object based watermarking for H.264/AVC video resistant to rst attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object segmentation; Compressed domain; Watermarking
ID SEGMENTATION
AB In this paper, a compressed domain video watermarking scheme is proposed which embeds the watermark in the homogeneous moving object within a shot of video sequence to resist geometric attacks such as rotation, scaling etc. Intuitively, object based watermarking results low payload and has the least impact on visual quality since the object area is generally small and highly textured. The proposed work has two main contributions, firstly, an existing compressed domain motion coherent block detection algorithm [7] is extended to detect the moving objects within a video shot and secondly, a watermarking scheme has been proposed by embedding within the moving objects to resist RST attacks. A comprehensive set of experiments has been carried out to justify the applicability of the proposed scheme over the existing literature.
C1 [Gaj, Sibaji; Patel, Ashish Singh; Sur, Arijit] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Gaj, S (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM sibaji@iitg.ernet.in; ashish.nitit@gmail.com; arijit@iitg.ac.in
RI Sur, Arijit/AAB-4216-2020; Patel, Ashish Singh/HIU-0959-2022; Gaj,
   Sibaji/AAE-8920-2022
OI Patel, Ashish Singh/0000-0002-2963-1039; Gaj,
   Sibaji/0000-0002-6997-5717; Sur, Arijit/0000-0002-9038-8138
FU DST (SERC) project "Shot Based Video Watermarking For Very Low Bit Rate
   Video"
FX This work is under grant for DST (SERC) project "Shot Based Video
   Watermarking For Very Low Bit Rate Video"
CR [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], P 2009 2 INT C IM SI
   [Anonymous], JIH MSP
   Babu RV, 2004, IEEE T CIRC SYST VID, V14, P462, DOI 10.1109/TCSVT.2004.825536
   Barni M, 2005, IEEE T MULTIMEDIA, V7, P23, DOI 10.1109/TMM.2004.840594
   Bas P, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P526, DOI 10.1109/ICIP.2001.958167
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   De Bruyne S, 2009, IEEE INT CON MULTI, P330, DOI 10.1109/ICME.2009.5202501
   Dhavale SV, 2014, J INF HIDING MULTIME, V5
   Dutta T, 2013, MULT EXP ICME 2013 I, P1, DOI DOI 10.1109/ICME.2013.6607430
   El Allali A, 2011, MULT COMP SYST ICMCS, P1, DOI [10.1109/ICMCS.2011.5945567, DOI 10.1109/ICMCS.2011.5945567]
   Essaouabi A., 2010, INT J ELECT COMPUTER, V5, P1
   Fu YG, 2007, 2007 INTERNATIONAL WORKSHOP ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION, P188, DOI 10.1109/IWASID.2007.373724
   Guo H, 2003, PATTERN RECOGN, V36, P2737, DOI 10.1016/S0031-3203(03)00048-7
   He DJ, 2004, IEEE IMAGE PROC, P737
   Huang HC, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P62
   Le Sun, 2012, 2012 Fourth International Conference on Computational and Information Sciences (ICCIS), P481, DOI 10.1109/ICCIS.2012.45
   Liu L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P605, DOI 10.1109/CISP.2008.7
   Lu CS, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P483, DOI 10.1109/ICIP.2001.958533
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Pei Dong, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2309, DOI 10.1109/ICIP.2011.6116063
   Swanson MD, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P369, DOI 10.1109/MMSP.1997.602663
   Szczerba K, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P478, DOI 10.1109/AVSS.2009.78
   Szolgay D, 2011, PATTERN ANAL APPL, V14, P311, DOI 10.1007/s10044-011-0221-2
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang JW, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P252, DOI 10.1109/AVSS.2012.68
   Zeng W, 2005, REAL-TIME IMAGING, V11, P290, DOI 10.1016/j.rti.2005.04.008
NR 30
TC 16
Z9 18
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3053
EP 3080
DI 10.1007/s11042-014-2422-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600007
DA 2024-07-18
ER

PT J
AU Huang, XT
   Chen, L
   Tian, J
   Zhang, XL
AF Huang, Xiaotong
   Chen, Li
   Tian, Jing
   Zhang, Xiaolong
TI Blind image noise level estimation using texture-based eigenvalue
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noise level estimation; Eigenvalue analysis; Image denoising
AB Blind noisy image estimation is useful in many visual processing systems. The challenge lies in accurately estimating the image noise level without any priori information of the image. To tackle this challenge, an iterative texture-based eigenvalue analysis approach is proposed in this paper. The proposed approach utilizes the eigenvalue analysis to mathematically derive a new noise level estimator based on weak-textured image patches. Furthermore, a new texture strength measure is proposed to adaptively select weak-textured patches from the noisy image. Experimental results are provided to demonstrate that the proposed image noise level estimation approach yields superior accuracy and stability performance to that of conventional noise level estimation approaches, so that to improve the performance of image denoising algorithm.
C1 [Huang, Xiaotong; Chen, Li; Tian, Jing; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Huang, Xiaotong; Chen, Li; Tian, Jing; Zhang, Xiaolong] Wuhan Univ Sci & Technol, Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430081, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University of Science &
   Technology
RP Tian, J (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430081, Peoples R China.
EM xiaotonghuang@foxmail.com; chenli@ieee.org; jingtian@ieee.org;
   xiaolong.zhang@wust.edu.cn
RI Tian, Jing/ABI-2886-2020; ZHANG, XIAOLONG/IZQ-4553-2023
OI Tian, Jing/0000-0002-4084-6911; 
FU National Natural Science Foundation of China [61105010, 61375017];
   Program for Outstanding Young Science and Technology Innovation Teams in
   Higher Education Institutions of Hubei Province, China [T201202]
FX This work was supported by National Natural Science Foundation of China
   (No. 61105010, 61375017), Program for Outstanding Young Science and
   Technology Innovation Teams in Higher Education Institutions of Hubei
   Province, China (No. T201202).
CR Aja-Fernández S, 2009, IMAGE VISION COMPUT, V27, P756, DOI 10.1016/j.imavis.2008.08.002
   Amer A, 2005, IEEE T CIRC SYST VID, V15, P113, DOI 10.1109/TCSVT.2004.837017
   Chen L, 2014, OPT LASER TECHNOL, V57, P265, DOI 10.1016/j.optlastec.2013.10.005
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   GAI S, 2013, MULTIMEDIA IN PRESS, P1
   Huang XT, 2014, COMPUT ELECTR ENG, V40, P796, DOI 10.1016/j.compeleceng.2013.08.002
   Li B, 2013, MULTIMEDIA IN PRESS
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Muresan DD, 2003, IEEE IMAGE PROC, P101
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Rank K, 1999, IEE P-VIS IMAGE SIGN, V146, P80, DOI 10.1049/ip-vis:19990238
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Tai SC, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1077, DOI 10.1109/ISCCSP.2008.4537384
   Tian J, 2012, IEEE SIGNAL PROC LET, V19, P395, DOI 10.1109/LSP.2012.2197200
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Tian J, 2010, J VIS COMMUN IMAGE R, V21, P232, DOI 10.1016/j.jvcir.2010.01.001
   Tsai DM, 2012, MACH VISION APPL, V23, P869, DOI 10.1007/s00138-011-0403-3
   Zeng W, 2013, MULTIMEDIA IN PRESS
NR 19
TC 9
Z9 11
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2713
EP 2724
DI 10.1007/s11042-015-2452-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000020
DA 2024-07-18
ER

PT J
AU Bouchrika, I
   Carter, JN
   Nixon, MS
AF Bouchrika, Imed
   Carter, John N.
   Nixon, Mark S.
TI Towards automated visual surveillance using gait for identity
   recognition and tracking across multiple non-intersecting cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait analysis; Gait biometrics; Markerless extraction
ID HUMAN MOTION; EXTRACTION; MODEL
AB Despite the fact that personal privacy has become a major concern, surveillance technology is now becoming ubiquitous in modern society. This is mainly due to the increasing number of crimes as well as the essential necessity to provide secure and safer environment. Recent research studies have confirmed now the possibility of recognizing people by the way they walk i.e. gait. The aim of this research study is to investigate the use of gait for people detection as well as identification across different cameras. We present a new approach for people tracking and identification between different non-intersecting un-calibrated stationary cameras based on gait analysis. A vision-based markerless extraction method is being deployed for the derivation of gait kinematics as well as anthropometric measurements in order to produce a gait signature. The novelty of our approach is motivated by the recent research in biometrics and forensic analysis using gait. The experimental results affirmed the robustness of our approach to successfully detect walking people as well as its potency to extract gait features for different camera viewpoints achieving an identity recognition rate of 73.6 % processed for 2270 video sequences. Furthermore, experimental results confirmed the potential of the proposed method for identity tracking in real surveillance systems to recognize walking individuals across different views with an average recognition rate of 92.5 % for cross-camera matching for two different non-overlapping views.
C1 [Bouchrika, Imed] Univ Souk Ahras, Dept Elect Engn, Souk Ahras, Algeria.
   [Carter, John N.; Nixon, Mark S.] Univ Southampton, Dept Elect & Comp Sci, Southampton SO17 2BJ, Hants, England.
C3 Universite de Souk Ahras Mohammed Cherif Messaadia; University of
   Southampton
RP Bouchrika, I (corresponding author), Univ Souk Ahras, Dept Elect Engn, Souk Ahras, Algeria.
EM imed@imed.ws
RI Bouchrika, Imed/F-1105-2015; Nixon, Mark S/F-7406-2014
OI Nixon, Mark/0000-0002-9174-5934
CR [Anonymous], 2005, The Kluwer International Series on Biometrics
   Bashir K., 2010, BRIT MACH VIS C
   BENABDELKADER C, 2002, 5 IEEE INT C AUT FAC, P357
   BenAbdelkader C, 2002, P WORKSH BIOM AUTH
   Bouchrika I, 2008, THESIS U SOUTHAMPTON
   Bouchrika I, 2009, P S IM CRIM DET PREV
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   Carter JN, 1999, MEAS CONTROL-UK, V32, P265, DOI 10.1177/002029409903200903
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   CVG, 2001, PETS PERF EV TRACK S
   DEMPSTER WT, 1967, AM J ANAT, V120, P33, DOI 10.1002/aja.1001200104
   Fujiyoshi H, 2004, IEICE T INF SYST, VE87D, P113
   Goffredo M., 2009, J IEEE T SYSTEMS M B
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Hadid A, 2013, LECT NOTES COMPUT SC, V8157, P1, DOI 10.1007/978-3-642-41184-7_1
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Havasi L, 2007, IEEE T IMAGE PROCESS, V16, P503, DOI 10.1109/TIP.2006.888339
   HOSD, 2009, I LIDS IM LIB INT DE
   Huang PS, 1999, IEE P-VIS IMAGE SIGN, V146, P93, DOI 10.1049/ip-vis:19990187
   Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Katiyar R., 2013, Int. J. Comput. Sci. Issues IJCSI, V10
   Khan S, 2001, 8 IEEE INT C COMP VI, V1
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Lipton A. J., 1998, 4 IEEE WORKSH APPL C
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Morzinger R., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P486, DOI 10.1109/AVSS.2011.6027381
   Murray M P, 1967, Am J Phys Med, V46, P290
   Nixon MS, 2010, EUR SIGNAL PR CONF, P1655
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   Orwell J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P14, DOI 10.1109/VS.1999.780264
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Shutler J.D., 2002, 4th International Conference on Recent Advances in Soft Computing, P66
   Somol P, 1999, PATTERN RECOGN LETT, V20, P1157, DOI 10.1016/S0167-8655(99)00083-5
   Spencer N., 2005, P IEEE INT C IM PROC, V3
   Stein G. P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P521, DOI 10.1109/CVPR.1999.786987
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yu Guan, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P321, DOI 10.1109/IIH-MSP.2012.84
   Yu SQ, 2006, INT C PATT RECOG, P441
NR 46
TC 44
Z9 49
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1201
EP 1221
DI 10.1007/s11042-014-2364-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700023
DA 2024-07-18
ER

PT J
AU Wu, HY
   Wang, JM
   Zhang, XL
AF Wu, Huiyue
   Wang, Jianmin
   Zhang, Xiaolong (Luke)
TI User-centered gesture development in TV viewing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision-based interfaces; Interactive digital television; Gesture
   interaction; User-centered design
AB Recent advances in interaction technologies make it possible for people to use freehand gestures in such application domains as virtual reality, augmented reality, ubiquitous computing, and smart rooms. While some applications and systems have been developed to support gesture-based interaction, it is unclear what design processes these systems have adopted. Considering the diversity of freehand gestures and the lack of design guidance on gesture-based interaction, we believe that a clear and systematic design process can help to improve the quality of gesture-based interaction. In this paper, we report a study that applies a user-centered approach in the process of gesture development, including the requirement gathering and functionality definition, gesture elicitation, gesture design and usability evaluation. Our results show that these issues must be taken into consideration when designing freehand gesture interfaces. The involvement of actual users, especially in the environment in which they would use the final systems, often leads to improved user experience and user satisfaction. Finally, we highlight the implications of this work for the development of all gesture-based applications.
C1 [Wu, Huiyue] Sun Yat Sen Univ, Sch Commun & Design, Guangzhou 510275, Guangdong, Peoples R China.
   [Wang, Jianmin] Tongji Univ, Coll Arts & Media, User Experience Lab, Shanghai 200092, Peoples R China.
   [Zhang, Xiaolong (Luke)] Penn State Univ, University Pk, PA 16802 USA.
   [Zhang, Xiaolong (Luke)] Taiyuan Univ Technol, Taiyuan, Shanxi, Peoples R China.
C3 Sun Yat Sen University; Tongji University; Pennsylvania Commonwealth
   System of Higher Education (PCSHE); Pennsylvania State University;
   Pennsylvania State University - University Park; Taiyuan University of
   Technology
RP Wu, HY (corresponding author), Sun Yat Sen Univ, Sch Commun & Design, Guangzhou 510275, Guangdong, Peoples R China.; Zhang, XL (corresponding author), Taiyuan Univ Technol, Taiyuan, Shanxi, Peoples R China.
EM wuhuiyue@gmail.com; wangjianmin@tongji.edu.cn; xiaolong.zhang@gmail.com
RI Jiang, Yalin/ITV-2565-2023; wang, jian/GVS-0711-2022; ZHANG,
   XIAOLONG/IZQ-4553-2023
OI Jiang, Yalin/0009-0003-3726-8828; Zhang, Xiaolong/0000-0002-6828-4930;
   wang, jianmin/0000-0001-8703-8973
FU National Natural Science Foundation of China [61202344]; Fundamental
   Research Funds for Central Universities, Sun Yat-Sen University
   [1209119]; Special Project on Integration of Industry, Education and
   Research of Guangdong Province [2012B091000062]; Fundamental Research
   Funds for Central Universities, Tongji University [0600219052,
   0600219053]
FX We thank the financial support from the National Natural Science
   Foundation of China, No. 61202344; the Fundamental Research Funds for
   the Central Universities, Sun Yat-Sen University, No. 1209119; Special
   Project on the Integration of Industry, Education and Research of
   Guangdong Province, No.2012B091000062; the Fundamental Research Funds
   for the Central Universities, Tongji University, No.0600219052,
   0600219053. We would like to express our great appreciation to editor
   and reviewers.
CR Alpern M., 2003, CHI 03 EXTENDED ABST, P932, DOI [10.1145/765891.766078, DOI 10.1145/765891.766078]
   [Anonymous], P 13 INT C MULT INT
   [Anonymous], NORDICHI 04
   [Anonymous], 2006, P 19 ANN ACM AYMPOSI
   [Anonymous], 2013, PROC CHI 2013
   [Anonymous], 2003, P SIGCHI C HUM FACT, DOI DOI 10.1145/642611.642690
   Ashbrook D, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2159
   Colaco Andrea., 2013, P 26 ANN ACM S USER, P227
   Epps J., 2006, CHI 06 EXTENDED ABST, P748, DOI DOI 10.1145/1125451.1125601
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Feng ZQ, 2013, PATTERN RECOGN, V46, P590, DOI 10.1016/j.patcog.2012.07.019
   Feng ZQ, 2011, PATTERN RECOGN, V44, P1089, DOI 10.1016/j.patcog.2010.08.007
   Hayashi E, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3453, DOI 10.1145/2556288.2557043
   Hilliges O, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P139
   Hoste L, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P156, DOI 10.1145/2254556.2254585
   Höysniemi J, 2005, COMMUN ACM, V48, P44, DOI 10.1145/1039539.1039568
   JACOB RJK, 1993, COMPUTER, V26, P65, DOI 10.1109/MC.1993.274943
   Karam M., 2005, CHI Extended Abstracts, P1961
   Kato J, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P189
   KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420
   Klemmer SR, 2009, HUM-COMPUT INTERACT, V24, P315, DOI 10.1080/07370020902990428
   Klemmer Scott R., 2000, P UIST C 2000, P1, DOI DOI 10.1145/354401
   Kölsch M, 2004, PROCEEDINGS OF MOBIQUITOUS 2004, P86
   Kulshreshth A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1093, DOI 10.1145/2556288.2557122
   Lampe T., 2014, P 19 INT C INT US IN, P83, DOI [10.1145/2557500.2557533, DOI 10.1145/2557500.2557533]
   Löcken A, 2012, MULTIMEDIA SYST, V18, P15, DOI 10.1007/s00530-011-0240-2
   Lu H., 2013, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 2013), P257
   Maynes-Aminzade D, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P33
   MILLER GA, 1994, PSYCHOL REV, V101, P343
   Mo Z.Y., 2005, P 10 INT C INT US IN, P239
   Morreau M, 2010, CURR RES SEMANT PRAG, V21, P261
   Mujibiya A., 2010, P ACM S US INT SOFTW, P443
   Nacenta MA, 2013, P ACM CHI C HUM FACT, P1099, DOI DOI 10.1145/2470654.2466142
   Nielsen J, 2003, 5 INT WORKSH GEST SI, P409
   Norman D.A., 1986, USER CTR SYSTEM DESI, DOI 10.1201/b15703
   Pan ZG, 2010, P IEEE VIRT REAL ANN, P219, DOI 10.1109/VR.2010.5444787
   Park J, 2010, IUI 2010, P1
   Pfeil K., 2013, P 2013 INT C INTELLI, P257, DOI [10.1145/2449396.2449429, DOI 10.1145/2449396.2449429]
   Poli R., 2013, P 2013 INT C INTELLI, P149
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rogers Yvonne, 2011, Interaction design: beyond humancomputer interaction
   Rovelo G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4077, DOI 10.1145/2556288.2557113
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Vatavu Radu-Daniel, 2012, P 10 EUR C INT TV VI, P45, DOI [10.1145/2325616.2325626, DOI 10.1145/2325616.2325626]
   Voida Stephen, 2005, P SIGCHI C HUM FACT, P611, DOI [10.1145/1054972.1055056, DOI 10.1145/1054972.1055056]
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Walter R., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P841, DOI [DOI 10.1145/2470654.2470774, 10.1145/2470654.2470774]
   Westeyn T., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P85
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wu Hui-Yue, 2011, Journal of Software, V22, P1067, DOI 10.3724/SP.J.1001.2011.03733
   Wu Hui-Yue, 2009, Chinese Journal of Computers, V32, P2030, DOI 10.3724/SP.J.1016.2009.02030
NR 52
TC 34
Z9 36
U1 0
U2 51
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 733
EP 760
DI 10.1007/s11042-014-2323-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700003
DA 2024-07-18
ER

PT J
AU Dooms, S
   De Pessemier, T
   Martens, L
AF Dooms, Simon
   De Pessemier, Toon
   Martens, Luc
TI Online optimization for user-specific hybrid recommender systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Hybrid; Optimization; Online; MovieTweetings;
   User-interface; HPC
AB User-specific hybrid recommender systems aim at harnessing the power of multiple recommendation algorithms in a user-specific hybrid scenario. While research has previously focused on self-learning hybrid configurations, such systems are often too complex to take out of the lab and are seldom tested against real-world requirements. In this work, we describe a self-learning user-specific hybrid recommender system and assess its ability towards meeting a set of pre-defined requirements relevant to online recommendation scenarios: responsiveness, scalability, system transparency and user control. By integrating a client-server architectural design, the system was able to scale across multiple computing nodes in a very flexible way. A specific user-interface for a movie recommendation scenario is proposed to illustrate system transparency and user control possibilities, which integrate directly in the hybrid recommendation process. Finally, experiments were performed focusing both on weak and strong scaling scenarios on a high performance computing environment. Results showed performance to be limited only by the slowest integrated recommendation algorithm with very limited hybrid optimization overhead.
C1 [Dooms, Simon; De Pessemier, Toon; Martens, Luc] iMinds Ghent Univ, Wica, B-9050 Ghent, Belgium.
C3 Ghent University; IMEC
RP Dooms, S (corresponding author), iMinds Ghent Univ, Wica, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM simon.dooms@intec.ugent.be; toon.depessemier@intec.ugent.be;
   luc.martens@intec.ugent.be
FU Agency for Innovation by Science and Technology (IWT Vlaanderen); Ghent
   University; Hercules Foundation; Flemish Government - department EWI
FX The described research activities were funded by a PhD grant to Simon
   Dooms of the Agency for Innovation by Science and Technology (IWT
   Vlaanderen). This work was carried out using the Stevin Supercomputer
   Infrastructure at Ghent University, funded by Ghent University, the
   Hercules Foundation and the Flemish Government - department EWI.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   Anand S.S., 2003, P 2003 INT C INTELLI, P1
   [Anonymous], 2012, Proceedings of the Sixth ACM Conference on Recommender Systems. RecSys '12, DOI DOI 10.1145/2365952.2365984
   [Anonymous], 2011, ACM RECSYS
   [Anonymous], 2010, Introduction to high performance computing for scientists and engineers
   [Anonymous], 2007, The bellkor solution to the netflix prize
   Bao Xinlong., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P109
   Bellogin Alejandro, 2012, THESIS
   Bobadilla J, 2010, KNOWL-BASED SYST, V23, P520, DOI 10.1016/j.knosys.2010.03.009
   Bostandjiev Svetlin, 2012, P 6 ACM C REC SYST D, P35, DOI [10.1145/2365952.2365964, DOI 10.1145/2365952.2365964]
   Brand M., 2003, SDM
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Burke R, 2000, ENCY LIB INFORM SYST, V69, P175
   Chandramouli B., 2011, International Conference on Management of Data, P1243
   Das Abhinandan S, 2007, P 16 INT C WORLD WID, P271
   De Pessemier Toon, 2011, Proceedings of the 7th International Conference on Web Information Systems and Technologies. WEBIST 2011, P237
   Dooms Simon, 2011, Proceedings of the 7th International Conference on Web Information Systems and Technologies. WEBIST 2011, P391
   Dooms S, 2013, MULTIMED TOOLS APPL, P1
   Dooms S., 2013, WORKSH CROWDS HUM CO, V13
   Dooms S, 2013, J INTELL INF SYST, P1
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Ekstrand Michael, 2012, P 6 ACM C RECOMMENDE, P233, DOI [DOI 10.1145/2365952.2366002, 10.1145/2365952.2366002]
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Gretarsson B, 2010, COMPUT GRAPH FORUM, V29, P833, DOI 10.1111/j.1467-8659.2009.01679.x
   Guy, 2015, RECOMMENDER SYSTEMS, P511, DOI DOI 10.1007/978-1-4899-7637-6_15
   Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P241, DOI 10.1145/358916.358995
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Jahrer M., 2010, P 16 ACM SIGKDD INT, P693, DOI [DOI 10.1145/1835804.1835893, 10.1145/1835804.1835893]
   Jing Jiang, 2011, Proceedings of the 2011 IEEE World Congress on Services (SERVICES 2011), P490, DOI 10.1109/SERVICES.2011.66
   Kille B., 2012, P ACM RECSYS 2012 WO, P30
   Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3
   Moore A.W., 2001, CROSS VALIDATION DET
   Nikulin V, 2011, STAT PROBABIL LETT, V81, P773, DOI 10.1016/j.spl.2011.02.001
   Peralta V., 2007, Extraction and Integration of Movielens and Imdb Data
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Rendle S, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P251, DOI 10.1145/1454008.1454047
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Ricci F., 2010, Information Technology and Tourism, V12, P205, DOI 10.3727/109830511X12978702284390
   Schafer J. B., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P43, DOI 10.1145/584792.584803
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Tintarev N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P479, DOI 10.1007/978-0-387-85820-3_15
   Tintarev N, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P153
   Witten I. H., 2005, DATA MINING PRACTICA
   Zhao ZD, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P478, DOI 10.1109/WKDD.2010.54
NR 45
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11297
EP 11329
DI 10.1007/s11042-014-2232-7
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600016
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Wang, W
   Wan, Z
   Xia, YH
   Lin, WS
AF Wang, Zhengyou
   Wang, Wan
   Wan, Zheng
   Xia, Yanhui
   Lin, Weisi
TI No-reference hybrid video quality assessment based on partial least
   squares regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No reference (NR); PLSR model; Bit stream; Packet loss; NS2; Video
   quality assessment
AB Constructing objective assessment model on visual quality is challenging, since it associates closely with many factors in human visual perception, as well as both source coding and transmission. In this paper, a no reference hybrid model for video quality assessment is proposed by employing Partial Least Squares Regression (PLSR). The hybrid model combines both bitstream-based features and network-based features, taking into video quality dependence on visual content and network conditions account. We have conducted subjective tests to validate its quality assessment accuracy. Simulation results in Network Simulator version 2 (NS-2) verify the performance advantage of the hybrid model for SD (standard definition) and HD (high definition) video sequences. Proposed model could be used as a quality monitoring tool for assessing the real-time video quality during wireless transmission. Simulation results show that the devised model can improve the quality prediction against a full-reference metric, and achieves a high correlation (0.955) between quality prediction and the actual perceived quality judged by subjective assessment.
C1 [Wang, Zhengyou; Wang, Wan; Xia, Yanhui] Shijiazhuang Tiedao Univ, Shijiazhuang, Hebei, Peoples R China.
   [Wan, Zheng] Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Shijiazhuang Tiedao University; Jiangxi University of Finance &
   Economics; Nanyang Technological University
RP Wang, ZY (corresponding author), Shijiazhuang Tiedao Univ, Shijiazhuang, Hebei, Peoples R China.
EM zhengyouwang@gmail.com
RI Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Lin, Weisi/0000-0001-9866-1947; 
FU National Natural Science Foundation of China [60963011, 61162009];
   Jiangxi Natural Science Foundation of China [2009GZS0022]
FX This work was partially supported by the National Natural Science
   Foundation of China (No: 60963011, 61162009), and the Jiangxi Natural
   Science Foundation of China (No: 2009GZS0022).
CR Abdelkefi Atef, 2011, Proceedings 2011 9th Annual Communication Networks and Services Research Conference (CNSR 2011), P41, DOI 10.1109/CNSR.2011.15
   Angrisani L, 2012, IEEE T INSTRUM MEAS, V61, P1405, DOI 10.1109/TIM.2012.2186478
   Bro R, 1996, J CHEMOMETR, V10, P47, DOI 10.1002/(SICI)1099-128X(199601)10:1<47::AID-CEM400>3.0.CO;2-C
   FARINA Modesto., 2011, PEREZ, Clotilde. BASTOS, P01
   Ke C-H, 2006, IEEE INT C SENS NETW, P5
   Keimel C, 2011, INT WORK QUAL MULTIM, P49, DOI 10.1109/QoMEX.2011.6065711
   Khan E, 2007, IET IMAGE PROCESS, V1, P95, DOI 10.1049/iet-ipr:20050158
   Lin CH, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P565
   Liu T, 2009, IEEE J-STSP, V3, P280, DOI 10.1109/JSTSP.2009.2015069
   Mu M, 2010, DISCRETE PERCEPTUAL
   Panayides A, 2011, IEEE T INF TECHNOL B, V15, P387, DOI 10.1109/TITB.2011.2105882
   Park I, 2011, P SOC PHOTO-OPT INS, P7867
   Raake A, 2008, INT CONF ACOUST SPEE, P1149, DOI 10.1109/ICASSP.2008.4517818
   Slanina M., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P114, DOI 10.1109/IWSSIP.2007.4381166
   Staelens N, 2011, INT WORK QUAL MULTIM, P61, DOI 10.1109/QoMEX.2011.6065713
   Stockhammer T, 2005, IEEE WIREL COMMUN, V12, P6, DOI 10.1109/MWC.2005.1497853
   Sugimoto O, 2009, IEEE IMAGE PROC, P2237, DOI 10.1109/ICIP.2009.5413957
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yamada T, 2007, P IEEE PACK VID LAUS
   Yamagishi K, 2008, PARAMETRIC PACKET LA
   Yamagishi K, 2009, GLOB TELECOMM CONF, P396, DOI 10.1109/GLOCOM.2009.5425823
   You FH, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P824, DOI 10.1109/ICIS.2009.24
   Zhang F, 2013, IEEE T IMAGE PROCESS, V22, P1534, DOI 10.1109/TIP.2012.2233486
NR 23
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10277
EP 10290
DI 10.1007/s11042-014-2166-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700006
DA 2024-07-18
ER

PT J
AU Mariscal-Ramirez, JA
   Fernandez-Prieto, JA
   Canada-Bago, J
   Gadeo-Martos, MA
AF Mariscal-Ramirez, J. A.
   Fernandez-Prieto, J. A.
   Canada-Bago, J.
   Gadeo-Martos, M. A.
TI A new algorithm to monitor noise pollution adapted to
   resource-constrained devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; Noise pollution; Sound pressure level;
   Frequency analysis
AB European Directive 2002/49/EC indicates that member states must provide mappings of noise levels throughout all areas with more than 250,000 inhabitants and for all major roads with a traffic volume exceeding six million vehicles per year. Noise levels in regions containing major railways and airports should be mapped as well. Traditionally, noise mappings have been created using sound level meters, and the noise indicator used is the equivalent continuous sound pressure level. However, over the last few years, Wireless Sensor Networks have been proposed for this task, but little attention has been paid to the deployment of frequency-based algorithms adapted to resource-constrained devices to calculate the noise indicator. This work presents a new algorithm based on frequency domain, which has been implemented successfully in a resource-constrained device for calculating the noise indicator. Several experiments have been carried-out using a variety of scenarios to compare the differences between the noise indicators calculated by the sensor and those from a commercial sound level meter. The results show the effectiveness of the algorithm because the difference between our method and the traditional technique is less than 2 % (1.2 dBA). This comparison pertains to an urban area, and it demonstrates that the proposed approach can be used for noise mappings in real time and space.
C1 [Mariscal-Ramirez, J. A.; Fernandez-Prieto, J. A.; Canada-Bago, J.; Gadeo-Martos, M. A.] Univ Jaen, Telecommun Engn Dept, Linares, Spain.
C3 Universidad de Jaen
RP Fernandez-Prieto, JA (corresponding author), Univ Jaen, Telecommun Engn Dept, Linares, Spain.
EM jan@ujaen.es; jamr0006@red.ujaen.es; jcbago@ujaen.es; gadeo@ujaen.es
RI Fernandez-Prieto, Jose-Angel/R-6063-2016; Canada Bago,
   Joaquin/S-3785-2016; Gadeo Martos, Manuel Angel/A-4010-2017
OI Fernandez-Prieto, Jose-Angel/0000-0002-6530-2902; Canada Bago,
   Joaquin/0000-0003-1626-8274; Gadeo Martos, Manuel
   Angel/0000-0002-2058-2904
FU Centro de Estudios Avanzados en Tecnologias de la Informacion y
   Comunicacion - University of Jaen [CEATIC-2013-001]
FX This work was supported by the Centro de Estudios Avanzados en
   Tecnologias de la Informacion y Comunicacion - University of Jaen
   (Project CEATIC-2013-001).
CR [Anonymous], 19991990 ISO
   [Anonymous], IEC651
   [Anonymous], 2007, Protocols and Architectures for Wireless Sensor Networks
   [Anonymous], 2003, 616722003 IEC
   [Anonymous], 2013, ADT7411
   [Anonymous], 2013, PCE 353 SOUND LEVEL
   [Anonymous], 2008, P WORKSHOP REALWORLD
   [Anonymous], 2006, GOOD PRACT GUID STRA
   BACON DF, 1994, ACM COMPUTING SURVEY, V26
   Bhusari P., 2013, INT J SOFTW WEB SCI, V220, P55
   European Commission, 1996, COM96540 EUR COMM
   Filipponi L, 2008, LECT NOTES COMPUT SC, V5067, P492, DOI 10.1007/978-3-540-69170-9_35
   Gubbi J, 2013, INT C ADV COMP COMM
   KUMARRANA R, 2010, P 9 ACM IEEE INT C I, P105, DOI DOI 10.1145/1791212.1791226
   Muchnick S., 1997, ADV COMPILER DESIGN
   Santini A, 2009, 1 EUROPEAN TINYOS TE
   Santini S, 2007, 6 GI ITG KUVS FACHGE, P16
   Santini S, 2009, P IEEE INT C NETW SE, P1
NR 18
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 21
BP 9175
EP 9189
DI 10.1007/s11042-014-2074-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CS1JB
UT WOS:000361819200005
DA 2024-07-18
ER

PT J
AU Bong, DBL
   Khoo, BE
AF Bong, David Boon Liang
   Khoo, Bee Ee
TI Objective blur assessment based on contraction errors of local contrast
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Objective blur assessment; Contrast maps; Contraction errors; Histogram
   distribution; Spatial domain
ID IMAGE QUALITY ASSESSMENT
AB Blur distortion appears in multimedia content due to acquisition, compression or transmission errors. In this paper, a method is proposed to predict blur severity based on the contraction errors of local contrast maps. The proposed method is developed from the observation that histogram distribution of natural image would contract according to the degree of blur distortion. In order to quantify the level of contraction, an efficient method of determining local contrast boundaries is used. The upper and lower bounds of local histogram distribution are defined for the original image, and outlying points beyond these bounds are used to form the local contrast map. For the corresponding patch of a blur image, the same values of upper and lower bounds are used and the local contrast map for the blur image could be produced. Total difference between local contrast maps of the original and blur images is the contraction errors which are used to derive the blur score. The proposed method has advantages in terms of computation efficiency, and is performed in the spatial domain without the need of data transformation, conversion or filtering. In addition, prior training is not required at all for the model. Implementation of the proposed method as a multimedia tool is useful for estimating blur severity in multimedia content. The performance of the proposed method is verified by using three different blur databases and compared to popular state-of-the-art methods. Experiment results show that the proposed blur metric has high correlation with human perception of blurriness.
C1 [Bong, David Boon Liang] Univ Malaysia Sarawak, Fac Engn, Kota Samarahan 94300, Malaysia.
   [Bong, David Boon Liang; Khoo, Bee Ee] Univ Sains Malaysia, Sch Elect & Elect Engn, George Town 14300, Malaysia.
C3 University of Malaysia Sarawak; Universiti Sains Malaysia
RP Bong, DBL (corresponding author), Univ Malaysia Sarawak, Fac Engn, Kota Samarahan 94300, Malaysia.
EM davidblbong@yahoo.com; beekhoo@eng.usm.my
RI Khoo, Bee Ee/D-8730-2011; Bong, David/I-8735-2016
OI Khoo, Bee Ee/0000-0002-3492-2551; Bong, David/0000-0002-9027-8422
CR Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   Ciancio A, 2009, ELECTRON LETT, V45, P1162, DOI 10.1049/el.2009.1800
   Cohen E, 2010, SIGNAL IMAGE VIDEO P, V4, P289, DOI 10.1007/s11760-009-0117-4
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Geisler WS, 2008, ANNU REV PSYCHOL, V59, P167, DOI 10.1146/annurev.psych.58.110405.085632
   Han HS, 2009, IEEE T CONSUM ELECTR, V55, P165, DOI 10.1109/TCE.2009.4814430
   Haun AM, 2013, PROC SPIE, V8651, DOI 10.1117/12.2008620
   Jain A., 2011, Communication and Industrial Application (ICCIA), 2011 International Conference on, P1, DOI [10.1109/ICCIndA.2011.6146668, DOI 10.1109/ICCINDA.2011.6146668]
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Seshadrinathan K, 2011, MULTIMED TOOLS APPL, V51, P163, DOI 10.1007/s11042-010-0625-9
   Sheikh H, 2013, LIVE IMAGE QUALITY A
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu SQ, 2009, J VIS COMMUN IMAGE R, V20, P231, DOI 10.1016/j.jvcir.2009.03.002
NR 22
TC 12
Z9 13
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7355
EP 7378
DI 10.1007/s11042-014-1983-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800034
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Choi, YS
AF Choi, Yong Suk
TI Effectiveness of game based learning to minimize boolean functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game based learning; Boolean function minimization; Learning
   effectiveness
AB We developed a game based content for learning to minimize boolean functions using Karnaugh Map. With interesting game based scenarios and an intelligent tutoring module, our content could give adaptive feedbacks to learners as needed in order to make the learners well-motivated and immersed in learning context. We performed an experiment for three student groups (one experimental group and two control groups) which were learning the minimization of boolean functions at a vocational high school in Korea, and compared our content aided learning to other conventional ones for evaluating the learning effectiveness. In this experiment, we identified that our content aided learning was more effective than other ones significantly in terms of both academic achievement and learning attitude. More specifically, our content was very useful for learners to improve academic attitude and learning habit.
C1 Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
C3 Hanyang University
RP Choi, YS (corresponding author), Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
EM cys@hanyang.ac.kr
FU Hanyang University (HY); MSIP, Korea, under the ITRC support program
   [NIPA-2013-H0301-13-1001]; National Research Foundation of Korea (NRF) -
   Korea government (MSIP) [2013026290]
FX The author would like to give special thanks to his research assistant,
   Hee Jung Yu for performing some parts of experiments. His efforts
   considerably contributed to building timely completion of this paper.
   This work was supported by the research fund of Hanyang University
   (HY-2013). This research was supported by the MSIP, Korea, under the
   ITRC support program (NIPA-2013-H0301-13-1001) supervised by the NIPA,
   and the National Research Foundation of Korea (NRF) grant funded by the
   Korea government (MSIP) (No. 2013026290).
CR [Anonymous], IMS LEARN DES BEST P
   Bersin J., 2009, Learning Management Systems 2009
   Burgos D, 2007, INT J LEARN TECHNOL, V3, P252, DOI 10.1504/IJLT.2007.015444
   Graesser A. C., 2007, Educational Technology, V47, P19
   Graesser AC, 2009, DEEP LEARNING EMOTIO
   Halverson R., 2005, INNOVATE, V1
   KEDI, 1992, 920502 KEDI RM
   Koedinger K.R., 1997, International Journal of Artificial Intelligence in Education, V8, P30
   *LSAL, 2004, SCORM BEST PRACT GUI
   Luk ETH, 2006, 1 INT C TECHN E LEAR
   Manske M, 2005, 12 INT C AI ED AMST
   McCluskey E.J., 1986, LOGIC DESIGN PRINCIP
   MILLS C, 2007, P ASC SING
   Mitrovic A., 2004, Journal of Interactive Learning Research, V15, P409
   Mohammed P, 2007, P LEARN GAM SOPH ANT
   Moreno R, 2005, J EDUC PSYCHOL, V97, P117, DOI 10.1037/0022-0663.97.1.117
   Ong James., 2003, Intelligent Tutoring Systems: Using AI to Improve Training Performance and ROI
   Piskurich G.M., 2006, RAPID INSTRUCTIONAL, V2nd
   Riad A.M., 2009, J CONVERGENCE INFORM, V4, P108
   Schmmel BJ, 1983, METAANALYSIS FEEDBAC, P67
   Shang J., 2007, 1 IEEE INT WORKSH DI
   TAN J, 2007, 1 IEEE INT WORKSH DI
   Van Eck R, 2007, BUILDING INTELLIGENT
   VanLehn K, 2007, COGNITIVE SCI, V31, P3, DOI 10.1080/03640210709336984
   Ward N, 2007, IMS COMMON CARTRIDGE
   Zhou Y, 1999, 11 IEEE INT C TOOLS
NR 26
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7131
EP 7146
DI 10.1007/s11042-014-1956-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800025
DA 2024-07-18
ER

PT J
AU Iranpour, M
   Safabakhsh, R
AF Iranpour, Mehran
   Safabakhsh, Reza
TI Reducing the embedding impact in steganography using Hamiltonian paths
   and writing on wet paper
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; LSB substitution; LSB matching; Hamiltonian paths;
   Writing on wet paper; Steganalysis
ID LSB; STEGANALYSIS
AB The distortion introduced in the cover image is one of the most important factors influencing image steganography. The lower the distortion is, the higher the quality of the stego image, and thus the higher the resistance to steganalysis would be. This paper proposes an image steganographic method which employs the Hamiltonian paths in order to decrease the distortion produced by the LSB substitution scheme. The proposed method divides the cover image into non-overlapping blocks. For each block, the arrangement of the pixels of the block is first changed according to a Hamiltonian path. Next, the pixels whose LSB is not equal to the secret data are determined. The path that results in minimum distortion is chosen, and its binary code as well as the mismatched pixels are recorded. Repeating this process for all blocks, the pixels that should be modified during data embedding and a binary key that includes the codes of the best Hamiltonian path in all blocks are determined. Then, the new values of the second LSB of the changeable pixels are computed using writing on wet paper approach with regard to the compressed key. Finally, +1 or -1 is added to each changeable pixel according to the value computed for its second LSB. By this strategy, the distortion of each pixel of the stego image is at most 1. Experimental results evaluated on 2000 natural images reveal that the proposed method can significantly decrease the image distortion and thus enhance security.
C1 [Iranpour, Mehran] Islamic Azad Univ, Garmsar Branch, Dept Comp Engn, Garmsar, Iran.
   [Safabakhsh, Reza] Amirkabir Univ Technol, Tehran Polytech, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 Islamic Azad University; Amirkabir University of Technology
RP Iranpour, M (corresponding author), Islamic Azad Univ, Garmsar Branch, Dept Comp Engn, Garmsar, Iran.
EM miranpoor@yahoo.com; safa@aut.ac.ir
RI Safabakhsh, Reza/K-9687-2018
OI Safabakhsh, Reza/0000-0002-4937-8026
CR Amirkhani H, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3554413
   Amirtharajan R, 2012, INFORM SCIENCES, V193, P115, DOI 10.1016/j.ins.2012.01.010
   [Anonymous], 2008, P SPIE ELECT IMAGING
   Chan CS, 2009, FUND INFORM, V96, P49, DOI 10.3233/FI-2009-166
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cogranne R, 2013, SIGNAL PROCESS, V93, P1724, DOI 10.1016/j.sigpro.2013.01.014
   Diestel R., 2005, GRAPH THEORY
   Fakhredanesh M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043007
   Filler T, 2009, LECT NOTES COMPUT SC, V5806, P31, DOI 10.1007/978-3-642-04431-1_3
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich Jessica, 2010, Steganography in digital media: Principles, algorithms and applications
   Ghazanfari K, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013022
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hsu Chin-Wei, 2010, Technical Report
   Iranpour M, 2013, P 55 IEEE INT S ELMA, P27
   Iranpour M, 2013, P 9 IEEE INT C INT I
   Iranpour M, 2013, 18 INT C DIG SIGN PR, P1
   Iranpour M, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2013), P167, DOI 10.1109/ICCKE.2013.6682811
   Iranpour M, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON HIGH CAPACITY OPTICAL NETWORKS AND ENABLING TECHNOLOGIES (HONET-CNS), P21, DOI 10.1109/HONET.2013.6729751
   Izadinia H, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P234, DOI 10.1109/SoCPaR.2009.55
   Jung KH, 2012, MULTIMED TOOLS APPL, P1
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kim CT, 2012, ENVIRON POL SER, V8, P1, DOI 10.3920/978-90-8686-773-8
   Kuhn M, 2010, JBIG KIT
   Li XL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P209, DOI 10.1109/ICME.2008.4607408
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lidl R., 1997, FINITE FIELDS, V2nd
   Lin GS, 2010, IEEE T MULTIMEDIA, V12, P345, DOI 10.1109/TMM.2010.2051243
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Sabeti V, 2013, MULTIMED TOOLS APPL, V64, P777, DOI 10.1007/s11042-011-0975-y
   Sagan H., 1994, SPACE FILLING CURVES
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Wang XT, 2012, SIGNAL PROCESS, V92, P1525, DOI 10.1016/j.sigpro.2011.12.013
   Westfeld A, BOWS2 IMAGE DATABASE
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 44
TC 5
Z9 5
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6657
EP 6670
DI 10.1007/s11042-014-1921-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800004
DA 2024-07-18
ER

PT J
AU Sadek, MM
   Khalifa, AS
   Mostafa, MGM
AF Sadek, Mennatallah M.
   Khalifa, Amal S.
   Mostafa, Mostafa G. M.
TI Video steganography: a comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Video steganography; Information hiding; Spatial domain; Transform
   domain; Adaptive steganography
ID COPYRIGHT PROTECTION; WATERMARKING; DISTORTION; ALGORITHM; SCHEME; LINE
AB Steganography is the art and science of secret communication, concealing the very existence of a communication. Modern cover types can take many forms such as text documents, audio tracks, digital images, and video streams. Extensive research has been done on image steganography in the previous decade due to their popularity on the internet. Nowadays, video files are drawing much more attention. They are transmitted more and more frequent on internet websites such as Facebook and YouTube imposing a larger practical significance on video steganography. Information hiding in video has a variety of techniques, each of which has its strengths and weaknesses. This paper intends to provide an up-to-date comprehensive review on the various video steganographic methods found in the literature in the last 5 years. Furthermore, since security and robustness are very important issues in designing a good steganographic algorithm, some relevant attacks and steganalysis techniques are also surveyed. The paper concludes with recommendations and good practices drawn from the reviewed techniques.
C1 [Sadek, Mennatallah M.; Khalifa, Amal S.; Mostafa, Mostafa G. M.] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University
RP Sadek, MM (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
EM menna.sadek@fcis.asu.edu.eg; amal.khalifa@fcis.asu.edu.eg;
   mgmostafa@cis.asu.edu.eg
RI Mostafa, Mostafa G. M./HGP-0396-2022; Khalifa, Amal/AAN-9725-2020
OI Mostafa, Mostafa G. M./0000-0002-3555-4148; Khalifa,
   Amal/0000-0002-2054-7869
CR Abbass AS, 2007, UBIQUIT COMPUT COMMU, V2
   Al-Frajat A. K., 2010, Journal of Applied Sciences, V10, P1644, DOI 10.3923/jas.2010.1644.1649
   Alattar AM, 2004, P SOC PHOTO-OPT INS, V5306, P685, DOI 10.1117/12.527147
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2010, INT J DATABASE MANAG
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2002, P ACM WORKSH MULT SE
   [Anonymous], 2013, INT J EMERGING TECHN
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Balaji R., 2011, Economic Policies and Human Rights, P1
   Calderbank AR, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P596, DOI 10.1109/ICIP.1997.647983
   Carli M., 2006, INT C NETW INT C SYS, P85
   Chae J. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P311, DOI 10.1109/ICIP.1999.821620
   Chandramouli R, 2003, PROC SPIE, V5020, P173, DOI 10.1117/12.479732
   Chang FC, 2007, J VLSI SIG PROC SYST, V49, P443, DOI 10.1007/s11265-007-0095-0
   CHANNALLI S, 2009, INT J COMPUTER SCI E, V1, P137, DOI DOI 10.3923/itj.2004.245.269
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Das Rig, 2012, 2012 3rd National Conference on Emerging Trends and Applications in Computer Science (NCETACS), P14, DOI 10.1109/NCETACS.2012.6203290
   Eltahir ME, 2009, INTERNATIONAL CONFERENCE ON FUTURE COMPUTER AND COMMUNICATIONS, PROCEEDINGS, P672, DOI 10.1109/ICFCC.2009.44
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Hamid N., 2012, International Journal of Computer Science and Security (IJCSS), V6, P168
   Hanafy A., 2008, IEEE MILITARY COMMUN, P1, DOI DOI 10.1109/MILCOM.2008.4753107
   Herrera-Moro D. R., 2007, 17 INT C EL COMM COM, P34
   Hmood AK, 2010, INT J PHYS SCI, V5, P1054
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Huang HC, 2011, INFORM SCIENCES, V181, P3379, DOI 10.1016/j.ins.2011.04.007
   International Telecommunication Union, 2008, OBJ PERC MULT VID QU
   Jalab H., 2009, Journal of Computing, V1, P108
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Johnson NF, 1998, 1998 IEEE INFORMATION TECHNOLOGY CONFERENCE, PROCEEDINGS, P113, DOI 10.1109/IT.1998.713394
   Katzenbeisser S., 2000, INFORM TECHNIQUES ST
   Kawaguchi E, 1999, P SOC PHOTO-OPT INS, V3528, P464, DOI 10.1117/12.337436
   Kiah M. M., 2011, International Journal of Physicial Sciences, V6, P3837
   Kim YW, 2003, PROC INT CONF DOC, P775
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   LAMBRECHT CJV, 1996, P IEEE INT C IM PROC, P885
   Langelaar GC, 2001, IEEE T IMAGE PROCESS, V10, P148, DOI 10.1109/83.892451
   Latif A, 2013, J INFORM HIDING MULT, V4, P250
   Liao YC, 2009, JCPC: 2009 JOINT CONFERENCE ON PERVASIVE COMPUTING, P185, DOI 10.1109/JCPC.2009.5420191
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P300, DOI 10.1109/TCSVT.2005.861948
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11888, DOI 10.1016/j.eswa.2009.04.026
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu YX, 2013, J SYST SOFTWARE, V86, P2174, DOI 10.1016/j.jss.2013.03.101
   LOW SH, 1995, IEEE INFOCOM SER, P853, DOI 10.1109/INFCOM.1995.515956
   Maniccam SS, 2004, PATTERN RECOGN, V37, P475, DOI 10.1016/j.patcog.2003.08.010
   Mansouri J, 2009, INT J IMAG SYST TECH, V19, P306, DOI 10.1002/ima.20207
   Mazurczyk W, 2011, SOFT COMPUT, V15, P505, DOI 10.1007/s00500-009-0530-1
   Mckeon R.T., 2007, P IEEE COMP SOC 2007, P178
   Mercuri RT, 2004, COMMUN ACM, V47, P25, DOI 10.1145/1005817.1005840
   Ming Yang, 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P935
   Mozo A. J., 2009, 2009 IEEE Instrumentation and Measurement Technology Conference (I2MTC), P822, DOI 10.1109/IMTC.2009.5168563
   Mulcahy C., 1997, SPELMAN SCI MATH J, V1, P22
   Navas KA, 2011, IETE TECH REV, V28, P50, DOI 10.4103/0256-4602.74507
   Neufeld A, 2013, P SOC PHOTO-OPT INS, P8665
   Niu Ke, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P447, DOI 10.1109/ICSESS.2013.6615345
   Noda H, 2004, IEEE IMAGE PROC, P2147
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Rabah K., 2004, Information Technology Journal, V3, P245
   Raja K. B., 2005, P 3 INT C INT SENS I, P170
   Rao RS, 2012, INT J ENG RES APPL I, V2, P1509
   Raphael AJ., 2010, International Journal of Computer Applications, V2, P626
   Risca VI, 2001, CRYPTOLOGIA, V25, P37, DOI 10.1080/0161-110191889761
   Ritchey PhilipC., 2012, Journal of Information Hiding and Multimedia Signal Processing, V3, P212
   Robie DL, 2002, EURASIP J APPL SIG P, V2002, P164, DOI 10.1155/S1110865702000562
   Rosiyadi D., 2012, Int J Comput Theory and Eng (IJCTE), V4, P329
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Sakib M. N., 2011, Proceedings of the 2011 2nd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2011), P419, DOI 10.1109/ISMS.2011.72
   Sampat V., 2012, INT J COMPUT APPL IJ
   Shang YY, 2007, ICNC 2007: Third International Conference on Natural Computation, Vol 5, Proceedings, P576
   ShengDun Hu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P57, DOI 10.1109/CSE.2011.24
   Shirali-Shahreza M, 2006, 8 INT C SIGN PROC
   Shirali-Shahreza M. H., 2006, IEEEACIS INT C COMPU, P310
   Shou-Dao W, HIGH BITRATE INFORM
   Singh S., 2010, INT J ENG SCI TECHNO, V2, P6999
   Stanescu D, 2007, SACI 2007: 4TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS, PROCEEDINGS, P241, DOI 10.1109/SACI.2007.375518
   Su YT, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1507, DOI 10.1109/ICALIP.2008.4590142
   Su YT, 2011, SIGNAL PROCESS, V91, P1901, DOI 10.1016/j.sigpro.2011.02.012
   Sur A, 2006, LECT NOTES COMPUT SC, V4338, P738
   Tak U. Kin, 2009, 2009 International Conference on Information and Automation (ICIA), P995, DOI 10.1109/ICINFA.2009.5205063
   Vranjes M, 2007, PROCEEDINGS ELMAR 2007, P45
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang Y, 2006, SURVEY OBJECTIVE VID, P1748
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Xu CY, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P297, DOI 10.1109/ICIG.2007.36
   Xu CY, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 1, PROCEEDINGS, P269
   Yilmaz A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P679
   Yuhong Wang CZ, SUKESH KAITHAAPUZHA
   Zaker N, 2012, MULTIMED TOOLS APPL, V58, P147, DOI 10.1007/s11042-010-0714-9
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
   Zhang Wei., 2005, IEEE International Conference on Image Processing 2005, V3, pII, DOI [DOI 10.1109/ICIP.2005.1530530, 10.1109/ICIP.2005.1530530]
NR 100
TC 102
Z9 110
U1 0
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7063
EP 7094
DI 10.1007/s11042-014-1952-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800022
DA 2024-07-18
ER

PT J
AU Muhammad, G
   Masud, M
   Alelaiwi, A
   Rahman, MA
   Karime, A
   Alamri, A
   Hossain, MS
AF Muhammad, Ghulam
   Masud, Mehedi
   Alelaiwi, Abdulhameed
   Rahman, Md. Abdur
   Karime, Ali
   Alamri, Atif
   Hossain, M. Shamim
TI Spectro-temporal directional derivative based automatic speech
   recognition for a serious game scenario
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spectro-temporal directional derivative (STDD); Voice disorder;
   Automatic speech recognition; Serious games
ID VOICE IMPAIRMENTS; EMOTION
AB Speech is one of the important modalities in a serious game platform. Serious game can be very useful for the rehabilitation of individuals with voice disorders. Therefore, we need an efficient and high-performance automatic speech recognition (ASR) system. In this paper, we propose a spectro-temporal directional derivative (STDD) feature that requires less number of computations in the modeling and yet gives high recognition accuracy in the ASR system. The proposed STDD feature is achieved by applying different directional derivative filters in the spectro-temporal domain. The feature dimension is then compressed by discrete cosine transform. The experiments are performed with voice samples of Arabic numerals spoken by persons with and without voice pathology. The experimental results show that the STDD feature outperforms the conventional mel-frequency cepstral coefficients both in clean and noisy environments.
C1 [Muhammad, Ghulam] King Saud Univ, Dept Comp Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Masud, Mehedi] Taif Univ, Dept Comp Sci, At Taif, Saudi Arabia.
   [Alelaiwi, Abdulhameed; Hossain, M. Shamim] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Rahman, Md. Abdur] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
   [Karime, Ali] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   [Alamri, Atif] King Saud Univ, Dept Informat Syst, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 King Saud University; Taif University; King Saud University; Umm Al Qura
   University; University of Ottawa; King Saud University
RP Muhammad, G (corresponding author), King Saud Univ, Dept Comp Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM ghulam@ksu.edu.sa
RI Alamri, Atif/KFQ-0028-2024; Alelaiwi, Abdulhameed A/D-8729-2015;
   Hossain, M. Shamim/K-1362-2014; Masud, Mehedi/AAZ-7022-2020; Rahman,
   Abdur/AAG-9302-2019; Guizani, Mohsen/AAX-4534-2021; Muhammad,
   Ghulam/H-5884-2011
OI Alamri, Atif/0000-0002-1887-5193; Hossain, M.
   Shamim/0000-0001-5906-9422; Masud, Mehedi/0000-0001-6019-7245; Rahman,
   Abdur/0000-0002-4105-0368; Guizani, Mohsen/0000-0002-8972-8094;
   Muhammad, Ghulam/0000-0002-9781-3969; Karime, Ali/0000-0001-7826-1540
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia [RGP-VPP-228]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University, Riyadh, Saudi Arabia for funding this
   work through the research group project No RGP-VPP-228.
CR Abe S., 2005, ADV PTRN RECOGNIT
   [Anonymous], SERIOUS GAMES
   [Anonymous], P ICSLP 04 JEJ ISL S
   [Anonymous], 2011, J. Cyber Ther. Rehabil.
   [Anonymous], P 2 JOINT C EMBS BEM
   Arias-Londoño JD, 2010, PATTERN RECOGN, V43, P3100, DOI 10.1016/j.patcog.2010.03.019
   ATAL BS, 1974, J ACOUST SOC AM, V55, P1304, DOI 10.1121/1.1914702
   Barab S, 2005, ETR&D-EDUC TECH RES, V53, P86, DOI 10.1007/BF02504859
   Batliner A, 2008, USER MODEL USER-ADAP, V18, P175, DOI 10.1007/s11257-007-9039-4
   Bergeron BP, 2008, STUD HEALTH TECHNOL, V132, P26
   Botella C, 2004, ST HEAL T, V99, P73
   Boyanov B, 1997, IEEE ENG MED BIOL, V16, P74, DOI 10.1109/51.603651
   Costa SC, 2008, IEEE INT C BIOINF BI, P799
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fernández-Aranda F, 2012, J MENT HEALTH, V21, P364, DOI 10.3109/09638237.2012.664302
   Godino-Llorente JI, 2009, BIOMED SIGNAL PROCES, V4, P176, DOI 10.1016/j.bspc.2009.01.007
   Godino-Llorente JI, 2004, IEEE T BIO-MED ENG, V51, P380, DOI 10.1109/TBME.2003.820386
   Hadjitodorov S, 2000, IEEE T INF TECHNOL B, V4, P68, DOI 10.1109/4233.826861
   Markaki M, 2011, IEEE T AUDIO SPEECH, V19, P1938, DOI 10.1109/TASL.2010.2104141
   Moore B. C. J., 1997, INTRO PSYCHOL HEARIN
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Muhammad G, 2012, J VOICE, V26, DOI 10.1016/j.jvoice.2012.05.002
   Muhammad G, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-41
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
NR 26
TC 10
Z9 10
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5313
EP 5327
DI 10.1007/s11042-014-1973-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900021
DA 2024-07-18
ER

PT J
AU Bao, L
   Lu, JJ
   Li, Y
   Shi, YW
AF Bao, Lei
   Lu, Jianjiang
   Li, Yang
   Shi, Yanwei
TI A saliency detection model using shearlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Shearlet transform; Feature map; Entropy
AB Visual attention is a mechanism to derive possible locations of objects or regions from natural scenes, and many studies have tried to simulate this mechanism to build saliency detection models, which would accelerate the course of many applications, such as object location, detection and recognition, image segmentation, retrieval and so on. Recently, researchers have tried building the detection models in transform domains. In this paper, a novel saliency detection model using shearlet transform is presented. Firstly, multi-scale feature maps are created. The feature maps built on scaling coefficients are used to generate potential salient regions, which is further used to update the feature maps generated on shearlet coefficients. As these feature maps represent the details of image in multi scale, based on them global and local contrast is calculated to form global and local saliency maps. That is the proposed model obtains the global saliency based on global probability density distribution, and measures the local saliency by calculating the entropy of local areas. By combining the local and global saliency maps, the final saliency maps are obtained. The work of this paper is absolutely a new try to detect saliency regions in shearlet domain, and experimental results demonstrate the saliency detection performance of the novel proposed model.
C1 [Bao, Lei; Lu, Jianjiang; Li, Yang] PLA Univ Sci & Technol, Coll Command Informat Syst, Qingdao 210000, Peoples R China.
   [Shi, Yanwei] PLA 91206 Troops, Training Command, Qingdao 266000, Peoples R China.
C3 Army Engineering University of PLA
RP Bao, L (corresponding author), PLA Univ Sci & Technol, Coll Command Informat Syst, Qingdao 210000, Peoples R China.
EM lbaodong001@gmail.com; solarleeon@163.com; miipl606@163.com;
   332352964@qq.com
RI Li, Yang/M-3902-2019
OI Li, Yang/0000-0003-1682-0284
FU National Natural Science Foundation of China [61273210]
FX This work was supported by the National Natural Science Foundation of
   China (61273210).
CR [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], P INT WORKSH IM AN M
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Duncan K, 2012, IEEE IMAGE PROC, P1093, DOI 10.1109/ICIP.2012.6467054
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, Models of bottom-up and top-down visual attention
   Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li ZQ, 2010, SCI CHINA INFORM SCI, V53, P738, DOI 10.1007/s11432-010-0055-3
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Ngau CWH, 2010, INT CONF COMP SCI, P692, DOI 10.1109/ICCSIT.2010.5564545
NR 18
TC 4
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4045
EP 4058
DI 10.1007/s11042-014-2043-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800020
DA 2024-07-18
ER

PT J
AU Kiktova-Vozarikova, E
   Juhar, J
   Cizmar, A
AF Kiktova-Vozarikova, Eva
   Juhar, Jozef
   Cizmar, Anton
TI Feature selection for acoustic events detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRMR; JMI; Supervector; Acoustic event
ID AUDIO CLASSIFICATION; MUTUAL INFORMATION; RELEVANCE
AB The paper deals with the detection of abnormal situations via captured sound processing. Different settings of feature extraction algorithms were realized and evaluated. Chosen feature sets were used for building the effective parametric representation for gun shots and breaking glass. This way two types of high dimensional feature supervectors were created in regard to the best individual settings of each feature extraction algorithm. For improving the recognition rate Minimum Redundancy Maximum Relevance (MRMR) and Joint Mutual Information (JMI) feature selection algorithms were also applied. They were used for the selection of superior features and for the creation of n-dimensional feature supervectors. The investigation of the appropriate dimension of feature supervectors was performed too. The framework for recognition of potentially dangerous acoustic events such as breaking glass and gun shots, based on the MRMR and JMI selected feature supervector through Hidden Markov Models based classification is proposed in the paper.
C1 [Kiktova-Vozarikova, Eva; Juhar, Jozef; Cizmar, Anton] Tech Univ Kosice, Dept Elect & Multimedia Commun, Kosice 04120, Slovakia.
C3 Technical University Kosice
RP Kiktova-Vozarikova, E (corresponding author), Tech Univ Kosice, Dept Elect & Multimedia Commun, Pk Komenskeho 13, Kosice 04120, Slovakia.
EM eva.kiktova@tuke.sk; jozef.juhar@tuke.sk; anton.cizmar@tuke.sk
RI Kiktova-Vozarikova, Eva/AAN-3730-2020; Čižmár, Anton/I-4612-2014; Juhár,
   Jozef/B-2803-2014
OI Kiktova-Vozarikova, Eva/0000-0001-9325-7339; Juhár,
   Jozef/0000-0002-1596-9258
FU EU ICT Project INDECT [FP7 - 218086]; Ministry of Education of Slovak
   Republic [VEGA 1/0386/12]; Research & Development Operational Programme
   - ERDF [ITMS-26220220155]
FX This work has been performed partially in the framework of the EU ICT
   Project INDECT (FP7 - 218086) (25 %) and under research project VEGA
   1/0386/12 (25 %) supported by the Ministry of Education of Slovak
   Republic and under research project ITMS-26220220155 (50 %) supported by
   the Research & Development Operational Programme funded by the ERDF.
CR Bach JH, 2012, STUD COMPUT INTELL, V384, P39
   Barras C., 1998, 1 INT C LANG RES EV, P1373
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Cruz R, 2012, LECT NOTES COMPUT SC, V7208, P61
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kiktova E, 2013, COMM COM INF SC, V368, P288
   Kim HG, 2005, MPEG 7 AUDIO AUDIO C, P304
   KOTUS J., 2010, IEEE INT C MULT COMM, P140
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   LATANE B, 1969, AM SCI, V57, P244
   Lin CH, 2012, COMM COM INF SC, V310, P536
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2002.1183917
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Pleva M., 2011, J ELECT ELECT ENG, V4, P185
   PSUTKA J., 2001, P EUR, P1813
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Saeys Y, 2007, BIOINFORMATICS, V23, P2507, DOI 10.1093/bioinformatics/btm344
   Sun YJ, 2007, IEEE T PATTERN ANAL, V29, P1035, DOI 10.1109/TPAMI.2007.1093
   Tourassi GD, 2001, MED PHYS, V28, P2394, DOI 10.1118/1.1418724
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Vavrek J, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P469, DOI 10.1109/TSP.2012.6256338
   Vozarikova E, 2011, DIGITAL TECHNOLOGIES, P295
   Vozarikova E, 2012, COMM COM INF SC, V287, P350
   Vozáriková E, 2011, COMM COM INF SC, V149, P191
   WILLETT P, 1988, INFORM PROCESS MANAG, V24, P577, DOI 10.1016/0306-4573(88)90027-1
   Yang HH, 2000, SPEECH COMMUN, V31, P35, DOI 10.1016/S0167-6393(00)00007-8
   YANG HH, 1999, P C ADV INT DAT AN C
   Young S, 2006, HTK BOOK, P368
   Zhu YY, 2007, LECT NOTES COMPUT SC, V4577, P474
NR 31
TC 18
Z9 19
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4213
EP 4233
DI 10.1007/s11042-013-1529-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600003
DA 2024-07-18
ER

PT J
AU Lin, CC
   Liu, XL
   Tai, WL
   Yuan, SM
AF Lin, Chia-Chen
   Liu, Xiao-Long
   Tai, Wei-Liang
   Yuan, Shyan-Ming
TI A novel reversible data hiding scheme based on AMBTC compression
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Block truncation coding; AMBTC; Watermarking
ID SIDE MATCH; DIFFERENCE; VECTOR; IMAGES
AB Data hiding encompasses a wide range of applications for embedding messages in content. However, hiding data inevitably destroys the host image, even though the distortion is imperceptible. To enhance the hiding capacity and maintain the quality of the host image after embedding hidden data, in this paper, we present a high payload reversible data hiding scheme that is based on the absolute moment block truncation coding (AMBTC) compression domain. We explore the redundancy in a block of AMBTC-compressed images to determine if a block is embeddable or non-embeddable. Next, we create four disjoint sets for embeddable blocks to embed data using different combinations of the mean value and the standard deviation. Performance comparisons with other BTC-based schemes are provided to demonstrate the superiority of the proposed scheme.
C1 [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
   [Liu, Xiao-Long; Yuan, Shyan-Ming] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Tai, Wei-Liang] Chinese Culture Univ, Dept Informat Commun, Taipei, Taiwan.
C3 Providence University - Taiwan; National Yang Ming Chiao Tung
   University; Chinese Culture University
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung, Taiwan.
EM mhlin3@pu.edu.tw; shallen548@gmail.com; tai.wei.liang@gmail.com;
   smyuan@cs.nctu.edu.tw
RI Liu, Xiaolong/AFP-0342-2022; Yuan, Shyan-Ming/O-1809-2013; Tai,
   Wei-Liang/V-2841-2019; chen, jenny/G-6723-2015
OI Liu, Xiaolong/0000-0001-6492-2723; Yuan, Shyan-Ming/0000-0002-3621-9528;
   Tai, Wei-Liang/0000-0001-7517-7570; chen, jenny/0000-0003-3501-9046
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alfred H, MATH ANN, V69, P331
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cai-Hua Li, 2011, Information Technology Journal, V10, P1421, DOI 10.3923/itj.2011.1421.1426
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2012, AEU-INT J ELECTRON C, V66, P758, DOI 10.1016/j.aeue.2012.01.008
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chiou SF, 2011, IMAGING SCI J, V59, P17, DOI 10.1179/136821910X12750339175943
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Goljan M., 2001, 4th Information Hiding Workshop, LNCS, V2137, P27, DOI DOI 10.1007/3-540-45496-9
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Rosiyadi D, 2012, IEEE MULTIMEDIA, V19, P62, DOI 10.1109/MMUL.2011.41
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XL, 1997, IEEE T IMAGE PROCESS, V6, P656, DOI 10.1109/83.568923
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
NR 27
TC 55
Z9 55
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3823
EP 3842
DI 10.1007/s11042-013-1801-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800011
DA 2024-07-18
ER

PT J
AU Rho, MJ
   Jang, KS
   Chung, KY
   Choi, IY
AF Rho, Mi Jung
   Jang, Kwang Soo
   Chung, Kyung-Yong
   Choi, In Young
TI Comparison of knowledge, attitudes, and trust for the use of personal
   health information in clinical research
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic Medical Record; Protected Health Information; HIPAA Privacy
   Rule
ID PRIVACY RULE; IDENTIFICATION; LINKAGE; RECORDS
AB As interest in the use of electronic medical record data for clinical research has increased, the protection of personal health information has become increasingly important. The Privacy Rule, established by the Health Insurance Portability and Accountability Act in 1996, proposed the concept of Protected Health Information (PHI) to restrict the use of personal health information from clinical settings. Because researchers and patients are not familiar with PHI despite its importance, our study aimed to find out the effect of the different knowledge, attitudes and levels of trust regarding personal health information on the use of them for clinical research. We collected 267 paper and online surveys from three groups: a clinical researcher group (n = 113), a non-clinical researcher group (n = 72) and a patient group (n = 82). The collected data were analyzed using one-way ANOVA depending on the three groups. We calculated the percentages of correct answers and incorrect answers to 40 questions related to PHI to determine the level of knowledge. Although the three groups had significantly different knowledge of PHI (p < 0.01), all three groups correctly understood that social security numbers and bank account numbers were Protected Health Information. In contrast, all three of the groups misunderstood that the physician's name, discharge date, and admission date were not non-PHI items. In addition, the three groups had significantly different attitudes and levels of trust regarding the use of PHI for clinical research (p < 0.05); however, all of the groups had favorable attitudes toward using and disclosing medical data in clinical research. Interestingly, although the three groups strongly agreed regarding the protection of the confidentiality of PHI, the patient groups trusted that hospitals would maintain a high level of PHI protection. The attitude toward using health information for clinical research was found to be favorable, but all of the groups were confused regarding date items. These results indicate that more education about PHI is required to protect identifiable health information. In particular, researcher groups, including both clinical and non-clinical researchers, must completely understand the protection of personal information to gain trust from patient groups.
C1 [Rho, Mi Jung; Choi, In Young] Catholic Univ Korea, Dept Med Informat, Coll Med, Seoul 137701, South Korea.
   [Jang, Kwang Soo] Hanyang Univ, Grad Sch Informat Syst, Seoul 133791, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju 220702, Gangwon Do, South Korea.
C3 Catholic University of Korea; Hanyang University; Sangji University
RP Choi, IY (corresponding author), Catholic Univ Korea, Dept Med Informat, Coll Med, 222 Banpo Daero, Seoul 137701, South Korea.
EM iychoi@catholic.ac.kr
RI Chung, Kyungyong/JAC-2276-2023
FU Korea Health technology R&D Project, Ministry of Health & Welfare,
   Republic of Korea [A112022]
FX This study was supported by a grant of the Korea Health technology R&D
   Project, Ministry of Health & Welfare, Republic of Korea (A112022).
CR Annas GJ, 2003, NEW ENGL J MED, V348, P1486, DOI 10.1056/NEJMlim035027
   Baumer D., 2000, Computers & Society, V30, P40, DOI 10.1145/572260.572261
   Belanger F, 2011, MIS QUART, V35, P1017
   Brownstein JS, 2010, DIABETES CARE, V33, P526, DOI 10.2337/dc09-1506
   Caine K, 2013, J AM MED INFORM ASSN, V20, P7, DOI 10.1136/amiajnl-2012-001023
   Choi IY, 2013, PROSTATE INT, V1, P59, DOI 10.12954/PI.12015
   Crawford AG, 2010, POPUL HEALTH MANAG, V13, P151, DOI 10.1089/pop.2009.0039
   Holman CDJ, 1999, AUST NZ J PUBL HEAL, V23, P453, DOI 10.1111/j.1467-842X.1999.tb01297.x
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   King T, 2012, INT J MED INFORM, V81, P279, DOI 10.1016/j.ijmedinf.2012.01.005
   Kuo KM, 2013, HEALTH INF MANAG J, P1, DOI 10.12826/18333575.2013.0011.Ma
   Kurtz Gary, 2003, J Healthc Inf Manag, V17, P41
   Lee SM, 2008, KOOKMIN LAW REV
   Leestma Ryan, 2003, Caring, V22, P16
   Liao KP, 2010, ARTHRIT CARE RES, V62, P1120, DOI 10.1002/acr.20184
   Longstaff D., 2005, CONTENTIOUS CROP HAR
   Meingast Marci, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5453
   Murff HJ, 2011, JAMA-J AM MED ASSOC, V306, P848, DOI 10.1001/jama.2011.1204
   Ness RB, 2007, JAMA-J AM MED ASSOC, V298, P2164, DOI 10.1001/jama.298.18.2164
   OCONNOR K, 1994, AUST COMPUT J, V26, P70
   Park MY, 2011, PHARMACOEPIDEM DR S, V20, P598, DOI 10.1002/pds.2139
   Rothstein MA, 2007, J LEGAL MED, V28, P487, DOI 10.1080/01947640701732148
   Rothstein MA, 2010, AM J BIOETHICS, V10, P3, DOI 10.1080/15265161.2010.494215
   Terry NP, 2009, J HLTH BIOMED LAW, V5, P1
   Whiddett R, 2006, INT J MED INFORM, V75, P530, DOI 10.1016/j.ijmedinf.2005.08.009
   Willison DJ, 2007, J AM MED INFORM ASSN, V14, P706, DOI 10.1197/jamia.M2457
   Wilson JF, 2006, ANN INTERN MED, V145, P313, DOI 10.7326/0003-4819-145-4-200608150-00019
   최인영, 2007, Healthcare Informatics Research, V13, P197
NR 28
TC 16
Z9 18
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2391
EP 2404
DI 10.1007/s11042-013-1772-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200013
DA 2024-07-18
ER

PT J
AU Kim, K
   Ha, W
   Choi, O
   Yeh, H
   Kim, JH
   Hong, M
   Shon, T
AF Kim, Kangseok
   Ha, Wonjeong
   Choi, Okkyung
   Yeh, Hongjin
   Kim, Jai-Hoon
   Hong, Manpyo
   Shon, Taeshik
TI An interactive pervasive whiteboard based on MVC architecture for
   ubiquitous collaboration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CSCW; Ubiquitous Collaboration; Interactive Shared Whiteboard; Mobile
   Device; MVC
AB Collaboration is about interactions among multiple users by sharing resources. With the advent of new generation of mobile access devices such as smartphone and tablet PC, we address this for ubiquitous collaboration-the capability of multiple users to link together with disparate access devices in anytime and in anywhere. The implementation and experiments of mobile applications for ubiquitous collaboration were challenge since cell phone (also referred to feature phone) prior to smartphone had high network latency and low computing performance. However, even though mobile device technologies and wireless networking are becoming more advanced with time, the research on the impact of ubiquitous collaboration is still immature. This paper extends our prior work with interactive multimedia services-whiteboard application on 3G and Wi-Fi Android platform based mobile devices, based on MVC (Model View Controller) architecture for ubiquitous collaboration. Then, we present interaction and usability study with multiple users using (wire, wireless) small-sized devices (smartphones), mid-sized devices (tablet PCs), and large-sized device (desktops) to show how disparate access devices and networking have an effect on software design of shared applications in ubiquitous collaboration system.
C1 [Kim, Kangseok; Ha, Wonjeong; Choi, Okkyung] Ajou Univ, Dept Knowledge Informat Engn, Grad Sch, Suwon 441749, South Korea.
   [Yeh, Hongjin; Kim, Jai-Hoon; Hong, Manpyo] Ajou Univ, Grad Sch Informat & Commun, Suwon 441749, South Korea.
   [Shon, Taeshik] Ajou Univ, Div Informat Comp Engn, Suwon 441749, South Korea.
C3 Ajou University; Ajou University; Ajou University
RP Kim, K (corresponding author), Ajou Univ, Dept Knowledge Informat Engn, Grad Sch, Suwon 441749, South Korea.
EM kangskim@ajou.ac.kr; seacoolth@ajou.ac.kr; okchoi@ajou.ac.kr;
   hjyeh@ajou.ac.kr; Jaikim@ajou.ac.kr; mphong@ajou.ac.kr;
   tsshon@ajou.ac.kr
FU MKE (Ministry of Knowledge Economy), Korea; National Research Foundation
   of Korea [22A20130000118] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This research was supported by the MKE (Ministry of Knowledge Economy),
   Korea, under the "Employment Contract based Master's Degree Program for
   Information Security" supervised by the KISA (Korea Internet Security
   Agency).
CR Bishop M., 2004, Introduction to computer security
   Dommel HP, 1997, ACM MULTIMEDIA SYSTE, V5
   Everitt K. M., 2003, P SIGCHI C HUM FACT, P553, DOI 10.1145/642611.642707event-place:Ft.Lauderdale,Florida,USA
   Fox G, 2003, COLL TECHN S CTS 03
   Fox G, 2003, P 1 INT WORKSH MIDDL
   Fox G, 2006, INT S COLLAB TECHNOL, P419, DOI 10.1109/CTS.2006.24
   Greenberg S, 1994, P ACM CSCW C COMP SU
   ISHII H, 1991, PROCEEDINGS OF THE SECOND EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK : ECSCW 91, P163
   Ishii H., 1992, P SIGCHI C HUM FACT, P3525, DOI [10.1145/142750.142977, DOI 10.1145/142750.142977]
   Kim K, 2011, MULTIMED TOOLS APPL, V53, P213, DOI 10.1007/s11042-010-0508-0
   Nescher T, 2011, VISUAL COMPUT, V27, P311, DOI 10.1007/s00371-011-0546-2
   Pallickara S, 2005, P IEEE ACM GRID 2005, P25
   PEDERSEN ER, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P391
   Qiu X, 2003, SVG OP 2003 C EXH VA
   Tang A, 2004, VID P CSCW, V4
   Tang A, 2007, PEOPLE AND COMPUTERS XX - ENGAGE, P85, DOI 10.1007/978-1-84628-664-3_8
   Tang J. C., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P315, DOI 10.1145/108844.108932
NR 17
TC 3
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1557
EP 1576
DI 10.1007/s11042-013-1458-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900003
DA 2024-07-18
ER

PT J
AU Liu, K
   Wei, SK
   Zhao, Y
   Zhu, ZF
   Wei, YC
   Xu, CS
AF Liu, Kai
   Wei, Shikui
   Zhao, Yao
   Zhu, Zhenfeng
   Wei, Yunchao
   Xu, Changsheng
TI Accumulated reconstruction error vector (AREV): a semantic
   representation for cross-media retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media; Accumulated reconstruction error vector; Retrieval;
   Consistency; Dictionary learning
ID IMAGE; AUDIO
AB Cross-media retrieval aims to automatically perform the content-based search procedure among various media types (e.g., image, video and text), in which media representation plays an important role for providing the heterogeneous similarity measure. In this work, a novel semantic representation of cross-media, called accumulated reconstruction error vector (AREV), is proposed, which includes category-specific dictionary learning, media sample reconstruction, and accumulative reconstruction error concatenation. Instead of directly learning the correlation relationship among heterogeneous items in the same semantic groups, the AREV projects individually their original feature descriptions into a shared semantic space, in which each component is semantic consistent for various media types due to the consistency in category information. Experiments on the commonly used datasets, i.e. Wikipedia dataset and NUS-Wide dataset, show the good performance in terms of effectiveness and efficiency.
C1 [Liu, Kai; Wei, Shikui; Zhao, Yao; Zhu, Zhenfeng; Wei, Yunchao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Xu, Changsheng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Liu, Kai; Wei, Shikui; Zhao, Yao; Zhu, Zhenfeng; Wei, Yunchao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Beijing Jiaotong University
RP Wei, SK (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM 12120382@bjtu.edu.cn; shkwei@bjtu.edu.cn; yzhao@bjtu.edu.cn;
   zhfzhu@bjtu.edu.cn; 11112065@bjtu.edu.cn; csxu@nlpr.ia.ac.cn
RI xu, cj/HJZ-3488-2023
FU 973 Program [2012CB316400]; PCSIRT [IRT201206]; National Science
   Foundation of China [61202241, 61210006, 61025013]; Fundamental Research
   Funds for the Central Universities [2013JBM024]; Open Project Program of
   the National Laboratory of Pattern Recognition (NLPR)
FX This work was supported in part by the 973 Program (No. 2012CB316400),
   PCSIRT (No.IRT201206), the National Science Foundation of China
   (No.61202241, No.61210006, and No.61025013), the Fundamental Research
   Funds for the Central Universities (No.2013JBM024), and the Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR).
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Broilo M, 2010, IEEE T MULTIMEDIA, V12, P267, DOI 10.1109/TMM.2010.2046269
   Chandrasekhar Vijay., 2011, ISMIR, V20, P801
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Ling L, 2012, INT C PATT RECOG, P230
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu GJ, 2001, MULTIMED TOOLS APPL, V15, P269, DOI 10.1023/A:1012491016871
   Mao X., 2013, P 21 ACM INT C MULT, P897
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Salton G., 1993, SIGIR Forum, P49
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tang JH, 2012, MULTIMED TOOLS APPL, V56, P1, DOI 10.1007/s11042-011-0822-1
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Wang S.H., 2012, IEEE INT C COMP VIS
   Wang SH, 2012, NEUROCOMPUTING, V95, P105, DOI 10.1016/j.neucom.2011.06.039
   Wang SH, 2012, IEEE T MULTIMEDIA, V14, P1259, DOI 10.1109/TMM.2012.2193120
   Wei S, 2013, IEEE T CYBERN
   Wei SK, 2011, IEEE T CIRC SYST VID, V21, P15, DOI 10.1109/TCSVT.2011.2105554
   Wei SK, 2010, IEEE T KNOWL DATA EN, V22, P1191, DOI 10.1109/TKDE.2009.145
   Xu Z, 2013, INT C COMP VIS
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Younessian E, 2013, MULTIMED TOOLS APPL, P1
NR 32
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 561
EP 576
DI 10.1007/s11042-014-1968-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300014
DA 2024-07-18
ER

PT J
AU Yoo, H
   Shon, T
AF Yoo, Hyunguk
   Shon, Taeshik
TI Novel Approach for Detecting Network Anomalies for Substation Automation
   based on IEC 61850
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IEC 61850; Substation automation; Smartgrid; Anomaly detection; Machine
   learning; EM; SVM
AB An SA (Substation Automation) system based on IEC 61850 is an intelligent substation; it has been receiving considerable attention as a core component of a smart grid. The explosive increase of threats to cyber security has been expanded to critical national infrastructures including the power grid. Substation Automation has also become a main target of cyber-attacks. Currently, various countermeasures such as firewalls, IDS (Intrusion Detection System)s, and anti-virus solutions have been developed, but to date, these have not sufficiently reflected the inherent features of Substation Automation based on IEC 61850. This study suggests a method of anomaly detection for MMS (Manufacturing Message Specification) and GOOSE (Generic Object Oriented Substation Events) packets, the main communication protocols of IEC 61850 Substation Automation. 3-Phase preprocessing, EM (Expect Maximization), and one-class SVM (Support Vector Machine) techniques are applied. The effectiveness of the suggested method is evaluated through experiments.
C1 [Yoo, Hyunguk] Ajou Univ, Comp Engn Integrated Course, Suwon 441749, Gyeonggi Do, South Korea.
   [Yoo, Hyunguk] Ajou Univ, ICS Informat Commun Secur Lab, Suwon 441749, Gyeonggi Do, South Korea.
   [Shon, Taeshik] Ajou Univ, Coll Informat Technol, Div Informat & Comp Engn, Suwon 441749, Gyeonggi Do, South Korea.
C3 Ajou University; Ajou University; Ajou University
RP Shon, T (corresponding author), Ajou Univ, Coll Informat Technol, Div Informat & Comp Engn, Suwon 441749, Gyeonggi Do, South Korea.
EM cielo1025@ajou.ac.kr; tsshon@ajou.ac.kr
FU Power Generation & Electricity Delivery Core Technology Program of the
   Korea Institute of Energy Technology Evaluation and Planning(KETEP) from
   the Ministry of Trade, Industry & Energy, Republic of Korea
   [20131020402090]
FX This work was supported by the Power Generation & Electricity Delivery
   Core Technology Program of the Korea Institute of Energy Technology
   Evaluation and Planning(KETEP) granted financial resource from the
   Ministry of Trade, Industry & Energy, Republic of Korea (No.
   20131020402090).
CR [Anonymous], 2010, P 1 WORKSH SEC CONTR
   Barbosa RRR, 2010, MECH AUTONOMOUS MANA
   Barbosa RRR, 2012, EM TECHN FACT AUT ET
   Breunig M.M., 2000, ACM SIGMOD REC, V29
   Cheung S., 2007, SCADA SEC SCI S
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dussel P, 2010, CRITICAL INFORM INFR
   Garitano I, 2010, INTELLIGENT SOFT COM
   Kirrmann H., 2012, INTRO IEC 61850 ELEC
   Markey E.J., 2013, Electric Grid Vulnerability: Industry Responses Reveal Security Gaps
   Mcafee, APPL CONTR
   Pleijsier E, 2013, ANOMALY DETECTION SC
   Premaratne U, 2008, INF AUT SUST 2008 IC
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Shon T., 2007, INFORM SCI
   Ten C., 2011, IEEE Transactions on Smart Grid
   Torfino, TORF MODB TCP ENF
   Valdes A, 2009, TECHN HOM SEC 2009 H
   Valdes A, 2009, SYST SCI 2009 HICSS
   Yang D., 2006, 5 INT TOP M NUCL PLA
NR 20
TC 32
Z9 36
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 303
EP 318
DI 10.1007/s11042-014-1870-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300020
DA 2024-07-18
ER

PT J
AU Hu, CL
   Gong, LY
   Wang, TJ
   Liu, F
   Feng, Q
AF Hu, Chunlong
   Gong, Liyu
   Wang, Tianjiang
   Liu, Fang
   Feng, Qi
TI An effective head pose estimation approach using Lie Algebrized
   Gaussians based face representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Head pose estimation; Structure properties; Gaussian mixture models; Lie
   algebrized Gaussians; Classification
ID VISION
AB The accuracy of head pose estimation is significant for many computer vision applications such as face recognition, driver attention detection and human-computer interaction. Most appearance-based head pose estimation works typically extract the low-dimensional face appearance features in some statistic subspaces, where the subspaces represent the underlying geometry structure of the pose space. However, there is an open problem, namely, how to effectively represent appearance-based subspace face for the head pose estimation problem. To address the problem, this paper proposes a head pose estimation approach based on the Lie Algebrized Gaussians (LAG) feature to model the pose characteristic. LAG is built on Gaussian Mixture Models (GMM), which actually not only models the distribution of local appearance features, but also captures the Lie group manifold structure of the feature space. Moreover, to keep multi-resolution structure information, LAG is operated on many subregions of the image. As a result, these properties of LAG enable it to effectivelymodel the structure of subspace face which can lead to powerful discriminative ability for head pose estimation. After representing subspace face using the LAG, we treat the head pose estimation as a classification problem. The within-class covariance normalization (WCCN) based Support Vector Machine (SVM) classifier is employed to achieve robust performance as WCCN could reduce the within-class variabilities of the same pose. Extensive experimental analysis and comparison with both traditional and state-of-the-art algorithms on two challenging benchmarks demonstrate the effectiveness of our approach.
C1 [Hu, Chunlong; Wang, Tianjiang; Liu, Fang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Gong, Liyu] Eedoo Inc, Beijing 100085, Peoples R China.
C3 Huazhong University of Science & Technology
RP Feng, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM fengqi@hust.edu.cn
FU National Natural Science Foundation of China [61073094, U1233119]
FX Thank the editors and the anonymous referees for their valuable
   comments. This work was supported by the National Natural Science
   Foundation of China under grant number 61073094 and U1233119. The
   authors would also like to thank Xinwei Jiang for his help.
CR [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   Ba SO, 2004, IEEE INT C PATT REC
   BEYMER DJ, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P756, DOI 10.1109/CVPR.1994.323893
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blanz V, 2005, PROC CVPR IEEE, P454
   Bo L, 2009, ANN C NEUR INF PROC
   Brown LM, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P125, DOI 10.1109/MOTION.2002.1182224
   Chen D, 2001, IEEE C COMP VIS PATT
   Cusano C, 2004, PROC SPIE, V5304, P330
   Dong Ligeng., 2010, IEEE Conf. on Acoustics, Speech, P1470
   Gong L, 2013, ARXIV13040823
   Gourier N, 2006, CLEAR WORKSH CONJ FA
   Gourier N, 2004, ICPR INT WORKSH VIS, P1
   Haj M, 2012, IEEE C COMP VIS PATT
   Hatch A, 2006, P ICSLP INT
   Horprasert T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P242, DOI 10.1109/AFGR.1996.557271
   Hu CL, 2013, IEEE INT CON MULTI
   Huang J, 1998, INT C PATT RECOG, P154, DOI 10.1109/ICPR.1998.711102
   Jilin Tu, 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P281
   Kruger B, 2000, BRIT MACH VIS C BMVC, P11
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li Z, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1810
   Liyu Gong, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2366, DOI 10.1109/CVPRW.2009.5206506
   Ma B, 2008, IEEE INT C PATT REC, P512
   Moon H, 2004, IEEE IMAGE PROC, P75
   Murphy-Chutorian E, 2008, IEEE INT VEH SYM, P1174
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Niyogi S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P374, DOI 10.1109/AFGR.1996.557294
   Ranganathan A, 2008, LECT NOTES COMPUT SC, V5302, P468, DOI 10.1007/978-3-540-88682-2_36
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Robertson N, 2006, IEEE EUR C COMP VIS
   Sherrah J, 2001, IMAGE VISION COMPUT, V19, P807, DOI 10.1016/S0262-8856(00)00096-2
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Srinivasan S, 2002, INT C PATT RECOG, P302, DOI 10.1109/ICPR.2002.1047456
   Stiefelhagen R, 2002, IEEE INT C MULT INT
   Stiefelhagen R, 2004, P POINT 2004 WORKSH
   Tian YL, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P92
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Voit M, 2006, CLEAR WORKSH CONJ FA
   Wang JG, 2007, IMAGE VISION COMPUT, V25, P1864, DOI 10.1016/j.imavis.2005.12.017
   Wu J., 2004, P EUR 04, P4
   Wu J, 2008, PATTERN RECOGN, V41, P1138, DOI 10.1016/j.patcog.2007.07.017
   Zhou X, 2009, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2009.5459435
NR 44
TC 7
Z9 10
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1863
EP 1884
DI 10.1007/s11042-013-1676-5
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200034
DA 2024-07-18
ER

PT J
AU Wang, E
   Yan, W
AF Wang, E.
   Yan, W.
TI iNavigation: an image based indoor navigation system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor; Navigation; Image; Photo-based; SIFT; IPM; ANN search;
   Best-bin-first
ID NEAREST-NEIGHBOR SEARCH
AB This paper presents a novel image-based indoor navigation web application designed for mobile phone. It is inspired by Google Street View that features 360 degrees imagery for navigation. Ordinary data collection of image based navigation systems implements panorama cameras, so it is difficult to be extended to indoor environment. On the other hand, they cannot provide timely updates because it requires immense image data. This paper introduces a 'proof of concept' which only uses ordinary organized photo collections instead of panoramic photo to guide people through the building. It implements SIFT (scale-invariant feature transform) feature detection and ANN (approximately nearest neighbor) search to provide positioning service. People can upload query images to obtain current position. It also enables information sharing by using IPM (inverse perspective mapping) technique to figure out distance from a single query image, and update the query image into the image collection correctly based on the distance calculation.
C1 [Wang, E.; Yan, W.] Auckland Univ Technol, Auckland, New Zealand.
C3 Auckland University of Technology
RP Yan, W (corresponding author), Auckland Univ Technol, Auckland, New Zealand.
EM wanglf.eric@gmail.com; dcsyanwq@gmail.com
CR ANDONI A, 2006, P S FDN COMP SCI
   [Anonymous], P WIR MOB COMP NETW
   [Anonymous], 6 INT S SAT NAV TECH
   [Anonymous], P INT C COMP VIS
   Babbar G., 2010, INT J INFORM TECHNOL, V2, P337
   Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P775, DOI 10.1109/INFCOM.2000.832252
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bradley D., 2005, P IEEE INT WORKSH HA
   Cattenoz M, 2011, P ADV MED TECHN, P27
   Couceiro M, 2010, SEGMENTATION
   Dijkstra EW., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Ekman I, 2002, P INT C HUM FACT COM, P622
   Gezici S, 2005, IEEE SIGNAL PROC MAG, V22, P70, DOI 10.1109/MSP.2005.1458289
   GILLIERON PY, 2003, P 11 IAIN WORLD C BE
   Ishikawa T, 2009, LECT NOTES COMPUT SC, V5756, P330, DOI 10.1007/978-3-642-03832-7_20
   Ivanov Rosen., 2010, P 11 INT C COMPUTER, P143
   Jaspers H, 2012, P INT C COMP SYST TE
   Kang H, 2009, IEEE COMP SOC C COMP
   Karimi H, 2011, INDOOR NAVIGATION UN, P17
   Kawaji Hisato., 2010, P 1 ACM INT WORKSHOP, P1, DOI DOI 10.1145/1878039.1878041
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kitasuka T, 2003, 2003 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS, AND SIGNAL PROCESSING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P272
   Kray C., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P117, DOI 10.1145/604045.604066
   Lu YH, 2004, PROC SPIE, V5308, P102, DOI 10.1117/12.538246
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MIKOLAJCZYK K, 2005, P INT C COMP VIS
   Moreels P, 2005, IEEE I CONF COMP VIS, P800
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Muja M., 2009, P INT C COMP VIS THE
   Nene SA, 1997, IEEE T PATTERN ANAL, V19, P989, DOI 10.1109/34.615448
   Ni LM, 2004, WIREL NETW, V10, P701, DOI 10.1023/B:WINE.0000044029.06344.dd
   Ozdenizci B., 2011, 2011 Fourth International Conference on Information and Computing (ICIC), P11, DOI 10.1109/ICIC.2011.53
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Renaudin V., 2007, European Journal of Navigation, V5, P36
   Ruotsalainen L., 2011, J. Glob. Position. Syst, V10, P11, DOI [10.5081/jgps.10.1.11, DOI 10.5081/JGPS.10.1.11]
   SATALICH G, 1995, THESIS U WASHINGTON
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Slipa-Anan C, 2004, LOCALISATION USING I
   Thongthammachart S, 2003, IEEE VTS VEH TECHNOL, P2023
   Tuohy S., 2010, IET Irish Signals and Systems Conference (ISSC 2010), P100, DOI 10.1049/cp.2010.0495
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759
   Werner M., 2011, P INT C IND POS IND, P21
   West D.B., 2001, INTRO GRAPH THEORY, P97
   Yazawa N, 2009, P IAPR C MACH VIS AP
NR 48
TC 8
Z9 10
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1597
EP 1615
DI 10.1007/s11042-013-1656-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200022
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xie, YR
   Huang, C
   Xu, LF
AF Xie, Yurui
   Huang, Chao
   Xu, Linfeng
TI Semantic superpixel extraction via a discriminative sparse
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Superpixel; Sparse representation; Multi-scale
ID FACE SEGMENTATION; RECOGNITION
AB The superpixel extraction algorithm is becoming increasingly significant for pattern recognition applications. Different superpixel generation methods have different properties and lead to various over-segmentation results. In this paper, we treat the over-segmentation as an image decomposition problem, and propose a novel discriminative sparse coding (DSC) algorithm to effectively extract the semantic superpixels. Specifically, the DSC algorithm incorporates a new discriminative regularization term in the traditional sparse representation model. Then the new regularization term is combined with the reconstruction error and sparse constraint to form a unified objective function. The extracted superpixels not only respect the local image boundaries, but also are dissimilar between each other. Meanwhile, the quantity of segments is sparse. These properties benefit for the semantic superpixel extraction. The final refined superpixels are generated based on an effective Bayesian-classification criterion in a post-processing step. Experimental results show that the over-segmentation quality of DSC algorithm outperforms the state of the art methods.
C1 [Xie, Yurui; Huang, Chao; Xu, Linfeng] Univ Elect Sci & Technol China Chengdu, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xie, YR (corresponding author), Univ Elect Sci & Technol China Chengdu, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM gloriousxyr@163.com
RI Huang, Chao/JJD-0553-2023; Huang, Chao/L-1445-2019; Xu,
   Linfeng/HME-1913-2023
OI Huang, Chao/0000-0001-8775-3192; Xu, Linfeng/0000-0002-9934-0958
FU NSFC [61179060, 61101091]; National High Technology Research and
   Development Program of China (863 Program) [2012AA011503]; Fundamental
   Research Funds for the Central Universities [ZYGX2012J019]
FX This work was partially supported by NSFC (No. 61179060, and 61101091),
   National High Technology Research and Development Program of China (863
   Program, No. 2012AA011503), and Fundamental Research Funds for the
   Central Universities (ZYGX2012J019).
CR Amri S, 2010, MULTIMED TOOLS APPL, V46, P175, DOI 10.1007/s11042-009-0348-y
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   [Anonymous], 149300 EPFL
   Ayvaci Alper, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P727, DOI 10.1109/ICCVW.2009.5457630
   Chen YS, 2012, PROC CVPR IEEE, P654, DOI 10.1109/CVPR.2012.6247733
   Dong WS, 2011, IEEE I CONF COMP VIS, P1259, DOI 10.1109/ICCV.2011.6126377
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P907, DOI 10.1002/cpa.20131
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Gkalelis N, 2013, IEEE T NEUR NET LEAR, V24, P8, DOI 10.1109/TNNLS.2012.2216545
   Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   Huang SY, 2010, MULTIMED TOOLS APPL, V48, P267, DOI 10.1007/s11042-009-0341-5
   Jing GD, 2014, MULTIMED TOOLS APPL, V70, P741, DOI 10.1007/s11042-011-0953-4
   Kalantidis Y, 2011, MULTIMED TOOLS APPL, V51, P555, DOI 10.1007/s11042-010-0651-7
   Kawulok M, 2010, MULTIMED TOOLS APPL, V49, P463, DOI 10.1007/s11042-009-0444-z
   Levinshtein A, 2009, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2009.5459472
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li HL, 2011, IEEE T CIRC SYST VID, V21, P1571, DOI 10.1109/TCSVT.2011.2129150
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Liu Q, 2013, MULTIMED TOOLS APPL, V67, P231, DOI 10.1007/s11042-012-1077-1
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Nowozin S, 2010, LECT NOTES COMPUT SC, V6316, P98, DOI 10.1007/978-3-642-15567-3_8
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pati YC, 2012, P 27 ANN AS C SIGN S, P40
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   Vazquez-Reina A, 2010, LECT NOTES COMPUT SC, V6315, P268, DOI 10.1007/978-3-642-15555-0_20
   Vedaldi A., VLFEAT OPEN PORTABLE
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Vieux R, 2012, MULTIMED TOOLS APPL, V60, P305, DOI 10.1007/s11042-010-0611-2
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu CL, 2012, PROC CVPR IEEE, P1202, DOI 10.1109/CVPR.2012.6247802
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315
   Zhang L, 2011, IEEE I CONF COMP VIS, P755, DOI 10.1109/ICCV.2011.6126313
   Zhao J, 2014, MULTIMED TOOLS APPL, V73, P61, DOI 10.1007/s11042-012-1299-2
   Zhu Y, 2010, IEEE T MED IMAGING, V29, P669, DOI 10.1109/TMI.2009.2031063
NR 54
TC 1
Z9 1
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1247
EP 1268
DI 10.1007/s11042-013-1626-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200009
DA 2024-07-18
ER

PT J
AU Jiang, DM
   Zhao, Y
   Sahli, H
   Zhang, YN
AF Jiang, Dongmei
   Zhao, Yong
   Sahli, Hichem
   Zhang, Yanning
TI Speech driven photo realistic facial animation based on an articulatory
   DBN model and AAM features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial animation; AF_AVDBN; Asynchrony; AAM
ID TO-VISUAL CONVERSION; INVERSION
AB This paper presents a photo realistic facial animation synthesis approach based on an audio visual articulatory dynamic Bayesian network model (AF_AVDBN), in which the maximum asynchronies between the articulatory features, such as lips, tongue and glottis/velum, can be controlled. Perceptual Linear Prediction (PLP) features from audio speech, as well as active appearance model (AAM) features from face images of an audio visual continuous speech database, are adopted to train the AF_AVDBN model parameters. Based on the trained model, given an input audio speech, the optimal AAM visual features are estimated via a maximum likelihood estimation (MLE) criterion, which are then used to construct face images for the animation. In our experiments, facial animations are synthesized for 20 continuous audio speech sentences, using the proposed AF_AVDBN model, as well as the state-of-art methods, being the audio visual state synchronous DBN model (SS_DBN) implementing a multi-stream Hidden Markov Model, and the state asynchronous DBN model (SA_DBN). Objective evaluations on the learned AAM features show that much more accurate visual features can be learned from the AF_AVDBN model. Subjective evaluations show that the synthesized facial animations using AF_AVDBN are better than those using the state based SA_DBN and SS_DBN models, in the overall naturalness and matching accuracy of the mouth movements to the speech content.
C1 [Jiang, Dongmei; Zhao, Yong; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
   [Jiang, Dongmei; Zhao, Yong; Zhang, Yanning] Shaanxi Prov Key Lab Speech & Image Informat Proc, Luoyang, Shaanxi, Peoples R China.
   [Sahli, Hichem] Vrije Univ Brussel, Elect & Informat Dept ETRO, Brussels, Belgium.
   [Sahli, Hichem] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
C3 Northwestern Polytechnical University; Vrije Universiteit Brussel; IMEC
RP Zhao, Y (corresponding author), Shaanxi Prov Key Lab Speech & Image Informat Proc, Luoyang, Shaanxi, Peoples R China.
EM jiangdm@nwpu.edu.cn; zhaoyongnpu@qq.com; hsahli@vub.ac.be
OI Sahli, Hichem/0000-0002-1774-2970
FU National Natural Science Foundation of China [61273265]; Shaanxi
   Provincial Key International Cooperation Project [2011KW-04];
   LIAMA-CAVSA; EU FP7 project ALIZ-E [248116]; VUB-HOA CaDE
FX This work is supported within the framework of the National Natural
   Science Foundation of China (grant 61273265), the Shaanxi Provincial Key
   International Cooperation Project (2011KW-04), the LIAMA-CAVSA project,
   the EU FP7 project ALIZ-E (grant 248116), and the VUB-HOA CaDE project.
CR Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   Bilmes J, 2002, INT CONF ACOUST SPEE, P3916
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Bregler C, 2006, COMPUTER GRAPHICS AN, P353
   Choi KH, 2001, J VLSI SIG PROC SYST, V29, P51, DOI 10.1023/A:1011171430700
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   Cosatto E, 2000, IEEE T MULTIMEDIA, V2, P152, DOI 10.1109/6046.865480
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Gowdy JN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P993
   Gutierrez-Osuna R, 2005, IEEE T MULTIMEDIA, V7, P33, DOI 10.1109/TMM.2004.840611
   Hou Y, 2007, LECT NOTES COMPUT SC, V4678, P340
   Jiang DM, 2010, INT CONF ACOUST SPEE, P2478, DOI 10.1109/ICASSP.2010.5494894
   Li Y, 2006, IEEE T MULTIMEDIA, V8, P542, DOI 10.1109/TMM.2006.870732
   Liu N, 2010, TENCON IEEE REGION, P1613, DOI 10.1109/TENCON.2010.5686036
   Livescu K, 2006, 2006 JHU SUMM WORKSH
   Massaro DominicW., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P172, DOI DOI 10.1145/958432.958466
   Mattheyses W, 2008, LECT NOTES COMPUT SC, V5237, P125, DOI 10.1007/978-3-540-85853-9_12
   Mattheyses W, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1113
   Rao RR, 1998, IEEE T IND ELECTRON, V45, P15, DOI 10.1109/41.661300
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Terissi LD, 2008, LECT NOTES ARTIF INT, V5249, P33, DOI 10.1007/978-3-540-88190-2_9
   Wu P, 2011, P AUD VIS SPEECH PRO, P59
   Xie L, 2007, PATTERN RECOGN, V40, P2325, DOI 10.1016/j.patcog.2006.12.001
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5
   Young S., 2001, HTK BOOK
NR 26
TC 6
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 397
EP 415
DI 10.1007/s11042-013-1610-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700020
DA 2024-07-18
ER

PT J
AU Arici, T
   Celebi, S
   Aydin, AS
   Temiz, TT
AF Arici, Tarik
   Celebi, Sait
   Aydin, Ali S.
   Temiz, Talha T.
TI Robust gesture recognition using feature pre-processing and weighted
   dynamic time warping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Dynamic time warping; Kinect
AB Gesture recognition is a technology often used in human-computer interaction applications. Dynamic time warping (DTW) is one of the techniques used in gesture recognition to find an optimal alignment between two sequences. Oftentimes a pre-processing of sequences is required to remove variations due to different camera or body orientations or due to different skeleton sizes between the reference gesture sequences and the test gesture sequences. We discuss a set of pre-processing methods to make the gesture recognition mechanism robust to these variations. DTW computes a dissimilarity measure by time-warping the sequences on a per sample basis by using the distance between the current reference and test sequences. However, all body joints involved in a gesture are not equally important in computing the distance between two sequence samples. We propose a weighted DTW method that weights joints by optimizing a discriminant ratio. Finally, we demonstrate the performance of our pre-processing and the weighted DTW method and compare our results with the conventional DTW and state-of-the-art.
C1 [Arici, Tarik; Celebi, Sait; Aydin, Ali S.; Temiz, Talha T.] Istanbul Sehir Univ, Dept Elect Engn, TR-34662 Istanbul, Turkey.
C3 Istanbul Sehir University
RP Arici, T (corresponding author), Istanbul Sehir Univ, Dept Elect Engn, Kusbakisi Caddesi 27, TR-34662 Istanbul, Turkey.
EM tarikarici@sehir.edu.tr; saitcelebi@std.sehir.edu.tr;
   aliaydin@std.sehir.edu.tr; talhatemiz@std.sehir.edu.tr
CR ADAMS NH, 2004, ISMIR
   AMIN TB, 2008, INT C ADV SPAC TECHN, DOI DOI 10.1109/ICAST.2008.4747690
   [Anonymous], INT WORKSH AUT FAC G
   [Anonymous], 2008, DYNAMIC TIME WARPING
   Baum L. E., 1972, Inequalities, V3, P1
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Bellman R., 1959, P IRE, V4, P1
   BRODLEY CE, 1995, MACH LEARN, V19, P45, DOI 10.1023/A:1022607123649
   Celebi S., 2013, Computer Vision Theory and Applications. Visapp
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Corradini A, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/RATFG.2001.938914
   Efrat A, 2007, J MATH IMAGING VIS, V27, P203, DOI 10.1007/s10851-006-0647-0
   Gehrig D., 2009, IEEE INT C HUM ROB H
   Hong Pengyu, 2000, P 4 IEEE INT C AUT F, P410
   Jain HP, 2011, LECT NOTES COMPUT SC, V6930, P227
   Jeong YS, 2011, PATTERN RECOGN, V44, P2231, DOI 10.1016/j.patcog.2010.09.022
   Kim S.-J., 2005, NEURAL INFORM PROCES
   Kuzmani A, 2007, EUROCON 2007: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOLS 1-6, P264, DOI 10.1109/EURCON.2007.4400350
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Muller M., 2007, INFORM RETRIEVAL MUS, V6
   Myers C., 1981, BELL SYST TECH J
   QUAM DL, 1990, PROC NAECON IEEE NAT, P755, DOI 10.1109/NAECON.1990.112862
   Rath TM, 2003, PROC CVPR IEEE, P521
   Rekha J., 2011, 2011 3rd International Conference on Trendz in Information Sciences & Computing (TISC), P30, DOI 10.1109/TISC.2011.6169079
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   Ryden F., 2011, ROB SCI SYST WORKSH
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Shotton J., 2011, CVPR, V2, P7
   Starner T., 1996, INT S COMP VIS
   Stowers J., 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics (ICM), P358, DOI 10.1109/ICMECH.2011.5971311
   Tan WJ, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 3, P163, DOI 10.1109/ICACC.2010.5486760
   TAPPERT CC, 1990, IEEE T PATTERN ANAL, V12, P787, DOI 10.1109/34.57669
   Wang S.B., 2006, P IEEE COMP SOC C CO
   *WIK, 2012, DYN TIM WARP
   Wilson A.D., 2010, ACM International Conference on Interactive Tabletops and Surfaces, P69, DOI DOI 10.1145/1936652.1936665
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
NR 39
TC 47
Z9 52
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 3045
EP 3062
DI 10.1007/s11042-013-1591-9
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300041
DA 2024-07-18
ER

PT J
AU Chung, M
   Choo, H
AF Chung, MyoungBeom
   Choo, Hyunseung
TI Picture browsing non-touch interaction methods for smartphones using an
   accelerometer and camera with a focus on phone dialing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smartphone; Mobile interaction; Touch interaction; Accelerometer;
   Dialing
AB This paper proposes various interaction methods for smartphones that allow users to call an intended contact without touching the smartphone screen. Existing applications allow users to answer phone calls without touching the screen-by shaking the phone, for example-but do not allow users to make phone calls. The proposed interaction allows users to select and call an intended contact by utilizing the iPhone's accelerometer. The interaction also involves video camera scanning for commands to switch between group-selection and individual-selection modes to facilitate the selection of the call candidate. Furthermore, the proposed interaction secures transparency by displaying the camera's video stream on the smartphone screen. In order to evaluate the efficacy of the interaction, an application using the interaction was developed, and two simple experiments were conducted, in which participants were asked to make phone calls using the application. The success rate was 98 %, and user satisfaction with the proposed interaction was approximately 90 %. Therefore, the results showed that the proposed interaction could be an effective solution to allow users to make phone calls in situations where they cannot physically touch the iPhone screen. Furthermore, this solution could be used in many fields that need interactions with users in mobile applications.
C1 [Chung, MyoungBeom; Choo, Hyunseung] Sungkyunkwan Univ, Sch Informat & Commun Engn, Suwon 440746, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Chung, M (corresponding author), Sungkyunkwan Univ, Sch Informat & Commun Engn, Suwon 440746, South Korea.
EM nzin@ssu.ac.kr; choo@skku.edu
FU MSIP(NIPA,KEIT); MOE(NRF), Korean government, under ITRC, IT RD Program
   [NIPA-2013-(H0301-13-3001), 10041244]; MOE(NRF), Korean government,
   under ITRC, PRCP [NRF-2010-0020210]
FX This research was supported in part by MSIP(NIPA,KEIT) and MOE(NRF),
   Korean government, under ITRC (NIPA-2013-(H0301-13-3001)), IT R&D
   Program [10041244, SmartTV 2.0 Software Platform], and
   PRCP(NRF-2010-0020210), respectively.
CR [Anonymous], P 1 INT WORKSH SENS
   Apple Inc, 2010, SIR
   Apple Inc, 2007, MULT GEST DICT
   Apple Inc, 2011, 3D GEST CONTR FUT IP
   Azizyan M, 2009, FIFTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2009), P261
   Chung M, 2012, MULTIMED TOOLS APPL, V59, P383, DOI 10.1007/s11042-011-0743-z
   Dale R, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001728
   David M, 2012, MUNSTER GOOGLE BEATS
   Gammeter Stephan, 2010, 2010 IEEE COMP SOC C, P1, DOI [10.1109/CVPRW.2010.5543248, DOI 10.1109/CVPRW.2010.5543248]
   HINCKLEY K, 2001, P UIST 01, P191, DOI DOI 10.1145/502348.502382
   Kim KD, 2012, SNAP CALL SPEED DIAL
   Lane ND, 2010, IEEE COMMUN MAG, V48, P140, DOI 10.1109/MCOM.2010.5560598
   Lee KW, 2012, P 24 C KOR OP RES MA, P233
   Lee S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P309
   LINJAMA J, 2005, CHI 2005 WORKSH HAND
   Lu H, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P165
   Miluzzo E., 2011, Smartphone Sensing
   Nintendo Inc, 2006, WII REM
   Parikh N, 2008, THESIS SAN JOSE STAT
   Ronkainen S., 2007, Proceedings of the 1st international conference on Tangible and embedded interaction - TEI '07, P263, DOI DOI 10.1145/1226969.1227023
   Samsung Inc, 2011, METH PROV UI US MOT
   Shanklin W, 2011, PANTECH ADDS 3D GEST
   So-NetFloor, 2011, NF SHAK CALL
   Ssensoft, 2010, SHAK IT
   Wang Y, 2009, MOBISYS'09: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P179, DOI 10.1016/B978-044306732-7.50020-9
   Yagoda RosemarieE., 2011, Using Mobile Devices for Robotic Controllers: Examples and Some Initial Concepts for Experimentation
NR 26
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2769
EP 2786
DI 10.1007/s11042-013-1576-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300031
DA 2024-07-18
ER

PT J
AU Bellini, P
   Nesi, P
   Pazzaglia, F
AF Bellini, Pierfrancesco
   Nesi, Paolo
   Pazzaglia, Fabio
TI Exploiting P2P scalability for grant authorization in digital rights
   management solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DRM complexity; DRM P2P; MPEG-21; DHT; AXMEDIS; Rights controls; Media
   distribution and protection; Rights control of electronic medical record
AB Digital rights management solutions are today quite widespread. Their cost is still quite expensive, and thus in many cases, their application is limited to specific business cases. On the other hand, the market still offers large cases where scalable DRM solutions would find their applicability, for example the management of complex cross media content such as the one used for the educational content, for electronic medical record, etc. In this paper, the focus is on reducing DRM costs by solving scalability problems lying behind the complexity of granting authorizations and performing verification for a large number of users, content and rights associated with them. The proposed solution is based on the exploitation of the DHT P2P network and storage to cope with verification and grant authorization. The paper reports the structure of the DRM solutions, the details for including the DHT P2P into the DRM architecture. The paper also reports details on how the proposed P2P DRM solution can be integrated into traditional DRM solutions. The provided experimental results have proved the reduction of costs, the scalability against the aforementioned cases. The studies and solutions reported in this paper have been worked out and validated on top of MPEG-21/AXMEDIS DRM solutions and tools. On the other hand, the solution is general enough to be adapted in other DRM solutions.
C1 [Bellini, Pierfrancesco; Nesi, Paolo; Pazzaglia, Fabio] Univ Florence, DISIT DSI, Distributed Syst & Internet Technol Lab, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, DISIT DSI, Distributed Syst & Internet Technol Lab, Dipartimento Sistemi & Informat, Via S Marta 3, I-50139 Florence, Italy.
EM paolo.nesi@unifi.it
RI Bellini, Pierfrancesco/D-5923-2015
OI Bellini, Pierfrancesco/0000-0002-8167-1003; nesi,
   paolo/0000-0003-1044-3107
FU European Commission
FX The authors would like to express their thanks to AXMEDIS partners, to
   the Expert-User-Group and all affiliated members for their contribution,
   support and collaboration; to the European Commission for the
   co-funding, and to Paolo De Luca who specifically helped us in the
   development of some of the P2P services.
CR Allasia W., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P130, DOI 10.1109/WIAMIS.2008.33
   Allasia W, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P147, DOI 10.1109/AXMEDIS.2007.17
   Allasia W, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES (ICIW 2008), P391, DOI 10.1109/ICIW.2008.40
   [Anonymous], 2004, P ANN C USENIX ANN T
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Bellini P, 2006, P IEEE INT C MULT EX
   Bellini P, 2007, P INT C DISTR MULT S
   Bellini P, 2005, P 1 INT C AUT PROD C
   Bellini P, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P105, DOI 10.1109/AXMEDIS.2007.31
   Bellini P, 2012, IEEE MULTIMEDIA, V19, P69, DOI 10.1109/MMUL.2011.55
   Bellini P, 2011, INT J SOFTW ENG KNOW, V21, P3, DOI 10.1142/S0218194011005141
   Señor IC, 2012, COMPUTER, V45, P27, DOI 10.1109/MC.2012.285
   Iannella R, 2002, VERSION 1 1 W3  0919
   Kuhlisch R, 2012, COMPUTER, V45, P34, DOI 10.1109/MC.2012.294
   Lin ET, 2005, P IEEE, V93, P171, DOI 10.1109/JPROC.2004.839623
   Liu DH, 2010, INT CONF COMP SCI, P466, DOI 10.1109/ICCSIT.2010.5564528
   Mourad M, 2005, COMPUTER IEEE, P58
   MPEG Group MPEG-21 DID, INTR MPEG 21 DID DIG
   Rhea S, 2005, SIGCOMM05 AUG 21 26
   Rodríguez E, 2007, AXMEDIS 2007: THIRD INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P163
   Wang X, 2005, IEEE T MULTIMEDIA, V7, P408, DOI 10.1109/TMM.2005.846788
   Zangrilli M, 2007, BAMBOO BASED DHT RES
NR 22
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1611
EP 1637
DI 10.1007/s11042-013-1468-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300026
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Federico, M
   Furini, M
AF Federico, Maria
   Furini, Marco
TI An automatic caption alignment mechanism for off-the-shelf speech
   recognition technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic caption alignment; Speech recognition; Off-the-shelf ASR
AB With a growing number of online videos, many producers feel the need to use video captions in order to expand content accessibility and face two main issues: production and alignment of the textual transcript. Both activities are expensive either for the high labor of human resources or for the employment of dedicated software. In this paper, we focus on caption alignment and we propose a novel, automatic, simple and low-cost mechanism that does not require human transcriptions or special dedicated software to align captions. Our mechanism uses a unique audio markup and intelligently introduces copies of it into the audio stream before giving it to an off-the-shelf automatic speech recognition (ASR) application; then it transforms the plain transcript produced by the ASR application into a timecoded transcript, which allows video players to know when to display every single caption while playing out the video. The experimental study evaluation shows that our proposal is effective in producing timecoded transcripts and therefore it can be helpful to expand video content accessibility.
C1 [Federico, Maria] Univ Modena & Reggio Emilia, Serv Accoglienza Studenti Disabili, Modena, Italy.
   [Furini, Marco] Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Reggio Emilia, Italy.
C3 Universita di Modena e Reggio Emilia; Universita di Modena e Reggio
   Emilia
RP Furini, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Reggio Emilia, Italy.
EM maria.federico@unimore.it; marco.furini@unimore.it
RI Furini, Marco/O-2867-2016
OI Furini, Marco/0000-0003-1094-6521
CR Canadian Association of Broadcasters, 2008, CABS CLOS CAPT MAN
   Federico Maria., 2012, P INT CROSS DISC C W, P40, DOI DOI 10.1145/2207016.2207053
   Furini M, 2008, IEEE T CONSUM ELECTR, V54, P513, DOI 10.1109/TCE.2008.4560123
   GARZA TJ, 1991, FOREIGN LANG ANN, V24, P239, DOI 10.1111/j.1944-9720.1991.tb00469.x
   Haubold A, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P224
   Hong R., 2010, Proceedings of the 18th ACM international conference on Multimedia, P421
   Huang C., 2003, TECHNICAL REPORT
   Jelinek Lewis M S, 2001, J Deaf Stud Deaf Educ, V6, P43
   Johnson K, 2011, ACOUSTIC AUDITORY PH
   Kemp T, 2000, INT CONF ACOUST SPEE, P1423, DOI 10.1109/ICASSP.2000.861862
   Kim SK, 2005, LECT NOTES COMPUT SC, V3568, P276
   Knight A, 2010, INT J MULTIMED DATA, V1, P1, DOI 10.4018/jmdem.2010040101
   Martone AF, 2004, PROC SPIE, V5307, P108
   Reager SE, 2009, STREAMING MEDIA IND, P100
   Shimogori N., 2010, P 3 INT C INT COLL I, P79
   Zhang XJ, 2007, IEEE T INF TECHNOL B, V11, P332, DOI 10.1109/TITB.2006.885549
NR 16
TC 19
Z9 19
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 21
EP 40
DI 10.1007/s11042-012-1318-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800002
DA 2024-07-18
ER

PT J
AU Su, QT
   Niu, YG
   Zou, HL
   Zhao, YS
   Yao, T
AF Su, Qingtang
   Niu, Yugang
   Zou, Hailin
   Zhao, Yongsheng
   Yao, Tao
TI A blind double color image watermarking algorithm based on QR
   decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR decomposition; Color watermark image; Blind extraction; Image
   watermarking
ID TRANSFORM
AB In this paper, a novel blind image watermarking scheme based on QR decomposition is proposed to embed color watermark image into color host image, which is significantly different from using the binary or gray image as watermark. When embedding watermark, the 24-bits color host image with size of 512 x 512 is divided into non-overlapping 4 x 4 pixel blocks and each pixel block is decomposed by QR. Then, according to the watermark information and the relation between the second row first column coefficient and the third row first column coefficient in the unitary matrix Q, the 24-bits color watermark image with size of 32 x 32 is embedded into the color host image. In addition, the new element compensatory method is used in the upper-triangle matrix R for reducing the visible distortion. When extracting watermark, only the watermarked image is needed. Compared with other SVD-based methods, the proposed method does not have the false-positive detection problem and has lower computational complexity, that is, the average running time of the proposed method only needs 1.481403 s. The experimental results show that the proposed method is robust against most common attacks including JPEG compression, JPEG 2000 compression, low-pass filtering, cropping, adding noise, blurring, rotation, scaling and sharpening et al. Compared with some related existing methods, the proposed algorithm has stronger robustness and better invisibility.
C1 [Su, Qingtang; Zou, Hailin; Zhao, Yongsheng; Yao, Tao] Lu Dong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
   [Su, Qingtang; Niu, Yugang] E China Univ Sci & Technol, Key Lab Adv Control & Optimizat Chem Proc, Minist Educ, Shanghai 200237, Peoples R China.
C3 Ludong University; East China University of Science & Technology
RP Su, QT (corresponding author), Lu Dong Univ, Sch Informat Sci & Engn, Yantai 264025, Shandong, Peoples R China.
EM sdytsqt@163.com
RI Su, Qingtang/P-4285-2017
FU NNSF from China [61074041, 61170161]; National Science and Technology
   Committee [2011BAD20B01]; Plan Project of Shandong Province Science and
   Technology Development Committee [2011YD01079]
FX The research was partially supported by NNSF from China (61074041,
   61170161), the 'Twelve Five-Year' plan major projects supported by
   National Science and Technology Committee (2011BAD20B01) and the Plan
   Project of Shandong Province Science and Technology Development
   Committee (2011YD01079). The authors would like to thank anonymous
   referees for their valuable comments and suggestions which lead to
   substantial improvements of this paper.
CR Ahn CJ, 2008, IEEE T VEH TECHNOL, V57, P2578, DOI 10.1109/TVT.2007.913179
   [Anonymous], 1992, RFC1321
   Bhatnagar G, 2012, COMPUT SECUR, V31, P40, DOI 10.1016/j.cose.2011.11.003
   Chen LF, 2010, OPT COMMUN, V283, P2043, DOI 10.1016/j.optcom.2010.01.009
   Chen W, 2009, OPT COMMUN, V282, P3680, DOI 10.1016/j.optcom.2009.06.014
   Chou CH, 2003, EURASIP J APPL SIG P, V2003, P32, DOI 10.1155/S1110865703211227
   DEMOOR B, 1992, SIAM J MATRIX ANAL A, V13, P993, DOI 10.1137/0613060
   Findik O, 2011, EXPERT SYST APPL, V38, P1942, DOI 10.1016/j.eswa.2010.07.126
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Li XH, 2000, IEEE T SIGNAL PROCES, V48, P60
   Mao L, 2011, MULTIMED TOOLS APPL, V52, P201, DOI 10.1007/s11042-010-0467-5
   Naderahmadian Yashar, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P127, DOI 10.1109/IIHMSP.2010.39
   Pei SC, 2010, IEEE INT CON MULTI, P122, DOI 10.1109/ICME.2010.5583883
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rawat S, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P206, DOI 10.1109/IADCC.2010.5423010
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2012, OPT COMMUN, V285, P1717, DOI 10.1016/j.optcom.2011.11.117
   Thorat CG, 2010, PROCEDIA COMPUT SCI, V2, P236, DOI 10.1016/j.procs.2010.11.030
   Tsolis DK, 2010, MULTIMED TOOLS APPL, V47, P581, DOI 10.1007/s11042-009-0338-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xing Y, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P3
   Yin CQ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P2607, DOI 10.1109/ICAL.2007.4339020
   Zhang YHP, 2009, METHODS MOL BIOL, V581, P213, DOI 10.1007/978-1-60761-214-8_14
NR 24
TC 47
Z9 49
U1 0
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 987
EP 1009
DI 10.1007/s11042-013-1653-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800045
DA 2024-07-18
ER

PT J
AU Wan, Z
   Xiong, NX
   Ghani, N
   Vasilakos, AV
   Zhou, L
AF Wan, Zheng
   Xiong, Naixue
   Ghani, Nasir
   Vasilakos, Athanasios V.
   Zhou, Liang
TI Adaptive unequal protection for wireless video transmission over IEEE
   802.11e networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive video transmission; Unequal protection; Fuzzy logic; IEEE
   802.11e; Cross layer
ID CROSS-LAYER DESIGN; SELECTION; MECHANISM
AB Packet loss of video streams cannot be avoided at wireless links for limited wireless bandwidth and frequently changed environments. To provide differentiated Quality of Service (QoS) guarantees between multimedia and data services, IEEE 802.11e was proposed. However, its performance and flexibility need to be further improved. In this paper, after a survey on various modifications of IEEE 802.11e, we formulate the problem of video transmission over IEEE 802.11e networks to help scheme design and performance analysis. Then accompanied with in-depth analysis, an adaptive unequal protection schema is proposed, which is composed of three mechanisms: (1) Insert each video packet into the access category (AC) with the minimum relative queuing delay; (2) Assign each packet dynamically to a proper AC based on several parameters to guarantee the transmission of high priority frames; (3) Apply fuzzy logic controllers to adjust parameters so as to reply quickly to the variation of video data rate, coding structure and network load. Finally, regarding MPEG-4 codec as the example, we perform extensive evaluations and validate the effectiveness and flexibility of proposed scheme. Simulations are divided into WLAN and multihop parts, involving different video sequences and various traffic modes of data streams. Beside performance comparison between proposed scheme and other ones, influence of parameter setting and combination with routing algorithms are also evaluated.
C1 [Wan, Zheng] Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
   [Xiong, Naixue] Colorado Tech Univ, Colorado Springs, CO USA.
   [Ghani, Nasir] Univ New Mexico, Albuquerque, NM 87131 USA.
   [Vasilakos, Athanasios V.] Kuwait Univ, Kuwait, Kuwait.
   [Zhou, Liang] Nanjing Univ Posts & Telecommun, Nanjing, Jiangsu, Peoples R China.
C3 Jiangxi University of Finance & Economics; Colorado Technical
   University; University of New Mexico; Kuwait University; Nanjing
   University of Posts & Telecommunications
RP Wan, Z (corresponding author), Jiangxi Univ Finance & Econ, Nanchang, Jiangxi, Peoples R China.
EM cloudcity66@yahoo.com.cn
RI vasilakos, athanasios/J-2824-2017; xiong, naixue/M-4277-2019
OI xiong, naixue/0000-0002-0394-4635; Vasilakos,
   Athanasios/0000-0003-1902-9877
FU National Natural Science Foundation of China [61162009, 60963011];
   Science and Technology Project of Jiangxi Education Department
   [GJJ12273]
FX This work was supported by National Natural Science Foundation of China
   (No. 61162009, No. 60963011), and Science and Technology Project of
   Jiangxi Education Department (No. GJJ12273).
CR American National Standard for Telecommunications, 2003, T1801031996 ANSI
   [Anonymous], COMM 2009 ICC 09 IEE
   Chen WT, 2008, IEEE WCNC, P3133
   Chen YS, 2011, J NETW COMPUT APPL, V34, P1566, DOI 10.1016/j.jnca.2010.08.012
   Cranley N, 2007, GLOB TELECOMM CONF, P2075
   Fiandrotti A, 2010, SIGNAL PROCESS-IMAGE, V25, P438, DOI 10.1016/j.image.2010.04.006
   Gan T, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P505, DOI 10.1109/ICME.2008.4607482
   Hsu JL, 2009, IEEE SIGNAL PROC LET, V16, P268, DOI 10.1109/LSP.2008.2010821
   IEEE, 2005, 80211E2005 IEEE
   Jansang A, 2011, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2011-158
   Kei CH, 2008, J INF SCI ENG, V24, P425
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Kompella S, 2009, IEEE ACM T NETWORK, V17, P212, DOI 10.1109/TNET.2008.925942
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Lai WP, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-59
   Li MD, 2011, J VIS COMMUN IMAGE R, V22, P284, DOI 10.1016/j.jvcir.2011.01.002
   Liao YT, 2011, IEEE T MULTIMEDIA, V13, P132, DOI 10.1109/TMM.2010.2089504
   Lin CH, 2009, TELECOMMUN SYST, V42, P223, DOI 10.1007/s11235-009-9182-9
   Lin CH, 2012, COMPUT NETW, V56, P2590, DOI 10.1016/j.comnet.2012.04.004
   Luo HY, 2009, IEEE T MULTIMEDIA, V11, P1362, DOI 10.1109/TMM.2009.2030639
   Qu Q, 2006, IEEE T MULTIMEDIA, V8, P1033, DOI 10.1109/TMM.2006.879840
   Shiang HP, 2007, IEEE J SEL AREA COMM, V25, P770, DOI 10.1109/JSAC.2007.070513
   Stuhlmüller K, 2000, IEEE J SEL AREA COMM, V18, P1012, DOI 10.1109/49.848253
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Wang H, 2012, PHYS LETT B, V707, P11, DOI 10.1016/j.physletb.2011.12.016
   Zhang Y, 2007, IEEE COMMUN LETT, V11, P498, DOI 10.1109/LCOMM.2007.062030
   Zheng Wan, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P180, DOI 10.1109/INFCOMW.2011.5928803
   Zhou L, 2010, IEEE J SEL AREA COMM, V28, P409, DOI 10.1109/JSAC.2010.100412
   Zhu XQ, 2005, SIGNAL PROCESS-IMAGE, V20, P773, DOI 10.1016/j.image.2005.05.005
NR 29
TC 57
Z9 57
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 541
EP 571
DI 10.1007/s11042-013-1378-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800025
DA 2024-07-18
ER

PT J
AU Saldana, J
   Fernández-Navajas, J
   Ruiz-Mas, J
   Viruete-Navarro, E
   Casadesus, L
AF Saldana, Jose
   Fernandez-Navajas, Julian
   Ruiz-Mas, Jose
   Viruete-Navarro, Eduardo
   Casadesus, Luis
TI Online FPS games: effect of router buffer and multiplexing techniques on
   subjective quality estimators
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaming; Delay; Multiplexing; Compressing; Measurement; Network games;
   Quality of Experience; First Person Shooter
ID ENTERTAINMENT
AB First Person Shooters are a genre of online games in which users demand a high interactivity, because the actions and the movements are very fast. They usually generate high rates of small packets which have to be delivered to the server within a deadline. When the traffic of a number of players shares the same link, these flows can be aggregated in order to save bandwidth. Certain multiplexing techniques are able to merge a number of packets, in a similar way to voice trunking, creating a bundle which is transmitted using a tunnel. In addition, the headers of the original packets can be compressed by means of standard algorithms. The characteristics of the buffers of the routers which deliver these bundled packets may have a strong influence on the network impairments (mainly delay, jitter and packet loss) which determine the quality of the game. A subjective quality estimator has been used in order to study the mutual influence of the buffer and multiplexing techniques. Taking into account that there exist buffers which size is measured in terms of bytes, and others measured in packets, both kinds of buffers have been tested, using different sizes. Traces from real game parties have been merged in order to obtain the traffic of 20 simultaneous players sharing the same Internet access. The delay and jitter produced by the buffer of the access router have been obtained using simulations. In general, the quality is expected to be reduced as the background traffic grows, but the results show an anomalous region in which the quality rises with the background traffic amount. Small buffers present better subjective quality results than bigger ones. When the total traffic amount gets above the available bandwidth, the buffers measured in bytes add to the packets a fixed delay, which grows with buffer size. They present a jitter peak when the offered traffic is roughly the link capacity. On the other hand, buffers which size is measured in packets add a smaller delay, but they increase packet loss for gaming traffic. The obtained results illustrate the need of knowing the characteristics of the buffer in order to make the correct decision about traffic multiplexing. As a conclusion, it would be interesting for game developers to identify the behaviour of the router buffer so as to adapt the traffic to it.
C1 [Saldana, Jose; Fernandez-Navajas, Julian; Ruiz-Mas, Jose; Viruete-Navarro, Eduardo; Casadesus, Luis] Univ Zaragoza, GTC, Aragon Inst Engn Res I3A, Dpt IEC,EINA, Zaragoza 50018, Spain.
C3 University of Zaragoza
RP Saldana, J (corresponding author), Univ Zaragoza, GTC, Aragon Inst Engn Res I3A, Dpt IEC,EINA, Ada Byron Building, Zaragoza 50018, Spain.
EM jsaldana@unizar.es; navajas@unizar.es; jruiz@unizar.es;
   eviruete@unizar.es; luis.casadesus@unizar.es
RI Navajas, Julián Fernández/K-1579-2014; Ruiz-Mas, Jose/K-9302-2014;
   Saldana, Jose/K-6595-2014
OI Navajas, Julián Fernández/0000-0002-5237-0447; Saldana,
   Jose/0000-0002-6977-6363
FU CPUFLIPI Project [MICINN TIN2010-17298]; MBACToIP Project, of Aragon I +
   D Agency and Ibercaja Obra Social; NDCIPI-QQoE Project of Catedra
   Telefonica, Univ. of Zaragoza
FX This work has been partially financed by CPUFLIPI Project (MICINN
   TIN2010-17298), MBACToIP Project, of Aragon I + D Agency and Ibercaja
   Obra Social, and NDCIPI-QQoE Project of Catedra Telefonica, Univ. of
   Zaragoza.
CR [Anonymous], 2007, 2007 2 INT C DIG TEL
   Appenzeller G, 2004, ACM SIGCOMM COMP COM, V34, P281, DOI 10.1145/1030194.1015499
   Batool SH, 2010, INFORM DEV, V26, P141, DOI 10.1177/0266666910366650
   Cooperative Association for Internet Data Analysis, COOP ASS INT DAT AN
   Dick M., 2005, NetGames'05, P1
   Dischinger M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P43
   Enachescu M, 2005, ACM SIGCOMM COMP COM, V35, P83, DOI 10.1145/1070873.1070886
   Feng WC, 2005, IEEE ACM T NETWORK, V13, P488, DOI 10.1109/TNET.2005.850221
   Furuholt Bjorn, 2008, International Information and Library Review, V40, P129, DOI 10.1016/j.iilr.2008.02.001
   Kaune S, 2009, EUROMICRO WORKSHOP P, P301, DOI [10.1109/.43, 10.1109/PDP.2009.44]
   KOREN T, 2003, 3545 RFC
   Nuaymi L, 2007, IEEE C WIR MOB COMP, P17
   Oliveira M., 2003, NETWORK SYSTEM SUPPO, P185
   Palazzi CE, 2006, IEEE T CONSUM ELECTR, V52, P1280, DOI 10.1109/TCE.2006.273146
   PAZHYANNUR R, 2001, 3153 RFC
   Pereira RM, 2009, ICDT: 2009 FOURTH INTERNATIONAL CONFERENCE ON DIGITAL TELECOMMUNICATIONS, P53, DOI 10.1109/ICDT.2009.17
   Saldana J, 2012, P IEEE ICC 2012 WORK
   Saldana J, 2011, P NEW TECHN MOB SEC
   Saldana J, 2011, P CCNC 2011 3 IEEE W, P1147
   Saldana J, 2011, IEEE COMMUN MAG, V49, P190, DOI 10.1109/MCOM.2011.6069728
   Saldana J, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL SYMPOSIUM ON PERFORMANCE EVALUATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, P253
   Saldana J, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL SYMPOSIUM ON PERFORMANCE EVALUATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, P227
   Schaefer C., 2002, Proc. ACM NetGames, P74
   Sevindik T., 2007, Telematics and Informatics, V24, P59, DOI 10.1016/j.tele.2005.12.004
   Sommers Joel, 2008, Performance Evaluation Review, V35, P40, DOI 10.1145/1364644.1364645
   Suznjevic M, 2011, P 4 INT C SIM TOOLS
   Sze HP, 2002, IEEE J SEL AREA COMM, V20, P1360, DOI 10.1109/JSAC.2002.802064
   Thompson B., 2005, 4170 RFC
   Trad A., 2003, 4929 INRIA
   Ubicom White Paper, 2005, OPSCORE ONL PLAYAB S
   VISHWANATH A, 2008, P IEEE IWQOS ENSCH N, P80
   Vishwanath A, 2009, IEEE INFOCOM 2009 BR
   Vishwanath A, 2009, ACM SIGCOMM COMP COM, V39, P34, DOI 10.1145/1517480.1517487
   Wattimena A. F., 2006, P 5 SIGCOMM WORKSH N
   Zander S., 2004, P AUSTR TELECOMMUNIC, P511
NR 35
TC 4
Z9 5
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1823
EP 1856
DI 10.1007/s11042-012-1309-4
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000038
DA 2024-07-18
ER

PT J
AU Yu, YS
   Cheng, JS
   Wei, ZH
   He, RH
AF Yu, Yongsheng
   Cheng, Jinshu
   Wei, Zhihua
   He, Ruhan
TI Image betrayal checking based on organization's watermarking in Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Betrayal checking; Digital fingerprint; Organization's watermarking;
   Trace betrayer
ID CODES
AB There is a growing need for confidential institutions to actively check the documents in Internet for detecting some leaked confidential images. This paper presents an efficient method of active image betrayal checking based on a new type of watermarking in addition to the user-specific fingerprint. The implemented organization's watermarking, as a 'fingerprint' for a group of staffs, with a codeword length far shorter than that of the user-specific fingerprint, is extracted from a suspected image at the first stage of betrayal checking, for the purpose of reducing the number of suspected images by a great deal. Then, only the remaining suspected images are subjected to the time-consuming user-specific fingerprint checking. Experimental tests confirmed the improved efficiency of this method.
C1 [Yu, Yongsheng; Cheng, Jinshu; Wei, Zhihua] Wuhan Univ Technol, Minist Educ, Green Bldg Mat & Mfg Engn Res Ctr, Wuhan 430070, Peoples R China.
   [He, Ruhan] Wuhan Text Univ, Coll Math & Comp Sci, Wuhan 430070, Peoples R China.
C3 Wuhan University of Technology; Wuhan Textile University
RP Yu, YS (corresponding author), Wuhan Univ Technol, Minist Educ, Green Bldg Mat & Mfg Engn Res Ctr, Wuhan 430070, Peoples R China.
EM yuyosh@hotmail.com; chengjinshu@whut.edu.cn; wgaodi@yahoo.com.cn;
   heruhan@gmail.com
FU National Natural Science Foundation of China [61170093]; China
   Postdoctoral Science Foundation [20110491149]
FX This paper is supported by National Natural Science Foundation of China
   (No.61170093) and China Postdoctoral Science Foundation
   (No.20110491149).
CR Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], P SPIE C MATH DAT IM
   [Anonymous], J SW JIAOTONG U
   [Anonymous], COUNTING NU IN PRESS
   [Anonymous], TR58598 PRINC U DEP
   [Anonymous], P FIN CRYPT
   Barg A, 2003, IEEE T INFORM THEORY, V49, P852, DOI 10.1109/TIT.2003.809570
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Cox IJ, 1998, IEEE J SEL AREA COMM, V16, P587, DOI 10.1109/49.668980
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fernandez M, 2002, LECT NOTES COMPUT SC, V2433, P459
   Hexmoor H, 2006, KNOWL ENG REV, V21, P127, DOI 10.1017/S0269888906000932
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Hu AF, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P1453, DOI 10.1109/ICYCS.2008.100
   Li GB, 2009, INT C COMP SUPP COOP, P107, DOI 10.1109/CSCWD.2009.4968043
   Li Z, 2005, IEEE ICC, P1336
   ORuanaidh JJK, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P536, DOI 10.1109/ICIP.1997.647968
   Piva A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P520, DOI 10.1109/ICIP.1997.647964
   Subashini S, 2011, J NETW COMPUT APPL, V34, P1, DOI 10.1016/j.jnca.2010.07.006
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang HJM, 1998, OPT EXPRESS, V3, P491, DOI 10.1364/OE.3.000491
   Wang ZJ, 2005, IEEE T IMAGE PROCESS, V14, P804, DOI 10.1109/TIP.2005.847284
   Yang WM, 2009, PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON EDUCATION TECHNOLOGY AND COMPUTER SCIENCE, VOL II, P899, DOI 10.1109/ETCS.2009.464
   Yixin Yan, 2009, 2009 IEEE International Workshop on Imaging Systems and Techniques (IST 2009), P377, DOI 10.1109/IST.2009.5071669
NR 26
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1249
EP 1262
DI 10.1007/s11042-012-1276-9
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000013
DA 2024-07-18
ER

PT J
AU Jeong, CH
   Choi, YS
   Chun, HW
   Song, SK
   Jung, H
   Lee, S
   Choi, SP
AF Jeong, Chang-Hoo
   Choi, Yun-Soo
   Chun, Hong-Woo
   Song, Sa-Kwang
   Jung, Hanmin
   Lee, Sangkwan
   Choi, Sung-Pil
TI Grid-based framework for high-performance processing of scientific
   knowledge
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scientific-knowledge processing; Grid computing; Workflow; Data mining
   framework; Text mining
AB An essential matter in the knowledge-based information society is how to extract useful information quickly from a large volume of literature. Since most existing data mining frameworks deal with structured input data, many limitations are faced in analyzing unstructured scientific literature and extracting new information. This study proposes a scientific-knowledge processing framework, which offers high performance by using grid computing technology for extracting important entities and their relations from the scientific literature. Since the grid computing provides a large volume of data storage and high-speed computing, the proposed framework can efficiently analyze the massive body of scientific literature and process knowledge. The workflow tool that we have developed for the proposed framework enables users to easily design and execute complicated applications that consist of complicated scientific-knowledge processes. The experimental results showed that the proposed framework reduced working time by approximately 83 % when the number of running nodes was assigned in accordance with the workload ratio of each step in scientific-knowledge processes. As a result, it is possible to effectively process a large volume of scientific literature by flexibly adjusting the number of computing nodes that constitute the grid environment as the number of documents for processing increases.
C1 [Jeong, Chang-Hoo; Choi, Yun-Soo; Chun, Hong-Woo; Song, Sa-Kwang; Jung, Hanmin; Choi, Sung-Pil] KISTI, Software Res Ctr, Taejon, South Korea.
   [Lee, Sangkwan] Catholic Univ Pusan, Dept Comp Engn, Pusan, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI); Catholic
   University Pusan
RP Choi, SP (corresponding author), KISTI, Software Res Ctr, 335 Gwahangno, Taejon, South Korea.
EM chjeong@kisti.re.kr; armian@kisti.re.kr; hw.chun@kisti.re.kr;
   esmallj@kisti.re.kr; jhm@kisti.re.kr; sklee@cup.ac.kr; sungpil@gmail.com
CR AlSairafi S, 2003, INT J HIGH PERFORM C, V17, P297, DOI 10.1177/1094342003173003
   Altintas I, 2004, 16TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, PROCEEDINGS, P423
   Brezany P, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P150, DOI 10.1109/WI.2005.68
   Choi S, 2010, P 23 INT C COMP LING
   Chun HW, 2011, COMM COM INF SC, V264, P269
   Congiusta A, 2008, J PARALLEL DISTR COM, V68, P3, DOI 10.1016/j.jpdc.2007.07.007
   Goble C., 2003, P UK E SCI PROGRAMME, P595
   Harrison A., 2007, INT J HIGH PERFORMAN
   Hull D, 2006, NUCLEIC ACIDS RES, V34, pW729, DOI 10.1093/nar/gkl320
   Le-Khac NA, 2006, ICSOFT 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON SOFTWARE AND DATA TECHNOLOGIES, VOL 2, P67
   Song SK, 2011, COMM COM INF SC, V264, P233
   Stankovski V, 2008, IEEE INTERNET COMPUT, V12, P69, DOI 10.1109/MIC.2008.122
   Talia D, 2007, P NAT SCI FDN S NEXT
   Talia D, 2008, CONCURR COMP-PRACT E, V20, P1933, DOI 10.1002/cpe.1311
   Talia D, 2010, COMMUN ACM, V53, P132, DOI 10.1145/1785414.1785451
NR 15
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 783
EP 798
DI 10.1007/s11042-013-1411-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400024
DA 2024-07-18
ER

PT J
AU Kim, J
   Kim, J
   Lee, D
   Chung, KY
AF Kim, Jonghun
   Kim, Jaekwon
   Lee, Daesung
   Chung, Kyung-Yong
TI Ontology driven interactive healthcare with wearable sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive health; Wearable sensors; Ontology; u-Healthcare Service
AB Ubiquitous healthcare is the service that offers health-related information and contents to users without any limitations of time and space. Especially, to offer customized services to users, the technology of acquiring context information of users in real time is the most important consideration. In this paper, we researched wearable sensors. We proposed the ontology driven interactive healthcare with wearable sensors (OdIH_WS) to achieve customized healthcare service. For this purpose, wearable-sensor-based smart-wear and methods of data acquisition and processing are being developed. The proposed system has potential value in healthcare. A smart wear using wearable sensors is fabricated as a way of non-tight and comfortable style fitting for the curves of the human body based on clothes to wear in daily life. The design sample of the smart wear uses basic stretch materials and is designed to sustain its wearable property. To offer related information, it establishes an environment-information-based healthcare ontology model needed for inference, and it is composed of inside-outside context information models depending on the users' context. The modeling of the proposed system involved combinations of information streams, focusing on service context information. With the proposed service inference rules, customized information and contents could be drawn by the inference engine. In the established OdIH_WS, real-time health information monitoring was achieved. The results of system performance and users' satisfaction evaluations confirmed that the proposed system is superior to other existing systems.
C1 [Kim, Jonghun] BIT Comp Co Ltd, U Healthcare Dept, Seoul, South Korea.
   [Kim, Jaekwon] Inha Univ, Sch Comp Sci & Engn, Inchon, South Korea.
   [Lee, Daesung] Catholic Univ Pusan, Dept Comp Engn, Pusan, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
C3 Inha University; Catholic University Pusan; Sangji University
RP Chung, KY (corresponding author), Sangji Univ, Sch Comp Informat Engn, Wonju, South Korea.
EM kimjh@bit.kr; jaekwonkorea@naver.com; xdilemma@naver.com;
   dragonhci@hanmail.net
RI Lee, Daesung/P-7946-2018; Chung, Kyungyong/JAC-2276-2023
OI Lee, Daesung/0000-0002-2435-6867; 
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education, Science and Technology [2012-0004478]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology (No. 2012-0004478). Sincere thanks go
   to Prof. Joong-Kyung Ryu who provided the idea for this thesis.
CR Cho HY, 2007, LECT NOTES COMPUT SC, V4551, P1070
   Cimiano P, 2006, ONTOLOGY LEARNING PO
   Dey A. K., 1998, Intelligent Environments. Papers from the 1998 AAAI Symposium, P51
   Gennari JH, 2003, INT J HUM-COMPUT ST, V58, P89, DOI 10.1016/S1071-5819(02)00127-1
   Han D, 2010, COMPUT METH PROG BIO, V97, P178, DOI 10.1016/j.cmpb.2009.08.004
   Jung KY, 2004, IEICE T INF SYST, VE87D, P2781
   Jung kyung-Yong, 2011, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V11, P14
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kim JH., 2011, Proc Int Conf Inf Sci Appl IEEE Comp Soc, P595
   Lee YD, 2009, SENSOR ACTUAT B-CHEM, V140, P390, DOI 10.1016/j.snb.2009.04.040
   Lim JE, 2009, IEEE T INF TECHNOL B, V13, P370, DOI 10.1109/TITB.2009.2013941
   Russell S., 2010, ARTIF INTELL, V3rd
   Ryu JK, 2011, P INT C INF SCI APPL, P116
   Ryu，Joong-Kyung, 2011, [The Journal of the Korea Contents Association, 한국콘텐츠학회 논문지], V11, P21
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Zhu Q, 2011, BMC BIOINFORMATICS, V12, P1
NR 16
TC 43
Z9 47
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 827
EP 841
DI 10.1007/s11042-012-1195-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400027
DA 2024-07-18
ER

PT J
AU Wang, SF
   Cai, Y
   Yu, ZL
   Cao, JJ
   Su, ZX
AF Wang, Shengfa
   Cai, Yu
   Yu, Zhiling
   Cao, Junjie
   Su, Zhixun
TI Normal-controlled coordinates based feature-preserving mesh editing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Differential coordinates; Normal-controlled coordinates; Editing;
   Reconstruction
ID DEFORMATION
AB As a local shape descriptor, normal-controlled coordinates (NCC) are well defined on the boundary vertices of open meshes, and proven being always parallel with the corresponding vertex normals, which means no tangential drift appears in various editing operations. These two properties make NCC outperform the previous differential coordinates in many mesh processing jobs. We develop an implicit editing algorithm based on NCC, which is efficient by subtly using vertex normals. In addition, by exploring the relationship between NCC and the normals of triangular faces, we present a linear method based on NCC to reconstruct a mesh from predefined face normals. It provides another convenient way that users can operate face normals to edit models. Experiments show that NCC perform better than the previous differential coordinates in both effectiveness and efficiency.
C1 [Wang, Shengfa] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
   [Wang, Shengfa] Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
   [Cai, Yu; Cao, Junjie; Su, Zhixun] Dalian Univ Technol, Sch Math Sci, Dalian, Liaoning, Peoples R China.
   [Yu, Zhiling] Nankai Univ, Sch Math Sci, Tianjin 300071, Peoples R China.
   [Cai, Yu] Nankai Univ, LPMC, Tianjin 300071, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology; Nankai University; Nankai University
RP Wang, SF (corresponding author), Dalian Univ Technol, Sch Software Technol, Dalian, Peoples R China.
EM shengfawang@gmail.com
FU Fundamental Research Fund for the Central Universities; National Natural
   Science Foundation of China - Guangdong Joint Fund grant [U0935004];
   National Natural Science Foundation of China [60873181, 91230103,
   61190120, 61190121, 61190125]; State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University
FX We are grateful to the anonymous reviewers in the Lab of Computational
   Geometry, Graphics and Image for their valuable comments and
   suggestions. This research is supported in part by the Fundamental
   Research Fund for the Central Universities, National Natural Science
   Foundation of China - Guangdong Joint Fund grant U0935004, National
   Natural Science Foundation of China grant 60873181, 91230103, 61190120,
   61190121 and 61190125, and the State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University.
CR Alexa M, 2003, VISUAL COMPUT, V19, P105, DOI 10.1007/s00371-002-0180-0
   Alexa M, 2002, COMPUT GRAPH FORUM, V21, P173, DOI 10.1111/1467-8659.00575
   Au O, 2005, EUR S GEOM PROC COMP
   Au OKC, 2006, IEEE T VIS COMPUT GR, V12, P386, DOI 10.1109/TVCG.2006.47
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Du HX, 2007, IEEE T VIS COMPUT GR, V13, P549, DOI 10.1109/TVCG.2007.1004
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Fu HB, 2007, COMPUT GRAPH FORUM, V26, P34, DOI 10.1111/j.1467-8659.2007.00940.x
   Hildebrandt K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019638
   Huang J, 2006, ACM T GRAPHIC, V25, P1126, DOI 10.1145/1141911.1142003
   Jin SS, 2005, VISUAL COMPUT, V21, P71, DOI 10.1007/s00371-004-0271-1
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Kilian M, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239515, 10.1145/1276377.1276457]
   Kraevoy Vladislav., 2006, International Journal of Shape Modeling, V12, P29
   Lipman Y, 2005, ACM T GRAPHIC, V24, P479, DOI 10.1145/1073204.1073217
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Sheffer A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P68
   Sheng B, 2013, MULTIMED TOOLS APPL, V62, P581, DOI 10.1007/s11042-011-0860-8
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Sorkine O., 2004, P 2004 EUR ACM SIGGR, P179
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   SUN X., 2007, ACM S SOLID PHYS MOD, P11
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Wan XM, 2012, MULTIMED TOOLS APPL, V58, P109, DOI 10.1007/s11042-010-0688-7
   Wang SF, 2011, VISUAL COMPUT, V27, P429, DOI 10.1007/s00371-011-0582-y
   Xu D, 2006, VISUAL COMPUT, V22, P493, DOI 10.1007/s00371-006-0024-4
   Xu WW, 2009, J COMPUT SCI TECH-CH, V24, P6, DOI 10.1007/s11390-009-9209-4
   Yagou H, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P28, DOI 10.1109/CGI.2003.1214444
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
NR 35
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 607
EP 622
DI 10.1007/s11042-013-1517-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400013
DA 2024-07-18
ER

PT J
AU Poulisse, GJ
   Patsis, Y
   Moens, MF
AF Poulisse, Gert-Jan
   Patsis, Yorgos
   Moens, Marie-Francine
TI Unsupervised scene detection and commentator building using multi-modal
   chains
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic event detection; Feature extraction; Multi-modal scene
   segmentation; Video summarization
ID VIDEO; TEXT
AB This paper presents a novel unsupervised method for identifying the semantic structure in long semi-structured video streams. We identify chains, i.e., local clusters of repeated features from both the video stream and audio transcripts. Each chain serves as an indicator that the temporal interval it demarcates is part of the same semantic event. By layering all the chains over each other, dense regions emerge from the overlapping chains, from which we can identify the semantic structure of the video. We present two clustering strategies that accomplish this task, and compare them against a baseline Scene Transition Graph approach. We then develop a commentator that provides a semantic labeling of the resultant video segmentation.
C1 [Poulisse, Gert-Jan; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.
   [Patsis, Yorgos] IBBT, Ghent, Belgium.
   [Patsis, Yorgos] Vrije Univ Brussel, ETRO DSSP, Brussels, Belgium.
C3 KU Leuven; Vrije Universiteit Brussel
RP Poulisse, GJ (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Louvain, Belgium.
EM Gert-Jan.Poulisse@cs.kuleuven.be; gpatsis@etro.vub.ac.be;
   Marie-Francine.Moens@cs.kuleuven.be
RI Moens, Marie-Francine/B-8378-2014
FU IWT-SBO project AMASS++ (Advanced Multimedia Alignment and Structured
   Summarization) [IWT 060051]; TOSCA-MP (Task-oriented search and content
   annotation for media production) [FP7-ICT 287532]
FX The work reported is supported by IWT-SBO project AMASS++ (Advanced
   Multimedia Alignment and Structured Summarization, IWT 060051) and
   TOSCA-MP (Task-oriented search and content annotation for media
   production, FP7-ICT 287532).
CR Amir A, 2004, P TRECVID
   [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631383
   [Anonymous], 2006, IEEE COMP SOC C COMP
   Babaguchi N, 2003, P INT C VID PROC
   Benini S, 2006, P INT C IM PROC
   Bertini M, 2005, MULTIMED TOOLS APPL, V27, P215, DOI 10.1007/s11042-005-2575-1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Finkel J.R., 2005, P ACL
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Liu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32135
   Nastase V., 2008, P AAAI
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Nitta N., 2002, Multimedia information systems, P110
   Patsis Y, 2008, INT WORKSHOP DATABAS, P585, DOI 10.1109/DEXA.2008.104
   Poulisse GJ, 2010, MULTIMED TOOLS APPL, V48, P3, DOI 10.1007/s11042-009-0358-9
   Poulisse GJ, 2010, P CBMI, P103
   Quenot G, 2004, P TRECVID
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Skorochod'ko E. F., 1972, Information Processing 71 Proceedings of the IFIP Congress 1971. Volume 2, P1179
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   XU C, 2006, P ACM MULT
   Xu CS, 2008, IEEE T MULTIMEDIA, V10, P1342, DOI 10.1109/TMM.2008.2004912
   Xu M, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352015
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
NR 27
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 159
EP 175
DI 10.1007/s11042-012-1086-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sadallah, M
   Aubert, O
   Prié, Y
AF Sadallah, Madjid
   Aubert, Olivier
   Prie, Yannick
TI CHM: an annotation- and component-based hypervideo model for the Web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Annotation; Advene; CHM; Hypervideo; Component; Time and
   synchronization; WebCHM
AB Hypervideos are hypermedia documents that focus on video content. While they have long been deployed using specialized software or even hardware, the Web now offers a ground for them to fit into standardized languages and implementations. However, hypervideo design also currently uses very specific models limited to a single class of documents, or very generic hypermedia models that may not appropriately express their specific features. In this article we describe such features, and we introduce CHM, an annotation-driven and component-based model to conceptualize hypervideos through a high level operational specification. An extensible set of high level components is defined to emphasize the presentation and interaction features modeling, while lower level components offer more flexibility and customization opportunities. Being annotation-based, the model promotes a clear separation between video content/metadata and their various potential presentations. We also describe WebCHM, an implementation of CHM with standard Web technologies that provides a general framework to experiment with hypervideos on the Web. Two examples are provided as well as a preliminary usage study of the model and its implementation to validate our claims and proposals.
C1 [Sadallah, Madjid] DTISI CERIST, Algiers, Algeria.
   [Aubert, Olivier; Prie, Yannick] Univ Lyon 1, CNRS, LIRIS, UMR5205, F-69622 Villeurbanne, France.
C3 Centre de Recherche sur l'Information Scientifique et Technique
   (CERIST); Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1; Centre National de la Recherche
   Scientifique (CNRS)
RP Aubert, O (corresponding author), Univ Lyon 1, CNRS, LIRIS, UMR5205, F-69622 Villeurbanne, France.
EM msadallah@mail.cerist.dz; olivier.aubert@liris.cnrs.fr;
   yannick.prie@liris.cnrs.fr
RI Prié, Yannick/JMP-3627-2023; Prié, Yannick/AAM-5273-2020; SADALLAH,
   Madjid/CAJ-2742-2022; SADALLAH, Madjid/G-7116-2012
OI Prié, Yannick/0000-0002-7068-0836; SADALLAH, Madjid/0000-0001-9118-0235;
   Aubert, Olivier/0000-0001-8204-1567
FU French FUI (Fonds Unique Interministeriel) CineCast project; Algerian
   Research Center on Scientific and Technical Information (CERIST)
FX This work has been partially funded by the French FUI (Fonds Unique
   Interministeriel) CineCast project. It is supported by the Algerian
   Research Center on Scientific and Technical Information (CERIST).
CR Alisi T, 2009, P 17 ACM INT C MULT, P965
   America ME, 2000, D91 SECURESCM
   [Anonymous], P 2006 ACM S DOC ENG
   AUBERT O., 2005, P 16 ACM C HYPERTEXT, P235
   Barisic A., Proceedings of the 3rd ACM SIGPLAN workshop on Evaluation and usability of programming languages and tools (PLATEAU) at SPLASH. PLATEAU '11 (2011), P65, DOI DOI 10.1145/2089155.2089170
   Bove VM, 2000, IBM SYST J, V39, P470, DOI 10.1147/sj.393.0470
   Bulterman Dick., 2008, SYNCHRONIZED MULTIME, p3.0
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Casanova M. A., 1991, Third ACM Conference on Hypertext Proceedings, P193, DOI 10.1145/122974.122993
   Cazenave F, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P43
   Chambel T, 2004, IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P345, DOI 10.1109/ICALT.2004.1357433
   CHAMBEL T., 2002, P 13 ACM C HYPERTEXT, P85
   Chambel T, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Daniels Jeremy, 2007, J Clin Monit Comput, V21, P323, DOI 10.1007/s10877-007-9091-y
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   FAGA R, 2010, 10 ACM S DOC ENG, P17
   Finke M, 2004, IST200137365 MUMMY P
   Geurts JPTM, 2010, THESIS TU EINDHOVEN
   GIRGENSOHN A., 2004, P WORKING C ADV VISU, P290, DOI [10.1145/989863.989913, DOI 10.1145/989863.989913]
   GUIMARAES RL, 2010, 10 ACM S DOC ENG, P27
   HALASZ F, 1994, COMMUN ACM, V37, P30, DOI 10.1145/175235.175237
   Hammoud RI, 2006, SIG COM TEC, P3
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   Hoffmann P, 2008, LECT NOTES COMPUT SC, V5066, P51
   ISO (International Organization for Standardization), 1998, ERG REQ OFF WORK 11
   Jansen J, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P87
   Jansen J, 2009, MULTIMED TOOLS APPL, V43, P203, DOI 10.1007/s11042-009-0270-3
   Kipp M., 2001, Proceedings of the European Conference on Speech Communication and Technology, P1367
   Kokkoras F, 2002, MULTIMEDIA SYST, V8, P328, DOI 10.1007/s005300200054
   Li Jun, 2010, INT J DIGITAL CONTEN, V4, P74, DOI DOI 10.4156/JDCTA.VOL4.ISSUE5.8.
   Likert R., 1932, ARCH PSYCHOL, V140, P53
   Lippman A., 1980, Computer Graphics, V14, P32, DOI 10.1145/965105.807465
   Meixner B., 2010, Proceedings of the 18th ACM international conference on Multimedia, P1563, DOI [https://doi.org/10.1145/1873951.1874287, DOI 10.1145/1873951.1874287]
   Memon Q. A., 2003, Malaysian Journal of Computer Science, V16, P73
   Miller G., 2011, Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, CHI EA'11, P1141
   Morales M, 2001, THESIS ISFSC SAINT L
   Mujacic S, 2012, MULTIMED TOOLS APPL, V58, P435, DOI 10.1007/s11042-010-0665-1
   Navarrete T., 2002, Proc. of the Conf. on geographic information science, P1
   Nelson T.H., 1987, Computer lib: Dream machines
   Nelson Theodor Holm, 1965, Proceedings of the 1965 20th National Conference. ACM'65, P84, DOI [DOI 10.1145/800197.806036(CIT.ONP.169, 10.1145/800197.806036, DOI 10.1145/800197.806036]
   Olivier M.S., 2009, INFORM TECHNOLOGY RE
   Pollone M, 2002, EL IM VIS ARTS C FLO
   Roisin C, 1998, LECT NOTES COMPUT SC, V1521, P222
   Sadallah M, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P53
   Sawhney N., 1996, Seventh ACM Conference on Hypertext. Hypertext '96, P1, DOI 10.1145/234828.234829
   SHIPMAN F, 2003, P 14 ACM C HYP HYP, P124
   Shipman F., 2003, P 11 ACM INT C MULT, P392, DOI DOI 10.1145/957013.957096
   Silva Heron V. O., 2004, P ACM S DOC ENG, P188, DOI 10.1145/1030397.1030433
   Soares LFG, 2005, D91 SECURESCM
   Tiellet C., 2010, P 21 ACM C HYPERTEXT, DOI DOI 10.1145/1810617.1810656
   Vendrig J, 2003, IEEE MULTIMEDIA, V10, P30, DOI 10.1109/MMUL.2003.1218254
   Zahn C, 2004, LEARN INSTR, V14, P275, DOI 10.1016/j.learninstruc.2004.06.004
   Zoller P, 2001, INFORMATION MODELING IN THE NEW MILLENNIUM, P383
NR 53
TC 10
Z9 11
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 869
EP 903
DI 10.1007/s11042-012-1177-y
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900015
DA 2024-07-18
ER

PT J
AU Yang, B
   Xu, DQ
AF Yang, Bing
   Xu, Duanqing
TI Color boosted visual saliency detection and its application to image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency detection; Color boosted algorithm; Regional contrast;
   Image classification
ID ATTENTION; MODEL
AB For many applications in graphics, design and human computer interaction, it is essential to reliably estimate the visual saliency of images. In this paper, we propose a visual saliency detection method that combines the respective merits of color saliency boosting and global region based contrast schemes to achieve more accurate saliency maps. Our method is compared with existing saliency detection methods when evaluated using four public available datasets. Experimental results show that our method consistently outperformed current state-of-the-art methods on predicting human fixations. We also demonstrate how the extracted saliency map can be used for image classification.
C1 [Yang, Bing; Xu, Duanqing] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Xu, DQ (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Peoples R China.
EM ybily061821@126.com; xdq@cs.zju.edu.cn
OI yang, bing/0000-0002-0585-0579
FU National Program on Key Basic Research Project (973 Program)
   [2012CB725305]; National Key Technology R&D Program of China
   [2012BAH03F02]
FX This work was supported by National Program on Key Basic Research
   Project (973 Program), under Grant No. 2012CB725305 and by The National
   Key Technology R&D Program of China, under Grant No. 2012BAH03F02.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], ACM T GRAPH
   [Anonymous], 2008, P INT C NEUR INF PRO
   Barrington L, 2008, J VISION, V8, DOI 10.1167/8.14.17
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Butko NJ, 2008, IEEE INT CONF ROBOT, P2398, DOI 10.1109/ROBOT.2008.4543572
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chikkerur S, 2010, VISION RES, V50, P2233, DOI 10.1016/j.visres.2010.05.013
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Dale R, 2003, P ACSC2003, V16, P1
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guraya FFE, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P508, DOI 10.1109/DCABES.2010.160
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Khan FS, 2009, IEEE I CONF COMP VIS, P979, DOI 10.1109/ICCV.2009.5459362
   Koene AR, 2007, J VISION, V7, DOI 10.1167/7.7.6
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Stottinger Julian, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204286
   Suzuki M, 2006, 2006 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES,VOLS 1-3, P1
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   van der Linde I, 2009, SPATIAL VISION, V22, P161, DOI 10.1163/156856809787465636
   Vigo DAR, 2010, P CGIV
   Wolfe J. M., 2007, INTEGRATED MODELS CO, P99, DOI [10.1093/acprof:oso/9780195189193.003.0008, DOI 10.1093/ACPROF:OSO/9780195189193.003.0008]
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 46
TC 2
Z9 4
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2014
VL 69
IS 3
BP 877
EP 896
DI 10.1007/s11042-012-1148-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AD4HM
UT WOS:000333209300015
DA 2024-07-18
ER

PT J
AU Acelas, P
   Arce, P
   Guerri, JC
   Castellanos, W
AF Acelas, P.
   Arce, P.
   Guerri, J. C.
   Castellanos, W.
TI Evaluation of the MDC and FEC over the quality of service and quality of
   experience for video distribution in ad hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ad hoc networks; Video streaming; Multiple description coding; Forward
   error correction; Quality of service; Quality of experience
ID TRANSMISSION
AB Mobile ad hoc networks (MANETs) offer an excellent scenario for deploying communication applications because of the connectivity and versatility of this kind of networks. In contrast, the topology is usually extremely dynamic causing high rate of packet loss, so that ensuring a specific Quality of Service (QoS) for real-time video services becomes a hard challenge. In this paper, we evaluate the effect of using Multiple Description Coding (MDC) and Forward Error Correction (FEC) techniques for improving video quality in a multimedia content distribution system. A hybrid architecture using fixed and wireless ad hoc networks is proposed, which enables the use of multipoint-to-point transmission. MDC and FEC mechanisms can be combined with multipath transmission to increase the network efficiency and recover lost packets, improving the overall Quality of Experience (QoE) of the receiver. Simulations have been analyzed paying attention to objective parameters (Peak Signal to Noise Ratio, Packet Delivery Ratio, Decodable Frame Rate and interruptions) and subjective parameters. Results show that MDC increases the probability of packet delivery and FEC is able to recover lost frames and reduce video interruptions in moderate mobility scenarios, resulting in the improvement of video quality and the final user experience.
C1 [Acelas, P.; Arce, P.; Guerri, J. C.; Castellanos, W.] Univ Politecn Valencia, ITEAM Inst, Multimedia Commun Grp, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia
RP Acelas, P (corresponding author), Univ Politecn Valencia, ITEAM Inst, Multimedia Commun Grp, Valencia 46022, Spain.
EM patacdel@iteam.upv.es; paarvi@iteam.upv.es; jcguerri@dcom.upv.es;
   wilcashe@upv.es
RI Arce, Pedro/L-1268-2014; Guerri, Juan Carlos/K-9659-2014
OI Castellanos, Wilder/0000-0003-0311-492X; Arce, Pau/0000-0001-5726-9228;
   Guerri, Juan Carlos/0000-0002-5807-1923
FU Spanish Ministry of Education and Science [TEC2007- 68119-C02-01/TCM]
FX This work was supported by project MIQUEL (TEC2007- 68119-C02-01/TCM) of
   the Spanish Ministry of Education and Science. The authors would like to
   thank the Editor and the reviewers for helpful suggestions to improve
   the quality of this paper.
CR [Anonymous], 2007, 5109 RFC
   [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], DEF QUAL EXP QOE
   Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   Boukerche A., 2009, ALGORITHMS PROTOCOLS
   Chow CO, 2007, COMPUT COMMUN, V30, P1754, DOI 10.1016/j.comcom.2007.02.004
   Clausen T., 2003, RFC 3626
   CORRIE BH, 2003, 3 ANN WORKSH ADV COL
   Gabrielyan E, 2006, P INT C DIG TEL ICDT, P65
   Gandikota VR, 2008, IEEE T MOBILE COMPUT, V7, P1184, DOI 10.1109/TMC.2008.42
   Gharavi H, 2008, INT C TEL 2008 ICT 2, P1
   Grega Michal, 2008, Przeglad Telekomunikacyjny + Wiadomosci Telekomunicayjne, V81, P142
   Hsieh MY, 2007, MULTIMED TOOLS APPL, V34, P155, DOI 10.1007/s11042-006-0086-3
   *ITU T, 2000, P910 ITUT
   Kao KL, 2006, IEEE REG 10 C, P1
   KE C, 2006, P IEEE INT C SENS NE
   Keisuke Utsu, 2008, Transactions of the Institute of Electrical Engineers of Japan, Part C, V128, P1431, DOI 10.1541/ieejeiss.128.1431
   Kilkki K, 2008, J UNIVERS COMPUT SCI, V14, P615
   Li J, 2001, 7 ANN INT C MOB COMP, P16
   Liao YT, 2011, IEEE T MULTIMEDIA, V13, P132, DOI 10.1109/TMM.2010.2089504
   Lindeberg M, 2011, MULTIMEDIA SYST, V17, P51, DOI 10.1007/s00530-010-0187-8
   Mao SW, 2003, IEEE J SEL AREA COMM, V21, P1721, DOI 10.1109/JSAC.2003.815965
   Ni P, 2009, OPTIMAL QUALITY EXPE
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rong B, 2010, IEEE J SEL AREA COMM, V28, P321, DOI 10.1109/JSAC.2010.100404
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schierl T, 2006, IEEE WIREL COMMUN, V13, P96, DOI 10.1109/WC-M.2006.250365
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei W, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1379, DOI 10.1109/ICME.2004.1394487
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xunqi Y, 2005, P IEEE INT C IM PROC, V2, P177
   Zink M, 2005, IEEE T MULTIMEDIA, V7, P75, DOI 10.1109/TMM.2004.840595
NR 33
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 969
EP 989
DI 10.1007/s11042-012-1111-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000022
OA Green Published
DA 2024-07-18
ER

PT J
AU Nin, J
   Tous, R
   Delgado, J
AF Nin, Jordi
   Tous, Ruben
   Delgado, Jaime
TI Variable linkage for multimedia metadata schema matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metadata integration; Image tagging; Variable integration; Schema
   matching; Record linkage
ID RECORD-LINKAGE; OPERATORS
AB Today there are many media sharing applications that use diverse metadata formats to describe media resources. This leads to interoperability issues in cataloguing, searching and annotation. This situation poses schema matching algorithms in the eye of the storm of metadata interoperability. In this paper we present two different solutions for multimedia metadata schema matching using variable linkage algorithms. These methods consist in directly comparing the data values stored in the different metadata variables, allowing to overcome the inherent limitations of schema-level matching approaches. We show the feasibility of these methods through some experiments with real metadata information extracted from the image hosting websites Deviantart, Flickr and Picasa.
C1 [Nin, Jordi; Tous, Ruben; Delgado, Jaime] Univ Politecn Cataluna, Dept Arquitectura Computadors, Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Nin, J (corresponding author), Univ Politecn Cataluna, Dept Arquitectura Computadors, Barcelona, Spain.
EM nin@ac.upc.edu; rtous@ac.upc.edu; jaime.delgado@ac.upc.edu
RI Nin, Jordi/AGR-6980-2022; Delgado, Jaime/AAA-8489-2019; Nin,
   Jordi/Y-4824-2019; Tous, Ruben/N-5610-2014
OI Nin, Jordi/0000-0002-9659-2762; Delgado, Jaime/0000-0003-1366-663X; Nin,
   Jordi/0000-0002-9659-2762; Tous, Ruben/0000-0002-1409-5843
FU Spanish government [TEC2008-06692-C02-01]; ARES CONSOLIDER INGENIO
   [CSD2007-00004]
FX This work has been partly supported by the Spanish government
   TEC2008-06692-C02-01 and ARES CONSOLIDER INGENIO 2010 CSD2007-00004.
CR [Anonymous], 1936, P NATL I SCI INDIA
   BERLIN J, 2002, LNCS, V2348, P452
   BOUYSSOU D, 2011, INT SERIES OPERATION, V86
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   DOELLER M, 2010, P 2010 ACM S APPL CO, P880
   Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581
   EUZENAT J, 2007, ONTOLOGY MATCHING DA
   Herranz J, 2011, IEEE T KNOWL DATA EN, V23, P1541, DOI 10.1109/TKDE.2010.190
   JARO MA, 1989, J AM STAT ASSOC, V84, P414, DOI 10.2307/2289924
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   Mitchell T. M., 1997, MACHINE LEARNING
   Nin J, 2009, INFORM SCIENCES, V179, P1663, DOI 10.1016/j.ins.2009.01.024
   RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.2307/2335739
   SELIGMAN L, 2010, ACM INT C MAN DAT SI, P1057
   Shvaiko P, 2005, LECT NOTES COMPUT SC, V3730, P146
   Torra V, 2004, IEEE T FUZZY SYST, V12, P652, DOI 10.1109/TFUZZ.2004.834814
   Torra V, 2007, Modeling Decisions: Information Fusion and Aggregation Operators
   Torra V, 2008, INT J INTELL SYST, V23, P715, DOI 10.1002/int.20293
   TOUS R, 2011, LECT NOTES COMPUTER, V6861, P234
   Tous R, 2009, PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, P246, DOI 10.1109/DEXA.2009.53
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Witten I. H., 2005, DATA MINING PRACTICA
   YAGER RR, 1988, IEEE T SYST MAN CYB, V18, P183, DOI 10.1109/21.87068
NR 23
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 845
EP 861
DI 10.1007/s11042-012-1094-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000016
DA 2024-07-18
ER

PT J
AU Zhang, P
   Zhang, YN
   Thomas, T
   Emmanuel, S
AF Zhang, Peng
   Zhang, Yanning
   Thomas, Tony
   Emmanuel, Sabu
TI Moving people tracking with detection by latent semantic analysis for
   visual surveillance applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking; Latent semantic analysis; Detection; Visual surveillance
ID SCALE
AB The latent semantic analysis (LSA) has been widely used in the fields of computer vision and pattern recognition. Most of the existing works based on LSA focus on behavior recognition and motion classification. In the applications of visual surveillance, accurate tracking of the moving people in surveillance scenes, is regarded as one of the preliminary requirement for other tasks such as object recognition or segmentation. However, accurate tracking is extremely hard under challenging surveillance scenes where similarity among multiple objects or occlusion among multiple objects occurs. Usual temporal Markov chain based tracking algorithms suffer from the 'tracking error accumulation problem'. The accumulated errors can finally make the tracking to drift from the target. To handle the problem of tracking drift, some authors have proposed the idea of using detection along with tracking as an effective solution. However, many of the critical issues still remain unsettled in these detection based tracking algorithms. In this paper, we propose a novel moving people tracking with detection based on (probabilistic) LSA. By employing a novel 'twin-pipeline' training framework to find the latent semantic topics of 'moving people', the proposed detection can effectively detect the interest points on moving people in different indoor and outdoor environments with camera motion. Since the detected interest points on different body parts can be used to locate the position of moving people more accurately, by combining the detection with incremental subspace learning based tracking, the proposed algorithms resolves the problem of tracking drift during each target appearance update process. In addition, due to the time independent processing mechanism of detection, the proposed method is also able to handle the error accumulation problem. The detection can calibrate the tracking errors during updating of each state of the tracking algorithm. Extensive, experiments on various surveillance environments using different benchmark datasets have proved the accuracy and robustness of the proposed tracking algorithm. Further, the experimental comparison results clearly show that the proposed tracking algorithm outperforms the well known tracking algorithms such as ISL, AMS and WSL algorithms. Furthermore, the speed performance of the proposed method is also satisfactory for realistic surveillance applications.
C1 [Zhang, Peng; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Thomas, Tony] Indian Inst Informat Technol & Management, Gwalior, Madhya Pradesh, India.
   [Emmanuel, Sabu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Northwestern Polytechnical University; ABV-Indian Institute of
   Information Technology & Management, Gwalior; Nanyang Technological
   University
RP Zhang, P (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM zh0036ng@nwpu.edu.cn; ynzhang@nwpu.edu.cn; tonykallivayalil@gmail.com;
   asemmanuel@ntu.edu.sg
RI Zhang, Penghui/HGB-7353-2022; Emmanuel, Sabu/A-3690-2011; zhang,
   yueqi/JXM-4287-2024
OI Zhang, Penghui/0000-0002-9518-7079; Thomas, Tony/0000-0002-9323-6607
CR Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Benfold B, 2011, PROC CVPR IEEE
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Collins RT, 2003, IEEE C COMP VIS PATT
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   David B, 2006, J MACHINE LEARNING R, V4-5, P993
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fabrice S, 2004, INT C IM VID RETR CI
   Grabner H, 2008, EUR C COMP VIS ECCV
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hohl L, 2004, INT C IM PROC ICIP
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   Liu D, 2006, IEEE C COMP VIS PATT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Miller A, 2007, IEEE INT C MULT EXP
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Rodriguez M, 2011, IEEE C COMP VIS PATT
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P, 2007, ACM MULT C ACM MM
   Shu-Fai W, 2007, IEEE INT C COMP VIS
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 33
TC 6
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 991
EP 1021
DI 10.1007/s11042-012-1110-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000023
DA 2024-07-18
ER

PT J
AU Lloret, J
   Canovas, A
   Rodrigues, JJPC
   Lin, K
AF Lloret, Jaime
   Canovas, Alejandro
   Rodrigues, Joel J. P. C.
   Lin, Kai
TI A network algorithm for 3D/2D IPTV distribution using WiMAX and WLAN
   technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; WiMAX; WLAN; Wireless access network
ID WIRELESS MESH NETWORKS
AB The appearance of new broadband wireless technologies jointly with the ability to offer enough quality of service to provide IPTV over them, have made possible the mobility and ubiquity of any type of device to access the IPTV network. The minimum bandwidth required in the access network to provide appropriate quality 3D/2D IPTV services jointly with the need to guarantee the Quality of Experience (QoE) to the end user, makes the need of algorithms that should be able to combine different wireless standards and technologies. In this paper, we propose a network algorithm that manages the IPTV access network and decides which type of wireless technology the customers should connect with when using multiband devices, depending on the requirements of the IPTV client device, the available networks, and some network parameters (such as the number of loss packets and packet delay), to provide the maximum QoE to the customer. The measurements taken in a real environment from several wireless networks allow us to know the performance of the proposed system when it selects each one of them. The measurements taken from a test bench demonstrate the success of our system.
C1 [Lloret, Jaime; Canovas, Alejandro] Univ Politecn Valencia, Integrated Management Coastal Res Inst, E-46071 Valencia, Spain.
   [Rodrigues, Joel J. P. C.] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
   [Lin, Kai] Dalian Univ Technol, Sch Comp Sci & Engn, Dalian, Peoples R China.
C3 Universitat Politecnica de Valencia; Universidade da Beira Interior;
   Dalian University of Technology
RP Rodrigues, JJPC (corresponding author), Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
EM jlloret@dcom.upv.es; alcasol@posgrado.upv.es; joeljr@ieee.org;
   link@dlut.edu.cn
RI Rodrigues, Joel J. P. C./A-8103-2013; lin, kai/KJL-3762-2024; Cánovas,
   Alejandro/HZI-5828-2023; Lloret, Jaime/H-3994-2013
OI Rodrigues, Joel J. P. C./0000-0001-8657-3800; Lloret,
   Jaime/0000-0002-0862-0533; Canovas Solbes, Alejandro/0000-0002-0422-0161
FU Polytechnic University of Valencia [PAID-15-10]; Instituto de
   Telecomunicacoes, Next Generation Networks and Applications Group
   (NetGNA), Portugal; FCT - Fundacao para a Ciencia e a Tecnologia
   [PEst-OE/EEI/LA0008/2011]
FX This work has been partially supported by the Polytechnic University of
   Valencia, though the PAID-15-10 multidisciplinary projects, by the
   Instituto de Telecomunicacoes, Next Generation Networks and Applications
   Group (NetGNA), Portugal, and by National Funding from the FCT -
   Fundacao para a Ciencia e a Tecnologia through the
   PEst-OE/EEI/LA0008/2011 Project.
CR Abukharis S, 2009, LOND COMM S LOND UK
   Alfonsi B, 2005, IEEE DISTRIBUTED SYS, V6
   [Anonymous], 802112007 IEEE
   [Anonymous], 80216 IEEE
   Atenas Marcelo, 2010, IEEE GLOB COMM C IEE
   Birlik F, 2009, IEEE T CONSUMER ELEC, V55
   Cai LX, 2009, WIREL NETW, V15, P443, DOI 10.1007/s11276-007-0062-5
   Canovas Alejandro, 2009, 5 INT C NETW SERV IC
   Cunningham G, 2009, IEEE T BROADCAST, V55, P796, DOI 10.1109/TBC.2009.2030466
   Dai Z, 2008, IEEE INT C COMM 2008, P19
   Garcia Miguel, 2009, INT S HIGH PERF DIST
   Gidlund M, 2008, IEEE T CONSUM ELECTR, V54, P1665, DOI 10.1109/TCE.2008.4711218
   Hellberg Chris., 2007, Broadband Network Architectures: 5] designing and deploying triple play services
   Hsu HT, 2010, MICROW OPT TECHN LET, V52, P471, DOI 10.1002/mop.24954
   inCode Telecom group Inc, 2006, QUAD PLAY 1 WAV CONV
   Jindal S, 2005, 1 IEEE IFIP INT C CE
   Knightson K, 2005, IEEE COMMUN MAG, V43, P49, DOI 10.1109/MCOM.2005.1522124
   Kuo WH, 2007, IEEE ICC, P1754, DOI 10.1109/ICC.2007.293
   Lai CF, 2011, IEEE SYST J, V5, P555, DOI 10.1109/JSYST.2011.2165190
   Lee S. Tran, 2008, P IEEE NETW OP MAN S, P71
   Park AH, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1077, DOI 10.1109/ICACT.2007.358545
   Retnasothie FE, 2006, WIRELESS IPTV WIMAX
   Schollmeier G, 2004, IEEE COMMUN MAG, V42, P102, DOI 10.1109/MCOM.2004.1304243
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   Shihab E, 2007, IEEE GLOB TEL GLOBEC, P26
   Shihab E, 2008, IEEE NETWORK, V22, P52, DOI 10.1109/MNET.2008.4435903
   SINGH H, 2008, 5 IEEE CONS COMM NET, P626
   Velez Karen Fernanda Medina, 2006, THESIS ESCUELA POLIT
   Xiao Y, 2007, IEEE COMMUN MAG, V45, P126, DOI 10.1109/MCOM.2007.4378332
   Yarali Abdulrahman, 2008, Journal of Communications, V3, P53, DOI 10.4304/jcm.3.2.53-63
   ZHANG JY, 2008, INT C INT INF HID MU, P117, DOI DOI 10.1109/IIH-MSP.2008.166
NR 31
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 7
EP 30
DI 10.1007/s11042-011-0929-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800002
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, SS
   Zhao, YH
   Qu, BY
   Wang, JA
AF Li, Shanshan
   Zhao, Yinghai
   Qu, Bayi
   Wang, Jiang'an
TI Image scrambling based on chaotic sequences and VeginSre cipher
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image scrambling; Image encryption; Chaotic sequence; Vigenere cipher;
   Pixel-based scrambling
ID ENCRYPTION
AB Digital image scrambling is commonly used for image data security. This paper proposes an image scrambling algorithm based on chaos theory and VigenSre cipher. The scrambling process is performed on the grey level of each pixel by sorting the chaotic sequence as VigenSre cipher, then the pixel positions are shuffled by accompanied chaotic sequence. The new scheme avoid discretization of chaotic sequence, therefore there is no requirement of probability density function of the chaotic orbits. The simulation and experiments validate the effectiveness and efficiency of the proposed new algorithm.
C1 [Li, Shanshan; Qu, Bayi; Wang, Jiang'an] Changan Univ, Dept Elect Informat Engn, Shaanxi Traff Intelligent Detect & Equipment Engn, Xian, Peoples R China.
   [Zhao, Yinghai] China Aerosp Sci & Ind Corp, Res Inst 35, Beijing, Peoples R China.
C3 Chang'an University; China Aerospace Science & Industry Corporation
   (CASIC)
RP Li, SS (corresponding author), Changan Univ, Dept Elect Informat Engn, Shaanxi Traff Intelligent Detect & Equipment Engn, Xian, Peoples R China.
EM sputnik@126.com
RI Li, Shanshan/HLH-7747-2023
FU Natural Science Basic Research Plan in Shaanxi Province of China
   [2011JQ8014]; Special Fund for Basic Scientific Research of Central
   Colleges, Chang'an University [CHD2011JC014]; Shaanxi Traffic
   intelligent detection and Equipment Engineering Technology Research
   Center
FX The project is supported by Natural Science Basic Research Plan in
   Shaanxi Province of China (Program No. 2011JQ8014) and the Special Fund
   for Basic Scientific Research of Central Colleges, Chang'an University
   (Program No. CHD2011JC014).; The project is also received supports from
   Shaanxi Traffic intelligent detection and Equipment Engineering
   Technology Research Center's open fund.
CR Blackledge Jonathan M., 2010, CHAOTIC IMAGE ENCRYP
   Chattopadhyay D., 2011, INDIAN J SCI TECHNOL, V4, P593, DOI 10.17485/ijst/2011/v4i5.27
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   [陈燕梅 CHEN Yanmei], 2006, [中国图象图形学报, Journal of image and graphics], V11, P1076
   Han FL, 2006, ISSCAA 2006: 1ST INTERNATIONAL SYMPOSIUM ON SYSTEMS AND CONTROL IN AEROSPACE AND ASTRONAUTICS, VOLS 1AND 2, P1273
   Kadir R, 2011, 2009 INT C COMP ENG, V2, P390
   Li Shan-shan, 2008, Computer Engineering, V34, P144
   [李扬 LI Yang], 2006, [中国图象图形学报, Journal of image and graphics], V11, P1088
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liu XD, 2008, INT J COMPUT SCI NET, V8, P64
   Mengyue Hu, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P147, DOI 10.1109/CISP.2010.5646384
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shanshan Li, 2011, Proceedings of the 2011 Seventh International Conference on Computational Intelligence and Security (CIS 2011), P555, DOI 10.1109/CIS.2011.128
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Xu S., 2010, INT J IMAGE GRAPH SI, V2, P61
   Yang Ya-li, 2006, Journal of Beijing Institute of Technology, V15, P216
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
NR 17
TC 21
Z9 24
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2013
VL 66
IS 3
BP 573
EP 588
DI 10.1007/s11042-012-1281-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 179TX
UT WOS:000321545300010
DA 2024-07-18
ER

PT J
AU Ali, A
   Irum, S
   Kausar, F
   Khan, FA
AF Ali, Aftab
   Irum, Sarah
   Kausar, Firdous
   Khan, Farrukh Aslam
TI A cluster-based key agreement scheme using keyed hashing for Body Area
   Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Body Area Network; Physiological values; Electrocardiogram; Hash-based
   Message Authentication Code (HMAC); L-sensors; H-sensors
AB In recent years, Body Area Networks (BANs) have gained immense popularity in the domain of healthcare as well as monitoring of soldiers in the battlefield. Security of a BAN is inevitable as we secure the lives of soldiers and patients. In this paper, we propose a security framework using Keyed-Hashing Message Authentication Code (HMAC-MD5) to protect the personal information in a BAN. We assume a network in which nodes sense physiological variables such as electrocardiography (EKG), electroencephalography (EEG), pulse oximeter data, blood pressure and cardiac output. Heterogeneous wireless sensor network is considered which consists of a powerful High-end sensor (H-sensor) and several Low-end sensors (L-sensors). EKG is used for secure communication between nodes as it introduces plug and play capability in BANs. The process is made secure by applying HMAC-MD5 on EKG blocks. Key agreement is done by comparing HMAC of feature blocks between sensors resulting in a more secure network. The analysis is done by calculating the entropy of keys and checking the randomness of EKG data using NIST-randomness testing suite.
C1 [Ali, Aftab; Irum, Sarah; Kausar, Firdous; Khan, Farrukh Aslam] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad, Pakistan.
RP Khan, FA (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, AK Brohi Rd H-11-4, Islamabad, Pakistan.
EM farrukh.aslam@nu.edu.pk
RI Kausar, Firdous/AAF-4717-2021; Khan, Farrukh Aslam/J-8358-2019
OI Kausar, Firdous/0000-0001-8922-549X; Khan, Farrukh
   Aslam/0000-0002-7023-7172; Ali, Aftab/0000-0002-4578-7631
CR Ali A, 2010, COMM COM INF SC, V76, P298
   [Anonymous], RFC2202
   [Anonymous], Proceedings of the 27th IEEE International Conference on Computer Communications (INFOCOM), DOI DOI 10.1109/INFOCOM.2008.4544608
   [Anonymous], RFC2104
   Cavoukian A, 2008, INT FED INFO PROC, V261, P57
   Godbole A.P., 1994, Runs and patterns in probability: Selected papers
   Kausar F, 2008, IEEE CONF WIREL MOB, P549, DOI 10.1109/WiMob.2008.120
   Mana M.M., 2009, Int J. Adv. Sei. Technol, V12, P45
   Saleem S., 2009, Int J Digit Content Technol Appl, DOI [10.4156/jdcta.vol3.issue3.22, DOI 10.4156/JDCTA.VOL3.ISSUE3.22]
   Venkatasubramanian KK, 2006, FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSSING, PROCEEDINGS, P197
   Venkatasubramanian KK, 2010, IEEE T INF TECHNOL B, V14, P60, DOI 10.1109/TITB.2009.2037617
NR 11
TC 26
Z9 27
U1 0
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 201
EP 214
DI 10.1007/s11042-011-0791-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000004
DA 2024-07-18
ER

PT J
AU Qureshi, B
   Min, GY
   Kouvatsos, D
AF Qureshi, Basit
   Min, Geyong
   Kouvatsos, Demetres
TI Countering the collusion attack with a multidimensional decentralized
   trust and reputation model in disconnected MANETs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Collusion detection; FIRE reputation model; Trust management;
   Disconnected MANETs; Peer-to-Peer (P2P) overlays
ID MANAGEMENT; FRAMEWORK
AB The FIRE trust and reputation model is a de-centralized trust model that can be applied for trust management in unstructured Peer-to-Peer (P2P) overlays. The FIRE model does not, however, consider malicious activity and possible collusive behavior in nodes of network and it is therefore susceptible to collusion attacks. This investigation reveals that FIRE is vulnerable to lying and cheating attacks and presents a trust management approach to detect collusion in direct and witness interactions among nodes based on colluding node's history of interactions. A witness ratings based graph building approach is utilized to determine possibly collusive behavior among nodes. Furthermore, various interaction policies are defined to detect and prevent collaborative behavior in colluding nodes. Finally a multidimensional trust model FIRE+ is devised for avoiding collusion attacks in direct and witness based interactions. The credibility of the proposed trust management scheme as an enhancement of the FIRE trust model is verified by extensive simulation experiments.
C1 [Qureshi, Basit; Min, Geyong; Kouvatsos, Demetres] Univ Bradford, NetPEn Networks & Performance Engn Res Unit, Informat Res Inst IRI, Sch Comp Informat & Media, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford
RP Qureshi, B (corresponding author), Univ Bradford, NetPEn Networks & Performance Engn Res Unit, Informat Res Inst IRI, Sch Comp Informat & Media, Bradford BD7 1DP, W Yorkshire, England.
EM b.qureshi@bradford.ac.uk; g.min@bradford.ac.uk;
   d.kouvatsos@bradford.ac.uk
RI Qureshi, Basit/T-7176-2018
OI Qureshi, Basit/0000-0001-7389-519X
CR [Anonymous], 2004, 2 WORKSH EC PEER TO
   Baras J. S., 2005, P 12 ANN NETW DISTR
   Hang C., 2008, P INT JOINT C AUTONO, P1485
   Huynh TD, 2006, AUTON AGENT MULTI-AG, V13, P119, DOI 10.1007/s10458-005-6825-4
   Jurca R, 2003, LECT NOTES ARTIF INT, V2631, P138
   Jyun-Cheng W, 2008, EXPERT SYST APPL, V34, P1666, DOI 10.1016/j.eswa.2007.01.045
   Kerr Reid., 2009, Proceedings of The 8th International Conference on Autonomous Agents and Multiagent Systems, V2, P993
   Keung SNLC, 2008, LECT NOTES ARTIF INT, V5396, P43, DOI 10.1007/978-3-540-92803-4_3
   Li HH, 2007, COMPUTER, V40, P45, DOI 10.1109/MC.2007.76
   Li J, 2008, IEEE COMMUN MAG, V46, P108, DOI 10.1109/MCOM.2008.4481349
   Lian Q., 2007, P 27 INT C DISTRIBUT, P56, DOI DOI 10.1109/ICDCS.2007.84
   Lim Choi Keung S, 2009, P 12 INT WORKSH TRUS, P68
   Narula P, 2008, COMPUT COMMUN, V31, P760, DOI 10.1016/j.comcom.2007.10.021
   Papadimitratos P., 2003, Elsevier Ad Hoc Networks Journal, V1
   Ramchurn SD, 2004, KNOWL ENG REV, V19, P1, DOI 10.1017/S0269888904000116
   Rehbock S, 2009, COMPUT COMMUN, V32, P1006, DOI 10.1016/j.comcom.2008.12.040
   Sabater J., 2001, 4 WORKSHOP DECEPTION, P61
   Salehi-Abari A, 2009, P 21 INT JOINT C ART
   Skogsrud H, 2003, IEEE INTERNET COMPUT, V7, P45, DOI 10.1109/MIC.2003.1250583
   Srivatsa M, 2006, J PARALLEL DISTR COM, V66, P1217, DOI 10.1016/j.jpdc.2006.04.003
   Teacy W.T. L., 2005, AAMAS 05 P 4 INT JOI, P997
   Uszok A, 2004, LECT NOTES COMPUT SC, V2995, P16
   Yu B, 2000, LECT NOTES ARTIF INT, V1860, P154
   Yu Bin., 2003, P 2 INT JOINT C AUTO, P73
   Yunfang F, 2007, CIS: 2007 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PROCEEDINGS, P804
   Zouridaki C., 2006, ACM workshop on Security of ad hoc and sensor networks, P23
   Zouridaki C., 2005, Proc. the 3rd ACM workshop on Security of ad hoc and sensor networks, P1, DOI DOI 10.1145/1102219.1102222
NR 27
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2013
VL 66
IS 2
BP 303
EP 323
DI 10.1007/s11042-011-0780-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 170PJ
UT WOS:000320865000010
DA 2024-07-18
ER

PT J
AU Chilamkurti, N
   Park, JH
   Kumar, N
AF Chilamkurti, Naveen
   Park, Jong Hyuk
   Kumar, Neeraj
TI Concurrent multipath transmission with forward error correction
   mechanism to overcome burst packet losses for delay-sensitive video
   streaming in wireless home networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE FEC; Wireless networks; Delay-sensitive; Multipath transmission
ID BANDWIDTH AGGREGATION; PATH; SCHEME
AB Wireless multimedia home servers are the next generation of home entertainment systems. The provision of high quality time-critical video streaming applications in indoor environments is very challenging due to high attenuation and interference caused by the walls and the contention in the shared wireless channel. This paper proposes a Delay-sensitive Multipath Forward Error Correction (DM-FEC) mechanism involving an estimation of available bandwidth and a mathematical analytical model with which the appropriate transmission rate, the FEC block length, and the FEC redundancy on each path in a multipath environment can be determined to solve previous problems. The DM-FEC mechanism not only selects the appropriate transmission rate and FEC redundancy on each path but also adaptively adjusts the FEC block length and concurrently sends data over multiple paths to overcome burst packet losses which otherwise can cause the video frame to be unplayable and impede the timely recovery of video information.
C1 [Chilamkurti, Naveen] La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic, Australia.
   [Park, Jong Hyuk] Seoul Natl Univ Technol, Dept Comp Sci & Engn, Seoul, South Korea.
   [Kumar, Neeraj] SMVD Univ, Sch Comp Sci & Engn, Katra, J&K, India.
C3 La Trobe University; Shri Mata Vaishno Devi University
RP Chilamkurti, N (corresponding author), La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic, Australia.
EM n.chilamkurti@latrobe.edu.au; jhpark1@snut.ac.kr; nehra04@yahoo.co.in
RI Kumar, Neeraj/J-4123-2017; Chilamkurti, Naveen/S-9636-2019; Kumar,
   Neeraj/L-3500-2016
OI Chilamkurti, Naveen/0000-0002-5396-8897; Kumar,
   Neeraj/0000-0002-3020-3947
CR [Anonymous], INT C POW SYST TECHN
   But J, 2005, IEEE COMMUN MAG, V43, P84, DOI 10.1109/MCOM.2005.1453427
   Chen JL, 2007, COMPUT NETW, V51, P3368, DOI 10.1016/j.comnet.2007.01.032
   Costamagna Eugenio, 2010, 2010 5th International Symposium on Wireless Pervasive Computing (ISWPC), P418, DOI 10.1109/ISWPC.2010.5483763
   Fan XP, 2009, J VIS COMMUN IMAGE R, V20, P365, DOI 10.1016/j.jvcir.2009.03.007
   Fashandi S, 2010, IEEE ACM T NETWORK, V18, P1373, DOI 10.1109/TNET.2010.2043368
   Gandikota VR, 2008, IEEE T MOBILE COMPUT, V7, P1184, DOI 10.1109/TMC.2008.42
   Glowac A, 2008, MULTIMED TOOLS APPL, V40, P321, DOI 10.1007/s11042-008-0209-0
   Habib A, 2007, COMPUT NETW, V51, P3323, DOI 10.1016/j.comnet.2007.01.024
   Hsieh MY, 2007, MULTIMED TOOLS APPL, V34, P155, DOI 10.1007/s11042-006-0086-3
   Jurca D, 2009, IEEE T CIRC SYST VID, V19, P1315, DOI 10.1109/TCSVT.2009.2022800
   Ke CH, 2010, J APPL SCI ENG, V13, P1
   Ke CH, 2010, J INTERNET TECHNOL, V11, P491
   Khirallah C, 2010, MULTIMED TOOLS APPL, V48, P457, DOI 10.1007/s11042-009-0313-9
   Ko D, 2008, WIREL COMMUN MOB COM, V8, P407, DOI 10.1002/wcm.459
   Korhonen J, 2006, MULTIMED TOOLS APPL, V29, P305, DOI 10.1007/s11042-006-0016-4
   Kurant M, 2009, IEEE INFOCOM SER, P2025, DOI 10.1109/INFCOM.2009.5062125
   Li Li, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P478, DOI 10.1109/IIHMSP.2010.122
   Ming-Fong Tsai, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P810, DOI 10.1109/WAINA.2010.142
   Ming-Fong Tsai, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1236, DOI 10.1109/IIH-MSP.2009.330
   Palazzi CE, 2009, MULTIMED TOOLS APPL, V44, P229, DOI 10.1007/s11042-009-0292-x
   Seferoglu H, 2010, IEEE T MULTIMEDIA, V12, P869, DOI 10.1109/TMM.2010.2053840
   Shih JY, 2010, MULTIMED TOOLS APPL, V47, P461, DOI 10.1007/s11042-009-0333-5
   Tsai M, 2010, COMPUT COMMUN, DOI [10.1016/j.comcom.2010.02.001, DOI 10.1016/J.C0MC0M.2010.02.001]
   Tsai M, 2008, IEEE INT C TEL, V1, P16
   Tsai M, 2010, COMPUT NETW, DOI [10.1016/j.comnet.2010.06.003, DOI 10.1016/J.C0MNET.2010.06.003]
   Tsai MF, 2010, IET COMMUN, V4, P937, DOI 10.1049/iet-com.2009.0661
   Tsai MF, 2011, MATH COMPUT MODEL, V53, P2067, DOI 10.1016/j.mcm.2010.05.019
   Tsai MF, 2011, WIRELESS PERS COMMUN, V56, P435, DOI 10.1007/s11277-010-9981-z
   Tsai MF, 2010, MULTIMED TOOLS APPL, V47, P49, DOI 10.1007/s11042-009-0406-5
NR 30
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 2
BP 201
EP 220
DI 10.1007/s11042-011-0779-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 141EJ
UT WOS:000318708100003
DA 2024-07-18
ER

PT J
AU Kim, CG
   Choi, YS
AF Kim, Cheong Ghil
   Choi, Yong Soo
TI A high performance parallel DCT with OpenCL on heterogeneous computing
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenCL; Multi-core; Many-core; DCT; Heterogeneous computing; Multimedia
AB A noteworthy thing in desktop PCs is that they can provide a great opportunity to increase the performance of processing multimedia data by exploiting task- and data-parallelism with multi-core CPU and many-core GPU. This paper presents a high performance parallel implementation of 2D DCT on this heterogeneous computing environment. For this purpose, Intel TBB (threading building blocks) and OpenCL (Open Compute Language) are utilized for task- and data-parallelism, respectively. The simulation result shows that the parallel DCT implementations far the serial ones in processing speed. Especially, OpenCL implementation shows a linear speedup, a typical SIMD characteristic as the increase of 2D data sets.
C1 [Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, Chungnam, South Korea.
   [Choi, Yong Soo] Korea Univ, Grad Sch Informat Secur, Seoul, South Korea.
   [Choi, Yong Soo] Korea Univ, Brain Korea Ubiquitous Informat Secur 21, Seoul, South Korea.
   [Choi, Yong Soo] Korea Univ, Ctr Informat Secur Technol, Seoul, South Korea.
C3 Namseoul University; Korea University; Korea University; Korea
   University
RP Choi, YS (corresponding author), Korea Univ, Grad Sch Informat Secur, 15 Anamro Seongbukgu, Seoul, South Korea.
EM cgkim@nsu.ac.kr; ciechoi@korea.ac.kr
FU National Research Foundation of Korea (NRF); Ministry of Education,
   Science and Technology [KRF 2011-0027264]; National Research Foundation
   of Korea [2009-0089445] Funding Source: Korea Institute of Science &
   Technology Information (KISTI), National Science & Technology
   Information Service (NTIS)
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (KRF 2011-0027264).
CR Akhter S., 2006, MULTICORE PROGRAMMIN, V1st
   [Anonymous], J CONVERG
   Antao S, 2010, PR IEEE COMP DESIGN, P425, DOI 10.1109/ICCD.2010.5647672
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   Conti G, 2008, LECT NOTES COMPUT SC, V5210, P1, DOI 10.1007/978-3-540-85933-8_1
   Fagerlund A, 2010, THESIS NORWEGIAN U S
   Gong CY, 2011, J INF PROCESS SYST, V7, P63, DOI 10.3745/JIPS.2011.7.1.063
   Hawick KA, 2009, CSTN102 MASS U
   Hwu W.-m, 2016, Programming Massively Parallel Processors: A Hands-On Approach
   Kim CG, 2005, LECT NOTES COMPUT SC, V3522, P675
   Klyuev Vitaly, 2011, International Journal of Information Technology, Communications and Convergence, V1, P221, DOI 10.1504/IJITCC.2011.039287
   Nie DH, 2009, J INF PROCESS SYST, V5, P105, DOI 10.3745/JIPS.2009.5.2.105
   Owens J.D., 2005, GPU Gems 2 Program. Tech. High-Performance Graph. Gen. Comput, P457
   Reinders James, 2007, Intel threading building blocks-outfitting C++ for multi-core processor parallelism
   Robison A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P598
   Sathappan OL, IJITCC, V1, P146
   Slo-Li Chu, 2010, Proceedings of the 2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC 2010), P556, DOI 10.1109/HPCC.2010.56
   Stallings W., 2009, COMPUTER ORG ARCHITE
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   TULLSEN DM, 1995, ACM COMP AR, P392, DOI 10.1109/ISCA.1995.524578
   Zhu WH, 2009, IEEE SYS MAN CYBERN, P1803, DOI 10.1109/ICSMC.2009.5346870
NR 21
TC 9
Z9 9
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 475
EP 489
DI 10.1007/s11042-012-1028-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200015
DA 2024-07-18
ER

PT J
AU Morales-González, A
   García-Reyes, EB
AF Morales-Gonzalez, Annette
   Garcia-Reyes, Edel B.
TI Simple object recognition based on spatial relations and visual features
   represented using irregular pyramids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object recognition; Spatial relations; Topological relations; Structure
   matching; Graph matching
ID IMAGE RETRIEVAL; CLASSIFICATION; INFORMATION; EXTRACTION; TEXTURE
AB Spatial relations among objects and object parts play a fundamental role in the human perception and understanding of images, thus becoming very relevant in the computational fields of object recognition, scene understanding and content-based image retrieval. In this work we propose a graph matching scheme that involves color, texture and shape features along with spatial descriptors to represent topological and orientation/directional relationships-which are obtained by means of combinatorial pyramids-in order to identify similar objects from a database. We also suggest a method for deciding which are the more useful levels in the hierarchy of segmentation for the recognition process. Our main objective is to prove that the combination of visual and spatial features is a promising road in order to improve the object recognition task. We performed experiments on two well known databases, COIL-100 and ETH-80 image sets, in order to evaluate the expressiveness of the proposed representation. These sets introduce challenges for simple object recognition in terms of view-point changes, and our results were comparable or superior than other state-of-the-art methods.
C1 [Morales-Gonzalez, Annette; Garcia-Reyes, Edel B.] Adv Technol Applicat Ctr CENATAV, Pattern Recognit Dept, Havana, Cuba.
RP Morales-González, A (corresponding author), Adv Technol Applicat Ctr CENATAV, Pattern Recognit Dept, Havana, Cuba.
EM amorales@cenatav.co.cu; egarcia@cenatav.co.cu
RI González-Quevedo, Annette Morales/A-6850-2018; Reyes, Edel
   Garcia/AFQ-2319-2022
OI González-Quevedo, Annette Morales/0000-0003-2716-3144; Garcia Reyes,
   Edel Bartolo/0000-0002-6426-1264
CR [Anonymous], P BRIT MACH VIS C 20
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], PRIPTR106 TU WIEN
   [Anonymous], 2010, INT J MULTIMED APPL
   [Anonymous], 1994, VLDB J, DOI [10.1007/BF01231602, DOI 10.1007/BF01231602]
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], MITCSAILTR2005017
   [Anonymous], CONTENT BASED IMAGE
   [Anonymous], P JOINT INT WORKSH S
   Arif Thawar, 2009, Journal of Theoretical and Applied Information Technology, V7, P31
   Brun L, 2006, PATTERN RECOGN, V39, P515, DOI 10.1016/j.patcog.2005.10.015
   Cheriet M, 2007, CHARACTER RECOGNITION SYSTEMS: A GUIDE FOR STUDENTS AND PRACTIONERS, P1, DOI 10.1002/9780470176535
   Duval MA, 2010, LECT NOTES COMPUT SC, V6419, P394
   Egenhofer M., 1993, Auto-Carto 11, P1
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fischer B, 2004, PROC SPIE, V5370, P598, DOI 10.1117/12.535294
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Hadjidemetriou E, 2001, PROC CVPR IEEE, P702
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hernández-Gracidas C, 2007, LECT NOTES COMPUT SC, V4872, P879
   Hodé Y, 2007, LECT NOTES COMPUT SC, V4538, P240
   Hsieh JW, 2003, IEEE T IMAGE PROCESS, V12, P1404, DOI 10.1109/TIP.2003.816013
   Hurtut T, 2008, COMPUT VIS IMAGE UND, V112, P101, DOI 10.1016/j.cviu.2007.12.006
   Ham MI, 2007, LECT NOTES COMPUT SC, V4756, P172
   Kropatsch WG, 2005, PATTERN RECOGN LETT, V26, P319, DOI 10.1016/j.patrec.2004.10.026
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leibe B, 2003, PROC CVPR IEEE, P409
   Lin PL, 2003, INFORM PROCESS MANAG, V39, P543, DOI 10.1016/S0306-4573(02)00034-1
   MAREE R, 2005, ICML WORKSH MACH LEA
   Markman AB, 2000, AM J PSYCHOL, V113, P501, DOI 10.2307/1423470
   Morales-González A, 2010, LECT NOTES COMPUT SC, V6419, P549
   Morioka N, 2008, LECT NOTES ARTIF INT, V5360, P551, DOI 10.1007/978-3-540-89378-3_56
   Murase Hiroshi, 1996, COLUMBIA OBJECT IMAG
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Punitha P, 2006, IEEE T KNOWL DATA EN, V18, P1368, DOI 10.1109/TKDE.2006.154
   Skiadopoulos S, 2004, ARTIF INTELL, V152, P143, DOI 10.1016/S0004-3702(03)00137-1
   SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409
   Song YZ, 2010, LECT NOTES COMPUT SC, V6314, P694, DOI 10.1007/978-3-642-15561-1_50
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Thies C, 2003, PROC SPIE, V5032, P598, DOI 10.1117/12.481393
   Pham TT, 2012, MULTIMED TOOLS APPL, V60, P419, DOI 10.1007/s11042-010-0598-8
   Tsapatsoulis N, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P92, DOI 10.1109/SMAP.2007.49
   Vieux R, 2012, MULTIMED TOOLS APPL, V60, P305, DOI 10.1007/s11042-010-0611-2
   Wang Y, 2006, INT C PATT RECOG, P33
   Zhang B, 2003, P SOC PHOTO-OPT INS, V5010, P28, DOI 10.1117/12.473347
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 46
TC 19
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 875
EP 897
DI 10.1007/s11042-011-0938-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000013
DA 2024-07-18
ER

PT J
AU Kim, KR
   Moon, N
AF Kim, Kyung-Rog
   Moon, NamMee
TI Recommender system design using movie genre similarity and preferred
   genres in SmartPhone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart-phone; Recommender system; Clustering; Multi-property; Interactive
   service
AB As e-commerce (e.g. www.amazon.com) and social media (e.g. www.facebook.com) services evolve, studies of recommender systems advance, especially concerning the application of collective intelligence to personalized service. With the development of smartphones and the new mobile environment, studies of customized services increase despite the physical limitations of mobile devices. A typical example combines customized services with location-based services. In this study, we propose a recommender system using movie genre similarity and preferred genres. A movie genre similarity profile is designed and generated to provide related services in a mobile experimental environment before prototyping and testing with data from MovieLens. In order to accomplish this, genre similarity correlations are determined with a Pearson correlation coefficient, and similar clusters are derived. The correlations within clusters are used to define genre similarity. Genre similarity is then used to recommend new genres to targeted customers.
C1 [Kim, Kyung-Rog; Moon, NamMee] Hoseo Univ, Dept IT App Tech GSV, Seoul, South Korea.
   [Moon, NamMee] Hoseo Univ, Dept IT Applicat Technol, Seoul, South Korea.
C3 Hoseo University; Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept IT App Tech GSV, Seoul, South Korea.
EM it4all@naver.com; mnm@hoseo.edu
FU Korea Science and Engineering Foundation (KOSEF); Korean government
   (MEST) [2010-0000487]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) grant funded by the Korean government (MEST) (No. 2010-0000487)
CR An BJ, 2000, KOREAN I INF SCI ENG, V27, P69
   BadrulMSarwar George Karypis, 2002, IEEE ICCIT
   Cho YH, 2004, EXPERT SYST APPL, V26, P233, DOI 10.1016/S0957-4174(03)00138-6
   Choi J-W, 2007, THESIS KOREA ADV I S, P19
   Chorianopoulos K, 2008, MULTIMED TOOLS APPL, V36, P1, DOI 10.1007/s11042-006-0081-8
   Drachsler H., 2007, Proceedings of Workshop on Social Information Retrieval for Technology-Enhanced Learning (SIRTEL'07) at the EC-TEL conference, P18
   권형준, 2009, [Journal of Internet Computing and Services, 인터넷정보학회논문지], V10, P111
   Huh MH, 2004, KOREAN J APPL STAT, V17, P135
   Jo SH, 2008, THESIS HANNAM U GRAD
   Kim JK, 2005, KOREA SOC MANAGE INF, V15, P223
   Kim KR, 2010, MULTIMEDIA UBIQUITOU
   Lee D-J, 2009, P KOR COMP C, V36
   Lee HC, 2009, THESIS KANGWON U GRA
   Lee TQ, 2008, EXPERT SYST APPL, V34, P3055, DOI 10.1016/j.eswa.2007.06.031
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Oh JM, 2010, MULTIMEDIA UBIQUITOU
   Park JY, 2009, J KOREA CONTENTS ASS, V10, P160
   Park KC, 2008, THESIS HANYANG U
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Sarwar Badrul M., 2000, WEBKDD 2000 WORKSH
   Zhang Y, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NATURAL COMPUTING, VOL II, P72, DOI 10.1109/CINC.2009.219
   Zhi-Mei Wang, 2009, WSEAS Transactions on Information Science and Applications, V6, P809
NR 22
TC 14
Z9 14
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 87
EP 104
DI 10.1007/s11042-011-0728-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000006
DA 2024-07-18
ER

PT J
AU Lu, W
   Sun, W
   Lu, HT
AF Lu, Wei
   Sun, Wei
   Lu, Hongtao
TI Novel robust image watermarking based on subsampling and DWT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Subsampling; DWT; Collusion
ID SPREAD-SPECTRUM WATERMARKING; WAVELET
AB This paper presents a robust digital image watermarking scheme based on subsampling and DWT. Subsampling is firstly used to construct a subimage sequence as a video segment. Then, a random watermark sequence satisfied with Gaussian distribution is block-wised embedded into the DWT domain of these subimages repeatedly using the video watermarking technique. And watermark is detected through computing correlation between watermark and watermarked frames. The experiment results demonstrate that the proposed scheme achieves good robustness against JPEG compression, common image processing operation and geometric distortions. Furthermore, the proposed watermarking scheme is also robust against linear collusion and other video watermarking attacks.
C1 [Lu, Wei] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Shanghai Jiao Tong
   University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM luwei3@mail.sysu.edu.cn; sunwei@mail.sysu.edu.cn; lu-ht@cs.sjtu.edu.cn
FU National Natural Science Foundation of China (NSFC) [60803136];
   Guangzhou Science and Technology Program [2009J1-C541-2]
FX This work was supported by National Natural Science Foundation of China
   (NSFC no. 60803136), Guangzhou Science and Technology Program (no.
   2009J1-C541-2).
CR [Anonymous], 2006, P 19 C COMP VIS GRAP
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Doërr G, 2003, SIGNAL PROCESS-IMAGE, V18, P263, DOI 10.1016/S0923-5965(02)00144-3
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Hartung F, 1998, SIGNAL PROCESS, V66, P283, DOI 10.1016/S0165-1684(98)00011-5
   Inoue H, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P391, DOI 10.1109/ICIP.1998.723388
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Lin WH, 2009, EXPERT SYST APPL, V36, P11509, DOI 10.1016/j.eswa.2009.03.060
   Lin WH, 2009, EXPERT SYST APPL, V36, P9869, DOI 10.1016/j.eswa.2009.02.036
   Liu QZ, 2010, INFORM SCIENCES, V180, P1643, DOI 10.1016/j.ins.2010.01.001
   Liu Qingzhong., 2009, Proceedings of the 17th ACM international conference on Multimedia, MM '09, P873
   Liu W, 2007, IEEE T INF FOREN SEC, V2, P645, DOI 10.1109/TIFS.2007.908226
   Lu W, 2010, COMPUT ELECTR ENG, V36, P2, DOI 10.1016/j.compeleceng.2009.04.002
   Lu W, 2009, COMPUT ELECTR ENG, V35, P183, DOI 10.1016/j.compeleceng.2008.09.004
   Lu W, 2008, INFORMATICA-LITHUAN, V19, P555
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Malvar HS, 2003, IEEE T SIGNAL PROCES, V51, P898, DOI 10.1109/TSP.2003.809385
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   ORuanaidh JJK, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P239, DOI 10.1109/ICIP.1996.560428
   PEREIRA S, 1999, LECT NOTES COMPUTER, V1768, P200
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Su K, 2005, IEEE T MULTIMEDIA, V7, P43, DOI 10.1109/TMM.2004.840617
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang SH, 2004, IEEE T IMAGE PROCESS, V13, P154, DOI 10.1109/TIP.2004.823822
   Zheng D, 2003, IEEE T CIRC SYST VID, V13, P753, DOI 10.1109/TCSVT.2003.815959
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
NR 29
TC 20
Z9 20
U1 0
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 31
EP 46
DI 10.1007/s11042-011-0794-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500002
DA 2024-07-18
ER

PT J
AU Park, SB
   Oh, KJ
   Jo, GS
AF Park, Seung-Bo
   Oh, Kyeong-Jin
   Jo, Geun-Sik
TI Social network analysis in a movie using character-net
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character-net; Character; Movie; Community clustering; Story-based;
   Social network
ID RETRIEVAL; SYSTEM
AB There have been various approaches to analyzing movie stories using social networks. Social network analysis is an effective means to extract semantic information from movies. Movie analysis through social relationships among characters can support various types of information retrieval better than audio-visual feature analysis. The relationships among characters form the main structure of the story. Therefore, through social network analysis among characters, movie story information such as the major roles and the corresponding communities can be determined. Progression of most movie stories is done by characters, and the scriptwriter or director narrates the story and relationships among characters using character dialogs. A dialog has a direction and time that supplies information. Therefore, the dialog is better for constructing social networks of characters than the co-appearance. Additionally, through social networks using the dialog, we can extract accurate movie stories such as classification of major, minor or extra roles, community clustering, and sequence detection. To achieve this, we propose a Character-net that can represent the relationships between characters using dialogs, and a method that can extract the sequences via clustering communities composed of characters. Our experiments show that our proposed method can efficiently detect sequences.
C1 [Park, Seung-Bo; Oh, Kyeong-Jin] Inha Univ, Dept Informat Engn, Inchon, South Korea.
   [Jo, Geun-Sik] Inha Univ, Sch Comp & Informat Engn, Inchon, South Korea.
C3 Inha University; Inha University
RP Park, SB (corresponding author), Inha Univ, Dept Informat Engn, 253 Yonghyun Nam, Inchon, South Korea.
EM molaal@eslab.inha.ac.kr; okjkillo@eslab.inha.ac.kr; gsjo@inha.ac.kr
CR Ajmera J, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P411, DOI 10.1109/ASRU.2003.1318476
   [Anonymous], 2000, AUDIO-VISUAL SPEECH RECOGNITION
   [Anonymous], 2008, Proc. ACM Multimedia, DOI [10.1145/1459359.1459462, DOI 10.1145/1459359.1459462]
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   Cour T, 2008, LECT NOTES COMPUT SC, V5305, P158, DOI 10.1007/978-3-540-88693-8_12
   Everingham M, 2008, IMAGE VISIO IN PRESS
   Guimerà R, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.065103
   Hung H., 2007, P ACM MULTIMEDIA, P835
   Jung B, 2004, P 12 ANN ACM INT C M
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kwon OB, 2003, EXPERT SYST APPL, V25, P387, DOI 10.1016/S0957-4174(03)00063-0
   Lienhart R., 1997, Communications of ACM, V40, P55
   Lin L, 2009, PATTERN RECOGN LETT, V30, P180, DOI 10.1016/j.patrec.2008.02.023
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Park SB, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P305
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P131, DOI 10.1016/j.jvcir.2008.12.002
   Rienks R., 2006, P 8 INT C MULTIMODAL, P257
   Ronfard R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P21
   Roth V, 1999, IMAGE VISION COMPUT, V17, P531, DOI 10.1016/S0262-8856(98)00144-9
   Rui Y, 1999, ACM MUL IN PRESS SEP
   Smeaton AF, 2007, INFORM SYST, V32, P545, DOI 10.1016/j.is.2006.09.001
   Smoliar S. W., 1994, IEEE Multimedia, V1, P62, DOI 10.1109/93.311653
   Turetsky R, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1659, DOI 10.1109/ICME.2004.1394570
   Vinciarelli A, 2006, P IEEE INT C MULT EX, P779
   Wasserman S., 1994, Social network analysis: Methods and applications'
   Weng CY, 2009, IEEE T MULTIMEDIA, V11, P256, DOI 10.1109/TMM.2008.2009684
   Yeung M, 1996, P IEEE MULT COMP SYS, P296
NR 28
TC 31
Z9 32
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 601
EP 627
DI 10.1007/s11042-011-0725-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000010
DA 2024-07-18
ER

PT J
AU Zaker, N
   Hamzeh, A
AF Zaker, Nazanin
   Hamzeh, Ali
TI A novel steganalysis for TPVD steganographic method based on differences
   of pixel difference histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Steganalysis; PVD; TPVD; Growing Anomalies
ID IMAGES
AB Tri-way Pixel Value Differencing (TPVD) steganographic method is a new modified version of another well-known method called PVD, which intents to increase embedding capacity and security of its successor by hiding secret bits in both vertical and diagonal edges of a cover image, in addition to the horizontal edges used in PVD. In this paper, it is shown that the histogram of difference values of a stego image under the TPVD algorithms is vulnerable to a particular statistical analysis. So, a new steganalytic measure named Growing Anomalies is introduced that its value has a linear relationship with secret message rate. It is shown empirically and theoretically that proposed steganalysis method based on this measure can estimate the amount of secret bits with a negligible error rate. The proposed steganalyser can classify test images as stego or cover with 97% accuracy when they contain more that 10% secret data. Implementation results indicate that proposed method can estimate secret message rate with an average accuracy of 95%.
C1 [Zaker, Nazanin; Hamzeh, Ali] Shiraz Univ, ECE Sch, CSE & IT Dept, Shiraz, Iran.
C3 Shiraz University
RP Zaker, N (corresponding author), Shiraz Univ, ECE Sch, CSE & IT Dept, Shiraz, Iran.
EM zaker@ieee.org; ali@cse.shirazu.ac.ir
OI Hamzeh, Ali/0000-0001-9873-4122
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Bui CN, 2010, INT J INNOV COMPUT I, V6, P3193
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Gul G, 2010, IEEE T INF FOREN SEC, V5, P349, DOI 10.1109/TIFS.2010.2041826
   Johnson N.F., 2001, Information Hiding: Steganography and Watermarking-Attacks and Countermeasures: Steganography and Watermarking: Attacks and Countermeasures, V1
   Johnson NF, 1998, LECT NOTES COMPUT SC, V1525, P273
   Joo JC, 2008, LECT NOTES COMPUT SC, V5353, P476
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   PROVOS N, 2001, CITI011A U MICH
   Sabeti V, 2010, PATTERN RECOGN, V43, P405, DOI 10.1016/j.patcog.2009.06.006
   Sabeti V, 2007, IEEE PACIF, P288
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zaker N, 2009, NTMS 09, P399, DOI [10.1109/NTMS.2009.5384692, DOI 10.1109/NTMS.2009.5384692]
   Zhang XP, 2004, PATTERN RECOGN LETT, V25, P331, DOI 10.1016/j.patrec.2003.10.014
NR 18
TC 14
Z9 15
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 147
EP 166
DI 10.1007/s11042-010-0714-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600007
DA 2024-07-18
ER

PT J
AU Fan, W
   Chen, ZY
   Chen, M
   Luo, LX
   Xiong, Z
AF Fan, Wei
   Chen, Zhenyong
   Chen, Ming
   Luo, Lixin
   Xiong, Zhang
TI Reversible data hiding with context modeling, generalized expansion and
   boundary map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boundary map; Context modeling; Generalized expansion; Reversible data
   hiding; Watermarking
ID LOSSLESS IMAGE COMPRESSION; DIFFERENCE EXPANSION; WATERMARKING; SCHEME;
   ALGORITHM; TRANSFORM
AB This paper proposes a reversible data hiding scheme with high capacity-distortion efficiency, which embeds data by expanding prediction-errors. Instead of using the MED predictor as did in other schemes, a predictor with context modeling, which refines prediction-errors through an error feedback mechanism, is adopted to work out prediction-errors. The context modeling can significantly sharpen the distribution of prediction-errors, and benefit the embedding capacity and the image quality. To expand prediction-errors, the proposed scheme utilizes a generalized expansion, which enables it to provide capacities larger than 1 bpp (bits per pixel) without resorting to multiple embedding. Besides, a novel boundary map is proposed to record overflow-potential pixels. The boundary map is much shorter compared with either a location map or an overflow map even though it is not compressed. The combination of the context modeling, the generalized expansion and the boundary map makes the overall scheme efficient in pursuing large embedding capacity and high image quality. Experimental results demonstrate that the proposed scheme provides competitive capacity compared with other state-of-the-art schemes when the image quality is kept at the same level.
C1 [Fan, Wei; Chen, Zhenyong; Chen, Ming; Luo, Lixin; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Fan, W (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM fanwei@cse.buaa.edu.cn; chzhyong@buaa.edu.cn; mingchen@cse.buaa.edu.cn;
   lixinluo@cse.buaa.edu.cn; xiongz@buaa.edu.cn
FU Fundamental Research Funds for the Central Universities, and Development
   Program of China; Beihang University
FX This work is supported by the Fundamental Research Funds for the Central
   Universities, and Development Program of China and Beihang University
   Graduate Innovation Fund. The authors would like to thank the anonymous
   reviewers for their valuable comments to improve the quality of the
   paper.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang Z, 2007, ELECTRON LETT, V43, P1353, DOI 10.1049/el:20072801
   Chen M, 2009, ACM MULTIMEDIA SECUR, P19
   Chen M, 2009, ICIP 2009 CAIR EG, P4253
   Chung KL, 2009, APPL MATH COMPUT, V208, P284, DOI 10.1016/j.amc.2008.10.066
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Jiang J, 2000, VISION IMAGE SIGNAL, P575
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim KS, 2008, ACM MULTIMEDIA SECUR, P69
   Kuribayashi M, 2008, IEICE T FUND ELECTR, VE91A, P1780, DOI 10.1093/ietfec/e91-a.7.1780
   Lee CC, 2008, PATTERN RECOGN, V41, P2097, DOI 10.1016/j.patcog.2007.11.018
   Lin Chin E., 2008, 2008 IEEE International Conference on Industrial Technology (ICIT), DOI 10.1109/ICIT.2008.4608417
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin CC, 2008, PATTERN RECOGN, V41, P1415, DOI 10.1016/j.patcog.2007.09.005
   Memon N, 1997, COMPUT J, V40, P127, DOI 10.1093/comjnl/40.2_and_3.127
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2008, IMAGE VISION COMPUT, V26, P1148, DOI 10.1016/j.imavis.2007.12.005
   Vasiliy S, 2008, LECT NOTES COMPUT SC, V5041, P254
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 29
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2012
VL 57
IS 3
BP 477
EP 499
DI 10.1007/s11042-010-0641-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HS
UT WOS:000301185900002
DA 2024-07-18
ER

PT J
AU Shirahama, K
   Matsuoka, Y
   Uehara, K
AF Shirahama, Kimiaki
   Matsuoka, Yuta
   Uehara, Kuniaki
TI Event retrieval in video archives using rough set theory and partially
   supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Query by example; Rough set theory; Bagging; Random subspace; Small
   sample size problem; Partially supervised learning
ID RANDOM SUBSPACE; CLASSIFICATION; EXAMPLES
AB This paper develops a query-by-example method for retrieving shots of an event (event shots) using example shots provided by a user. The following three problems are mainly addressed. Firstly, event shots cannot be retrieved using a single model as they contain significantly different features due to varied camera techniques, settings and so forth. This is overcome by using rough set theory to extract multiple classification rules with each rule specialized to retrieve a portion of event shots. Secondly, since a user can only provide a small number of example shots, the amount of event shots retrieved by extracted rules is inevitably limited. We thus incorporate bagging and the random subspace method. Classifiers characterize significantly different event shots depending on example shots and feature dimensions. However, this can result in the potential retrieval of many unnecessary shots. Rough set theory is used to combine classifiers into rules which provide greater retrieval accuracy. Lastly, counter example shots, which are a necessity for rough set theory, are not provided by the user. Hence, a partially supervised learning method is used to collect these from shots other than example shots. Counter example shots, which are as similar to example shots as possible, are collected because they are useful for characterizing the boundary between event shots and the remaining shots. The proposed method is tested on TRECVID 2009 video data.
C1 [Shirahama, Kimiaki] Kobe Univ, Grad Sch Econ, Nada Ku, Kobe, Hyogo 6578501, Japan.
   [Matsuoka, Yuta] Kobe Univ, Grad Sch Engn, Nada Ku, Kobe, Hyogo 6578501, Japan.
   [Uehara, Kuniaki] Kobe Univ, Grad Sch Syst Informat, Nada Ku, Kobe, Hyogo 6578501, Japan.
C3 Kobe University; Kobe University; Kobe University
RP Shirahama, K (corresponding author), Kobe Univ, Grad Sch Econ, Nada Ku, 2-1 Rokkodai, Kobe, Hyogo 6578501, Japan.
EM shirahama@econ.kobe-u.ac.jp; matuoka@ai.cs.scitec.kobe-u.ac.jp;
   uehara@kobe-u.ac.jp
FU (SCOPE) by the Ministry of Internal Affairs and Communications, Japan;
   Grants-in-Aid for Scientific Research [23300038] Funding Source: KAKEN
FX This research is supported in part by Strategic Information and
   Communications R&D Promotion Programme (SCOPE) by the Ministry of
   Internal Affairs and Communications, Japan.
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   Alpaydin E, 2004, INTRO MACHINE LEARNI
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2009, Hadoop: The definitive guide
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Fung GPC, 2006, IEEE T KNOWL DATA EN, V18, P6
   Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658
   Han J., 2006, DATA MINING CONCEPTS
   Hauptmann A, 2004, P 2004 IEEE INT C MU, P27
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Japkowicz N, 2000, IC-AI'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOL 1-III, P111
   Kashino K, 2003, IEEE T MULTIMEDIA, V5, P348, DOI 10.1109/TMM.2003.813281
   Komorowski J, 2002, HDB DATA MINING KNOW
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Liu B., 2002, ICML, P387
   Liu H, 2005, IEEE INTELL SYST, V20, P64, DOI 10.1109/MIS.2005.105
   Luszczek P, 2008, ENHANCING MULTIPLE S
   Mizui A, 2008, P TRECVID 2008, P123
   Natsev A., 2005, 13th Annual ACM International Conference on Multimedia, P598, DOI 10.1145/1101149.1101288
   Ngo C.W., 2009, Proc. of TRECVID, P415
   Peng YX, 2005, LECT NOTES COMPUT SC, V3568, P71
   Ranger C, 2007, INT S HIGH PERF COMP, P13
   Saha S, 2007, FUND INFORM, V76, P171
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shirahama K, 2009, P TRECVID 2009, P76
   Snoek C., 2009, P TRECVID2009, P226
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004
   Yao P, 2009, 2009 INTERNATIONAL CONFERENCE ON BUSINESS INTELLIGENCE AND FINANCIAL ENGINEERING, PROCEEDINGS, P138, DOI 10.1109/BIFE.2009.41
   Yu HJ, 2004, IEEE T KNOWL DATA EN, V16, P70, DOI 10.1109/TKDE.2004.1264823
   Yuan Jinhui., 2006, P 14 ANN ACM INT C M, P441
   Zhao G., 2005, Journal of the Institute of Image Information and Television Engineers, V59, P884, DOI 10.3169/itej.59.884
NR 38
TC 7
Z9 8
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 1
BP 145
EP 173
DI 10.1007/s11042-011-0727-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 898YR
UT WOS:000300778800010
OA hybrid
DA 2024-07-18
ER

PT J
AU Qin, C
   Wang, SZ
   Zhang, XP
AF Qin, Chuan
   Wang, Shuozhong
   Zhang, Xinpeng
TI Simultaneous inpainting for image structure and texture using
   anisotropic heat transfer model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Structure; Texture; PDE; Heat transfer; Anisotropic;
   Finite difference
ID OBJECT REMOVAL; COMPRESSION
AB We propose a PDE-based image inpainting method using anisotropic heat transfer model, which can simultaneously propagate the structure and texture information. In structure inpainting, the propagating direction and intensity are related to image contents, and the strength of propagation along gradient direction is made inversely proportional to the magnitude of gradient. In texture inpainting, the added texture term reflects periodicity along the texture and its perpendicular direction. For numerical implementation, the step size of finite difference is adaptively chosen according to the curvature, leading to fewer iteration steps and satisfactory inpainting quality. Compared with other high order PDE methods and layered methods, the proposed approach is more concise and doesn't need image decomposition. Experiments are carried out to show effectiveness of the method.
C1 [Qin, Chuan] Shanghai Univ Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Wang, Shuozhong; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai University
RP Qin, C (corresponding author), Shanghai Univ Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM qin@usst.edu.cn; shuowang@shu.edu.cn; xzhang@shu.edu.cn
RI Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU Natural Science Foundation of China [60872116, 60832010, 60773079];
   Shanghai Rising-Star Program [10QH14011]; Shanghai Education Committee
   [10ZZ59]; Shanghai Specialized Research Foundation for Excellent Young
   Teacher in University [slg09005]; OECE Innovation Foundation of USST
   [GDCX-Y-103]
FX This work was supported by the Natural Science Foundation of China
   (60872116, 60832010, and 60773079), the Shanghai Rising-Star Program
   (10QH14011), the Key Scientific Research Project of Shanghai Education
   Committee (10ZZ59), the Shanghai Specialized Research Foundation for
   Excellent Young Teacher in University (slg09005), and the OECE
   Innovation Foundation of USST (GDCX-Y-103).
CR Ballester C, 2007, IEEE T IMAGE PROCESS, V16, P2476, DOI 10.1109/TIP.2007.903844
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertalmio M., 2001, PROC CVPR IEEE, V1, P1, DOI DOI 10.1109/CVPR.2001.990497
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Hsu HJ, 2007, IEEE T IMAGE PROCESS, V16, P1611, DOI 10.1109/TIP.2007.896675
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Robles-Kelly A, 2004, INT C PATT RECOG, P94, DOI 10.1109/ICPR.2004.1334048
   Shih TK, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P71
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   WITKIN A, 1991, COMP GRAPH, V25, P299, DOI 10.1145/127719.122750
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhu ZJ, 2009, ELECTRON LETT, V45, P1310, DOI 10.1049/el.2009.2686
NR 19
TC 20
Z9 25
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 469
EP 483
DI 10.1007/s11042-010-0601-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700004
DA 2024-07-18
ER

PT J
AU Joshi, D
   Gallagher, A
   Yu, J
   Luo, J
AF Joshi, Dhiraj
   Gallagher, Andrew
   Yu, Jie
   Luo, Jiebo
TI Inferring photographic location using geotagged web images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geotagged images; Location probability maps; KNN; Visual matching
AB Geotagging has become a recent phenomenon that allows users to visualize and manage photo collections in many new and interesting ways. Unfortunately, manual geotagging of a large collection of pictures on the globe is still a time-consuming and laborious task even though geotagging devices are gradually being adopted. At the same time, there exist billions of legacy pictures taken before the onset of geotagging. In recent times, large collections of Web images have been found to facilitate a number of image understanding tasks including geolocation estimation. In this paper, we leverage user tags along with image content to infer the geolocation of images. Our model builds upon the fact that the visual content and user tags of pictures can together provide significant hints about their geolocations. Using a collection of over a million geotagged pictures, we build location probability maps for commonly used image tags over the entire globe. These maps reflect the collective picture-taking and tagging behaviors of thousands of users from all over the world. We further study the geographic entropy and frequency of user tags as geo-inference features and investigate the usefulness of using these features for selecting geographically meaningful annotations. On the other hand, visual content matching is performed using multiple feature descriptors including tiny images, color histograms, GIST features, and bags of textons. Finally, visual KNN matching based geographic mapping scheme is integrated with tag location probability maps to form a strong geo-inference engine. Experiments have shown improvements over geolocation inference performed using either modality alone.
C1 [Joshi, Dhiraj] Eastman Kodak Co, Kodak Res Labs, Rochester, NY USA.
C3 Eastman Kodak
RP Joshi, D (corresponding author), Eastman Kodak Co, Kodak Res Labs, Rochester, NY USA.
EM dhiraj.joshi@kodak.com
RI Luo, Jiebo/AAI-7549-2020
OI Luo, Jiebo/0000-0002-4516-9729
CR Ames M, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P971
   Amitay E., 2004, P ACM SIGIR C RES DE
   [Anonymous], P IEEE INT C MOB DAT
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P 19 NAT C ART INT
   [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], P INT C COMP VIS
   Chen Y, 2004, IBM J RES DEV, V48, P601, DOI 10.1147/rd.485.0601
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dubinko M, 2006, P WORLD WID WEB
   Gallagher Andrew, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P55, DOI 10.1109/CVPR.2009.5204168
   Hinze A, 2003, LECT NOTES COMPUT SC, V2750, P489
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   JAIN V, 2008, P INT C COMP VIS PAT
   Joshi D, 2008, ACM INT C IM VID RET
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Lazebnik S, 2006, P INT C COMP VIS PAT
   Li J, 2007, P ACM INT WORKSH MUL
   LI LJ, 2007, P INT C COMP VIS
   Luo J., 2008, ACM International Conference on Multimedia, P1071, DOI DOI 10.1145/1459359.1459574MULTIMEDIA-MM'PLACE
   Luo JB, 2006, IEEE SIGNAL PROC MAG, V23, P101
   Quack T, 2008, P ACM C IM VID RETR
   Schiller J., 2004, Location-Based Services
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Schindler G, 2008, PROC CVPR IEEE, P925
   Simon I, 2007, P IEEE INT C COMP VI
   TORRALBA A, 2007, MITCSAILTR2007024
   Wolf L, 2006, INT J COMPUT VISION, V68, P43, DOI 10.1007/s11263-005-4841-0
   Yu J, 2008, P ACM INT C IM VID R
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 33
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 131
EP 153
DI 10.1007/s11042-010-0553-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500007
DA 2024-07-18
ER

PT J
AU Kim, HN
   Roczniak, A
   Lévy, P
   El Saddik, A
AF Kim, Heung-Nam
   Roczniak, Andrew
   Levy, Pierre
   El Saddik, Abdulmotaleb
TI Social media filtering based on collaborative tagging in semantic space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social recommender system; Semantic collaborative filtering; Social
   tagging; Folksonomy; Semantic tagging; IEML
AB We propose a semantic collaborative filtering method to enhance recommendation quality derived from user-generated tags. Social tagging is employed as an approach in order to grasp and filter users' preferences for items. In addition, we explore several advantages of semantic tagging for ambiguity, synonymy, and semantic interoperability, which are notable challenges in information filtering. The proposed approach first determines semantically similar users using social tagging and subsequently discovers semantically relevant items for each user. Experimental results show that our method offers significant advantages both in terms of improving the recommendation quality and in dealing with ambiguity, synonymy, and interoperability issues.
C1 [Kim, Heung-Nam; Levy, Pierre] Univ Ottawa, Collect Intelligence Lab, Canada Res Chair Collect Intelligence, Ottawa, ON, Canada.
   [Kim, Heung-Nam; El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
   [Levy, Pierre] Univ Ottawa, Dept Commun, Ottawa, ON, Canada.
C3 University of Ottawa; University of Ottawa; University of Ottawa
RP Kim, HN (corresponding author), Univ Ottawa, Collect Intelligence Lab, Canada Res Chair Collect Intelligence, Ottawa, ON, Canada.
EM hnkim@mcrlab.uottawa.ca; roczniak@mcrlab.uottawa.ca;
   pierre.levy@mac.com; abed@mcrlab.uottawa.ca
RI /D-4159-2009
OI /0000-0002-7690-8547
FU Canada Research Chair in Collective Intelligence at University of Ottawa
FX The work was mainly funded since 2009 by the Canada Research Chair in
   Collective Intelligence at University of Ottawa.
CR Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99
   [Anonymous], 2010, FACEBOOK STAT
   [Anonymous], 2008, P 17 INT C WORLD WID
   Bao S., 2007, P 16 INT C WORLD WID, P501, DOI DOI 10.1145/1242572.1242640
   Bonhard P, 2006, BT TECHNOL J, V24, P84, DOI 10.1007/s10550-006-0080-3
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Jäschke R, 2008, AI COMMUN, V21, P231, DOI 10.3233/AIC-2008-0438
   Kim HN, 2010, ELECTRON COMMER R A, V9, P73, DOI 10.1016/j.elerap.2009.08.004
   Knowledge and Data Engineering Group, 2007, U KASS BENCHM FOLKS
   Lévy P, 2009, LECT NOTES ARTIF INT, V5796, P22
   Lévy P, 2010, INFORM SCIENCES, V180, P71, DOI 10.1016/j.ins.2009.08.001
   Li XH, 2008, IEEE T SIGNAL PROCES, V56, P675, DOI 10.1109/TSP.2007.907820
   Marchetti A., 2007, P TAGG MET SOC INF O
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Peis E., 2008, Semantic recommender systems. analysis of the state of the topic
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Sarwar B., 2000, EC'00. Proceedings of the 2nd ACM Conference on Electronic Commerce, P158, DOI 10.1145/352871.352887
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Schenkel R., 2008, SIGIR, DOI DOI 10.1145/1390334.1390424
   Siersdorfer S, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P261
   Tso-Sutter KHL, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1995
   Xu Z., 2006, COLL WEB TAGG WORKSH
   Zanardi V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P51
   Zhang ZK, 2010, PHYSICA A, V389, P179, DOI 10.1016/j.physa.2009.08.036
NR 28
TC 10
Z9 14
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 1
SI SI
BP 63
EP 89
DI 10.1007/s11042-010-0557-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 876SH
UT WOS:000299127500004
DA 2024-07-18
ER

PT J
AU Koubaa, M
   Elarbi, M
   Ben Amar, C
   Nicolas, H
AF Koubaa, Mohamed
   Elarbi, Maher
   Ben Amar, Chokri
   Nicolas, Henri
TI Collusion, MPEG4 compression and frame dropping resistant video
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Mosaic image; Collusion attack; MPEG4 compression;
   Frame dropping
AB We present in this article a new video watermarking which resists collusion, MPEG4 compression and frame dropping attacks. This scheme is based on video mosaicing. For that, we are going to start by describing the mosaicing technique in order to illustrate the contribution of this technique in video watermarking. In fact, mosaicing allows to select an interesting area where the mark should be embedded. The idea is to insert the same mark into the same pixels which represent the same physical point. This is exactly the information which can be provided by a mosaic image at least for the located points in the scene background. Next, we present extensive experimental simulations which prove the watermark imperceptibility and robustness against several video attacks.
C1 [Koubaa, Mohamed; Elarbi, Maher; Ben Amar, Chokri] Univ Sfax, Natl Sch Engineers ENIS, REGIM REs Grp Intelligent Machines, Sfax 3038, Tunisia.
   [Nicolas, Henri] Univ Bordeaux 1, LaBRI Lab Bordelais Rech Informat, F-33405 Talence, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Bordeaux
RP Koubaa, M (corresponding author), Univ Sfax, Natl Sch Engineers ENIS, REGIM REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM mohamed.koubaa@gmail.com; maher.elarbi@gmail.com;
   chokri.benamar@enis.rnu.tn; nicolas@labri.fr
RI Chokri, BEN AMAR/K-5237-2012
OI Nicolas, Henri/0000-0003-2179-4965
FU General Direction of Scientific Research (DGRST), Tunisia, under the
   ARUB
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Amir H, 2007, LECT NOTES COMPUTER, V4437, P343
   Cayre F, 2005, P SOC PHOTO-OPT INS, V5681, P746, DOI 10.1117/12.586876
   Cayre F, 2005, PROC SPIE, V5681, P758, DOI 10.1117/12.586890
   Charfeddine M, 2010, IEEE INT C SIGN PROC, P26
   Chong C, 2009, P 8 INT WORKSH DIG W, P81
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Doerr G., 2005, Traitement du Signal, V22, P563
   El'Arbi M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1131
   Elarbi M, 2010, MULTIMED TOOLS APPL, V50, P1
   Hernández JR, 1999, P IEEE, V87, P1142, DOI 10.1109/5.771069
   Hernandez-Avalos PA, 2009, MIDWEST SYMP CIRCUIT, P853, DOI 10.1109/MWSCAS.2009.5235901
   Iwan S, 2002, SECURITY WATERMARKIN, V4675, P520
   Jiande S, 2005, ICIP, P265
   Jiang X, 2008, NOVEL REAL TIME MPEG, P45
   Koubaa M, 2006, IEEE INT SYM MULTIM, P161
   Koubaa M, 2007, IEEE ICSPC DUB
   Lama R, 2009, EJSR, V30, P389
   Lertrusdachakul T, 2006, IMSA 06, P86
   Nicolas H, 2001, IEEE T IMAGE PROCESS, V10, P1239, DOI 10.1109/83.935039
   Patrick B, 2001, TS TRAIT SIGNAL, V18, P249
   Patrick B, 2001, APPL DIGITAL IMAGE P
   Sheng-Chuan T, 2002, INT COMP S, P85
   Su K, 2005, IEEE T MULTIMEDIA, V7, P43, DOI 10.1109/TMM.2004.840617
   Su K, 2001, IEEE IMAGE PROC, P818, DOI 10.1109/ICIP.2001.959171
   Su K, 2002, PROC SPIE, V4675, P491, DOI 10.1117/12.465307
   Swanson MD, 1998, IEEE J SEL AREA COMM, V16, P540, DOI 10.1109/49.668976
   Vicky ZH, 2005, IEEE T IMAGE PROCESS, V14, P646
   Wang HX, 2005, INT J INNOV COMPUT I, V1, P247
   Zhaowan S, 2009, NEURAL COMPUT APPL, V18, P507
NR 29
TC 20
Z9 20
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 281
EP 301
DI 10.1007/s11042-010-0626-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100004
DA 2024-07-18
ER

PT J
AU Wang, DL
   Zhang, Q
   Morris, J
AF Wang, Danling
   Zhang, Qin
   Morris, John
TI Distributed Markov Chain Monte Carlo kernel based particle filtering for
   object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle filter; Kernel function; MCMC; Local parallel scheme; Global
   parallel scheme
ID RESAMPLING ALGORITHMS
AB Particle filters are computationally intensive and thus efficient parallelism is crucial to effective implementations, especially object tracking in video sequences. Two schemes for pipelining particles under high performance computing environment, including an alternative Markov Chain Monte Carlo (MCMC) resampling algorithm and kernel function, are proposed so as to improve tracking performance and minimize execution time. Experimental results on a network of workstations composed of simple off-the-shelf hardware components show that global parallelizable scheme provides a promising resolution to clearly reduce execution time with increasing particles, compared with generic particle filtering.
C1 [Wang, Danling; Zhang, Qin] Commun Univ China, Sch Informat & Engn, Beijing, Peoples R China.
   [Morris, John] Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand.
C3 Communication University of China; University of Auckland
RP Wang, DL (corresponding author), Commun Univ China, Sch Informat & Engn, Beijing, Peoples R China.
EM wangdl@cuc.edu.cn; zhangqin@cuc.edu.cn; jmor59@cs.auckland.ac.nz
FU National Science Foundation of China [60572041, 60832004]
FX This research was supported by the National Science Foundation of China
   under Grants 60572041 and 60832004.
CR Bolic M, 2004, EURASIP J APPL SIG P, V2004, P2267, DOI 10.1155/S1110865704405149
   Chang C, 2005, IEEE SIGNAL PROC LET, V12, P242, DOI 10.1109/LSP.2004.842254
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   Cho JU, 2007, IEEE INT CONF ROBOT, P4639, DOI 10.1109/ROBOT.2007.364194
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Higuchi T, 1997, J STAT COMPUT SIM, V59, P1, DOI 10.1080/00949659708811843
   Hong S, 2006, J VLSI SIG PROC SYST, V44, P47, DOI 10.1007/s11265-006-5919-9
   Huang A., 2005, A Tutorial on Bayesian Estimation and Tracking Techniques Applicable to Non-Linear and Non-Gaussian Process
   Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2592, DOI 10.1109/TSP.2003.816758
   Liu JS, 2001, LECT NOTES COMPUTER
   MASKELL S, 2006, P NONL STAT SIGN PRO
   Míguez J, 2007, SIGNAL PROCESS, V87, P3155, DOI 10.1016/j.sigpro.2007.06.011
   Musa ZB, 2008, LECT NOTES ARTIF INT, V5179, P119, DOI 10.1007/978-3-540-85567-5_16
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   Quinn M.J., 2003, Parallel Programming in C with MPI and OpenMP
   RISTIC BS, 2004, KALMAR FILTER PARTIC
   Rui Y, 2001, PROC CVPR IEEE, P786
   SUTHARSAN S, 2005, P SOC PHOTO-OPT INS, V5913, P87
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 20
TC 3
Z9 4
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 303
EP 314
DI 10.1007/s11042-010-0646-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100005
DA 2024-07-18
ER

PT J
AU Tomás, B
   Pereira, F
AF Tomas, Bruno
   Pereira, Fernando
TI Musical slideshow: boosting user experience in photo presentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photo presentation; Musical slideshow; Color descriptors; Music beating;
   Content-based; Time-based
ID IMAGE ORIENTATION DETECTION; LAYOUTS
AB With the advance of digital acquisition and storage technology, people got used to take photos at will and to record almost any event with (many) photos. However, large amounts of photos without appropriate organization for access and consumption raise several potential problems, reducing the users' quality of experience. Therefore, to facilitate an effective photo selection and organization process making the consumption process more enjoyable, it is useful to develop advanced image analysis and presentation tools, eventually integrating also some music content in a synchronized way, to further boost the photo presentation user experience. As people's time is getting more precious and scarce, the availability of applications able to automatically generate a musical slideshow as a pleasant way to consume large amounts of photos is highly desirable. In this context, this paper describes the context and motivation for the development of a musical slideshow application, the architecture designed and the entire signal processing flow implemented. To assess the performance of this multimedia application, a user evaluation methodology was designed and applied with promising results, showing that the developed application is able to create entertaining and efficient photo presentation experiences.
C1 [Tomas, Bruno; Pereira, Fernando] Inst Super Tecn, Inst Telecomunicacoes, P-1049001 Lisbon, Portugal.
C3 Universidade de Lisboa; Instituto de Telecomunicacoes
RP Pereira, F (corresponding author), Inst Super Tecn, Inst Telecomunicacoes, Av Rovisco Pais, P-1049001 Lisbon, Portugal.
EM brunocondetomas@gmail.com; fp@lx.it.pt
RI Pereira, Fernando/K-4046-2012; Pereira, Fernando/HNR-7786-2023
OI Bernardo Pereira, Fernando Manuel/0000-0001-6100-947X
CR CHEN JC, 2006, ACM INT C MULT SAN B
   Chu WT, 2007, IEEE MULTIMEDIA, V14, P36, DOI 10.1109/MMUL.2007.66
   Geigel J, 2003, IEEE MULTIMEDIA, V10, P16, DOI 10.1109/MMUL.2003.1237547
   HUA XS, 2003, IEEE INT S CIRCUITS, V2, P648
   *JAP EL IND DEV AS, 1998, CP3451 JEITZ JAP EL
   Kustanowitz J, 2006, IEEE MULTIMEDIA, V13, P62, DOI 10.1109/MMUL.2006.83
   Luo JB, 2005, IEEE T PATTERN ANAL, V27, P715, DOI 10.1109/TPAMI.2005.96
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Manjunath B.S., 2002, INTRO MPEG 7
   Scheirer ED, 1998, J ACOUST SOC AM, V103, P588, DOI 10.1121/1.421129
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Vailaya A, 2002, IEEE T IMAGE PROCESS, V11, P746, DOI [10.1109/TIP.2002.801590, 10.1109/TIP2002.801590]
   MP3 HEADER CLASS
NR 13
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 627
EP 653
DI 10.1007/s11042-010-0582-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600012
DA 2024-07-18
ER

PT J
AU Shan, YX
   Liu, J
AF Shan, Yuxiang
   Liu, Jia
TI Robust speaker recognition in cross-channel condition based on Gaussian
   mixture model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Cross-channel; Echo cancellation; Latent factor analysis; Noise
   reduction; Score normalization; Speaker verification
ID VARIABILITY; INFORMATION; FEATURES
AB One of the most difficult challenges for speaker recognition is dealing with channel variability. In this paper, several new cross-channel compensation techniques are introduced for a Gaussian mixture model-universal background model (GMM-UBM) speaker verification system. These new techniques include wideband noise reduction, echo cancellation, a simplified feature-domain latent factor analysis (LFA) and data-driven score normalization. A novel dynamic Gaussian selection algorithm is developed to reduce the feature compensation time by more than 60% without any performance loss. The performance of different techniques across varying channel train/test conditions are presented and discussed, finding that speech enhancement, which used to be neglected for telephone speech, is essential for cross-channel tasks, and the channel compensation techniques developed for telephone channel speech also perform effectively. The per microphone performance analysis further shows that speech enhancement can boost the effects of other techniques greatly, especially on channels with larger signal-to-noise ratio (SNR) variance. All results are presented on NIST SRE 2006 and 2008 data, showing a promising performance gain compared to the baseline. The developed system is also compared with other state-of-the-art speaker verification systems. The result shows that the developed system can obtain comparable or even better performance but consumes much less CPU time, making it more suitable for practical use.
C1 [Shan, Yuxiang; Liu, Jia] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Liu, J (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM syx06@mails.tsinghua.edu.cn; liuj@tsinghua.edu.cn
CR [Anonymous], P EUROSPEECH 03
   [Anonymous], 2008, NIST YEAR 2008 SPEAK
   Burget L, 2007, IEEE T AUDIO SPEECH, V15, P1979, DOI 10.1109/TASL.2007.902499
   CAMPBELL B, 2006, NIST SRE 2006 MIT LI
   Campbell WilliamM., 2004, Advances in Neural Information Processing Systems, V16
   Dehak N, 2007, IEEE T AUDIO SPEECH, V15, P2095, DOI 10.1109/TASL.2007.902758
   Ferrer L, 2008, INT CONF ACOUST SPEE, P4853, DOI 10.1109/ICASSP.2008.4518744
   Ferrer L, 2006, INT CONF ACOUST SPEE, P101
   HE L, 2008, P IEEE AS PAC C CIRC
   HOU T, CHINESE J E IN PRESS
   *ITU T, 1996, G 723 1 ANN A SPEECH
   Kajarekar SS, 2005, INT CONF ACOUST SPEE, P173
   Kenny P, 2008, IEEE T AUDIO SPEECH, V16, P980, DOI 10.1109/TASL.2008.925147
   *LING DAT CONS, 2008, MIX 4 5 CORP SUPP SR
   *NAT I STAND TECHN, 2008, NIST SPEAK REC WORKS
   Pelecanos J., 2001, Proc. Speaker Odyssey, V13, P1
   PELLOM BL, 2001, IEEE SIGNAL PROCESSI, V8
   Reynolds D, 2003, INT CONF ACOUST SPEE, P784
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Stolcke A, 2007, IEEE T AUDIO SPEECH, V15, P1987, DOI 10.1109/TASL.2007.902859
   STURIM D, 2005, P IEEE INT C AC SPEE
   STURIM DE, 2007, P IEEE INT C AC SPEE
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   VAIR C, 2006, SPEAK OD WORKSH
NR 24
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 159
EP 173
DI 10.1007/s11042-009-0456-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500013
DA 2024-07-18
ER

PT J
AU Shi, MH
   Fu, R
   Guo, Y
   Bai, SX
   Xu, BG
AF Shi, Meihong
   Fu, Rong
   Guo, Yong
   Bai, Shixian
   Xu, Bugao
TI Fabric defect detection using local contrast deviations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Fabric defect detection; Local contrast deviation (LCD); Image
   segmentation
ID TEXTURE
AB Defect inspection is a vital step for quality assurance in fabric production. The development of a fully automated fabric defect detection system requires robust and efficient fabric defect detection algorithms. The inspection of real fabric defects is particularly challenging due to delicate features of defects complicated by variations in weave textures and changes in environmental factors (e.g., illumination, noise, etc.). Based on characteristics of fabric structure, an approach of using local contrast deviation (LCD) is proposed for fabric defect detection in this paper. LCD is a parameter used to describe features of the contrast difference in four directions between the analyzed image and a defect-free image of the same fabric, and is used with a bilevel threshold function for defect segmentation. The validation tests on the developed algorithms were performed with fabric images from TILDA's Textile Texture Database and captured by a line-scan camera on an inspection machine. The experimental results show that the proposed method has robustness and simplicity as opposed to the approach of using modified local binary patterns (LBP).
C1 [Xu, Bugao] Univ Texas Austin, Dept Human Ecol, Austin, TX 78712 USA.
   [Shi, Meihong; Fu, Rong; Guo, Yong; Bai, Shixian] Xian Polytechn Univ, Sch Comp Sci, Xian 710048, Peoples R China.
C3 University of Texas System; University of Texas Austin; Xi'an
   Polytechnic University
RP Xu, BG (corresponding author), Univ Texas Austin, Dept Human Ecol, Austin, TX 78712 USA.
EM bxu@mail.utexas.edu
CR CHEN JJ, 2006, TEX RES J, V27, P36
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Conci A, 2000, J TEXT I, V91, P317, DOI 10.1080/00405000008659509
   FUSHENG Y, 2000, ENG ANAL APPL BASED, P32
   Jasper WJ, 1996, OPT ENG, V35, P3140, DOI 10.1117/1.601054
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kuo CFJ, 2003, TEXT RES J, V73, P238, DOI 10.1177/004051750307300307
   LI LQ, 2002, J DONGHUA U, V28, P118
   LI LQ, 2001, J DONGHUA U, V27, P82
   Meylani R, 2006, IEICE T FUND ELECTR, VE89A, P1484, DOI 10.1093/ietfec/e89-a.5.1484
   Sezer OG, 2007, PATTERN RECOGN, V40, P121, DOI 10.1016/j.patcog.2006.05.023
   TAJERIPOUR F, 2008, EURASIP J ADV SIG PR, V1155, P1
   *WORK TEXT AN DFG, TILDA TEXT TEXT DAT
   ZHANG YXF, 1995, TEXT RES J, V65, P1, DOI 10.1177/004051759506500101
NR 16
TC 18
Z9 22
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 147
EP 157
DI 10.1007/s11042-010-0472-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500012
DA 2024-07-18
ER

PT J
AU Zou, YX
   Shi, GY
   Shi, H
   Zhao, H
AF Zou, Yuexian
   Shi, Guangyi
   Shi, Hang
   Zhao, He
TI Traffic incident classification at intersections based on image
   sequences by HMM/SVM classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE ITS; Traffic incident detection; HMM; SVM; Intersection
AB With the development of modern intelligent transportation systems (ITS), automatic traffic incident detection with quick response and high accuracy becomes one of the most important issues, especially for metropolitan streets that are full of signaled intersections. In this paper, we present our up-to-date research outcomes of the traffic incident detection system, which makes use of the image sequences gathered from a typical urban intersection. Basic image signal processing was used to extract image difference information for traffic image database construction. Feature extraction algorithms were then discussed and compared including PCA, FFT, and hybrid analysis of DCT-FFT. Finally, multi-classification of traffic signal logics (East-West, West-East, South-North, North-South) and accidents were realized by HMM (Hidden Markov Model) and SVM (Support Vector Machine) respectively. Experimental results showed that the hybrid DCT-FFT method gives the best features, and classification performance of SVM is superior to HMM with limited training samples, where the correction rate is 100% for SVM and 91% for HMM.
C1 [Zou, Yuexian; Shi, Guangyi; Shi, Hang; Zhao, He] Peking Univ, Shenzhen Grad Sch, Adv Digital Signal Proc Lab, Shenzhen, Peoples R China.
C3 Peking University
RP Shi, GY (corresponding author), Peking Univ, Shenzhen Grad Sch, Adv Digital Signal Proc Lab, Shenzhen, Peoples R China.
EM gyshi@szpku.edu.cn
RI Zhao, He/I-1463-2016
OI Zhao, He/0000-0001-5763-9743
CR Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dia H, 1997, TRANSPORT RES C-EMER, V5, P313, DOI 10.1016/S0968-090X(97)00016-8
   DOUGHERTY M, 1995, TRANSPORT RES C-EMER, V3, P247, DOI 10.1016/0968-090X(95)00009-8
   Ikeda H., 1999, Proceedings 199 IEEE/IEEJ/JSAI International Conference on Intelligent Transportation Systems (Cat. No.99TH8383), P748, DOI 10.1109/ITSC.1999.821154
   Kamijo Shunsuke, 2000, IEEE transactions on Intelligent Transportation Systems, V1
   KI YK, 2007, IEEE T INTELL TRANSP, V9
   LEE SH, P 4 ANN ACIS INT C C
   LIN CP, 2003, P 2003 IEEE INT C RO
   Owens J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P77, DOI 10.1109/VS.2000.856860
   Vapnik V., 1999, NATURE STAT LEARNING
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   ZOU YX, 2009, IEEE INT C HYBR INT
NR 12
TC 11
Z9 14
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 133
EP 145
DI 10.1007/s11042-010-0466-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500011
DA 2024-07-18
ER

PT J
AU Joho, H
   Staiano, J
   Sebe, N
   Jose, JM
AF Joho, Hideo
   Staiano, Jacopo
   Sebe, Nicu
   Jose, Joemon M.
TI Looking at the viewer: analysing facial activity to detect personal
   highlights of multimedia contents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial activity; Facial expression; Affective summarization
ID MODELS; CLASSIFIERS; RETRIEVAL; FRAMEWORK
AB This paper presents an approach to detect personal highlights in videos based on the analysis of facial activities of the viewer. Our facial activity analysis was based on the motion vectors tracked on twelve key points in the human face. In our approach, the magnitude of the motion vectors represented a degree of a viewer's affective reaction to video contents. We examined 80 facial activity videos recorded for ten participants, each watching eight video clips in various genres. The experimental results suggest that useful motion vectors to detect personal highlights varied significantly across viewers. However, it was suggested that the activity in the upper part of face tended to be more indicative of personal highlights than the activity in the lower part.
C1 [Staiano, Jacopo; Sebe, Nicu] Univ Trent, Dept Informat Engn & Comp Sci, I-38100 Trento, Italy.
   [Joho, Hideo] Univ Tsukuba, Dept Lib Informat & Media Studies, Tsukuba, Ibaraki 3058550, Japan.
   [Jose, Joemon M.] Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Lanark, Scotland.
C3 University of Trento; University of Tsukuba; University of Glasgow
RP Sebe, N (corresponding author), Univ Trent, Dept Informat Engn & Comp Sci, Via Sommar 14, I-38100 Trento, Italy.
EM hideo@slis.tsukuba.ac.jp; staiano@disi.unitn.it; sebe@disi.unitn.it;
   joemon.jose@glasgow.ac.uk
RI Sebe, Niculae/KEC-2000-2024; Staiano, Jacopo/AAA-5977-2022; Staiano,
   Jacopo/B-8976-2015
OI Sebe, Niculae/0000-0002-6597-7248; Staiano, Jacopo/0000-0002-1260-4640;
   Jose, Joemon/0000-0001-9228-1759
FU EU [IST-033715]; european project; FIRB S-PATTERNS
FX Funding was provided by the MIAUCE Project (EU IST-033715). Any
   opinions, findings, and conclusions described here are the authors and
   do not necessarily reflect those of the sponsor. The work of Jacopo
   Staiano and Nicu Sebe has been supported by the FP7 IP GLOCAL european
   project and by the FIRB S-PATTERNS project.
CR [Anonymous], 2000, THESIS U ILLINOIS UR
   ARIFIN S, 2007, ACM INT C MULT
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   CHEON Y, 2009, PATTERN RECOGN, V42, P260
   Ching Hau Chan, 2005, 13th Annual ACM International Conference on Multimedia, P427, DOI 10.1145/1101149.1101243
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   DIETZ R, 1999, COGN TECHN C
   Ekman P, 1978, FACIAL ACTION CODING
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2008, P IEEE, V96, P541, DOI 10.1109/JPROC.2008.916338
   Huijsmans DP, 2005, IEEE T PATTERN ANAL, V27, P245, DOI 10.1109/TPAMI.2005.30
   Jaimes A, 2007, COMPUTER, V40, P30, DOI 10.1109/MC.2007.169
   JOHO H, 2009, ACM INT C IM VID RET
   KANG H, 2002, ACM INT C MULT
   MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   MONCRIEFF S, 2001, ACM INT C MULT
   MONEY A, 2008, AFFECT EMOTION HUMAN
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   MOONEY C, 2006, EUR C INF RETR, P570
   OVER P, 2007, TVS 07, P1
   Sebe N, 2005, MULTIMEDIA SYST, V10, P484, DOI 10.1007/s00530-005-0177-4
   Soleymani M., 2008, P 2 ACM WORKSHOP MUL, P32, DOI DOI 10.1145/1460676.1460684
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Tao H, 1998, PROC CVPR IEEE, P735, DOI 10.1109/CVPR.1998.698685
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   XU M, 2005, IEEE INT C MULT EXP
NR 31
TC 59
Z9 62
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 505
EP 523
DI 10.1007/s11042-010-0632-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300005
DA 2024-07-18
ER

PT J
AU Rama, A
   Tarres, F
   Rurainsky, J
AF Rama, Antonio
   Tarres, Francesc
   Rurainsky, Juergen
TI Aligned texture map creation for pose invariant face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D Face recognition; Partial PCA; PCA; Eigenfaces; Image stitching;
   Image alignment
ID HEAD
AB In last years, Face recognition based on 3D techniques is an emergent technology which has demonstrated better results than conventional 2D approaches. Using texture (180A degrees multi-view image) and depth maps is supposed to increase the robustness towards the two main challenges in Face Recognition: Pose and illumination. Nevertheless, 3D data should be acquired under highly controlled conditions and in most cases depends on the collaboration of the subject to be recognized. Thus, in applications such as surveillance or control access points, this kind of 3D data may not be available during the recognition process. This leads to a new paradigm using some mixed 2D-3D face recognition systems where 3D data is used in the training but either 2D or 3D information can be used in the recognition depending on the scenario. Following this concept, where only part of the information (partial concept) is used in the recognition, a novel method is presented in this work. This has been called Partial Principal Component Analysis (P(2)CA) since they fuse the Partial concept with the fundamentals of the well known PCA algorithm. This strategy has been proven to be very robust in pose variation scenarios showing that the 3D training process retains all the spatial information of the face while the 2D picture effectively recovers the face information from the available data. Furthermore, in this work, a novel approach for the automatic creation of 180A degrees aligned cylindrical projected face images using nine different views is presented. These face images are created by using a cylindrical approximation for the real object surface. The alignment is done by applying first a global 2D affine transformation of the image, and afterward a local transformation of the desired face features using a triangle mesh. This local alignment allows a closer look to the feature properties and not the differences. Finally, these aligned face images are used for training a pose invariant face recognition approach (P(2)CA).
C1 [Rama, Antonio; Tarres, Francesc] Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
   [Rurainsky, Juergen] HHI, Image Proc Dept, Fraunhofer Inst Telecommun, Berlin, Germany.
C3 Universitat Politecnica de Catalunya; Fraunhofer Gesellschaft
RP Rama, A (corresponding author), Univ Politecn Cataluna, Dept Signal Theory & Commun, Barcelona, Spain.
EM tonirama@gps.tsc.upc.edu; tarres@gps.tsc.upc.edu;
   rurainsky@hhi.fraunhofer.de
RI Tarres, Francesc R/L-8860-2014
OI Tarres, Francesc/0000-0003-0920-4782
FU EC
FX The work presented was developed within VISNET II, a European Network Of
   Excellence funded under the EC IST FP6 programme.
CR AKIMOTO T, 1993, IEEE COMPUT GRAPH, V13, P16, DOI 10.1109/38.232096
   [Anonymous], 1985, Introduction to non-linear optimization
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BOWYER K, 2004, IEEE INTLCONF PATT R
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Brown LM, 2001, PROC CVPR IEEE, P998
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   FARKAS LG, 1995, ANTHROPOMETRY HEAD F
   KOUZANI A, 1999, P IEEE INT C SYST MA, P835
   La Cascia M, 1998, PROC CVPR IEEE, P508, DOI 10.1109/CVPR.1998.698653
   Lee WS, 2000, IMAGE VISION COMPUT, V18, P355, DOI 10.1016/S0262-8856(99)00057-8
   Lewis J., 1995, Fast normalized cross-correlation
   ONOFRIO D, 2006, IEEE INT C IM PROC A
   PHILLIPS PJ, 2003, 6965 NISTIR
   PRETZEL L, 2007, RES PROJECT FACE REC
   RAMA A, 2005, IEEE INT C IM PROC G
   SAVVIDES M, 2004, INT C PATT REC WASH
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Soh AlvinW K., 2002, International Journal of Information Technology, V8, P54
   Szeliski R., 2004, MSRTR200492
   TSAPATSOULIS N, 1998, IEEE ICASSP SEATTL W
   Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050
   Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048
   YANG J, 2004, IEEE T PATTERN A JAN
   YOUNG JW, 1993, ADA268661 FED AV ADM
   Zhao W., 2006, FACE PROCESSING ADV
   UPC FACE DATABASE
NR 28
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2010
VL 49
IS 3
SI SI
BP 545
EP 565
DI 10.1007/s11042-009-0447-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 608ZF
UT WOS:000278623800009
DA 2024-07-18
ER

PT J
AU Viana, P
   Alves, AP
AF Viana, Paula
   Alves, Artur Pimenta
TI A semantic management model to enable the integrated management of media
   and devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media asset management; Metadata integration; Semantic metadata
   management; Multimedia and infrastructures ontologies
ID MULTIMEDIA; ONTOLOGIES; MPEG-7; XML
AB The challenge of managing large scale media assets has led to the development of metadata schemas that are expected to enable efficient search and retrieval of multimedia content. Those approaches propose schemas that can range from simple keyword based descriptions to complex hierarchical organization of information. However, effective media asset management requires more than content searching and retrieval: underlying infrastructures are usually complex, require the use of a number of different equipment and management decisions have to be done based on information available from the multimedia metadata layer as well as on data describing system resources and capabilities. In this paper we propose a new ontology that aggregates information from different sources and enables a top level business oriented view of multimedia archives.
C1 [Viana, Paula] Inst Politecn Porto, Inst Super Engn Porto, P-4200072 Oporto, Portugal.
   [Viana, Paula; Alves, Artur Pimenta] INESC Porto, P-4200465 Oporto, Portugal.
   [Alves, Artur Pimenta] Univ Porto, Fac Engn, P-4200465 Oporto, Portugal.
C3 Instituto Politecnico do Porto; INESC TEC; Universidade do Porto;
   Universidade do Porto
RP Viana, P (corresponding author), Inst Politecn Porto, Inst Super Engn Porto, Rua Dr Antonio Bernardino de Almeida 431, P-4200072 Oporto, Portugal.
EM pviana@isep.ipp.pt; pviana@inescporto.pt
RI Viana, Paula/T-2920-2019
OI Viana, Paula/0000-0001-8447-2360
CR [Anonymous], 15938 ISOIEC
   [Anonymous], XML SCHEM
   [Anonymous], RDF PRIM
   [Anonymous], P C INN DAT RES CIDR
   [Anonymous], 2004, W3C RECOMMENDATION 1
   ANTONIOU G, 2003, WEB ONTOLOGY LANGUAG, P76
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   Bertini M, 2007, INT J PARALLEL EMERG, V22, P407, DOI 10.1080/17445760701207652
   Brickley D., 2004, RDF VOCABULARY DESCR
   CASE JD, 1990, SIMPLE NETWORK MANAG, V1157
   Choi MJ, 2004, IEEE COMMUN MAG, V42, P84, DOI 10.1109/MCOM.2004.1316538
   de Vergara JEL, 2004, IEEE COMMUN MAG, V42, P68, DOI 10.1109/MCOM.2004.1316535
   *DMTF, 2008, CIM SCHEM V2 17 1
   Doan A., 2004, HDB ONTOLOGIES, P385, DOI DOI 10.1007/978/3/540-24750-0
   *EBU, 1995, 24 EBU ESCORT
   *EBU, 2007, 3295V2 EBU
   ETSI, 2006, 10282231 ETSI TS
   *ETSI, 2006, 102822314 ETSI TS
   ETSI EN 300 468, 1998, 300468 ETSI EN
   *FIAT IFTA DOC COM, 1992, MIN DAT LIST
   Garcia R., 2006, P SEM WEB ANN MULT W
   GARCIA R, 2005, P 4 INT SEM WEB C IS
   Garcia R, 2007, ARTIF INTELL LAW, V15, P137, DOI 10.1007/s10506-007-9032-6
   Gil R., 2005, IAAIL WORKSHOP SERIE, P135
   HOPPER R, 2002, EBU TECHNICAL REV, V290
   Hunter J, 2003, IEEE T CIRC SYST VID, V13, P49, DOI 10.1109/TCSVT.2002.808088
   *IEEE, 2000, 12441 IEEE
   ISAAC A, 2004, CEUR P, V118
   MADHAVAN J, 2003, 18 INT JOINT C ART I, P59
   Martin M, 2002, ATHLET THER TODAY, V7, P7, DOI 10.1123/att.7.3.7
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   MCCLOGHRIE K, 1991, MANAGEMENT INFORM BA, V1213
   Menten LE, 2004, IEEE COMMUN MAG, V42, P92, DOI 10.1109/MCOM.2004.1316539
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   Quirolgico S, 2004, LECT NOTES COMPUT SC, V3307, P11
   Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057
   Roitman H, 2006, LECT NOTES COMPUT SC, V4254, P573
   *SMPTE, 2001, 335M2001 SMPTE
   Straccia U, 2005, LECT NOTES COMPUT SC, V3806, P133
   Troncy R, 2003, LECT NOTES COMPUT SC, V2870, P566
   Tsinaraki C, 2005, MULTIMED TOOLS APPL, V26, P299, DOI 10.1007/s11042-005-0894-x
   Tsinaraki C, 2004, BIOMED SCI INSTRUM, V3084, P398
   TSINARAKI C, 2004, LNCS, V3115, P2050
   VERGARA J, 2003, P HP OP U ASS 10 PLE
   VERGARA JEL, 2005, LNCS, V3775, P1
   VERGARA JEL, 2004, LNCS, V3079, P1007
   VIANA Paula., 2008, Media Asset Management in Broadcasting-New approaches to enable the effective management of physical resources and media objects
   W3C, 2006, EXT MARK LANG XML 1
NR 48
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2010
VL 49
IS 1
SI SI
BP 37
EP 62
DI 10.1007/s11042-009-0395-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 595WF
UT WOS:000277643600003
DA 2024-07-18
ER

PT J
AU Kamel, I
   Akinlar, C
   El-Sayed, H
AF Kamel, Ibrahim
   Akinlar, Cuneyt
   El-Sayed, Hesham
TI QoS guarantee for multimedia traffic in smart homes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia systems; QoS; Smart spaces; Smart home; VoD
AB With the advent of home networking and widespread deployment of broadband connectivity to homes, a wealth of new services with real-time Quality of Service (QoS) requirements have emerged, e.g., Video on Demand (VoD), IP Telephony, which have to co-exist with traditional non-real-time services such as Web browsing and file downloading over the Transmission Control Protocol (TCP). The co-existence of such real-time and non-real-time services demands the residential gateway (RG) to employ bandwidth management algorithms to control the amount of non-real-time TCP traffic on the broadband access link from the Internet Service Provider (ISP) to the RG so that the bandwidth requirements of the real-time traffic are satisfied. In this paper we propose an algorithm to control the aggregate bandwidth of the incoming non-real-time TCP traffic at the RG so that QoS requirements of the real-time traffic can be guaranteed. The idea is to limit the maximum data rates of active TCP connections by dynamically manipulating their flow control window sizes based on the total available bandwidth for the non-real-time traffic. We show by simulation results that our algorithm limits the aggregate bandwidth of the non-real-time TCP traffic thus granting the real-time traffic the required bandwidth.
C1 [Kamel, Ibrahim] Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
   [Akinlar, Cuneyt] Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
   [El-Sayed, Hesham] UAE Univ, Coll Informat Technol, Al Ain, U Arab Emirates.
C3 University of Sharjah; Anadolu University; United Arab Emirates
   University
RP Kamel, I (corresponding author), Univ Sharjah, Dept Elect & Comp Engn, Sharjah, U Arab Emirates.
EM kamel@sharjah.ac.ae; cakinlar@anadolu.edu.tr; helsayed@uaeu.ac.ae
RI Akinlar, Cuneyt/AAH-7483-2019; Akinlar, Cuneyt/U-5132-2019
OI Kamel, Ibrahim/0000-0001-5546-939X; AKINLAR, CUNEYT/0000-0002-0961-7790
CR AKINLAR C, 2002, IEEE INT C WIR LANS
   Allman Mark., 1998, ACM Computer Communication Review
   Azuma K, 2006, INT J COMMUN SYST, V19, P751, DOI 10.1002/dac.767
   BENNETT JCR, 1996, P IEEE INFOCOM SAN F
   Breslau L, 2000, COMPUTER, V33, P59, DOI 10.1109/2.841785
   CLEVENOT F, 2005, P PERF 2005
   CROVELLA M, 1998, P IEEE INFOCOM
   CROWCROFT J, 1998, DIFFERENTIATED END T
   DONG Y, 2002, PRACTICAL TECHNIQUE
   FLOYD S, 2000, EQUATION BASED CONGE
   GUPTA M, 2003, P ACM 5 INT WORKSH N
   HAWNG W, 2005, IEEE T CONSUMER ELEC, V51
   HOE J, 1998, IMPROVING START BEHA
   HSIAO PH, 2001, P IEEE GLOB
   HUANG T, 2009, J NETWORKS COMPUTER, V32
   Jacobson V., 1988, Computer Communication Review, V18, P314, DOI 10.1145/52325.52356
   JAIN M, 2003, GITCERCS0302 COLL CO
   KUZMANOVIC KE, 2003, P IEEE INFOCOM
   LIU S, 2007, 15 IEEE INT WORKSH Q, P21
   MA RTB, 2004, P ACM SIGMETRICS PER
   Mehra P, 2005, IEEE T MULTIMEDIA, V7, P740, DOI 10.1109/TMM.2005.846783
   Mehra P., 2003, P IEEE INFOCOM
   PADHYE J, 1996, MODELING TCP THROUGH
   POSTEL J, 1981, 793 RFC INF SCI I
   Semke J., 1998, Computer Communication Review, V28, P315, DOI 10.1145/285243.285292
   Spring N. T., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P245, DOI 10.1109/INFCOM.2000.832194
   STEVENS W, 1996, TCP IP ILLUSTRATED, V1
   STOICA I, 1998, P ACM SIGC
   TANENBAUM, 1994, COMPUTER NETWORKS
   Tsugawa T, 2006, IEICE T COMMUN, VE89B, P2152, DOI 10.1093/ietcom/e89-b.8.2152
   *UCB LBNL VINT, UCB LBNL VINT NETW S
   Venkataramani A, 2002, COMPUT COMMUN, V25, P367, DOI 10.1016/S0140-3664(01)00408-X
   VENKATARAMANI RK, 2002, P OP SYST DES IMPL
   Wu C, 2007, IEEE J SEL AREA COMM, V25, P222, DOI 10.1109/JSAC.2007.070122
NR 34
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 87
EP 103
DI 10.1007/s11042-009-0408-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400006
DA 2024-07-18
ER

PT J
AU Yu, ZW
   Zhou, XS
   Shu, L
AF Yu, Zhiwen
   Zhou, Xingshe
   Shu, Lei
TI Towards a semantic infrastructure for context-aware e-learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic learning space; E-learning; Context-aware; Semantic Web;
   Infrastructure
ID FRAMEWORK
AB Architectural supports, e.g., user context processing and learning content management are essential for facilitating the development and proliferation of context-aware e-learning services. In this paper, we propose a context-aware e-learning infrastructure called Semantic Learning Space. It leverages the Semantic Web technologies to support semantic knowledge representation, systematic context management, interoperable content integration, expressive knowledge query, and adaptive content recommendation. The functionality encapsulated in the infrastructure handles the common, time-consuming and low-level details in learning context processing and content management. The architectural design and enabling technologies are described in detail. Finally, the prototype implementation and preliminary experimental results are presented.
C1 [Yu, Zhiwen; Zhou, Xingshe] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Shu, Lei] Natl Univ Ireland, Digital Enterprise Res Inst, Galway, Ireland.
C3 Northwestern Polytechnical University; Ollscoil na Gaillimhe-University
   of Galway
RP Yu, ZW (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM zhiwenyu@nwpu.edu.cn
RI zhou, xt/GWZ-9212-2022; Zhou, Xiangfeng/KDO-8724-2024; Shu,
   Lei/JQW-2386-2023; zhou, xing/GQP-4516-2022
OI Shu, Lei/0000-0002-6700-9347; 
FU High-Tech Program of China [2009AA011903]; National Natural Science
   Foundation of China [60903125, 60803044]; Specialized Research Fund for
   the Doctoral Program of Higher Education [20070699014]; France ICT-Asia
   project; Science Foundation Ireland [SFI/08/CE/I1380]
FX This work was partially supported by the High-Tech Program of China
   (863) (No. 2009AA011903), the National Natural Science Foundation of
   China (No. 60903125, 60803044), Specialized Research Fund for the
   Doctoral Program of Higher Education (No. 20070699014), France ICT-Asia
   project "I-CROSS: Impromptu, Context-aware and Trustworthy Service
   Provision in Heterogeneous and Unfamiliar Spaces", and the Science
   Foundation Ireland under grant No. SFI/08/CE/I1380 (Lion-2).
CR *ACM, ACM TAX
   [Anonymous], P WORLD C WWW INT WE
   Carroll Jeremy J., 2004, P 13 INT WORLD WID W, P74, DOI [10.1145/, DOI 10.1145/1013367.1013381]
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Fischer G, 2001, USER MODEL USER-ADAP, V11, P65, DOI 10.1023/A:1011145532042
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   Huang WH, 2006, BRIT J EDUC TECHNOL, V37, P351, DOI 10.1111/j.1467-8535.2006.00610.x
   Jovanovic J, 2007, IEEE INTERNET COMPUT, V11, P45, DOI 10.1109/MIC.2007.116
   McGuinness D.L., OWL Web Ontology Language Overview
   MILLER L, 2002, P 1 INT SEM WEB C IS, P423
   NABETH T, 2005, COMPUTER SCI INFORM, V2, P99
   Ni HB, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P846
   Ogata H, 2004, 2ND IEEE INTERNATIONAL WORKSHOP ON WIRELESS AND MOBILE TECHNOLOGIES IN EDUCATION, P27
   Paraskakis I., 2005, Proc. 3rd Int. Conf. on multimedia and Information Communication Technologies in Education (m-ICTE2005), P26
   Schmidt A, 2004, J UNIVERS COMPUT SCI, V10, P38
   SIMON B, 2003, 12 INT WORLD WID WEB, P616
   Tane J., 2004, WWW, P1, DOI DOI 10.1145/1013367.1013369
   UHLMANN S, 12 INT C ENT MED UB, P117
   Wolf C., 2003, ACE 03 P 5 AUSTRALAS, V20, P273
   Yang SJH, 2006, EDUC TECHNOL SOC, V9, P188
   Yu ZW, 2008, IEEE PERVAS COMPUT, V7, P62, DOI 10.1109/MPRV.2008.69
   Yu ZW, 2007, LECT NOTES COMPUT SC, V4611, P898
   Yu ZW, 2006, USER MODEL USER-ADAP, V16, P63, DOI 10.1007/s11257-006-9005-6
   Yu ZW, 2006, IEEE PERVAS COMPUT, V5, P68, DOI 10.1109/MPRV.2006.61
NR 24
TC 13
Z9 13
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2010
VL 47
IS 1
BP 71
EP 86
DI 10.1007/s11042-009-0407-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 554LV
UT WOS:000274437400005
DA 2024-07-18
ER

PT J
AU Van Deursen, D
   Van Lancker, W
   De Neve, W
   Paridaens, T
   Mannens, E
   Van de Walle, R
AF Van Deursen, Davy
   Van Lancker, Wim
   De Neve, Wesley
   Paridaens, Tom
   Mannens, Erik
   Van de Walle, Rik
TI NinSuna: a fully integrated platform for format-independent multimedia
   content adaptation and delivery using Semantic Web technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE BSDL; Format-independent; Multimedia adaptation; Multimedia delivery;
   Multimedia model; Semantic Web; XML
ID BITSTREAM SYNTAX DESCRIPTION; XML
AB The current multimedia landscape is characterized by a significant heterogeneity in terms of coding and delivery formats, usage environments, and user preferences. The main contribution of this paper is a discussion of the design and functioning of a fully integrated platform for multimedia adaptation and delivery, called NinSuna. This platform is able to efficiently deal with the aforementioned heterogeneity in the present-day multimedia ecosystem, thanks to the use of format-agnostic adaptation engines (i.e., engines independent of the underlying coding format) and format-agnostic packaging engines (i.e., engines independent of the underlying delivery format). Moreover, NinSuna also provides a seamless integration between metadata standards and adaptation processes. Both our format-independent adaptation and packaging techniques rely on a model for multimedia bitstreams, describing the structural, semantic, and scalability properties of these multimedia streams. News sequences were used as a test case for our platform, enabling the user to select news fragments matching his/her specific interests and usage environment characteristics.
C1 [Van Deursen, Davy; Van Lancker, Wim; De Neve, Wesley; Paridaens, Tom; Mannens, Erik; Van de Walle, Rik] Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Van Deursen, D (corresponding author), Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, Gaston Crommenlaan 8,Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM davy.vandeursen@elis.ugent.be; wim.vanlancker@elis.ugent.be;
   wesley.deneve@kaist.ac.kr; tom.paridaens@elis.ugent.be;
   erik.mannens@elis.ugent.be; rik.vandewalle@elis.ugent.be
RI De Neve, Wesley Marcel/C-6480-2008
OI De Neve, Wesley Marcel/0000-0002-8190-3839; Mannens,
   Erik/0000-0001-7946-4884
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT); Fund for Scientific Research-Flanders
   (FWO-Flanders); European Union
FX The research activities as described in this paper were funded by Ghent
   University, the Interdisciplinary Institute for Broadband Technology
   (IBBT), the Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT), the Fund for Scientific Research-Flanders
   (FWO-Flanders), and the European Union.
CR AMIELH M, 2002, P 11 INT WORLD WID W
   Amielh M, 2001, P 8 INT C MULT MOD A, P127
   [Anonymous], 1593852003 ISOIEC
   [Anonymous], 3550 RFC
   ARNDT R, 2007, 6 INT SEM WEB C ISWC
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Clark Kendall Grant, 2008, SPARQL PROTOCOL RDF
   De Neve W, 2005, LECT NOTES COMPUT SC, V3767, P641
   Decker S, 2000, IEEE INTERNET COMPUT, V4, P63, DOI 10.1109/4236.877487
   Devillers S, 2005, IEEE T MULTIMEDIA, V7, P463, DOI 10.1109/TMM.2005.846794
   *DUBL COR MET IN, 2004, DUBL COR MET EL SET
   Eleftheriadis A., 1997, Proceedings ACM Multimedia 97, P1, DOI 10.1145/266180.266319
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   Hong D, 2008, MULTIMED TOOLS APPL, V39, P101, DOI 10.1007/s11042-007-0157-0
   *ISO IEC, 2004, 14496142003 ISOIEC
   *ISO IEC, 2007, 21000182007 ISOIEC
   *ISO IEC, 2008, 230005 ISOIEC
   *ISO IEC, 2004, 2100072004 ISOIEC
   *ISO IEC, 2007, 2100072007FPDAMD2 IS
   *ISO IEC JTC 1, 1993, 1117231993 ISOIEC JT
   *ISO IEC JTC 1, 2005, 1449632005 ISOIEC JT
   *ISO IEC JTC 1, 2008, 1381822000 ISOIEC JT
   *ITU T, 2003, H264 ITUT
   Klyne G, 2004, Resource description framework (RDF): Concepts and abstract syntax
   McGuinness D.L., 2004, W3C RECOMMENDATION, V10
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Panis G, 2003, SIGNAL PROCESS-IMAGE, V18, P721, DOI 10.1016/S0923-5965(03)00061-4
   PFEIFFER S, 2003, MIR 03, P87
   Prud'hommeaux Eric., 2007, SPARQL QUERY LANGUAG
   R, 1999, HYPERTEXT TRANSFER P
   RANSBURG M, 2007, P 6 WORKSH MULT SEM
   *RFC, 1998, 2327 RFC
   *RFC, 2005, 3984 RFC
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   *SMPTE, 2004, 377M2004 SMPTE
   SRINIVASAN S, 2007, P SPIE, V6696
   Thomas-Kerr J, 2008, IEEE T MULTIMEDIA, V10, P514, DOI 10.1109/TMM.2008.917337
   VANDEURSEN D, 2007, P 9 INT S MULT WASH, P131
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P16, DOI 10.1109/MSP.2003.1184335
   *W3C MULT SEM INC, 2006, INC ACT W3C MULT SEM
   2009, SUMO SUGGESTED UPPER
   [No title captured]
NR 43
TC 11
Z9 11
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 371
EP 398
DI 10.1007/s11042-009-0354-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300010
DA 2024-07-18
ER

PT J
AU Kim, KS
   Lee, HY
   Lee, HK
AF Kim, Kyung-Su
   Lee, Hae-Yeoun
   Lee, Heung-Kyu
TI Supplementary loss concealment technique for image transmission through
   data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Loss concealment; Data hiding; JPEG compression; Image transmission
ID ERROR CONCEALMENT; VIDEO; TRANSFORM
AB This paper addresses a loss concealment technique of image transmission in error prone environments. Imperfect transmission of imagery results in the loss of lines or blocks. Previous concealment techniques utilize the spatial, spectral, or temporal redundancy of the imagery. We propose a supplementary loss concealment technique that uses a data-hiding method. We divide an image into 8 x 8 pixels blocks and generate block description information of each block. The block description information is inserted into other blocks in the same image through LSB-based data hiding. Missing lines or blocks during transmission are restored by extracting this block description information. The technique to resist against lossy compression is also considered. We have performed a simulation to show the outstanding performance of the proposed technique in comparison with other loss concealment methods.
C1 [Lee, Hae-Yeoun] Kumoh Natl Inst Technol, Sch Comp & Software Engn, Gumi, Gyeongbuk, South Korea.
   [Kim, Kyung-Su; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.
C3 Kumoh National University Technology; Korea Advanced Institute of
   Science & Technology (KAIST)
RP Lee, HY (corresponding author), Kumoh Natl Inst Technol, Sch Comp & Software Engn, 1 Yanghodong, Gumi, Gyeongbuk, South Korea.
EM haeyeoun.lee@kumoh.ac.kr
RI Lee, Heung Kyu/C-1941-2011
FU Korea government (MEST) [ROA-2007-000-20023-0]; Defense Acquisition
   Program Administration and Agency for Defense Development
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) grant funded by the Korea government (MEST) (No.
   ROA-2007-000-20023-0), and Defense Acquisition Program Administration
   and Agency for Defense Development under the contract.
CR ANHARI AK, 2008, P INT C TEL, P1
   Bashiri D, 2008, 2008 INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS, VOLS 1 AND 2, P792, DOI 10.1109/ISTEL.2008.4651408
   Chung YJ, 1999, IEEE T CIRCUITS-II, V46, P951, DOI 10.1109/82.775393
   Gür G, 2007, IEEE COMMUN LETT, V11, P179, DOI 10.1109/LCOMM.2007.061055
   HEMAMI SS, 1995, IEEE T IMAGE PROCESS, V4, P1023, DOI 10.1109/83.392344
   Hwang MC, 2008, IEEE T BROADCAST, V54, P198, DOI 10.1109/TBC.2008.917274
   Jayalakshmi M, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P1713
   Jo MH, 2007, IET IMAGE PROCESS, V1, P141, DOI 10.1049/iet-ipr:20060290
   Kang LW, 2006, J VIS COMMUN IMAGE R, V17, P1127, DOI 10.1016/j.jvcir.2006.08.003
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Lee SH, 2001, ELECTRON LETT, V37, P218, DOI 10.1049/el:20010147
   MA Y, 2006, P INT C DIG TEL, P21
   NAVATHE B, 2006, J ELECTRON IMAGING, V15, P1, DOI DOI 10.1117/1.2204453
   SHI Y, 2008, P C IMAGE SIGNAL PRO, V1, P264, DOI DOI 10.1109/CISP.2008.45
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wu TH, 2008, IEEE INT SYMP CIRC S, P3466, DOI 10.1109/ISCAS.2008.4542205
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 20
TC 2
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2009
VL 44
IS 1
BP 1
EP 16
DI 10.1007/s11042-009-0265-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 457KJ
UT WOS:000266926600001
DA 2024-07-18
ER

PT J
AU Schroeder, R
   Mello, RD
AF Schroeder, Rebeca
   Mello, Ronaldo dos Santos
TI Designing XML documents from conceptual schemas and workload information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conceptual schemas; XML schemas; Workload; Query performance
AB Due to the increase of XML-based applications, XML schema design has become an important task. One approach is to consider conceptual schemas as a basis for generating XML documents compliant to consensual information of specific domains. However, the conversion of conceptual schemas to XML schemas is not a straightforward process and inconvenient design decisions can lead to a poor query processing on XML documents generated. This paper presents a conversion approach which considers data and query workload estimated for XML applications, in order to generate an XML schema from a conceptual schema. Load information is used to produce XML schemas which can respond well to the main queries of an XML application. We evaluate our approach through a case study carried out on a native XML database. The experimental results demonstrate that the XML schemas generated by our methodology contribute to a better query performance than related approaches.
C1 [Schroeder, Rebeca; Mello, Ronaldo dos Santos] Univ Fed Santa Catarina, Informat & Stat Dept, BR-88040900 Florianopolis, SC, Brazil.
C3 Universidade Federal de Santa Catarina (UFSC)
RP Schroeder, R (corresponding author), Univ Fed Santa Catarina, Informat & Stat Dept, BR-88040900 Florianopolis, SC, Brazil.
EM rebecks@inf.ufsc.br; ronaldo@inf.ufsc.br
CR AG S, 2008, WEB METHODS TAMINO S
   [Anonymous], 2007, XQuery 1.0: An XML Query Language
   [Anonymous], 2000, EXTENSIBLE MARKUP LA
   [Anonymous], 1992, Conceptual Database Design-An entity-relationship Approach
   BARBOSA D, 2002, P WEBDB
   BIRD L, 2000, INT C CONC MOD, P661
   Camillo SD, 2003, LECT NOTES COMPUT SC, V2813, P186
   CHOI M, 2003, INT C COMP SCI, P920
   CONRAD R, 2000, INT C CONC MOD, P558
   Elmasri R., 1985, Data & Knowledge Engineering, V1, P75, DOI 10.1016/0169-023X(85)90027-8
   Fong J, 2006, INT J SOFTW ENG KNOW, V16, P201, DOI 10.1142/S0218194006002744
   JAGADISH H, 2002, VLDB J, V4, P274
   Liu CF, 2006, LECT NOTES COMPUT SC, V4016, P508, DOI 10.1007/11775300_43
   MANI M, 2004, INT XML DAT S, P128
   Mok WY, 2006, IEEE T KNOWL DATA EN, V18, P1082, DOI 10.1109/TKDE.2006.125
   PIGOZZO P, 2005, IT S ADV DAT SYST, P192
   ROUTLEDGE N, 2002, AUSTR DAT C, P157
   Schöning H, 2001, PROC INT CONF DATA, P149, DOI 10.1109/ICDE.2001.914823
   Schroeder R, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1036
   Schroeder R, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P177
   Smith J. M., 1977, ACM Transactions on Database Systems, V2, P105, DOI 10.1145/320544.320546
   Stephens LM, 2004, WORLD WIDE WEB, V7, P421, DOI 10.1023/B:WWWJ.0000040801.68204.2b
   Thompson H.S., 2001, Recommendation REC-xmlschema-1-20041028.
   WIWATWATTANA N, 2006, INT C DAT ENG
   XIAO H, 2006, LECT NOTES COMPUT SC, V4, P67
   Xu ZC, 2003, SEVENTH INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P76
NR 26
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2009
VL 43
IS 3
BP 303
EP 326
DI 10.1007/s11042-009-0272-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 450HY
UT WOS:000266392800006
DA 2024-07-18
ER

PT J
AU Lian, SG
AF Lian, Shiguo
TI Quasi-commutative watermarking and encryption for secure media content
   distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Video encryption; Digital rights management (DRM);
   Commutative watermarking and encryption (CWE)
ID MPEG VIDEO; ATTACKS
AB Commutative Watermarking and Encryption (CWE) provides a solution for interoperation between watermarking and encryption. It realizes the challenging operation that embeds a watermark into the encrypted multimedia data directly, which avoids the decryption-watermarking-encryption triples. Till now, few CWE schemes have been reported. They often obtain the commutative property by partitioning multimedia data into independent parts (i.e., the encryption part and the watermarking part). Since the two parts are isolated, it can not keep secure enough against replacement attacks. To avoid the disadvantage, a novel quasi-commutative watermarking and encryption (QCWE) scheme based on quasi-commutative operations is proposed in this paper. In the proposed scheme, the encryption operation and watermarking operation are applied to the same data part. Since the two operations are homogenous with commutative properties, their orders can be commutated. As an example, the scheme for MPEG2 video encryption and watermarking is presented. In this example, the DCs in intra macroblocks are encrypted or watermarked based on random module addition, while the DCs in other macroblocks and all the ACs' signs are encrypted with a stream cipher or block cipher. Analysis and experiments show that the scheme obtains high perceptual security and time efficiency, and the watermarking and encryption operations can be commutated. These properties make the scheme a suitable choice for efficient media content distribution. Additionally, the paper shows the availability of constructing the commutative watermarking and encryption scheme with homogenous operations, which is expected to activate the new research topic.
C1 France Telecom R&D Orange Labs Beijing, Beijing 100080, Peoples R China.
RP Lian, SG (corresponding author), France Telecom R&D Orange Labs Beijing, Bejing 2 Sci Inst S Rd, Beijing 100080, Peoples R China.
EM shiguo.lian@orange-ftgroup.com
CR Anderson R, 1997, LECT NOTES COMPUT SC, V1267, P107
   Bloom JA, 1999, P IEEE, V87, P1267, DOI 10.1109/5.771077
   Changgui Shi, 1998, Proceedings ACM Multimedia 98, P81
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   *ECRYPT EUR NETW E, 2005, 1 ECRYPT EUR NETW EX
   Furht B., 2004, MULTIMEDIA SECURITY
   Golomb S. W., 1967, SHIFT REGISTER SEQUE
   Hauer E, 2004, PROC SPIE, V5306, P315, DOI 10.1117/12.526859
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   *ISO IEC, 1994, 138182 ISOIEC IS
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lemma A, 2006, LECT NOTES COMPUT SC, V4283, P433
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lian SG, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1523
   Lian SG, 2006, IEEE IMAGE PROC, P1953, DOI 10.1109/ICIP.2006.312797
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   Lin ET, 2005, P IEEE, V93, P171, DOI 10.1109/JPROC.2004.839623
   Mao YN, 2006, IEEE T IMAGE PROCESS, V15, P2061, DOI 10.1109/TIP.2006.873426
   Mollin R.A., 2006, An introduction to cryptography
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Qiao L., 1997, Las Vegas : Proceedings of the 1s International Conference on Imaging Science, Systems and Technology, P21
   Simitopoulos D, 2003, MULTIMEDIA SYST, V9, P217, DOI 10.1007/s00530-003-0093-4
   TOSUN AS, 2002, TECHNICAL REPORT COM
   Uehara T, 2006, IEEE T IMAGE PROCESS, V15, P3592, DOI 10.1109/TIP.2006.881939
   Wang SH, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.065202
   Wang YL, 2006, IEEE T IMAGE PROCESS, V15, P1536, DOI 10.1109/TIP.2006.873476
   WU T, 1997, INT C IM SCI SYST TE
   Yeung SF, 2005, IEEE T MULTIMEDIA, V7, P330, DOI 10.1109/TMM.2005.843361
   YEUNG SF, 2002, ACM MULT C JUAN LES
   Zeng WJ, 2003, IEEE T MULTIMEDIA, V5, P118, DOI 10.1109/TMM.2003.808817
   Zeng WJ, 1999, IEEE T IMAGE PROCESS, V8, P1534, DOI 10.1109/83.799882
NR 36
TC 32
Z9 37
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 43
IS 1
BP 91
EP 107
DI 10.1007/s11042-008-0258-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 425HF
UT WOS:000264626900005
DA 2024-07-18
ER

PT J
AU Shi, ZP
   He, Q
   Shi, ZZ
AF Shi, Zhiping
   He, Qing
   Shi, Zhongzhi
TI An index and retrieval framework integrating perceptive features and
   semantics for multimedia databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBMR; High-dimensional index; Semantics; Relevance feedback
ID IMAGE RETRIEVAL
AB Typically, in multimedia databases, there exist two kinds of clues for query: perceptive features and semantic classes. In this paper, we propose a novel framework for multimedia databases index and retrieval integrating the perceptive features and semantic classes to improve the speed and the precision of the content-based multimedia retrieval (CBMR). We develop a semantics supervised clustering based index approach (briefly as SSCI): the entire data set is divided hierarchically into many clusters until the objects within a cluster are not only close in the perceptive feature space but also within the same semantic class, and then an index term is built for each cluster. Especially, the perceptive feature vectors in a cluster are organized adjacently in disk. So the SSCI-based nearest-neighbor (NN) search can be divided into two phases: first, the indexes of all clusters are scanned sequentially to get the candidate clusters with the smallest distances from the query example; second, the original feature vectors within the candidate clusters are visited to get search results. Furthermore, if the results are not satisfied, the SSCI supports an effective relevance feedback (RF) search: users mark the positive and negative samples regarded a cluster as unit instead of a single object; then the Bayesian classifiers on perceptive features and that on semantics are used respectively to adjust retrieval similarity distance. Our experiments show that SSCI-based searching was faster than VA(+)-based searching; the quality of the search result based on SSCI was better than that of the sequential search in terms of semantics; and a few cycles of the RF by the proposed approach can improve the retrieval precision significantly.
C1 [Shi, Zhiping; He, Qing; Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Shi, ZP (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM shizp@ics.ict.ac.cn
RI shi, zhiping/J-9594-2012; He, Qing/C-1249-2013
OI Shi, Zhiping/0000-0002-3562-8602
CR [Anonymous], P 3 ACM INT C MULT S
   [Anonymous], P ACM INT C MAN DAT
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BOUJEMAA N, 1999, 10 DELOS WORKSH AUD
   Chen Y, 2001, PROC SPIE, V4315, P292, DOI 10.1117/12.410939
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Ferhatosmanoglu H., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P202, DOI 10.1145/354756.354820
   Ferhatosmanoglu H, 2006, INFORM SYST, V31, P512, DOI 10.1016/j.is.2005.01.001
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Liang Shuang, 2006, Journal of Computer Aided Design & Computer Graphics, V18, P1753
   Meilhac C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P512, DOI 10.1109/MMCS.1999.779254
   Mittal A, 2004, IEEE T KNOWL DATA EN, V16, P230, DOI 10.1109/TKDE.2004.1269600
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   NIEVERGELT J, 1984, ACM T DATABASE SYST, V9, P38, DOI 10.1145/348.318586
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Rui Y, 2000, PROC CVPR IEEE, P236, DOI 10.1109/CVPR.2000.855825
   Shi Zhi-Ping, 2005, Journal of Software, V16, P1039, DOI 10.1360/jos161039
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   Su Zhong, 2002, Journal of Software, V13, P2001
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   WEBER R, 2000, P 7 INT C EXT DAT TE
   Ye HJ, 2003, LECT NOTES COMPUT SC, V2728, P477
NR 26
TC 4
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 207
EP 231
DI 10.1007/s11042-008-0235-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300004
DA 2024-07-18
ER

PT J
AU Baraldi, S
   Del Bimbo, A
   Landucci, L
AF Baraldi, Stefano
   Del Bimbo, Alberto
   Landucci, Lea
TI Natural interaction on tabletops
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Natural Interaction
CY APR, 2004
CL Florence, ITALY
DE HCI; natural interaction; tabletop interaction; wiki; multimedia
   interface
AB We present two different Computer Vision based systems that enable multiple users to concurrently manipulate graphic objects presented over tabletop displays. The two solutions have different hardware layouts and use two different algorithms for gesture analysis and recognition. The first one is a media-handling application that can be used by co-located and remote users. The second is a knowledge-building application where users can manipulate the contents of a wiki as a visual concept map. The performance of both systems is evaluated and expounded. A conceptual framework is introduced, providing the fundamental guidelines for the design of natural interaction languages on tabletops.
C1 [Baraldi, Stefano; Del Bimbo, Alberto; Landucci, Lea] Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
C3 University of Florence
RP Baraldi, S (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
EM Stefano.baraldi@gmail.com
OI DEL BIMBO, ALBERTO/0000-0002-1052-8322
CR AIFANTI S, 2002, GESTURE RECOGNITION
   [Anonymous], P 14 ANN ACM S US IN
   [Anonymous], 2002, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/503376.503413
   APPERLEY M, 2001, S HUM COMP INT PALM
   BERARD C, 2001, BARE HAND HUMAN COMP
   Cadoz C., 1994, Les realites virtuelles: Un expose pour comprendre, un essai pour reflechir
   FRIGOLA M, 2003, VISUAL HUMAN MACHINE
   *GTCO CALCOMP, 2007, INT M SUIT
   ISAACS J, 2004, HAND POSE ESTIMATION
   KAPUSCINSKI T, 2001, HAND GESTURE RECOGNI
   LEIBE B, 2000, PERCEPTIVE WORKBENCH
   LETESSIER J, 2004, P 17 ANN ACM S US IN
   MARSIC I, 2002, NATURAL COMMUNICATIO
   MULDER A, 1996, 96I S FRAS U SCH KIN
   MULDER A, 1996, HAND GESTURES HCI RE
   Norman D. A., 1988, PSYCHOL EVERYDAY THI
   Novak J.D., 1998, LEARNING CREATING US
   OHAGAN R, 2000, VISUAL GESTURE INTER
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   RYALL K, 2006, IEEE INT WORKSH HOR
   Scott S.D., 2003, P ECSCW 03 EUR C COM
   Shen Chia., 2004, CHI 04, P167, DOI DOI 10.1145/985692.985714
   Smart Technologies, SMART BOARD
   STARNER T, 2000, GESTURE PENDANT SELF
   STEFIK M, 1987, P ACM T OFF INF SYST
   TSE E, 2004, P 5 AUSTR US INT C A, P101
NR 26
TC 5
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2008
VL 38
IS 3
BP 385
EP 405
DI 10.1007/s11042-007-0195-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 300ZV
UT WOS:000255866300006
DA 2024-07-18
ER

PT J
AU Behera, A
   Lalanne, D
   Ingold, R
AF Behera, Ardhendu
   Lalanne, Denis
   Ingold, Rolf
TI DocMIR: An automatic document-based indexing system for meeting
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE meeting recordings; automated meeting indexing and retrieval;
   low-resolution document identification; multimedia content extraction;
   multimedia IR
AB This paper describes the DocMIR system which captures, analyzes and indexes automatically meetings, conferences, lectures, etc. by taking advantage of the documents projected (e.g. slideshows, budget tables, figures, etc.) during the events. For instance, the system can automatically apply the above-mentioned procedures to a lecture and automatically index the event according to the presented slides and their contents. For indexing, the system requires neither specific software installed on the presenter's computer nor any conscious intervention of the speaker throughout the presentation. The only material required by the system is the electronic presentation file of the speaker. Even if not provided, the system would temporally segment the presentation and offer a simple storyboard-like browsing interface. The system runs on several capture boxes connected to cameras and microphones that records events, synchronously. Once the recording is over, indexing is automatically performed by analyzing the content of the captured video containing projected documents and detects the scene changes, identifies the documents, computes their duration and extracts their textual content. Each of the captured images is identified from a repository containing all original electronic documents, captured audio-visual data and metadata created during post-production. The identification is based on documents' signatures, which hierarchically structure features from both layout structure and color distributions of the document images. Video segments are finally enriched with textual content of the identified original documents, which further facilitate the query and retrieval without using OCR. The signature-based indexing method proposed in this article is robust and works with low-resolution images and can be applied to several other applications including real-time document recognition, multimedia IR and augmented reality systems.
C1 [Behera, Ardhendu; Lalanne, Denis; Ingold, Rolf] Univ Fribourg, Dept Informat, CH-1700 Fribourg, Switzerland.
C3 University of Fribourg
RP Behera, A (corresponding author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM ardhendu.behera@unifr.ch; denis.lalanne@unifr.ch; rolf.ingold@unifr.ch
RI ; Behera, Ardhendu/O-2213-2015
OI Ingold, Rolf/0000-0001-7738-133X; Lalanne, Denis/0000-0001-7834-0417;
   Behera, Ardhendu/0000-0003-0276-9000
CR Abowa G. D., 1996, Proceedings ACM Multimedia 96, P187, DOI 10.1145/244130.244191
   Adar E, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P413, DOI 10.1145/319950.323231
   Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   [Anonymous], 2003, P 11 ACM INT C MULT
   Barakonyi I, 2004, PROC GRAPH INTERF, P89
   Behera A, 2005, PROC INT CONF DOC, P468, DOI 10.1109/ICDAR.2005.104
   BEHERA A, 2005, INT J SIGNAL PROCESS, V1304, P7
   BEHERA A, 2006, THESIS
   BEHERA A, 2004, P ACM S DOC ENG MILW, P178
   BIANCHI MH, 1998, JOINT DARPA NIST SMA
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   Brotherton JA, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P54, DOI 10.1109/MMCS.1998.693625
   Chiu P., 2000, IEEE Multimedia, V7, P48, DOI 10.1109/93.895154
   Chiu P, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P149, DOI 10.1145/319463.319483
   CHIU P, 2000, P HYP 00, P244
   Cutler R., 2002, MULTIMEDIA 02, P503, DOI DOI 10.1145/641007.641112
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gemmell J., 2002, P 10 ACM INT C MULTI, P235, DOI DOI 10.1145/641007.641053
   GEYER W, 2001, P 2001 INT ACM SIGGR, P188
   Girgensohn A, 1999, HUMAN-COMPUTER INTERACTION - INTERACT '99, P205
   Hadjar K, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P212, DOI 10.1109/DIAL.2004.1263250
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Hunter J., 2001, Research and Advanced Technology for Digital Libraries. 5th European Conference, ECDL 2001. Proceedings (Lecture Notes in Computer Science Vol.2163), P415
   LALANNE D, 2004, LNCS, V3361, P87
   LALANNE D, 2005, IM2 MULTIMODAL M BRO
   Lee Dar-Shyang., 2002, P 10 ACM INT C MULT, P493
   LIM JS, 1990, 2DIMENSIONAL SIGNAL
   Lu T, 2004, MULTIMED TOOLS APPL, V22, P89, DOI 10.1023/B:MTAP.0000008661.37331.c7
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Nakanishi H, 1999, IEEE MULTIMEDIA, V6, P20, DOI 10.1109/93.771370
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PETKOVIC M, 2000, P C EXT DAT TECHN KO, P74
   Prince S., 2002, Proceedings of the 2002 ACM Conference on Computer Supported Cooperative Work, P364, DOI [DOI 10.1145/587078.587129, 10.1145/587078.587129]
   Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482
   Rui Y, 2004, MULTIMEDIA SYST, V10, P3, DOI 10.1007/s00530-004-0132-9
   Scott DW, 2015, WILEY SER PROBAB ST, P1
   Shirmohammadi S, 2003, MULTIMED TOOLS APPL, V19, P135, DOI 10.1023/A:1022143111606
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Steinmetz A, 2001, PROC SPIE, V4312, P25
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197
   Wactlar HD, 1999, ACM COMPUT SURV, V31
   WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647
   ZAHO W, 1999, P IEEE INT C MULT CO, P752
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
NR 46
TC 10
Z9 10
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 135
EP 167
DI 10.1007/s11042-007-0137-4
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Arigon, AM
   Miquel, M
   Tchounikine, A
AF Arigon, Anne-Muriel
   Miquel, Maryvonne
   Tchounikine, Anne
TI Multimedia data warehouses: a multiversion model and a medical
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE data warehouse; OLAP; multimedia data; functional version; multimedia
   data descriptor
AB In field such as Cardiology, data used for clinical studies is not only alphanumeric, but can also be composed of images or signals. Multimedia data warehouse then must be studied in order to provide an efficient environment for the analysis of this data. The analysis environment must include appropriate processing methods in order to compute or extract the knowledge embedded into raw data. Traditional multidimensional models have a static structure which members of dimensions are computed in a unique way. However, multimedia data is often characterized by descriptors that can be obtained by various computation modes. We define these computation modes as "functional versions" of the descriptors. We propose a Functional Multiversion Multidimensional Model by integrating the concept of "version of dimension." This concept defines dimensions with members computed according to various functional versions. This new approach integrates different computation modes of these members into the proposed model, in order to allow the user to select the best representation of data. In this paper, a conceptual model is formally defined and a prototype for this study is presented. A multimedia data warehouse in the medical field has been implemented on a therapeutic study on acute myocardial infarction.
C1 LBBE, UMR, CNRS 5558, UCBL,Lab Biometre Biol Evolut, F-69622 Villeurbanne, France.
C3 VetAgro Sup; Universite Claude Bernard Lyon 1
RP Arigon, AM (corresponding author), LBBE, UMR, CNRS 5558, UCBL,Lab Biometre Biol Evolut, F-69622 Villeurbanne, France.
EM arigon@biomserv.univ-lyon1.fr; maryvonne.miquel@liris.cnrs.fr;
   anne.tchounikine@insa-lyon.fr
CR AGRAWAL R, 1995, MODELING MULTIDIMENS
   BLASCHKA M, 1999, LECT NOTES COMPUTER, V1676
   BODY M, 2003, IEEE COMPUTER SCI
   CABIBBO L, 1998, IEEE COMPUTER SCI, V1377
   Chauret N, 1998, DRUG METAB DISPOS, V26, P1
   Chevalier P, 2001, CARDIOVASC RES, V50, P386, DOI 10.1016/S0008-6363(01)00263-2
   EDER J, 2001, P DAT WAR KNWOL DISC, V2114
   GYSSENS M, 1997, P 23 INT C VER LARG
   Han J., 2001, DATA MINING
   Hristovski D, 2000, J AM MED INFORM ASSN, P369
   HURTADO C, 1999, P 15 INT C DAT ENG 2
   HURTADO C, 1999, P ACM 2 INT WORKSH D
   Huyn N, 2001, SIGMOD RECORD, V30, P76, DOI 10.1145/603867.603880
   Inmon W.H., 1996, BUILDING DATA WAREHO, VSecond
   ISKEN MW, 2001, J HLTH INF MANAG JHI, V15
   JARKE M, 2000, P 26 INT C VER LARG
   KAMP V, 1997, P INT DATT ENG APPL
   KIMBALL R., 1996, DATA WAREHOUSE TOOLK
   LEHNER W, 1998, P 1998 INT C EXT DAT
   LI C, 1996, P 5 INT C INF KNOWL
   MENCLELZON AO, 2000, P 26 INT C VER LARG
   NIINIMAKI J, 1996, MED INFORM EUROPEA M
   Pedersen M, 1998, SENSOR MATER, V10, P1
   PEDERSEN TB, 2001, INF SYST, V26
   TCHOUNIKINE A, 2001, 3 INT C DAWAK 2001 M, V2114
   TIKEKAR RV, 1995, DIGITAL IMAGE STORAG
   Vassiliadis P., 1999, SIGMOD Record, V28, P64, DOI 10.1145/344816.344869
   VASSILIADIS P, 1998, 10 INT C SCI STAT DA
   YOU J, 2001, P 2001 INT C IMAG P
   ZAIANE OR, 1998, P CASCON 98 M MINDS, P83
   ZUCKER R, 2001, 5 EUR C PKDD 2001 FR
NR 31
TC 10
Z9 10
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2007
VL 35
IS 1
BP 91
EP 108
DI 10.1007/s11042-007-0118-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 209RY
UT WOS:000249406900005
DA 2024-07-18
ER

PT J
AU Harb, H
   Chen, L
AF Harb, Hadi
   Chen, Liming
TI A general audio classifier based on human perception motivated model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE audio classification; gender identification; music genre recognition;
   highlights detection; perceptually motivated features; content-based
   audio indexing; piecewise gaussian modelling
ID RETRIEVAL; SEGMENTATION
AB The audio channel conveys rich clues for content-based multimedia indexing. Interesting audio analysis includes, besides widely known speech recognition and speaker identification problems, speech/music segmentation, speaker gender detection, special effect recognition such as gun shots or car pursuit, and so on. All these problems can be considered as an audio classification problem which needs to generate a label from low audio signal analysis. While most audio analysis techniques in the literature are problem specific, we propose in this paper a general framework for audio classification. The proposed technique uses a perceptually motivated model of the human perception of audio classes in the sense that it makes a judicious use of certain psychophysical results and relies on a neural network for classification. In order to assess the effectiveness of the proposed approach, large experiments on several audio classification problems have been carried out, including speech/music discrimination in Radio/TV programs, gender recognition on a subset of the switchboard database, highlights detection in sports videos, and musical genre recognition. The classification accuracies of the proposed technique are comparable to those obtained by problem specific techniques while offering the basis of a general approach for audio classification.
C1 Ecole Cent Lyon, Dept Math Informat, CNRS, LIRIS,FRE 2672, F-69131 Ecully, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   des Sciences Appliquees de Lyon - INSA Lyon; Ecole Centrale de Lyon
RP Harb, H (corresponding author), Ecole Cent Lyon, Dept Math Informat, CNRS, LIRIS,FRE 2672, 36 Av Guy Collongue, F-69131 Ecully, France.
EM hadi.harb@ec-lyon.fr; liming.chen@ec-lyon.fr
OI Harb, Hadi/0000-0002-4170-6654
CR Ajmera J, 2003, SPEECH COMMUN, V40, P351, DOI 10.1016/S0167-6393(02)00087-0
   Carey MJ, 1999, INT CONF ACOUST SPEE, P149, DOI 10.1109/ICASSP.1999.758084
   Chang YL, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P306, DOI 10.1109/MMCS.1996.534992
   CHAO LL, 1995, EVOKED POTENTIAL, V96, P157, DOI 10.1016/0168-5597(94)00256-E
   DAGTAS S, 2001, P IEEE 4 WORKSH MULT
   De Santo M, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P386, DOI 10.1109/ICIAP.2001.957040
   El-Maleh K, 2000, INT CONF ACOUST SPEE, P2445, DOI 10.1109/ICASSP.2000.859336
   FOOTE J, 1997, P AAAI 1997 SPRI S I
   GAUVAIN JL, 1998, P ICSLP 98 SYDN AUST, V5, P1335
   Goto M., 2002, P 3 INT C MUS INF RE, V2, P287
   HAGEN S, 1998, P 1998 IEEE INT C AC
   Hain T., 1998, P 1998 DARPA BROADCA, P133
   HANJALIC A, 2001, P IEEE WORKSH CONT B
   Harb H, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P125, DOI 10.1109/ISSPA.2003.1224831
   Harb H, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P733
   Haykin S., 1994, NEURAL NETWORKS COMP
   HUANG XD, 1991, P ICASSP, V1, P345
   Jiang D.N., 2002, Proceedings
   JUNG E, 2002, P 14 INT C DIG SIGN, V2, P827
   KIMBER D, 1996, P INT C SYDN AUSTR J
   KIRANYAZ S, 2003, P 4 EUR WORKSH IM AN
   KONIG Y, 1992, P INT JOINT C NEUR N, V2, P332
   Li DG, 2001, PATTERN RECOGN LETT, V22, P533, DOI 10.1016/S0167-8655(00)00119-7
   Li GH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P885, DOI 10.1109/ICME.2000.871501
   Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383
   Liu F.H., 1993, P 6 ARPA WORKSHOP HU, P69
   LIU Z, 1998, J VLSI SIGNAL PROCES
   Miyamori H, 2002, INT C PATT RECOG, P826, DOI 10.1109/ICPR.2002.1048430
   MONCRIEFF S, 2001, P ACM MM
   Moore B.C. J., 1995, HEARING, V2nd
   Neti C, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P192, DOI 10.1109/ASRU.1997.659005
   Noppeney U, 2002, NEUROIMAGE, V15, P917, DOI 10.1006/nimg.2001.1016
   Parris ES, 1996, INT CONF ACOUST SPEE, P685, DOI 10.1109/ICASSP.1996.543213
   PERROT D, P 1999 SOC MUS PERC
   Pfeiffer S., 1996, Proceedings ACM Multimedia 96, P21, DOI 10.1145/244130.244139
   Pinquier J, 2002, INT CONF ACOUST SPEE, P4164
   Pye D, 2000, INT CONF ACOUST SPEE, P2437, DOI 10.1109/ICASSP.2000.859334
   REYESGOMEZ M, 2003, P IEEE INT C MULT EX
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   RIVAROL V, 1996, ICSLP 96, V2, P1081
   Saunders J, 1996, INT CONF ACOUST SPEE, P993, DOI 10.1109/ICASSP.1996.543290
   SCHEIRER E, 1997, P IEEE ICASSP 97 MUN
   SECK M, 2001, P ICASSP01, V1, P601
   SLANEY M, 2002, ECME 2002, V1, P345
   Slomka S, 1997, TENCON IEEE REGION, P145, DOI 10.1109/TENCON.1997.647278
   Sundaram H., 2000, IEEE INT C MULT EXP
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   TZANETAKIS G, 2001, P INT S MUS INF RETR
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   WILLIAMS G, 1999, P EUR
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Yabe H, 2001, BRAIN RES, V897, P222, DOI 10.1016/S0006-8993(01)02224-7
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
   Zhou WS, 2002, INFORM SYST, V27, P559, DOI 10.1016/S0306-4379(02)00018-2
NR 54
TC 14
Z9 14
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 375
EP 395
DI 10.1007/s11042-007-0108-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500006
DA 2024-07-18
ER

PT J
AU Bailey, K
   Curran, K
AF Bailey, Karen
   Curran, Kevin
TI An evaluation of image based steganography methods using visual
   inspection and automated detection techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE steganography; steganalysis
AB Steganography is a process that involves hiding a message in an appropriate carrier for example an image or an audio file. The carrier can then be sent to a receiver without anyone else knowing that it contains a hidden message. This is a process, which can be used for example by civil rights organisations in repressive states to communicate their message to the outside world without their own government being aware of it. Less virtuously it can be used by terrorists to communicate with one another without anyone else's knowledge. In both cases the objective is not to make it difficult to read the message as cryptography does, it is to hide the existence of the message in the first place possibly to protect the courier. The initial aim of this study was to investigate steganography and how it is implemented. Based on this work a number of common methods of steganography could then be implemented and evaluated. The strengths and weaknesses of the chosen methods can then be analysed. To provide a common frame of reference all of the steganography methods implemented and analysed used GIF images. Seven steganography methods were implemented. The methods were chosen for their different strengths in terms of resistance to different types of steganalysis or their ability to maximise the size of the message they could store. All of the methods used were based on the manipulation of the least significant bits of pixel values or the rearrangement of colours to create least significant bit or parity patterns, which correspond to the message being hidden.
C1 Letterkenny Inst Technol, Port Rd, Letterkenny, Co Donegal, Ireland.
   Univ Ulster, Internet Technol Res Grp, Derry, North Ireland.
C3 Atlantic Technological University (ATU); Ulster University
RP Bailey, K (corresponding author), Letterkenny Inst Technol, Port Rd, Letterkenny, Co Donegal, Ireland.
EM karen.bailey@lyit.ie; kj.curran@ulster.ac.uk
RI Curran, Kevin/AAC-4865-2019
OI Curran, Kevin/0000-0001-5237-5355
CR Brown A., 1994, S TOOLS WINDOWS SHAR
   Fridrich J, 2000, LECT NOTES COMPUT SC, V1768, P47
   HANSMANN F, 1996, STEGANOS DEUS MACHIN
   JIRI F, 1999, IS TS PICS C, P285
   NEIL FJ, 1998, 2 INT WORKSH IH 98 P, P273
   NEIL FJ, 2001, INFORMATION HIDING W
   NELSON M, 1989, DOBBS J
   PFITZMANN B, 1996, P 1 INT WORKSH INF H, V1174, P347
   Wayner Peter., 2002, DISAPPEARING CRYPTOG
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Zöllner J, 1998, LECT NOTES COMPUT SC, V1525, P344
NR 11
TC 84
Z9 85
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2006
VL 30
IS 1
BP 55
EP 88
DI 10.1007/s11042-006-0008-4
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CF
UT WOS:000240363400003
DA 2024-07-18
ER

PT J
AU Wang, YB
   Claypool, M
AF Wang, YB
   Claypool, M
TI RealTracer - Tools for measuring the performance of RealVideo on the
   Internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE streaming video; RealPlayer; performance measurement
AB The increase in high-bandwidth connections and high-speed computers has spurred the growth of streaming media across the Internet. While there have been a number of studies measuring the performance of traditional Internet traffic, there have not been sufficient empirical measurements of video performance especially for commercial videos across the Internet. The lack of empirical work that measures streaming video traffic may arise from the lack of effective video performance measurement tools. In this paper, we present RealTracer, a set of tools for measuring the performance of RealNetworks Video. RealTracer includes RealTracker, a customized video player that plays RealNetworks Video from pre-selected playlist and records user-centric video performance information. RealTracer also includes RealData, a data analysis tool that helps manage, parse and analyze data captured by RealTracker. We describe the software architecture and usage of RealTracker and the usage of RealData, both publicly available for download. To illustrate the use of RealTracer, we present some results from a study that used RealTracker to measure RealVideo performance across the Internet. Using RealData, that study made several contributions to better understanding the performance of streaming video on the Internet. Typical RealVideos have high quality, achieving an average frame rate of 10 frames per second and very smooth playout, but very few videos achieve full-motion frame rates. Overall video performance is most influenced by the bandwidth of the end-user connection to the Internet, but high-bandwidth Internet connections are pushing the video performance bottleneck closer to the server.
C1 EMC Corp, Hopkinton, MA 01748 USA.
   Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
C3 Dell Incorporated; Dell EMC; Worcester Polytechnic Institute
RP Wang, YB (corresponding author), EMC Corp, Hopkinton, MA 01748 USA.
EM wang_yubing@emc.com; claypool@cs.wpi.edu
RI Claypool, Mark/ABC-5316-2020
CR CLAYPOOL M, 1999, P SCS EUR C COMTEC M
   CLAYPOOL M, 1999, P ACM MULT C ORL FLO, V2
   CUNNINGHAM D, 2001, INTRO STREAMING VIDE
   DALAL AC, 2003, P PASS ACT MEAS WORK
   Devore J.R. Peck., 1993, Statistics: The Exploration and Analysis of Data, V2nd
   Floyd S., 2000, P ACM SIGCOMM C, P45
   Krishnamurthy B, 2001, P ACM SIGCOMM INT ME
   Krishnamurthy B., 2000, P 9 INT WORLD WID WE
   LOGUINOV D, 2001, P ACM SIGCOMM INT ME
   MAH B, 1997, P ACM SIGCOMM C, P301
   Mena A., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P101, DOI 10.1109/INFCOM.2000.832178
   Paxson V, 1999, IEEE ACM T NETWORK, V7, P277, DOI 10.1109/90.779192
   *REAL NETW INC, 2000, REALPRODUCER US GUID
   *REAL NETW INC, 2000, REALPLAYER 8 US MAN
   REJAIE R, 1999, P IEEE INFOCOM C
   SCHULZRINNE H, 1996, 1889 RFC
   Schulzrinne H., 1998, 2326 RFC
   THOMPSON K, 1997, IEEE NETWORK     NOV
   TRIPATHI A, 2002, P 2 INT WORKSH INT M
   van der Merwe Jacobus, 2000, ACM COMPUTER COMMUNI, V30
   Veloso E., 2002, P SIGCOMM INT MEAS W
   WANG Y, 2001, P ACM SIGCOMM INT ME
   [No title captured]
NR 23
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 411
EP 430
DI 10.1007/s11042-005-3757-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300006
DA 2024-07-18
ER

PT J
AU Barde, J
   Libourel, T
   Maurel, P
AF Barde, J
   Libourel, T
   Maurel, P
TI A metadata service for integrated management of knowledges related to
   coastal areas
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE mediation; ontology; metadata; knowledge sharing; coastal management
AB The research outlined in this paper is part of a wider research program named SYSCOLAG (Coastal and LAGoonal SYStems in Languedoc-Roussillon area, France) dedicated to sustainable coastal management. The main objective of this program is to build up a communication infrastructure to improve the exchange of information and knowledge between the various scientific disciplines involved in the research. In order to ensure the sharing of resources without affecting the autonomy and independance of the partners, we propose a three-level infrastructure (resources, federation and knowledge access) based on a metadata service (using ISO 19115 standard for geographic information metadata) completed by a common vocabulary (ontology).
C1 Maison Teledetect, F-34093 Montpellier, France.
   LIRMM, F-34392 Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Barde, J (corresponding author), Maison Teledetect, 500 Rue JF Breton, F-34093 Montpellier, France.
EM julien@teledection.fr; libourel@lirmm.fr; pim@teledection.fr
OI Maurel, Pierre/0000-0001-5988-5446; Barde, Julien/0000-0002-3519-6141
CR AITCHISON J., 2000, THESAURUS CONSTRUCTI, V4th
   [Anonymous], LNAI
   [Anonymous], 2 NISO
   [Anonymous], 2000, Knowledge Representation: Logical, Philosophical, and Computational Foundations
   BERGERON M, 1993, VOCABULAIRE GEOMATIQ
   Booch Grady, 1999, UNIFIED MODELING LAN, DOI DOI 10.1007/3-540-40011-7_10
   BORTZMEYER S, 1996, SYSTEMES RECHERCHE M
   CLARKE SGD, 2000, DYNAMISM STABILITY K, P41
   DESCONNETS JC, 2001, P JOURN CASSINI 01 G, P69
   DESCONNETS JC, 2003, P 21 INFORSID C INF
   FARQUHAR A, 9626 KSL
   GRUBER TR, 1993, KNOWL ACQUIS, V5, P199, DOI 10.1006/knac.1993.1008
   *ISO, 19115 ISO
   LIBOUREL T, 2003, P GEOEV 2003
   LIBOUREL T, 1999, P 3 IEEE META DATA C
   Miller G.A., 1990, Int. J. Lexicogr, V3, P235, DOI [DOI 10.1093/IJL/3.4.235, 10.1093/ijl/3.4.235]
   Noy NF, 2001, IEEE INTELL SYST APP, V16, P60, DOI 10.1109/5254.920601
NR 17
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 419
EP 429
DI 10.1007/s11042-005-6544-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400008
DA 2024-07-18
ER

PT J
AU Dong, LG
   Veeravalli, B
   Ko, CC
AF Dong, LG
   Veeravalli, B
   Ko, CC
TI Efficient movie retrieval strategies for movie-on-demand multimedia
   services on distributed networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video/Movie-on-demand; multiple servers retrieval; retrieval scheduling;
   channel partition; access; time
ID ARCHITECTURE; ALLOCATION; POLICIES; STORAGE; SYSTEMS; DESIGN
AB In this paper, for a network-based multimediaVideo/Movie-on-demand(VoD/MoD) service, we design and analyze efficient retrieval strategies to minimize both the access times of the movies and the block rates. We consider a heterogeneous set of servers and a generic network topology in which clients can request for movies from any site. We design and analyze a multiple servers retrieval strategy (MSRS) to retrieve the movies requested by the clients and present a rigorous analysis on its performance with respect to access times of the requested movies and the block rates. A generalized approach of MSRS is designed in a judicious manner using a two-step approach. In the first step, we partition the available bandwidth among the requested movies and in the second step, we derive optimal portions of the movies to be retrieved from each of the servers for each movie, based on allocated bandwidths in the first step. Thus, with the optimal playback portions of the movies using aggregate retrieval bandwidth from several servers, the access times of the movies are minimized. In the first step, in addition to the access times, we minimize the block rates by balancing the total accesses/requests among the servers. In generating the retrieval schedule, our scheme utilizes the available bandwidth (resource) among the servers and guarantees to use less buffer space than a single server retrieval strategy (SSRS). With this two-step approach, a complete flexibility is provided in tuning the access times of the movies and also shown to be robust to any variations in the user access rates of the movies, in reality. Rigorous simulation experiments are presented to observe the performance of MSRS with respect to some important system dependent parameters. Comparing with SSRS, MSRS shows better performance in the simulation.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Open Source Software Lab, Singapore 119260, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Dept Elect & Comp Engn, Open Source Software Lab, 10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM elebv@nus.edu.sg; engp9433@nus.edu.sg; elekocc@nus.edu.sg
CR Aggarwal CC, 1999, MULTIMEDIA SYST, V7, P439, DOI 10.1007/s005300050144
   BARNETT SA, 1996, IEEE J SELECTED AREA, V14
   BASU P, 1998, P PAR DISTR COMP SYS
   BASU P, 1998, P SPIE MULT COMP NET
   Candan KS, 1998, MULTIMEDIA SYST, V6, P232, DOI 10.1007/s005300050091
   CHEN PM, 1994, ACM COMPUT SURV, V26, P145, DOI 10.1145/176979.176981
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   DAN A, 1997, MULTIMEDIA TOOLS APP, V4
   Fahmi H, 1999, MULTIMED TOOLS APPL, V8, P91, DOI 10.1023/A:1009651431672
   GEMMELL DJ, 1995, IEEE COMPUTER    MAY, P40
   Ghose D, 2000, MULTIMED TOOLS APPL, V11, P167, DOI 10.1023/A:1009681521536
   HUA KA, 1997, P ACM SIGCOMM 97 C A
   HWANG RH, 1998, IEEE T BROADCASTING, V44
   JADAV D, 1999, IEEE T KNOWLEDGE DAT, V11
   JIANG X, 1998, INT C PAR PROC MINN
   KHAN MF, ICDE 1999, P592
   KRISHNAN R, 1997, P ACM MULT SEATTL WA
   Lau SW, 1997, MULTIMEDIA SYST, V5, P310, DOI 10.1007/s005300050063
   Leff A, 1996, IEEE T PARALL DISTR, V7, P191, DOI 10.1109/71.485508
   Lie PWK, 2000, MULTIMED TOOLS APPL, V11, P35, DOI 10.1023/A:1009673332611
   MERCHANT A, 1996, P IEEE GLOB 96 LOND, P272
   MIYOSHI T, 1999, ELECT COMMUNICATIO 1, V82
   PANG HH, 1999, IEEE T KNOWLEDGE DAT, V11
   PING B, 2000, IN PRESS RETRIEVAL S
   RANGAN PV, 1993, IEEE T KNOWLEDGE DAT, V5
   SHACHNAI H, 1995, RC20038 IBM TJ WATS
   Veeravalli B, 2000, MULTIMED TOOLS APPL, V12, P235, DOI 10.1023/A:1009623825393
   Vin H. M., 1994, Proceedings ACM Multimedia '94, P33, DOI 10.1145/192593.192616
   VIN HM, 1995, COMPUT COMMUN, V18, P192, DOI 10.1016/0140-3664(95)98542-D
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Wang YW, 1997, MULTIMEDIA SYST, V5, P283, DOI 10.1007/s005300050061
   WOLF JL, 1995, P ACM SIGMETRICS C M, P157
   YU PS, 1995, MULTIMEDIA SYST, V3, P137, DOI 10.1007/BF02176235
NR 33
TC 10
Z9 10
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2003
VL 20
IS 2
BP 99
EP 133
DI 10.1023/A:1023654818590
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 675WP
UT WOS:000182720800001
DA 2024-07-18
ER

PT J
AU Benhari, M
   Hossseini, R
AF Benhari, Mona
   Hossseini, Rahil
TI An improved ensemble deep belief model (EDBM) for pap-smear cell image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Modelling uncertainty; Dempster-Shafer theory of
   evidence; Belief network; Cell image classification
AB Applications of deep learning models for medical image analysis have been concentrated in recent years. This study presents an improved automatic Deep Learning Ensemble model to detect cervical cancer. The proposed model takes advantage of the Deep Belief Network and Ensemble classification model called EDBM to improve the accuracy of the prediction. In this method, a new classification layer using Belief Network with Dempster combinational rule combines the evidence to handle uncertainty. An ensemble classifier was applied to address the issue of sample rejection in previous classification models. This method used three classifiers, including Support Vector Machine, K-Nearest Neighbour, and Fuzzy classifier, to improve the model's performance. Experimental results on the Herlev dataset and the SIPaKMeD dataset revealed the superiority of the proposed EDBM model. The EDBM On the Herlev dataset with an accuracy of 99%, specificity of 98%, the sensitivity of 98%, and AUC of 99.98%, and the SIPaKMeD dataset with an accuracy of 97.2%, specificity of 98.79%, the sensitivity of 98.70%, and AUC of 99.89%, outperformed counterpart Deep learning methods and showed promising achievements in the early detection of Cervical Cancer.
C1 [Benhari, Mona; Hossseini, Rahil] Islamic Azad Univ, Dept Comp Engn, Shahr Eqods Branch, Tehran, Iran.
C3 Islamic Azad University
RP Hossseini, R (corresponding author), Islamic Azad Univ, Dept Comp Engn, Shahr Eqods Branch, Tehran, Iran.
EM rahil.hosseini@qodsiau.ac.ir
CR Abhinaav R, 2019, INT C COMPUTER COMMU
   Araujoa FHD, 2018, Comput Med Imaging Graphics, V29
   Basak H, 2021, SN Comp Sci, V369
   Benhari M., 2022, Intelligent Systems with Applications, V16
   Bhatt AR, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.348
   Bora K., 2018, Int J Appl Eng Res, V13, P6709
   Bora K, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010068
   Dalal T, 2021, Springer Nature, V140
   Deepa K., 2021, Annals of the Romanian Society for Cell Biology, V25, P1092
   Denoeux T, 2000, IEEE T SYST MAN CY A, V30, P131, DOI 10.1109/3468.833094
   Desiani A., 2021, Int J Comput Sci, V48, P37
   Desiani Anita, 2021, IAENG Int. J. Comput. Sci., V48
   Dharani C., 2020, Int J New Innov Eng Technol, V2319-6319, P196
   Diniz DN, 2021, J IMAGING, V7, DOI 10.3390/jimaging7070111
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu K, 2020, IEEE Trans Inst Meas, V69
   Gu K, 2020, IEEE Trans Multimedia, V22
   Gu K, 2021, IEEE Trans Industr Inform, V17
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Harangi B, 2019, 11 IEEE INT S IMAGE
   Hosseini R, 2011, EUR C MACH LEARN PRI, P05
   Hosseini R, 2010, FOURTH INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2010, PROCEEDINGS, P255, DOI 10.1109/ICDS.2010.59
   Hussain E, 2020, TISSUE CELL, V65, DOI 10.1016/j.tice.2020.101347
   Khamparia A, 2021, MULTIMED TOOLS APPL, V80, P30399, DOI 10.1007/s11042-020-09607-w
   Kim HLJ, 2015, Segmentation of overlapping cervical cells in microscopic images with superpixel partitioning and cell-wise contour refinement
   Lu Z, 2015, J Biomed Health Inf, V11
   Martinez J, 2020, Expert Sys Appl, V31
   Mohammed Mohammed Aliy, 2021, BMC Biomed Eng, V3, P11, DOI 10.1186/s42490-021-00056-6
   Nguyen LD, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351550
   Nosrati MS, 2015, I S BIOMED IMAGING, P186, DOI 10.1109/ISBI.2015.7163846
   Plissiti ME, 2018, IEEE IMAGE PROC, P3144, DOI 10.1109/ICIP.2018.8451588
   Plissiti ME, 2011, IEEE T INF TECHNOL B, V15, P233, DOI 10.1109/TITB.2010.2087030
   Rahaman MM, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104649
   Saha R, 2017, COMPUT BIOL MED, V85, P13, DOI 10.1016/j.compbiomed.2017.04.008
   Sahba F, 2003, CCEC 2003 CCGEI 2003
   Palanisamy VS, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6608
   Shafer G., 1976, A mathematical theory of evidence, P1976, DOI [10.1515/9780691214696, DOI 10.1515/9780691214696]
   Sharma B, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1924, DOI 10.1109/ICACCI.2016.7732332
   Singh S.K., 2021, Recent Advances in Computer Science and Communications, V14, P62
   Sompawong N, 2019, IEEE ENG MED BIO, P7044, DOI [10.1109/embc.2019.8856369, 10.1109/EMBC.2019.8856369]
   Subhi Al-batah M, 2017, Comput Math Methods Med
   Taha B, 2017, COMM COM INF SC, V723, P261, DOI 10.1007/978-3-319-60964-5_23
   Tong Z, 2019, LECT NOTES ARTIF INT, V11940, P368, DOI 10.1007/978-3-030-35514-2_27
   Tripathi Anurag, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1210, DOI 10.1109/ICICCS51141.2021.9432382
   Waly MI., 2021, Comput Mater Contin, V70, P3296
   William W, 2018, Comput Meth Programs Biomedical, V13
   William W, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0634-5
   Win KP, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051800
   Wu M, 2019, Bioscience Report 14
   Yaman O, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103428
   Zhang L, 2018, J Biomed Health Inf, V11
   Zhang L, 2018, IEEE J Biomed Health Inf, V11
   Zhao M, 2016, Block Image Processing, V20
   Zhao M, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0131-z
NR 54
TC 2
Z9 2
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17499-9
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500016
DA 2024-07-18
ER

PT J
AU Kwon, H
AF Kwon, Hyun
TI AudioGuard: Speech Recognition System Robust against Optimized Audio
   Adversarial Examples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Evasion attack; Deep neural network; Defense method;
   Adversarial example
ID NEURAL-NETWORKS; IMAGE; FUSION
AB Deep neural networks provide good performance in image recognition, voice recognition, pattern recognition, and intrusion detection. However, deep neural networks are vulnerable to adversarial examples. Adversarial examples are samples that are created by adding a small amount of noise to normal data in such a way that they are recognized as normal by humans but are misclassified by a target model. In this paper, we propose a method for defending against audio adversarial examples using a noise vector, without the need for a separate module or process. The proposed method correctly identifies adversarial examples while maintaining the model's accuracy on normal samples by using a noise vector. In our experiments, the Mozilla Common Voice dataset was used as test data, with TensorFlow as the machine learning library. The experimental results showed that the proposed method correctly identified the adversarial examples with 84.2% accuracy.
C1 [Kwon, Hyun] Korea Mil Acad, Dept Artificial Intelligence & Data Sci, 574 Hwarang Ro, Seoul 01819, South Korea.
RP Kwon, H (corresponding author), Korea Mil Acad, Dept Artificial Intelligence & Data Sci, 574 Hwarang Ro, Seoul 01819, South Korea.
EM hkwon.cs@gmail.com
RI Kwon, Hyun/M-1140-2018
OI Kwon, Hyun/0000-0003-1169-9892
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2021R1I1A1A01040308]
FX This study was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education (2021R1I1A1A01040308).
CR Alzantot M, 2018, Arxiv, DOI arXiv:1801.00554
   Canziani A., 2017, arXiv
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009
   Carlini N, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P513
   Cisse M, 2017, Arxiv, DOI arXiv:1707.05373
   Deng YP, 2020, Arxiv, DOI arXiv:2010.01506
   Ebrahimi J, 2018, Arxiv, DOI arXiv:1712.06751
   Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X
   Fernando T., 2020, IEEE-ACM T AUDIO SPE
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Guo C., 2019, arXiv
   Hannun A, 2014, Arxiv, DOI arXiv:1412.5567
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hooper C, 2021, Arxiv, DOI arXiv:2105.01134
   Hu RF, 2018, J LOW POWER ELECTRON, V14, P475, DOI 10.1166/jolpe.2018.1579
   Ilyas A, 2018, Arxiv, DOI arXiv:1804.08598
   Jin X., 2021, Multimedia Tools and Applications, P1
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P29303, DOI 10.1007/s11042-018-5959-8
   Karthik K, 2021, VISUAL COMPUT, V37, P1837, DOI 10.1007/s00371-020-01941-2
   Kingma D. P., 2015, P INT C LEARN REPR, P1, DOI DOI 10.1002/9781118900772.ETRDS0277
   Kwon H, 2023, APPL INTELL, V53, P19161, DOI 10.1007/s10489-022-03313-w
   Kwon H, 2022, COMPUT SECUR, V117, DOI 10.1016/j.cose.2022.102695
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nazemi A., 2019, Potential adversarial samples for white-box attacks, DOI 10.48550/arxiv.1912.06409
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tamura K, 2019, 2019 IEEE 11TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA 2019), P115, DOI [10.1109/IWCIA47330.2019.8955062, 10.1109/iwcia47330.2019.8955062]
   Unar S, 2019, KNOWL-BASED SYST, V179, P8, DOI 10.1016/j.knosys.2019.05.001
   Unar S, 2018, INFORM FUSION, V44, P176, DOI 10.1016/j.inffus.2018.03.006
   Vaidya T., 2015, WOOT
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Lee AX, 2018, Arxiv, DOI arXiv:1804.01523
   Yu H, 2018, IEEE T NEUR NET LEAR, V29, P4633, DOI 10.1109/TNNLS.2017.2771947
NR 37
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 23
PY 2023
DI 10.1007/s11042-023-15961-2
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DO9H2
UT WOS:001133108800001
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Chang, T
   Lai, CC
AF Kuo, Lungwen
   Chang, Tsuiyueh
   Lai, Chih-Chun
TI Research on cultural and creative color aesthetics of Fujian
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Product design; Cultural and creative; Aesthetic; Packaging design;
   Color
ID PACKAGE DESIGN; PRODUCT DESIGN; EXPECTATIONS; IMPLICIT; HARMONY; SYSTEM;
   NEEDS
AB The shape and color of a product constitute the aesthetic and visual language that conveys the product's quality and emotional elements. Evaluating psychological perceptions in experimental scenarios can help determine the optimal product shape and color. The shape of a product is regarded as its fundamental element, which provides visual stimulation to consumers, elicits aesthetic appreciation, encourages purchases, and enhances product visibility. In this study, we comprehensively investigated the emotional design elements of product shapes and colors. We also examined user characteristics and various emotional aspects of product and packaging designs. Three experiments involving portable speakers were conducted to explore the emotional associations between product shape, product color, and packaging color. The first experiment was conducted to identify the most popular speaker shape on the basis of user ratings with four emotion adjectives. The results indicated that the rectangular speaker was the most popular speaker shape, followed by the cylindrical speaker. The second experiment was conducted to identify the most popular color design for the rectangular speaker from the first experiment on the basis of four pairs of emotion adjectives, namely popular-outdated, international-local, innovative-conservative, and elegant-vulgar. The participants were shown color images of the speaker in various color designs and asked to rate them by using these adjectives. The results indicated that the most popular color was dodger blue, followed by lime green. The third experiment was conducted to identify the most popular three-color scheme for the speaker's packaging box from 45 schemes developed in accordance with Horiguchi's Munsell New Color Psychology System. The results indicated that the most popular color scheme was cresol (sharp), followed by lavender (refined) and incense (quiet and tranquil). Overall, this study investigates the shape and color of the packaging box of a technology product and contributes to the literature by offering guidance for future research on product shape design and packaging color design. Our findings provide researchers with both theoretical and practical insights into color aesthetics.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
   [Lai, Chih-Chun] Tatung Univ, Dept Ind Design, Taipei, Taiwan.
C3 Sanming University; Tatung University
RP Chang, T (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
EM yueh5031162@yahoo.com.tw
RI lai, chih chun/AAE-6772-2021
OI Lai, Chih-Chun/0000-0003-4261-6228
FU Supported by Fujian Province Science
FX No Statement Available
CR Al-Rasheed AS, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00030
   [Anonymous], 1991, Color Image Scale
   Bahn S, 2009, HUM FACTORS ERGONOM, V19, P105, DOI 10.1002/hfm.20140
   Becker L, 2011, FOOD QUAL PREFER, V22, P17, DOI 10.1016/j.foodqual.2010.06.007
   BLOCH PH, 1995, J MARKETING, V59, P16, DOI 10.2307/1252116
   Chiu SW, 2006, SEX ROLES, V55, P385, DOI 10.1007/s11199-006-9089-9
   Chiyoda Y, 2008, J Appl Asychol
   Demirtas EA, 2009, INT J IND ERGONOM, V39, P866, DOI 10.1016/j.ergon.2009.06.007
   Desmet P., 2002, Pleasure with products, beyond usability, P60, DOI DOI 10.1201/9780203302279.CH4
   Desmet PMA, 2004, IN PRESS
   Ding M, 2020, COLOR RES APPL, V45, P142, DOI 10.1002/col.22441
   Duje K, 2022, COLOR RES APPL, V47, P182, DOI 10.1002/col.22705
   Festila A, 2018, J CONSUM BEHAV, V17, P461, DOI 10.1002/cb.1732
   Gabbas Malika, 2021, [Archives of Design Research, 디자인학연구], V34, P5, DOI 10.15187/adr.2021.02.34.1.5
   Garaus M, 2020, REV MANAG SCI, V14, P1077, DOI 10.1007/s11846-018-0325-9
   Gobe M., 2001, imba translation, high-sensibility brand marketing, P1
   Han SH, 2003, ERGONOMICS, V46, P1441, DOI 10.1080/00140130310001610928
   He XF, 2022, COLOR RES APPL, V47, P758, DOI 10.1002/col.22748
   Holbrook MB., 1985, The role of affect in consumer behavior: Emerging theories and applications, P17
   Horiguchi S, 2018, COLOR RES APPL, V43, P827, DOI 10.1002/col.22286
   Hou YD, 2020, COLOR RES APPL, V45, P699, DOI 10.1002/col.22489
   Hsiao KA, 2006, INT J IND ERGONOM, V36, P553, DOI 10.1016/j.ergon.2005.11.009
   Ishaq M, 2023, Comput. Syst. Sci. Eng, V46, P3355, DOI 10.32604/csse.2023.037373
   Jeong SH., 2005, J Korean Soc Des Sci, V18, P69
   Jiang LL, 2020, COLOR RES APPL, V45, P754, DOI 10.1002/col.22507
   Jiao JX, 2006, EXPERT SYST APPL, V30, P658, DOI 10.1016/j.eswa.2005.07.020
   Jonauskaite D, 2019, SEX ROLES, V80, P630, DOI 10.1007/s11199-018-0955-z
   Jordan PW., 1995, Contemporary Ergonomics, P341
   Kaya N., 2004, COLL STUD J, V38, P396
   Khalid HM, 2006, APPL ERGON, V37, P409, DOI 10.1016/j.apergo.2006.04.005
   Kunz S, 2020, PSYCHOL MARKET, V37, P900, DOI 10.1002/mar.21317
   Labrecque LI, 2013, MARKET LETT, V24, P165, DOI 10.1007/s11002-012-9210-5
   Lajos J, 2010, ADV CONSUM RES, V37, P838
   Lind C, 1985, ACPTC P COMB CENTR E, P243
   Mustaqeem K, 2023, KNOWL-BASED SYST, V270, DOI 10.1016/j.knosys.2023.110525
   OSGOOD CE, 1957, MEASURE MEANING
   Pereira C, 2021, COLOR RES APPL, V46, P566, DOI 10.1002/col.22651
   Phlip MD., 2009, Des J, V3, P31
   Picard RW., 2000, AFFECTIVE COMPUTING, DOI [10.7551/mitpress/1140.001.0001, DOI 10.7551/MITPRESS/1140.001.0001]
   Rasband, 1993, Art Essentials in Color Fairchild
   Robert H, 2002, The experience of visual thinking
   Silverstein MJ., 2006, Translated by Chen Liwen, cheap is a good thing, P4
   Spaeth T., 2001, Cloth Text Res J, V12, P57
   Tijssen IOJM, 2019, FOOD QUAL PREFER, V72, P126, DOI 10.1016/j.foodqual.2018.09.009
   Tjalve, 1979, A short course in industrial design, P15
   Tokutake M, 2019, COLOR RES APPL, V44, P798, DOI 10.1002/col.22400
   Wei ST, 2015, COLOR RES APPL, V40, P157, DOI 10.1002/col.21867
   Wei ST, 2014, INT J DES, V8, P109
   Wei ST, 2012, FOOD QUAL PREFER, V23, P49, DOI 10.1016/j.foodqual.2011.07.004
   Won S, 2018, COLOR RES APPL, V43, P100, DOI 10.1002/col.22167
   Young E, 2023, PACKAG TECHNOL SCI, V36, P905, DOI 10.1002/pts.2766
NR 51
TC 0
Z9 0
U1 8
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 20
PY 2023
DI 10.1007/s11042-023-17676-w
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4E4
UT WOS:001126688600008
DA 2024-07-18
ER

PT J
AU Gad, AF
AF Gad, Ahmed Fawzy
TI PyGAD: an intuitive genetic algorithm Python library
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Genetic algorithm; Evolutionary algorithm; Optimization; Deep learning;
   Python; NumPy; Keras; PyTorch
AB This paper introduces PyGAD, an open-source easy-to-use Python library for building the genetic algorithm (GA) and solving multi-objective optimization problems. PyGAD is designed as a general-purpose optimization library with the support of a wide range of parameters to give the user control over its life cycle. This includes, but not limited to, the population, fitness function, gene value space, gene data type, parent selection, crossover, and mutation. Its usage consists of 3 main steps: build the fitness function, create an instance of the pygad.GA class, and call the pygad.GA.run() method. The library supports training deep learning models created either with PyGAD itself or with frameworks such as Keras and PyTorch. Given its stable state, PyGAD is also in active development to respond to the user's requested features and enhancements received on GitHub.
C1 [Gad, Ahmed Fawzy] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
C3 University of Ottawa
RP Gad, AF (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
EM agad069@uottawa.ca
CR [Anonymous], 2009, SIGEVOlution
   Coletti MA, 2020, P 2020 GEN EV COMP C
   Deb K., 2000, Parallel Problem Solving from Nature PPSN VI. 6th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1917), P849
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Gad A.F., 2018, PRACTICAL COMPUTER V, P183
   Gen M., 2023, Springer handbook of engineering statistics, P635
   github, PyGAD GitHub Repository
   Kim J, 2019, GENET PROGRAM EVOL M, V20, P139, DOI 10.1007/s10710-018-9341-4
   pygad.readthedocs, PyGAD Documentation
   Simon D., 2013, EVOLUTIONARY OPTIMIZ
   Sohail A., 2021, Ann Data Sci, DOI DOI 10.1007/S40745-021-00354-9
NR 11
TC 9
Z9 9
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17167-y
EA DEC 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mustapha, AA
   Yoosuf, MS
AF Mustapha, Ahmad Abubakar
   Yoosuf, Mohamed Sirajudeen
TI Exploring the efficacy and comparative analysis of one-stage object
   detectors for computer vision: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Object detection; One-stage detection; Computer vision; Deep learning;
   Machine learning
AB One-stage object detection is a technique that uses a single deep neural network to detect objects in an image or video. This method trains the network from start to end to recognize objects and determine their location in a single forward pass. This method's speed and efficiency are its key benefits since they do away with the requirement for many stages or proposals and shorten calculation times. By limiting our survey to only recent one-stage object detection models, the paper was able to fulfil our objectives. In this paper, various object detection models are explored, and comparative analysis has been done, it is concluded that the main difficulty in one-stage object detection is striking a balance between accuracy and speed, as the network must make accurate predictions for numerous objects in real-time while still accurately detecting objects.
C1 [Mustapha, Ahmad Abubakar; Yoosuf, Mohamed Sirajudeen] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
C3 VIT-AP University
RP Mustapha, AA (corresponding author), VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India.
EM abubakar.22phd7073@vitap.ac.in; md.sirajudeen@vitap.ac.in
OI Mustapha, Ahmad Abubakar/0000-0001-6872-4097
CR Akhtar MJ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11213425
   Arulprakash E, 2022, J KING SAUD UNIV-COM, V34, P7347, DOI 10.1016/j.jksuci.2021.08.001
   Authors PP, 2019, PaddleDetection, object detection and instance segmentation toolkit based on PaddlePaddle
   Balakrishna S, 2023, MULTIMED TOOLS APPL, V82, P22405, DOI 10.1007/s11042-022-14131-0
   Barbalau A, 2023, COMPUT VIS IMAGE UND, V229, DOI 10.1016/j.cviu.2023.103656
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chen G, 2022, IEEE T CIRC SYST VID, V32, P6981, DOI 10.1109/TCSVT.2022.3178173
   Chen K, 2022, NEUROCOMPUTING, V477, P14, DOI 10.1016/j.neucom.2021.12.049
   Chen SF, 2023, IEEE I CONF COMP VIS, P19773, DOI 10.1109/ICCV51070.2023.01816
   Chen TY, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108901
   Chilukuri DM, 2022, COMPUT INTELL-US, V38, P1338, DOI 10.1111/coin.12511
   Christ PF, 2017, I S BIOMED IMAGING, P839, DOI 10.1109/ISBI.2017.7950648
   Cui C, 2021, Arxiv, DOI [arXiv:2109.15099, 10.48550/arXiv.2109.15099]
   Cui ZT, 2022, LECT NOTES COMPUT SC, V13669, P473, DOI 10.1007/978-3-031-20077-9_28
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong L, 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P19538
   Du XZ, 2021, Arxiv, DOI arXiv:2107.00057
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Er M.J., 2023, Research challenges, recent advances and benchmark datasets in deep-learning-based underwater marine object detection: A review
   Feng QH, 2023, MATH BIOSCI ENG, V20, P6551, DOI 10.3934/mbe.2023282
   Fradi H, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P248, DOI 10.1109/ICIEV.2012.6317376
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Ghasemi Y, 2022, COMPUT IND, V139, DOI 10.1016/j.compind.2022.103661
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong H, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122861
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   Haritaoglu I., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P877, DOI 10.1007/BFb0055710
   Hati KK, 2013, IEEE SIGNAL PROC LET, V20, P759, DOI 10.1109/LSP.2013.2263800
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang K, 2022, PATTERN RECOGN LETT, V160, P122, DOI 10.1016/j.patrec.2022.06.006
   Ingle PY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103862
   Jiang PY, 2022, PROCEDIA COMPUT SCI, V199, P1066, DOI 10.1016/j.procs.2022.01.135
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kalsotra R, 2022, VISUAL COMPUT, V38, P4151, DOI 10.1007/s00371-021-02286-0
   Kandelkar A., 2022, INT C INNOVATIVE COM, P299
   Kaur J, 2022, MULTIMED TOOLS APPL, V81, P38297, DOI 10.1007/s11042-022-13153-y
   Keerthikeshwar Mamilla, 2021, Intelligent Manufacturing and Energy Sustainability. Proceedings of ICIMES 2020. Smart Innovation, Systems and Technologies (SIST 213), P357, DOI 10.1007/978-981-33-4443-3_34
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ljosa V, 2012, NAT METHODS, V9, P637, DOI 10.1038/nmeth.2083
   Long X, 2020, Arxiv, DOI [arXiv:2007.12099, DOI 10.48550/ARXIV.2007.12099]
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Malamas EN, 2003, IMAGE VISION COMPUT, V21, P171, DOI 10.1016/S0262-8856(02)00152-X
   Mani VRS, 2022, MICROELECTRON J, V119, DOI 10.1016/j.mejo.2021.105319
   Mankodiya H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115310
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Menezes AG, 2023, Neural Networks
   Naddaf-Sh S, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/4637939
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Pandey V, 2022, MATH BIOSCI ENG, V19, P7920, DOI 10.3934/mbe.2022370
   Peric S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063041
   Poeppel D, 2012, COGN NEUROPSYCHOL, V29, P34, DOI 10.1080/02643294.2012.710600
   Qi GQ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020420
   Raghunandan A, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P563, DOI 10.1109/ICCSP.2018.8524461
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Santosh DH, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P1484, DOI 10.1109/ICACCCT.2014.7019350
   Singh N S., 2020, Lecture Notes in Electrical Engineering, P375, DOI 10.1007/978-981-15-0372-6_30
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Upschulte E, 2022, MED IMAGE ANAL, V77, DOI 10.1016/j.media.2022.102371
   Wang X, 2022, NEURAL PROCESS LETT, V54, P5169, DOI 10.1007/s11063-022-10855-0
   Wu D, 2022, MACH INTELL RES, V19, P550, DOI 10.1007/s11633-022-1339-y
   Wu J., 2018, MATEC Web of Conferences
   Xu C, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.110047
   Yang J., 2022, IEEE Conference on Computer Vision and Pattern Recognition, P5385
   Yang JR, 2022, Arxiv, DOI arXiv:2207.10433
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yu G., 2021, arXiv, DOI 10.48550/arXiv.2111.00902
   Zhang Yujie, 2022, The International Conference on Image, Vision and Intelligent Systems (ICIVIS 2021). Lecture Notes in Electrical Engineering (813), P291, DOI 10.1007/978-981-16-6963-7_27
   Zhang Y., 2022, P IEEECVF C COMPUTER, P19548
   Zhang ZJ, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104425
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zou ZX, 2023, P IEEE, V111, P257, DOI 10.1109/JPROC.2023.3238524
NR 79
TC 0
Z9 0
U1 19
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17751-2
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200007
DA 2024-07-18
ER

PT J
AU Singh, A
   Kalaichelvi, V
   Karthikeyan, R
AF Singh, Abhilasha
   Kalaichelvi, V.
   Karthikeyan, R.
TI Machine learning-based multi-sensor fusion for warehouse robot in
   GPS-denied environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sensor Fusion; Kalman Filter; IMU; Ultra-Wide Band; Turtlebot2i; RMSE
ID SENTIMENT ANALYSIS; DOMAIN ADAPTATION; EMOTION; CLASSIFICATION;
   ENSEMBLE; LEXICON; SYSTEM
AB Mobile robots have been widely used in warehouse applications because of their ability to move and handle heavy loads. This study deals with sensor fusion of Inertial Measurement Unit (IMU) and Ultra-Wide Band (UWB) devices like Pozyx for indoor localization in a warehouse environment. UWB is a key positioning technology for the complex indoor environment and provides low-cost solutions for sensor fusion. The IMU and position data are collected for different random trajectories from Pozyx tags placed in the Turtlebot2i differential drive mobile robot. These data are used to estimate the position and orientation of the robot. Different filters like Long Short Term Memory (LSTM), Convolution Neural Network based LSTM (CNN-LSTM), Multi-Layer Perceptron (MLP), and Convolution Neural Network (CNN) filters are employed for accurate indoor positioning. Furthermore, the performance of IMU sensor fusion with IMU + UWB sensor fusion was compared based on Mean Absolute Error (MAE), Loss, and Root Mean Square Error (RMSE) for different trajectories. Simulations and experimental tests were carried out for different trajectories and the test results show that fused data using CNN-LSTM had less positioning error compared to other filters.
C1 [Singh, Abhilasha; Kalaichelvi, V.] Birla Inst Technol & Sci Pilani, Dept Elect & Elect Engn, Dubai Campus POB 345055, Dubai, U Arab Emirates.
   [Karthikeyan, R.] Birla Inst Technol & Sci Pilani, Dept Mech Engn, Dubai Campus,POB 345055, Dubai, U Arab Emirates.
RP Kalaichelvi, V (corresponding author), Birla Inst Technol & Sci Pilani, Dept Elect & Elect Engn, Dubai Campus POB 345055, Dubai, U Arab Emirates.
EM p20180906@dubai.bits-pilani.ac.in; kalaichelvi@dubai.bits-pilani.ac.in;
   rkarthikeyan@dubai.bits-pilani.ac.in
RI Singh, Abhilasha/KGK-4819-2024
FU Birla Institute of Science and Technology Pilani, Dubai campus
FX The authors are immensely grateful to the authorities of Birla Institute
   of Science and Technology Pilani, Dubai campus for their support
   throughout this research work.
CR Abdi A, 2023, SOFT COMPUT, V27, P14073, DOI 10.1007/s00500-023-07926-2
   Abdi A, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106658
   Abdi A, 2019, INFORM PROCESS MANAG, V56, P1245, DOI 10.1016/j.ipm.2019.02.018
   Abdi A, 2018, EXPERT SYST APPL, V109, P66, DOI 10.1016/j.eswa.2018.05.010
   Abdi A, 2018, INFORM PROCESS MANAG, V54, P318, DOI 10.1016/j.ipm.2017.12.002
   Alqahtani Y, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103338
   Alsayat A, 2022, ARAB J SCI ENG, V47, P2499, DOI 10.1007/s13369-021-06227-w
   Amini I., 2019, P 10 WORKSHOP COMPUT, P81
   [Anonymous], 2007, P 45 ANN M ASS COMPU
   Araque O, 2017, INT CONF AFFECT, P105, DOI 10.1109/ACIIW.2017.8272598
   Araque O, 2017, EXPERT SYST APPL, V77, P236, DOI 10.1016/j.eswa.2017.02.002
   Asghar MZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171649
   Aung KZ, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P149
   Baccianella S., 2010, P 7 INT C LANG RES O, P2200
   Barnes J, 2021, NAT LANG ENG, V27, P249, DOI 10.1017/S1351324920000510
   Benamara F., 2012, Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics, ExProM'12, P10
   Blanco E, 2011, P 24 INT FLOR ART IN, V24, P228
   Blanco E, 2021, NAT LANG ENG, V27, P119, DOI 10.1017/S1351324920000522
   Bokolo Biodoumoye George, 2023, 2023 8th International Conference on Automation, Control and Robotics Engineering (CACRE), P79, DOI 10.1109/CACRE58689.2023.10208384
   Boukabous M, 2022, 2022 2 INT C INN RES, P1131
   Bradley M.M., 1999, C1 U FLOR CTR RES PS
   Brooke J., 2009, SEMANTIC APPROACH AU
   Brooke Julian., 2009, RANLP, P50
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Chauhan S, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3574130
   Cheng RH, 2020, NEUROCOMPUTING, V398, P55, DOI 10.1016/j.neucom.2020.01.059
   Chiha R, 2022, APPL INTELL, V52, P17845, DOI 10.1007/s10489-022-03279-9
   Choi Y., 2008, Proceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP '08, P793, DOI DOI 10.3115/1613715.1613816
   Cruz NP, 2016, J ASSOC INF SCI TECH, V67, P2118, DOI 10.1002/asi.23533
   De Chastelain Finnigan Kaitlin, 2022, 2022 IEEE 21st International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC), P91, DOI 10.1109/ICCICC57084.2022.10101520
   de Melo T, 2019, INFORM PROCESS MANAG, V56, P823, DOI 10.1016/j.ipm.2019.01.004
   Dey A, 2018, EXPERT SYST APPL, V103, P92, DOI 10.1016/j.eswa.2018.03.004
   Dey A, 2017, LECT NOTES COMPUT SC, V10597, P380, DOI 10.1007/978-3-319-69900-4_48
   Dragut E., 2014, Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore, P38
   Eng T., 2021, Int J Sci Res Comput Sci Eng Inf Technol, V3307, P57
   Fahfouh A, 2024, IEEE T NEUR NET LEAR, V35, P1228, DOI 10.1109/TNNLS.2022.3183037
   Fernández-Gavilanes M, 2018, EXPERT SYST APPL, V103, P74, DOI 10.1016/j.eswa.2018.02.043
   Fu YP, 2022, KNOWL-BASED SYST, V245, DOI 10.1016/j.knosys.2022.108649
   García-Pablos A, 2018, EXPERT SYST APPL, V91, P127, DOI 10.1016/j.eswa.2017.08.049
   Georgiadou E, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.102048
   Ghosh S, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103234
   Giachanou A, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102079
   Greco F, 2020, INT J INFORM MANAGE, V51, DOI 10.1016/j.ijinfomgt.2019.04.007
   Hartman JohnJ., 1967, AM SOCIOL REV, V32, DOI DOI 10.2307/2092070
   Hiremath BN, 2022, J KING SAUD UNIV-COM, V34, P2840, DOI 10.1016/j.jksuci.2020.03.006
   Hong Y, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P549
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Jadon Priyanshu, 2021, Rising Threats in Expert Applications and Solutions. Proceedings of FICR-TEAS 2020. Advances in Intelligent Systems and Computing (AISC 1187), P617, DOI 10.1007/978-981-15-6014-9_74
   Jain T.I., 2010, Int. J. Comput. Appl., V7, P12, DOI 10.5120/1160-1453
   Jurek Anna., 2015, Security Informatics, V4, P9, DOI DOI 10.1186/S13388-015-0024-X
   Kamvar SepandarD., 2011, PROC ACM INT C WEB S, P117
   Kennedy A, 2006, COMPUT INTELL-US, V22, P110, DOI 10.1111/j.1467-8640.2006.00277.x
   Khan A., 2011, Trends in Applied Sciences Research, V6, P1141, DOI [DOI 10.3923/tasr.2011.1141.1157, DOI 10.3923/TASR.2011.1141.1157, 10.3923/tasr.2011.1141.1157]
   Kirchner AN, 2019, orthern Illinois Univ, P1
   Kiritchenko S, 2017, The effect of negators, modals, and degree adverbs on sentiment composition, P43
   Kiritchenko S, 2014, J ARTIF INTELL RES, V50, P723, DOI 10.1613/jair.4272
   Lee L, P 42 ANN M ASS COMP, P271, DOI 10.3115/1218955.1218990
   Li SY, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102177
   Lin XM, 2021, SUSTAIN ENERGY TECHN, V44, DOI 10.1016/j.seta.2021.101014
   Liu H., 2016, Open J Stat, V06, P749, DOI [10.4236/ojs.2016.65061, DOI 10.4236/OJS.2016.65061]
   Liu J., 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1 EMNLP '09, V1, P161
   Mohammad S., 2010, P NAACL HLT 2010 WOR, DOI DOI 10.5555/1860631.1860635
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Mudgal P, 2020, 5 INT C ART INT APPL, P383
   Mukhtar N, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12317
   Musat Claudiu Cristian, 2012, P 3 WORK PEOPL WEB M, P1
   Neviarouskaya A., 2009, 3 INT C AFF COMP INT, P1, DOI [DOI 10.1109/ACII.2009.5349575, 10.1109/ACII.2009.5349575]
   Neviarouskaya A, 2007, LECT NOTES COMPUT SC, V4738, P218
   Neviarouskaya A, 2011, IEEE T AFFECT COMPUT, V2, P22, DOI 10.1109/T-AFFC.2011.1
   Pal M., 2023, INT C ADV INTELL COM, P1
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pennebaker J.W., 2015, LIWC 2015 operators manual, DOI DOI 10.15781/T29G6Z
   Phan HT, 2023, INFORM FUSION, V91, P149, DOI 10.1016/j.inffus.2022.10.004
   Polanyi L, 2005, AAAI SPRING S, P106
   Rashid J, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102060
   Rathore AK, 2020, INT J INFORM MANAGE, V50, P111, DOI 10.1016/j.ijinfomgt.2019.05.015
   Sahoo KK, 2021, IEEE ACCESS, V9, P166518, DOI 10.1109/ACCESS.2021.3135658
   Sahu S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091568
   Sarsam SM, 2021, BIOMED SIGNAL PROCES, V65, DOI 10.1016/j.bspc.2020.102355
   Satthar FS, 2015, 2015 IMP COLL COMP S, P46
   Savanur SR, 2023, INT J SOFTW INNOV, V11, P26, DOI 10.4018/IJSI.315741
   Sebastiani F., 2007, Evaluation, V17, P1
   Sharounthan B., 2021, Int Conf Comput Commun Informatics, V2021, P1
   Shunxiang Z, 2023, IEEE Trans Neural Networks Learn Syst, P1
   Siledar Tejpalsingh, 2023, CODS-COMAD '23: Proceedings of the 6th Joint International Conference on Data Science & Management of Data (10th ACM IKDD CODS and 28th COMAD), P55, DOI 10.1145/3570991.3571035
   Srinivasarao U, 2023, INT J COMPUT SCI ENG, V26, P65, DOI 10.1504/IJCSE.2023.129147
   Srivastava Tushar, 2023, Proceedings of International Conference on Recent Trends in Computing: ICRTC 2022. Lecture Notes in Networks and Systems (600), P523, DOI 10.1007/978-981-19-8825-7_45
   Strapparava C., 2004, Lrec, Volume, V4, P1083
   Subrahmanian VS, 2008, IEEE INTELL SYST, V23, P43, DOI 10.1109/MIS.2008.57
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Taboada M, 2005, AAAI Spring Symp-Tech Rep SS-04-07, P158
   Taboada M, 2016, ANNU REV LINGUIST, V2, P325, DOI 10.1146/annurev-linguistics-011415-040518
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Tan KL, 2022, IEEE ACCESS, V10, P21517, DOI 10.1109/ACCESS.2022.3152828
   Tan YY, 2023, WIRELESS PERS COMMUN, V129, P2213, DOI 10.1007/s11277-023-10235-4
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Wang Y, 2020, CMC-COMPUT MATER CON, V62, P631, DOI 10.32604/cmc.2020.07920
   Wilson T., 2005, P HUMAN LANGUAGE TEC, P347, DOI DOI 10.3115/1220575.1220619
   Wu HY, 2023, INFORM FUSION, V92, P289, DOI 10.1016/j.inffus.2022.12.004
   Wu JS, 2019, IEEE ACCESS, V7, P183924, DOI 10.1109/ACCESS.2019.2960655
   Wu SX, 2019, EXPERT SYST APPL, V116, P285, DOI 10.1016/j.eswa.2018.09.024
   Xing FZ, 2019, INFORM PROCESS MANAG, V56, P554, DOI 10.1016/j.ipm.2018.11.002
   Xu G, 2020, ACM T ASIAN LOW-RESO, V19, DOI 10.1145/3345518
   Xu YM, 2022, DATA SCI ENG, V7, P279, DOI 10.1007/s41019-022-00187-3
   You L, 2022, KNOWL-BASED SYST, V253, DOI 10.1016/j.knosys.2022.109511
   Zargari H, 2021, J INTELL FUZZY SYST, V40, P11763, DOI 10.3233/JIFS-202879
   Zhang Q, 2023, ADV ENG INFORM, V56, DOI 10.1016/j.aei.2023.101935
   Zhang W, 2020, INT J INFORM MANAGE, V50, P498, DOI 10.1016/j.ijinfomgt.2019.04.001
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zhu XD, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P304
   Zhu XH, 2023, APPL INTELL, V53, P4609, DOI 10.1007/s10489-022-03702-1
NR 111
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17753-0
EA DEC 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800014
DA 2024-07-18
ER

PT J
AU Shoaib, M
   Shah, B
   Hussain, T
   Yang, BL
   Ullah, A
   Khan, J
   Ali, F
AF Shoaib, Muhammad
   Shah, Babar
   Hussain, Tariq
   Yang, Bailin
   Ullah, Asad
   Khan, Jahangir
   Ali, Farman
TI A deep learning-assisted visual attention mechanism for anomaly
   detection in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Transfer learning; Attention mechanism; Background
   subtraction; Violence detection
ID RECOGNITION
AB Ensuring public safety in urban areas is a crucial element in maintaining a good quality of life. The successful deployment of video surveillance systems depends heavily on the acquisition and processing of large volumes of urban data to derive meaningful insights. Manual monitoring and analysis of anomalous activities in the surveillance footage is both a time-consuming and error-prone process that is not scalable for urban environments with high levels of foot and vehicular traffic. Moreover, traditional surveillance systems are limited by their inability to process real-time data at scale, which can result in missed or delayed detection of potential security threats. This paper tackles this problem by proposing an automatic anomaly detection method via an attention mechanism. The attention area is identified using the background subtraction (BG) algorithm which identifies motion regions in the video frames. This information is then passed through a 3D convolutional neural network (3D CNN) to classify the normal and anomalous events. To evaluate the proposed method, experiments and analysis were conducted using the publicly available UCF crime dataset, demonstrating its effectiveness with an accuracy of 96.89% compared to the state-of-the-art methods. In case an anomaly is detected, an alert is sent to the nearest authorities to take immediate action to prevent further harm or damage.
C1 [Shoaib, Muhammad] CECOS Univ IT & Emerging Sci, Dept Comp Sci, Peshawar 25000, Pakistan.
   [Shoaib, Muhammad; Ullah, Asad; Khan, Jahangir] Sarhad Univ Sci & Informat Technol, Dept Comp Sci & Informat Technol, Peshawar 25000, Pakistan.
   [Shah, Babar] Zayed Univ, Coll Technol Innovat, Dubai 19282, U Arab Emirates.
   [Hussain, Tariq; Yang, Bailin] Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Hussain, Tariq; Yang, Bailin] Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Peoples R China.
   [Ali, Farman] Sungkyunkwan Univ, Coll Comp & Informat, Sch Convergence, Dept Comp Sci & Engn, Seoul 03063, South Korea.
C3 Zayed University; Zhejiang Gongshang University; Zhejiang Gongshang
   University; Sungkyunkwan University (SKKU)
RP Yang, BL (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.; Yang, BL (corresponding author), Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Peoples R China.; Ali, F (corresponding author), Sungkyunkwan Univ, Coll Comp & Informat, Sch Convergence, Dept Comp Sci & Engn, Seoul 03063, South Korea.
EM mshoaib@cecos.edu.pk; Babar.Shah@zu.ac.ae; ybl@mail.zjgsu.edu.cn;
   asadullah.csit@suit.edu.pk; jahangir.csit@suit.edu.pk;
   farmankanju@gmail.com
RI Hussain, Tariq/AAO-1864-2020; Ali, Farman/AAA-9677-2020
OI Hussain, Tariq/0000-0002-4761-0346; Ali, Farman/0000-0002-9420-1588
FU National Natural Science Foundation of China [62172366]; Pioneer and
   "Leading Goose" R & D. Program of Zhejiang Province [2023C01150]; Zayed
   University, UAE [R20143]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No.62172366), and "Pioneer" and "Leading Goose" R & D.
   Program of Zhejiang Province (2023C01150). This research work was also
   supported by the Cluster grant R20143 of Zayed University, UAE.
CR Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Antic B, 2011, IEEE I CONF COMP VIS, P2415, DOI 10.1109/ICCV.2011.6126525
   Basharat A, 2008, PROC CVPR IEEE, P1301
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Cardenas Alvaro A., 2008, 2008 28th International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P495, DOI 10.1109/ICDCS.Workshops.2008.40
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Cong Y, 2002, Studi Tingkah Laku Pelolosan Kerapu Macan (Epinephelus fuscoguttatus)
   Curtis JB, 2013, Evaluation of Niobrara and Mowry formation petroleum systems in the Powder River, Denver and Central Basins of the Rocky Mountains, P31
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Dong J, Fast and robust multi-person 3D pose estimation from multiple views
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Dutta JK, 2015, AAAI CONF ARTIF INTE, P3755
   Ghazal S, 2019, IET IMAGE PROCESS, V13, P2572, DOI 10.1049/iet-ipr.2019.0030
   Gnouma Mariem, 2020, International Joint Conference: 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019). Proceedings. Advances in Intelligent Systems and Computing (AISC 951), P87, DOI 10.1007/978-3-030-20005-3_9
   Hanson A, 2019, LECT NOTES COMPUT SC, V11130, P280, DOI 10.1007/978-3-030-11012-3_24
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Hospedales T, 2009, IEEE I CONF COMP VIS, P1165, DOI 10.1109/ICCV.2009.5459342
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Irfanullah, 2022, MULTIMED TOOLS APPL, V81, P38151, DOI 10.1007/s11042-022-13169-4
   Ivanov YA, 2000, IEEE T PATTERN ANAL, V22, P852, DOI 10.1109/34.868686
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Khan UA, 2021, MULTIMED TOOLS APPL, V80, P26911, DOI 10.1007/s11042-021-10530-x
   Koller D., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P189
   Kooij JFP, 2016, COMPUT VIS IMAGE UND, V144, P106, DOI 10.1016/j.cviu.2015.06.009
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Landi F., 2019, arXiv
   Leyva R, 2017, Feature sets for online performance, V26, P3463
   Lin CY, 2020, IEEE T INTELL TRANSP, V21, P1404, DOI 10.1109/TITS.2019.2909915
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Pekalska E, 2003, Adv Neural Inf Process Syst
   Pinhanez CS, 1999, Media Arts Sci Progr
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ren H, 2015, Unsupervised behavior-specific dictionary learning for abnormal event detection, V28, P1, DOI [10.5244/c.29.28, DOI 10.5244/C.29.28]
   Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Tan WJ, 2022, Arxiv, DOI arXiv:2210.06688
   Wang XK, 2021, IEEE T IND INFORM, V17, P2231, DOI 10.1109/TII.2020.2999901
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   Xu D., 2015, Learning deep representations of appearance and motion for anomalous event detection (pp. 8.18.12), DOI [10.5244/c.29.8, DOI 10.5244/C.29.8]
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu QC, 2019, IEEE INT CON MULTI, P568, DOI 10.1109/ICME.2019.00104
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zaheer Muhammad Zaigham, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P358, DOI 10.1007/978-3-030-58542-6_22
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P98, DOI 10.1016/j.patrec.2017.08.021
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhang Y, 2016, Video anomaly detection based on locality sensitive hashing filters, V59
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhu YY, 2013, IEEE J-STSP, V7, P91, DOI 10.1109/JSTSP.2012.2234722
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 61
TC 3
Z9 3
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17770-z
EA DEC 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900006
DA 2024-07-18
ER

PT J
AU Wang, J
   Huang, Z
   Huang, ZQ
   Zhang, MH
   Ren, X
AF Wang, Jun
   Huang, Zhu
   Huang, Ziqing
   Zhang, Miaohui
   Ren, Xing
TI DSFNet: dynamic selection-fusion networks for video salient object
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video salient object detection; Dynamic selection-fusion network;
   Spatiotemporal features
ID SEGMENTATION; OPTIMIZATION; ATTENTION; ACCURATE
AB How to effectively fuse spatiotemporal clues is the key to improve the accuracy of video salient object detection. Although most existing methods have achieved great success regarding fusion strategies, the issue of reliability of spatiotemporal clues needs further investigation, and the use of unreliable spatiotemporal clues can corrupt the final saliency results. In this work, we propose a novel dynamic selection-fusion network (DSFNet) for video salient object detection, and DSFNet is jointly constructed by two branches. The one is the spatial learning network, which completes the learning of video sequences to obtain the spatial saliency of images. The other is the spatiotemporal contrast network, which creatively obtains the dynamic spatiotemporal saliency in the synchronized state by learning the video sequence and the corresponding optical flow images. To further screen and fuse the spatiotemporal clues, a series of joint modules for selection were developed, mainly including contrast transformation module (CTM), contrast analysis module (CAM) and selection guidance module (SGM) which play an important role in selecting spatiotemporal features. In addition, a fusion refinement module (FRM) is designed to further refine and enhance the input features. The experimental results show that the proposed method is significantly better than other algorithms in solving the problem of motion information distortion and spatiotemporal salient irrelevance.
C1 [Wang, Jun; Huang, Zhu; Huang, Ziqing; Zhang, Miaohui; Ren, Xing] Henan Univ, Zhengzhou, Peoples R China.
C3 Henan University
RP Ren, X (corresponding author), Henan Univ, Zhengzhou, Peoples R China.
EM 10280031@vip.henu.edu.cn
FU This work was supported by the National Natural Science Foundation of
   China Youth Fund (No.62202142), the Science and Technology Foundation of
   Henan Province of China (No.212102210156) and the Scientific Research
   Key Foundation of Higher Education Institut [62202142]; National Natural
   Science Foundation of China Youth Fund [212102210156]; Science and
   Technology Foundation of Henan Province of China [23A520025]; Scientific
   Research Key Foundation of Higher Education Institutions of Henan
   Province
FX This work was supported by the National Natural Science Foundation of
   China Youth Fund (No.62202142), the Science and Technology Foundation of
   Henan Province of China (No.212102210156) and the Scientific Research
   Key Foundation of Higher Education Institutions of Henan Province
   (No.23A520025).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen C, 2019, IEEE Trans Image Process
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P3995, DOI 10.1109/TIP.2021.3068644
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2018, IEEE SIGNAL PROC LET, V25, P154, DOI 10.1109/LSP.2017.2775212
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen CLZ, 2016, PATTERN RECOGN, V52, P410, DOI 10.1016/j.patcog.2015.09.033
   Chen YH, 2018, IEEE T IMAGE PROCESS, V27, P3345, DOI 10.1109/TIP.2018.2813165
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan RC, 2019, PROC CVPR IEEE, P6096, DOI 10.1109/CVPR.2019.00626
   Fortun D, 2015, COMPUT VIS IMAGE UND, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Gu YC, 2020, AAAI CONF ARTIF INTE, V34, P10869
   Guanbin L, 2017, Instance-level salient object segmentation, P10
   Guo F, 2020, IEEE T CIRC SYST VID, V30, P4887, DOI 10.1109/TCSVT.2019.2906226
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Huang LL, 2019, IEEE ACCESS, V7, P166203, DOI 10.1109/ACCESS.2019.2953046
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jerripothula KR, 2019, IEEE T CIRC SYST VID, V29, P744, DOI 10.1109/TCSVT.2018.2805811
   Ji GP, 2021, Full-duplex strategy for video object segmentation, P4902
   Ji YZ, 2021, IEEE T NEUR NET LEAR, V32, P2676, DOI 10.1109/TNNLS.2020.3007534
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Kong Y, 2021, IEEE Trans Multimed, V1-1
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li SY, 2018, LECT NOTES COMPUT SC, V11207, P215, DOI 10.1007/978-3-030-01219-9_13
   Li YX, 2020, IEEE T MULTIMEDIA, V22, P1153, DOI 10.1109/TMM.2019.2940851
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2020, IEEE T IMAGE PROCESS, V29, P6438, DOI 10.1109/TIP.2020.2988568
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4481, DOI 10.1145/3474085.3475601
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Peijia Chen, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), DOI 10.1109/ICME51207.2021.9428139
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tang Y, 2019, IEEE T CIRC SYST VID, V29, P1973, DOI 10.1109/TCSVT.2018.2859773
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Wang J, 2022, APPL INTELL, V52, P12034, DOI 10.1007/s10489-021-02971-6
   Wang J, 2022, APPL INTELL, V52, P6208, DOI 10.1007/s10489-021-02713-8
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Xu C, 2021, Appl Soft Comput, V108
   Xu MZ, 2020, IEEE T CIRC SYST VID, V30, P2191, DOI 10.1109/TCSVT.2019.2920652
   Yan PX, 2019, IEEE I CONF COMP VIS, P7283, DOI 10.1109/ICCV.2019.00738
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yao R, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3391743
   Zhang M, 2021, Dynamic context-sensitive filtering network for video salient object detection, P1533
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zheng QP, 2022, NEUROCOMPUTING, V467, P465, DOI 10.1016/j.neucom.2021.10.007
   Zhengyun Z, 2021, J Phys Conf Ser, V1873
NR 75
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17614-w
EA NOV 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500004
DA 2024-07-18
ER

PT J
AU Bajait, V
   Malarvizhi, N
AF Bajait, Vaishali
   Malarvizhi, N.
TI Grape leaf disease prediction using Sine Cosine Butterfly
   Optimization-based deep neuro fuzzy network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Agriculture; Deep neuro-fuzzy model; Multi-classification; DeepJoint
   model; Gaussian filtering; Black spot segmentation; Threshold
ID IDENTIFICATION
AB The diseases in plants produce a distressing impact to initiate safety in producing food and show a qualitative fall in farming. Commonly, plant disease can lead to no grain harvest. Hence, automated discovery of leaf disease is highly needed to discover the agricultural data. Various strategies are devised for detecting the leaf disease in which deep learning is preferred due to its effectual performance. This paper devises a novel optimization-driven deep model for classifying the grape leaf disease. The first step is pre-processing, which is performed by a Gaussian filter. From the pre-processed image, interesting regions are extracted which are utilized for segmentation. The segmentation is performed by the Deep Joint model for identifying the black spot region. The segments obtained are passed to a multi-class classification module, wherein the Deep Neuro-Fuzzy network (DNFN) is utilized in generating multiple classes. DNFN training is performed by exploiting proposed Sine Cosine Butterfly Optimization (SCBO), obtained by integrating Monarch Butterfly Optimization (MBO) and Sine Cosine Algorithm (SCA). Thus, the proposed SCBO-based DNFN helps to classify the grape leaf disease. The proposed SCBO-based DNFN provided improved outcomes with utmost accuracy of 92%, sensitivity of 91.7%, specificity of 92%, the precision of 92.5%, and an F1-Score of 92.5%.
C1 [Bajait, Vaishali; Malarvizhi, N.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept CSE, Chennai, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Bajait, V (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept CSE, Chennai, India.
EM vaishalibajait2018@gmail.com; drnmalarvizhi@veltech.edu.in
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Al Balushi K, 2020, J Comput Mech, Power Syst Control, V3, DOI [10.46253/jcmps.v3i4.a5, DOI 10.46253/JCMPS.V3I4.A5]
   Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Alajas O.J., 2021, 2021 International Conference on Intelligent Technologies (CONIT), Hubli, India, 2527 June 2021, P1
   Amalarethinam DD.I.G., 2012, IOSR J Eng, P1168, DOI DOI 10.9790/3021-020511681176
   Anandkumar M., 2020, MULTIMEDIA RES, V3, P43, DOI [10.46253/j.mr.v3i4.a5, DOI 10.46253/J.MR.V3I4.A5]
   Andrushia AD, 2020, EVOL SYST-GER, V11, P105, DOI 10.1007/s12530-019-09289-2
   [Anonymous], 2014, Advanced computing, networking and informatics- volume 1. Smart innovation, DOI DOI 10.1007/978-3-319-07353-8_44
   Ashwinkumar S, 2022, MATER TODAY-PROC, V51, P480, DOI 10.1016/j.matpr.2021.05.584
   Bojja GR, 2020, P P MWAIS
   Bojja GR, 2021, AMCIS 2021 P
   Chouhan SS, 2020, ARCH COMPUT METHOD E, V27, P611, DOI [10.1007/s11831-019-09324-0, 10.33552/abeb.2018.01.000510]
   Falaschetti L, 2021, IEEE J EM SEL TOP C, V11, P468, DOI 10.1109/JETCAS.2021.3098454
   Ghoneim S, 2019, Towards Data Sci.
   Gondchawar N., 2016, INT J ADV RES COMPUT, P838, DOI [DOI 10.17148/IJARCCE.2016.56188, 10.17148/IJARCCE.2016.56188]
   Hwang JJ, 2016, 2016 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES, RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P153, DOI 10.1109/RIVF.2016.7800286
   Issad H. A., 2019, Engineering in Agriculture, Environment and Food, V12, P511
   Jaisakthi SM, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI 10.1109/iccids.2019.8862084
   Javaid S, 2019, INT WIREL COMMUN, P1594
   kaggle, New Plant Diseases Dataset
   Kartikeyan P., 2021, INT J COMPUT APPL, V975, P8887, DOI [DOI 10.5120/IJCA2021920990, 10.5120/ijca2021920990]
   Kaviyaraj R., 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P47, DOI 10.1109/ICAIS50930.2021.9395838
   Khanna M, 2021, Analytics Vidhya
   Li Y, 2021, POWDER TECHNOL, V388, P251, DOI 10.1016/j.powtec.2021.04.068
   Liu B, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.01082
   Liu B, 2020, IEEE ACCESS, V8, P102188, DOI 10.1109/ACCESS.2020.2998839
   Mahesh KM, 2020, IET IMAGE PROCESS, V14, P2541, DOI 10.1049/iet-ipr.2018.6682
   Martinelli F, 2015, AGRON SUSTAIN DEV, V35, P1, DOI 10.1007/s13593-014-0246-1
   Miaomiao Ji, 2020, Information Processing in Agriculture, V7, P418, DOI 10.1016/j.inpa.2019.10.003
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Patil R., 2016, Int. Res. J. Eng. Technol. (IRJET), V3, P2330
   Poojari S, 2020, 2 INT C COMMUNICATIO, P10
   Preetha N.S. Ninu, 2018, Multimedia Res, P17
   Pydipati R, 2006, COMPUT ELECTRON AGR, V52, P49, DOI 10.1016/j.compag.2006.01.004
   Rothe PR, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Shantkumari M, 2021, MULTIMED TOOLS APPL, V80, P8861, DOI 10.1007/s11042-020-09853-y
   Sujatha R, 2021, MICROPROCESS MICROSY, V80, DOI 10.1016/j.micpro.2020.103615
   Swaminathan B, 2020, Int J Innov Sci Res Technol, V5, P564
   Tambulunde S., 2021, J Netw Commun Syst, V4
   Wang GG, 2019, NEURAL COMPUT APPL, V31, P1995, DOI 10.1007/s00521-015-1923-y
   Xie XY, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00751
   Zhou CJ, 2021, IEEE ACCESS, V9, P100480, DOI 10.1109/ACCESS.2021.3097050
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17353-y
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200001
DA 2024-07-18
ER

PT J
AU Li, HJ
   Chen, MY
   Sun, XH
   Chen, JJ
AF Li, Hongjun
   Chen, Mingyi
   Sun, Xiaohu
   Chen, Junjie
TI MTM-net: a multidimensional two-stage memory-guided network for vedio
   abnormal detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video abnormal detection; Temporal feature extraction; Feature
   separation and fusion; Two-stage memory-guided network
ID VIDEO ANOMALY DETECTION
AB Video anomaly detection is a very challenging task in the field of computer vision. In this paper, we propose a multidimensional two-stage memory-guided network based on future frame prediction. Firstly, based on the understanding of the temporal correlation information between continuous video frames, we use an implicit computational approach to extract the temporal mobility features between continuous video frames effectively. Then, unify the representation of spatial and temporal features through a feature dimensional expansion strategy. However, we noted that the mobility features changed morphology and presented different feature distributions at two key stages before and after the entire extraction process, both with the ability to represent normal behavior. In this way, we can obtain a more standardized representation of features in the temporal dimension and increase the reconstruction error of abnormal events to improve the detection effect. We conduct a wide range of experiments on three publicly available datasets and obtain good results to demonstrate the effectiveness of our proposed network.
C1 [Li, Hongjun; Chen, Mingyi; Sun, Xiaohu; Chen, Junjie] Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.
   [Li, Hongjun; Chen, Junjie] Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
C3 Nantong University
RP Li, HJ; Chen, MY (corresponding author), Nantong Univ, Sch Informat Sci & Technol, 9 Seyuan Rd, Nantong 226019, Jiangsu, Peoples R China.; Li, HJ (corresponding author), Nantong Res Inst Adv Commun Technol, Nantong 226019, Jiangsu, Peoples R China.
EM lihongjun103@126.com; 2110310018@stmail.ntu.edu.cn;
   2010310052@stmail.ntu.edu.cn; cjjcy@ntu.edu.cn
OI Chen, Junjie/0000-0003-4219-6171; li, hongjun/0000-0001-7500-4979; sun,
   xiao hu/0000-0002-5501-5424
FU National Natural Science Foundation of China [61871241, 61971245,
   61976120]; Nantong Science and Technology Program [JC2021131];
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province [KYCX21_3084, KYCX22_3340]
FX This work is supported in part by National Natural Science Foundation of
   China under Grant 61871241, Grant 61971245 and Grant 61976120, in part
   by Nantong Science and Technology Program JC2021131 and in part by
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province KYCX21_3084 and KYCX22_3340.
CR Aggarwal A. K., 2020, J COMPUT SCI-NETH, V16, P651, DOI DOI 10.3844/JCSSP.2020.651.659
   Aggarwal A.K., 2022, Int J Biol Biomed Eng, V16, P241, DOI DOI 10.46300/91011.2022.16.30
   [Anonymous], 2018, P EUR C COMP VIS ECC
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Chen C., 2022, A novel long-term iterative mining scheme for video salient object detection, V32, P7662
   Chen C, 2016, Robust salient motion detection in non-stationary videos via novel integrated strategies of spatio-temporal coherency clues and low-rank analysis, V52, P410
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fanta H, 2020, INFORM SCIENCES, V524, P15, DOI 10.1016/j.ins.2020.03.034
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Garg M, 2021, Autonomous driving and advanced driver-assistance systems (ADAS), P233
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Guo JY, 2022, PROC CVPR IEEE, P12165, DOI 10.1109/CVPR52688.2022.01186
   Hayashi T, 2021, INFORM SCIENCES, V560, P217, DOI 10.1016/j.ins.2021.01.069
   Heeseung Kwon, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P345, DOI 10.1007/978-3-030-58517-4_21
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jais IKM., 2019, KNOWL ENG DATA SCI, V2, P41, DOI [DOI 10.17977/UM018V2I12019P41-46, 10.17977/um018v2i12019p41-46]
   Ji DJ, 2019, IEEE COMMUN LETT, V23, P1769, DOI 10.1109/LCOMM.2019.2930287
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Kaur A, 2023, IETE J RES, V69, P7907, DOI 10.1080/03772063.2022.2060869
   Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238
   Li CB, 2023, APPL INTELL, V53, P542, DOI 10.1007/s10489-022-03488-2
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li HJ, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108173
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P1883, DOI 10.1007/s11042-020-09708-6
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Luo WX, 2022, IEEE T PATTERN ANAL, V44, P7505, DOI 10.1109/TPAMI.2021.3129349
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Massoli FV, 2022, IEEE T NEUR NET LEAR, V33, P2313, DOI 10.1109/TNNLS.2021.3130074
   Niu TZ, 2022, IEEE-ASME T MECH, V27, P46, DOI 10.1109/TMECH.2021.3058147
   Park H, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258065
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Sevilla-Lara Laura, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P281, DOI 10.1007/978-3-030-12939-2_20
   Sharma R, 2022, IEEE WINT CONF APPL, P1302, DOI 10.1109/WACV51458.2022.00137
   Stroud JC, 2020, IEEE WINT CONF APPL, P614, DOI 10.1109/wacv45572.2020.9093274
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Sun X, 2022, IEEE T CYBERNETICS, V52, P8239, DOI 10.1109/TCYB.2021.3051028
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Véstias M, 2021, J SIGNAL PROCESS SYS, V93, P531, DOI 10.1007/s11265-020-01606-2
   Wang WQ, 2021, NEUROCOMPUTING, V433, P37, DOI 10.1016/j.neucom.2020.12.025
   Wu RZ, 2021, NEUROCOMPUTING, V462, P523, DOI 10.1016/j.neucom.2021.05.112
   Xiao J, 2023, IEEE ACCESS, V11, P85600, DOI 10.1109/ACCESS.2023.3297513
   Xiao J, 2023, MEASUREMENT, V214, DOI 10.1016/j.measurement.2023.112764
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yang LX, 2021, IEEE T IND INFORM, V17, P6390, DOI 10.1109/TII.2020.3011441
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Yu G, 2020, Cloze test helps: Effective video anomaly detection via learning to complete video events, P583, DOI [10.1145/3394171.3413973, DOI 10.1145/3394171.3413973]
   Yu M, 2022, NEURAL COMPUT APPL, V34, P2503, DOI 10.1007/s00521-021-05933-8
   Yunpeng Chang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P329, DOI 10.1007/978-3-030-58555-6_20
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
NR 54
TC 1
Z9 1
U1 7
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17164-1
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200006
DA 2024-07-18
ER

PT J
AU Pak, C
   Jong, C
   Pang, RS
   Ri, S
   Kim, J
AF Pak, Chanil
   Jong, Cholmin
   Pang, Ryusung
   Ri, Songjun
   Kim, Jinsim
TI A new image encryption algorithm using 2D infinite collapse coupling map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaos map; Chaotic system; 1D-ICM; 2D-ICCM; Image encryption;
   Pixel-level image encryption
AB Chaotic map is widely used in various fields such as information security, information communication, and system control, etc. due to its excellent unpredictability and complexity performance. In this study, based on the published literatures, a novel 2D-ICCM (2D Infinite Collapse Coupling Map) is developed by combining two 1D-ICM (1D Infinite Collapse Map) and its chaotic performance is verified through different analyses on bifurcation characteristic, lyapunov exponent, and information entropy and through randomness test. The results obtained from experiments demonstrate that proposed 2D-ICCM has excellent chaotic behavior. In addition, in order to validate applicability of the proposed 2D chaotic map to image encryption, 2D-ICCM implemented simple-structured pixel-level image encryption algorithm is proposed and the performance of our scheme is verified through experiments. The experimental results show that the proposed image encryption algorithm is robust to various cyber-attacks and has excellent performance.
C1 [Pak, Chanil; Jong, Cholmin; Pang, Ryusung; Ri, Songjun] Kim Chaek Univ Technol, Inst Informat Technol, Pyongyang 950003, South Korea.
   [Kim, Jinsim] Kim Chaek Univ Technol, Int Technol Cooperat Ctr, Pyongyang 950003, South Korea.
RP Pak, C (corresponding author), Kim Chaek Univ Technol, Inst Informat Technol, Pyongyang 950003, South Korea.
EM pchi75826@star-co.net.kp
OI Pak, Chanil/0000-0003-2344-6438
FU Authors extend the sincere thanks to editors, reviewers and all the
   people who have made a contribution to this publication.
FX Authors extend the sincere thanks to editors, reviewers and all the
   people who have made a contribution to this publication.
CR Akif O. Z., 2021, Bull Electr Eng Inform, V10, P1580, DOI DOI 10.11591/EEI.V10I3.2610
   Askar SS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122001
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Cao WJ, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107457
   Erkan U., 2022, Inf Sci, V11, P1
   Gao XH, 2021, OPT LASER TECHNOL, V142, DOI 10.1016/j.optlastec.2021.107252
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Hua ZY, 2021, INFORM SCIENCES, V546, P1063, DOI 10.1016/j.ins.2020.09.032
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Li DH, 2023, NONLINEAR DYNAM, V111, P2917, DOI 10.1007/s11071-022-07949-8
   Li Q, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abfa01
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Liu HJ, 2019, MULTIMED TOOLS APPL, V78, P15997, DOI 10.1007/s11042-018-6996-z
   Liu LD, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102854
   Liu Z, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6625579
   Mondal B, 2021, J REAL-TIME IMAGE PR, V18, P1, DOI 10.1007/s11554-019-00940-4
   Nunez JA., 1996, Information entropy. Celest Mech Dyn Astron, V64, P43, DOI [10.1007/BF00051604, DOI 10.1007/BF00051604]
   Pak C, 2021, MULTIMED TOOLS APPL, V80, P25367, DOI 10.1007/s11042-021-10660-2
   Pak C, 2020, MULTIMED TOOLS APPL, V79, P1409, DOI 10.1007/s11042-019-08103-0
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Qiu HJ, 2022, NONLINEAR DYNAM, V110, P2869, DOI 10.1007/s11071-022-07756-1
   Shakiba A, 2021, MULTIMED TOOLS APPL, V80, P17983, DOI 10.1007/s11042-021-10584-x
   Sun JL, 2021, IEEE ACCESS, V9, P59313, DOI 10.1109/ACCESS.2021.3070350
   Wang JY, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13122290
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang F, 2023, IEEE ACCESS, V11, P59346, DOI 10.1109/ACCESS.2023.3282370
   Zhang XQ, 2023, NONLINEAR DYNAM, V111, P6839, DOI 10.1007/s11071-022-08185-w
   Zhang ZZ, 2023, NONLINEAR DYNAM, V111, P10629, DOI 10.1007/s11071-023-08397-8
   Zhu HG, 2019, IEEE ACCESS, V7, P14081, DOI 10.1109/ACCESS.2019.2893538
NR 35
TC 1
Z9 1
U1 8
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 7
PY 2023
DI 10.1007/s11042-023-17493-1
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3TF7
UT WOS:001097705200005
DA 2024-07-18
ER

PT J
AU Chen, HS
   Wu, J
   Xu, ZH
   Feng, QS
   Fan, YY
   Li, ZH
AF Chen, Huasong
   Wu, Jing
   Xu, Zhenhua
   Feng, Qiansheng
   Fan, Yuanyuan
   Li, Zhenhua
TI Single image deraining using local rain distribution map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Single image deraining; Rain streak detection; Local rain streak
   removal; Sparse distribution of rain streak
ID SIMULTANEOUS CARTOON; MODEL; ALGORITHM; REMOVAL; RESTORATION; SHRINKAGE
AB Existing image deraining methods work on the entire domain of images causing the deraining results to contain rain streaks or over-smoothing. To alleviate these problems, we propose a local pixel rain streak removal method based on the observation that rain streaks are sparsely distributed in images when rain levels are slight and middle. We first propose a discriminative anisotropic gradient prior to efficiently extract rain streaks from the background and generate a rain streak distribution (RSD) mask. Then, we recover the information in the rain-distorted regions with the RSD mask using a simple multi-layer image inpainting method. Experiments on both synthesized and real-world images demonstrate that our method outperforms the state-of-the-art methods in terms of rain streak detection, removal, and information restoration.
C1 [Chen, Huasong; Wu, Jing; Feng, Qiansheng; Fan, Yuanyuan] Huaiyin Inst Technol, Fac Math & Phys, Huaian 223001, Peoples R China.
   [Xu, Zhenhua; Li, Zhenhua] Nanjing Univ Sci & Technol, Sch Sci, Nanjing 210094, Peoples R China.
C3 Huaiyin Institute of Technology; Nanjing University of Science &
   Technology
RP Chen, HS (corresponding author), Huaiyin Inst Technol, Fac Math & Phys, Huaian 223001, Peoples R China.
EM chenhuasong@hyit.edu.cn
RI Xu, Zhenhua/AAQ-3512-2020; Chen, Huasong/ABF-1382-2021
FU The authors would like to thank the support by Natural Science
   Foundation of Huaian (HABZ202116). In addition, they would like to thank
   Dr. Xueyang Fu, Dr. Liangjian Deng, Yu Luo, and Wenhan Yang for sharing
   their codes online. [HABZ202116]; Natural Science Foundation of Huaian
FX The authors would like to thank the support by Natural Science
   Foundation of Huaian (HABZ202116). In addition, they would like to thank
   Dr. Xueyang Fu, Dr. Liangjian Deng, Yu Luo, and Wenhan Yang for sharing
   their codes online.
CR Arias P, 2011, INT J COMPUT VISION, V93, P319, DOI 10.1007/s11263-010-0418-7
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Chen HS, 2021, APPL MATH MODEL, V98, P628, DOI 10.1016/j.apm.2021.04.003
   Chen HS, 2020, CIRC SYST SIGNAL PR, V39, P2507, DOI 10.1007/s00034-019-01268-x
   Chen HS, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115762
   Chen HS, 2015, J VIS COMMUN IMAGE R, V31, P282, DOI 10.1016/j.jvcir.2015.07.004
   Deng LJ, 2018, APPL MATH MODEL, V59, P662, DOI 10.1016/j.apm.2018.03.001
   Ding XH, 2016, MULTIMED TOOLS APPL, V75, P2697, DOI 10.1007/s11042-015-2657-7
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Esser E, 2009, CAM reports, V09-31
   Fu XY, 2021, INT J COMPUT VISION, V129, P1691, DOI 10.1007/s11263-020-01428-6
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Fu YH, 2011, INT CONF ACOUST SPEE, P1453
   Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Jung M, 2015, SIAM J IMAGING SCI, V8, P721, DOI 10.1137/140967416
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189
   Li RT, 2019, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2019.00173
   Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Liu RS, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1408, DOI 10.1109/ICASSP.2018.8461892
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Moll JS, 2005, MATH ANN, V332, P177, DOI 10.1007/s00208-004-0624-0
   Mu P, 2019, IEEE SIGNAL PROC LET, V26, P307, DOI 10.1109/LSP.2018.2889277
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Tang LM, 2019, APPL MATH MODEL, V69, P355, DOI 10.1016/j.apm.2018.12.021
   Wang H, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-020-3225-9
   Wang H, 2020, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR42600.2020.00317
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wang YL, 2017, IEEE T IMAGE PROCESS, V26, P3936, DOI 10.1109/TIP.2017.2708502
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei W, 2019, PROC CVPR IEEE, P3872, DOI 10.1109/CVPR.2019.00400
   Wen ZW, 2010, SIAM J SCI COMPUT, V32, P1832, DOI 10.1137/090747695
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xu J., 2012, CANADIAN CTR SCI ED, V5, P49, DOI DOI 10.5539/CIS.V5N3P49
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yang WH, 2021, IEEE T PATTERN ANAL, V43, P4059, DOI 10.1109/TPAMI.2020.2995190
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
   Zhou M, 2021, PROC CVPR IEEE, P4905, DOI 10.1109/CVPR46437.2021.00487
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 53
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-16972-9
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500013
DA 2024-07-18
ER

PT J
AU Uke, SN
   Zade, A
AF Uke, Shailaja N.
   Zade, Amol
TI Optimal video processing and soft computing algorithms for human hand
   gesture recognition from real-time video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Frames; Features extraction; Hand gesture recognition; Spatiotemporal;
   Soft computing; Video processing
AB An essential component of building an automated hand gesture detection system is the ability to extract hand movements using a single video camera. Results for hand extraction using color cues have been encouraging utilizing local spatiotemporal approaches. When the video is recorded in real life, the color intensities are not clear. The research of hand gesture machine translation for real-world video processing has halted. Video frames make it hard to recognize the hand and extract the required information for accurate identification. A new framework for real-time hand gesture detection from films is proposed using optimum video and soft computing algorithms. In the proposed system, real-time video is captured for human Hand Gesture Recognition (HGR). The framework consists of real-time video acquisition, video normalization, Hand Frames Feature Extraction (HFFE), and classification. In the video normalization phase, we first discard the redundant frames to reduce the time and space complexity using dynamic thresholding. The remaining video frames are normalized by applying the image pre-processing operations to enhance the frame's quality. The HFEF is the vital and novel phase of the proposed model as it consists of enhanced spatiotemporal-based feature extraction where we have designed a cuboid-based detector and Speeded-Up Robust Features (SURF). The HFEF phase extracts the robust hand features from the sequence of pre-processed video frames for efficient classification. Finally, the recognition of hand gestures is performed by applying different soft computing algorithms. The simulation results using the real-time research datasets prove the improvement using the proposed model over the existing solutions.
C1 [Uke, Shailaja N.; Zade, Amol] GHRaisoni Univ, Amravati, India.
RP Uke, SN (corresponding author), GHRaisoni Univ, Amravati, India.
EM shailajauke274@gmail.com; amol.zade@ghru.edu.in
RI Uke, Shailaja/ABG-5419-2021
OI Uke, Shailaja/0000-0001-5185-627X
CR Abdallah MS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010002
   Ahmed S, 2023, MULTIMED TOOLS APPL, V82, P43945, DOI 10.1007/s11042-023-14835-x
   Al Farid F, 2022, J IMAGING, V8, DOI 10.3390/jimaging8060153
   Badi H, 2016, INT J DATA SCI ANAL, V1, P77, DOI DOI 10.1007/S41060-016-0008-Z
   Bakheet S, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00567-1
   Benitez-Garcia G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020356
   Bhushan S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060968
   Bowman-Smart H, 2019, MONASH BIOETH REV, V37, P94, DOI 10.1007/s40592-019-00101-0
   Brunet D, 2011, LECT NOTES COMPUT SC, V6753, P100, DOI 10.1007/978-3-642-21593-3_11
   Chakraverti S, 2024, MULTIMED TOOLS APPL, V83, P11017, DOI 10.1007/s11042-023-16016-2
   Chen R, 2013, ICIRA 2013. Lect Notes Comput Sci, V8102, DOI [10.1007/978-3-642-40852-6_66, DOI 10.1007/978-3-642-40852-6_66]
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Dakshayani V, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071063
   Elouariachi I, 2020, PATTERN ANAL APPL, V23, P1337, DOI 10.1007/s10044-020-00866-9
   Galván-Ruiz J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123571
   Goel R., 2021, SSRN Electron J, DOI [10.2139/ssrn.3884967, DOI 10.2139/SSRN.3884967]
   Jana A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12147303
   Joksimoski B, 2022, IEEE ACCESS, V10, P40979, DOI 10.1109/ACCESS.2022.3161440
   Kang SD, 2007, ICCSA 2007. Lect Note Comput Sci, V4705, DOI [10.1007/978-3-540-74472-6_30, DOI 10.1007/978-3-540-74472-6_30]
   Kim T-K, 2007, R.: Tensor canonical correlation analysis for action classification, DOI [10.1109/CVPR.2007.383137, DOI 10.1109/CVPR.2007.383137]
   Li YF, 2022, SCI PROGRESS-UK, V105, DOI 10.1177/00368504221086362
   Mahajan H, 2024, CLUSTER COMPUT, V27, P2785, DOI 10.1007/s10586-023-04123-6
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P23251, DOI 10.1007/s11042-022-14253-5
   Mahajan HB, 2022, WIRELESS PERS COMMUN, V126, P2425, DOI 10.1007/s11277-022-09535-y
   Mahajan HB, 2023, MULTIMED TOOLS APPL, V82, P44335, DOI 10.1007/s11042-023-15204-4
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Miah AM, 2023, COMPUTERS, V12, DOI 10.3390/computers12010013
   Moysiadis V, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168160
   Mujahid A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094164
   Noble F, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073419
   Nogales RE, 2021, INT J MACH LEARN CYB, V12, P2859, DOI 10.1007/s13042-021-01372-y
   Obaid F, 2020, APPL COMPUT SYST, V25, P57, DOI 10.2478/acss-2020-0007
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Oyallon E, 2015, IMAGE PROCESS ON LIN, V5, P176, DOI 10.5201/ipol.2015.69
   Ravi S, 2019, J COMPUT LANG, V52, P88, DOI 10.1016/j.cola.2019.04.002
   Sahana T, 2022, MULTIMED TOOLS APPL, V81, P8539, DOI 10.1007/s11042-021-11743-w
   Sarma Debajit, 2021, SN Comput Sci, V2, P436, DOI 10.1007/s42979-021-00827-x
   Sen A, 2022, MULTIMED TOOLS APPL, V81, P40043, DOI 10.1007/s11042-022-11909-0
   Shanthakumar VA, 2020, MULTIMED TOOLS APPL, V79, P17707, DOI 10.1007/s11042-019-08520-1
   Sharma I, 2023, J INF SCI, DOI 10.1177/01655515231165230
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Swapna B, 2011, COMM COM INF SC, V250, P782
   Tsai DM, 2002, INT J ADV MANUF TECH, V20, P664, DOI 10.1007/s001700200205
   Wang F, 2021, PROCEDIA COMPUT SCI, V187, P140, DOI 10.1016/j.procs.2021.04.044
   Yang L., 2019, Virtual Real. Intell. Hardw, V1, P84, DOI [10.3724/SP.J.2096-5796.2018.0006, DOI 10.3724/SP.J.2096-5796.2018.0006, 10.3724/sp.j.2096-5796.2018.0006]
   Yasen M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.218
   Yu JM, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08133-z
   Zengeler N, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010059
NR 48
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17608-8
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500008
DA 2024-07-18
ER

PT J
AU Agarwal, YK
   Pandey, D
   Umrao, LS
AF Agarwal, Yatin Kumar
   Pandey, Dilkeshwar
   Umrao, Lokendra Singh
TI Hybrid query refinement based approach for enhanced biomedical image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Content-based image retrieval; MeSH ontology; Concept-based retrieval;
   Feature extraction; Hybrid query refinement; Rapid automatic keyword
   extraction
ID INFORMATION-RETRIEVAL; ONTOLOGY; EXAMPLE
AB With the advent of technology, abundant electronic biomedical data is available and extracting relevant information from huge data is a fundamental need. In medical image retrieval, majority of the information is extracted either through content-based or context-based retrieval. The semantic information in images is not considered in previous research. In this work, the proposed hybrid query refinement framework for medical image retrieval shows promising results in improving the accuracy of search results compared to existing approaches. By incorporating both low-level features and high-level semantic terms based on the MeSH hierarchy, the framework addresses some existing limitations of content-based image retrieval (CBIR) approach based on relevance feedback and semantic knowledge. The framework uses the OpenI search engine to retrieve a pool of images based on user-generated queries related to a medical disease. Then, the images are processed using Scikit Image library to extract features like size, orientation, shape, and color. Edge feature extraction and region-based segmentation are performed to identify important features and analyze them more closely. The results show that the proposed approach achieves improved precision@10 and MAP for OpenI search engine compared to baseline CBIR. The number of retrieved images is also significantly reduced, indicating the relevance of the retrieved images. The proposed approach provides a more accurate and efficient medical image retrieval system that can help medical practitioners conclude diagnoses faster. Future research can focus on expanding the framework to incorporate more advanced machine learning algorithms for feature extraction and classification.
C1 [Agarwal, Yatin Kumar] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
   [Pandey, Dilkeshwar] Krishna Inst Engn & Technol, Ghaziabad, Uttar Pradesh, India.
   [Umrao, Lokendra Singh] Dr Rammanohar Lohia Avadh Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Ayodhya, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); KIET Group of
   Institutions; KIET School of Engineering & Technology
RP Umrao, LS (corresponding author), Dr Rammanohar Lohia Avadh Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Ayodhya, Uttar Pradesh, India.
EM yatinaga@gmail.com; dilkeshwar.pandey@kiet.edu;
   lokendra.rs.cse12@iitbhu.ac.in
RI UMRAO, LOKENDRA/I-5586-2013
OI UMRAO, LOKENDRA/0000-0001-6362-4476
CR Abulaisha M., 2006, Web Intelligence and Agent Systems, V4, P407
   Ahmed A, 2020, IEEE ACCESS, V8, P79969, DOI 10.1109/ACCESS.2020.2990557
   Akinribido CT., 2011, Int J Comput Sci, V8, P382
   Alsmadi MK, 2020, ARAB J SCI ENG, V45, P3317, DOI 10.1007/s13369-020-04384-y
   Alsmadi MK, 2018, J KING SAUD UNIV-COM, V30, P373, DOI 10.1016/j.jksuci.2017.05.002
   Aversano L, 2006, INT J WEB SERV RES, V3, P32, DOI 10.4018/jwsr.2006100102
   Ayadi H, 2018, J ASSOC INF SCI TECH, V69, P1095, DOI 10.1002/asi.24045
   Ballerini L, 2010, LECT NOTES COMPUT SC, V5853, P31, DOI 10.1007/978-3-642-11769-5_3
   Banerjee I, 2018, J BIOMED INFORM, V84, P123, DOI 10.1016/j.jbi.2018.07.002
   Bhogal J, 2007, INFORM PROCESS MANAG, V43, P866, DOI 10.1016/j.ipm.2006.09.003
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   Choe J, 2022, RADIOLOGY, V302, P187, DOI 10.1148/radiol.2021204164
   Choras RyszardS., 2007, INT J BIO BIOMED ENG, V1, P6
   Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Deserno TM, 2009, J DIGIT IMAGING, V22, P202, DOI 10.1007/s10278-007-9092-x
   Ghosh P, 2011, COMP MED SY
   Goyenka R, 2017, Feedback, V6
   Hliaoutakis A, 2006, INT J SEMANT WEB INF, V2, P55, DOI 10.4018/jswis.2006070104
   Irtazal A, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040495
   Jaworska T, 2016, ADV INTELL SYST, V400, P403, DOI 10.1007/978-3-319-26154-6_31
   Kalpathy-Cramer J, 2015, COMPUT MED IMAG GRAP, V39, P55, DOI 10.1016/j.compmedimag.2014.03.004
   Kammoun H, 2022, COMPUT J, V65, DOI 10.1093/comjnl/bxaa073
   Lalmas M, 1998, INFORM PROCESS MANAG, V34, P19, DOI 10.1016/S0306-4573(97)00041-1
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Malik Sumbal, 2020, 2020 14th International Conference on Innovations in Information Technology (IIT), P18, DOI 10.1109/IIT50501.2020.9299028
   Mandikal V, 2018, C NEUR INF PROC SYST
   Mihalcea R., 2006, P 21 NAT C ART INT, V6, P775
   Mitra M., 2000, Information Retrieval, V2, P141, DOI 10.1023/A:1009950525500
   Mutasem K.A., 2017, Egyptian Journal of Basic and Applied Sciences, V4, P112, DOI 10.1016/j.ejbas.2017.02.004
   Nastar C, 1998, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1998.698659
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Rajasurya S, 2012, arXiv
   Reddy KS., 2016, Int J Electron Commun Eng, V9, P19
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sahni L, 2014, PROCEEDINGS OF 2014 2ND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P89, DOI 10.1109/ISCBI.2014.26
   Sanderson M, 2010, NAT LANG ENG, V16, P100, DOI 10.1017/S1351324909005129
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   Souissi N, 2017, INT C ENG SCI BIOL M
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Torjmen-Khemakhem M, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103210
   Yang CC, 2004, J INF SCI, V30, P254, DOI 10.1177/0165551504044670
   Zhai J, 2012, ADV INTEL SOFT COMPU, V137, P661
   Zin NAM., 2018, In J Phys: Conf Ser, V1019
NR 45
TC 0
Z9 0
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17469-1
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200018
DA 2024-07-18
ER

PT J
AU Madhubabu, K
   Snehalatha, N
AF Madhubabu, Kotakonda
   Snehalatha, N.
TI Optimal Path Selection in Vehicular Adhoc Network Using Hybrid
   Optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular Adhoc Networks; Bat Hybridized Grey Wolf Optimization Method
   Optimal Path Selection; Congestion; Mobility
ID AD HOC NETWORKS; ALGORITHM
AB Businesses, academics, and professionals are concentrating on enhancing safety as a consequence of the swift development of wireless technology. The gathering of meaningful traffic data enables travelers to choose more informed routes. The main query is, "How do we receive traffic information? Although it is frequently necessary to conduct further research on issues like "How can we collect traffic information efficiently and economically?" and "Which path is the shortest trip time between two vertices?". The goal of this research project is to identify the best, quickest route between the starting point and the finishing point. This is accomplished by the proposed BHGWO model. This paper intends to introduce an optimal path or route selection in VANET. Between the source and the destination, the vehicle information should be noted for the selection of better paths or routes. From this, the mobility and congestion details are stored in the IoT. In prior, the possible paths are listed out, from which the optimal route or path is selected. The Bat Hybridized Grey Wolf Optimization (BHGWO) method, a new hybrid optimization model that conceptually combines the Bat Optimization Algorithm (BOA) with the Grey Wolf Optimization (GWO) algorithm, is presented as a solution to this problem. The accepted BHGWO model's convergence analysis was calculated using the conventional schemes ACO, GA, GWO, CSA, and BOA, correspondingly. Further, the performance was calculated with respect to congestion, delay, and energy based on 50 vehicles, 100 vehicles, 150 vehicles, and 200 vehicles, respectively.
C1 [Madhubabu, Kotakonda; Snehalatha, N.] SRM Inst Sci & Technol, Dept Computat Intelligence, Chennai, Tamil Nadu, India.
C3 SRM Institute of Science & Technology Chennai
RP Madhubabu, K (corresponding author), SRM Inst Sci & Technol, Dept Computat Intelligence, Chennai, Tamil Nadu, India.
EM madhuimp9@gmail.com; snehalan@srmist.edu.in
RI MADHUBABU, KOTAKONDA/HTS-0510-2023
OI MADHUBABU, KOTAKONDA/0000-0003-4857-3142
CR Afrashteh M, 2020, IEEE T VEH TECHNOL, V69, P16017, DOI 10.1109/TVT.2020.3041754
   Al-Kharasani NM, 2020, IEEE ACCESS, V8, P128757, DOI 10.1109/ACCESS.2020.2974105
   AlBalushi FM., 2020, MULTIMED RES, V3, P2
   Alzamzami O, 2020, AD HOC NETW, V106, DOI 10.1016/j.adhoc.2020.102213
   Aravindhan K, 2019, SOFT COMPUT, V23, P2499, DOI 10.1007/s00500-018-03685-7
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Bujari A, 2019, AD HOC NETW, V82, P126, DOI 10.1016/j.adhoc.2018.07.024
   Cai Z, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1475-4
   Chahal M, 2019, COMPUT ELECTR ENG, V76, P40, DOI 10.1016/j.compeleceng.2019.03.006
   Chakri A, 2017, EXPERT SYST APPL, V69, P159, DOI 10.1016/j.eswa.2016.10.050
   Darekar RV., 2019, MULTIMED RES, V2, P412
   Debnath A, 2020, AEU-INT J ELECTRON C, V2020
   Fan N, 2019, AD HOC NETW, V90, DOI 10.1016/j.adhoc.2018.08.010
   Ghorai C, 2019, VEH COMMUN, V2019
   Gupta D, 2014, 2014 5 INT C CONFL N
   Gurumoorthi E, 2019, WIRELESS PERS COMMUN, V109, P1195, DOI 10.1007/s11277-019-06610-9
   Gurumoorthi E, 2022, INT J INF TECNOL, V1-10
   Kumari ND, 2018, J KING SAUD U COMPUT, V2018
   Lakshmanaprabu SK, 2019, J CLEAN PROD, V217, P584, DOI 10.1016/j.jclepro.2019.01.115
   Li GY, 2017, IEEE T VEH TECHNOL, V66, P3249, DOI 10.1109/TVT.2016.2586382
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Naderi M, 2019, AD HOC NETW, V2019
   Nebbou T, 2019, VEH COMMUN, V18, DOI 10.1016/j.vehcom.2019.100162
   Raja M, 2021, SOFT COMPUT, V25, P4053, DOI 10.1007/s00500-020-05432-3
   Rehman O, 2019, FUTURE GENER COMP SY, V93, P1, DOI 10.1016/j.future.2018.10.042
   Rewadkar D., 2019, J NETW COMMUN SYST, V2, P29
   Rewadkar D., 2018, J NETWORKING COMMUNI, V1, P36, DOI DOI 10.46253/JNACS.V1I1.A5
   Rui LL, 2018, AD HOC NETW, V81, P211, DOI 10.1016/j.adhoc.2018.06.012
   Sharef B, 2019, VEH COMMU 2019
   Srivastava A, 2020, PEER PEER NETW APPL, V13, P1375, DOI 10.1007/s12083-020-00892-8
   Usha M, 2019, WIRELESS PERS COMMUN, V109, P271, DOI 10.1007/s11277-019-06564-y
   Usha M, 2019, WIRELESS PERS COMMUN, V106, P763, DOI 10.1007/s11277-019-06189-1
   Wagh MB., 2019, J NETW COMMUN SYST, V2, P34, DOI DOI 10.46253/JNACS.V2I1.A4
   Zhao J, 2019, VEH COMMUN, V17, P1, DOI 10.1016/j.vehcom.2019.03.005
NR 34
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18261
EP 18280
DI 10.1007/s11042-023-17513-0
EA NOV 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001098545500018
DA 2024-07-18
ER

PT J
AU Aljabri, A
   Jemili, F
   Korbaa, O
AF Aljabri, Ahmed
   Jemili, Farah
   Korbaa, Ouajdi
TI Intrusion detection in cyber-physical system using rsa blockchain
   technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cyber-Physical Systems; Intrusion Detection Systems; RSA; Deep Learning;
   Blockchain
ID SECURE
AB Connected cyber and physical elements exchange information through feedback in a cyber-physical system (CPS). Since CPS oversees the infrastructure, it is an integral part of modern living and is viewed as crucial to the development of cutting-edge smart devices. As the number of CPSs rises, so does the need for intrusion detection systems (IDS). The use of metaheuristic methods and Artificial Intelligence for feature selection and classification can offer solutions to some of the problems caused by the curse of dimensionality. In this research, we present a blockchain-based approach to data security in which blocks are generated using the RSA hashing method. Using Differential Evolution (DE), we first select the blockchain-secured data, and then we partition that data into train and testing datasets to use for training and testing our model. It is also permitted for the validated model to use a deep belief network (DBN) to predict attacks. The purpose of the simulation is to evaluate the safety and precision of the classifications. It turns out that the proposed strategy not only improves classification accuracy but also makes the data more resistant to attacks.
C1 [Aljabri, Ahmed; Jemili, Farah; Korbaa, Ouajdi] Univ Sousse, MARS Res Lab, ISITCom, LR17ES05, Hammam Sousse 4011, Tunisia.
C3 Universite de Sousse
RP Jemili, F (corresponding author), Univ Sousse, MARS Res Lab, ISITCom, LR17ES05, Hammam Sousse 4011, Tunisia.
EM Jmili_farah@yahoo.fr
RI Jemili, Farah/ABD-9891-2021; KORBAA, Ouajdi/G-4705-2019
OI Jemili, Farah/0000-0001-7511-1221; KORBAA, Ouajdi/0000-0003-4462-1805
CR Afanasev Maxim Ya, 2018, 2018 IEEE Industrial Cyber-Physical Systems (ICPS). Proceedings, P13, DOI 10.1109/ICPHYS.2018.8387630
   Ahmed E., 2021, Future Comput Inf J, V6, P1
   Akay B., 2021, Swarm Evol Comput, V61, P100866
   Alhalafi A., 2021, IEEE Access, V9, P123372
   Almajed R., 2022, Periodicals of Engineering and Natural Sciences, V10, P261, DOI [10.21533/pen.v10i3.3035, DOI 10.21533/PEN.V10I3.3035]
   Bouachir O, 2020, COMPUTER, V53, P36, DOI 10.1109/MC.2020.2996212
   Evsutin O., 2022, Security and Privacy Preserving for IoT and 5G Networks: Techniques, Challenges, and New Directions, P81
   Ghrabat MJJ, 2019, IEEE ACCESS, V7, P169142, DOI 10.1109/ACCESS.2019.2948266
   Gontara S, 2019, IEEE SYS MAN CYBERN, P2071, DOI 10.1109/SMC.2019.8914491
   Hannah S, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/5038851
   Jemili F, 2023, CLUSTER COMPUT, V26, P3719, DOI 10.1007/s10586-022-03769-y
   Jia Y., 2021, IEEE Trans Industr Inf, V17, P7469
   Jiang S., 2021, Comput Electr Eng, V92, P107137
   Kariri E, 2022, IETE J RES, DOI 10.1080/03772063.2022.2032848
   Khalil AA, 2022, 2022 IEEE 46TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2022), P1774, DOI 10.1109/COMPSAC54236.2022.00282
   Khan R, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13031959
   Koumidis K, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013452
   Ksiksi T., 2021, IEEE Access, V9, P122337
   Lakhan A, 2022, IEEE Trans Network Sci Eng
   Lv P, 2019, IEEE ACCESS, V7, P41309, DOI 10.1109/ACCESS.2019.2907599
   Nair MM, 2019, PROCEDIA COMPUT SCI, V165, P647, DOI 10.1016/j.procs.2020.01.059
   Saleem S., 2021, Eng Appl Artif Intell, V105, P104202
   Teslya Nikolay, 2018, MATEC Web of Conferences, V161, DOI 10.1051/matecconf/201816103018
   Trivedi RS, 2022, Handbook of Research of Internet of Things and Cyber-Physical Systems, P453
   Tyagi AK., 2021, Internet of Things and Cyber-Physical Systems, V1, P22, DOI DOI 10.1016/J.IOTCPS.2021.12.002
   Wang D, 2021, IEEE INTERNET THINGS, V8, P9294, DOI 10.1109/JIOT.2021.3057594
   Yuvaraj N, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/6644652
   Yuvaraj N, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107186
   Zhang GF, 2022, INT J INTERACT MULTI, V7, P66, DOI 10.9781/ijimai.2022.07.004
   Zhao YQ, 2018, IEEE ACCESS, V6, P12295, DOI 10.1109/ACCESS.2018.2799205
   Zhu XD, 2022, INT J INTERACT MULTI, V7, P59, DOI 10.9781/ijimai.2022.08.002
NR 31
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17576-z
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900008
DA 2024-07-18
ER

PT J
AU Sabaneh, K
   Sabha, M
AF Sabaneh, Kefaya
   Sabha, Muath
TI Improving SLIC superpixel by color difference-based region merging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image segmentation; Image processing; SLIC; Region merging; Superpixel
ID IMAGE SEGMENTATION
AB Superpixel-based segmentation has been widely used as a primary prepossessing step to simplify the subsequent image processing tasks. Since determining the number of clusters is subjective and varies based on the type of image, the segmentation algorithm may provide over-segmented or under-segmented superpixels. This paper proposes an image segmentation method to improve the SLIC superpixel by region merging. It aims to improve the segmentation accuracy without defining a precise number of superls. The color difference between superpixels is employed as a homogeneity criterion for the merging process. The Berkeley dataset is used with different quantitative performance metrics to evaluate the proposed model's performance. Results obtained from probabilistic rand index (PRI), boundary recall, and under-segmentation error proved the ability of the proposed algorithm to provide comparable segmentation with a reduced number of clusters.
C1 [Sabaneh, Kefaya; Sabha, Muath] Arab Amer Univ, Fac Engn & Informat Technol, Jenin, Palestine.
C3 Arab American University
RP Sabaneh, K (corresponding author), Arab Amer Univ, Fac Engn & Informat Technol, Jenin, Palestine.
EM kefaya.kmail@aaup.edu; muath.sabha@aaup.edu
RI Sabha, Muath/R-1282-2019
OI Sabha, Muath/0000-0002-0496-6502
CR Abdulateef S.K., 2021, Iraqi Journal for Electrical & Electronic Engineering, V17
   Achanta R., 2010, SLIC Superpixels
   Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alorf A, 2017, K-means, mean shift, and SLIC clustering algorithms: a comparison of performance in color-based skin segmentation
   Bano A., 2021, IOP Conference Series: Materials Science and Engineering, V1119, DOI 10.1088/1757-899X/1119/1/012017
   Bao H, 2023, COMPUT BIOL MED, V152, DOI 10.1016/j.compbiomed.2022.106439
   Basar S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240015
   Boemer F, 2018, NEUROCOMPUTING, V277, P228, DOI 10.1016/j.neucom.2017.05.096
   Calderero F, 2010, IEEE T IMAGE PROCESS, V19, P1567, DOI 10.1109/TIP.2010.2043008
   Chamalis T, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P381, DOI 10.1109/ICCAR.2017.7942722
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dhanachandra N, 2019, ADV INTELL SYST, V698, P603, DOI 10.1007/978-981-13-1819-1_57
   Di SH, 2021, OPT LASER TECHNOL, V135, DOI 10.1016/j.optiastec.2020.106703
   Dong RR, 2016, CHIN CONT DECIS CONF, P777, DOI 10.1109/CCDC.2016.7531090
   Fejjari A, 2022, INT ARAB J INF TECHN, V19, P949, DOI 10.34028/iajit/19/6/13
   Gómez D, 2015, KNOWL-BASED SYST, V87, P26, DOI 10.1016/j.knosys.2015.07.017
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Ibrahim A., 2020, J Comp Sci Inform Syst, V15, P1
   Javed R., 2019, BIOMED RES, V30, P1, DOI DOI 10.1016/J.MICRON.2018.09.015
   Khan AsadMohammed., 2013, Image segmentation methods: a comparative study
   Liu Z-M, 2018, Image segmentation algorithm based on slic and fast nearest neighbor region merging
   Manoharan S., 2020, Journal of Innovative Image Processing (JIIP), V2, P14
   Martin A, 2015, Graphic Des Print Prod Fundament, V95
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mittal H, 2022, MULTIMED TOOLS APPL, V81, P35001, DOI 10.1007/s11042-021-10594-9
   Prakash J, 2023, ARCH COMPUT METHOD E, V30, P3749, DOI 10.1007/s11831-023-09919-8
   Ramadan H, 2020, COMPUT VIS MEDIA, V6, P355, DOI 10.1007/s41095-020-0177-5
   Ran Siyuan, 2020, Journal of Physics: Conference Series, V1533, DOI 10.1088/1742-6596/1533/3/032067
   Sasmal B, 2023, Multimed Tools Appl, P1
   Shan PF, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0322-6
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Su TF, 2020, ISPRS J PHOTOGRAMM, V168, P89, DOI 10.1016/j.isprsjprs.2020.07.017
   Ullah S, 2021, MULTIMED TOOLS APPL, V80, P25649, DOI 10.1007/s11042-021-10900-5
   Wang H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9030031
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Warrens M.J., 2020, Advanced Studies in Classification and Data Science, P301
   Wu C, 2020, IEICE T INF SYST, VE103D, P2246, DOI 10.1587/transinf.2020EDL8025
   Yu ZD, 2010, PATTERN RECOGN, V43, P1889, DOI 10.1016/j.patcog.2009.11.015
   Zhang Q, 2015, P 7 INT C INT MULT C
NR 41
TC 0
Z9 0
U1 6
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17304-7
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500010
DA 2024-07-18
ER

PT J
AU Jani, Y
   Raajan, P
AF Jani, Y.
   Raajan, P.
TI An efficient framework for authentication and blockchain authorization
   of secured healthcare information using hpcsg- rotdf-slorb and dhsk-decc
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Healthcare systems; Internet of Things; Blockchain; Authentication;
   Authorization; And data security
AB In the present scenario, Information technology has emerged rapidly in various sectors. But, it has various barriers in securing the information during the process, storage, transmission, and retrieval. Past few decades, it has entered the doors of the medical field. Recently, the confidential information of the health care system oscillates with security and privacy. It is significant to secure the patients' data, which is engendered by several healthcare systems. For researchers, those data are of great value; in addition, could help in understanding phenomena and conquering particular challenges. Since this information refers to the patient's personal data, it must be treated as confidential. An adverse effect might be caused by the unauthorized disclosure of patients' personal information. Hence, by employing Hospital id Patient id Central or State Govt. id - ROT Digit Folding Shift Left OR - BLAKE (HPCSG- ROTDF-SLORB) and Diffie Hellman Secret Key - Double Elliptic Curve Cryptography (DHSK-DECC), an efficient Cipher Hashing-based user authentication and Secure Data Transfer along with Block Chain-based (BC) User Verification are proposed for surpassing those issues. For generating strong credentials for authentication, the HPCSG-ROTDF is wielded. For converting the cipher text into hash code, SLOR-BLAKE is deployed. By employing DHSK-DECC, the data is encrypted and decrypted for enhancing data security. Regarding several metrics, the performances of the proposed system were analyzed. As per the outcomes, the proposed system exhibited enhanced performance when analogized to the prevailing methodologies.
C1 [Jani, Y.; Raajan, P.] Manonmaniam Sundaranar Univ, Muslim Arts Coll, PG & Res Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Jani, Y (corresponding author), Manonmaniam Sundaranar Univ, Muslim Arts Coll, PG & Res Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM janijaanu05@gmail.com
CR Abdullah Al Omar, 2018, Futur Gener Comput Syst, V95, P511, DOI [10.1016/j.future.2018.12.044, DOI 10.1016/J.FUTURE.2018.12.044]
   Arul Rajakumar, 2024, Personal and Ubiquitous Computing, V28, P3, DOI 10.1007/s00779-021-01527-2
   Aujla GS, 2021, IEEE J SEL AREA COMM, V39, P491, DOI 10.1109/JSAC.2020.3020655
   Besher KM, 2021, IEEE SENS J, V21, P11977, DOI 10.1109/JSEN.2020.3013634
   Bhattacharya P, 2021, IEEE T NETW SCI ENG, V8, P1242, DOI 10.1109/TNSE.2019.2961932
   Cheng X, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1468-1
   Chenthara S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243043
   El-Zouka HA., 2019, Internet Things, V13, P1
   Ismail L, 2019, IEEE ACCESS, V7, P149935, DOI 10.1109/ACCESS.2019.2947613
   Kumar R, 2021, J AMB INTEL HUM COMP, V12, P2321, DOI 10.1007/s12652-020-02346-8
   M HEALTH Dataset, 2014, The MHEALTH (Mobile Health) dataset is devised to benchmark techniques dealing with human behavior analysis based on multimodal body sensing
   MuruganA TusharChechare., 2020, International Journal of Electrical and Computer Engineering, V10, P421
   Quasim MT, 2020, INT C COMP PERF EV C, P2
   Rajawat Anand Singh, 2021, Blockchain-based model for expanding IoT device data security
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Renuka K, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1251-3
   Shahnaz A, 2019, IEEE ACCESS, V7, P147782, DOI 10.1109/ACCESS.2019.2946373
   Sharma G, 2019, IJST-T ELECTR ENG, V43, P619, DOI 10.1007/s40998-018-0146-5
   Shen BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061207
   Srivastava G., 2019, IEEE CAN C EL COMP E
   Sun Y, 2022, IEEE T IND INFORM, V18, P1981, DOI 10.1109/TII.2021.3070544
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Ullah A, 2020, PEER PEER NETW APPL, V13, P163, DOI 10.1007/s12083-019-00745-z
   Wang JC, 2020, FUTURE GENER COMP SY, V110, P675, DOI 10.1016/j.future.2019.09.049
   Xu J., 2018, Futur Gener Comput Syst, V108, P1, DOI [10.1016/j.future.2020.02.042, DOI 10.1016/J.FUTURE.2020.02.042]
   Zhuang Y, 2020, IEEE J BIOMED HEALTH, V24, P2169, DOI 10.1109/JBHI.2020.2993072
NR 26
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17362-x
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000002
DA 2024-07-18
ER

PT J
AU Archana, MR
   Biradar, DN
   Dayanand, J
AF Archana, M. R.
   Biradar, Deepak N.
   Dayanand, J.
TI Image forgery detection in forensic science using optimization based
   deep learning models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image forgery detection; Keypoints; Features; Deep learning; Optimal
   classification
AB Image forgery detection has become a hot research topic in security and forensics applications. Keypoints (KPs) based image forgery detection extracts image KPs and utilizes local visual features for identifying forgery regions which shows excellent performance on the basis of memory and robustness over attacks. But, these methods are lacking in handling the cases when forgeries in small regions, in which KPs are limited. To address these challenges, this work introduces a fast and efficient forgery detection using the processes like pre-processing, feature extraction and optimal classification. Initially, the RGB image is converted into L*a*b color space. Then, the KPs are determined using the Eigenvalue Asymmetry (EAS) and after determining the KPs, the texture features like Haralick and skewness are extracted. Then, these features are classified by the deep learning (DL) classifier Deep belief network (DBN) with an adaptive crow search algorithm (ACSA). The proposed DBN-ACSA classifier categorizes the detected image as a normal or forgery image. The experimental results are carried out on the Vision, UCID and CoMoFoD datasets and achieved accuracy, precision, F1 score, recall and ROC values.
C1 [Archana, M. R.; Biradar, Deepak N.] GITAM Univ, Dept CSE, Hyderabad, India.
   [Dayanand, J.] Guru Nanak Dev Engn Coll, Dept CSE, Bidar, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Archana, MR (corresponding author), GITAM Univ, Dept CSE, Hyderabad, India.
EM archana17phd@gmail.com; deepak.n.biradar@gmail.com; jdayanand1@gmail.com
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Al azrak FM, 2020, WIRELESS PERS COMMUN, V110, P503, DOI 10.1007/s11277-019-06739-7
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Dhivya S, 2020, SOFT COMPUT, V24, P14429, DOI 10.1007/s00500-020-04795-x
   Diallo B., 2020, Forensic Sci Int Rep, V2, P100, DOI DOI 10.1016/J.FSIR.2020.100112
   Dua Shilpa, 2020, Procedia Computer Science, V171, P369, DOI 10.1016/j.procs.2020.04.038
   Dua S, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2020.115778
   Elaskily MA, 2023, MULTIMED TOOLS APPL, V82, P34409, DOI 10.1007/s11042-023-14424-y
   Galvan F., 2020, Eur Police Sci Res Bull, V20, P105
   Gupta R, 2022, Multimed Tools Appl, P1
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lyu QY, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103057
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Mei F, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6688393
   Muzaffer G, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P595, DOI 10.1109/TSP.2017.8076056
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Ojeniyi J. A., 2018, HYBRIDIZED TECHNIQUE
   Park JY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040492
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shahroudnejad A, 2016, P ICSPIS TEHR IR, P1
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Tahaoglu G, 2022, MULTIMED TOOLS APPL, V81, P22867, DOI 10.1007/s11042-021-11503-w
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang CY, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10120706
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Zhang Z, 2018, J INF PROCESS SYST, V14, P6
   Zhou GS, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0450-5
NR 32
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17316-3
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100005
DA 2024-07-18
ER

PT J
AU Farokhian, M
   Rafe, V
   Veisi, H
AF Farokhian, Mahmood
   Rafe, Vahid
   Veisi, Hadi
TI Fake news detection using dual BERT deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fake news detection; Transfer learning; Transformers; BERT; MWPBert;
   MaxWorth
ID FALSE NEWS
AB Fake news is a growing challenge for social networks and media. Detection of fake news always has been a problem for many years, but the evolution of social networks and increasing speed of news dissemination in recent years has been considered again. There are several approaches to solving this problem, one of which is to detect fake news based on its text style using deep neural networks. In recent years, transfer learning with transformers is one of the most used forms of deep neural networks for natural language processing. BERT is one of the most promising transformers that outperforms other models in many NLP benchmarks. In this article, we introduce MWPBert, which uses two parallel BERT networks to perform veracity detection on full-text news articles. One of the BERT networks encodes news headline, and another encodes news bodies. Since the input length of the BERT network is limited and constant and the news body is usually a long text, we cannot feed the whole text into the BERT. Therefore, using the MaxWorth algorithm, we selected the part of the news text that is more valuable for fact-checking, and fed it into the BERT network. Finally, we encode the output of the two BERT networks to an output network to classify the news. The experiment results showed that the proposed model outperformed previous models regarding accuracy and other performance measures.
C1 [Farokhian, Mahmood; Rafe, Vahid] Arak Univ, Dept Comp Engn, Arak, Iran.
   [Veisi, Hadi] Univ Tehran, Dept New Sci & Technol, Tehran, Iran.
C3 Arak University; University of Tehran
RP Farokhian, M (corresponding author), Arak Univ, Dept Comp Engn, Arak, Iran.
EM farokhian@gmail.com; v-rafe@araku.ac.ir; h.veisi@ut.ac.ir
CR Abouelenien M, 2017, P S APPL COMPUTING, VF1280, P137, DOI [DOI 10.1145/3019612.3019644, 10.1145/3019612.3019644]
   Albawi S, 2017, I C ENG TECHNOL
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bordes A., 2013, P 26 INT C NEURAL IN, P2787
   Dagan Ido, 2010, Natural Language Engineering, V16, pi, DOI 10.1017/S1351324909990209
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hassan N, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1803, DOI 10.1145/3097983.3098131
   Kaliyar RK, 2021, MULTIMED TOOLS APPL, V80, P11765, DOI 10.1007/s11042-020-10183-2
   Karimi H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3432
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Kwon S, 2013, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2013.61
   Li LY, 2017, NEUROCOMPUTING, V254, P33, DOI 10.1016/j.neucom.2016.10.080
   Long Q., 2017, P INT JOINT C NAT LA, P252
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Bronstein MM, 2017, Arxiv, DOI arXiv:1611.08097
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Monti F, 2019, Arxiv, DOI arXiv:1902.06673
   Ott M., 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293
   Palani B, 2022, MULTIMED TOOLS APPL, V81, P5587, DOI 10.1007/s11042-021-11782-3
   Pan JZ, 2018, LECT NOTES COMPUT SC, V11136, P669, DOI 10.1007/978-3-030-00671-6_39
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Pierri F, 2019, SIGMOD REC, V48, P18, DOI 10.1145/3377330.3377334
   Rajpurkar P., 2016, P 2016 C EMP METH NA, V2016, P2383
   Roy A, 2019, P 16 INT C NATURAL L
   Sadeghi F, 2022, MULTIMED TOOLS APPL, V81, P33801, DOI 10.1007/s11042-022-12428-8
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Thorne J., 2018, P 27 INT C COMP LING, P3346
   Thota A, 2018, SMU Data Sci Rev, V1
   Vaswani A, 2017, ADV NEUR IN, V30
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Wang B, 2023, APPL INTELL, V53, P10429, DOI 10.1007/s10489-022-04055-5
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Williams A., 2018, P 2018 C N AM CHAPTE, P1112
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu K, 2015, PROC INT CONF DATA, P651, DOI 10.1109/ICDE.2015.7113322
   Zhou X, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P983, DOI 10.1145/2740908.2742571
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
NR 44
TC 2
Z9 2
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17115-w
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400022
DA 2024-07-18
ER

PT J
AU Magalhaes, M
   Coelho, A
   Melo, M
   Bessa, M
AF Magalhaes, Mariana
   Coelho, Antonio
   Melo, Miguel
   Bessa, Maximino
TI Measuring users' emotional responses in multisensory virtual reality: a
   systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Emotions in human-computer interaction; Evaluation/methodology;
   Multimodal systems; Multisensory stimulation; Systematic literature
   review; Virtual reality
ID ENVIRONMENTS; VALIDATION; CHALLENGES; REACTIVITY; BEHAVIOR; MEMORY;
   GAMES
AB Virtual reality and emotions have become inseparable concepts over the past few years, supported by the increasing number of studies relating them. However, these studies' methodologies are often poorly justified or dependent on the authors' subjective definition of emotion and its classification. Moreover, frequently, these studies only consider two stimuli, specifically audiovisual, despite being known the relevance of including a greater variety of sensory channels to improve the relationship between the individual and the virtual environment. So, to address these gaps, and considering the importance of multisensory stimulation, this paper aims to review the methods and instruments found in the literature regarding the analysis of the users' emotions in virtual reality. Also, we provide an overview of the main limitations of such studies. Little information can be found in the literature regarding the connection between the input stimulus and the users' emotional responses. This corroborates the difficulty in creating and evaluating immersive virtual experiences when stimulating more than two human senses, typically audiovisual. Nevertheless, we address some clues on the impact of visual, auditory, haptic, smell, and taste elements to trigger specific emotions. Also, we address the association between the research area and the method used. Finally, the main gaps and challenges are discussed. We expect that the combination of these results acts as guidelines for designing richer multisensory virtual experiences. Moreover, we intend to contribute to future research on emotions-based immersive virtual reality by providing a review of the most suitable methodologies and instruments for specific contexts.
C1 [Magalhaes, Mariana; Coelho, Antonio] Univ Porto, Dept Informat Engn, INESC TEC, Fac Engn, Porto, Portugal.
   [Melo, Miguel] INESC TEC, Ctr Informat Syst & Comp Graph, Porto, Portugal.
   [Bessa, Maximino] Univ Tras Os Montes & Alto Douro, Dept Informat Engn, INESC TEC, Vila Real, Portugal.
C3 Universidade do Porto; INESC TEC; INESC TEC; University of
   Tras-os-Montes & Alto Douro; INESC TEC
RP Magalhaes, M (corresponding author), Univ Porto, Dept Informat Engn, INESC TEC, Fac Engn, Porto, Portugal.
EM mariana.o.magalhaes@inesctec.pt
RI Magalhães, Mariana/JTV-4045-2023; Coelho, Antonio/G-2216-2011
OI Magalhães, Mariana/0000-0003-2162-742X; Melo,
   Miguel/0000-0003-4050-3473; Bessa, Maximino/0000-0002-3002-704X; Coelho,
   Antonio/0000-0001-7949-2877
FU FCT|FCCN (b-on); ERDF - European Regional Development Fund through the
   Operational Programme for Competitiveness and Internationalisation -
   COMPETE 2020 Programme; Portuguese funding agency, FCT - Fundacao para a
   Ciencia e a Tecnologia [PD/BD/150491/2019]; Portuguese Foundation for
   Science and Technology (FCT);  [POCI-01-0145-FEDER-030740]
FX This work is financed by the ERDF - European Regional Development Fund
   through the Operational Programme for Competitiveness and
   Internationalisation - COMPETE 2020 Programme and by National Funds
   through the Portuguese funding agency, FCT - Fundacao para a Ciencia e a
   Tecnologia within project POCI-01-0145-FEDER-030740. The work of Mariana
   Magalhaes was also supported by the Portuguese Foundation for Science
   and Technology (FCT) under Doctoral Grant PD/BD/150491/2019.Open access
   funding provided by FCT|FCCN (b-on).
CR [Anonymous], 2023, General Information and content coverage
   Archer NS, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0265039
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Bazeley P, 2012, AM BEHAV SCI, V56, P814, DOI 10.1177/0002764211426330
   Bindman SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174031
   Bockelman P, 2017, CCIS, P3, DOI DOI 10.1007/978-3-319-58753-0_1
   Botella C, 1999, Cyberpsychol Behav, V2, P49, DOI 10.1089/cpb.1999.2.49
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brengman M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.747456
   Brivio E, 2021, VIRTUAL REAL-LONDON, V25, P303, DOI 10.1007/s10055-020-00453-7
   Brooks J, 2021, 2021 CHI C HUM FACT, P1
   Brooks J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376806
   Cabanac M, 2002, BEHAV PROCESS, V60, P69, DOI 10.1016/S0376-6357(02)00078-5
   Calvo RA, 2013, COMPUT INTELL-US, V29, P527, DOI 10.1111/j.1467-8640.2012.00456.x
   Chen H., 2017, Proceedings of the 29th Australian conference on computer-human interaction, P108, DOI [10.1145/3152771.3152783, DOI 10.1145/3152771.3152783]
   Cheok AD, 2018, HUM-COMPUT INT-SPRIN, P49, DOI 10.1007/978-3-319-73864-2_4
   Chin K, 2021, HUCAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 2: HUCAPP, P128, DOI 10.5220/0010195601280134
   Chirico A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-01242-0
   Colla K, 2023, FOOD QUAL PREFER, V103, DOI 10.1016/j.foodqual.2022.104717
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Cornelio P, 2022, INT J GASTRON FOOD S, V30, DOI 10.1016/j.ijgfs.2022.100626
   Costello P.J., 1997, HLTH SAFETY ISSUES A
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Dey A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P101, DOI 10.1145/3242671.3242676
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elmqaddem N, 2019, INT J EMERG TECHNOL, V14, P234, DOI 10.3991/ijet.v14i03.9289
   Feick M., 2020, ADJUNCT P ANN ACM S, P68, DOI [DOI 10.1145/3379350.3416188, 10.1145/3379350.3416188]
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Ferreira H., 2019, Emotional Design in Human-Robot Interaction, V1st, P143
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gomes W.B., 1997, Psicologia USP, V8, P305, DOI [10.1590/S0103-65641997000200015, DOI 10.1590/S0103-65641997000200015]
   Gonçalves G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533377
   GOODMAN LA, 1954, J AM STAT ASSOC, V49, P732, DOI 10.2307/2281536
   Gusenbauer M, 2020, RES SYNTH METHODS, V11, P181, DOI 10.1002/jrsm.1378
   GUTIERREZ D., 2008, SIMP METROL, P1
   Haraguchi G, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P773, DOI 10.1109/VRW55335.2022.00242
   Hayes M., 1921, Psychological Bulletin, V18, P98, DOI [DOI 10.1037/H0064147, DOI 10.4236/OJPSYCH.2014.41010]
   Hoppu U, 2020, FOODS, V9, DOI 10.3390/foods9101349
   Hosany S, 2021, J TRAVEL RES, V60, P1391, DOI 10.1177/0047287520937079
   Hoyer WD, 2020, J INTERACT MARK, V51, P57, DOI 10.1016/j.intmar.2020.04.001
   Hulsmann F, 2014, P 2014 VIRT REAL INT, P1
   IJsselsteijn WA., 2004, Presence in depth, P2004
   Johnson R. B., 2004, ED RES, V33, P14, DOI DOI 10.3102/0013189X033007014
   Junker A, 2020, P 11 NORD C HUM COMP, P1
   Kaminska D, 2020, IEEE ACCESS, V8, P200351, DOI 10.1109/ACCESS.2020.3035540
   Kampa M, 2022, TRIALS, V23, DOI 10.1186/s13063-022-06307-8
   Kang J, 2018, I C INF COMM TECH CO, P546, DOI 10.1109/ICTC.2018.8539405
   Karafotias G, 2018, IEEE T HAPTICS, V11, P185, DOI 10.1109/TOH.2017.2781693
   KENEALY PM, 1986, MOTIV EMOTION, V10, P315, DOI 10.1007/BF00992107
   Kim A, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364703
   Kong YZ, 2020, FOODS, V9, DOI 10.3390/foods9040515
   Kono M, 2018, P 24 ACM S VIRT REAL, P1
   Kruijff E, 2015, 7 INT C GAM VIRT WOR, V2015, P1
   Kruijff E, 2017, VISUAL COMPUT, V33, P471, DOI 10.1007/s00371-016-1294-0
   Li RC, 2021, P 2021 ACM S SPAT US, P1
   Macefield R, 2009, J USABILITY STUD, V5, P34
   Maggioni E, 2019, INT J HUM-COMPUT ST, V130, P248, DOI 10.1016/j.ijhcs.2019.06.014
   Mania K, 2001, CYBERPSYCHOL BEHAV, V4, P247, DOI 10.1089/109493101300117938
   Marcolin F, 2021, IEEE COMPUT GRAPH, V41, P171, DOI 10.1109/MCG.2021.3115015
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Masood N, 2018, LECT NOTES COMPUT SC, V10901, P419, DOI 10.1007/978-3-319-91238-7_34
   Meiselman HL, 2017, FOOD QUAL PREFER, V62, P374, DOI 10.1016/j.foodqual.2017.05.011
   Melo M, 2022, MULTIMEDIA SYST, V28, P1027, DOI 10.1007/s00530-022-00898-7
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Meyners M, 2013, FOOD QUAL PREFER, V30, P309, DOI 10.1016/j.foodqual.2013.06.010
   Mi Feng, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P149, DOI 10.1109/3DUI.2015.7131744
   Mishra A, 2021, PSYCHOL MARKET, V38, P385, DOI [10.1002/mar.21436, 10.1016/j.procir.2020.04.049]
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Munyan BG, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157568
   Narumi T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P93
   Nichols AL, 2008, J GEN PSYCHOL, V135, P151, DOI 10.3200/GENP.135.2.151-166
   Nilsson NC, 2021, IEEE COMPUT GRAPH, V41, P104, DOI 10.1109/MCG.2021.3097671
   Nivedhan A, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P301, DOI 10.1145/3395035.3425646
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   Patrono L., 2019, J Commun Softw Syst, V15, P1
   Peiris RL, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300400
   Prescott J, 2017, FOOD QUAL PREFER, V62, P360, DOI 10.1016/j.foodqual.2017.04.005
   Raheel A, 2021, INFORM FUSION, V65, P37, DOI 10.1016/j.inffus.2020.08.007
   Ranasinghe N., 2013, Proceedings of the 2013 ACM International Workshop on Immersive Media Experiences, P29, DOI DOI 10.1145/2512142.2512148
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Safikhani S, 2021, P 27 ACM S VIRT REAL, P1
   Saladin ME, 2006, ADDICT BEHAV, V31, P1881, DOI 10.1016/j.addbeh.2006.01.004
   Salgado DP, 2022, P 13 ACM MULT SYST C, P1
   Samara A, 2019, J AMB INTEL HUM COMP, V10, P2175, DOI 10.1007/s12652-017-0636-8
   Schweizer T, 2018, J ANXIETY DISORD, V59, P42, DOI 10.1016/j.janxdis.2018.08.005
   Schweizer T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190360
   Schwind V, 2019, Paper 360, P1
   Sinesio F, 2019, FOOD QUAL PREFER, V77, P123, DOI 10.1016/j.foodqual.2019.05.004
   Singhal Y, 2021, P 27 ACM S VIRT REAL, P1
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spezi V, 2018, J DOC, V74, P137, DOI 10.1108/JD-06-2017-0092
   Spielberger CD, 1970, MANUAL STATE TRAIT A
   Steinhaeusser Sophia C., 2020, CHI PLAY '20: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, P80, DOI 10.1145/3383668.3419924
   Steinhaeusser SC., 2023, Entertain Comput, V539, P1
   Tamaki R, 2021, P 2021 ACM S SPAT US, P1
   Tamtama GIW, 2022, 2022 7 INT C INF COM, P1
   Torrico DD, 2020, FOODS, V9, DOI 10.3390/foods9020191
   Valzolgher C, 2018, ACTA PSYCHOL, V191, P261, DOI 10.1016/j.actpsy.2018.09.009
   van der Waal NE, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.989676
   van Veelen N., 2022, Front Virtual Reality, V2, P1
   van't Wout M, 2017, APPL PSYCHOPHYS BIOF, V42, P209, DOI 10.1007/s10484-017-9366-0
   Verschuere B, 2001, PSYCHOL BELG, V41, P205
   Wang G., 2021, LECT NOTES COMPUTER, V12776, P97, DOI [10.1007/978-3-030-78114-9_8, DOI 10.1007/978-3-030-78114-9_8, 10.1007/978-3-030-78114-9]
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wee C, 2021, IEEE ACCESS, V9, P112145, DOI 10.1109/ACCESS.2021.3103598
   Williamson K, 2018, RESEARCH METHODS: INFORMATION, SYSTEMS, AND CONTEXTS, 2ND EDITION, P379, DOI 10.1016/B978-0-08-102220-7.00016-9
   Wilson G, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P535, DOI 10.1145/3242671.3242684
   Worch T, 2020, FOOD QUAL PREFER, V83, DOI 10.1016/j.foodqual.2020.103895
   Wu D., 2016, ELECT IMAGING, V28, P1, DOI [10.2352/ISSN.2470-1173.2016.4.ERVR-419, DOI 10.2352/ISSN.2470-1173.2016.4.ERVR-419]
   Yanagida Y, 2003, INT C COMP GRAPH INT, P1
NR 114
TC 3
Z9 3
U1 9
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-16918-1
EA OCT 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Mishra, AD
   Mustafa, K
AF Mishra, Aditya Dev
   Mustafa, Khurram
TI Security requirements specification by formal methods: a research
   metadata analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security requirement specification; Formal specification; Security
   requirement engineering; Formal framework; Metadata
ID FORMALIZATION; VERIFICATION; FRAMEWORK; LANGUAGE; PATTERNS; TRUST
AB In recent years, the field of security requirements specification by formal methods has changed radically. The security requirement specification is now one of the widely recognized as well as actively pursued research challenges in both requirement engineering and security engineering communities. In this paper, we focus on the research metadata to find the state of the art in the field of security requirements specification using the formal approach. In order, a review was taken up to perform metadata, obtained from frequently used databases. In total, 200 publications were retrieved; out of which 110 were found to be relevant to our research questions. The results of metadata provided an insight into the main contributions of the field, research gaps, and challenges, which motivated the discussion for important research direction in the future.
C1 [Mishra, Aditya Dev] Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, India.
   [Mustafa, Khurram] Jamia Millia Islamia, Dept Comp Sci, New Delhi, India.
C3 Galgotias College of Engineering & Technology (GCET); Jamia Millia
   Islamia
RP Mishra, AD (corresponding author), Galgotias Coll Engn & Technol, Dept Comp Sci & Engn, Greater Noida, India.
EM aditya2aug@gmail.com
OI Mishra, Aditya Dev/0000-0002-7060-2600
CR Abrial JR, 2007, J UNIVERS COMPUT SCI, V13, P619
   Affleck A, 2015, COMPUT J, V58, P1122, DOI 10.1093/comjnl/bxu027
   Agudo I, 2004, COMPSYSTECH, P1
   Amrani M., 2012, 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation (ICST 2012), P921, DOI 10.1109/ICST.2012.197
   Anand Abhishek, 2014, Interactive Theorem Proving. 5th International Conference, ITP 2014, Held as Part of the Vienna Summer of Logic, VSL 2014. Proceedings: LNCS 8558, P27, DOI 10.1007/978-3-319-08970-6_3
   [Anonymous], 2000, Proceedings of the Conference on the Future of Software Engineering, DOI [10.1145/336512.336546, DOI 10.1145/336512.336546]
   Armstrong RC, 2014, Sandia Report SAND2014-20533, DOI [10.2172/1166644, DOI 10.2172/1166644]
   Asif M, 2019, IEEE ACCESS, V7, P36164, DOI 10.1109/ACCESS.2019.2903133
   Avigad J, 2014, COMMUN ACM, V57, P66, DOI 10.1145/2591012
   Baier C, 2008, PRINCIPLES OF MODEL CHECKING, P1
   Barthe G, 2005, LECT NOTES COMPUT SC, V3655, P133
   Biondi F, 2016, LECT NOTES COMPUT SC, V9952, P883, DOI 10.1007/978-3-319-47166-2_61
   Blazy S, 2006, LECT NOTES COMPUT SC, V4085, P460
   Boldo S, 2016, MATH STRUCT COMP SCI, V26, P1196, DOI 10.1017/S0960129514000437
   Breaux TD, 2014, REQUIR ENG, V19, P281, DOI 10.1007/s00766-013-0190-7
   Briffaut J., 2009, Int J Adv Secur, V2, P325
   Bugliesi M, 2017, J LOG ALGEBR METHODS, V87, P110, DOI 10.1016/j.jlamp.2016.08.006
   Butin DF, 2012, Inductive analysis of security protocols in Isabelle/HOL with applications to electronic voting
   Cerone A, 2008, INNOV SYST SOFTW ENG, V4, P123, DOI 10.1007/s11334-008-0051-6
   Cheney J, 2011, 2011 IEEE 24TH COMPUTER SECURITY FOUNDATIONS SYMPOSIUM (CSF), P281, DOI 10.1109/CSF.2011.26
   Chiang CC, 2004, P 2 ANN C MIDSOUTH C, P39
   Chong SP, 2016, Arxiv, DOI arXiv:1608.00678
   Clarkson MichaelRyan., 2010, QUANTIFICATION FORMA
   Dahl M, 2022, CIRP J MANUF SCI TEC, V38, P129, DOI 10.1016/j.cirpj.2022.04.013
   De Landtsheer R., 2005, Proceedings 10th European Software Engineering Conference/13th ACM SIGSOFT International Symposium on Foundations of Software Engineering (ESEC/SIGSOFT FSE), P41, DOI DOI 10.1145/1081706.1081715
   Demirel ST, 2018, 2018 6TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSIC AND SECURITY (ISDFS), P44
   Demolombe R, 2004, LECT NOTES COMPUT SC, V2995, P291
   Dunne P., 2013, RES J APPL SCI ENG T, V5, P4664, DOI 10.19026/rjaset.5.4298
   El-Hadary H, 2014, J ADV RES, V5, P463, DOI 10.1016/j.jare.2014.03.001
   Emeka BO, 2018, 2018 INT C ELECT INF, P1, DOI [10.23919/ELINFOCOM.2018.8330613, DOI 10.23919/ELINFOCOM.2018.8330613]
   Emeka BO, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS), P176, DOI 10.1109/QRS.2017.28
   Fabian B, 2010, REQUIR ENG, V15, P7, DOI 10.1007/s00766-009-0092-x
   Firesmith Donald., 2003, J OBJECT TECHNOL, V2, P53
   Fuchs A., 2011, J Inf Process, V19, P274, DOI [10.2197/ipsjjip.19.274, DOI 10.2197/IPSJJIP.19.274]
   Fuchs A, 2010, IFIP ADV INF COMM TE, V321, P200
   Gerber M., 2001, Information Management & Computer Security, V9, P32, DOI 10.1108/09685220110366768
   Giorgini P, 2005, 13TH IEEE INTERNATIONAL CONFERENCE ON REQUIREMENTS ENGINEERING, PROCEEDINGS, P167, DOI 10.1109/RE.2005.43
   Goertzel KM, 2007, Software security assurance: A State-of-Art Report (SAR), DOI [10.21236/ADA472363, DOI 10.21236/ADA472363]
   Gruner S, 2010, INNOV SYST SOFTW ENG, V6, P135, DOI 10.1007/s11334-009-0101-8
   Gürgens S, 2005, COMPUT STAND INTER, V27, P457, DOI 10.1016/j.csi.2005.01.004
   Hadavi MA, 2008, LECT NOTES ENG COMP, P985
   Haley C.B., 2006, SESS 06, P35, DOI DOI 10.1145/1137627.1137634
   Haley CB, 2008, IEEE T SOFTWARE ENG, V34, P133, DOI 10.1109/TSE.2007.70754
   Haley CharlesB., 2004, PROC AOSD 04, P112, DOI [10.1145/976270.976285, DOI 10.1145/976270.976285]
   Hamid B, 2016, INNOV SYST SOFTW ENG, V12, P109, DOI 10.1007/s11334-015-0259-1
   Hamid B., 2014, Int Symp Eng, DOI [10.1007/978-3-319-04897-0_7, DOI 10.1007/978-3-319-04897-0_7]
   Harbach MR, 2011, Doctoral dissertation
   Hassan R, 2008, P 4 ANN WORKSHOP CYB, P10, DOI [10.1145/1413140.1413152, DOI 10.1145/1413140.1413152]
   Heitmeyer C, 2001, LECT NOTES COMPUT SC, V2052, P84
   Heitmeyer CL, 2009, ELECTRON NOTES THEOR, V238, P3, DOI 10.1016/j.entcs.2009.09.001
   Hinchey M, 2008, COMMUN ACM, V51, P54, DOI 10.1145/1378727.1378742
   Howard G, 2017, 2017 2ND IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW), P174, DOI 10.1109/EuroSPW.2017.68
   Islam G, 2012, A framework for security requirements elicitation
   Jain S, 2011, Int J Adv Comput Sci Appl (IJACSA), V2
   Jang SJ, 2006, INT J COMPUT SCI NET, V6, P163
   Jindal R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2027, DOI 10.1109/ICACCI.2016.7732349
   Josang A, 2007, DECIS SUPPORT SYST, V43, P618, DOI 10.1016/j.dss.2005.05.019
   Klein G, 2014, NATO SCI PEAC SECUR, V36, P77, DOI 10.3233/978-1-61499-385-8-77
   Kozachok Aleksandr, 2017, [Вопросы кибербезопасности, Voprosy Kiberbezopasnosti, Voprosy kiberbezopasnosti], P2, DOI 10.21581/2311-3456-2017-2-2-7
   Li GD, 2011, SCI COMPUT PROGRAM, V76, P65, DOI 10.1016/j.scico.2010.03.007
   Li HB, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS), P352, DOI 10.1109/QRS.2017.45
   Liu SY, 2021, J SYST SOFTWARE, V178, DOI 10.1016/j.jss.2021.110948
   Lúcio L, 2014, ADV COMPUT, V93, P103, DOI 10.1016/B978-0-12-800162-2.00003-8
   Maña A, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P80, DOI 10.1109/ARES.2008.202
   Matoussi A, 2008, LACL
   Mellado D, 2010, COMPUT STAND INTER, V32, P153, DOI 10.1016/j.csi.2010.01.006
   Menzel M, 2009, ISSE 2009 SECURING E, P145, DOI [10.1007/978-3-8348-9363-5_14, DOI 10.1007/978-3-8348-9363-5_14]
   Michael JB, 2020, COMPUTER, V53, P81, DOI 10.1109/MC.2020.2978567
   Mishra Aditya Dev, 2021, 2021 3rd International Conference on Advances in Computing, Communication Control and Networking (ICAC3N), P1453, DOI 10.1109/ICAC3N53548.2021.9725779
   Mishra AD., 2022, J Sci Res, V66, P108, DOI [10.37398/JSR.2022.660214, DOI 10.37398/JSR.2022.660214]
   Mishra AD, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6702
   Mokos K., 2020, Array, V7, DOI [10.1016/j.array.2020.100030, DOI 10.1016/J.ARRAY.2020.100030]
   Morimoto S, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1506, DOI 10.1145/1244002.1244325
   Motii A, 2015, PROCEEDINGS OF THE 20TH EUROPEAN CONFERENCE ON PATTERN LANGUAGES OF PROGRAMS (EUROPLOP 2015), DOI 10.1145/2855321.2855332
   Mousavi H, 2023, ACM TRANS CYBER-PHYS, V7, DOI 10.1145/3605948
   Muñante D, 2014, LECT NOTES COMPUT SC, V8708, P79, DOI 10.1007/978-3-319-10975-6_6
   Mustafa N, 2021, J TheorAppl Inf Technol, V99, P1
   Nawaz MS, 2018, SEKE, P391, DOI [10.18293/SEKE2018-024, DOI 10.18293/SEKE2018-024]
   Older S, 2002, COMPUT J, V45, P46, DOI 10.1093/comjnl/45.1.46
   Parnas DL, 2010, COMPUTER, V43, P28, DOI 10.1109/MC.2010.22
   Pironti A, 2012, Cyber Security Standards, Practices and Industrial Applications: Systems and Methodologies, P138, DOI [10.4018/978-1-60960-851-4.ch008, DOI 10.4018/978-1-60960-851-4.CH008]
   Ramesh MR., 2016, INT J APPL ENG RES, V11, P64
   Rêgo YS, 2013, J FORMALIZ REASON, V6, P31
   Rivera Joey, 2017, 2017 International Conference on Cyber-Conflict (CyCon U.S.), P76, DOI 10.1109/CYCONUS.2017.8167500
   Rodano M, 2013, PROCEDIA COMPUT SCI, V20, P210, DOI 10.1016/j.procs.2013.09.263
   Rouland Q, 2019, IEEE INT C ENG COMP, P236, DOI 10.1109/ICECCS.2019.00033
   Rushby J, 2001, S REQUIR ENG INF SEC, V441
   Saâdaoui A, 2014, INT CONF RES CHAL
   Nawaz MS, 2019, Arxiv, DOI [arXiv:1912.03028, 10.48550/arXiv.1912.03028, DOI 10.48550/ARXIV.1912.03028]
   Saranya R., 2014, Int J Comput Appl, V90, P12
   Sassaman L, 2013, IEEE SYST J, V7, P489, DOI 10.1109/JSYST.2012.2222000
   Schaffer K, 2016, COMPUTER, V49, P70, DOI 10.1109/MC.2016.228
   Sengupta Anirban, 2009, 2009 Fourth International Conference on Risks and Security of Internet and Systems (CRiSIS 2009), P74, DOI 10.1109/CRISIS.2009.5411976
   Shaoying Liu, 2009, SIGCSE Bulletin, V41, P17, DOI 10.1145/1595453.1595457
   Sodiya AS, 2006, Issues Informing Sci Information Technol, V3
   Staffs Keele, 2007, Tech. Rep.
   Subburaj VH, 2016, Intelligent Agents in Data-intensive Computing, P99, DOI [10.1007/978-3-319-23742-8_5, DOI 10.1007/978-3-319-23742-8_5]
   Subburaj VH, 2018, FED CONF COMPUT SCI, P707, DOI 10.15439/2018F262
   Tolmach P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3464421
   Tschantz MC, 2009, LECT NOTES COMPUT SC, V5850, P1, DOI 10.1007/978-3-642-05089-3_1
   Valenza F., 2017, J. Wirel. Mob. Networks Ubiquitous Comput. Dependable Appl, V8, P79
   van Lamsweerde A, 2004, PROC INT CONF SOFTW, P148, DOI 10.1109/ICSE.2004.1317437
   Viega J., 2005, SESS 05, P1, DOI DOI 10.1145/1082983.1083207
   Wang CL, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 1, PROCEEDINGS, P615, DOI 10.1109/NSWCTC.2009.104
   Weiss M, 2008, INT REQUIR ENG CONF, P169, DOI 10.1109/RE.2008.32
   Weldemariam K, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P164, DOI 10.1109/ARES.2010.83
   Woodcock J, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1592434.1592436
   Zhao Y, 2014, SCI COMPUT PROGRAM, V96, P337, DOI 10.1016/j.scico.2014.04.002
   Zhioua Z., 2018, Adv Sci, Technol Eng Syst J, V3, P38, DOI [10.25046/aj030106, DOI 10.25046/AJ030106]
   Zhioua Z, 2017, IEEE PAC RIM INT SYM, P267, DOI 10.1109/PRDC.2017.51
NR 110
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17218-4
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW2V2
UT WOS:001155653100002
DA 2024-07-18
ER

PT J
AU Sharma, M
   Kumar, N
   Singh, VP
   Madan, C
   Sarowa, S
AF Sharma, Manoj
   Kumar, Naresh
   Singh, Vijay Pal
   Madan, Charanjeet
   Sarowa, Sandeep
TI Hybrid intelligent feature selector framework for darknet traffic
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Traffic classification; Dark web; Machine learning; Random forest; LASSO
AB With the rapid growth in the internet traffic, analysis and exploration of traffic classification has become more challenging task especially for dark net or dark web. Darknet, within the confines of deep web, has been witnessing illegitimate doings such as drug trafficking, terrorism, betting etc. Hence classification of darknet traffic is an important task. This paper presents intelligent framework for the darknet traffic categorization with proposed hybrid feature selector. The darknet traffic consists of data packet related information as input predictors for the model. Twenty-one machine learning models with and without feature selectors are presented to categorize the darknet traffic. We propose a Hybrid LASSO-Random Forest (HLRF) feature selector to reduce feature dimensionality. Classification of darknet traffic is evaluated with well-known KNN, Extra Tree and XGBoost classifiers. The performance of proposed models was assessed in terms of Accuracy, Precision, Recall, Harmonic Mean Value of True Positive Value (TPV) and Positive Predicted Value (PPV), Matthews Corelation Coefficients (MCC) and Jaccard Score. The experimental results approve that XGBoost with proposed HLRF feature selector outperforms in categorization of darknet traffic. The results revel that proposed XGBoost-HLRF model obtain an accuracy and recall value of 98.10% with precision of 98.12%. Comparison of XGBoost-HLRF model with other proposed state of art models are presented for performance assessment of our model.
C1 [Sharma, Manoj] MRSPTU, Giani Zail Singh Campus Coll Engn & Technol, Dept Elect & Commun Engn, Bathinda, India.
   [Kumar, Naresh] Panjab Univ, Dept Elect & Commun Engn, UIET, Chandigarh, India.
   [Singh, Vijay Pal] GJU S&T, Dept Elect & Commun Engn, Hisar, Haryana, India.
   [Madan, Charanjeet] GJU S&T, Dept Elect Engn, Hisar, Haryana, India.
   [Sarowa, Sandeep] Minist Elect & Informat Technol, CERT In, New Delhi, India.
C3 Panjab University; Guru Jambheshwar University of Science & Technology;
   Guru Jambheshwar University of Science & Technology
RP Sharma, M (corresponding author), MRSPTU, Giani Zail Singh Campus Coll Engn & Technol, Dept Elect & Commun Engn, Bathinda, India.; Kumar, N (corresponding author), Panjab Univ, Dept Elect & Commun Engn, UIET, Chandigarh, India.
EM neelmanoj@gmail.com; naresh_uiet@yahoo.com
RI Singh, Vijay/AAH-9906-2020; sharma, manoj/ABA-4143-2021; Kumar,
   Naresh/AHE-7369-2022
OI Singh, Vijay/0000-0002-6803-7585; Kumar, Naresh/0000-0001-5677-971X;
   MADAN, DR.CHARANJEET/0000-0002-9032-9728
CR Aceto G, 2018, J NETW COMPUT APPL, V103, P131, DOI 10.1016/j.jnca.2017.11.007
   ALSABAH M, 2012, P 2012 ACM C COMP CO, DOI DOI 10.1145/2382196.2382208
   [Anonymous], 2014, Going Dark: the Internet behind the Internet
   [Anonymous], 2006, Distance metric learning: a comprehensive survey
   Bai XF, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, PROCEEDINGS, P548, DOI 10.1109/ISDA.2008.209
   Baldi P, 2000, BIOINFORMATICS, V16, P412, DOI 10.1093/bioinformatics/16.5.412
   Berger V, 2020, HAL Id: hal-02497248
   Biddle P, 2002, LECT NOTES COMPUT SC, V2696, P155
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bouazza SH, 2018, PROCEDIA COMPUT SCI, V127, P300, DOI 10.1016/j.procs.2018.01.126
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chertoff M., 2017, J CYBER POLICY, V2, P26, DOI DOI 10.1080/23738871.2017.1298643
   Chicco D, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-019-6413-7
   Danihelka I, 2016, PR MACH LEARN RES, V48
   Dingledine R, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P303
   Draper-Gil Gerard, 2016, ICISSP 2016. 2nd International Conference on Information Systems Security and Privacy. Proceedings, P407
   Gaofeng He, 2014, 2014 Second International Conference on Advanced Cloud and Big Data (CBD), P220, DOI 10.1109/CBD.2014.37
   Gayard L, 2018, Darknet: geopolitics and uses
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Gorodkin J, 2004, COMPUT BIOL CHEM, V28, P367, DOI 10.1016/j.compbiolchem.2004.09.006
   Graves A, 2007, LECT NOTES COMPUT SC, V4668, P549
   Hector V-C, Robust design of artificial neural networks methodology in neutron spectrometry
   Hideko K., 2012, IPSJ SIG Tech Rep, VMPS-89, P1
   Hodo E, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2017), DOI 10.1145/3098954.3106068
   Jurman G, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041882
   Kursa MB, 2010, FUND INFORM, V101, P271, DOI 10.3233/FI-2010-288
   Lashkari AH, 2017, ICISSP: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P253, DOI 10.5220/0006105602530262
   Lim H, 2017, PATTERN RECOGN LETT, V89, P25, DOI 10.1016/j.patrec.2017.02.004
   Loh WY, 2014, INT STAT REV, V82, P329, DOI 10.1111/insr.12016
   Lotfollahi M, 2020, SOFT COMPUT, V24, P1999, DOI 10.1007/s00500-019-04030-2
   Nazari Z, 2019, PROCEEDINGS OF 2019 THE 3RD INTERNATIONAL CONFERENCE ON CRYPTOGRAPHY, SECURITY AND PRIVACY (ICCSP 2019) WITH WORKSHOP 2019 THE 4TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2019), P39, DOI 10.1145/3309074.3309102
   Reed MG, 1998, IEEE J SEL AREA COMM, V16, P482, DOI 10.1109/49.668972
   Severalnines, 2020, About us
   Shubham VG, 2017, Int J Eng Res Technol, V5, P1
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   unb, 2020, ABOUT US
   Venkateswaran R, 2001, IEEE POTENTIALS, V20, P11, DOI 10.1109/45.913204
   Ward M, 2014, Tor's most visited hidden sites host child abuse images
   Zhai JT, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8863169
   Zhou K, 2020, ETRI J, V42, P311, DOI 10.4218/etrij.2019-0190
   Zou Z, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P329, DOI 10.1109/HPCC/SmartCity/DSS.2018.00074
NR 43
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17338-x
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900011
DA 2024-07-18
ER

PT J
AU El Joumani, S
   El Amraoui, K
   Mechkouri, SE
   Zennouhi, R
   Masmoudi, L
AF El Joumani, Saleh
   El Amraoui, Khalid
   Mechkouri, Salah Eddine
   Zennouhi, Rachid
   Masmoudi, Lhoussaine
TI Segmentation of satellite image based on quantum approach and the
   Havrda-Charvat entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Segmentation; 2D-histogram; Havrda-Charvat Entropy; Euclidean distance;
   Mahalanobis distance; QuickBird image
AB In this paper, we present a new segmentation founded on the theory of quantum mechanics and the Havrda-Charvat entropy. This segmentation method is a continuous improvement of the method developed in 2014 by Mechkouri et al. (J Theor Appl Inf Technol 62(2):539-545, 2014). The segmentation was performed using an unsupervised segmentation method using the hierarchical analysis of the 2D histograms, which was constructed using the wave function and Havrda-Charvat entropy. We upgrade the quality of the segmentation method by reclassifying no segmented pixels into the classes defined by the Euclidean distance and Mahalanobis distance. The proposed approach was first tested on the synthetic image; it was applied to the segmentation of the environment for the QuickBird data of a selected urban area in the region of Rabat- Sale-Kenitra, prefecture of Skhirate-Temara, Morocco. The segmentation result obtained is more satisfactory than that obtained in the previous study (Mechkouri et al. in J Theor Appl Inf Technol 62(2):539-545, 2014). The development method is very hopeful and needs to be more investigating.
C1 [El Joumani, Saleh; El Amraoui, Khalid; Mechkouri, Salah Eddine; Zennouhi, Rachid; Masmoudi, Lhoussaine] Univ Mohammed V Rabat, Fac Sci Rabat, LCS ESI, Phys Dept, BP 1014 Ave Ibn Battouta, Rabat, Morocco.
C3 Mohammed V University in Rabat
RP Mechkouri, SE (corresponding author), Univ Mohammed V Rabat, Fac Sci Rabat, LCS ESI, Phys Dept, BP 1014 Ave Ibn Battouta, Rabat, Morocco.
EM jomanisalh@gmail.com; khalid.elamraoui@um5r.ac.ma;
   salahmechkouri@gmail.com; r.zennouhi@gmail.com; lhmasmoudi@fsr.ac.ma
OI EL AMRAOUI, Khalid/0009-0005-3854-5721; SALAH EDDINE,
   MECHKOURI/0000-0002-0561-2861
FU AECI "Agencia Espanola de Cooperacion Internacional"
FX The author acknowledges the financial support received from AECI
   "Agencia Espanola de Cooperacion Internacional" for the
   PCI-Mediterranean program Project / Morocco-Spain that provided the
   image data.
CR Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Clément A, 2003, PATTERN RECOGN LETT, V24, P1951, DOI 10.1016/S0167-8655(03)00034-5
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Havrda J., 1967, Kybernetica (Prague), V3, P95
   Lezoray O, 2003, P ICISP 2003, V1, P22
   Mechkouri S., 2010, Geo Observateur, V18, P43
   Mechkouri Salah Eddine, 2014, Journal of Theoretical and Applied Information Technology, V62, P539
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Zennouhi R, 2009, IMAGING SCI J, V57, P260, DOI 10.1179/136821909X12490307952874
   Zennouhi R, 2009, INT C SCI EL TECHN I
NR 11
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17299-1
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300001
DA 2024-07-18
ER

PT J
AU Mondelo, V
   Lado, MJ
   Méndez, AJ
AF Mondelo, Victor
   Lado, Maria J.
   Mendez, Arturo J.
TI ECGDT: a graphical software tool for ECG diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Electrocardiogram; Computer-assisted diagnosis; Software tool; User
   computer interface; Cardiac diseases
ID COMPUTER-AIDED DIAGNOSIS; HEART-RATE-VARIABILITY; SLEEP-APNEA; QRS; RISK
AB While cardiovascular diseases are the leading causes of death in developed countries, detection of cardiac abnormalities can reduce mortality rates, through early and accurate diagnosis. One of the main assets used to help in the diagnosis process is the electrocardiogram (ECG). A free software tool for electrocardiogram analysis and diagnosis is presented. The tool, named ECGDT, allows: (1) to detect beats present on the ECG, both in single and multi-channel levels, (2) to identify beat waves, and (3) to diagnose different cardiac abnormalities. System evaluation was performed in two ways: (1) diagnostic capabilities were tested with Receiver Operating Characteristic (ROC) analysis, and (2) Graphical Software Interface (GUI) aspects, such as attraction, efficiency, or novelty, were evaluated employing User Experience Questionnaire (UEQ) scores. For disease diagnosis, the mean Area Under the ROC Curve (AUC) was 0.821. The system was also capable of detecting 100% of several cardiac abnormalities, such as bradycardia or tachycardia. Related to the GUI, all usability estimators scored values ranged between 2.208 and 2.750 (overall positive evaluations are obtained for values over 0.8). ECGDT could serve as an aid in the diagnosis of different medical abnormalities. In addition, the suitability of the developed interface has been proven.
C1 [Mondelo, Victor; Lado, Maria J.; Mendez, Arturo J.] Univ Vigo, Dept Comp Sci, ESEI, Campus As Lagoas, Orense 32004, Spain.
C3 Universidade de Vigo
RP Mondelo, V (corresponding author), Univ Vigo, Dept Comp Sci, ESEI, Campus As Lagoas, Orense 32004, Spain.
EM vmondelo@uvigo.es; mrpepa@uvigo.es; mrarthur@uvigo.es
RI Lado, Maria J/F-9196-2011
OI Lado, Maria J/0000-0002-9027-7788
FU We would also like to acknowledge the persons that kindly collaborated
   in the validation of this tool and gave us feedback for improving it.
FX We would also like to acknowledge the persons that kindly collaborated
   in the validation of this tool and gave us feedback for improving it.
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Afonso VX, 1999, IEEE T BIO-MED ENG, V46, P192, DOI 10.1109/10.740882
   [Anonymous], 2020, Normal ECG
   [Anonymous], 1999, Generalized Additive Models
   [Anonymous], 2016, 2016 14 INT WORKSH C, DOI DOI 10.1109/CBMI.2016.7500257
   Asiri N, 2019, Arxiv, DOI arXiv:1811.01238
   Chouhan VS, 2008, INT J COMPUT SCI NET, V8, P155
   Ebigbo A, 2019, GUT, V68, P1143, DOI 10.1136/gutjnl-2018-317573
   ECG interpretation, 2020, Characteristics of the normal ECG (P-wave, QRS complex, ST segment, T-wave)
   ECGpedia, 2020, About us
   El-Dahshan ESA, 2014, EXPERT SYST APPL, V41, P5526, DOI 10.1016/j.eswa.2014.01.021
   García J, 2002, IEEE T INF TECHNOL B, V6, P277, DOI 10.1109/TITB.2002.806087
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Khelassi Abdeldjalil, 2017, Electron Physician, V9, P4357, DOI 10.19082/4357
   KIRKLIN JK, 1986, J THORAC CARDIOV SUR, V92, P1049
   Lado MJ, 2008, COMPUT BIOL MED, V38, P475, DOI 10.1016/j.compbiomed.2008.01.011
   Lado MJ, 2011, J MED SYST, V35, P473, DOI 10.1007/s10916-009-9383-5
   Ledezma CA, 2015, 5 C VEN BIOING MER V, V162, P118
   Macfarlane PW, 2005, COMPUT CARDIOL, V32, P451
   Macfarlane PW., 2012, Basic electrocardiology: cardiac electrophysiology, ECG systems and mathematical modeling
   Mangrum JM, 2000, NEW ENGL J MED, V342, P703, DOI 10.1056/NEJM200003093421006
   Martínez JP, 2004, IEEE T BIO-MED ENG, V51, P570, DOI 10.1109/TBME.2003.821031
   Mondelo V, 2019, 3 ANN M CINB BENCH B, P46
   Mondelo V., 2017, J. Adv. Theor. Appl. Inform., V3, P5
   Mondelo V, 2019, Sistema de apoyo al diagnostico de electrocardiogramas
   Mondelo V, 2017, J Inf Syst Eng Manag, V2, DOI [10.20897/jisem.201713, DOI 10.20897/JISEM.201713]
   Mondelo V, 2017, IBER CONF INF SYST
   Nielsen JB, 2015, HEART RHYTHM, V12, P1887, DOI 10.1016/j.hrthm.2015.04.026
   Normal Electrocardiography (ECG), 2020, Intervals: Normal Electrocardiography Intervals
   O'Keefe JH., 2008, The Complete Guide to ECGs, V3rd
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Park JA, 2017, COMPUT ASSIST SURG, V22, P176, DOI 10.1080/24699322.2017.1389396
   Pathan S, 2018, BIOMED SIGNAL PROCES, V39, P237, DOI 10.1016/j.bspc.2017.07.010
   Pu Q, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.870391
   Rauschenberger M, 2013, INT J INTERACT MULTI, V2, P39, DOI 10.9781/ijimai.2013.215
   Rodríguez B, 2006, ANN NY ACAD SCI, V1080, P395, DOI 10.1196/annals.1380.029
   RStudio, OP SOURC PROF SOFTW
   Sethi K K, 2007, J Assoc Physicians India, V55 Suppl, P10
   Shiny, About us
   Thaler MalcolmS., 2010, ONLY EKG BOOK YOULL
   Thygesen K, 2007, J AM COLL CARDIOL, V50, P2173, DOI [10.1161/CIRCULATIONAHA.107.187397, 10.1016/j.jacc.2007.09.011]
   TOWNSEND N., 2014, CARDIOVASCULAR DIS S
   Virani SS, 2020, CIRCULATION, V141, pE139, DOI 10.1161/CIR.0000000000000757
   Wellens HJ., 2012, Electrical stimulation of the heart in the study and treatment of tachycardias
   WHO | World Health Organization, About us
   Wood S.N., 2017, Generalized Additive Models, DOI 10.1201/9781315370279
   Yakut Ö, 2018, BIOMED SIGNAL PROCES, V42, P230, DOI 10.1016/j.bspc.2018.02.004
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Yochum M, 2016, BIOMED SIGNAL PROCES, V25, P46, DOI 10.1016/j.bspc.2015.10.011
   Zhang LL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21100927
NR 51
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17101-2
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800003
OA hybrid
DA 2024-07-18
ER

PT J
AU Rayatifard, M
   Mehrabi, M
   Ghanbari, M
AF Rayatifard, M.
   Mehrabi, M.
   Ghanbari, M.
TI A fast and robust shot detection method in HEVC/H.265 compressed video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE HEVC/H.265 video standard; Shot detection; Content based video
   retrieval; Compressed domain; Video segmentation
ID BOUNDARY DETECTION
AB Temporal segmentation of video into shots is the first step in most video analysis. This is because within a shot, consecutive frames are similar to each other, leading to numerous video analyses. It is highly desired if temporal segmentation can be carried out directly on the compressed video streams. In this paper, a method is presented for time segmentation and shot detection of compressed HEVC/H.265 video streams without their complete decompression. The proposed method uses the values of non-zero coefficients of P-frames and B-frames Coded Transform Unit (CTU) flags in the compressed bitstream headers to detect shot boundaries. It is based on the fact that, the similarity of consecutive frames is high if they belong to the same shot. To increase the shot detection accuracy, the boundary threshold is adaptively adjusted. Experiments show that the proposed method based on P-frame detects shots without decompressing video with an average precision of 97%, recall of 86%, and F-measure of 91%. Based on B-frames, it detects shot without decompressing video with an average precision of 82%, recall of 71%, and F-measure of 76%. Moreover, the robustness of the proposed method to different coding parameters is also preserved and under different coding conditions, on average they become (based on P and B type frames): at least a precision of 82%, recall of 84.7%, and an F-measure of 83.7%.
C1 [Rayatifard, M.; Mehrabi, M.] Islamic Azad Univ, Dept Comp Engn, Shiraz Branch, Shiraz, Iran.
   [Ghanbari, M.] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, England.
C3 Islamic Azad University; University of Essex
RP Mehrabi, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Shiraz Branch, Shiraz, Iran.
EM Mostafa_rayati24@yahoo.com; mahdi.mehrabi@iau.ac.ir; ghan@essex.uk
RI Mehrabi, Mahdi/AAO-2879-2021
OI Mehrabi, Mahdi/0000-0002-1551-5723
CR Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Amirpour H, 2021, 2021 IEEE INT C MULT, ppp1
   [Anonymous], 2006, P WORKSH VID PROC QU
   Babu RV, 2016, MULTIMED TOOLS APPL, V75, P1043, DOI 10.1007/s11042-014-2345-z
   Basavarajaiah M, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355398
   Biswas S, 2013, INT CONF ACOUST SPEE, P2040, DOI 10.1109/ICASSP.2013.6638012
   Boyce J., 2018, JVETJ1010
   Cebrián-Márquez G, 2019, SIGNAL PROCESS-IMAGE, V76, P97, DOI 10.1016/j.image.2019.04.019
   Chai CL, 2021, INFORM SCIENCES, V577, P483, DOI 10.1016/j.ins.2021.07.012
   Chakraborty Dipanita, 2021, 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P272, DOI 10.1109/ECTI-CON51831.2021.9454775
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Dawood A. M., 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P253, DOI 10.1109/MMSP.1999.793841
   Dawood AM, 1999, IEEE T MULTIMEDIA, V1, P77, DOI 10.1109/6046.748173
   Dawood AM, 2001, INT CONF ACOUST SPEE, P1645, DOI 10.1109/ICASSP.2001.941252
   Dawood AM, 1999, IEE CONF PUBL, P285, DOI 10.1049/cp:19990328
   De Bruyne S, 2008, SIGNAL PROCESS-IMAGE, V23, P473, DOI 10.1016/j.image.2008.04.012
   Dhiman S, 2019, MULTIMED TOOLS APPL, V78, P34707, DOI 10.1007/s11042-019-08170-3
   Tran DL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040684
   Dorfeshan N., 2018, Journal of Computer & Robotics, V11, P41
   Duan FF, 2020, IEEE ACCESS, V8, P214633, DOI 10.1109/ACCESS.2020.3040861
   Dutta D, 2016, MULTIMED TOOLS APPL, V75, P93, DOI 10.1007/s11042-014-2273-y
   Feng J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P821, DOI 10.1109/ICIP.1996.561031
   Ghanbari M, 2011, US Patent, Patent No. 7869517
   Gunawan IP, 2008, IEEE T BROADCAST, V54, P669, DOI 10.1109/TBC.2008.2000734
   Gygli M, 2018, INT WORK CONTENT MUL
   Hassanien A, 2017, Arxiv, DOI arXiv:1705.03281
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Iwan LH, 2017, MULTIMED TOOLS APPL, V76, P1379, DOI 10.1007/s11042-015-3130-3
   Kar T, 2023, MULTIMED TOOLS APPL, V82, P8489, DOI 10.1007/s11042-022-13547-y
   Koprinska I., 1998, 9 EUR SIGN PROC C EU, P1
   Lesmono W D, 2021, Journal of Physics: Conference Series, V1725
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Liu TC, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1230812.1230813
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Masera M, 2017, SIGNAL PROCESS-IMAGE, V57, P173, DOI 10.1016/j.image.2017.06.001
   MENG JH, 1995, P SOC PHOTO-OPT INS, V2419, P14, DOI 10.1117/12.206359
   Menon VV, 2021, IEEE IMAGE PROC, P2174, DOI 10.1109/ICIP42928.2021.9506092
   Midya A, 2015, MULTIMED TOOLS APPL, V74, P2033, DOI 10.1007/s11042-013-1739-7
   Moharrami A., 2023, Electron Energy, V4
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   Nishani E, 2017, MEDD C EMBED COMPUT, P242
   open-video, Video data set
   Pinson MH, 2013, IEEE SIGNAL PROC MAG, V30, P171, DOI 10.1109/MSP.2013.2258265
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Sze V, 2014, Integr. Circ. Syst. Algor. Archit, V39, P40
   Trichet R, 2015, 2015 12 IEEE INT C A, P1
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
   Zeng W, 2005, IEEE INT SYMP CIRC S, P3459
   Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227
NR 50
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-16974-7
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800027
DA 2024-07-18
ER

PT J
AU Sawadogo, MAL
   Pala, F
   Singh, G
   Selmi, I
   Puteaux, P
   Othmani, A
AF Sawadogo, Moctar Abdoul Latif
   Pala, Furkan
   Singh, Gurkirat
   Selmi, Imen
   Puteaux, Pauline
   Othmani, Alice
TI PTSD in the wild: a video database for studying post-traumatic stress
   disorder recognition in unconstrained environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Affective computing in the wild; PTSD diagnosis; Video analysis; Mental
   disorder diagnosis; Affect recognition
AB POST-traumatic stress disorder (PTSD) is a chronic and debilitating mental condition that is developed in response to catastrophic life events, such as military combat, sexual assault, and natural disasters. PTSD is characterized by flashbacks of past traumatic events, intrusive thoughts, nightmares, hypervigilance, and sleep disturbance, all of which affect a person's life and lead to considerable social, occupational, and interpersonal dysfunction. The diagnosis of PTSD is done by medical professionals using self-assessment questionnaire of PTSD symptoms as defined in the Diagnostic and Statistical Manual of Mental Disorders (DSM). In this paper, and for the first time, we collected, annotated, and prepared for public distribution a new video database for automatic PTSD diagnosis, called PTSD-in-the-wild dataset. The database exhibits "natural" and big variability in acquisition conditions with different pose, facial expression, lighting, focus, resolution, age, gender, race, occlusions and background. In addition to describing the details of the dataset collection, we provide a benchmark for evaluating machine learning-based approaches on PTSD-in-the-wild dataset. In addition, we propose and we evaluate a deep learning-based approach for PTSD detection in respect to the given benchmark. The proposed approach shows very promising results. Interested researcher can download a copy of PTSD-in-the wild dataset from http://www.lissi.fr/PTSD-Dataset/.
C1 [Sawadogo, Moctar Abdoul Latif; Pala, Furkan; Singh, Gurkirat; Selmi, Imen; Othmani, Alice] Univ Paris Est Creteil UPEC, LISSI, F-94400 Vitry Sur Seine, France.
   [Sawadogo, Moctar Abdoul Latif] Univ Paris, Rue St Peres, F-75270 Paris, France.
   [Pala, Furkan] Istanbul Tech Univ, TR-34467 Istanbul, Turkiye.
   [Singh, Gurkirat] Natl Inst Technol, Warangal 506004, India.
   [Selmi, Imen] ENIS, Natl Engn Sch Sfax, Route Soukra, Sfax 3038, Tunisia.
   [Puteaux, Pauline] Univ Lille, CRIStAL, CNRS, Cent Lille, F-59000 Lille, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC); Universite Paris Cite;
   Istanbul Technical University; National Institute of Technology (NIT
   System); National Institute of Technology Warangal; Universite de Sfax;
   Ecole Nationale dIngenieurs de Sfax (ENIS); Universite de Lille;
   Centrale Lille; Centre National de la Recherche Scientifique (CNRS)
RP Othmani, A (corresponding author), Univ Paris Est Creteil UPEC, LISSI, F-94400 Vitry Sur Seine, France.
EM moctar-abdoul-latif.sawadogo@u-pec.fr; pala18@itu.edu.tr;
   gs832025@student.nitw.ac.in; imen.selmi@enis.tn;
   pauline.puteaux@cnrs.fr; alice.othmani@u-pec.fr
OI OTHMANI, Alice/0000-0002-3442-0578
CR Aadam Tubaishat A, 2022, Soft Computing, P1
   Alfar HE, 2020, Recent Advances in NLP: The Case of Arabic Language, P129, DOI DOI 10.1007/978-3-030-34614-0_7
   Baevski A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5360
   Baevski Alexei, 2020, Advances in neural information processing systems
   Banerjee D, 2019, KNOWL INF SYST, V60, P1693, DOI 10.1007/s10115-019-01337-2
   Batbaatar E, 2019, IEEE ACCESS, V7, P111866, DOI 10.1109/ACCESS.2019.2934529
   Bauer MR, 2013, PSYCHOL ASSESSMENT, V25, P1037, DOI 10.1037/a0033432
   Chaari Sirine, 2022, P 2022 INT C MED IM
   de Beurs E, 2020, Tijdschr Psychiatr, V62, P448
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Desmet B, 2013, EXPERT SYST APPL, V40, P6351, DOI 10.1016/j.eswa.2013.05.050
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dia M, 2023, 36 IEEE INT S COMP B
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Gupta S, 2022, COGN NEURODYNAMICS, V16, P833, DOI 10.1007/s11571-021-09771-1
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Islam KA, 2018, IEEE INT CONF BIG DA, P5252, DOI 10.1109/BigData.2018.8622447
   Kaur S, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01078-1
   Kingma D. P., 2014, arXiv
   Kusters R, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.577974
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   McLean SA, 2020, MOL PSYCHIATR, V25, P283, DOI 10.1038/s41380-019-0581-3
   Muzammel M, 2021, COMPUT METH PROG BIO, V211, DOI 10.1016/j.cmpb.2021.106433
   Muzammel M, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100005
   OMalley T.a.B., 2019, KERASTUNER
   Othmani Alice, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P5, DOI 10.1007/978-3-030-68790-8_1
   Othmani A, 2023, Machine learning-based approaches for post-traumatic stress disorder diagnosis using video and eeg sensors: A review
   Pampouchidou A, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01080-7
   Rahman AU, 2023, APPL INTELL, V53, P2798, DOI 10.1007/s10489-022-03552-x
   Rejaibi E, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103107
   Rozgic Viktor, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3636, DOI 10.1109/ICASSP.2014.6854279
   Schoneveld L, 2021, PATTERN RECOGN LETT, V146, P1, DOI 10.1016/j.patrec.2021.03.007
   Schultebraucks K, 2022, PSYCHOL MED, V52, P957, DOI 10.1017/S0033291720002718
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stappen Lukas, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P5706, DOI 10.1145/3474085.3478582
   Stappen L, 2021, Arxiv, DOI arXiv:2101.06053
   Tokuno S., 2013, 2011 DEF SCI RES C E, P1, DOI [DOI 10.1109/DSR.2011.6026823, 10.1109/DSR.2011.6026823]
   Ullah S, 2021, MED BIOL ENG COMPUT, V59, P1167, DOI 10.1007/s11517-021-02368-0
   Yang L, 2017, Hybrid depression classification and estimation from audio video and text information, DOI [DOI 10.1145/3133944.3133950, 10.1145/3133944.3133950]
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhuang XD, 2014, IEEE W SP LANG TECH, P260, DOI 10.1109/SLT.2014.7078584
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17203-x
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800022
DA 2024-07-18
ER

PT J
AU Viana, HO
   Araújo, AFR
   Barbosa, DS
AF Viana, Hesdras O.
   Araujo, Aluizio F. R.
   Barbosa, Danilo S.
TI Self-organizing speech recognition that processes acoustic and
   articulatory features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Robust speech recognition; Neural network; Self-organizing map;
   Acoustic-to-articulatory inversion; Articulatory feature; Acoustic
   feature
ID INFORMATION
AB In automatic speech recognition (ASR) systems, the minimization of noxious effects caused by different background noises between training and operating situations has been a challenging task for many years. An ASR robust to noise that can deal with different types of speeches and various speakers still is an open research point. Typically, conventional ASR models for missing-feature reconstructions and robust speech descriptors employ acoustic features and statistical methods. In spite of improved performance in dealing with noise, such methods still degrade the performance when different background noises co-exist with the main signal. More recent approaches use neural networks, particularly deep learning models, for ASR purposes. Such models increase performance at the high training cost. In order to mitigate such limitations, we proposed an ASR model called Self-Organizing Speech Recognizer (SOSR). Unlike most conventional ASRs, SOSR is characterized by using acoustic and articulatory features, employing unsupervised and incremental learning, and is suitable for real-time applications due to its quick training stage. SOSR simultaneously processes an audio signal in a two-branch. In the first path, the acoustic features are extracted from the original signal whereas in the second path an acoustic-to-articulatory inversion is performed by several Self-organizing Maps. The signal from both paths is delivered to a Self-organizing Map with a time-varying structure, which is responsible for recognizing the input speech signal. Four datasets (TIMIT, Aurora 2, Aurora 4, and CHIME 2) were used for SOSR assessment. The Word Error Rate (WER) was the chosen metric to compare the experimental results of the tests with different noise levels and signal variations. Hence, the experimental results suggest that SOSR can learn quickly, and it can handle noisy signals, various speakers, different types of speeches, and assorted lengths of utterances.
C1 [Viana, Hesdras O.] Uninassau, Campus Dantas Barreto,Ave Dantas Barreto,315-Santo, BR-50010360 Recife, Brazil.
   [Araujo, Aluizio F. R.; Barbosa, Danilo S.] Univ Fed Pernambuco, Ctr Informat, BR-50740560 Recife, Brazil.
C3 Universidade Federal de Pernambuco
RP Barbosa, DS (corresponding author), Univ Fed Pernambuco, Ctr Informat, BR-50740560 Recife, Brazil.
EM hesdras.viana@uninassau.edu.br; aluizioa@cin.ufpe.br; dsb5@cin.ufpe.br
OI de sousa barbosa, danilo/0000-0002-6393-2716
CR Afshan A, 2015, SPEECH COMMUN, V66, P1, DOI 10.1016/j.specom.2014.07.005
   Araujo AFR, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522975
   Araújo ARF, 2009, IMAGE VISION COMPUT, V27, P1229, DOI 10.1016/j.imavis.2008.11.014
   Arora N., 2016, Int J Comput Appl, V151, P24
   Bastanfard A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P592, DOI 10.1109/KBEI.2019.8735005
   Cheung ESH., 1993, Fast nearest neighbour search algorithms for self-organizing map and vector quantisation
   Das B, 2017, INT CONF ACOUST SPEE, P5235, DOI 10.1109/ICASSP.2017.7953155
   Deng L., 2018, Speech processing: a dynamic and optimization-oriented approach, DOI [10.1201/9781482276237, DOI 10.1201/9781482276237]
   Dev Amita, 2010, International Journal of Computer Applications, V10, P36
   Gibbons JD., 2011, Nonparametric Statistical Inference, P977
   Goodarzi MM, 2016, SPEECH COMMUN, V76, P218, DOI 10.1016/j.specom.2015.06.009
   Han J, 2020, J ACOUST SOC KOREA, V39, P64, DOI 10.7776/ASK.2020.39.1.064
   Hartmann W, 2013, IEEE T AUDIO SPEECH, V21, P1993, DOI 10.1109/TASL.2013.2263802
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H, 1991, INT C AC SPEECH SIGN
   Hui L, 2006, INT CONF ACOUST SPEE, P377
   Illa A, 2019, INT CONF ACOUST SPEE, P5931, DOI 10.1109/ICASSP.2019.8682506
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Kim C, 2010, INT CONF ACOUST SPEE, P4574, DOI 10.1109/ICASSP.2010.5495570
   Kim W, 2011, SPEECH COMMUN, V53, P1, DOI 10.1016/j.specom.2010.08.005
   Kinoshita K, 2020, INT CONF ACOUST SPEE, P7009, DOI [10.1109/icassp40776.2020.9053266, 10.1109/ICASSP40776.2020.9053266]
   Kirchhoff K, 2002, SPEECH COMMUN, V37, P303, DOI 10.1016/S0167-6393(01)00020-6
   Kohonen T. K., 2001, SELF ORG MAPS, V3rd ed.
   Kollig T., 2002, Efficient multidimensional sampling
   Ladefoged P., 1996, The sounds of the world's languages
   Lee HS, 2022, 2022 13TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P145, DOI 10.1109/ISCSLP57327.2022.10037796
   Lee M, 2019, DIGIT SIGNAL PROCESS, V85, P1, DOI 10.1016/j.dsp.2018.11.005
   Li B, 2014, IEEE-ACM T AUDIO SPE, V22, P1296, DOI 10.1109/TASLP.2014.2329237
   Li J, 2007, PROCEEDINGS OF THE 3RD INTERNATIONAL YELLOW RIVER FORUM ON SUSTAINABLE WATER RESOURCES MANAGEMENT AND DELTA ECOSYSTEM MAINTENANCE, VOL VI, P65, DOI 10.1109/ASRU.2007.4430085
   Mahdavi R, 2020, 2020 25 INT COMP C C
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Mitra V, 2011, INT C AC SPEECH SIGN
   Mitra V, 2011, IEEE T AUDIO SPEECH, V19, P1913, DOI 10.1109/TASL.2010.2103058
   Naess AB, 2011, INT SPEECH COMMUNICA
   Narayanan A, 2013, INT CONF ACOUST SPEE, P7092, DOI 10.1109/ICASSP.2013.6639038
   Ouni S, 2005, J ACOUST SOC AM, V118, P444, DOI 10.1121/1.1921448
   PAUL DB, 1992, SPEECH AND NATURAL LANGUAGE, P357
   Paylakhi SH, 2015, Int J Innov Res Technol Sci Eng
   Powers DMW, 2002, Evaluation: from precision, recall and f-measure to roc, informedness, markedness correlation
   Qian YM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5604, DOI 10.1109/ICASSP.2018.8462629
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Rabiner L.R., 1996, AUTOMATIC SPEECH SPE, P1
   Rabiner LR., 2007, Introduction to digital speech processing, DOI [10.1561/9781601980717, DOI 10.1561/9781601980717]
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Seltzer ML, 2010, INT CONF ACOUST SPEE, P4550, DOI 10.1109/ICASSP.2010.5495581
   Seltzer ML., 2013, Techniques for Noise Robustness in Automatic Speech Recognition, chapter Acoustic Model Training for Robust Speech Recognition
   Song YZ, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 7, PROCEEDINGS, P48, DOI 10.1109/ICNC.2008.335
   Sudhakar P, 2014, 15 ANN C INT SPEECH
   Tarek B, 2014, 2014 15TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P41
   Toda T, 2004, INT C SPOK LANG PROC
   Viana HO, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P104, DOI 10.1109/ICDSP.2016.7868525
   Vincent E, 2013, INT CONF ACOUST SPEE, P126, DOI 10.1109/ICASSP.2013.6637622
   Wang ZQ, 2016, IEEE-ACM T AUDIO SPE, V24, P796, DOI 10.1109/TASLP.2016.2528171
   Weninger F., 2013, Proceedings of the 2nd CHiME workshop on machine listening in multisource environments, P86
   Weninger F, 2015, LECT NOTES COMPUT SC, V9237, P91, DOI 10.1007/978-3-319-22482-4_11
   Wu B, 2017, IEEE J-STSP, V11, P1289, DOI 10.1109/JSTSP.2017.2756439
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yoon KM, 2019, J ACOUST SOC KOREA, V38, P47, DOI 10.7776/ASK.2019.38.1.047
   Yu D, 2008, P ICASSP
   Yu JG, 2019, IEEE-ACM T AUDIO SPE, V27, P742, DOI 10.1109/TASLP.2019.2894554
   Zhang ZX, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178115
NR 61
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17080-4
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600013
DA 2024-07-18
ER

PT J
AU Zhang, J
   Xie, QG
   Xu, LH
   Zhu, XP
   Hou, JY
AF Zhang, Jie
   Xie, Qinggang
   Xu, Longhao
   Zhu, Xiaopeng
   Hou, Jinyou
TI Circuit simulation and image encryption based on a six-dimensional
   cellular neural network hyperchaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Six-dimensional hyperchaos; Circuit simulation; Double image encryption;
   DNA dynamic encoding
ID CHAOTIC SYSTEM; ALGORITHM
AB This paper proposes a six-dimensional hyperchaotic system based on the Cellular Neural Networks (CNN) theory. Numerical analysis of the Lyapunov exponential spectrum, bifurcation diagrams, and complexity methods reveals that the system has multiple coexisting attractors and high initial sensitivity, verifying its rich dynamics and making it highly valuable in secure communications. The circuit of the system was then designed and implemented using the Multisim circuit simulation software, and the experimental results agreed with the numerical simulation results, verifying the realistic feasibility of the system. Finally, a color image chunking encryption algorithm is designed with the DNA algorithm, using the chaotic sequence generated by the six-dimensional CNN as the secret key source and the Logistic chaos mapping to generate the private key again to achieve double encryption. Since the legend of the algorithm is generated from the plaintext image, the effect of "one image, one secret" can be realized. The results show that the encryption algorithm has a good effect, high dislocation of the encrypted image, low correlation between neighboring pixels, increased sensitivity to the key, and high complexity and security.
C1 [Zhang, Jie; Xie, Qinggang; Xu, Longhao; Zhu, Xiaopeng; Hou, Jinyou] Northwest Normal Univ, Coll Phys & Elect Engn, Engn Res Ctr Gansu Prov Intelligent Informat Techn, Gansu 730070, Peoples R China.
RP Zhang, J (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Engn Res Ctr Gansu Prov Intelligent Informat Techn, Gansu 730070, Peoples R China.
EM zhangjie@nwnu.edu.cn; 1365901912@qq.com; 1401564978@qq.com;
   1095164046@qq.com; h15222898171@163.com
RI Xu, Longhao/HSG-6707-2023
OI Xu, Longhao/0000-0003-0040-7532
CR Bao-Wen C., 2020, Inf Commun, V10, P4
   BinGe H-B., 2020, Int J Autom Comput: English Edition, V17, P16
   CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1257, DOI 10.1109/31.7600
   Deng Xiao-Heng, 2014, Journal on Communications, V35, P216, DOI 10.3969/j.issn.1000-436x.2014.03.025
   Gottwald GA, 2005, PHYSICA D, V212, P100, DOI 10.1016/j.physd.2005.09.011
   He Z., 1999, J China Inst Commun, V20, P59
   Hu XY, 2018, NONLINEAR DYNAM, V91, P1541, DOI 10.1007/s11071-017-3963-6
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Lei T., 2020, Sci Technol Eng, V20, P12711
   Li F., 2020, J Hangzhou Univ Electron Sci Technol: Natural Science Edition, V40, P6
   Li MYL., 2021, J Northeast Normal Univ (Natural Science Edition), V53, P120
   Li W, 2021, OPT LASER ENG, V136, DOI 10.1016/j.optlaseng.2020.106319
   Li X., 2023, Electron Components Mater, V42, P103
   Ma CG, 2021, NONLINEAR DYNAM, V103, P2867, DOI 10.1007/s11071-021-06276-8
   Pan CX, 2021, IEEE T COMPUT AID D, V40, P521, DOI 10.1109/TCAD.2020.3002568
   Peng F, 2005, ACTA PHYS SIN-CH ED, V54, P4562, DOI 10.7498/aps.54.4562
   Quan QBJ., 2020, J Quanzhou Normal Coll, V38, P10
   Quan X., 2022, J Hubei Univ National (Natural Science Edition), V40, P163
   Shao H, 2022, J Guangxi Norm Univ (Natural Science Edition), P433, DOI [10.16088/j.issn.1001-6600.2020022803, DOI 10.16088/J.ISSN.1001-6600.2020022803]
   Shuxia Z., 2022, Sci Technol Eng, V013, P022
   Song W, 2020, INFORM SCIENCES, V518, P211, DOI 10.1016/j.ins.2020.01.009
   [孙克辉 Sun Kehui], 2013, [电子学报, Acta Electronica Sinica], V41, P1765
   Sun ZK, 2018, CHAOS, V28, DOI 10.1063/1.5019772
   Pham VT, 2020, RADIOENGINEERING, V29, P140, DOI 10.13164/re.2020.0140
   Wang WSR., 2017, J Phys, V66, P11
   Wang XY, 2010, COMMUN NONLINEAR SCI, V15, P124, DOI 10.1016/j.cnsns.2009.03.035
   Wang YZ, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/abd50f
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Xia G., 2023, Electron Components Mater, V42, P704
   Xiangqiu Z., 2021, Comput Eng, V47, P9
   Xiu CB, 2022, CHAOS SOLITON FRACT, V158, DOI 10.1016/j.chaos.2022.112040
   Xu WMJ, 2013, Electron Devices, V36, P6
   Yan S, 2022, Physica A: Statistical mechanics and its applications, V602
   Yan SH, 2021, PHYS SCRIPTA, V96, DOI 10.1088/1402-4896/ac379b
   Yanping Z., 2016, J Natural Sci Harbin Normal Univ, V32, P5
   Ye X., 2018, J Dalian Polytech Univ, V37, P71
   Zhang G., 2022, J Phys, V71, P10
   Zhang XH, 2018, IET CIRC DEVICE SYST, V12, P263, DOI 10.1049/iet-cds.2017.0052
   [张小红 Zhang Xiaohong], 2013, [计算机科学, Computer Science], V40, P262
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhou Feng GZ., 2003, Comput Technol Autom, V22, P3
   Zhu SQ, 2018, MULTIMED TOOLS APPL, V77, P29119, DOI 10.1007/s11042-018-6078-2
NR 44
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17089-9
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600002
DA 2024-07-18
ER

PT J
AU Wang, HY
   Tian, XJ
   Xia, Y
AF Wang, Huanying
   Tian, Xiaojie
   Xia, Yu
TI A robust dual color image blind watermarking scheme in the frequency
   domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Information security; Blind extraction; Color image; Image correction
ID ALGORITHM; TRANSFORM; DCT
AB Aiming at the problems that many watermarking schemes cannot adapt to the image copyright protection with large amount of information, and the copyright protection of color images faces severe challenges, this paper proposes a robust dual color image blind watermarking scheme in the frequency domain. The scheme uses nonsubsampled contourlet transform (NSCT)'s good multi-directivity and multi-scale, translation invariance and Schur decomposition stability and anti-aggression to balance the invisibility and robustness of the watermarking scheme. Firstly, the host image is transformed by layered NSCT to obtain the layered low frequency coefficient matrix, and non-overlapping 4 x 4 coefficient blocks are selected in the layered low-frequency coefficient matrix, and the maximum eigenvalue of the coefficient block is obtained by Schur decomposition, and Quantized index modulation (QIM) is applied to the maximum eigenvalue to embed watermark information. When extracting watermarks, if watermarked image is attacked by geometry, and use image correction algorithm based on perspective transform to preprocess the image, which mainly includes feature point detection, image correction and sawtooth processing. The simulation results show that the proposed scheme has strong robustness to common signal processing attacks, and stronger and more effective robustness to common geometric attacks. Compared with the existing dual color image blind watermarking schemes, the proposed scheme has better performance.
C1 [Wang, Huanying] Ludong Univ, Dept Educ & Informat Technol, Yantai 264025, Peoples R China.
   [Tian, Xiaojie; Xia, Yu] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University; Ludong University
RP Wang, HY (corresponding author), Ludong Univ, Dept Educ & Informat Technol, Yantai 264025, Peoples R China.
EM ldumaster@163.com
FU The work was supported by National Natural Science Foundations of China
   (No.61771231, 62171209), Key Project of Shandong Natural Science
   Foundation (No.ZR2020KF023), Shandong Big Data Development and
   Innovation Laboratory of Public Resources, and China Sch [61771231,
   62171209]; National Natural Science Foundations of China; Key Project of
   Shandong Natural Science Foundation; Shandong Big Data Development and
   Innovation Laboratory of Public Resources [202008370052]; China
   Scholarship Council
FX The work was supported by National Natural Science Foundations of China
   (No.61771231, 62171209), Key Project of Shandong Natural Science
   Foundation (No.ZR2020KF023), Shandong Big Data Development and
   Innovation Laboratory of Public Resources, and China Scholarship Council
   (202008370052).
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Ashraf I, 2017, IEEE ACCESS, V5, P8250, DOI 10.1109/ACCESS.2017.2699686
   Botta M, 2021, INFORM SCIENCES, V576, P228, DOI 10.1016/j.ins.2021.06.073
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen HY, 2012, J ZHEJIANG U-SCI C, V13, P573, DOI 10.1631/jzus.C1100338
   Chen Y, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108088
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gong LH, 2023, OPT LASER TECHNOL, V167, DOI 10.1016/j.optlastec.2023.109665
   Gul E, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118730
   Han SC, 2022, OPTIK, V268, DOI 10.1016/j.ijleo.2022.169832
   Hsu LY, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117134
   Kasapbasi MC, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-018-0848-4
   Li YM, 2021, INFORM SCIENCES, V551, P205, DOI 10.1016/j.ins.2020.11.020
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu DC, 2021, VISUAL COMPUT, V37, P2355, DOI 10.1007/s00371-020-01991-6
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Luo YL, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118133
   Luo YL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114272
   Mellimi S, 2021, PATTERN RECOGN LETT, V151, P222, DOI 10.1016/j.patrec.2021.08.015
   Molina A, 2017, IEEE T MICROW THEORY, V65, P1381, DOI 10.1109/TMTT.2016.2634001
   Muñoz D, 2019, IEEE LAT AM T, V17, P1326, DOI 10.1109/TLA.2019.8932342
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Prabha K, 2022, J KING SAUD UNIV-COM, V34, P2982, DOI 10.1016/j.jksuci.2020.04.003
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Saritas OF, 2023, MULTIMED TOOLS APPL, V82, P15475, DOI 10.1007/s11042-022-13928-3
   Shen YX, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114414
   Su QT, 2022, INT J INTELL SYST, V37, P7548, DOI 10.1002/int.22893
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Thomas R, 2022, INTELL AUTOM SOFT CO, V33, P879, DOI 10.32604/iasc.2022.024070
   Uruma K, 2019, SIGNAL PROCESS-IMAGE, V74, P266, DOI 10.1016/j.image.2018.12.011
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040548
   Wang KS, 2022, NEURAL COMPUT APPL, V34, P3811, DOI 10.1007/s00521-021-06642-y
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
   Zhou J., 2005, IEEE INT C IM PROC, P469, DOI DOI 10.1109/ICIP.2005.1529789
   Zhou NR, 2023, SIGNAL PROCESS, V211, DOI 10.1016/j.sigpro.2023.109107
NR 38
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16975-6
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200016
DA 2024-07-18
ER

PT J
AU Xiong, LY
   Deng, HZ
   Yi, H
   Huang, P
   Zhou, QY
AF Xiong, Li Yan
   Deng, Huizi
   Yi, Hu
   Huang, Peng
   Zhou, Qiyun
TI SFPANet: Separation and fusion pyramid attention network for crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Crowd counting; Dramatic scale variation; Spatial contextual; Channel
   attention
AB Crowd counting methods have become increasingly mature. However, the problem of dramatic scale variation still exists. For this reason, we propose an efficient separated and fused pyramid attention network, which can extract multiscale features on channels and space and greatly alleviate the problem of dramatic scale variation. First, in order to extract the rich features on the channel, we design a separated and fused channel attention module, which is composed of two 3x3 convolution layers, a separated attention module, and a SE module. Second, we design a spatial contextual feature fusion module to fully extract multiscale features in spatial dimensions. Finally, we conduct comparison experiments with state-of-the-art methods on several challenging datasets, including the ShanghaiTech, UCF_CC_50, and WorldExpo'10 datasets. The experimental results show our method outperforms most of the state-of-the-art methods. We conduct ablation experiments on the ShanghaiTech Part A and Part B datasets to verify the importance of each submodule.
C1 [Xiong, Li Yan; Deng, Huizi; Yi, Hu] East China Jiaotong Univ, Sch Informat Engn, Shuanggang East St, Nanchang 330013, Jiangxi, Peoples R China.
   [Huang, Peng] Jiangxi Prov Commun Investment Grp Co Ltd, Rd Network Operat Management Co, Shuanggang East St, Nanchang 330013, Jiangxi, Peoples R China.
   [Zhou, Qiyun] Jiangxi Univ Finance & Econ, Sch Software & Internet Things Engn, Shuanggang East St, Nanchang 330013, Jiangxi, Peoples R China.
C3 East China Jiaotong University; Jiangxi University of Finance &
   Economics
RP Deng, HZ (corresponding author), East China Jiaotong Univ, Sch Informat Engn, Shuanggang East St, Nanchang 330013, Jiangxi, Peoples R China.
EM 445935939@qq.com; 3372712106@qq.com; 2456871226@qq.com;
   365702240@qq.com; 2816480867@qq.com
RI wang, yan/GSE-6489-2022
FU This work was supported in part by the National Natural Science
   Foundation of China (Nos.62067002), and in part by the Science and
   Technology Project of Transportation Department of Jiangxi Province,
   China (Nos.2021X0011, 2022X0040). [62067002]; National Natural Science
   Foundation of China [2021X0011, 2022X0040]; Science and Technology
   Project of Transportation Department of Jiangxi Province, China
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos.62067002), and in part by the Science and
   Technology Project of Transportation Department of Jiangxi Province,
   China (Nos.2021X0011, 2022X0040).
CR Aldhaheri S, 2023, APPL INTELL, V53, P9285, DOI 10.1007/s10489-022-03954-x
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chen XY, 2019, IEEE WINT CONF APPL, P1941, DOI 10.1109/WACV.2019.00211
   Guo D, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1823, DOI 10.1145/3343031.3350881
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Hou Y, 2020, INT CONF ACOUST SPEE, P4072, DOI [10.1109/ICASSP40776.2020.9053955, 10.1109/icassp40776.2020.9053955]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Kingma D. P., 2014, arXiv
   Li B, 2021, PATTERN ANAL APPL, V24, P853, DOI 10.1007/s10044-021-00959-z
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2018, Arxiv, DOI arXiv:1807.00601
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YB, 2021, APPL INTELL, V51, P427, DOI 10.1007/s10489-020-01842-w
   Luan F-J, 2023, SPIE, V12642, P428
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Miao YQ, 2020, AAAI CONF ARTIF INTE, V34, P11765
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Varior RR, 2019, Arxiv, DOI arXiv:1901.06026
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Tang YY, 2015, NAT REV NEUROSCI, V16, P213, DOI 10.1038/nrn3916
   Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751
   Wang WX, 2022, APPL INTELL, V52, P1825, DOI 10.1007/s10489-021-02537-6
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu D, 2022, APPL INTELL, V52, P1376, DOI 10.1007/s10489-021-02470-8
   Yang X, 2021, P 5 INT C COMP SCI A
   Yu Xu, 2023, 2023 3rd International Conference on Neural Networks, Information and Communication Engineering (NNICE), P591, DOI 10.1109/NNICE58320.2023.10105713
   Yu Y, 2021, INT J MACH LEARN CYB, V12, P931, DOI 10.1007/s13042-020-01212-5
   Yutao Hu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P747, DOI 10.1007/978-3-030-58542-6_45
   Zeng X, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112977
   Zhai WZ, 2023, MULTIMEDIA SYST, V29, P3027, DOI 10.1007/s00530-021-00877-4
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang A, 2019, IEEE I CONF COMP VIS, P5713, DOI 10.1109/ICCV.2019.00581
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2018, IEEE WINT CONF APPL, P1113, DOI 10.1109/WACV.2018.00127
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou WJ, 2022, IEEE T CIRC SYST VID, V32, P1224, DOI 10.1109/TCSVT.2021.3077058
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2192, DOI 10.1109/TMM.2021.3077767
   Zhou WJ, 2021, IEEE T MULTIMEDIA, V23, P3388, DOI 10.1109/TMM.2020.3025166
   Zhou WJ, 2021, IEEE T SYST MAN CY-S, V51, P3641, DOI 10.1109/TSMC.2019.2957386
NR 47
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-17219-3
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200011
DA 2024-07-18
ER

PT J
AU Fang, H
   Xu, G
   Long, YF
   Guan, Y
   Yang, XY
   Chen, Z
AF Fang, Hui
   Xu, Ge
   Long, Yunfei
   Guan, Yin
   Yang, Xiaoyan
   Chen, Zhou
TI A system review on bootstrapping information extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Bootstrapping information extraction; Seed generation; Pattern learning;
   Instance acquisition; Pattern evaluation; Instance evaluation
ID PATTERNS
AB Focusing on the supervision problems caused by high-cost and low-quality labeling in information extraction, we provided a detailed overview of the various approaches that were proposed to solve the sub-tasks of bootstrapping information extraction. We summarized current principal approaches and depicted the specific issues addressed in recent research. To provide inspiration and reference for similar studies in terms of mainstream data sources, evaluation specifications and applications, we summarized the relevant datasets, evaluation metrics, and systematic applications of bootstrapping information extraction. In addition, we reflected on the remaining problems of bootstrapping information extraction and highlighted some directions for future work.
C1 [Fang, Hui; Xu, Ge; Guan, Yin; Yang, Xiaoyan; Chen, Zhou] Minjiang Univ, Coll Comp & Control Engn, Fujian Prov Key Lab Informat Proc & Intelligent Co, 200 Xiyuangong Rd, Fuzhou 350108, Fujian, Peoples R China.
   [Long, Yunfei] Univ Essex, Sch Comp Sci & Elect Engn, Wivenhoe Pk, Colchester CO2 8JT, Essex, England.
C3 Minjiang University; University of Essex
RP Fang, H (corresponding author), Minjiang Univ, Coll Comp & Control Engn, Fujian Prov Key Lab Informat Proc & Intelligent Co, 200 Xiyuangong Rd, Fuzhou 350108, Fujian, Peoples R China.
EM fh_mju@126.com; xuge@pku.edu.cn; yl20051@essex.ac.uk;
   niynaug@foxmail.com; 349622662@qq.com; 1801619490@qq.com
RI LONG, YUNFEI/O-5784-2019
OI LONG, YUNFEI/0000-0002-4407-578X; , Hui/0000-0002-4924-5012
FU Fujian Mental Health Human-Computer Interaction Technology Research
   Center [2020L3024]; Central Leading Local Project "Fujian Mental Health
   Human-Computer Interaction Technology Research Center
FX This research is supported by the following projects: Central Leading
   Local Project "Fujian Mental Health Human-Computer Interaction
   Technology Research Center", under the authorization number 2020L3024.
CR Abdullah MHA, 2023, IEEE Access
   Abe N., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P1
   Abney S, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P360
   Agichtein E., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P85, DOI 10.1145/336597.336644
   Alashri S, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON DATA INTELLIGENCE AND SECURITY (ICDIS 2018), P234, DOI 10.1109/ICDIS.2018.00045
   Alba A, 2017, K-CAP 2017: PROCEEDINGS OF THE KNOWLEDGE CAPTURE CONFERENCE, DOI 10.1145/3148011.3148021
   [Anonymous], 2009, P 18 INT C WORLD WID, DOI DOI 10.1145/1526709.1526724
   Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [10.1080/1364557032000119616, DOI 10.1080/1364557032000119616]
   Banko M., 2008, P ACL 08 HLT, P28
   Bart Robert, 2012, P C EMP METH NAT LAN, P523
   Batista DS, 2015, P 2015 C EMP METH NA, P499
   Bhutani N., 2016, P 2016 C EMP METH NA, P55
   Brin S, 1999, LECT NOTES COMPUT SC, V1590, P172
   Canisius S, 2007, P 2007 JOINT C EMPIR, P827
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Chen C, 2012, P 6 INT C UBIQUITOUS, P1
   Chen M, 2022, P 2022 C N AM CHAPTE, P14, DOI [10.18653/v1/2022.naacl-tutorials.3.https://aclanthology.org/2022.naacl, DOI 10.18653/V1/2022.NAACL-TUTORIALS.3.HTTPS://ACLANTHOLOGY.ORG/2022.NAACL]
   Chen PY, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P189, DOI 10.1145/3041021.3054729
   Cheng J, 2021, KSII Trans Internet Inf Syst, V15
   Cheng Z, 2014, Research on named entity recognition and relation extraction facing to domain-oriented knowledge base construction
   Cheng ZG, 2013, INT CONF MACH LEARN, P45, DOI 10.1109/ICMLC.2013.6890442
   Chunxia Zhang, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1290, DOI 10.1109/FSKD.2012.6234350
   Curran J. R, 2007, P 10 C PAC ASS COMP, V6, P172
   Dalvi Bhavana, 2016, P 5 WORKSHOP AUTOMAT, P12
   Deepika SS, 2021, ENG APPL ARTIF INTEL, V99, DOI 10.1016/j.engappai.2020.104130
   Deng Bo, 2007, Computer Engineering, V33, P212
   Ding H, 2018, P C N AM CHAPT ASS C, V1, P1919, DOI DOI 10.18653/V1/N18-1174
   Doumari SA, 2023, Comput Math Methods Med
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Etzioni O, 2008, COMMUN ACM, V51, P68, DOI 10.1145/1409360.1409378
   Feng X, 2016, Research and application of chinese comparative sentence elements extraction technique
   FengYingHui, 2016, Research on information extraction techniques for tibetan cultural field
   Gao TY, 2020, AAAI CONF ARTIF INTE, V34, P7772
   Gentile AL, 2019, LECT NOTES COMPUT SC, V11503, P131, DOI 10.1007/978-3-030-21348-0_9
   Gupta S., 2014, Proceedings of the Eighteenth Conference on Computational Natural Language Learning, P98
   He Yifan., 2015, P 2015 C N AM CHAPTE, P31, DOI 10.3115/v1/N15-3007
   Huang JX, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2188, DOI 10.1145/3366423.3380284
   Ji J, 2015, A grammar and dependency information based relation extraction system for streaming data
   Ji JS, 2014, IEEE I C NETW INFRAS, P117, DOI 10.1109/ICNIDC.2014.7000277
   Kirsch B, 2020, COMM COM INF SC, V1168, P63, DOI 10.1007/978-3-030-43887-6_6
   Komachi Mamoru., 2008, Proceedings of the Conference on Empirical Methods in Natural Language Processing, P1011
   Kozareva Z, 2012, P COLING 2012 POSTER, P599
   Landolsi MY, 2023, KNOWL INF SYST, V65, P463, DOI 10.1007/s10115-022-01779-1
   Li PF, 2016, ACM T ASIAN LOW-RESO, V16, DOI 10.1145/2994600
   Li SY, 2012, 2011 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), VOLS 1-4, P1740
   Li Wei-gang, 2007, Acta Electronica Sinica, V35, P2111
   Li YF, 2023, Arxiv, DOI arXiv:2305.03827
   Li ZX, 2018, IEEE T KNOWL DATA EN, V30, P852, DOI 10.1109/TKDE.2017.2782697
   Liang JQ, 2021, PROC INT CONF DATA, P49, DOI 10.1109/ICDE51399.2021.00012
   Lin HT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1073, DOI 10.1145/3308558.3313573
   Liu Y, 2014, The information gain based binary entity relationship extraction on web corpus
   Long LY, 2014, PROCESSING OF 2014 INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INFORMATION INTEGRATION FOR INTELLIGENT SYSTEMS (MFI)
   Makarov P, 2018, P 2 JOINT SIGHUM WOR, P103
   McNeil N, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P60, DOI 10.1109/ICMLA.2013.106
   Menhour H, 2023, J INF SCI, V49, P335, DOI 10.1177/01655515211000642
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Momtazi S, 2019, SCI IRAN, V26, P26, DOI 10.24200/sci.2018.20198
   Novotn V, 2023, arXiv
   Omurca SI, 2023, APPL INTELL, V53, P15295, DOI 10.1007/s10489-022-04306-5
   Pantel P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P113
   Phi V-T, 2016, P 30 PACIFIC ASIA C, P173
   Qadir A, 2012, SEM 2012 1 JOINT C L, P199
   Qichen H., 2018, Chin J Inf, V32, P1
   Rahman S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502068
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   Rondon Alexandre, 2015, P 11 WORKSH MULT EXP, P45
   Rosenfeld B, 2006, P COLINGACL 2006 MAI, P667
   Saha S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P317, DOI 10.18653/v1/P17-2050
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Shi B, 2014, A probabilistic co-bootstrapping method for entity set expansion
   Sijia C, 2014, Research on entity relationship extraction
   Tai L, 2017, P 2017 2 INT C COMMU, P324
   Tai L-T, 2018, Research on entity relation extraction algorithm based on semi-supervised machine learning
   Tandon N, 2012, P COLING 2012 DEMONS, P439
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   Thomas A, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.108956
   Tuo JY, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P212, DOI 10.1109/ICISCE.2017.54
   Phi VT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P89
   Vechtomova O, 2012, P 1 JOINT INT WORKSH, P1
   Wang Q, 2017, Research on entity relationship extraction based on convolutional neural network
   Wu WT, 2017, IEEE T KNOWL DATA EN, V29, P446, DOI 10.1109/TKDE.2016.2619347
   Wu Z, 2019, Research and application on content understanding algorithm for conditional semi-structured text
   Xia X, 2014, Research on semi-supervised chinese event extraction
   Xiong G, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
   Yada S, 2017, INT CONF DAT MIN WOR, P414, DOI 10.1109/ICDMW.2017.60
   Yahya M., 2014, Proc. EMNLP'14, P325, DOI DOI 10.3115/V1/D14-1038
   Yan LY, 2021, Arxiv, DOI arXiv:2109.12082
   Yan LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P292
   Yan LY, 2020, AAAI CONF ARTIF INTE, V34, P9402
   Yan Lingyong, 2002, FINDINGS ASS COMPUTA, P3705
   Yang CM, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01908-4
   Yang Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199691
   Ye FY, 2014, INT SYM COMPUT INTEL, P568, DOI 10.1109/ISCID.2014.154
   Yildirim S, 2012, P COLING 2012 DEMONS, P493
   Yurtsever MME, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6529
   Zhang C, 2013, P 6 INT JOINT C NATU, P293
   Zhang CY, 2015, KNOWL-BASED SYST, V86, P278, DOI 10.1016/j.knosys.2015.06.012
   Zhang CY, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P609, DOI 10.1109/ISCSLP.2014.6936605
   Zhang T, 2022, EVID-BASED COMPL ALT
   Zhang YY, 2020, Arxiv, DOI arXiv:2004.13897
   Zhao H, 2018, PROCEEDINGS OF THE 2018 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'18), P155, DOI 10.1145/3234944.3234966
   Zhou SW, 2022, Arxiv, DOI arXiv:2205.11725
   Zhuang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5608
   Ziering P, 2013, P 6 INT JOINT C NATU, P1321
   Ziering P, 2013, P 6 INT JOINT C NATU, P844
   Zupon A., 2019, P 3 WORKSH STRUCT PR, P18
NR 106
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17005-1
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900015
DA 2024-07-18
ER

PT J
AU Arora, I
   Gangadharappa, M
AF Arora, Ishita
   Gangadharappa, M.
TI SRFCNM: Spatiotemporal recurrent fully convolutional network model for
   salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Fully convolutional network (FCN); Salient object
   detection (SOD); Synthetic video data video saliency
ID OPTIMIZATION; MOTION
AB Video saliency detection has recently been widely used because of its ability to distinguish significant regions of interest. It has several applications, such as video segmentation, abnormal activity detection, video summarization, etc. This research paper develops a novel technique for video saliency detection known as Spatiotemporal Recurrent Fully Convolutional Network Model (SRFCNM). This model uses recurrent convolutional layers to represent spatial and temporal features of superpixels for element uniqueness. The model is trained in two phases; initially, we pre-train the model on the segmented data sets and then fine-tune it for saliency detection, which allows the network to learn salient objects more accurately. The uniqueness of integrating saliency maps with recurrent convolutional layers and spatiotemporal characteristics facilitates the robust representation of salient objects to capture the relevant features. The SRFCNM model is extensively estimated on the challenging datasets viz. SegTrackV2, FBMS and DAVIS. Our model is compared with the existing Deep Learning and Convolutional Neural Network algorithms. This research demonstrates that SRFCNM outperforms the state-of-the-art saliency models considerably over the three public datasets regarding accuracy recall and mean absolute error (MAE). The proposed SRFCNM model produces the lowest MAE values, 3.2%, 3.5%, and 7.5%, for SegTrackV2, DAVIS, and FBMS datasets, respectively, with hand-crafted color features, compared with the existing models.
C1 [Arora, Ishita] AIACTR, GGSIPU, Dept Elect & Commun, Delhi 110031, India.
   [Gangadharappa, M.] NSUT, Dept Elect & Commun Engn, East Campus, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology;
   Netaji Subhas University of Technology (East Campus); Netaji Subhas
   University of Technology
RP Arora, I (corresponding author), AIACTR, GGSIPU, Dept Elect & Commun, Delhi 110031, India.
EM ishitaarora202@gmail.com; gangadharaccess@gmail.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chang QY, 2021, Arxiv, DOI arXiv:2105.04213
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YH, 2018, IEEE T IMAGE PROCESS, V27, P3345, DOI 10.1109/TIP.2018.2813165
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Fu KR, 2018, NEUROCOMPUTING, V275, P788, DOI 10.1016/j.neucom.2017.09.028
   Gastal ESL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185529
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Huang K, 2020, NEUROCOMPUTING, V403, P325, DOI 10.1016/j.neucom.2020.04.015
   Huang K, 2020, VISUAL COMPUT, V36, P1355, DOI 10.1007/s00371-019-01734-2
   Huang LL, 2019, IEEE ACCESS, V7, P166203, DOI 10.1109/ACCESS.2019.2953046
   Huang LM, 2022, IEEE T CIRC SYST VID, V32, P1366, DOI 10.1109/TCSVT.2021.3069812
   Ji YZ, 2021, IEEE T NEUR NET LEAR, V32, P2676, DOI 10.1109/TNNLS.2020.3007534
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jian MW, 2021, INFORM SCIENCES, V576, P819, DOI 10.1016/j.ins.2021.08.069
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li GB, 2018, PROC CVPR IEEE, P3243, DOI 10.1109/CVPR.2018.00342
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Li J, 2018, IEEE T IMAGE PROCESS, V27, P349, DOI 10.1109/TIP.2017.2762594
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Liang J, 2018, PATTERN RECOGN, V76, P476, DOI 10.1016/j.patcog.2017.11.024
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mahamud S, 2003, IEEE T PATTERN ANAL, V25, P433, DOI 10.1109/TPAMI.2003.1190570
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pan HY, 2016, Arxiv, DOI arXiv:1602.00577
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sajid H, 2019, SIGNAL PROCESS-IMAGE, V75, P11, DOI 10.1016/j.image.2019.03.003
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2014, Arxiv, DOI arXiv:1406.2199
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tang L, 2022, IEEE T CIRC SYST VID, V32, P5453, DOI 10.1109/TCSVT.2022.3150923
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2019, IEEE T PATTERN ANAL, V41, P1734, DOI 10.1109/TPAMI.2018.2846598
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao F, 2018, SIGNAL PROCESS, V144, P392, DOI 10.1016/j.sigpro.2017.10.019
   Xu CC, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107433
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Yang B, 2017, NEUROCOMPUTING, V221, P60, DOI 10.1016/j.neucom.2016.09.062
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang QD, 2022, IEEE T CIRC SYST VID, V32, P6543, DOI 10.1109/TCSVT.2022.3171563
   Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 73
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17009-x
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500011
DA 2024-07-18
ER

PT J
AU Kumar, Y
   Guleria, V
AF Kumar, Yashavant
   Guleria, Vandana
TI Mixed-multiple image encryption algorithm using RSA cryptosystem with
   fractional discrete cosine transform and 2D-Arnold Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mixed image elements; RSA cryptosystem; Big image; Fractional discrete
   cosine transform; Mixed image; 2D-Arnold Transform
ID OPTICAL ENCRYPTION; ARNOLD TRANSFORM; CHAOTIC SYSTEM; MAP; TRUNCATION;
   SECURITY; DOMAIN; 3D
AB This paper presents a novel multiple-image encryption (MIE) technique based on mixed image elements associated with RSA cryptosystem, fractional discrete cosine transform (FrDCT) and 2D-Arnold transform (AT). Firstly, we combine k-original images into a big image using knowledge of matrix theory. The big image is extracted into three components, i.e., red (R), green (G) and blue (B). The RSA cryptographic scheme is applied to each component R, G and B individually. Secondly, the FrDCT is used on each component with individual fractions. Thirdly, the 2D-AT is applied on three components to enhance the security as well as the key space. Finally, three components are concatenated to generate a final encrypted image. The resulting cipher image is a single-channel real-valued image that is easy to display, store and transmit over an unsecured network. The proposed algorithm offers multi-layered security in frequency, time and coordinate domains. Security of the presented MIE technique depends on both secrete keys and their proper arrangement. Simulation analysis and their results support the robustness and appropriateness of the introduced encryption technique. Sensitivity analysis confirms that the introduced technique is extremely sensitive to its private keys and their arrangement. The effectiveness and viability of our proposed cryptosystem are confirmed by statistical analysis, including MSE, PSNR, SSIM, entropy analysis, noise attack, correlation coefficient, occlusion attack analysis, histogram analysis, UACI, NPCR, classic types of attacks and comparison analysis. The proposed algorithm is proved to be very effective and secure for real-world image encryption, which is supported by the experimental results and algorithm analysis.
C1 [Kumar, Yashavant; Guleria, Vandana] Birla Inst Technol Mesra, Dept Math, Ranchi 835215, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi 835215, India.
EM vandana.math@gmail.com
FU One of the authors, Yashavant Kumar, would like to acknowledge the
   financial assistance provided by the Birla institute of technology,
   Mesra, Ranchi.; Birla institute of technology, Mesra, Ranchi
FX One of the authors, Yashavant Kumar, would like to acknowledge the
   financial assistance provided by the Birla institute of technology,
   Mesra, Ranchi.
CR Abuturab MR, 2021, OPT COMMUN, V493, DOI 10.1016/j.optcom.2021.127034
   Abuturab MR, 2015, OPT COMMUN, V343, P157, DOI 10.1016/j.optcom.2014.12.085
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Chen H, 2019, OPT LASER ENG, V112, P7, DOI 10.1016/j.optlaseng.2018.08.020
   Chen H, 2016, SPECTROSC LETT, V49, P103, DOI 10.1080/00387010.2015.1089447
   Chen H, 2013, OPT LASER ENG, V51, P768, DOI 10.1016/j.optlaseng.2013.01.016
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   Deb S, 2019, MULTIMED TOOLS APPL, V78, P34901, DOI 10.1007/s11042-019-08086-y
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hahn J, 2006, OPT EXPRESS, V14, P11103, DOI 10.1364/OE.14.011103
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Huang LQ, 2019, OPT LASER ENG, V115, P7, DOI 10.1016/j.optlaseng.2018.11.015
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Joshi M, 2007, OPT COMMUN, V279, P35, DOI 10.1016/j.optcom.2007.07.012
   Karawia AA, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20100801
   Kaur M, 2018, IMAGING SCI J, V66, P453, DOI 10.1080/13682199.2018.1505327
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Li YB, 2015, OPT LASER ENG, V72, P18, DOI 10.1016/j.optlaseng.2015.03.027
   Liu H, 2013, OPT LASER TECHNOL, V50, P1, DOI 10.1016/j.optlastec.2013.02.003
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501734
   Liu HJ, 2019, OPT LASER ENG, V122, P123, DOI 10.1016/j.optlaseng.2019.05.027
   Liu HJ, 2019, APPL MATH COMPUT, V360, P83, DOI 10.1016/j.amc.2019.04.078
   Liu ST, 2001, OPT LETT, V26, P1242, DOI 10.1364/OL.26.001242
   Liu ZJ, 2007, OPT LETT, V32, P2088, DOI 10.1364/OL.32.002088
   Liu ZJ, 2018, OPT LASER ENG, V105, P1, DOI 10.1016/j.optlaseng.2017.12.007
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Mir UH, 2022, INF SECUR J, V31, P49, DOI 10.1080/19393555.2021.1963018
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Mishra DC, 2016, INF SECUR J, V25, P213, DOI 10.1080/19393555.2016.1241323
   Sabir S, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108609
   Shi XY, 2013, OPT COMMUN, V306, P90, DOI 10.1016/j.optcom.2013.05.041
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Tanveer M, 2021, IEEE ACCESS, V9, P73924, DOI 10.1109/ACCESS.2021.3081362
   Wang XG, 2011, OPT COMMUN, V284, P4441, DOI 10.1016/j.optcom.2011.06.025
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2021, INFORM SCIENCES, V569, P217, DOI 10.1016/j.ins.2021.04.013
   Wu JH, 2014, OPTIK, V125, P4474, DOI 10.1016/j.ijleo.2014.02.026
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Xian YJ, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106202
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yong-Liang XA, 2011, OPT LASER TECHNOL, V43, P889, DOI 10.1016/j.optlastec.2010.10.003
   You SP, 2015, OPT COMMUN, V355, P419, DOI 10.1016/j.optcom.2015.07.014
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu GL, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2931495
   Zhu K, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540028
   Zhu Wei, 2014, Journal of Nanjing University of Posts and Telecommunications, V34, P87
NR 57
TC 1
Z9 1
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16953-y
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500019
DA 2024-07-18
ER

PT J
AU da Silva, CAS
   Krohling, RA
AF da Silva, Carlos A. S.
   Krohling, Renato A.
TI An extreme learning machine algorithm for semi-supervised classification
   of unbalanced data streams with concept drift
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Semi-supervised learning; Extreme learning machine
   (ELM); Data streams; Concept drift; Unbalanced datasets
ID EVOLUTIONARY
AB Data streams are important sources of information nowadays, and with the popularization of mobile devices and sensor systems that collect all kinds of data, more and more information is generated at an ever increasing speed. This growth in data supply poses some problems for traditional machine learning algorithms. Tasks such as data classification, regression, or data clustering presents some limitations regarding very large datasets, data streams, or variations in data. The high cost of labeling instances for training classification algorithms makes it difficult to use fully supervised algorithms. Unbalanced datasets tend to cause algorithms to ignore one or more classes. Moreover, concept drifts in data streams require algorithms to be retrained from time to time. In order to tackle such problems mentioned, a semi-supervised and online algorithm based on Extreme Learning Machine (ELM) called SSOE-FP-ELM is proposed and detailed. Experimental results show that the proposed algorithm outperform others in the literature in accuracy, generalization ability and concept drift detection and recovery, showing suitable alternatives for data streams classification.
C1 [da Silva, Carlos A. S.] Fed Inst Espirito Santo, Informat Dept, BR-29500000 Alegre, ES, Brazil.
   [Krohling, Renato A.] Univ Fed Espirito Santo, LABCIN, Prod Engn Dept, BR-29075910 Vitoria, ES, Brazil.
   [Krohling, Renato A.] Fed Univ Espirito Santo UFES, Grad Program Comp Sci, BR-29075910 Vitoria, ES, Brazil.
C3 Instituto Federal do Espirito Santo (IFES); Universidade Federal do
   Espirito Santo; Universidade Federal do Espirito Santo
RP da Silva, CAS (corresponding author), Fed Inst Espirito Santo, Informat Dept, BR-29500000 Alegre, ES, Brazil.
EM carlosalexandress@gmail.com; krohling.renato@gmail.com
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq); Fundacao de Amparo a Pesquisa e Inovacao do Espirito
   Santo (FAPES); NVIDIA Corporation;  [309729/2018-1];  [575/2018]
FX This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001. R.A.
   Krohling would like to thank the Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq) - grant n. 309729/2018-1 - and the
   Fundacao de Amparo a Pesquisa e Inovacao do Espirito Santo (FAPES) -
   grant n. 575/2018. The authors would like to thank the support of NVIDIA
   Corporation with the donation of the Titan X GPU used for this research.
CR Agrahari S, 2022, J KING SAUD UNIV-COM, V34, P9523, DOI 10.1016/j.jksuci.2021.11.006
   Akusok A, 2015, IEEE ACCESS, V3, P1011, DOI 10.1109/ACCESS.2015.2450498
   Anderson R, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112832
   [Anonymous], 2005, ADV NEURAL INF PROCE
   Bartlett PL, 1998, IEEE T INFORM THEORY, V44, P525, DOI 10.1109/18.661502
   Ben-Israel A., 2003, Generalized Inverses: Theory and Applications
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Budiman A, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/8091267
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   da Costa FG, 2016, EXPERT SYST APPL, V60, P39, DOI 10.1016/j.eswa.2016.04.026
   da Silva CAS, 2019, IEEE IJCNN
   daSilva CAS, 2018, 2018 IEEE IJCNN INT, P1511, DOI [10.1109/IJCNN.2018.8489632, DOI 10.1109/IJCNN.2018.8489632]
   Derrac J, 2011, SWARM EVOL COMPUT, V1, P3, DOI 10.1016/j.swevo.2011.02.002
   du Prel JB, 2010, DTSCH ARZTEBL INT, V107, P343, DOI 10.3238/arztebl.2010.0343
   Dua D, 2019, UCI MACHINE LEARNING
   Fan RE, 2019, LIBSVM Data: classification, regression, and multi-label
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Gu XW, 2023, APPL SOFT COMPUT, V136, DOI 10.1016/j.asoc.2023.110053
   Han F, 2013, NEUROCOMPUTING, V116, P87, DOI 10.1016/j.neucom.2011.12.062
   HAYASHI Y, 1990, INTERNATIONAL NEURAL NETWORK CONFERENCE, VOLS 1 AND 2, P781
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Huang G, 2014, IEEE T CYBERNETICS, V44, P2405, DOI 10.1109/TCYB.2014.2307349
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jia XB, 2016, NEUROCOMPUTING, V174, P168, DOI 10.1016/j.neucom.2015.04.102
   Lei YX, 2020, NEUROCOMPUTING, V381, P186, DOI 10.1016/j.neucom.2019.11.012
   Li L, 2019, MULTIMED TOOLS APPL, V78, P33375, DOI 10.1007/s11042-019-7543-2
   Li QD, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115591
   Li YC, 2019, PATTERN RECOGN, V88, P383, DOI 10.1016/j.patcog.2018.11.006
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Liu D, 2016, NEUROCOMPUTING, V207, P322, DOI 10.1016/j.neucom.2016.04.043
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Ma L, 2016, PATTERN RECOGN LETT, V83, P133, DOI 10.1016/j.patrec.2016.01.022
   Barros RSM, 2018, INFORM SCIENCES, V451, P348, DOI 10.1016/j.ins.2018.04.014
   de Barros RSM, 2018, NEUROCOMPUTING, V275, P1954, DOI 10.1016/j.neucom.2017.10.051
   Nene S.A, 1996, COIL-100)
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   PAO YH, 1994, NEUROCOMPUTING, V6, P163, DOI 10.1016/0925-2312(94)90053-1
   PAO YH, 1992, COMPUTER, V25, P76, DOI 10.1109/2.144401
   Qiu SY, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892701
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sawant SS, 2020, EGYPT J REMOTE SENS, V23, P243, DOI 10.1016/j.ejrs.2018.11.001
   SCHMIDT WF, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P1, DOI 10.1109/ICPR.1992.201708
   Sethi TS, 2017, EXPERT SYST APPL, V82, P77, DOI 10.1016/j.eswa.2017.04.008
   Tsymbal Alexey, 2004, COMPUTER SCI DEP TRI, V106, P58
   Vanschoren Joaquin, 2013, SIGKDD Explorations, V15, P49, DOI DOI 10.1145/2641190.2641198
   Wang H., 2015, Proceedings of the 2015 International Joint Conference on Neural Networks
   Wang J, 2022, MULTIMED TOOLS APPL, V81, P41611, DOI 10.1007/s11042-021-11007-7
   Xie J, 2019, NEUROCOMPUTING, V355, P24, DOI 10.1016/j.neucom.2019.03.079
   Xin JC, 2015, NEUROCOMPUTING, V149, P464, DOI 10.1016/j.neucom.2013.09.075
   Xu SL, 2017, NEUROCOMPUTING, V238, P433, DOI 10.1016/j.neucom.2016.12.078
   Yan J, 2021, IEEE SENS J, V21, P3635, DOI 10.1109/JSEN.2020.3028579
   Yang Z, 2016, PR MACH LEARN RES, V48
   Zhang ZJ, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119164
   Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003
   Zheng XL, 2022, BIG DATA RES, V30, DOI 10.1016/j.bdr.2022.100356
NR 57
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17039-5
EA OCT 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100016
DA 2024-07-18
ER

PT J
AU Jha, P
   Dembla, D
   Dubey, W
AF Jha, Pradeep
   Dembla, Deepak
   Dubey, Widhi
TI Deep learning models for enhancing potato leaf disease prediction:
   Implementation of transfer learning based stacking ensemble model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DNN; Transfer learning; ResNet; MobileNet; Inception; Potato; Ensemble
   model; Deep stacking approach
AB MotivationCrop diseases pose a critical threat to global food security, causing substantial agricultural yield losses. Manual disease identification is labor-intensive and requires expertise, hindering timely and accurate detection.Problem GapTraditional methods for identifying plant diseases are time-consuming and demand specialized knowledge. The need for a more efficient, automated, and accurate approach is evident to minimize crop losses and ensure food security.ContributionThis research paper addresses the challenge of plant disease detection by proposing a novel approach that combines image processing and deep learning techniques. The primary contribution is a sophisticated deep neural network ensemble model, which integrates Residual Network, MobileNet, and Inception models. This ensemble architecture is designed to maximize accuracy and robustness in disease classification. The model is trained on an extensive dataset containing images of both healthy and infected potato leaves. It accomplishes the precise categorization of leaves into three classes: healthy potato leaves, infected potato leaves (two classes). The model's proficiency lies in its ability to discern intricate leaf features, colors, and types, enabling it to differentiate between healthy and potentially diseased leaves. This research makes a significant contribution to the development of automated disease detection systems. By bridging the gap between manual identification and advanced technology, it presents a promising solution for early disease detection and prevention. Ultimately, this approach can foster increased agricultural productivity, ensuring enhanced food security on a global scale.ResultsResults demonstrate the proposed model's effectiveness, achieving an impressive overall accuracy of 98.86%. This high accuracy attests to the model's competence in precisely detecting and classifying potato diseases. By harnessing the potential of ensemble-based deep learning and image processing, this research introduces an innovative tool for agriculturalists and researchers.
C1 [Jha, Pradeep] JECRC Univ, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Dembla, Deepak] JECRC Univ, Dept Comp Applicat, Jaipur 303905, Rajasthan, India.
   [Dubey, Widhi] JECRC Univ, Dept Bot, Jaipur, Rajasthan, India.
RP Jha, P (corresponding author), JECRC Univ, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM pradeep.jha1988@gmail.com; dembla.deepak@gmail.com;
   widhi.dubey@jecrcu.edu.in
RI Dembla, Prof.Deepak/J-3039-2019; Jha, Dr.Pradeep/KQV-3218-2024; dubey,
   widhi/KJM-4720-2024
OI Dembla, Prof.Deepak/0000-0003-0741-3935; Jha,
   Dr.Pradeep/0009-0007-9005-2574; dubey, widhi/0000-0002-5296-9388
CR Ali MH, 2020, Computers and Electronics in Agriculture, V178
   [Anonymous], 2022, Global Food Security Index
   Bangari Sindhuja, 2022, 2022 Second International Conference on Artificial Intelligence and Smart Energy (ICAIS), P144, DOI 10.1109/ICAIS53314.2022.9742963
   Dembla D, 2023, IEEE 3 INT C ART INT
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Khan Adnan, 2022, Chemo Intell Lab Systems
   Kukreja Vinay, 2021, 2021 8th International Conference on Signal Processing and Integrated Networks (SPIN), P967, DOI 10.1109/SPIN52536.2021.9566079
   Lee TY., 2021, SN Comput Sci, V2, P297, DOI [10.1007/s42979-021-00691-9, DOI 10.1007/S42979-021-00691-9]
   Ma F., 2021, Information Processing in Agriculture, V8, P31
   Maity D., 2022, Plant Dis, V106, P271
   Nishad Md Ashiqur Rahaman, 2022, Procedia Computer Science, P220, DOI 10.1016/j.procs.2022.11.006
   Oishi Y, 2021, INT J APPL EARTH OBS, V104, DOI 10.1016/j.jag.2021.102509
   Padhy R, 2020, Computers and Electronics in Agriculture, V179
   Qu M., 2020, J Intelligent Fuzzy Systems, V38, P1077
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Salem A., 2019, Plant Dis, V103, P2394
   Sarkar A, 2020, Computers and Electronics in Agriculture, V175
   Shariff NNM., 2021, J Computer Sci Technol, V21, P185
   Surya SS., 2022, Computers Electron Agricul, V191, P106324
   Vallabhajosyula S, 2022, J PLANT DIS PROTECT, V129, P545, DOI 10.1007/s41348-021-00465-8
   Wang X, 2020, Remote Sensing, V12, P2813
   Xiao YL, 2019, INFORMATION, V10, DOI 10.3390/info10110356
   Zaman MS., 2021, Computers Electronics in Agricul, V182, P106042
   Zhou M., 2020, IEEE Access, V8, P18952
NR 24
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-16993-4
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100005
DA 2024-07-18
ER

PT J
AU Chen, X
   Li, DY
   Tang, YM
   Huang, SS
   Wu, YQ
   Wu, YT
AF Chen, Xing
   Li, Danyang
   Tang, Yumei
   Huang, Shisong
   Wu, Yiqing
   Wu, Yating
TI Pairwise dependency-based robust ensemble pruning for facial expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Facial expression recognition; Classifier ensemble pruning; Classifier
   dependency; 1-norm
ID DIVERSITY; NETWORK
AB Facial expression recognition is crucial in analyzing an individual's emotional state. Ensemble pruning becomes essential to enhance the effectiveness of this recognition by selecting appropriate classifiers from a pool of base classifiers. However, outliers and noise within the classifiers can adversely affect the final recognition results and the generalization performance of the selected subset of classifiers. Additionally, effectively combining accuracy and low redundancy of base classifiers remains a challenging problem that requires further investigation. In this paper, we propose a novel algorithm called Pairwise Dependency-based Robust Ensemble Pruning (PDREP) to address these issues. The PDREP algorithm treats the predicted results of classifiers for sample instances as features of the classifier and evaluates their dependencies between pairs of classifiers using mutual information. By incorporating this dependency measure into the regression-based objective equation, we can assess the redundancy of a subset of base classifiers and prune redundant classifiers. We use the l(2,1-)norm in PDREP's objective equation to perform robust classifier pruning while considering the base classifiers' dependencies and accuracy. Furthermore, we introduce weight control parameters to balance accuracy and dependencies, facilitating the elimination of ineffective and redundant classifiers. The results show significant improvements when evaluating the proposed method's recognition accuracy on five public face sentiment datasets (FER2013, JAFFE, CK+, RaFD, and KDEF). Specifically, the proposed method achieves 3.15%, 9.39%, 1.72%, 3.70%, and 4.70% higher accuracy than integrating all base classifiers, respectively. Extensive experiments conducted on five facial expression datasets demonstrate that the proposed method consistently outperforms existing state-of-the-art ensemble pruning algorithms in most cases.
C1 [Chen, Xing; Li, Danyang; Tang, Yumei; Huang, Shisong; Wu, Yiqing; Wu, Yating] Guizhou Univ, Coll Big Data & Informat Engn, Jiaxiu South Rd, Guiyang 550025, Guizhou, Peoples R China.
C3 Guizhou University
RP Li, DY (corresponding author), Guizhou Univ, Coll Big Data & Informat Engn, Jiaxiu South Rd, Guiyang 550025, Guizhou, Peoples R China.
EM chenstar8@foxmail.com; danyangcl@163.com; tym5894237@163.com;
   sshuangyyds@gmail.com; yq_wu517@foxmail.com; 20300631@qq.com
RI 汤, 玉梅/HJY-9567-2023; danyang, li/GLT-1067-2022
OI 汤, 玉梅/0000-0002-8038-1186; 
FU This work was supported by the Science and Technology Plan Project of
   Guizhou Province (Qiankehe Platform Talents [2018] 5781) and was
   supported by the Guizhou Provincial Science and Technology Plan Project
   (Qiankehe Support [2023] General 251). [[2018] 5781]; Science and
   Technology Plan Project of Guizhou Province (Qiankehe Platform Talents)
   [251]; Guizhou Provincial Science and Technology Plan Project (Qiankehe
   Support [2023] General)
FX This work was supported by the Science and Technology Plan Project of
   Guizhou Province (Qiankehe Platform Talents [2018] 5781) and was
   supported by the Guizhou Provincial Science and Technology Plan Project
   (Qiankehe Support [2023] General 251).
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Chirra VRR, 2021, J AMB INTEL HUM COMP, V12, P10581, DOI 10.1007/s12652-020-02866-3
   Dai Q, 2017, APPL SOFT COMPUT, V58, P75, DOI 10.1016/j.asoc.2017.04.058
   Dai Q, 2013, NEUROCOMPUTING, V122, P258, DOI 10.1016/j.neucom.2013.06.026
   Didaci L, 2005, PATTERN RECOGN, V38, P2188, DOI 10.1016/j.patcog.2005.02.010
   Du SQ, 2017, NEUROCOMPUTING, V241, P115, DOI 10.1016/j.neucom.2017.02.034
   Fletcher S, 2020, NEUROCOMPUTING, V409, P93, DOI 10.1016/j.neucom.2020.05.029
   Ganaie MA, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105151
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Guo HP, 2018, NEUROCOMPUTING, V275, P237, DOI 10.1016/j.neucom.2017.06.052
   Guo YF, 2022, NEUROCOMPUTING, V493, P119, DOI 10.1016/j.neucom.2022.04.052
   Hou C., 2016, Learning classifier competence based on graph for dynamic classifier selection, DOI [10.1109/FSKD.2016.7603343, DOI 10.1109/FSKD.2016.7603343]
   Huang SS, 2023, MULTIMEDIA SYST, V29, P1463, DOI 10.1007/s00530-023-01062-5
   Ji JZ, 2023, PATTERN RECOGN, V143, DOI 10.1016/j.patcog.2023.109744
   Jia X, 2014, KSII Trans Internet Inform Syst, V8, DOI [10.1007/s11042-020-08746-4, DOI 10.1007/S11042-020-08746-4]
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Li DY, 2023, APPL INTELL, V53, P20730, DOI 10.1007/s10489-023-04572-x
   Li DY, 2019, APPL INTELL, V49, P3188, DOI 10.1007/s10489-019-01435-2
   Li DY, 2019, KNOWL INF SYST, V59, P219, DOI 10.1007/s10115-018-1176-z
   Li DY, 2018, MULTIMED TOOLS APPL, V77, P15251, DOI 10.1007/s11042-017-5105-z
   Li TK, 2023, PATTERN RECOGN, V142, DOI 10.1016/j.patcog.2023.109691
   Li X, 2023, OPTIK, V283, DOI 10.1016/j.ijleo.2023.170892
   Lim H, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107663
   Liu YY, 2021, INFORM SCIENCES, V578, P195, DOI 10.1016/j.ins.2021.07.034
   Lv SX, 2022, INFORM SCIENCES, V612, P994, DOI 10.1016/j.ins.2022.09.002
   Markatopoulou F, 2015, NEUROCOMPUTING, V150, P501, DOI 10.1016/j.neucom.2014.07.063
   Martinez-Munoz G, 2006, Pruning in ordered bagging ensembles, DOI [10.1145/1143844.1143921, DOI 10.1145/1143844.1143921]
   Meena Gaurav, 2023, Procedia Computer Science, P1640, DOI 10.1016/j.procs.2023.01.142
   Nan YH, 2022, ALEX ENG J, V61, P4435, DOI 10.1016/j.aej.2021.09.066
   Rajagopal SD, 2022, COMPUT INTELL-US, V38, P345, DOI 10.1111/coin.12498
   Roshan S, 2021, INT J MACH LEARN CYB, V12, P1737, DOI 10.1007/s13042-020-01271-8
   Shen X, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120148
   Sun N, 2023, COMPUT ELECTR ENG, V107, DOI 10.1016/j.compeleceng.2023.108583
   Tsai KY, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116321
   Wang ZL, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108061
   Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027
   Wu XM, 2023, APPL SOFT COMPUT, V145, DOI 10.1016/j.asoc.2023.110530
   Xia XH, 2023, INFORM SCIENCES, V644, DOI 10.1016/j.ins.2023.119301
   Yang AYQ, 2020, MULTIMED TOOLS APPL, V79, P18767, DOI 10.1007/s11042-020-08746-4
   Yang ZX, 2022, DISCRETE APPL MATH, V318, P1, DOI 10.1016/j.dam.2022.04.014
   Yin XC, 2014, INFORM FUSION, V20, P49, DOI 10.1016/j.inffus.2013.11.003
   Zhang HJ, 2022, CATENA, V212, DOI 10.1016/j.catena.2022.106055
NR 44
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16756-1
EA SEP 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000016
DA 2024-07-18
ER

PT J
AU Gu, XL
   Yao, QM
   Gong, XJ
   Kuang, ZZ
AF Gu, Xiaoling
   Yao, Qiming
   Gong, Xiaojun
   Kuang, Zhenzhong
TI iDesigner: making intelligent fashion designs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fashion design; Fashion image synthesis; Generative adversarial network;
   Sketch synthesis
AB This paper presents iDesigner, a novel AI-assisted design system tailored to support intelligent fashion designs. Our proposed system aims to assist fashion designers by automatically synthesizing high-quality product images conditioned on category attributes and texture examples. Since fashion sketches are the fundamental basis of fashion designs, we implement iDesigner with two design assistants, namely Fashion-Sketcher and Style-Transfer. Specifically, Fashion-Sketcher generates a variety of realistic fashion sketches conditioned on the category attribute by mimicking human painters that first draw the outlines and then finish the detailed contents of the objects. Style-Transfer synthesizes the fashion product images by applying texture examples onto the synthetic sketch images with a feature transformation scheme. We validate our approach using a new dataset and demonstrate that our proposed iDesigner can not only successfully generate diverse sketch images conditioned on category attributes, but also generate high-quality fashion product images conditioned on sketch images and texture examples.
C1 [Gu, Xiaoling; Yao, Qiming; Gong, Xiaojun; Kuang, Zhenzhong] Hangzhou Dianzi Univ, Coll Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Baiyang St, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Gu, XL (corresponding author), Hangzhou Dianzi Univ, Coll Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Baiyang St, Hangzhou 310018, Peoples R China.
EM guxl@hdu.edu.cn; yaoqiming@hdu.edu.cn; gongxj@hdu.edu.cn;
   zzkuang@hdu.edu.cn
FU This work was supported by the Zhejiang Provincial Natural Science
   Foundation of China (No.LY21F020019) and the National Science Foundation
   of China under Grants 61802100 and 61972119. We also thank the
   postgraduate student, Shengwenzhuo Xu, for her assist; Zhejiang
   Provincial Natural Science Foundation of China [61802100, 61972119];
   National Science Foundation of China
FX This work was supported by the Zhejiang Provincial Natural Science
   Foundation of China (No.LY21F020019) and the National Science Foundation
   of China under Grants 61802100 and 61972119. We also thank the
   postgraduate student, Shengwenzhuo Xu, for her assistance in carrying
   out the experiments.
CR AlBahar B, 2019, IEEE I CONF COMP VIS, P9015, DOI 10.1109/ICCV.2019.00911
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Barratt S, 2018, ARXIV
   Brock A., 2019, INT C LEARN REPR
   Cao N, 2019, AAAI CONF ARTIF INTE, P2564
   Chen Y, 2017, ARXIV
   Dumoulin V.., 2017, P INT C LEARN REPR I
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Gu SY, 2022, PROC CVPR IEEE, P10686, DOI 10.1109/CVPR52688.2022.01043
   Gulrajani I, 2017, INT C LEARN REPR ICL, P1
   Ha D., 2017, P INT C LEARN REPR
   Han Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1533, DOI 10.1145/3394171.3413953
   Hensel M, 2017, ADV NEUR IN, V30
   Ho J., 2020, NEURIPS
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Gulrajani I, 2017, ADV NEUR IN, V30
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kato N, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P529, DOI 10.1145/3173225.3173302
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Lim J, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0286-7
   Odena A, 2017, PR MACH LEARN RES, V70
   Pidhorskyi S, 2018, ADV NEUR IN, V31
   Radford A., 2015, ARXIV
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sbai O, 2019, LECT NOTES COMPUT SC, V11131, P37, DOI 10.1007/978-3-030-11015-4_5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JF, 2018, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2018.00090
   van den Oord A, 2017, ADV NEUR IN, V30
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang Y, 2020, PROC CVPR IEEE, P5093, DOI 10.1109/CVPR42600.2020.00514
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu Q, 2018, ARXIV
   Yan HZ, 2024, IEEE T COMPUT SOC SY, V11, P3079, DOI [10.1109/TCSS.2022.3161996, 10.1109/TMM.2022.3146010]
   Yu C, 2019, IEEE I CONF COMP VIS, P9045, DOI 10.1109/ICCV.2019.00914
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XJ, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P4525, DOI 10.1145/3503161.3548230
   Zhang Z, 2021, ADV NEUR IN
   Zhao TC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P654, DOI 10.18653/v1/P17-1061
NR 50
TC 2
Z9 2
U1 16
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32835
EP 32855
DI 10.1007/s11042-023-16780-1
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100008
DA 2024-07-18
ER

PT J
AU Gundu, V
   Simon, SP
   Kumba, K
AF Gundu, Venkateswarlu
   Simon, Sishaj P.
   Kumba, Krishna
TI Short-term solar power forecasting- An approach using JAYA based
   recurrent network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JAYA algorithm; Deep Network Model; Long Short Memory Network
ID CLASSIFICATION
AB Solar power generation is variable and weather-dependent, making accurate forecasting essential for power system operation and planning. In this work, we use multiple deep neural network models and different weather parameters to forecast solar power generation. We compare the performance of the distinct models and test the anticipated forecast model using 100 kW solar data from a specific region in Asia in the year 2021. Here, the proposed work uses a deep recurrent network model that is Long Short Memory Network (LSMN) for solar power forecasting. In this work, we used the JAYA algorithm for hyperparameters optimization to demonstrate their forecast strength related to standard analysis. The forecasted results using JAYA-based LSMN show superior predicting performance compared to the conventional techniques.
C1 [Gundu, Venkateswarlu] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, AP, India.
   [Simon, Sishaj P.] Natl Inst Technol, Dept Elect & Elect Engn, Tiruchirappalli, India.
   [Kumba, Krishna] Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Vellore Institute of Technology (VIT); VIT
   Chennai
RP Gundu, V (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur, AP, India.
EM psv2482109@gmail.com
RI Gundu, Venkateswarlu/AFJ-5988-2022
OI Gundu, Venkateswarlu/0000-0002-4412-5054; Kumba, Dr.
   Krishna/0000-0003-1577-2516
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   Bai Y, 2021, COMPUT IND ENG, V155, DOI 10.1016/j.cie.2021.107227
   Fahimullah M, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16399-2
   Kantipudi MVVP, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/2676780
   Kumari P, 2021, J CLEAN PROD, V318, DOI 10.1016/j.jclepro.2021.128566
   Kumari P, 2021, J CLEAN PROD, V279, DOI 10.1016/j.jclepro.2020.123285
   Li L, 2021, J BIOMED INFORM, V122, DOI 10.1016/j.jbi.2021.103894
   Li PS, 2023, J MOD POWER SYST CLE, V11, P324, DOI 10.35833/MPCE.2020.000624
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Rizzi S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2025324118
   Sharifi A, 2021, J SCI FOOD AGR, V101, P891, DOI 10.1002/jsfa.10696
   Sharma S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-16419-1
   Shi ZY, 2021, RELIAB ENG SYST SAFE, V205, DOI 10.1016/j.ress.2020.107257
   Wang J., 2021, ARXIV
   Yan JCA, 2021, IEEE T IND APPL, V57, P3282, DOI 10.1109/TIA.2021.3073652
   Zhao J, 2021, ENERGY, V218, DOI 10.1016/j.energy.2020.119509
   Zhao X, 2021, SUSTAIN ENERGY TECHN, V45, DOI 10.1016/j.seta.2021.101061
   Zhou X, 2021, IEEE ACCESS, V9, P84306, DOI 10.1109/ACCESS.2021.3087696
NR 19
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32411
EP 32422
DI 10.1007/s11042-023-16723-w
EA SEP 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100010
DA 2024-07-18
ER

PT J
AU Yang, Y
   Wu, D
   Zeng, LL
   Li, ZR
AF Yang, Yang
   Wu, Dan
   Zeng, Lanling
   Li, Zhuoran
TI Weighted least square filter via deep unsupervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image smoothing; Optimization model; Unsupervised learning;
   Computational photography
AB The weighted least square (WLS) filter is a popular edge-preserving image smoother that is particularly useful for detail enhancing and HDR tone mapping. However, it suffers from limited edge-preserving capability and high computational cost. Existing deep learning-based filters under the WLS framework are mostly based on supervised learning. They improve the efficiency but not the quality. In this paper, we propose a novel edge-preserving filter under the weighted least square framework based on deep unsupervised learning. According to the spatial-varying smoothing property of the edge-preserving filter, we propose a lightweight fully convolution neural network based on dilated convolutions with varying expanding factors. The proposed filter fully makes use of the 2D neighborhood information, thus it is able to suppress various artifacts. Thanks to the highly optimized framework for deep learning, the proposed filter is highly efficient, enabling the processing of 720P images at interactive rates (approximate to 12 fps) on a modern desktop. Experimental results indicate that the proposed filter achieves the state-of-the-art smoothing quality. Therefore, our filter benefits a variety of tasks in the field of image processing and computer graphics.
C1 [Yang, Yang; Wu, Dan; Zeng, Lanling] Jiangsu Univ, Dept Comp Sci, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Li, Zhuoran] Natl Univ Singapore, Dept Stat & Data Sci, Singapore 119077, Singapore.
C3 Jiangsu University; National University of Singapore
RP Yang, Y (corresponding author), Jiangsu Univ, Dept Comp Sci, Zhenjiang 212013, Jiangsu, Peoples R China.
EM yyoung@ujs.edu.cn; 2222008070@stmail.ujs.edu.cn; lanling73@163.com;
   zhuoran.li@u.nus.edu
OI , Yang/0000-0001-8782-4819
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   [Anonymous], 2015, Comput. Vis. Media
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barron JT, 2016, LECT NOTES COMPUT SC, V9907, P617, DOI 10.1007/978-3-319-46487-9_38
   Bhat P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731048
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Ding XH, 2016, MULTIMED TOOLS APPL, V75, P2697, DOI 10.1007/s11042-015-2657-7
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan QN, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275081
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Feng YT, 2021, INT J NUMER METH ENG, V122, P2581, DOI 10.1002/nme.6633
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kala R, 2020, MULTIMED TOOLS APPL, V79, P15513, DOI 10.1007/s11042-019-7459-x
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kingma D. P., 2014, arXiv
   Koutis I, 2011, COMPUT VIS IMAGE UND, V115, P1638, DOI 10.1016/j.cviu.2011.05.013
   Krishnan D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461992
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu K, 2021, MULTIMED TOOLS APPL, V80, P19421, DOI 10.1007/s11042-021-10740-3
   Liu QG, 2016, MULTIMED TOOLS APPL, V75, P7909, DOI 10.1007/s11042-015-2709-z
   Liu W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3388887
   Liu W, 2020, IEEE T CIRC SYST VID, V30, P23, DOI 10.1109/TCSVT.2018.2890202
   Liu W, 2017, IEEE I CONF COMP VIS, pCP32, DOI 10.1109/ICCV.2017.624
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Mondal K, 2024, MULTIMED TOOLS APPL, V83, P15413, DOI 10.1007/s11042-021-11890-0
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Qiang ZP, 2019, MULTIMED TOOLS APPL, V78, P619, DOI 10.1007/s11042-017-5347-9
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sun ZG, 2020, IEEE T IMAGE PROCESS, V29, P500, DOI 10.1109/TIP.2019.2928631
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang X, 2017, MULTIMED TOOLS APPL, V76, P17497, DOI 10.1007/s11042-016-4106-7
   Wu HK, 2018, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2018.00197
   Xu J, 2021, IEEE T MULTIMEDIA, V23, P4065, DOI 10.1109/TMM.2020.3037535
   Xu L, 2015, PR MACH LEARN RES, V37, P1669
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang Y, 2023, IEEE T MULTIMEDIA, V25, P4148, DOI 10.1109/TMM.2022.3171686
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P4150, DOI 10.1109/TCSVT.2021.3124291
   Yin H, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107717
   Yu F., 2015, ARXIV
   Yu S, 2021, MULTIMED TOOLS APPL, V80, P5673, DOI 10.1007/s11042-020-09877-4
   Zhu FD, 2019, IEEE T IMAGE PROCESS, V28, P3556, DOI 10.1109/TIP.2019.2908778
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
   Zhu SP, 2017, MULTIMED TOOLS APPL, V76, P199, DOI 10.1007/s11042-015-3023-5
   Zhuang PX, 2020, MULTIMED TOOLS APPL, V79, P17257, DOI 10.1007/s11042-019-08404-4
NR 50
TC 1
Z9 1
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31361
EP 31377
AR s11042-023-16844-2
DI 10.1007/s11042-023-16844-2
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066958500006
DA 2024-07-18
ER

PT J
AU Padate, R
   Jain, A
   Kalla, M
   Sharma, A
AF Padate, Roshni
   Jain, Amit
   Kalla, Mukesh
   Sharma, Arvind
TI Combining semi-supervised model and optimized LSTM for image caption
   generation based on pseudo labels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image caption; NIC model; N-gram; CNN; HH-SCME scheme
AB Artificial intelligence's crucial area of image captions. It's a very difficult situation until the advancement of DL is made. A lot of open challenges remain as robustness, generalization and accuracy, results are far from reasonable. As image captioning schemes are data avaricious, pre-training on larger scale datasets, even if not well-curated, is fetching a solid approach. In addition to precisely identifying the image includes the scene, object, connection, and qualities of the item in the image, the image caption generation method should produce natural, fluid, precise, and useful sentences. However, since not all visual information may be utilized, it might be difficult to effectively convey the image's content when writing image captions. Here, the image captioning is done under two models, i.e. NIC model and LSTM based model. At first, (Neural Image Caption) NIC process is done, where, CNN based caption generation is carried out for unlabelled and labeled dataset. Further, features namely, improved BOW and N-gram are derived that are used for training the CNN model. The final caption is generated by optimized LSTM, where the weights are optimally tuned by Harris Hawks with Sinusoidal Chaotic Map Assisted Exploitation (HH-SCME). Finally, BLEU score, rouge and CIDER scores are computed to prove the efficiency of HH-SCME. The proposed model of LSTM+HH-SCME achieves 0.84 BLEU score 1 value as compared to other existing methods like CNN, SSO, PRO, AOA, RNN, LSTM and LSTM+HH-SCME.
C1 [Padate, Roshni; Jain, Amit; Kalla, Mukesh] Sir Padampat Singhania Univ, Dept Comp Sci & Engn, Bhatewar, Rajasthan, India.
   [Sharma, Arvind] Sir Padampat Singhania Univ, Dept Math, Bhatewar, Rajasthan, India.
C3 Sir Padampat Singhania University; Sir Padampat Singhania University
RP Padate, R (corresponding author), Sir Padampat Singhania Univ, Dept Comp Sci & Engn, Bhatewar, Rajasthan, India.
EM roshnip8876@gmail.com
RI Padate, Roshni/JJD-9798-2023
CR Bang S, 2020, AUTOMAT CONSTR, V112, DOI 10.1016/j.autcon.2020.103116
   Cao S, 2020, NEUROCOMPUTING, V417, P419, DOI 10.1016/j.neucom.2020.08.019
   Chen X, 2018, Pattern Recognition Letters, P30
   Cheng C, 2021, INT J APPROX REASON, V131, P93, DOI 10.1016/j.ijar.2020.12.016
   Christie G, 2017, COMPUT VIS IMAGE UND, V163, P101, DOI 10.1016/j.cviu.2017.09.001
   Deng ZR, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115836
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Fan C, 2018, J VIS COMMUN IMAGE R, V55, P40, DOI 10.1016/j.jvcir.2018.05.008
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guan JN, 2018, SIGNAL PROCESS-IMAGE, V63, P141, DOI 10.1016/j.image.2018.02.005
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Huang G, 2018, Neural Process Lett, V11
   Kinghorn P, 2018, NEUROCOMPUTING, V272, P416, DOI 10.1016/j.neucom.2017.07.014
   Li RF, 2020, NEUROCOMPUTING, V396, P92, DOI 10.1016/j.neucom.2020.02.041
   Liu D, 2021, FRONT NEUROROBOTICS, V15, DOI 10.3389/fnbot.2021.697634
   Liu Q, 2018, COMPUT IND, V97, P47, DOI 10.1016/j.compind.2018.01.015
   Liu S, 2023, IEEE T RELIAB, V72, P15, DOI 10.1109/TR.2022.3162346
   Padate R, 2022, Journal of Telecommunications and Information Technology
   Padate R, 2023, ENG APPL ARTIF INTEL, V123, DOI 10.1016/j.engappai.2023.106112
   Padate R, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500572
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Singh A, 2021, MULTIMED TOOLS APPL, V80, P35721, DOI 10.1007/s11042-021-11106-5
   Su JS, 2019, NEUROCOMPUTING, V367, P144, DOI 10.1016/j.neucom.2019.08.012
   Sur C., 2020, SN COMPUT SCI, V1, P229, DOI [10.1007/s42979-020-00238-4, DOI 10.1007/S42979-020-00238-4]
   Tan YH, 2018, Neurocomputing, V28
   Tiwary T, 2023, MULTIMED TOOLS APPL, V82, P3801, DOI 10.1007/s11042-022-13443-5
   Wang HZ, 2020, NEUROCOMPUTING, V401, P249, DOI 10.1016/j.neucom.2020.03.087
   Wang SS, 2023, COMPUT ELECTRON AGR, V209, DOI 10.1016/j.compag.2023.107863
   Wei YW, 2020, NEUROCOMPUTING, V387, P91, DOI 10.1016/j.neucom.2019.12.073
   Wu CL, 2018, SIGNAL PROCESS-IMAGE, V67, P100, DOI 10.1016/j.image.2018.06.002
   Xia PF, 2020, MULTIMED TOOLS APPL, V79, P24225, DOI 10.1007/s11042-020-09110-2
   Xiao F, 2019, NEUROCOMPUTING, V364, P322, DOI 10.1016/j.neucom.2019.06.085
   Yang J, 2018, Neurocomputing, V20
   Yang M, 2020, IEEE T IMAGE PROCESS, V29, P9627, DOI 10.1109/TIP.2020.3028651
   Ye ZF, 2021, MULTIMED TOOLS APPL, V80, P25557, DOI 10.1007/s11042-021-10632-6
   Yuan A, 2018, Neurocomputing, V1
   Zhang HB, 2020, SOFT COMPUT, V24, P1377, DOI 10.1007/s00500-019-03973-w
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
   Zhou X., Neuro computing
NR 40
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29997
EP 30017
DI 10.1007/s11042-023-16687-x
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600010
DA 2024-07-18
ER

PT J
AU Vrysis, L
   Almaliotis, D
   Almpanidou, S
   Papadopoulou, EP
   Oikonomides, K
   Chatzisavvas, KC
   Karampatakis, V
AF Vrysis, Lazaros
   Almaliotis, Diamantis
   Almpanidou, Stavroula
   Papadopoulou, Eleni P.
   Oikonomides, Konstantinos
   Chatzisavvas, Konstantinos Ch.
   Karampatakis, Vasileios
TI Mobile software aids for people with low vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low vision; Smartphones; Tablets; Mobile devices; Accessibility
ID SMARTPHONE; ACCESSIBILITY; TECHNOLOGY; DEVICES; READER; ADULTS; TABLET;
   USAGE; IPAD
AB The usage of smartphones is increasingly widespread, and the usefulness of mobile applications as low-vision aids is evident but not thoroughly examined. In this study, we surveyed people with low vision to assess the usability of common, preloaded mobile applications, to evaluate the usage of typical assistive technologies of smartphones, and to measure the usefulness, and usability of recent software advancements that can be used as visual aids. We invited 134 low-vision individuals to participate, and 45 of them met the eligibility criteria and completed an in-person survey. The eligibility criteria were as follows: aged 18 years or older and mentally competent, visual acuity worse than 0.4 logMAR with best-corrected glasses in the better-seeing eye, ownership of a smartphone and familiarity with visual assistive technologies. All testing scenarios were carried out using the participants' smartphones, either with Android or iOS operating systems. Participants reported the usefulness and ease of use for common visual display enhancements (i.e., text size, bold text, increased contrast, inverted colors, and dark mode), audio feedback capabilities, four primary preloaded apps (Dialer, Clock, Calculator, and Calendar), and four usage scenarios that serve as low-vision aids (magnify with camera, hard-copy text-to-speech, voice typing, and voice commands). Participants also indicated whether they could use the apps or execute the scenarios independently. The Dialer and Clock apps, text enhancements, camera magnification, and voice typing were rated as highly useful, while the Calendar application received lower ratings. Most of the selected apps or services were rated as easy to use, with lower ratings recorded for the Calendar and Select to Speak ones. Considering the positive results across all options, this collection of apps and services proved useful for all age groups, regardless of gender, technological familiarity, or education. The feedback received in this study can help towards improving the everyday lives of low-vision people as well as informing the design of apps and assistive features, guiding future research and development to enhance visual accessibility on mobile computing devices.
C1 [Vrysis, Lazaros; Almaliotis, Diamantis; Almpanidou, Stavroula; Papadopoulou, Eleni P.; Oikonomides, Konstantinos; Karampatakis, Vasileios] Aristotle Univ Thessaloniki, GR-54124 Thessaloniki, Greece.
   [Chatzisavvas, Konstantinos Ch.] mSensis SA, VEPE Technopolis, GR-55535 Thessaloniki, Greece.
   [Chatzisavvas, Konstantinos Ch.] Univ Western Macedonia, Elect & Comp Engn Dept, ZEP Campus Kozani, GR-50100 Kozani, Greece.
C3 Aristotle University of Thessaloniki; University of Western Macedonia
RP Vrysis, L (corresponding author), Aristotle Univ Thessaloniki, GR-54124 Thessaloniki, Greece.
EM lvrysis@auth.gr; dalma@auth.gr; almpstav@auth.gr; elena55@auth.gr;
   kokakis@auth.gr; kchatz@msensis.com; karophth@auth.gr
RI Vrysis, Lazaros/V-2260-2019
OI Vrysis, Lazaros/0000-0003-2900-4657
FU HEAL-Link Greece; European Union; Greek national funds through the
   Operational Program Competitiveness, Entrepreneurship and Innovation,
   under the call RESEARCH - CREATE - INNOVATE [T1EDK-03742]
FX Open access funding provided by HEAL-Link Greece. This research has been
   co-financed by the European Union and Greek national funds through the
   Operational Program Competitiveness, Entrepreneurship and Innovation,
   under the call RESEARCH - CREATE - INNOVATE (project code: T1EDK-03742).
CR AbouElwafa A, 2018, ACAD PERSPECTIVE PRO, V1, P645, DOI [10.33793/acperpro.01.01.120, DOI 10.33793/ACPERPRO.01.01.120]
   Almpanidou S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12072549
   Almpanidou S, 2021, ACTA OPHTHALMOL, V99, DOI 10.1111/j.1755-3768.2020.0254
   [Anonymous], 2010, GLOBAL DATA VISUAL I
   [Anonymous], COMP ACC SCREEN ENH
   [Anonymous], 2014, J Lang Linguist Stud
   apple, VIS ACC IPHONE
   bit, MOB ACC VIS ENH SAMS
   bit, SMARTPH ACC COMPR GU
   Bohouta G., 2017, INT J ENG RES APPL, V2248-9622, P20, DOI DOI 10.9790/9622-0703022024
   Conradi J, 2015, PROCEDIA MANUF, V3, P387, DOI 10.1016/j.promfg.2015.07.182
   Crossland MD, 2014, OPHTHAL PHYSL OPT, V34, P552, DOI 10.1111/opo.12136
   Davenport T, 2018, The AI Advantage: How to Put the Artificial Intelligence Revolution to Work
   Dimoulas C, 2015, MULTIMEDIA AUTHORING
   Dockery Dominique M, 2020, R I Med J (2013), V103, P69
   da Silva PBE, 2022, DISABIL REHABIL-ASSI, V17, P848, DOI 10.1080/17483107.2020.1820086
   Fok D, 2011, WORK, V39, P37, DOI 10.3233/WOR-2011-1149
   Gill K, 2013, EYE, V27, P639, DOI 10.1038/eye.2013.14
   Granquist C, 2021, J VISUAL IMPAIR BLIN, V115, P277, DOI 10.1177/0145482X211027492
   Haji SA, 2015, CLIN OPHTHALMOL, V9, P17, DOI 10.2147/OPTH.S73193
   Hoggan E, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1573
   Irvine D, 2014, NEURO-OPHTHALMOLOGY, V38, P53, DOI 10.3109/01658107.2013.874448
   Kalmpourtzis G., 2019, Educational game design fundamentals: A journey to creating intrinsically motivating learning experiences, V1st, DOI [DOI 10.1201/9781315208794, 10.1201/ 9781315208794]
   Kalmpourtzis G, 2020, 2020 15TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2020), P174, DOI 10.1109/smap49528.2020.9248471
   Kalmpourtzis G, 2021, IEEE GLOB ENG EDUC C, P1288, DOI 10.1109/EDUCON46332.2021.9453877
   Kalmpourtzis G, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P123, DOI 10.1109/SMAP.2016.7753396
   Khan A, 2019, MULTIMED TOOLS APPL, V78, P17495, DOI 10.1007/s11042-018-7094-y
   LEGGE GE, 1985, VISION RES, V25, P253, DOI 10.1016/0042-6989(85)90118-X
   Liu X, 2020, PREPRINT, DOI [10.20944/preprints202008.0487.v1, DOI 10.20944/PREPRINTS202008.0487.V1]
   Lu ZY, 2014, IEEE T HUM-MACH SYST, V44, P293, DOI 10.1109/THMS.2014.2302794
   Maeng M, 2020, INVEST OPHTH VIS SCI, V61
   Martiniello N, 2022, ASSIST TECHNOL, V34, P34, DOI 10.1080/10400435.2019.1682084
   Morrice E, 2017, EYE, V31, P865, DOI 10.1038/eye.2016.309
   Punchoojit Lumpapun, 2017, Advances in Human-Computing Interaction, V2017, DOI 10.1155/2017/6787504
   Pundlik S, 2017, IEEE T NEUR SYS REH, V25, P49, DOI 10.1109/TNSRE.2016.2546062
   Sivakumar P, 2020, EYE, V34, P344, DOI 10.1038/s41433-019-0545-5
   Szpiro S, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P171, DOI 10.1145/2982142.2982168
   Thoidis I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101698
   Viana P, 2016, P 6 INT C WEB INT MI, P1, DOI [10.1145/2912845.2912852, DOI 10.1145/2912845.2912852]
   Vrysis L, 2013, AUDIO ENG SOC CONVEN
   Vrysis L, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13030080
   Vrysis L, 2019, 146TH AES CONVENTION
   Vrysis L, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814906
   White S, 2010, J LIT RES, V42, P276, DOI 10.1080/1086296X.2010.503552
   Wu YH, 2020, OPTOMETRY VISION SCI, V97, P249, DOI 10.1097/OPX.0000000000001503
NR 45
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30919
EP 30936
DI 10.1007/s11042-023-16639-5
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Wang, G
   Tan, L
   Shang, ZL
   Liu, H
AF Wang, Ge
   Tan, Li
   Shang, Ziliang
   Liu, He
TI Multimodal dual emotion with fusion of visual sentiment for rumor
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rumor detection; Multimodal emotion; Social media; Deep learning
ID VALENCE; AROUSAL
AB In recent years, widely spreading rumors have brought devastating impacts on society, making rumor detection a significant challenge. Exsisting researches improves that image palys an important role in rumor detection. But they only pay attention to semantic features of images' content, while neglecting visual emotions. We propose a Multimodal Dual Emotion feature for rumor detection, which consists of publish visual emotion, publish textual emotion and social emotion. Our experiments proves that the image emotion improves the rumor detection efficiency. To the best of our knowledge, this is the first study which uses visual emotion in rumor detection. The proposed Multimodal Dual Emotion feature serves as a model plugin that can be seamlessly integrated with various rumor detection models, leading to performance enhancements.
C1 [Wang, Ge; Tan, Li; Shang, Ziliang] Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.
   [Tan, Li] Univ Elect Sci & Technol China, Chongqing Inst Microelect Ind Technol, Xiyong Microelect Pk, Chongqing 400000, Peoples R China.
   [Liu, He] Chongqing Acad Educ Sci, Chongqing 400015, Peoples R China.
C3 Beijing Technology & Business University; University of Electronic
   Science & Technology of China
RP Tan, L (corresponding author), Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing 100048, Peoples R China.; Tan, L (corresponding author), Univ Elect Sci & Technol China, Chongqing Inst Microelect Ind Technol, Xiyong Microelect Pk, Chongqing 400000, Peoples R China.
EM wanggestu@163.com; tanli@th.btbu.edu.cn; shangziliang@st.btbu.edu.cn;
   bjxiexintong@163.com
FU Funding from the Natural Science Foundation of Chongqing
   (CSTB2022NSCQ-MSX1415), Chongqing Municipal Education Commission of
   Science and Technology Research Project (KJZD-K202114401) and 2022
   Postgraduate Research Capability Improvement Program Funding are
   [CSTB2022NSCQ-MSX1415]; Natural Science Foundation of Chongqing
   [KJZD-K202114401]; Chongqing Municipal Education Commission of Science
   and Technology Research Project; 2022 Postgraduate Research Capability
   Improvement Program
FX Funding from the Natural Science Foundation of Chongqing
   (CSTB2022NSCQ-MSX1415), Chongqing Municipal Education Commission of
   Science and Technology Research Project (KJZD-K202114401) and 2022
   Postgraduate Research Capability Improvement Program Funding are
   gratefully acknowledged.
CR Ajao O, 2019, INT CONF ACOUST SPEE, P2507, DOI 10.1109/ICASSP.2019.8683170
   Alam F, 2021, ARXIV
   Alonso MA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111348
   Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Cao J., 2020, Disinformation, Misinformation, and Fake News in Social Media (Lecture Notes in Social Networks), P141, DOI 10.1007/978-3-030-42699-6_8
   Cao J, 2018, ARXIV
   Castillo C., 2011, P 20 INT C WORLD WID, P675, DOI DOI 10.1145/1963405.1963500
   Cheema GS, 2021, CEUR WORKSHOP PROC
   Chen JX, 2022, IEEE MULTIMEDIA, V29, P104, DOI 10.1109/MMUL.2022.3146568
   Chen X, KNOWL-BASED SYST
   Chen YX, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2897, DOI 10.1145/3485447.3511968
   Cheng MX, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2892, DOI 10.1145/3366423.3380054
   Choudhry A, 2024, IEEE T COMPUT SOC SY, V11, P588, DOI 10.1109/TCSS.2022.3228312
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Domm P., 2013, CNBC COM, V23, P2062
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fisher D, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01533-w
   Friggeri Adrien, 2014, 8 INT AAAI C WEBL SO
   Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025
   Ghanem B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P679
   Giachanou A, 2021, J ASSOC INF SCI TECH, V72, P1117, DOI 10.1002/asi.24480
   Giachanou A, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P877, DOI 10.1145/3331184.3331285
   Guo H, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P943, DOI 10.1145/3269206.3271709
   He L, 2015, SIGNAL IMAGE VIDEO P
   Hou JR, 2022, INTERNET RES, V32, P1978, DOI 10.1108/INTR-04-2021-0236
   Jiang JJ, 2018, IEEE T DEPEND SECURE, V15, P166, DOI 10.1109/TDSC.2016.2522436
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jing J, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103120
   Kauffmann E, 2020, IND MARKET MANAG, V90, P523, DOI 10.1016/j.indmarman.2019.08.003
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kim HR, 2018, IEEE T MULTIMEDIA, V20, P2980, DOI 10.1109/TMM.2018.2827782
   Kim HR, 2016, COMPUT GRAPH FORUM, V35, P209, DOI 10.1111/cgf.13018
   Kondamudi MR, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101571
   Kumari R, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102740
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li QZ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1173
   Liu Yinhan, 2019, ARXIV190711692
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Meeker M, 2018, INTERNET TRENDS 2018
   Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P198
   Mohammad SM, 2013, COMPUT INTELL-US, V29, P436, DOI 10.1111/j.1467-8640.2012.00460.x
   Nakamura K, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6149
   Nan Q, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3343, DOI 10.1145/3459637.3482139
   Palani B, 2022, MULTIMED TOOLS APPL, V81, P5587, DOI 10.1007/s11042-021-11782-3
   Pröllochs N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01813-2
   Pröllochs N, 2021, EPJ DATA SCI, V10, DOI 10.1140/epjds/s13688-021-00307-5
   Rani N, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6479
   Sailunaz K, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0505-2
   Shi AQ, 2020, 2020 IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC 2020), P376, DOI 10.1109/SEC50012.2020.00055
   Tony R, 2020, Facebook will remove misinformation about coronavirus
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Wei Z, 2020, P IEEE CVF C COMP VI, P115
   Wu L, 2023, P AAAI C ART INT
   Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Zhang K, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106803
   Zhang X, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.830002
   Zhang XY, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3465, DOI 10.1145/3442381.3450004
   Zhao SC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P192, DOI 10.1145/3343031.3351062
   Zhao SC, 2020, IEEE T AFFECT COMPUT, V11, P574, DOI [10.1109/TAFFC.2018.2818685, 10.1109/TAFFC.2016.2628787]
   Zheng P., 2023, INFORM SCIENCES, V642, P083
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 65
TC 0
Z9 0
U1 20
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29805
EP 29826
DI 10.1007/s11042-023-16732-9
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yadava, GT
   Nagaraja, BG
   Jayanna, HS
   Shivakumar, BR
AF Yadava, Thimmaraja G.
   Nagaraja, B. G.
   Jayanna, H. S.
   Shivakumar, B. R.
TI A spoken query system to access the real time agricultural commodity
   prices and weather information in Kannada language/dialects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Speech enhancement; Farmers; Districts; Mandis;
   Commodities; Kannada ASR
ID AUTOMATIC SPEECH RECOGNITION; SPEAKER ADAPTATION
AB We develop two improvements over our previously proposed spectral subtraction with voice activity detection and minimum mean square error spectrum power estimator based on zero crossing (SS-VAD + MMSE-SPZC) enhancement for a real-time spoken query system (SQS). Firstly, we introduce a time delay neural network (TDNN) based modeling technique. Secondly, to properly train the models, we increase the size of the database by collecting the Kannada speech data from an additional 500 farmers under real-time conditions. The proposed combined enhancement technique effectively removes background noise and improves speech quality. When evaluated on the updated degraded speech corpus, our proposed automatic speech recognition (ASR) system achieves better performance compared to previous framework. Moreover, experimental results demonstrate an improvement of 1.32% and 1.48% in terms of speech recognition accuracy for noisy and enhanced speech data respectively, compared to our earlier work.
C1 [Yadava, Thimmaraja G.] Nitte Meenakshi Inst Technol, E&CE, Bengaluru 560064, Karnataka, India.
   [Nagaraja, B. G.] Vidyavardhaka Coll Engn, E&CE, Gokulam 3 Stage, Mysuru 570002, Karnataka, India.
   [Jayanna, H. S.] Siddaganga Inst Technol, IS&E, BH Rd, Tumkur 572103, Karnataka, India.
   [Shivakumar, B. R.] Nitte Mahalinga Adyanthaya Mem Inst Technol, E&CE, Nitte 574110, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology; Vidyavardhaka College of
   Engineering; Siddaganga Institute of Technology; NITTE (Deemed to be
   University); NMAM Institute of Technology
RP Yadava, GT (corresponding author), Nitte Meenakshi Inst Technol, E&CE, Bengaluru 560064, Karnataka, India.
EM thimrajyadav@gmail.com; nagarajbg@gmail.com; jayannahs@gmail.com;
   shivkumarbr@nitte.edu.in
RI B R, Shivakumar/S-1536-2019; Yadava G, Thimmaraja/AEO-3181-2022
OI B R, Shivakumar/0000-0002-3090-2203; Yadava G,
   Thimmaraja/0000-0002-3266-9732
FU Technology Development for Indian Languages (TDIL) programme initiated
   by the Department of Electronics & Information Technology(DeitY),
   Ministry of Communication & Information Technology (MC&IT), Govt. of
   India [11(18)/2012-HCC]
FX This work was a part of consortium project on "Speech-based Access of
   Agricultural Commodity Prices and Weather Information in 11 Indian
   Languages /Dialects, funded by the Technology Development for Indian
   Languages (TDIL) programme initiated by the Department of Electronics &
   Information Technology(DeitY), Ministry of Communication & Information
   Technology (MC&IT), Govt. of India (Grant number:11(18)/2012-HCC(TDIL))
CR Aldarmaki H, 2022, SPEECH COMMUN, V139, P76, DOI 10.1016/j.specom.2022.02.005
   Ali A, 2014, IEEE W SP LANG TECH, P525, DOI 10.1109/SLT.2014.7078629
   [Anonymous], 2018, PROC 6 WORKSHOP SPOK
   Cardinal, 2014, RECENT ADV ASR APPL, P2088
   Chang E, 2002, IEEE T SPEECH AUDI P, V10, P531, DOI 10.1109/TSA.2002.804301
   Chiu Chung-Cheng, 2023, arXiv
   Dai YJ, 2023, COMPUT ASSIST LANG L, V36, P861, DOI 10.1080/09588221.2021.1952272
   Das R, 2020, INT CONF SPEECH DATA, P83, DOI [10.1109/o-cocosda50338.2020.9295007, 10.1109/O-COCOSDA50338.2020.9295007]
   Davies M, 2009, IDS WORKING PAPERS, V01-37
   Defrancq B, 2021, TARGET-NETH, V33, P73, DOI 10.1075/target.19166.def
   Feng SY, 2021, ARXIV
   Jainar SJ, 2020, INT J SIGNAL IMAGING, V12, P1, DOI 10.1504/IJSISE.2020.113552
   Karpov A, 2014, SPEECH COMMUN, V56, P213, DOI 10.1016/j.specom.2013.07.004
   Kotkar P., 2008, HCI COMMUNITY INT DE
   Kuhn R, 2000, IEEE T SPEECH AUDI P, V8, P695, DOI 10.1109/89.876308
   LEGGETTER CJ, 1995, COMPUT SPEECH LANG, V9, P171, DOI 10.1006/csla.1995.0010
   Li JY, 2022, APSIPA TRANS SIGNAL, V11, DOI 10.1561/116.00000050
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Mantena GV, 2011, P ICON 2011 9 INT C
   Meng LH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7008, DOI 10.1109/ICASSP39728.2021.9414483
   Miao HR, 2020, IEEE-ACM T AUDIO SPE, V28, P1452, DOI 10.1109/TASLP.2020.2987752
   Miao Y, 2015, ARXIV
   Nagaraja B. G., 2013, International Journal of Image, Graphics and Signal Processing, V5, P14, DOI 10.5815/ijigsp.2013.09.03
   Patel S. G., 2013, 2013 Abstracts IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2013.6635012
   Perero-Codosero JM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020903
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Rabiner LR, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P501, DOI 10.1109/ASRU.1997.659129
   Schultz BG, 2021, INT J SPEECH TECHNOL, V24, P771, DOI 10.1007/s10772-021-09836-w
   Shah ST, 2016, IEEE VTS VEH TECHNOL, DOI 10.1109/VTCSpring.2016.7504290
   Shahamiri SR, 2021, IEEE T NEUR SYS REH, V29, P852, DOI 10.1109/TNSRE.2021.3076778
   Wu CK, 2022, AUTOMAT CONSTR, V134, DOI 10.1016/j.autcon.2021.104059
   Wu Felix, 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10096988
   Yadav H, 2022, ARXIV
   Yadava TG, 2022, EMERGING RES COMPUTI, P407
   Yadava TG, 2020, J INTELL SYST, V29, P664, DOI 10.1515/jisys-2018-0120
   Yadava TG, 2019, INT J SPEECH TECHNOL, V22, P639, DOI 10.1007/s10772-018-9506-9
   Zhang F., 2020, ARXIV
   Zhang Y, 2022, IEEE J-STSP, V16, P1519, DOI 10.1109/JSTSP.2022.3182537
NR 38
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28675
EP 28688
DI 10.1007/s11042-023-16554-9
EA SEP 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001169100200001
DA 2024-07-18
ER

PT J
AU Kumar, P
   Malik, S
   Raman, B
AF Kumar, Puneet
   Malik, Sarthak
   Raman, Balasubramanian
TI Interpretable multimodal emotion recognition using hybrid fusion of
   speech and image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective computing; Interpretable AI; Multimodal analysis; Information
   fusion; Speech and image processing
AB This paper proposes a multimodal emotion recognition system based on hybrid fusion that classifies the emotions depicted by speech utterances and corresponding images into discrete classes. A new interpretability technique has been developed to identify the important speech and image features leading to the prediction of particular emotion classes. The proposed system's architecture has been determined through intensive ablation studies. It fuses the speech & image features and then combines speech, image, and intermediate fusion outputs. The proposed interpretability technique incorporates the divide and conquer approach to compute shapely values denoting each speech and image feature's importance. We have also constructed a large-scale dataset, IIT-R SIER dataset, consisting of speech utterances, corresponding images, and class labels, i.e., 'anger,' 'happy,' 'hate,' and 'sad.' The proposed system has achieved 83.29% accuracy for emotion recognition. The enhanced performance of the proposed system advocates the importance of utilizing complementary information from multiple modalities for emotion recognition.
C1 [Kumar, Puneet; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, India.
   [Malik, Sarthak] Indian Inst Technol Roorkee, Dept Elect Engn, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Kumar, P (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, India.
EM pkumar99@cs.iitr.ac.in; sarthak_m@mt.iitr.ac.in; bala@cs.iitr.ac.in
RI Kumar, Dr. Puneet/ILC-4863-2023
OI Kumar, Puneet/0000-0002-4318-1353; Malik, Sarthak/0000-0001-5224-1445
FU Ministry of Education, India, has supported this work with grant no.
   1-3146198040. It has been carried out at the Machine Intelligence Lab,
   IIT Roorkee, India. [1-3146198040]; Ministry of Education, India; IIT
   Roorkee, India
FX Ministry of Education, India, has supported this work with grant no.
   1-3146198040. It has been carried out at the Machine Intelligence Lab,
   IIT Roorkee, India.
CR Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Chen GH, 2021, IEEE SIGNAL PROC LET, V28, P533, DOI 10.1109/LSP.2021.3055755
   Dai DY, 2019, INT CONF ACOUST SPEE, P7405, DOI [10.1109/icassp.2019.8683765, 10.1109/ICASSP.2019.8683765]
   Deep Mind, 2016, WAVENET GENERATIVE M
   Fan S, 2022, P 2022 C EMP METH NA, P4984, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.332
   Finka LR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46330-5
   Fortin MP, 2019, PROCEEDINGS OF THE ACM WORKSHOP ON CROSSMODAL LEARNING AND APPLICATION (WCRML'19), P3, DOI 10.1145/3326459.3329165
   Gaspar A, 2019, LECT NOTES COMPUT SC, V11871, P302, DOI 10.1007/978-3-030-33607-3_33
   Han W, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9180
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu A, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P350, DOI 10.1145/3219819.3219853
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kim HR, 2018, IEEE T MULTIMEDIA, V20, P2980, DOI 10.1109/TMM.2018.2827782
   Kumar P, 2021, INTERSPEECH, P1748, DOI 10.21437/Interspeech.2021-1718
   Kumar P, 2021, IEEE IMAGE PROC, P314, DOI 10.1109/ICIP42928.2021.9506714
   Kumar P, 2021, INT C PATT RECOG, P8766, DOI 10.1109/ICPR48806.2021.9413144
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu X, 2017, INT CONF AFFECT, P440, DOI 10.1109/ACII.2017.8273637
   Lundberg SM, 2017, ADV NEUR IN, V30
   Maji B, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11091328
   Majumder N, 2019, AAAI CONF ARTIF INTE, P6818
   Makiuchi MR, 2021, 2021 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P350, DOI 10.1109/ASRU51503.2021.9688036
   Malik S., 2021, PROC IEEE MADRID POW, P1
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Oord A., 2016, ARXIV160903499
   Opitz J., 2019, ARXIV
   Ping W., 2018, 6 INT C LEARN REPR I
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Rao TR, 2020, NEURAL PROCESS LETT, V51, P2043, DOI 10.1007/s11063-019-10033-9
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siriwardhana S, 2020, INTERSPEECH, P3755, DOI 10.21437/Interspeech.2020-1212
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Teng JY, 2022, IEEE T MULTIMEDIA, V24, P1141, DOI 10.1109/TMM.2021.3120545
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vadicamo L, 2017, IEEE INT CONF COMP V, P308, DOI 10.1109/ICCVW.2017.45
   Vieira SM, 2010, IEEE INT CONF FUZZY, DOI 10.1109/FUZZY.2010.5584447
   Xu MK, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P1058, DOI 10.1109/ccwc47524.2020.9031207
   Yenigalla P, 2018, INTERSPEECH, P3688, DOI 10.21437/Interspeech.2018-1811
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   Zeng YF, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-2256-5
   Zeng YF, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119240
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 54
TC 2
Z9 2
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28373
EP 28394
DI 10.1007/s11042-023-16443-1
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001183487500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vedpal
   Tanwar, H
   Chauhan, N
   Khanna, M
AF Vedpal
   Tanwar, Harish
   Chauhan, Naresh
   Khanna, Munish
TI Test case prioritization using a Hybrid Chaotic Flower-fruit fly
   optimization algorithm with multiple objectives
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Test Case Prioritization; Optimization; Multi-objectives; Coverage;
   Software defect prediction
ID SINGLE IMAGE SUPERRESOLUTION; DEEP LEARNING-METHODS; NTIRE 2017
   CHALLENGE; QUALITY ASSESSMENT; NETWORK
AB The research aims to resolve the challenges faced in traditional Test Case Prioritization(TCP) techniques and the need to enhance the efficiency of the software testing process.Software development involves test case execution, which tests the changes to the system that requires more resources and time. TCP is the indispensable method, which is established to obtain the goals, such as attaining fast fault detection and a high convergence rate. The code-coverage- methods are the advanced approach employed in the TCP, which is utilized in various prioritization methods to enhance the efficiencyof the method. In this research, the multi-objective- hybrid Chaotic Flower fruit-fly optimization algorithm (Hybrid CFFO) is proposed for the TCP. Instead of using rigid rules or deterministic algorithms, metaheuristic algorithms were created to make intelligent decisions on heuristics and approximations. The foraging behavior of the flower fly and the reproduction characters of the flower are merged which covers a large exploration phase and overcome the local optima. In TCP, being able to quickly explore interesting search space regions and avoid local optima the proposed hybrid Chaotic Flower fruit-fly optimization is essential for producing high-quality solutions. The selection measures used by the optimization algorithm are on the average percentage of combinatorial coverage (APCC) and the Normalized average of the percentage of faults detected (NAPFD), which is designed to develop the multi-objective function. Based on the algorithm, the significance of the test cases is ordered and prioritized. The effectiveness of the proposed methodology is revealed by comparing the proposed multi-objective-based hybrid CFFO method with the conventional methods. From the results obtained, it is proved that the multi-objective-hybrid CFFO method outperforms all the conventional methods in terms of fitness, NAPFD, and APCC. The maximum fitness, NAPFD,and APCC achieved by the proposed methods are 93.1%,92.82%, and 91.1%, respectively for the big fault matrix data.
C1 [Vedpal] JC Bose Univ Sci & Technol, Dept Comp Applicat, YMCA, Faridabad 121006, Haryana, India.
   [Tanwar, Harish; Chauhan, Naresh] JC Bose Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad 121006, Haryana, India.
   [Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Farah, Mathura 281122, Uttar Pradesh, India.
C3 J.C. Bose University of Science & Technology, YMCA; J.C. Bose University
   of Science & Technology, YMCA
RP Khanna, M (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Farah, Mathura 281122, Uttar Pradesh, India.
EM Ved_ymca@yahoo.co.in; htanwar@gmail.com; nareshchauhan19@gmail.com;
   munishkhanna.official@rocketmail.com
RI Chauhan, Naresh/AAG-5800-2021
OI Chauhan, Naresh/0000-0002-3132-7968
CR Bajaj A, 2021, RECENT ADV COMPUTER, V14, P593
   Banias O, 2019, INFORM SOFTWARE TECH, V115, P119, DOI 10.1016/j.infsof.2019.06.001
   Chi JL, 2020, J SYST SOFTWARE, V163, DOI 10.1016/j.jss.2020.110539
   github, Big fault matrix dataset
   github, Small fault matrix dataset.
   Gokilavani N, 2020, 2020 4 INT C TRENDS, P567
   Gopinath R, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P72, DOI 10.1145/2568225.2568278
   Hoffman J., 2000, Foundations of Intelligent Systems. 12th International Symposium, ISMIS 2000. Proceedings (Lecture Notes in Artificial Intelligence Vol.1932), P216
   Huang RB, 2020, J SYST SOFTWARE, V169, DOI 10.1016/j.jss.2020.110712
   Huang RB, 2020, IEEE T RELIAB, V69, P349, DOI 10.1109/TR.2019.2908068
   Huang YC, 2021, IEEE ACCESS, V9, P16365, DOI 10.1109/ACCESS.2021.3053163
   Khanna M, 2019, ARAB J SCI ENG, V44, P9599, DOI 10.1007/s13369-019-03817-7
   Khanna M, 2018, ARAB J SCI ENG, V43, P4179, DOI 10.1007/s13369-017-2830-6
   Khatibsyarbini Muhammad, 2017, Journal of Theoretical and Applied Information Technology, V95, P2723
   Khatibsyarbini M, 2019, IEEE ACCESS, V7, P132360, DOI 10.1109/ACCESS.2019.2940620
   Khatibsyarbini M, 2018, INFORM SOFTWARE TECH, V93, P74, DOI 10.1016/j.infsof.2017.08.014
   Kochhar PS, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P61, DOI 10.1109/ICSE-SEIP.2019.00015
   Kochhar PS, 2015, IEEE ICST WORKSHOP
   Lu CY, 2020, IEEE T RELIAB, V69, P1004, DOI 10.1109/TR.2019.2930358
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Mitic M, 2015, KNOWL-BASED SYST, V89, P446, DOI 10.1016/j.knosys.2015.08.010
   Nayak S, 2021, SOFT COMPUT, V25, P9925, DOI 10.1007/s00500-020-05428-z
   Planning S, 2002, The economic impacts of inadequate infrastructure for software testing
   Rothermel G, 2001, IEEE T SOFTWARE ENG, V27, P929, DOI 10.1109/32.962562
   Thomas SW, 2014, EMPIR SOFTW ENG, V19, P182, DOI 10.1007/s10664-012-9219-7
   Wenjun Su, 2020, 2020 International Conference on Computer Engineering and Application (ICCEA), P430, DOI 10.1109/ICCEA50009.2020.00099
   Yang XS, 2014, ENG OPTIMIZ, V46, P1222, DOI 10.1080/0305215X.2013.832237
   Yoo S, 2012, SOFTW TEST VERIF REL, V22, P67, DOI [10.1002/stv.430, 10.1002/stvr.430]
NR 28
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28395
EP 28418
DI 10.1007/s11042-023-16606-0
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300005
DA 2024-07-18
ER

PT J
AU Xie, B
   Zhuang, Y
   Jiang, N
   Liu, JK
AF Xie, Bo
   Zhuang, Yi
   Jiang, Nan
   Liu, Jingkun
TI An effective and efficient framework of content-based similarity
   retrieval of large CT image sequences based on WSLEN model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based similarity retrieval; CT image sequence; Spatial
   transformation layer; White stripe
AB The rapid development of medical imaging diagnostic technology makes high-definition CT image sequence(CIS)s more and more important for clinical diagnosis as well as medical research. Given a retrieval CIS, it can effectively assist physicians' diagnosis to retrieve similar CISs from the large-scale CIS database. The state-of-the-art content-based medical image similarity retrieval often adopts single CI as a retrieval one rather than CIS, and the retrieval accuracy is usually not satisfactory. To address this issue, we take lung CIS as an example and propose a progressive Content-based Similarity Retrieval method for the lung CISs (CSRS) based on a Weakly Supervised Learning & Evaluation Network(WSLEN) model. Three enabling techniques (i.e., the WSLEN model, KCI-based similarity measure of CISs, and the distance-based indexing scheme) are proposed to facilitate the CSRS processing of the large lung CISs. Extensive experiments show that the WSLEN-based CSRS method is superior to the two competitors such as the CNNSH [2] and the DSH [12] in terms of the retrieval accuracy; and the DIndex-support CSRS method is superior to that of the sequential scan by a large margin according to the retrieval efficiency.
C1 [Xie, Bo; Zhuang, Yi] Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Jiang, Nan] Zhejiang Univ, Sch Med, Affiliated Hangzhou Peoples Hosp 1, Hangzhou, Peoples R China.
   [Liu, Jingkun] Tonglu Cty Second Peoples Hosp, Dept Gastroenterol, Hangzhou, Peoples R China.
C3 Zhejiang Gongshang University; Zhejiang University
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
EM boxie@mail.zjgsu.edu.cn; zhuang@mail.zjgsu.edu.cn; jiangn198202@163.com;
   zy158cn@163.com
RI wang, nan/KHW-4897-2024
FU The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by Zhejiang
   Province Philosophy and Social Science Planning Project under Grant No.
   23NDJC165YB; Zhejiang Provincial Natural Sc [LY22F020010]; Zhejiang
   Province Philosophy and Social Science Planning Project [LGF22H180039,
   LTGY23F020002, 2023ZL119]; Zhejiang Provincial Natural Science
   Foundation of China; Zhejiang Traditional Chinese Medicine Science and
   Technology Project;  [23NDJC165YB]
FX The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by Zhejiang
   Province Philosophy and Social Science Planning Project under Grant No.
   23NDJC165YB; Zhejiang Provincial Natural Science Foundation of China
   under Grant No. LY22F020010, LGF22H180039 and LTGY23F020002; the
   Zhejiang Traditional Chinese Medicine Science and Technology Project
   under grant No. 2023ZL119.
CR BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Cai YH, 2019, IEEE ACCESS, V7, P51877, DOI 10.1109/ACCESS.2019.2911630
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Ghostan Khatchatoorian A., 2017, PROC 2017 IEEE 30 CA, P1
   He K, 2016, IEEE C COMP VIS PATT, DOI [10.1109/ICCV.2017.201, DOI 10.1109/ICCV.2017.201]
   Jaderberg M, 2015, ADV NEUR IN, V28
   Karthik K., 2018, 2018 IEEE 13th International Conference on Industrial and Information Systems (ICIIS), P7, DOI 10.1109/ICIINFS.2018.8721432
   Khatami A, 2018, EXPERT SYST APPL, V100, P224, DOI 10.1016/j.eswa.2018.01.056
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma L, 2017, J BIOMED INFORM, V66, P148, DOI 10.1016/j.jbi.2017.01.002
   Mizotin M, 2012, IEEE IMAGE PROC, P1241, DOI 10.1109/ICIP.2012.6467091
   Muller H, 2009, WORKSH CROSS LANG EV, DOI [10.1007/978-3-642-15751-6_8, DOI 10.1007/978-3-642-15751-6_8]
   Pan HW, 2014, IEEE J BIOMED HEALTH, V18, P574, DOI 10.1109/JBHI.2013.2274798
   Sampathila N, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12652
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Sundararajan SK, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1305-6
   Vaswani A, 2017, ADV NEUR IN, V30
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
NR 24
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27435
EP 27462
DI 10.1007/s11042-023-16226-8
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600005
DA 2024-07-18
ER

PT J
AU Shah, T
   Khan, DA
   Ali, A
AF Shah, Tariq
   Khan, Dilawar Abbas
   Ali, Asif
TI Design of nonlinear component of block cipher using quaternion integers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion Integers; S-box; Nonlinearity; Prime Integer; Elliptic Curve;
   Symmetric Key Cryptography
ID S-BOX DESIGN; SUBSTITUTION BOX; CONSTRUCTION; CODES
AB As the only nonlinear component of many cryptosystems, the block cipher is an integral part of symmetric ciphering techniques that increase confidentiality at the substitution stage and create randomness. Encryption's strength is solely determined by the competence of its nonlinear component (S-box). The creation of S-boxes has gotten a lot of attention in recent years and opened vast research directions in cryptography and most recent method is designing S-boxes through elliptic curves (ECs). Accordingly, for the generation of S-boxes by ECs one has to fix a prime integer and other two parameters. In this paper a novel S-boxes constructing method is introduced based on the quaternion integers. Alike the S-boxes over ECs in this work a prime integer and other two parameters are taken to be fixed and a rigorous scheme for constructing S- boxes via affine mapping is described. The proposed work is developed in such a way that for every input, it generates two S-boxes, whereas, in the design of ECs based S-boxes one may obtained the only one S-box. The strength of S-boxes is measured by applying different security analyses, e.g., strict avalanche criterion, differential approximation probability, nonlinearity, bit independence criterion, and linear approximation probability. A detailed comparison between the newly constructed S-boxes and some existing S-boxes, focusing on some ECs-based S-boxes has been given. The cryptographic analysis reveals that the proposed algorithm can generate many distinct S-boxes that are cryptographically strong and are useful for the applications of secure data communication.
C1 [Shah, Tariq; Khan, Dilawar Abbas; Ali, Asif] Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Khan, DA (corresponding author), Quaid I Azam Univ, Dept Math, Islamabad, Pakistan.
EM stariqshah@qau.edu.pk; dilawar@math.qau.edu.pk; dr_asif_ali@hotmail.com
CR Ahmad M, 2018, WIRELESS PERS COMMUN, V101, P1715, DOI 10.1007/s11277-018-5787-1
   Al Solami E, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070525
   Alkhaldi AH, 2015, ALEX ENG J, V54, P65, DOI 10.1016/j.aej.2015.01.003
   Azam NA, 2019, FRONT INFORM TECH EL, V20, P1378, DOI 10.1631/FITEE.1800434
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Chen G, 2008, CHAOS SOLITON FRACT, V36, P1028, DOI 10.1016/j.chaos.2006.08.003
   Cheon JH, 1999, LECT NOTES COMPUT SC, V1592, P286
   Davidoff G., 2003, Elementary number theory, group theory, and Ramanujan graphs
   Grigoryan A.M., 2018, Quaternion and Octonion Color Image Processing with Matlab, DOI 10.1117/3.2278810.ch1
   Hayat U, 2019, SIGNAL PROCESS, V155, P391, DOI 10.1016/j.sigpro.2018.10.011
   Hayat U, 2018, WIRELESS PERS COMMUN, V101, P439, DOI 10.1007/s11277-018-5698-1
   Hussain I, 2011, WORLD APPL SCI J, V13, P2389
   Hussain I., 2011, WORLD APPL SCI J, V14, P1779
   Hussain I, 2013, NEURAL COMPUT APPL, V23, P97, DOI 10.1007/s00521-012-0914-5
   Irfan M, 2023, IEEE ACCESS, V11, P2138, DOI 10.1109/ACCESS.2022.3217211
   Isa H, 2016, NEW GENERAT COMPUT, V34, P221, DOI 10.1007/s00354-016-0302-2
   Jamal SS, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0125-z
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Khan M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0043-x
   Khan M, 2015, SECUR COMMUN NETW, V8, P1627, DOI 10.1002/sec.1110
   Khan MA, 2018, IJST-T ELECTR ENG, V42, P219, DOI 10.1007/s40998-018-0061-9
   Khan MF, 2019, IEEE ACCESS, V7, P15999, DOI 10.1109/ACCESS.2019.2893176
   Khanna V.K., 2016, A course in abstract algebra
   Kim J, 2009, CRYPTOLOGIA, V33, P246, DOI 10.1080/01611190802653228
   Knudsen LR, 2011, INFORM SEC CRYPT TEX, P1, DOI 10.1007/978-3-642-17342-4
   Lambic D, 2017, NONLINEAR DYNAM, V87, P2407, DOI 10.1007/s11071-016-3199-x
   Liu HJ, 2023, MULTIMED TOOLS APPL, V82, P23899, DOI 10.1007/s11042-022-12069-x
   Liu HJ, 2020, APPL MATH COMPUT, V376, DOI 10.1016/j.amc.2020.125153
   Özen M, 2010, EUR J PURE APPL MATH, V3, P670
   Özen M, 2011, J FRANKLIN I, V348, P1312, DOI 10.1016/j.jfranklin.2010.02.008
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Peng J., 2012, COGNITIVE INFORM COG, P274, DOI [10.1109/ICCI-CC.2012.6311160, DOI 10.1109/ICCI-CC.2012.6311160]
   Qureshi A, 2017, ELECTRON LETT, V53, P604, DOI 10.1049/el.2017.0194
   Razaq A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5101934
   Shahzad I, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2847801
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Siddiqui N, 2021, WIRELESS PERS COMMUN, V116, P3015, DOI 10.1007/s11277-020-07832-y
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wu Y, 2011, IEEE SYS MAN CYBERN, P3358, DOI 10.1109/ICSMC.2011.6084188
   Yong Wang, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P1033, DOI 10.1109/ICNC.2010.5582968
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
NR 43
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25657
EP 25674
DI 10.1007/s11042-023-16518-z
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052012100001
DA 2024-07-18
ER

PT J
AU de Oliveira, CI
   do Nascimento, MZ
   Roberto, GF
   Tosta, TAA
   Martins, AS
   Neves, LA
AF de Oliveira, Cleber I.
   do Nascimento, Marcelo Z.
   Roberto, Guilherme F.
   Tosta, Thaina A. A.
   Martins, Alessandro S.
   Neves, Leandro A.
TI Hybrid models for classifying histological images: An association of
   deep features by transfer learning with ensemble classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep features; Transfer learning; Hybrid models; Histological images;
   Pattern recognition
ID CANCER; BREAST; ALGORITHMS; DIAGNOSIS; MULTIPLE; RELIEFF
AB The use of a convolutional neural network with transfer learning is a strategy that defines high-level features, commonly explored to study patterns in medical images. These features can be analyzed via different methods in order to design hybrid models with more useful and accurate solutions for clinical practice. In this paper, a computational scheme is presented to define hybrid models through deep features by transfer learning, selection by ranking and a robust ensemble classifier with five algorithms. The obtained models were applied to classify histological images from breast, colorectal and liver tissue. The strategy developed here allows knowing important results and conditions to improve models of computer-aided diagnosis, even exploring classic CNN models. The features were defined using layers from the AlexNet and ResNet-50 architectures. The attributes were organized into subsets of the most relevant features and submitted to a k-fold cross-validation process. The best hybrid models were obtained with deep features from the ResNet-50 network, using distinct layers (activation_48_relu and avg_pool) and a maximum of 35 descriptors. These hybrid models provided 98.00% and 99.32% of accuracy values, with emphasis on histological images of breast cancer, indicating the best solution among those available in the specialized Literature. Also, these models provided more relevant results for classifying UCSB and LG datasets than regularized techniques and CNN architectures, exploring data augmentation or not. The computational scheme with detailed information regarding the main hybrid models is a relevant contribution to the community interested in the study of machine learning techniques for pattern recognition.
C1 [de Oliveira, Cleber I.; Neves, Leandro A.] Sao Paulo State Univ UNESP, Dept Comp Sci & Stat DCCE, Rua Cristovao Colombo 2265, BR-15054000 Sao Jose Do Rio Preto, SP, Brazil.
   [do Nascimento, Marcelo Z.; Roberto, Guilherme F.] Fed Univ Uberlandia UFU, Fac Comp Sci FACOM, Ave Joao Neves Avila 2121,Bl B, BR-38400902 Uberlandia, MG, Brazil.
   [Tosta, Thaina A. A.] Fed Univ Sao Paulo UNIFESP, Sci & Technol Inst ICT, Ave Cesare Mansueto Giulio Lattes 1201, BR-12247014 Sao Jose Dos Campos, SP, Brazil.
   [Martins, Alessandro S.] Fed Inst Triangulo Mineiro IFTM, Rua Belarmino Vilela Junqueira Sn, BR-38305200 Ituiutaba, MG, Brazil.
C3 Universidade Estadual Paulista; Universidade Federal de Sao Paulo
   (UNIFESP)
RP de Oliveira, CI (corresponding author), Sao Paulo State Univ UNESP, Dept Comp Sci & Stat DCCE, Rua Cristovao Colombo 2265, BR-15054000 Sao Jose Do Rio Preto, SP, Brazil.
EM oliveira.cleber@gmail.com; marcelo.zanchetta@gmail.com;
   guilhermefroberto@gmail.com; tosta.thaina@gmail.com;
   alessandro@iftm.edu.br; leandro.neves@unesp.br
RI Neves, Leandro Alves/B-3878-2013; Roberto, Guilherme F/M-1606-2017
OI Oliveira, Cleber/0000-0002-3623-6889
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior-Brasil
   (CAPES) [001]; National Council for Scientific and Technological
   Development CNPq [132940/2019-1, 313643/2021-0, 311404/2021-9]; State of
   Minas Gerais Research Foundation - FAPEMIG [APQ-00578-18]; State of Sao
   Paulo Research Foundation - FAPESP [2022/03020-1]
FX This study was financed in part by the: Coordenacao de Aperfeicoamento
   de Pessoal de Nivel Superior-Brasil (CAPES)-Finance Code 001;National
   Council for Scientific and Technological Development CNPq (Grants
   #132940/2019-1, #313643/2021-0 and #311404/2021-9); the State of Minas
   Gerais Research Foundation - FAPEMIG (Grant #APQ-00578-18); the State of
   Sao Paulo Research Foundation - FAPESP(Grant #2022/03020-1).
CR Abraham B, 2020, BIOCYBERN BIOMED ENG, V40, P1436, DOI 10.1016/j.bbe.2020.08.005
   AGEMAP NIoA, 2020, The Atlas of Gene Expression in Mouse Aging Project (AGEMAP)
   Al Rahhal MM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121890
   Alpaydin E., 2009, INTRO MACHINE LEARNI
   [Anonymous], 2019, Matlab®
   [Anonymous], 2009, Proceedings of the 26th annual international conference on machine learning, DOI DOI 10.1145/1553374.1553442
   Araújo T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177544
   Awan R, 2020, COMPUT ELECTR ENG, V85, DOI 10.1016/j.compeleceng.2019.106450
   BenTaieb A, 2018, IEEE T MED IMAGING, V37, P792, DOI 10.1109/TMI.2017.2781228
   Bianconi F, 2020, CANCERS, V12, DOI 10.3390/cancers12113337
   Bolón-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042
   Bouziane A, 2020, 2020 INT C E HLTH BI, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Burçak KC, 2022, TRAIT SIGNAL, V39, P521, DOI 10.18280/ts.390214
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   Cleary J.G., 1995, PROC 12 INT C MACHIN, P108, DOI [DOI 10.1016/B978-1-55860-377-6.50022-0, 10.1016/B978-1-55860-377-6.50022-0]
   Coccia M, 2020, TECHNOL SOC, V60, DOI 10.1016/j.techsoc.2019.101198
   Cui XT, 2022, APPL INTELL, V52, P5063, DOI 10.1007/s10489-021-02659-x
   Dabass M, 2018, 5 GRADE CANC CLASSIF
   Dabass M, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105680
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   dos Santos FP, 2019, SIBGRAPI, P241, DOI 10.1109/SIBGRAPI.2019.00040
   dos Santos FP, 2018, SIBGRAPI, P189, DOI 10.1109/SIBGRAPI.2018.00031
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Feng YQ, 2018, INT J COMPUT ASS RAD, V13, P179, DOI 10.1007/s11548-017-1663-9
   Gad A.F., 2018, PRACTICAL COMPUTER V, P183
   Gelasca ED, 2008, IEEE IMAGE PROC, P1816, DOI 10.1109/ICIP.2008.4712130
   Ghandour C, 2023, J OPT-INDIA, V52, P1931, DOI 10.1007/s12596-022-01078-6
   Ghosh P, 2021, IEEE ACCESS, V9, P19304, DOI 10.1109/ACCESS.2021.3053759
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Kassani SH, 2019, TISSUE CELL, V58, P76, DOI 10.1016/j.tice.2019.04.009
   Kausar T, 2019, BIOCYBERN BIOMED ENG, V39, P967, DOI 10.1016/j.bbe.2019.09.003
   Kim YJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83199-9
   King AP., 2019, STAT BIOMEDICAL ENG, P119, DOI DOI 10.1016/B978-0-08-102939-8.00015-3
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kononenko I, 1997, APPL INTELL, V7, P39, DOI 10.1023/A:1008280620621
   Kononenko I, 1996, FR ART INT, V35, P31
   Kumar S., 2022, ENG COMPUT-GERMANY, V38, P1185, DOI DOI 10.1007/s00366-020-01280-9
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   LECESSIE S, 1992, APPL STAT-J ROY ST C, V41, P191
   Lee JS, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22249838
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4, DOI 10.1007/BFb0026666
   Li M, 2021, IEEE ACCESS, V9, P53687, DOI 10.1109/ACCESS.2021.3071057
   Li YX, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2979-y
   Long Long, 2022, 2022 IEEE 9th International Conference on Power Electronics Systems and Applications (PESA), P1, DOI 10.1109/PESA55501.2022.10038408
   Lu SY, 2019, J COMPUT SCI-NETH, V30, P41, DOI 10.1016/j.jocs.2018.11.008
   Majtner T, 2016, INT CONF IMAG PROC, DOI 10.1109/IPTA.2016.7821017
   Manhrawy IIM, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6200
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nanni L, 2021, Arxiv, DOI arXiv:1904.08084
   Ng A.Y., 2004, INT C MACH LEARN, V19, P379
   Novitasari DCR, 2020, COMMUN MATH BIOL NEU, DOI 10.28919/cmbn/4765
   Papastergiou T, 2018, COMPLEXITY, DOI 10.1155/2018/8651930
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rajesh G, 2023, J ENG SCI, V14
   Ribeiro MG, 2019, EXPERT SYST APPL, V120, P262, DOI 10.1016/j.eswa.2018.11.034
   Roberto GF, 2019, COMPUT GRAPH-UK, V84, P134, DOI 10.1016/j.cag.2019.08.008
   Roberto GF, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114103
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Saxena S, 2020, INT J IMAG SYST TECH
   Scholkopf B., 2002, Learning with Kernels
   dos Santos LFS, 2018, COMPUT BIOL MED, V103, P148, DOI 10.1016/j.compbiomed.2018.10.013
   Sena P, 2019, ONCOL LETT, V18, P6101, DOI 10.3892/ol.2019.10928
   Sethy PK, 2022, MULTIMED TOOLS APPL, V81, P9631, DOI 10.1007/s11042-021-11756-5
   Shi ZH, 2019, MULTIMED TOOLS APPL, V78, P1017, DOI 10.1007/s11042-018-6082-6
   Silva AB, 2022, SIBGRAPI, P264, DOI 10.1109/SIBGRAPI55357.2022.9991758
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Tavolara TE, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55257-w
   Tenguam JJ., 2022, 2022 29 INT C SYSTEM, P1
   Tran VL, 2023, J MATER ENG STRUCT, V10, P5
   Urbanowicz RJ, 2018, J BIOMED INFORM, V85, P189, DOI 10.1016/j.jbi.2018.07.014
   Watanabe K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166413
   Witten I., 2002, ACM Sigmod Rec., V31, P76, DOI [10.1145/507338.507355, DOI 10.1145/507338.507355]
   Yang M., 2008, SURVEY SHAPE FEATURE
   Younas F, 2023, MULTIMED TOOLS APPL, V82, P18925, DOI 10.1007/s11042-022-14177-0
   Zebari R., 2020, Journal of Applied Science and Technology Trends, V1, P56, DOI [DOI 10.38094/JASTT1224, 10.38094/jastt1224]
   Zhang R, 2022, INT CONF ACOUST SPEE, P1276, DOI 10.1109/ICASSP43922.2022.9747400
NR 84
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16351-4
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O5QZ5
UT WOS:001044367100001
DA 2024-07-18
ER

PT J
AU Krishnakumar, K
   Vasandkumar, K
AF Krishnakumar, K.
   Vasandkumar, K.
TI A novel Mutual Information based PCA approach for face identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mutual information; PCA; WPCA; RMSE; SSIM
ID PRINCIPAL COMPONENT ANALYSIS; IMAGE REGISTRATION; MAXIMIZATION
AB Principal component analysis (PCA) is a statistical tool designed to reduce dimensionality, removing redundant information in the database. When the database is a fusion of inter-similar but not intra-similar groups of databases, PCA has its limitations: poor discriminatory power and large computational load - as cumulative variance accumulation is used for selecting top features considering the global variance of the entire database. In this work, combining the information contained in the database and the Principal Components, a new approach that improves the discriminatory power of the conventional PCA is presented. This approach is developed mainly in two stages. First is the weighting of the training set through a weight vector based on mutual information. The second one is the linear projection of a weighted database using principal components. The ultimate aim of this work, given a facial image and a database of facial images, is to identify the image in the database which is most similar to the given image. The main contribution of this work is to consider the significance of the database images in the identification process in terms of the information they possess about the given image.
C1 [Krishnakumar, K.] Vellore Inst Technol, VIT Sch Design V SIGN, Dept Multimedia, Vellore 632014, Tamil Nadu, India.
   [Vasandkumar, K.] HCL Technol Ltd, Chennai 600130, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Krishnakumar, K (corresponding author), Vellore Inst Technol, VIT Sch Design V SIGN, Dept Multimedia, Vellore 632014, Tamil Nadu, India.
EM kunakrishnakumar@gmail.com
OI , Krishnakumar K/0000-0003-2443-1553
FU VIT Seed Grant [SG20210269]
FX The authors would like to thank Vellore Institute of Technology for
   providing research facilities and VIT Seed Grant (SG20210269).
CR Adebayo Kolawole John, 2014, International Journal of Computer Information Systems and Industrial Management Applications, V6, P150
   Al-Saffar ZA, 2020, IEEE ACCESS, V8, P52575, DOI 10.1109/ACCESS.2020.2980728
   Alkandari A, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P76, DOI 10.1109/ICCTIM.2015.7224596
   Azmeen J, 2021, SOFT COMPUTING INTEL, P369
   Battaglino S, 2020, INT CONF ACOUST SPEE, P3607, DOI [10.1109/ICASSP40776.2020.9054154, 10.1109/icassp40776.2020.9054154]
   Bennasar M, 2015, EXPERT SYST APPL, V42, P8520, DOI 10.1016/j.eswa.2015.07.007
   Chehade W. E. H., 2021, Int. J. Electr. Comput. Eng, V11, P2613, DOI [10.11591/ijece.v11i3.pp2613-2620, DOI 10.11591/IJECE.V11I3.PP2613-2620]
   COLLIGNON A, 1995, COMP IMAG VIS, V3, P263
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Cover Thomas M, 1999, Elements of information theory
   da Costa JFP, 2011, IEEE ACM T COMPUT BI, V8, P246, DOI 10.1109/TCBB.2009.61
   Dandpat S.K., 2013, 2013 INT C COMPUTER, P1
   Delac K, 2005, INT J IMAG SYST TECH, V15, P252, DOI 10.1002/ima.20059
   El Akadi A, 2008, INT J COMPUT SCI NET, V8, P116
   Guo BF, 2009, IEEE T SYST MAN CY A, V39, P36, DOI 10.1109/TSMCA.2008.2007977
   Hasan B.M.S., 2021, J SOFT COMPUT DATA M, V1, P20, DOI DOI 10.30880/JSCDM.2021.02.01.003
   Haskins G, 2019, INT J COMPUT ASS RAD, V14, P417, DOI 10.1007/s11548-018-1875-7
   Huang WL, 2009, IEEE IMAGE PROC, P3337, DOI 10.1109/ICIP.2009.5413898
   Jansen JJ, 2004, BIOINFORMATICS, V20, P2438, DOI 10.1093/bioinformatics/bth268
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Kumar D, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P1469
   Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864
   Muhammad HI., 2021, EUROPEAN J ELECT ENG, V5, P9, DOI [10.24018/ejece.2021.5.3.321, DOI 10.24018/EJECE.2021.5.3.321]
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Petty M.D., 2012, Proceedings of the fall simulation interoperability workshop 2012 (2012 Fall SIW), Orlando, Florida, USA, P10
   Pluim JPW, 2000, LECT NOTES COMPUT SC, V1935, P452
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Safi ME., 2021, DIYALA J ENG SCI, V14, P120, DOI [10.24237/djes.2021.14211, DOI 10.24237/DJES.2021.14211]
   Sarra L, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.200601
   Sengupta D, 2022, NEUROCOMPUTING, V486, P174, DOI 10.1016/j.neucom.2021.11.023
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Su H, 2014, INT C DIGITAL HOME, P30, DOI 10.1109/ICDH.2014.13
   Su HT, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P436
   Torkkola K., 2000, MACHINE LEARNING INT, P1015
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang H., 1999, P INT ICSC S ADV INT, P22
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhu YN, 2018, SIGNAL PROCESS, V145, P175, DOI 10.1016/j.sigpro.2017.11.018
NR 40
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16261-5
EA AUG 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700007
DA 2024-07-18
ER

PT J
AU Ge, JY
   Mao, LB
   Shi, JL
   Jiang, Y
AF Ge, Junyan
   Mao, Lingbo
   Shi, Jinlong
   Jiang, Yan
TI Fusion-Mask-RCNN: Visual robotic grasping in cluttered scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic dataset; Image segmentation; Point cloud processing; Robotic
   grasping
ID CALIBRATION
AB Realizing stable robotic grasping in cluttered scenes is a key problem in the field of intelligent robots. In this paper, we design a visual strategy to grasp unoccluded objects in cluttered scenes, which improves the instability of grasping caused by stacking objects. Firstly, a method for generating synthetic dataset is proposed to obtain object bounding boxes, masks, and occlusion information, which saves labor and time; Secondly, based on Mask-RCNN image segmentation network, fusion of color information and re-encoded depth information improves the accuracy of object segmentation; Finally, we obtain point cloud of unoccluded objects via object segmentation results, and use point cloud registration to calculate the poses of objects, realizing the 6-Dof grasping. Experiments show that the occlusion detection and segmentation accuracy of the proposed network on the synthetic dataset reaches 97%, which is better than the original network. The accuracy of the network on the real scene dataset is 92%, which also shows good performance. In real grasping task, the successfully grasping rate reaches 91%.
C1 [Ge, Junyan; Mao, Lingbo; Shi, Jinlong] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212100, Peoples R China.
   [Jiang, Yan] Beijing Inst Fash Technol, Coll Arts & Sci, Beijing 100029, Peoples R China.
C3 Jiangsu University of Science & Technology; Beijing Institute of Fashion
   Technology
RP Shi, JL (corresponding author), Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212100, Peoples R China.
EM shi_jinlong@163.com
FU Teaching reform key project of Beijing Institute of Fashion Technology
   [ZDJG-1712]; National Key Research and Development Program of the
   Ministry of Science and Technology [2018YFC0309104]
FX The authors would like to thank Maximilian Denninger (Scientist at
   German Aerospace Center) for helpful discussions on topics related to
   this work. Also, we would like to thank Csaba Botos and his teammates,
   the provider of open-source code of Mask-RCNN written in PyTorch.
   Meanwhile, we would like to express our deepest gratitude to Dr. Kai
   Ding from BOSCH Research Center for his invaluable contributions to this
   research. Dr. Kai Ding provides some novel ideas for this paper and
   makes careful revisions to the writing of this paper. This project is
   sponsored by the Teaching reform key project of Beijing Institute of
   Fashion Technology "Classroom Observation and Analysis of College Basic
   Courses based on COUPS Scale" (ZDJG-1712) and National Key Research and
   Development Program of the Ministry of Science and Technology
   (2018YFC0309104).
CR [Anonymous], 2018, P ROBOTICS SCI SYSTE, DOI DOI 10.15607/RSS.2018.XIV.021
   Bergamini L, 2020, ADV ENG INFORM, V44, DOI 10.1016/j.aei.2020.101052
   Bukschat Y, ARXIV, DOI DOI 10.48550/ARXIV.2011.04307
   Chemelil P K, 2021, JKUAT COETEC
   Chen W, 2020, PROC CVPR IEEE, P4232, DOI 10.1109/CVPR42600.2020.00429
   Chen ZX, 2022, C IND ELECT APPL, P804, DOI 10.1109/ICIEA54703.2022.10006045
   Denninger M, 2019, ARXIV
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hafiz AM, 2020, INT J MULTIMED INF R, V9, P171, DOI 10.1007/s13735-020-00195-x
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He Y, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3002, DOI 10.1145/3447548.3467205
   Hou Rui, 2020, P IEEECVF C COMPUTER, DOI DOI 10.48550/ARXIV.1912.01202
   Li B, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00051
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mahanta GB, 2022, P I MECH ENG E-J PRO, V236, P712, DOI 10.1177/09544089211039977
   Mahler J, 2018, IEEE INT CONF ROBOT, P5620
   Mahler J, 2016, IEEE INT CONF ROBOT, P1957, DOI 10.1109/ICRA.2016.7487342
   Miao CX, 2021, CHIN CONTR CONF, P3943, DOI 10.23919/CCC52363.2021.9550615
   Mohamad M, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P598, DOI 10.1109/3DV.2015.74
   PARK FC, 1994, IEEE T ROBOTIC AUTOM, V10, P717, DOI 10.1109/70.326576
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Ren T, 2021, J ELECTRON IMAGING, V30, DOI 10.1117/1.JEI.30.6.063025
   ROTH WE, 1952, P AM MATH SOC, V3, P392, DOI 10.2307/2031890
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Schneider L, 2017, LECT NOTES COMPUT SC, V10269, P98, DOI 10.1007/978-3-319-59126-1_9
   Segal Aleksandr, 2009, ROBOTICS SCI SYSTEMS, V2
   SHIU YC, 1989, IEEE T ROBOTIC AUTOM, V5, P16, DOI 10.1109/70.88014
   Wang YW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1477, DOI 10.1109/ROBIO.2018.8665076
   Ward I.R., 2019, RGB-D Image Analysis and Processing, P169, DOI 10.1007/978-3-030-28603-3_8
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
NR 34
TC 0
Z9 0
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20953
EP 20973
DI 10.1007/s11042-023-16365-y
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042485500001
DA 2024-07-18
ER

PT J
AU Caruccio, L
   Cimino, G
   Deufemia, V
   Iuliano, G
   Stanzione, R
AF Caruccio, Loredana
   Cimino, Gaetano
   Deufemia, Vincenzo
   Iuliano, Gianpaolo
   Stanzione, Roberto
TI Surveying federated learning approaches through a multi-criteria
   categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine Learning; Federated Learning; Data Privacy
ID POISONING ATTACKS; PRIVACY
AB In recent years, more and more attention has been paid to the privacy issues associated with storing user data in a centralized manner. In fact, strict laws have been introduced to regulate the use of personal data, making it more difficult to find enough data for training artificial intelligence models. As this new challenge arises, Federated Learning (FL) has been introduced to leverage user data without jeopardizing their privacy. To make FL possible, it was necessary to face several technical and algorithmic challenges. As a result, many different approaches have been proposed in recent years. In this survey, we begin by describing the FL approach and delving into both its advantages and challenges. Furthermore, a thorough analysis of various literature approaches is provided through the exploration of three key aspects characterizing them. Firstly, different network topologies proposed over the years are discussed in detail, with a focus on highlighting the benefits and drawbacks of each. Secondly, attention is given to the data distribution aspect, particularly focusing on the feature and sample spaces of the data, which may differ among participants. Lastly, potential security threats associated with FL are outlined, and the countermeasures proposed in the literature to address them are described in detail. By employing these analytical criteria, comparisons are made among the different approaches to provide a multi-criteria categorization of FL methodologies.
C1 [Caruccio, Loredana; Cimino, Gaetano; Deufemia, Vincenzo; Iuliano, Gianpaolo; Stanzione, Roberto] Univ Salerno, Dept Comp Sci, Via Giovanni Paolo 2, I-84084 Fisciano, SA, Italy.
C3 University of Salerno
RP Caruccio, L; Cimino, G (corresponding author), Univ Salerno, Dept Comp Sci, Via Giovanni Paolo 2, I-84084 Fisciano, SA, Italy.
EM lcaruccio@unisa.it; gcimino@unisa.it
RI Stanzione, Roberto/KFQ-0851-2024; Deufemia, Vincenzo/M-3553-2016
OI Stanzione, Roberto/0000-0001-9212-821X; Iuliano,
   Gianpaolo/0000-0001-5049-0317; Cimino, Gaetano/0000-0001-8061-7104;
   Deufemia, Vincenzo/0000-0002-6711-3590; Caruccio,
   Loredana/0000-0002-2418-1606
FU EU [PE00000014]
FX AcknowledgementsThis work was partially supported by project SERICS
   (PE00000014) under the NRRP MUR program funded by the EU - NGEU.
CR Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]
   Andrew G, 2021, ADV NEUR IN, V34
   Awan S, 2021, LECT NOTES COMPUT SC, V12972, P455, DOI 10.1007/978-3-030-88418-5_22
   Bagdasaryan E, 2020, PR MACH LEARN RES, V108, P2938
   Balakrishnan R, 2021, P 2021 INT C LEARN R
   Baruch M, 2019, ADV NEUR IN, V32
   Blanchard P, 2017, ADV NEUR IN, V30
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Caldas S., 2018, arXiv
   Caldas S., 2018, P SYSML C, P1
   Cao KY, 2020, IEEE ACCESS, V8, P85714, DOI 10.1109/ACCESS.2020.2991734
   Chen TY, 2020, Arxiv, DOI arXiv:2007.06081
   Chen XY, 2017, Arxiv, DOI arXiv:1712.05526
   Chen YQ, 2020, IEEE INTELL SYST, V35, P83, DOI 10.1109/MIS.2020.2988604
   Chen Y, 2020, INFORM SCIENCES, V522, P69, DOI 10.1016/j.ins.2020.02.037
   Cheng KW, 2021, IEEE INTELL SYST, V36, P87, DOI 10.1109/MIS.2021.3082561
   Dinh C. T., 2020, P 49 INT C PAR PROC, P1
   Doku R, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369581
   Dong CZ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143197
   Duchi JC, 2018, J AM STAT ASSOC, V113, P182, DOI 10.1080/01621459.2017.1389735
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Fang MH, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1623
   Feng SW, 2020, Arxiv, DOI arXiv:2001.11154
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Fung C., 2020, 23 INT S RES ATT INT, P301
   Gao DS, 2020, Arxiv, DOI arXiv:1909.05784
   Gao DS, 2019, IEEE INT CONF BIG DA, P2552, DOI 10.1109/BigData47090.2019.9005992
   Goddard M, 2017, INT J MARKET RES, V59, P703, DOI 10.2501/IJMR-2017-050
   Hardy S, 2017, Arxiv, DOI arXiv:1711.10677
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Hosseinalipour S, 2022, IEEE ACM T NETWORK, V30, P1569, DOI 10.1109/TNET.2022.3143495
   Hu BX, 2018, IEEE GLOB COMM CONF
   Cho YJ, 2020, Arxiv, DOI arXiv:2010.01243
   Ju C, 2020, IEEE ENG MED BIO, P3040, DOI [10.1109/EMBC44109.2020.9175344, 10.1109/embc44109.2020.9175344]
   Khan WZ, 2019, FUTURE GENER COMP SY, V97, P219, DOI 10.1016/j.future.2019.02.050
   Konečny J, 2016, Arxiv, DOI arXiv:1610.02527
   Kumar A., 2022, ROBOTICS CYBERSECURI, P89, DOI 10.1007/978-3-030-96737-6_5
   Lee J.-W., 2020, arXiv
   Li GH, 2022, Arxiv, DOI arXiv:2206.10546
   Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599
   Li QB, 2020, AAAI CONF ARTIF INTE, V34, P4642
   Lim WYB, 2020, IEEE COMMUN SURV TUT, V22, P2031, DOI 10.1109/COMST.2020.2986024
   Liu W, 2022, IEEE T SIGNAL INF PR, V8, P131, DOI 10.1109/TSIPN.2022.3151242
   Liu Y, 2020, IEEE INTELL SYST, V35, P70, DOI 10.1109/MIS.2020.2988525
   Luo SQ, 2020, IEEE T WIREL COMMUN, V19, P6535, DOI 10.1109/TWC.2020.3003744
   Lyu M., 2016, arXiv
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Melis L, 2019, P IEEE S SECUR PRIV, P691, DOI 10.1109/SP.2019.00029
   Mothukuri V, 2021, FUTURE GENER COMP SY, V115, P619, DOI 10.1016/j.future.2020.10.007
   Nguyen DC, 2021, IEEE COMMUN SURV TUT, V23, P1622, DOI 10.1109/COMST.2021.3075439
   Nilsson A, 2018, DIDL'18: PROCEEDINGS OF THE SECOND WORKSHOP ON DISTRIBUTED INFRASTRUCTURES FOR DEEP LEARNING, P1, DOI 10.1145/3286490.3286559
   Qian L, 2009, LECT NOTES COMPUT SC, V5931, P626, DOI 10.1007/978-3-642-10665-1_63
   Rahman SA, 2020, IEEE NETWORK, V34, P310, DOI 10.1109/MNET.011.2000286
   Rai S, 2022, AI-BASEL, V3, P124, DOI 10.3390/ai3010008
   Ryffel T, 2018, Arxiv, DOI arXiv:1811.04017
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Sun ZT, 2019, Arxiv, DOI arXiv:1911.07963
   Tolpegin V., 2020, Computer Security-ESORICS 2020, P480
   Truex S, 2020, PROCEEDINGS OF THE THIRD ACM INTERNATIONAL WORKSHOP ON EDGE SYSTEMS, ANALYTICS AND NETWORKING (EDGESYS'20), P61, DOI 10.1145/3378679.3394533
   Wachter S, 2018, COMPUT LAW SECUR REV, V34, P436, DOI 10.1016/j.clsr.2018.02.002
   Wang G, 2019, IEEE INT CONF BIG DA, P2597, DOI 10.1109/BigData47090.2019.9006179
   Wang N, 2019, PROC INT CONF DATA, P638, DOI 10.1109/ICDE.2019.00063
   Wang Y, 2017, THESIS U ALBERTA
   Wang Z, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11101548
   Wibawa F, 2022, arXiv
   Yang HW, 2021, IEEE T NETW SCI ENG, V8, P1084, DOI 10.1109/TNSE.2020.2996612
   Yang SW, 2019, Arxiv, DOI arXiv:1911.09824
   Ye DD, 2020, IEEE ACCESS, V8, P23920, DOI 10.1109/ACCESS.2020.2968399
   Zhang C, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106775
   Zhang CL, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P493
   Zhang JL, 2021, IEEE INTERNET THINGS, V8, P3310, DOI 10.1109/JIOT.2020.3023126
   Zhang WY, 2021, IEEE ACCESS, V9, P24462, DOI 10.1109/ACCESS.2021.3056919
   Zhou XC, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13030073
   Zhu LG, 2019, ADV NEUR IN, V32
NR 75
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 3
PY 2023
DI 10.1007/s11042-023-16050-0
EA AUG 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O3BI7
UT WOS:001042601200008
DA 2024-07-18
ER

PT J
AU Zhou, SR
   Zou, WM
AF Zhou, Shuren
   Zou, Wenmin
TI Fusion pose guidance and transformer feature enhancement for person
   re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Occluded person re-identification;
   Convolutional neural network; Transformer; Attention mechanism; Pose
   estimation
AB In spite of Convolutional Neural Network (CNN) has dominated in the area of Person Re-Identification, Transformer-based methods have emerged with their advantages in computer vision for processing long sequences in recent two years. In this work, for the purpose of reinforcing complementary advantages of Transformer and CNN in computer vision, a concise method combining Convolution and Transformer is proposed to boost the performance. Firstly, a convolutional network with attention mechanism is employed to generate features with channel and inter-channel relationship information. Moreover, a feature enhancement module is designed to combine pose information and ViT information, and the heatmap generated by the pose estimator is applied to guide ViT features to become good discriminative features. Finally, a relationship reinforced transformer layer is proposed to effectively increase the relationship between features. Experimental results show that the proposed method achieves superior results than interrelated advanced methods on two large-scale person re-Identification benchmark datasets and one occlusion dataset. For Market-1501, our method called Fusion Pose Guidance and Transformer Feature Enhancement for Person Re-Identification gain 94.3% and 87.0% for Rank-1 and mAP respectively. For DukeMTMC-reID our method reaches 88.7% and 77.2% for Rank-1 and mAP respectively. Especially, for the dataset Occluded-Duke, compared with the state of art model HONet, our method, with up to 2.7% and 4.5% performance gains in Rank-1 and mAP respectively.
C1 [Zhou, Shuren; Zou, Wenmin] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
C3 Changsha University of Science & Technology
RP Zhou, SR (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Peoples R China.
EM zsr_hn@163.com
RI zhou, shuren/JNS-2873-2023
OI zhou, shuren/0000-0002-0465-3258
FU National Natural Science Foundation of China [61972056]; Hunan
   Provincial Natural Science Foundation of China [2021JJ30743]; Degree
   amp; Post-graduate Education Reform Project of Hunan Province of China
   [2020JGZD043]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61972056, in part by the Hunan
   Provincial Natural Science Foundation of China under Grant 2021JJ30743,
   in part by the Degree & Post-graduate Education Reform Project of Hunan
   Province of China under Grant 2020JGZD043.
CR Adil M, 2020, IEEE ACCESS, V8, P177351, DOI 10.1109/ACCESS.2020.3023594
   Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Gao H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061239
   Ge Yixiao., 2018, Advances in Neural Information Processing Systems, P1229
   Han L, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1469, DOI 10.1145/3394171.3413927
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He LH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P364
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hendrycks D., 2016, ARXIV
   Hermans Alexander, 2017, ARXIV170307737
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang Y, 2017, NEUROCOMPUTING, V241, P191, DOI 10.1016/j.neucom.2017.02.055
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kumar TA, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060904
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun H, 2019, IEEE I CONF COMP VIS, P6736, DOI 10.1109/ICCV.2019.00684
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun P., 2020, arXiv
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zhang X, 2017, ARXIV
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, ARXIV
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 62
TC 1
Z9 1
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21745
EP 21763
DI 10.1007/s11042-023-15303-2
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400008
DA 2024-07-18
ER

PT J
AU Maurya, A
   Singh, D
AF Maurya, Anjali
   Singh, Durgesh
TI Rotation, scaling, and translation invariant an optimized and effective
   robust watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Discrete wavelet transform; SURF; Differential
   evolution; Singular value decomposition; M-SAC algorithm
ID INTEGER WAVELET TRANSFORM; IMAGE AUTHENTICATION; SVD
AB These days image processing technology has evolved a lot. Digital media can be distorted easily due to the availability of editing tools. So, watermarking can be used to protect digital media. This article proposes the Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) based effective and optimal robust image watermarking technique using the differential evolution (DE) algorithm, which is invariant against rotation, scaling, and translation (RST). The watermark embedding process uses a 3-level DWT and SVD. Here, speeded-up robust features (SURF) are also used to extract feature points and match features. The RST-attacked image can be restored using these features by applying the M-estimator SAmple Consensus(M-SAC) algorithm. DE algorithm is used to estimate the optimized value of the scaling factor. The optimized scaling factor is assisted in acquiring the highest possible robustness with enhanced imperceptibility. After experimentation, results illustrate the proposed technique is invariant to the RST, and signal processing attacks.
C1 [Maurya, Anjali; Singh, Durgesh] PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Singh, D (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Dept Comp Sci & Engn, Jabalpur, Madhya Pradesh, India.
EM durgesh@iiitdmj.ac.in
RI Singh, Durgesh/AAZ-2801-2020
OI Singh, Durgesh/0000-0002-6078-1502
CR Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Arafa M, 2014, INT CONF DIGIT INFO, P216, DOI 10.1109/DICTAP.2014.6821685
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bilal, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103479
   Cui XC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196306
   Hana O, 2013, ROBUST MULTIPLE WATE
   Kawamura M, 2018, SMART INNOV SYST TEC, V81, P381, DOI 10.1007/978-3-319-63856-0_46
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Lyu WL, 2014, KSII T INTERNET INF, V8, P3591, DOI 10.3837/tiis.2014.10.018
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   mathworks, FIND IM ROT SCAL US
   Mehta R, 2017, INT J MACH LEARN CYB, V8, P379, DOI 10.1007/s13042-015-0331-z
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Owalla FO, 2012, IEEE MEDITERR ELECT, P379, DOI 10.1109/MELCON.2012.6196453
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Rinki K, 2022, J KING SAUD UNIV-COM, V34, P5510, DOI 10.1016/j.jksuci.2021.01.013
   Senapati RK, 2020, ARAB J SCI ENG, V45, P3331, DOI 10.1007/s13369-020-04387-9
   Singh D., 2013, Intelligent Interactive Technologies and Multimedia, P111, DOI [10.1007/978-3-642-37463-010, DOI 10.1007/978-3-642-37463-010]
   Singh D, 2023, MULTIMED TOOLS APPL, V82, P1045, DOI 10.1007/s11042-022-13270-8
   Singh D, 2019, MULTIMED TOOLS APPL, V78, P4197, DOI 10.1007/s11042-017-5454-7
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Thorat CG, 2010, PROCEDIA COMPUT SCI, V2, P236, DOI 10.1016/j.procs.2010.11.030
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Viet Quoc Pham, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P473
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030410
   Ye XY, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P323, DOI 10.1109/CISP.2014.7003800
   Zhang L, 2012, 2012 INTERNATIONAL CONFERENCE ON INDUSTRIAL CONTROL AND ELECTRONICS ENGINEERING (ICICEE), P1092, DOI 10.1109/ICICEE.2012.289
   Zhang YP, 2017, ALGORITHMS, V10, DOI 10.3390/a10020041
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 34
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20033
EP 20053
DI 10.1007/s11042-023-16321-w
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001039850700002
DA 2024-07-18
ER

PT J
AU Verma, S
   Singh, VK
AF Verma, Sakshi
   Singh, Vishal K. K.
TI Multi-sensor fusion for real-time object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kalman filter; Rotation vector; Geohash filter; Linear acceleration
ID SYSTEM
AB Accurate orientation and position estimation are critical elements in optimizing real-time object tracking performance when leveraging smartphone sensors such as accelerometers and gyroscopes. The primary challenges encountered in smartphone-based object tracking are attributed to the GPS signal, canyon effect, and orientation errors, accumulation error in sensor. To address these limitations, a novel approach is proposed wherein a smartphone application is developed based on IMU Multi -sensor fusion using Kalman filter and Rotation vector. The proposed approach integrates Kalman filtering to fuse sensor data and leverages the rotation vector for precise orientation estimation. Additionally, geohash filtering is employed to efficiently proficiency in quantifying intricate spatial interdependencies and display track paths on maps within the application. A detailed mathematical analysis and thorough comparison with existing algorithms in the field proves the dexterity of the proposed object tracking scheme. The comprehensive evaluation showcases the algorithm's capability and advancement compared to state-of-the-art approaches.
C1 [Verma, Sakshi; Singh, Vishal K. K.] Indian Inst Informat Technol, Dept Comp Sci, Wireless Commun & Analyt Res Lab WCARL, Lucknow 226002, Uttar Pradesh, India.
RP Singh, VK (corresponding author), Indian Inst Informat Technol, Dept Comp Sci, Wireless Commun & Analyt Res Lab WCARL, Lucknow 226002, Uttar Pradesh, India.
EM sakshiv1357@gmail.com; vashukrishna@gmail.com
RI Singh, Vishal Krishna/ACZ-1600-2022
OI Singh, Vishal Krishna/0000-0002-5438-579X
CR Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Celesti A, 2018, IEEE SENS J, V18, P4795, DOI 10.1109/JSEN.2017.2777786
   Choi E, 2017, IEEE T CONSUM ELECTR, V63, P450, DOI 10.1109/TCE.2017.015064
   Faragher R, 2012, IEEE SIGNAL PROC MAG, V29, P128, DOI 10.1109/MSP.2012.2203621
   Fleischer P. B., 2012, 2012 IEEE 4th International Conference on Adaptive Science & Technology (ICAST 2012), P1, DOI 10.1109/ICASTech.2012.6381056
   Gobi R, 2021, MULTIMED TOOLS APPL, V80, P15377, DOI 10.1007/s11042-020-10438-y
   Guo N, 2019, IEEE ACCESS, V7, P39815, DOI 10.1109/ACCESS.2019.2906871
   Ibisch A, 2013, IEEE INT VEH SYM, P829, DOI 10.1109/IVS.2013.6629569
   Kok M, 2017, FOUND TRENDS SIGNAL, V11, P1, DOI 10.1561/2000000094
   Li CD, 2019, IEEE SENS J, V19, P6460, DOI 10.1109/JSEN.2019.2907716
   Lin CY, 2020, IEEE SYST J, V14, P4523, DOI 10.1109/JSYST.2019.2960193
   Manogaran G, 2021, IEEE SENS J, V21, P15564, DOI 10.1109/JSEN.2020.3017384
   Obediencia DC, 2019, I C HUMANOID NANOTEC, DOI 10.1109/HNICEM48295.2019.9073452
   Permatasari J, 2020, MULTIMED TOOLS APPL, V79, P32665, DOI 10.1007/s11042-020-09438-9
   Plangi S, 2018, IEEE SENS J, V18, P10077, DOI 10.1109/JSEN.2018.2873050
   Vitali RV, 2021, IEEE SENS J, V21, P3561, DOI 10.1109/JSEN.2020.3026895
   Yang PT, 2020, IEEE T VEH TECHNOL, V69, P14355, DOI 10.1109/TVT.2020.3031900
NR 18
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19563
EP 19585
DI 10.1007/s11042-023-16144-9
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037377100005
DA 2024-07-18
ER

PT J
AU Chauhan, P
   Sharma, N
   Sikka, G
AF Chauhan, Priyavrat
   Sharma, Nonita
   Sikka, Geeta
TI On the importance of pre-processing in small-scale analyses of twitter:
   a case study of the 2019 Indian general election
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Election prediction; Lok Sabha election 2019; Media bias; Pre-processing
   of twitter data for election prediction; Twitter sentiment analysis;
   Twitter-xlm-roberta-base-sentiment
ID SENTIMENT ANALYSIS; SOCIAL MEDIA; ALGORITHMS
AB The main purpose of this paper is to emphasize the role of data pre-processing in the sentiment analysis of Twitter data. The paper provides detailed analysis and methods to understand and handle Twitter data for analyzing public views during elections. We argue that in order to accurately assess public opinion towards a political party or leader, there is a need to focus on users' personal tweets rather than tweets from news or media sources. We also argue that emojis, punctuations, stopwords, emphasized words, and some specific regions (Unicode, #, @) inside tweets play a very significant role in analyzing sentiments. In view of this, this paper provides a novel set of pre-processing steps that perform filtering and cleaning of tweets without losing any vital information. For experimentation, a small case study is taken that comprises 258,891 instances related to the 2019 Indian General Election from Twitter using #LoksabhaElection2019. A pre-trained sentiment analysis model called twitter-xlm-roberta-base-sentiment is used to analyze the sentiment of public tweets. Results show that tweets from media sources and the specific regions of tweets inject data bias and affect final sentiment analysis results. We found that out of the collected data, only 40% of tweets were useful for determining public sentiments for election analysis, while the rest were irrelevant media tweets. Also, an increase in negative and neutral sentiment outputs is observed due to the presence of media tweets and the specific regions. Further, explorative analysis analyzes public sentiments towards various political terms inferred using top2vec topic modeling.
C1 [Chauhan, Priyavrat] Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144008, Punjab, India.
   [Sharma, Nonita] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Kashmere Gate, Delhi 110006, India.
   [Sikka, Geeta] Natl Inst Technol Delhi, Dept Comp Sci & Engn, Plot FA7, Zone P1, GT Karnal Rd, Delhi 110036, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Indira Gandhi Delhi Technical
   University for Women (IGDTUW); National Institute of Technology (NIT
   System); National Institute of Technology Delhi
RP Chauhan, P (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144008, Punjab, India.
EM priyavrat.cs.18@nitj.ac.in; nonitasharma@igdtuw.ac.in;
   sikkag@nitdelhi.ac.in
RI Chauhan, Priyavrat/ABC-5698-2020
OI Chauhan, Priyavrat/0000-0003-3685-182X
CR Abdullah Manal, 2020, International Journal of Computers and Applications, V42, P661, DOI 10.1080/1206212X.2018.1482395
   Agarwal A, 2020, COMM COM INF SC, V1168, P38, DOI 10.1007/978-3-030-43887-6_4
   Al Hamoud A, 2018, LECT NOTES ARTIF INT, V10868, P736, DOI 10.1007/978-3-319-92058-0_71
   Alam S, 2019, COMPUT MATH ORGAN TH, V25, P319, DOI 10.1007/s10588-018-9266-8
   Ali H, 2022, SOFT COMPUT, V26, P7535, DOI 10.1007/s00500-021-06569-5
   Angelov D., 2020, ARXIV
   [Anonymous], 2016, International Journal of Computer Applications, DOI [DOI 10.5120/IJCA2016908625, 10.5120/ijca2016908625]
   Antonakaki D, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114006
   Appel O, 2016, IEEE C EVOL COMPUTAT, P4950, DOI 10.1109/CEC.2016.7744425
   Asghar MZ, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12233
   Awais M, 2021, J AMB INTEL HUM COMP, V12, P4305, DOI 10.1007/s12652-019-01378-z
   Babu Nirmal Varghese, 2022, SN Comput Sci, V3, P74, DOI 10.1007/s42979-021-00958-1
   Bahri Shivani, 2018, Procedia Computer Science, V132, P669, DOI 10.1016/j.procs.2018.05.067
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bansal Barkha, 2019, International Journal of Web Based Communities, V15, P85
   Barbieri F, 2021, ARXIV
   Batista-Navarro Riza Theresa, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P559, DOI 10.1007/978-3-642-37247-6_45
   BILAL M, 2018, 2018 12 INT C MATH A, P1, DOI DOI 10.1109/MACS.2018.8628445
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Bose R, 2019, SMART INNOV SYST TEC, V107, P427, DOI 10.1007/978-981-13-1747-7_41
   Budiharto W, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0164-1
   Chakraborty K, 2020, IEEE T COMPUT SOC SY, V7, P450, DOI 10.1109/TCSS.2019.2956957
   Chan JYL, 2023, ARTIF INTELL REV, V56, P749, DOI 10.1007/s10462-022-10183-8
   Chauhan P, 2021, J AMB INTEL HUM COMP, V12, P2601, DOI 10.1007/s12652-020-02423-y
   Curiskis SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.04.002
   Dangi D, 2022, MULTIMED TOOLS APPL, V81, P42261, DOI 10.1007/s11042-022-13492-w
   Duncombe C, 2019, INT POLIT SOCIOL, V13, P409, DOI 10.1093/ips/olz013
   Feldman R, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2436256.2436274
   Sánchez-Rada JF, 2019, INFORM FUSION, V52, P344, DOI 10.1016/j.inffus.2019.05.003
   Gandhi A, 2023, INFORM FUSION, V91, P424, DOI 10.1016/j.inffus.2022.09.025
   Gayo-Avello D, 2011, COMMUN ACM, V54, P121, DOI 10.1145/2001269.2001297
   Gayo-Avello Daniel., 2011, ICWSM
   Heredia B, 2018, SOC NETW ANAL MIN, V8, DOI 10.1007/s13278-018-0525-y
   Jacobi C, 2016, DIGIT JOURNAL, V4, P89, DOI 10.1080/21670811.2015.1093271
   Jain Vinay K., 2017, International Journal of Intelligent Systems and Applications, V9, P20, DOI 10.5815/ijisa.2017.12.03
   Karami Amir, 2018, International Journal of Strategic Decision Sciences, V9, P18, DOI 10.4018/IJSDS.2018010102
   Khan A, 2021, COMPUT INTELL-US, V37, P1745, DOI 10.1111/coin.12459
   Khatua A, 2015, P ANN HICSS, P1676, DOI 10.1109/HICSS.2015.202
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Liu CC, 2021, J SAF SCI RESIL, V2, P246, DOI 10.1016/j.jnlssr.2021.10.003
   Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059
   Liu RW, 2021, ANN GIS, V27, P43, DOI 10.1080/19475683.2020.1829704
   Makazhanov A, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0193-5
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mohbey K. K., 2020, Journal of Digital Information Management, V2, P1, DOI [10.1007/s42488-019-00013-y, DOI 10.1007/S42488-019-00013-Y]
   Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6
   Naseem U, 2021, MULTIMED TOOLS APPL, V80, P35239, DOI 10.1007/s11042-020-10082-6
   Naz H, 2021, MULTIMED TOOLS APPL, V80, P11443, DOI 10.1007/s11042-020-10190-3
   Oikonomou L., 2018, 2018 S E EUR DES AUT, P1, DOI [10.23919/SEEDA-CECNSM.2018.8544919, DOI 10.23919/SEEDA-CECNSM.2018.8544919]
   Pandey AC, 2017, INFORM PROCESS MANAG, V53, P764, DOI 10.1016/j.ipm.2017.02.004
   Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Sahi Geetanjali, 2022, International Journal of Information Communication Technologies and Human Development, V14, P1, DOI 10.4018/IJICTHD.295561
   Salunkhe P., 2017, INT RES J ENG TECHNO, V4, P539
   Santos JS, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00813-4
   Sharma P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1966, DOI 10.1109/BigData.2016.7840818
   Shi L., 2012, PREDICTING US PRIMAR, P1, DOI DOI 10.1186/S13635-017-0057-4
   Singh Akhilesh Kumar, 2017, International Journal of Modern Education and Computer Science, V9, P60, DOI 10.5815/ijmecs.2017.09.07
   Singh P., 2017, C E BUS E SERV E SOC, P412, DOI DOI 10.1007/978-3-319-68557-1_36
   Singh P, 2020, GOV INFORM Q, V37, DOI 10.1016/j.giq.2019.101444
   Singhal K, 2015, ADV INTELL SYST, V339, P469, DOI 10.1007/978-81-322-2250-7_46
   Sohrabi MK, 2019, MULTIMED TOOLS APPL, V78, P24863, DOI 10.1007/s11042-019-7586-4
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Spina S, 2019, DISCOURSE PROCESS, V56, P345, DOI 10.1080/0163853X.2018.1510654
   Stieglitz S, 2012, P PAC AS C INF SYST
   Stieglitz S, 2013, SOC NETW ANAL MIN, V3, P1277, DOI 10.1007/s13278-012-0079-3
   Symeonidis S, 2018, EXPERT SYST APPL, V110, P298, DOI 10.1016/j.eswa.2018.06.022
   Tomazic T, 2019, LEX LOCALIS, V17, P1057, DOI 10.4335/17.4.1057-1079(2019)
   Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1
   Wankhede S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P723, DOI 10.1109/ICICCT.2018.8473277
   Wisnu GRG, 2020, 2020 5TH INTERNATIONAL WORKSHOP ON BIG DATA AND INFORMATION SECURITY (IWBIS 2020), P37, DOI [10.1109/IWBIS50925.2020.9255583, 10.1109/iwbis50925.2020.9255583]
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yu JF, 2020, IEEE-ACM T AUDIO SPE, V28, P429, DOI 10.1109/TASLP.2019.2957872
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhao JQ, 2017, IEEE ACCESS, V5, P2870, DOI 10.1109/ACCESS.2017.2672677
   Zheng A., 2018, Feature Engineering for Machine Learning
   Zhou J, 2021, NEUROCOMPUTING, V455, P47, DOI 10.1016/j.neucom.2021.05.040
   Zucco C, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1333
NR 78
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19219
EP 19258
DI 10.1007/s11042-023-16158-3
EA JUL 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000004
DA 2024-07-18
ER

PT J
AU Kumar, A
   Aelgani, V
   Vohra, R
   Gupta, SK
   Bhagawati, M
   Paul, S
   Saba, L
   Suri, N
   Khanna, NN
   Laird, JR
   Johri, AM
   Kalra, M
   Fouda, MM
   Fatemi, M
   Naidu, S
   Suri, JS
AF Kumar, Ashish
   Aelgani, Vivekanand
   Vohra, Rubeena
   Gupta, Suneet K.
   Bhagawati, Mrinalini
   Paul, Sudip
   Saba, Luca
   Suri, Neha
   Khanna, Narendra N.
   Laird, John R.
   Johri, Amer M.
   Kalra, Manudeep
   Fouda, Mostafa M.
   Fatemi, Mostafa
   Naidu, Subbaram
   Suri, Jasjit S.
TI Artificial intelligence bias in medical system designs: a systematic
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Data bias; Algorithmic bias; Bias visualization; Bias accountability;
   Mitigating bias; Legal manifestations
ID RISK; DISCRIMINATION; HEALTH; AI; CLASSIFICATION; FUTURE; PLAQUE
AB Inherent bias in the artificial intelligence (AI)-model brings inaccuracies and variabilities during clinical deployment of the model. It is challenging to recognize the source of bias in AI-model due to variations in datasets and black box nature of system design. Additionally, there is no distinct process to identify the potential source of bias in the AI-model. To the best of our knowledge, this is the first review of its kind that addresses the bias in AI-model by categorizing 48 studies into three classes, namely, point-based, image-based, and hybrid-based AI-models. Selection strategy using PRISMA is adopted to select the 72 crucial AI studies for identifying bias in AI models. Using the three classes, bias is identified in these studies based on 44 critical AI attributes. Bias in the AI-models is computed by analytical, butterfly, and ranking-based bias models. These bias models were evaluated using two experts and compared using variability analysis. AI-studies that lacked sufficient AI-attributes are more prone to risk-of-bias (RoB) in all three classes. Studies with high RoB loses fins in the butterfly model. It has been analyzed that the majority of the studies in healthcare suffer from data bias and algorithmic bias due to incomplete specifications mentioned in the design protocol and weak AI design exploited for prediction.
C1 [Kumar, Ashish; Gupta, Suneet K.] Bennett Univ, Sch Comp Sci Engn & Technol, Greater Noida, UP, India.
   [Aelgani, Vivekanand] CMR Coll Engn & Technol, Dept CSE, Seethariguda, Telangana, India.
   [Vohra, Rubeena] Bharati Vidyapeeths Coll Engn, Dept ECE, New Delhi, India.
   [Bhagawati, Mrinalini; Paul, Sudip] North Eastern Hill Univ, Dept Biomed Engn, Shillong, India.
   [Saba, Luca] Univ Cagliari, Dept Radiol, Cagliari, Italy.
   [Suri, Neha] Mira Loma High Sch, Sacramento, CA 95821 USA.
   [Khanna, Narendra N.] Indraprastha APOLLO Hosp, Dept Cardiol, New Delhi, India.
   [Laird, John R.] St Helena Hosp, Cardiol Dept, St Helena, CA USA.
   [Johri, Amer M.] Queens Univ, Dept Med, Div Cardiol, Kingston, ON, Canada.
   [Kalra, Manudeep] Massachusetts Gen Hosp, Dept Radiol, 55 Fruit St, Boston, MA USA.
   [Fouda, Mostafa M.] Idaho State Univ, Dept Elect & Comp Engn, Pocatello, ID 83209 USA.
   [Fatemi, Mostafa] Mayo Clin, Coll Med & Sci, Dept Physiol & BME, Rochester, MN 55441 USA.
   [Naidu, Subbaram] Univ Minnesota, Elect Engn Dept, Duluth, MN 55812 USA.
   [Suri, Jasjit S.] AtheroPoint, Stroke Diagnost & Monitoring Div, Roseville, CA 95661 USA.
C3 North Eastern Hill University; University of Cagliari; Queens University
   - Canada; Harvard University; Massachusetts General Hospital; Idaho;
   Idaho State University; Mayo Clinic; University of Minnesota System;
   University of Minnesota Duluth
RP Suri, JS (corresponding author), AtheroPoint, Stroke Diagnost & Monitoring Div, Roseville, CA 95661 USA.
EM jasjit.suri@atheropoint.com
RI Arjmandmanesh, Saba/AGA-7907-2022; Fouda, Mostafa M./G-7324-2012
OI Fouda, Mostafa M./0000-0003-1790-8640; Vohra,
   Rubeena/0009-0000-0650-8997
CR Abbasi-Sureshjani S, 2020, LECT NOTES COMPUT SC, V12446, P183, DOI 10.1007/978-3-030-61166-8_20
   Acharya UR, 2014, ULTRASCHALL MED, V35, P237, DOI 10.1055/s-0032-1330336
   Acharya UR, 2013, COMPUT METH PROG BIO, V110, P66, DOI 10.1016/j.cmpb.2012.09.008
   Agarwal M, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105571
   Ahmed S, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P557, DOI 10.1109/ICICT50816.2021.9358507
   Ahn E, 2020, IEEE T MED IMAGING, V39, P2385, DOI 10.1109/TMI.2020.2971258
   Akter S, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102387
   Alvarez-Rodríguez L, 2022, BMC MED RES METHODOL, V22, DOI 10.1186/s12874-022-01578-w
   Araki T, 2016, COMPUT METH PROG BIO, V128, P137, DOI 10.1016/j.cmpb.2016.02.004
   Ashraf A, 2018, ARXIV
   Assayag D, 2020, THORAX, V75, P407, DOI 10.1136/thoraxjnl-2019-213968
   Banchhor SK, 2018, COMPUT BIOL MED, V101, P184, DOI 10.1016/j.compbiomed.2018.08.017
   Baylor D, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1387, DOI 10.1145/3097983.3098021
   Beesley LJ, 2022, BIOMETRICS, V78, P214, DOI 10.1111/biom.13400
   Belenguer Lorenzo, 2022, AI Ethics, V2, P771, DOI 10.1007/s43681-022-00138-8
   Bellamy RKE, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2942287
   Benjamin M, 2019, ARXIV
   Berg T, 2020, REV FINANC STUD, V33, P2845, DOI 10.1093/rfs/hhz099
   Biswas M, 2019, FRONT BIOSCI-LANDMRK, V24, P392, DOI 10.2741/4725
   Byrne MD, 2021, J PERIANESTH NURS, V36, P313, DOI 10.1016/j.jopan.2021.03.009
   Calderon-Ramirez S, 2021, IEEE ACCESS, V9, P85442, DOI 10.1109/ACCESS.2021.3085418
   Calmon FP, 2017, ADV NEUR IN, V30
   Cardenas S., 2019, 2019 IEEE INT S TECH, P1
   Cau R, 2022, EUR RADIOL, V32, P4384, DOI 10.1007/s00330-022-08598-6
   Cau R, 2022, CAN ASSOC RADIOL J, V73, P573, DOI 10.1177/08465371211042497
   Celi Leo Anthony, 2022, PLOS Digit Health, V1, pe0000022, DOI 10.1371/journal.pdig.0000022
   Challen R, 2019, BMJ QUAL SAF, V28, P231, DOI 10.1136/bmjqs-2018-008370
   Chung H, 2021, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.778720
   Cirillo D, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0288-5
   Corrias G, 2021, EXPERT REV NEUROTHER, V21, P745, DOI 10.1080/14737175.2021.1951234
   Cruz BGS, 2021, MED IMAGE ANAL, V74, DOI 10.1016/j.media.2021.102225
   d'Alessandro B, 2017, BIG DATA-US, V5, P120, DOI 10.1089/big.2016.0048
   Danks D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4691
   Dankwa-Mullan I, 2022, CANCER DISCOV, V12, P1423, DOI 10.1158/2159-8290.CD-22-0373
   Das S, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105273
   Dastin J., 2018, Ethics of data and analytics, P296
   de Hert P, 2016, INT DATA PRIV LAW, V6, P230, DOI 10.1093/idpl/ipw008
   Catalá OD, 2021, IEEE ACCESS, V9, P42370, DOI 10.1109/ACCESS.2021.3065456
   El-Baz A., 2016, Biomedical Image Segmentation: Advances and Trends
   El-Baz A., 2019, Big data in multimodal medical imaging
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Estiri H, 2022, J AM MED INFORM ASSN, V29, P1334, DOI 10.1093/jamia/ocac070
   Ezzeddine Hassane, 2021, 2021 IEEE 3rd International Multidisciplinary Conference on Engineering Technology (IMCET), P136, DOI 10.1109/IMCET53404.2021.9665574
   Falco G, 2019, IEEE INT C COMPUT, P160, DOI 10.1109/CSE/EUC.2019.00038
   Fernandez-Quilez Alvaro, 2022, Al Ethics, P1, DOI [10.1007/s43681-022-00161-9, DOI 10.1007/S43681-022-00161-9]
   Ferrer X, 2021, IEEE TECHNOL SOC MAG, V40, P72, DOI 10.1109/MTS.2021.3056293
   Gallifant J, 2022, BRIT J ANAESTH, V128, P343, DOI 10.1016/j.bja.2021.09.025
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Geis JR, 2019, CAN ASSOC RADIOL J, V70, P329, DOI [10.1016/j.carj.2019.08.010, 10.1186/s13244-019-0785-8]
   Georgopoulos M, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103954
   Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Gurupur V, 2020, MEDICINA-LITHUANIA, V56, DOI 10.3390/medicina56030141
   Haoran Zhang, 2020, CHIL '20: Proceedings of the Conference on Health, Inference, and Learning, P110, DOI 10.1145/3368555.3384448
   Iosifidis V, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P781, DOI 10.1145/3357384.3357974
   Jain R, 2023, MULTIMED TOOLS APPL, V82, P22613, DOI 10.1007/s11042-023-14432-y
   Jamthikar A, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105102
   Jamthikar AD, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3139693
   Kallus N, 2019, ADV NEURAL INF PROCE, V32
   Kamishima Toshihiro, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P35, DOI 10.1007/978-3-642-33486-3_3
   Kim DW, 2019, KOREAN J RADIOL, V20
   Klann JG, 2021, J AM MED INFORM ASSN, V28, P1411, DOI 10.1093/jamia/ocab018
   Krasanakis E, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P853, DOI 10.1145/3178876.3186133
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kumar A., 2023, 6G ENABLED IOT SMART, DOI [10.1201/9781003321668, DOI 10.1201/9781003321668]
   Kumar A., 2023, 6G ENABLED IOT AI SM, P41, DOI [10.1201/9781003321668-3, DOI 10.1201/9781003321668-3]
   Kumar A., 2021, CANC PREDICTION IND, P65, DOI [10.1201/9781003185604-4, DOI 10.1201/9781003185604-4]
   Kumar A., 2021, CANC PREDICTION IND, P91, DOI [10.1201/9781003185604-6, DOI 10.1201/9781003185604-6]
   Kumar A., 2021, CANC PREDICTION IND, P107
   Kumar A, 2023, SIGNAL IMAGE VIDEO P, V17, P3749, DOI 10.1007/s11760-023-02602-2
   Kumar A, 2023, ADV TECHNOL SOC CH, P83, DOI [10.1007/978-981-19-5723-9_6, 10.1145/3610419.3610502]
   Kumar A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113711
   Kuppili V, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0797-1
   Lambrecht A, 2019, MANAGE SCI, V65, P2966, DOI 10.1287/mnsc.2018.3093
   Landers RN, 2023, AM PSYCHOL, V78, P36, DOI 10.1037/amp0000972
   Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4
   Larrazabal AJ, 2020, P NATL ACAD SCI USA, V117, P12592, DOI 10.1073/pnas.1919012117
   Le EPV, 2019, CLIN RADIOL, V74, P357, DOI 10.1016/j.crad.2019.02.006
   Leavy S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON GENDER EQUALITY IN SOFTWARE ENGINEERING (GE 2018), P14
   Lee N.T., 2019, Algorithmic Bias Detection and Mitigation
   Lerman K, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098914
   Li M, 2020, IEEE T MED IMAGING, V39, P2289, DOI 10.1109/TMI.2020.2968472
   Li YX, 2022, IEEE J BIOMED HEALTH, V26, P172, DOI 10.1109/JBHI.2021.3119325
   Loftus Joshua R., 2018, ARXIV
   Luo LY, 2022, LECT NOTES COMPUT SC, V13438, P621, DOI 10.1007/978-3-031-16452-1_59
   Maier-Hein L, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101796
   Marshall IJ, 2015, IEEE J BIOMED HEALTH, V19, P1406, DOI 10.1109/JBHI.2015.2431314
   McDuff D.J., 2018, ARXIV
   McGregor C, 2021, INT SYMP TECHNOL SOC, DOI 10.1109/ISTAS52410.2021.9629162
   Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607
   Meng CZ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11012-2
   Mia Md Raihan, 2022, Smart Health, DOI 10.1016/j.smhl.2021.100238
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Minot Joshua R., 2022, ACM Transactions on Computing for Healthcare, DOI 10.1145/3524887
   Mitchell S, 2021, ANNU REV STAT APPL, V8, P141, DOI 10.1146/annurev-statistics-042720-125902
   Nagare M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1175, DOI 10.1109/ICASSP39728.2021.9413855
   Nillmani, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030652
   Noriega M, 2020, FUTURES, V117, DOI 10.1016/j.futures.2019.102510
   Norori N, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100347
   Noseworthy PA, 2020, CIRC-ARRHYTHMIA ELEC, V13, DOI 10.1161/CIRCEP.119.007988
   Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356
   Oala L, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01783-y
   Oala L, 2020, PR MACH LEARN RES, V136, P280
   Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
   Obermeyer Z, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P89, DOI 10.1145/3287560.3287593
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   de Sousa IP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165657
   Panch T, 2019, J GLOB HEALTH, V9, DOI 10.7189/jogh.09.020318
   Panman JL, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00729
   Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058
   Parra Carlos M., 2022, IEEE Transactions on Technology and Society, V3, P41, DOI 10.1109/TTS.2021.3120303
   Paul S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12010166
   Pfau J, 2019, ARXIV
   Pfohl SR, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103621
   Puyol-Anton E, 2022, FRONT CARDIOVASC MED, V664
   Rajotte Jean-Francois, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P79, DOI 10.1145/3462203.3475875
   Renner A, 2022, MED PHYS, V49, P2366, DOI 10.1002/mp.15586
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Roselli D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P539, DOI 10.1145/3308560.3317590
   Rueckel J, 2021, EUR RADIOL, V31, P7888, DOI 10.1007/s00330-021-07833-w
   Saba L, 2019, EUR J RADIOL, V114, P14, DOI 10.1016/j.ejrad.2019.02.038
   Saleiro Pedro, 2018, ARXIV
   Saxena S, 2022, CANCERS, V14, DOI 10.3390/cancers14122860
   Seyyed-Kalantari L., 2021, MED IMAGING ALGORITH, DOI DOI 10.21203/RS.3.RS-151985/V1
   Seyyed-Kalantari L, 2021, NAT MED, V27, P2176, DOI 10.1038/s41591-021-01595-0
   Seyyed-Kalantari L, 2021, PACIFIC SYMPOSIUM ON BICOMPUTING 2021, P232
   Shimron E, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2117203119
   Shrivastava VK, 2015, EXPERT SYST APPL, V42, P6184, DOI 10.1016/j.eswa.2015.03.014
   Sikstrom L, 2022, BMJ HEALTH CARE INFO, V29, DOI 10.1136/bmjhci-2021-100459
   Sounderajah V, 2021, NAT MED, V27, P1663, DOI 10.1038/s41591-021-01517-0
   Srivastava B, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2935966
   SRIVASTAVA S. K., 2020, Cogn. Inform. Comput. Model. Cogn. Sci, V2, P319
   Stanley A., 2021, American Journal of Medical Research, V8, P105, DOI DOI 10.22381/AJMR8220218
   Sterne JAC, 2016, BMJ-BRIT MED J, V355, DOI 10.1136/bmj.i4919
   Straw I, 2020, ARTIF INTELL MED, V110, DOI 10.1016/j.artmed.2020.101965
   Sugiyama M, 2000, IEEE IJCNN, P15, DOI 10.1109/IJCNN.2000.857807
   Sun TY, 2020, ARXIV
   Suresh Harini, 2019, arXiv
   Suri J, 2021, IEEE J BIOMED HEALTH, V25, P4128, DOI 10.1109/JBHI.2021.3103839
   Suri JS, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030722
   Suri JS, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105204
   Suri JS, 2020, COMPUT BIOL MED, V124, DOI 10.1016/j.compbiomed.2020.103960
   Suri JS., 2022, IEEE T INSTRUM MEAS
   Suri JS., 2006, MAMMOGRAPHY COMPUTER
   Tandel GS, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103804
   Tasci E, 2022, CANCERS, V14, DOI 10.3390/cancers14122897
   Teoh K. H., 2021, Journal of Physics: Conference Series, V1755, DOI 10.1088/1742-6596/1755/1/012006
   Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2
   Trueblood JS, 2021, COGNITION, V212, DOI 10.1016/j.cognition.2021.104713
   Tzovaras BG, 2019, PHILOS STUD SER, V137, P133, DOI 10.1007/978-3-030-04363-6_8
   Vollmer S, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.l6927
   Wachinger C, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101879
   Wachinger C, 2019, LECT NOTES COMPUT SC, V11767, P484, DOI 10.1007/978-3-030-32251-9_53
   Wachter S, 2021, COMPUT LAW SECUR REV, V41, DOI 10.1016/j.clsr.2021.105567
   Weber C, 2019, IEEE PULSE, V10, P15, DOI 10.1109/MPULS.2018.2885857
   Wolff RF, 2019, ANN INTERN MED, V170, P51, DOI 10.7326/M18-1376
   Wu Y., 2018, ARXIV
   Xu YW, 2019, CLIN CANCER RES, V25, P3266, DOI 10.1158/1078-0432.CCR-18-2495
   Zafar MB, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1171, DOI 10.1145/3038912.3052660
   Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779
   Zhang Lu, 2017, International Journal of Data Science and Analytics, V4, P1
   Zhang Qian, 2021, 2021 2nd International Conference on Artificial Intelligence and Education (ICAIE), P89, DOI 10.1109/ICAIE53562.2021.00026
   Zhou N, 2021, ARXIV
NR 163
TC 1
Z9 1
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18005
EP 18057
DI 10.1007/s11042-023-16029-x
EA JUL 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001034665300009
OA Bronze
DA 2024-07-18
ER

PT J
AU Bhosale, RD
   Yadav, DM
AF Bhosale, Rajendra D.
   Yadav, D. M.
TI Customized convolutional neural network for pulmonary multi-disease
   classification using chest x-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pulmonary diseases; Covid-19; Wavelet; MBConv; Multi-class
ID TUBERCULOSIS; COVID-19; PNEUMONIA; DISEASES
AB The development of accurate and reliable diagnostic tools is crucial for the timely and effective treatment of pulmonary diseases. However, in the midst of a pandemic, it is also important to have faster diagnosis of other types of pneumonia using reliable assistive technology to ensure effective treatment. To address this need, a novel DWTMBConvNet Convolutional Neural Network (CNN) model has been proposed. This model aims to detect multiple pulmonary diseases, including normal/healthy conditions, tuberculosis, Covid-19, bacterial pneumonia, and non-Covid-19 viral pneumonia. By analyzing Chest X-Ray (CXR) images, the model extracts relevant features for the classification of these diseases. The DWTMBConvNet model incorporates wavelet features and EfficientNet-inspired MBConv blocks to achieve impressive accuracy. With an accuracy of 0.955, specificity of 0.989, and sensitivity of 0.955 for five-way classification, the model outperforms several state-of-the-art CNN models. The discrete wavelet transform is employed to extract frequency and location-based features, which are informative for detecting pulmonary diseases. The EfficientNet-inspired MBConv blocks allow the model to learn highly discriminative features while using fewer parameters, thereby improving its performance. The model's accuracy for binary, three way, four way and five is analyzed which outperforms the various state-of-the-art models. These results showcase the effectiveness of the proposed DWTMBConvNet model in detecting pulmonary diseases with a high degree of accuracy. Consequently, it serves as a valuable tool for clinical diagnosis, aiding in the timely and effective treatment of patients.
C1 [Bhosale, Rajendra D.] GH Raisoni Coll Engn & Management, Dept Elect & Telecommun, Pune, Maharashtra, India.
   [Yadav, D. M.] SND Coll Engn & Res Ctr, Nasik, Maharashtra, India.
RP Bhosale, RD (corresponding author), GH Raisoni Coll Engn & Management, Dept Elect & Telecommun, Pune, Maharashtra, India.
EM rajendrabhosale008@gmail.com
RI Bhosale, Rajendra/JCO-1468-2023
OI Bhosale, Rajendra/0000-0002-7674-102X
CR Agrawal T, 2023, VISUAL COMPUT, V39, P875, DOI 10.1007/s00371-021-02352-7
   Alahmari SS, 2022, IEEE ACCESS, V10, P100763, DOI 10.1109/ACCESS.2022.3208138
   Alshmrani Goram Mufarah M., 2023, Alexandria Engineering Journal, P923, DOI 10.1016/j.aej.2022.10.053
   Annamalai B, 2023, NEURAL COMPUT APPL, V35, P7463, DOI 10.1007/s00521-022-08033-3
   Arias-Garzón D, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100138
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bushara AR, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14893-1
   Choi SH, 2012, AM J RESP CRIT CARE, V186, P325, DOI 10.1164/rccm.201112-2240OC
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Cohen JP, 2020, arXiv
   data.lhncbc.nlm.nih.gov, IND PUBL TUB CHEST X
   Duong LT, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115519
   El Asnaoui K, 2021, J BIOMOL STRUCT DYN, V39, P3615, DOI 10.1080/07391102.2020.1767212
   Elzeki OM, 2021, PEERJ COMPUT SCI, DOI [10.7717/peerj-sc.358, 10.7717/peerj-cs.358]
   Gaur L, 2023, MULTIMEDIA SYST, V29, P1729, DOI 10.1007/s00530-021-00794-6
   Gordienko Y, 2018, P INT C COMP SCI ENG, P638
   Goyal S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03464-7
   Hashmi MF, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10060417
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heil C, 2009, FUNDAM PAP WAVELET T, P1, DOI [10.1515/9781400827268/PDF, DOI 10.1515/9781400827268/PDF]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Humeau-Heurtier A, 2019, IEEE ACCESS, V7, P8975, DOI 10.1109/ACCESS.2018.2890743
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Karar ME, 2021, COMPLEX INTELL SYST, V7, P235, DOI 10.1007/s40747-020-00199-4
   Kaya Y, 2023, SOFT COMPUT, V27, P5521, DOI 10.1007/s00500-022-07798-y
   Keles A, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09795-5
   Kermany Daniel, 2018, Mendeley Data, V3
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Kurt Z, 2023, NEURAL COMPUT APPL, V35, P12121, DOI 10.1007/s00521-023-08344-z
   Liu Y, 2020, PROC CVPR IEEE, P2643, DOI 10.1109/CVPR42600.2020.00272
   Luz Eduardo, 2022, Research on Biomedical Engineering, V38, P149, DOI 10.1007/s42600-021-00151-6
   Ma Ningning, 2018, P EUR C COMP VIS ECC, DOI [10.1007/978-3-030-01264-9_8, DOI 10.1007/978-3-030-01264-9_8]
   Malik H, 2023, MULTIMED TOOLS APPL, V82, P13855, DOI 10.1007/s11042-022-13843-7
   Mehta Tirth, 2021, Research on Biomedical Engineering, V37, P803, DOI 10.1007/s42600-021-00174-z
   Müller D, 2022, BMC RES NOTES, V15, DOI 10.1186/s13104-022-06096-y
   Murphy K, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62148-y
   Nafisah SI, 2024, NEURAL COMPUT APPL, V36, P111, DOI 10.1007/s00521-022-07258-6
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nigam B, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114883
   Nwankpa C, 2021, INT C COMP SCI TEC, P124, DOI DOI 10.48550/ARXIV.1811.03378
   Park J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161996
   Pi P., 2021, Int. J. Cogn. Comput. Eng., V2, P93
   Qaid TS, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/9996737
   Qin CL, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0544-y
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Ramya C.M., 2014, Res. J. Pharm. Technol, V7, P942, DOI [DOI 10.5005/JP/BOOKS/10485_24, 10.5005/jp/books/10485_24]
   Ravi V, 2023, CLUSTER COMPUT, V26, P1181, DOI 10.1007/s10586-022-03664-6
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AK, 2021, COGN COMPUT, DOI 10.1007/s12559-021-09848-3
   Su YF, 2020, LANCET INFECT DIS, V20, P929, DOI [10.1016/S1473-3099(20)30124-9, 10.1016/51473-3099(20)30124-9]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Versaci Francesco, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P605, DOI 10.1007/978-3-030-68763-2_46
   Visca D, 2021, PULMONOLOGY, V27, P151, DOI 10.1016/j.pulmoe.2020.12.012
   W. Health Organization, 2022, PROP PROGR BUDG 2022
   Wang LJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61138-4
   Wang Y., 2022, International Journal of Information Management Data Insights, DOI [10.1016/j.jjimei.2022.100100, DOI 10.1016/J.JJIMEI.2022.100100]
   WHO, Global Tuberculosis Report 2021: Supplementary Material
   Yao SJ, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/8854892
NR 64
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18537
EP 18571
DI 10.1007/s11042-023-16297-7
EA JUL 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300001
DA 2024-07-18
ER

PT J
AU Lakshmi, HR
   Borra, S
AF Lakshmi, H. R.
   Borra, Surekha
TI Improved adaptive reversible watermarking in integer wavelet transform
   using moth-flame optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Fractal encryption; IWT; MFO; PSO; SVD
ID VALUE DECOMPOSITION; IMAGE WATERMARKING; MEDICAL IMAGES; SCHEME;
   INFORMATION; ALGORITHM; STEGANOGRAPHY; INTELLIGENT; EFFICIENT; SYSTEM
AB With increasing connectivity, unprotected digital content is vulnerable to attacks and thus watermarking them is essential for copyright protection. This paper presents an effective adaptive reversible image watermarking. The approach utilizes the selection of optimal location for embedding according to entropy, where appropriate threshold for entropy selection is taken care by particle swarm optimization (PSO) algorithm. A technique in integer wavelet transform (IWT) domain is proposed, further discrete cosine transform (DCT) and singular value decomposition (SVD) is hybridized for embedding process in all the chosen blocks, and the Fractal encrypted watermark bits are integrated into coefficients of image using the average proximity coefficient. The embedding process is governed by optimal scale, which is adaptively generated by moth-flame optimization (MFO) according to specially designed fitness function. The proposed technique when evaluated using several standard indicators exhibited improved reliability, robustness, and imperceptibility in comparison to the existing schemes.
C1 [Lakshmi, H. R.] Visvesvaraya Technol Univ, KS Inst Technol, Dept ECE, Belagavi, Karnataka, India.
   [Borra, Surekha] K S Inst Technol, Dept ECE, Bangalore 560109, India.
C3 Visvesvaraya Technological University
RP Lakshmi, HR (corresponding author), Visvesvaraya Technol Univ, KS Inst Technol, Dept ECE, Belagavi, Karnataka, India.
EM hrl.lakshmi@gmail.com; borrasurekha@gmail.com
OI H R, Lakshmi/0000-0002-6748-4500
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Arsalan M, 2017, APPL SOFT COMPUT, V51, P168, DOI 10.1016/j.asoc.2016.11.044
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Arunkumar S, 2019, MEASUREMENT, V139, P426, DOI 10.1016/j.measurement.2019.02.069
   Ayad H, 2018, INT J INTERACT MULTI, V5, P81, DOI 10.9781/ijimai.2018.01.001
   Balasamy K, 2019, CLUSTER COMPUT, V22, pS4431, DOI 10.1007/s10586-018-1991-8
   Bhuyan HMK., 2017, INT J COMPUT APPL, V975, P8887, DOI [10.5120/IJCA2017913725, DOI 10.5120/IJCA2017913725]
   Borra S., 2018, DIGITAL IMAGE WATERM, DOI DOI 10.1201/9780429423291
   Chatterjee S, 2017, ADV INTELLIGENT SYST, V516, DOI 10
   Dey N., 2011, INT J COMPUTER APPL, V36, P19, DOI [10.48550/arXiv.1208.0803, DOI 10.48550/ARXIV.1208.0803]
   Elshazly E, 2018, J SYST ENG ELECTRON, V29, P639, DOI 10.21629/JSEE.2018.03.21
   Fang H, 2019, MULTIMED TOOLS APPL, V78, P8075, DOI 10.1007/s11042-018-6596-y
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Gujjunoori S, 2019, MULTIMED TOOLS APPL, V78, P25889, DOI 10.1007/s11042-019-07767-y
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Heidari M, 2016, IRAN CONF ELECTR ENG, P838, DOI 10.1109/IranianCEE.2016.7585636
   Hou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090397
   Jain A, 2017, INT J AMBIENT COMPUT, V8, P19, DOI 10.4018/IJACI.2017100102
   Jimson N., 2018, INT J ADV RES COMPUT, V9, P540, DOI [10.26483/ijarcs.v9i2.5747, DOI 10.26483/IJARCS.V9I2.5747]
   Kapadia Amishi Mahesh, 2020, International Journal of Information and Computer Security, V12, P70
   Kaur P, 2020, INT J AMBIENT COMPUT, V11, P30, DOI 10.4018/IJACI.2020040102
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Kazemivash B, 2018, SOFT COMPUT, V22, P4083, DOI 10.1007/s00500-017-2617-4
   Kulkarni R., 2021, INT J RES ENG SCI MA, V4, P193
   Lakshmi HR, 2021, INT J SPEECH TECHNOL, V24, P823, DOI 10.1007/s10772-021-09818-y
   Li Q, 2019, GENETIC EVOLUTIONARY, V834, P234, DOI [10.1007/978-981-13-5841-8_26, DOI 10.1007/978-981-13-5841-8_26]
   Li Y, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12081234
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin CC, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11060765
   Loukhaoukha Khaled, 2017, Journal of Electrical Systems and Information Technology, V4, P359, DOI 10.1016/j.jesit.2016.12.011
   Loukhaoukha K., 2015, INT J APPL MATH INFO, V9, P1159, DOI [10.12785/amis/090307, DOI 10.12785/AMIS/090307]
   Loukhaoukha K, 2016, INFORM PROCESS MANAG, V52, P644, DOI 10.1016/j.ipm.2015.12.009
   Loukhaoukha K, 2016, ADV ENG SOFTW, V93, P44, DOI 10.1016/j.advengsoft.2015.12.006
   Loukhaoukha K, 2013, DIGIT SIGNAL PROCESS, V23, P1334, DOI 10.1016/j.dsp.2013.02.006
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Malallah FL., 2020, INT J EL COMP ENG SY, V10, P3519, DOI [10.11591/ijece.v10i4.pp3519-3527, DOI 10.11591/IJECE.V10I4.PP3519-3527]
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Melendez-Melendez G, 2022, ENG SCI TECHNOL, V34, DOI 10.1016/j.jestch.2021.101080
   Meng LZ, 2021, MULTIMED TOOLS APPL, V80, P711, DOI 10.1007/s11042-020-09686-9
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Muhammad N, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176979
   Muhuri PK, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106257
   Naskar R, 2011, INFORM SYSTEMS SECUR, V7093, DOI [10.1007/978-3-642-25560-1_13, DOI 10.1007/978-3-642-25560-1_13]
   Nazari M, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5514944
   Pakdaman Z, 2021, MULTIMED TOOLS APPL, V80, P8931, DOI 10.1007/s11042-020-10058-6
   Parah SA, 2020, FUTURE GENER COMP SY, V108, P935, DOI 10.1016/j.future.2018.02.023
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Quinn D, 2012, INT J AMBIENT COMPUT, V4, P46, DOI 10.4018/jaci.2012070104
   Sangeetha N, 2021, SIGNAL IMAGE PROCESS, P203, DOI [10.1007/978-981-15-6141-2_11, DOI 10.1007/978-981-15-6141-2_11]
   Sara U., 2019, J COMPUT COMMUN, V7, P8, DOI [10.4236/jcc.2019.73002, DOI 10.4236/JCC.2019.73002]
   Sharma S, 2019, INT J AMBIENT COMPUT, V10, P60, DOI 10.4018/IJACI.2019100104
   Thakur S, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5108
   Thanki R, 2018, L N COMPUT VIS BIOME, V26, P3, DOI 10.1007/978-3-319-65981-7_1
   Ustubioglu A, 2019, MULTIMED TOOLS APPL, V78, P22269, DOI 10.1007/s11042-019-7529-0
   Wu XT, 2019, SIGNAL PROCESS-IMAGE, V78, P437, DOI 10.1016/j.image.2019.08.007
   Yuan ZH, 2020, IET IMAGE PROCESS, V14, P3829, DOI 10.1049/iet-ipr.2019.1740
   Zhang XP, 2005, IEEE T MULTIMEDIA, V7, P593, DOI 10.1109/TMM.2005.843357
   Zhang ZW, 2018, ARAB J SCI ENG, V43, P979, DOI 10.1007/s13369-017-2898-z
   Zhu T, 2022, J SUPERCOMPUT, V78, P222, DOI 10.1007/s11227-021-03886-2
NR 61
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17183
EP 17215
DI 10.1007/s11042-023-16203-1
EA JUL 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300009
DA 2024-07-18
ER

PT J
AU Verma, S
   Chug, A
   Singh, AP
AF Verma, Shradha
   Chug, Anuradha
   Singh, Amit Prakash
TI Revisiting activation functions: empirical evaluation for image
   understanding and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Activation Functions; Deep Learning; Convolutional Neural Networks
   (CNN); Image Classification; Uncertainty; Semantic Segmentation; Object
   Detection; Hyperspectral Image Classification
AB In this paper, the authors have devised four novel activation functions by coupling and combining a few existing functions implemented with four standard CNN architectures namely VGG19, ResNet50, InceptionV3, and DenseNet121 on existing benchmark datasets CIFAR10, CIFAR100, and MNIST. The best-performing function is also implemented with EfficientNet (B0-B7) models, on the abovementioned datasets, with improved performance as compared to the Swish function. Apart from classification accuracy, measures such as top5 accuracy, Cohen's kappa, precision, recall, f1-score, RMSE, MSE, and loss have been recorded. The authors have also implemented Monte-Carlo Dropout to evaluate the uncertainty of the implementations in terms of Brier Score, mean, variance, standard deviation, and peak accuracy values. Lastly, a few instances of classification with the Tiny-ImageNet dataset, semantic segmentation, object detection, and hyperspectral image classification have been implemented for evaluation and comparison purposes. The research work presented in this paper aims to experiment with combinations of different activation functions, analyze the performance and find a better version that improves the performance of DNNs for the task of image understanding and classification.
C1 [Verma, Shradha; Chug, Anuradha; Singh, Amit Prakash] Guru Gobind Singh Indraprastha Univ GGSIPU, Univ Sch Informat Commun & Technol USIC&T, New Delhi, India.
C3 GGS Indraprastha University
RP Verma, S (corresponding author), Guru Gobind Singh Indraprastha Univ GGSIPU, Univ Sch Informat Commun & Technol USIC&T, New Delhi, India.
EM shradha.usict.122164@ipu.ac.in
RI Verma, Shradha/HLH-0433-2023
OI Verma, Shradha/0000-0002-7053-1654
FU Department of Science and Technology (DST), Ministry of Science and
   Technology, Government of India, New Delhi, under the ICPS Programme
   [T-319]
FX This study was funded by the Department of Science and Technology (DST),
   Ministry of Science and Technology, Government of India, New Delhi,
   under the ICPS Programme (Project Titled "Application of Internet of
   Things (IoT) in Agriculture Sector", Reference No. T-319).
CR Ahmad M, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3043710
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bawa VS, 2019, EXPERT SYST APPL, V120, P346, DOI 10.1016/j.eswa.2018.11.042
   Bozkurt F, 2023, MULTIMED TOOLS APPL, V82, P18985, DOI 10.1007/s11042-022-14095-1
   CHUI CK, 1992, J APPROX THEORY, V70, P131, DOI 10.1016/0021-9045(92)90081-X
   Chung H, 2016, IEEE IJCNN, P348, DOI 10.1109/IJCNN.2016.7727219
   Clevert D., 2016, ARXIV151107289
   Das D, 2019, MULTIMED TOOLS APPL, V78, P19495, DOI 10.1007/s11042-019-7330-0
   Ding B, 2018, CHIN CONT DECIS CONF, P1836, DOI 10.1109/CCDC.2018.8407425
   Divamgupta, GITHUB DIV IM SEGM K
   Dubey Arun Kumar, 2019, Applications of Computing, Automation and Wireless Systems in Electrical Engineering. Proceedings of MARC 2018. Lecture Notes in Electrical Engineering (LNEE 553), P873, DOI 10.1007/978-981-13-6772-4_76
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gao DQ, 2005, PATTERN RECOGN, V38, P1469, DOI 10.1016/j.patcog.2005.03.024
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kamruzzaman J, 2002, IEICE T FUND ELECTR, VE85A, P2373
   Klambauer G, 2017, ADV NEUR IN, V30
   Kulkarnikeerti, GITHUB KULK SEGN SEM
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Liew SS, 2016, NEUROCOMPUTING, V216, P718, DOI 10.1016/j.neucom.2016.08.037
   Lu L., 2019, ARXIV
   Lv WJ, 2020, J SENSORS, V2020, DOI 10.1155/2020/4817234
   Mian Mian Lau, 2017, 2017 2nd International Conference on Control and Robotics Engineering (ICCRE), P201, DOI 10.1109/ICCRE.2017.7935070
   Misra D., 2019, ARXIV190808681
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Ramachandran P., 2017, ARXIV171005941V1, V7, P1
   Rohit, GITHUB 1297 ROH RCNN
   Shen SL, 2022, EXPERT SYST APPL, V199, DOI 10.1016/j.eswa.2022.117181
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang MX, 2022, NEURAL NETWORKS, V145, P56, DOI 10.1016/j.neunet.2021.10.001
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xu B., 2015, ARXIV
   Ying Y, 2021, APPL INTELL, V51, P7427, DOI 10.1007/s10489-021-02247-z
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Yu YB, 2020, IEEE ACCESS, V8, P72727, DOI 10.1109/ACCESS.2020.2987829
   Zaheer R, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P769, DOI 10.1109/ICISC.2018.8398903
   Zhang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051520
   Zhang ZX, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3178115
NR 44
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18497
EP 18536
DI 10.1007/s11042-023-16159-2
EA JUL 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035582300008
DA 2024-07-18
ER

PT J
AU Pandey, C
   Baghel, N
   Gupta, R
   Dutta, MK
AF Pandey, Chandrasen
   Baghel, Neeraj
   Gupta, Rinki
   Dutta, Malay Kishore
TI Nocturnal sleep sounds classification with artificial neural network for
   sleep monitoring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sleep monitoring; Non-speech human sounds; Artificial neural network;
   Mel-frequency cepstrum coefficients
AB Due to improper lifestyle, sleep disorders are becoming increasingly common worldwide. Early detection may help in preventing diseases arising due to sleep disorders, such as insomnia, muscle loss, breathing, and cardiac disorders. In this paper, nocturnal human sounds are analysed to develop a personal sleep monitoring system. Multiple audio-related features are extracted from the spectrograms of sleep sounds and analysed for discriminatory ability. The selected features are given as input to a fully-connected Artificial Neural Network (ANN) to classify the sleep sounds. The proposed approach classifies the considered seven categories of sleep sounds, including coughing, laughing, screaming, sneezing, snoring, sniffling, and farting, with an average accuracy of 97.4%. This is significantly higher than the classification accuracy obtained by applying conventional machine learning models on the selected features. This indicates that the ANN learns new features to enhance the classification accuracy of the sleep sounds. Moreover, the computational requirement of the system is kept low by reducing the number of features given as input to the ANN classifier. The proposed approach may be integrated with a smartphone or a cloud platform to develop a device for sleep monitoring or diagnosis of sleep disorders.
C1 [Pandey, Chandrasen; Baghel, Neeraj] Ctr Adv Studies, Lucknow, India.
   [Gupta, Rinki; Dutta, Malay Kishore] Amity Univ, Ctr Artificial Intelligence, Noida, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Centre for Advanced
   Studies (CAS, AKTU); Amity University Noida
RP Dutta, MK (corresponding author), Amity Univ, Ctr Artificial Intelligence, Noida, India.
EM developer.chandrasen@gmail.com; nbaghel777@gmail.com; rgupta3@amity.edu;
   malaykishoredutta@gmail.com
RI Baghel, Neeraj/CAA-1198-2022
OI Baghel, Neeraj/0000-0002-0081-6224; Dutta, Malay
   Kishore/0000-0003-2462-737X
CR Adesuyi T, 2022, INT J FUZZY LOG INTE, V22, P1, DOI 10.5391/IJFIS.2022.22.1.1
   Akbal E, 2020, APPL ACOUST, V167, DOI 10.1016/j.apacoust.2020.107413
   Alías F, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050143
   Amoh J, 2016, IEEE T BIOMED CIRC S, V10, P1003, DOI 10.1109/TBCAS.2016.2598794
   [Anonymous], 2000, USE ZERO CROSSING RA
   Chang XM, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3392049
   Cheng SY, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103238
   De Zambotti M, 2019, MED SCI SPORT EXER, V51, P1538, DOI 10.1249/MSS.0000000000001947
   Galván A, 2020, TRENDS COGN SCI, V24, P79, DOI 10.1016/j.tics.2019.11.002
   Ganchev T., 2005, 10th International Conference on Speech and Computer (SPECOM 2005), V1, P191
   Khan T, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090987
   Kim J, 2017, BIOMED ENG ONLINE, V16, DOI 10.1186/s12938-016-0306-7
   Kortelainen JM, 2010, IEEE T INF TECHNOL B, V14, P776, DOI 10.1109/TITB.2010.2044797
   Kos M, 2013, DIGIT SIGNAL PROCESS, V23, P659, DOI 10.1016/j.dsp.2012.10.008
   Mantua J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050646
   Marelli S, 2021, J NEUROL, V268, P8, DOI 10.1007/s00415-020-10056-6
   Perez-Pozuelo I, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0244-4
   Sharaff Aakanksha, 2020, International Journal of Web-Based Learning and Teaching Technologies, V15, P19, DOI 10.4018/IJWLTT.2020040102
   Zhang HB, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3300125
NR 19
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15693
EP 15709
DI 10.1007/s11042-023-16190-3
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031517600001
DA 2024-07-18
ER

PT J
AU Tyagi, P
   Agarwal, K
   Jaiswal, G
   Sharma, A
   Rani, R
AF Tyagi, Prachi
   Agarwal, Khushboo
   Jaiswal, Garima
   Sharma, Arun
   Rani, Ritu
TI Forged document detection and writer identification through unsupervised
   deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imaging; Document forgery; Writer identification;
   Convolutional autoencoders; SVM
AB In recent years, there has been a significant increase in document forgery, which includes the fraudulent replication of currency, diplomas, and works of art. This has become a major issue due to the widespread usage of paper-based documentation. Handwriting is closely linked to document forgery and forensics as it possesses unique characteristics, including variations in text characters, pen pressure, writing angle, and stroke patterns, which makes it impossible to replicate accurately. As a result, handwriting serves as a personalized biometric that can be used to determine the authenticity of documents. However, traditional methods of writer identification are both time-consuming and destructive, requiring substantial expertise. To overcome these limitations, the study explores the potential of hyperspectral imaging (HSI) as a non-destructive and advanced approach for detecting and preventing document forgery. HSI provides detailed spectral information from a scene, making it possible to capture subtle spectral differences in handwriting samples. This imaging technique has diverse applications in various fields such as agriculture, environmental monitoring, remote sensing, forensics, document analysis, and medical imaging. Our study proposes a novel unsupervised approach, CAE-SVM that uses Convolutional Autoencoder (CAE) for feature extraction and Support Vector Machine (SVM) for writer identification. It was tested on the UWA writing ink hyperspectral images dataset for blue and black inks which is available publicly and compared with state-of-the-art methods and CNN. The proposed approach achieved the highest accuracy of 92.78% for blue ink, surpassing existing methods. The study's results emphasize the efficacy of HSI as a potent forensic analysis tool for detecting and preventing document forgery.
C1 [Tyagi, Prachi; Agarwal, Khushboo; Sharma, Arun; Rani, Ritu] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Jaiswal, Garima] Bennett Univ, Greater Noida, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Jaiswal, G (corresponding author), Bennett Univ, Greater Noida, India.
EM garima121@gmail.com
OI Rani, Dr.Ritu/0000-0001-6219-8751; JAISWAL, GARIMA/0000-0002-2676-299X
CR Abbas A, 2017, PROC INT CONF DOC, P1229, DOI 10.1109/ICDAR.2017.203
   Albawi S, 2017, I C ENG TECHNOL
   Amaral AMM, 2012, P INT C IM PROC COMP, P1
   Bank D, 2020, ARXIV, DOI [DOI 10.48550/ARXIV.2003.05991, 10.48550/arXiv.2003.05991]
   Chauhan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P278, DOI 10.1109/ICSCCC.2018.8703316
   Christlein V, 2017, PROC INT CONF DOC, P991, DOI 10.1109/ICDAR.2017.165
   Christlein V, 2017, PATTERN RECOGN, V63, P258, DOI 10.1016/j.patcog.2016.10.005
   Durou A, 2019, INFORM PROCESS MANAG, V56, P354, DOI 10.1016/j.ipm.2017.09.005
   Fiel S, 2015, LECT NOTES COMPUT SC, V9257, P26, DOI 10.1007/978-3-319-23117-4_3
   He S, 2020, IEEE T INF FOREN SEC, V15, P3013, DOI 10.1109/TIFS.2020.2981236
   Nguyen HT, 2019, PATTERN RECOGN LETT, V121, P104, DOI 10.1016/j.patrec.2018.07.022
   Islam A, 2019, 2019 IEEE PUNE SECTION INTERNATIONAL CONFERENCE (PUNECON), DOI [10.1109/punecon46936.2019.9105677, 10.1109/CICN.2019.01]
   Jaiswal G, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103690
   Jaiswal G, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107770
   Jaiswal G, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1426
   Javidi M, 2020, ENG APPL ARTIF INTEL, V95, DOI 10.1016/j.engappai.2020.103912
   Khan Z, 2013, PROC INT CONF DOC, P877, DOI 10.1109/ICDAR.2013.179
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Luo ZP, 2015, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2015.7333811
   Mangotra H, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13311
   Mukherjee S, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P324, DOI [10.1109/ASPCON49795.2020.9276700, 10.1109/aspcon49795.2020.9276700]
   Prakash JS, 2012, 2012 INTERNATIONAL CONFERENCE ON MACHINE VISION AND IMAGE PROCESSING (MVIP), P197, DOI 10.1109/MVIP.2012.6428794
   Rehman A, 2019, IEEE ACCESS, V7, P17149, DOI 10.1109/ACCESS.2018.2890810
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sakshi, 2018, LECT NOTE DATA ENG, V9, P125, DOI 10.1007/978-981-10-6319-0_11
   Silva CS, 2014, ANALYST, V139, P5176, DOI 10.1039/c4an00961d
   Ul Islam A, 2022, DATA BRIEF, V41, DOI 10.1016/j.dib.2022.107964
   Zhang SF, 2018, IEEE SYS MAN CYBERN, P415, DOI 10.1109/SMC.2018.00080
NR 29
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18459
EP 18478
DI 10.1007/s11042-023-16146-7
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001033457500001
DA 2024-07-18
ER

PT J
AU Sarooraj, RB
   Shyry, SP
AF Sarooraj, R. B.
   Shyry, S. Prayla
TI Analysis of traffic flow prediction from spatial-temporal data using
   hybrid GSA-Adam optimizer based LSTM network for intelligent transport
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent transportations system (ITS); Spatiotemporal data; Traffic
   flow prediction and GSA-Adam Optimizer based LSTM
AB In recent decades, the intelligent transportation system (ITS) has gotten extensive consideration, because of greater levels of popularity for road safety and productivity in profoundly interconnected road networks. In ITS, traffic flow prediction from the spatiotemporal data is the major challenge to reduce the congestion of vehicles in a specific region of road network. Although deep learning techniques had been presented by the researchers for predicting the traffic flow, the accuracy of prediction is further to be enhanced. So, we present Adam optimizer based long short term memory (LSTM) for the prediction of traffic flow. At first, the spatiotemporal data is filtered using Kalman filter. Then the filtered data are compressed using Douglas-Peucker algorithm. Using this compressed data; inflow and outflow of vehicles in a region at time 'T' are estimated. Finally, with the compressed data and traffic flow measured data, the proposed LSTM model predicts the inflow and outflow of vehicles in a region at time 'T + 1'. To enhance the prediction accuracy, weight parameters of LSTM is updated using hybrid gravitational search algorithm (GSA) and Adam optimizer. Simulation results depict that the accuracy of the Adam optimizer based LSTM is increased than that of the conventional LSTM and machine learning techniques.
C1 [Sarooraj, R. B.; Shyry, S. Prayla] Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, India.
C3 Sathyabama Institute of Science & Technology
RP Sarooraj, RB (corresponding author), Sathyabama Inst Sci & Technol, Sch Comp, Dept Comp Sci & Engn, Chennai, India.
EM sarooraj@gmail.com; praylashyry.cse@sathyabama.ac.in
RI shyry, s prayla/I-4441-2018
CR Do LNN, 2019, TRANSPORT RES C-EMER, V108, P12, DOI 10.1016/j.trc.2019.09.008
   Duan ZT, 2018, IEEE ACCESS, V6, P31820, DOI 10.1109/ACCESS.2018.2845863
   Essien A, 2021, WORLD WIDE WEB, V24, P1345, DOI 10.1007/s11280-020-00800-3
   Fei Z, 2010, 2010 INT C MECH AUT, P2826
   Liang Z, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS (ITST), P378, DOI 10.1109/ITST.2013.6685576
   Lu SQ, 2021, ALEX ENG J, V60, P87, DOI 10.1016/j.aej.2020.06.008
   Luo XL, 2018, KSCE J CIV ENG, V22, P4107, DOI 10.1007/s12205-018-0429-4
   Mukkamala MC, 2017, PR MACH LEARN RES, V70
   Ramezani-Kebrya A, 2021, ARXIV
   Sarooraj RB., 2021, ADV SMART GRID RENEW
   Tampubolon H, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART GREEN TECHNOLOGY IN ELECTRICAL AND INFORMATION SYSTEMS (ICSGTEIS): SMART GREEN TECHNOLOGY FOR SUSTAINABLE LIVING, P95, DOI 10.1109/ICSGTEIS.2018.8709102
   Wang SF, 2019, TRANSPORT RES C-EMER, V108, P74, DOI 10.1016/j.trc.2019.09.007
   Wang ZY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS (SOLI 2006), PROCEEDINGS, P999, DOI 10.1109/SOLI.2006.328887
   Wei XJ, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/9242598
   Xie P, 2020, INFORM FUSION, V59, P1, DOI 10.1016/j.inffus.2020.01.002
   Zhao L, 2020, ARAB J SCI ENG, V45, P10845, DOI 10.1007/s13369-020-04862-3
   Zhao ZY, 2021, INT J AUTOM COMPUT, V18, P219, DOI 10.1007/s11633-020-1271-y
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
NR 18
TC 0
Z9 0
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16735
EP 16761
DI 10.1007/s11042-023-16253-5
EA JUL 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100001
DA 2024-07-18
ER

PT J
AU Roy, S
   Bhalla, K
   Patel, R
AF Roy, Santanu
   Bhalla, Kanika
   Patel, Rachit
TI Mathematical analysis of histogram equalization techniques for medical
   image enhancement: a tutorial from the perspective of data loss
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Contrast enhancement of medical images; Histogram Equalization (HE)
   techniques; Contrast Limited Adaptive Histogram Equalization (CLAHE);
   Image analysis; Correlation co-efficient
ID CONTRAST; BRIGHTNESS; ENTROPY; LIMIT
AB This tutorial demonstrates a novel mathematical analysis of histogram equalization techniques and its application in medical image enhancement. In this paper, conventional Global Histogram Equalization (GHE), Contrast Limited Adaptive Histogram Equalization (CLAHE), Histogram Specification (HS) and Brightness Preserving Dynamic Histogram Equalization (BPDHE) are re-investigated by a novel mathematical analysis. All these HE methods are widely employed by researchers in image processing and medical image diagnosis domain, however, this has been observed that these HE methods have significant limitation of data loss. In this paper, a mathematical proof is given that any kind of Histogram Equalization method is inevitable of data loss, because any HE method is a non-linear method. All these Histogram Equalization methods are implemented on two different datasets, they are, brain tumor MRI image dataset and colorectal cancer H and E-stained histopathology image dataset. Pearson Correlation Coefficient (PCC) and Structural Similarity Index Matrix (SSIM) both are found in the range of 0.6-0.95 for overall all HE methods. Moreover, those results are compared with Reinhard method which is a linear contrast enhancement method. The experimental results suggest that Reinhard method outperformed any HE methods for medical image enhancement. Furthermore, a popular CNN model VGG-16 is implemented, on the MRI dataset in order to prove that there is a direct correlation between less accuracy and data loss.
C1 [Roy, Santanu] Christ Deemed Univ, Sch Engn & Technol, Bangalore, India.
   [Bhalla, Kanika] Washington Univ, Sch Med St Louis, St Louis, MO 63110 USA.
   [Patel, Rachit] ABES Inst Technol, Dept Elect & Commun Engn, Ghaziabad, India.
C3 Christ University; Saint Louis University; Washington University (WUSTL)
RP Roy, S (corresponding author), Christ Deemed Univ, Sch Engn & Technol, Bangalore, India.
EM santanuroy35@gmail.com; kanikabhalla1594@gmail.com;
   rachit05081gece@gmail.com
RI bhalla, kanika/ITT-0604-2023
OI bhalla, kanika/0000-0001-8663-5813; Roy, Dr. Santanu/0000-0001-6963-8019
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Aboshosha S, 2019, MULTIMED TOOLS APPL, V78, P18751, DOI 10.1007/s11042-018-7022-1
   Agarwal M, 2018, PROCEDIA COMPUT SCI, V125, P149, DOI 10.1016/j.procs.2017.12.021
   Akila K, 2015, PROCEDIA COMPUT SCI, V47, P255, DOI 10.1016/j.procs.2015.03.205
   Aquino-Morínigo PB, 2017, SIGNAL IMAGE VIDEO P, V11, P857, DOI 10.1007/s11760-016-1032-0
   Chen SD, 2004, DIGIT SIGNAL PROCESS, V14, P413, DOI 10.1016/j.dsp.2004.04.001
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Chen X, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/9414937
   Chen XQ, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0479-7
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   El Houby EMF, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102954
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ibrahim H, 2007, IEEE T CONSUM ELECTR, V53, P1752, DOI 10.1109/TCE.2007.4429280
   Kandhway P, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101677
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Li Y, 2016, OPT LASER TECHNOL, V83, P99, DOI 10.1016/j.optlastec.2016.03.017
   Liang XC, 2019, IEEE SENS J, V19, P7107, DOI 10.1109/JSEN.2019.2913281
   Majeed SH, 2020, IEEE ACCESS, V8, P144218, DOI 10.1109/ACCESS.2020.3014453
   Manimekalai MAP, 2019, CLUSTER COMPUT, V22, P12805, DOI 10.1007/s10586-018-1761-7
   Mayathevar K, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164927
   McCann MT, 2014, IEEE T IMAGE PROCESS, V23, P2033, DOI 10.1109/TIP.2014.2307475
   Ooi CH, 2010, IEEE T CONSUM ELECTR, V56, P2543, DOI 10.1109/TCE.2010.5681139
   Ooi CH, 2009, IEEE T CONSUM ELECTR, V55, P2072, DOI 10.1109/TCE.2009.5373771
   Oppenheim A. V., 1997, SIGNALS SYSTEMS
   Panetta K, 2013, IEEE T CONSUM ELECTR, V59, P643, DOI 10.1109/TCE.2013.6626251
   Papoulis A., 1965, PROBABILITY RANDOM V
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Patel S, 2020, ADV INTELL SYST, V1048, P657, DOI 10.1007/978-981-15-0035-0_54
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Reddy E, 2019, P NATL A SCI INDIA A, V89, P673, DOI 10.1007/s40010-018-0530-6
   Reddy PS, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P124, DOI 10.1109/ICCSP.2018.8524518
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Roy S, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106092
   Roy S, 2021, EUR SIGNAL PR CONF, P1231, DOI 10.23919/EUSIPCO54536.2021.9616117
   Roy S, 2019, IEEE ACCESS, V7, P28982, DOI 10.1109/ACCESS.2019.2894791
   Roy S, 2018, MICRON, V114, P42, DOI 10.1016/j.micron.2018.07.005
   Roy S, 2021, J ENG DES TECHNOL, V19, P1620, DOI 10.1108/JEDT-10-2020-0400
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Sajeev S, 2015, INT C DIG IM COMP TE, P1
   Sanagavarapu S., 2021, 2021 IEEE INT IOT EL, P1
   Sengee N, 2008, IEEE T CONSUM ELECTR, V54, P1329, DOI 10.1109/TCE.2008.4637624
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Siddhartha M, 2020, ARXIV
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh H, 2018, COMPUT ELECTR ENG, V70, P462, DOI 10.1016/j.compeleceng.2017.06.029
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Sirinukunwattana K, 2017, MED IMAGE ANAL, V35, P489, DOI 10.1016/j.media.2016.08.008
   Sun CC, 2005, IEEE T CONSUM ELECTR, V51, P1300
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wongsritong K, 1998, APCCAS '98 - IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P455, DOI 10.1109/APCCAS.1998.743808
   Wu XM, 2021, IEEE T CIRC SYST VID, V31, P863, DOI 10.1109/TCSVT.2020.2991437
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2225, DOI 10.1109/ICACCI.2014.6968569
   Zhu YL, 2012, PHYSCS PROC, V25, P601, DOI 10.1016/j.phpro.2012.03.132
   Zhuang LY, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/3837275
   Zhuang LY, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/6029892
NR 69
TC 4
Z9 4
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14363
EP 14392
DI 10.1007/s11042-023-15799-8
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001026613700009
DA 2024-07-18
ER

PT J
AU Shi, JY
   Yu, SS
   Li, HA
   Zhang, XG
   Liu, CX
AF Shi, Jinyu
   Yu, Shanshan
   Li, Huanan
   Zhang, Xiuguo
   Liu, Changxin
TI Underwater image enhancement based on adaptive color correction and
   multi-scale fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image enhancement; Adaptive color correction; Logarithmic
   image processing model; Multi-scale fusion
ID HISTOGRAM; CONTRAST; SYSTEM; MODEL
AB In actual captured underwater images, serious color distortion, detail loss and limited visibility are common issues due to the combined influence of water medium scattering and absorption. To solve these problems, an underwater image enhancement method based on adaptive color correction and multi-scale fusion is proposed, which does not rely on any specific equipment or auxiliary information. According to the attenuation degree of underwater images, an adaptive color correction method of piecewise linear transformation is used to address the color distortion. Then, the color-corrected image is converted from RGB to CIE-Lab color space, and the luminance channel L is applied to the updated logarithmic image processing (LIP) model alone to improve contrast. The final enhanced image is created by fusing the color-corrected image with the contrast-improved image using a multi-scale fusion technique based on contrast, saliency, and saturation. The qualitative and quantitative evaluation results demonstrate that compared with some state-of-the-art methods, the proposed method can produce better visual quality and have higher average values in underwater image quality evaluation such as AG, IE, PCQI, UIQM and UCIQE.
C1 [Shi, Jinyu; Yu, Shanshan; Li, Huanan; Zhang, Xiuguo; Liu, Changxin] Dalian Maritime Univ, Dalian, Peoples R China.
C3 Dalian Maritime University
RP Shi, JY (corresponding author), Dalian Maritime Univ, Dalian, Peoples R China.
EM sjy1967@dlmu.edu.cn
RI Wang, Chen/JZE-6385-2024; Yang, Fan/JMA-9594-2023; Wei,
   Wei/JVM-8876-2024; Yuan, Fang/JQV-7426-2023; Yang, Fan/JVO-8611-2024;
   Chen, Nuo/JZD-0344-2024
OI Wei, Wei/0000-0002-4109-3878; 
FU National Natural Science Foundation of China [62103072]; China
   Postdoctoral Science Foundation [2021M690502]; Fundamental Research
   Funds for the Central Universities [3132021242]
FX AcknowledgmentsThis work was supported by the National Natural Science
   Foundation of China No. 62103072, China Postdoctoral Science Foundation
   No. 2021M690502 and the Fundamental Research Funds for the Central
   Universities No. 3132021242.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ancuti C.O., 2017, Proc. IEEE Conf. on Image Processing, P1
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Anwar S, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115978
   Ao J, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418540010
   Bai LF, 2020, IEEE ACCESS, V8, P128973, DOI 10.1109/ACCESS.2020.3009161
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Bhateja V., 2020, HUMAN VISUAL SYSTEM, P199
   Boom BJ, 2014, ECOL INFORM, V23, P83, DOI 10.1016/j.ecoinf.2013.10.006
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews P, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P825, DOI 10.1109/ICCVW.2013.113
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gao FR, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9020225
   Ghani ASA, 2017, COMPUT ELECTRON AGR, V141, P181, DOI 10.1016/j.compag.2017.07.021
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Iqbal K, 2010, IEEE INT C SYSTEMS M
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Khan A, 2018, IEEE ACCESS, V6, P40585, DOI 10.1109/ACCESS.2018.2855725
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2016, IEEE T IMAGE PROCESS, V26, P5664, DOI 10.1109/TIP.2016.2612882
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Marques TP, 2020, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW50498.2020.00277
   Moghimi MK, 2021, J REAL-TIME IMAGE PR, V18, P1509, DOI 10.1007/s11554-020-01052-0
   Naik A, 2021, AAAI CONF ARTIF INTE, V35, P15853
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Raveendran S, 2021, ARTIF INTELL REV, V54, P5413, DOI 10.1007/s10462-021-10025-z
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Steffens C, 2018, P 2018 LAT AM ROB S, P6
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang N., 2019, ARXIV
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wang WC, 2020, IEEE ACCESS, V8, P87884, DOI 10.1109/ACCESS.2020.2992749
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Xue XW, 2021, IEEE SIGNAL PROC LET, V28, P818, DOI 10.1109/LSP.2021.3072563
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang WD, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116030
   Zhang WD, 2019, IEEE ACCESS, V7, P182259, DOI 10.1109/ACCESS.2019.2959560
   Zhang WD, 2019, IEEE ACCESS, V7, P72492, DOI 10.1109/ACCESS.2019.2920403
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 61
TC 0
Z9 0
U1 9
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12535
EP 12559
DI 10.1007/s11042-023-15652-y
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022149800001
DA 2024-07-18
ER

PT J
AU Mactina, FJN
   Neduncheliyan, S
AF Mactina, F. Josephine Nijofi
   Neduncheliyan, S.
TI Multi-classification of kidney abnormalities in sonography using the
   LOA-MFO and long-term recurrent convolutional network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Chronic kidney disease; Feature selection;
   Classification; Ultrasound images; Long-term recurrent convolutional
   network; Feature extraction; Lion optimization algorithm; Moth flame
   optimization
ID ALGORITHM
AB CKD is a medical condition that affects people all around the world and is a major health concern. It increases the risk of developing cardiovascular and cerebrovascular diseases, which can lead to serious illness and even death. Ultrasound imaging is typically the initial and most widely used diagnostic technique for individuals at risk for CKD. The existing methods are restricted by features with high dimensions, computational hurdles, and extended processing times. To address these issues, this article proposes the development of an enhanced deep-learning model with an optimum selection of features for the accurate diagnosis of CKD. The proposed technique begins with pre-processing, involving image filtering and contrast enhancement. Then, presented an improved Otsu's algorithm for segmenting kidney masses, followed by a stage of feature extraction. A hybrid Lion Optimization Algorithm (LOA) and Moth flame Optimization (MFO) is a novel contributions to improve the convergence rate of the MFO algorithm. The hybrid FS algorithms select the optimal subset of features for disease classification. Finally, a novel Long-Term Recurrent Convolutional Network (LRCN) is introduced for detecting kidney impairment. The models are developed and validated utilizing a database of ultrasonography (US) images including four classes of Chronic kidney images: stone, cyst, tumor, and normal. The efficiency of the framework is assessed based on its of accuracy, precision, recall, F1-score, and specificity of 98.7%, 96.6%, 96.4%, 97.9%, and 96.2% respectively. In addition, testing results show that the framework obtains the best overall performance when compared to existing methods for the classification of ultrasound images.
C1 [Mactina, F. Josephine Nijofi; Neduncheliyan, S.] Bharath Inst higher Educ & Res, Chennai 600126, Tamil Nadu, India.
C3 Bharath Institute of Higher Education & Research
RP Mactina, FJN (corresponding author), Bharath Inst higher Educ & Res, Chennai 600126, Tamil Nadu, India.
EM josephinenijofimactinaf78@gmail.com
OI SUBBU, Dr.NEDUNCHELIYAN/0009-0002-0904-8695
CR Ahmad R, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102695
   Alex DM, 2020, PATTERN RECOGN LETT, V131, P49, DOI 10.1016/j.patrec.2019.12.005
   Alkurdy NH., 2023, INT J EL COMP ENG SY, V13, P3440, DOI [10.11591/ijece.v13i3.pp3440-3448, DOI 10.11591/IJECE.V13I3.PP3440-3448]
   Antony, 2015, ABOUT US
   Aprilianto D., 2020, J SOFT COMPUT EXPLOR, V1, P24
   Chaudhuri AK, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00302-w
   Chittora P, 2021, IEEE ACCESS, V9, P17312, DOI 10.1109/ACCESS.2021.3053763
   Cui WC, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101625
   Debal DA, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00657-5
   Eddy S, 2020, NAT REV NEPHROL, V16, P657, DOI 10.1038/s41581-020-0286-5
   Elhoseny M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46074-2
   Han XR, 2020, CLIN CHIM ACTA, V510, P298, DOI 10.1016/j.cca.2020.07.040
   Harimoorthy K, 2021, J AMB INTEL HUM COMP, V12, P3715, DOI 10.1007/s12652-019-01652-0
   Hosseinzadeh M, 2021, MULTIMED TOOLS APPL, V80, P16933, DOI 10.1007/s11042-020-09049-4
   Huang CY, 2021, ALEX ENG J, V60, P183, DOI 10.1016/j.aej.2020.06.054
   Jain D, 2020, INT J HEALTHC INF SY, V15, P1, DOI 10.4018/IJHISI.2020010101
   Khamparia A, 2020, MULTIMED TOOLS APPL, V79, P35425, DOI 10.1007/s11042-019-07839-z
   Khare S, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.102997
   Kim DH, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11050864
   Liao YT, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010352
   Ma FZ, 2020, FUTURE GENER COMP SY, V111, P17, DOI 10.1016/j.future.2020.04.036
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Murugesan G, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/2653665
   Navaneeth B, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102068
   Nithya A, 2020, MEASUREMENT, V149, DOI 10.1016/j.measurement.2019.106952
   Parthiban R., 2021, Eur. J. Mol. Clin. Med, V7, P2511
   Pradeepa P, 2023, MULTIMED TOOLS APPL, V82, P6309, DOI 10.1007/s11042-022-13561-0
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Qin JM, 2020, IEEE ACCESS, V8, P20991, DOI 10.1109/ACCESS.2019.2963053
   Rahimizadeh N, 2021, MULTIMED TOOLS APPL, V80, P9231, DOI 10.1007/s11042-020-10051-z
   Raju P, 2019, MULTIMED TOOLS APPL, V78, P18419, DOI 10.1007/s11042-018-7145-4
   Rubini LJ, 2020, INT J IMAG SYST TECH, V30, P660, DOI 10.1002/ima.22406
   Schena FP, 2022, J NEPHROL, V35, P1953, DOI 10.1007/s40620-022-01302-3
   Senan EM, 2021, TIERAERZTL PRAX, V42
   Shobana S, 2022, TIERAERZTL PRAX, V42
   Singh V, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12010116
   Sudharson S, 2021, COMPUT METH PROG BIO, V205, DOI 10.1016/j.cmpb.2021.106071
   Sudharson S, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105709
   Viswanath K, 2022, MULTIMED TOOLS APPL, V81, P41807, DOI 10.1007/s11042-021-11263-7
   Wang N, 2020, J ELECTRON MATER, V49, P7085, DOI 10.1007/s11664-020-08483-2
   Wu Y, 2020, KNOWL-BASED SYST, V200, DOI 10.1016/j.knosys.2020.105873
   Yazdani M, 2016, J COMPUT DES ENG, V3, P24, DOI 10.1016/j.jcde.2015.06.003
   Zhang XL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091458
   Zheng Q, 2019, J PEDIATR UROL, V15, DOI 10.1016/j.jpurol.2018.10.020
NR 44
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13577
EP 13612
DI 10.1007/s11042-023-16013-5
EA JUL 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023428100002
DA 2024-07-18
ER

PT J
AU Coccoli, M
   Torre, I
   Galluccio, I
AF Coccoli, Mauro
   Torre, Ilaria
   Galluccio, Ilenia
TI User experience evaluation of Edurell interface for video augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent user interfaces; Interactive visual feedback; Hypervideos;
   MOOCs; Technology enhanced learning
ID CONCEPT MAPS; HYPERVIDEO; EDUCATION; ENHANCE; SCIENCE
AB This paper deals with the use of videos in education and describes an approach to improve the learners' experience in the first-watch and rewatch learning contexts. Actually, learning through videos raises challenging issues like non-linear navigation and poor structure of the video content. Hence, a novel application is presented, designed to address such issues. To this aim, the proposed Edurell environment enriches standard video lessons with new services based on the contents' structure of the video, resulting in a new hypervideo educational application. The system extracts the concepts explained in a given video lesson, their prerequisite relations, and the segments of the video where they occur, together with other pieces of knowledge. The resulting knowledge graph allows creating augmented video lessons and enables learners to perform non-linear navigation and in-depth exploration of their learning contents. This idea was implemented in a custom web-based video player with interactive visual tools. Then, a heuristic usability evaluation was performed with HCI experts. Also, a user study with university students was done, aimed to evaluate the perceived usability and the student's experience in the two mentioned learning contexts. The first results achieved show the effectiveness of the proposed approach.
C1 [Coccoli, Mauro; Torre, Ilaria; Galluccio, Ilenia] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Opera Pia 13, I-16145 Genoa, Italy.
C3 University of Genoa
RP Coccoli, M; Torre, I (corresponding author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, Via Opera Pia 13, I-16145 Genoa, Italy.
EM mauro.coccoli@unige.it; ilaria.torre@unige.it;
   ilenia.galluccio@edu.unige.it
RI Coccoli, Mauro/E-8971-2012
OI Coccoli, Mauro/0000-0001-5802-138X
FU DIBRIS (Dept. of Informatics, Bioengineering, Roboticsand Systems
   Engineering) University of Genoa
FX Partial financial support was received from DIBRIS (Dept. of
   Informatics, Bioengineering, Roboticsand Systems Engineering) University
   of Genoa, in the framework of the SEED competing research grant.
CR Adorni G, 2019, LECT NOTES ARTIF INT, V11625, P1, DOI 10.1007/978-3-030-23204-7_1
   Bevan N, 2015, LECT NOTES COMPUT SC, V9169, P143, DOI 10.1007/978-3-319-20901-2_13
   Birbili M., 2006, Early Childhood Research Practice, V8
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Cattaneo AAP, 2019, INTERACT LEARN ENVIR, V27, P508, DOI 10.1080/10494820.2018.1486860
   Cattaneo AAP, 2018, COMPUT SCH, V35, P249, DOI 10.1080/07380569.2018.1531597
   Caviglione L., 2011, 2011 3rd International Conference on Next Generation Networks and Services (NGNS), P12, DOI 10.1109/NGNS.2011.6142540
   Chatti Mohamed Amine, 2016, Smart Learning Environments, V3, DOI 10.1186/s40561-016-0035-1
   Ciullo S, 2015, BEHAV MODIF, V39, P117, DOI 10.1177/0145445514552890
   Coccoli M, 2022, P 28 INT DISTR MULT, P77, DOI [10.18293/DMSVIVA22-004, DOI 10.18293/DMSVIVA22-004]
   Coccoli M, 2016, DMS 2016: THE 22ND INTERNATIONAL CONFERENCE ON DISTRIBUTED MULTIMEDIA SYSTEMS, P153, DOI 10.18293/DMS2016-018
   Coccoli M, 2015, J E-LEARN KNOWL SOC, V11, P73
   Cummins S, 2016, IEEE T LEARN TECHNOL, V9, P57, DOI 10.1109/TLT.2015.2444374
   Daley BJ, 2010, MED EDUC, V44, P440, DOI 10.1111/j.1365-2923.2010.03628.x
   Dziuban C, 2018, INT J EDUC TECHNOL H, V15, DOI 10.1186/s41239-017-0087-5
   Ellis GW, 2004, INT J ENG EDUC, V20, P1012
   Fesmire M., 2003, Education and Treatment of Children, V26, P89
   Guimaraes Nuno, 2000, INTERACTIVE MULTIMED, V2, P1
   Hrastinski S, 2019, TECHTRENDS, V63, P564, DOI 10.1007/s11528-019-00375-5
   Iso I, 1998, 9241111998 ISO
   Izotova Nadezhda, 2021, E3S Web of Conferences, V284, DOI 10.1051/e3sconf/202128409011
   Kim Juho, 2014, P 27 ANN ACM S USER, P563
   Kovacs G, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P31, DOI 10.1145/2876034.2876041
   Lewis JR, 2014, INT J HUM-COMPUT INT, V30, P663, DOI 10.1080/10447318.2014.930311
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Liu S, 2022, COMPUT EDUC, V181, DOI 10.1016/j.compedu.2022.104461
   LOCATIS C, 1990, ETR&D-EDUC TECH RES, V38, P41, DOI 10.1007/BF02298268
   Mitrovic A, 2017, LECT NOTES ARTIF INT, V10331, P224, DOI 10.1007/978-3-319-61425-0_19
   Moore RL, 2022, COMPUT EDUC, V190, DOI 10.1016/j.compedu.2022.104596
   Nielsen J., 1990, SIGCHI Bulletin, P249
   Niu XJ, 2021, IEEE INT CONF ADV LE, P30, DOI 10.1109/ICALT52272.2021.00016
   Pal D, 2021, INT J HUM-COMPUT INT, V37, P903, DOI 10.1080/10447318.2020.1848164
   Perini M, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0156-z
   Pia AB, 2011, J IND ENG MANAG-JIEM, V4, P81, DOI 10.3926/jiem.2011.v4n1.p81-102
   Quiñones D, 2017, COMPUT STAND INTER, V53, P89, DOI 10.1016/j.csi.2017.03.009
   Rabiger Stefan, 2020, Proceedings of the 16th International Conference Mobile Learning 2020, P71
   Regis A, 1996, J CHEM EDUC, V73, P1084, DOI 10.1021/ed073p1084
   Sauli F, 2018, TECHNOL PEDAGOG EDUC, V27, P115, DOI 10.1080/1475939X.2017.1407357
   Seo K, 2021, COMPUT EDUC, V165, DOI 10.1016/j.compedu.2021.104132
   Tan WS, 2009, INT J IND ERGONOM, V39, P621, DOI 10.1016/j.ergon.2008.02.012
   Torre I, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531179
   Torre I, 2022, LECT NOTES COMPUT SC, V13356, P616, DOI 10.1007/978-3-031-11647-6_128
   Van Zele E, 2004, INT J SCI EDUC, V26, P1043, DOI 10.1080/1468181032000158336
   Verma G, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P249, DOI 10.1145/3397481.3450672
   Zahn C, 2004, LEARN INSTR, V14, P275, DOI 10.1016/j.learninstruc.2004.06.004
   ZIMMERMAN DW, 1987, J EXP EDUC, V55, P171, DOI 10.1080/00220973.1987.10806451
NR 46
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 29
PY 2023
DI 10.1007/s11042-023-15912-x
EA JUN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L3EX6
UT WOS:001022136100012
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chatterjee, S
   Saha, D
   Sen, S
   Oliva, D
   Sarkar, R
AF Chatterjee, Somnath
   Saha, Debyarati
   Sen, Shibaprasad
   Oliva, Diego
   Sarkar, Ram
TI Moth-flame optimization based deep feature selection for facial
   expression recognition using thermal images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Fractional order calculus; Feature
   selection; Thermography image
ID ALGORITHM; INTERNET; SYSTEM; MODEL
AB Automatic human facial expression recognition, a challenging research problem, has many real-life applications in the fields of social media, digital marketing, and healthcare, etc. Facial expression recognition using machine learning is a challenging task due to the variability in facial expressions across different people and situations, as well as the impact of lighting conditions and camera angles on the appearance of a face, thereby making it difficult to accurately recognize expressions. In this paper, we developed a two-stage facial expression recognition system using thermal images. In the first stage, we used a lightweight convolution neural network model called MobileNet, to generate features from the input images. In the second stage, we employed a nature-inspired meta-heuristic, called the Moth-flame Optimization algorithm, to select the optimal subset of features obtained from the MobileNet model. To increase the overall performance, a memory-based variant built on the Grunwald-Letnikov approach is designed. The proposed two-stage model is evaluated on the IR database, a publicly available standard dataset on thermal image-based facial expressions. The proposed model efficiently eliminates the redundant features, and the overall model achieves an accuracy of 97.47% on the said dataset while using only 29% features generated from the MobileNet model.
C1 [Chatterjee, Somnath] Future Inst Engn & Management, Kolkata 700150, West Bengal, India.
   [Saha, Debyarati; Sarkar, Ram] Jadavpur Univ, Kolkata 700032, West Bengal, India.
   [Sen, Shibaprasad] Techno Main Salt Lake, Kolkata 700091, West Bengal, India.
   [Oliva, Diego] Univ Guadalajara, Dept Innovac Basada Informac & Conocimiento, CUCEI, Guadalajara 44430, Mexico.
C3 Jadavpur University; Universidad de Guadalajara
RP Oliva, D (corresponding author), Univ Guadalajara, Dept Innovac Basada Informac & Conocimiento, CUCEI, Guadalajara 44430, Mexico.
EM somnathchatterjee796@gmail.com; debyaratiju@gmail.com;
   shibubiet@gmail.com; diego.oliva@cucei.udg.mx;
   ram.sarkar@jadavpuruniversity.in
RI Oliva, Diego/A-3271-2016
OI Oliva, Diego/0000-0001-8781-7993
CR Abd Elaziz M, 2021, ENG APPL ARTIF INTEL, V98, DOI 10.1016/j.engappai.2020.104105
   Agada R, 2015, P 2015 IEEE INT C EL, P1, DOI [10.1109/icecct.2015.7226014, DOI 10.1109/ICECCT.2015.7226014]
   Akrout B, 2023, EXPERT SYST, DOI 10.1111/exsy.13314
   Banerjee D, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115756
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Bhattacharyya A, 2022, HDB MOTH FLAME OPTIM, P281, DOI [10.1201/9781003205326-18, DOI 10.1201/9781003205326-18]
   Bhattacharyya A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99998-z
   Bindu CH, 2020, COMP M BIO BIO E-IV, V8, P581, DOI 10.1080/21681163.2020.1761454
   Bindu H, 2018, SENSOR REV, V38, P269, DOI 10.1108/SR-06-2017-0115
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chattopadhyay S, 2023, MULTIMED TOOLS APPL, V82, P9693, DOI 10.1007/s11042-021-11839-3
   Chauhan R, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P278, DOI 10.1109/ICSCCC.2018.8703316
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   Chen LS, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P366, DOI 10.1109/AFGR.1998.670976
   Chollet F., 2016, arXiv
   Cruz-Albarran IA, 2017, INFRARED PHYS TECHN, V81, P250, DOI 10.1016/j.infrared.2017.01.002
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P., 2005, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression Using the Facial Action Coding System (FACS), VSecond, DOI DOI 10.1093/ACPROF:OSO/9780195179644.001.0001
   Filippini C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082924
   Frymier A.B., 1993, Communication Reports, V6, P8, DOI [https://doi.org/10.1080/08934219309367556, DOI 10.1080/08934219309367556, 10.1080/08934219309367556]
   Gao HX, 2023, NEURAL NETWORKS, V158, P228, DOI 10.1016/j.neunet.2022.11.025
   Gharsalli S, 2015, VISAPP 2015, P424, DOI [10.5220/0005312804240431, DOI 10.5220/0005312804240431]
   Ghobaei-Arani M, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3770
   Ghosh M, 2019, EXPERT SYST APPL, V116, P172, DOI 10.1016/j.eswa.2018.06.057
   Ghosh M, 2019, MED BIOL ENG COMPUT, V57, P159, DOI 10.1007/s11517-018-1874-4
   Ghosh S, 2022, SOFT COMPUT, V26, P891, DOI 10.1007/s00500-021-06260-9
   Goggins KA, 2022, APPL ERGON, V98, DOI 10.1016/j.apergo.2021.103576
   Graves A., 2013, GENERATING SEQUENCES
   Guyon I., 2006, FEATURE EXTRACTION F, DOI [DOI 10.1007/978-3-540-35488-8, 10.1007/978-3-540-35488-8]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He S, 2013, INT CONF AFFECT, P239, DOI 10.1109/ACII.2013.46
   Hossain MA, 2020, 2020 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P330, DOI [10.1109/esci48226.2020.9167616, 10.1109/ESCI48226.2020.9167616]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hsu HH, 2011, EXPERT SYST APPL, V38, P8144, DOI 10.1016/j.eswa.2010.12.156
   Huang YX, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101189
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan AH, 2022, EXP TECHNIQUES, V46, P335, DOI 10.1007/s40799-021-00470-4
   Khan MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217286
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Kopaczka M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194135
   Kopaczka M, 2018, IEEE IMTC P, P1962
   Majee A, 2022, HDB MOTH FLAME OPTIM, P129, DOI [10.1201/9781003205326-10, DOI 10.1201/9781003205326-10]
   Merla A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00802
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P43, DOI 10.1007/978-3-319-93025-1_4
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohamed NS, 2017, EXPERT SYST APPL, V90, P224, DOI 10.1016/j.eswa.2017.08.026
   Pabba C, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12839
   Prabhakaran Aiswarya K., 2021, Advances in Computing and Network Communications. Proceedings of CoCoNet 2020. Lecture Notes in Electrical Engineering (LNEE 736), P389, DOI 10.1007/978-981-33-6987-0_32
   Prossinger H, 2022, TECHNOLOGIES, V10, DOI 10.3390/technologies10040075
   Raj RJS, 2020, IEEE ACCESS, V8, P58006, DOI 10.1109/ACCESS.2020.2981337
   Rashedi E, 2010, NAT COMPUT, V9, P727, DOI 10.1007/s11047-009-9175-3
   Reddy GV, 2020, COGN SYST RES, V62, P23, DOI 10.1016/j.cogsys.2020.03.002
   Reddy MPK, 2019, CLUSTER COMPUT, V22, P13095, DOI 10.1007/s10586-017-1261-1
   Refaeilzadeh P., 2016, Encyclopedia of database systems, P1, DOI [DOI 10.1007/978-0-387-39940-9, 10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_565]
   Teodoro GS, 2019, J COMPUT PHYS, V388, P195, DOI 10.1016/j.jcp.2019.03.008
   Sayette MA, 2001, J NONVERBAL BEHAV, V25, P167, DOI 10.1023/A:1010671109788
   Sen S, 2021, APPL INTELL, V51, P8985, DOI 10.1007/s10489-021-02292-8
   Shehab M, 2020, NEURAL COMPUT APPL, V32, P9859, DOI 10.1007/s00521-019-04570-6
   Sikkandar H, 2021, J AMB INTEL HUM COMP, V12, P3037, DOI 10.1007/s12652-020-02463-4
   Smith L.N., 2017, ARXIV
   Sorostinean M, 2015, IEEE-RAS INT C HUMAN, P14, DOI 10.1109/HUMANOIDS.2015.7363516
   Sun Z, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109157
   Tan TY, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105725
   Wang SF, 2012, INT CONF CLOUD COMPU, P94, DOI 10.1109/CCIS.2012.6664375
   Wang S, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P327, DOI 10.1109/ISCSCT.2008.356
   Wei YH, 2019, J COMPUT NONLIN DYN, V14, DOI 10.1115/1.4042635
   Wu M, 2021, IEEE T SYST MAN CY-S, V51, P1473, DOI 10.1109/TSMC.2019.2897330
   Xue DY, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1043
   Zervoudakis K, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106559
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
NR 74
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11299
EP 11322
DI 10.1007/s11042-023-15861-5
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900006
DA 2024-07-18
ER

PT J
AU Özmen, G
   Özsen, S
   Paksoy, Y
   Güler, O
   Tekdemir, R
AF Ozmen, Guzin
   Ozsen, Seral
   Paksoy, Yahya
   Guler, Ozkan
   Tekdemir, Rukiye
TI Machine learning based detection of depression from task-based fMRI
   using weighted-3D-DWT denoising method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depression; fMRI; 3D-Discrete wavelet transform; Machine learning; PCA;
   Spm; T
ID PATTERN-CLASSIFICATION; MR-IMAGES; NEUROBIOLOGICAL MARKERS; PATIENT
   CLASSIFICATION; BIPOLAR DEPRESSION; MAJOR DEPRESSION; EMOTIONAL FACES;
   ACTIVATION; VULNERABILITY; RESILIENCE
AB Depression has become an important public health problem in recent years because the probability of a depressive episode in a person's entire life is generally between 18-20%. Neuroimaging techniques investigate diagnostic biomarkers in depression disorders and support traditional communication-based diagnosis in psychiatry. The quality of the brain images used in functional MRI (fMRI), and the design of decision support systems using these images are essential for accurate diagnosis. The Gaussian smoothing for fMRI preprocessing blurs the image for statistical analysis but is inadequate because image detail is lost during filtering, leading to poor classification results. We argue that the weighted-3 Dimensional-Discrete Wavelet Transform (weighted-3D-DWT) denoising approach instead of Gaussian smoothing for task-based fMRI. The activation maps show differences in intensity values in the cluster size of voxels in the mood-related regions between patients and control subjects (p<0.05). Thus, we classify depression disorders using a machine learning approach and improve the classification accuracy using weighted-3D-DWT. The classification results show that weighted-3D- DWT with Random Forest and 10-fold cross-validation achieves 96.4% accuracy, while Gaussian Smoothing with a Support Vector Machine achieves 83.9% classification accuracy. Classification accuracy increases to 97.3% when 30 components are used with principal component analysis. Our results show that an fMRI experiment with visual stimuli that can aid the diagnosis of depression provides significant classification accuracy using weighted-3D-DWT.
C1 [Ozmen, Guzin] Selcuk Univ, Fac Technol, Dept Biomed Engn, TR-42075 Konya, Turkiye.
   [Ozsen, Seral] Konya Tech Univ, Fac Engn & Nat Sci, Dept Elect Elect Engn, TR-42250 Konya, Turkiye.
   [Paksoy, Yahya] Hamad Med Corp, Neurosci Inst, Neuroradiol Dept, Doha, Qatar.
   [Paksoy, Yahya] Selcuk Univ, Dept Radiol, Konya, Turkiye.
   [Paksoy, Yahya] Qatar Univ, Dept Neuroradiol, Doha, Qatar.
   [Guler, Ozkan; Tekdemir, Rukiye] Selcuk Univ, Fac Med, Dept Psychiat, Konya, Turkiye.
C3 Selcuk University; Konya Technical University; Hamad Medical
   Corporation; Selcuk University; Qatar University; Selcuk University
RP Özmen, G (corresponding author), Selcuk Univ, Fac Technol, Dept Biomed Engn, TR-42075 Konya, Turkiye.
EM gozmen@selcuk.edu.tr; sozsen@ktun.edu.tr; yahyapaksoy@yahoo.com;
   gulerozkan@hotmail.com; dr.rtekdemir@gmail.com
RI OZMEN, Guzin/AHB-8712-2022; tekdemir, rukiye/JBJ-7542-2023; PAKSOY,
   YAHYA/JBS-4953-2023; tekdemir, rukiye/KRQ-6319-2024
OI OZMEN, Guzin/0000-0003-3007-5807; tekdemir, rukiye/0000-0001-7912-5727;
   PAKSOY, YAHYA/0000-0002-4738-9194; tekdemir, rukiye/0000-0001-7912-5727
FU Selcuk University [16101006]
FX This work was supported by the Scientific Research Projects Coordination
   of Selcuk University with the project number: 16101006.
CR Aderka IM, 2021, BEHAV RES THER, V144, DOI 10.1016/j.brat.2021.103929
   Aja-Fernandez S., 2013, A review on statistical noise models for magnetic resonance imaging
   Al-Hiyali MI, 2021, IEEE EMBS CONF BIO, P94, DOI 10.1109/IECBES48179.2021.9398803
   Al-Hiyali MI, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165256
   Bürger C, 2017, NEUROPSYCHOPHARMACOL, V42, P1399, DOI 10.1038/npp.2017.36
   Chen JYE, 2015, NEUROPSYCHOL REV, V25, P289, DOI 10.1007/s11065-015-9294-9
   Drevets WC, 2008, BRAIN STRUCT FUNCT, V213, P93, DOI 10.1007/s00429-008-0189-x
   Dunlop BW, 2014, DIALOGUES CLIN NEURO, V16, P479
   Erdogan SB, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145407
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fischer AS, 2021, CURR OPIN PSYCHIATR, V34, P22, DOI 10.1097/YCO.0000000000000662
   Flint C, 2021, NEUROPSYCHOPHARMACOL, V46, P1510, DOI 10.1038/s41386-021-01020-7
   Francis S, 2014, PHYSIOL MEAS, V35, pR167, DOI 10.1088/0967-3334/35/9/R167
   Frangou S, 2017, NEUROIMAGE, V145, P230, DOI 10.1016/j.neuroimage.2016.08.066
   Friston KJ, 1995, HUM BRAIN MAPP, V3, P165, DOI 10.1002/hbm.460030303
   Fu CHY, 2008, BIOL PSYCHIAT, V63, P656, DOI 10.1016/j.biopsych.2007.08.020
   Gao S, 2018, CNS NEUROSCI THER, V24, P1037, DOI 10.1111/cns.13048
   Gibbs P, 1996, PHYS MED BIOL, V41, P2437, DOI 10.1088/0031-9155/41/11/014
   Gonzalez RE Woods R.C., 2002, DIGITAL IMAGE PROCES
   Grecucci A, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.804440
   Grotegerd D, 2014, HUM BRAIN MAPP, V35, P2995, DOI 10.1002/hbm.22380
   Gui RZ, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/5850830
   Habes I, 2013, NEUROIMAGE-CLIN, V2, P675, DOI 10.1016/j.nicl.2013.05.001
   Hahn T, 2011, ARCH GEN PSYCHIAT, V68, P361, DOI 10.1001/archgenpsychiatry.2010.178
   Halidou A, 2023, MULTIMED TOOLS APPL, V82, P41539, DOI 10.1007/s11042-023-15127-0
   Hall LMJ, 2014, J AFFECT DISORDERS, V168, P44, DOI 10.1016/j.jad.2014.06.037
   HASLAM N, 1993, J NERV MENT DIS, V181, P725, DOI 10.1097/00005053-199312000-00003
   Haweel R, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175822
   Johnston BA, 2015, BRAIN, V138, P2766, DOI 10.1093/brain/awv177
   Kay KN, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00247
   Khullar S, 2011, NEUROIMAGE, V54, P2867, DOI 10.1016/j.neuroimage.2010.10.063
   Kuncheva LI, 2010, MAGN RESON IMAGING, V28, P583, DOI 10.1016/j.mri.2009.12.021
   Li ZZ, 2021, COMPUT MED IMAG GRAP, V89, DOI 10.1016/j.compmedimag.2021.101882
   Lindquist MA, 2008, STAT SCI, V23, P439, DOI 10.1214/09-STS282
   Malekian V, 2020, J NEUROSCI METH, V331, DOI 10.1016/j.jneumeth.2019.108497
   Manjón JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003
   Marquand AF, 2008, NEUROREPORT, V19, P1507, DOI 10.1097/WNR.0b013e328310425e
   Mayberg HS, 2003, BRIT MED BULL, V65, P193, DOI 10.1093/bmb/65.1.193
   McGrath CL, 2013, JAMA PSYCHIAT, V70, P821, DOI 10.1001/jamapsychiatry.2013.143
   Misaki M, 2010, NEUROIMAGE, V53, P103, DOI 10.1016/j.neuroimage.2010.05.051
   Mitchell TM, 2004, MACH LEARN, V57, P145, DOI 10.1023/B:MACH.0000035475.85309.1b
   Modinos G, 2013, PEERJ, V1, DOI 10.7717/peerj.42
   Mourao-Miranda J, 2011, NEUROIMAGE, V58, P793, DOI 10.1016/j.neuroimage.2011.06.042
   Myers RH, 1997, J QUAL TECHNOL, V29, P274, DOI 10.1080/00224065.1997.11979769
   Nouretdinov I, 2011, NEUROIMAGE, V56, P809, DOI 10.1016/j.neuroimage.2010.05.023
   OLIVER JM, 1984, J CONSULT CLIN PSYCH, V52, P892, DOI 10.1037/0022-006X.52.5.892
   Ozmen G, 2016, P 4 INT C ADV TECHN, P311
   Ozmen G, 2017, 5 INT C ADV TECHN SC, P814
   Özmen G, 2018, NEURAL COMPUT APPL, V29, P263, DOI 10.1007/s00521-017-2995-7
   Patel MJ, 2016, NEUROIMAGE-CLIN, V10, P115, DOI 10.1016/j.nicl.2015.11.003
   Pereira Francisco, 2009, Neuroimage, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007
   Poline JB, 2012, NEUROIMAGE, V62, P871, DOI 10.1016/j.neuroimage.2012.01.133
   Prochazka A, 2011, P IASTED INT C GRAPH, P268
   Rondina JM, 2014, IEEE T MED IMAGING, V33, P85, DOI 10.1109/TMI.2013.2281398
   Rosa MJ, 2015, NEUROIMAGE, V105, P493, DOI 10.1016/j.neuroimage.2014.11.021
   Sato JR, 2015, PSYCHIAT RES-NEUROIM, V233, P289, DOI 10.1016/j.pscychresns.2015.07.001
   Semmlow J.L., 2008, Biosignal and medical image processing
   Sheline YI, 2001, BIOL PSYCHIAT, V50, P651, DOI 10.1016/S0006-3223(01)01263-X
   Shim M, 2019, NEUROIMAGE-CLIN, V24, DOI 10.1016/j.nicl.2019.102001
   Shimizu F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0122000
   Suma HN, 2007, INT J COMPUT SCI NET, V7, P235
   Sun JF, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.876121
   Townsend JD, 2010, PSYCHIAT RES-NEUROIM, V183, P209, DOI 10.1016/j.pscychresns.2010.06.001
   Tripoliti EE, 2010, J BIOMED INFORM, V43, P307, DOI 10.1016/j.jbi.2009.10.004
   Wang Y, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-40
   WHO, 2023, Epilepsy
   Wink AM, 2004, IEEE T MED IMAGING, V23, P374, DOI 10.1109/TMI.2004.824234
   Wollenhaupt-Aguiar B, 2020, AUST NZ J PSYCHIAT, V54, P393, DOI 10.1177/0004867419888027
   Yan BY, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00191
   Yang WJ, 2016, J AFFECT DISORDERS, V190, P880, DOI 10.1016/j.jad.2015.05.034
   Yang XF, 2011, MEAS SCI TECHNOL, V22, DOI 10.1088/0957-0233/22/2/025803
   Zeng LL, 2012, BRAIN, V135, P1498, DOI 10.1093/brain/aws059
NR 72
TC 0
Z9 0
U1 19
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11805
EP 11829
DI 10.1007/s11042-023-15935-4
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000007
DA 2024-07-18
ER

PT J
AU Chen, Y
   Ni, JJ
   Tang, GY
   Cao, WD
   Yang, SX
AF Chen, Yan
   Ni, Jianjun
   Tang, Guangyi
   Cao, Weidong
   Yang, Simon X.
TI An improved dense-to-sparse cross-modal fusion network for 3D object
   detection in RGB-D images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D object detection; RGB-D; Deep learning; Cross-modal fusion
AB 3D object detection has received extensive attention from researchers. RGB-D sensors are often used for the information complementary in 3D object detection tasks due to their easy acquisition of aligned point cloud and RGB image data, relatively reasonable prices, and reliable performance. However, how to effectively fuse point cloud data and RGB image data in RGB-D images, and use this cross-modal information to improve the performance of 3D object detection, remains a challenge for further research. To deal with these problems, an improved dense-to-sparse cross-modal fusion network for 3D object detection in RGB-D images is proposed in this paper. First, a dense-to-sparse cross-modal learning module (DCLM) is designed, which reduces information waste in the interaction between 2D dense information and 3D sparse information. Then, an inter-modal attention fusion module (IAFM) is designed, which can retain more meaningful information adaptively in the fusion process for the 2D and 3D features. In addition, an intra-modal attention context aggregation module (IACAM) is designed to aggregate context information in both 2D and 3D modalities, and model the relationship between objects. Finally, the detailed quantitative and qualitative experiments are carried out on the SUN RGB-D dataset, and the results show that the proposed model can obtain state-of-the-art 3D object detection results.
C1 [Chen, Yan; Ni, Jianjun; Tang, Guangyi; Cao, Weidong] Hohai Univ, Coll Informat Sci & Engn, Changzhou 213022, Peoples R China.
   [Chen, Yan; Ni, Jianjun; Tang, Guangyi; Cao, Weidong] Hohai Univ, Sch Artificial Intelligence & Automat, Changzhou 213022, Peoples R China.
   [Yang, Simon X.] Univ Guelph, Sch Engn, Adv Robot & Intelligent Syst ARIS Lab, Guelph, ON N1G 2W1, Canada.
C3 Hohai University; Hohai University; University of Guelph
RP Ni, JJ (corresponding author), Hohai Univ, Coll Informat Sci & Engn, Changzhou 213022, Peoples R China.; Ni, JJ (corresponding author), Hohai Univ, Sch Artificial Intelligence & Automat, Changzhou 213022, Peoples R China.
EM stcy401_doc@hhu.edu.cn; njjhhuc@gmail.com; tang_gy@hhu.edu.cn;
   cwd2018@hhu.edu.cn; syang@uoguelph.ca
RI Li, Yan/JUU-5189-2023
FU National Natural Science Foundation of China [61873086]; Science and
   Technology Support Program of Changzhou [CE20215022]
FX AcknowledgementsThis work was supported by National Natural Science
   Foundation of China (61873086) and the Science and Technology Support
   Program of Changzhou (CE20215022).
CR Araki R, 2022, ADV ROBOTICS, V36, P373, DOI 10.1080/01691864.2022.2043183
   Bai XY, 2022, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR52688.2022.00116
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Chen Z, 2022, ARXIV
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Cheng BW, 2021, PROC CVPR IEEE, P8959, DOI 10.1109/CVPR46437.2021.00885
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Engelcke Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1355, DOI 10.1109/ICRA.2017.7989161
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Gao ZP, 2020, DISPLAYS, V65, DOI 10.1016/j.displa.2020.101972
   Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Huang SY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6515, DOI 10.1109/ICCV48922.2021.00647
   Jeon G, 2020, MULTIMED TOOLS APPL, V79, P34129, DOI 10.1007/s11042-020-09232-7
   Ji CF, 2022, MULTIMED TOOLS APPL, V81, P5973, DOI 10.1007/s11042-021-11801-3
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Li L, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533876
   Li YW, 2022, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR52688.2022.00119
   Li Y, 2020, ISPRS J PHOTOGRAMM, V165, P43, DOI 10.1016/j.isprsjprs.2020.05.008
   Liu BZ, 2018, VISUAL COMPUT, V34, P707, DOI 10.1007/s00371-017-1408-3
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2929, DOI 10.1109/ICCV48922.2021.00294
   Lu YF, 2022, NEUROCOMPUTING, V513, P70, DOI 10.1016/j.neucom.2022.09.117
   Luo QH, 2020, NEUROCOMPUTING, V378, P364, DOI 10.1016/j.neucom.2019.10.025
   Luo SJ, 2021, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR46437.2021.00608
   Misra I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2886, DOI 10.1109/ICCV48922.2021.00290
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Ng MY, 2020, IEEE COMPUT SOC CONF, P4306, DOI 10.1109/CVPRW50498.2020.00508
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Ni JJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082749
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rahman MM, 2020, IEEE T IMAGE PROCESS, V29, P2947, DOI 10.1109/TIP.2019.2955239
   Ren YZ, 2018, J VIS COMMUN IMAGE R, V55, P131, DOI 10.1016/j.jvcir.2018.05.019
   Ren ZL, 2020, IEEE T PATTERN ANAL, V42, P2670, DOI 10.1109/TPAMI.2019.2923201
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Sun RD, 2020, IEEE T VLSI SYST, V28, P565, DOI 10.1109/TVLSI.2019.2945982
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang D., 2020, P IEEECVF C COMPUTER, P12695, DOI DOI 10.1109/CVPR42600.2020.01271
   Wang HY, 2022, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR52688.2022.00118
   Wang YF, 2021, DISPLAYS, V70, DOI 10.1016/j.displa.2021.102077
   Wang YK, 2022, PROC CVPR IEEE, P12176, DOI 10.1109/CVPR52688.2022.01187
   Wang YK, 2022, PROC CVPR IEEE, P12104, DOI 10.1109/CVPR52688.2022.01180
   Wang ZT, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3462219
   Woodford OJ, 2014, INT J COMPUT VISION, V106, P332, DOI 10.1007/s11263-013-0623-2
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xie Q, 2021, INT J COMPUT VISION, V129, P1857, DOI 10.1007/s11263-021-01456-w
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Zhang LP, 2021, DISPLAYS, V68, DOI 10.1016/j.displa.2021.102022
   Zhang MH, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13224706
   Zhang YA, 2022, PROC CVPR IEEE, P898, DOI 10.1109/CVPR52688.2022.00098
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao LC, 2021, IEEE T CIRC SYST VID, V31, P4735, DOI 10.1109/TCSVT.2021.3102025
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhou ZK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12757, DOI 10.1109/ICCV48922.2021.01254
NR 70
TC 0
Z9 0
U1 10
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12159
EP 12184
DI 10.1007/s11042-023-15845-5
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200007
DA 2024-07-18
ER

PT J
AU Taneja, N
   Bramhe, VS
   Bhardwaj, D
   Taneja, A
AF Taneja, Neeti
   Bramhe, Vijendra Singh
   Bhardwaj, Dinesh
   Taneja, Ashu
TI Understanding digital image anti-forensics: an analytical review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Blocking artifacts; Anti-forensics; JPEG compression; MFR; CNN
ID JPEG; ENHANCEMENT; COUNTER; IDENTIFICATION; QUALITY; FORGERY; MODELS;
   TRACES
AB Image forensics is essential for detecting image manipulation, authenticating images, and identifying sources of images. A forensic analyst can make use of various artifacts to develop a powerful forensic technique. These artifacts include JPEG blocking and quantization artifacts, streaking artifacts and contrast enhancement artifacts, etc. With the introduction of anti-forensics, it has become difficult for forensic experts to identify forged images. There are various anti-forensic methods available that try to eradicate these detection footprints/artifacts to fool the existing forensic detectors. Thus the detection of anti-forensic attacks is very crucial and plays a vital role in forensic analysis. This paper presents a review of various types of anti-forensic attacks, such as JPEG anti-forensics, Contrast enhancement anti-forensics, and Median filtering anti-forensics. Firstly a brief introduction is given about image forgery, JPEG compression, contrast enhancement, and median filtering. Then, anti-forensics is described in detail, and finally, the recent state-of-the-art anti-forensic techniques are summarized in tabular form for better understanding. This may be helpful for the forensic analyst to develop robust methods for forgery detection that can be applied in various applications such as the identification of cybercrimes, identity thefts, etc.
C1 [Taneja, Neeti; Bramhe, Vijendra Singh] Sharda Univ, Sharda Sch Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
   [Bhardwaj, Dinesh] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala 147004, Punjab, India.
   [Taneja, Ashu] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura 140401, Punjab, India.
C3 Sharda University; Thapar Institute of Engineering & Technology;
   Chitkara University, Punjab
RP Taneja, N (corresponding author), Sharda Univ, Sharda Sch Engn & Technol, Dept Comp Sci & Engn, Greater Noida 201310, Uttar Pradesh, India.
EM neeti.taneja30@gmail.com; vijendra.singh1@sharda.ac.in;
   dinesh.bhardwaj@thapar.edu; ashu.taneja@chitkara.edu.in
RI Bramhe, Vijendra/AAC-5783-2022
OI Bramhe, Vijendra/0000-0001-7957-4100
CR [Anonymous], 2012, INFORM HIDING IH 201
   [Anonymous], 2019, MULTIDIM SYST SIGN P
   Barni M, 2018, EUR SIGNAL PR CONF, P962, DOI 10.23919/EUSIPCO.2018.8553305
   Barni M, 2015, LECT NOTES COMPUT SC, V9023, P31, DOI 10.1007/978-3-319-19321-2_3
   Bhardwaj D, 2018, SIGNAL PROCESS-IMAGE, V68, P155, DOI 10.1016/j.image.2018.07.011
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P25
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen C., 2011, P 10 INT WORKSHOP DI, P361
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chun-Wing Kwok, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P398, DOI 10.1007/978-3-642-32205-1_32
   Cruz F, 2017, PROC INT CONF DOC, P1223, DOI 10.1109/ICDAR.2017.202
   Dang-Nguyen DT, 2013, IEEE INT WORKSH MULT, P260, DOI 10.1109/MMSP.2013.6659298
   Datta P, 2020, LECT NOTES ELECTR EN, V597, P515, DOI 10.1007/978-3-030-29407-6_37
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Fan W, 2015, IEEE T INF FOREN SEC, V10, P1076, DOI 10.1109/TIFS.2015.2398362
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hingrajiya Krishna H., 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P83, DOI 10.1109/ICACITE51222.2021.9404748
   Hui Zeng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2704, DOI 10.1109/ICASSP.2014.6854091
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   KAIMAL AB, 2019, BIOMED PHARMACOL J, V12, P1395, DOI DOI 10.13005/bpj/1768
   Kang XG, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P483, DOI 10.1109/ChinaSIP.2015.7230449
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kim D, 2021, IEEE ACCESS, V9, P13390, DOI 10.1109/ACCESS.2021.3051678
   Kim D, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2782363
   Kumar A, 2021, IEEE ACCESS, V9, P4364, DOI 10.1109/ACCESS.2020.3048246
   Kumar A, 2019, MULTIMED TOOLS APPL, V78, P25427, DOI 10.1007/s11042-019-7734-x
   Kumawat C, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.116008
   Lalitha RVSS, 2017, LECT NOTE NETW SYST, V5, P261, DOI 10.1007/978-981-10-3226-4_26
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li HD, 2012, IEEE IMAGE PROC, P241, DOI 10.1109/ICIP.2012.6466840
   Lin XF, 2013, IEEE IMAGE PROC, P4467, DOI 10.1109/ICIP.2013.6738920
   Lin XF, 2014, PROC SPIE, V9028, DOI 10.1117/12.2038644
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Mehrish A, 2019, IEEE ACCESS, V7, P27183, DOI 10.1109/ACCESS.2019.2901345
   Pasquini Cecilia, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2699, DOI 10.1109/ICASSP.2014.6854090
   Peng AJ, 2019, IEEE ACCESS, V7, P28525, DOI 10.1109/ACCESS.2019.2897761
   Priyanka, 2020, MULTIMED TOOLS APPL, V79, P13011, DOI 10.1007/s11042-019-08354-x
   Qazi T, 2013, IET IMAGE PROCESS, V7, P660, DOI 10.1049/iet-ipr.2012.0388
   Ravi H, 2016, IEEE SIGNAL PROC LET, V23, P212, DOI 10.1109/LSP.2015.2509477
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Sharma A, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P1, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.18
   Sharma K, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118612
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Singh G, 2019, IEEE T INF FOREN SEC, V14, P1194, DOI 10.1109/TIFS.2018.2871751
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Srinivasu PN, 2022, GAZI U J SCI, V35, P1372, DOI 10.35378/gujs.884880
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Sutthiwan Patchara, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P411, DOI 10.1007/978-3-642-32205-1_33
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Valenzise G, 2013, IEEE T INF FOREN SEC, V8, P335, DOI 10.1109/TIFS.2012.2234117
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wen LY, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183518
   Wu ZH, 2013, INT CONF ACOUST SPEE, P3043, DOI 10.1109/ICASSP.2013.6638217
   Xie H, 2022, IEEE T CIRC SYST VID, V32, P1701, DOI 10.1109/TCSVT.2021.3068294
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yang P, 2018, ROBUST CONTRAST ENHA
   Yang PP, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101318
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang KJ, 2019, IEEE ACCESS, V7, P129494, DOI 10.1109/ACCESS.2019.2939812
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
   Zhao MN, 2020, IEEE ACCESS, V8, P54431, DOI 10.1109/ACCESS.2019.2959627
   Zou H., 2021, SECUR COMMUN NETW, V1-8, P2021
NR 73
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10445
EP 10466
DI 10.1007/s11042-023-15866-0
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200008
DA 2024-07-18
ER

PT J
AU Wang, J
   Yang, ZJ
   Huo, ZQ
   Chen, W
AF Wang, Jing
   Yang, Zongju
   Huo, Zhanqiang
   Chen, Wei
TI Local and nonlocal flow-guided video inpainting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video inpainting; Deep flow completion network; Sample window; Local and
   nonlocal; Edge completion
AB The purpose of video inpainting is to get a reasonable content from the video to fill in the missing region. Video is a continuous four-dimensional sequence in the temporal dimension. It's difficult to ensure the temporal continuity of video by inpaint video frames respectively along the time dimension. Video inpainting has gone from the traditional inpainting algorithm to the advanced learning based inpainting method. It has been able to inpainting for a variety of scenes. However, there are still unresolved questions in video inpainting, and video inpainting is still a challenging task. Existing works focused on fixing the problem of object removal in the video, and neglected the importance of inpainting the occlusion scene in the middle region. For the occlusion problem in the middle region, we propose a local and nonlocal optical flow video inpainting framework. First, according to the forward and backward directions of the reference frame and the sampling window, we divide the video into local and nonlocal frames, extract the local and nonlocal optical flow and feed them to the residual network for rough inpainting. Next, our approach extracts and completes the edges of the predicted flow. Finally, the composed optical flow field guides the propagation of pixels to inpaint the video content. Experimental results on DAVIS and YouTube-VOS datasets show that our method has significantly improved in terms of the image quality and optical flow quality compared with the state of the art. Codes are available at https://github. com/lengfengio/LNFVI.git.
C1 [Wang, Jing; Yang, Zongju; Huo, Zhanqiang; Chen, Wei] Henan Polytech Univ, Sch Software, Jiaozuo 454003, Peoples R China.
C3 Henan Polytechnic University
RP Huo, ZQ (corresponding author), Henan Polytech Univ, Sch Software, Jiaozuo 454003, Peoples R China.
EM wjasmine@hpu.edu.cn; zongjuyang@home.hpu.edu.cn; hzq@hpu.edu.cn;
   cw@hpu.edu.cn
RI Wang, Ling/AGR-4917-2022; Li, Fan/KBB-8931-2024; Liu,
   Fuyi/KDO-6120-2024; Wang, Ling/KBA-9814-2024; Jing, Jing/JSK-6237-2023;
   xiang, wei/JXL-3308-2024; wang, wenjing/KEH-0575-2024; Zhang,
   Tianxi/KEH-5921-2024; Wang, Yue/JRY-8962-2023; WANG,
   YUHAO/KBB-0213-2024; Yuan, Ye/KBC-9835-2024; zhang,
   jiahao/KEE-9357-2024; Chen, GuanYu/KGK-6328-2024; Liu,
   Song/KCX-6842-2024; li, yuan/KBQ-4200-2024; xu, liu/KCL-1154-2024; Lu,
   Yi/KEJ-2560-2024; Yun, Wang/KHM-3009-2024; zhang, xiaoyu/KEJ-0657-2024;
   Li, Chun/KBC-9591-2024; Qi, Ling/KHE-3068-2024; LI, HAO/KBD-0866-2024
OI Wang, Ling/0000-0003-0272-2974; Wang, Ling/0000-0003-0272-2974; Wang,
   Yue/0000-0001-8673-6358; Yuan, Ye/0009-0008-1640-7047; Huo,
   Zhanqiang/0000-0001-9243-5009
FU Fundamental Research Funds for the Universities of Henan Province
   [NSFRF220414]; Excellent Young Teachers Program of Henan Polytechnic
   University [2019XQG-02]
FX This work was supported by Fundamental Research Funds for the
   Universities of Henan Province(NSFRF220414), Excellent Young Teachers
   Program of Henan Polytechnic University(No.2019XQG-02)
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P713, DOI 10.1007/978-3-030-58610-2_42
   Chen L, 2012, IEICE T INF SYST, VE95D, P1130, DOI 10.1587/transinf.E95.D.1130
   Cheng JR, 2020, KSII T INTERNET INF, V14, P4625, DOI 10.3837/tiis.2020.12.001
   Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377
   Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Elharrouss O, 2020, NEURAL PROCESS LETT, V51, P2007, DOI 10.1007/s11063-019-10163-0
   GIBBONS FX, 1990, ADV EXP SOC PSYCHOL, V23, P249, DOI 10.1016/S0065-2601(08)60321-4
   Huang JB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982398
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jam J, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103147
   Kim D, 2019, PROC CVPR IEEE, P5785, DOI 10.1109/CVPR.2019.00594
   Köhler R, 2014, LECT NOTES COMPUT SC, V8753, P523, DOI 10.1007/978-3-319-11752-2_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2019, IEEE I CONF COMP VIS, P4412, DOI 10.1109/ICCV.2019.00451
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Li Z, 2022, PROC CVPR IEEE, P17541, DOI 10.1109/CVPR52688.2022.01704
   Lin J, 2018, ARXIV181108383, P1811
   Liu K, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/9291971
   Liu K, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/680623
   Nazeri K., 2019, ARXIV
   Newson A, 2014, SIAM J IMAGING SCI, V7, P1993, DOI 10.1137/140954933
   Oh SW, 2019, IEEE I CONF COMP VIS, P4402, DOI 10.1109/ICCV.2019.00450
   Ouyang H., 2021, P IEEE CVF INT C COM, P14579
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Ren JSJ, 2015, ADV NEUR IN, V28
   Shao MW, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105778
   Shaw P., 2018, ARXIV
   Shih TK, 2009, IEEE T CIRC SYST VID, V19, P347, DOI 10.1109/TCSVT.2009.2013519
   Sridevi G, 2019, CIRC SYST SIGNAL PR, V38, P3802, DOI 10.1007/s00034-019-01029-w
   Theckedath D., 2020, SN COMPUT SCI, V1, P1
   Wang C, 2019, AAAI CONF ARTIF INTE, P5232
   Wang L, 2020, IEEE ACCESS, V8, P63514, DOI 10.1109/ACCESS.2020.2982224
   Wang LG, 2020, IEEE T IMAGE PROCESS, V29, P4323, DOI 10.1109/TIP.2020.2967596
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xu N., 2018, ARXIV
   Xu R, 2019, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2019.00384
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang KD, 2022, PROC CVPR IEEE, P5972, DOI 10.1109/CVPR52688.2022.00589
   Zhang M, 2021, COMPUT MATH APPL, V102, P1, DOI 10.1016/j.camwa.2021.10.005
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang Y, 2021, COMPUT GRAPH FORUM, V40, P179, DOI 10.1111/cgf.142624
   Zhao WB, 2021, PROC CVPR IEEE, P16821, DOI 10.1109/CVPR46437.2021.01655
NR 50
TC 1
Z9 1
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10321
EP 10340
DI 10.1007/s11042-023-15457-z
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600008
DA 2024-07-18
ER

PT J
AU Liu, YH
   Li, XY
   Yu, HN
   Yang, L
AF Liu, Yanhong
   Li, Xingyu
   Yu, Hongnian
   Yang, Lei
TI A novel sEMG-based dynamic hand gesture recognition approach via
   residual attention network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand gesture recognition; Wearable sensor; Residual network; Feature
   attention; Feature fusion
ID FUSION
AB With the emergence of more andmore lightweight, convenient and cheap surface electromyography signal (sEMG) snsors, gesture recognition based on sEMG sensors has attracted much attention of researchers. In this study, combined with the sEMGsensor, a novel dynamic hand gesture recognition approach is proposed for effective and accurate dynamic gesture prediction. Here, a portable sEMG sensor (Myo wristband) is adopted to acquire the multi-channel sEMG signals of dynamic hand gestures and the continuous wavelet transformation (CWT) is proposed for data preprocessing to acquire the time-frequency maps. Due to the success of powerful contextual feature representation capability of deep convolutional neural networks (DCNNs), a deep residual attention network is proposed for accurate prediction of time-frequency maps. To effectively extract the key spatial and channel features from multi-channel sEMG signals, a residual attention network is proposed to act as the backbone network for effective feature representation. Besides, In the proposed recognition network, a multi-scale feature enhancement (MFE) module and an attention fusion block (AFB) are proposed, which respectively improve the multi-scale expression ability of the network and effectively realize multi-scale feature enhancement, respectively. Experimental results show that the proposed recognition network could achieve a superior detection ability compared with other state-of-the-art recognition models. The source code and dataset are available at https:// github.com/lyangucas92/ Ges_Net.
C1 [Liu, Yanhong; Li, Xingyu; Yu, Hongnian; Yang, Lei] Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou 450001, Henan, Peoples R China.
   [Liu, Yanhong; Li, Xingyu; Yang, Lei] Root Percept & Control Engn Lab, Zhengzhou 450001, Henan, Peoples R China.
   [Yu, Hongnian] Edinburgh Napier Univ, Built Environm, Edinburgh EH10 5DT, Scotland.
C3 Zhengzhou University; Edinburgh Napier University
RP Yang, L (corresponding author), Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou 450001, Henan, Peoples R China.; Yang, L (corresponding author), Root Percept & Control Engn Lab, Zhengzhou 450001, Henan, Peoples R China.
EM leiyang2019@zzu.edu.cn
RI Yang, Lei/K-8424-2018; Yu, Hongnian/JUV-0863-2023; Li,
   Xingyu/AHE-0001-2022
OI Yang, Lei/0000-0003-1212-9445; Li, Xingyu/0000-0002-5547-9894
FU National Key Research amp; Development Project of China
   [2020-YFB1313701]; National Natural Science Foundation of China
   [62003309]; Outstanding Foreign Scientist Support Project in Henan
   Province of China [GZS2019008]
FX This work was supported by the National Key Research & Development
   Project of China (2020-YFB1313701), the National Natural Science
   Foundation of China (No. 62003309) and Outstanding Foreign Scientist
   Support Project in Henan Province of China (No. GZS2019008).
CR Al-Timemy AH, 2016, IEEE T NEUR SYS REH, V24, P650, DOI 10.1109/TNSRE.2015.2445634
   Allard UC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2464, DOI 10.1109/IROS.2016.7759384
   Chen L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030672
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Côté-Allard U, 2017, IEEE SYS MAN CYBERN, P1663, DOI 10.1109/SMC.2017.8122854
   Dong YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3077967
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Duan F, 2021, IEEE T COGN DEV SYST, V13, P200, DOI 10.1109/TCDS.2018.2884942
   Fatimah B, 2021, BIOCYBERN BIOMED ENG, V41, P690, DOI 10.1016/j.bbe.2021.03.004
   Feng Q, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P1319, DOI 10.1109/MEC.2013.6885271
   Gao Q, 2021, IEEE SENSORS J
   Ghotbabadi A.R., 2012, INT C MANAGEMENT PRO, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jiang S, 2020, SENSOR ACTUAT A-PHYS, V301, DOI 10.1016/j.sna.2019.111738
   Joseph K. J., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5826, DOI 10.1109/CVPR46437.2021.00577
   Kang P, 2021, IEEE J BIOMED HEALTH
   Khodabandelou G, 2021, IEEE T AUTOM SCI ENG, V18, P495, DOI 10.1109/TASE.2020.3030852
   Lee S, 2010, IEEE T AUTOM SCI ENG, V7, P817, DOI 10.1109/TASE.2009.2035708
   Liu K, 2014, IEEE SENS J, V14, P1898, DOI 10.1109/JSEN.2014.2306094
   Liu MK, 2020, IEEE SENS J, V20, P14703, DOI 10.1109/JSEN.2020.3011825
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Mehta S., 2021, ARXIV
   Nahid Nazmun., 2020, 2020 JOINT 9 INT C I, P1
   Panella M, 2019, IEEE CONSUM ELECTR M, V8, P25, DOI 10.1109/MCE.2018.2868109
   Phinyomark A, 2018, IEEE ENG MED BIO, P5236, DOI 10.1109/EMBC.2018.8513427
   Phinyomark A, 2012, EXPERT SYST APPL, V39, P7420, DOI 10.1016/j.eswa.2012.01.102
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Qureshi SA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083715
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   RIOUL O, 1992, IEEE T INFORM THEORY, V38, P569, DOI 10.1109/18.119724
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song W, 2019, IEEE T BIOMED CIRC S, V13, P1563, DOI 10.1109/TBCAS.2019.2953998
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan M., 2020, PROC IEEECVF C COMPU, p10 781
   Wei WT, 2019, IEEE T BIO-MED ENG, V66, P2964, DOI 10.1109/TBME.2019.2899222
   Wen RS, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102592
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang YK, 2021, IEEE T COGN DEV SYST, V13, P141, DOI 10.1109/TCDS.2020.2969297
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Yu F., 2015, ARXIV
   Yuan G, 2021, IEEE SENS J, V21, P539, DOI 10.1109/JSEN.2020.3014276
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
NR 49
TC 0
Z9 0
U1 7
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9329
EP 9349
DI 10.1007/s11042-023-15748-5
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700005
DA 2024-07-18
ER

PT J
AU Chang, YJ
   Tsai, KL
   Jiang, WC
   Liu, MK
AF Chang, Yen-Jen
   Tsai, Kun-Lin
   Jiang, Wei-Cheng
   Liu, Meng-Kun
TI Content-aware malicious webpage detection using convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content awareness; Convolutional neural network (CNN); Malicious
   webpages; Webpage contextual visualization
AB Malicious websites often install malware on user devices to gather user information or to disrupt device operations, violate user privacy, or adversely affect company interests. Many commercial tools are available to prevent malicious webpages from accessing devices; however, current versions of these tools may become useless as soon as a new generation of malware is released. In this study, a content-aware malicious webpage detection (CAMD) method was developed; this CAMD method can verify whether a webpage is malicious by applying a novel webpage contextual visualization process, which retrieves the critical codes of webpages, transforms those codes into one-dimensional grayscale images, and applies convolutional neural networks to detect any malicious webpages. To verify the feasibility of proposed CAMD, 50000 normal and 50000 malicious webpages from the VirusTotal website were used. The results indicated that the proposed CAMD achieved an accuracy of > 98%.
C1 [Chang, Yen-Jen; Liu, Meng-Kun] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung, Taiwan.
   [Tsai, Kun-Lin; Jiang, Wei-Cheng] Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
C3 National Chung Hsing University; Tunghai University
RP Jiang, WC (corresponding author), Tunghai Univ, Dept Elect Engn, Taichung, Taiwan.
EM ychang@cs.nchu.edu.tw; kltsai@thu.edu.tw; enjoysea0605@gmail.com;
   whichild@gmail.com
RI Chang, Yen-Jen/AAE-9101-2020; Liu, Mengkun/B-3241-2019
OI Jiang, Wei-Cheng/0000-0003-4432-8801
FU National Science and Technology Council, Taiwan [MOST
   110-2634-F-005-006-, 110-2221-E-029-027-]
FX Detailed information of all authors' receives research support is
   listing as: This study was funded by the National Science and Technology
   Council, Taiwan, under Grant MOST 110-2634-F-005-006- and
   110-2221-E-029-027-. No other author has reported a potential conflict
   of interest relevant to this article.
CR Abdi F.D., 2017, INT J COMPUT SCI ENG, V7, P1, DOI 10.5121/ijcseit.2017.7601
   Aleroud A, 2017, COMPUT SECUR, V68, P160, DOI 10.1016/j.cose.2017.04.006
   [Anonymous], 2010, P 19 INT C WORLD WID
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Bakkouri I, 2019, MULTIMED TOOLS APPL, V78, P12939, DOI 10.1007/s11042-018-6267-z
   Canali D, 2011, P 20 INT C WORLD WID, P197, DOI DOI 10.1145/1963405.1963436
   Chiba D, 2012, 2012 IEEE/IPSJ 12TH INTERNATIONAL SYMPOSIUM ON APPLICATIONS AND THE INTERNET (SAINT), P29, DOI 10.1109/SAINT.2012.14
   Cui QM, 2022, IEEE SYST J, V16, P5831, DOI 10.1109/JSYST.2021.3134820
   Dos Santos C., 2014, Coling, P69
   Fukushima Y, 2011, IEEE INT CONF TRUST, P352, DOI 10.1109/TrustCom.2011.46
   Goldberg Y., 2014, ARXIV
   Heartfield R, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2835375
   Huang Lin-Shung., 2012, USENIX Security Symposium, P413
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu D, 2020, IEEE ACCESS, V8, P97258, DOI 10.1109/ACCESS.2020.2995157
   Manan WNW, 2020, IOP C SERIES MAT SCI, V769
   Oh I, 2022, IEEE T GAMES, V14, P212, DOI 10.1109/TG.2021.3049539
   Patil D.R., 2015, International Journal of u- and e-Service, Science and Technology, V8, P195, DOI DOI 10.14257/IJUNESST.2015.8.5.18
   Peng TR, 2018, IEEE INT C SEMANT CO, P300, DOI 10.1109/ICSC.2018.00056
   Purkait S., 2012, Phishing counter measures
   Sahoo D., 2017, ARXIV, P170107179
   Saxe J, 2017, ARXIV
   Saxe J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P8, DOI 10.1109/SPW.2018.00010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha S, 2008, MALWARE 2008: Proceedings of the 2008 3rd International Conference on Malicious and Unwanted Software, P65, DOI 10.1109/MALWARE.2008.4690858
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Total V, 2019, VIRUS TOTAL
   Verma R, 2018, 2018 RESILIENCE WEEK (RWS), P88, DOI 10.1109/RWEEK.2018.8473509
   Yan XD, 2020, IEEE T IND INFORM, V16, P6673, DOI 10.1109/TII.2020.2977886
   Yang WC, 2019, IEEE ACCESS, V7, P29891, DOI 10.1109/ACCESS.2019.2895751
   Zhang X, 2015, ADV NEUR IN, V28
NR 36
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8145
EP 8163
DI 10.1007/s11042-023-15559-8
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010465000005
DA 2024-07-18
ER

PT J
AU Raoof, I
   Gupta, MK
AF Raoof, Ifrah
   Gupta, Manoj Kumar
TI Domain-independent short-term calibration based hybrid approach for
   motor imagery electroencephalograph classification: a comprehensive
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Brain computer interface; Generative adversarial networks; Deep
   learning; Transfer learning; Electroencephalography; Computer vision;
   Machine learning; Artificial intelligence
ID BRAIN-COMPUTER-INTERFACE; BCI COMPETITION 2003; COMMON SPATIAL-PATTERNS;
   EEG CLASSIFICATION; DATA AUGMENTATION; PERFORMANCE; POTENTIALS;
   MOVEMENT; NETWORKS
AB Small availability of electroencephalograph (EEG) data makes the training of Brain-Computer Interface (BCI) significantly a difficult task. Recently, Deep Learning (DL) has shown tremendous performance in all domains but it requires an abundant amount of data for the training. Another challenging task is the non-stationary nature of EEG data. In this study, we illustrate a roadmap of various adversarial networks, review Transfer Learning (TL) methods, and give insights on the development route to generate and classify motor imagery (MI) EEG data. To make the use of BCI more practical, a Comprehensive review of Generative Adversarial Networks (GANs) and TL was performed to address the following questions: (1) Why GANs, rather than expansion on traditional data augmentation technique? (2) What input formulations have been used for generating brain signal data using GANs? (3) Are there particular GANs suitable for EEG data? (4) How can we solve the problem of data scarcity and the non-stationary nature of EEG? Comprehensive literature on data augmentation using GANs and feature transferring using advanced TL has been performed. The studies were examined based on different GAN architectures, various input formulations of EEG data, and different advanced TL techniques. For MI EEG data augmentation, signal input formulation is classified into five types and advanced TL techniques into seven types. For all these categories, the previous work from a technical point of view is discussed. Towards the end of the paper, a novelistic hybrid approach based on data augmentation and TL has been put forward for classifying MI EEG data with a short-term calibration process. To the best of our knowledge, no review article has completely discussed the various variants of GANs for augmenting brain signals. This review article will help the researchers in the deployment of BCI in future research.
C1 [Raoof, Ifrah; Gupta, Manoj Kumar] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Raoof, I (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra, Jammu & Kashmir, India.
EM 19dcs002@smvdu.ac.in
RI Arjmandmanesh, Saba/AGA-7907-2022
CR Abdelfattah SM, 2018, IEEE IJCNN
   Abdellaoui IA, 2020, ARXIV
   Ajagbe S, 2021, INT J ADV COMPUT RES, V11, P51, DOI [10.19101/IJACR.2021.1152001, DOI 10.19101/IJACR.2021.1152001, 10.3390/electronics12030676]
   Ajagbe SA, 2022, 2022 INT C ELECT COM, P1, DOI [10.1109/ICECET55527.2022.9872568, DOI 10.1109/ICECET55527.2022.9872568]
   Al-Saegh A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102172
   Albuquerque I, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.549524
   Ali O, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07992-w
   [Anonymous], 2018, WELCOME NFB LABS DOC
   [Anonymous], 2006, INRIA SOPHIA ANTIPOL
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2007, OPENVIBE SOFTWARE BR
   [Anonymous], 2012, ARXIV12064660
   [Anonymous], 1997, PSYCHTOOLBOX 3 OVERV
   [Anonymous], 2010, P 27 INT C MACH LEAR, DOI DOI 10.1145/2505515.2505603
   [Anonymous], 2014, Psychology Software Tools
   [Anonymous], 2009, POLITECNICO
   [Anonymous], 2001, PYTHON COMMUNITY BCI
   [Anonymous], 2009, Journal of the Vision Society of Japan, DOI DOI 10.24636/VISION.21.1_19
   Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x
   2010, TOBI TOOLS BRAIN COM
   Azab AM, 2019, INT CONF ACOUST SPEE, P3897, DOI 10.1109/ICASSP.2019.8682689
   Aznan NKN, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852227
   Bablani A, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3297713
   Bak S, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121486
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   2008, PYFF
   2009, US
   Bhat S, 2021, THE 14TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2021, P453, DOI 10.1145/3453892.3461338
   Blanchard G, 2004, IEEE T BIO-MED ENG, V51, P1062, DOI 10.1109/TBME.2004.826691
   Blankertz B, 2004, IEEE T BIO-MED ENG, V51, P1044, DOI 10.1109/TBME.2004.826692
   Blankertz B, 2007, NEUROIMAGE, V37, P539, DOI 10.1016/j.neuroimage.2007.01.051
   Blankertz B, 2006, IEEE T NEUR SYS REH, V14, P153, DOI 10.1109/TNSRE.2006.875642
   Bostanov V, 2004, IEEE T BIO-MED ENG, V51, P1057, DOI 10.1109/TBME.2004.826702
   Bouché M, 2020, BIOCONJUGATE CHEM, V31, P303, DOI 10.1021/acs.bioconjchem.9b00669
   Bousseta R, 2018, IRBM, V39, P129, DOI 10.1016/j.irbm.2018.02.001
   Brunner C., 2012, Bci software platforms, P303, DOI [10.1007/978-3-642-29746-5_16, DOI 10.1007/978-3-642-29746-5_16]
   Caceres CA, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00041
   Cantillo-Negrete J, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1624637
   Cao L, 2021, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.629572
   Chiang KJ, 2019, I IEEE EMBS C NEUR E, P424, DOI [10.1109/ner.2019.8716958, 10.1109/NER.2019.8716958]
   Dai MX, 2019, IEEE ACCESS, V7, P49951, DOI 10.1109/ACCESS.2019.2908851
   Das Chakladar D, 2018, BIOL INSPIR COGN ARC, V25, P88, DOI 10.1016/j.bica.2018.06.001
   Delijorge J, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.589659
   Delorme A, 2007, NEUROIMAGE, V34, P1443, DOI 10.1016/j.neuroimage.2006.11.004
   Devlaminck D, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/217987
   Duan LL, 2020, IEEE T NEUR SYS REH, V28, P2411, DOI 10.1109/TNSRE.2020.3027004
   Duan T., 2021, P CAN C ART INT, DOI [10.21428/594757db.6bc1ca44, DOI 10.21428/594757DB.6BC1CA44]
   Fahimi Fahimi F. F., 2019 IEEE EMBS International Conference on Biomedical Health Informatics (BHI), P1, DOI DOI 10.1109/BHI.2019.8834503
   Fahimi F, 2021, IEEE T NEUR NET LEAR, V32, P4039, DOI 10.1109/TNNLS.2020.3016666
   Fahimi F, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/aaf3f6
   Fernández-Rodríguez A, 2016, J NEURAL ENG, V13, DOI 10.1088/1741-2560/13/6/061001
   Feuz KD, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629528
   Freer D, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab57c0
   Ganin Y, 2017, ADV COMPUT VIS PATT, P189, DOI 10.1007/978-3-319-58347-1_10
   García-Salinas JS, 2019, BIOMED SIGNAL PROCES, V50, P151, DOI 10.1016/j.bspc.2019.01.006
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grosse-Wentrup M, 2008, IEEE T BIO-MED ENG, V55, P1991, DOI 10.1109/TBME.2008.921154
   Gui J., 2020, REV GENERATIVE ADVER, V14, P1
   Gupta A, 2020, NEUROCOMPUTING, V417, P558, DOI 10.1016/j.neucom.2020.07.050
   Hajinoroozi M, 2016, SIGNAL PROCESS-IMAGE, V47, P549, DOI 10.1016/j.image.2016.05.018
   Hartmann KG, 2018, ARXIV
   He H, 2020, IEEE T NEUR SYS REH, V28, P1091, DOI 10.1109/TNSRE.2020.2980299
   Ho S, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103066
   Hoffman J., 2018, Int. Conf. Mach. Learn., V5, P3162
   Hoffmann U, 2008, J NEUROSCI METH, V167, P115, DOI 10.1016/j.jneumeth.2007.03.005
   Hong Y, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3301282
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hwang S, 2019, INT WINT WORKSH BR, P141, DOI 10.1109/iww-bci.2019.8737322
   Imani M, 2019, J NETW COMPUT APPL, V147, DOI 10.1016/j.jnca.2019.102423
   Islam Jyoti, 2020, Brain Inform, V7, P3, DOI 10.1186/s40708-020-00104-2
   Janapati Ravichander, 2020, IOP Conference Series: Materials Science and Engineering, V981, DOI 10.1088/1757-899X/981/3/032019
   Jeon E, 2019, INT WINT WORKSH BR, P134, DOI 10.1109/iww-bci.2019.8737340
   Jeong JH, 2020, IEEE ACCESS, V8, P66941, DOI 10.1109/ACCESS.2020.2983182
   Ji Z, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105847
   Kaiser V, 2011, FRONT NEUROSCI-SWITZ, V5, DOI [10.3389/fnins.2011.00086, 10.3389/fninf.2011.00030]
   Kandaswamy Chetak, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P265, DOI 10.1007/978-3-319-11179-7_34
   Kaya M, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.211
   Khalaf A, 2020, BIOMED ENG ONLINE, V19, DOI 10.1186/s12938-020-00765-4
   Ko W, 2019, INT WINT WORKSH BR, P167, DOI 10.1109/iww-bci.2019.8737345
   Kothe CA, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/5/056014
   Kovács B, 2020, ECOL APPL, V30, DOI 10.1002/eap.2043
   Kumar P, 2017, J NETW COMPUT APPL, V89, P62, DOI 10.1016/j.jnca.2017.02.011
   Kwak NS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0172578
   2008, PSYKINEMATIX VISUAL
   Latifi S., 2019, International Journal of Computer Applications, V182, P27, DOI [https://doi.org/10.5120/ijca2019918334, DOI 10.5120/IJCA2019918334]
   Lebal A, 2023, MULTIMED TOOLS APPL, V82, P17391, DOI 10.1007/s11042-022-13947-0
   Lee J, 2020, IEEE J BIOMED HEALTH, V24, P1265, DOI 10.1109/JBHI.2019.2936583
   Lee T, 2020, I WINT C BRAIN-COMP, P112, DOI 10.1109/bci48061.2020.9061656
   Li JP, 2020, IEEE T COGN DEV SYST, V12, P344, DOI 10.1109/TCDS.2019.2949306
   Li JH, 2013, INT J NEURAL SYST, V23, DOI 10.1142/S0129065713500135
   Li MA, 2020, IEEE ACCESS, V8, P3197, DOI 10.1109/ACCESS.2019.2962740
   Liang Y, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102101
   Lioi G, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0498-3
   Liu BC, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00627
   Liu H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1333, DOI 10.1109/ICASSP.2018.8462061
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   López-Larraz E, 2018, NEUROREHABILITATION, V43, P77, DOI 10.3233/NRE-172394
   McCartney B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214342
   Memmott T, 2021, BRAIN-COMPUT INTERFA, V8, P137, DOI 10.1080/2326263X.2021.1878727
   Mensh BD, 2004, IEEE T BIO-MED ENG, V51, P1052, DOI 10.1109/TBME.2004.827081
   MEYERSON E, 2018, ARXIV180304062
   Ming YR, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105689
   Mozafari AS, 2016, PATTERN RECOGN, V56, P142, DOI 10.1016/j.patcog.2016.03.009
   Nagasawa T, 2020, J NEURAL ENG, V17, DOI 10.1088/1741-2552/ab6cb9
   Naik A, 2018, SPRINGERBRIEF COMPUT, P75, DOI 10.1007/978-3-030-01620-3_5
   Navidan H, 2021, COMPUT NETW, V194, DOI 10.1016/j.comnet.2021.108149
   2002, HOME PSYCHOPY V3 0
   Odena A, 2017, PR MACH LEARN RES, V70
   Ortega P, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00919
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panneerselvam IR, 2022, MULTIMED TOOLS APPL, V81, P17547, DOI 10.1007/s11042-022-12597-6
   Panwar S, 2019, IEEE SYS MAN CYBERN, P1304, DOI 10.1109/SMC.2019.8914492
   Parvan M, 2019, IRAN CONF ELECTR ENG, P1825, DOI [10.1109/IranianCEE.2019.8786636, 10.1109/iraniancee.2019.8786636]
   Pei Y, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.645952
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   Rashid M, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00025
   Rathee D, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00899-7
   Reed S, 2016, PR MACH LEARN RES, V48
   Reingold et al. at Ottawa,Ontario, 2004, EXPT BUILDER EYE TRA
   Richard L, 2009, TUTOR QUANT METHODS, V5, P68, DOI 10.20982/tqmp.05.2.p068
   Roy S, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206942
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   Rupp K, 2017, NEUROIMAGE, V148, P318, DOI 10.1016/j.neuroimage.2016.12.074
   Saha S, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.578875
   Sahlan F., 2021, International Journal on Perceptive and Cognitive Computing, V7, P85
   Sajda P, 2003, IEEE T NEUR SYS REH, V11, P184, DOI 10.1109/TNSRE.2003.814453
   Sakanas A., 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8086362
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Schalk G, 2004, IEEE T BIO-MED ENG, V51, P1034, DOI 10.1109/TBME.2004.827072
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   Schlögl A, 2005, J NEURAL ENG, V2, pL14, DOI 10.1088/1741-2560/2/4/L02
   Shell Jethro, 2012, Ambient Intelligence. Third International Joint Conference (AML 2012). Proceedings, P145, DOI 10.1007/978-3-642-34898-3_10
   Shen J, 2018, AAAI CONF ARTIF INTE, P4058
   Shin J, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.3
   Shin J, 2017, IEEE T NEUR SYS REH, V25, P1735, DOI 10.1109/TNSRE.2016.2628057
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Signals E, 2019, NO JASPER 1958, P1
   Simoes M, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.568104
   Smetanin N, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00100
   Song Y, 2023, CRIT REV ANAL CHEM, V53, P69, DOI 10.1080/10408347.2021.1936446
   Stropahl M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00309
   Subasi A, 2010, EXPERT SYST APPL, V37, P8659, DOI 10.1016/j.eswa.2010.06.065
   2006, NITRC BCILAB TOOL RE
   Tang XL, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113285
   Tang XL, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010096
   Tangermann M, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00055
   Tiwari N, 2018, BIOL INSPIR COGN ARC, V26, P118, DOI 10.1016/j.bica.2018.10.005
   Tzeng E., ADVERSARIAL DISCRIMI
   Varona J, 2008, J NETW COMPUT APPL, V31, P357, DOI 10.1016/j.jnca.2008.03.003
   Vidaurre C, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/935364
   von Lühmann A, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.579353
   Wakeman DG, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.1
   Wang XQ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122529
   Wei W, 2020, IEEE ENG MED BIO, P2963, DOI [10.1109/embc44109.2020.9175581, 10.1109/EMBC44109.2020.9175581]
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wickramaratne SD, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.659146
   Wu D, 2016, IEEE T NEUR SYS REH, V24, P1125, DOI 10.1109/TNSRE.2016.2544108
   Wu X, 2017, TSINGHUA SCI TECHNOL, V22, P660, DOI 10.23919/TST.2017.8195348
   Xia Y, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102037
   Xu FZ, 2021, IEEE T NEUR SYS REH, V29, P2417, DOI 10.1109/TNSRE.2021.3123969
   Yanagimoto M, 2016, 2016 IEEE 9TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P27, DOI 10.1109/IWCIA.2016.7805744
   Yang BH, 2019, IEEE ENG MED BIO, P774, DOI [10.1109/embc.2019.8857672, 10.1109/EMBC.2019.8857672]
   Yang BY, 2018, PATTERN RECOGN, V81, P615, DOI 10.1016/j.patcog.2018.04.027
   Yang J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041798
   Yang Q., 2009, P JOINT C 47 ANN M A, V1, P1
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   Yeh CI, 2009, J NEUROSCI, V29, P11753, DOI 10.1523/JNEUROSCI.1991-09.2009
   Yeom SK, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111157
   Yeung G, 2021, SPEECH COMMUN, V135, P1, DOI 10.1016/j.specom.2021.08.002
   Yin Z, 2017, BIOMED SIGNAL PROCES, V33, P30, DOI 10.1016/j.bspc.2016.11.013
   Yonggun Lee, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P182, DOI 10.1109/BHI.2018.8333399
   Zanini P, 2018, IEEE T BIO-MED ENG, V65, P1107, DOI 10.1109/TBME.2017.2742541
   Zhang K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164485
   Zhang Q, 2018, arXiv
   Zhang RK, 2022, J NEUROSCI METH, V376, DOI 10.1016/j.jneumeth.2022.109621
   Zhang X., 2015, ARXIV
   Zhang XF, 2019, INT CONF ACOUST SPEE, P2807, DOI [10.1109/icassp.2019.8683197, 10.1109/ICASSP.2019.8683197]
   Zhang XY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2069
   ZHANG XL, 1995, BRAIN RES BULL, V38, P531, DOI 10.1016/0361-9230(95)02023-5
   Zhao H., 2018, P ADV NEUR INF PROC, V31, P8568
   Zheng L, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.579469
   Zheng XC, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/6056383
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
   Zihlmann M, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.070-060
NR 188
TC 0
Z9 0
U1 19
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9181
EP 9226
DI 10.1007/s11042-023-15900-1
EA JUN 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400010
DA 2024-07-18
ER

PT J
AU Lin, SF
   Zeng, C
   Yang, CG
AF Lin, Shifeng
   Zeng, Chao
   Yang, Chenguang
TI Robot grasping based on object shape approximation and LightGBM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grasp planning; Novel object grasping; Shape approximation; LightGBM
AB Object grasp planning is a challenging task. Recently, methods based on deep learning have made great progress in this area, but they are highly dependent on datasets, which means that they may encounter some difficulties when facing novel objects that are not available in the datasets. In this paper, a novel method is proposed to generate grasping candidate rectangles for object based on shape approximation, without datasets or shape priori of objects. Specifically, combining K-means and the minimum oriented bounding box algorithm for point sets, an adaptive K-means algorithm is applied for decomposing objects into multiple rectangles. The algorithm can independently select the number of K-means cores and automatically select the number of rectangles used to approximate the shape of the object. According to the parameters of each rectangle, a candidate grasping rectangle of the object is generated. In addition, using the Cornell grasping dataset, a LightGBM classifier is trained for the classification and evaluation of object candidate grasping rectangles. Experimental results show that our classification accuracy rate has reached 94.5% and the detection time is only 0.0003s. Among the candidate rectangles, the one with the highest score in the LightGBM model would be selected for real robot grasping. Finally, a multi-object grasping experiment conducted on a real robot platform shows that our algorithm can help the robot grasp new objects with an average success rate of 91.81%.
C1 [Lin, Shifeng; Yang, Chenguang] South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Minist Educ, Guangzhou 510640, Peoples R China.
   [Lin, Shifeng; Yang, Chenguang] South China Univ Technol, Coll Automat Sci & Engn, GuangDong Engn Technol Res Ctr Control Intelligent, Guangzhou 510640, Peoples R China.
   [Zeng, Chao] Univ Hamburg, Dept Informat, TAMS Grp, D-22527 Hamburg, Germany.
C3 South China University of Technology; South China University of
   Technology; University of Hamburg
RP Yang, CG (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Minist Educ, Guangzhou 510640, Peoples R China.; Yang, CG (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, GuangDong Engn Technol Res Ctr Control Intelligent, Guangzhou 510640, Peoples R China.
EM cyang@ieee.org
OI Yang, Chenguang/0000-0001-5255-5559
FU National Nature Science Foundation of China (NSFC) [U20A20200,
   92148204]; Guangdong Basic and Applied Basic Research Foundation
   [2020B1515120054]; Industrial Key Technologies R & D Program of Foshan
   [2020001006308, 2020001006496]
FX National Nature Science Foundation of China (NSFC) under Grant U20A20200
   and Major Research Grant No. 92148204 , Guangdong Basic and Applied
   Basic Research Foundation under Grants 2020B1515120054 and Industrial
   Key Technologies R & D Program of Foshan under Grant 2020001006308 and
   Grant 2020001006496.
CR Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bonilla M, 2015, IEEE INT C INT ROBOT, P518, DOI 10.1109/IROS.2015.7353421
   Chauhan Sumika, 2021, 2021 International Conference on Intelligent Technologies (CONIT), DOI [10.1109/ICEPES52894.2021.9699655, 10.1109/CONIT51480.2021.9498358]
   Chauhan S, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P124, DOI [10.1109/icct46177.2019.8968779, 10.1109/ICCT46177.2019.8968779]
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chib PS, 2023, COMM COM INF SC, V1704, P261, DOI 10.1007/978-3-031-23599-3_19
   Ding XL, 2021, SCI CHINA TECHNOL SC, V64, P462, DOI 10.1007/s11431-020-1737-4
   DIZIOGLU B, 1984, ACTA MECH, V52, P107, DOI 10.1007/BF01175968
   Dong H., 2022, IEEE ASME T MECHATRO
   Du GG, 2021, ARTIF INTELL REV, V54, P1677, DOI 10.1007/s10462-020-09888-5
   Guo KL, 2022, IEEE T CONTR SYST T, V30, P2717, DOI 10.1109/TCST.2022.3145645
   Hang KY, 2017, IEEE ROBOT AUTOM LET, V2, P704, DOI 10.1109/LRA.2017.2651381
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Ke GL, 2017, ADV NEUR IN, V30
   Khari M, 2019, INT J INTERACT MULTI, V5, P22, DOI 10.9781/ijimai.2019.09.002
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Lin HF, 2019, INT J FUZZY SYST, V21, P1026, DOI 10.1007/s40815-018-00604-8
   Lin SF, 2022, IEEE ROBOT AUTOM LET, V7, P6526, DOI 10.1109/LRA.2022.3174261
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Morrison D, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Morrison D, 2020, INT J ROBOT RES, V39, P183, DOI 10.1177/0278364919859066
   Mousavian A, 2019, IEEE I CONF COMP VIS, P2901, DOI 10.1109/ICCV.2019.00299
   Pillai MS, 2021, SOFT COMPUT, V25, P11929, DOI 10.1007/s00500-021-05576-w
   PONCE J, 1993, INT J ROBOT RES, V12, P263, DOI 10.1177/027836499301200305
   Raj R, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103957
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Wu BX, 2022, IEEE-CAA J AUTOMATIC, V9, P510, DOI 10.1109/JAS.2021.1004243
   Yu Y, 2020, IEEE T SYST MAN CY-S
   Yun Jiang, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3304, DOI 10.1109/ICRA.2011.5980145
   Zhang H, 2019, IEEE Transactions on Systems, Man, and Cybernetics: Systems
   Zhang HB, 2019, IEEE INT C INT ROBOT, pCP1, DOI 10.1109/iros40897.2019.8967869
   Zhang JH, 2020, MULTIMED TOOLS APPL, V79, P2427, DOI 10.1007/s11042-019-08302-9
   Zhang JH, 2018, LECT NOTES ARTIF INT, V11357, P160, DOI 10.1007/978-3-030-05204-1_16
NR 33
TC 1
Z9 1
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 9103
EP 9119
DI 10.1007/s11042-023-15547-y
EA JUN 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001000907700010
DA 2024-07-18
ER

PT J
AU Srinivas, K
   Sri, RG
   Pravallika, K
   Nishitha, K
   Polamuri, SR
AF Srinivas, K.
   Sri, R. Gagana
   Pravallika, K.
   Nishitha, K.
   Polamuri, Subba Rao
TI COVID-19 prediction based on hybrid Inception V3 with VGG16 using chest
   X-ray images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Corona virus; COVID-19; Inception V3; VGG16; IV3-VGG; RT-PCR; ResNet50;
   DenseNet121; MobileNet; Chest X-ray
ID SARS-COV-2; DIAGNOSIS; ENSEMBLE
AB The Corona Virus was first started in the Wuhan city, China in December of 2019. It belongs to the Coronaviridae family, which can infect both animals and humans. The diagnosis of coronavirus disease-2019 (COVID-19) is typically detected by Serology, Genetic Real-Time reverse transcription-Polymerase Chain Reaction (RT-PCR), and Antigen testing. These testing methods have limitations like limited sensitivity, high cost, and long turn-around time. It is necessary to develop an automatic detection system for COVID-19 prediction. Chest X-ray is a lower-cost process in comparison to chest Computed tomography (CT). Deep learning is the best fruitful technique of machine learning, which provides useful investigation for learning and screening a large amount of chest X-ray images with COVID-19 and normal. There are many deep learning methods for prediction, but these methods have a few limitations like overfitting, misclassification, and false predictions for poor-quality chest X-rays. In order to overcome these limitations, the novel hybrid model called "Inception V3 with VGG16 (Visual Geometry Group)" is proposed for the prediction of COVID-19 using chest X-rays. It is a combination of two deep learning models, Inception V3 and VGG16 (IV3-VGG). To build the hybrid model, collected 243 images from the COVID-19 Radiography Database. Out of 243 X-rays, 121 are COVID-19 positive and 122 are normal images. The hybrid model is divided into two modules namely pre-processing and the IV3-VGG. In the dataset, some of the images with different sizes and different color intensities are identified and pre-processed. The second module i.e., IV3-VGG consists of four blocks. The first block is considered for VGG-16 and blocks 2 and 3 are considered for Inception V3 networks and final block 4 consists of four layers namely Avg pooling, dropout, fully connected, and Softmax layers. The experimental results show that the IV3-VGG model achieves the highest accuracy of 98% compared to the existing five prominent deep learning models such as Inception V3, VGG16, ResNet50, DenseNet121, and MobileNet.
C1 [Srinivas, K.; Sri, R. Gagana; Nishitha, K.] VR Siddhartha Engn Coll, Dept CSE, Vijayawada 520007, India.
   [Pravallika, K.] Sir CR Reddy Engn Coll, Dept CSE, Eluru 534007, India.
   [Polamuri, Subba Rao] Bonam Venkata Chalamayya Engn Coll Autonomous, Dept CSE, Odalarevu 533210, India.
C3 Velagapudi Ramakrishna Siddhartha Engineering College
RP Polamuri, SR (corresponding author), Bonam Venkata Chalamayya Engn Coll Autonomous, Dept CSE, Odalarevu 533210, India.
EM kudipudi72@gmail.com; gagana.rachamalla@gmail.com;
   kudipudipravallika@gmail.com; nishithakommineni0204@gmail.com;
   psr.subbu546@gmail.com
RI Kudipudi, Srinivas/JBR-9171-2023
OI Kudipudi, Srinivas/0000-0003-4714-1380; Srinivas, Dr.
   Pattlola/0000-0002-5723-396X
CR Adhikari SP, 2020, INFECT DIS POVERTY, V9, DOI 10.1186/s40249-020-00646-x
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi JA, 2023, ARAB J SCI ENG, V48, P11003, DOI 10.1007/s13369-021-05810-5
   ALzubi JA, 2019, APPL SOFT COMPUT, V80, P579, DOI 10.1016/j.asoc.2019.04.031
   Asif S., 2020, MEDRXIV
   Bonifazi Gianluca., 2022, INT J INFORM TECHNOL, V2022, P1
   Dai LP, 2020, CELL, V182, P722, DOI 10.1016/j.cell.2020.06.035
   Ehsan S, 2019, COMPUT TOMOGR, P470
   Govindarajan S, 2021, APPL INTELL, V51, P2764, DOI 10.1007/s10489-020-01941-8
   Hu B, 2015, VIROL J, V12, DOI 10.1186/s12985-015-0422-1
   Hussain E, 2021, CHAOS SOLITON FRACT, V142, DOI 10.1016/j.chaos.2020.110495
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Mahdy L. N., 2020, medRxiv
   Mangal A, 2020, Arxiv, DOI arXiv:2004.09803
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Pan YB, 2020, J INFECTION, V81, pE28, DOI 10.1016/j.jinf.2020.03.051
   Porte L, 2020, INT J INFECT DIS, V99, P328, DOI 10.1016/j.ijid.2020.05.098
   Punn NS, 2021, APPL INTELL, V51, P2689, DOI 10.1007/s10489-020-01900-3
   Rahman, 2022, COVID 19 RADIOGRAPHY
   Sastre P, 2011, CLIN VACCINE IMMUNOL, V18, P113, DOI 10.1128/CVI.00355-10
   Spicuzza L, 2020, J INFECTION, V81, pE53, DOI 10.1016/j.jinf.2020.04.022
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thejeshwar SS, 2020, MEDRXIV
   Togaçar M, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103805
   Wang LY, 2014, EMERG INFECT DIS, V20, P1227, DOI 10.3201/eid2007.140296
   Wang YS, 2020, J MED VIROL, V92, P538, DOI 10.1002/jmv.25721
   Watanabe S, 2010, EMERG INFECT DIS, V16, P1217, DOI 10.3201/eid1608.100208
   Worldmeter, 2022, COVID-19 coronavirus pandemic
   Yan YX, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17072323
   Yasar H, 2021, APPL INTELL, V51, P2740, DOI 10.1007/s10489-020-02019-1
NR 32
TC 6
Z9 6
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 5
PY 2023
DI 10.1007/s11042-023-15903-y
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2CE9
UT WOS:001000907700002
PM 37362699
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Cheggoju, N
   Satpute, V
AF Cheggoju, Naveen
   Satpute, Vishal
TI BlinQS: Blind quality scalable image compression algorithm without using
   PCRD optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Blind quality scalability (BlinQS); Image compression; Rate-distortion
   optimization; JPEG-2000 standard
ID EFFICIENT RATE CONTROL; JPEG2000
AB Quality Scalability is one of the important features of interactive imaging to obtain better perceptual quality at a specified target bit rate. In JPEG 2000, it is achieved using quality layers obtained by Rate-Distortion (R-D) optimization techniques in Tier-II coding. Some important concerns here are: (i) inefficient conventional Post-Compression Rate-Distortion (PCRD) optimization algorithms, (ii) lack of quality scalability for less or single quality layer string. This paper takes the above mentioned concerns into account and proposes a Blind Quality Scalable (BlinQS) algorithm that provides scalability with the least computational complexity. The novel part of this method is to eliminate the Tier-II coding and add a blind string selection i.e., transcoding algorithm through a normal distribution function for efficient rate control. The results obtained suggest that the proposed method achieves better results than JPEG-2000 at single quality layer and achieves results close to JPEG-2000 without using PCRD optimization algorithms.
C1 [Cheggoju, Naveen] Indian Inst Informat Technol, Sch Electro, Dept Elect & Commun Engn, Haroli 177209, Himachal Prades, India.
   [Satpute, Vishal] Visvesvaraya Natl Inst Technol, Elect & Commun Engn, Nagpur 440010, Maharashtra, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Cheggoju, N (corresponding author), Indian Inst Informat Technol, Sch Electro, Dept Elect & Commun Engn, Haroli 177209, Himachal Prades, India.
EM naveen.c@iiitu.ac.in; vrsatpute@ece.vnit.ac.in
RI Cheggoju, Naveen/L-3006-2019; SATPUTE, VISHAL RAMESH/AAA-7713-2022
OI Cheggoju, Naveen/0000-0002-4734-9344; SATPUTE, VISHAL
   RAMESH/0000-0001-9944-9489
CR Aminlou A, 2005, INT CONF ACOUST SPEE, P21
   Aminlou A, 2006, IEEE IMAGE PROC, P2493, DOI 10.1109/ICIP.2006.312799
   Aulí-Linàs F, 2007, IEEE SIGNAL PROC LET, V14, P251, DOI 10.1109/LSP.2006.884900
   Auli-llinas F, 2007, MODEL BASED JPEG2000
   Aulí-Llinàs F, 2008, IEEE T CIRC SYST VID, V18, P923, DOI 10.1109/TCSVT.2008.920748
   Aulí-Llinàs F, 2006, IEEE DATA COMPR CONF, P282
   Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Auli-Llinas F, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/803542
   Aulí-Llinàs F, 2009, IEEE T IMAGE PROCESS, V18, P1772, DOI 10.1109/TIP.2009.2022209
   Bi CY, 2017, IEEE T IMAGE PROCESS, V26, P3594, DOI 10.1109/TIP.2017.2700765
   Boliek M., 2002, JPEG 2000 IMAGE CODI
   Bruni V, 2020, J COMPUT APPL MATH, V367, DOI 10.1016/j.cam.2019.112467
   Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P3612, DOI 10.1109/TIP.2020.2963956
   Chebil F, 2006, PROC SPIE, V6077, DOI 10.1117/12.643368
   Choi H, 2022, IEEE T IMAGE PROCESS, V31, P2739, DOI 10.1109/TIP.2022.3160602
   Chung R, 2019, PICTORIAL COLOR REFE
   Du WN, 2004, IEEE T CONSUM ELECTR, V50, P1218, DOI 10.1109/TCE.2004.1362522
   Edwards T., 2021, SMPTE Mot. Imag. J, V130, P22, DOI [10.5594/jmi.2021.3066183, DOI 10.5594/JMI.2021.3066183]
   Etesaminia A, 2017, J CENT SOUTH UNIV, V24, P1396, DOI 10.1007/s11771-017-3544-3
   Gaubatz MD, 2007, IEEE T IMAGE PROCESS, V16, P649, DOI 10.1109/TIP.2006.888355
   Hu Y, 2020, 2020 IEEE INT C MULT, P1
   Kanchi, 2011, SPIHT SET PART HIER
   Kim SH, 2021, IEEE ACCESS, V9, P119418, DOI 10.1109/ACCESS.2021.3108449
   Kim T, 2005, IEEE T CIRC SYST VID, V15, P181, DOI 10.1109/TCSVT.2004.839970
   Mei Yixin, 2021, IEEE Transactions on Multimedia
   Naman AA, 2019, IEEE IMAGE PROC, P1084, DOI 10.1109/ICIP.2019.8803729
   Naman AT, 2020, IEEE IMAGE PROC, P1171, DOI 10.1109/ICIP40778.2020.9190899
   Naman AT, 2018, COMPUT NETW, V134, P152, DOI 10.1016/j.comnet.2018.01.043
   openjpeg, 2019, OFF REP OP PROJ OP V
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Parisot C, 2002, SIGN PROC C 2002 11, P1
   Rajput A, 2022, INT J DISTRIB SENS N, V18, DOI 10.1177/15501329221083168
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHAPIRO JM, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P486, DOI 10.1109/ACSSC.1993.342561
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Su RG, 2020, IEEE IMAGE PROC, P3369, DOI 10.1109/ICIP40778.2020.9190704
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Taubman D, 2000, ABOUT US
   Taubman DS, 2002, P IEEE, V90, P1336, DOI 10.1109/JPROC.2002.800725
   Taubman DS., 2018, SMPTE MOTION IMAG J, V127, P1, DOI [10.5594/JMI.2018.2859120, DOI 10.5594/JMI.2018.2859120]
   Tu HY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4044, DOI 10.1145/3474085.3475533
   University S, 2015, SCIEN TEST IM VID
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe Osamu, 2019, 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), P491, DOI 10.1109/GCCE46687.2019.9015602
   Yan N, 2021, IEEE T IMAGE PROCESS, V30, P8939, DOI 10.1109/TIP.2021.3121131
   Yeung YM, 2005, IEEE T CIRC SYST VID, V15, P335, DOI 10.1109/TCSVT.2004.842605
   Yu W, 2006, IEEE T CIRC SYST VID, V16, P577, DOI 10.1109/TCSVT.2006.873161
   Zhang YZ, 2006, IEEE IMAGE PROC, P2465, DOI 10.1109/ICIP.2006.312776
NR 50
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 31
PY 2023
DI 10.1007/s11042-023-15454-2
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H9TW0
UT WOS:000999312400008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kamil, S
   Abdullah, SNHS
   Hasan, MK
   Alomari, YM
   Alyasseri, Z
AF Kamil, Samar
   Abdullah, Siti Norul Huda Sheikh
   Hasan, Mohammad Kamrul
   Alomari, Yazan M.
   Alyasseri, Zaid
TI Binary nonogram puzzle based data hiding technique for data security
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Data Security; Steganography; Least Significant Bit; Nonogram Puzzle;
   Binary Nonogram Puzzle
ID IMAGE STEGANOGRAPHY; LIGHTWEIGHT; INTERNET
AB Data security is one of the critical challenges for digital information. The existing steganography algorithms hide confidential data in the cover media to preserve the presence of hidden data. One type of steganography algorithm is a puzzle-based algorithm such as sudoku, magic cube, and basic nonogram puzzle. These puzzles depend on an auxiliary reference matrix for communication with the receiver. However, using a reference matrix is prone to a statistical histogram attack because image data hiding pixels are fixed. The challenging task here is to design a secured secret data technique that hides the secret data bits in the cover using a suitable puzzle without communicating the reference matrix with the receiver. This paper proposes a new Binary Nonogram Puzzle (BNP) technique. The BNP is based on two elements: searching the BNP indexes based on LSB of the cover pixel and hiding the secret data in random pixel based on the index information. The first row and column for each block are considered an index for the remaining block elements used for data hiding. We also identify the position to hide the secret data that calculates vertical and horizontal summation to indicate a suitable index with the specified rule. The effectiveness of the BNP was tested on the standard dataset images (USC-SIPI image database) and evaluated using Peak signal-to-noise ratio (PSNR) and Mean Square Error (MSE). The results showed that BNP achieves high PSNR and low MSE compared to the existing puzzles (Magic Cube and Basic Nonogram puzzle) and guarantees a better stego image quality.
C1 [Kamil, Samar; Abdullah, Siti Norul Huda Sheikh; Hasan, Mohammad Kamrul] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43600, Selangor, Malaysia.
   [Kamil, Samar] Middle Tech Univ, Tech Coll Management, Dept Business Adm Tech, Baghdad 10047, Iraq.
   [Alomari, Yazan M.] Imam Abdulrahman bin Faisal Univ, Coll Appl Studies & Community Serv, Dammam, Saudi Arabia.
   [Alyasseri, Zaid] Univ Kufa, Informat Technol Res & Dev Ctr ITRDC, Kufa 54001, Najaf, Iraq.
C3 Universiti Kebangsaan Malaysia; Middle Technical University; Imam
   Abdulrahman Bin Faisal University; University of Kufa
RP Hasan, MK (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Ctr Cyber Secur, Bangi 43600, Selangor, Malaysia.
EM hasankamrul@ieee.org
RI Alyasseri, Zaid Abdi Alkareem/H-5280-2013
OI Alyasseri, Zaid Abdi Alkareem/0000-0003-4228-9298; Hasan, Dr. Mohammad
   Kamrul/0000-0001-5511-0205
CR Alhaddad MJ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12122071
   Alyousuf Din, 2020, Bulletin of Electrical Engineering and Informatics, V9, P573
   Bharathi DA., 2017, INT J ADV RES IDEAS, V3, P693
   Butun I, 2020, IEEE COMMUN SURV TUT, V22, P616, DOI 10.1109/COMST.2019.2953364
   California US, 1977, USC SIPI IMAGE DATAB
   Evsutin O, 2020, IEEE ACCESS, V8, P166589, DOI 10.1109/ACCESS.2020.3022779
   Hasan MK, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5540296
   Hasan MK, 2021, IEEE ACCESS, V9, P47731, DOI 10.1109/ACCESS.2021.3061710
   Hashim Mohammed Mahdi, 2018, Journal of Theoretical and Applied Information Technology, V96, P956
   Hsiao TC, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13030387
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jana S, 2019, INNOV SYST SOFTW ENG, V15, P65, DOI 10.1007/s11334-019-00324-8
   Jansi KR, 2020, ADV INTELL SYST COMP, V1056, P701, DOI 10.1007/978-981-15-0199-9_60
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Kamil S, 2018, INT J ADV COMPUT SC, V9, P256
   Kieu D, 2009, Int. J. Smart Home, V3, P1
   Lee CF, 2020, IEEE ACCESS, V8, P39445, DOI 10.1109/ACCESS.2020.2975385
   Liu YX, 2022, IEEE INTERNET THINGS, V9, P298, DOI 10.1109/JIOT.2021.3099028
   Liu YX, 2021, IEEE INTERNET THINGS, V8, P17227, DOI 10.1109/JIOT.2021.3078407
   Lv ZH, 2021, IEEE INTERNET THINGS, V8, P9531, DOI 10.1109/JIOT.2020.3007130
   Lyu W, 2018, RELIABLE DATA HIDING, DOI [10.2991/ncce-18.2018.133, DOI 10.2991/NCCE-18.2018.133]
   Lyu W., 2018, INT C NETW COMMUN CO, V147, P805, DOI [10.2991/ncce-18.2018.133, DOI 10.2991/NCCE-18.2018.133]
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Mohamed M. H., 2016, Appl. Math. Inf. Sci., V10, P259, DOI [10.18576/amis/100126, DOI 10.18576/AMIS/100126]
   Premamayudu B., 2011, INT J TECHNOL ENGIN, V2, P133
   Rahman S, 2020, CMC-COMPUT MATER CON, V64, P31, DOI 10.32604/cmc.2020.09186
   Shalu, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2019), P286, DOI 10.1109/iss1.2019.8908097
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Solak S, 2020, IEEE ACCESS, V8, P166513, DOI 10.1109/ACCESS.2020.3023197
   Song Houbing, SECURITY PRIVACY CYB
   Su WK, 2021, IEEE T CIRC SYST VID, V31, P1001, DOI 10.1109/TCSVT.2020.3001122
   Sushma RB, 2019, 2019 INT C DATA SCI, P19, DOI [10.1109/IconDSC.2019.8816945, DOI 10.1109/ICONDSC.2019.8816945]
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Vidya G., 2014, INDIAN J SCI TECHNOL, V7, P1403, DOI 10.17485/ijst/2014/v7i9.13
   Wazirali R, 2019, IEEE ACCESS, V7, P133496, DOI 10.1109/ACCESS.2019.2941440
   Wei W, 2019, MULTIMED TOOLS APPL, V78, P27109, DOI 10.1007/s11042-017-5083-1
   Weng SW, 2019, IEEE ACCESS, V7, P34570, DOI 10.1109/ACCESS.2019.2904174
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
NR 39
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15618-0
EA MAY 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4ZS6
UT WOS:000996068400001
DA 2024-07-18
ER

PT J
AU Vignesh, R
   Prasad, KM
AF Vignesh, R.
   Prasad, K. Mohana
TI Blockchain assisted AHMFA authentication in employee performance
   assessment system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Decentralized network; Elliptic curve cryptography; Optimal key
   selection; Quantum blockchain; Adaptive hash multi-factor
   authentication; Enhanced Diffie-Hellman
ID CHALLENGES; UTILITY
AB The concept of blockchain has attained more attention recently to promote secured encryption and decryption, especially in industrial explorations and research institutions. The secured authentication process is highly required in intelligent governance focusing on effective decision-making, common entity participation and openness. By this, resource usage, energy consumption and cost-efficiency can be greatly reduced. A Smart governance system is highly needed to observe and assess government workers' performance. As most systems are centralized, trust is lagging and prone to single-point failure issues. Also, employers or hackers tend to obtain data to favour individual workers. In most existing research works, the security is not maintained properly because of ineffective data handling and high latency. A decentralized system that promotes accountability, trust, transparency, tamper-resistance, security and reliability is required to overcome the existing issues. Hence, a novel Blockchain Assisted Decentralized Employee Performance Assessment (BDEPA) System is proposed in this research. Initially, the employee information like username or password is registered. During the encryption process, the keys are generated using Elliptic curve cryptography (ECC), whereas the optimal keys are chosen using an improved water wave's optimization (IWWO) algorithm. By this, higher security can be promoted among the users for secured encryption, whereas the data can be highly protected from third parties. The data are stored in a Quantum blockchain (QBC) to minimize energy costs and improve security. When accessing the data, employee authenticity is verified using the Adaptive hash multi-factor authentication (AHMFA) approach to avoid data loss, theft, and malicious attacks. In the data retrieval or decryption phase, Enhanced Diffie-Hellman (EDH) algorithm is used to secure data access. Performances like energy costs, delay, processing time, successful authentication, etc.; are analyzed through the implementation of the proposed work in PYTHON.
C1 [Vignesh, R.] Sathyabama Inst Sci & Technol Chennai, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
   [Prasad, K. Mohana] Sathyabama Inst Sci & Technol Chennai, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Vignesh, R (corresponding author), Sathyabama Inst Sci & Technol Chennai, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
EM vignesh.cse@sathyabama.ac.in
RI Vignesh, R/AIC-4276-2022; vignesh, R/ITV-9615-2023
OI Vignesh, R/0000-0002-1355-7276; vignesh, R/0000-0002-1355-7276
CR Ali O, 2020, GOV INFORM Q, V37, DOI 10.1016/j.giq.2019.101419
   Andoni M, 2019, RENEW SUST ENERG REV, V100, P143, DOI 10.1016/j.rser.2018.10.014
   Bankar J, 2017, 2017 INT C COMPUTING, P1
   Chow MC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124525
   Góes ASD, 2020, IEEE ACCESS, V8, P39403, DOI 10.1109/ACCESS.2020.2975485
   Dewi N, 2020, 2020 14 INT C TELECO, P1
   Esposito C, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102468
   Hamilton RH, 2020, BUS HORIZONS, V63, P85, DOI 10.1016/j.bushor.2019.10.001
   He J., 2021, INT J NETWORK SECURI, V23, P776
   Khliefat A, 2020, INT J HOSP MANAG, V86
   Kibok B, 2019, J BUS RES, V104
   Li JX, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102382
   Liang KT, 2015, COMPUT J, V58, P2778, DOI 10.1093/comjnl/bxv050
   Libert B, 2008, LECT NOTES COMPUT SC, V4939, P360, DOI 10.1007/978-3-540-78440-1_21
   Lin JCW, 2021, IEEE INTERNET THINGS, V8, P5340, DOI 10.1109/JIOT.2020.3032896
   Lin JCW, 2018, INT CONF DAT MIN WOR, P1459, DOI 10.1109/ICDMW.2018.00208
   Lin JCW, 2016, ENG APPL ARTIF INTEL, V55, P269, DOI 10.1016/j.engappai.2016.07.003
   Liu TE, 2020, IEEE INTERNET THINGS, V7, P7928, DOI 10.1109/JIOT.2020.2990428
   Luo HB, 2018, AUTOMAT CONSTR, V94, P282, DOI 10.1016/j.autcon.2018.06.007
   Mingquan L, 2021, MICROPROCESS MICROSY, V83
   Mohammed IA, 2021, MATER TODAY-PROC
   Nasiri E, 2023, MULTIMED TOOLS APPL, V82, P3745, DOI 10.1007/s11042-022-12943-8
   Niu J, 2020, IEEE INTERNET THINGS, V7, P1502, DOI 10.1109/JIOT.2019.2956322
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Shabbir M, 2021, IEEE ACCESS, V9, P8820, DOI 10.1109/ACCESS.2021.3049564
   Sifah EB, 2020, IEEE ACCESS, V8, P99528, DOI 10.1109/ACCESS.2020.2997650
   Singh AK, 2021, J APPL SEC RES, P1
   Stephen TTT, 2020, INT J HOSP MANAG, V88
   Suthanthiramani P, 2021, INT ARAB J INF TECHN, V18, P56, DOI 10.34028/iajit/18/1/7
   Velmurugadass P, 2021, MATER TODAY-PROC, V37, P2653, DOI 10.1016/j.matpr.2020.08.519
   Venkatraman S, 2022, SYSTEMS-BASEL, V10, DOI 10.3390/systems10020039
   Vinoth Kumar K., 2020, International Journal of Intelligent Networks (Elsevier-KeAi), V1, P36
   Wang JT, 2021, J SYST ARCHITECT, V114, DOI 10.1016/j.sysarc.2020.101910
   Wang XQ, 2020, IEEE ACCESS, V8, P11732, DOI 10.1109/ACCESS.2019.2961169
   Wei F, 2019, FUTURE GENER COMP SY, V95
   Wu JMT, 2022, IEEE TETCI, V6, P16, DOI 10.1109/TETCI.2020.3032701
   Yang XH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110812
   Zeng P, 2018, IEEE ACCESS, V6, P70017, DOI 10.1109/ACCESS.2018.2879479
   Zhang C, 2021, IEEE INTERNET THINGS, V8, P6624, DOI 10.1109/JIOT.2021.3051295
   Ma ZF, 2021, IEEE INTERNET THINGS, V8, P2116, DOI 10.1109/JIOT.2020.3037733
   Zheng H, 2020, PEER PEER NETW APPL, V13, P1643, DOI 10.1007/s12083-020-00918-1
NR 41
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15846-4
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700011
DA 2024-07-18
ER

PT J
AU Gopal, GY
   Amer, M
AF Gopal, Goutam Yelluru
   Amer, Maria
TI Reliable interconnected channels for dynamic DCF based visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object tracking; Correlation filtering; Channel reliability; Temporal
   consistency; Adaptive channel weights
ID OBJECT TRACKING
AB In Discriminative Correlation Filter (DCF) based trackers, individual channel responses are aggregated to compute the overall DCF response during target localization. Due to the effect of various external factors, several non-discriminative or unreliable channels display ambiguous filter responses. The reliability-based methods mitigate this problem by computing channel weights based on estimated scores from filter responses. However, this approach is prone to false suppression of discriminative channels due to noisy reliability scores. In this paper, we address this problem by proposing a three-fold objective function that accounts for the relationship between channels along with per-channel reliability scores during channel weight learning and a temporal prior. In addition, our paper presents an algorithm to compute channel weights efficiently and maintain the tracking speed. We show that our channel adaptation method can be seamlessly integrated into a multi-channel DCF-based tracking framework. Results on OTB2015, TC128, and VOT2018 datasets show that the proposed method improves the performance of baseline DCF trackers; for example, our dca-ECO is on average 12.7% better than ECO and outperforms related channel-adaptive Convolutional Neural Network-based trackers CGRCF, ACSDCF, and GFSDCF by 17.1% in terms of failure rate, also the recent trackers E.T.Track and FEAR by 4% and 19.1%, respectively.
C1 [Gopal, Goutam Yelluru; Amer, Maria] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Gopal, GY (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ, Canada.
EM g_yellur@encs.concordia.ca
OI Yelluru Gopal, Goutam/0000-0002-4508-6202
FU Concordia University
FX For the submitted work, the authors did not receive funds, grants, or
   support from any organization other than Concordia University
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   An XW, 2021, MULTIMED TOOLS APPL, V80, P14041, DOI 10.1007/s11042-020-10345-2
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Blatter Philippe, 2023, 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), P1571, DOI 10.1109/WACV56688.2023.00162
   Borsuk V, 2022, P EUR C COMP VIS, P644
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Che MQ, 2019, LECT NOTES COMPUT SC, V11129, P70, DOI 10.1007/978-3-030-11009-3_3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Du F, 2020, IEEE T CIRC SYST VID, V30, P1625, DOI 10.1109/TCSVT.2019.2909654
   Fang S, 2021, MULTIMED TOOLS APPL, V80, P23963, DOI 10.1007/s11042-021-10804-4
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Ge SM, 2020, IEEE T IMAGE PROCESS, V29, P2610, DOI 10.1109/TIP.2019.2950508
   Gopal GY, 2020, INT CONF ACOUST SPEE, P5700, DOI [10.1109/ICASSP40776.2020.9053333, 10.1109/icassp40776.2020.9053333]
   Grant Michael., Matlab software for disciplined convex programming, version 2.0 beta
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jain M, 2022, IEEE T CIRC SYST VID, V32, P715, DOI 10.1109/TCSVT.2021.3063144
   Javed S, 2023, IEEE T PATTERN ANAL, V45, P6552, DOI [10.1109/IECON49645.2022.9969084, 10.1109/TPAMI.2022.3212594]
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laue S, 2022, AAAI CONF ARTIF INTE, P7300
   Lee SI., 2006, AAAI, P401
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu C, 2020, IEEE T CIRC SYST VID, V30, P3153, DOI 10.1109/TCSVT.2019.2938038
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Pang YH, 2020, MULTIMED TOOLS APPL, V79, P27229, DOI 10.1007/s11042-020-09267-w
   Paszke A, 2019, ADV NEUR IN, V32
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2021, INT J COMPUT VISION, V129, P1359, DOI 10.1007/s11263-021-01435-1
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Yan B, 2021, PROC CVPR IEEE, P15175, DOI 10.1109/CVPR46437.2021.01493
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 44
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15235-x
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400004
DA 2024-07-18
ER

PT J
AU Qin, XY
   Li, LS
   Pang, GY
AF Qin, Xueyang
   Li, Lishuang
   Pang, Guangyao
TI Multi-scale motivated neural network for image-text matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image-text matching; Multi-scale information; Cross-modal interaction;
   Matching score fusion algorithm
ID ATTENTION
AB Existing mainstream image-text matching methods usually measure the relevance of image-text pairs by capturing and aggregating the affinities between textual words and visual regions, while failing to consider the single-scale matching bias caused by the imbalance of image and text information. In this paper, we design a Multi-Scale Motivated Neural Network (MSMNN) model for image-text matching. In contrast to previous single-scale methods, MSMNN encourages neural networks to extract visual and textual features from three scales, including local features, global features and salient features, which can take full advantage of the complementarity of multi-scale matching to reduce the bias of single-scale matching. Also, we propose a cross-modal interaction module to realize the fusion of visual and textual features in local alignment, so as to discover the potential relationship between image-text pairs. Furthermore, we also propose a matching score fusion algorithm to fuse matching results from three different levels, which can be freely applied to other initial image-text matching results with a negligible overhead. Extensive experiments validate the effectiveness of our method, and the performance has achieved fairly competitive results on two well-known datasets, Flickr30K and MSCOCO, with a boost of 1.04% and 0.59% on evaluation metric mR compared with the advanced method.
C1 [Qin, Xueyang; Li, Lishuang] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
   [Pang, Guangyao] Wuzhou Univ, Sch Data Sci & Software Engn, Wuzhou 543002, Peoples R China.
C3 Dalian University of Technology; Wuzhou University
RP Li, LS (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
EM qinxueyang@snnu.edu.cn; lils@dlut.edu.cn; pangguangyao@gmail.com
RI Li, Kexin/KAO-2519-2024; Wang, Ling/AGR-4917-2022; JIANG,
   Peng/KGL-3427-2024; Wang, Ling/KBA-9814-2024; Qin, Xueyang/HTO-5087-2023
OI Wang, Ling/0000-0003-0272-2974; Wang, Ling/0000-0003-0272-2974; 
FU National Natural Science Foundation of China [62076048]; Science and
   Technology Innovation Foundation of Dalian [2020JJ26GX035]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China [grant number 62076048]; and the Science and
   Technology Innovation Foundation of Dalian [grant number 2020JJ26GX035].
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Andrew G., 2013, ICML, P1247
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng YH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3499027
   Cui Z, 2022, MULTIMED TOOLS APPL, V81, P23615, DOI 10.1007/s11042-022-12444-8
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Diao HW, 2021, AAAI CONF ARTIF INTE, V35, P1218
   Gan Z, 2020, Arxiv, DOI arXiv:2006.06195
   Gao QX, 2020, AAAI CONF ARTIF INTE, V34, P3938
   Goodfellow I., 2014, PROC NEURIPS, P2672, DOI DOI 10.1145/3422622
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang FR, 2019, IEEE T IMAGE PROCESS, V28, P2008, DOI 10.1109/TIP.2018.2882225
   Huang Y, 2018, PROC CVPR IEEE, P6163, DOI 10.1109/CVPR.2018.00645
   Huang ZC, 2021, PROC CVPR IEEE, P12971, DOI 10.1109/CVPR46437.2021.01278
   Ji Z, 2021, P 31TH INTRNATIONAL
   Kang PP, 2022, APPL INTELL, V52, P33, DOI 10.1007/s10489-021-02308-3
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lee KH, 2018, LECT NOTES COMPUT SC, V11208, P212, DOI 10.1007/978-3-030-01225-0_13
   Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336
   Li WH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102432
   Li XP, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108455
   Liu C., 2020, P IEEE CVF C COMP VI, P10921, DOI DOI 10.1109/CVPR42600.2020.01093
   Liu CX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P3, DOI 10.1145/3343031.3350869
   Liu H, 2021, IEEE T IMAGE PROCESS, V30, P2450, DOI 10.1109/TIP.2021.3051476
   Liu JW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P665, DOI 10.1145/3343031.3350991
   Liu Y, 2019, PATTERN RECOGN, V93, P365, DOI 10.1016/j.patcog.2019.05.008
   Lu D., 2019, arXiv
   Ma L, 2019, NEUROCOMPUTING, V345, P36, DOI 10.1016/j.neucom.2018.11.089
   Ma L, 2015, IEEE I CONF COMP VIS, P2623, DOI 10.1109/ICCV.2015.301
   Qi JW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P892
   Qian K, 2021, NEURAL COMPUT APPL, V33, P11889, DOI 10.1007/s00521-021-05894-y
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Shaw P., 2018, P 2018 NAACL, V2, P464, DOI [DOI 10.18653/V1/N18-2074, 10.18653/v1/N18-2074]
   Shi BT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5182
   Shu X, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107905
   Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]
   Vaswani A, 2017, P 31 C ADV NEUR INF, ppp5998
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang H, 2020, P 16 EUR C COMP VIS, ppp18
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang SH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1398, DOI 10.1145/3240508.3240535
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3792
   Wu H, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3470850
   Wu YL, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2088, DOI 10.1145/3343031.3350940
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yan F, 2015, P IEEE C COMP VIS PA, ppp3441
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yuan H, 2021, INT C PATT RECOG, P3728, DOI 10.1109/ICPR48806.2021.9413223
   Zhang K, 2022, IEEE T MULTIMED, P1
   Zhang Q, 2020, P IEEE C COMP VIS PA, ppp3536
   Zhang S, 2021, INFORM FUSION, V73, P1, DOI 10.1016/j.inffus.2021.02.022
   Zhang YF, 2021, IEEE T IMAGE PROCESS, V30, P617, DOI 10.1109/TIP.2020.3038354
NR 59
TC 0
Z9 0
U1 8
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15321-0
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CT7
UT WOS:000994103300002
DA 2024-07-18
ER

PT J
AU Tsai, TH
   Wang, RZ
   Tung, NC
AF Tsai, Tsung-Han
   Wang, Rui-Zhi
   Tung, Nai-Chieh
TI Hardware architecture design for real-time SIFT extraction with reduced
   memory usage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Real-time; Key-point; Object recognition; Gaussian pyramid; Low memory
   VLSI design
ID SCALE; FEATURES
AB Scale-invariant feature transform (SIFT) is considered one of the best algorithms to get feature points in an image. It maintains the accuracy in results even in image scaling, rotation, deformation, and light changes. However, memory requirements are the bottleneck to achieving real-time performance as SIFT has high computation complexity. Therefore, this paper has proposed the improved hardware architecture of the scale-invariant feature transform (SIFT) algorithm. The Gaussian pyramid is constructed using parallel operations instead of the original cascade operation to reduce memory requirements. Coordinate Rotation Digital Computer (CORDIC) has been adapted to perform trigonometric operations to reduce computational complexity. The ASIC design has been implemented using TSMC 90 nm technology. The system can achieve the performance of 35.6 FPS for an image resolution of 1280 x 720 while using only 237.4 Kbit of memory.
C1 [Tsai, Tsung-Han; Wang, Rui-Zhi; Tung, Nai-Chieh] Natl Cent Univ, Dept Elect Engn, Taoyuan, Taiwan.
C3 National Central University
RP Tsai, TH (corresponding author), Natl Cent Univ, Dept Elect Engn, Taoyuan, Taiwan.
EM han@ee.ncu.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST 1112221-E-008-089-MY3]
FX This work was supported by the Ministry of Science and Technology,
   Taiwan, under Grant MOST 111-2221-E-008-089-MY3.
CR Acharya KA, 2018, J REAL-TIME IMAGE PR, V14, P267, DOI 10.1007/s11554-014-0446-6
   Alhwarin F., 2008, BCS INT AC C VIS COM, P179
   [Anonymous], 2011, INT J SMART HOME
   Azad P, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4275, DOI 10.1109/IROS.2009.5354611
   Banu VC, 2017, INT SYM DES TECH ELE, P208, DOI 10.1109/SIITME.2017.8259891
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bonato V, 2008, IEEE T CIRC SYST VID, V18, P1703, DOI 10.1109/TCSVT.2008.2004936
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chiu LC, 2013, IEEE T IMAGE PROCESS, V22, P3158, DOI 10.1109/TIP.2013.2259841
   Digital Circuits/CORDIC, 2009, WIKIPEDIA FREE E
   Doménech-Asensi G, 2020, J REAL-TIME IMAGE PR, V17, P371, DOI 10.1007/s11554-018-0781-0
   Flitton Greg, 2010, BMVC, DOI [DOI 10.5244/C.24.11, 10.5244/C.24.11]
   Fritz G, 2005, LECT NOTES COMPUT SC, V3540, P629
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Huang FC, 2012, IEEE T CIRC SYST VID, V22, P340, DOI 10.1109/TCSVT.2011.2162760
   Huang MY, 2014, IEEE T CIRCUITS-I, V61, P613, DOI 10.1109/TCSI.2013.2284189
   Jain AK, 2009, IEEE IMAGE PROC, P2745, DOI 10.1109/ICIP.2009.5414140
   Jiang J, 2014, IEEE T CIRC SYST VID, V24, P1209, DOI 10.1109/TCSVT.2014.2302535
   Karami E, 2017, Arxiv, DOI [arXiv:1710.02726, 10.48550/arXiv.1710.02726, DOI 10.48550/ARXIV.1710.02726]
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kreowsky P, 2021, IEEE ACCESS, V9, P128564, DOI 10.1109/ACCESS.2021.3104387
   Kuffner A, 2006, ACM INT C P SER, VSer56, P29
   Kwon Y, 2021, 2021 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), DOI 10.1109/ICEIC51217.2021.9369740
   Li Sanchez HA, 2021, 2021 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT), P115, DOI 10.1109/ICFPT52863.2021.9609932
   Li SA, 2018, IEEE ACCESS, V6, P43850, DOI 10.1109/ACCESS.2018.2863019
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu BQ, 2022, IEEE T CIRCUITS-I, V69, P4930, DOI 10.1109/TCSI.2022.3199475
   Liu Jinxia, 2011, Proceedings of the 2011 IEEE 10th International Conference on Electronic Measurement & Instruments (ICEMI 2011), P177, DOI 10.1109/ICEMI.2011.6037882
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Ouyang P, 2018, IEEE T CIRCUITS-I, V65, P3362, DOI 10.1109/TCSI.2018.2806447
   Qasaimeh M, 2019, ANALOG INTEGR CIRC S, V99, P325, DOI 10.1007/s10470-019-01419-9
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Suzuki T, 2012, P 2012 AS PAC SIGN I, P1
   Vourvoulakis J, 2017, PROCEEDINGS OF THE 2017 9TH IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS (IDAACS), VOL 1, P95, DOI 10.1109/IDAACS.2017.8095057
   Vourvoulakis J, 2016, MICROPROCESS MICROSY, V40, P53, DOI 10.1016/j.micpro.2015.11.013
   Wang N, 2010, PROCEEDINGS OF THE 2ND (2010) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P320
   Yi-Ming Lin, 2010, 2010 International Symposium on Next-Generation Electronics (ISNE 2010), P48, DOI 10.1109/ISNE.2010.5669202
   Yum J, 2018, IEEE T CIRC SYST VID, V28, P3251, DOI 10.1109/TCSVT.2017.2740175
   Yum J, 2016, IEEE T CIRC SYST VID, V26, P1943, DOI 10.1109/TCSVT.2015.2489458
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zhu Daixian, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P415, DOI 10.1109/IASP.2010.5476084
NR 45
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15789-w
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900007
DA 2024-07-18
ER

PT J
AU Singh, AK
   Kumar, A
   Kumar, V
   Prakash, S
AF Singh, Anil Kumar
   Kumar, Ankit
   Kumar, Vinay
   Prakash, Shiv
TI COVID-19 Detection using adopted convolutional neural networks and
   high-performance computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chest radiography pictures; Computed tomography (CT) scan Covid-19; CNN;
   Polymerase chain response; ResNet50; ResNet101
ID BIOMOLECULE CORONA
AB The COVID 19 pandemic is highly contagious disease is wreaking havoc on people's health and well-being around the world. Radiological imaging with chest radiography is one among the key screening procedure. This disease contaminates the respiratory system and impacts the alveoli, which are small air sacs in the lungs. Several artificial intelligence (AI)-based method to detect COVID-19 have been introduced. The recognition of disease patients using features and variation in chest radiography images was demonstrated using this model. In proposed paper presents a model, a deep convolutional neural network (CNN) with ResNet50 configuration, that really is freely-available and accessible to the common people for detecting this infection from chest radiography scans. The introduced model is capable of recognizing coronavirus diseases from CT scan images that identifies the real time condition of covid-19 patients. Furthermore, the database is capable of tracking detected patients and maintaining their database for increasing accuracy of the training model. The proposed model gives approximately 97% accuracy in determining the above-mentioned results related to covid-19 disease by employing the combination of adopted-CNN and ResNet50 algorithms.
C1 [Singh, Anil Kumar] Dr APJ Abdul Kalam Tech Univ, Pranveer Singh Inst Technol, Dept Comp Sci & Engn, Lucknow, India.
   [Prakash, Shiv] Univ Allahabad, Dept Elect & Commun, Prayagraj, Uttar Pradesh, India.
   [Kumar, Ankit] Dr APJ Abdul Kalam Tech Univ, Pranveer Singh Inst Technol, Lucknow, India.
   [Kumar, Vinay] Dr APJ Abdul Kalam Tech Univ, Lucknow, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); University of
   Allahabad; Dr. A.P.J. Abdul Kalam Technical University (AKTU); Dr.
   A.P.J. Abdul Kalam Technical University (AKTU)
RP Prakash, S (corresponding author), Univ Allahabad, Dept Elect & Commun, Prayagraj, Uttar Pradesh, India.
EM anilsinghrkg@gmail.com; 7667ankit@gmail.com; vinay.bncet@gmail.com;
   shivprakash@allduniv.ac.in
RI Kumar, Vinay/JAC-0865-2023; Singh, Anil/JUU-2219-2023
OI Kumar, Vinay/0000-0001-7125-505X; kumar, Ankit/0000-0002-2059-5545;
   Singh, Anil Kumar/0000-0001-6889-1186
CR Al-Hazmi A, 2016, SAUDI J BIOL SCI, V23, P507, DOI 10.1016/j.sjbs.2016.02.019
   Al-Osail AM, 2017, MULTIDISCIP RESP MED, V12, DOI 10.1186/s40248-017-0101-8
   Albahli S, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107645
   alodokter.com, 2020, VIR COR
   [Anonymous], 2020, WELLNESS HEAL MAG, V2, P187
   [Anonymous], FREEL AV DAT SET
   Burhanuddin CI, 2020, AKMEN ANCAMAN KRISIS
   Calderon-Ramirez S, 2021, IEEE ACCESS, V9, P85442, DOI 10.1109/ACCESS.2021.3085418
   Das AK, 2021, PATTERN ANAL APPL, V24, P1111, DOI 10.1007/s10044-021-00970-4
   Docter D, 2015, CHEM SOC REV, V44, P6094, DOI 10.1039/c5cs00217f
   Ezzat K, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10192-2
   Gunawan C, 2014, J MATER CHEM B, V2, P2060, DOI 10.1039/c3tb21526a
   Hadjidemetriou M, 2015, ACS NANO, V9, P8142, DOI 10.1021/acsnano.5b03300
   Kumar D, 2020, EURASIAN J MED ONCOL, V4, P8, DOI 10.14744/ejmo.2020.51418
   Monopoli MP, 2011, J AM CHEM SOC, V133, P2525, DOI 10.1021/ja107583h
   Pane CD, 2020, VIRUS CORONA COVID 1
   Rahman M., 2013, PROTEIN NANOPARTICLE, P21
   Rehman A, 2021, IT PROF, V23, P63, DOI 10.1109/MITP.2020.3036820
   Vilanova O, 2016, ACS NANO, V10, P10842, DOI 10.1021/acsnano.6b04858
   Wang Y, 2019, CHONGQING MED
   Yang P, 2020, J INFECTION, V80, P684, DOI 10.1016/j.jinf.2020.02.024
   Yunus N. R., 2020, SALAM: Jurnal Sosial Dan Budaya Syar-i, V7, P227, DOI [https://doi.org/10.15408/sjsbs.v7i3.15083, DOI 10.15408/SJSBS.V7I3.15083]
NR 22
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15640-2
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400002
PM 37362712
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Su, GD
   Chang, CC
   Lin, CC
AF Su, Guo-Dong
   Chang, Chin-Chen
   Lin, Chia-Chen
TI An effective compressed image authentication scheme based on
   <i>N</i>-variant AMBTC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image authentication; Variant AMBTC; N-variant AMBTC; Accuracy; Image
   quality
ID TAMPER-DETECTION SCHEME; PROTOCOL
AB Image authentication is one technique that provides integrity protection for digital images, making them sensitive to any slight modification. Recently, the detectability of absolute moment block truncation coding (AMBTC) compressed images has been attracting more attention due to its integrity authentication concerns. Thus, this paper proposes an effective N-variant AMBTC based image authentication scheme for AMBTC compressed images. First, a novel AMBTC compression code is derived using a variant AMBTC technique that can provide a better quality of compressed images. Then, each AMBTC compression code is further eliminated into a version requiring fewer bits using the proposed N-variant AMBTC technique, and those vacated N-bits are used to conceal authentication codes, which is generated by hashing the AMBTC compression code and location information. Experimental results confirm that the proposed scheme has superior stability and accuracy in tampering detection while providing better visual quality of the watermarked image.
C1 [Su, Guo-Dong] Fujian Polytech Normal Univ, Sch Big Data & Artificial Intelligence, Fuzhou 350300, Peoples R China.
   [Su, Guo-Dong; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
C3 Fujian Polytechnic Normal University; Feng Chia University; National
   Chin-Yi University of Technology
RP Lin, CC (corresponding author), Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 41170, Taiwan.
EM gdsu0206@gmail.com; alan3c@gmail.com; ally.cclin@ncut.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
FU National of Science and Technology Council, Taiwan [MOST
   110-2410-H-167-004]; National Natural Science Foundation of China
   [62272103]; Natural Science Foundation of Fujian Province [2020J01300,
   2022J01971, 2022J01974, 2022J01975]
FX AcknowledgementsThis work was supported in part by the National of
   Science and Technology Council, Taiwan, under MOST 110-2410-H-167-004,
   in party by the National Natural Science Foundation of China under Grant
   62272103, and in part by the Natural Science Foundation of Fujian
   Province under Grant Nos. 2020J01300, 2022J01971, 2022J01974 and
   2022J01975.
CR Chang CC, 2019, MATH BIOSCI ENG, V16, P3367, DOI 10.3934/mbe.2019168
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen CC, 2019, IEEE ACCESS, V7, P149515, DOI 10.1109/ACCESS.2019.2944833
   Chen TS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9202610
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P12979, DOI 10.1007/s11042-017-4927-z
   Cvitic I, 2021, INT J MACH LEARN CYB, V12, P3179, DOI 10.1007/s13042-020-01241-0
   Datta K, 2022, J KING SAUD UNIV-COM, V34, P5240, DOI 10.1016/j.jksuci.2022.05.013
   Hong W, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230997
   Hong W, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080318
   Hong W, 2018, MULTIMED TOOLS APPL, V77, P4677, DOI 10.1007/s11042-017-4899-z
   Horng MH, 2012, EXPERT SYST APPL, V39, P1078, DOI 10.1016/j.eswa.2011.07.108
   Hu YC, 2013, OPTO-ELECTRON REV, V21, P137, DOI 10.2478/s11772-013-0078-6
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Hui YC, 2013, INT J SECUR APPL, V7, P11
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li W, 2016, MULTIMED TOOLS APPL, V75, P4771, DOI 10.1007/s11042-015-2502-z
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin CC, 2014, KSII T INTERNET INF, V8, P4588, DOI 10.3837/tiis.2014.12.020
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mani N, 2021, INT J SOFTW SCI COMP, V13, P72, DOI 10.4018/IJSSCI.2021010105
   Nguyen TS, 2022, J INTERNET TECHNOL, V23, P255, DOI 10.53106/160792642022032302006
   Su GD., 2018, COMPUTER SYSTEMS APP, V27, P265
   Su GD, 2020, IEEE ACCESS, V8, P26984, DOI 10.1109/ACCESS.2020.2966234
   Su GD, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102618
   Su GD, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11080996
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Xu LJ, 2004, IEEE T INSTRUM MEAS, V53, P1539, DOI 10.1109/TIM.2004.834066
   Zhong H., 2016, J INFORM HIDING MULT, V7, P362
   Zhou ZL, 2022, IEEE INTERNET THINGS, V9, P9332, DOI 10.1109/JIOT.2021.3103779
NR 35
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15486-8
EA MAY 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MY7
UT WOS:000990968000004
DA 2024-07-18
ER

PT J
AU El-Fatyany, A
   Wang, HZ
   Khan, M
   El-atty, SMA
AF El-Fatyany, Aya
   Wang, Hongzhi
   Khan, Mehak
   El-atty, Saied M. Abd
TI Analytical framework for end-to-end channel capacity in molecular
   communication system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless body area network; Molecular communication; Nanonetwork;
   Reservoir nanodevices; Target drug delivery; Nanomachines
ID DRUG-DELIVERY; DIFFUSION; MODEL; POLYMERS
AB The molecular communication system (MCS) is mainly based on the design structure of the nanodevices which are employed as nano-transmitter (Nano-TX) and nano-receiver (Nano-RX), owing to the limited drug-reservoir capacity. The current work addresses the physical design of such nanodevices and the coordination of molecular communication to accomplish an end-to-end capacity system model, which can be employed in the targeted drug delivery system (TDDS). In MCS, Nano-RX is a spherical structure with a cylindrical shell with adapting receptors that enables an increase in the received number of drug molecules according to the transmission rate. On the other hand, the more realistic structure of Nano-TX is a cylindrical reservoir capable of controlling the emitted nanocarriers in the blood vessel. The analytical framework and the performance of the proposed MCS are presented by using a compartmental model while a closed-form expression of the proposed end-to-end channel capacity is obtained. The performance evaluation is evaluated by applying network performance metrics such as channel capacity, throughput, and efficiency. The simulation results show that the proposed model can enhance the delivery of the therapeutic dose and thus minimize the side effects on healthy cells compared with conventional schemes.
C1 [El-Fatyany, Aya; Wang, Hongzhi; Khan, Mehak] Harbin Inst Technol HIT, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [El-Fatyany, Aya] Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm, Egypt.
   [El-Fatyany, Aya] Zhejiang Univ, ZJU Hangzhou Global Sci & Technol Innovat Ctr, Hangzhou, Peoples R China.
   [El-atty, Saied M. Abd] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun Engn, Menoufia 32952, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University; Zhejiang University; Egyptian Knowledge Bank (EKB); Menofia
   University
RP El-Fatyany, A (corresponding author), Harbin Inst Technol HIT, Sch Comp Sci & Technol, Harbin, Peoples R China.; El-Fatyany, A (corresponding author), Menoufia Univ, Fac Sci, Dept Math, Shibin Al Kawm, Egypt.; El-Fatyany, A (corresponding author), Zhejiang Univ, ZJU Hangzhou Global Sci & Technol Innovat Ctr, Hangzhou, Peoples R China.
EM ayaelfatyany@hit.edu.cn; wangzh@hit.edu.cn; mehakkhan@hit.edu.cn;
   sabdelatty@el-eng.menofia.edu.eg
RI Abd El-atty, Saied/AAI-6029-2020; Elfatyany, Aya/A-4216-2019; Khan,
   Mehak/AAS-2369-2020; Khan, Mehak/HGB-4078-2022
OI Abd El-atty, Saied/0000-0003-0979-4292; Khan, Mehak/0000-0001-8959-6872;
   
CR Abd El-atty SM, 2018, IET NANOBIOTECHNOL, V12, P201, DOI 10.1049/iet-nbt.2016.0150
   Ahmadzadeh A, 2016, IEEE T NANOBIOSCI, V15, P713, DOI 10.1109/TNB.2016.2609600
   Akdeniz BC, 2021, IEEE T NANOBIOSCI, V20, P193, DOI 10.1109/TNB.2021.3062473
   Akkaya A, 2015, IEEE COMMUN LETT, V19, P155, DOI 10.1109/LCOMM.2014.2375214
   Chahibi Y, 2015, IEEE T BIO-MED ENG, V62, P1683, DOI 10.1109/TBME.2015.2400631
   Chahibi Y, 2013, IEEE T BIO-MED ENG, V60, P3468, DOI 10.1109/TBME.2013.2271503
   Chude-Okonkwo UAK, 2017, IEEE COMMUN SURV TUT, V19, P3046, DOI 10.1109/COMST.2017.2705740
   Chude-Okonkwo UAK, 2015, IEEE GLOBE WORK
   Chude-Okonkwo UAK, 2016, IEEE T COMMUN, V64, P3444, DOI 10.1109/TCOMM.2016.2582870
   Chude-Okonkwo UAK, 2014, IEEE GLOB COMM CONF, P2826, DOI 10.1109/GLOCOM.2014.7037236
   Dhillon S, 2006, CLINICALPHARMACOKINE
   El-Fatyany A, 2020, WIREL NETW, V26, P3701, DOI 10.1007/s11276-020-02294-3
   Farsad N, 2016, IEEE COMMUN SURV TUT, V18, P1887, DOI 10.1109/COMST.2016.2527741
   Felicetti L, 2019, IEEE ACCESS, V7, P5769, DOI 10.1109/ACCESS.2018.2889031
   Felicetti L, 2016, NANO COMMUN NETW, V7, P27, DOI 10.1016/j.nancom.2015.08.004
   Freiberg S, 2004, INT J PHARMACEUT, V282, P1, DOI 10.1016/j.ijpharm.2004.04.013
   Gandhi A, 2015, ASIAN J PHARM SCI, V10, P99, DOI 10.1016/j.ajps.2014.08.010
   Hossen S, 2019, J ADV RES, V15, P1, DOI 10.1016/j.jare.2018.06.005
   James HP, 2014, ACTA PHARM SIN B, V4, P120, DOI 10.1016/j.apsb.2014.02.005
   Korde JM, 2019, IND ENG CHEM RES, V58, P9709, DOI 10.1021/acs.iecr.9b00683
   Larson N, 2012, CHEM MATER, V24, P840, DOI 10.1021/cm2031569
   Liu Q, 2021, IEEE T NANOBIOSCI, V20, P416, DOI 10.1109/TNB.2021.3077297
   Mucchi L, 2019, IEEE ACCESS, V7, P110687, DOI 10.1109/ACCESS.2019.2932567
   Nakano T., 2012, 2012 IEEE Wireless Communications and Networking Conference (WCNC), P704, DOI 10.1109/WCNC.2012.6214461
   Nakano T, 2013, IEEE J SEL AREA COMM, V31, P835, DOI 10.1109/JSAC.2013.SUP2.12130016
   Pierobon M, 2013, IEEE T INFORM THEORY, V59, P942, DOI 10.1109/TIT.2012.2219496
   Pierobon M, 2010, IEEE J SEL AREA COMM, V28, P602, DOI 10.1109/JSAC.2010.100509
   Shi JJ, 2017, NAT REV CANCER, V17, P20, DOI 10.1038/nrc.2016.108
   Siepmann J, 2012, J CONTROL RELEASE, V161, P351, DOI 10.1016/j.jconrel.2011.10.006
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Torchilin V, 2009, EUR J PHARM BIOPHARM, V71, P431, DOI 10.1016/j.ejpb.2008.09.026
   Wicke W, 2018, IEEE WCNC
   Yang WW, 2012, JALA-J LAB AUTOM, V17, P50, DOI 10.1177/2211068211428189
   Zoofaghari M, 2021, IEEE WIREL COMMUN LE, V10, P2786, DOI 10.1109/LWC.2021.3117411
NR 34
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15715-0
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G7MZ8
UT WOS:000990969100001
DA 2024-07-18
ER

PT J
AU Saini, A
   Gill, NS
   Gulia, P
AF Saini, Ashish
   Gill, Nasib Singh
   Gulia, Preeti
TI Gray scale image denoising technique using regression based residual
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image de-noising; L0 smoothing; Salt and pepper noise; Gray scale image;
   Image quality improvement
AB In recent years the application of digital images has increased in a rapid manner, but due to noise the limited applications are currently openly adopting these applications. The noise can degrade the image quality and the application's quality of service too. However, in literature, there are a number of different kinds of noise available and to rectify different types of noise different image filtering techniques are also available. But most of the techniques are computationally expensive or less effective, less efficient, and not able to preserve the image features for higher levels of noise. Therefore, in this paper, we introduced an optimization technique for impulse noise removal and measured its effect on the different levels of noise in the image. The proposed filter detects and removes impulse noise from digital grey-scale images. Thus the algorithm first classifies the image pixels in terms of noisy and non-noisy pixels. Here the classification of pixels has been carried out using the regression analysis of the image vector. After locating the corrupted pixel the mean of self and neighbor pixels which are non-noisy (except pixel values 0 and 255) has been used to replace the noisy pixel. However, this technique is not completely removing the noise in a single step thus we eliminate the noise in an iterative manner. Additionally to deal with the blurring effect and to preserve the image edges we employ L0 smoothing. Finally, in the last step, we utilize the median filter for constructing the final output image. The simulation of the proposed algorithm has been carried out with MATLAB and with the help of a publically available dataset. The experiments have been carried out and performance is measured in terms of the visual quality histogram and PSNR (pick signal to noise ratio). The comparison with the relevant techniques demonstrates the effective denoising consequences of the proposed technique.
C1 [Saini, Ashish; Gill, Nasib Singh; Gulia, Preeti] Maharshi Dayanand Univ, Dept Comp Sci & Applicat, Rohtak, Haryana, India.
C3 Maharshi Dayanand University
RP Saini, A (corresponding author), Maharshi Dayanand Univ, Dept Comp Sci & Applicat, Rohtak, Haryana, India.
EM aashishsaini565@gmail.com; nasib.gill@mdurohtak.ac.in;
   preeti@mdurohtak.ac.in
RI GILL, Nasib Singh/H-3914-2015; A, P/JUU-6693-2023
OI GILL, Nasib Singh/0000-0002-8594-4320; 
CR Ahmad F, 2022, CAAI T INTELL TECHNO, V7, P200, DOI 10.1049/cit2.12083
   Alvi AM, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD)
   [Anonymous], 2012, International Journal of Electronics Communication Engineering
   [Anonymous], MEAN FILTER
   Chen B, 2012, HINDAWI PUBLISHING C
   Chen Y., 2019, IEEE T IMAGE PROCESS, V29, P1057
   Cvrkova F., 2019, DATA ILLUSTRATIONS C
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Ge FH, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0423-x
   Hambal M, 2017, INT J SCI RES, V6
   Hasan M, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0264-z
   Helou ME, 2020, IEEE T IMAGE PROCESS, V29
   Hosono K, 2019, IEEE ACCESS, V7, P88768, DOI 10.1109/ACCESS.2019.2926507
   Huang T, 2018, INT C PATT RECOG, P127, DOI 10.1109/ICPR.2018.8546057
   Huang XJ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P637
   Kaur S., 2015, International Journal of Advanced Research in Electronics and Communication Engineering (IJARECE) Volume, V4
   Kong ZM, 2019, Arxiv, DOI arXiv:1902.03954
   Li X., 2019, COLOR IMAGE DENOISIN, DOI [10.1109/ICIP.2019.8803209, DOI 10.1109/ICIP.2019.8803209]
   Li XY, 2019, IEEE SYS MAN CYBERN, P1602, DOI 10.1109/SMC.2019.8913860
   Lv JR, 2019, J INF PROCESS SYST, V15, P1108, DOI 10.3745/JIPS.02.0122
   Lyra M., 2011, MATLAB UBIQUITOUS TO, DOI [10.5772/19999, DOI 10.5772/19999]
   Mafi M., 2020, SURVEY MIXED IMPULSE, DOI [10.1049/iet-ipr.2018.6335, DOI 10.1049/IET-IPR.2018.6335]
   Narasimha C, 2020, IET IMAGE PROCESS, V14, P442, DOI 10.1049/iet-ipr.2018.6434
   Naseera S, 2017, RES J PHARM TECH, V10, P10
   Ralevic N, 2021, TEH VJESN, V28, P819, DOI 10.17559/TV-20200305075136
   Rao MN, 2016, INT J ENGIN RES TECH, V4
   Roy A, MULTIMED TOOLS APPL
   Roy A, 2018, IEEE T IND ELECTRON
   Sadreazami H, 2017, DATA ADAPTIVE COLOR, V275
   Singh A, 2020, IEEE ACCESS
   Suneetha A, 2021, J INTELL SYST, V30, P240, DOI 10.1515/jisys-2019-0211
   Tallapragada VVS, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2816-y
   Verma R, 2013, INT J ADV RES COMPUT, V3
   Vijayaraghavan S, DIGITAL IMAGE PROCES
   Westin CF, 2000, BIOMED EN S, P19
   Win NN, 2019, INT J SCI RES PUBL, V9
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yadav VP, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P114
   Zhao J, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550113
   Zhou Z, 2012, IEEE T IMAGE PROCESS, V21, P3157, DOI 10.1109/TIP.2012.2189577
NR 41
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 18
PY 2023
DI 10.1007/s11042-023-15603-7
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5VQ1
UT WOS:000989835300002
DA 2024-07-18
ER

PT J
AU Bhatti, KA
   Asghar, S
   Naz, S
AF Bhatti, Kabeer Ahmed
   Asghar, Sohail
   Naz, Sheneela
TI Multi-objective fuzzy krill herd congestion control algorithm for WSN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Wireless sensor network; Meta-heuristics techniques; Krill herd
   optimization; Congestion control
ID WIRELESS SENSOR NETWORKS; OPTIMIZATION; PROTOCOL
AB Wireless Sensor Network (WSN) consists of hundreds of devices with limited resources that collect, analyze, and transmit data to a base station. The carry-send nature and inconsistent transmission rate caused network congestion. Congestion incites decreased throughput, increased packet loss, and energy depletion. The existing congestion control strategies address congestion problems but still lack performance and quality of service issues. The optimal source transmission rate helps to alleviate congestion. The article proposes a Multi-objective Fuzzy Krill Herd Algorithm (MFKHA) control network congestion by optimizing the source sending rate. This innovative multi-objective outflow rate optimization mechanism improves network performance by designing a unique probability-based data differentiation mechanism coupled with an optimal source outflow rate optimization. To minimize network congestion by achieving fast convergence, this optimization algorithm incorporates the five objectives (congestion level, inflow rate, outflow rate, bandwidth, and queue length). To validate the performance of the proposed MFKHA algorithm, extensive simulations are carried out using MATLAB. Moreover, the proposed MFKHA algorithm is compared to those of cutting-edge meta-heuristic algorithms such as ECA-HA, ACSRO, and PSOGSA. The simulation result shows that the proposed MFKHA outperformed all counterparts and specifically improved the sending rate, throughput, and fairness and friendliness index. Furthermore, it has also reduced packet loss, delay, queue size, energy usage, and congestion against ECA-HA.
C1 [Bhatti, Kabeer Ahmed] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol SZA, Dept Comp Sci, Islamabad, Pakistan.
   [Asghar, Sohail; Naz, Sheneela] Comsats Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Bhatti, KA (corresponding author), Shaheed Zulfikar Ali Bhutto Inst Sci & Technol SZA, Dept Comp Sci, Islamabad, Pakistan.
EM kabeerahmed@hotmail.com; sohail.asghar@comsats.edu.pk;
   shahneela.cs@gmail.com
RI Bhatti, Kabeer Ahmed/IAR-2801-2023
OI Bhatti, Kabeer Ahmed/0000-0002-8500-7185; asghar,
   sohail/0000-0001-6883-3584
CR Ahmed MM, 2019, TELECOMMUN SYST, V72, P243, DOI 10.1007/s11235-019-00559-7
   Aimtongkham P, 2020, WIREL NETW, V26, P3603, DOI 10.1007/s11276-020-02289-0
   Aimtongkham P, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/6421717
   Alaei M, 2019, WIREL NETW, V25, P4173, DOI 10.1007/s11276-018-1738-8
   Alipio MI, 2018, IEEE T WIREL COMMUN, V17, P4607, DOI 10.1109/TWC.2018.2827986
   Almalawi A, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4048197
   Amer H, 2020, AD HOC NETW, V107, DOI 10.1016/j.adhoc.2020.102181
   Beitelspacher S, 2020, IEEE WIREL COMMUNN, DOI 10.1109/wcncw48565.2020.9124867
   Bhatti KA, 2023, ARAB J SCI ENG, V48, P1157, DOI 10.1007/s13369-022-06701-z
   Bohloulzadeh A, 2020, INT J WIREL INF NETW, V27, P365, DOI 10.1007/s10776-020-00479-3
   Cameron J, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113672
   Chaturvedi S., 2015, Computer, Communication and Control (IC4), 2015 International Conference on, P1, DOI DOI 10.1109/IC4.2015.7375552
   Chuang Ma, 2018, Computational Data and Social Networks. 7th International Conference, CSoNet 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11280), P356, DOI 10.1007/978-3-030-04648-4_30
   Daanoune I, 2019, 2019 7TH MEDITERRANEAN CONGRESS OF TELECOMMUNICATIONS (CMT 2019), DOI 10.1109/cmt.2019.8931320
   Dev K, 2022, IEEE T GREEN COMMUN, V6, P685, DOI 10.1109/TGCN.2022.3143991
   Fei ZS, 2017, IEEE COMMUN SURV TUT, V19, P550, DOI 10.1109/COMST.2016.2610578
   Grover A, 2022, ALEX ENG J, V61, P4765, DOI 10.1016/j.aej.2021.10.032
   Hamidouche R, 2019, IEEE ACCESS, V7, P156733, DOI 10.1109/ACCESS.2019.2943546
   Khan AI, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.104996
   Khan AI, 2022, CMC-COMPUT MATER CON, V70, P2835, DOI 10.32604/cmc.2022.020342
   Lin L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071862
   Maddikunta PKR, 2020, COMPUT COMMUN, V159, P97, DOI 10.1016/j.comcom.2020.05.020
   Mansouri N, 2020, J NETW COMPUT APPL, V171, DOI 10.1016/j.jnca.2020.102811
   Narawade V, 2018, ALEX ENG J, V57, P131, DOI 10.1016/j.aej.2016.10.005
   Nikokheslat HD, 2017, WIRELESS PERS COMMUN, V95, P3233, DOI 10.1007/s11277-017-3992-y
   Parsa A, 2021, COMPUT ELECTR ENG, V94, DOI 10.1016/j.compeleceng.2021.107330
   Qu SC, 2020, NEURAL COMPUT APPL, V32, P13505, DOI 10.1007/s00521-020-04758-1
   Qureshi IA, 2021, WIREL NETW, V27, P2323, DOI 10.1007/s11276-021-02572-8
   Rezaee AA, 2018, WIRELESS PERS COMMUN, V98, P815, DOI 10.1007/s11277-017-4896-6
   Sarker IH, 2023, MOBILE NETW APPL, V28, P296, DOI 10.1007/s11036-022-01937-3
   Shah SA, 2017, J KING SAUD UNIV-COM, V29, P236, DOI 10.1016/j.jksuci.2015.12.005
   Shelke MP, 2017, COMPUT ELECTR ENG, V64, P248, DOI 10.1016/j.compeleceng.2017.03.007
   Singh K, 2018, COMPUT NETW, V138, P90, DOI 10.1016/j.comnet.2018.03.023
   Srivastava V, 2020, J AMB INTEL HUM COMP, V11, P1325, DOI 10.1007/s12652-019-01449-1
   Vijayalakshmi K, 2019, CLUSTER COMPUT, V22, P12275, DOI 10.1007/s10586-017-1608-7
   Wang GG, 2019, ARTIF INTELL REV, V51, P119, DOI 10.1007/s10462-017-9559-1
   Yadav SL, 2021, J SENSORS, V2021, DOI 10.1155/2021/5575802
   Yang XP, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041265
   Yannibelli V, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/4653204
NR 39
TC 6
Z9 6
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 11
PY 2023
DI 10.1007/s11042-023-15200-8
EA MAY 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G1LI4
UT WOS:000986851800001
DA 2024-07-18
ER

PT J
AU Bagchi, P
   Bhattacharjee, D
AF Bagchi, Parama
   Bhattacharjee, Debotosh
TI JULive3D: a live image acquisition protocol for real-time 3D face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Kinect; Registration; Recognition; Calibration
ID ALGORITHM
AB The capturing and development of a real time 3D face recognition system is always a big challenge and attracts huge popularity nowadays. This is because, in most security systems employing face recognition, it is always crucial to capture live images and recognize them. This should save time and cost as well, and incredibly is acceptable across all areas of security concerns. This paper deals with the development of an entirely new 3D face recognition system which was developed in Jadavpur University with six subjects captured fully in real time. The main problem which we have tried to address in the present work is that, how various issues like camera calibration, alignment of the camera, distance of the camera from the subject affects the facial recognition rate. We will also analyze how facial registration helps to increase the recognition rates which have been imposed by the above factors. The problem is relevant, because, it's always a challenge to capture and correctly predict a real time system. The necessary problems needed for setting up a real time system is always a matter to be investigated by the researchers in face recognition domain. The main overview of our present proposed method is to capture the subjects in real-time taking into consideration all the calibration issues like camera alignment, distance of camera from the subject, and several other factors. We have also discussed how these factors affect the recognition rate. Once captured, we have tried to justify the varying recognition rate of the subjects due to the changes in calibration, alignment and other issues. Now, in order to improve the performances of the subjects, we have proposed a new 3D face registration algorithm termed as FaRegAvFM8, which was tested on the subjects from our database acquired in real-time, as well as on Frav3D and GavabDB databases. Our system attained a recognition rate of 95.83% after registration on frontal subjects using Haar wavelet as the feature extraction method, which depicts the robustness of the present system. Not only that, we have improved our recognition rate up to 96% using the Deep Convolutional Neural Network (DCNN).
C1 [Bagchi, Parama] RCC Inst Informat Technol, Kolkata, India.
   [Bhattacharjee, Debotosh] Jadavpur Univ, Kolkata, India.
C3 RCC Institute of Information Technology (RCCIIT); Jadavpur University
RP Bagchi, P (corresponding author), RCC Inst Informat Technol, Kolkata, India.
EM paramabagchi@gmail.com; debotosh@ieee.org
RI Bhattacharjee, Debotosh/L-8521-2015
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; BAGCHI,
   PARAMA/0000-0002-9725-9582
CR AbdELminaam DS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242269
   Achermann B, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P129, DOI 10.1109/VSMM.1997.622339
   Alghaili M, 2020, FACEFILTER FACE IDEN
   [Anonymous], 2013, IVMSP 2013
   Bagchi P, 2012, IEEE INT C ADV ENG S, P1
   Bagchi P, 2019, KUNSTL INTELL, V33, P369, DOI 10.1007/s13218-019-00593-2
   Bakkouri I, 2022, MULTIMED TOOLS APPL, V81, P10743, DOI 10.1007/s11042-022-12242-2
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Ben AB., 2008, SIGNAL PROCESSING IM, P141
   Bhateja A, 2022, MULTIMED TOOLS APPL, V81, P35775, DOI 10.1007/s11042-021-11392-z
   Bhattacharjee D, 2012, COMPUT INTEL NEUROSC, VNeurosci2012, P6
   Bhople AR, 2021, MULTIMED TOOLS APPL, V80, P30237, DOI 10.1007/s11042-020-09008-z
   Hu ZG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194124
   Mahdi FP, 2017, INTELL DECIS TECHNOL, V11, P79, DOI 10.3233/IDT-160279
   Mayya V, 2016, PROCEDIA COMPUT SCI
   Min R, 2012, INT C PATT RECOG, P1739
   Moreno A.B., 2004, WHITENING RACE ESSAY, P75
   Perakis P., 2010, Tech. Rep. TP-2010-01
   Ray B, 2022, MULTIMED TOOLS APPL, V81, P2681, DOI 10.1007/s11042-021-11671-9
   Regaya Y, 2021, MULTIMED TOOLS APPL, V80, P28161, DOI 10.1007/s11042-021-10924-x
   Su YX, 2020, IEEE T INSTRUM MEAS, V69, P6436, DOI 10.1109/TIM.2020.2968756
   Suchocki C, 2019, GEOSCIENCES, V9, DOI 10.3390/geosciences9020070
   Sui D, 2017, MULTIMED TOOLS APPL, V76, P19575, DOI 10.1007/s11042-015-3233-x
   Tulyakov S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P28, DOI 10.1109/ICCVW.2015.13
   Yan P, 2007, COMPUT VIS IMAGE UND, V107, P195, DOI 10.1016/j.cviu.2006.11.001
   Zeng JH, 2021, MATH BIOSCI ENG, V18, P1187, DOI 10.3934/mbe.2021064
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15728-9
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F8KZ4
UT WOS:000984795600004
DA 2024-07-18
ER

PT J
AU Kolkar, R
   Geetha, 
AF Kolkar, Ranjit
   Geetha, V
TI Human activity recognition using deep learning techniques with spider
   monkey optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; HAR; WISDM; UCI-HAR; Spider monkey
   Optimization
AB The human activity recognition (HAR) system recognizes human actions in daily life. There is a need for HAR to build a smart home and an intelligent healthcare environment. HAR is challenging, considering the complexity and heterogeneity of sensors used to recognize it. Deep learning models are the one area where the researcher applies to recognize the activities. However, effective feature engineering and optimization methods help improve the recognition model's performance. In this work, Spider Monkey Optimization is applied for training the deep neural network. UCI HAR, WISDM, KTH action and PAMAP2 datasets are used to evaluate the proposed system. The dataset has the activities like walking, standing, lying, jogging, stair-up and stair-down activities. Here, the spider monkey model's fitness function is initialized in the hidden layer of the Recurrent Neural Network to enhance accuracy and precision. The experiment results show improvements in performance as compared to other state-of-the-art methods like DL-Q, End to End DNN and SVM. With various assessments and experimentation, it is observed that the proposed SMO-based performs better in terms of accuracy of 98.92%, precision of 98.12%, recall of 98.9%, and F1-score 95.90%, respectively for the WISDM dataset. There is an improvement in performances for other datasets. Also, the Error rate has reduced to 2.8% as compared to other state-of-the-art methods.
C1 [Kolkar, Ranjit; Geetha, V] Natl Inst Technol Karnataka, Informat Technol, Manglore 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Kolkar, R (corresponding author), Natl Inst Technol Karnataka, Informat Technol, Manglore 575025, Karnataka, India.
EM ranjit.kolkar@gmail.com; geethav@gmail.com
OI Kolkar, Ranjit/0000-0001-6835-7821
CR Abdel-Basset M., 2018, Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications, P185, DOI [10.1016/b978-0-12-813314-9.00010-4, 10.1016/B978-0-12-813314-9.00010-4, DOI 10.1016/B978-0-12-813314]
   Anguita D, 2013, ESANN, P437, DOI DOI 10.3390/S20082200
   Atkinson G, 2021, 14 PERVASIVE TECHN R
   Bokhari SM, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108245
   Chattopadhyay A., 2022, Neurosci. Inform., V2, DOI DOI 10.1016/J.NEURI.2022.100060
   Dua N, 2021, COMPUTING, V103, P1461, DOI 10.1007/s00607-021-00928-8
   Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1
   Hamad RA, 2021, NEURAL COMPUT APPL, V1, P18
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Hussain K, 2019, ARTIF INTELL REV, V52, P2191, DOI 10.1007/s10462-017-9605-z
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Janarthanan R, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108050
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Manavizadeh N, 2020, J PROJ MANAGE, V5, P27, DOI 10.5267/j.jpm.2019.8.001
   Minarno AE, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS'2020), P19, DOI [10.1109/icoias49312.2020.9081858, 10.1109/ICoIAS49312.2020.9081858]
   Mliki H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107140
   Mukherjee D, 2020, MULTIMED TOOLS APPL, V79, P31663, DOI 10.1007/s11042-020-09537-7
   Nandan A., 2020, EXPLORING ALTERNATIV, DOI [10.1101/2020.05.14.20101352, DOI 10.1101/2020.05.14.20101352]
   Oliver N, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P3, DOI 10.1109/ICMI.2002.1166960
   Piyathilaka L, 2013, C IND ELECT APPL, P567
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shaikh MAM, 2011, SYSTEMIC DIMENSION G
   Shankar K, 2020, IEEE ACCESS, V8, P118164, DOI 10.1109/ACCESS.2020.3005152
   Sharma Basudev, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P109, DOI 10.1007/978-981-15-0751-9_10
   Singla G, 2010, J AMB INTEL HUM COMP, V1, P57, DOI 10.1007/s12652-009-0007-1
   Soleimani E, 2021, NEUROCOMPUTING, V426, P26, DOI 10.1016/j.neucom.2020.10.056
   Subasi A, 2020, Innovation in Health Informatics, P123, DOI DOI 10.1016/B978-0-12-819043-2.00005-8
   Tahir SBUD, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055944
   Tanberk S, 2020, IEEE ACCESS, V8, P19799, DOI 10.1109/ACCESS.2020.2968529
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Zela A., 2018, ARXIV
   Zhou XK, 2020, IEEE INTERNET THINGS, V7, P6429, DOI 10.1109/JIOT.2020.2985082
NR 35
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47253
EP 47270
DI 10.1007/s11042-023-15007-7
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800017
DA 2024-07-18
ER

PT J
AU Subhashini, S
   Revathi, S
AF Subhashini, S.
   Revathi, S.
TI Static and dynamic hand gesture recognition system with deep
   convolutional levy flight whale optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Gabor Line Derivative (GLD); Optimized deep convolutional neural network
   (ODCNN); Levy Flight- Whale optimization algorithm (LWOA); Greyscale
   conversion; Hyperparameters
ID NEURAL-NETWORKS
AB The Hand gesture recognition-based research field plays a prominent role in the automated transformation of sign language and is the major source of communication among deaf people. During a reorganization of hand gestures, the background deduction cannot deal with sudden, drastic lighting changes leading to several inconsistencies. This method also requires relatively many parameters, which need to be selected intelligently. A novel Gabor Line Derivative Deep Convolution Neural Network-based Levy flight Whale optimization is introduced. Primarily pre-processing is done to diminish the computation complexity of processing red, green, and blue channel images. With the Gabor Line Derivative-based feature extraction technique, a relevant set of line features are extracted and subjected to the proposed optimization-driven deep learning algorithm. Deep learning approaches are quite popular in the recognition of HGIs, but choosing appropriate hyper-parameters is a complex problem. Additionally, the key problem associated with deep learning techniques is that the outcome of the accuracy measure attained is not much effective in the existing models. Thus, a novel Deep Convolution Neural Network based Levy flight Whale optimization is introduced in terms of categorizing dissimilar static and dynamic HGIs. The experimental analysis reveals that the proposed classifier performs better than other competitive existing methods through the performance matrices such as Precision, Accuracy, F1-score, Recall, specificity, Recognition time, FNR, FDR, loss, FPR, MCC, training time, and NPV. The combination of the proposed methods is enabled and attained an accuracy of about 97%. The implementation of this work is done in the python platform.
C1 [Subhashini, S.; Revathi, S.] BS Abdur Rahman Crescent Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
C3 B. S. Abdur Rahman Crescent Institute of Science & Technology
RP Subhashini, S (corresponding author), BS Abdur Rahman Crescent Inst Sci & Technol, Dept Comp Sci & Engn, Chennai, India.
EM subhashini10@gmail.com; revathisathiya2202@gmail.com
RI S, Subhashini/GQQ-4298-2022
OI S, Subhashini/0000-0003-4297-8528
CR Ahuja R, 2019, INT J AMBIENT COMPUT, V10, P60, DOI 10.4018/IJACI.2019070104
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P192527, DOI 10.1109/ACCESS.2020.3032140
   Al-Hammadi M, 2020, IEEE CONSUM ELECTR M, V9, P95, DOI 10.1109/MCE.2019.2941464
   Ameur S, 2020, ENTERTAIN COMPUT, V35, DOI 10.1016/j.entcom.2020.100373
   Banning WP, 2013, COMMERCIAL BROADCAST
   Bao PJ, 2017, IEEE T CONSUM ELECTR, V63, P251, DOI 10.1109/TCE.2017.014971
   Benalcázar ME, 2017, EUR SIGNAL PR CONF, P1040, DOI 10.23919/EUSIPCO.2017.8081366
   Bhuvaneshwari C, 2020, MATER TODAY-PROC, V21, P731, DOI 10.1016/j.matpr.2019.06.748
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Choi HR, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/2404089
   Chung YL, 2020, J INTELL FUZZY SYST, V39, P4405, DOI 10.3233/JIFS-200385
   De Smedt Q, 2019, COMPUT VIS IMAGE UND, V181, P60, DOI 10.1016/j.cviu.2019.01.008
   Kane L, 2019, PATTERN RECOGN LETT, V120, P24, DOI 10.1016/j.patrec.2019.01.003
   Khodabandelou G, 2021, IEEE T AUTOM SCI ENG, V18, P495, DOI 10.1109/TASE.2020.3030852
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Kumar M, 2022, SADHANA-ACAD P ENG S, V47, DOI 10.1007/s12046-022-01847-w
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Liu FL, 2019, ARTIF INTELL REV, V52, P563, DOI 10.1007/s10462-019-09703-w
   Nayak J, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107478
   Ozcan T, 2019, NEURAL COMPUT APPL, V31, P8955, DOI 10.1007/s00521-019-04427-y
   Parvathy P, 2021, J AMB INTEL HUM COMP, V12, P6793, DOI 10.1007/s12652-020-02314-2
   Pinto RF, 2019, J ELECTR COMPUT ENG, V2019, DOI 10.1155/2019/4167890
   Saboo S, 2022, MULTIMEDIA SYST, V28, P183, DOI 10.1007/s00530-021-00811-8
   Sharma S, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115657
   Skaria S, 2019, IEEE SENS J, V19, P3041, DOI 10.1109/JSEN.2019.2892073
   Smith JW, 2021, IEEE ACCESS, V9, P10893, DOI 10.1109/ACCESS.2021.3051454
   Verma B, 2020, MULTIMED TOOLS APPL, V79, P2213, DOI 10.1007/s11042-019-08266-w
   Walugembe H, 2021, IEEE SENS J, V21, P8002, DOI 10.1109/JSEN.2020.3047268
   Xia ZY, 2021, IEEE T GEOSCI REMOTE, V59, P4749, DOI 10.1109/TGRS.2020.3010880
   Zheng DA, 2004, PROCEEDINGS OF THE SIXTH IASTED INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING, P139
NR 32
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15397-8
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800003
DA 2024-07-18
ER

PT J
AU Rehman, A
   Saba, T
   Haseeb, K
   Jeon, G
   Alam, T
AF Rehman, Amjad
   Saba, Tanzila
   Haseeb, Khalid
   Jeon, Gwanggil
   Alam, Teg
TI Modeling and optimizing IoT-driven autonomous vehicle transportation
   systems using intelligent multimedia sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Route optimization; Transportation problem; Next-generation
   technologies; Multimedia traffic; Green computing; Devices security
ID INTERNET; ARCHITECTURE; COMMUNICATION
AB With the rapid development of the Internet of Things (IoT) communication system, a huge number of devices are interconnected to sense the unpredictable environment. These systems are needed to manage a lot of varied data in addition to facilitating human lives. With the use of sensors, vehicles exchange multimedia data in smart transportation applications and subsequently give useful information to the road. Many approaches have been proposed to overcome the route optimization problems in improving the transportation system, but a major study is still needed to address intelligence in the context of autonomous processing with lower route reconstruction. Data privacy and the assurance of its integrity are also crucial components of the transportation system since vehicles use next-generation technology to carry roadway information. To cope with vehicle communication through unreliable wireless infrastructure and effectively use the resources of the communication model, this work proposed a smart vehicular algorithm employing an IoT system (SVA-IoT). Firstly, it guarantees the reliability of the intelligent transportation system (ITS) with heuristic computing and decreases the overhead on the devices. Second, route optimization is carried out to balance the load on parallel routes while transmitting highway information, as a result, it increases the intelligence of smart vehicle systems. In the end, authentic devices are identified to establish a secure and trusted communication structure. The proposed technique is tested through a variety of simulated experiments, and the findings show considerable improvement over existing work.
C1 [Rehman, Amjad; Saba, Tanzila; Haseeb, Khalid; Jeon, Gwanggil] CCIS Prince Sultan Univ, Artificial Intelligence & Data Analyt AIDA Lab, Riyadh 11586, Saudi Arabia.
   [Haseeb, Khalid] Islamia Coll Peshawar, Dept Comp Sci, Peshawar 25120, Pakistan.
   [Jeon, Gwanggil] Incheon Natl Univ, Coll Informat Technol, Dept Embedded Syst Engn, Incheon 22012, South Korea.
   [Alam, Teg] Prince Sattam bin Abdulaziz Univ Al Kharj, Coll Engn, Dept Ind Engn, Al Kharj 11924, Saudi Arabia.
   [Alam, Teg] Azad Inst Engn & Technol, Chandrawal Via Bangla Bazar & Bijnour,Near CRPF Ca, Lucknow 226002, India.
C3 University of Peshawar; Incheon National University; Prince Sattam Bin
   Abdulaziz University
RP Jeon, G (corresponding author), CCIS Prince Sultan Univ, Artificial Intelligence & Data Analyt AIDA Lab, Riyadh 11586, Saudi Arabia.; Jeon, G (corresponding author), Incheon Natl Univ, Coll Informat Technol, Dept Embedded Syst Engn, Incheon 22012, South Korea.
EM arkhan@psu.edu.sa; tsaba@psu.edu.sa; khaseeb@psu.edu.sa;
   gjeon@inu.ac.kr; t.alam@psau.edu.sa
RI Haseeb/J-5472-2017
CR Abbas G, 2022, COMPUT NETW, V213, DOI 10.1016/j.comnet.2022.109097
   Abir SMA, 2021, IEEE ACCESS, V9, P50961, DOI 10.1109/ACCESS.2021.3067331
   Abunadi I, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.13202
   Ahmed I, 2023, IEEE CONSUM ELECTR M, V12, P117, DOI 10.1109/MCE.2021.3139170
   Al Ja'afreh M, 2022, CLUSTER COMPUT, V25, P1619, DOI 10.1007/s10586-021-03402-4
   Avatefipour O, 2018, INT CONF ELECTRO INF, P1041
   Bhatti F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092071
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3832, DOI 10.1109/TITS.2020.3048844
   Cao B, 2021, SWARM EVOL COMPUT, V63, DOI 10.1016/j.swevo.2021.100864
   Din S, 2019, COMPUT NETW, V150, P81, DOI 10.1016/j.comnet.2018.11.035
   Fang YK, 2022, IEEE T INTELL TRANSP, V23, P15298, DOI 10.1109/TITS.2022.3140219
   Habibzadeh H, 2019, SUSTAIN CITIES SOC, V50, DOI 10.1016/j.scs.2019.101660
   Han Y, 2023, IEEE T INTELL TRANSP, V24, P1261, DOI 10.1109/TITS.2022.3183893
   Haseeb K, 2023, ISA T, V132, P61, DOI 10.1016/j.isatra.2022.09.035
   Hu L, 2018, IEEE INTERNET THINGS, V5, P747, DOI 10.1109/JIOT.2017.2705560
   Islam N, 2023, CLUSTER COMPUT, V26, P1631, DOI 10.1007/s10586-022-03677-1
   Jian LH, 2019, IEEE CONSUM ELECTR M, V8, P81, DOI 10.1109/MCE.2019.2892286
   Khan LU, 2020, IEEE ACCESS, V8, P147029, DOI 10.1109/ACCESS.2020.3015289
   Kong L, 2022, ACM COMPUT SURV CSUR
   Kumar P, 2021, IEEE T NETW SCI ENG, V8, P2326, DOI 10.1109/TNSE.2021.3089435
   Li B, 2022, IEEE T WIREL COMMUN, V21, P4579, DOI 10.1109/TWC.2021.3131384
   Liu MZ, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13053082
   Majid M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062087
   Maskuriy R, 2019, ECONOMIES, V7, DOI 10.3390/economies7030068
   Min C, 2023, MECH MACH THEORY, V181, DOI 10.1016/j.mechmachtheory.2022.105185
   Nellore K, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020157
   Nguyen D., 2021, IEEE Internet of Things Journal
   Olimid RF, 2020, IEEE ACCESS, V8, P99999, DOI 10.1109/ACCESS.2020.2997702
   Qureshi KN, 2021, IEEE T INTELL TRANSP, V22, P3850, DOI 10.1109/TITS.2021.3049429
   Qureshi KN, 2021, IEEE T INTELL TRANSP, V22, P1777, DOI 10.1109/TITS.2020.2994972
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Rehman O, 2019, FUTURE GENER COMP SY, V93, P1, DOI 10.1016/j.future.2018.10.042
   Sharma A, 2020, COMPUT COMMUN, V160, P475, DOI 10.1016/j.comcom.2020.06.030
   Sharma S, 2022, WIRELESS PERS COMMUN, V124, P2735, DOI 10.1007/s11277-022-09487-3
   Sodhro AH, 2021, IEEE INTERNET THINGS, V8, P5141, DOI 10.1109/JIOT.2020.3024715
   Taghieh A, 2022, OCEAN ENG, V266, DOI 10.1016/j.oceaneng.2022.113014
   Xie HM, 2019, IEEE INTERNET THINGS, V6, P2205, DOI 10.1109/JIOT.2018.2883403
   Xu JW, 2022, IEEE T INTELL TRANSP, V23, P16386, DOI 10.1109/TITS.2022.3149994
   Xu JW, 2022, IEEE T INTELL TRANSP, V23, P4972, DOI 10.1109/TITS.2020.3044927
NR 39
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 5
PY 2023
DI 10.1007/s11042-023-15563-y
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F5VE6
UT WOS:000983013200002
DA 2024-07-18
ER

PT J
AU Singh, S
   Singh, P
   Tanwar, S
AF Singh, Shubhuam
   Singh, Pawan
   Tanwar, Sudeep
TI Energy aware resource allocation via MS-SLnO in cloud data center
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Resource allocation; Improved K-means clustering; LAAM;
   MS-SLnO
ID PARTICLE SWARM OPTIMIZATION; SCIENTIFIC WORKFLOW; SCHEDULING ALGORITHM;
   SECURITY-AWARE; TASKS; STRATEGY
AB Cloud computing has evolved as a cutting-edge platform of consumer and business opportunities. It also allows the users to view apps and data from any place. Companies will borrow services from the cloud for storage and other operational tasks, which dramatically reduces the technology costs. Also, it gives the benefits of company-wide platform accessibility built on the pay-as-you-go model. There is no need of purchasing specific product licenses. However, resource allocation becomes the most important pitfalls in cloud computing. This paper aims to implement a new optimization-assisted resource allocation approach that maximizes sales with minimized costs. Prior to this allocation, the workload (allocated tasks) clustering is performed using an advanced k-means clustering with the Lion with Advanced Mating Process (LAAM) that fine-tunes the centroid. The clustering of tasks is undergone depending on the QoS (trust) and task time. Finally, a hybrid algorithm termed as Moth Search Adapted Sealion optimization (MS-SLnO) for optimal resource allocation under the consideration of Power Usage Effectiveness (PUE), CPU usage, and execution time. Furthermore, the suggested work's performance was compared to that of the latest systems in regard to energy use, execution time, and resource usage.
C1 [Singh, Shubhuam; Singh, Pawan] Amity Univ Uttar Pradesh, Dept Comp Sci & Engn, Lucknow Campus, Lucknow, India.
   [Tanwar, Sudeep] Nirma Univ, Inst Technol, Dept Comp Sci & Engn, Ahmadabad, India.
C3 Nirma University
RP Singh, S (corresponding author), Amity Univ Uttar Pradesh, Dept Comp Sci & Engn, Lucknow Campus, Lucknow, India.
EM singhshubham070@gmail.com; pawansingh51279@gmail.com;
   sudeep149@rediffmail.com
RI Tanwar, Sudeep/AAI-6709-2020; Singh, Shubham/JZD-1909-2024; Singh,
   Pawan/Q-1916-2015
OI Tanwar, Sudeep/0000-0002-1776-4651; Singh, Pawan/0000-0002-1342-9493;
   Singh, Shubham/0000-0001-7327-5417
CR Abdulhamid SM, 2016, SECURE SCIENTIFIC AP
   Abdullahi M, 2016, FUTURE GENER COMP SY, V56, P640, DOI 10.1016/j.future.2015.08.006
   [Anonymous], 2020, Multi Res, V3, P45
   Beno MM, 2014, INT J IMAG SYST TECH, V24, P129, DOI 10.1002/ima.22087
   Boothalingam R, 2018, EVOL INTELL, V11, P31, DOI 10.1007/s12065-018-0168-y
   Chen HK, 2017, IEEE T PARALL DISTR, V28, P2674, DOI 10.1109/TPDS.2017.2678507
   Chen MH, 2018, IEEE T WIREL COMMUN, V17, P6790, DOI 10.1109/TWC.2018.2864559
   Chen ZY, 2020, IEEE ACCESS, V8, P190173, DOI 10.1109/ACCESS.2020.3032545
   Farid M, 2020, IEEE ACCESS, V8, P24309, DOI 10.1109/ACCESS.2020.2970475
   Fernández-Cerero D, 2018, J PARALLEL DISTR COM, V119, P191, DOI 10.1016/j.jpdc.2018.04.015
   George Amalarathinam DI., 2018, INT J PURE APPL MATH, V118, P323
   Grzonka D, 2015, FUTURE GENER COMP SY, V51, P72, DOI 10.1016/j.future.2014.10.031
   Ismayilov G, 2020, FUTURE GENER COMP SY, V102, P307, DOI 10.1016/j.future.2019.08.012
   Juarez F, 2018, FUTURE GENER COMP SY, V78, P257, DOI 10.1016/j.future.2016.06.029
   Lavanya M, 2020, COMPUT COMMUN, V151, P183, DOI 10.1016/j.comcom.2019.12.050
   Lee JW, 2019, PERVASIVE MOB COMPUT, V60, DOI 10.1016/j.pmcj.2019.101082
   Li ZJ, 2016, FUTURE GENER COMP SY, V65, P140, DOI 10.1016/j.future.2015.12.014
   Liu YK, 2017, ROBOT CIM-INT MANUF, V45, P3, DOI 10.1016/j.rcim.2016.09.008
   Mahesh K., 2020, Multimedia Research, V3, P36
   Mansouri N, 2019, COMPUT IND ENG, V130, P597, DOI 10.1016/j.cie.2019.03.006
   Masadeh R, 2019, INT J ADV COMPUT SC, V10, P388
   Mishra SK, 2020, IEEE ACCESS, V8, P178825, DOI 10.1109/ACCESS.2020.3026875
   Mulge MY, 2019, INT J INTELL ENG SYS, V12, P192
   Neelima P, 2020, CLUSTER COMPUT, V23, P2891, DOI 10.1007/s10586-020-03054-w
   Netaji V. K., 2020, Multi Res, V3, P11
   Niu SC, 2016, IEEE T PARALL DISTR, V27, P1915, DOI 10.1109/TPDS.2015.2476459
   Panda SK, 2019, INFORM SYST FRONT, V21, P241, DOI 10.1007/s10796-017-9742-6
   Pang SC, 2019, IEEE ACCESS, V7, P146379, DOI 10.1109/ACCESS.2019.2946216
   Rahman CM, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/9293617
   Rajakumar B.R., 2013, International Journal of Hybrid Intelligent Systems, V10, P11, DOI [10.3233/HIS-120161, DOI 10.3233/HIS-120161]
   Rjoub G, 2020, FUTURE GENER COMP SY, V110, P1079, DOI 10.1016/j.future.2019.11.019
   Salman T., 2015, SEMANTIC SCHOLAR, V7, P1
   Sanaj MS, 2020, ENG SCI TECHNOL, V23, P891, DOI 10.1016/j.jestch.2019.11.002
   Senthilnathan R., 2018, INT J PURE APPL MATH, V119, P1007
   Shishido HY, 2018, COMPUT ELECTR ENG, V69, P378, DOI 10.1016/j.compeleceng.2017.12.004
   Simic V, 2019, FUTURE GENER COMP SY, V101, P909, DOI 10.1016/j.future.2019.07.042
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Uma Maheswari S, 2016, INT J ENG SCI COMPUT, V6, P4860
   Wang GG, 2018, MEMET COMPUT, V10, P151, DOI 10.1007/s12293-016-0212-3
   Wang N, 2018, IEEE ACCESS, V6, P15663, DOI 10.1109/ACCESS.2018.2790392
   Wilczynski A, 2020, SIMUL MODEL PRACT TH, V99, DOI 10.1016/j.simpat.2019.102038
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Zeng LF, 2015, J PARALLEL DISTR COM, V75, P141, DOI 10.1016/j.jpdc.2014.09.002
   Zhang Y, 2020, FUTURE GENER COMP SY, V112, P148, DOI 10.1016/j.future.2020.05.025
   Zhou CJ, 2020, IEEE T IND INFORM, V16, P3112, DOI 10.1109/TII.2019.2903224
NR 46
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 29
SI SI
BP 45541
EP 45563
DI 10.1007/s11042-023-15521-8
EA MAY 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS8T7
UT WOS:000981387900009
DA 2024-07-18
ER

PT J
AU Veranyurt, O
   Sakar, CO
AF Veranyurt, Ozan
   Sakar, C. Okan
TI Concealed pistol detection from thermal images with deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks; Transfer learning; Thermal
   imaging; Concealed weapons
ID VIDEOS
AB Violence involving firearms is a rising threat that requires precise and competent surveillance systems. Current surveillance technologies involve continuous human observation and are prone to human errors. To handle such errors and monitor with minimal human effort, new solutions using artificial intelligence approaches that can detect and pinpoint the threat are required. In this study, our aim is to develop a deep learning-based solution capable of detecting and locating concealed pistols on thermal images for real-time surveillance. For this purpose, we generate a dataset consisting of thermal video recordings of multiple human models and combine this dataset with thermal images from public sources. Then, we build up a deep learning-based framework by combining two deep learning models that detects and localizes the concealed pistol in the given thermal image. We evaluate multiple deep learning architectures for the classification and segmentation of the images. The best test set results in detecting the concealed pistol was achieved by a fine-tuned VGG19-based convolutional neural network model with an F1 score of 0.84 on the test set. In the second module of the system, a fine-tuned Yolo-V3 model trained as a multi-tasking model for both classification and location detection gave the highest mean average precision value of 0.95 in labeling and locating the pistol in a bounding box in approximately 10 milliseconds. The findings exhibit the potential of using deep learning techniques with thermal imaging for the real time concealed pistol detection.
C1 [Veranyurt, Ozan; Sakar, C. Okan] Bahcesehir Univ, Dept Comp Engn, Istanbul, Turkiye.
C3 Bahcesehir University
RP Veranyurt, O (corresponding author), Bahcesehir Univ, Dept Comp Engn, Istanbul, Turkiye.
EM ozan.veranyurt@bahcesehir.edu.tr; okan.sakar@eng.bau.edu.tr
CR [Anonymous], 2015, PROC 12 IEEE INT C A
   Carlueho J, 2018, IEEE INT C INT ROBOT, P2336, DOI 10.1109/IROS.2018.8594067
   Castillo A, 2019, NEUROCOMPUTING, V330, P151, DOI 10.1016/j.neucom.2018.10.076
   Cheng L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16208-0
   Hussein NJ, 2017, PATTERN RECOGN LETT, V94, P219, DOI 10.1016/j.patrec.2016.12.011
   Jain Harsh, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P193, DOI 10.1109/ICESC48915.2020.9155832
   Kowalski M, 2019, J INFRARED MILLIM TE, V40, P1074, DOI 10.1007/s10762-019-00628-7
   Kowalski M., 2015, SAF SECUR ENG 6, V151, P215
   Lai J., 2017, Course: CS231n
   Lamas A, 2022, NEUROCOMPUTING, V489, P488, DOI 10.1016/j.neucom.2021.12.059
   Fernandez-Carrobles MM, 2019, LECT NOTES COMPUT SC, V11868, P441, DOI 10.1007/978-3-030-31321-0_38
   National Research Council, 1996, AIRL PASS SEC SCREEN, V482
   Olmos R, 2018, NEUROCOMPUTING, V275, P66, DOI 10.1016/j.neucom.2017.05.012
   Palmero C, 2016, INT J COMPUT VISION, V118, P217, DOI 10.1007/s11263-016-0901-x
   Pang L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061678
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Sai SM, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P962, DOI 10.1109/ICICCT.2018.8473140
   González JLS, 2020, NEURAL NETWORKS, V132, P297, DOI 10.1016/j.neunet.2020.09.013
   Sitara K., 2022, 2022 3 INT C EM TECH, DOI 10.1109/INCET54531.2022.9824281
   Vallez N, 2021, NEURAL COMPUT APPL, V33, P5885, DOI 10.1007/s00521-020-05365-w
   Veranyurt O, 2020, Turkey Patent Application, Patent No. [2020,14269, 202014269]
   Verma GK, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P84, DOI 10.1145/3154979.3154988
   Wei YX, 2020, NEURAL COMPUT APPL, V32, P8711, DOI 10.1007/s00521-019-04360-0
   Wu T, 2015, IEEE ICC, P2423, DOI 10.1109/ICC.2015.7248688
   Yeom S, 2011, OPT EXPRESS, V19, P2530, DOI 10.1364/OE.19.002530
   Yuenyong S, 2018, 2018 1ST INTERNATIONAL ECTI NORTHERN SECTION CONFERENCE ON ELECTRICAL, ELECTRONICS, COMPUTER AND TELECOMMUNICATIONS ENGINEERING (ECTI-NCON, P65, DOI 10.1109/ECTI-NCON.2018.8378283
   Zhang DJ, 2021, NEURAL COMPUT APPL, V33, P4639, DOI 10.1007/s00521-020-05307-6
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
NR 28
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 44259
EP 44275
DI 10.1007/s11042-023-15358-1
EA MAY 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:001033146000010
DA 2024-07-18
ER

PT J
AU Deng, LW
   Liu, SS
   Cheng, YX
   Zhao, GF
   Xu, JZ
AF Deng, Liwei
   Liu, Shanshan
   Cheng, Yuxin
   Zhao, Guofu
   Xu, Jiazhong
TI Algorithm for diabetic retinal image analysis based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retina; Deep learning; Faster-RCNN network; Object detection
ID OBJECT-DETECTION; CONVOLUTIONAL NETWORKS
AB In the last several years, diabetes incidence has increased year over year. Due to the large contrast between ophthalmologists' numbers and diabetic patients' numbers, many patients with diabetic retinal disease cannot be diagnosed and treated on time, worsening their condition. An improved Faster-RCNN network was designed to detect the location of the optic disc in the diabetic retina using object classification. In this study, the selection of the improved VGG16 model and ResNet50 model for feature extraction and the Faster-RCNN algorithm-based object classification detection for fundus images was experimentally investigated. The experimental data show that the ResNet50-based Faster-RCNN network model has higher average precision and faster model convergence in detecting diabetic retinal disease, achieving a mean average precision (mAP) of 97.42% and a precision of 98.96%. In the case of categories with more minor distinct features and smaller datasets, the precision is enhanced by 24.26% over the Yolov5-based object detection approach. The mAP value is improved by 6.12%. The algorithm better balances the precision and speed of object detection to better meet the requirements for detecting diabetic retinal disease.
C1 [Deng, Liwei; Liu, Shanshan; Cheng, Yuxin; Xu, Jiazhong] Harbin Univ Sci & Technol, Sch Automat, Heilongjiang Prov Key Lab Complex Intelligent Syst, Harbin 150080, Peoples R China.
   [Zhao, Guofu] Heilongjiang Acad Agr Machinery Sci, Jiamusi Branch, Jiamusi 154003, Peoples R China.
   [Xu, Jiazhong] Harbin Univ Sci & Technol, Key Lab Adv Mfg & Intelligent Technol, Minist Educ, Harbin 150080, Peoples R China.
C3 Harbin University of Science & Technology; Harbin University of Science
   & Technology
RP Cheng, YX (corresponding author), Harbin Univ Sci & Technol, Sch Automat, Heilongjiang Prov Key Lab Complex Intelligent Syst, Harbin 150080, Peoples R China.
EM dengliwei666@hrbust.edu.cn; 2120510096@stu.hrbust.edu.cn;
   1920500014@stu.hrbust.edu.cn; bhjxzgf@163.com; xujiazhong@hrbust.edu.cn
OI Liu, Shanshan/0000-0003-3115-2413; Deng, Liwei/0000-0002-3996-5569;
   cheng, yuxin/0000-0001-9882-8153
FU National Science Foundation for Young Scientists of China [61806060];
   Natural Science Foundation of Heilongjiang Province [LH2019F024]
FX This research was funded by the National Science Foundation for Young
   Scientists of China, grant number (Grant No.61806060), 2019-2021,
   "Research of Diabetic Retinal Image Analysis Algorithms Based on
   Fractional Order Differential and the Deep Learning," and the Natural
   Science Foundation of Heilongjiang Province (LH2019F024), China,
   2019-2022, "Research on The Key Technology of Defect Detection of Wind
   Turbine Blade Based on Unmanned Aerial Vehicle-Taken Images."
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Carrera EV, 2017, PROCEEDINGS OF THE 2017 IEEE XXIV INTERNATIONAL CONFERENCE ON ELECTRONICS, ELECTRICAL ENGINEERING AND COMPUTING (INTERCON), DOI 10.1109/INTERCON.2017.8079692
   Chambers EC, 2019, DIABETES EDUCATOR, V45, P616, DOI 10.1177/0145721719880503
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Fangbo Zhou, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P6, DOI 10.1109/ICPECA51329.2021.9362711
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghosh R, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P550, DOI 10.1109/SPIN.2017.8050011
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Harris NR, 2019, BIORHEOLOGY, V56, P181, DOI 10.3233/BIR-180200
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hosang J, 2014, ARXIV
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Kajan S, 2020, PROCEEDINGS OF THE 2020 30TH INTERNATIONAL CONFERENCE CYBERNETICS & INFORMATICS (K&I '20), DOI 10.1109/ki48306.2020.9039793
   Kolosnjaji Bojan, 2016, AI 2016: Advances in Artificial Intelligence. 29th Australasian Joint Conference. Proceedings: LNAI 9992, P137, DOI 10.1007/978-3-319-50127-7_11
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li H, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201102
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mendonça HR, 2020, NEURAL REGEN RES, V15, P625, DOI 10.4103/1673-5374.266910
   Miri Maliheh, 2017, J Med Signals Sens, V7, P59
   Monika KM, 2021, XGBOOST 2D OBJECT RE
   Padmanabha AGA, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND KNOWLEDGE ENGINEERING (IEEE ISKE), DOI 10.1109/ISKE.2017.8258754
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qiao L., 2020, IEEE ACCESS, VPP, P1
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Sermanet P., 2013, ARXIV
   Shah SAA, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.10.101404
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Yao S., 2020, MACH VISION APPL, V32, P1
   Zhenhuan Z, 2008, INT C BIOM ENG INF I
NR 43
TC 0
Z9 0
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47559
EP 47584
DI 10.1007/s11042-023-15503-w
EA APR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000978477000007
DA 2024-07-18
ER

PT J
AU Simhadri, PK
   Kns, S
AF Simhadri, Phani Kumar
   Kns, Suman
TI Analysis of tribological and mechanical properties of coated graphene
   oxide, tungsten disulphide reinforced nylon hybrid composites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Nylon66; Graphene Oxide; Tungsten Disulphide; Composite Gear; Buffalo
   Fitness
AB Nylon with various reinforcements is utilized for composite gear preparation; however, the composite specimens have less strength and a higher wear rate. Moreover, the materials and processing costs are high when selecting various mix proportions. Hence, this research has examined the impacts of adding Graphene oxide (GO) and Tungsten disulphide (TD) with Nylon 66 (PA66) on the tribological and mechanical properties. The research aims to identify the best hybrid nylon-reinforced composite specimen for composite gear manufacturing. The GO was prepared by the Modified Hummers-based method and coated with epoxy resin by dip coating. Further, a novel Decision Buffalo-based Mix Selection (DBbMS) has been developed for selecting the best mix proportions to reduce the processing time and material cost. The test specimens are set up by varying the rates of coated GO and TD blended with PA66. In addition, the test examples for tribological and mechanical tests were shaped using an injection moulding machine. The mechanical and tribological properties of PA66, TD, and GO mixed with PA66 hybrid composites were identified. The PA66 composite with 4wt% TD and 15wt% coated GO (PTO-3) uncovered better strengths and higher wear and erosion resistance. In this work, PTO-3 hybrid composite material has been utilized for gear manufacturing.
C1 [Simhadri, Phani Kumar; Kns, Suman] Andhra Univ, Anil Neerukonda Inst Technol & Sci, Dept Mech Engn, Visakhapatnam, Andhra Pradesh, India.
C3 Andhra University
RP Simhadri, PK (corresponding author), Andhra Univ, Anil Neerukonda Inst Technol & Sci, Dept Mech Engn, Visakhapatnam, Andhra Pradesh, India.
EM sphani.me@anits.edu.in; sumankoka@yahoo.com
RI SIMHADRI, PHANI KUMAR/ABB-7262-2022
OI Naga Sai Suman, Koka/0000-0002-1681-6915
CR Ahmadijokani F, 2020, WEAR, V452, DOI 10.1016/j.wear.2020.203280
   Ali MKA, 2020, FRICTION, V8, P905, DOI 10.1007/s40544-019-0308-0
   Balaji KV, 2020, MATER TODAY CHEM, V17, DOI 10.1016/j.mtchem.2020.100334
   Chen D, 2022, POLYM DEGRAD STABIL, V203, DOI 10.1016/j.polymdegradstab.2022.110041
   Chen SB, 2021, COLLOID SURFACE A, V628, DOI 10.1016/j.colsurfa.2021.127309
   Dabees S, 2021, J MATER RES TECHNOL, V12, P2476, DOI 10.1016/j.jmrt.2020.09.129
   Gupta MK, 2020, J CLEAN PROD, V251, DOI 10.1016/j.jclepro.2019.119598
   Hirai T, 2021, COMPOS PART B-ENG, V225, DOI 10.1016/j.compositesb.2021.109258
   Hribersek M, 2021, J MECH SCI TECHNOL, V35, P3389, DOI 10.1007/s12206-021-0712-z
   Kim M, 2022, POLYM TEST, V108, DOI 10.1016/j.polymertesting.2022.107517
   Kumar SS, 2021, MATER TODAY-PROC, V37, P3038, DOI 10.1016/j.matpr.2020.08.777
   Kumar SS, 2021, MATER TODAY-PROC, V37, P3352, DOI 10.1016/j.matpr.2020.09.204
   Kunishima T, 2021, TRIBOL INT, V153, DOI 10.1016/j.triboint.2020.106578
   Kunishima T, 2021, WEAR, V477, DOI 10.1016/j.wear.2021.203899
   Kunishima T, 2020, MATER DESIGN, V188, DOI 10.1016/j.matdes.2019.108447
   Landi L, 2021, MECH MACH THEORY, V166, DOI 10.1016/j.mechmachtheory.2021.104496
   Li JC, 2021, J APPL POLYM SCI, V138, DOI 10.1002/app.50042
   Liu H, 2020, MECH MACH THEORY, V145, DOI 10.1016/j.mechmachtheory.2019.103701
   Panhalkar AR, 2022, J KING SAUD UNIV-COM, V34, P4763, DOI 10.1016/j.jksuci.2021.01.011
   Ramanjaneyulu S, 2017, MATER TODAY-PROC, V4, P8678, DOI 10.1016/j.matpr.2017.07.216
   Shanmugam V, 2021, INT J FATIGUE, V143, DOI 10.1016/j.ijfatigue.2020.106007
   Trobentar B, 2020, ENG FAIL ANAL, V111, DOI 10.1016/j.engfailanal.2020.104496
   Verma C, 2020, REACT FUNCT POLYM, V156, DOI 10.1016/j.reactfunctpolym.2020.104741
   Virmani K, 2021, EUR PHYS J PLUS, V136, DOI 10.1140/epjp/s13360-021-01931-w
   Walker S, 2020, J CLEAN PROD, V261, DOI 10.1016/j.jclepro.2020.121158
   Wang L, 2020, CARBON, V159, P345, DOI 10.1016/j.carbon.2019.12.034
   Xie M., 2021, MULTISTAGE DAMPER CH, V34, P1
   Zhou HF, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113842
   Zorko D, 2021, POLYM TEST, V102, DOI 10.1016/j.polymertesting.2021.107339
   Zorko D, 2021, INT J FATIGUE, V151, DOI 10.1016/j.ijfatigue.2021.106394
   Zorko D, 2021, POLYM TEST, V93, DOI 10.1016/j.polymertesting.2020.106994
NR 31
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42485
EP 42508
DI 10.1007/s11042-023-15218-y
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968990200002
DA 2024-07-18
ER

PT J
AU Zhang, FK
   Zhang, LL
   Zhang, HY
   Ma, YQ
AF Zhang, Fukai
   Zhang, Lulu
   Zhang, Haiyan
   Ma, Yongqiang
TI Image-to-image domain adaptation for vehicle re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle re-identification; Domain adaptation; Single-image super
   resolution; Transfer learning
ID SIMILARITY
AB Cross-domain vehicle re-identification (ReID) is an interesting but challenging task in computer vision. A ReID model well-trained on one dataset often experiences a severe performance drop when applied to another dataset due to the domain discrepancy between the different datasets. This is especially true for low-resolution images. In this paper, we present a vehicle image domain adaptation framework (VDAF) which contains a single-image super resolution network (SISR) and a vehicle transfer generative adversarial network (VTGAN). SISR is an enhancement task for mapping low-resolution (LR) images to high-resolution (HR) images. Based on the reconstructed HR images, VTGAN can translate vehicle images from a source domain to a target domain with consistent styles and identities. VTGAN is an unsupervised approach designed for source-target translation for vehicle ReID and is composed of two adversarial networks and one Siamese network. Based on the translated images, we can infer an enhanced vehicle representation free of influences from style variations, allowing distance metrics for vehicle ReID to be learned. Through extensive experiments on the VeRi, VehicleID, and VRIC datasets, we show that images translated by VTGAN are effective for domain adaptation and are superior at promoting the accuracy of vehicle ReID.
C1 [Zhang, Fukai; Zhang, Lulu; Ma, Yongqiang] Henan Polytech Univ, Sch Software, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Fukai] Henan Polytech Univ, Coll Safety Sci & Engn, Jiaozuo 454000, Henan, Peoples R China.
   [Zhang, Haiyan] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
C3 Henan Polytechnic University; Henan Polytechnic University; Henan
   Polytechnic University
RP Zhang, HY (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454000, Henan, Peoples R China.
EM zhangfukai@hpu.edu.cn; zhanghaiyan@hpu.edu.cn
FU Key Research and Development and Promotion in Henan Province
   [222102240045]; Key Scientific Research Projects of Colleges and
   Universities in Henan Province [22A520028]; Fundamental Research Funds
   for the Universities of Henan Province [NSFRF210342]
FX This work was supported in part by the Key Research and Development and
   Promotion in Henan Province (Science and Technology Research) under
   Grant 222102240045, in part by the Key Scientific Research Projects of
   Colleges and Universities in Henan Province under Grant 22A520028, in
   part by the Fundamental Research Funds for the Universities of Henan
   Province under Grant NSFRF210342.
CR Marín-Reyes PA, 2018, IEEE COMPUT SOC CONF, P166, DOI 10.1109/CVPRW.2018.00030
   Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Bai Y, 2018, IEEE T MULTIMEDIA, V20, P2385, DOI 10.1109/TMM.2018.2796240
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Guo HY, 2019, IEEE T IMAGE PROCESS, V28, P4328, DOI 10.1109/TIP.2019.2910408
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou JH, 2019, IEEE T VEH TECHNOL, V68, P8512, DOI 10.1109/TVT.2019.2927353
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kanaci A., 2018, P GERM C PATT REC GC, P377, DOI 10.48550/arXiv.1809.09409
   Khan SD, 2019, COMPUT VIS IMAGE UND, V182, P50, DOI 10.1016/j.cviu.2019.03.001
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2016, IEEE INT CON MULTI
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Long MS, 2016, ADV NEUR IN, V29
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Lou YH, 2019, IEEE T IMAGE PROCESS, V28, P3794, DOI 10.1109/TIP.2019.2902112
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Peng JJ, 2020, NEUROCOMPUTING, V401, P133, DOI 10.1016/j.neucom.2020.02.112
   Peng JJ, 2019, IEEE INT CONF MULTI, P453, DOI 10.1109/ICMEW.2019.00084
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Taigman Y., 2017, INT C LEARN REPR ICL, P1
   Wang HB, 2021, IEEE T MULTIMEDIA, V23, P3828, DOI 10.1109/TMM.2020.3032023
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Wang Q, 2022, IEEE T MULTIMEDIA, V24, P1031, DOI 10.1109/TMM.2021.3104141
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wu CW, 2018, IEEE COMPUT SOC CONF, P121, DOI 10.1109/CVPRW.2018.00024
   Wu FY, 2019, SIGNAL PROCESS-IMAGE, V76, P261, DOI 10.1016/j.image.2019.04.021
   Wu YW, 2019, IEEE INT CONF COMP V, P1065, DOI 10.1109/ICCVW.2019.00136
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yan LY, 2021, MULTIMED TOOLS APPL, V80, P14363, DOI 10.1007/s11042-020-10310-z
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zapletal D, 2016, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW.2016.195
   Zhang FK, 2019, IEEE ACCESS, V7, P72660, DOI 10.1109/ACCESS.2019.2919103
   Zhang SL, 2021, NEUROCOMPUTING, V447, P118, DOI 10.1016/j.neucom.2021.02.095
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252
   Zheng ZD, 2021, IEEE T MULTIMEDIA, V23, P2683, DOI 10.1109/TMM.2020.3014488
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou Y., 2017, 1 AS AUSTR C PREC PA, P1, DOI DOI 10.5244/C.31.186
   Zhou Y, 2018, IEEE WINT CONF APPL, P653, DOI 10.1109/WACV.2018.00077
   Zhou Y, 2018, IEEE T IMAGE PROCESS, V27, P3275, DOI 10.1109/TIP.2018.2819820
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
   Zhu JQ, 2019, MULTIMED TOOLS APPL, V78, P29043, DOI 10.1007/s11042-018-6270-4
   Zhu JQ, 2018, IEEE ACCESS, V6, P43724, DOI 10.1109/ACCESS.2018.2862382
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 59
TC 0
Z9 0
U1 6
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40559
EP 40584
DI 10.1007/s11042-023-14839-7
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100008
DA 2024-07-18
ER

PT J
AU Madichetty, S
   Sridevi, M
   Madisetty, S
AF Madichetty, Sreenivasulu
   Sridevi, M.
   Madisetty, Sreekanth
TI A RoBERTa based model for identifying the multi-modal informative tweets
   during disaster
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE RoBERTa; VGG-16 architecture; Disaster; Multiplicative fusion; Twitter;
   Social Media
AB Detecting informative tweets is very important to the government or non-government organizations during a disaster. Most of the literature works focused on either text or image separately for getting informative tweets. A very few existing works used multi-modal information such as both image and text to identify the informative tweets. However, the existing works do not give much performance on multi-modal informative tweets. There is a chance to lose useful information in critical times. Hence, we propose a novel approach to identify the multi-modal informative tweets during a disaster. Our proposed method comprises the pre-trained RoBERTa and VGG-16 models to extract the text and image features, respectively. The outputs of these two models are combined using a multiplicative fusion technique. Experiments are conducted on diverse disaster datasets such as Hurricane Maria, Hurricane Harvey, California wildfires, Iraq-Iran earthquake, Hurricane Irma, and Mexico earthquake. Experimental results demonstrated that the proposed method outperforms the existing baseline methods on various parameters.
C1 [Madichetty, Sreenivasulu] Centific, Hyderabad, India.
   [Sridevi, M.] Natl Inst Technol, Tiruchirappalli, India.
   [Madisetty, Sreekanth] Woosong Univ, Endicott Coll Int Studies, Daejeon, South Korea.
   [Madisetty, Sreekanth] Jio Platforms Ltd, Hyderabad, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Woosong University
RP Madichetty, S (corresponding author), Centific, Hyderabad, India.
EM sreea568@gmail.com; msridevi@nitt.edu; mr.sreekanth2008@gmail.com
RI Madisetty, Sreekanth/AAF-1408-2020; Madichetty, Sreedhar/N-9849-2017
OI Madichetty, Sreedhar/0000-0002-0373-9092
CR Aipe A., 2018, P 15 ISCRAM C
   Alam F, 2018, AAAI C WEB SOCIAL ME
   Alam F, 2018, 12 INT AAAI C WEB SO, P465, DOI DOI 10.1609/ICWSM.V12I1.14983
   Alam F, 2020, BEHAV INFORM TECHNOL, V39, P288, DOI 10.1080/0144929X.2019.1610908
   [Anonymous], 2016, INT C INF SYST CRIS
   [Anonymous], 2017, P MEDIAEVAL 2017 WOR
   Ashktorab Z., 2014, P 11 INT ISCRAM C, P269
   Batool R, 2013, 2013 IEEE/ACIS 12TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P461, DOI 10.1109/ICIS.2013.6607883
   Berahmand K, 2022, CLUSTER COMPUT, V25, P869, DOI 10.1007/s10586-021-03430-0
   Caragea C., 2014, ISCRAM 2014 C P 11 I, P642
   da Silva NFF, 2014, DECIS SUPPORT SYST, V66, P170, DOI 10.1016/j.dss.2014.07.003
   Da Silva NFF, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2932708
   Fan C, 2020, IEEE ACCESS
   Gautam AK, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P94, DOI [10.1109/BigMM.2019.00-38, 10.1109/BigMM.2019.00024]
   Houston JB, 2015, DISASTERS, V39, P1, DOI 10.1111/disa.12092
   Li QZ, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2016), P568, DOI [10.1109/WI.2016.96, 10.1109/WI.2016.0097]
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Madichetty S, 2019, INT CONF COMMUN SYST, P709, DOI [10.1109/COMSNETS.2019.8711095, 10.1109/comsnets.2019.8711095]
   Maiya A. S., 2020, Published online, DOI DOI 10.48550/ARXIV.2004.10703
   Moumtzidou A., 2018, P MEDIAEVAL 2018 WOR
   Nalluru Ganesh., 2019, Classifying relevant social media posts during disasters using ensemble of domain-agnostic and domain-specific word embeddings
   Nguyen Dat T., 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P569, DOI 10.1145/3110025.3110109
   Nizzoli L, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P203, DOI 10.1145/3292522.3326050
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rudra K, 2018, ACM T WEB, V12, DOI 10.1145/3178541
   Rudra K, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P96, DOI 10.1109/ASONAM.2016.7752219
   Siddiqua UA, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1868
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stefan I., 2019, RoCHI, P46
   Stowe K., 2016, P 4 INT WORKSHOP NAT, P1, DOI DOI 10.18653/V1/W16-6201
   To H, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P330, DOI 10.1109/BigMM.2017.82
NR 32
TC 4
Z9 4
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 29
PY 2023
DI 10.1007/s11042-023-14780-9
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C2QK9
UT WOS:000960423600010
DA 2024-07-18
ER

PT J
AU Chetih, N
   Boutiche, Y
   Ramou, N
   Khorchef, M
AF Chetih, Nabil
   Boutiche, Yamina
   Ramou, Naim
   Khorchef, Mohammed
TI Efficient and robust level set model for extracting regions of interest
   in X-ray welding images and MRI brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conventional level set (CLS); Possibilistic c-means clustering (PCMC);
   Image segmentation; Region of interest (ROI); X-ray welding images; MRI
   brain images
ID ACTIVE CONTOUR MODEL; FUZZY C-MEANS; SEGMENTATION; EVOLUTION; DRIVEN
AB Extraction the region of interest (ROI) from the X-ray welding images and MRI brain images is extremely challenging due to their poor quality, low contrast, high noise and blurry boundaries. The level set technique is one of the most often employed in this field, but its main problem is the initial contour selection. To solve this problem and obtain reliable and accurate extraction of ROI, we propose in this work an efficient and robust level set model (ERLSM). More specifically, our model is a hybrid between the conventional level set method (CLS) and the possibilistic c-means clustering (PCMC) method. The main idea of PCMC is to initially divide the input image into clusters. Then, the obtained results are used to initialize and estimate the controlling parameters of the CLS method. Experimental results on X-ray welding images and MRI brain images show that the ERLSM model offers very good performance and confirms its efficiency and robustness against image noise. Moreover, the proposed model has the advantage of high computational speed under different processing conditions. It is able to extract ROIs with high accuracy after very few iterations and eliminates the sensitivity problem of CLS to the initial contour.
C1 [Chetih, Nabil; Boutiche, Yamina; Ramou, Naim; Khorchef, Mohammed] Res Ctr Ind Technol CRTI, POB 64, Cheraga 16014, Algiers, Algeria.
RP Chetih, N (corresponding author), Res Ctr Ind Technol CRTI, POB 64, Cheraga 16014, Algiers, Algeria.
EM chetih.tsi@gmail.com
CR Anami BS, 2013, COMP VIS PATT REC IM, P1, DOI DOI 10.1109/NCVPRIPG.2013.6776216
   Aswathy SU., 2015, INDIAN J SCI TECHNOL, V8, P1, DOI 10.17485/ijst/2015/v8i34/85361
   Baghdadi M, 2017, INT J IMAG SYST TECH, V27, P281, DOI 10.1002/ima.22233
   Ben Gharsallah M, 2015, ADV MATER SCI ENG, V2015, DOI 10.1155/2015/871602
   Bezdek James C., 1981, PATTERN RECOGN
   BEZDEK JC, 1993, MED PHYS, V20, P1033, DOI 10.1118/1.597000
   Boudani FZ, 2019, 2019 INTERNATIONAL CONFERENCE ON ADVANCED ELECTRICAL ENGINEERING (ICAEE), DOI 10.1109/icaee47123.2019.9015093
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Chetih N, 2017, 2017 EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER SCIENCE (EECS), P188, DOI 10.1109/EECS.2017.43
   Chetih N, 2018, IET IMAGE PROCESS, V12, P652, DOI 10.1049/iet-ipr.2017.0399
   Dera D, 2016, B MATH BIOL, V78, P1450, DOI 10.1007/s11538-016-0190-0
   El-Melegy MT, 2020, IEEE INT CONF FUZZY, DOI 10.1109/fuzz48607.2020.9177563
   Fang JM, 2019, J MATER ENG PERFORM, V28, P4467, DOI 10.1007/s11665-019-04168-y
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Fedkiw R., 2003, LEVEL SET METHODS DY
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Goumeidane AB, 2015, J X-RAY SCI TECHNOL, V23, P289, DOI 10.3233/XST-150488
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Khadidos A, 2017, IEEE T IMAGE PROCESS, V26, P1979, DOI 10.1109/TIP.2017.2666042
   Khosravanian A, 2022, MULTIMED TOOLS APPL, V81, P21719, DOI 10.1007/s11042-022-12445-7
   Krishnapuram R, 1996, IEEE T FUZZY SYST, V4, P385, DOI 10.1109/91.531779
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P98, DOI 10.1109/91.227387
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li BN, 2009, IFMBE PROC, V23, P202
   Li CM, 2005, PROC CVPR IEEE, P430
   Li DX, 2019, IEEE T BIO-MED ENG, V66, P1884, DOI 10.1109/TBME.2018.2880733
   Li HF, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102845
   Masood A., 2013, LEVEL SET INITIALIZA, P341
   Menard M, 2000, PATTERN RECOGN, V33, P1219, DOI 10.1016/S0031-3203(99)00110-7
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Ramou N, 2018, ARAB J SCI ENG, V43, P7167, DOI 10.1007/s13369-017-3031-z
   Reddy G. Raghotham, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P522, DOI 10.1109/ICCSP.2011.5739377
   Sethian J., 1999, LEVEL SET METHODS FA
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Soomro S, 2019, EXPERT SYST APPL, V120, P387, DOI 10.1016/j.eswa.2018.10.052
   Sowmyalakshmi R, 2020, LEC NO MULTI IND ENG, P409, DOI 10.1007/978-981-32-9433-2_36
   Sran PK, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102964
   Srikanth R, 2022, MULTIMED TOOLS APPL, V81, P20963, DOI 10.1007/s11042-022-12344-x
   Virupakshappa, 2019, COGN TECHNOL WORK, V21, P357, DOI 10.1007/s10111-018-0472-4
   Wang ZB, 2021, ARCH COMPUT METHOD E, V28, P2429, DOI 10.1007/s11831-020-09463-9
   Yu CY, 2013, COMPUT MATH APPL, V65, P1746, DOI 10.1016/j.camwa.2013.03.021
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhang YY, 2014, IEEE T IMAGE PROCESS, V23, P97, DOI 10.1109/TIP.2013.2286901
   Zheng ZZ, 2020, IEEE ACCESS, V8, P112674, DOI 10.1109/ACCESS.2020.3003089
   Zhi XH, 2018, PATTERN RECOGN, V80, P241, DOI 10.1016/j.patcog.2018.03.010
NR 52
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31775
EP 31792
DI 10.1007/s11042-023-15142-1
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000984793600001
DA 2024-07-18
ER

PT J
AU Roberti, WC Jr
   Pereira, LT
   Silva, RLS
   Moreno, MF
AF Roberti, Wellingston C., Jr.
   Pereira, Lidiane T.
   Silva, Rodrigo L. S.
   Moreno, Marcelo F.
TI U-DiVE - design and evaluation of a distributed photorealistic virtual
   reality environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Photorealism; Virtual reality; Ray tracing; Mobile device; Distributed
   environment
ID LATENCY
AB Mobile devices such as smartphones are increasingly being used for immersive content consumption, mostly involving 360(o_) video and 3D audio media delivery. However these smartphones, especially low-cost ones, are still not able to provide the processing and battery power needed for a real-time rendering, visualization and interaction with photorealistic virtual reality scenes. In this context, this paper proposes and evaluates U-DiVE (Unity-based Distributed Virtual Reality Environment), a framework that decouples the processing and rendering processes from the delivery, visualization and interaction with realistic VR models. The U-DiVE framework produces a photorealistic scene using a general ray-tracing algorithm and a virtual reality camera configured to use barrel shaders to correct the lens distortion, allowing the visualization through inexpensive smartphone-based head-mount displays. The framework also includes a method to obtain the smartphone's spatial orientation to control the user's field of view, which is delivered via real-time WebRTC streaming. The analysis show U-DiVE allows for the real-time visualization and manipulation of realistic, immersive scenes via smartphone-based, low-cost head-mounted displays, with low end-to-end latency, considering the required continuous data processing and delivery.
C1 [Roberti, Wellingston C., Jr.; Pereira, Lidiane T.; Silva, Rodrigo L. S.; Moreno, Marcelo F.] Univ Fed Juiz de Fora, Postgrad Program Comp Sci, Juiz De Fora, MG, Brazil.
C3 Universidade Federal de Juiz de Fora
RP Silva, RLS (corresponding author), Univ Fed Juiz de Fora, Postgrad Program Comp Sci, Juiz De Fora, MG, Brazil.
EM junimduic@hotmail.com; lidianepereira@ice.ufjf.br;
   rodrigoluis@ice.ufjf.br; moreno@ice.ufjf.br
OI Moreno, Marcelo/0000-0002-0030-0885
CR Ahmadi H, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P170, DOI 10.1145/3126686.3126743
   [Anonymous], 2014, INFORM TECHNOLOGY 1
   Bergkvist A., 2012, Working draft, W3C, V91
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Csongei M., 2014, GLOBAL ILLUMINATION, DOI [10.1109/VR.2014.6802055, DOI 10.1109/VR.2014.6802055]
   El-Ganainy T, 2016, Arxiv, DOI arXiv:1612.08350
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Freniere ER, 1997, P SOC PHOTO-OPT INS, V3130, P170, DOI 10.1117/12.284059
   Friston S, 2014, IEEE T VIS COMPUT GR, V20, P616, DOI 10.1109/TVCG.2014.30
   Glassner A. S., 1989, INTRO RAY TRACING
   Godoy AP, 2014, P 20 BRAZILIAN S MUL, P143
   Gunkel SNB, 2022, Arxiv, DOI arXiv:2201.05552
   Gunkel SNB, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P65, DOI 10.1145/3458305.3459595
   He D, 2000, INT IMM PROJ TECHN W, V111
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Jacobs M. C., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P49, DOI 10.1145/253284.253306
   Jung GS, 2006, LECT NOTES COMPUT SC, V3942, P797, DOI 10.1007/11736639_98
   Junior WCR, 2020, SYMP VIRTUAL AUGMENT, P406, DOI 10.1109/SVR51698.2020.00067
   Lee W-J, 2013, SIGGRAPH AS 2013 S M, P1
   Li Z.-N., 2004, Fundamentals of Multimedia
   Liang J., 1991, UIST Fourth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P19, DOI 10.1145/120782.120784
   Loreto S, 2012, IEEE INTERNET COMPUT, V16, P68, DOI 10.1109/MIC.2012.115
   Miller D, 2002, P SPIE, V4660
   Mine MR, 1993, TR93001 U N CAR CHAP
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   Prakash S, 2019, P 17 ANN INT C MOBIL, P142
   Prins Martin J, 2018, SMPTE Motion Imaging Journal, V127, P39, DOI DOI 10.5594/JMI.2018.2840618
   Rohmer K, 2014, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2014.6948406
   Salehi S, 2020, Arxiv, DOI arXiv:2011.09035
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Steed A., 2008, P 2008 ACM S VIRT RE, P123, DOI [10.1145/1450579.1450606, DOI 10.1145/1450579.1450606]
   Whitted T., 1998, IMPROVED ILLUMINATIO, P119
   Won-Jong Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P355, DOI 10.1109/ICCE.2017.7889353
   Yoo S, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010987
NR 34
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34129
EP 34145
DI 10.1007/s11042-023-15064-y
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000983485500002
OA Green Published
DA 2024-07-18
ER

PT J
AU Iqbal, N
   Hussain, I
   Khan, MA
   Abbas, S
   Yousaf, S
AF Iqbal, Nadeem
   Hussain, Ibrar
   Khan, Muhammad Adnan
   Abbas, Sagheer
   Yousaf, Shahid
TI An efficient image cipher based on the 1D scrambled image and 2D
   logistic chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 1D scrambled image; Encryption; Decryption; Image processing; 2D chaotic
   map
ID ENCRYPTION ALGORITHM; DNA ENCRYPTION; CRYPTANALYSIS; MATRIX;
   IMPROVEMENT; SYSTEMS
AB Researchers have paid increasing attention towards the usage of scrambled image for the image encryption in recent years. 2D and 3D scrambled images have already been employed to write the different image encryption algorithms. On the other hand, we need speedy and efficient ciphers to meet the rising demands of our society. The current study has used 1D scrambled image to develop a novel and a speedy image encryption algorithm. As the gray scale image is given to the encryption algorithm, its pixels are inserted randomly to the different positions of the scrambled image. This act has been iterated for a number of times. To throw the diffusion effects in the proposed cipher, Exclusive-OR (XOR) operation has been carried out. 2D logistic map has been selected for the chaotic vectors. First vector served the purpose of scrambling and the second one, the purpose of diffusion. The average time taken by the proposed image cipher is 0.0997 seconds, the information entropy of the cipher image came out to be 7.9975 and the number of pixels change rate (NPCR) is 99.6048%. Simulation and an exhaustive performance analyses depict that the proposed scheme has the desirable security effects and has the prospects for some real world application.
C1 [Iqbal, Nadeem; Yousaf, Shahid] Univ Lahore, Dept Comp Sci, IT, Lahore, Pakistan.
   [Hussain, Ibrar] Univ Lahore, Dept Software Engn, Lahore, Pakistan.
   [Khan, Muhammad Adnan] Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
   [Abbas, Sagheer] Natl Coll Business Adm, Dept Comp Sci, Econ, Lahore, Pakistan.
C3 University of Lahore; University of Lahore; Gachon University
RP Khan, MA (corresponding author), Gachon Univ, Dept Software, Pattern Recognit & Machine Learning Lab, Seongnam 13557, South Korea.
EM nadeem.iqbal537@gmail.com; adnan@gachon.ac.kr
RI Abbas, Dr.Sagheer/AAB-1365-2020; Hussain, Ibrar/ACF-9272-2022; Khan,
   Muhammad Adnan/GLU-1911-2022
OI Abbas, Dr.Sagheer/0000-0001-5289-7831; hussain,
   ibrar/0000-0001-6118-0314; Khan, Muhammad Adnan/0000-0003-4854-9935;
   Iqbal, Nadeem/0000-0002-0954-5563
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Murillo-Escobar MA, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080815
   Bashir Z, 2022, MULTIMED TOOLS APPL, V81, P3867, DOI 10.1007/s11042-021-11687-1
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Boreale M, 2020, SCI COMPUT PROGRAM, V193, DOI 10.1016/j.scico.2020.102441
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen JX, 2020, INFORM SCIENCES, V520, P130, DOI 10.1016/j.ins.2020.02.024
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Eckmann J.-P., 2004, The Theory of Chaotic Attractors, P273, DOI DOI 10.1007/978-0-387-21830-4_17
   ElKamchouchi DH, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020180
   Fournier-Prunaret D., 2003, ARXIV
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Hanif M, 2020, IEEE ACCESS, V8, P146408, DOI 10.1109/ACCESS.2020.3015085
   Hanif M, 2020, IEEE ACCESS, V8, P123536, DOI 10.1109/ACCESS.2020.3004536
   Huang HQ, 2020, IET IMAGE PROCESS, V14, P1157, DOI 10.1049/iet-ipr.2019.0551
   Iqbal N, 2022, MULTIMED TOOLS APPL, V81, P8107, DOI 10.1007/s11042-022-11912-5
   Iqbal N, 2021, IEEE ACCESS, V9, P118253, DOI 10.1109/ACCESS.2021.3106028
   Iqbal N, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102809
   Iqbal N, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023025
   Iqbal N, 2019, IEEE ACCESS, V7, P174051, DOI 10.1109/ACCESS.2019.2956389
   Iqbal N, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P383, DOI [10.1109/CCOMS.2019.8821642, 10.1109/ccoms.2019.8821642]
   Kahan W., 1996, Lect. Not. Status IEEE 754 (94720-1776), V754, P94720
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Liu LF, 2018, IET SIGNAL PROCESS, V12, P22, DOI 10.1049/iet-spr.2016.0584
   Liu MZ, 2019, J INTERNET TECHNOL, V20, P2141, DOI 10.3966/160792642019122007012
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Malik MGA, 2020, IEEE ACCESS, V8, P88093, DOI 10.1109/ACCESS.2020.2990170
   Mani N, 2021, INT J SOFTW SCI COMP, V13, P72, DOI 10.4018/IJSSCI.2021010105
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Mirsadeghi F, 2021, PEER PEER NETW APPL, V14, P2537, DOI 10.1007/s12083-020-01010-4
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sivakumar T, 2016, J INF SCI ENG, V32, P133
   Strogatz S.H., 2018, Nonlinear dynamics and chaos: with applications to physics, biology, chemistry, and engineering, DOI [10.1201/9780429492563, DOI 10.1201/9780429492563]
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Hoang TM, 2018, OPTIK, V155, P366, DOI 10.1016/j.ijleo.2017.10.072
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xian YJ, 2021, INFORM SCIENCES, V547, P1154, DOI 10.1016/j.ins.2020.09.055
   Xiong ZG, 2019, MULTIMED TOOLS APPL, V78, P31035, DOI 10.1007/s11042-018-7081-3
   Xu M, 2019, INFORM SCIENCES, V478, P1, DOI 10.1016/j.ins.2018.11.010
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Zaman J., 2012, Journal of Theoretical Physics and Cryptography, V1, P18
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
   Zhu CX, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10090399
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 57
TC 4
Z9 4
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40345
EP 40373
DI 10.1007/s11042-023-15037-1
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000956325500001
DA 2024-07-18
ER

PT J
AU Xu, QZ
   Qiao, H
   Liu, S
   Liu, SQ
AF Xu, Qingzhen
   Qiao, Han
   Liu, Shuang
   Liu, Shouqiang
TI Deepfake detection based on remote photoplethysmography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Deepfake detection; rRRG; DeepPhys
AB Deepfake, which superimpose an image of one person's face on another person's image. However, the number of malicious Deepfake uses is largely dominant. Deepfake technology has also improved in recent years, making previously effective detection methods less effective in the new fake videos. There is currently not a very effective Deepfake detection method. DeepPhys is an end-to-end system based on deep convolutional network, which can be used to remotely measure biological signals such as human heart rate and respiratory rate in video. In this paper, we first introduce the Deepfake and its background, the current mainstream Deepfake detection methods and the related research situation. Then, we introduce the Remote Photoplethysmography(rPPG) and introduce the method of Deepfake detection based on rPPG. Then it introduces the traditional method of rPPG and the specific implementation method of DeepPhys, and then compares the gap between DeepPhys and traditional rPPG. Finally, by comparing with several state-of-the art rPPG methods, the DeepPhys model trained in this experiment can better detect the biological information in the video and achieve a high availability.
C1 [Xu, Qingzhen; Qiao, Han; Liu, Shuang] South China Normal Univ, Sch Comp, Guangzhou, Peoples R China.
   [Liu, Shouqiang] South China Normal Univ, Fac Engn, Sch Artificial Intelligence, Guangzhou, Peoples R China.
C3 South China Normal University; South China Normal University
RP Liu, SQ (corresponding author), South China Normal Univ, Fac Engn, Sch Artificial Intelligence, Guangzhou, Peoples R China.
EM xqz1997@126.com; han@m.scnu.edu.cn; 2818434355@qq.com;
   liusq@m.scnu.edu.cn
FU Guangzhou Science and Technology Plan Project [201903010103]; "13th
   Five-Year Plan" for the development of Philosophy and Social Sciences in
   Guangzhou [2018GZYB36]; Science Foundation of Guangdong Provincial
   Communications Department, China [N2015-02-064]; Ministry of Education's
   2018 first batch of Industry-University Cooperation Collaborative
   Education Information Security curriculum system construction projects
   [201801087012]
FX The Project was supported by Guangzhou Science and Technology Plan
   Project (No.201903010103), the "13th Five-Year Plan" for the development
   of Philosophy and Social Sciences in Guangzhou (No.2018GZYB36), Science
   Foundation of Guangdong Provincial Communications Department, China
   (No.N2015-02-064), The Ministry of Education's 2018 first batch of
   Industry-University Cooperation Collaborative Education Information
   Security curriculum system construction projects (201801087012).
CR Chen WX, 2018, LECT NOTES COMPUT SC, V11206, P356, DOI 10.1007/978-3-030-01216-8_22
   de Haan G, 2014, PHYSIOL MEAS, V35, P1913, DOI 10.1088/0967-3334/35/9/1913
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Dolhansky B, 2019, ARXIV
   Dong X., 2020, arXiv
   Goodfellow I. J., 2014, ARXIV
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hernandez-Ortega J., 2020, arXiv
   Hernandez-Ortega J, 2020, P INT COMP SOFTW APP, P1438, DOI 10.1109/COMPSAC48688.2020.00-53
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Lam A, 2015, IEEE I CONF COMP VIS, P3640, DOI 10.1109/ICCV.2015.415
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2017, ADV NEUR IN, V30
   Masi Iacopo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P667, DOI 10.1007/978-3-030-58571-6_39
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Mirsky Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3425780
   Monkaresi H, 2014, IEEE J BIOMED HEALTH, V18, P1153, DOI 10.1109/JBHI.2013.2291900
   Osman Ahmed, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163150
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Pokroy AA, 2021, IEEE NW RUSS YOUNG, P598, DOI 10.1109/ElConRus51938.2021.9396092
   Qian Y., 2020, EUROPEAN C COMPUTER, V12357, P86, DOI 10.1007/978-3- 030-58610-2 6
   Sun C, 2019, PHYSICA A, V532, DOI 10.1016/j.physa.2019.121812
   Tolosana R., 2020, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang WJ, 2017, IEEE T BIO-MED ENG, V64, P1479, DOI 10.1109/TBME.2016.2609282
   Wang WJ, 2015, IEEE T BIO-MED ENG, V62, P415, DOI 10.1109/TBME.2014.2356291
   Xiang J, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P424, DOI 10.1109/ICISCE.2017.95
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yu Z., 2019, arXiv
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 30
TC 1
Z9 1
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35439
EP 35456
DI 10.1007/s11042-023-14744-z
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000956327700006
DA 2024-07-18
ER

PT J
AU Kumar, P
   Purohit, G
   Tanwar, PK
   Kota, SR
AF Kumar, Prashant
   Purohit, Gaurav
   Tanwar, Pramod Kumar
   Kota, Solomon Raju
TI Feasibility analysis of convolution neural network models for
   classification of concrete cracks in Smart City structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network model; Transfer learning; Image
   pre-processing; Global standardization; Clipping and rescaling pixel
   values; Confusion matrix; VGG-16; Inception-v3; ResNet-50; DenseNet-121;
   Xception; InceptionResNet-v2
AB Cracks are one of the forms of damage to concrete structures that debase the strength and durability of the building material and may pose a danger to the living being associated with it. Proper and regular diagnosis of concrete cracks is therefore necessary. Nowadays, for the more accurate identification and classification of cracks, various automated crack detection techniques are employed over a manual human inspection. Convolution Neural Network (CNN) has shown excellent performance in image processing. Thus, it is becoming the mainstream choice to replace the manual crack classification techniques, but this technique requires huge labeled data for training. Transfer learning is a strategy that tackles this issue by using pre-trained models. This work first time strives to classify concrete surface cracks by re-training of six pre-trained deep CNN models such as VGG-16, DenseNet-121, Inception-v3, ResNet-50, Xception, and InceptionResNet-v2 using transfer learning and comparing them with different metrics, such as Accuracy, Precision, Recall, F1-Score, Cohen Kappa, ROC AUC, and Error Rate in order to find the model with the best suitability. A dataset from two separate sources is considered for the re-training of pre-trained models, for the classification of cracks on concrete surfaces. Initially, the selective crack and non-crack images of the Mendeley dataset are considered, and later, a new dataset is used. As a result, the re-trained classifier of CNN models provides a consistent performance with an accuracy range of 0.95 to 0.99 on the first dataset and 0.85 to 0.98 on the new dataset. The results show that these CNN variants can produce the best outcome when finding cracks in the real situation and have strong generalization capabilities.
C1 [Kumar, Prashant; Purohit, Gaurav; Tanwar, Pramod Kumar] CSIR, Cent Elect Engn Res Inst, Pilani 333031, Rajasthan, India.
   [Kumar, Prashant; Purohit, Gaurav; Tanwar, Pramod Kumar; Kota, Solomon Raju] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
   [Kota, Solomon Raju] CSIR, Natl Aerosp Labs, Bengaluru 560017, Karnataka, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Electronics Engineering Research Institute (CEERI); Academy of
   Scientific & Innovative Research (AcSIR); Council of Scientific &
   Industrial Research (CSIR) - India; CSIR - National Aerospace
   Laboratories (NAL)
RP Kumar, P (corresponding author), CSIR, Cent Elect Engn Res Inst, Pilani 333031, Rajasthan, India.; Kumar, P (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
EM prashant.mnnit10@gmail.com
RI Kumar, Prashant/AAC-2412-2022
OI Kumar, Prashant/0000-0002-7902-8924
FU All India Council of Technical Education, New Delhi, India; Indian
   National Academy of Engineering (INAE), Gurgaon, India
FX The work of Prashant Kumar was supported in part by the All India
   Council of Technical Education, New Delhi, India, and in part by the
   Indian National Academy of Engineering (INAE), Gurgaon, India.
CR Athanasiou A, 2020, COMPUT-AIDED CIV INF, V35, P565, DOI 10.1111/mice.12509
   Brownlee J., 2019, Machine Learning Mastery
   Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Cho, 2019, SMAR 2019 5 C SMART
   Developers S-L, 2020, SCIK LEARN
   Dorafshan S, 2018, CONSTR BUILD MATER, V186, P1031, DOI 10.1016/j.conbuildmat.2018.08.011
   Gao YQ, 2018, COMPUT-AIDED CIV INF, V33, P748, DOI 10.1111/mice.12363
   Huang HW, 2018, TUNN UNDERGR SP TECH, V77, P166, DOI 10.1016/j.tust.2018.04.002
   Islam MT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010169
   Jung NLWM, 2019, CHIN CONTR CONF
   Kim A-R, 2019, ADV STRUCT ENG MECH
   Kim B, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103452
   Kim H, 2019, STRUCT HEALTH MONIT, V18, P725, DOI 10.1177/1475921718768747
   Koch C, 2015, ADV ENG INFORM, V29, P196, DOI 10.1016/j.aei.2015.01.008
   Li SM, 2019, AM J ROENTGENOL, V212, P950, DOI 10.2214/AJR.18.20414
   Liu H, 2019, MEASUREMENT, V133, P168, DOI 10.1016/j.measurement.2018.09.081
   Moon H.G., 2011, P 28 INT S AUTOMATIO, P1461, DOI DOI 10.22260/ISARC2011/0279
   Hoang ND, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7913952
   Ozgenel CF, 2018, IS P INT S AUT ROB C, V35, P1, DOI DOI 10.22260/ISARC2018/0094
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Perez H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163556
   Qian YF, 2019, 2019 2ND IEEE INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND SIGNAL PROCESSING (ICICSP), P415, DOI [10.1109/icicsp48821.2019.8958529, 10.1109/ICICSP48821.2019.8958529]
   Qu Z, 2019, IEEE ACCESS, V7, P57592, DOI 10.1109/ACCESS.2019.2914259
   Rajeshwari M, 2018, SSRG INT J COMPUT SC, V5, P6, DOI [10.14445/23488387/IJCSE-V5I5P102, DOI 10.14445/23488387/IJCSE-V5I5P102]
   Sagar RV, 2019, SUPPORT VECTOR MACHI
   Scholar P. G., 2021, Int. J. Appl. Eng. Res., V13, P6056
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Shi CP, 2020, IEEE ACCESS, V8, P154436, DOI 10.1109/ACCESS.2020.3016116
   Shibing Wang, 2018, IOP Conference Series: Earth and Environmental Science, V189, DOI 10.1088/1755-1315/189/2/022005
   Silva W. R. L. D., 2018, PROCEEDINGS, V2, DOI [https://doi.org/10.3390/ICEM18-05387, DOI 10.3390/ICEM18-05387]
   Simler C, 2019, PROC SPIE, V11144, DOI 10.1117/12.2531951
   Slonski M., 2019, COMPUT ASSIST METHOD, V26, P105, DOI DOI 10.24423/CAMES.267
   Raj APSS, 2019, IET IMAGE PROCESS, V13, P2176, DOI 10.1049/iet-ipr.2019.0346
   Wang BX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030614
   Wu X, 2020, IEEE ACCESS, V8, P156792, DOI 10.1109/ACCESS.2020.3019484
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xu GW, 2019, IEEE ACCESS, V7, P112767, DOI 10.1109/ACCESS.2019.2930958
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   Zhang JM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132686
   Zhang KG, 2021, IEEE T INTELL TRANSP, V22, P1306, DOI 10.1109/TITS.2020.2990703
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
   Zhu JS, 2020, STRUCT INFRASTRUCT E, V16, P1037, DOI 10.1080/15732479.2019.1680709
NR 42
TC 2
Z9 3
U1 4
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38249
EP 38274
DI 10.1007/s11042-023-15136-z
EA MAR 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000955293100011
DA 2024-07-18
ER

PT J
AU Wang, H
   Dong, BX
   Ke, HC
   Qi, QQ
   Liu, G
AF Wang, Hui
   Dong, Boxin
   Ke, Hongchang
   Qi, Qianqian
   Liu, Gang
TI A novel image shift encryption algorithm based on the dynamic Joseph
   ring problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joseph ring; Image encryption algorithm; Shift encryption; Information
   security
AB Image encryption can effectively prevent unauthorized users from stealing personal information. Attackers usually analyze the information of the encrypted image according to the strong correlation between image pixels and use it as the breakthrough point of the image encryption algorithm. How to destroy the strong correlation of pixels is a hot topic of current research. In this paper, we propose a novel and simple encryption scheme that is no less effective than other algorithms, called Joseph shift encryption (JSE). To enhance the effectiveness of image encryption, we propose the static Joseph shift encryption (S-JSE) and the dynamic Joseph shift encryption (D-JSE) algorithms. S-JSE can decrease the dimension of the image and shift with the generated Joseph sequence group, then the encrypted image can be generated. D-JSE can increase the number of iterations on the basis of S-JSE, and the Joseph sequence of each iteration is different. Furthermore, the encrypted sequence is scrambled according to the Joseph mapping table and upgraded the dimension to complete the encryption. We analyze the effectiveness of the proposed S-JSE including the impact of the key selection on the effect of image encryption, and the encryption security. Thereafter, we utilize the proposed D-JSE to improve the security of grayscale and color image and verify the effectiveness of the proposed algorithm by extensive and comprehensive experiments in terms of correctness verification, histogram equalization and information entropy, adjacent pixel correlation, plaintext sensitivity, key sensitivity, encrypted image anti-interference, key space, encryption time and defense against special image attacks
C1 [Wang, Hui; Dong, Boxin; Qi, Qianqian; Liu, Gang] ChangChun Univ Technol, Changchun 130012, Peoples R China.
   [Ke, Hongchang] Changchun Inst Technol, Changchun 130012, Peoples R China.
C3 Changchun University of Technology; Changchun Institute Technology
RP Ke, HC (corresponding author), Changchun Inst Technol, Changchun 130012, Peoples R China.
EM kehongchang1981@163.com
RI Liu, Gang/AAU-3119-2020
OI Liu, Gang/0000-0002-0489-2638; Ke, Hongchang/0000-0003-0946-9289
FU Natural Science Foundation Project of Jilin Provincial Department of
   Science and Technology [YDZJ202201ZYTS556]; Jilin Province Education
   Department Scientific Research Planning Foundation of China
   [JJKH20210753KJ, JJKH20200618KJ]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation Project of Jilin Provincial Department of Science and
   Technology(YDZJ202201ZYTS556), the Jilin Province Education Department
   Scientific Research Planning Foundation of China (JJKH20210753KJ,
   JJKH20200618KJ).
CR Abdeljawad T, 2020, OPTIK, V218, DOI 10.1016/j.ijleo.2019.163698
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Balasamy K, 2021, MULTIMED TOOLS APPL, V80, P7167, DOI 10.1007/s11042-020-09981-5
   Bashir Z, 2021, MULTIMED TOOLS APPL, V80, P1029, DOI 10.1007/s11042-020-09695-8
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chai ZQ, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1167-5
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   Gupta M, 2021, MULTIMED TOOLS APPL, V80, P10391, DOI 10.1007/s11042-020-10116-z
   Haider MI, 2021, MULTIMED TOOLS APPL, V80, P4693, DOI 10.1007/s11042-020-09892-5
   Hosny KM, 2022, J AMB INTEL HUM COMP, V13, P973, DOI 10.1007/s12652-021-03675-y
   Hu Y, 2020, MATH PROBL ENG
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Kang YL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091393
   Krishnan KS, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691320500423
   Kumar S, 2019, MED BIOL ENG COMPUT, V57, P2517, DOI 10.1007/s11517-019-02037-3
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P8721, DOI 10.1007/s11042-020-10117-y
   Li YF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030916
   Li Z, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12091497
   Liu BC, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.3020077
   Liu YJ, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.3001595
   Malik A, 2021, MULTIMED TOOLS APPL, V80, P7911, DOI 10.1007/s11042-020-09973-5
   Malik DS, 2020, MATH COMPUT SIMULAT, V178, P646, DOI 10.1016/j.matcom.2020.07.007
   Mishra Z, 2020, MICROPROCESS MICROSY, V78, DOI 10.1016/j.micpro.2020.103214
   Ghadirli HM, 2021, MULTIMED TOOLS APPL, V80, P8445, DOI 10.1007/s11042-020-10014-4
   Musanna F, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102560
   Naseer Y, 2020, MATH COMPUT SIMULAT, V178, P207, DOI 10.1016/j.matcom.2020.06.007
   Roy SK, 2021, MIN PROC EXT MET REV, V42, P242, DOI 10.1080/08827508.2020.1743290
   Sangavi V, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102626
   Sun YJ, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.3020307
   Tao Y, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102650
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P10301, DOI 10.1007/s11042-020-10101-6
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang Y, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020251
   Yang G, 2014, MATH PROBL ENG
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P691, DOI 10.1007/s11042-020-09779-5
   Yildirim M, 2020, MICROELECTRON J, V104, DOI 10.1016/j.mejo.2020.104878
   Zhang X, 2021, MULTIMED TOOLS APPL, V80, P8809, DOI 10.1007/s11042-020-09465-6
NR 40
TC 2
Z9 2
U1 22
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 39897
EP 39927
DI 10.1007/s11042-023-14947-4
EA MAR 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000954481800001
DA 2024-07-18
ER

PT J
AU Bagla, P
   Kumar, K
AF Bagla, Piyush
   Kumar, Kuldeep
TI A rule-based fuzzy ant colony improvement (ACI) approach for automated
   disease diagnoses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Machine learning; Ant Colony improvement; ACO; Fuzzy logic; Medical
   expert system
ID CLASSIFICATION ALGORITHM; OPTIMIZATION
AB India has approximately seven qualified doctors for every 10,000 people, highlighting the several issues confronting the medical industry, including physician insufficiency, slower pace of diagnosis, and untimely provision of medical aid to common people. Because clinical decision-making requires the highest degree of precision in diagnosis, it is time-consuming and challenging work for physicians. Physicians may benefit significantly from using an automated computing system that aids them in disease diagnosis. Numerous research studies have developed an effective medical expert system to support physicians. However, reaching the highest level of precision remains a challenge. We developed an intelligent medical system based on machine learning and enhancement methodologies because we saw a need to improve diagnostic precision. This research proposes and tests a medical intelligent system design using four different medical datasets. The authors offer a fuzzy logic-based expert system for ACI (Ant Colony Improvement). To develop fuzzy categorization rules, this system uses the ACO approach. The artificial ants create possible fuzzy search criteria, and stochasticity the method encourages ants to develop more accurate rules. The fuzzy inference engine makes conclusions about testing patterns using these updated rules. The suggested system's performance is compared to those of various current systems. With an average accuracy of 93.27% on different datasets, it is discovered that the suggested approach outperforms all existing methodologies for different disease diagnosis datasets.
C1 [Bagla, Piyush] Dr B R Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144027, India.
   [Kumar, Kuldeep] Natl Inst Technol, Dept Comp Engn, Kurukshetra 136119, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; National Institute of Technology (NIT
   System); National Institute of Technology Kurukshetra
RP Bagla, P (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Comp Sci & Engn, Jalandhar 144027, India.
EM piyushb.cs.19@nitj.ac.in; kuldeepkumar@nitkkr.ac.in
RI Bagla, Piyush/KDO-2459-2024; BAGLA, PIYUSH/JFK-8635-2023
OI BAGLA, PIYUSH/0000-0002-1664-7787
CR Aha D, 1987, UC IRVINE MACHINE LE
   Al-Behadili HNK., 2020, INDONESIAN J ELECT E, V8, P149, DOI [10.52549/ijeei.v8i1.1423, DOI 10.52549/IJEEI.V8I1.1423]
   Ali S, 2022, IEEE J BIOMED HEALTH
   [Anonymous], 2002, 6 AUSTR JAP JOINT WO
   [Anonymous], Heart disease dataset
   [Anonymous], 1991, POSITIVE FEEDBACK SE
   [Anonymous], 1993, WEKA 3 MACHINE LEARN
   Baig AR, 2012, NEURAL COMPUT APPL, V21, P219, DOI 10.1007/s00521-010-0490-5
   Basak H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09293-8
   Chan A, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P27
   Chan A, 2006, LECT NOTES COMPUT SC, V3871, P25
   Dash S, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020194
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Dorigo M, 1996, IEEE T SYST MAN CY B, V26, P29, DOI 10.1109/3477.484436
   Dorigo M, 2010, INT SER OPER RES MAN, V146, P227, DOI 10.1007/978-1-4419-1665-5_8
   El-Rashidy N, 2022, NEURAL COMPUT APPL, V34, P3603, DOI 10.1007/s00521-021-06631-1
   El-Sappagh S, 2022, NEURAL COMPUT APPL, V34, P14487, DOI 10.1007/s00521-022-07263-9
   Ganji MF, 2011, EXPERT SYST APPL, V38, P14650, DOI 10.1016/j.eswa.2011.05.018
   He JB, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P819
   Hongxing Wu, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P239, DOI 10.1109/IHMSC.2012.67
   Jin P, 2006, LECT NOTES CONTR INF, V344, P654
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Liang ZP, 2016, APPL SOFT COMPUT, V38, P1000, DOI 10.1016/j.asoc.2015.10.046
   Liu B, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P83
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Nasir H. J. A., 2010, Proceedings 2010 Second International Conference on Computational Intelligence, Modelling and Simulation (CIMSiM 2010), P160, DOI 10.1109/CIMSiM.2010.29
   Nasir Husna Jamal Abdul, 2010, Proceedings of the 2010 Second International Conference on Computer and Network Technology (ICCNT 2010), P207, DOI 10.1109/ICCNT.2010.10
   Nozaki K, 1996, IEEE T FUZZY SYST, V4, P238, DOI 10.1109/91.531768
   Otero FEB, 2008, LECT NOTES COMPUT SC, V5217, P48, DOI 10.1007/978-3-540-87527-7_5
   Otero FEB, 2012, APPL SOFT COMPUT, V12, P3615, DOI 10.1016/j.asoc.2012.05.028
   Otero FEB, 2009, 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, P225, DOI 10.1109/CIDM.2009.4938653
   Parpinelli RS, 2002, IEEE T EVOLUT COMPUT, V6, P321, DOI 10.1109/TEVC.2002.802452
   Prabha GM., 2014, INT J INNOV RES SCI, V3, P1687
   Rajpiplawala S., 2014, IOSR J COMPUT ENG, V16, P63, DOI [10.9790/0661-16326372, DOI 10.9790/0661-16326372]
   Sagban R., 2015, SCI WORLD J, V2015, P1, DOI [10.1155/2015/392345, DOI 10.1155/2015/392345]
   Saian R, 2011, UKSIM EURO SYMP COMP, P70, DOI 10.1109/EMS.2011.17
   Salama KM, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P900
   Salama KM, 2010, LECT NOTES COMPUT SC, V6234, P167, DOI 10.1007/978-3-642-15461-4_15
   Shahzad W, 2010, J CIRCUIT SYST COMP, V19, P297, DOI 10.1142/S0218126610006244
   Shyi-Ching Liang, 2011, 2011 IEEE International Conference on Granular Computing, P390, DOI 10.1109/GRC.2011.6122628
   Smaldon J, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P43
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Thangavel K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL II, PROCEEDINGS, P135, DOI 10.1109/ICCIMA.2007.225
   Tripathy S, 2013, EMERGING RESERCH COM, P1
   Verbeke W, 2011, EXPERT SYST APPL, V38, P2354, DOI 10.1016/j.eswa.2010.08.023
   Vulli A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082988
   Young M., 2002, Technical Writer's Handbook
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 48
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 21
PY 2023
DI 10.1007/s11042-023-15115-4
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A3XA1
UT WOS:000954480900005
DA 2024-07-18
ER

PT J
AU Su, D
   Zhang, C
   Chen, ZS
   Ji, RJ
AF Su, Di
   Zhang, Cheng
   Chen, Zhisheng
   Ji, Ruijing
TI SR-net: satellite relative pose estimation network for a noncooperative
   target via RGB images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Noncooperative target; Pose estimation; CNN; Object detection; Weighted
   least squares
AB Space exploration has drawn increasing attention to space control technology. For debris removal missions and on-orbit servicing, accurate pose estimation of a noncooperative target is critical. This article introduces the satellite relative pose estimation network (SR-Net) two-stage training method for a noncooperative target via RGB images. As the first stage in regressing the 3D translation, we combined the detection and translation regression modules into a single model. SR-Net decouples the translation and rotation information in stage two by utilizing classification instead of regression, using the detected picture as input and fitting a rotation by minimizing the weighted least squares. Furthermore, a large-scale dataset for 6-DoF pose estimation is introduced, which can be utilized as a benchmark for various state-of-the-art monocular vision-based 6-DoF pose estimation methods. Ablation studies are used to verify the effectiveness and scalability of each module. SR-Net can be added to a baseline model as a separate module to improve the 6-DoF pose estimation accuracy for noncooperative targets. The results are extremely encouraging since they show that using only vision data, it is feasible to accurately estimate the 6-DoF pose of a noncooperative target.
C1 [Su, Di; Zhang, Cheng; Chen, Zhisheng; Ji, Ruijing] Beijing Inst Technol, Sch Aerosp Engn, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Zhang, C (corresponding author), Beijing Inst Technol, Sch Aerosp Engn, Beijing 100081, Peoples R China.
EM zhangcheng@bit.edu.cn
CR Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding M, 2011, CHINESE J AERONAUT, V24, P807, DOI 10.1016/S1000-9361(11)60095-2
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kingma D. P., 2014, arXiv
   Kisantal M, 2020, IEEE T AERO ELEC SYS, V56, P4083, DOI 10.1109/TAES.2020.2989063
   Liao X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103244
   Liao X, 2016, SECUR COMMUN NETW, V9, P5756, DOI 10.1002/sec.1734
   Liao X, 2013, IEICE T FUND ELECTR, VE96A, P2731, DOI 10.1587/transfun.E96.A.2731
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2020, CHINESE J AERONAUT, V33, P1494, DOI 10.1016/j.cja.2019.08.024
   Liu Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P221, DOI 10.1109/RCAR.2016.7784029
   Markley FL, 2007, J GUID CONTROL DYNAM, V30, P1193, DOI 10.2514/1.28949
   Park TH, 2019, AASAIAA ASTRODYNAMIC, DOI DOI 10.48550/ARXIV.1909.00392
   Paszke A, 2019, ADV NEUR IN, V32
   Phisannupawong T, 2020, AEROSPACE-BASEL, V7, DOI 10.3390/aerospace7090126
   Proença PF, 2020, IEEE INT CONF ROBOT, P6007, DOI [10.1109/icra40945.2020.9197244, 10.1109/ICRA40945.2020.9197244]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma S, 2020, IEEE T AERO ELEC SYS, V56, P4638, DOI 10.1109/TAES.2020.2999148
   Ventura J., 2016, THESIS TU MUNCHEN
   Wang G, 2021, PROC CVPR IEEE, P16606, DOI 10.1109/CVPR46437.2021.01634
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xu WF, 2011, ADV SPACE RES, V48, P95, DOI 10.1016/j.asr.2011.02.012
   Yann LeCun, 2015, Nature, V521, P436, DOI 10.1038/nature14539
   Zhang HP, 2014, CHINESE J AERONAUT, V27, P1233, DOI 10.1016/j.cja.2014.03.021
NR 24
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31557
EP 31573
DI 10.1007/s11042-023-14791-6
EA MAR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000984224700003
DA 2024-07-18
ER

PT J
AU Amdouni, R
   Gafsi, M
   Abbassi, N
   Hajjaji, MA
   Mtibaa, A
AF Amdouni, Rim
   Gafsi, Mohamed
   Abbassi, Nessrine
   Hajjaji, Mohamed Ali
   Mtibaa, Abdellatif
TI Robust hardware implementation of a block-cipher scheme based on chaos
   and biological algebraic operations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DNA; Chaos; Cryptography; FPGA; PRNG; Hardware implementation
ID IMAGE ENCRYPTION; ALGORITHM
AB Currently, chaos-based cryptosystems are widely used for the reason of protecting sensitive data. Various different chaos-based cryptography systems with software implementation have been studied and documented in the literature. Nevertheless, with the fast growth of the internet and connected objects, the development of hardware secure and low-resource cryptographic systems is required. This article presents an FPGA implementation of a block-cipher image encryption scheme based on different three-dimensional chaotic systems and genetic operations. Our approach is to define a novel approach to block-cipher hardware systems while basing it on the biological characteristics of DNA and chaos. Firstly, a robust chaos-based PRNG based on four 3D chaotic maps is proposed to create high-quality keys. The generated key sequences validate with no fail the NIST SP 800-22 test suite. Furthermore, some biological operations are added in the encryption process such as DNA biological algebraic operations to strengthen the confusion process and improve the complexity of the generated keys. Verily, a very secure block-cipher method is created to perform encryption and decryption of different images. The cryptosystem is implemented and evaluated on a Xilinx ZedBoard Zynq Evaluation and Development Kit platform. The proposed hardware architecture is capable of securing different sizes of gray-scale, medical and RGB color images. As a result, a new hardware architecture is implemented that accomplishes numerical image confusion and diffusion with a good frequency of 194.906 MHz and high throughput of 49,895,936 Mbps. Furthermore, the simulation results show that the encryption system is capable of higher security against cryptographic attacks. The entropy has reached a new high of 7.9998. A comparative study of the suggested algorithm with various new encryption methods shows that our system produces good results and provides better solutions than the state-of-the-art designs.
C1 [Amdouni, Rim; Gafsi, Mohamed; Abbassi, Nessrine; Hajjaji, Mohamed Ali; Mtibaa, Abdellatif] Univ Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.
   [Amdouni, Rim; Gafsi, Mohamed; Mtibaa, Abdellatif] Univ Monastir, Natl Engn Sch Monastir, Monastir, Tunisia.
   [Abbassi, Nessrine] Univ Sousse, Natl Sch Engineers Sousse, Sousse 4054, Tunisia.
   [Hajjaji, Mohamed Ali] Univ Sousse, Higher Inst Appl Sci & Technol, Sousse 4003, Tunisia.
   [Mtibaa, Abdellatif] Univ Sfax, Syst Integrat & Emerging Energies Lab LR 21 ES 14, Sfax, Tunisia.
C3 Universite de Monastir; Universite de Monastir; Universite de Sousse;
   Universite de Sousse; Universite de Sfax
RP Gafsi, M (corresponding author), Univ Monastir, Lab Elect & Microelect, LR99ES30, Monastir 5000, Tunisia.; Gafsi, M (corresponding author), Univ Monastir, Natl Engn Sch Monastir, Monastir, Tunisia.
EM Rimamdouni0@gmail.com; mohammed.elgafsi@gmail.com;
   nessrineabbassi1@gmail.com; mohamedali.hajjaji@issatso.rnu.tn;
   abdellatif.mtibaa@enim.rnu.tn
RI Hajjaji, mohamed/JOK-1304-2023; Gafsi, Mohamed/Y-9538-2018
OI Hajjaji, mohamed/0000-0003-4317-6308; ABBASSI,
   Nessrine/0000-0002-7662-5096; Gafsi, Mohamed/0000-0002-3623-9844
CR Ajili S, 2016, INT J SIGNAL IMAGING, V9, P242, DOI 10.1504/IJSISE.2016.078269
   Ajili S, 2014, 2014 GLOBAL SUMMIT ON COMPUTER & INFORMATION TECHNOLOGY (GSCIT)
   Al-Maadeed TA, 2021, MULTIMED TOOLS APPL, V80, P24801, DOI 10.1007/s11042-021-10695-5
   Al-Musawi WA, 2022, INT J ELECT COMPUTER, V12, DOI [10.11591/ijece.v12i3, DOI 10.11591/IJECE.V12I3]
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Belazi A, 2019, IEEE ACCESS, V7, P36667, DOI 10.1109/ACCESS.2019.2906292
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dridi M, 2016, I C SCI TECH AUTO CO, P772, DOI 10.1109/STA.2016.7952064
   ElBeltagy M, 2022, 2022 IEEE 12TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P716, DOI 10.1109/CCWC54503.2022.9720905
   Gafsi M., 2020, SETIT 2018 SMART INN, V146, P311, DOI DOI 10.1007/978-3-030-21005-2_30
   Gafsi M, 2022, PROCEEDINGS OF THE 2022 5TH INTERNATIONAL CONFERENCE ON ADVANCED SYSTEMS AND EMERGENT TECHNOLOGIES IC_ASET'2022), P324, DOI 10.1109/IC_ASET53395.2022.9765864
   Gafsi M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03555-5
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Hao J, 2021, IEEE ACCESS, V9, P52364, DOI 10.1109/ACCESS.2021.3069977
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Kaur M, 2021, IEEE T GREEN COMMUN, V5, P1223, DOI 10.1109/TGCN.2021.3081616
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Masood F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111893
   Mirsadeghi F, 2021, PEER PEER NETW APPL, V14, P2537, DOI 10.1007/s12083-020-01010-4
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Pitman EJG, 1939, BIOMETRIKA, V31, P9, DOI 10.1093/biomet/31.1-2.9
   Rehman AU, 2019, IEEE ACCESS, V7, P162786, DOI 10.1109/ACCESS.2019.2951749
   Rezk AA, 2019, AEU-INT J ELECTRON C, V98, P174, DOI 10.1016/j.aeue.2018.10.024
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Stalin S, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1389-z
   Syafalni I, 2022, IEEE ACCESS, V10, P7753, DOI 10.1109/ACCESS.2022.3143804
   Telem ANK, 2021, MULTIMED TOOLS APPL, V80, P19011, DOI 10.1007/s11042-021-10549-0
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Xu JJ, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020186
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu F, 2021, FRONT PHYS-LAUSANNE, V9, DOI 10.3389/fphy.2021.690651
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P13841, DOI 10.1007/s11042-020-10437-z
NR 39
TC 2
Z9 2
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15027-3
EA MAR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900007
DA 2024-07-18
ER

PT J
AU Montero, D
   Aranjuelo, N
   Leskovsky, P
   Loyo, E
   Nieto, M
   Aginako, N
AF Montero, David
   Aranjuelo, Nerea
   Leskovsky, Peter
   Loyo, Estibaliz
   Nieto, Marcos
   Aginako, Naiara
TI Multi-camera BEV video-surveillance system for efficient monitoring of
   social distancing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd monitoring; Multi-camera tracking; 2D-3D projection; COVID-19
ID EMERGING TECHNOLOGIES; COMPREHENSIVE SURVEY
AB The current sanitary emergency situation caused by COVID-19 has increased the interest in controlling the flow of people in indoor infrastructures, to ensure compliance with the established security measures. Top view camera-based solutions have proven to be an effective and non-invasive approach to accomplish this task. Nevertheless, current solutions suffer from scalability problems: they cover limited range areas to avoid dealing with occlusions and only work with single camera scenarios. To overcome these problems, we present an efficient and scalable people flow monitoring system that relies on three main pillars: an optimized top view human detection neural network based on YOLO-V4, capable of working with data from cameras at different heights; a multi-camera 3D detection projection and fusion procedure, which uses the camera calibration parameters for an accurate real-world positioning; and a tracking algorithm which jointly processes the 3D detections coming from all the cameras, allowing the traceability of individuals across the entire infrastructure. The conducted experiments show that the proposed system generates robust performance indicators and that it is suitable for real-time applications to control sanitary measures in large infrastructures. Furthermore, the proposed projection approach achieves an average positioning error below 0.2 meters, with an improvement of more than 4 times compared to other methods.
C1 [Montero, David; Aranjuelo, Nerea; Aginako, Naiara] Univ Basque Country, Comp Vis & Artificial Inteligence, Donostia San Sebastian 20018, Guipuzcoa, Spain.
   [Aranjuelo, Nerea; Leskovsky, Peter; Loyo, Estibaliz; Nieto, Marcos] Vicomtech, ITS & Engn, Donostia San Sebastian 20009, Guipuzcoa, Spain.
C3 University of Basque Country
RP Montero, D (corresponding author), Univ Basque Country, Comp Vis & Artificial Inteligence, Donostia San Sebastian 20018, Guipuzcoa, Spain.
EM dmontero005@ikasle.ehu.eus; naranjuelo@vicomtech.org;
   pleskovsky@vicomtech.org; eloyo@vicomtech.org; mnieto@vicomtech.org;
   naiara.aginako@ehu.eus
RI Nieto, Marcos/A-7786-2011
OI Nieto, Marcos/0000-0001-9879-0992; Leskovsky, Peter/0000-0003-4215-051X
FU CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Agarwal N, 2021, SUSTAIN CITIES SOC, V70, DOI 10.1016/j.scs.2021.102942
   Ahmad J, 2019, ADV INTELL SYST, V869, P957, DOI 10.1007/978-3-030-01057-7_71
   Ahmed I, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102571
   Ahmed I, 2021, SUSTAIN CITIES SOC, V69, DOI 10.1016/j.scs.2021.102777
   Ahmed I, 2018, CLUSTER COMPUT, V21, P633, DOI 10.1007/s10586-017-0968-3
   Ahmed I, 2018, IEEE INTERNET THINGS, V5, P1598, DOI 10.1109/JIOT.2017.2787779
   Ali W, 2021, MULTIMED TOOLS APPL, V80, P4825, DOI 10.1007/s11042-020-09850-1
   Annu Malik, 2013, INT J SCI RES PUBLIC, V3
   Aranjuelo N, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107105
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bianco S, 2020, IEEE RAD CONF, DOI 10.1109/radarconf2043947.2020.9266516
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen L, 2021, MULTIMED TOOLS APPL, V80, P6661, DOI 10.1007/s11042-020-10002-8
   Chen SC, 2021, IEEE MULTIMEDIA, V28, P5, DOI 10.1109/MMUL.2021.3063011
   Chu SL, 2022, MULTIMED TOOLS APPL, V81, P1867, DOI 10.1007/s11042-021-11599-0
   Dendorfer P., 2020, ARXIV
   Fernandez-Rincon A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 4, P556, DOI 10.5220/0006169905560564
   Li YK, 2018, IEEE T MULTIMEDIA, V20, P3289, DOI 10.1109/TMM.2018.2834873
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lit S, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014262
   Montero D, 2021, VISAPP VISIGRAPP 202
   Montero D, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902674
   Nguyen CT, 2020, IEEE ACCESS, V8, P153479, DOI 10.1109/ACCESS.2020.3018140
   Nguyen CT, 2020, IEEE ACCESS, V8, P154209, DOI 10.1109/ACCESS.2020.3018124
   Nodehi H, 2022, IEEE T CIRC SYST VID, V32, P147, DOI 10.1109/TCSVT.2021.3059250
   Punn N. S., 2020, ARXIV
   Rahmani AM, 2021, SUSTAIN CITIES SOC, V64, DOI 10.1016/j.scs.2020.102568
   Ramadass L, 2020, INT J PERVASIVE COMP, V16, P223, DOI 10.1108/IJPCC-05-2020-0046
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Rezaei Mahdi, 2020, Applied Sciences, V10, DOI 10.3390/app10217514
   Sathyamoorthy AJ, 2020, ARXIV
   Scheck T, 2020, IEEE WINT CONF APPL, P932, DOI 10.1109/WACV45572.2020.9093563
   Shao ZF, 2022, IEEE T MULTIMEDIA, V24, P2069, DOI 10.1109/TMM.2021.3075566
   Shorfuzzaman M, 2021, SUSTAIN CITIES SOC, V64, DOI 10.1016/j.scs.2020.102582
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Su J, 2021, SUSTAIN CITIES SOC, V68, DOI 10.1016/j.scs.2021.102765
   Su XP, 2022, MULTIMED TOOLS APPL, V81, P4475, DOI 10.1007/s11042-021-11772-5
   Sun CJ, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102390
   Thu TPB, 2020, SCI TOTAL ENVIRON, V742, DOI 10.1016/j.scitotenv.2020.140430
   Uras M, 2020, J CLEAN PROD, V270, DOI 10.1016/j.jclepro.2020.122084
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P1057, DOI 10.1007/s11042-019-08208-6
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Yang D, 2020, ARXIV
   Zhang P., 2019, ARXIV
   Zoph Barret, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P566, DOI 10.1007/978-3-030-58583-9_34
   Zou Z, 2020, MULTIMED TOOLS APPL, V79, P29145, DOI 10.1007/s11042-020-09541-x
NR 46
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34995
EP 35019
DI 10.1007/s11042-023-14416-y
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945313000014
PM 37362701
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sharma, A
   Gautam, R
   Singh, J
AF Sharma, Aanchal
   Gautam, Rahul
   Singh, Jaspal
TI Deep learning for face mask detection: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19; Face mask detection; Deep learning; Machine learning; Object
   detection; Convolutional neural network
ID OBJECT DETECTION; FEATURES
AB The Coronavirus Disease (Covid-19) was declared as a pandemic by WHO (World Health Organization) on 11 March 2020, and it is still currently going on, thereby impacting tremendously the whole world. As of September 2021, more than 220 million cases and 4.56 million deaths have been confirmed, which is a vast number and a significant threat to humanity. Although, As of 6 September 2021, a total of 5,352,927,296 vaccine doses have been administered, still many people worldwide are not fully vaccinated yet. As stated by WHO, "Masks" should be used as one of the measures to restrain the transmission of this virus. So, to reduce the infection, one has to cover their face, and to detect whether a person's face is covered with a mask or not, a "Face mask detection system" is needed. Face Mask Detection falls under the category of "Object Detection," which is one of the sub-domains of Computer Vision and Image Processing. Object Detection consists of both "Image Classification" and "Image Localization". Deep learning is a subset of Machine learning which, in turn, is a subset of Artificial intelligence that is widely being used to detect face masks; even some people are using hybrid approaches to make the most use of it and to build an efficient "Face mask detection system". In this paper, the main aim is to review all the research that has been done till now on this topic, various datasets and Techniques used, and their performances followed by limitations and improvements. As a result, the purpose of this study is to give a broader perspective to a researcher to identify patterns and trends in Face mask detection (Object Detection) within the framework of covid-19.
C1 [Sharma, Aanchal; Gautam, Rahul; Singh, Jaspal] St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Longowal, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET)
RP Gautam, R (corresponding author), St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Longowal, Punjab, India.
EM rahulgautam@sliet.ac.in
RI Gautam, Rahul/HNC-1209-2023; Gautam, Rahul/JPA-5220-2023; Gupta, Sindhu
   Hak/ABH-8530-2020
OI Gautam, Rahul/0000-0002-0845-1688; Gupta, Sindhu Hak/0000-0002-0977-4809
CR Adithya K, 2020, REV FACE MASK DETECT, P1302
   [Anonymous], 2021, WHO COR COVID 19
   [Anonymous], 2021, FEAT ENG IM  VAL INT
   [Anonymous], 2021, Convolutional neural network: a review of models
   [Anonymous], 2021, COVID 19 PAND
   [Anonymous], 2021, ADV PUBL COR DIS COV
   [Anonymous], 2021, MASK US CONT COVID 1
   [Anonymous], 2021, POSS COVID 19 VACC B
   [Anonymous], 2021, UND FEAT PYR NETW OB
   [Anonymous], 2021, COVID 19 ACT GUID
   [Anonymous], 2021, HAAR WAV
   [Anonymous], 2021, OBJ DET
   [Anonymous], YOLO-V5
   [Anonymous], REAL TIM MED MASK DE
   [Anonymous], 2021, A comprehensive guide to smart home device compatibility
   [Anonymous], 2021, VIOL JON OBJ DET FRA
   [Anonymous], 2021, SCAL INV FEAT TRANSF
   [Anonymous], 2021, OR SARS COV 2 VIR
   Aziz L, 2020, IEEE ACCESS, V8, P170461, DOI 10.1109/ACCESS.2020.3021508
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310
   Bu W, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P458, DOI 10.1109/ICCIS.2017.8274819
   Cabani Adnane, 2021, Smart Health (Amst), V19, P100144, DOI 10.1016/j.smhl.2020.100144
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chiang D., 2020, Detect faces and determine whether people are wearing mask
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ejaz M.S., 2019, 2019 1 INT C ADV SCI, P1
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan XQ, 2021, IEEE SYS MAN CYBERN, P832, DOI 10.1109/SMC52423.2021.9659271
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb P, 2013, COMMUN ACM, V56, P97, DOI [10.1145/2500468.2494532, 10.1145/2494532]
   Feng X, 2019, INTEGRATION, V69, P309, DOI 10.1016/j.vlsi.2019.07.005
   Forsyth D, 2014, COMPUTER, V47, P6, DOI 10.1109/MC.2014.42
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Frischholz R, 2021, BAO FACE DATABASE FA
   Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu Y.Q., 2021, ARXIV
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G.B., 2008, PROC WORKSHOP FACES
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin T., 2016, arXiv
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Loey M, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108288
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   M K, 2021, INT J PHARM SCI REV, V67, P24, DOI [10.47583/ijpsrr.2021.v67i01.004, DOI 10.47583/IJPSRR.2021.V67I01.004]
   Msonda P, 2020, TRAIT SIGNAL, V37, P1075, DOI 10.18280/ts.370620
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Najibi M, 2016, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2016.260
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Nowrin A, 2021, IEEE ACCESS, V9, P106839, DOI 10.1109/ACCESS.2021.3100070
   Opitz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Ouyang WL, 2017, IEEE I CONF COMP VIS, P1956, DOI 10.1109/ICCV.2017.214
   Pitts Walter, 1947, BULL MATH BIOPHYS, V9, P127, DOI 10.1007/BF02478291
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Salve SG, 2010, INT CONF COMP SCI, P471, DOI 10.1109/ICCSIT.2010.5565098
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suard F, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P207
   Szegedy C, 2014, INT C LEARN REPR
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Phung VH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214500
   Vibhuti, 2022, MULTIMED TOOLS APPL, V81, P40013, DOI 10.1007/s11042-022-12999-6
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z, 2021, WEARMASK FAST IN BRO, P1
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Yoo D, 2015, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2015.305
   Zhang J, 2021, IEEE ACCESS, V9, P42975, DOI 10.1109/ACCESS.2021.3066538
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zou Z, 2019, OBJECT DETECTION 20, P1
NR 99
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34321
EP 34361
DI 10.1007/s11042-023-14686-6
EA MAR 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943638900005
PM 37362645
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Frikha, T
   Chaabane, F
   Halima, RB
   Wannes, W
   Hamam, H
AF Frikha, Tarek
   Chaabane, Faten
   Halima, Riadh Ben
   Wannes, Walid
   Hamam, Habib
TI Embedded decision support platform based on multi-agent systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-agent system; Resources; Blockchain; Augmented reality; Artificial
   intelligence; Execution time
ID OPTIMIZATION; MODEL
AB There has been an outstanding use of memory storage of processors as current applications: Artificial Intelligence-based applications, 3D-reconstruction or Blockchain ones, take advantage of their large computing effort, as well as their ability to support greedy treatments, and it grows the concern about providing reasonable resources for an efficient performance. This increase in demand requires optimized hardware configurations. In this context, the multi agent approach is a suitable solution to control the required resources for a multi-technology application. This paper investigates the scenario in which an embedded architecture implemented on FPGA is using a dynamic reconfigurable system that involves a multi-agent-based control part allowing optimizing and scheduling resources for technology processing requests. Hence, according to the required technology, the minimum of resources is selected. In a first time, performance is evaluated in terms of number of slices' resources and task execution time for both a fixed and a dynamic reconfigurable architecture. A Dynamic Partial Reconfiguration is used to minimize efficiently the number of agents and consequently to minimize the allocated resources. The proposed dynamic reconfigurable architecture allows to save efficiently resources and execution time constraints.
C1 [Frikha, Tarek; Chaabane, Faten] Univ Sfax, Fac Sci Sfax, Data Engn & Semant Res Unit, Sfax, Tunisia.
   [Halima, Riadh Ben] Univ Sfax, ReDCAD, ENIS, Sfax, Tunisia.
   [Wannes, Walid] Univ Sfax, Fac Sci, Algebre Geometrie & Theorie Spectrale, Sfax, Tunisia.
   [Hamam, Habib] Univ Moncton, Fac Engn, IIT, Sfax, Tunisia.
   [Hamam, Habib] Int Inst Technol & Management, POB 1989, Libreville, Gabon.
   [Hamam, Habib] Spectrum Knowledge Prod & Skills Dev, Sfax 3027, Tunisia.
   [Hamam, Habib] Univ Johannesburg, Sch Elect Engn, Dept Elect & Elect Engn Sci, ZA-2006 Johannesburg, South Africa.
C3 Universite de Sfax; Faculty of Sciences Sfax; Universite de Sfax; Ecole
   Nationale dIngenieurs de Sfax (ENIS); Universite de Sfax; Faculty of
   Sciences Sfax; Universite de Sfax; University of Johannesburg
RP Frikha, T (corresponding author), Univ Sfax, Fac Sci Sfax, Data Engn & Semant Res Unit, Sfax, Tunisia.
EM tarek.frikha@enis.tn
RI FRIKHA, Tarek/AGH-4470-2022; Hamam, Habib/C-1761-2019
OI FRIKHA, Tarek/0000-0001-8402-8059; Hamam, Habib/0000-0002-5320-1012
CR Allal A, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107342
   Allouche M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157169
   [Anonymous], 2015, IEEE EUROCON 2015 IN, DOI DOI 10.1109/EUROCON.2015.7313688
   Balouch S, 2022, FRONT ENERGY RES, V10, DOI 10.3389/fenrg.2022.861571
   Barreteau O, 1998, MULTIAGENT SYSTEM EX
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Dhouioui M, 2021, J REAL-TIME IMAGE PR, V18, P2403, DOI 10.1007/s11554-021-01117-8
   Duan Y, 2012, ARTIF INTELL REV, V38, P193, DOI 10.1007/s10462-011-9244-8
   Dudek G, 1996, AUTON ROBOT, V3, P375, DOI 10.1007/BF00240651
   Eldesokey HM, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4694
   Ferber J., 1995, Les Systemes Multi Agents: Vers Une Intelligence Collective
   Fiosina J., 2013, HYBRID ARTIFICIAL IN, DOI [10.1007/978-3-642-40846-5_64, DOI 10.1007/978-3-642-40846-5_64]
   Frikha Tarek, 2013, WSEAS Transactions on Circuits and Systems, V12, P263
   Frikha T, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9978863
   Frikha T, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9918697
   Frikha T, 2019, MULTIMED TOOLS APPL, V78, P14947, DOI 10.1007/s11042-018-6886-4
   Frikha T, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P393, DOI 10.1109/ATSIP.2016.7523130
   Cena CG, 2013, EXPERT SYST APPL, V40, P4737, DOI 10.1016/j.eswa.2013.01.048
   Gatti Maira, 2014, Multi-Agent-Based Simulation XIV. International Workshop, MABS 2013. Revised Selected Papers. LNCS: 8235, P17, DOI 10.1007/978-3-642-54783-6_2
   Ghorbel A, 2015, INT CONF INTELL SYST, P528, DOI 10.1109/ISDA.2015.7489172
   Gorodetski V, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE SYSTEMS, PROCEEDINGS, P297, DOI 10.1109/ICAIS.2002.1048117
   Govinda K, 2012, PROCEDIA ENGINEER, V38, P125, DOI 10.1016/j.proeng.2012.06.018
   Goyal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051583
   Guesmi A, 2022, IEEE DES TEST, V39, P63, DOI 10.1109/MDAT.2021.3077542
   Guo C, 2021, IEEE ACCESS, V9, P60516, DOI 10.1109/ACCESS.2021.3074070
   Hager K, 2015, TRANSP RES PROC, V10, P306, DOI 10.1016/j.trpro.2015.09.080
   Helbing D., 2012, Social Self-Organization: Agent-Based Simulations and Experiments To Study Emergent Social Behavior, P25, DOI [DOI 10.1007/978-3-642-24004-1_2, 10.1007/978-3-642-24004-12, DOI 10.1007/978-3-642-24004-12]
   Hou F, 2016, CONCURR COMP-PRACT E, V28, P3213, DOI 10.1002/cpe.3760
   Inigo-Blasco P, 2012, ROBOT AUTON SYST, V60, P803, DOI 10.1016/j.robot.2012.02.004
   Issaoui S, 2016, INT MULTICONF SYST, P336, DOI 10.1109/SSD.2016.7473747
   Jayanetti A, 2022, FUTURE GENER COMP SY, V137, P14, DOI 10.1016/j.future.2022.06.012
   Jiang YC, 2014, IEEE T PARALL DISTR, V25, P2743, DOI 10.1109/TPDS.2013.254
   Kaur J, 2021, CMC-COMPUT MATER CON, V69, P2617, DOI 10.32604/cmc.2021.017470
   Khaleel MI, 2022, SIMUL MODEL PRACT TH, V119, DOI 10.1016/j.simpat.2022.102589
   Khayyat M, 2016, TRANSP RES PROC, V12, P325, DOI 10.1016/j.trpro.2016.02.069
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1683, DOI 10.1007/s11277-021-08714-7
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Ktari J, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6030072
   Ktari J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152314
   Manikandan N, 2022, MATER TODAY-PROC, V62, P4903, DOI 10.1016/j.matpr.2022.03.535
   Manikandan N, 2022, COMPUT COMMUN, V187, P35, DOI 10.1016/j.comcom.2022.01.016
   Mechtri L., 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P65, DOI 10.1109/ITNG.2012.18
   Milicka P, 2022, EUR J OPER RES, V296, P72, DOI 10.1016/j.ejor.2021.03.028
   Nguyen CP, 2012, IEEE T SMART GRID, V3, P1029, DOI 10.1109/TSG.2012.2186833
   Nikbazm R, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P352, DOI 10.1109/ICCKE.2014.6993399
   Gutierrez-Garcia JO, 2015, J SYST SOFTWARE, V104, P17, DOI 10.1016/j.jss.2015.02.039
   Ota J, 2006, ADV ENG INFORM, V20, P59, DOI 10.1016/j.aei.2005.06.002
   Rani S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196474
   Sarika S, 2015, PROCEDIA COMPUT SCI, V46, P574, DOI 10.1016/j.procs.2015.02.094
   Seçkiner SU, 2022, COMPUT IND ENG, V169, DOI 10.1016/j.cie.2022.108163
   Sim KM, 2012, IEEE T SERV COMPUT, V5, P564, DOI 10.1109/TSC.2011.52
   Soriano A., 2013, DISTRIB COMPUT, DOI [10.1007/978-3-319-00551-5_52, DOI 10.1007/978-3-319-00551-5_52]
   Tang XY, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107914
   van Pruissen O, 2014, ENRGY PROCED, V62, P170, DOI 10.1016/j.egypro.2014.12.378
   Vytelingum P., 2010, Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: volume 1 - Volume 1. Toronto, Canada, V1, P39
   Wangapisit O, 2014, PROCD SOC BEHV, V125, P472, DOI 10.1016/j.sbspro.2014.01.1489
   Yu T, 2021, J MANUF SYST, V60, P487, DOI 10.1016/j.jmsy.2021.07.015
   Zaabar B, 2021, COMPUT NETW, V200, DOI 10.1016/j.comnet.2021.108500
NR 58
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32607
EP 32633
DI 10.1007/s11042-023-14843-x
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000941926100013
DA 2024-07-18
ER

PT J
AU Sharma, A
   Shrivastava, BP
AF Sharma, Ajay
   Shrivastava, Bhavana P.
TI Facial image super-resolution using progressive network interleaved
   correlation filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face hallucination super resolution; Deep learning; CNN; Up-sampling;
   Down-sampling; And perceptual quality
AB The very low resolution (VLR) issue arises in many face application systems because of the rising demand for surveillance camera-based applications. On the VLR face image, the face recognition algorithms in use are unable to work satisfactorily. Although face super-resolution (SR) techniques can be used to improve the resolution of the images, these VLR face images do not respond well to the existing learning-based face SR techniques. This work suggests a novel method for learning the link between the high-resolution image space and the VLR image space for face SR to solve this issue. The paper aims to address the problem of face image super-resolution and solutions for resolving the issues related to facial images. The major issues related to face image super-resolution during reconstruction end is a fusion of more than one kind of feature which may cause noise in the image, blind spot generation, low perceptual quality, and checkboard issues. The existing models are designed to improvise the perceptual quality of face super-resolution but still fail to generate better perceptual quality of image due to loss during the reconstruction stage. Therefore, this paper proposes a novel progressive face hallucination super-resolution (FHSR) model with a loss-aware upscaling network layer. The upscaling layer is integrated with correlation filters and used a combined loss function. The model is designed as cascading of upscaling modules that are progressive with dense skip connection layers. Loss functions from each upscaling module are evaluated and cascaded together and fed forwards to the next layer to minimize the reconstruction losses. The architecture upscaled the images with 3 cascading modules which magnify 2x,4x, and 8x. The paper also presented the ablation study that assured that the designed FHSR model is better as compared to baseline models. This architecture overcomes the issue of extraction of more features with minimum losses and constructs the high magnification at the reconstruction end. The comparative study shows enhanced performance over state-of-art models.
C1 [Sharma, Ajay] Maulana Azad Natl Inst Technol, Bhopal, India.
   [Shrivastava, Bhavana P.] MANIT, Elect Dept, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal; National Institute of Technology (NIT
   System); Maulana Azad National Institute of Technology Bhopal
RP Sharma, A (corresponding author), Maulana Azad Natl Inst Technol, Bhopal, India.
EM er.ajaysharma9303@gmail.com; sonibhavana1@gmail.com
RI shrivastava, bhavana/JSL-1739-2023; Sharma, Ajay/AFG-6302-2022
OI Sharma, Ajay/0000-0001-7951-9371; Shrivastava, Dr Bhavana
   Prakash/0000-0003-4281-4240
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Anari V, 2019, COMPUTERS, V8, DOI 10.3390/computers8020041
   Anwar S, 2019, ARXIV
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Choi J-H, 2019, NEUROCOMPUTING
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Gao H, 2022, ACM T MULTIM COMPUT
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P1725, DOI 10.1109/TCSS.2022.3178416
   Gao HH, 2023, IEEE T NETW SCI ENG, V10, P2978, DOI 10.1109/TNSE.2022.3163144
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Grm K, 2020, IEEE T IMAGE PROCESS, V29, P2150, DOI 10.1109/TIP.2019.2945835
   Haris M., 2018, arXiv
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang G, 2018, ARXIV
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J-H, 2016, ARXIV
   Kim JS, 2021, IEEE ACCESS, V9, P169321, DOI 10.1109/ACCESS.2021.3138442
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Luo SX, 2022, IEEE ACCESS, V10, P8073, DOI 10.1109/ACCESS.2022.3143499
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Nazeri K, 2019, IEEE INT CONF COMP V, P3275, DOI 10.1109/ICCVW.2019.00409
   Seif G, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1468, DOI 10.1109/ICASSP.2018.8461664
   Wang X, 2019, IDEAS HIST MOD CHINA
   Wang YQ, 2016, NEUROCOMPUTING, V174, P988, DOI 10.1016/j.neucom.2015.10.035
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1072
   Xue S, 2019, SIGNAL IMAGE VIDEO P
   Yu X., 2017, J LATEX CLASS FILES
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang KP, 2018, LECT NOTES COMPUT SC, V11215, P196, DOI 10.1007/978-3-030-01252-6_12
   Zhang Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3099300
   Zhu X, 2017, HINDAWI MATH PROBLEM
NR 40
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29587
EP 29606
DI 10.1007/s11042-023-14765-8
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100018
DA 2024-07-18
ER

PT J
AU Gautam, S
   Kumar, A
AF Gautam, Sarita
   Kumar, Anuj
TI Image-based automatic traffic lights detection system for autonomous
   cars: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Image-processing; Computer Vision; Color Perception Deficiency; Feature
   & Shape Identification; Traffic Lights; Autonomous cars
ID RECOGNITION; ROBUST; ALGORITHM
AB From the early stages of autonomous vehicle's development, traffic light detection/perception system have been an important area of research for making collision safe self-driving vehicles. Here Automatic Traffic Light Detection System (ALTDS) helps in accurate detection of Traffic Lights for Autonomous vehicles and Driver assistance systems (DAS). These vision-based system captures images using a camera mounted on a car and no other sensors. As traffic light is a small object in a real-time traffic scenario, so high-quality images are the main success factor of ATLDS. This paper elucidates the ideas and challenges that needs to be worked upon for better traffic light detection system used in self-driving cars. In this paper, we present a state-of-art review of various techniques used in traffic light detection. Different ATLDS techniques such as preprocessing, segmentation, feature extraction, classification and post-processing are categorized based on the features used at each stage, a comparison of the pros and cons of each technique is also provided. The hardware/software limitations, laws related to self-driving vehicles along-with simulation environments are also provided. The conclusion and future scope are given at the end.
C1 [Gautam, Sarita; Kumar, Anuj] Panjab Univ, Chandigarh, India.
C3 Panjab University
RP Gautam, S (corresponding author), Panjab Univ, Chandigarh, India.
EM Gautamsarry@gmail.com; Anuj_gupta@pu.ac.in
CR Almagambetov A, 2015, IEEE T INTELL TRANSP, V16, P1305, DOI 10.1109/TITS.2014.2361139
   Aneesh A. N., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P1554, DOI 10.1109/ICICICT46008.2019.8993293
   Any G, 2019, 2019 IEEE INT VEH S
   Arena F, 2022, J ADV TRANSPORT, V2022, DOI 10.1155/2022/1383349
   Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816
   Barnes D, 2015, IEEE INT VEH SYM, P573, DOI 10.1109/IVS.2015.7225746
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Belkouri D, 2022, TRANSP RES PROCEDIA, V60, P496, DOI [10.1016/j.trpro.2021.12.064, DOI 10.1016/J.TRPRO.2021.12.064]
   Benjelloun F, 2020, 2020 INT C INTELLIGE, P1, DOI [10.1109/ISCV49265.2020.9204197, DOI 10.1109/ISCV49265.2020.9204197]
   Bhalla Aman, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P519, DOI 10.1109/ICISS49785.2020.9315968
   Chen SC, 2019, IEEE MULTIMEDIA, V26, P5, DOI 10.1109/MMUL.2019.2935397
   Chen ZL, 2016, IEEE INTEL TRANSP SY, V8, P28, DOI 10.1109/MITS.2016.2605381
   Chongchong Jin, 2018, 2018 International Computers, Signals and Systems Conference (ICOMSSC). Proceedings, P640
   Daily, MEDASANI S SELF DRIV
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   de Charette R, 2009, IEEE INT VEH SYM, P358, DOI 10.1109/IVS.2009.5164304
   Dean MD, 2022, NAT ELECTRON, V5, P2, DOI 10.1038/s41928-021-00708-4
   Diaz-Cabrera M, 2015, EXPERT SYST APPL, V42, P3911, DOI 10.1016/j.eswa.2014.12.037
   Diaz-Cabrera M, 2012, IEEE INT C INTELL TR, P1315, DOI 10.1109/ITSC.2012.6338765
   Ditty MA, 2019, U.S. Patent Application, Patent No. [16/186,473, 16186473]
   Fairfield N., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5421, DOI 10.1109/ICRA.2011.5980164
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Gao F, 2020, IET INTELL TRANSP SY, V14, P735, DOI 10.1049/iet-its.2019.0782
   Gautam S, 2022, LECT NOTES NETWORKS
   Greenblatt NA, 2016, IEEE SPECTRUM, V53, P46, DOI 10.1109/MSPEC.2016.7419800
   Gupta A, 2021, ARRAY-NY, V10, DOI 10.1016/j.array.2021.100057
   Gwang-Gook Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P277, DOI 10.1109/ICCE.2017.7889317
   Haltakov V, 2015, LECT NOTES COMPUT SC, V9358, P446, DOI 10.1007/978-3-319-24947-6_37
   Hassan N, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT AUTONOMOUS SYSTEMS (ICOIAS'2020), P71, DOI [10.1109/icoias49312.2020.9081854, 10.1109/ICoIAS49312.2020.9081854]
   Hirabayashi M, 2019, ROBOT AUTON SYST, V111, P62, DOI 10.1016/j.robot.2018.10.004
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ichikawa K, 2016, U.S. Patent, Patent No. [9,304,513, 9304513]
   Iftikhar M, 2022, TRAFFIC LIGHT DETECT
   Jensen MB, 2016, IEEE T INTELL TRANSP, V17, P1800, DOI 10.1109/TITS.2015.2509509
   Ji XX, 2021, IEEE SENS J, V21, P15598, DOI 10.1109/JSEN.2020.3009242
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2286, DOI 10.1109/ITSC.2014.6958056
   Kim HK., 2011, INT J ELECTR COMPUT, V5, P1429
   Kim HK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071700
   Kim HK, 2018, J ADV TRANSPORT, DOI 10.1155/2018/2365414
   Kim Hyun-Koo., 2013, Proceedings of World Academy of Science, Engineering and Technology, P571
   Kim J, 2018, IEEE INT C INTELL TR, P280, DOI 10.1109/ITSC.2018.8569575
   Kim Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030354
   KimSangKi, 2017, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V22, P62, DOI 10.5909/JBE.2017.22.1.62
   Kulkarni R, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Le Quang Thao, 2022, Ingenierie des systemes d'information, V27, P75, DOI 10.18280/isi.270109
   Levinson J., TRAFFIC LIGHT MAPPIN
   Li J, 2017, MULTIMED TOOLS APPL, V76, P23017, DOI 10.1007/s11042-016-4211-7
   LISA, about us
   Michael M, 2015, IEEE IJCNN
   Müller J, 2018, IEEE INT C INTELL TR, P266, DOI 10.1109/ITSC.2018.8569683
   mxnet, PASCAL VOC
   Ni JJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082749
   Nienhuser Dennis, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1705, DOI 10.1109/ITSC.2010.5625241
   O'Malley R, 2010, IEEE T INTELL TRANSP, V11, P453, DOI 10.1109/TITS.2010.2045375
   Omachi M, 2010, INT CONF SIGN PROCES, P809, DOI 10.1109/ICOSP.2010.5655932
   Ouyang ZC, 2020, IEEE T MOBILE COMPUT, V19, P300, DOI 10.1109/TMC.2019.2892451
   Ozcelik Z, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P424, DOI 10.1109/UBMK.2017.8093430
   Philipsen MP, 2015, IEEE INT C INTELL TR, P2341, DOI 10.1109/ITSC.2015.378
   Rao SS, 2 INT C IOT BAS CONT
   Rubio JC, 2012, IEEE T INTELL TRANSP, V13, P594, DOI 10.1109/TITS.2011.2175219
   Saha D, 2022 PRACTICAL SELF, DOI [10.20944/preprints202202.0123.v1, DOI 10.20944/PREPRINTS202202.0123.V1]
   Saini S, 2017, IEEE INT VEH SYM, P606, DOI 10.1109/IVS.2017.7995785
   Salarian M, 2015, 2015 SAI INTELLIGENT SYSTEMS CONFERENCE (INTELLISYS), P747, DOI 10.1109/IntelliSys.2015.7361224
   Salti S, 2013, IEEE IJCNN
   Shen YH, 2009, IEEE INT VEH SYM, P521, DOI 10.1109/IVS.2009.5164332
   Shi ZW, 2016, IEEE T INTELL TRANSP, V17, P690, DOI 10.1109/TITS.2015.2481459
   Singh P, 2021, J REAL-TIME IMAGE PR, V18, P1051, DOI 10.1007/s11554-021-01125-8
   Siogkas George, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P620
   Sooksatra S., 2014, Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), 2014 11th International Conference on, P1, DOI [DOI 10.1109/ECTICON.2014.6839767, 10.1109/ecticon.2014.6839767]
   Surasak T, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR), P172, DOI 10.1109/ICBIR.2018.8391187
   Tran TV, 2016, 2016 INTERNATIONAL CONFERENCE ON SOFTWARE NETWORKING (ICSN), P21
   Trehard G, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION)
   tsinghua.edu, DATASET LINK TT100K
   uni, DRIVEU DRIVEU
   Vallespi-Gonzalez C, 2017, U.S. Patent, Patent No. [9,672,446, 9672446]
   Vitas D, 2020, IEEE CONSUM ELECTR M, V9, P90, DOI 10.1109/MCE.2020.2969156
   Wang CX, 2011, INT J COMPUT INT SYS, V4, P1383, DOI 10.1080/18756891.2011.9727889
   Wang JG, 2019, IEEE T INTELL TRANSP, V20, P1341, DOI 10.1109/TITS.2018.2849505
   Wang K, 2022, J AMB INTEL HUM COMP, V13, P271, DOI 10.1007/s12652-021-02900-y
   Wentao Liu, 2021, IOP Conference Series: Earth and Environmental Science, V769, DOI 10.1088/1755-1315/769/4/042069
   Widyantoro DH, 2015, 2015 INTERNATIONAL CONFERENCE ON DATA AND SOFTWARE ENGINEERING (ICODSE), P237, DOI 10.1109/ICODSE.2015.7437004
   Wong PC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI [10.1109/ICOPS35962.2018.9575596, 10.1145/3173574.3173752]
   Yabuuchi K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20144035
   Yifan Lu, 2018, Computational Visual Media, V4, P253, DOI 10.1007/s41095-018-0116-x
   Ying J, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P644
   Yoneda K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041181
   Zhang Y, 2014, CHIN CONTR CONF, P4924, DOI 10.1109/ChiCC.2014.6895775
   Zhou XR, 2017, COMPUT INFORM, V36, P793, DOI 10.4149/cai_2017_4_793
   Zhou YT, 2016, IEEE INT SYMP CIRC S, P1778, DOI 10.1109/ISCAS.2016.7538913
NR 89
TC 3
Z9 3
U1 20
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26135
EP 26182
DI 10.1007/s11042-023-14340-1
EA JAN 2023
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000917999700003
DA 2024-07-18
ER

PT J
AU Ribeiro, LSF
   Bui, T
   Collomosse, J
   Ponti, M
AF Sampaio Ferraz Ribeiro, Leo
   Bui, Tu
   Collomosse, John
   Ponti, Moacir
TI Scene designer: compositional sketch-based image retrieval with
   contrastive learning and an auxiliary synthesis task
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sketch-based image retrieval; Cross-domain representation learning;
   Image synthesis; Scene understanding
AB Scene Designer is a novel method for Compositional Sketch-based Image Retrieval (CSBIR) that combines semantic layout synthesis with its main task both to boost performance and enable new creative workflows. While most studies on sketch focus on single-object retrieval, we look to multi-object scenes instead for increased query specificity and flexibility. Our training protocol improves contrastive learning by synthesising harder negative samples and introduces a layout synthesis task that further improves the semantic scene representations. We show that our object-oriented graph neural network (GNN) more than doubles the current SoTA recall@1 on the SketchyCOCO CSBIR benchmark under our novel contrastive learning setting and combined search and synthesis tasks. Furthermore, we introduce the first large-scale sketched scene dataset and benchmark in QuickDrawCOCO.
C1 [Sampaio Ferraz Ribeiro, Leo; Ponti, Moacir] Univ Sao Paulo, ICMC, Sao Carlos, SP, Brazil.
   [Bui, Tu; Collomosse, John] Univ Surrey, CVSSP, Guildford, England.
   [Collomosse, John] Adobe Res, Creat Intelligence Lab, San Jose, CA USA.
   [Ponti, Moacir] Mercado Livre, Osasco, SP, Brazil.
C3 Universidade de Sao Paulo; University of Surrey; Adobe Systems Inc.
RP Ribeiro, LSF (corresponding author), Univ Sao Paulo, ICMC, Sao Carlos, SP, Brazil.
EM leo.sampaio.ferraz.ribeiro@usp.br; t.bui@surrey.ac.uk;
   j.collomosse@surrey.ac.uk; ponti@usp.br
OI Sampaio Ferraz Ribeiro, Leo/0000-0003-1781-2630
FU Fundacao de Amparo a Pesquisa do Estado de Sao Paulo [2017/22366-8,
   2019/02808-1, 2019/07316-0]; Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico [304266/2020-5]
FX This work was supported by Fundacao de Amparo a Pesquisa do Estado de
   Sao Paulo (grants 2017/22366-8, 2019/02808-1, 2019/07316-0), Conselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (304266/2020-5),
   and a charitable donation from Adobe Inc.
CR Abdul-Rashid H., 2019, 3DOR EUROGRAPHICS, DOI DOI 10.1007/978-3
   Abe K, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P82, DOI 10.1145/3192975.3192988
   Ashual O, 2019, IEEE I CONF COMP VIS, P4560, DOI 10.1109/ICCV.2019.00466
   Brown T.B., 2020, P 34 INT C NEURAL IN, DOI DOI 10.5555/3495724.3495883
   Bui T, 2017, COMPUT VIS IMAGE UND, V164, P27, DOI 10.1016/j.cviu.2017.06.007
   Bui T, 2018, COMPUT GRAPH-UK, V71, P77, DOI 10.1016/j.cag.2017.12.006
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Dhariwal P, 2021, ADV NEUR IN, V34
   Dutta A, 2020, INT J COMPUT VISION, V128, P2684, DOI 10.1007/s11263-020-01350-x
   Dutta T, 2021, IEEE T MULTIMEDIA, V23, P2833, DOI 10.1109/TMM.2020.3017918
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Fang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P718, DOI 10.1007/978-3-030-58529-7_42
   Ribeiro LSF, 2021, IEEE INT CONF COMP V, P2424, DOI 10.1109/ICCVW54120.2021.00275
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gao CY, 2020, PROC CVPR IEEE, P5173, DOI 10.1109/CVPR42600.2020.00522
   Goodfellow IJ, 2014, GENERATIVE ADVERSARI, DOI [10.5555/2969033.2969125, DOI 10.5555/2969033.2969125]
   Guo LT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P765, DOI 10.1145/3343031.3350943
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kingma D, 2014, ICLR P, V2014, P1
   Lu YY, 2018, LECT NOTES COMPUT SC, V11220, P213, DOI 10.1007/978-3-030-01270-0_13
   Mao X., 2016, arXiv, DOI 10.48550/arXiv.1611.04076
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Pandey A, 2020, IEEE WINT CONF APPL, P2529, DOI 10.1109/WACV45572.2020.9093402
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Radford A, 2021, PR MACH LEARN RES, V139
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Rombach R., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.10752
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sampaio Ferraz Ribeiro Leo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14141, DOI 10.1109/CVPR42600.2020.01416
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Shaw P, 2018, Arxiv, DOI arXiv:1803.02155
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Siegel R, 2012, CA-CANCER J CLIN, V62, P10, DOI 10.3322/caac.20138
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sukhbaatar Sainbayar, 2015, ADV NEURAL INFORM PR, P2440
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   The Quick Draw!, 2018, DAT
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Xu P, 2022, IEEE T NEUR NET LEAR, V33, P5150, DOI 10.1109/TNNLS.2021.3069230
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yelamarthi SK, 2018, LECT NOTES COMPUT SC, V11208, P316, DOI 10.1007/978-3-030-01225-0_19
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   Yu Z., 2020, PROC IEEECVF C COMPU, P170, DOI DOI 10.1109/CVPRW50498.2020.00093
NR 57
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 20
PY 2022
DI 10.1007/s11042-022-14282-0
EA DEC 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7D9XP
UT WOS:000900835100001
DA 2024-07-18
ER

PT J
AU Chen, G
   Peng, JJ
   Wang, L
   Yuan, HC
   Huang, YS
AF Chen, Gan
   Peng, Junjie
   Wang, Lu
   Yuan, Haochen
   Huang, Yansong
TI Feature constraint reinforcement based age estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Constraint feature; Factors reinforcement
ID ORDINAL REGRESSION; RANK; CLASSIFICATION; NETWORKS
AB As one of the critical biological characteristics of human age, the face has been widely studied for age prediction, which has broad application prospects in the fields of commerce, security, entertainment, etc. Duo to complicated multi-latent heterogeneous features(e.g. gender) bring valuable messages for the image-based age estimation. A variety of methods utilize heterogeneous information for age estimation. However, heterogeneous features may have uncertain noise, and exploiting them without evaluating the reliability of confidence influence may impact the estimation accuracy. Inspired by the observation that gender has a noticeable impact on face at some particular age stage, this paper proposes a Feature Constraint Reinforcement Network (FCRN) to take advantage of constraint gender influence on the age estimation. The model extracts multi-scale latent heterogeneous features and deduces their confidence of influence upon age estimation methods. Specifically, it gets the gender and age features by classification and regression. Then, the model uses the gender factors extracted from the constraint gender features to reinforce and calculate the influence of different genders on age predictions among different age groups and improve the result of age prediction. Extensive experiments were conducted on the existing public aging datasets. The results show the effectiveness and superiority of the proposed method.
C1 [Chen, Gan; Peng, Junjie; Wang, Lu; Yuan, Haochen; Huang, Yansong] Shanghai Univ, Sch Comp Engn & Sci, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
   [Chen, Gan] Gannan Univ Sci & Technol, Informat Engn, 156 Kejia Blvd, Ganzhou 341000, Jiangxi, Peoples R China.
   [Peng, Junjie] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Peng, JJ (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, 333 Nanchen Rd, Shanghai 200444, Peoples R China.; Peng, JJ (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
EM jjie.peng@shu.edu.cn
FU Open Project Program of Shanghai Key Laboratory of Data Science
   [2020090600004]; Science and Technology Project of Jiangxi Provincial
   Department of Education [GJJ181503, GJJ218513]; Shanghai Engineering
   Research Center of Intelligent Computing System [19DZ2252600]
FX The authors would like to thank the funding from the Open Project
   Program of Shanghai Key Laboratory of Data Science (No. 2020090600004),
   the Science and Technology Project of Jiangxi Provincial Department of
   Education (No.GJJ181503), (No.GJJ218513) and the resources and technical
   support from the High performance computing Center of Shanghai
   University, and Shanghai Engineering Research Center of Intelligent
   Computing System (No. 19DZ2252600).
CR Akbari A, 2022, IEEE T PATTERN ANAL, V44, P1869, DOI 10.1109/TPAMI.2020.3029486
   [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   Berg A, 2021, INT C PATT RECOG, P2740, DOI 10.1109/ICPR48806.2021.9412608
   Cao WZ, 2020, PATTERN RECOGN LETT, V140, P325, DOI 10.1016/j.patrec.2020.11.008
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Chen G., 2021, IEEE T AFFECT COMPUT
   Chen SX, 2018, IEEE T MULTIMEDIA, V20, P2209, DOI 10.1109/TMM.2017.2786869
   Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86
   Clapés A, 2018, IEEE COMPUT SOC CONF, P2436, DOI 10.1109/CVPRW.2018.00314
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dagher I, 2021, MULTIMED TOOLS APPL, V80, P20369, DOI 10.1007/s11042-021-10739-w
   Dammak S, 2021, MULTIMED TOOLS APPL, V80, P28001, DOI 10.1007/s11042-021-11060-2
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Franzoi S., 2010, Psychology: A discovery experience
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Geng X, 2008, IEEE T PATTERN ANAL, V30, P368, DOI 10.1109/TPAMI.2008.8
   github, 2020, AFAD DATASET
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Hsu TC, 2010, LECT NOTES COMPUT SC, V6298, P526, DOI 10.1007/978-3-642-15696-0_49
   Keaney TC, 2016, DERMATOL SURG, V42, P797, DOI 10.1097/DSS.0000000000000505
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lephart ED, 2018, J COSMET DERMATOL-US, V17, P282, DOI 10.1111/jocd.12508
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Liu JY, 2019, MULTIMED TOOLS APPL, V78, P33703, DOI 10.1007/s11042-019-08203-x
   Liu N, 2019, INT CONF ACOUST SPEE, P2377, DOI 10.1109/ICASSP.2019.8683005
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu PC, 2018, NONLINEAR DYNAM, V94, P1803, DOI 10.1007/s11071-018-4458-9
   Liu SQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4892
   Liu SQ, 2019, PHYSICA A, V521, P667, DOI 10.1016/j.physa.2019.01.036
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mercer J., 2013, Child development: Myths and misunderstandings, V2nd
   Ouloul IM, 2019, MULTIMED TOOLS APPL, V78, P1913, DOI 10.1007/s11042-018-6275-z
   Pan HY, 2018, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR.2018.00554
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Savchenko, 2018, ARXIV
   Savchenko Andrey V., 2021, 2021 IEEE 19th International Symposium on Intelligent Systems and Informatics (SISY), P119, DOI 10.1109/SISY52375.2021.9582508
   Sawant M, 2019, MULTIMED TOOLS APPL, V78, P30419, DOI 10.1007/s11042-019-7589-1
   Shaikh R.A., 2018, MULTIMEDIA TOOLS APP, P1
   Shen W, 2021, IEEE T PATTERN ANAL, V43, P404, DOI 10.1109/TPAMI.2019.2937294
   Shen W, 2018, PROC CVPR IEEE, P2304, DOI 10.1109/CVPR.2018.00245
   Shin NH, 2022, PROC CVPR IEEE, P18739, DOI 10.1109/CVPR52688.2022.01820
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   susanqq, 2020, UTKFACE DATASET
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taheri S, 2019, NEUROCOMPUTING, V329, P300, DOI 10.1016/j.neucom.2018.10.071
   Tan ZC, 2018, IEEE T PATTERN ANAL, V40, P2610, DOI 10.1109/TPAMI.2017.2779808
   Tian Q, 2021, NEUROCOMPUTING, V444, P158, DOI 10.1016/j.neucom.2020.07.149
   Tian Q, 2019, NEURAL PROCESS LETT, V50, P2141, DOI 10.1007/s11063-019-09993-9
   Tian Q, 2018, IMAGE VISION COMPUT, V69, P9, DOI 10.1016/j.imavis.2017.10.003
   Tian Q, 2017, NEUROCOMPUTING, V238, P286, DOI 10.1016/j.neucom.2017.01.064
   TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132
   uncw, 2020, MORPH 2 DATASET
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Wang HY, 2022, IEEE T IMAGE PROCESS, V31, P1084, DOI 10.1109/TIP.2021.3139226
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Windhager S, 2019, AM J PHYS ANTHROPOL, V169, P678, DOI 10.1002/ajpa.23878
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Xiao B, 2009, LECT NOTES COMPUT SC, V5879, P88, DOI 10.1007/978-3-642-10467-1_7
   Xie JC, 2020, IEEE T INF FOREN SEC, V15, P2361, DOI 10.1109/TIFS.2020.2965298
   Xu QZ, 2019, CLUSTER COMPUT, V22, pS2731, DOI 10.1007/s10586-017-1436-9
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, SOFT COMPUT, V23, P9413, DOI 10.1007/s00500-018-3608-9
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Xu QZ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0904-y
   Yang TY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1078
   Zhang BC, 2022, IEEE ACCESS, V10, P24048, DOI 10.1109/ACCESS.2022.3154403
   Zhang C, 2019, PROC CVPR IEEE, P12579, DOI 10.1109/CVPR.2019.01287
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 84
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17033
EP 17054
DI 10.1007/s11042-022-14094-2
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000879728900002
DA 2024-07-18
ER

PT J
AU Anju, AJ
   Judith, JE
AF Anju, A. J.
   Judith, J. E.
TI Adaptive recurrent neural network for software defect prediction with
   the aid of quantum theory- particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software defect prediction; Feature selection; Deep neural network;
   Optimization
ID MODEL
AB With the proliferation of software programs, predicting defects has become a big concern. Therefore, to overcome this challenge, this research introduces a new Optimized Deep Learning model. The software defect is predicted using the new Adaptive Recurrent Neural network (ARNN), wherein the hyper-parameters (weight) function is fine-tuned using the new Levy-Flight Integrated Cuckoo Search Optimization (LICSO) model to accurately predict the defects. First, the data is pre-processed via box-cox transformation. The outcomes of the pre-processed data are then subjected to a Feature Selection technique, wherein the relevant features are selected using the new Quantum Theory-Particle Swarm Optimization (QPSO-FS). Finally, ARNN is utilized to predict the software defects. To validate the performance of the proposed approach evaluation metrics are considered such as detection Accuracy, Precision, Recognition error, Sensitivity, Specificity, F1-Score, and Processing time are evaluated and tested. As per the acquired results, the projected model outperforms the existing models. The projected model has recorded the highest accuracy level as 96.48%.
C1 [Anju, A. J.; Judith, J. E.] Noorul Islam Ctr Higher Educ, Comp Sci & Engn, Thuckalay, Kumarakovil, India.
RP Anju, AJ (corresponding author), Noorul Islam Ctr Higher Educ, Comp Sci & Engn, Thuckalay, Kumarakovil, India.
EM ajanju1@gmail.com
CR Akbari, 2020, ARXIV
   Al Qasem O, 2020, IEEE ACCESS, V8, P63945, DOI 10.1109/ACCESS.2020.2985290
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Phan AV, 2017, PROC INT C TOOLS ART, P45, DOI 10.1109/ICTAI.2017.00019
   Arar ÖF, 2017, APPL SOFT COMPUT, V59, P197, DOI 10.1016/j.asoc.2017.05.043
   Arar ÖF, 2015, APPL SOFT COMPUT, V33, P263, DOI 10.1016/j.asoc.2015.04.045
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Balogun AO, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071147
   Benni KE, 2018, IEEE T SOFTWARE ENG, V44, P534, DOI 10.1109/TSE.2017.2731766
   Cai XJ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5478
   Cai ZY, 2019, IEEE ACCESS, V7, P170844, DOI 10.1109/ACCESS.2019.2953696
   Chakraborty T, 2021, IEEE T RELIAB, V70, P481, DOI 10.1109/TR.2020.3020238
   Chen L, 2018, SOFTWARE QUAL J, V26, P97, DOI 10.1007/s11219-016-9342-6
   Deng JH, 2020, IET SOFTW, V14, P443, DOI 10.1049/iet-sen.2019.0149
   Deng JH, 2020, IEEE ACCESS, V8, P66647, DOI 10.1109/ACCESS.2020.2985780
   Ding ZG, 2020, RELIAB ENG SYST SAFE, V204, DOI 10.1016/j.ress.2020.107170
   Dong F, 2018, WIRELESS PERS COMMUN, V102, P2261, DOI 10.1007/s11277-017-5069-3
   He P, 2015, INFORM SOFTWARE TECH, V59, P170, DOI 10.1016/j.infsof.2014.11.006
   Jayanthi R, 2019, CLUSTER COMPUT, V22, P77, DOI 10.1007/s10586-018-1730-1
   Jin C, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114637
   Jin C, 2021, SOFT COMPUT, V25, P447, DOI 10.1007/s00500-020-05159-1
   Li N, 2020, INFORM SOFTWARE TECH, V122, DOI 10.1016/j.infsof.2020.106287
   Li ZQ, 2018, AUTOMAT SOFTW ENG, V25, P201, DOI 10.1007/s10515-017-0220-7
   Liang HL, 2019, IEEE ACCESS, V7, P83812, DOI 10.1109/ACCESS.2019.2925313
   Lin JH, 2021, IEEE ACCESS, V9, P13112, DOI 10.1109/ACCESS.2021.3051957
   Majd A, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2019.113156
   Manjula C, 2019, CLUSTER COMPUT, V22, pS9847, DOI 10.1007/s10586-018-1696-z
   Miholca DL, 2018, INFORM SCIENCES, V441, P152, DOI 10.1016/j.ins.2018.02.027
   Morasca S, 2020, EMPIR SOFTW ENG, V25, P3977, DOI 10.1007/s10664-020-09861-4
   Ni C, 2017, J COMPUT SCI TECH-CH, V32, P1090, DOI 10.1007/s11390-017-1785-0
   Paniri M, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105285
   Rhmann W, 2020, J KING SAUD UNIV-COM, V32, P419, DOI 10.1016/j.jksuci.2019.03.006
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Shi K, 2021, J SOFTW-EVOL PROC, V33, DOI 10.1002/smr.2330
   Thota M. K., 2020, Int. J. ApplSci Eng., V17, P331, DOI [DOI 10.6703/IJASE.20201217(4).331, DOI 10.6703/IJASE.202012_17(4).331]
   Tong HN, 2018, INFORM SOFTWARE TECH, V96, P94, DOI 10.1016/j.infsof.2017.11.008
   Wang H, 2021, IEEE T RELIAB, V70, P711, DOI 10.1109/TR.2020.3047396
   Wang SH, 2018, MECH SYST SIGNAL PR, V112, P154, DOI 10.1016/j.ymssp.2018.04.038
   Wang S, 2020, IEEE T SOFTWARE ENG, V46, P1267, DOI 10.1109/TSE.2018.2877612
   Xu JX, 2021, IEEE T RELIAB, V70, P613, DOI 10.1109/TR.2020.3040191
   Xu XL, 2021, J SYST ENG ELECTRON, V32, P389, DOI 10.23919/JSEE.2021.000032
   Xu Z, 2019, INFORM SOFTWARE TECH, V106, P182, DOI 10.1016/j.infsof.2018.10.004
   Yang XS, 2017, INT CONF SOFT COMP, P55, DOI 10.1109/ISCMI.2017.8279597
   Zhao LC, 2019, IEEE ACCESS, V7, P7663, DOI 10.1109/ACCESS.2018.2889061
NR 48
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16257
EP 16278
DI 10.1007/s11042-022-14065-7
EA NOV 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000878460900001
DA 2024-07-18
ER

PT J
AU Chen, XY
   Chen, MY
   Hang, JR
   He, FC
   Qi, W
   Han, J
AF Chen, Xiaoyu
   Chen, Mingyang
   Hang, Jinru
   He, Fengchen
   Qi, Wei
   Han, Jing
TI The online scene-adaptive tracker based on self-supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Siamese network; Online scene-adaptive; Self-supervised
   learning
ID OBJECT TRACKING
AB In recent years, with the advancement of deep learning technology, visual object tracking has developed rapidly. However, the real world is complex and changeable, and the CNN-based trackers lack an effective updating mechanism for unseen targets and scene adaptation. Aiming at the two key issues that existed in current trackers algorithms: (1) the poor generalization with the limited offline training data; (2) lacking an online model updating mechanism for scene adaptation, this paper designs a simple and effective self-supervised framework for online model adaptation and propose OSATracker, which construct a cycle self-supervision based on unlabeled online data. OSATracker utilizes decision-level information to update the model rather than template by self-supervised optimization in the online tracking process, which effectively improves the generalization ability of the model in the tracking process. Extensive experiments on visual tracking benchmarks including VOT2018, VOT2016, OTB2015, and OTB2013 demonstrate the effectiveness of OSATracker with outstanding performance.
C1 [Chen, Xiaoyu; Chen, Mingyang; Hang, Jinru; He, Fengchen; Han, Jing] Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
   [Qi, Wei] AVIC Suzhou Changfeng Av, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Suzhou 215151, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Han, J (corresponding author), Nanjing Univ Sci & Technol, Jiangsu Key Lab Spectral Imaging & Intelligent Se, Nanjing 210094, Jiangsu, Peoples R China.
EM 115104000466@njust.edu.cn; chenmingyang@njust.edu.cn;
   jungle_fish@foxmail.com; hfc@njust.edu.cn; bjweiqi@gmail.com;
   eohj@njust.edu.cn
RI Wu, Jiangjiexing/JXM-8280-2024
OI Wu, Jiangjiexing/0000-0003-1652-4047
FU China Postdoctoral Science Foundation [2021M69 1591]
FX This work was supported by the China Postdoctoral Science Foundation
   (2021M69 1591).
CR [Anonymous], 2019, P ICCCN
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bharath, 2017, DENOISING AUTOENCODE
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   CHUA LO, 1993, IEEE T CIRCUITS-I, V40, P147, DOI 10.1109/81.222795
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Fekir A, 2014, I C COMP SYST APPLIC, P184, DOI 10.1109/AICCSA.2014.7073197
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Hadfield S., 2016, VISUAL OBJECT TRACKI
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   Jiang CR, 2018, NEUROCOMPUTING, V275, P2892, DOI 10.1016/j.neucom.2017.10.043
   Krieger EW, 2017, OPT LASER TECHNOL, V95, P133, DOI 10.1016/j.optlastec.2017.04.011
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Lai ZH, 2020, PROC CVPR IEEE, P6478, DOI 10.1109/CVPR42600.2020.00651
   Lee BY, 2014, IOP C SER EARTH ENV, V18, DOI 10.1088/1755-1315/18/1/012020
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang YT, 2018, INT C ADV MECH SYST, P332, DOI 10.1109/ICAMechS.2018.8506735
   Liu R, 2016, ARTIF INTELL MED, V74, P9, DOI 10.1016/j.artmed.2016.11.002
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Sun M, 2016, INT C PATT RECOG, P3270, DOI 10.1109/ICPR.2016.7900139
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
NR 32
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15695
EP 15713
DI 10.1007/s11042-022-13791-2
EA OCT 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000869338900001
DA 2024-07-18
ER

PT J
AU Xin, Y
   Wei, YF
   Huang, Z
   Jia, ZH
   Yang, J
   Kasabov, NK
AF Xin, Ye
   Wei, Yifei
   Huang, Zhuang
   Jia, Zhenhong
   Yang, Jie
   Kasabov, Nikola K.
TI A fast and effective algorithm for specular reflection image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Specular reflection image enhancement; Dark channel prior; Weighting
   function; Guided image filtering (GIf); Adaptive magnification factor
ID HIGHLIGHT REMOVAL; SEPARATION; COMPONENTS
AB Aiming at the problems of image quality degradation and information loss in images affected by reflections in real scenes, this paper proposes a fast and effective specular reflection image enhancement algorithm. This method uses the dark channel prior algorithm to process the specular image, in which the moving window minimum filter is used to estimate the global illumination component of the specular image, and a weighting function based on local pixel chromatic aberration is introduced under the boundary constraints. Then, it uses an improved guided image filtering algorithm to enhance the image, introduces adjustment parameters based on local variance information in the cost function of the guided filtering algorithm, and introduces an adaptive magnification factor in the detail layer. Finally, we compare the algorithm in this paper with the existing algorithms in subjective vision and objective evaluation. The results show that the calculation speed of this method is faster, and it can effectively enhance the information in the reflection image, and simultaneously effectively improve the clarity of the image.
C1 [Xin, Ye; Wei, Yifei; Huang, Zhuang; Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200400, Peoples R China.
   [Kasabov, Nikola K.] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 1020, New Zealand.
C3 Xinjiang University; Shanghai Jiao Tong University; Auckland University
   of Technology
RP Jia, ZH (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Key Lab Signal Detect & Proc, Urumqi 830046, Peoples R China.
EM jzhh@xju.edu.cn
RI Sun, Xinyu/JXX-2281-2024; Yang, Jie/JCD-9867-2023; Kasabov, Nikola
   Kirilov/JQJ-5530-2023
FU National Natuaral Science Foundation of China [U1803261]
FX This research was funded by the National Natuaral Science Foundation of
   China with Grant U1803261. We would like to thank the referees for their
   efforts to review our manuscript, as well as for their valuable
   suggestions and questions.
CR Akashi Y., 2014, SEPARATION REFLECTIO
   Ngo D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185170
   Fu G, 2019, COMPUT GRAPH FORUM, V38, P253, DOI 10.1111/cgf.13834
   Guo J, 2018, LECT NOTES COMPUT SC, V11208, P282, DOI 10.1007/978-3-030-01225-0_17
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Guo XJ, 2014, PROC CVPR IEEE, P2195, DOI 10.1109/CVPR.2014.281
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang Z, 2021, IEEE ACCESS, V9, P154513, DOI 10.1109/ACCESS.2021.3128939
   Kansal I, 2020, MULTIMED TOOLS APPL, V79, P12069, DOI 10.1007/s11042-019-08240-6
   Kim H, 2013, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR.2013.192
   Kordelas GA, 2016, IEEE T MULTIMEDIA, V18, P155, DOI 10.1109/TMM.2015.2505905
   Li C, 2017, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2017.297
   Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Lu ZW, 2018, IEEE SIGNAL PROC LET, V25, P1585, DOI 10.1109/LSP.2018.2867896
   Mallick SP, 2006, LECT NOTES COMPUT SC, V3951, P550
   Mallick SP, 2005, PROC CVPR IEEE, P619
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Ramos VS, 2020, IEEE ACCESS, V8, P3240, DOI 10.1109/ACCESS.2019.2963037
   Ren WH, 2017, IEEE T IMAGE PROCESS, V26, P2327, DOI 10.1109/TIP.2017.2675204
   Saha R, 2020, IET IMAGE PROCESS, V14, P1851, DOI 10.1049/iet-ipr.2019.1099
   Shen HL, 2008, PATTERN RECOGN, V41, P2461, DOI 10.1016/j.patcog.2008.01.026
   Shen HL, 2013, APPL OPTICS, V52, P4483, DOI 10.1364/AO.52.004483
   Son M, 2020, IEEE T IMAGE PROCESS, V29, P4204, DOI 10.1109/TIP.2020.2967857
   Suo JL, 2016, IEEE T IMAGE PROCESS, V25, P5441, DOI 10.1109/TIP.2016.2605002
   Nguyen T, 2014, APPL OPTICS, V53, P7924, DOI 10.1364/AO.53.007924
   Tan P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P164, DOI 10.1109/ICCV.2003.1238333
   Ting Zhu, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12305), P422, DOI 10.1007/978-3-030-60633-6_35
   Wei X, 2018, COMPUT VIS IMAGE UND, V168, P132, DOI 10.1016/j.cviu.2017.10.010
   Wei YF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112311497
   Xia WY, 2019, IEEE ACCESS, V7, P125976, DOI 10.1109/ACCESS.2019.2939229
   Xin Y, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3053906
   Yamamoto T, 2019, ITE TRANS MEDIA TECH, V7, P92, DOI 10.3169/mta.7.92
   Yang JW, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P891, DOI 10.1109/ICCVW.2013.122
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Zheng MY, 2020, IEEE SENS J, V20, P8062, DOI 10.1109/JSEN.2020.2981719
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 41
TC 0
Z9 0
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 14897
EP 14914
DI 10.1007/s11042-022-13706-1
EA OCT 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000867602700003
DA 2024-07-18
ER

PT J
AU Hui, S
   Sai, M
   Jian, Z
   Zhang, ZY
   Dan, H
AF Hui, Shi
   Sai, Ma
   Jian, Zhao
   Zhang Zhiyu
   Dan, Huang
TI A separable and dual data hiding algorithm based on adaptive ternary
   segmentation coding and ZN-shape space-filling curve
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ternary segmentation (TS); Hidden pixel pair (HPP); Lucas-Arnold
   scrambling (LAS); Separable keys; Reversible data hiding; Zero data
   hiding
ID IMAGE ENCRYPTION; MOMENTS; CHAOS
AB Considering the applications of requiring high fidelity of multimedia content, and for the purpose of copyright protection, a separable and dual data hiding algorithm is proposed. In this paper, the definitions of Ternary Segmentation (TS), Hidden Pixel Pair (HPP), ZN-shape space-filling curve, and Lucas-Arnold Scrambling (LAS) are presented for the first time. By virtue of without degrading the quality of the host image, this paper combines reversible data hiding and zero data hiding to solves the contradiction between robustness and imperceptibility. Firstly, 1-level reversible data hiding is performed using TS, HPP and Huffman compression. Then, 2-level zero data hiding is adopted based on LAS, IWT (Integer Wavelet Transform), BN-SVD(Boost Normed Singular Value Decomposition) and ZN-shape space-filling curve. Finally, separable decryption and extraction is conducted. The experiment results prove that the proposed scheme achieves a better image perceptual quality with an average PSNR of about 49 dB, and stronger robustness with an average NCC of about 0.99 under various attacks. Moreover, it achieves higher security, and the average values of information entropy, correlation coefficient, NPCR and UACI are 7.9, 0.01, 99.6854% and 33.4378%, respectively.
C1 [Hui, Shi; Sai, Ma; Jian, Zhao; Zhang Zhiyu; Dan, Huang] Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Hui, S (corresponding author), Liaoning Normal Univ, Comp & Informat Technol Coll, Dalian 116029, Peoples R China.
EM shihui_jiayou@126.com
RI Sai, Ma/HDO-8143-2022
FU Scientific Research Program - Liaoning Provincial Education Department
   [WQ2020014]; Key Research Project of Dalian academy of social sciences
   [2020dlsky042, 2021dlsky027]; Liaoning Planning Office of Philosophy and
   Social Science (CN) [L19BTQ001]; National Youth Science Foundation of
   China [61601214]
FX This work was supported by the Scientific Research Program Funded by
   Liaoning Provincial Education Department (Grant No. WQ2020014), the Key
   Research Project of Dalian academy of social sciences (Grant No.
   2020dlsky042, 2021dlsky027) and Liaoning Planning Office of Philosophy
   and Social Science (CN) (Grant L19BTQ001), the National Youth Science
   Foundation of China(61601214).
CR Abdel-Nabi H, 2021, MULTIMEDIA SYST, V27, P229, DOI 10.1007/s00530-020-00732-y
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   [Anonymous], 2016, Kodak lossless true color image suite
   [Anonymous], 2016, UCID UNCOMPRESSED CO
   [Anonymous], 2016, USC-SIPI image database
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Hu K, 2021, VISUAL COMPUT, V37, P2841, DOI 10.1007/s00371-021-02168-5
   Jiang XY, 2018, ARXIV
   Kaur G, 2021, MULTIDIM SYST SIGN P, V32, P533, DOI 10.1007/s11045-020-00748-7
   Li LJ, 2020, L N INST COMP SCI SO, V336, P439, DOI 10.1007/978-3-030-63095-9_28
   Li Q, 2022, IEEE T CIRC SYST VID, V32, P5695, DOI 10.1109/TCSVT.2021.3138795
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Li Q, 2021, NEURAL PROCESS LETT, V53, P4037, DOI 10.1007/s11063-021-10582-y
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   [梁锡坤 Liang Xikun], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P325
   Liu J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040700
   Mansour RF, 2021, ARAB J SCI ENG, V46, P9129, DOI 10.1007/s13369-021-05716-2
   Nguyen TD, 2021, MULTIMED TOOLS APPL, V80, P13099, DOI 10.1007/s11042-020-10347-0
   Pal P, 2021, MULTIMED TOOLS APPL, V80, P21651, DOI 10.1007/s11042-021-10651-3
   Priya C, 2021, CIRC SYST SIGNAL PR, V40, P2464, DOI 10.1007/s00034-020-01585-6
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang JS, 2018, J BIOMED OPT, V23, DOI 10.1117/1.JBO.23.10.106002
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xia ZQ, 2022, APPL INTELL, V52, P607, DOI 10.1007/s10489-021-02476-2
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   [肖振久 Xiao Zhenjiu], 2019, [中国图象图形学报, Journal of Image and Graphics], V24, P1
   Yamni M, 2021, MULTIMED TOOLS APPL, V80, P21679, DOI 10.1007/s11042-021-10717-2
   [张新鹏 Zhang Xinpeng], 2005, [光电子·激光, Journal of Optoelectronics·Laser], V16, P956
   Zhou ZL, 2023, IET IMAGE PROCESS, V17, P3660, DOI 10.1049/ipr2.12143
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 40
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21205
EP 21241
DI 10.1007/s11042-022-14032-2
EA OCT 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000865376900001
DA 2024-07-18
ER

PT J
AU Chen, JY
   Chen, C
   Tan, L
   Peng, SX
AF Chen, Jingying
   Chen, Chang
   Tan, Lei
   Peng, Shixin
TI Channel decoupling network for cross-modality person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Cross modality; Channel decoupling
AB Cross-modality person re-identification (CM-ReID) is a very challenging problem due to the discrepancy in data distributions between visible and near-infrared modalities. To obtain a robust sharing feature representation, existing methods mainly focus on image generation or feature constrain to decrease the modality discrepancy, which ignores the large gap between mixed-spectral visible images and single-spectral near-infrared images. In this paper, we address the problem by decoupling the mixed-spectral visible images into three single-spectral subspaces R, G, and B. By aligning the spectrum, we noted that even using a single spectral image instead of the VIS images could result in a better performance. Based on the above observation, we further introduce a clear and effective three-path channel decoupling network (CDNet) for combining the three spectral images. Extensive experiments implemented on the benchmark CM-ReID datasets, SYSU-MM01 and RegDB indicated that our method achieved state-of-the-art performance and outperformed existing approaches by a large margin. On the RegDB dataset, the absolute gain of our method in terms of rank-1 and mAP is well over 15.4% and 8.5%, respectively, compared with the state-of-the-art methods.
C1 [Chen, Jingying; Chen, Chang; Tan, Lei; Peng, Shixin] Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
C3 Central China Normal University
RP Peng, SX (corresponding author), Cent China Normal Univ, Natl Engn Res Ctr E Learning, Wuhan, Peoples R China.
EM chenjy@mails.ccnu.edu.cn; cherishappinecc2011@gmail.com;
   lei.tan@mails.ccnu.edu.cn; pengshixin@mail.ccnu.edu.cn
FU National Natural Science Foundation of China [61702208]; Hubei
   Technological Innovation Special Fund [61702208]; MOE (Ministry of
   Education in China) Project of Humanities and Social Sciences
   [19YJC880068]; Hubei Provincial Natural Science Foundation of China
   [2019CFB347]; China Postdoctoral Science Foundation [2018M632889,
   2022T150250]
FX This work is funded in part by the National Natural Science Foundation
   of China (No.61702208),the Hubei Technological Innovation Special
   Fund(No.61702208), the MOE (Ministry of Education in China) Project of
   Humanities and Social Sciences (No.19YJC880068), the Hubei Provincial
   Natural Science Foundation of China (No.2019CFB347), the China
   Postdoctoral Science Foundation (No.2018M632889, No.2022T150250).
CR Arora M, 2018, NATL ACAD SCI LETT, V41, P365, DOI 10.1007/s40009-018-0694-2
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Hao X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16383, DOI 10.1109/ICCV48922.2021.01609
   Hao Y, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107533
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Jia MX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1026
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Lin GJ, 2021, NEUROCOMPUTING, V453, P777, DOI 10.1016/j.neucom.2020.05.111
   Liu LY, 2019, IEEE INT SYMP PARAL, P1436, DOI 10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00206
   Liu Y, 2020, NEUROCOMPUTING, V414, P27, DOI 10.1016/j.neucom.2020.07.020
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wu AC, 2020, INT J COMPUT VISION, V128, P1765, DOI 10.1007/s11263-019-01290-1
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu DM, 2022, IEEE T INF FOREN SEC, V17, P115, DOI 10.1109/TIFS.2021.3075894
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yang F, 2020, AAAI CONF ARTIF INTE, V34, P12589
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P924, DOI 10.1109/TPAMI.2020.3013379
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Zhang YK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P788, DOI 10.1145/3474085.3475250
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
NR 47
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14091
EP 14105
DI 10.1007/s11042-022-13927-4
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000863188000004
DA 2024-07-18
ER

PT J
AU Gao, Y
   Che, XJ
   Liu, QL
   Bie, M
   Xu, H
AF Gao, Yan
   Che, Xiangjiu
   Liu, Quanle
   Bie, Mei
   Xu, Huan
TI SFSM: sensitive feature selection module for image semantic segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Convolutional neural network; Deep learning;
   Feature selection; Attention mechanism
ID NETWORK
AB One of the great challenges for image semantic segmentation is the loss of object details caused by the extensive use of convolution and pooling operations, such as blurred edges and lines, ignoring small objects, etc. To address these problems, we propose the sensitive feature selection module (SFSM), which learns the distribution characteristics of each pixel on different channels at the same location by utilizing the feature maps from prior convolution layers. Then, the obtained weights are used to reweight each pixel on different channels, so that the object boundaries and small objects can be better focused by the network in the feature extraction process. At last, the information obtained by SFSM is combined with the original features to further improve the feature representation and help to obtain more accurate segmentation results. Experimental results show that our SFSM algorithm can improve the performance of semantic segmentation networks. By integrating our SFSM into FCN and DeepLabv3, we can get 0.21% and 0.6% accuracy improvement on the PASCAL VOC 2012 dataset respectively. For the Cityscapes dataset, although the segmentation task is relatively complicated, our improved networks still achieve excellent performance. To further verify our module is not restricted to specific networks or datasets, we embed it into DoubleU-Net to do medical image segmentation task on dataset ISIC-2018 and get 0.16% accuracy improvement.
C1 [Gao, Yan; Che, Xiangjiu; Liu, Quanle; Bie, Mei; Xu, Huan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Bie, Mei] Changchun Normal Univ, Inst Educ, Changchun 130032, Peoples R China.
C3 Jilin University; Changchun Normal University
RP Che, XJ (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM chexj@jlu.edu.cn
RI Liu, Quanle/AAL-9648-2020
OI Liu, Quanle/0000-0001-7565-8024
FU National Natural Science Foundation of China [62172184]; Science and
   Technology Development Plan of Jilin Province of China [20200401077GX,
   20200201292JC]; Social Science Research of the Education Department of
   Jilin Province [JJKH20210901SK]; Jilin Educational Scientific Research
   Leading Group [ZD21003]; Humanities and Social Science Foundation of
   Changchun Normal University [2020[011]]
FX This work was financially supported by National Natural Science
   Foundation of China under Grant 62172184, Science and Technology
   Development Plan of Jilin Province of China under Grant 20200401077GX
   and 20200201292JC, Social Science Research of the Education Department
   of Jilin Province (JJKH20210901SK), Jilin Educational Scientific
   Research Leading Group (ZD21003), and Humanities and Social Science
   Foundation of Changchun Normal University (2020[011]).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Ding HH, 2019, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2019.00909
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Ess A, 2009, BMVC, V1, P2
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Geiger A., 2012, CVPR
   Guo M, 2023, NAT PROD RES, V37, P1411, DOI 10.1080/14786419.2021.2011271
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong Y., 2021, ARXIV
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jha D, 2020, COMP MED SY, P558, DOI 10.1109/CBMS49503.2020.00111
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Ke TW, 2018, LECT NOTES COMPUT SC, V11205, P605, DOI 10.1007/978-3-030-01246-5_36
   Kim JH, 2016, ADV NEUR IN, V29
   Larochelle H., 2010, ADV NEURAL INFORM PR, V23, P1243
   Li XX, 2017, PROC CVPR IEEE, P6459, DOI 10.1109/CVPR.2017.684
   Li Z., 2021, arXiv
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maaz M., 2022, ARXIV
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oberweger M, 2015, ARXIV
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seichter D, 2021, IEEE INT CONF ROBOT, P13525, DOI 10.1109/ICRA48506.2021.9561675
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava RK, 2015, ADV NEUR IN, V28
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takahashi N, 2021, PROC CVPR IEEE, P993, DOI 10.1109/CVPR46437.2021.00105
   Valada A, 2020, INT J COMPUT VISION, V128, P1239, DOI 10.1007/s11263-019-01188-y
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xie Enze, 2021, ARXIV210515203, DOI DOI 10.48550/ARXIV.2105.15203
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan H., 2022, ARXIV
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang X, 2021, PROC CVPR IEEE, P13951, DOI 10.1109/CVPR46437.2021.01374
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 67
TC 2
Z9 2
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13905
EP 13927
DI 10.1007/s11042-022-13901-0
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600009
DA 2024-07-18
ER

PT J
AU Bialecki, A
   Gajewski, J
   Bialecki, P
   Phatak, A
   Memmert, D
AF Bialecki, Andrzej
   Gajewski, Jan
   Bialecki, Piotr
   Phatak, Ashwin
   Memmert, Daniel
TI Determinants of victory in Esports-StarCraft II
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Esports; Performance analysis; Gaming; Starcraft; Real-time strategy
ID SPORT
AB Esports offer a unique opportunity to conduct human performance studies, as they use modern hardware and software as an operation platform. Insights on gameplay and underlying processes may push the development of new and optimal practice methods. The aim of this study was to investigate performance indicators from in-game data to predict the outcome of the matches in StarCraft II: Legacy of The Void. Data from 6509 games (game records) provided by 5 players at the level of Master or GrandMaster were used. The distribution of analyzed players concerning the preferred in-game race was as follows: "Protoss" (n = 3), "Zerg" (n = 1), "Terran" (n = 1). Each game record contained data for both the winner and the loser. In total, 3719 game records and 9 performance indicators were obtained after applying the inclusion criteria. Logistic regression with 5-fold cross-validation was performed to predict the game outcome. The model was able to discriminate the game outcome (won, lost) with an out-of-sample accuracy of 0.728 +/- 0.021. The performance indicators which showed the strongest effect in predicting the game outcome were "minerals lost army" [p-value< 0.001, std_odds_ratio: 0.069], "minerals killed army" [p-value< 0.001, std_odds_ratio: 6.446], "minerals used current army" [p-value< 0.001, std_odds_ratio: 4.081], and "minerals killed economy" [p-value< 0.001, std_odds_ratio: 2.896]. It seems evident that winner optimized interaction with an opponent by keeping his/her own army intact while inflicting damage to the opponent's army or economy. In conclusion, the effective use of the army, based on optimizing the ratio between units lost and units killed, may be significant in predicting the game outcome.
C1 [Bialecki, Andrzej] Warsaw Univ Technol, Pl Politech 1, PL-00661 Warsaw, Poland.
   [Gajewski, Jan] Jozef Pilsudski Univ Phys Educ Warsaw, Marymoncka 34, PL-00968 Warsaw, Poland.
   [Phatak, Ashwin; Memmert, Daniel] Inst Exercise Training & Sport Informat, Sportpk Mungersdorf 6, D-50933 Cologne, Germany.
C3 Warsaw University of Technology; Jozef Pilsudski University Physical
   Education in Warsaw
RP Bialecki, A (corresponding author), Warsaw Univ Technol, Pl Politech 1, PL-00661 Warsaw, Poland.
EM a.phatak@dshs-koeln.de
RI Gajewski, Jan/B-7781-2018; Białecki, Andrzej/HZL-8792-2023
OI Gajewski, Jan/0000-0002-2146-6198; Białecki,
   Andrzej/0000-0003-3668-4638; Phatak, Ashwin/0000-0003-1772-8949;
   Memmert, Daniel/0000-0002-3406-9175
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Alligulac, 2013, STARCRAFT 2 PROGAMIN
   Barr P, 2007, INTERACT COMPUT, V19, P180, DOI 10.1016/j.intcom.2006.08.008
   Bednárek D, 2017, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON DATA SCIENCE, TECHNOLOGY AND APPLICATIONS (DATA), P269, DOI 10.5220/0006475002690276
   Blizzard, 2013, S2 PROTOCOL
   Braun P, 2017, PROCEDIA COMPUT SCI, V112, P2259, DOI 10.1016/j.procs.2017.08.141
   Buro M, 2014, GLOBAL STATE EVALUAT
   Consalvo M., 2011, The handbook of internet studies, DOI DOI 10.1002/9781444314861
   Drachen A., 2009, MINDTREK C EV LIF UB, P182, DOI [10.1145/1621841.1621875, DOI 10.1145/1621841.1621875]
   Edge N., 2013, The Elon Journal of Undergraduate Research in Communication, V4, P33
   Edwards Tyler F.M., 2013, ESPORTS: A BRIEF HISTORY
   Esport Earnings, 2012, ESPORTS EARNINGS PRI
   Freihaut P, 2021, INT J HUM-COMPUT ST, V145, DOI 10.1016/j.ijhcs.2020.102520
   Gaming B, 2018, HIST EVOLUTION ESPOR
   Good O., 2012, KOTAKU
   H2O.ai, 2020, H2O PYTHON INTERFACE
   Hallmann K, 2018, SPORT MANAG REV, V21, P14, DOI 10.1016/j.smr.2017.07.011
   Hutchins B, 2008, NEW MEDIA SOC, V10, P851, DOI 10.1177/1461444808096248
   Intel, 2020, INTEL BRINGS ESPORTS
   Jaderberg M, 2019, SCIENCE, V364, P859, DOI 10.1126/science.aau6249
   Justesen N, 2020, IEEE T GAMES, V12, P1, DOI 10.1109/TG.2019.2896986
   Kane D., 2017, The Sport Journal, V20, punpaginated
   Kato T, 2013, PLOS ONE, V8, DOI [10.1371/journal.pone.0072540, 10.1371/journal.pone.0064007]
   Kaytoue M., 2012, Proceedings of the 21st International Conference Companion on World Wide Web-WWW'12 Companion, P1181, DOI [DOI 10.1145/2187980.2188259, 10.1145/2187980.2188259]
   Kim M-J, 2016, P 2016 CHI C HUM FAC, P05, DOI [10.1145/2851581.2892305, DOI 10.1145/2851581.2892305]
   Kow YongMing., 2013, Proceedings of the 2013 Conference on Computer Supported Cooperative Work - CSCW'13, P387, DOI DOI 10.1145/2441776.2441821
   Lee D, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115592
   Liquipedia, 2010, BATTLENET LEAGUES
   Liquipedia, 2011, STALEMATE DETECTION
   Liquipedia, 2012, INTERNATIONAL
   Asensio JML, 2014, EXPERT SYST APPL, V41, P7281, DOI 10.1016/j.eswa.2014.05.004
   Low-Kam C, 2013, IEEE DATA MINING, P488, DOI 10.1109/ICDM.2013.124
   Menard S, 2011, SOC FORCES, V89, P1409, DOI 10.1093/sf/89.4.1409
   Paszke A, 2019, ADV NEUR IN, V32
   Ramos G, 2020, HUM-COMPUT INTER-US, V35, P413, DOI 10.1080/07370024.2020.1734931
   Ranked For Teh Win, 2013, STARCRAFT 2 LADDER R
   Reitman JG, 2020, GAMES CULT, V15, P32, DOI 10.1177/1555412019840892
   Sánchez-Ruiz AA, 2017, ENTERTAIN COMPUT, V19, P29, DOI 10.1016/j.entcom.2016.11.005
   Sarlis V, 2020, INFORM SYST, V93, DOI 10.1016/j.is.2020.101562
   Schubert M, 2016, MANAGE INT REV, P1
   Si C, 2017, ENTERTAIN COMPUT, V19, P13, DOI 10.1016/j.entcom.2016.11.003
   Silberman S., 2015, Neurotribes: The legacy of autism and the future of neurodiversity
   Sozanski H, MONOGRAFIE OPRACOWAN, V23
   Taylor TL, 2012, RAISING THE STAKES: E-SPORTS AND THE PROFESSIONALIZATION OF COMPUTER GAMING, P1
   Thiel A, 2018, EUR J SPORT SOC, V15, P311, DOI 10.1080/16138171.2018.1559019
   Uriarte A, 2018, IEEE T GAMES, V10, P29, DOI 10.1109/TCIAIG.2017.2669895
   Yulia C., 2019, Sports and Economics, P477
NR 47
TC 3
Z9 3
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11099
EP 11115
DI 10.1007/s11042-022-13373-2
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854429500004
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Rajee, MV
   Mythili, C
AF Rajee, M., V
   Mythili, C.
TI Novel technique for caries detection using curvilinear semantic deep
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dental X-ray image; Segmentation; Notch filter
ID SEGMENTATION; ALGORITHM
AB Radiography image processing is a technique used for processing radiography images using mathematical operations in which the input is a dental X- ray image or a sequence of X- ray images. The accuracy related segmentation for tooth images forms key point in computer based algorithms. To the great extent image processing techniques has two dimensional images used for processing. The methods of dental X-ray image diagnostic procedure are well established in the dentistry field. This is very useful to the dentist to get extra diagnostic information. Typically, in dental X-ray images, detection of caries and other hard tissues are challenging tasks. These x-ray images have unwanted noises that lead to poor diagnostic information. The main aim of proposed dental image processing system is to remove the unwanted noises at first with the help of robust Hybrid Binary Thresholding with Notch Filter (HBT-NF). The next step with the segmentation of caries, hard tissues from tooth lies with proposed Curvilinear Semantic Deep Convolutional neural network. Finally the teeth are separated from hard tissues and caries at high accuracy of 93.7%. Experimental results on the real dental X-ray images of the proposed system will give better effectiveness compared with other detection methods.
C1 [Rajee, M., V] Anna Univ, Dept Informat & Commun Engn, Chennai, Tamil Nadu, India.
   [Mythili, C.] Univ Coll Engn, Dept Elect & Elect Engn, Nagercoil, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University of Technology Tirunelveli
RP Rajee, MV (corresponding author), Anna Univ, Dept Informat & Commun Engn, Chennai, Tamil Nadu, India.
EM rajeemv82@gmail.com; mythiliselva@yahoo.co.in
CR Abualhaj B, 2017, MED PHYS, V44, P209, DOI 10.1002/mp.12025
   Ali M, 2018, EXPERT SYST APPL, V91, P434, DOI 10.1016/j.eswa.2017.09.027
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Arshad A, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P365, DOI 10.1109/ITOEC.2017.8122317
   Buhari M. P. A., 2020, International Journal of Computers and Applications, V42, P17, DOI 10.1080/1206212X.2017.1396422
   Chauhan N.C, 2019, DENT IMAGE ANAL DIS, P103, DOI DOI 10.1007/978-3-030-14136-3_6
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Gong SJ, 2019, J ENG-JOE, P543, DOI 10.1049/joe.2018.9377
   Guido RC, 2019, J FRANKLIN I, V356, P2346, DOI 10.1016/j.jfranklin.2018.12.007
   Guido RC, 2016, NEUROCOMPUTING, V179, P264, DOI 10.1016/j.neucom.2015.12.012
   Gupta VK., 2022, Int. J. Mod. Res, V2, P1, DOI DOI 10.1109/INDISCON53343.2021.9582222
   Huang H, 2019, IEEE ACCESS, V7, P12386, DOI 10.1109/ACCESS.2019.2893063
   Karthick G., 2017, 2017 4th International Conference on Electronics and Communication Systems (ICECS). Proceedings, P88, DOI 10.1109/ECS.2017.8067843
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khammari M, 2019, IET IMAGE PROCESS, V13, P1880, DOI 10.1049/iet-ipr.2018.5560
   Krishan A, 2020, BIOMED ENG-BIOMED TE, V65, P301, DOI 10.1515/bmt-2018-0175
   Kumar A, 2020, MULTIMED TOOLS APPL, V79, P2745, DOI 10.1007/s11042-019-08268-8
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Li QY, 2017, CAAI T INTELL TECHNO, V2, P109, DOI 10.1049/trit.2017.0013
   Lin WY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77264-y
   Lingappa AZA, 2018, INT SOC OPTICS PHOTO
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Said EH, 2004, PROC SPIE, V5404, P409, DOI 10.1117/12.541658
   Shang RH, 2017, IEEE J-STARS, V10, P5657, DOI 10.1109/JSTARS.2017.2743338
   Shen L., 2020, IEEE T INSTRUM MEAS, V70, P1
   Song JH, 2019, INFORMATION, V10, DOI 10.3390/info10020074
   Strisciuglio N, 2019, IEEE T IMAGE PROCESS, V28, P5852, DOI 10.1109/TIP.2019.2922096
   Su LL, 2018, IEEE ACCESS, V6, P19993, DOI 10.1109/ACCESS.2018.2815031
   Suresh R, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.5293
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Veena Divya Krishnappa, 2019, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2017. Advances in Intelligent Systems and Computing (AISC 713), P25, DOI 10.1007/978-981-13-1708-8_3
   Wang HB, 2019, IEEE ACCESS, V7, P108261, DOI 10.1109/ACCESS.2019.2928472
   Yin SH, 2020, BIOPHYS J, V118, P2458, DOI 10.1016/j.bpj.2020.04.009
   Zheng J, 2018, IET IMAGE PROCESS, V12, P785, DOI 10.1049/iet-ipr.2017.0760
NR 36
TC 1
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10745
EP 10762
DI 10.1007/s11042-022-13789-w
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000854682700004
DA 2024-07-18
ER

PT J
AU Dhanushree, M
   Chitrakala, S
   Bhatt, CM
AF Dhanushree, M.
   Chitrakala, S.
   Bhatt, C. M.
TI Robust human detection system in flood related images with data
   augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram of oriented gradients (HOG); Support vector machine (SVM);
   Data augmentation; Non-maximum suppression
AB Floods are one of the major natural disasters that are very common in monsoon countries like India. They cause enormous damage, both to properties and to human lives. It is very essential to detect humans in flooded environments, which plays an important role in rescue management, disaster management, flood assessment, etc. Detection in a flooded environment is particularly challenging due to the weather conditions, which affect the efficiency of the detection system. The limited availability of proper datasets with natural weather changes also affects the robustness of human object detection in flooded images. In this paper, data augmentation techniques are introduced in order to mimic the changing weather conditions such as rainy, cloudy, and foggy days during flood times, and a HOG-based Robust Human Object Detection (HOG_based_RHOD) algorithm is proposed and has been demonstrated on the augmented dataset. The proposed HOG_based_RHOD algorithm detects human objects in flood-related images, demonstrating its robustness in a variety of challenging weather conditions.
C1 [Dhanushree, M.; Chitrakala, S.] Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Bhatt, C. M.] Indian Inst Remote Sensing, Disaster Management Studies, Dehra Dun, Uttarakhand, India.
C3 Anna University; Anna University Chennai; Department of Space (DoS),
   Government of India; Indian Space Research Organisation (ISRO); Indian
   Institute of Remote Sensing (IIRS)
RP Dhanushree, M (corresponding author), Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM dhanushree269@gmail.com; chitrakala.au@gmail.com
RI S, Chitrakala/T-9631-2019; S, C/JLK-9983-2023; M,
   DHANUSHREE/AAP-3535-2021
OI M, DHANUSHREE/0000-0003-1747-7617
FU RESPOND project - Indian Space Research Organization [ISRO-IIRS 007,
   RES/4/676/19-20]
FX This work has been supported by the RESPOND project funded by the Indian
   Space Research Organization (ISRO-IIRS 007) under Grant No:
   RES/4/676/19-20".
CR Aarthy KP, 2022, INT C COMPUT INTELL, P2021, DOI [10.1007/978-981-16-7182-1_17, DOI 10.1007/978-981-16-7182-1_17]
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chaudhary P., 2019, REMOTE SENSING SPATI, P5, DOI [10.3929/ethz-b-000351581, DOI 10.5194/ISPRS-ANNALS-IV-2-W5-5-2019]
   Chen HT, 2018, IEEE INT C MULTIMEDI, P1, DOI [10.1109/ICMEW.2018.8551501, DOI 10.1109/ICMEW.2018.8551501]
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalla Valle P, 2020, INT J PAVEMENT ENG, V21, P930, DOI 10.1080/10298436.2018.1517873
   Degrossi L.C., 2014, SEKE, P570
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Feng Y, 2020, ISPRS J PHOTOGRAMM, V169, P301, DOI 10.1016/j.isprsjprs.2020.09.011
   Fujimoto Y, 2019, IEEE ACCESS, V7, P12206, DOI 10.1109/ACCESS.2019.2892197
   Geetha M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P603, DOI 10.1109/ICCSP.2017.8286429
   Giannelli P., 2018, IEEE 13 IM VID MULT, V68, P1, DOI DOI 10.1109/IVMSPW.2018.8448732
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Keerthana T., 2019, INT RES J ENG TECHNO
   Liu T., 2018, 2018 IEEE International Conference on Consumer Electronics (ICCE), P1
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Nasim M, 2019, INT J ENG ADV TECHNO, V4, P2249
   Nikouei SY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P125, DOI 10.1109/EDGE.2018.00025
   Okafor E, 2018, J INFORM TELECOMMUN, V2, P465, DOI 10.1080/24751839.2018.1479932
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Quan Khanh-An C., 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P479, DOI 10.1145/3372278.3390704
   Salehinejad H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3016, DOI 10.1109/ICASSP.2018.8462241
   Smith L, 2017, J FLOOD RISK MANAG, V10, P370, DOI 10.1111/jfr3.12154
   Wang RQ, 2018, COMPUT GEOSCI-UK, V111, P139, DOI 10.1016/j.cageo.2017.11.008
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zacharie M, 2018, INT CONF INTEL INFOR, P230, DOI 10.1109/ICIIBMS.2018.8549955
   Zhu JG, 2020, IEEE WINT CONF APPL, P1380, DOI 10.1109/WACV45572.2020.9093280
NR 27
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10661
EP 10679
DI 10.1007/s11042-022-13760-9
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852929600001
DA 2024-07-18
ER

PT J
AU Rahman, SU
   Alam, F
   Ahmad, N
   Arshad, S
AF Rahman, Sami Ur
   Alam, Fakhre
   Ahmad, Niaz
   Arshad, Shakil
TI Image processing based system for the detection, identification and
   treatment of tomato leaf diseases.
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Tomato crop; Leaf diseases; Early blight; late blight;
   Septoria leaf spot
ID RECOGNITION
AB Disease detection and treatment in tomato plant at its early stage contributes towards better production. It is a natural phenomenon that normally tomato plant got disease and if a proper care and remedial action have not taken on time, it badly affects the respective product quality, quantity or productivity. Health monitoring and disease detection of leaves in tomato crop is very critical and if left untreated, can cause serious problems with the plant and fruit, resulting in large losses, especially in fresh markets. Traditional manual methods of disease detection and treatment is based on naked eye observation which cannot provide accurate and on time information at a very early stage of its attack. This paper presents an image processing based techniques for the automatic detection and treatment of leaf diseases in tomato crop. In the proposed method, 13 different statistical features are calculated from tomato leaves using Gray Level Co Occurrence Matrix (GLCM) algorithm. The obtained features are classified into different diseases using Support Vector Machine (SVM). The processed leaf is compared with the stored features on the basis of which disease is recognized. Data are collected from local tomato crop fields and the dataset is divided into a training set and a test set used in the experiments. Experimental results show that the proposed method provides excellent annotation with accuracy of 100% for healthy leaf, 95% for early blight, 90% for septoria leaf spot and 85% late blight. The proposed method is implemented in the form of a cell phone application.
C1 [Rahman, Sami Ur; Alam, Fakhre; Ahmad, Niaz; Arshad, Shakil] Univ Malakand, Dept Comp Sci & IT, Dir Lower, Kpk, Pakistan.
C3 University of Malakand
RP Alam, F (corresponding author), Univ Malakand, Dept Comp Sci & IT, Dir Lower, Kpk, Pakistan.
EM srahman@uom.edu.pk; fakhrealam@uom.edu.pk; sarshad@uom.edu.pk
FU King Khalid University of Saudi Arabia [R.G.P. 2/177/42]
FX The authors would like to thank King Khalid University of Saudi Arabia
   for supporting this research under grant number R.G.P. 2/177/42.
CR Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Anuradha K., 2013, J GLOBAL RES COMPUTE, V4, P8
   Arakeri MP., 2015, INT J ENG MANUF, V5, P12
   Basavaiah J, 2020, WIRELESS PERS COMMUN, V115, P633, DOI 10.1007/s11277-020-07590-x
   Bhowmik D., 2012, Journal of Pharmacognosy and Phytochemistry, V1, P33
   de Almeida CWD, 2010, IEEE SYS MAN CYBERN
   Din MZ, 2018, CLASSIFICATION DIS T, V23
   El Massi I, 2017, INT J COMPUT APPL, V158, P48
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hitimana E., 2014, Comput. Sci. Inf. Technol, V19, P255, DOI [10.5121/csit.2014.4221, DOI 10.5121/CSIT.2014.4221]
   Husin Z., 2013, International Journal of Digital Content Technology and its Applications, V7, P107, DOI 10.4156/jdcta.vol7.issue10.11
   Jabal M. F. A., 2013, Journal of Computer Science, V9, P1295, DOI [DOI 10.3844/J.CSSP.2013.1295.1304, 10.3844/jcssp.2013.1295.1304, DOI 10.3844/JCSSP.2013.1295.1304]
   Joshi B, 2011, MOL TAGGING RESISTAN, P1
   Kekre H.B., 2010, International Journal of Computer Theory and Engineering, P695
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Liu XD, 2021, IEEE T IMAGE PROCESS, V30, P2003, DOI 10.1109/TIP.2021.3049334
   Mokhtar U, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P246, DOI 10.1109/ICENCO.2015.7416356
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rao C.N., 2013, INT J INNOV RES SCI, V2, P4531
   Revathy R., 2015, INT J SCI ENG RES, V6, P391
   Sahoo M, 2011, 2 NAT C COMP COMM SE
   Sanaullah Noonari Sanaullah Noonari, 2015, Research on Humanities and Social Sciences, V5, P158
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Vala Hetal J., 2013, INT J ADV RES COMPUT, V2, P387, DOI DOI 10.1007/S11548-009-0389-8
   Walker RF, 1997, DSP 97: 1997 13TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P63, DOI 10.1109/ICDSP.1997.627968
NR 26
TC 19
Z9 19
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9431
EP 9445
DI 10.1007/s11042-022-13715-0
EA SEP 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000852263800001
DA 2024-07-18
ER

PT J
AU Chan, YK
   Lin, YC
   Wang, WJ
   Hu, WT
   Lin, CH
   Yu, SS
AF Chan, Yung-Kuan
   Lin, You-Cian
   Wang, Wei-Jyun
   Hu, Wan-Ting
   Lin, Chuen-Horng
   Yu, Shyr-Shen
TI Identifying <i>the occlusion</i> of left subclavian artery with stent
   based on chest MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE In-stent restenosis; Vascular obstruction; Left aortic arch; Left
   subclavian artery; Image segmentation
ID CT ANGIOGRAPHY
AB Left subclavian artery occlusion is frequently treated by stent placement. The most commented on In-Stent Restenosis is excessive thrombus that squeezes the stent and leads to vessel occlusion. In this paper, an automatic system is provided to segment the left subclavian arteries and left aortic arches from chest MRI (Magnetic Resonance Imaging) images, and then to identify the occlusion of left subclavian artery based on the gray-levels of the extracted left subclavian artery and left aortic arch. Experimental results show that the system obtains the accuracy rate 97.33% of detecting the occlusion of left subclavian artery. The other task in this paper is to explore the relationship between stent/vascular diameter ratio and restenosis of left subclavian artery after stenting. Besides that, the experimental results also show that Assurance is useful for reducing the restenosis of left subclavian artery with stent.
C1 [Chan, Yung-Kuan; Hu, Wan-Ting] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.
   [Lin, You-Cian] China Med Univ Hosp, Div Cardiovasc Surg, Taichung, Taiwan.
   [Wang, Wei-Jyun; Yu, Shyr-Shen] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung, Taiwan.
   [Lin, Chuen-Horng] Natl Taichung Inst Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Chung Hsing University; China Medical University Taiwan; China
   Medical University Hospital - Taiwan; National Chung Hsing University
RP Chan, YK (corresponding author), Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung, Taiwan.; Lin, YC (corresponding author), China Med Univ Hosp, Div Cardiovasc Surg, Taichung, Taiwan.
EM ykchan@nchu.edu.tw; linch@nutc.edu.tw
RI HU, WANTING/KLC-9257-2024; Wang, Wei-Jyun/KJM-4227-2024
OI Chan, Yung-Kuan/0000-0002-1556-0567
FU Ministry of Science and Technology, Taiwan, R.O.C. [110-2221-E-005-077]
FX The research leading to these results received funding from Ministry of
   Science and Technology, Taiwan, R.O.C. under Grant Agreement No.
   110-2221-E-005-077.
CR Aye CYL, 2017, PEDIATR RES, V82, P36, DOI 10.1038/pr.2017.96
   Baek JH, 2017, STROKE, V48, P2746, DOI 10.1161/STROKEAHA.117.018096
   Bonati LH, 2018, LANCET NEUROL, V17, P587, DOI 10.1016/S1474-4422(18)30195-9
   Boulahia SY, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01249-8
   Charlick M., 2021, ANATOMY HEAD NECK IN
   Chen K, 2021, ARXIV
   Chen X, 2018, ADV SCI, V5, DOI 10.1002/advs.201700560
   Chowdhury MM, 2020, JACC-CARDIOVASC IMAG, V13, P1008, DOI 10.1016/j.jcmg.2019.03.031
   Coffey S, 2017, EUR J PREV CARDIOL, V24, P1799, DOI 10.1177/2047487317732273
   Crespo J, 1994, COMP IMAG VIS, V2, P85
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Deng CF, 2022, IEEE T MULTIMEDIA, V24, P1968, DOI 10.1109/TMM.2021.3074273
   Dey D, 2019, J AM COLL CARDIOL, V73, P1317, DOI 10.1016/j.jacc.2018.12.054
   Gadzicki K, 2020, PROCEEDINGS OF 2020 23RD INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2020), P292
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gunnoo T, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2015-009535
   He ZW, 2020, IEEE T MULTIMEDIA, V22, P1042, DOI 10.1109/TMM.2019.2937688
   Hellinger JC, 2014, APPL RADIOL, V43, P10
   Horiuchi Y, 2018, INT J CARDIOL, V262, P57, DOI 10.1016/j.ijcard.2018.03.098
   Iwana BK, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107024
   Jarvis R. A., 1973, Information Processing Letters, V2, P18, DOI 10.1016/0020-0190(73)90020-3
   Kelm BM, 2011, LECT NOTES COMPUT SC, V6893, P25, DOI 10.1007/978-3-642-23626-6_4
   Lancaster MC, 2019, JACC-CARDIOVASC IMAG, V12, P1149, DOI 10.1016/j.jcmg.2018.02.005
   Liu H, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2686, DOI 10.1145/3394486.3403319
   Meijs M, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101810
   Migón P, 2020, GEOMORPHOLOGY, V367, DOI 10.1016/j.geomorph.2020.107308
   Nishie R, 2019, SURG CASE REP, V5, DOI 10.1186/s40792-019-0670-1
   Niu GC, 2020, FRONT NEUROL, V11, DOI 10.3389/fneur.2020.00264
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pandeya YR, 2021, MULTIMED TOOLS APPL, V80, P2887, DOI 10.1007/s11042-020-08836-3
   Sawicki M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110017
   Shlofmitz E, 2019, CIRC-CARDIOVASC INTE, V12, DOI 10.1161/CIRCINTERVENTIONS.118.007023
   Slomka PJ, 2017, EXPERT REV MED DEVIC, V14, P197, DOI 10.1080/17434440.2017.1300057
   Suryawati E, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00508-9
   SYSWERDA G, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P2
   Tan LK, 2018, J MAGN RESON IMAGING, V48, P140, DOI 10.1002/jmri.25932
   Tang SY, 2021, J SUPERCOMPUT, V77, P3870, DOI 10.1007/s11227-020-03422-8
   Tran L, DATA SCI
   Vaezi Joze Hamid Reza, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13286, DOI 10.1109/CVPR42600.2020.01330
   Trong VH, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105506
   Wang S, 2021, IEEE J BIOMED HEALTH, V25, P514, DOI 10.1109/JBHI.2020.2997760
   Waszyk-Nowaczyk M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9082572
   Wu YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204363
   Xu G, 2009, SECOND INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DESIGN, VOL 1, PROCEEDINGS, P60, DOI 10.1109/ISCID.2009.22
   Zhang D., 2012, 11 ANGL FRENCH PHYS, P1
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zreik M, 2018, MED IMAGE ANAL, V44, P72, DOI 10.1016/j.media.2017.11.008
NR 48
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10617
EP 10639
DI 10.1007/s11042-022-13735-w
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000852463800002
OA hybrid
DA 2024-07-18
ER

PT J
AU Thamizharasan, V
   Das, A
   Battaglino, D
   Bremond, F
   Dantcheva, A
AF Thamizharasan, Vikas
   Das, Abhijit
   Battaglino, Daniele
   Bremond, Francois
   Dantcheva, Antitza
TI Face attribute analysis from structured light: an end-to-end approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft biometrics; Age estimation; Gender estimation; Depth imagery;
   Structured light; IRDP; C-GAN
ID DATABASE
AB In this work we explore the use of structured-light imaging for face analysis. Towards this and due to lack of a publicly available structured-light face dataset, we (a) firstly generate a synthetic structured-light face dataset constructed based on the RGB-dataset London Face and the RGB-D dataset Bosphorus 3D Face. We then (b) propose a conditional adversarial network for depth map estimation from generated synthetic data. Associated quantitative and qualitative results suggest the efficiency of the proposed depth estimation technique. Further, we (c) study the estimation of gender and age directly from (i) structured-light, (ii) binarized structured-light, as well as (iii) estimated depth maps from structured-light. In this context we (d) study the impact of different subject-to-camera distances, as well as pose-variations. Finally, we (e) validate the proposed gender and age models that we train on synthetic data on a small set of real data, which we acquire. While these are early results, our findings clearly indicate the suitability of structured-light based approaches in facial analysis.
C1 [Thamizharasan, Vikas; Das, Abhijit; Bremond, Francois; Dantcheva, Antitza] Inria Sophia Antipolis Meediterranee, Antipolis, France.
   [Das, Abhijit] BITS Pilani, Pilani, Rajasthan, India.
   [Battaglino, Daniele] Blu Manta, Sophia Antipolis, Antipolis, France.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Das, A (corresponding author), Inria Sophia Antipolis Meediterranee, Antipolis, France.; Das, A (corresponding author), BITS Pilani, Pilani, Rajasthan, India.
EM abhijit.das@inria.fr
FU Company Blu Manta
FX Vikas Thamizharasan has received a research funding from the Company Blu
   Manta for this work.
CR Abate AF, 2019, CLUSTERING FACIAL AT
   [Anonymous], 2012, CONVOLUTIONAL RECURS
   Aytar Y, 2018, IEEE T PATTERN ANAL, V40, P2303, DOI 10.1109/TPAMI.2017.2753232
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bleyer M, 2013, ADV COMPUT VIS PATT, P143, DOI 10.1007/978-1-4471-5520-1_6
   Boutellaa E., 2017, THESIS ECOLE NATL SU
   Cai Y, 2019, NEUROCOMPUTING, V363, P375, DOI 10.1016/j.neucom.2019.07.047
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chowdhury Animesh R., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534285
   Cui JY, 2018, INT CONF BIOMETR, P140, DOI 10.1109/ICB2018.2018.00031
   Dantcheva A, 2017, IEEE T INF FOREN SEC, V12, P719, DOI 10.1109/TIFS.2016.2632070
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   DeBruine L M., 2017, Face research laboratory London set, DOI DOI 10.6084/M9.FIGSHARE.5047666.V3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Eigen D, 2014, ADV NEUR IN, V27
   Fanello SR, 2016, PROC CVPR IEEE, P5441, DOI 10.1109/CVPR.2016.587
   Freedman B., 2012, US Patent, Patent No. [8,150,142, 8150142]
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A., 2012, CVPR
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hansard M., 2012, Time-of-Flight Cameras: Principles, Methods and Applications
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kingma D. P., 2014, arXiv
   Kittler J, 2018, INT CONF BIOMETR, P124, DOI 10.1109/ICB2018.2018.00029
   KORTYLEWSKI A, 2018, ARXIV180205891
   Levi G, 2015, IEEE COMPUT SOC CONF
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Mathieu M., 2015, ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pilzer A, 2018, INT CONF 3D VISION, P587, DOI 10.1109/3DV.2018.00073
   Radford A., 2015, ARXIV
   Ratyal N, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/3547416
   Ren WQ, 2019, IEEE I CONF COMP VIS, P9387, DOI 10.1109/ICCV.2019.00948
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Rosales R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P472
   Rose J, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P1120, DOI 10.1145/3341161.3343525
   Rozsa A, 2019, PATTERN RECOGN LETT, V124, P100, DOI 10.1016/j.patrec.2017.10.024
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Shekhawat Hitendra Singh, 2020, Smart Systems and IoT: Innovations in Computing. Proceeding of SSIC 2019. Smart Innovation, Systems and Technologies (SIST 141), P801, DOI 10.1007/978-981-13-8406-6_75
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Taigman Y, 2016, ARXIV
   Tornow M, 2012, MACHINE VISION, P3, DOI [10.5772/34976, DOI 10.5772/34976]
   Vondrick C., 2016, ADV NEURAL INFORM PR, P613, DOI DOI 10.13016/M26GIH-TNYZ
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Xie JC, 2019, IEEE T INF FOREN SEC, V14, P2500, DOI 10.1109/TIFS.2019.2902823
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Zhang YD, 2018, LECT NOTES COMPUT SC, V11212, P802, DOI 10.1007/978-3-030-01237-3_48
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 66
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10471
EP 10490
DI 10.1007/s11042-022-13224-0
EA SEP 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000849487500004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Suji, RJ
   Godfrey, WW
   Dhar, J
AF Suji, R. Jenkin
   Godfrey, W. Wilfred
   Dhar, Joydip
TI Border to border distance based lung parenchyma segmentation including
   juxta-pleural nodules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Border to border; Distance computation; Lung nodules; Computed
   tomography; Thresholding
ID CT
AB Lung Segmentation is one of the pre-processing steps for lung cancer diagnosis. Segmentation of lung contour is challenging when the nodules are attached to the surrounding tissues of the lung, such as juxta-pleural boundary or vasculature. This paper proposes a lung parenchyma segmentation framework based on multiple image frames with novel approaches for juxta-pleural nodule identification and lung contour correction. The juxta-pleural nodule identification works by computing the distance between the lung borders on adjacent slices. These approaches extract the lung boundary of current and previous slices and calculate the shortest distance between the two boundary contour points to detect the nodule candidates and correct the nodule boundary. These approaches were experimented on at least 11 thoracic image volumes with juxta-pleural nodules from the LIDC-IDRI dataset and achieved an average volumetric overlap fraction of 98.59%. Compared with the other state-of-the-art methods, the proposed method is simple and very efficient for segmenting the lung parenchyma while including the juxta-pleural nodules.
C1 [Suji, R. Jenkin; Godfrey, W. Wilfred; Dhar, Joydip] ABV IIITM, Gwalior, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior
RP Suji, RJ (corresponding author), ABV IIITM, Gwalior, India.
EM sujijenkin@gmail.com; godfrey@iiitm.ac.in; jdhar@iiitm.ac.in
RI Dhar, Joydip/L-6769-2013
FU Kiran Division, Department of Science and Technology, Govt. of India
   [SR/WOSA/ET-153/2017]
FX The authors would like to acknowledge the Kiran Division, Department of
   Science and Technology, Govt. of India, for funding this research work
   through the SR/WOSA/ET-153/2017 Research Grant. The authors also thank
   the anonymous reviewers for their encouraging reviews and
   recommendations.
CR Amin Javeria, 2016, Immunology Endocrine & Metabolic Agents in Medicinal Chemistry, V16, P82, DOI 10.2174/187152221602161221215304
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Armato SG, 2004, ACAD RADIOL, V11, P1011, DOI 10.1016/j.acra.2004.06.005
   Chung H, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2837901
   Javaid M, 2016, COMPUT METH PROG BIO, V135, P125, DOI 10.1016/j.cmpb.2016.07.031
   Liu CX, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102032
   Mukhopadhyay S, 2016, J DIGIT IMAGING, V29, P86, DOI 10.1007/s10278-015-9801-9
   Nurfauzi R, 2021, J KING SAUD UNIV-COM, V33, P518, DOI 10.1016/j.jksuci.2019.02.009
   Nurfauzi R, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE AND TECHNOLOGY - COMPUTER (ICST), P57, DOI 10.1109/ICSTC.2017.8011852
   Pu J, 2008, COMPUT MED IMAG GRAP, V32, P452, DOI 10.1016/j.compmedimag.2008.04.005
   Rachid EA, 2016, IEEE C ANTENNA MEAS
   Sahu P, 2021, IEEE J BIOMED HEALTH, V25, P1151, DOI 10.1109/JBHI.2020.3004296
   Shen SW, 2015, COMPUT BIOL MED, V57, P139, DOI 10.1016/j.compbiomed.2014.12.008
   Singadkar G, 2021, J KING SAUD UNIV-COM, V33, P975, DOI 10.1016/j.jksuci.2018.07.005
   van Rikxoort EM, 2009, MED PHYS, V36, P2934, DOI 10.1118/1.3147146
   Wei Y, 2013, J DIGIT IMAGING, V26, P483, DOI 10.1007/s10278-012-9528-9
   Xiao XJ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050832
   Zhou SJ, 2014, BIOMED SIGNAL PROCES, V13, P62, DOI 10.1016/j.bspc.2014.03.010
NR 18
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10421
EP 10443
DI 10.1007/s11042-022-13660-y
EA AUG 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000847985800002
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Li, H
   Li, L
   Lu, JF
   Chang, CC
AF Zhang, Shanqing
   Li, Hui
   Li, Li
   Lu, Jianfeng
   Chang, Ching-Chun
TI A video watermarking algorithm based on time factor matrix
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermark; tensor; Time factor matrix; Geometric attack; Cropping
   attack
AB Recent studies of digital video watermarking have demonstrated the superiority of the core tensor as a robust feature against various attacks. However, embedding watermarks into the core tensor often introduces perceptible distortions to the host videos. In order to improve the imperceptibility while preserving the robustness, we propose a novel video watermarking algorithm based on a time factor matrix. By applying the Tucker decomposition, we transform the host video into the core tensor and three factor matrices representing the row, column and time axis directions of the video frames, respectively. We found that the first column of the time factor matrix contains the time correlation among frames of the video tensor, which is stable and does not change drastically after geometric deformation or cropping. Hence, our algorithm embeds the watermark by modifying the first column of the time factor matrix. The experimental results show that our algorithm is robust not only to attacks such as cropping, scaling, and rotation, but also to video-specific attacks such as frame deletion and video compression, which outperforms other tensor-based video watermarking algorithms.
C1 [Zhang, Shanqing; Li, Hui; Li, Li; Lu, Jianfeng] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Chang, Ching-Chun] Univ Warwick, Dept Comp Sci, Coventry, W Midlands, England.
C3 Hangzhou Dianzi University; University of Warwick
RP Zhang, SQ; Lu, JF (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM sqzhang@hdu.edu.cn; jflu@hdu.edu.cn
FU Public Welfare Technology and Industry Project of Zhejiang Provincial
   Science Technology Department [LGG19F020016, LGF21F020014]; National
   Natural Science Foundation of China [61802101]; "Pioneer" and "Leading
   Goose" R&D Program of Zhejiang [2022C03132]
FX This research was funded by the Public Welfare Technology and Industry
   Project of Zhejiang Provincial Science Technology Department (Grant No.
   LGG19F020016, No. LGF21F020014). and the National Natural Science
   Foundation of China (Grant No. 61802101).and "Pioneer" and "Leading
   Goose" R&D Program of Zhejiang(No. 2022C03132).
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abdulla AA, 2014, INT C RES SECURITY S, ppp151
   Allwinnaldo Budiman G, 2019, 2019 4 INT C INFORM, P216
   [Anonymous], 2015, 5 NAT C COMP VIS PAT, DOI DOI 10.1109/NCVPRIPG.2015.7490065
   [Anonymous], 2005, DIGITAL WATERMARKING
   Ayubi P, 2021, ARTIF INTELL REV, V54, P1237, DOI 10.1007/s10462-020-09877-8
   Cao Z, 2019, MULTIMED TOOLS APPL, V78
   Chen H, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P145, DOI 10.1109/ICISCE.2017.40
   He Y, 2014, 5 INT C GRAPHIC IMAG, P9069
   Hemalatha P, 2018, DISCRET MATH ALGORIT, V10, DOI 10.1142/S1793830918500556
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Le NT, 2019, SENSORS-BASEL, V19, P133
   Li DS, 2019, MATH METHOD APPL SCI, V42, P4664, DOI 10.1002/mma.5668
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Mansouri A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102370
   Sun W, 2018, IEEE SIGNAL PROC LET, V1
   Xu H, 2018, IEEE ACCESS, V6, P99
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang H, 2019, IEEE T VEH TECHNOL, V68, P7160, DOI 10.1109/TVT.2019.2913865
   Zhang SQ, 2019, MATH BIOSCI ENG, V16, P3435, DOI 10.3934/mbe.2019172
NR 20
TC 0
Z9 0
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7509
EP 7527
DI 10.1007/s11042-022-13609-1
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000844473700002
DA 2024-07-18
ER

PT J
AU Umer, M
   Imtiaz, Z
   Ahmad, M
   Nappi, M
   Medaglia, C
   Choi, GS
   Mehmood, A
AF Umer, Muhammad
   Imtiaz, Zainab
   Ahmad, Muhammad
   Nappi, Michele
   Medaglia, Carlo
   Choi, Gyu Sang
   Mehmood, Arif
TI Impact of convolutional neural network and FastText embedding on text
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional Neural Network (CNN); FastText; Text mining; Deep
   learning; Natural language processing
ID SENTIMENT
AB Efficient word representation techniques (word embeddings) with modern machine learning models have shown reasonable improvement on automatic text classification tasks. However, the effectiveness of such techniques has not been evaluated yet in terms of insufficient word vector representation for training. Convolutional Neural Network has achieved significant results in pattern recognition, image analysis, and text classification. This study investigates the application of the CNN model on text classification problems by experimentation and analysis. We trained our classification model with a prominent word embedding generation model, Fast Text on publically available datasets, six benchmark datasets including Ag News, Amazon Full and Polarity, Yahoo Question Answer, Yelp Full, and Polarity. Furthermore, the proposed model has been tested on the Twitter US airlines non-benchmark dataset as well. The analysis indicates that using Fast Text as word embedding is a very promising approach.
C1 [Umer, Muhammad; Mehmood, Arif] Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur 63100, Pakistan.
   [Imtiaz, Zainab] Khwaja Fareed Univ Engn & Informat Technol KFUEIT, Dept Comp Sci, Rahim Yar Khan, Pakistan.
   [Ahmad, Muhammad] Khwaja Fareed Univ Engn & Informat Technol KFUEIT, Dept Comp Engn, Rahim Yar Khan, Pakistan.
   [Nappi, Michele] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
   [Medaglia, Carlo] Link Campus Univ Rome, Res Dept, Via Casale San Pio V 44, I-00165 Rome, Italy.
   [Choi, Gyu Sang] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Islamia University of Bahawalpur; Khwaja Fareed University of
   Engineering & Information Technology, Pakistan; Khwaja Fareed University
   of Engineering & Information Technology, Pakistan; University of
   Salerno; Yeungnam University
RP Mehmood, A (corresponding author), Islamia Univ Bahawalpur, Dept Comp Sci & Informat Technol, Bahawalpur 63100, Pakistan.; Choi, GS (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM umer.sabir@iub.edu.pk; zainabimtiaz29@hotmail.com; mahmad00@gmail.com;
   mnappi@unisa.it; c.medaglia@unilink.it; castchoi@ynu.ac.kr;
   arif.mehmood@iub.edu.pk
RI Umer, Muhammad/KHU-2339-2024; Umer, Muhammad/AAX-4594-2020; Ahmad,
   Muhammad/X-6113-2019
OI Umer, Muhammad/0009-0001-8751-6100; Umer, Muhammad/0000-0002-6015-9326;
   Ahmad, Muhammad/0000-0002-3320-2261
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2019R1A2C1006159, NRF-2021R1A6A1A03039493]; 2022 Yeungnam
   University Research Grant
FX This work was supported in part by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2019R1A2C1006159) and
   (NRF-2021R1A6A1A03039493), and in part by the 2022 Yeungnam University
   Research Grant.
CR Aas Kjersti., 1999, Text categorisation: A survey
   Ali N. M., 2019, Int J Data Min Knowl Manag Process (IJDKP), V9, P19, DOI DOI 10.5121/IJDKP.2019.9302
   [Anonymous], 2017, P 15 C EUROPEAN CHAP
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Bollen J., 2011, Computer, V44, P91, DOI 10.1109/MC.2011.323
   Chen T, 2017, EXPERT SYST APPL, V72, P221, DOI 10.1016/j.eswa.2016.10.065
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Dai A.M., 2015, Document Embedding with Paragraph Vectors
   Dodds PS, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026752
   Dos Santos C., 2014, Coling, P69
   Du CX, 2019, AAAI CONF ARTIF INTE, P6359
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   GARDNER WA, 1984, SIGNAL PROCESS, V6, P113, DOI 10.1016/0165-1684(84)90013-6
   Gregorutti B, 2017, STAT COMPUT, V27, P659, DOI 10.1007/s11222-016-9646-1
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Imtiaz Z, 2020, IEEE ACCESS, V8, P21932, DOI 10.1109/ACCESS.2020.2969041
   Iyyer M, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1681
   Johnson R, 2015, P 2015 C N AM CHAPT, DOI 10.3115/v1/N15-1011
   Johnson R, 2016, PR MACH LEARN RES, V48
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kaya M, 2013, LECT NOTES ELECTR EN, V264, P139, DOI 10.1007/978-3-319-01604-7_14
   Kim Y., 2014, P 2014 C EMP METH NA, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Lee VLS, 2019, PROCEDIA COMPUT SCI, V161, P577, DOI 10.1016/j.procs.2019.11.159
   LEWIS DD, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P37
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Mccallum Andrew., 2001, Work Learn Text Categ, P752, DOI DOI 10.3115/1067807.1067848
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Mitchell T M, 2006, DISCIPLINE MACHINE L, V9
   Nakagawa T., 2010, HUMAN LANGUAGE TECHN, P786
   Post M., 2013, ACL, P866
   Qiao Chao., 2018, ICLR
   Qureshi Muhammad Atif, 2013, Information Retrieval Technology. 9th Asia Information Retrieval Societies Conference, AIRS 2013. Proceedings: LNCS 8281, P170, DOI 10.1007/978-3-642-45068-6_15
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Sadiq S, 2021, FUTURE GENER COMP SY, V114, P120, DOI 10.1016/j.future.2020.07.050
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Sharaff A, 2019, ADV INTELL SYST, V924, P189, DOI 10.1007/978-981-13-6861-5_17
   Silva J, 2011, ARTIF INTELL REV, V35, P137, DOI 10.1007/s10462-010-9188-4
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I, 2014, ADV NEUR IN, V27
   Tang Duyu, 2015, P 2015 C EMPIRICAL M, P1422
   Umer M, 2020, IEEE ACCESS, V8, P93782, DOI 10.1109/ACCESS.2020.2994810
   Wang J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
   Wang P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P352
   Wang SQ, 2012, 2012 2ND INTERNATIONAL CONFERENCE ON UNCERTAINTY REASONING AND KNOWLEDGE ENGINEERING (URKE), P90, DOI 10.1109/URKE.2012.6319592
   Xia R, 2017, IEEE T AFFECT COMPUT, V8, P480, DOI 10.1109/TAFFC.2017.2771234
   Yenigalla P, 2018, LECT NOTES COMPUT SC, V10859, P339, DOI 10.1007/978-3-319-91947-8_36
   Yin W., 2017, CoRR
   Yousaf A, 2021, IEEE ACCESS, V9, P6286, DOI 10.1109/ACCESS.2020.3047831
   Zhang X, 2019, TEXTCLASSIFICATIONDA
   Zhang X, 2015, TEXT UNDERSTANDING S
   Zhang X, 2015, ADV NEUR IN, V28
   Zhou Chunting, 2015, ARXIV
NR 56
TC 21
Z9 21
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5569
EP 5585
DI 10.1007/s11042-022-13459-x
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000843996100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Unnikrishnan, S
   Sreelekha, G
AF Unnikrishnan, Supriya
   Sreelekha, G.
TI Performance analysis of memory data layout for sub-block data access
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DRAM; Memory controller; FPGA; Video stabilization; Dual data rate
   memory; Memory access pattern
AB The design of Digital Signal Processing systems involving video data has many challenges other than the optimal design of the processing algorithms. The data handling starting from the raw data storage and retrieval for efficient processing to store back for further analysis, has many challenges. The memory data layout, access patterns, and interface design are critical factors that need more investigation in the architectural design of video processing systems in general. With the increase in video post-processing algorithms' complexity, the memory access pattern is turning more and more irregular. Unless the memory data layout, i.e., data storage pattern across the Dynamic Random Access Memory (DRAM), is tailored to the application, the memory bandwidth and power dissipation will be affected adversely. Memory efficiency in terms of throughput and energy consumption plays a vital role in deciding the overall efficiency of such systems involving a massive volume of data. An exhaustive analysis of different memory data layouts and access patterns for video data received in raster scan order and processed in blocks is conducted in this work. A Field Programmable Gate Array (FPGA) based video stabilization system for marine surveillance using inbuilt memory controller Intellectual Property (IP) is the user application under consideration. The optimal memory data layout and access patterns for this system are proposed here, and we can extend the findings from this study to many other application scenarios.
C1 [Unnikrishnan, Supriya; Sreelekha, G.] Natl Inst Technol, Dept Elect & Commun, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Unnikrishnan, S (corresponding author), Natl Inst Technol, Dept Elect & Commun, Calicut 673601, Kerala, India.
EM ksupriya_unni@yahoo.com
OI UNNIKRISHNAN, SUPRIYA/0000-0001-5136-112X
CR [Anonymous], 2015, TN4040 DDR4
   [Anonymous], 2018, PG150
   Bhati I, 2016, IEEE T COMPUT, V65, P108, DOI 10.1109/TC.2015.2417540
   Chandrasekar K., 2012, DRAMPOWER OPEN SOURC, P22
   Choi H, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102942
   Delaluz V, 2001, IEEE T COMPUT, V50, P1154, DOI 10.1109/12.966492
   Guilluy W, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116015
   Jeong MK, 2012, INT S HIGH PERF COMP, P53
   Lee KB, 2005, IEEE T CIRC SYST VID, V15, P620, DOI 10.1109/TCSVT.2005.846412
   Marino MD, 2018, IEEE T VLSI SYST, V26, P697, DOI 10.1109/TVLSI.2018.2789520
   Nedbailo YA, 2020, 2020 MOSCOW WORKSHOP, P1
   Unnikrishnan S, 2020, J PHARM INNOV, V15, P392, DOI 10.1007/s12247-019-09390-8
   Wang X, 2018 14 IEEE INT C S, P1
   Youn JM, 2017, MULTIMED TOOLS APPL, V76, P5951, DOI 10.1007/s11042-015-2807-y
   Zulian EF, 2020, 2020 IEEE INT S CIRC, P1
NR 15
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7229
EP 7245
DI 10.1007/s11042-022-13564-x
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842591000002
DA 2024-07-18
ER

PT J
AU Khan, H
   Hazzazi, MM
   Jamal, SS
   Hussain, I
   Khan, M
AF Khan, Hamza
   Hazzazi, Mohammad Mazyad
   Jamal, Sajjad Shaukat
   Hussain, Iqtadar
   Khan, Majid
TI New color image encryption technique based on three-dimensional logistic
   map and Grey wolf optimization based generated substitution boxes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional logistic map; Grey wolf optimization; S-boxes
ID DESIGN
AB In this paper, highly nonlinear substitution boxes (S-boxes) are generated by utilizing a chaotic map accompanied by the Grey wolf optimization technique. To check their applicability in the encryption scheme, an encryption scheme utilizing a three dimensional (3D) logistic map and the proposed S-boxes for confusion is proposed. The performance analyses of suggested S-boxes are performed and compared with existing techniques. Moreover, security analysis of projected encryption scheme is also performed and tabulated. The results show the strength of the proposed S-boxes in the design of encryption schemes.
C1 [Khan, Hamza; Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
   [Hazzazi, Mohammad Mazyad; Jamal, Sajjad Shaukat] King Khalid Univ, Coll Sci, Dept Math, Abha 61413, Saudi Arabia.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Math Program, Doha 2713, Qatar.
   [Hussain, Iqtadar] Qatar Univ, Coll Arts & Sci, Stat Consulting Unit, Doha, Qatar.
C3 King Khalid University; Qatar University; Qatar University
RP Khan, H (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM hamz.khan78@gmail.com
RI Hazzazi, Mohammad Mazyad/ABB-4202-2021; Jamal, Sajjad/AHE-6498-2022;
   Khan, Majid/T-9408-2019
OI Hazzazi, Mohammad Mazyad/0000-0002-7945-9994; Khan,
   Majid/0000-0001-5454-3770
FU Deanship of Scientific Research at King Khalid University [G. 2/109/43]
FX The author Sajjad Shaukat Jamal extends his gratitude to Deanship of
   Scientific Research at King Khalid University for funding this work
   through research groups program under grant number. R. G. 2/109/43.
CR Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Buchman J.A., 2004, INTRO CRYPTOGRAPHY
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   KAM JB, 1979, IEEE T COMPUT, V28, P747, DOI 10.1109/TC.1979.1675242
   Khan M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225031
   Khan M, 2018, NEURAL COMPUT APPL, V29, P993, DOI 10.1007/s00521-016-2511-5
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan MF, 2019, IEEE ACCESS, V7, P15999, DOI 10.1109/ACCESS.2019.2893176
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Kocarev L, 2001, PHYS LETT A, V289, P199, DOI 10.1016/S0375-9601(01)00609-0
   Kohli M, 2018, J COMPUT DES ENG, V5, P458, DOI 10.1016/j.jcde.2017.02.005
   Liu LY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122650
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mitsuru, 1993, ADV CRYPTOLOGY
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Ozkaynak F., 2017, PROC ACM INT C SER, P27, DOI [10.1145/3143344.3143355, DOI 10.1145/3143344.3143355]
   Ozkaynak F., 2019, Chaotic Modeling Simulation, V1, P49
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tanyildizi E, 2019, IEEE, V7
   ul Islam F, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0119-x
   Wang MJ, 2017, ENG APPL ARTIF INTEL, V63, P54, DOI 10.1016/j.engappai.2017.05.003
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
NR 30
TC 9
Z9 9
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6943
EP 6964
DI 10.1007/s11042-022-13612-6
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000839516900001
DA 2024-07-18
ER

PT J
AU Balaha, MM
   El-Kady, S
   Balaha, HM
   Salama, M
   Emad, E
   Hassan, M
   Saafan, MM
AF Balaha, Mostafa Magdy
   El-Kady, Sara
   Balaha, Hossam Magdy
   Salama, Mohamed
   Emad, Eslam
   Hassan, Muhammed
   Saafan, Mahmoud M.
TI A vision-based deep learning approach for independent-users Arabic sign
   language interpretation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arabic Sign Language (ASL); Convolutional Neural Network (CNN); Deep
   Learning (DL); Recurrent Neural Network (RNN); Sign Language Recognition
   (SLR); Video recognition
ID ACTION RECOGNITION; GESTURE
AB More than 5% of the people around the world are deaf and have severe difficulties in communicating with normal people according to the World Health Organization (WHO). They face a real challenge to express anything without an interpreter for their signs. Nowadays, there are a lot of studies related to Sign Language Recognition (SLR) that aims to reduce this gap between deaf and normal people as it can replace the need for an interpreter. However, there are a lot of challenges facing the sign recognition systems such as low accuracy, complicated gestures, high-level noise, and the ability to operate under variant circumstances with the ability to generalize or to be locked to such limitations. Hence, many researchers proposed different solutions to overcome these problems. Each language has its signs and it can be very challenging to cover all the languages' signs. The current study objectives: (i) presenting a dataset of 20 Arabic words, and (ii) proposing a deep learning (DL) architecture by combining convolutional neural network (CNN) and recurrent neural network (RNN). The suggested architecture reported 98% accuracy on the presented dataset. It also reported 93.4% and 98.8% for the top-1 and top-5 accuracies on the UCF-101 dataset.
C1 [Balaha, Mostafa Magdy; El-Kady, Sara; Balaha, Hossam Magdy; Salama, Mohamed; Emad, Eslam; Hassan, Muhammed; Saafan, Mahmoud M.] Mansoura Univ, Fac Engn, Comp & Syst Engn Dept, El Gharbia, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University
RP Balaha, MM (corresponding author), Mansoura Univ, Fac Engn, Comp & Syst Engn Dept, El Gharbia, Egypt.
EM hossam.m.balaha@mans.edu.eg
RI Salama, Mohamed F/C-9010-2017; Balaha, Hossam Magdy/Z-1960-2018; Saafan,
   Mahmoud M./O-9976-2018
OI Balaha, Hossam Magdy/0000-0002-0686-4411; Saafan, Mahmoud
   M./0000-0002-9279-1537
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB). No funding was received for this work.
CR Abdulazeem Y, 2021, IEEE ACCESS, V9, P82058, DOI 10.1109/ACCESS.2021.3086668
   Agarap A. F., 2018, ARXIV
   Al-Hammadi M, 2020, IEEE ACCESS, V8, P79491, DOI 10.1109/ACCESS.2020.2990434
   Al-Tashi Q, 2020, IEEE ACCESS, V8, P125076, DOI 10.1109/ACCESS.2020.3007291
   Albawi S, 2017, I C ENG TECHNOL
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   [Anonymous], 2016, Number of smartphone users in the United States from 2010 to 2021 (in millions)
   Bahgat WM, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.555
   Balaha HM, 2022, NEURAL COMPUT APPL, V34, P8671, DOI 10.1007/s00521-021-06851-5
   Balaha HM, 2022, ARTIF INTELL REV, V55, P5063, DOI 10.1007/s10462-021-10127-8
   Balaha HM, 2021, ARTIF INTELL MED, V119, DOI 10.1016/j.artmed.2021.102156
   Balaha HM, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115805
   Balaha HM, 2021, MULTIMED TOOLS APPL, V80, P32473, DOI 10.1007/s11042-021-11185-4
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P3011, DOI 10.1007/s00521-020-05137-6
   Baldi Pierre, 2013, Advances in Neural Information Processing Systems, P2814
   Beal MJ, 2002, ADV NEUR IN, V14, P577
   Bheda V., 2017, ARXIV
   Bock S., 2018, ARXIV
   Bock S, 2019, IEEE IJCNN
   Browne MW, 2000, J MATH PSYCHOL, V44, P108, DOI 10.1006/jmps.1999.1279
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dunne R. A., 1997, Proceedings of the Eighth Australian Conference on Neural Networks (ACNN'97), P181
   ElSaid A, 2016, P IEEE INT C E-SCI, P260, DOI 10.1109/eScience.2016.7870907
   López-Noriega JE, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE)
   Er-Rady A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P535
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao Jie, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P164, DOI 10.1109/ICCSEE.2012.154
   Ghadiyaram, 2019, ABS190500561
   Gong WF, 2020, IEEE ACCESS, V8, P73677, DOI 10.1109/ACCESS.2020.2988323
   Grobel K, 1997, IEEE SYS MAN CYBERN, P162, DOI 10.1109/ICSMC.1997.625742
   Hara K, 2015, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2015.7280578
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hienz H, 1999, LECT NOTES ARTIF INT, V1739, P185
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsiao TY, 2019, J SYST ARCHITECT, V95, P9, DOI 10.1016/j.sysarc.2019.02.008
   Huang J, 2015, IEEE INT C MULTIMEDI
   Johnston T., 2007, AustralianSign Language (Auslan): An introduction to sign language linguistics, DOI [10.1017/CBO9780511607479, DOI 10.1017/CBO9780511607479]
   kaggle.com, HIGH SCH SIGN LANG D
   kaggle.com, DATASET ALPHABETS AM
   KIRA K, 1992, MACHINE LEARNING /, P249
   Koller Oscar., 2016, P BMVC, P1, DOI 10.5244/C.30.136
   Latif G, 2019, DATA BRIEF, V23, DOI 10.1016/j.dib.2019.103777
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu S, 2021, MOBILE NETW APPL, V26, P1891, DOI 10.1007/s11036-020-01725-x
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Martinez B, 2019, IEEE I CONF COMP VIS, P5481, DOI 10.1109/ICCV.2019.00558
   Masood S., 2018, SMART COMPUTING INFO, P403
   Medsker L.R., 2001, Design and Applications, V5
   Mehdi SA, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2204
   Nandy A, 2010, COMM COM INF SC, V70, P102
   OShea K., 2015, arXiv
   Parcheta Z, 2017, LECT NOTES COMPUT SC, V10255, P419, DOI 10.1007/978-3-319-58838-4_46
   Qiu ZF, 2019, PROC CVPR IEEE, P12048, DOI 10.1109/CVPR.2019.01233
   Rastgoo R, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113794
   review42.com, 39 SMARTPHONE STAT Y
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sandler W, 2006, SIGN LANGUAGE AND LINGUISTIC UNIVERSALS, P1, DOI 10.2277/ 0521483956
   Shohieb SM, 2015, J KING SAUD UNIV-COM, V27, P68, DOI 10.1016/j.jksuci.2014.03.011
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Starner T., 1997, Motion-Based Recognit, P227
   Starner T.E., 1995, VISUAL RECOGNITION A
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Sutton-Spence R., 1999, The Linguistics of British Sign Language: An Introduction, V1st ed, DOI [10.1017/CBO9781139167048, DOI 10.1017/CBO9781139167048]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TAMURA S, 1988, PATTERN RECOGN, V21, P343, DOI 10.1016/0031-3203(88)90048-9
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   Upendran S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P1477, DOI 10.1109/ICCICCT.2014.6993193
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yang S, 2017, PROC SPIE, V10420, DOI 10.1117/12.2281671
   Yegnanarayana B., 2009, ARTIFICIAL NEURAL NE
   Youssif AAA, 2011, INT J ADV COMPUT SC, V2, P45
   Zhang Q., 2020, ARXIV
   Zhang ZS, 2018, IEEE T VEH TECHNOL, V67, P10378, DOI [10.1109/TIE.2018.2835378, 10.1109/TVT.2018.2866828]
NR 82
TC 19
Z9 19
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6807
EP 6826
DI 10.1007/s11042-022-13423-9
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840140700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Humanoid robot fetching objects using monocular vision unit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NAO robot; Object fetching way; Image calibration; Control approach;
   Positive and inverse kinematics
AB The aim of this paper is to establish an object fetching way formed by a monocular vision unit through the analysis of robot target fetching based on vision. The position distance between the target object and the robot by an NAO robot video camera is measured roughly; however, it is not necessary to measure precisely. Compared with the general steady object fetching way, it is easy to calculate and realize in the algorithm by this paper's vision fetching way and can avoid the problems generated by the general steady object fetching way, including having difficulty in locating a target, a complicated and difficult image calibration, a high requirement for precision, and so on. There are five different fetching ways including the vertical, horizontal, holding by the two-hand, independently and respectively fetching by the two-hands, and holding the book by two-hands fetching modes. It is proved by the test that this paper's fetching way has a good recognition capacity, can keep the fetching processing stable, and successfully fetches the various objects by a control approach with positive and inverse kinematics.
C1 [Juang, Li-Hong] Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
RP Juang, LH (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
EM lipuu@qq.com
CR Aldana-Murillo NG, 2018, INTELL AUTOM SOFT CO, V24, P471, DOI 10.1080/10798587.2017.1304508
   Aldebaran Robotics, 2012, NAO DAT H25 CORP ALD
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Becerra HM, 2014, INTELL AUTOM SOFT CO, V20, P245, DOI 10.1080/10798587.2014.906378
   Buschmann T, 2009, J PHYSIOL-PARIS, V103, P141, DOI 10.1016/j.jphysparis.2009.07.008
   Carbonera JL, 2019, INT J ADV COMPUT SC, V10, P1
   Chen MY, 2018, INTELL AUTOM SOFT CO, V24, P593, DOI 10.31209/2018.100000026
   Choi T, 2006, SICE ICASE INT JOINT, P4733
   Chou YC, 2017, INTELL AUTOM SOFT CO, V23, P117, DOI 10.1080/10798587.2016.1159059
   Huang YL, 2017, IEEE SYS MAN CYBERN, P2690, DOI 10.1109/SMC.2017.8123032
   Jarfi AR, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P1384, DOI 10.1109/ROBIO.2006.340131
   Jean-Christophe PL, 2012, INT J HUM ROBOT, V9, DOI 10.1142/S0219843612500193
   Kim JY, 2005, IEEE INT CONF ROBOT, P1431
   Lichocki M, 2020, 2020 EUROPEAN CONTROL CONFERENCE (ECC 2020), P1949, DOI 10.23919/ecc51009.2020.9143947
   Liu ZL, 2020, IET INTELL TRANSP SY, V14, P172, DOI 10.1049/iet-its.2019.0334
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma HX, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P457, DOI 10.1109/ROBIO.2009.5420690
   Mao Yongyi, 2011, Computer Engineering and Applications, V47, P238, DOI 10.3778/j.issn.1002-8331.2011.20.066
   Ogura Y, 2006, IEEE INT CONF ROBOT, P76
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, LECT NOTES COMPUT SC, V9256, P501, DOI 10.1007/978-3-319-23192-1_42
   Park IW, 2005, IEEE-RAS INT C HUMAN, P321
   Park JH, 2003, FUZZY SET SYST, V134, P189, DOI 10.1016/S0165-0114(02)00237-3
   Raza Jafri Ali, 2008, Journal of Beijing Institute of Technology, V17, P439
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shabrina Nabilah, 2020, 2020 International Conference on Intelligent Engineering and Management (ICIEM), P1, DOI 10.1109/ICIEM48762.2020.9160286
   Shen JL, 2018, ROBOTICA, V36, P241, DOI 10.1017/S0263574717000339
   Singh AK, 2016, ROBOT AUTON SYST, V79, P108, DOI 10.1016/j.robot.2016.01.009
   Smolar P., 2011, 2011 2 INT C COGN IN, P1
   Tang Y, 2014, J CHANGCHUN U SCI TE
   Wang J, 2006, 6 WORLD C INT CONTR, P8848
   Xu D, 2009, IEEE T IND ELECTRON, V56, P1617, DOI 10.1109/TIE.2009.2012457
   Yunhua Gu, 2011, 2011 International Conference on Information Science and Technology (ICIST 2011), P733, DOI 10.1109/ICIST.2011.5765349
   Zheng X, 2013, THESIS NE U
   Zhong QB, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P967, DOI 10.1109/ROBIO.2009.4913130
   Zhu HN, 2018, IEEE ROMAN, P483, DOI 10.1109/ROMAN.2018.8525656
   Zhuo SK, 2020, J ENG-JOE, V2020, P476, DOI 10.1049/joe.2019.1142
NR 37
TC 2
Z9 2
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 6747
EP 6767
DI 10.1007/s11042-022-13602-8
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000840140800003
DA 2024-07-18
ER

PT J
AU Hallabia, H
   Hamam, H
   Ben Hamida, A
AF Hallabia, Hind
   Hamam, Habib
   Ben Hamida, Ahmed Ben
TI A novel detail injection framework using latent low-rank decomposition
   for multispectral pan-sharpening
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pansharpening; Resolution enhancement; Latent low-rank decomposition;
   Detail injection
ID IMAGE FUSION; SPARSE REPRESENTATION; WAVELET TRANSFORM; DRIVEN FUSION;
   LANDSAT TM; MULTIRESOLUTION; RESOLUTION; QUALITY; REGRESSION; FILTER
AB A novel framework for pansharpening based on Latent Low-Rank Representation theory, called Detail injection using Latent Low-Rank decomposition based Pansharpening approach (DiLRP), is proposed. Our proposal comprises two fusion stages. In the first step, a primary joint fusion scheme is defined as a combination of low-rank and saliency images, which is used further for extracting spatial details. In this model, the histogram-matched PAN and up-sampled images are decomposed into low-rank and saliency components, and the corresponding fusion strategies are designed according to their characteristics. Indeed, to preserve more global structural information, low-rank components are combined by an optimized weighted average fusion strategy to generate a low-rank image. Furthermore, the saliency image is obtained by a simple average fusion rule in order get high-frequencies details (i.e., edges) that are highly relevant to MS image. The second stage consists in injecting (globally or locally) the high-frequency details, extracted from the reconstructed primary joint fused image using a multi-scale approach, into the up-sampled MS image. The performances of the proposed method have been studied both at reduced resolution and at full resolution. Three different datasets, acquired by the QuickBird, Pleaides-1A and WorldView-2 sensors, are used for validation. Compared with several well-known algorithms, experimental results reveal the validity and the advantages of the proposed DiLRP method.
C1 [Hallabia, Hind] Aix Marseille Univ, Equipe Modelisat Geometr G Mod, Lab Informat & Syst, Arles, France.
   [Hamam, Habib] Univ Moncton, Fac Engn, Moncton, NB, Canada.
   [Ben Hamida, Ahmed Ben] Univ Sfax, ATMS, Sfax, Tunisia.
C3 Aix-Marseille Universite; University of Moncton; Universite de Sfax;
   Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Hallabia, H (corresponding author), Aix Marseille Univ, Equipe Modelisat Geometr G Mod, Lab Informat & Syst, Arles, France.
EM hind.hallabia@amu-univ.fr
RI Hallabia, Hind/AAH-7578-2019; Hamam, Habib/C-1761-2019
OI Hallabia, Hind/0000-0001-8256-6646; Hamam, Habib/0000-0002-5320-1012
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Aiazzi B, 2002, IEEE T GEOSCI REMOTE, V40, P2300, DOI 10.1109/TGRS.2002.803623
   Aiazzi B, 2007, IEEE T GEOSCI REMOTE, V45, P3230, DOI 10.1109/TGRS.2007.901007
   Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2004, IEEE GEOSCI REMOTE S, V1, P313, DOI 10.1109/LGRS.2004.836784
   Alparone L, 2016, IEEE T GEOSCI REMOTE, V54, P2563, DOI 10.1109/TGRS.2015.2503045
   Amro I, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-79
   Azarang A, 2019, IEEE ACCESS, V7, P35673, DOI 10.1109/ACCESS.2019.2905511
   Ballester C, 2006, INT J COMPUT VISION, V69, P43, DOI 10.1007/s11263-006-6852-x
   CARPER WJ, 1990, PHOTOGRAMM ENG REM S, V56, P459
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Cheng M, 2014, IEEE GEOSCI REMOTE S, V11, P293, DOI 10.1109/LGRS.2013.2256875
   Choi J, 2011, IEEE T GEOSCI REMOTE, V49, P295, DOI 10.1109/TGRS.2010.2051674
   Demirel H, 2011, IEEE T GEOSCI REMOTE, V49, P1997, DOI 10.1109/TGRS.2010.2100401
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fei RR, 2019, IEEE GEOSCI REMOTE S, V16, P1595, DOI 10.1109/LGRS.2019.2904526
   Gao Y., 2019, IEEE T SYST MAN CYB, V99, P1
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Garzelli A, 2009, IEEE GEOSCI REMOTE S, V6, P662, DOI 10.1109/LGRS.2009.2022650
   Hallabia H, 2016, MULTIDIM SYST SIGN P, V27, P831, DOI 10.1007/s11045-016-0421-4
   Hallabia H, 2018, ADV MULTIRATE SYSTEM, P271
   Hallabia H, 2021, IEEE GEOSCI REMOTE S, V18, P1620, DOI 10.1109/LGRS.2020.3004320
   He XY, 2014, IEEE T IMAGE PROCESS, V23, P4160, DOI 10.1109/TIP.2014.2333661
   Imani M, 2018, IEEE J-STARS, V11, P4994, DOI 10.1109/JSTARS.2018.2851791
   Kallel A, 2015, IEEE T GEOSCI REMOTE, V53, P3124, DOI 10.1109/TGRS.2014.2369056
   Khademi G, 2018, IEEE GEOSCI REMOTE S, V15, P917, DOI 10.1109/LGRS.2018.2817561
   Kim Y, 2017, IEEE GEOSCI REMOTE S, V14, P2295, DOI 10.1109/LGRS.2017.2762427
   Laben C. A., 2000, US Patent, Patent No. 6,011,875
   Li H., 2018, ARXIV
   LI H, 2018, REMOTE SENS-BASEL, V10
   Li ZH, 2009, IEEE T GEOSCI REMOTE, V47, P1480, DOI 10.1109/TGRS.2008.2005639
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Liu PF, 2018, IEEE T GEOSCI REMOTE, V56, P1788, DOI 10.1109/TGRS.2017.2768386
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Mahyari AG, 2011, IEEE T GEOSCI REMOTE, V49, P1976, DOI 10.1109/TGRS.2010.2103944
   Masi G, 2017, JOINT URB REMOTE SEN
   Núñez J, 1999, IEEE T GEOSCI REMOTE, V37, P1204, DOI 10.1109/36.763274
   Otazu X, 2005, IEEE T GEOSCI REMOTE, V43, P2376, DOI 10.1109/TGRS.2005.856106
   Palsson F, 2016, IEEE J-STARS, V9, P2255, DOI 10.1109/JSTARS.2016.2546061
   Restaino R, 2016, IEEE T IMAGE PROCESS, V25, P2882, DOI 10.1109/TIP.2016.2556944
   Rong KX, 2014, IEEE J-STARS, V7, P4793, DOI 10.1109/JSTARS.2014.2347072
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Ulfarsson MO, 2018, INT GEOSCI REMOTE SE, P8857, DOI 10.1109/IGARSS.2018.8519256
   Vicinanza MR, 2015, IEEE GEOSCI REMOTE S, V12, P180, DOI 10.1109/LGRS.2014.2331291
   Vivone G, 2018, IEEE T IMAGE PROCESS, V27, P3418, DOI 10.1109/TIP.2018.2819501
   Vivone G, 2018, IEEE T GEOSCI REMOTE, V56, P984, DOI 10.1109/TGRS.2017.2757508
   Vivone G, 2015, IEEE T GEOSCI REMOTE, V53, P2565, DOI 10.1109/TGRS.2014.2361734
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wang JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090585
   Wang WQ, 2019, INT J REMOTE SENS, V40, P3029, DOI 10.1080/01431161.2018.1539269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ward CM, 2019, ARXIV
   Wei YC, 2017, IEEE GEOSCI REMOTE S, V14, P1795, DOI 10.1109/LGRS.2017.2736020
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Xu H, 2021, IEEE T GEOSCI REMOTE, V59, P4120, DOI 10.1109/TGRS.2020.3022482
   Yang SY, 2018, IEEE T NEUR NET LEAR, V29, P3647, DOI 10.1109/TNNLS.2017.2736011
   Yang Y, 2018, IEEE GEOSCI REMOTE S, V15, P734, DOI 10.1109/LGRS.2018.2810219
   Yang Y, 2018, IEEE ACCESS, V6, P6849, DOI 10.1109/ACCESS.2018.2791574
   Yin HT, 2017, IEEE T GEOSCI REMOTE, V55, P3545, DOI 10.1109/TGRS.2017.2675961
   Yin HT, 2015, SIGNAL PROCESS, V113, P218, DOI 10.1016/j.sigpro.2014.12.017
   Yuan X., 2009, SPARSE LOW RANK MATR
   Yuhas R.H., 1992, Discrimination Among Semi-arid Landscape Endmembers Using the Spectral Angle Mapper (SAM) Algorithm
   Zhang GX, 2015, INT J REMOTE SENS, V36, P1484, DOI 10.1080/01431161.2015.1014973
   Zhang LB, 2017, IEEE GEOSCI REMOTE S, V14, P2433, DOI 10.1109/LGRS.2017.2768070
   Zhang LB, 2016, IEEE T GEOSCI REMOTE, V54, P3750, DOI 10.1109/TGRS.2016.2527044
   Zhang YF, 2018, INT GEOSCI REMOTE SE, P7188, DOI 10.1109/IGARSS.2018.8518822
   Zhao Jieyu, 2019, ARXIV
   Zhou J, 1998, INT J REMOTE SENS, V19, P743, DOI 10.1080/014311698215973
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 74
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5987
EP 6012
DI 10.1007/s11042-022-12770-x
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000835601400009
DA 2024-07-18
ER

PT J
AU Cai, J
   Xie, SC
   Zhang, JZ
AF Cai, Jiao
   Xie, Shucui
   Zhang, Jianzhong
TI Image compression-encryption algorithm based on chaos and compressive
   sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Compressive sensing (CS); Discrete wavelet transform
   (DWT); Logistic-tent system (LTS)
ID SCHEME; SYSTEM; PERMUTATION
AB An image encryption scheme based on compressive sensing (CS) and chaos is proposed. Firstly, the plain image is transformed into the sparse coefficient matrix by discrete wavelet transform (DWT). Secondly, to achieve compression and encryption, the sparse coefficient matrix is measured by the measurement matrix, which is constructed by the Logistic-Tent system (LTS). This process can effectively reduce storage space or transmission bandwidth of the image. Finally, the resulting measurement value matrix is re-encrypted by executing dual random index permutation and bit-level diffusion to improve security of the cryptosystem, and then the cipher image is obtained. In addition, the SHA 256 hash value of the original image is utilized to calculate the initial value and parameter of LTS, making the proposed algorithm robust to known-plaintext and chosen-plaintext attacks. The simulation results show that our algorithm has good image compression-encryption capability and security performance.
C1 [Cai, Jiao] Xian Univ Posts & Telecommun, Sch Cyberspace Secur, Xian 710121, Peoples R China.
   [Xie, Shucui] Xian Univ Posts & Telecommun, Sch Sci, Xian 710121, Peoples R China.
   [Zhang, Jianzhong] Shaanxi Normal Univ, Coll Math & Informat Sci, Xian 710119, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications; Shaanxi Normal University
RP Xie, SC (corresponding author), Xian Univ Posts & Telecommun, Sch Sci, Xian 710121, Peoples R China.
EM xieshucui@163.com
RI zhang, jian/HPD-1712-2023; jin, li/IWU-4648-2023; zhan, y/ISA-2807-2023;
   Zhang, Jianjun/KEJ-3941-2024
OI Xie, Shucui/0000-0002-1503-8330
FU Natural Science Foundation of Shaanxi Province [2015JM6263]
FX All the authors are deeply grateful to the editors and reviewers for
   their handling of this manuscript. Special thanks to Liu Dingqin for her
   contribution to improving the writing and experiment of the manuscript.
   This work was supported by the Natural Science Foundation of Shaanxi
   Province (Grant No. 2015JM6263).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Huang H, 2018, SIGNAL PROCESS, V150, P183, DOI 10.1016/j.sigpro.2018.04.014
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu L, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106297
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Lu P, 2013, OPTIK, V124, P2514, DOI 10.1016/j.ijleo.2012.08.017
   Lv XP, 2018, MULTIMED TOOLS APPL, V77, P28633, DOI 10.1007/s11042-018-6013-6
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Shi H, 2019, ACTA PHYS SIN-CH ED, V68, DOI 10.7498/aps.68.20190553
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wu T, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053008
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yoon JW, 2010, COMMUN NONLINEAR SCI, V15, P3998, DOI 10.1016/j.cnsns.2010.01.041
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 36
TC 2
Z9 2
U1 6
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22189
EP 22212
DI 10.1007/s11042-022-13346-5
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000826131200002
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, HR
   Liu, ZY
AF Yang, Xu
   Li, Hongru
   Liu, Zhenyu
TI Adaptive comprehensive learning particle swarm optimization with spatial
   weighting for global optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swarm optimization; Spatial weighting; Euclidean distance;
   Adaptive
ID ALGORITHM
AB Although particle swarm optimization (PSO) algorithm shows excellent performance in solving optimization problems, how to balance exploration and exploitation is still a crucial problem. In this paper, an adaptive comprehensive learning particle swarm optimization with spatial weighting (APSO-SW) is proposed. In APSO-SW, in order to increase the population diversity, the Euclidean distance between each particle and the global optimum is calculated in each generation and the particles in the whole population select their exemplars learning weight according to their Euclidean distance adaptively. Therefore, not only different particles have various learning weight, but also the same particle can select learning weight adaptively in different generations. In addition, for the purpose of improving the convergence property, the terminal elimination strategy is used. In terminal elimination strategy, the population can delete inferior particles and add preferable particles dynamically during the process of evolution. The comparisons among APSO-SW and other 7 state-of-the-art PSO variants on the CEC2013 and CEC2017 test suites reflect that APSO-SW is a trustable and remarkable optimization algorithm for solving various types problems. Furthermore, extensive experiments confirm the validity of our method.
C1 [Yang, Xu; Li, Hongru] Northeastern Univ, Informat Sci & Engn, 11 St 3,Wenhua Rd, Shenyang 110819, Peoples R China.
   [Liu, Zhenyu] Northeastern Univ, State Key Lab Rolling & Automat, 11 St 3,Wenhua Rd, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Li, HR (corresponding author), Northeastern Univ, Informat Sci & Engn, 11 St 3,Wenhua Rd, Shenyang 110819, Peoples R China.
EM 13998346746@163.com; lihongru@ise.neu.edu.cn; liuzhenyu@neusoft.edu.cn
OI Yang, Xu/0000-0001-6853-9449
FU National Key R&D Program of China [2019YFF0302203]; National Natural
   Science Foundation of China [61973067]; Fundamental Research Funds for
   the Central Universities [N2004006]; State Key Laboratory of Rolling and
   Automation, Northeastern University [2019RALKFKT004]
FX The authors thank the Editor and all the anonymous referees for their
   constructive comments and valuable suggestions, which are helpful to
   improve the quality of this paper. This work was supported by the
   National Key R&D Program of China (2019YFF0302203), the National Natural
   Science Foundation of China (61973067), the Fundamental Research Funds
   for the Central Universities under Grant N2004006 and the Open Research
   Fund from the State Key Laboratory of Rolling and Automation,
   Northeastern University(2019RALKFKT004).
CR Cao YL, 2019, IEEE T EVOLUT COMPUT, V23, P718, DOI 10.1109/TEVC.2018.2885075
   Carrasco J, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100665
   Chen K, 2019, EXPERT SYST APPL, V128, P140, DOI 10.1016/j.eswa.2019.03.039
   Chen K, 2018, KNOWL-BASED SYST, V139, P23, DOI 10.1016/j.knosys.2017.10.011
   Chen K, 2018, INFORM SCIENCES, V422, P218, DOI 10.1016/j.ins.2017.09.015
   Chen YG, 2018, SWARM EVOL COMPUT, V39, P209, DOI 10.1016/j.swevo.2017.10.004
   Chen YG, 2018, ENG APPL ARTIF INTEL, V70, P159, DOI 10.1016/j.engappai.2018.01.009
   Dhanachandra N, 2020, MULTIMED TOOLS APPL, V79, P18839, DOI 10.1007/s11042-020-08699-8
   Draa A, 2015, APPL SOFT COMPUT, V27, P99, DOI 10.1016/j.asoc.2014.11.003
   Du SY, 2020, MULTIMED TOOLS APPL, V79, P4619, DOI 10.1007/s11042-019-08142-7
   El Sehiemy RA, 2020, ENERGY, V193, P1084, DOI 10.1016/j.energy.2019.116817
   Engin O, 2018, APPL SOFT COMPUT, V72, P166, DOI 10.1016/j.asoc.2018.08.002
   Fang W, 2016, INFORM SCIENCES, V330, P19, DOI 10.1016/j.ins.2015.09.055
   Gao WF, 2015, INFORM SCIENCES, V316, P180, DOI 10.1016/j.ins.2015.04.006
   Gülcü S, 2015, ENG APPL ARTIF INTEL, V45, P33, DOI 10.1016/j.engappai.2015.06.013
   Hosseinabadi AAR, 2019, SOFT COMPUT, V23, P5099, DOI 10.1007/s00500-018-3177-y
   Jawahar M, 2021, MULTIMED TOOLS APPL, V80, P4203, DOI 10.1007/s11042-020-09727-3
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kennedy J, 2002, IEEE C EVOL COMPUTAT, P1671, DOI 10.1109/CEC.2002.1004493
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Liang JJ, 2013, PROBLEM DEFINITIONS, DOI [10.1016/j.knosys.2017.10.011, DOI 10.1016/J.KNOSYS.2017.10.011]
   Lim WH, 2014, INFORM SCIENCES, V273, P49, DOI 10.1016/j.ins.2014.03.031
   Lin AP, 2019, APPL SOFT COMPUT, V77, P533, DOI 10.1016/j.asoc.2019.01.047
   Lin AP, 2019, SWARM EVOL COMPUT, V44, P571, DOI 10.1016/j.swevo.2018.07.002
   Liu H, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113353
   Lynn N, 2017, APPL SOFT COMPUT, V55, P533, DOI 10.1016/j.asoc.2017.02.007
   Lynn N, 2015, SWARM EVOL COMPUT, V24, P11, DOI 10.1016/j.swevo.2015.05.002
   Mendes R, 2004, IEEE T EVOLUT COMPUT, V8, P204, DOI [10.1109/TEVC.2004.826074, 10.1109/tevc.2004.826074]
   Pan XQ, 2019, MULTIMED TOOLS APPL, V78, P29921, DOI 10.1007/s11042-018-6602-4
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Sadeghi D, 2020, ENERGY, V209, DOI 10.1016/j.energy.2020.118471
   Shao SK, 2020, ISA T, V97, P415, DOI 10.1016/j.isatra.2019.08.018
   Suganthan P, 2016, Problem definitions and evaluation criteria for the CEC 2017 special session and competition on single objective bound constrained real-parameter numerical optimization
   Tanweer MR, 2015, INFORM SCIENCES, V294, P182, DOI 10.1016/j.ins.2014.09.053
   Walton S, 2011, CHAOS SOLITON FRACT, V44, P710, DOI 10.1016/j.chaos.2011.06.004
   Wang F, 2018, INFORM SCIENCES, V436, P162, DOI 10.1016/j.ins.2018.01.027
   Wang HN, 2018, MULTIMED TOOLS APPL, V77, P3871, DOI 10.1007/s11042-016-4242-0
   Wang SL, 2020, INFORM SCIENCES, V540, P175, DOI 10.1016/j.ins.2020.06.027
   Wei B, 2020, SWARM EVOL COMPUT, V57, DOI 10.1016/j.swevo.2020.100731
   Xia XW, 2019, SWARM EVOL COMPUT, V44, P349, DOI 10.1016/j.swevo.2018.04.006
   Xu GP, 2019, SWARM EVOL COMPUT, V45, P33, DOI 10.1016/j.swevo.2018.12.009
   Yao LP, 2021, MULTIMED TOOLS APPL, V80, P3425, DOI 10.1007/s11042-020-09812-7
   Zhang JQ, 2009, IEEE T EVOLUT COMPUT, V13, P945, DOI 10.1109/TEVC.2009.2014613
   Zhang K, 2019, INFORM SCIENCES, V471, P1, DOI 10.1016/j.ins.2018.08.049
   Zhang X, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107132
NR 46
TC 0
Z9 0
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36397
EP 36436
DI 10.1007/s11042-021-11547-y
EA JUL 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000823376700021
DA 2024-07-18
ER

PT J
AU Shahid, MH
   Islam, MA
   Beg, M
AF Shahid, Muzammil Hussain
   Islam, Muhammad Arshad
   Beg, Mirza
TI Exploiting time series based story plot popularity for movie success
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Movie success prediction; Time series forecasting; Topic modeling; Movie
   story analysis; Hybrid classifier; Sentiment analysis
ID BOX-OFFICE; MODEL
AB Movie success prediction in the development phase is considered a challenging task due to the availability of very limited information. A movie plot is established during the development phase and it is crucial aspect for determining the movie success. In this research, novel time series based features are proposed for "say" Story popularity in order to predict the movie success accurately. Multiple time series are generated representing the sentiment of a story and plot topics that are collectively termed as "say" Story popularity. A hybrid voting based classifier is created using Gradient Boosting, Random Forest, Support Vector Machine, Multilayer Perceptron, and Deep Learning classifiers to forecast the success of the movies in the development phase. The proposed features enhanced the accuracy by 11.9% and achieves an F1 Score of 75.1% in comparison to the state-of-the-art. This study also conducts experiments that highlight the importance of story popularity on release time related to movie success.
C1 [Shahid, Muzammil Hussain; Islam, Muhammad Arshad; Beg, Mirza] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad 44000, Pakistan.
RP Shahid, MH (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad 44000, Pakistan.
EM muzammilhuxx@gmail.com; arshad.islam@nu.edu.pk; omer.beg@nu.edu.pk
RI Islam, Muhammad Arshad/M-2385-2019
OI Islam, Muhammad Arshad/0000-0002-7503-5086; Shahid,
   Muzammil/0000-0001-7013-335X
CR Abidi SMR, 2020, POPULARITY PREDICTIO, P1
   Ahmad IS, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102278
   Ahmed U, 2020, SOFT COMPUT, V24, P6635, DOI 10.1007/s00500-019-04303-w
   [Anonymous], 2020, DATA MOVIE BUSINESS
   [Anonymous], 2020, SARIMAX INTRO
   [Anonymous], 2006, Time series analysis
   Banik R, 2017, The Movies Dataset
   Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chaturvedi Snigdha, 2018, P 2018 C N AM CHAPTE, V2, P673
   Chen K, 2021, ARXIV 210704191
   Chow PS, 2020, YOU ARE HERE HOMESPR
   Dashtipour K, 2020, NEUROCOMPUTING, V380, P1, DOI 10.1016/j.neucom.2019.10.009
   Dora L, 2018, EXPERT SYST APPL, V114, P313, DOI 10.1016/j.eswa.2018.07.039
   Eliashberg J, 2010, THESIS U PENNSYLVANI
   Eliashberg J, 2014, IEEE T KNOWL DATA EN, V26, P2639, DOI 10.1109/TKDE.2014.2306681
   Ertugrul AM, 2018, IEEE INT C SEMANT CO, P248, DOI 10.1109/ICSC.2018.00043
   Fathalla A, 2020, KNOWL INF SYST, V62, P4541, DOI 10.1007/s10115-020-01495-8
   Franses PH, 2021, TECHNOL FORECAST SOC, V169, DOI 10.1016/j.techfore.2021.120812
   Gorinski P. J., 2018, P 2018 C N AM CHAPTE, V1, P1770
   Gross JA, 2021, CS 230 FILM SUCCESS
   Hunter SD, 2016, J SCREENWRITING, V7, P135, DOI 10.1386/josc.7.2.135_1
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Hyndman RJ., 2014, FORECASTING PRINCIPL
   Jabrayilzade E, 2020, 2020 28 SIGNAL PROCE, P1
   Kim D, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03366-8
   Kim T, 2015, INT J FORECASTING, V31, P364, DOI 10.1016/j.ijforecast.2014.05.006
   Kim YJ, 2019, STORYTELLING, P127
   Lash MT, 2016, J MANAGE INFORM SYST, V33, P874, DOI 10.1080/07421222.2016.1243969
   Lee O.-J., 2018, IUI WORKSH
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Moon S, 2022, J BUS RES
   Mun MK, 2018, Jurnal Ekonomi Malaysia, V52, P81
   Mundra Shikha, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P219, DOI 10.1007/978-981-13-1742-2_22
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nawar A., 2021, 2021 IEEE 15 INT C A, P1
   Parvandeh S, 2020, BIOINFORMATICS, V36, P3093, DOI 10.1093/bioinformatics/btaa046
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rasmussen Nina Vindum., AOIR 2020 21 A UNPUB
   Razeen Faaez, 2021, Intelligent Computing and Applications. Proceedings of ICICA 2019. Advances in Intelligent Systems and Computing (AISC 1172), P657, DOI 10.1007/978-981-15-5566-4_59
   Redfern Nick, 2012, EUROPEAN J AM CULTUR, V31, P145, DOI DOI 10.1386/EJAC.31.2.145_1
   Ru YN, 2018, COGN SYST RES, V52, P182, DOI 10.1016/j.cogsys.2018.06.018
   Ryoo JH, 2021, J MARKETING, V85, P70, DOI 10.1177/0022242920937703
   Seabold S., 2010, P 9 PYTH SCI C, P57, DOI DOI 10.25080/MAJORA-92BF1922-011
   Silver-Lasky P, 2004, SCREENWRITING 21 CEN
   Usero Belen, 2022, Intelligent Computing: Proceedings of the 2021 Computing Conference. Lecture Notes in Networks and Systems, P981, DOI 10.1007/978-3-030-80119-9_65
   van Gerven M., 2018, ARTIFICIAL NEURAL NE
   Wang Z, 2020, PREDICTING RANKING B
   Xu LW, 2021, IEEE T VEH TECHNOL, V70, P1365, DOI 10.1109/TVT.2021.3051966
   Zhang C, 2021, FORECASTING BOX OFFI
   Zheng Gao, 2019, Information in Contemporary Society. 14th International Conference, iConference 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11420), P669, DOI 10.1007/978-3-030-15742-5_63
   Zhou QF, 2019, KNOWL INF SYST, V61, P905, DOI 10.1007/s10115-018-1302-y
NR 53
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3509
EP 3534
DI 10.1007/s11042-022-13219-x
EA JUL 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825016300002
DA 2024-07-18
ER

PT J
AU Yu, L
   Li, GH
   Yuan, L
   Zhang, L
AF Yu, Lei
   Li, Guohui
   Yuan, Ling
   Zhang, Li
TI Time-bounded targeted influence spread in online social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online social networks; Viral marketing; Influence maximization;
   Heuristic algorithm
ID INFLUENCE MAXIMIZATION
AB Influence maximization with application to viral marketing aims to find a small set of influencers in a social network to maximize the number of influenced users under a certain propagation model. However, in many actual marketing scenarios, companies are usually concerned about precision marketing before the specified deadline. In this paper, different from most of influence maximization problems, we focus on an issue of time-bounded targeted influence spread, where it asks for finding a seed set to maximize the influence on a specific set of target users within a bounded time in the network. This problem is NP-hard, and its objective function maintains the monotonicity and submodularity. We devise a greedy algorithm with approximate guarantee to effectively solve the problem. To overcome the low calculational efficiency of this algorithm in large networks, we further propose several efficient heuristic algorithms to greatly speed up the seed selection. Extensive experiments over real-world available social networks of different sizes show the effectiveness and efficiency of the proposed algorithms.
C1 [Yu, Lei; Li, Guohui; Yuan, Ling] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Zhang, Li] Wuhan Fiberhome Tech Serv Co Ltd, Wuhan, Peoples R China.
C3 Huazhong University of Science & Technology
RP Yuan, L (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM LYU91@hust.edu.cn; guohuili@hust.edu.cn; cherryyuanling@hust.edu.cn;
   lzhang@fiberhome.com
RI xiao, wei/KCK-6954-2024; Li, Guo/JNR-1700-2023; yang, zhuo/JPK-3133-2023
CR Ahmad A, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123590
   [Anonymous], 2014, SNAP Datasets
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Borgs C., 2014, P 25 ANN ACM SIAM S, P946, DOI DOI 10.1137/1.9781611973402.70
   Chen W., 2010, ACM SIGKDD INT C KNO, P1029, DOI DOI 10.1145/1835804.1835934
   Chen Wei, 2011, Influence Maximization in Social Networks When Negative Opinions May Emerge and Propagate, P379, DOI [DOI 10.1137/1.9781611972818.33, 10.1137/1.9781611972818.33]
   Chen YC, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532549
   Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345
   D'Angelo G, 2019, THEOR COMPUT SCI, V764, P30, DOI 10.1016/j.tcs.2018.01.017
   Domingos P., 2001, P 7 ACM SIGKDD INT C, P57, DOI [DOI 10.1145/502512.502525, 10.1145/502512.502525]
   Guler B, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P906, DOI 10.1109/ASONAM.2014.6921693
   Guo J, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P199
   Hong WJ, 2021, IEEE T CYBERNETICS, V51, P6091, DOI 10.1109/TCYB.2020.2966593
   Huang HM, 2019, INFORM PROCESS MANAG, V56, P939, DOI 10.1016/j.ipm.2019.01.006
   Kempe David, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Kim S, 2017, INFORM SCIENCES, V415, P171, DOI 10.1016/j.ins.2017.06.018
   Leskovec J, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P420
   Li H, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1525, DOI 10.1145/2723372.2723710
   Li YC, 2015, PROC VLDB ENDOW, V8, P1070, DOI 10.14778/2794367.2794376
   Liu B, 2012, IEEE DATA MINING, P439, DOI 10.1109/ICDM.2012.158
   NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971
   Nguyen HT, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P695, DOI 10.1145/2882903.2915207
   Ohsaka N, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P635, DOI 10.1145/3035918.3064045
   Pham Canh V., 2018, Computational Data and Social Networks. 7th International Conference, CSoNet 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11280), P13, DOI 10.1007/978-3-030-04648-4_2
   Richardson M., 2002, P 8 ACM SIGKDD INT C, P61, DOI DOI 10.1145/775047.775057
   Shi QH, 2019, PROC INT CONF DATA, P1502, DOI 10.1109/ICDE.2019.00135
   Song GJ, 2015, IEEE T PARALL DISTR, V26, P1379, DOI 10.1109/TPDS.2014.2320515
   Su S, 2018, J ASSOC INF SCI TECH, V69, P229, DOI 10.1002/asi.23931
   Tang YZ, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1539, DOI 10.1145/2723372.2723734
   Tang YZ, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P75, DOI 10.1145/2588555.2593670
   VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032
   Wang XY, 2017, IEEE T KNOWL DATA EN, V29, P243, DOI 10.1109/TKDE.2016.2624734
   Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI [10.1145/1718487.1718520, DOI 10.1145/1718487.1718520]
   Wong P, 2017, INFORM SYST, V65, P93, DOI 10.1016/j.is.2016.12.002
   Zhu JM, 2020, IEEE T COMPUT SOC SY, V7, P897, DOI 10.1109/TCSS.2020.2997188
NR 35
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9065
EP 9081
DI 10.1007/s11042-021-11461-3
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000818623900002
DA 2024-07-18
ER

PT J
AU Tabassum, M
   Perumal, S
   Kashem, SB
   Ponnan, S
   Chakraborty, C
   Chowdhury, MEH
   Khandakar, A
AF Tabassum, Mujahid
   Perumal, Sundresan
   Kashem, Saad Bin Abdul
   Ponnan, Suresh
   Chakraborty, Chinmay
   Chowdhury, Muhammad E. H.
   Khandakar, Amith
TI Enhance data availability and network consistency using artificial
   neural network for IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Artificial Neural Network; Cluster base network; Wireless Sensor
   Network; Data aggregation; Decision tree algorithm; On-demand routing
   protocol
ID ENERGY-EFFICIENT; ROUTING PROTOCOL; DATA AGGREGATION; FUZZY-LOGIC; WSN
AB IoT networks have become famous and utilized in many industries such as agriculture, medical, manufacture, and others due to their efficiency and productivity. WSN is an IoT network used for smart farming and smart health monitoring. WSNs can self-manage, self-configure, self-diagnose, and self-heal, making them ideal for agricultural monitoring. A wireless sensor network collects data from numerous sensor nodes scattered across the physical world. WSN data processing is critical when a node fails for unknown reasons. Data handling is an essential aspect of WSN; once any node fails due to unknown reasons, data reliability and availability become crucial. Hence, limited battery energy, low bandwidth, limited computing capacity, and link failure affect network performance. Therefore, an effective cluster-based data aggregation with an appropriate routing must be designed in the media access control. The proposed hybrid artificial neural network and decision tree algorithm with cognitive radio is developed to select the cluster head. The higher amount of residual energy increases the number of packets received at the base station and aggregate the data from the normal sensor nodes. The on-demand routing protocol is designed to keep data in local storage for retransmission during link failure to obtain reliable data transmission. The proposed method performance is analyzed as residual energy, end to end delay, normalized overhead, packet delivery ratio, packet drop, and throughput. This proposed method is evaluated with the cluster-based data aggregation scheme to prove its efficiency. The proposed method residual energy is 8.3Joules for 50 nodes; it is high compared to the cluster-based data aggregation scheme.
C1 [Tabassum, Mujahid; Perumal, Sundresan] Univ Sains Islam Malaysia, Fac Sci & Technol, Nilai 71800, Negeri Sembilan, Malaysia.
   [Kashem, Saad Bin Abdul] Qatar Fdn, Qatar Armed Forces Acad Bridge Program, Robot & Adv Comp Fac, Doha, Qatar.
   [Ponnan, Suresh] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai 600062, Tamil Nadu, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Elect & Commun Engn, Jharkhand, India.
   [Chowdhury, Muhammad E. H.; Khandakar, Amith] Qatar Univ, Coll Engn, Dept Elect Engn, Doha 2713, Qatar.
C3 Universiti Sains Islam Malaysia; Qatar Foundation (QF); Vel Tech
   Rangarajan Dr Sagunthala R&D Institute of Science & Technology; Birla
   Institute of Technology Mesra; Qatar University
RP Ponnan, S (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci &, Dept ECE, Chennai 600062, Tamil Nadu, India.
EM suresh3982@yahoo.co.in
RI Chowdhury, Muhammad E.H./J-6916-2019; Chakraborty, Chinmay/N-3608-2017;
   P, SURESH/D-2981-2014; K P, Suresh/AAK-4725-2021; Kashem, Dr
   Saad/AAU-7928-2020
OI Chowdhury, Muhammad E.H./0000-0003-0744-8206; Chakraborty,
   Chinmay/0000-0002-4385-0975; P, SURESH/0000-0002-0488-972X; K P,
   Suresh/0000-0002-4672-8334; Kashem, Dr Saad/0000-0002-6061-9409
CR Abbasi-Daresari S, 2016, AD HOC NETW, V36, P368, DOI 10.1016/j.adhoc.2015.08.014
   Ali A. B., 2016, P INT MULT ENG COMP
   Azharuddin M, 2017, SOFT COMPUT, V21, P6825, DOI 10.1007/s00500-016-2234-7
   Chakraborty C. S. Chinmay, 2011, CIIT INT J FUZZY SYS, V3, P35
   Chakraborty C, 2013, TELEMED E-HEALTH, V19, P619, DOI 10.1089/tmj.2012.0215
   Daneshvar SMMH, 2019, IEEE ACCESS, V7, P170019, DOI 10.1109/ACCESS.2019.2955993
   Devi VS, 2020, COMPUT COMMUN, V149, P36, DOI 10.1016/j.comcom.2019.10.003
   El Alami H, 2019, IEEE ACCESS, V7, P107142, DOI 10.1109/ACCESS.2019.2933052
   Elsmany EFA, 2019, IEEE ACCESS, V7, P96974, DOI 10.1109/ACCESS.2019.2929578
   Gupta SK, 2015, WIRELESS PERS COMMUN, V83, P2403, DOI 10.1007/s11277-015-2535-7
   Hidoussi F, 2017, WIRELESS PERS COMMUN, V96, P4929, DOI 10.1007/s11277-017-4963-z
   Kamalesh S, 2017, J EXP THEOR ARTIF IN, V29, P133, DOI 10.1080/0952813X.2015.1132262
   Mantri DS, 2016, WIRELESS PERS COMMUN, V86, P975, DOI 10.1007/s11277-015-2965-2
   Mantri DS, 2015, COMPUT ELECTR ENG, V41, P256, DOI 10.1016/j.compeleceng.2014.08.008
   Mishra Sanju, 2021, International Journal of Computers and Applications, V43, P109, DOI 10.1080/1206212X.2018.1521895
   Mohanasundaram R, 2015, WIRELESS PERS COMMUN, V85, P1381, DOI 10.1007/s11277-015-2846-8
   Nayak P, 2016, IEEE SENS J, V16, P137, DOI 10.1109/JSEN.2015.2472970
   Perumal S, 2021, CMC-COMPUT MATER CON, V69, P1447, DOI 10.32604/cmc.2021.014854
   Qian HW, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020341
   Rahul M, 2019, INT J GRID UTIL COMP, V10, P488, DOI 10.1504/IJGUC.2019.102018
   Sharon T, 2021, ETHICS INF TECHNOL, V23, P331, DOI 10.1007/s10676-020-09575-7
   Srividhya V, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718767598
   Sun ZY, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/5131949
   Suresh P, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106996
   Tabassum M., 2021, Design Methodologies and Tools for 5G Network Development and Application, P109, DOI [10.4018/978-1-7998-4610-9.ch006, DOI 10.4018/978-1-7998-4610-9.CH006]
   Tabassum M, 2017, J TELECOMMUN ELECT C, V9, P111
   Tabassum M, 2014, 19 INT C TRANSF RES
   Tabassum Mujahid., 2014, International Journal of Digital Information and Wireless Communications (IJDIWC), V4, P124, DOI [DOI 10.17781/P001091, 10.17781/p001091]
   Toor AS, 2019, AEU-INT J ELECTRON C, V102, P41, DOI 10.1016/j.aeue.2019.02.006
   Xie WX, 2015, WIRELESS PERS COMMUN, V84, P1165, DOI 10.1007/s11277-015-2682-x
   Xu C, 2019, IEEE ACCESS, V7, P135277, DOI 10.1109/ACCESS.2019.2942321
   Yadav RN, 2018, COMPUT COMMUN, V129, P54, DOI 10.1016/j.comcom.2018.07.020
   Yue YG, 2018, IEEE ACCESS, V6, P67434, DOI 10.1109/ACCESS.2018.2879364
NR 33
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 21
PY 2022
DI 10.1007/s11042-022-13337-6
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2G4RV
UT WOS:000813585000001
DA 2024-07-18
ER

PT J
AU Niu, MD
   Zhang, Y
AF Niu, Mengdie
   Zhang, Ye
TI Underdetermined blind speech source separation based on deep nearest
   neighbor clustering algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep nearest neighbor clustering; Underdetermined blind sources
   separation; Deep autoencoder network
AB In this paper, we propose a new autoencoder network architecture with clustering mechanism for underdetermined blind speech source separation, i.e., the number of mixtures is less than that of sources. The autoencoder network is employed to project the mixtures to embedding space and obtain their embedding vectors. The network model additionally incorporates the clustering mechanism and nearest neighbor clustering algorithm to estimate the clustering centers of the embedding vectors. Then, according to the embedding vectors, the hard and the probability assignment method are proposed to assign the mixtures to their corresponding clusters to recover the sources. The experimental results demonstrate that the proposed method yields better performance compared to the baseline algorithms.
C1 [Niu, Mengdie; Zhang, Ye] Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University
RP Zhang, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang, Jiangxi, Peoples R China.
EM nmd_smile@163.com; zhangye@ncu.edu.cn
FU National Natural Science Foundation of China [61866024]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61866024).
CR Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Bofill P, 2001, SIGNAL PROCESS, V81, P2353, DOI 10.1016/S0165-1684(01)00120-7
   Chen P, 2017, IEEE ACCESS, V5, P21731, DOI 10.1109/ACCESS.2017.2764044
   Cichocki A, 2008, MACHINE LEARN SIGN P, P73, DOI 10.1109/MLSP.2008.4685458
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Elmannai H, 2015, ISPRS ANN PHOTO REM, VII-2, P69, DOI 10.5194/isprsannals-II-2-W2-69-2015
   Fan N., 2016, 2016 10 INT SYM CHIN, P1
   Gavrilescu M., 2014, P THE2014 10 INT C C, P1
   Guo J, 2017, IEEE ACCESS, V5, DOI 10.1109/ACCESS.2017.2757028
   Guo YN, 2013, IEEE ENG MED BIO, P6812, DOI 10.1109/EMBC.2013.6611121
   Han C, 2019, INT CONF ACOUST SPEE, P361, DOI 10.1109/ICASSP.2019.8682884
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jiang Y, 2014, IEEE-ACM T AUDIO SPE, V22, P2112, DOI 10.1109/TASLP.2014.2361023
   Jun H, 2018, IEEE ACCESS, V6, P658, DOI 10.1109/ACCESS.2017.2773665
   Keriven N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P771, DOI 10.1109/ICASSP.2018.8462095
   Kolbæk M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Li H, 2012, 2012 INT C COMPUTING
   Ma L, 2012, 2012 INT JOINT C NEU, P18
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Pandey A, 2019, IEEE-ACM T AUDIO SPE, V27, P1179, DOI [10.1109/taslp.2019.2913512, 10.1109/TASLP.2019.2913512]
   Saab R, 2007, IEEE T SIGNAL PROCES, V55, P4004, DOI 10.1109/TSP.2007.895998
   Salan Y, 2014, IEEE INT C AC SPEECH
   Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang S, 2019, INT CONF ACOUST SPEE, P76, DOI 10.1109/ICASSP.2019.8683437
   Wang ZQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1, DOI 10.1109/ICASSP.2018.8461639
   Williamson DS, 2017, IEEE-ACM T AUDIO SPE, V25, P1492, DOI 10.1109/TASLP.2017.2696307
   Xu T, 2009, 2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P493, DOI 10.1109/SSP.2009.5278532
   Yang ZY, 2017, IEEE T NEUR NET LEAR, V28, P948, DOI 10.1109/TNNLS.2016.2517096
   Yang ZY, 2011, IEEE T IMAGE PROCESS, V20, P1112, DOI 10.1109/TIP.2010.2081678
   Yul D, 2017, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2017.7952154
   Zermini A, 2017, IEEE INT WORKSH MULT, DOI 10.1109/MMSP.2017.8122280
   Zhang Y, 2012, ARTIF INTELL, P7581
   Zhang Y, 2014, CHINA COMMUN, V11, P71, DOI 10.1109/CC.2014.6879005
   Zhen LL, 2020, MEASUREMENT, V152, DOI 10.1016/j.measurement.2019.107268
   Zibulevsky M, 2001, NEURAL COMPUT, V13, P863, DOI 10.1162/089976601300014385
   2007, SIGNALS COMMUN TECHN, P1
NR 39
TC 0
Z9 0
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1171
EP 1183
DI 10.1007/s11042-022-13009-5
EA JUN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810821800001
DA 2024-07-18
ER

PT J
AU Zhao, DX
   Yang, RX
   Wang, ZH
   Qi, ZY
AF Zhao, Dexin
   Yang, Ruixue
   Wang, Zhaohui
   Qi, Zhiyang
TI A cooperative approach based on self-attention with interactive
   attribute for image caption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image caption; Deep neural network; Self-attention
AB Image caption is a challenging issue in the area of image understanding, in which most of the models are trained by the framework combined a deep convolutional neural network with a recurrent neural network. However, the features extracted by the convolutional neural network could capture the information of salient regions, which fails to cover the details in the image. Moreover, the gradient vanishing problem of the recurrent neural networks would cause the loss of the previous information as the time step grows. In this paper, Cooperative Self-Attention (CSA) is proposed address these problems. Comparing with existing methods, our model enhances the representation of the image by fusing the additional attribute information from the object detection. A sub-module named Inter-Attribute indicating the interaction of objects is proposed to strengthen the context of the entities. In virtue of the advantages of Self-Attention, different from previous methods that predict the next word based on one prior word and hidden state, our model concatenates all of the words generated step by step to solve long-term dependencies. Comparing with published state-of-the-art methods, our CSA demonstrates outstanding performance.
C1 [Zhao, Dexin; Yang, Ruixue; Wang, Zhaohui; Qi, Zhiyang] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology
RP Yang, RX (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM zhaodexin@email.tjut.edu.cn; yanguixue@stud.tjut.edu.cn;
   wangzhaohuigg@163.com; qzy@stud.tjut.edu.cn
RI tong, li/KDO-7821-2024; li, sixuan/KGR-3943-2024; Wang,
   Zixi/KEI-0077-2024
CR Agrawal H, 2019, IEEE I CONF COMP VIS, P8947, DOI 10.1109/ICCV.2019.00904
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Chen H, 2018, AAAI CONF ARTIF INTE, P6706
   Chen LJ, 2018, PR MACH LEARN RES, V80
   Ding GG, 2019, COGN COMPUT, V11, P763, DOI 10.1007/s12559-018-9581-x
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Guo LT, 2019, PROC CVPR IEEE, P4199, DOI 10.1109/CVPR.2019.00433
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4013
   Lu JS, 2018, PROC CVPR IEEE, P7219, DOI 10.1109/CVPR.2018.00754
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sharif NABM, 2020, IEEE 10TH SYMPOSIUM ON COMPUTER APPLICATIONS AND INDUSTRIAL ELECTRONICS (ISCAIE 2020), P18, DOI [10.1109/iscaie47305.2020.9108707, 10.1109/ISCAIE47305.2020.9108707]
   Shirai K, 2020, ARXIV ABS201214124
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JF, 2019, NEUROCOMPUTING, V328, P56, DOI 10.1016/j.neucom.2018.03.078
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhao DX, 2019, NEUROCOMPUTING, V329, P476, DOI 10.1016/j.neucom.2018.11.004
   Zhao WT, 2020, AAAI CONF ARTIF INTE, V34, P12984
   Zheng Y, 2019, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2019.00859
NR 38
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1223
EP 1236
DI 10.1007/s11042-022-13279-z
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000810329200003
DA 2024-07-18
ER

PT J
AU Huang, R
   McIntyre, S
   Song, MN
   E, HH
   Ou, ZH
AF Huang, Ruo
   McIntyre, Shelby
   Song, Meina
   E, Haihong
   Ou, Zhonghong
TI A knowledge distilled attention-based latent information extraction
   network for sequential user behavior
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender systems; Click-through rate prediction; Sequential patterns
   modeling; High-order feature interactions; Knowledge distillation;
   Attention mechanism
AB When modeling user-item interaction sequences to extract sequential patterns, current recommender systems face the dual issues of a) long-distance dependencies in conjunction with b) high levels of noise. In addition, with the complexity of current recommendation model architectures there is a significant increase in computation time. Therefore, these models cannot meet the requirement of fast response needed in application scenarios such as online advertising. To deal with these issues, we propose a Knowledge Distilled Attention-based Latent Information Extraction Network for Sequential user behavior (KD-ALIENS). In this model structure, user and item attributes and history are utilized to model the latent information from high-order feature interactions in conjunction with user sequential historical behavior. With regard to the issues of long-distance dependency and noise, we have adopted the self-attention mechanism to learn the sequential patterns between items in a user-item interaction history. With regard to the issue of a complex model architecture which cannot meet the requirement of fast response, the use of model compression and acceleration is realized by: (a) use of a knowledge-distilled teacher and student module, wherein the complex teacher module extracts a user's general preference from high-order feature interactions and sequential patterns of long history sequences; and (b) a sampling method to sample both the relatively long-term and short-term item histories. Experimental studies on two real-world datasets demonstrate considerable improvements for click-through rate (CTR) prediction accuracy relative to strong baseline models and also show the effectiveness of the student-model compression and acceleration for speed.
C1 [Huang, Ruo; Song, Meina; E, Haihong; Ou, Zhonghong] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
   [Huang, Ruo] Minist Transport, Transport Planning & Res Inst, Beijing 100028, Peoples R China.
   [Huang, Ruo] Lab Traff & Transport Planning Digitalizat, Beijing 100028, Peoples R China.
   [McIntyre, Shelby] Santa Clara Univ, Leavey Sch Business, Santa Clara, CA 95053 USA.
C3 Beijing University of Posts & Telecommunications; Ministry of Transport
   of the People's Republic of China; Santa Clara University
RP E, HH (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
EM charleshuangruo@bupt.edu.cn; smcintyre@scu.edu; mnsong@bupt.edu.cn;
   ehaihong@bupt.edu.cn; zhonghong.ou@bupt.edu.cn
RI Elbe, Hulya/JTV-6940-2023
FU National Key Research and Development Program of China [2018YFB1403501]
FX This work is supported by the National Key Research and Development
   Program of China (2018YFB1403501).
CR Chen HY, 2016, PROCEEDINGS 2016 5TH IIAI INTERNATIONAL CONGRESS ON ADVANCED APPLIED INFORMATICS IIAI-AAI 2016, P710, DOI 10.1109/IIAI-AAI.2016.16
   Chen Qian, 2019, CoRR
   Chen X, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3281659
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Dean J., 2015, NIPS DEEP LEARNING R
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Lopez PG, 2015, ACM SIGCOMM COMP COM, V45, P37, DOI 10.1145/2831347.2831354
   Gong Y, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2477, DOI 10.1145/3340531.3412700
   Gou J, 2020, CORR ARXIV ABS200605
   Graepel T., 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725
   He RN, 2016, IEEE DATA MINING, P191, DOI [10.1109/ICDM.2016.88, 10.1109/ICDM.2016.0030]
   HIDASI B, 2018, SESSION BASED RECOMM, P843, DOI DOI 10.1145/3269206.3271761
   Huang R, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165468
   Kang S, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P605, DOI 10.1145/3340531.3412005
   Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035
   Lee JW, 2019, IEEE DATA MINING, P369, DOI 10.1109/ICDM.2019.00047
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Qu YR, 2016, IEEE DATA MINING, P1149, DOI [10.1109/ICDM.2016.0151, 10.1109/ICDM.2016.57]
   Ren RY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P89, DOI 10.1145/3397271.3401111
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Tang JX, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2289, DOI 10.1145/3219819.3220021
   Vaswani A., 2017, Proceedings of the 31st International Conference on Neural Information Processing Systems, P5998
   Wang RX, 2017, ADKDD'17: 23RD ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2017), DOI 10.1145/3124749.3124754
   Wang SJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6332
   Wu CY, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P495, DOI 10.1145/3018661.3018689
   Wu LW, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P328, DOI 10.1145/3383313.3412258
   Xu C, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2590, DOI 10.1145/3394486.3403309
   Zhou GR, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1059, DOI 10.1145/3219819.3219823
   Zhu JM, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2941, DOI 10.1145/3340531.3412704
NR 32
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1017
EP 1043
DI 10.1007/s11042-022-12513-y
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700006
DA 2024-07-18
ER

PT J
AU Hsiao, FY
   Chang, FY
   Vida, P
   Kuo, BC
   Chen, PC
AF Hsiao, Fu-Yuen
   Chang, Feng-Yu
   Vida, Pablo
   Kuo, Brian C.
   Chen, Pei-Chung
TI Reading detection of needle-type instrument in a noisy environment using
   computer vision-based algorithms Application to airspeed instrument
   readings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Needle-type instrument; Aviation safety investigation
AB This study investigated the use of computer vision-based algorithms for detecting needle-type instrument readings in the cockpit of an aerial vehicle. A flight data recorder plays a crucial role in aviation safety investigations and flight operation review. In practice, not all aerial vehicles are equipped with flight data recorders, and this poses problems in the retrieval of instrument readings during investigations. Installing a lightweight recorder such as a camera in the cockpit to record the instrument panel is a solution to the mentioned problem. Although recorded flight data can be retrieved through human inspection, computer vision-based algorithms enable more rapid and efficient detection. Accordingly, this study developed two computer vision-based algorithms operated in both of the grayscale color space and the value layer of the hue-saturation-value color space. Performance of the four combinations is then compared and the best combination of algorithm along with operation space is suggested. The airspeed meter of a Bell 206 helicopter was selected to test the proposed detection algorithm in this study. GPS data and human inspection results were used as references. Herein, experimental results are presented, performance of algorithms is discussed, and conclusions are provided. This study contributes to aviation safety investigations and flight operation review involving aerial vehicles that are not equipped with flight data recorders.
C1 [Hsiao, Fu-Yuen; Chang, Feng-Yu] Tamkang Univ, Dept Aerosp Engn, New Taipei 25137, Taiwan.
   [Vida, Pablo] Ecole Natl Aviat Civile, Toulouse, France.
   [Kuo, Brian C.; Chen, Pei-Chung] Taiwan Transportat Safety Board, New Taipei, Taiwan.
C3 Tamkang University; Universite Federale Toulouse Midi-Pyrenees (ComUE);
   Universite de Toulouse; Ecole Nationale de l'Aviation Civile (ENAC)
RP Hsiao, FY (corresponding author), Tamkang Univ, Dept Aerosp Engn, New Taipei 25137, Taiwan.
EM fyhsiao@mail.tku.edu.tw
OI Hsiao, Fu-Yuen/0000-0002-4562-0356
FU Taiwan Ministry of Science and Technology [MOST 107-2221-E-032-027]
FX This research was funded by the Taiwan Ministry of Science and
   Technology under grant number MOST 107-2221-E-032-027.
CR CAA, 2018, CIV AV ACT REP CHIN
   Chmielinska Jolanta, 2016, Przeglad Elektrotechniczny, V92, P95, DOI 10.15199/48.2016.11.24
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Ezatzadeh S, 2019, MULTIMED TOOLS APPL, V78, P25515, DOI 10.1007/s11042-019-7720-3
   FAA, FAA ORD JO 7110 65Z
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hsiao FY, 2016, J AERONAUT ASTRONAUT, V48, P11, DOI 10.6125/15-0830-860
   Jiannan Chi, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/283629
   Medjram S, 2018, MULTIMED TOOLS APPL, V77, P13821, DOI 10.1007/s11042-017-4995-0
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   SABLATNIG R, 1994, INT C PATT RECOG, P794, DOI 10.1109/ICPR.1994.576447
   Shin S, 2016, 16 AIAA AV TECHN INT
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   TTSB, 2017, ASCASR1810012
   Vision-1000, 2020, WEBS VIS 1000 APP
   Xu L, 2015, PROC SPIE, V9675, DOI 10.1117/12.2202805
   Ye XF, 2013, J COMPUT, V8, P1309, DOI 10.4304/jcp.8.5.1309-1314
   Zhou Y., 2016, INT J SCI, V3, P125
NR 18
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1749
EP 1782
DI 10.1007/s11042-022-13226-y
EA JUN 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000808527500003
DA 2024-07-18
ER

PT J
AU Yin, YP
   Wei, L
AF Yin, Yuping
   Wei, Lin
TI Hyperspectral image classification using ensemble extreme learning
   machine based on fuzzy entropy weights and auto-adapted spatial-spectral
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Extreme learning machine; Fuzzy entropy weights;
   Auto-adapted spatial-spectral features
AB In order to improve the classification of hyperspectral image, we propose a novel hyperspectral image classification model using ensemble extreme learning machine based on fuzzy entropy weights and auto-adapted spatial-spectral features (FEW-ASSELM). To be specific, the fuzzy entropy weight of the band is proposed as a new metric to measure the importance of each band, which can optimize the grouping strategy of the effective bands. With the change of grouping strategy and random training set, the method of auto-adapted spatial-spectral features extraction is proposed to extract the more effective features. According to the characteristics of the suboptimal grouping strategy and auto-adapted spatial-spectral features, the matching framework of ensemble extreme learning machine can be proposed to perform classification operation. Experimental results on the typical hyperspectral image datasets illustrate that the proposed FEW-ASSELM has few adjustable parameters to make the operation simple, and outperforms a variety of the image classification counterparts in terms of the calculation cost and classification accuracy.
C1 [Yin, Yuping] Liaoning Tech Univ, Sch Elect & Control Engn, Huludao, Peoples R China.
   [Wei, Lin] Liaoning Tech Univ, Dept Basic Educ, Huludao, Peoples R China.
C3 Liaoning Technical University; Liaoning Technical University
RP Wei, L (corresponding author), Liaoning Tech Univ, Dept Basic Educ, Huludao, Peoples R China.
EM 315227336@qq.com; 29766164@qq.com
RI Wei, Lin/HTO-6723-2023
FU Science and Technology Research Project of the Education Department of
   Liaoning [LJ2020QNL013]; Doctoral Initiation Foundation of Liaoning
   Technical University [19-1026, 21-1050]
FX This work was supported in part by the Science and Technology Research
   Project of the Education Department of Liaoning under Grant No.
   LJ2020QNL013, in part by the Doctoral Initiation Foundation of Liaoning
   Technical University under Grant No. 19-1026 and Grant No. 21-1050.
CR Abbasi M, 2020, IET INTELL TRANSP SY, V14, P1484, DOI 10.1049/iet-its.2019.0783
   Abbasi M, 2020, J GRID COMPUT, V18, P43, DOI 10.1007/s10723-020-09507-1
   Abbasi M, 2020, J GRID COMPUT, V18, P305, DOI 10.1007/s10723-019-09502-1
   Cai YM, 2021, NEUROCOMPUTING, V434, P21, DOI 10.1016/j.neucom.2020.12.064
   Cao FX, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112603
   Cervellera C, 2017, IEEE T CYBERNETICS, V47, P3254, DOI 10.1109/TCYB.2017.2648261
   Chen HY, 2021, IEEE J-STARS, V14, P2781, DOI 10.1109/JSTARS.2021.3059451
   Du PJ, 2015, IEEE J-STSP, V9, P1089, DOI 10.1109/JSTSP.2015.2423260
   Fauvel M, 2012, PATTERN RECOGN, V45, P381, DOI 10.1016/j.patcog.2011.03.035
   [谷雨 Gu Yu], 2018, [测绘学报, Acta Geodetica et Cartographica Sinica], V47, P1238
   Jiang MY, 2018, IEEE ACCESS, V6, P22645, DOI 10.1109/ACCESS.2018.2825978
   Jiang Q, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132637
   Li JJ, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.097296
   [刘艳霞 Liu Yanxia], 2015, [仪器仪表学报, Chinese Journal of Scientific Instrument], V36, P1921
   [吕飞 Lu Fei], 2018, [大连理工大学学报, Journal of Dalian University of Technology], V58, P166
   Minchao Y, 2019, NEURAL COMPUT APPL
   Neal LC, 2018, J GEOCHEM EXPLOR, V184, P179, DOI 10.1016/j.gexplo.2017.10.019
   Okwuashi O, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107298
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Peters J, 2017, ADAPT COMPUT MACH LE
   Pour AB, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030519
   Qing YY, 2020, NEUROCOMPUTING, V412, P426, DOI 10.1016/j.neucom.2020.06.110
   Samat A, 2014, IEEE J-STARS, V7, P1060, DOI 10.1109/JSTARS.2014.2301775
   [孙伟伟 Sun Weiwei], 2018, [遥感学报, Journal of Remote Sensing], V22, P110
   [唐意东 Tang Yidong], 2017, [电子学报, Acta Electronica Sinica], V45, P2368
   Wang CY, 2021, ARTIF INTELL REV, V54, P5205, DOI 10.1007/s10462-021-10018-y
   Yin YP, 2020, IEEE ACCESS, V8, P187991, DOI 10.1109/ACCESS.2020.3030649
   Zhou YC, 2015, IEEE J-STARS, V8, P2351, DOI 10.1109/JSTARS.2014.2359965
NR 28
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 217
EP 238
DI 10.1007/s11042-022-13255-7
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000806706500003
DA 2024-07-18
ER

PT J
AU Fang, C
   Wang, XP
   Wang, QS
AF Fang, Chao
   Wang, Xiaopeng
   Wang, Qingsheng
TI Adaptive morphology structural element construction algorithm based on
   local pixel density and symmetry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mathematical morphology; Adaptive structuring element; Local pixel
   density; Symmetry
ID SEGMENTATION
AB Conventional morphological operations are implemented with fixed shape and size structuring elements. However, under these conditions, image features may change due to the complexity and diversity of images, leading to target boundary shifting, pseudo-target appearance, loss of detail, etc. In this paper, an adaptive mathematical morphology structuring element based on local pixel density and symmetry is proposed. The proposed structuring element can adaptively change shape according to the local pixel density, symmetry, and boundary features of pixels of image targets. First, the image is locally smoothed with a neighbourhood grey difference changing vector field to produce homogeneous image targets. Second, a local pixel density function based on pixel Euclidean distance, a pixel symmetry function based on pixel relative density, and a variation coefficient based on local pixel density and symmetry are defined. Finally, whether the centre pixel of the local pixel neighbourhood is a border pixel is determined with the variation coefficient. The adaptive structuring element is composed of all the border pixels determined in the local region of the image. According to the constructed structuring element, morphological dilation and erosion as well as other derived morphological operations are presented. The experimental results show that, with morphological operations, the proposed structuring element has the ability to adaptively fit the shape of image targets, preserve the necessary information of image features completely, and avoid image target boundary shifting. In addition to weakening the shading details, other image information is preserved, and distortion of the image is reduced.
C1 [Fang, Chao; Wang, Xiaopeng; Wang, Qingsheng] Lanzhou Jiaotong Univ, Sch Elect & Informat Engn, Lanzhou 730070, Peoples R China.
C3 Lanzhou Jiaotong University
RP Wang, XP (corresponding author), Lanzhou Jiaotong Univ, Sch Elect & Informat Engn, Lanzhou 730070, Peoples R China.
EM 408964018@qq.com; wangxiaopeng@mail.lzjtu.cn; 835693027@qq.com
OI Wang, Qingsheng/0000-0002-7080-0105
CR Adamski M, 2021, INFORM SCIENCES, V551, P168, DOI 10.1016/j.ins.2020.11.019
   Bai RX, 2017, PROC INT CONF ANTI, P69, DOI 10.1109/ICASID.2017.8285746
   Curic V, 2012, IEEE J-STSP, V6, P809, DOI 10.1109/JSTSP.2012.2207371
   Das, 2016, C CONTROL INSTRUMENT, P1215
   Diggle P.J., 1983, Biometrics, V39, P536, DOI [DOI 10.2307/2531038, 10.2307/2531038]
   Ding L., 2017, IMAGE SIGNAL PROCESS
   Fang C, 2020, IEEE ACCESS, V8, P54928, DOI 10.1109/ACCESS.2020.2980885
   Fouladivanda M, 2016, IRAN CONF ELECTR ENG, P960, DOI 10.1109/IranianCEE.2016.7585660
   Khurshid Hasnat, 2015, Asia Modelling Symposium 2015 (AMS). 9th International Conference on Mathematical Modelling and Computer Simulation. Proceedings, P96, DOI 10.1109/AMS.2015.24
   Landström A, 2013, PATTERN RECOGN LETT, V34, P1416, DOI 10.1016/j.patrec.2013.05.003
   Legaz-Aparicio AG, 2018, J COMPUT APPL MATH, V330, P965, DOI 10.1016/j.cam.2017.05.001
   Lei T, 2019, IEEE T IMAGE PROCESS, V28, P5510, DOI 10.1109/TIP.2019.2920514
   Lerallut R, 2007, IMAGE VISION COMPUT, V25, P395, DOI 10.1016/j.imavis.2006.04.018
   Makhlouf Y, 2019, EXPERT SYST APPL, V119, P342, DOI 10.1016/j.eswa.2018.10.049
   Mallat K, 2016, 2016 INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), P253, DOI 10.1109/ISIVC.2016.7893996
   Pal S, 2019, MULTIDIM SYST SIGN P, V30, P373, DOI 10.1007/s11045-018-0561-9
   Pinoli JC, 2009, IEEE IMAGE PROC, P2249, DOI 10.1109/ICIP.2009.5413979
   Rishikeshan CA, 2018, ISPRS J PHOTOGRAMM, V146, P11, DOI 10.1016/j.isprsjprs.2018.08.014
   Stawiaski J, 2009, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2009.5413942
   Ti CL, 2017, IEEE SENS J, V17, P4534, DOI 10.1109/JSEN.2017.2707522
   Wang XP, 2014, OPTOELECTRON LETT, V10, P152, DOI 10.1007/s11801-014-3209-5
   Zhang CB, 2015, AEU-INT J ELECTRON C, V69, P226, DOI 10.1016/j.aeue.2014.09.006
NR 22
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 195
EP 215
DI 10.1007/s11042-022-13259-3
EA JUN 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749700004
DA 2024-07-18
ER

PT J
AU Nagar, A
   Kumar, MA
   Vaegae, NK
AF Nagar, Anubha
   Kumar, Mithra Anand
   Vaegae, Naveen Kumar
TI Hand hygiene monitoring and compliance system using convolution neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural networks (CNN); Template matching; Optical character
   recognition (OCR); Frame extraction; Image processing; Hand hygiene;
   Healthcare associated infections (HCAI)
AB Hand hygiene monitoring and compliance systems play a significant role in curbing the spread of healthcare associated infections and the COVID-19 virus. In this paper, a model has been developed using convolution neural networks (CNN) and computer vision to detect an individual's germ level, monitor their hand wash technique and create a database containing all records. The proposed model ensures all individuals entering a public place prevent the spread of healthcare associated infections (HCAI). In our model, the individual's identity is verified using two-factor authentication, followed by checking the hand germ level. Furthermore, if required the model will request sanitizing/ hand wash for completion of the process. During this time, the hand movements are checked to ensure each hand wash step is completed according to World Health Organization (WHO) guidelines. Upon completion of the process, a database with details of the individual's germ level is created. The advantage of our model is that it can be implemented in every public place and it is easily integrable. The performance of each segment of the model has been tested on real-time images an validated. The accuracy of the model is 100% for personal identification, 96.87% for hand detection, 93.33% for germ detection and 85.5% for the compliance system respectively.
C1 [Nagar, Anubha; Kumar, Mithra Anand; Vaegae, Naveen Kumar] Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Vaegae, NK (corresponding author), Vellore Inst Technol, Sch Elect Engn, Vellore 632014, Tamil Nadu, India.
EM anubha.ed@gmail.com; madhumithraa99@gmail.com; vegenaveen@vit.ac.in
RI Vaegae, Naveen Kumar/R-3232-2019
OI Vaegae, Naveen Kumar/0000-0002-0292-697X
CR Alzyood M, 2020, J CLIN NURS, V29, P2760, DOI 10.1111/jocn.15313
   [Anonymous], SYSTEM REQUIREMENTS
   [Anonymous], 2006, WHO GUID HAND HYG HL
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Erasmus V, 2010, INFECT CONT HOSP EP, V31, P283, DOI 10.1086/650451
   Llorca DF, 2011, MACH VISION APPL, V22, P219, DOI 10.1007/s00138-009-0234-7
   Fitzpatrick F, 2020, CURR TREAT OPT INFEC, V12, P135, DOI 10.1007/s40506-020-00216-7
   Galkin M, 2019, HYGIENE MONITORING S
   Gurav RM, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INSTRUMENTATION AND CONTROL (ICIC), P974, DOI 10.1109/IIC.2015.7150886
   Haque A, ProcMach Learn, V68, P75
   Jian Zhang, 2013, 2013 Fourth International Conference on Emerging Intelligent Data and Web Technologies (EIDWT), P708, DOI 10.1109/EIDWT.2013.122
   Kaggle, 2020, KAGGLE
   Kumar S, 2020, INT J HEALTHCARE MAN, V13, P337, DOI 10.1080/20479700.2020.1810453
   Kumar Vedant, 2020, 2020 International Conference on Smart Electronics and Communication (ICOSEC), P72, DOI 10.1109/ICOSEC49089.2020.9215246
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Nayal K, 2022, INT J LOGIST MANAG, V33, P744, DOI 10.1108/IJLM-12-2020-0493
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Patel B, 2016, SAMJ S AFR MED J, V106, P32, DOI [10.7196/SAMJ.2016.v106i4.10671, 10.7196/samj.2016.v106i4.10671]
   Saylan Y, 2019, BIOSENSORS-BASEL, V9, DOI 10.3390/bios9020065
   who, HLTH CAR ASS INF FAC
   World Health Organization, 2009, Hand Hygiene Technical Reference Manual: to be Used by Health-Care Workers, Trainers and Observers of Hand Hygiene Practices
   Yang L, 2019, MACH VISION APPL, V30, P1071, DOI 10.1007/s00138-019-01038-4
   Yeung S., 2016, AMIA
   Zelic F, 2021, MACHINE LEARNING BLO
NR 24
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44431
EP 44444
DI 10.1007/s11042-022-11926-z
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805749900006
PM 35677317
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Wang, XY
   Shen, YX
   Dai, Y
   Tian, J
   Niu, PP
   Yang, HY
AF Wang, Xiangyang
   Shen, Yixuan
   Dai, Yu
   Tian, Jing
   Niu, Panpan
   Yang, Hongying
TI UDTCWT difference domain statistical decoder using vector-based Weibull
   PDF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Statistical image watermarking; UDTCWT difference coefficients; Vector
   based Weibull distribution; MAP parameters estimation; LMP test
   criterion
ID MULTIPLICATIVE WATERMARK DETECTOR; IMAGE WATERMARKING;
   MAXIMUM-LIKELIHOOD
AB Invisibility, data payload and robustness are widely regarded as the three main attributes that are critical to any digital image watermarking schemes. They restrict each other, so it is a research focus to strike a favorable balance between them. Multiplicative watermarking based on statistical models is an effective method to achieve the trade-off between these three demands. However, most of the existing approaches until now focus on employing transform coefficients, which are usually poor in resistance to multiple attacks. We proposed a new digital image watermarking system in the difference domain of Undecimated Dual Tree Complex Wavelet Transform (UDTCWT) in this article, in which the UDTCWT difference coefficients are used for hiding the watermark information and constructing the watermark decoder. In the process of embedding the watermark, the watermark message is hidden in the UDTCWT difference domain of the carrier image using a multiplicative manner so as to achieve better imperceptibility and robustness. In watermark decoding, we first prove that the vector based Weibull distribution can suitably fit the distribution of the UDTCWT difference coefficients. And then, we constructed a blind statistical digital image watermark decoder in UDTCWT difference coefficients, combining the vector based Weibull distribution with the locally most powerful (LMP) rule. Experimental results on some standard test images demonstrate the efficacy and superiority of the proposed approach.
C1 [Wang, Xiangyang; Shen, Yixuan; Dai, Yu; Tian, Jing; Niu, Panpan; Yang, Hongying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023; Niu, Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61701212];
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZ0985]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212), Scientific Research
   Project of Liaoning Provincial Education Department (No. LJKZ0985), and
   Natural Science Foundation of Liaoning Province (No. 2019-ZD-0468).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amirmazlaghani M, 2019, IET COMPUT VIS, V13, P249, DOI 10.1049/iet-cvi.2018.5254
   Amirmazlaghani M, 2016, INFORM SCIENCES, V370, P1, DOI 10.1016/j.ins.2016.06.037
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Bi HB, 2016, MATH PROBL ENG, V7, P1
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   DUTTA MK, 2009, TENCON 2009 2009 IEE, P10, DOI DOI 10.1109/MINES.2009.229
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Evsutin O, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116523
   FISHER NI, 1985, BIOMETRIKA, V72, P253
   Hill PR, 2015, SIGNAL PROCESS-IMAGE, V35, P61, DOI 10.1016/j.image.2015.04.010
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Li Y, 2021, NEUROCOMPUTING, V461, P171, DOI 10.1016/j.neucom.2021.07.051
   Liu JH, 2019, KSII T INTERNET INF, V13, P452, DOI 10.3837/tiis.2019.01.025
   Niu PP, 2020, IEEE ACCESS, V8, P46624, DOI 10.1109/ACCESS.2020.2978119
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Riad R, 2018, COMPUT ELECTR ENG, V68, P181, DOI 10.1016/j.compeleceng.2018.04.004
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Sparacino G, 2000, IEEE T BIO-MED ENG, V47, P801, DOI 10.1109/10.844232
   Wang XY, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2022.103450
   Wang XY, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115972
   Yang HY, 2019, SOFT COMPUT, V23, P4749, DOI 10.1007/s00500-018-3127-8
NR 31
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43037
EP 43061
DI 10.1007/s11042-022-13229-9
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800827600001
DA 2024-07-18
ER

PT J
AU Sanober, A
   Anwar, S
AF Sanober, Adla
   Anwar, Shamama
TI Crytographical primitive for blockchain: a secure random DNA encoded key
   generation technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Availability; Key generation; Random DNA sequence; Encryption
ID IMAGE ENCRYPTION; CRYPTOGRAPHY; CRYPTOSYSTEM
AB Data Security has always been a challenge while sharing sensitive information and a lot of techniques have been developed to achieve it. Security should not hamper the availability of the data and hence, a technique that caters to both is needed. The use of classical and modern encryption technique are very common and are becoming prone to attacks by crypto-analytics. Due to the technological advancement, new ideas of data security comes very rapidly. For this reason the use of blockchain has become profound but the actual security of the data encryption technique always depends on the choice of the key. Stronger key leads to high data security. The paper aims to explore the concept of DNA encoding to propose a data encryption algorithm. It uses a dynamic DNA encoded table which contains different combination of four DNA bases A, C, G, and T but the main feature of dynamic DNA sequence table is its randomness which is changed for different characters in ASCII code in each run time. This randomness in the encryption disables attackers to perform any sort of statistical analysis to decipher the encrypted text or guess the key.
C1 [Sanober, Adla; Anwar, Shamama] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Anwar, S (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
EM shamama@bitmesra.ac.in
RI Anwar, Shamama/GWZ-7119-2022
OI Anwar, Shamama/0000-0002-2013-7181; SANOBER, ADLA/0000-0001-8678-3701
CR Abdalrdha ZK, 2019, SUBJECT REV KEY GENE
   Advani NA, 2019, PROCEEDINGS OF THE 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P359
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Banu SA, 2020, MULTIMED TOOLS APPL, V79, P28807, DOI 10.1007/s11042-020-09501-5
   Bassham III LE, 2010, 80022 SP NAT I STAN
   Basu S, 2019, J SYST ARCHITECT, V94, P24, DOI 10.1016/j.sysarc.2019.02.005
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Bhadoria R.S., 2020, ADV APPL BLOCKCHAIN, P269, DOI DOI 10.1007/978-981-13-8775-3_13
   Bhattacharyya R, 2010, LECT NOTES COMPUT SC, V6147, P168, DOI 10.1007/978-3-642-13858-4_10
   Chen WH, 2019, J PHYS CONF SER, V1267, DOI 10.1088/1742-6596/1267/1/012014
   Dagadu JC, 2019, MULTIMED TOOLS APPL, V78, P24979, DOI 10.1007/s11042-019-7693-2
   Devi RS, 2020, MULTIMED TOOLS APPL, V79, P12093, DOI 10.1007/s11042-019-08562-5
   Gehani A, 2004, LECT NOTES COMPUT SC, V2950, P167
   Hossain EMS, 2016, 2016 19 INT C COMPUT
   Huang Z, 2019, ARXIV 190503013
   Hussain SM, 2016, P INT C SEC MAN SAM1
   KAHATE A., 2013, Cryptography and network security
   Kalsi S, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0851-z
   Kaur M, 2013, INT J COMPUT APPL, V70
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khatal S, 2020, INT C MOD SIM INT CO
   Kim P, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-2107-3
   Leier A, 2000, BIOSYSTEMS, V57, P13, DOI 10.1016/S0303-2647(00)00083-6
   Liu H, 2019, IEEE ACCESS, V7, P65450, DOI 10.1109/ACCESS.2019.2917498
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Padate R., 2014, International Journal of Emerging Technology and Advanced Engineering, V4, P54
   Pramanik S., 2012, 2012 7th International Conference on Electrical & Computer Engineering (ICECE), P551, DOI 10.1109/ICECE.2012.6471609
   Prasetyadi GC., 2018, TELKOMNIKA, V16, P361, DOI [10.12928/telkomnika.v16i1.6409, DOI 10.12928/TELKOMNIKA.V16I1.6409]
   Qadir A.M., 2019, 2019 7TH INTERNATIONAL SYMPOSIUM ON DIGITAL FORENSICS AND SECURITY (ISDFS), P1
   Rahouma KH, EGYPTIAN COMPUTER SC, V44
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Rivest R., 1992, Tech. Rep.
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Saraf KR, 2014, Int J Em Trends Technol Comp Sci (IJETTCS), V3, P118
   Selent D., 2010, Rivier Academic Journal, V6, P1
   Sivaraman R, 2020, IET IMAGE PROCESS, V14, P2987, DOI 10.1049/iet-ipr.2019.0168
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Zhang JQ, 2016, IEEE ACCESS, V4, P614, DOI 10.1109/ACCESS.2016.2521718
NR 41
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40413
EP 40430
DI 10.1007/s11042-022-13063-z
EA MAY 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000792555900001
DA 2024-07-18
ER

PT J
AU Hematpour, N
   Ahadpour, S
   Sourkhani, IG
   Sani, RH
AF Hematpour, Nafiseh
   Ahadpour, Sodeif
   Sourkhani, Iman Golbaz
   Sani, Reza Hoseini
TI A new steganographic algorithm based on coupled chaotic maps and a new
   chaotic S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Pair coupled map; Substitution boxes(S-boxes);
   Ergodicity; Kolmogorov Sinai entropy; Synchronization; Random number
   test
ID IMAGE ENCRYPTION ALGORITHM; INTEGER WAVELET TRANSFORM;
   SUBSTITUTION-BOXES; HIERARCHY; SYNCHRONIZATION; DESIGN; SCHEME; DOMAIN;
   SPACE
AB The art of concealing information by embedding it in a seemingly "innocent" message is called steganography. An appropriate system for steganography is essential to guarantee the safety of the transfer file and, moreover, the size of the attached file is of great importance. Ergodic dynamical systems with confusion guarantee an acceptable level of security for cryptographic systems. Here, we suggest a new steganography algorithm based on a measurable dynamical system and a new chaotic S-box. We use two different chaotic maps at the same time to create the new S-box aimed at providing adequate key space and high security for the encryption. In the encryption stage, the message is encrypted with a new S-box. The capability of S-box and encryption has been confirmed by performance analysis. Our goal in adding this encryption step is to increase security and complicate the process to access the steganographic stage secret message. The pixel position of the cover color image is determined by using chaotic maps in the proposed algorithm, in which, a secret information bit can be hidden. By considering the key role in the security of cryptographic systems, an entropy calculation is presented to determine the chaotic area of the proposed system. The problems of the low security against some existing tests as well as the small key space may lead to the steganography failure, which can be fixed by the proposed algorithm. The contributions of the suggested steganography algorithm are as follows: (1) It allows us to use an ergodic coupled system that provides ample key space. (2) It uses an encryption step with new, well-performance S-boxes that provides high security. (3) The performance of the steganographic design performs better than previous works.
C1 [Hematpour, Nafiseh; Ahadpour, Sodeif; Sourkhani, Iman Golbaz] Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
   [Sani, Reza Hoseini] Urmia Univ Technol, Dept Phys, Orumiyeh, Iran.
C3 University of Mohaghegh Ardabili; Urmia University of Technology
RP Ahadpour, S (corresponding author), Univ Mohaghegh Ardabili, Dept Phys, Ardebil, Iran.
EM n_hematpour@uma.ac.ir; ahadpour@uma.ac.ir
RI Hoseini sani, Reza/CAE-9766-2022
OI Hoseini sani, Reza/0000-0001-5550-567X; Ahadpour,
   Sodeif/0000-0002-0474-4678
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Agiza HN, 2004, NONLINEAR ANAL-THEOR, V58, P11, DOI 10.1016/j.na.2004.04.002
   Ahadpour, 2012, ARXIV 12075590V1
   Ahadpour S, 2009, COMMUN NONLINEAR SCI, V14, P2916, DOI 10.1016/j.cnsns.2008.10.029
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   [Anonymous], FEDERAL INFORM PROCE
   [Anonymous], 1996, Invitation to dynamical systems
   Azoug SE, 2016, OPT COMMUN, V359, P85, DOI 10.1016/j.optcom.2015.09.054
   Bai JL, 2017, DISPLAYS, V46, P42, DOI 10.1016/j.displa.2016.12.004
   Bassham L. E., 2010, SPECIAL PUBLICATION
   Batool SI, 2021, MULTIMED TOOLS APPL, V80, P28857, DOI 10.1007/s11042-021-11090-w
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Çavusoglu U, 2018, NONLINEAR DYNAM, V92, P1745, DOI 10.1007/s11071-018-4159-4
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cui QQ, 2016, CHAOS SOLITON FRACT, V87, P158, DOI 10.1016/j.chaos.2016.04.002
   Cusick TW, 2017, CRYPTOGRAPHIC BOOLEAN FUNCTIONS AND APPLICATIONS, 2ND EDITION, P1
   Diaconu AV, 2016, INFORM SCIENCES, V355, P314, DOI 10.1016/j.ins.2015.10.027
   Dorfman J.R., 1999, An Introduction to Chaos in Nonequilibrium Statistical Mechanics
   Gonzalez, 2010, DIGITAL IMAGE PROCES, V21, P797
   Hakak S, 2019, INFORM PROCESS MANAG, V56, P367, DOI 10.1016/j.ipm.2017.08.004
   Hematpour N, 2021, MULTIMED TOOLS APPL, V80, P10509, DOI 10.1007/s11042-020-10059-5
   Hematpour N, 2021, NEURAL COMPUT APPL, V33, P5111, DOI 10.1007/s00521-020-05304-9
   Huang TS, 2016, CHAOS SOLITON FRACT, V91, P92, DOI 10.1016/j.chaos.2016.05.009
   Hussain I, 2012, NONLINEAR DYNAM, V70, P1791, DOI 10.1007/s11071-012-0573-1
   Jafarizadeh MA, 2006, PRAMANA-J PHYS, V67, P1073, DOI 10.1007/s12043-006-0024-y
   Jafarizadeh MA, 2002, J NONLINEAR MATH PHY, V9, P26, DOI 10.2991/jnmp.2002.9.1.4
   Jafarizadeh MA, 2001, J STAT PHYS, V104, P1013, DOI 10.1023/A:1010449627146
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kalita M, 2019, COMPUT J, V62, P1639, DOI 10.1093/comjnl/bxz014
   Kaneko K., 1996, FUKUZATSUKEI NO KAOS
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kaur R, 2021, MULTIMED TOOLS APPL, V80, P14665, DOI 10.1007/s11042-021-10528-5
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Korba KA, 2021, MULTIMED TOOLS APPL, V80, P32595, DOI 10.1007/s11042-021-11226-y
   Laishram D, 2021, MULTIMED TOOLS APPL, V80, P831, DOI 10.1007/s11042-020-09519-9
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee K, 2007, LECT NOTES COMPUT SC, V4567, P378
   Lee YP, 2012, INFORM SCIENCES, V191, P214, DOI 10.1016/j.ins.2012.01.002
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu L, 2017, OPT COMMUN, V398, P62, DOI 10.1016/j.optcom.2017.04.015
   Lv XP, 2018, MULTIMED TOOLS APPL, V77, P28633, DOI 10.1007/s11042-018-6013-6
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Murugan GVK, 2020, MULTIMED TOOLS APPL, V79, P9101, DOI 10.1007/s11042-019-7507-6
   National Institute of Standards and Technology, 1999, 463 NAT I STAND TECH
   Nestor T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010083
   Njitacke ZT, 2021, NEURAL COMPUT APPL, V33, P6733, DOI 10.1007/s00521-020-05451-z
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Poornima R., 2013, Int. JComput. Sci. Engin. Survey., V4, P23, DOI [10.5121/ijcses.2013.4102, DOI 10.5121/IJCSES.2013.4102]
   Pratt, 2010, DIGITAL IMAGE PROCES, P782
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Ramalingam M, 2015, APPL SOFT COMPUT, V34, P744, DOI 10.1016/j.asoc.2015.05.040
   Reshma, 2020, COMPUT J, P1
   Schneier B., 2007, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Shoeibi, 2020, REV ARXIV PREPRINT A
   Shoeibi A, 2021, ARXIV 210504881
   Shoeibi A, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113788
   Strogatz S. H., 2000, Nonlinear Dynamics and Chaos: With Applications to Physics, Biology, Chemistry and Engineering
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Thanikaiselvan V, 2015, SECUR COMMUN NETW, V8, P2374, DOI 10.1002/sec.1185
   Trithemius J., 1606, STEGANOGRAPHIA, VFirst
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang ZX, 1989, SPECIAL FUNCTIONS, P677
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wilf, 1994, ALGORITHMS COMPLEXIT, P139
   Wong KS, 2007, SIGNAL PROCESS, V87, P1251, DOI 10.1016/j.sigpro.2006.10.014
   Yang CH, 2010, J SYST SOFTWARE, V83, P1635, DOI 10.1016/j.jss.2010.03.081
   Yang FF, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106031
   Zhang HG, 2010, IEEE T SYST MAN CY B, V40, P831, DOI 10.1109/TSMCB.2009.2030506
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
NR 79
TC 6
Z9 6
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 39753
EP 39784
DI 10.1007/s11042-022-12828-w
EA MAY 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000789768900003
DA 2024-07-18
ER

PT J
AU Shringi, S
   Sharma, H
AF Shringi, Sakshi
   Sharma, Harish
TI Detection of spam reviews using hybrid grey wolf optimizer clustering
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Grey Wolf Optimizer; k-Means; Data clustering; Spam detection;
   Metaheuristic methods
ID SELECTION; CLASSIFICATION
AB Currently, online reviews play an essential role in the decision-making of customers. Various online websites such as Amazon, Yelp, Google Plus, BookMyShow, Facebook, Twitter, etc., allow its users to generate huge bulk of data. The data is generated in the form of feedback/reviews, comments, or tweets. This data is helpful for organizations to improve the quality of their products. Due to dependency on these online reviews, spam reviews are generated pretentiously by some organizations and people concerning promotion or demotion of the prominence of any product, organization, or person. Thus, identifying spam or non-spam review by the naked eye is nearly impossible. Classifying the reviews manually is also highly speculative. Hence, to overcome this issue, a hybrid Grey Wolf Optimizer (GWOK) based clustering method is proposed in this paper to identify spam reviews. In the proposed GWOK, the k-Means algorithm is used for initialization of the initial population for the basic GWO algorithm, and then the GWO algorithm is used for finding the optimal Cluster Heads. To prove that the proposed strategy is effective, three spam datasets, namely Synthetic Spam Reviews, Movie Reviews, and Yelp Hotel & Restaurant Reviews, have been used in our work. The reported results are compared with the existing state-of-art metaheuristic clustering methods like a genetic algorithm (GA), differential evolution (DE), particle swarm optimization (PSO), cuckoo search (CS), and k-Means. The results obtained by experimental and statistical analysis legitimize that the proposed GWOK algorithm surpasses contemporary techniques.
C1 [Shringi, Sakshi; Sharma, Harish] Rajasthan Tech Univ, Kota, India.
C3 Rajasthan Technical University
RP Shringi, S (corresponding author), Rajasthan Tech Univ, Kota, India.
EM sakshi.shringi@gmail.com; hsharma@rtu.ac.in
RI Shringi, Sakshi/IVU-8831-2023
OI Shringi, Sakshi/0000-0003-1737-3340
CR Abu-Nimeh S., 2007, P ANT WORK GROUPS 2, DOI DOI 10.1145/1299015.1299021
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514
   [Anonymous], 2014, Int. J. Metaheuristics (IJMHeur), DOI [10.1504/IJMHEUR.2014.068914, DOI 10.1504/IJMHEUR.2014.068914]
   Asghar MZ, 2020, SOFT COMPUT, V24, P3475, DOI 10.1007/s00500-019-04107-y
   Baeza-Yates R., 1999, Modern information retrieval
   Bindu PV, 2018, J INTELL INF SYST, V51, P503, DOI 10.1007/s10844-017-0494-z
   Bird S., 2009, NATURAL LANGUAGE PRO
   Blackburn, 2015, DEV PSYCHOMETRIC PRO
   Tran CT, 2018, APPL SOFT COMPUT, V73, P848, DOI 10.1016/j.asoc.2018.09.026
   Catal C, 2017, IET SOFTW, V11, P89, DOI 10.1049/iet-sen.2016.0137
   Chang T, 2015, LECT NOTES COMPUT SC, V9243, P181, DOI 10.1007/978-3-319-23862-3_18
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hu YH, 2017, INFORM PROCESS MANAG, V53, P436, DOI 10.1016/j.ipm.2016.12.002
   Idris I, 2014, ENG APPL ARTIF INTEL, V28, P97, DOI 10.1016/j.engappai.2013.12.001
   Inuwa-Dutse I, 2018, NEUROCOMPUTING, V315, P496, DOI 10.1016/j.neucom.2018.07.044
   Jindal N., 2008, P WSDM, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li F., 2011, P 22 INT JOINT C ART, P2488, DOI [10.5555/2283696, DOI 10.5591/978-1-57735-516-8/IJCAI11-414, 10.5591/978-1-57735-516-8/IJCAI11-]
   Li YC, 2018, EXPERT SYST APPL, V96, P261, DOI 10.1016/j.eswa.2017.12.016
   Liu SG, 2016, ASIA CCS'16: PROCEEDINGS OF THE 11TH ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1, DOI 10.1145/2897845.2897928
   Luca Michael, 2011, Reviews, reputation, and revenue: The case of Yelp.com (March 15, DOI DOI 10.2139/SSRN.1928601
   Mateen M, 2017, INT BHURBAN C APPL S, P466, DOI 10.1109/IBCAST.2017.7868095
   McCord M., 2011, Autonomic and Trusted Computing. Proceedings 8th International Conference (ATC 2011), P175, DOI 10.1007/978-3-642-23496-5_13
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moh'd Abdelwadood, 2007, Journal of Computer Sciences, V3, P430, DOI 10.3844/jcssp.2007.430.435
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Mukherjee A., 2013, UICCS201303
   Mukhopadhyay A, 2013, IEEE WORKSH HYBRID, P7, DOI 10.1109/HIMA.2013.6615016
   Narayan R, 2018, ADV INTELL SYST, V719, P281, DOI 10.1007/978-981-10-3376-6_31
   Pereira FB, 2009, EVOL INTELL, V2, P121, DOI 10.1007/s12065-009-0020-5
   Petrescu M, 2018, J RETAIL CONSUM SERV, V41, P288, DOI 10.1016/j.jretconser.2017.04.005
   Rajamohana S. P., 2017, 2017 Third International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB). Proceedings, P524, DOI 10.1109/AEEICB.2017.7972369
   Rajasekaran S, 2017, IEEE INT C BIOINFORM, P1, DOI 10.1109/ULTSYM.2017.8091730
   Salehi S., 2011, Proceedings 2011 IEEE 2nd International Conference on Software Engineering and Service Science (ICSESS 2011), P594, DOI 10.1109/ICSESS.2011.5982390
   Santos I, 2009, ICEIS 2009 : PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS, VOL AIDSS, P317
   Sasaki M, 2005, 2005 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P316, DOI 10.1109/CW.2005.83
   Sedhai S, 2018, IEEE T COMPUT SOC SY, V5, P169, DOI 10.1109/TCSS.2017.2773581
   Shehnepoor S, 2017, IEEE T INF FOREN SEC, V12, P1585, DOI 10.1109/TIFS.2017.2675361
   Shekhawat SS, 2021, EVOL INTELL, V14, P1307, DOI 10.1007/s12065-019-00334-2
   Shojaee S, 2013, INT CONF INTELL SYST, P53, DOI 10.1109/ISDA.2013.6920707
   Singh A, 2018, FUTURE GENER COMP SY, V81, P359, DOI 10.1016/j.future.2017.09.072
   Singh M, 2018, ICT BASED INNOVATION, P213
   Singh S, 2018, PROCEDIA COMPUT SCI, V125, P568, DOI 10.1016/j.procs.2017.12.073
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Sun H, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1088
   Talbi E-G, 2009, Metaheuristics: from Design to Implementation, DOI DOI 10.1002/9780470496916
   van der Aalst WMP, 2010, SOFTW SYST MODEL, V9, P87, DOI 10.1007/s10270-008-0106-z
   Wang H, 2010, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P783, DOI [DOI 10.1145/1835804.1835903, 10.1145/1835804.1835903]
   Wu CH, 2009, EXPERT SYST APPL, V36, P4321, DOI 10.1016/j.eswa.2008.03.002
   Wu Tingmin., 2017, P AUSTRALASIAN COMPU, P1, DOI 10.1145/3014812.3014815
   Wu Z, 2015, IEEE DATA MINING, P1039, DOI 10.1109/ICDM.2015.73
   Xie S., 2012, P 18 ACM SIGKDD INT, P823, DOI DOI 10.1145/2339530.2339662
   Xu Y., 2014, P 23 ACM INT C CONFE, P879
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Yang Z, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P861
   Zhai YJ, 2018, INT CONF SOFTW ENG, P160, DOI 10.1109/ICSESS.2018.8663882
NR 57
TC 1
Z9 1
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38623
EP 38641
DI 10.1007/s11042-022-12848-6
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787139200006
DA 2024-07-18
ER

PT J
AU Pandey, NN
   Muppalaneni, NB
AF Pandey, Nageshwar Nath
   Muppalaneni, Naresh Babu
TI A survey on visual and non-visual features in Driver's drowsiness
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection techniques; Driver fatigue; Image processing; Face
   detection; Eye detection; Accidents
ID PATTERN-ANALYSIS; SYSTEM; RECOGNITION; PERFORMANCE; ATTENTION; TRACKING;
   NETWORK; MOUTH
AB Many road accidents are happening due to the negligent behaviour of the drivers, which increases the death rate day by day. The tiredness and drowsiness of the drivers are the primary cause of road accidents. Due to technological advancement, various techniques evolved to identify the drowsy state and alert the driver. As per the literature, the drowsiness detection techniques are categorized into three classes based on driving pattern, physiological characteristics and Computer vision. Among these techniques, we have focussed mainly on the Computer Vision technique in our survey due to its low cost and non-intrusive nature. This technique analyses the various images of driver's posture, such as facial expression, yawning duration, head movement and eye closure to identify drowsy state. A detailed comparative study is presented in this paper and observed that spatial feature based techniques have given highest result with precision 97.12%. Also, state-of-the-art drowsiness detection techniques are exposed, analyzed and reviewed rigorously.
C1 [Pandey, Nageshwar Nath; Muppalaneni, Naresh Babu] Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Pandey, NN (corresponding author), Natl Inst Technol Silchar, Dept Comp Sci & Engn, Silchar, Assam, India.
EM nageshwar0@gmail.com; nareshmuppalaneni@gmail.com
RI Muppalaneni, Naresh Babu/X-7315-2019
OI Muppalaneni, Naresh Babu/0000-0002-8499-1918; PANDEY,
   NAGESHWAR/0000-0003-2015-4296
CR Aaronson L S, 1999, Image J Nurs Sch, V31, P45
   Abtahi S, 2011, IEEE IMTC P, P1606
   Albu AB, 2008, IEEE INT VEH SYM, P50
   Alioua N, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0103-z
   Ang Liu, 2010, 2010 Second Asia Pacific Conference on Postgraduate Research in Microelectronics & Electronics (PrimeAsia 2010), P235, DOI 10.1109/PRIMEASIA.2010.5604919
   [Anonymous], 2014, INT J VEH TECHNOL
   [Anonymous], 2016, Int. Res. J. Eng. Technol
   Arefnezhad S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040943
   Ayudhya CDN, 2009, 6 INT JOINT C COMP S
   Bai X, 2019, 2 INT C PERS TECHN, V11264
   Bamidele AA, 2019, INT J ADV COMPUT SC, V10, P549
   Benoit A, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P207
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Bhandari GM., 2014, Int. J. Res. Eng. Technol, V3, P502
   Bouvier C, 2008, LECT NOTES COMPUT SC, V5259, P1093, DOI 10.1007/978-3-540-88458-3_99
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Chai M, 2019, TRANSPORT RES D-TR E, V66, P95, DOI 10.1016/j.trd.2018.07.007
   Cui YQ, 2019, IEEE T NEUR SYS REH, V27, P2263, DOI 10.1109/TNSRE.2019.2945794
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   Danisman T., 2010, Proceedings International Conference on Machine and Web Intelligence (ICMWI 2010), P230, DOI 10.1109/ICMWI.2010.5648121
   Dasgupta A, 2019, IEEE T INTELL TRANSP, V20, P4045, DOI 10.1109/TITS.2018.2879609
   Dasgupta A, 2013, IEEE T INTELL TRANSP, V14, P1825, DOI 10.1109/TITS.2013.2271052
   Debener S, 2015, SCI REP-UK, V5, DOI 10.1038/srep16743
   Dinges D.F., 1998, US DEP TRANSPORTATIO
   Dinges D.F., 1998, EVALUATION TECHNIQUE
   Dornaika F, 2018, VIDEO ANAL FACE FACI, P61, DOI [10.1007/978-3-030-12177-8_6, DOI 10.1007/978-3-030-12177-8_6]
   Tran D, 2018, IET INTELL TRANSP SY, V12, P1210, DOI 10.1049/iet-its.2018.5172
   Eskandarian A, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1284
   Fletcher L, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P322, DOI 10.1109/IVS.2003.1212930
   Forsman PM, 2013, ACCIDENT ANAL PREV, V50, P341, DOI 10.1016/j.aap.2012.05.005
   Friedrichs F, 2010, EUR SIGNAL PR CONF, P209
   Friedrichs F, 2010, IEEE INT VEH SYM, P101, DOI 10.1109/IVS.2010.5548039
   García-García M, 2018, LECT NOTES COMPUT SC, V10882, P435, DOI 10.1007/978-3-319-93000-8_49
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Ghoddoosian R, 2019, IEEE COMPUT SOC CONF, P178, DOI 10.1109/CVPRW.2019.00027
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grace R., 1996, 17 DASC AIAAIEEESAE, V2, pI36/1, DOI [DOI 10.1109/DASC.1998.739878, 10.1109/DASC.1998.739878]
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Gurudath N, 2014, PROCEDIA COMPUT SCI, V34, P400, DOI 10.1016/j.procs.2014.07.045
   Hammedi J, 2020, INT MULTICONF SYST, P179, DOI 10.1109/SSD49366.2020.9364253
   Han S., 2012, proceedings of IEEE Custom Integrated Circuits Conference (CICC), P1, DOI [10.1109/ISGT.2012.6175717, DOI 10.1145/2162081.2162090]
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   He J., 2013, Journal of Ergonomics, V3, P1
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Hsu HT, 2016, IEEE T NEUR SYS REH, V24, P603, DOI 10.1109/TNSRE.2015.2496184
   Hu TC, 2022, IEEE T INTELL TRANSP, V23, P8063, DOI 10.1109/TITS.2021.3075350
   Huang R, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1174, DOI 10.1109/ICCT.2018.8599947
   Ingre M, 2006, J SLEEP RES, V15, P47, DOI 10.1111/j.1365-2869.2006.00504.x
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   Jayanthi D., 2012, INT J ENG ADV TECHNO
   Jayaram V, 2016, IEEE COMPUT INTELL M, V11, P20, DOI 10.1109/MCI.2015.2501545
   Ji QM, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2018), P316, DOI 10.1109/ICISCE.2018.00073
   Jo J, 2014, EXPERT SYST APPL, V41, P1139, DOI 10.1016/j.eswa.2013.07.108
   Jo J, 2011, OPT ENG, V50, DOI 10.1117/1.3657506
   Joshi A, 2020, IEEE INT VEH SYM, P207, DOI 10.1109/IV47402.2020.9304579
   Kaplan S, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2462084
   Kashiba Y, 2009, P 5 INT WORKSH COMP, V2009, P88
   Kidmose P, 2013, IEEE T BIO-MED ENG, V60, P2824, DOI 10.1109/TBME.2013.2264956
   Koporec G., OBSERVATION SELECTED
   Krithika LB, 2021, J AMB INTEL HUM COMP, V12, P2131, DOI 10.1007/s12652-020-02311-5
   Lee SJ, 2011, IEEE T INTELL TRANSP, V12, P254, DOI 10.1109/TITS.2010.2091503
   Lee YH, 2019, INTELL AUTOM SOFT CO, V25, P205
   Li YG, 2020, CMC-COMPUT MATER CON, V63, P1575, DOI 10.32604/cmc.2020.07451
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Lin CT, 2010, IEEE T BIOMED CIRC S, V4, P214, DOI 10.1109/TBCAS.2010.2046415
   Liu CC, 2009, J SAFETY RES, V40, P239, DOI 10.1016/j.jsr.2009.04.005
   Liu WH, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11050115
   Liu ZM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102723
   Lv X., 2021, Microprocessors and Microsystems
   Malla AM, 2010, IEEE ENG MED BIO, P6741, DOI 10.1109/IEMBS.2010.5626013
   Manoharan K, 2018, IET IMAGE PROCESS, V12, P1567, DOI 10.1049/iet-ipr.2017.0864
   Mavely Annu George, 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P364, DOI 10.1109/ICCS1.2017.8326022
   Miah A.A., 2020, P INT JOINT C COMPUT, P111
   Mittal A, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P903, DOI 10.1109/ICETECH.2016.7569378
   Nair Vivek, 2019, Proceedings of the International Conference on ISMAC in Computational Vision and Bio-Engineering 2018 (ISMAC-CVB).Lecture Notes in Computational Vision and Biomechanics (LNCVB 30), P1191, DOI 10.1007/978-3-030-00665-5_113
   Naqvi RA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020456
   Ngxande M, 2017, 2017 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS (PRASA-ROBMECH), P156, DOI 10.1109/RoboMech.2017.8261140
   Niloy A. R., 2020, International Journal of Image, Graphics and Signal Processing, V10, P41
   Norton JJS, 2015, P NATL ACAD SCI USA, V112, P3920, DOI 10.1073/pnas.1424875112
   Nugraha B.T., 2016, J THEOR APPL INF TEC, V86
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pandey Nageshwar Nath, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1182, DOI 10.1109/ICAIS50930.2021.9395975
   Pandey NN, 2021, J REAL-TIME IMAGE PR, V18, P2287, DOI 10.1007/s11554-021-01114-x
   Panicker AD, 2017, SADHANA-ACAD P ENG S, V42, P1835, DOI 10.1007/s12046-017-0728-3
   Park EJ, 2008, SENSOR REPORT MQ 3 G
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Picot Antoine, 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P801, DOI 10.1109/IMTC.2010.5488257
   Ramzan M, 2019, IEEE ACCESS, V7, P61904, DOI 10.1109/ACCESS.2019.2914373
   Reddy B, 2017, IEEE COMPUT SOC CONF, P438, DOI 10.1109/CVPRW.2017.59
   Ren ZW, 2021, FRONT NEUROROBOTICS, V15, DOI 10.3389/fnbot.2021.618408
   Rezaei M, 2014, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2014.24
   Sabet M., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1247, DOI 10.1109/IranianCEE.2012.6292547
   Saradadevi M, 2008, INT J COMPUT SCI NET, V8, P183
   Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240
   Shakeel MF, 2019, LECT NOTES COMPUT SC, V11506, P283, DOI 10.1007/978-3-030-20521-8_24
   Shamsuddin MRB, 2017, INT C SOFT COMP DAT, DOI [10.1007/978-981-10-7242-0_10, DOI 10.1007/978-981-10-7242-0_10]
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   Simon M, 2011, CLIN NEUROPHYSIOL, V122, P1168, DOI 10.1016/j.clinph.2010.10.044
   Siy H, 2009, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING AND INFORMATION, P12, DOI 10.1109/ICC.2009.72
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Smith P, 2000, INT C PATT RECOG, P636, DOI 10.1109/ICPR.2000.902999
   Soni R, 2019, APPL INTELL, V49, P1376, DOI 10.1007/s10489-018-1338-4
   Maior CBS, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113505
   Sun C, 2014, APPL MECH MATER, V457-458, P944, DOI 10.4028/www.scientific.net/AMM.457-458.944
   Sun XH, 2007, P SOC PHOTO-OPT INS, V6786, P78612, DOI 10.1117/12.747671
   Tumen V, 2018, 2018 EL EL COMP SCI, DOI [10.1109/EBBT.2018.839142, DOI 10.1109/EBBT.2018.839142]
   Phanikrishna BV, 2023, IETE J RES, V69, P3104, DOI 10.1080/03772063.2021.1913070
   Vurall E, 2007, LECT NOTES COMPUT SC, V4796, P6
   2018, ROAD SAF TECH
   Wang D, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P523, DOI 10.1109/ICECC.2011.6067708
   Wang JQ, 2015, INTEGR COMPUT-AID E, V22, P171, DOI 10.3233/ICA-150486
   Wang RB, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P314, DOI 10.1109/ITSC.2004.1398917
   Wang Y, 2019, IEEE ACCESS, V7, P183739, DOI 10.1109/ACCESS.2019.2960157
   Wang Y, 2019, PATTERN RECOGN LETT, V123, P61, DOI 10.1016/j.patrec.2019.03.013
   Wang YT, 2017, IEEE T NEUR SYS REH, V25, P11, DOI 10.1109/TNSRE.2016.2573819
   Wei CS, 2018, IEEE T NEUR SYS REH, V26, P400, DOI 10.1109/TNSRE.2018.2790359
   Weiwei Liu, 2010, 2010 International Conference on Bioinformatics and Biomedical Technology (ICBBT 2010), P404, DOI 10.1109/ICBBT.2010.5478931
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Wu DR, 2017, IEEE T FUZZY SYST, V25, P1522, DOI 10.1109/TFUZZ.2016.2633379
   Wu JD, 2008, EXPERT SYST APPL, V34, P1556, DOI 10.1016/j.eswa.2007.01.019
   Yan C, 2011, COMPUT VIS IMAGE UND, V115, P1223, DOI 10.1016/j.cviu.2011.03.001
   Yoshihara Y, 2020, IEEE INT VEH SYM, P1021, DOI 10.1109/IV47402.2020.9304700
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 125
TC 6
Z9 6
U1 2
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 38175
EP 38215
DI 10.1007/s11042-022-13150-1
EA APR 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000785933700006
DA 2024-07-18
ER

PT J
AU Liu, DH
   Wang, GD
   Zhai, GT
AF Liu, Donghua
   Wang, Guodong
   Zhai, Guangtao
TI Multi-scale dilated convolution of feature Fusion Network for Crowd
   counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Convolution neural network; Dilated convolution; Feature
   fusion
ID TRACKING
AB Crowd counting has long been a challenging task due to the perspective distortion and variability in head size. The previous methods ignore the multi-scale information in images or simply use convolutions with different kernel sizes to extract multi-scale features, resulting in incomplete multi-scale features extracted. In this paper, we propose a crowd counting model called Multi-scale Dilated Convolution of Feature Fusion Network (MsDFNet) based on a CNN (convolutional neural network). Our MsDFNet is based on the regression method of the density map. The density map is predicted by the parameters learned by CNN to obtain better prediction results. The proposed network mainly includes three components, a CNN to extract low-level features, a multi-scale dilated convolution module and multi-column feature fusion blocks, a density map regression module. Multi-scale dilated convolutions are employed to extract multi-scale high-level features, and the features extracted from different columns are fused. The combination of the multi-scale dilated convolution module and the multi-column feature fusion block can effectively extract more complete multi-scale features and boost the performance of counting small-sized targets. Experiments show that the problem of various head sizes in images can be effectively solved by fusing multi-scale context feature information. We prove the effectiveness of our method on two public datasets (The ShanghaiTech dataset and the UCF_CC_50 dataset). We compare our method with the previous state-of-the-art crowd counting algorithms in terms of MAE (Mean Absolute Error) and MSE (Mean Square Error) and significantly improves the performance, especially in case of various head sizes. On the UCF_CC_50 dataset, our method reduces the MAE index by 28.6 compared with the previous state-of-the-art method. (The lower the MAE, the better the performance).
C1 [Liu, Donghua; Wang, Guodong] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
   [Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
C3 Qingdao University; Shanghai Jiao Tong University
RP Wang, GD (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Shandong, Peoples R China.
EM doctorwgd@gmail.com
RI liu, dong/GRJ-9115-2022; Zhai, Guangtao/X-5949-2019; liu,
   dongsheng/IWM-1597-2023; Liu, DY/JPL-4171-2023
OI Zhai, Guangtao/0000-0001-8165-9322; 
FU Natural Science Foundation of Shandong Province [ZR2019MF050]; Shandong
   Province colleges and universities youth innovation technology plan
   innovation team project [2020KJN011]
FX This work was supported by the Natural Science Foundation of Shandong
   Province (No. ZR2019MF050) and the Shandong Province colleges and
   universities youth innovation technology plan innovation team project
   under Grant (No. 2020KJN011).
CR Aich S., 2019, P IEEE C COMP VIS PA, P73
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Cai WW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3026587
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chen JY, 2016, SEP SCI TECHNOL, V51, P1523, DOI 10.1080/01496395.2016.1156699
   Chen JC, 2016, INT CONF BIOMETR THE
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Denman S, 2007, PATTERN RECOGN LETT, V28, P1232, DOI 10.1016/j.patrec.2007.02.008
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liu L, 2021, IEEE T MULTIMEDIA, V23, P1060, DOI 10.1109/TMM.2020.2992979
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Paszke A, 2019, ADV NEUR IN, V32
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi ML, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON INDUSTRIAL ARTIFICIAL INTELLIGENCE (IAI 2019), DOI 10.1109/iciai.2019.8850794
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang YJ, 2019, MULTIMED TOOLS APPL, V78, P19945, DOI 10.1007/s11042-019-7377-y
   Wang Z, 2018, IEEE WINT CONF APPL, P1888, DOI 10.1109/WACV.2018.00209
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xiong F, 2017, IEEE I CONF COMP VIS, P5161, DOI 10.1109/ICCV.2017.551
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
NR 40
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37939
EP 37952
DI 10.1007/s11042-022-13130-5
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000786824500004
DA 2024-07-18
ER

PT J
AU Chen, Y
   Xia, SX
   Zhao, JQ
   Zhou, Y
   Niu, Q
   Yao, R
   Zhu, DJ
   Chen, H
AF Chen, Ying
   Xia, Shixiong
   Zhao, Jiaqi
   Zhou, Yong
   Niu, Qiang
   Yao, Rui
   Zhu, Dongjun
   Chen, Hao
TI Adversarial learning-based skeleton synthesis with spatial-channel
   attention for robust gait recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Gait recognition; Encoder-decoder
   architecture; Adversarial learning
ID RECOGNIZING GAITS
AB Person re-identification (ReID) aims to identify the same person across multiple cameras. Gait recognition is the person ReID using human gait to identify a walking person, which is an effective identification technology with many advantages, such as remote identification and without invasion. State-of-the-art solutions solve the problem of extensive annotation skeleton information and labeling process by employing encoder-decoders to reconstruct skeleton data, which encodes gait feature with a fixed-length vector limiting the performance of this architecture. In this paper, we propose an end-to-end pipeline dubbed as SCA-GAN, which assembles spatial-channel attention with GAN-like framework to synthesize skeleton sequences reversely without labeled skeleton data. A disadvantage of traditional encoder-decoder architecture is that, because of the fixed-length latent vector encoded from the encoder, the decoder fails to learn the reasonable standard to generate imperfect samples. Therefore, we design a GAN-like framework for discriminative gait feature extraction via adversarial learning. In addition, for learning the rich global information of skeleton data, the information of skeleton is extracted via convolutional block embedding locality-aware attention mechanism. Specifically, a contrastive feature loss is constructed between the gait encoder and the gait decoder to minimize their pixel-wise distance explicitly. The proof-of-principle experiments and ablation study on several benchmarks prove that the proposed method significantly outperforms gait recognition counterparts in precision.
C1 [Chen, Ying; Xia, Shixiong; Zhao, Jiaqi; Zhou, Yong; Niu, Qiang; Yao, Rui; Zhu, Dongjun] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Chen, Ying; Xia, Shixiong; Zhao, Jiaqi; Zhou, Yong; Niu, Qiang; Yao, Rui; Zhu, Dongjun] Minist Educ, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Chen, Hao] Xuzhou Guanglian Technol Co Ltd, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Xia, SX (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Xia, SX (corresponding author), Minist Educ, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
EM shixiongxia.cumt@outlook.com
FU National Natural Science Foundation of China [U1610124, 61806206,
   62172417]; Natural Science Foundation of Jiangsu Province [BK20180639,
   BK20201346]; Six Talent Peaks Project in Jiangsu Province
   [2015-DZXX-010, 2018-XYDXX-044]; Postgraduate Research and Practice
   Innovation Program of Jiangsu Province [KYCX21 2263]
FX This work was supported by the National Natural Science Foundation of
   China (No. U1610124, 61806206, 62172417), and the Natural Science
   Foundation of Jiangsu Province (No. BK20180639, BK20201346), the Six
   Talent Peaks Project in Jiangsu Province (No. 2015-DZXX-010,
   2018-XYDXX-044), the Postgraduate Research and Practice Innovation
   Program of Jiangsu Province (NO. KYCX21 2263).
CR Andersson VO, 2015, AAAI CONF ARTIF INTE, P425
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chao HQ, 2022, IEEE T PATTERN ANAL, V44, P3467, DOI 10.1109/TPAMI.2021.3057879
   Ching-Hang Chen, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5759, DOI 10.1109/CVPR.2017.610
   Feng Y, 2016, INT C PATT RECOG, P325, DOI 10.1109/ICPR.2016.7899654
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He YW, 2019, IEEE T INF FOREN SEC, V14, P102, DOI 10.1109/TIFS.2018.2844819
   Jean F, 2009, IMAGE VISION COMPUT, V27, P1272, DOI 10.1016/j.imavis.2008.11.009
   Jian-De Li, 2017, 2017 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT), DOI 10.1109/DFT.2017.8244448
   Kusakunniran Worapan, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P17, DOI 10.1109/AVSS.2011.6027286
   Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   LI N, 2020, ARXIV 200508625, P1
   Liao R., 2020, 2020 IEEE INT JOINT, P1
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Liu Y., 2019, 2019 16 IEEE INT C A, P1, DOI [DOI 10.1109/AVSS.2019.8909881, 10.1109/AVSS.2019.8909881]
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Martín-Félez R, 2014, PATTERN RECOGN, V47, P3793, DOI 10.1016/j.patcog.2014.06.010
   Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8
   Munaro M, 2014, IEEE INT CONF ROBOT, P5644, DOI 10.1109/ICRA.2014.6907689
   Nambiar A, 2017, IEEE INT CONF AUTOMA, P973, DOI 10.1109/FG.2017.121
   Rao HC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P898
   Rao H, 2022, INNOV-ORGAN MANAG, V24, P315, DOI 10.1080/14479338.2021.1897468
   Rijun Liao, 2017, Biometric Recognition. 12th Chinese Conference, CCBR 2017. Proceedings: LNCS 10568, P474, DOI 10.1007/978-3-319-69923-3_51
   Shiraga K, 2016, INT CONF BIOMETR
   Sun JD, 2018, MULTIMED TOOLS APPL, V77, P24909, DOI 10.1007/s11042-018-5722-1
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Teepe T, 2021, ARXIV 210111228, P1
   Wang YY, 2019, NEUROCOMPUTING, V339, P245, DOI 10.1016/j.neucom.2019.02.025
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2019, MULTIMED TOOLS APPL, V78, P35789, DOI 10.1007/s11042-019-08153-4
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Wu ZF, 2015, IEEE T MULTIMEDIA, V17, P1960, DOI 10.1109/TMM.2015.2477681
   Yu SQ, 2019, PATTERN RECOGN, V87, P179, DOI 10.1016/j.patcog.2018.10.019
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yu SQ, 2017, NEUROCOMPUTING, V239, P81, DOI 10.1016/j.neucom.2017.02.006
   Zhang P, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852401
   Zhang P, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852258
   Zhang YQ, 2020, IEEE T IMAGE PROCESS, V29, P1001, DOI 10.1109/TIP.2019.2926208
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
   Zou GF, 2021, MULTIMED TOOLS APPL, V80, P26855, DOI 10.1007/s11042-021-10953-6
NR 48
TC 2
Z9 2
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 1489
EP 1504
DI 10.1007/s11042-022-12665-x
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000784122500001
DA 2024-07-18
ER

PT J
AU Borade, JL
   Lakshmi, MA
AF Borade, Jay Laxman
   Lakshmi, Muddana A.
TI Multi-class object detection system using hybrid convolutional neural
   network architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Object localization; Deep learning; Object
   recognition; Machine learning
ID SALIENT
AB Object detection in computer vision has been a significant research area for the past decade. Identifying objects with multiple classes from an image has attracted great attention because it can effectively classify and detect the image. A multi-class object detection system from a video or image is quite challenging because of the errors obtained by the location classification process. Our proposed system generalized a hybrid convolutional neural network (H-CNN) model is used to realize the user object from an image. The proposed work integrates pre-processing, object localization, feature extraction and classification. First, the input image is pre-processed with Gaussian filtering to remove noise and improve the image quality. After completing the pre-processing procedure, it is subjected to object localization. Here the object in the image is localized using Grid Guided Localization (GGL). In the feature extraction phase, the model would be pre-trained with AlexNet. Here the AlexNet are generalized as fully connected (FC) layers. Finally, the Softmax layer in the AlexNet architecture is replaced by SVR (Support Vector Regression), which acts as a classifier for identifying the object class. The classification loss is minimized using the Improved Grey Wolf (IGW) optimization algorithm. Thus, the H-CNN model can quickly classify and label the objects from images. It also offers improved classification performance in managing effective training time. The proposed work will be implemented in PYTHON. Therefore, the model would be built using various datasets such as MIT-67, PASCAL VOC2010, MS (Microsoft)-COCO, and MSRC to effectively train and classify the object. The proposed H-CNN achieved improved results with MIT-67 (96.02%), PASCAL VOC2010 (95.04%), MSRC (97.37%), and MS COCO (94.53%). The results obtained by H-CNN proved that the excluded result of Mean Average Precision (mAP), Precision, Accuracy, Recall values and F1-Score achieved better results than with recently developed works such as YOLO-fine, EfficientDet, YOLOv4, RetinaNet, GCNet and HRNet architectures.
C1 [Borade, Jay Laxman] GITAM Deemed Univ, Hyderabad, India.
   [Lakshmi, Muddana A.] GITAM Deemed Univ, CSE Dept, Hyderabad, India.
C3 Gandhi Institute of Technology & Management (GITAM); Gandhi Institute of
   Technology & Management (GITAM)
RP Borade, JL (corresponding author), GITAM Deemed Univ, Hyderabad, India.
EM jaayb84@gmail.com; amuddana@gitam.edu
RI Muddana, Akkalakshmi/GON-4333-2022
OI Muddana, Akkalakshmi/0000-0002-9721-6507; Borade,
   Jay/0000-0002-5719-6361
CR Ahmad Tanvir, 2021, 2021 IEEE 6th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA), P478, DOI 10.1109/ICCCBDA51879.2021.9442506
   Aziz L, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104287
   Bappy JH, 2016, IEEE IMAGE PROC, P3658, DOI 10.1109/ICIP.2016.7533042
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cao DY, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00219-9
   Dai JF, 2016, ADV NEUR IN, V29
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Jalled F, 2016, ARXIV PREPRINT ARXIV
   Kumar Ashwani, 2020, Procedia Computer Science, V171, P2610, DOI 10.1016/j.procs.2020.04.283
   Lei Y, 2020, IEEE IJCNN, P1
   Liao H.-Y, 2020, ARXIV PREPRINT ARXIV
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lingaswamy S, 2020, MULTIMED TOOLS APPL, V79, P8519, DOI 10.1007/s11042-018-5843-6
   Manikandan V. M., 2020, 2020 INT C INN TREND, P1
   Mathivanan G., 2021, P 2021 5 INT C ELECT, P1
   Pham MT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152501
   Ning W, 2020, P IEEE CVF C COMP VI, P11943
   Ojha S, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Pramanik A, 2022, IEEE TETCI, V6, P171, DOI 10.1109/TETCI.2020.3041019
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091470
   Sachdeva S., 2017, 2017 8 INT C COMP CO, P1, DOI DOI 10.1109/ICCCNT.2017.8204182
   Sarikaya D, 2017, IEEE T MED IMAGING, V36, P1542, DOI 10.1109/TMI.2017.2665671
   Sharma P, 2020, J SUPERCOMPUT, V76, P1226, DOI 10.1007/s11227-018-2639-4
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian S., 2021, IEEE T GEOSCI ELECT, V60, P1
   Tomasz M, 2007, IMPROVING SPATIAL SU
   Videira G, 2019, THESIS
   Wang JH, 2020, IEEE T CYBERNETICS, V50, P2971, DOI 10.1109/TCYB.2019.2891265
   Wang Y, EUR C COMP VIS, P18
   Wu ZX, 2021, IJST-T ELECTR ENG, V45, P493, DOI 10.1007/s40998-020-00388-4
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou XY, 2017, 2017 16TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS 2017), P631
NR 38
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31727
EP 31751
DI 10.1007/s11042-022-13007-7
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779973300006
DA 2024-07-18
ER

PT J
AU Liu, Q
   Ji, H
   Liu, G
AF Liu, Qian
   Ji, Hua
   Liu, Gang
TI Generative image inpainting using edge prediction and appearance flow
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Edge prediction; Flow operation; Gaussian sample
AB At present, most of the existing image inpainting methods can not reconstruct the reasonable structure of the image, especially when the important part of the image are missing. Some methods focus on reconstructing a continuous and reasonable structure between the missing area and the undamaged area, but when restoring the image texture, it will generate a fuzzy texture inconsistent with the surrounding area. In order to make the inpainted image have continuous structure and vivid texture, a three-stage model is proposed in this paper: in the first stage, the edge generator is trained by using the edge map of the image to inpaint the input missing edge structure; in the second stage, the predicted edge structure map is used as a guide, and the smooth image is used to train the structure reconstructor to complete the overall structure of the image; in the third stage, based on the reconstructed structure, the texture generator using appearance flow operation is used to generate the texture details of the image. We have conducted experiments on multiple datasets. Compared with the state-of-the-art methods, the repaired images using our method have more reasonable structure and vivid texture,and our method has better performance.
C1 [Liu, Qian; Ji, Hua] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.
   [Liu, Gang] Shandong Jianzhu Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Jianzhu University
RP Ji, H (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Shandong, Peoples R China.
EM 1091214733@qq.com; jihua@sdnu.edu.cn
CR Abdulla AA, 2021, MULTIMED TOOLS APPL, V80, P13143, DOI 10.1007/s11042-020-10414-6
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carrillo JA, 2020, ENHANCEMENT DAMAGED
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chao YW, 2017, PROC CVPR IEEE, P3643, DOI 10.1109/CVPR.2017.388
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3081421
   Ciortan IM, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062091
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hedjazi MA, 2021, KNOWL-BASED SYST, V217, DOI 10.1016/j.knosys.2021.106789
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu J, 2021, NEUROCOMPUTING, V437
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Odena A, 2018, PR MACH LEARN RES, V80
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1007/978-3-030-01216-8_1, 10.1109/APCAP.2017.8420330]
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Wang Y, 2018, ADV NEUR IN, V31
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang YZ, 2022, VISUAL COMPUT, V38, P2647, DOI 10.1007/s00371-021-02143-0
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang H., 2018, ARXIV180508318
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 42
TC 0
Z9 0
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31709
EP 31725
DI 10.1007/s11042-022-12486-y
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781124000023
DA 2024-07-18
ER

PT J
AU Jayasudha, JC
   Lalithakumari, S
AF Jayasudha, J. C.
   Lalithakumari, S.
TI Weld defect segmentation and feature extraction from the acquired phased
   array scan images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Omni scan MX2 instrument; Weld pad; Adaptive anisotropic diffusion
   filter; Adaptive mean adjustment; Gradient cluster fuzzy C means; Gray
   level co-occurrence matrix
AB In the recent past, Non-Destructive Testing (NDT) methods play a significant role in welding defect detection. Phased array ultrasonic testing is the advanced NDT testing method that is used for accessing the weld integrity. But qualified personnel are required for measuring the geometrical features of the defects in welds. A full-fledged computer-based measuring system is very much required IN ORDER To avoid Manual interpretation, since, it always leads to some errors in inferring the Phased Array (PA) signals and images. This work proposes an artificial intelligence- based measuring approach to enhance the features of the image. The 2D Adaptive Anisotropic Diffusion Filter (2D AADF) is used to remove noise and also scattered pixels are corrected by applying a hexagonal sampled grid. The adaptive mean adjustment (AMA) algorithm would be used for enhancing features of the image in terms of contrast and brightness. The hybrid clustering segmentation incorporates non overlapping K means improved Fuzzy C Means (FCM) pixels clustering. The automatic seed point is selected by K means clustering, and high-intensity gradient is estimated by applying Gradient Cluster Fuzzy C Means (GCFCM) segmentation method. After segmenting the Region of Interest (ROI), the features are estimated due to Gray Level Co-Occurrence Matrix (GLCM). The computed segmented image features are further given to deep learning to classify different stages of welding defect. The investigational results are proven that the proposed algorithm would be high professional and accurate. The above technique is also implemented on the images acquired from the Omniscan MX2 instrument with a suitable linear array probe with 64 transducer elements in it. The proposed work aims to propose an automatic measurement technique for identifying the defect and characterizing it.
C1 [Jayasudha, J. C.; Lalithakumari, S.] Sathyabama Inst Sci & Technol, Fac Elect, Chennai, Tamil Nadu, India.
   [Jayasudha, J. C.; Lalithakumari, S.] Sathyabama Inst Sci & Technol, Dept EIE, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; Sathyabama Institute of
   Science & Technology
RP Jayasudha, JC (corresponding author), Sathyabama Inst Sci & Technol, Fac Elect, Chennai, Tamil Nadu, India.; Jayasudha, JC (corresponding author), Sathyabama Inst Sci & Technol, Dept EIE, Chennai, Tamil Nadu, India.
EM Sudhafrance2@gmail.com
RI F.V., Jayasudha/ABC-3642-2020; s, lalithakumari/A-4936-2017
OI F.V., Jayasudha/0000-0003-2103-0893; s,
   lalithakumari/0000-0003-1447-4736
CR Almahfud Mustofa Alisahid, 2018, 2018 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P11, DOI 10.1109/ISRITI.2018.8864326
   Barbu T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON THE SCIENCE OF ELECTRICAL ENGINEERING IN ISRAEL (ICSEE)
   Bean E, 2008, IEEE INSTRU MEAS MAG, V11, P16, DOI 10.1109/MIM.2008.4579267
   Dang CY, 2015, IET IMAGE PROCESS, V9, P943, DOI 10.1049/iet-ipr.2014.0716
   Dong XH, 2018, INT C PATT RECOG, P2002, DOI 10.1109/ICPR.2018.8545738
   Foudazi A, 2015, IEEE T INSTRUM MEAS, V64, P2583, DOI 10.1109/TIM.2015.2450353
   Liu JH, 2018, IEEE T INSTRUM MEAS, V67, P12, DOI 10.1109/TIM.2017.2755918
   Liu K, 2020, IEEE T INSTRUM MEAS, V69, P4732, DOI 10.1109/TIM.2019.2952706
   Liu K, 2017, IEEE T INSTRUM MEAS, V66, P2585, DOI 10.1109/TIM.2017.2712838
   Liu ZP, 2017, IEEE INSTRU MEAS MAG, V20, P34, DOI 10.1109/MIM.2017.8006392
   Thien ND, 2017, INT CONF SYST SCI EN, P371, DOI 10.1109/ICSSE.2017.8030899
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qi A, 2016, WELDING DEFECT SIGNA
   Su BY, 2019, IEEE T INSTRUM MEAS, V68, P4675, DOI 10.1109/TIM.2019.2900961
   Sun J, 2018, EFFECTIVE METHOD WEL
   Wu, 2018, DC BIASED MAGNETIZAT
   Wu Y, 2018, WELD CRACK DETECTION
   Yaohua Shen, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P329, DOI 10.1109/ICMA.2018.8484533
   Zhan X, 2009, SIGNAL ANAL METHOD A
   Zhang HD, 2019, IEEE INT CON AUTO SC, P1574, DOI [10.1109/coase.2019.8842998, 10.1109/COASE.2019.8842998]
   Zhang L, 2019, IET IMAGE PROCESS, V13, P2647, DOI 10.1049/iet-ipr.2018.5840
NR 21
TC 3
Z9 3
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31061
EP 31074
DI 10.1007/s11042-022-13030-8
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500006
DA 2024-07-18
ER

PT J
AU Kapoor, S
   Kumar, T
AF Kapoor, Shalini
   Kumar, Tarun
TI Fusing traditionally extracted features with deep learned features from
   the speech spectrogram for anger and stress detection using convolution
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Convolutional neural networks; Deep
   learning; Emotion change detection; Spectrograms
ID EMOTION RECOGNITION
AB Stress and anger are two negative emotions that affect individuals both mentally and physically; there is a need to tackle them as soon as possible. Automated systems are highly required to monitor mental states and to detect early signs of emotional health issues. In the present work convolutional neural network is proposed for anger and stress detection using handcrafted features and deep learned features from the spectrogram. The objective of using a combined feature set is gathering information from two different representations of speech signals to obtain more prominent features and to boost the accuracy of recognition. The proposed method of emotion assessment is more computationally efficient than similar approaches used for emotion assessment. The preliminary results obtained on experimental evaluation of the proposed approach on three datasets Toronto Emotional Speech Set (TESS), Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), and Berlin Emotional Database (EMO-DB) indicate that categorical accuracy is boosted and cross-entropy loss is reduced to a considerable extent. The proposed convolutional neural network (CNN) obtains training (T) and validation (V) categorical accuracy of T = 93.7%, V = 95.6% for TESS, T = 97.5%, V = 95.6% for EMO-DB and T = 96.7%, V = 96.7% for RAVDESS dataset.
C1 [Kapoor, Shalini] Dr APJ Abdul Kalam Tech Univ, Res Scholar, Lucknow, Uttar Pradesh, India.
   [Kumar, Tarun] Radha Govind Grp Inst, Dept Comp Sci & Engn, Meerut, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU)
RP Kapoor, S (corresponding author), Dr APJ Abdul Kalam Tech Univ, Res Scholar, Lucknow, Uttar Pradesh, India.
EM shalini_kapoor311@rediffmail.com
RI Kumar, Tarun/T-8152-2018
OI Kumar, Tarun/0000-0001-6011-8498; Kumar, Tarun/0000-0001-5033-5544
CR [Anonymous], 1997, The handbook of phonetic sciences
   Anvarjon T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185212
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Dupuis Kate, 2010, Toronto emotional speech set (tess)-younger talkerhappy
   Fink G., 2016, STRESS CONCEPTS COGN, P3, DOI [DOI 10.1016/B978-0-12-800951-2.00001-7, DOI 10.1016/B978-0-12-800951-2.00001-3]
   Govoreanu VC, 2020, INT C INTELL COMP CO, P69, DOI [10.1109/iccp51029.2020.9266265, 10.1109/ICCP51029.2020.9266265]
   Guo LL, 2018, INTERSPEECH, P1611, DOI 10.21437/Interspeech.2018-2156
   Hajarolasvadi N, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050479
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Jiang L, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5427
   Juslin PatrikN., 2008, SCHOLARPEDIA, V3, P4240, DOI DOI 10.4249/SCHOLARPEDIA.4240
   Kadiri SR, 2020, INT CONF ACOUST SPEE, P7379, DOI [10.1109/ICASSP40776.2020.9054737, 10.1109/icassp40776.2020.9054737]
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Low DM, 2020, LARYNGOSCOPE INVEST, V5, P96, DOI 10.1002/lio2.354
   Lu Guanming, 2018, Journal of Nanjing University of Posts and Telecommunications (Natural Science Edition), V38, P63, DOI 10.14132/j.cnki.1673-5439.2018.05.009
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mustaqeem, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114177
   Mustaqeem, 2020, IEEE ACCESS, V8, P79861, DOI 10.1109/ACCESS.2020.2990405
   Nayak J, 2021, APPL INTELL, V51, P2908, DOI 10.1007/s10489-020-02102-7
   Schuller BW, 2018, COMMUN ACM, V61, P90, DOI 10.1145/3129340
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tavi L, 2019, INT J SPEECH TECHNOL, V22, P511, DOI 10.1007/s10772-018-09574-6
   Yao ZW, 2020, SPEECH COMMUN, V120, P11, DOI 10.1016/j.specom.2020.03.005
   Zhang LJ, 2018, LECT NOTES COMPUT SC, V11304, P62, DOI 10.1007/978-3-030-04212-7_6
   Zhang LJ, 2018, LECT NOTES COMPUT SC, V11139, P782, DOI 10.1007/978-3-030-01418-6_76
   Zhang SQ, 2021, SPEECH COMMUN, V127, P73, DOI 10.1016/j.specom.2020.12.009
NR 30
TC 0
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31107
EP 31128
DI 10.1007/s11042-022-12886-0
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500008
PM 35431609
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kuçukbay, SE
   Yazici, A
   Kalkan, S
AF Kucukbay, Selver Ezgi
   Yazici, Adnan
   Kalkan, Sinan
TI Hand-crafted versus learned representations for audio event detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio event detection; Audio event classification; Deep learning; Log
   mel spectogram; Mel spectrogram; Spectrogram; MFCC
ID NEURAL-NETWORKS; CLASSIFICATION; SCALE
AB Audio Event Detection (AED) pertains to identifying the types of events in audio signals. AED is essential for applications requiring decisions based on audio signals, which can be critical, for example, for health, surveillance and security applications. Despite the proven benefits of deep learning in obtaining the best representation for solving a problem, AED studies still generally employ hand-crafted representations even when deep learning is used for solving the AED task. Intrigued by this, we investigate whether or not hand-crafted representations (i.e. spectogram, mel spectogram, log mel spectogram and mel frequency cepstral coefficients) are better than a representation learned using a Convolutional Autoencoder (CAE). To the best of our knowledge, our study is the first to ask this question and thoroughly compare feature representations for AED. To this end, we first find the best hop size and window size for each hand-crafted representation and compare the optimized hand-crafted representations with CAE-learned representations. Our extensive analyses on a subset of the AudioSet dataset confirm the common practice in that hand-crafted representations do perform better than learned features by a large margin (similar to 30 AP). Moreover, we show that the commonly used window and hop sizes do not provide the optimal performances for the hand-crafted representations.
C1 [Kucukbay, Selver Ezgi; Yazici, Adnan; Kalkan, Sinan] Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
   [Yazici, Adnan] Nazarbayev Univ, Dept Comp Sci, SEDS, Nur Sultan, Kazakhstan.
C3 Middle East Technical University; Nazarbayev University
RP Kuçukbay, SE (corresponding author), Middle East Tech Univ, Dept Comp Engn, Ankara, Turkey.
EM ezgi.kucukbay@metu.edu.tr; yazici@metu.edu.tr; skalkan@metu.edu.tr
RI KALKAN, Sinan/AAC-3625-2019
OI Kalkan, Sinan/0000-0003-0915-5917; YAZICI, Adnan/0000-0001-9404-9494
FU BAGEP Award of the Science Academy, Turkey
FX We would like to thank Turk Telekom Research Center for providing
   hardware components for the experiments. Dr. Kalkan is supported by the
   BAGEP Award of the Science Academy, Turkey.
CR Aytar Y, 2016, ADV NEUR IN, V29
   Becker Soren, 2018, ABS180703418 ARXIV
   Çakir E, 2018, IEEE IJCNN
   Çakir E, 2017, IEEE-ACM T AUDIO SPE, V25, P1291, DOI 10.1109/TASLP.2017.2690575
   Dai W, 2017, INT CONF ACOUST SPEE, P421, DOI 10.1109/ICASSP.2017.7952190
   Dinkel H, 2018, HYBRID ASR MODEL APP
   Eutizi C, 2021, 2021 44TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P141, DOI 10.1109/TSP52935.2021.9522625
   Fonseca E, 2020, UNSUPERVISED CONTRAS
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Giannakopoulos T, 2019, IFIP ADV INF COMM TE, V560, P184, DOI 10.1007/978-3-030-19909-8_16
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Kayser M, 2015, CS231
   Kong QQ, 2020, IEEE-ACM T AUDIO SPE, V28, P2880, DOI 10.1109/TASLP.2020.3030497
   Kothinti S, 2019, INTEGRATED BOTTOM UP
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwak JY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10144911
   Lee J., 2017, 31 C NEUR INF PROC S
   Lefèvre S, 2011, DIGIT SIGNAL PROCESS, V21, P270, DOI 10.1016/j.dsp.2010.07.003
   Li J., 2017, A COMPARISON OF DEEP LEARNING METHODS FOR ENVIRONMENTAL SOUND
   Liu HW, 2012, J SYST SOFTWARE, V85, P1067, DOI 10.1016/j.jss.2011.12.019
   Maas AL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P22
   Maria A, 2021, J CONTROL AUTOM ELEC, V32, P853, DOI 10.1007/s40313-021-00727-8
   Mesaros A, 2021, IEEE SIGNAL PROC MAG, V38, P67, DOI 10.1109/MSP.2021.3090678
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Ntalampiras Stavros, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1121
   Ntalampiras S, 2009, INT CONF ACOUST SPEE, P165, DOI 10.1109/ICASSP.2009.4959546
   Piczak K J, 2016, RECOGNIZING BIRD SPE
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Raj B., 2018, ARXIV180409288
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saeed A, 2020, CONTRASTIVE LEARNING
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Stowell D, 2015, IEEE T MULTIMEDIA, V17, P1733, DOI 10.1109/TMM.2015.2428998
   Sun YW, 2020, INT CONF ACOUST SPEE, P321, DOI [10.1109/icassp40776.2020.9053389, 10.1109/ICASSP40776.2020.9053389]
   Turpault Nicolas, 2020, PROC DCASE2020 WORKS
   Vasilakis M, 2009, BIOMED SIGNAL PROCES, V4, P183, DOI 10.1016/j.bspc.2009.02.001
   Wang Z, 2021, ARXIV210507596
   Xu Y, 2016, ARXIV160703681
   Zang Z, 2019, IMPROVED SYSTEM DECA
   Zhuang XD, 2008, INT CONF ACOUST SPEE, P17
NR 41
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30911
EP 30930
DI 10.1007/s11042-022-12873-5
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779229700008
DA 2024-07-18
ER

PT J
AU Srinivasarao, V
AF Srinivasarao, V.
TI An efficient recurrent Rats function network (Rrfn) based speech
   enhancement through noise reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech enhancement; Speech quality; Recurrent RATS function network
   (RRFN); Recurrent function network (RFN) and elliptic filter
ID QUALITY; ALGORITHM; RECOGNITION; PESQ
AB In modern communication system, speech communication is almost utilized in vast range of applications. Usually, during transmission of speech signal, environment interference causes degradation of signal. Few speech interference which affects quality of speech signal are acoustic noise, acoustic reverberation or white noise. In this research work, it is aimed to estimate the noise in the speech signal using Recurrent Function Network (RFN). The proposed technique is termed as Recurrent RATS Function Network (RRFN). The proposed network estimates the different noise exists in the input noisy speech signal. Once the noises are identified in speech signal, features are estimated using novel radial based RATS (Robust Automatic Transcription of Speech) approach. Further to enhance the clarity of speech signal, a novel generalized recursive singular value technique integrated in elliptic filter is used to effectively remove noises in the speech signal. Simulation analysis is performed for proposed RFN and compared with existing techniques in terms of PESQ and STOI. The proposed method exhibits good performance improvement over the existing techniques for different SNR levels.
C1 [Srinivasarao, V.] Natl Inst Technol, ECE Dept, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Srinivasarao, V (corresponding author), Natl Inst Technol, ECE Dept, Kurukshetra, Haryana, India.
EM sraoyaar@yahoo.co.in
CR Achanta S, 2017, SPEECH COMMUN, V93, P31, DOI 10.1016/j.specom.2017.08.003
   Chaudhari A, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Daneshfar F, 2020, APPL ACOUST, V166, DOI 10.1016/j.apacoust.2020.107360
   Djendi M, 2016, COMPUT ELECTR ENG, V52, P12, DOI 10.1016/j.compeleceng.2016.04.006
   Djendi M, 2016, APPL SOFT COMPUT, V42, P132, DOI 10.1016/j.asoc.2016.01.049
   Drioli C., 2001, EURASIP Journal on Applied Signal Processing, V2001, P36, DOI 10.1155/S1110865701000117
   EV, 2017, AUDIO ENG SOC CONVEN
   Hansen PC, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/92953
   Henni R, 2019, COMPUT ELECTR ENG, V73, P349, DOI 10.1016/j.compeleceng.2018.12.009
   Juang CF, 2009, EXPERT SYST APPL, V36, P321, DOI 10.1016/j.eswa.2007.10.028
   Kadiri SR, 2020, COMPUT SPEECH LANG, V64, DOI 10.1016/j.csl.2020.101097
   Kadiri SR, 2020, SPEECH COMMUN, V116, P30, DOI 10.1016/j.specom.2019.11.004
   Kasthuri, 2012, INT J COMPUT APPL, V975
   Kohli Rashi, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P55, DOI 10.1007/978-981-13-5934-7_6
   Kulkarni D.S., 2016, INT J COMPUT APPL, V139
   Lakshmikanth S., 2014, INT J ADV RES COMPUT, V3, P5175
   Lezzoum N, 2016, APPL ACOUST, V109, P37, DOI 10.1016/j.apacoust.2016.03.001
   Li AD, 2020, APPL ACOUST, V166, DOI 10.1016/j.apacoust.2020.107347
   Mehrkian S, 2019, INT J PEDIATR OTORHI, V125, P192, DOI 10.1016/j.ijporl.2019.07.007
   Ng T, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P1967
   Peng JX, 2019, APPL ACOUST, V153, P48, DOI 10.1016/j.apacoust.2019.04.013
   Podder P., 2020, ARXIV PREPRINT ARXIV
   Rajini GK, 2019, INT J INNOV TECHNOL, V8
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Shrawankar U, 2010, IFIP ADV INF COMM TE, V340, P336, DOI 10.1007/978-3-642-16327-2_40
   Sudro, 2020, SPEECH COMMUN
   Sun Z, 2020, IEEE T BIOMED CIRC S
   Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701
   Taha T.M., 2018, Int. J. Comput. Appl, V179, P1
   Tan ZH, 2020, COMPUT SPEECH LANG, V59, P1, DOI 10.1016/j.csl.2019.06.005
   Tu JX, 2017, NEUROCOMPUTING, V267, P333, DOI 10.1016/j.neucom.2017.06.018
   Vanus J, 2018, IFAC PAPERSONLINE, V51, P202, DOI 10.1016/j.ifacol.2018.07.154
   Wang WJ, 2019, FUTURE GENER COMP SY, V98, P227, DOI 10.1016/j.future.2018.12.060
   Yang, 2013, 3 RD INT C MULT TECH
   Yong PC, 2011, EUR SIGNAL PR CONF, P211
NR 35
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30599
EP 30614
DI 10.1007/s11042-022-12473-3
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779233200007
DA 2024-07-18
ER

PT J
AU Karthiga, R
   Narasimhan, K
AF Karthiga, R.
   Narasimhan, K.
TI Automated diagnosis of breast cancer from ultrasound images using
   diverse ML techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Deep learning; Transfer learning; Machine learning;
   Convolutional neural network
ID CLASSIFICATION; LESIONS; BENIGN
AB An accurate diagnosis of breast cancer requires analyzing the tumors and giving appropriate treatment. A cancer diagnosis should be carried out as early as possible to minimize mortality rates. The handcrafted features are utilized for traditional breast cancer diagnosis, and the system's performance is based on selected features. However, it is a challenging task to analyze shape complexity and different sizes. In recent years, deep learning has become a viable alternative to overcome the drawbacks of conventional cancer diagnosis methods. In this work, machine learning (ML) classifier, deep convolutional neural network (CNN) and transfer learning models (Alexnet, VGG-16, VGG-19, Resnet-50, and Resnet-101) are used to analyse the performance of the classifier. To process data before machine learning classification, an anisotropic diffusion filter is used to extract the tumor. The significant ten features were selected based on statistical testing and achieved an accuracy of 99% in the KNN classifier. The proposed deep CNN achieves a most satisfactory accuracy of 100%. The results outperform current techniques and demonstrate the ability of breast cancer classification. Also, the fast evaluation speed makes the analysis possible in real-time. The accuracy results of Alexnet, VGG-16, VGG-19, Resnet-50, and Resnet-101 are 86%, 82%, 84%, 84% and 74% respectively. Due to the small size of the data, the transfer learning model produces insignificant results, whereas the transfer learning models require a specific data size. The CNN can classify breast ultrasound images of cancer with promising results with relatively few training cases and is suitable for biomedical applications.
C1 [Karthiga, R.; Narasimhan, K.] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Narasimhan, K (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM knr@ece.sastra.edu
RI R, KARTHIGA/ITU-4122-2023
OI Kumaravelu, Dr. Narasimhan/0000-0001-6929-6039
CR Agarwal V, 2006, J PATTERN RECOGNIT R, V1, P42, DOI 10.13176/11.9
   Akin O, 2012, CA-CANCER J CLIN, V62, P364, DOI 10.3322/caac.21156
   Ara SR, 2015, ULTRASOUND MED BIOL, V41, P2022, DOI 10.1016/j.ultrasmedbio.2015.01.023
   Azar AT, 2013, NEURAL COMPUT APPL, V23, P2387, DOI 10.1007/s00521-012-1196-7
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Barbu T, 2021, P ROMANIAN ACAD A, V22, P267
   Becker AS, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170576
   Bedi AK, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1119, DOI 10.1109/CCAA.2017.8229964
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Byra M, 2018, BIOCYBERN BIOMED ENG, V38, P684, DOI 10.1016/j.bbe.2018.05.003
   Byra M, 2016, MED PHYS, V43, P5561, DOI 10.1118/1.4962928
   Byra M, 2019, MED PHYS, V46, P746, DOI 10.1002/mp.13361
   CHENG H, 2021, PATTERN RECOGNIT, V43
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Chiang TC, 2019, IEEE T MED IMAGING, V38, P240, DOI 10.1109/TMI.2018.2860257
   Choi JS, 2019, KOREAN J RADIOL, V20, P749, DOI 10.3348/kjr.2018.0530
   Ciritsis A, 2019, EUR RADIOL, V29, P5458, DOI 10.1007/s00330-019-06118-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Geras KJ., 2017, High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gokhale Sudheer, 2009, Indian J Radiol Imaging, V19, P242, DOI 10.4103/0971-3026.54878
   Guan FD, 2014, SCI CHINA TECHNOL SC, V57, P607, DOI 10.1007/s11431-014-5483-7
   Gupta K, 2020, PROCEDIA COMPUT SCI, V167, P878, DOI 10.1016/j.procs.2020.03.427
   Han S, 2017, PHYS MED BIOL, V62, P7714, DOI 10.1088/1361-6560/aa82ec
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hijab A, 2019, I CON ADV BIOMED ENG, P64, DOI 10.1109/icabme47164.2019.8940291
   Howlader N. A., 2017, SEER CANC STAT REV 1
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Kohli M, 2017, AM J ROENTGENOL, V208, P754, DOI 10.2214/AJR.16.17224
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Moon WK, 2017, ULTRASONICS, V76, P70, DOI 10.1016/j.ultras.2016.12.017
   Moura DC, 2013, INT J COMPUT ASS RAD, V8, P561, DOI 10.1007/s11548-013-0838-2
   Narayanan S., 2009, International Journal of Signal Processing, Image Processing and Pattern Recognition, V2, P85
   Ong MS, 2015, HEALTH AFFAIR, V34, P576, DOI 10.1377/hlthaff.2014.1087
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rajaguru Harikumar, 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P266, DOI 10.1109/CESYS.2017.8321279
   Ren HY, 2015, IEEE I CONF COMP VIS, P46, DOI 10.1109/ICCV.2015.14
   Rodrigues P. S., 2017, Mendeley Data, V1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghi-Naini A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13977-x
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   STAVROS AT, 1995, RADIOLOGY, V196, P123, DOI 10.1148/radiology.196.1.7784555
   Tan T, 2012, IEEE T MED IMAGING, V31, P1034, DOI 10.1109/TMI.2012.2184549
   Torheim T, 2014, IEEE T MED IMAGING, V33, P1648, DOI 10.1109/TMI.2014.2321024
   Xi JN, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3756, DOI 10.1145/3447548.3467106
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Yap MH, 2010, EUR J RADIOL, V73, P682, DOI 10.1016/j.ejrad.2008.11.007
   Zeebaree DQ, 2021, CMC-COMPUT MATER CON, V66, P3363, DOI 10.32604/cmc.2021.013314
NR 55
TC 4
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30169
EP 30193
DI 10.1007/s11042-022-12933-w
EA APR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000778057600001
DA 2024-07-18
ER

PT J
AU Pour, NR
   Yaghoobi, M
AF Pour, Nafise Ramezani
   Yaghoobi, Mahdi
TI A new method in encryption of gray scale images using chaos game
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos game representation; S-box; Hilbert fractal; DNA sequence
ID SECURE
AB In recent years, digital images have gained special significances due to increasing growth of mass media systems. Security of confidential information against unauthorized access during transmission is a serious issue for users of such media and the required level of security must be provided according to different applications. This paper uses chaos game for encryption. The proposed algorithm converts image pixels into binary digits, and produces a binary string with combining them. Taking each pair of bits as one letter of DNA sequence, you can produce an artificial DNA string and draw a Chaos Game Representation (CGR) image. The process also uses a static S-box technique for the substitution process through a Hilbert fractal. The advantage of this method is that it provides a large key space(2(418)), which is a significant amount to prevent various attacks. Besides that, in Lena, Baboon, Pepper images, the acquired average amount for entropy is 7.9988, NPCR is 99.625, UACI is 35.597.The use of one-dimensional chaos function, and static s-box makes the model more complicated. But it has been proved that the proposed method is capable of providing a high level of security.
C1 [Pour, Nafise Ramezani; Yaghoobi, Mahdi] Islamic Azad Univ, Comp Engn Dept, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
C3 Islamic Azad University
RP Pour, NR (corresponding author), Islamic Azad Univ, Comp Engn Dept, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
EM nafiseramezanipoor@yahoo.com; yaghoobi@mshdiau.ac.ir
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Almeida JS, 2001, BIOINFORMATICS, V17, P429, DOI 10.1093/bioinformatics/17.5.429
   [Anonymous], 2008, INT J ENG-IRAN
   [Anonymous], 2010, INFOCOM 2010 P IEEE
   Arun KS., 2013, INT J COMPUT BIOL IJ, V2, P1, DOI [10.34040/IJCB.2.1.2013.11, DOI 10.34040/IJCB.2.1.2013.11]
   Asgari-Chenaghlu M, 2019, SIGNAL PROCESS, V157, P1, DOI 10.1016/j.sigpro.2018.11.010
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Cheng GF, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419501153
   Girdhar A, 2021, APPL PHYS B-LASERS O, V127, DOI 10.1007/s00340-021-07585-x
   Hsiao HI, 2015, SIGNAL PROCESS, V113, P169, DOI 10.1016/j.sigpro.2015.01.024
   Hussain I, 2018, CHINESE J PHYS, V56, P1609, DOI 10.1016/j.cjph.2018.04.013
   Hussain I, 2012, NONLINEAR DYNAM, V70, P181, DOI 10.1007/s11071-012-0440-0
   JEFFREY HJ, 1990, NUCLEIC ACIDS RES, V18, P2163, DOI 10.1093/nar/18.8.2163
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0016-5
   Khan M, 2012, NONLINEAR DYNAM, V70, P2303, DOI 10.1007/s11071-012-0621-x
   Kumar GS, 2009, VIRTUAL PHYS PROTOTY, V4, P91, DOI 10.1080/17452750802688215
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Peitgen H.-O., 2006, Chaos and Fractals: New Frontiers of Science, DOI DOI 10.1007/B97624
   Poor NR, 2019, EXPERT SYST APPL, V116, P487, DOI 10.1016/j.eswa.2018.09.012
   Shaji V., 2015, INT J ENG RES GEN SC, V3, P580
   Sulistyo B, 2009, 2009 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS, VOLS 1 AND 2, P247
   Tavazoei MS, 2007, APPL MATH COMPUT, V187, P1076, DOI 10.1016/j.amc.2006.09.087
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang SC, 2020, OPT LASER ENG, V128, DOI 10.1016/j.optlaseng.2019.105995
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Yang FF, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107373
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhou SH, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P335, DOI 10.1109/CISP.2014.7003802
NR 35
TC 7
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29653
EP 29672
DI 10.1007/s11042-022-12779-2
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777642100002
DA 2024-07-18
ER

PT J
AU Abeje, BT
   Salau, AO
   Mengistu, AD
   Tamiru, NK
AF Abeje, Bekalu Tadele
   Salau, Ayodeji Olalekan
   Mengistu, Abreham Debasu
   Tamiru, Nigus Kefyalew
TI Ethiopian sign language recognition using deep convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ethiopian sign language; Deep convolutional neural network; Amharic
   alphabet
AB In recent years, several technologies have been utilized to bridge the communication gap between persons who have hearing or speaking impairments and those who don't. This paper presents the development of a novel sign language recognition system which translates Ethiopian sign language (ETHSL) to Amharic alphabets using computer vision technology and Deep Convolutional Neural Network (CNN). The system accepts sign language images as input and gives Amharic text as the desired output. The proposed system comprises of three main stages which are: preprocessing, feature extraction, and recognition. The methodology employed involves data acquisition, preprocessing the acquired data, background normalization, image resizing, region of interest (ROI) identification, noise removal, brightness adjustment, and feature extraction, while Deep Convolutional Neural Network (CNN) was used for end-to-end classification. The data used in this study was acquired from students with hearing impairments at the Debre Markos Teaching College with an iPhone 6s phone which has a resolution of 3024 x 4020. The images are in JPEG file format and were collected in a controlled environment. The proposed system was implemented using Kera's (Tensorflow2.3.0 as backend) in python and tested using the image dataset collected from Debre Markos Teaching College graduating students of 2012. The results show that the running time was minimized by adjusting the images to a suitable size and color. In addition, the results show an improved recognition accuracy compared to previous works. The proposed model achieves 98.5% training, 95.59% validation, and 98.3% testing accuracy of recognition.
C1 [Abeje, Bekalu Tadele] Haramaya Univ, Dept Informat Technol, Coll Comp & Informat, Dire Dawa, Ethiopia.
   [Salau, Ayodeji Olalekan] Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.
   [Salau, Ayodeji Olalekan] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
   [Mengistu, Abreham Debasu] Bahir Dar Univ, Inst Technol, Dept Comp Sci, Bahir Dar, Ethiopia.
   [Tamiru, Nigus Kefyalew] Debre Markos Univ, Inst Technol, Sch Elect & Comp Engn, Debre Markos, Ethiopia.
C3 Haramaya University; Saveetha Institute of Medical & Technical Science;
   Saveetha School of Engineering; Bahir Dar University
RP Salau, AO (corresponding author), Afe Babalola Univ, Dept Elect Elect & Comp Engn, Ado Ekiti, Nigeria.; Salau, AO (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Chennai, Tamil Nadu, India.
EM bekalutadele@gmail.com; ayodejisalau98@gmail.com; abitiy@gmail.com;
   kefyalewnigus@gmail.com
RI salau, ayodeji Olalekan/C-1016-2018; Abeje, Bekalu Tadele/AGN-7021-2022
OI salau, ayodeji Olalekan/0000-0002-6264-9783; Abeje, Bekalu
   Tadele/0000-0002-5494-2277
CR Admasu Y. F., 2010, Proceedings 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), P995, DOI 10.1109/ISDA.2010.5687057
   Bantupalli K, 2018, IEEE INT CONF BIG DA, P4896, DOI 10.1109/BigData.2018.8622141
   Gimibi, 2014, RECOGNITION ISOLATED, P174
   Patel, 2018, INT J INNOV RES COMP, P9101, DOI [10.15680/IJIRCCE.2018, DOI 10.15680/IJIRCCE.2018]
   Rao GA, 2018, 2018 CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P194, DOI 10.1109/SPACES.2018.8316344
   Ravikiran J., 2010, Lecture Notes in Electrical Engineering, V52, P321, DOI [10.1007/978-90-481-3517-2-25, DOI 10.1007/978-90-481-3517-2-25]
   Rivera-Acosta M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102176
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Singha J., 2013, International Journal of Computer Applications, V70, P17, DOI [DOI 10.5120/12174-7306, 10.5120/12174-7306]
   Tamiru NK, 2022, VISUAL COMPUT, V38, P1703, DOI 10.1007/s00371-021-02099-1
   Tamiru NK, 2018, AMHARIC SIGN LANGUAG, P201
   Taskiran M, 2018, 2018 41ST INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P258, DOI 10.1109/TSP.2018.8441304
   Tesfaye, 2010, MACH TRANSL, P252
   Truong VNT, 2016, 2016 IEEE 5TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS
   Wadhawan A, 2020, NEURAL COMPUT APPL, V32, P7957, DOI 10.1007/s00521-019-04691-y
   Zerubabel, 2008, ETHIOPIAN FINGER SPE, P203
NR 16
TC 8
Z9 8
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29027
EP 29043
DI 10.1007/s11042-022-12768-5
EA APR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375700001
DA 2024-07-18
ER

PT J
AU Anandhalli, M
   Tanuja, A
   Baligar, VP
   Baligar, P
AF Anandhalli, Mallikarjun
   Tanuja, A.
   Baligar, Vishwanath P.
   Baligar, Pavana
TI Corner based statistical modelling in vehicle detection under various
   condition for traffic surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Corner points; Clustering; Vehicle detection; Tracking
AB The paper proposes a robust approach to detect and track the vehicle under various climatic conditions and in the presence of camera shake, shadows, sudden illumination change. Corners have significant features to detect and track the vehicle. Corner points from the vehicular region are segmented from non - vehicular regions based on the statistical background corner point model. The foreground corner points that belong to the vehicular region are grouped using Euclidean distance as they are closely associated with each other. The flickering effects caused by the corner detection algorithm are handled by tracking these corner points. The detection accuracy of the algorithm is 94.32%.
C1 [Anandhalli, Mallikarjun; Tanuja, A.] KLS Gogte Inst Technol, Dept Elect & Commun Engn, Belagavi, India.
   [Baligar, Vishwanath P.] KLE Technol Univ, Dept Comp Sci & Engn, Hubballi, India.
   [Baligar, Pavana] Smt Kamala Sri Venkappa M Agadi Coll Engn & Techn, Dept Informat Sci & Engn, Laxmeshwar, India.
C3 KLE Technological University
RP Anandhalli, M (corresponding author), KLS Gogte Inst Technol, Dept Elect & Commun Engn, Belagavi, India.
EM malliarjun71@gmail.com; a.tanuja3@gmail.com
RI Anandhalli, Mallikarjun/AAF-5880-2020
OI Anandhalli, Mallikarjun/0000-0002-0048-3925
FU Science Engineering Research Board, under startup Research Grant Program
   in Engineering Science [SERB/SRG/2019/002277]
FX The Research is supported by Science Engineering Research Board, under
   startup Research Grant Program in Engineering Science with File NO. :
   SERB/SRG/2019/002277 and is gratefully acknowledged.
CR Anandhalli M, 2018, J INTELL SYST, V27, P363, DOI 10.1515/jisys-2016-0073
   [Anonymous], 1998, P EMPIRICAL EVAL TEC
   Billones RKC, 2017, 2017 COMPUTING CONFERENCE, P688, DOI 10.1109/SAI.2017.8252170
   Cai YF, 2017, IEEE ACCESS, V5, P22804, DOI 10.1109/ACCESS.2017.2756081
   Chen Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092686
   Dooley Damien, 2016, IEEE Transactions on Intelligent Transportation Systems, V17, P264, DOI 10.1109/TITS.2015.2467357
   Feng RY, 2020, IEEE ACCESS, V8, P43508, DOI 10.1109/ACCESS.2020.2976890
   Geiger A., 2012, CVPR
   Hao LY, 2020, NEURAL COMPUT APPL, V32, P14497, DOI 10.1007/s00521-019-04486-1
   Hsu SC, 2018, PROC INT WORKSH ADV
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Li Y, 2013, IEEE T INTELL TRANSP, V14, P984, DOI 10.1109/TITS.2013.2250501
   Lin RJ, 2009, IEEE INT VEH SYM, P203, DOI 10.1109/IVS.2009.5164278
   Mansour A, 2019, IOP C SERIES MAT SCI, V610
   Min WD, 2018, IEEE T INTELL TRANSP, V19, P174, DOI 10.1109/TITS.2017.2756989
   Munajat MDE, 2016, PROCEEDINGS OF 2016 2ND INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH) - INFORMATION SCIENCE FOR GREEN SOCIETY AND ENVIRONMENT, P244, DOI 10.1109/ICSITech.2016.7852641
   Satzoda RK, 2016, IEEE T INTELL TRANSP, V17, P926, DOI 10.1109/TITS.2015.2494586
   Song HS, 2019, EUR TRANSP RES REV, V11, DOI 10.1186/s12544-019-0390-4
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tian B, 2014, IEEE T INTELL TRANSP, V15, P597, DOI 10.1109/TITS.2013.2283302
   Yamazaki F, 2008, IGARSS 2008
NR 21
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28849
EP 28874
DI 10.1007/s11042-022-12422-0
EA MAR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900010
DA 2024-07-18
ER

PT J
AU Yousaf, A
   Razaq, A
   Baig, H
AF Yousaf, Awais
   Razaq, Abdul
   Baig, Hira
TI A lightweight image encryption algorithm based on patterns in Rubik's
   revenge cube
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE S-box; Cryptography; Rubik Cube and Puzzle Permutations
ID HARDWARE ARCHITECTURES; SUBSTITUTION-BOXES; CONSTRUCTION; OPTIMIZATION
AB Typical security confirmation for a cryptographic protocol correlates its resilience to a specific attack to assure the hardness of some mathematical problem. Block encryption algorithm depends on the two most critical aspects; its sophistication and ease of use, to support security criteria. In this scheme, the principle of the moves of Rubik's Revenge cube has been operated to generate puzzle permutations and hence puzzle group. Afterwards, highly nonlinear S-boxes are evolved through the action of puzzle subgroup over the set of elements of Rubik's Revenge cube. The effectiveness of the proposed S- boxes are ensured through rigorous theoretical analysis and experimental results.
C1 [Yousaf, Awais; Baig, Hira] Islamia Univ Bahawalpur, Dept Math, Bahawalpur 63100, Pakistan.
   [Razaq, Abdul] Univ Educ, Dept Math, Div Sci & Technol, Lahore 54000, Pakistan.
C3 Islamia University of Bahawalpur
RP Yousaf, A (corresponding author), Islamia Univ Bahawalpur, Dept Math, Bahawalpur 63100, Pakistan.
EM awais.yousaf@iub.edu.pk
RI Razaq, Abdul/Q-6545-2019
CR Ahmad M, 2020, IEEE ACCESS, V8, P110397, DOI 10.1109/ACCESS.2020.3001868
   Ahmad M, 2018, WIRELESS PERS COMMUN, V101, P1715, DOI 10.1007/s11277-018-5787-1
   Ali KM, 2019, INT J THEOR PHYS, V58, P3091, DOI 10.1007/s10773-019-04188-3
   Alzaidi AA, 2018, COMPLEXITY, DOI 10.1155/2018/9389065
   Lara-Nino CA, 2017, IEEE T CIRCUITS-I, V64, P2544, DOI 10.1109/TCSI.2017.2686783
   Baumslag G, 2006, APPL ALGEBR ENG COMM, V17, P205, DOI 10.1007/s00200-006-0003-z
   Bilgin B, 2012, LECT NOTES COMPUT SC, V7428, P76, DOI 10.1007/978-3-642-33027-8_5
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Cid C, 2005, LECT NOTES COMPUT SC, V3557, P145
   Courtois NT, 2008, LECT NOTES COMPUT SC, V5086, P97
   Eisenbarth T, 2007, IEEE DES TEST COMPUT, V24, P522, DOI 10.1109/MDT.2007.178
   El-Sheikh HM., 2012, INT J COMPUTER THEOR, V4, P158, DOI [10.7763/IJCTE.2012.V4.442, DOI 10.7763/IJCTE.2012.V4.442]
   Hussain S, 2020, IEEE ACCESS, V8, P123492, DOI 10.1109/ACCESS.2020.3005087
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jamal SS, 2019, IEEE ACCESS, V7, P173273, DOI 10.1109/ACCESS.2019.2956385
   Kaiser U, 2008, RFID SECURITY, DOI [10.1007/978-0-387-76481-8_8, DOI 10.1007/978-0-387-76481-8_8]
   Kitsos P, 2012, COMPUT ELECTR ENG, V38, P148, DOI 10.1016/j.compeleceng.2011.11.022
   Lu Q, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101004
   Mihajloska DG, 2012, 6 INT C EM SEC INF S
   Mihajloska H., 2012, P SECURWARE 2012 6 I, P163
   Nakahara, 2009, DAGST SEM P SCHLOSS
   Rafiq A, 2019, MULTIMED TOOLS APPL, V78, P15527, DOI 10.1007/s11042-018-6953-x
   Razaq A, 2021, WIRELESS PERS COMMUN, V116, P3165, DOI 10.1007/s11277-020-07841-x
   Razaq A, 2020, IEEE ACCESS, V8, P75473, DOI 10.1109/ACCESS.2020.2989676
   Razaq A, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/4987021
   Shah T, 2017, COMPUT APPL MATH, V36, P843, DOI 10.1007/s40314-015-0265-9
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   Wang X, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040781
   Yousaf MA, 2020, IEEE ACCESS, V8, P39781, DOI 10.1109/ACCESS.2020.2975880
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
NR 32
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28987
EP 28998
DI 10.1007/s11042-022-11898-0
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900009
DA 2024-07-18
ER

PT J
AU Pawan, YVRN
   Prakash, KB
   Chowdhury, S
   Hu, YC
AF Pawan, Y. V. R. Naga
   Prakash, Kolla Bhanu
   Chowdhury, Subrata
   Hu, Yu-Chen
TI Particle swarm optimization performance improvement using deep learning
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inertia weight; Convolutional neural network; Long short-term memory;
   Particle swarm optimization
AB Deep learning is widely used to automate processes, improve performance, detect patterns, and solve problems. Thus, applications of deep learning are limitless. Particle swarm optimization is a computational method that optimizes a problem by trying to improve a candidate solution. Although many researchers proposed particle swarm optimization variants, each variant is unique and superior to the existing ones. Among them, inertia weight-based particle swarm optimization has its own identity. By adjusting the inertia weight, the performance of the swarm can be improved. This paper proposes two new particle swarm optimization models using the convolutional neural network and long short-term memory to predict the inertia weight in moving the swarm for improving the swarm performance. The performance of the two new inertia weight models is compared in terms of mean absolute error and standard deviation, with the existing inertia weight based particle swarm optimizations like constant inertia weight, random inertia weight, and linearly decreasing inertia weight particle swarm optimizations. Experiments are conducted with swarm sizes 50, 75, and 100 with dimensions 10, 15, and 25 using the five most commonly used benchmark functions. The results show that the new models have significant performance gain over existing constant, random and linearly decreasing inertia weight particle swarm optimization models.
C1 [Pawan, Y. V. R. Naga] Anurag Engn Coll, Dept Comp Sci & Engn, Ananthagiri Vm, Telangana, India.
   [Prakash, Kolla Bhanu] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Vaddeswaram, Andhra Pradesh, India.
   [Chowdhury, Subrata] SVCET Engn Coll, Dept Comp Sci & Applicat, Chittoor, Andhra Pradesh, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Providence University - Taiwan
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM ynpawan@gmail.com; drkbp@kluniversity.in; subrata895@gmail.com;
   ychu@pu.edu.tw
RI Chowdhury, Dr. Subrata/Y-5282-2018; KOLLA, Dr BHANU PRAKASH/A-7603-2013;
   Yallapragada, V.R.Naga pawan/AAB-9079-2021
OI Chowdhury, Dr. Subrata/0000-0001-5679-3140; KOLLA, Dr BHANU
   PRAKASH/0000-0002-7955-2777; Yallapragada, V.R.Naga
   pawan/0000-0002-8985-8550; Hu, Yu-Chen/0000-0002-5055-3645
CR Amidi Afshine., RECURRENT NEURAL NET
   Babitha D., 2020, INT J ADV TRENDS COM, V8, P1767
   Bansal J C, 2011, 3 WORLD C NAT BIOL I, P633, DOI [10.1109/NaBIC.2011.6089659, DOI 10.1109/NABIC.2011.6089659]
   Bharadwaj S. S. Y., 2020, INT J ADV TRENDS COM, V9, P1335
   Bonyadi MR, 2017, IEEE T EVOLUT COMPUT, V21, P378, DOI 10.1109/TEVC.2016.2605668
   CAO YU, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P226, DOI 10.1109/IROS.1995.525801
   Engelbrecht A.P., 2007, Computational Intelligence, P289, DOI [10.1002/9780470512517.ch16, DOI 10.1002/9780470512517.CH16]
   Freitas D, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030362
   Hammer B, 2000, NEUROCOMPUTING, V31, P107, DOI 10.1016/S0925-2312(99)00174-5
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Imambi S, 2021, PROGRAMMING TENSORFL, DOI DOI 10.1007/978-3-030-57077-4_10
   Jha A.K., 2021, Programming with TensorFlow, P5
   Kanagachidambaresan GR., 2021, PROGRAMMING TENSORFL, P145, DOI DOI 10.1007/978-3-030-57077-4_12
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kumar A., 2016, International Journal of Computer Applications, V135, P24, DOI DOI 10.5120/IJCA2016908406
   Kushwaha N, 2019, MULTIMED TOOLS APPL, V78, P23917, DOI 10.1007/s11042-018-6324-7
   Lin YH, 2018, PROCESSES, V6, DOI 10.3390/pr6120236
   Liu TH, 2017, MULTIMED TOOLS APPL, V76, P11961, DOI 10.1007/s11042-016-3776-5
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Oldewage ET, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P785
   Pan F, 2020, MULTIMED TOOLS APPL, V79, P9509, DOI 10.1007/s11042-019-08015-z
   Parsopoulos K.E., 2002, Advances in Intelligent Systems, Fuzzy Systems, Evolutionary Computation, P216
   Piotrowski AP, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100718
   Poli Riccardo, 2008, Journal of Artificial Evolution & Applications, DOI 10.1155/2008/761459
   Prakash KB., 2020, Int J Adv Trends Comp Sci Eng, V9, P3216
   Ruwali A, 2021, IEEE GEOSCI REMOTE S, V18, P1004, DOI 10.1109/LGRS.2020.2992633
   Serani A, 2016, APPL SOFT COMPUT, V49, P313, DOI 10.1016/j.asoc.2016.08.028
   Shahzad F, 2009, ADV INTEL SOFT COMPU, V61, P339
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Tejasri K., 2020, INT J ADV SCI TECH, V29, P2232
   Vaddi L., 2020, INT J ADV TRENDS COM, V9, P6603, DOI DOI 10.30534/IJATCSE/2020/110942020
   Vamsidhar E., 2021, Programming with TensorFlow: Solution for Edge Computing Applications, P63
   Van den Bergh F., 2006, ANAL PARTICLE SWARM
   Zhang YY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/807527
   Zhihua Cui, 2009, International Innovative Computing and Applications, V2, P77, DOI 10.1504/IJICA.2009.031778
   Zhu HJ, 2017, MULTIMED TOOLS APPL, V76, P8951, DOI 10.1007/s11042-016-3486-z
NR 36
TC 16
Z9 16
U1 12
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27949
EP 27968
DI 10.1007/s11042-022-12966-1
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100016
DA 2024-07-18
ER

PT J
AU Hu, H
   Liu, TC
   Feng, HL
AF Hu, Heng
   Liu, Tongcun
   Feng, Hailin
TI Fast-slow visual network for action recognition in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Visual speed; Video classification; Frame-difference
   method
AB The visual speed, as important visual information on videos, has the ability to enhance the performance of video action recognition. Modeling the visual speed of different actions facilitates their recognition. Previous works have often attempted to capture the visual speed through sampling raw videos at multiple rates and then constructing an input-level frame pyramid, which usually requires to manipulate a costly multibranched network. In this work, we proposed a fast-slow visual network (FSVN) to improve the accuracy of video action recognition via a visual speed stripping strategy which can flexibly be integrated into various excellent 2-D or 3-D backbone networks. Specifically, by the method of the frame difference, we divided a video into fast visual frames and slow visual frames which can respectively represent the action information and the spatial information in the video. Then, we designed a fast visual information recognition network to capture the action information and a slow visual information recognition network to record the spatial information; finally, these two networks were integrated. The experiments on the data sets UCF101 (98.3%) and HMDB51 (76.4%) prove the superiority of our method over the traditional approaches.
C1 [Hu, Heng; Liu, Tongcun; Feng, Hailin] Zhejiang A&F Univ, Sch Informat Engn, Hangzhou, Peoples R China.
   [Hu, Heng; Liu, Tongcun; Feng, Hailin] Key Lab Forestry Intelligent Monitoring & Informa, Hangzhou, Peoples R China.
   [Hu, Heng; Liu, Tongcun; Feng, Hailin] Key Lab State Forestry Adm Forestry Sensing Techn, Hangzhou, Peoples R China.
C3 Zhejiang A&F University
RP Feng, HL (corresponding author), Zhejiang A&F Univ, Sch Informat Engn, Hangzhou, Peoples R China.; Feng, HL (corresponding author), Key Lab Forestry Intelligent Monitoring & Informa, Hangzhou, Peoples R China.; Feng, HL (corresponding author), Key Lab State Forestry Adm Forestry Sensing Techn, Hangzhou, Peoples R China.
EM hlfeng@zafu.edu.cn
RI hu, heng/GRX-1082-2022
OI hu, heng/0000-0002-9505-4049
FU National Natural Science Foundation of China [U1809208]; Research and
   Development Fund Talent Startup Project of Zhejiang AF University
   [2019FR070]
FX This research was jointly supported by (1) National Natural Science
   Foundation of China (U1809208); (2) the Research and Development Fund
   Talent Startup Project of Zhejiang A&F University (No. 2019FR070).
CR Avola D, 2019, MULTIMED TOOLS APPL, V78, P5919, DOI 10.1007/s11042-018-6875-7
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chu Hongxia, 2008, Journal of Projectiles, Rockets, Missiles and Guidance, V28, P85
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Ge HW, 2019, MULTIMED TOOLS APPL, V78, P20533, DOI 10.1007/s11042-019-7404-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Kashiwagi T., 2000, Transactions of the Institute of Electrical Engineers of Japan, Part C, V120-C, P715
   Kay W., 2017, ARXIV170506950
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar Krishan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P385, DOI 10.1007/978-981-10-7895-8_30
   Kumar K, 2019, ADV INTELL SYST, V748, P453, DOI 10.1007/978-981-13-0923-6_39
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Lan ZZ, 2017, IEEE COMPUT SOC CONF, P1219, DOI 10.1109/CVPRW.2017.161
   Peng L, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P187
   Pengcheng D, 2019, 2019 CHIN CONTR DEC, P3333
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solanki Akshay, 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2018. Advances in Intelligent Systems and Computing (AISC 1053), P905, DOI 10.1007/978-981-15-0751-9_83
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Subrahmanyam KV, 2020, IETE TECH REV, V37, P211, DOI 10.1080/02564602.2019.1593890
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang Q, 2013, APPL MECH MAT 2013
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wu H, 2021, P 20 9 INT C INT JOI, P753
   Xu Y, 2017, DESTECH T ENG TECHNO
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Yoo GH., 2005, J KOREAN I COMMUNICA, V30, P949
   Zhang D, 2018, AS C COMP VIS, P712
   Zhong X, 2017, 2017 IEEE 2ND ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P1245, DOI 10.1109/IAEAC.2017.8054213
NR 38
TC 0
Z9 0
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26361
EP 26379
DI 10.1007/s11042-022-12948-3
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900014
DA 2024-07-18
ER

PT J
AU Latha, D
   Bell, TB
   Sheela, CJJ
AF Latha, D.
   Bell, T. Beula
   Sheela, C. Jaspin Jeba
TI Red lesion in fundus image with hexagonal pattern feature and two-level
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Red lesion; Microaneurysms; Hemorrhage; Background elimination;
   Recurrent neural network; Lesion candidates
AB Red lesion identification at its early stage is very essential for the treatment of diabetic retinopathy to prevent loss of vision. This work proposes a red lesion detection algorithm that uses Hexagonal pattern-based features with two-level segmentation that can detect hemorrhage and microaneurysms in the fundus image. The proposed scheme initially pre-processes the fundus image followed by a two-level segmentation. The level 1 segmentation eliminates the background whereas the level 2 segmentation eliminates the blood vessels that introduce more false positives. A hexagonal pattern-based feature is extracted from the red lesion candidates which can highly differentiate the lesion from non-lesion regions. The hexagonal pattern features are then trained using the recurrent neural network and are classified to eliminate the false negatives. For the evaluation of the proposed red lesion algorithm, the datasets namely ROC challenge, e-ophtha, DiaretDB1, and Messidor are used with the metrics such as Accuracy, Recall, Precision, F1 score, Specificity, and AUC. The scheme provides an average Accuracy, Recall (Sensitivity), Precision, F1 score, Specificity, and AUC of 95.48%, 84.54%, 97.3%, 90.47%, 86.81% and 93.43% respectively.
C1 [Latha, D.; Sheela, C. Jaspin Jeba] Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
   [Bell, T. Beula] Nesamony Mem Christian Coll, Dept Comp Applicat, Marthandam, India.
RP Latha, D (corresponding author), Nesamony Mem Christian Coll, Dept PG Comp Sci, Marthandam, India.
EM dlathasatheesh@gmail.com; beulamaglin@gmail.com;
   jaspinjebasheela@gmail.com
CR Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Al-Rawi M, 2007, COMPUT BIOL MED, V37, P262, DOI 10.1016/j.compbiomed.2006.03.003
   Alyoubi WL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113704
   Amalia R., 2021, Journal of Physics: Conference Series, V1722, P12010, DOI [DOI 10.1088/1742-6596/1722/1/012010, 10.1088/1742-6596/1722/1/012010]
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Cree MJ, 1997, EYE, V11, P622, DOI 10.1038/eye.1997.166
   Dai BS, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161556
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Dashtbozorg B, 2018, IEEE T IMAGE PROCESS, V27, P3300, DOI 10.1109/TIP.2018.2815345
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   Gardiner B, 2011, COMPARING HEXAGONAL
   Gayathri S, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102115
   Giancardo L, 2011, IEEE ENG MED BIO, P5939, DOI 10.1109/IEMBS.2011.6091562
   Goatman KA, 2003, INVEST OPHTH VIS SCI, V44, P5335, DOI 10.1167/iovs.02-0951
   Gothwal R, 2014, 2014 3RD INTERNATIONAL CONFERENCE ON RELIABILITY, INFOCOM TECHNOLOGIES AND OPTIMIZATION (ICRITO) (TRENDS AND FUTURE DIRECTIONS)
   Kandhasamy JP, 2020, MULTIMED TOOLS APPL, V79, P10581, DOI 10.1007/s11042-019-7485-8
   Khan MK, 2021, IEEE EMBS CONF BIO, P472, DOI 10.1109/IECBES48179.2021.9398745
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Li JY, 2021, NEUROCOMPUTING, V465, P15, DOI 10.1016/j.neucom.2021.08.105
   Long QX, 2020, NAT MED, V26, P845, DOI 10.1038/s41591-020-0897-1
   Mizutani A, 2009, PROC SPIE, V7260, DOI 10.1117/12.813468
   Narasimha-Iyer H, 2007, IEEE T BIO-MED ENG, V54, P1436, DOI 10.1109/TBME.2007.900807
   Narasimha-Iyer H, 2006, IEEE T BIO-MED ENG, V53, P1084, DOI 10.1109/TBME.2005.863971
   Niemeijer M, 2005, IEEE T MED IMAGING, V24, P584, DOI 10.1109/TMI.2005.843738
   Rajinikanth V., 2021, 2021 7 INT C BIOS IM, P1, DOI [10.1109/ICBSII51839.2021.9445134, DOI 10.1109/ICBSII51839.2021.9445134]
   Ramasamy LK, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.456
   Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785
   Suchetha M, 2021, REGION INTEREST BASE
   Verma SS, 2021, BIOMED SIGNAL PROCES
   Yadav D, 2021, MEASUREMENT, V176, DOI 10.1016/j.measurement.2021.109084
   Yildirim O, 2019, COMPUT BIOL MED, V113, DOI 10.1016/j.compbiomed.2019.103387
   Youssif A., 2006, Cairo International Biomedical Engineering Conference, P1
   Zaremba W., 2014, CORR
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
   Zhang X, 2014, Ph.D. dissertation
   Zhou W, 2017, IEEE ACCESS, V5, P2563, DOI 10.1109/ACCESS.2017.2671918
NR 37
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26143
EP 26161
DI 10.1007/s11042-022-12667-9
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000780464900009
PM 35368859
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Ren, H
   Niu, SZ
AF Ren, Hua
   Niu, Shaozhang
TI Joint encryption and authentication in hybrid domains with hidden double
   random-phase encoding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Authentication; DRPE; DWT; SVD; Image security
ID MULTIPLE-IMAGE ENCRYPTION; WATERMARKING ALGORITHM; INFORMATION; SCHEME;
   TRANSFORM
AB Double random-phase encoding (DRPE) has widely used in image encryption and authentication schemes for image privacy and integrity protection. However, most of these schemes cannot ensure the balanced performance of security, robustness, and running efficiency. To solve this issue, a joint encryption and authentication scheme based on DRPE and singular value decomposition (SVD) is proposed. The phase information of the secret image is generated by exploiting DRPE and quantized into a binary type to produce the hidden authentication bits. The cover image is transformed by discrete wavelet transform (DWT) to obtain the coefficient sub-bands. The sub-band HH is used for SVD embedding to optimize perceptual transparency and robustness constraints. The sub-band LL that contains the approximate details of the cover image is permuted for security enhancement. The final encrypted hidden image is produced after diffusion is applied to the permuted hidden image. Security is ensured in this scheme by combining the permutation and diffusion in hybrid domains and an additional layer of authentication due to DRPE. Experimental results confirm the effectiveness in security and robustness.
C1 [Ren, Hua; Niu, Shaozhang] Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Niu, SZ (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM renhuahtu@163.com; szniu@bupt.edu.cn
OI Niu, Shaozhang/0000-0002-9639-5910
FU National Natural Science Foundation of China [U1536121, 61370195]
FX This work is supported by The National Natural Science Foundation of
   China (No.61370195) and the Joint Funds of the National Natural Science
   Foundation of China (No. U1536121).
CR Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bhardwaj R, 2021, MULTIMED TOOLS APPL, V80, P31687, DOI 10.1007/s11042-021-10892-2
   Biswas R, 2020, MULTIMED TOOLS APPL, V79, P7101, DOI 10.1007/s11042-019-08497-x
   Chen YY, 2010, OPT LASER TECHNOL, V42, P617, DOI 10.1016/j.optlastec.2009.10.013
   Dittmann J., 2001, IEEE Multimedia, V8, P54, DOI 10.1109/93.959103
   He MZ, 2005, OPT COMMUN, V247, P29, DOI 10.1016/j.optcom.2004.11.034
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Huo DM, 2018, J MOD OPTIC, V65, P2093, DOI 10.1080/09500340.2018.1498547
   Kishk S, 2002, APPL OPTICS, V41, P5462, DOI 10.1364/AO.41.005462
   Lai YL, 2019, INFORM SCIENCES, V502, P492, DOI 10.1016/j.ins.2019.05.064
   Li XW, 2019, OPT LASER ENG, V112, P162, DOI 10.1016/j.optlaseng.2018.09.015
   Makbol NM, 2013, LECT NOTES COMPUT SC, V8237, P36, DOI 10.1007/978-3-319-02958-0_4
   Pérez-Cabré E, 2011, OPT LETT, V36, P22, DOI 10.1364/OL.36.000022
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Ren H, 2019, IEEE ACCESS, V7, P149527, DOI 10.1109/ACCESS.2019.2946929
   Sheela SJ, 2018, MULTIMED TOOLS APPL, V77, P25223, DOI 10.1007/s11042-018-5782-2
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Ye CH, 2014, J VISUAL LANG COMPUT, V25, P658, DOI 10.1016/j.jvlc.2014.10.020
   Yi FL, 2018, IEEE ACCESS, V6, P70113, DOI 10.1109/ACCESS.2018.2880730
   Yi FL, 2017, APPL OPTICS, V56, P4381, DOI 10.1364/AO.56.004381
   Yildirim M, 2021, NONLINEAR DYNAM, V105, P2677, DOI 10.1007/s11071-021-06700-z
   Yuan S, 2009, OPT EXPRESS, V17, P3270, DOI 10.1364/OE.17.003270
   Zhang LZ, 2018, OPT LASER TECHNOL, V105, P162, DOI 10.1016/j.optlastec.2018.03.004
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zheng JC, 2015, J OPT SOC KOREA, V19, P241, DOI 10.3807/JOSK.2015.19.3.241
   Zhou KL, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105769
   Zhu LY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108015
NR 32
TC 1
Z9 1
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25993
EP 26014
DI 10.1007/s11042-022-12013-z
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000773206100009
DA 2024-07-18
ER

PT J
AU Nimmagadda, SM
   Harish, KS
AF Nimmagadda, Satyanarayana Murthy
   Harish, K. Sai
TI Review paper on technology adoption and sustainability in India towards
   smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Smart cities; Sustainability; Governance; Internet of things; Smart
   agriculture; Smart healthcare systems; Economy; Urbanisation
ID CYBER-SECURITY; CITY; CHALLENGES; INTERNET; THINGS; GRIDS
AB This paper mainly aims to identify the key factors that should be included in building of smart cities in a proper efficient way. Due to rapid increase in urban population, it should be responsible to provide a better way in building of a smart city. Smart city is an idea of providing urban development that includes social, financial, ecological parts of a society. A smart and sustainable city has goals to be achieved in an adaptable, reliable, scalable, accessible, and in resilient way which will be discussed in the methodology section. This paper mainly focuses on some important factors in improving sustainability of smart cities such as climate and environmental issues and governance authorities for improving quality of life of citizens. Also, this paper explains 3E's which are environment, economy and equity are plays a crucial role in rapid development of smart cities. This research is focused on discussing various smart technologies recently used in India and the challenges involved in them. Recent literature on smart city development is reviewed, and the challenges that prevailed in recent technologies are analysed. This paper includes how Internet of Things (IoT), Connectivity, Cloud computing and AI etc., should be effectively used for developing a smart city. This paper deals with the requirements to build smart cities in India - regarding various aspects like available resources, lifestyle, transport management system, smart healthcare system, smart waste management, smart Sanitation, smart railways, smart agriculture, home automation, smart energy consumption etc. This paper also discusses 'smart living,"smart infrastructure,"smart governance,"smart economy,' and other various systems which are need for Smart India in particular. When adopted with proper planning, all the above catalysing with smart services and solutions, build a sustainable city.
C1 [Nimmagadda, Satyanarayana Murthy; Harish, K. Sai] VR Siddhartha Engn Coll, ECE Dept, Vijayawada, Andhra Pradesh, India.
C3 Velagapudi Ramakrishna Siddhartha Engineering College
RP Nimmagadda, SM (corresponding author), VR Siddhartha Engn Coll, ECE Dept, Vijayawada, Andhra Pradesh, India.
EM nsmmit@gmail.com; ksharish98@gmail.com
CR Aazam M, 2016, 2016 IEEE 21ST INTERNATIONAL WORKSHOP ON COMPUTER AIDED MODELLING AND DESIGN OF COMMUNICATION LINKS AND NETWORKS (CAMAD), P188, DOI 10.1109/CAMAD.2016.7790356
   Aelenei L, 2016, ENRGY PROCED, V91, P970, DOI 10.1016/j.egypro.2016.06.264
   Ahlgren B, 2016, IEEE INTERNET COMPUT, V20, P52, DOI 10.1109/MIC.2016.124
   Angelidou M, 2018, J SCI TECHNOL POLICY, V9, P146, DOI 10.1108/JSTPM-05-2017-0016
   [Anonymous], 2009, TIMES INDIA
   [Anonymous], 2015, World Population Ageing
   Baig ZA, 2017, DIGIT INVEST, V22, P3, DOI 10.1016/j.diin.2017.06.015
   Bhattacharya S., 2015, Reconceptualising smart cities: A reference framework for India
   Braun T, 2018, SUSTAIN CITIES SOC, V39, P499, DOI 10.1016/j.scs.2018.02.039
   Caird SP, 2019, J URBAN DES, V24, P188, DOI 10.1080/13574809.2018.1469402
   Chauhan Sumedha, 2016, Info, V18, P73, DOI 10.1108/info-03-2016-0012
   Chowdhury B, 2007, 2007 AUSTRALASIANTELECOMMUNICATION NETWORKS AND APPLICATIONS CONFERENCE, P64
   Ding ZM, 2016, IEEE T COMPUT, V65, P1377, DOI 10.1109/TC.2015.2479596
   Elmaghraby AS, 2014, J ADV RES, V5, P491, DOI 10.1016/j.jare.2014.02.006
   Farahat IS., 2019, Security in Smart Cities: Models, Applications, and Challenges, P117
   Folianto F, 2015, 2015 IEEE TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING (ISSNIP)
   Gade DS., 2021, INT J MANAG TECHNOL, V6, P47, DOI [10.5281/zenodo.5221206, DOI 10.5281/ZENODO.5221206]
   Government of India AFD, 2018, THES 12 IND CIT FUT
   Haribabu P, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P1155, DOI 10.1109/ISS1.2017.8389367
   Israilidis J, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2019.07.015
   Jawaid M. F., 2015, INT J ADV RES SCI EN
   Jha IS, 2014, 2014 EIGHTEENTH NATIONAL POWER SYSTEMS CONFERENCE (NPSC)
   Kim TH, 2017, FUTURE GENER COMP SY, V76, P159, DOI 10.1016/j.future.2017.03.034
   Kumar NM, 2018, TECHNOL SMART CITY E, DOI 10.1109/ICSESP.2018.8376669
   Lopes NV, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART GRID AND SMART CITIES (ICSGSC), P277, DOI 10.1109/ICSGSC.2017.8038591
   Lund H, 2012, ENERGY, V42, P96, DOI 10.1016/j.energy.2012.04.003
   Madakam S., 2015, 2015 5 NATL S INFORM, P1, DOI DOI 10.1109/NSITNSW.2015.7176407
   Mardacany E., 2014, SMART CITIES CHARACT
   Masera M, 2018, P IEEE, V106, P613, DOI 10.1109/JPROC.2018.2812212
   Matthiesen BV, 2013, DESIGN SMART ENERGY, DOI 10.1016/j.rser.2016.02.025
   Mckinsey Global Solutions, 2018, SMART CIT DIG SOL MO
   Mosannenzadeh F, 2017, CITIES, V64, P54, DOI 10.1016/j.cities.2017.02.001
   MoUD, 2015, SMART CIT MISS GUID
   Mrityunjaya DH, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P1, DOI 10.1109/I-SMAC.2017.8058235
   Murthy, 2020, INT J ADV SCI TECHNO, V29, P6618
   Murthy, 2014, IEEE INT C COMM SIGN
   Murthy, 2014, INT J APPL ENG RES, V9, P9341
   Murthy, 2019, INT J RECENT TECHNOL, V7, P1119
   Murthy Nimmagadda S., 2020, Progress In Electromagnetics Research C, V100, P247
   Murthy N. S., 2012, ELSEVIER SCIVERSE SC
   Murthy NS, 2021, STAT METHODS MED RES, V30, P1042, DOI 10.1177/0962280220983541
   Murthy NS, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03147-3
   MURTHY NS, 2011, WIRELESS COMMUNICATI
   Nimmagadda SM, 2021, WIRELESS PERS COMMUN, V120, P2135, DOI 10.1007/s11277-021-08696-6
   Nimmagadda SM, 2021, WIRELESS PERS COMMUN, V117, P1259, DOI 10.1007/s11277-020-07921-y
   Nimmagadda SM, 2020, SOFT COMPUT, V24, P12523, DOI 10.1007/s00500-020-04690-5
   Okai E, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1726, DOI 10.1109/HPCC/SmartCity/DSS.2018.00282
   Pierce P., 2017, CHALLENGES SMART CIT
   Pira M, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00879-7
   Prochazkova D, 2018, SMART CITY S PRAGUE, DOI 10.1109/scsp.2018.8402676
   Rana NP, 2019, INFORM SYST FRONT, V21, P503, DOI 10.1007/s10796-018-9873-4
   Ratnavel, 2020, SENIOR PROFESSIONAL
   Raun NF, 2016, 7TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE IEEE IEMCON-2016
   Rhee S, 2016, 2016 1ST INTERNATIONAL WORKSHOP ON SCIENCE OF SMART CITY OPERATIONS AND PLATFORMS ENGINEERING (SCOPE) IN PARTNERSHIP WITH GLOBAL CITY TEAMS CHALLENGE (GCTC) (SCOPE - GCTC)
   Satyanarayana MN, 2020, INNOVATIONS ELECT CO, V107, DOI 10.1007/978-981-15-3172-9_50
   Scuotto V, 2016, BUS P MANAJ J
   Shrivastava VP, 2019, DEFINITION ITS PRACT, V8
   Silva BN, 2018, SUSTAIN CITIES SOC, V38, P697, DOI 10.1016/j.scs.2018.01.053
   Smart Cities Index, 2017, TOOL EV CIT PUNJ LLO
   Smart Waste Management in Smart Cities, 2018, CLEAN INDIA J
   Stefansson G, 2008, INT J PRODUCT PERFOR, V58, P55, DOI 10.1108/17410400910921083
   Su KH, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P1028, DOI 10.1109/ICECC.2011.6066743
   Toli AM, 2020, FRONT BUILT ENVIRON, V6, DOI 10.3389/fbuil.2020.00077
   Trindade EP., 2017, J. Open Innov. Technol. Mark. Complex, V3, P1, DOI [DOI 10.1186/S40852-017-0063-2, 10.1186/S40852-017-0063-2]
   Valencia-Arias A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132011214
   Veselitskaya N., 2019, Theoretical and Empirical Researches in Urban Management, V14, P85
   Washburn D., 2009, Growth, V17, P1
   Wijaya AS, 2017, INT CONF INSTRUM, P62, DOI 10.1109/ICA.2017.8068414
   Wu ZZ, 2021, J URBAN TECHNOL, V28, P29, DOI 10.1080/10630732.2020.1777045
   Yadav G, 2019, SUSTAIN CITIES SOC, V47, DOI 10.1016/j.scs.2019.101462
   Zanella A, 2014, IEEE INTERNET THINGS, V1, P22, DOI 10.1109/JIOT.2014.2306328
   Zantalis F, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040094
NR 72
TC 5
Z9 5
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27217
EP 27245
DI 10.1007/s11042-022-12885-1
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000772731900006
DA 2024-07-18
ER

PT J
AU Jarjar, M
   Hraoui, S
   Najah, S
   Zenkouar, K
AF Jarjar, Mohamed
   Hraoui, Said
   Najah, Said
   Zenkouar, Khalid
TI New technology of color image encryption based on chaos and two improved
   Vigenere steps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vigenere grid; Broadcast function; Chaotic map; Encryption function;
   S-box
ID ALGORITHM
AB This article traces the development trajectory of the new cryptographic system using two circuits provided by the profound improvement of the traditional Vigenere technology. This new method uses several dynamic permutation matrices attached to the advanced chaotic permutation function. Explain its structure and definition in detail. The first round will modify the first bootloader block by intervening the initial value calculated from the original image, and will be infected by all the chaotic maps used to overcome the problem of uniform color images, and then restore our new depth advanced Vigenere technology. The second round will recalculate new initialization values based on the obtained encrypted image and the generated chaotic map. The last round will focus on the introduction of the new replacement matrix, in which strong links will be implemented, strong propagation will be achieved, and encrypted blocks will be linked with subsequent transparent blocks to eliminate any differential attacks. Simulations performed on a large number of images of different sizes and formats showed encouraging results and confirmed that this method is not affected by known attacks.
C1 [Jarjar, Mohamed; Najah, Said; Zenkouar, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab SIA, Fes, Morocco.
   [Hraoui, Said] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, LIASSE, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Jarjar, M (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci & Technol, Lab SIA, Fes, Morocco.
EM jarjar.moharned@gmail.com; said.hraoui@usmba.ac.ma;
   said.najah@usmba.ae.ma; khalid.zenkouar@yahoo.fr
RI HRAOUI, Said/ABD-3324-2021
CR Ali SMA, 2019, NOVEL ENCRYPTION ALG, V80
   [Anonymous], 2016, 2016 10 INT C TELECO
   [Anonymous], 2017, J KING SAUD U COMP I
   [Anonymous], 2010, IJ NETWORK SECURITY
   Boussif M, 2020, IET DIGITAL LABRERY
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ge R, 2019, NOVEL CHAOS BASED SY
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Hraoui S, 2013, 2013 ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS (AICCSA)
   Jarjar A, 2017, INT J STAT APPL MATH, V2
   JarJar M., 2019, P COMPUT SCI, V00, P000
   Kester Q-A., 2012, INT J ADV RES COMPUT, V1
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Noshadian S, 2020, MULTIMED TOOLS APPL, V79, P25635, DOI 10.1007/s11042-020-09233-6
   Patidar U, 2011, UD OPTICS COMMUNICAT, V254, P4331
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Peng J, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P492, DOI 10.1109/ICCCAS.2002.1180666
   Reddy VVK, 2018, INT J PURE APPL MATH, V118
   Saputra I, 2017, INT J ENG RES TECHNO, V6
   Shah A., 2016, INT J COMPUT APPL, V136, P0975
   Sum F., 2008, CHAOS SOLUTION FRACT, V3, P631
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang Y, 2009, CHAOS SOLITON FRACT, V41, P1773, DOI 10.1016/j.chaos.2008.07.031
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 28
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 MAR 21
PY 2022
DI 10.1007/s11042-022-012750-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW7HR
UT WOS:000771380200002
DA 2024-07-18
ER

PT J
AU Morace, CC
   Le, TNH
   Yao, SY
   Zhang, SW
   Lee, TY
AF Morace, Charles C.
   Thi-Ngoc-Hanh Le
   Yao, Sheng-Yi
   Zhang, Shang-Wei
   Lee, Tong-Yee
TI Learning a perceptual manifold with deep features for animation video
   resequencing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Deep features; Manifold learning; Animation video
   resequencing
ID DIMENSIONALITY REDUCTION
AB We propose a novel deep learning framework for animation video resequencing. Our system produces new video sequences by minimizing a perceptual distance of images from an existing animation video clip. To measure perceptual distance, we utilize the activations of convolutional neural networks and learn a perceptual distance by training these features on a small network with data comprised of human perceptual judgments. We show that with this perceptual metric and graph-based manifold learning techniques, our framework can produce new smooth and visually appealing animation video results for a variety of animation video styles. In contrast to previous work on animation video resequencing, the proposed framework applies to wide range of image styles and does not require hand-crafted feature extraction, background subtraction, or feature correspondence. In addition, we also show that our framework has applications to appealingly arrange unordered collections of images.
C1 [Morace, Charles C.; Thi-Ngoc-Hanh Le; Yao, Sheng-Yi; Zhang, Shang-Wei; Lee, Tong-Yee] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
EM tonylee@mail.ncku.edu.tw
FU Ministry of Science and Technology [107-2221-E-006-196-MY3,
   108-2221-E-006-038-MY3]
FX The authors would like to thank the reviewers for the many constructive
   comments that help improve the paper. This work was supported in part by
   the Ministry of Science and Technology (contracts 107-2221-E-006-196-MY3
   and 108-2221-E-006-038-MY3), Taiwan.
CR Averbuch-Elor H, 2016, COMPUT GRAPH FORUM, V35, P203, DOI 10.1111/cgf.12823
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Cormen T. H., 2009, Introduction to Algorithms, VSecond
   de Juan Christina., 2004, SCA 2004: Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P267, DOI DOI 10.1145/1028523.1028559
   Fried O, 2017, COMPUT GRAPH FORUM, V36, P183, DOI 10.1111/cgf.13284
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Holden D., 2015, P SIGGRAPH AS TECH B, DOI DOI 10.1145/2820903.2820918
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Inc WR., 2018, MATH VERS 11, V3
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   LAPORTE G, 1992, EUR J OPER RES, V59, P231, DOI 10.1016/0377-2217(92)90138-Y
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu G, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P402, DOI 10.1109/ICACI.2018.8377492
   Osadchy M, 2007, J MACH LEARN RES, V8, P1197
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schödl A, 2001, ADV NEUR IN, V13, P1002
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Schodl A., 2002, SCA 02 P 2002 ACM SI, P121, DOI DOI 10.1145/545261.545281
   Schoeffmann K., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P422, DOI 10.1109/ISM.2011.76
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   STACY EW, 1962, ANN MATH STAT, V33, P1187, DOI 10.1214/aoms/1177704481
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Yu J, 2012, IEEE T SYST MAN CY B, V42, P1413, DOI 10.1109/TSMCB.2012.2192108
   Yu J, 2012, SIGNAL PROCESS, V92, P2147, DOI 10.1016/j.sigpro.2012.01.028
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang S, 2019, SAR QSAR ENVIRON RES, V30, P209, DOI 10.1080/1062936X.2019.1576222
NR 34
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23687
EP 23707
DI 10.1007/s11042-022-12251-1
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770205600001
DA 2024-07-18
ER

PT J
AU Baloni, D
   Verma, SK
AF Baloni, Dev
   Verma, Shashi Kant
TI Detection of hydrocephalus using machine learning in medical science - a
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Hydrocephalus; Machine learning; Image segmentation; Mean shift
   clustering; Fuzzy c-means algorithm; Feature extraction; Pattern
   analysis; Conventional neural network
ID AUTOMATIC CHANGE DETECTION; CEREBROSPINAL-FLUID; CLASSIFICATION;
   DYNAMICS
AB Machine learning (ML) is the study of computer algorithms that expand spontaneously by knowledge. ML algorithms construct an analytical model centred on sample data, recognized as 'training data,' in order to make projections or conclusions without being specifically programmed to do so. Hydrocephalus is the generally known disease found in children of the central nervous system and requires neurosurgical treatment and that has been studied and imaged for years however, there is still no prevalent solution and effective method for precise detection and computable evaluation of this. This work suggests a modern form of Machine Learning (ML) for the early detection of hydrocephalus. ML is the fast growing and challenging field now days. For medical diagnosis, ML methods are used. Four phases are involved in the identification of hydrocephalus using image processing methods, namely image pre-processing, image segmentation, detection and classification of features.
C1 [Baloni, Dev] Uttarakhand Tech Univ, Comp Sci & Engn, Sudhowala, India.
   [Verma, Shashi Kant] Govind Ballabh Pant Inst Engn & Technol, Pauri, Garhwal, India.
C3 Uttarakhand Technical University
RP Baloni, D (corresponding author), Uttarakhand Tech Univ, Comp Sci & Engn, Sudhowala, India.
EM devbaloni1982@gmail.com
CR Agarwal S., 2013, INT J BIOSCI BIOTECH, V5, P241, DOI [DOI 10.14257/IJBSBT.2013.5.5.25, 10.14257/ijbsbt.2013.5.5.25]
   Ambarki, 2010, AM J NEURORADIOL
   An L, 2012, IEEE IMAGE PROC, P2209, DOI 10.1109/ICIP.2012.6467333
   [Anonymous], 2019, INT J ENG ADV TECHNO
   [Anonymous], DIV DEEP DIM RED IND
   [Anonymous], 1997, NEUROIMAGE
   Bazi Y, 2014, IEEE GEOSCI REMOTE S, V11, P1066, DOI 10.1109/LGRS.2013.2286078
   Bezdek J. C., 1981, Pattern recognition with fuzzy objective function algorithms
   Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   BURRASCANO P, 1991, IEEE T NEURAL NETWOR, V2, P458, DOI 10.1109/72.88165
   Cao FL, 2013, NEUROCOMPUTING, V102, P90, DOI 10.1016/j.neucom.2012.02.042
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Dumskyj MJ, 1996, CURR EYE RES, V15, P625, DOI 10.3109/02713689609008902
   Fang CY, 2003, IEEE T NEURAL NETWOR, V14, P646, DOI 10.1109/TNN.2003.811353
   Flores S., 2019, Variational autoencoders are beautiful
   GATH I, 1989, IEEE T PATTERN ANAL, V11, P773, DOI 10.1109/34.192473
   Halberstadt W, 2005, 2005 IEEE ENG MED BI
   Hansen GA., 2005, MESH ENHANCEMENT SEL, DOI [10.1142/p351, DOI 10.1142/P351]
   Ippolito P. P., 2019, Feature extraction techniques
   Kan WY, 1996, OPT ENG, V35, P1723, DOI 10.1117/1.600747
   Kaur N., 2013, SURVEY PATTERN RECOG
   Klauschen F, 2009, HUM BRAIN MAPP, V30, P1310, DOI 10.1002/hbm.20599
   Kobashi S, 2006, IEICE T INF SYST, VE89D, P340, DOI 10.1093/ietisy/e89-d.1.340
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Landis EN, 1999, J ENG MECH-ASCE, V125, P599, DOI 10.1061/(ASCE)0733-9399(1999)125:6(599)
   LEBART K, 2000, P MTS IEEE OC 00 PRO, P337
   Li B, 2013, NEURAL COMPUT APPL, V22, P531, DOI 10.1007/s00521-012-0858-9
   Linguraru MG, 2009, MED IMAGING 2009 COM, P7260
   Linninger AA, 2007, IEEE T BIO-MED ENG, V54, P291, DOI 10.1109/TBME.2006.886853
   Linninger AA, 2009, ANN BIOMED ENG, V37, P1434, DOI 10.1007/s10439-009-9691-4
   Madhusudhan M, 2011, COMM COM INF SC, V192, P365
   Mao KZ, 2000, IEEE T NEURAL NETWOR, V11, P1009, DOI 10.1109/72.857781
   Nagy G., 2001, Visual Form 2001. 4th International Workshop on Visual Form IWVF4. Proceedings (Lecture Notes in Computer Science Vol.2059), P759
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pustkova R, 2010, 9 ROEDUNET IEEE INT
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Schalkoff R., 1992, PATTERN RECOGN
   Schalkoff R. J, 2007, PATTERN RECOGN
   Segal MB, 2001, MICROSC RES TECHNIQ, V52, P38, DOI 10.1002/1097-0029(20010101)52:1<38::AID-JEMT6>3.0.CO;2-J
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Shakunthala M., 2019, 2019 IEEE INT C EL C, P1
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Sweetman B, 2011, COMPUT BIOL MED, V41, P67, DOI 10.1016/j.compbiomed.2010.12.001
   Thompson D, 2005, SPR SP SURG SER, P425
   Venkataramana NK, 2011, J PEDIATR NEUROSCI, V6, P11, DOI 10.4103/1817-1745.85704
   Viswanath K, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1894, DOI 10.1109/RTEICT.2017.8256926
   Weglinski T, 2011, CONCEPT IMAGE PROCES
   WHORFF JS, 1992, J EXP MAR BIOL ECOL, V160, P1, DOI 10.1016/0022-0981(92)90106-K
   Zhu DC, 2006, J MAGN RESON IMAGING, V24, P756, DOI 10.1002/jmri.20679
NR 52
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21199
EP 21222
DI 10.1007/s11042-022-12744-z
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000768100000001
DA 2024-07-18
ER

PT J
AU Liu, LF
   Wei, ZX
   Xiang, HY
AF Liu, Lingfeng
   Wei, ZhiXiang
   Xiang, Hongyue
TI A novel image encryption algorithm based on compound-coupled logistic
   chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Compound-coupled chaotic model; Dynamics characteristics; Image
   encryption; Logistic map
ID COMPLEXITY; SYSTEM
AB Chaos has been widely used in many different kinds of scientific fields, especially in the field of cryptography. While most of the original chaotic systems are not complex and secure enough for practical uses, therefore, in this paper, a novel compounding coupling technique is firstly proposed to enhance the complexity of chaotic systems. The provided compound-coupled chaotic model is universal for all different chaotic maps. Here, to prove the validity of the proposed model, 1D Logistic map, the most widely used chaotic map, is taken as the example. Then a series of numerical experiments were conducted to compare and analyze the maps before and after improvement. From the results, it's obvious that the improved map has higher dynamical complexity than the original one. Furthermore, a novel image encryption algorithm based on the compound-coupled Logistic map is proposed to prove the practicability of the improvement model. Sufficient experimental tests indicate that this encryption algorithm has a high security level, which can be competitive to other chaos-based image encryption algorithms.
C1 [Liu, Lingfeng; Wei, ZhiXiang; Xiang, Hongyue] Nanchang Univ, Sch Software, Nanchang 330029, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, LF (corresponding author), Nanchang Univ, Sch Software, Nanchang 330029, Jiangxi, Peoples R China.
EM vatanoilcy@163.com
RI Liu, Lingfeng/W-7547-2018; Wei, Zhixiang/K-1802-2018
FU National Natural Science Foundation of China [61862042]; Jiangxi Key
   Laboratory of cyberspace and information security project
   [20181BCD40005]
FX This work is supported by the National Natural Science Foundation of
   China (61862042). Jiangxi Key Laboratory of cyberspace and information
   security project (20181BCD40005)
CR Bandt C, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.174102
   Banerjee M, 2016, ECOL COMPLEX, V27, P17, DOI 10.1016/j.ecocom.2015.12.001
   Deng W, 2020, IEEE T INSTRUM MEAS, V69, P7319, DOI 10.1109/TIM.2020.2983233
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Hua ZY, 2021, IEEE T SYST MAN CY-S, V51, P3713, DOI 10.1109/TSMC.2019.2932616
   Hua ZY, 2019, IEEE T IND ELECTRON, V66, P1273, DOI 10.1109/TIE.2018.2833049
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Ismail SM, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107280
   Jamal SS, 2019, CHINESE J PHYS, V60, P564, DOI 10.1016/j.cjph.2019.05.038
   Jia M, 2020, IET IMAGE PROCESS, V14, P973, DOI 10.1049/iet-ipr.2019.0310
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Lacasa L, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.168703
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LF, 2021, NONLINEAR DYNAM, V103, P1099, DOI 10.1007/s11071-020-06113-4
   Liu LF, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500591
   Liu LF, 2017, INFORM SCIENCES, V396, P1, DOI 10.1016/j.ins.2017.02.031
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Natiq H, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010048
   Natiq H, 2019, EUR PHYS J-SPEC TOP, V228, P185, DOI 10.1140/epjst/e2019-800206-9
   Ortiz A, 2020, NONLINEAR DYNAM, V102, P2323, DOI 10.1007/s11071-020-06070-y
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Thorne B, 2021, CHAOS, V31, DOI 10.1063/5.0039193
   Wang XY, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abdea3
   Xian YJ, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abda35
   Xiaoqiang Z., 2021, ELECTRONICS, V10, P10, DOI [10.3390/electronics10091015, DOI 10.3390/ELECTRONICS10091015]
   Ye GD, 2018, NONLINEAR DYNAM, V94, P745, DOI 10.1007/s11071-018-4391-y
   Yin ZZ, 2017, PHYS REV E, V95, DOI 10.1103/PhysRevE.95.012218
   Yu F, 2020, INT J BIFURCAT CHAOS, V30, DOI 10.1142/S0218127420501473
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhao HX, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166307
   Zhao HM, 2020, IEEE T CIRCUITS-I, V67, P983, DOI 10.1109/TCSI.2019.2959886
   Zhao HM, 2020, IEEE T INSTRUM MEAS, V69, P4165, DOI 10.1109/TIM.2019.2948414
   Zhou YC, 2015, IEEE T CYBERNETICS, V45, P2001, DOI 10.1109/TCYB.2014.2363168
NR 38
TC 5
Z9 5
U1 2
U2 66
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19999
EP 20019
DI 10.1007/s11042-022-12765-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000767089800001
DA 2024-07-18
ER

PT J
AU Mishra, J
   Goyal, S
AF Mishra, Jayant
   Goyal, Sachin
TI An effective automatic traffic sign classification and recognition deep
   convolutional networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic traffic sign recognition; Convolutional neural networks (CNN);
   Deep learning algorithms; GTSRB; GTSDB; BTSC; and TSRD; Standard traffic
   sign image datasets
AB Automatic traffic sign recognition is essential for autonomous driving, assisted driving, and driver safety. Convolutional neural networks (CNNs) are the most widely used deep learning algorithm for traffic signs recognition. This research presents an effective technique for automatically recognizing traffic signs images. This technique mainly uses four GTSRB, GTSDB, BTSC, and TSRD standard traffic signs images datasets of different traffic sign images and provides the best result using our CNN model architecture. It helps to assists the driver in driving the motor vehicle safely. Drivers devote too much attention and effort to recognizing traffic signs by manually analyzing and recognizing their aspects. This study presents an automatic traffic sign recognition system to minimize motor vehicle accidents using representation to identify signs-this task utilizing a deep convolutional neural network. Here, our work presents a novel CNN architecture (.001) with Adam optimizer, batch size 128, and multi-interconnect layers to improve the performance of traffic signs detection. A Convolutional Neural Network (CNN) achieved more accuracy, results based on a complex network. Our model learns from the GTSDB dataset, which contains 43 traffic classes, and uses this information to predict the proper class of an anonymous traffic sign with 99.81% accuracy and minimum losses. Contradictory, the result is improved than the earlier study, which examined 98.20% accuracy that the approach can still detect traffic signs with extreme weather conditions and blur image conditions.
C1 [Mishra, Jayant; Goyal, Sachin] UIT RGPV, Bhopal, MP, India.
C3 Rajiv Gandhi Technological University
RP Mishra, J (corresponding author), UIT RGPV, Bhopal, MP, India.
EM rgtu.jayant@gmail.com; sachingoyal@rgtu.net
CR Alghmgham D.A., 2019, Procedia Comput. Sci., V163, P266, DOI [10.1016/j.procs.2019.12.108, DOI 10.1016/J.PROCS.2019.12.108]
   [Anonymous], 2013, GERMAN TRAFFIC SIGN
   Arcos-García A, 2018, NEURAL NETWORKS, V99, P158, DOI 10.1016/j.neunet.2018.01.005
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Cao JW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19184021
   Cheng H, 2017, J IMAGING, V3, DOI 10.3390/jimaging3010006
   Dewi C, 2020, MULTIMED TOOLS APPL, V79, P32897, DOI 10.1007/s11042-020-09509-x
   Fu J, 2020, VEHICLE WHEEL DETECT
   Garcia-Garrido MA, 2006, IEEE INTELLIGENT TRA
   Ghosh R, 2021, MULTIMED TOOLS APPL, V80, P25985, DOI 10.1007/s11042-021-10954-5
   GUPTA H, 2021, MULTIMEDIA TOOLS APP
   He SH, 2021, IEEE ACCESS, V9, P43253, DOI 10.1109/ACCESS.2021.3059052
   Huang W, 2018, IOP C SER J PHYS C S
   Jiang Y, 2020, PLANT PHENOMICS, V2020, DOI 10.34133/2020/4152816
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Kaixuan Xie, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P201, DOI 10.1007/978-3-319-48890-5_20
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P27867, DOI 10.1007/s11042-021-10811-5
   KHERARBA M, 2021, LECT NOTES COMPUTER, V2629
   Koresh M. H. J. D., 2019, J INNOV IMAGE PROCES, V1, P11
   Laguna R., 2014, IFAC Proceedings Volumes, V47, P104, DOI DOI 10.3182/20140824-6-ZA-1003.00693
   Li WH, 2020, MULTIMED TOOLS APPL, V79, P16473, DOI 10.1007/s11042-019-7475-x
   Liang ZW, 2020, NEURAL COMPUT APPL, V32, P6533, DOI 10.1007/s00521-019-04086-z
   Liu Z, 2019, APPL INTELL
   Loukmane A, 2020, 2020 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES (ICDS), DOI 10.1109/icds50568.2020.9268761
   Mishra J., 2011, INT J MANAG INF TECH, V3, P9
   Nartey OT, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092684
   Natarajan S, 2018, IET INTELL TRANSP SY, V12, P1396, DOI 10.1049/iet-its.2018.5171
   Ngiam Jiquan, 2011, P 28 INT C MACH LEAR, P265
   Saadna Y, 2017, INT J MULTIMED INF R, V6, P193, DOI 10.1007/s13735-017-0129-8
   Saha S, 2019, EFFICIENT TRAFFIC SI
   Said Y, 2021, MULTIMED TOOLS APPL, V80, P14753, DOI 10.1007/s11042-021-10509-8
   Sajja TK, 2021, J AMB INTEL HUM COMP, V12, P9423, DOI 10.1007/s12652-020-02663-y
   Sarigul M, 2020, NEURAL PROCESS LETT, V51, P2839, DOI 10.1007/s11063-020-10233-8
   Satti S.K., 2020, J KING SAUD U COMPUT, P243
   Serna CG., 2021, IEEE ACCESS, V6, P78136, DOI 10.1109/ACCESS.2018.28848262018
   Shustanov A, 2017, PROCEDIA ENGINEER, V201, P718, DOI 10.1016/j.proeng.2017.09.594
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Sun C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226570
   Sun Y, 2019, CHIN AUTOM CONGR, P2851, DOI [10.1109/CAC48633.2019.8997240, 10.1109/cac48633.2019.8997240]
   Taki Y, 2021, LECT NOTES NETWORKS, V183, DOI 10.1007/978-3-030-66840-2_26
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Triki N, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P775, DOI 10.5220/0010239807750780
   Villaión-Sepúlveda G, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061207
   Wali SB, 2021, CURR TRENDS CHALLENG, DOI 10.3390/s19092093
   Wang GY, 2014, VISUAL COMPUT, V30, P539, DOI 10.1007/s00371-013-0879-0
   Wu YH, 2013, IEEE IJCNN
   Xing J., 2021, P INT S GEOMETRY VIS, VVolume 1386, P85, DOI 10.1007/978-3-030-72073-5_7
   Yifan Lu, 2018, Computational Visual Media, V4, P253, DOI 10.1007/s41095-018-0116-x
   Zeng YJ, 2017, IEEE T INTELL TRANSP, V18, P1647, DOI 10.1109/TITS.2016.2614916
   Zeng YJ, 2015, LECT NOTES COMPUT SC, V9242, P272, DOI 10.1007/978-3-319-23989-7_28
   Zhang JM, 2017, ALGORITHMS, V10, DOI 10.3390/a10040127
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 53
TC 5
Z9 5
U1 16
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18915
EP 18934
DI 10.1007/s11042-022-12531-w
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000767089800002
DA 2024-07-18
ER

PT J
AU Liu, Y
   Guo, YC
   Zhu, Y
   Yu, M
AF Liu, Yu
   Guo, Yingchun
   Zhu, Ye
   Yu, Ming
TI Mining semantic information from intra-image and cross-image for
   few-shot segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot segmentation; Intra-image; Cross-image; Self-attention
   relation; Co-attention
ID NETWORK
AB In recent years, few-shot segmentation has been proposed to alleviate the scarcity of pixel-wise labels, which performs segmentation on new categories using only a few annotated samples, while the problems of category-agnostic and low-data make few-shot segmentation very challenging. To address the task, we propose a new symmetric network, which mines semantic information from intra-image and cross-image in a holistic view and guides the segmentation of the paired images (i.e., the support image and the query image). We emphasize the importance of self-correlations in intra-image and inter-correlations in cross-image. Taking advantage of the provided labels, a self-attention relation module is proposed to transfer more category information for non-linear relation metrics by mining intra-image semantics. A co-attention module is designed to obtain common semantic information by exploring long-range dependencies of cross-image in spatial and channel dimensions, thus producing more precise segmentation results for the few-shot segmentation task. Experiments on two benchmark datasets (FSS-1000 and PASCAL-5(i)) show that the mean Intersection-over-Union scores of our method attain state-of-the-art performance.
C1 [Liu, Yu; Yu, Ming] Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.
   [Guo, Yingchun; Zhu, Ye; Yu, Ming] Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
C3 Hebei University of Technology; Hebei University of Technology
RP Yu, M (corresponding author), Hebei Univ Technol, Sch Elect & Informat Engn, Tianjin 300401, Peoples R China.; Yu, M (corresponding author), Hebei Univ Technol, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.
EM yuming@hebut.edu.cn
RI qian, chen/HSG-9475-2023; Zhu, Ye/HGB-2543-2022
FU National Natural Science Foundation of China [61806071, 62102129]; Major
   Research plan of the National Natural Science Foundation of China
   [91746207]; National Key R&D Program of China [2018YFC08]; Natural
   Science Foundation of Hebei Province [F2019202381, F2019202464,
   F2020202025, F2021202030]; Key Research and Development Program of
   Xinjiang Province [2020B03001]; Open Projects Program of National
   Laboratory of Pattern Recognition [201900043]; Technical Expert Project
   of Tianjin [19JCTPJC55800, 19JCTPJC57000]; Sci-tech Research Project of
   Higher Education of Hebei Province [QN2019207, QN2020185]
FX This research was supported by the National Natural Science Foundation
   of China under Grant 61806071 and 62102129, the Major Research plan of
   the National Natural Science Foundation of China under Grant 91746207,
   National Key R&D Program of China under Grant 2018YFC08, Natural Science
   Foundation of Hebei Province under Grants F2019202381, F2019202464,
   F2020202025 and F2021202030, Key Research and Development Program of
   Xinjiang Province under Grant 2020B03001, Open Projects Program of
   National Laboratory of Pattern Recognition under Grant 201900043,
   Technical Expert Project of Tianjin under Grants 19JCTPJC55800 and
   19JCTPJC57000, and Sci-tech Research Project of Higher Education of
   Hebei Province under Grant QN2019207 and QN2020185.
CR Boyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P763, DOI 10.1007/978-3-030-58598-3_45
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong N., 2018, BMVC, V4, P4
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gadekallu TR, 2021, COMPLEX INTELL SYST, V7, P1855, DOI 10.1007/s40747-021-00324-x
   Guolei Sun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P347, DOI 10.1007/978-3-030-58536-5_21
   Han MY, 2020, MULTIMED TOOLS APPL, V79, P11617, DOI 10.1007/s11042-019-08413-3
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He SR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174897
   Hong S, 2016, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2016.349
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu T, 2019, AAAI CONF ARTIF INTE, P8441
   Hui BY, 2019, IEEE INT CONF MULTI, P198, DOI 10.1109/ICMEW.2019.00041
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li X, 2020, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR42600.2020.00294
   Liu WD, 2020, PROC CVPR IEEE, P4164, DOI 10.1109/CVPR42600.2020.00422
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JS, 2016, ADV NEUR IN, V29
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Rakelly K., 2018, Few-shot segmentation propagation with guided networks
   Rakelly K., 2018, P ICLR WORKSH
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodner E, 2010, LECT NOTES COMPUT SC, V6376, P232
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shaban A, 2017, 1 SHOT LEARNING SEMA
   Shen T, 2018, AAAI C ARTIFICIAL IN, V32
   Siam M, 2019, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2019.00535
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smirnov EA, 2014, AASRI PROC, V6, P89, DOI 10.1016/j.aasri.2014.05.013
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vasan D, 2020, COMPUT SECUR, V92, DOI 10.1016/j.cose.2020.101748
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, NEURAL INFORM PROCES, P630
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Q, 2018, PROC CVPR IEEE, P6106, DOI 10.1109/CVPR.2018.00639
   Wu ZY, 2019, IEEE I CONF COMP VIS, P6658, DOI 10.1109/ICCV.2019.00676
   Yang K, 2021, ARXIV PREPRINT ARXIV
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zheng ZL, 2019, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2019.00683
NR 56
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18305
EP 18326
DI 10.1007/s11042-022-12096-8
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300002
DA 2024-07-18
ER

PT J
AU Maria, HH
   Jossy, AM
   Malarvizhi, G
   Jenitta, A
AF Maria, H. Heartlin
   Jossy, A. Maria
   Malarvizhi, G.
   Jenitta, A.
TI De-noising low dose CT images of the ovarian region using modified
   discrete wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LDCT; DWT; Lifting scheme; Denoising
ID SIGNAL
AB Computed Tomography (CT) is a medical imaging technique that is being prominently used in the healthcare domain to obtain a detailed view of the body for diagnostic purposes of various diseases. This form of medical imaging is associated with high ionizing radiations that are powerful enough to penetrate through the body to create images on the computer screen. But, multiple exposures to such high dose ionizing radiation could raise the chances of cancer and could be fatal for patients diagnosed with cancer. However, to reduce the radiation dosage associated with CT images, low-dose CT (LDCT) is being used for medical screening in recent days. The United States Preventive Services Task Force guidelines has revealed that LDCT screening reduces the mortality rate of patients and can be considered safe comparatively. But, as radiation dosage is reduced, LDCT images are corrupted with noise and artifacts which affect the visibility of the medical image. This in turn can affect the decision of the radiologists. Therefore, LDCT images are required to be de-noised before being used for diagnosis to improve the image quality and elevate visibility. This work is one such method where a combination of modified Discrete Wavelet Transform (DWT) and Goodness of Fit shrinkage (GoFShrink) thresholding technique is used to denoise the LDCT images to enhance the quality for diagnostic purposes. The modified DWT is associated with a lifting scheme that provides memory for in-place arithmetic operations, flexible factorization of the 2-channel filter banks as well as robustness with exact reversible reconstruction and enhances the performance of the wavelet transform (WT). The PSNR, MSE, SSIM, and SNR values of the de-noised images are calculated and a comparative analysis is performed with the conventional de-noising techniques. A comparative analysis between the various shrinkage techniques is also performed. The simulation results show an increase in PSNR and SNR values when compared with the conventional methods.
C1 [Maria, H. Heartlin; Jossy, A. Maria; Malarvizhi, G.] SRM Inst Sci & Technol, Chennai, Tamil Nadu, India.
   [Jenitta, A.] Idhaya Engn Coll Women, Chinnasalem, India.
C3 SRM Institute of Science & Technology Chennai
RP Maria, HH (corresponding author), SRM Inst Sci & Technol, Chennai, Tamil Nadu, India.
EM heartlim@srmist.edu.in
RI Jossy, Maria/AAE-9901-2021
OI Jossy, Maria/0000-0002-2136-129X; H, Heartlin Maria/0000-0001-8001-6923
CR Abramovich F, 1999, LECT NOTES STAT, V141, DOI 10.1007/978-1-4612-0567-8_3
   Acharya T, 2006, J VLSI SIG PROC SYST, V42, P321, DOI 10.1007/s11266-006-4191-3
   Acharya UK, 2020, OPTIK, V224, DOI 10.1016/j.ijleo.2020.165760
   [Anonymous], 2016, DIGIT SIGNAL PROCESS, DOI DOI 10.1007/978-3-319-25468-5_14
   Anumala V, 2017, LECT NOTE NETW SYST, V5, P157, DOI 10.1007/978-981-10-3226-4_15
   Anutam R., 2014, Int. J. Multimed. Its Appl, V6, P35, DOI [10.5121/ijma.2014.6303, DOI 10.5121/IJMA.2014.6303]
   Aravindan TE, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1069-4
   Bal A, 2019, MED BIOL ENG COMPUT, V57, P2567, DOI 10.1007/s11517-019-02014-w
   Biswas Mantosh, 2016, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V97, P1, DOI 10.1007/s40031-014-0167-z
   Chen BQ, 2019, J CENT SOUTH UNIV, V26, P120, DOI 10.1007/s11771-019-3987-9
   Chen XF, 2013, IEEE T INSTRUM MEAS, V62, P1354, DOI 10.1109/TIM.2012.2224277
   Diwakar M., 2019, HDB MULTIMEDIA INFOR
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Kaur R, 2018, MULTIMED TOOLS APPL, V77, P22735, DOI 10.1007/s11042-017-5500-5
   Lahmiri S, 2015, BIOMED ENG LETT, V5, P131, DOI 10.1007/s13534-015-0182-2
   Maria HH, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166883
   McNitt-Gray MF, 2015, TRANSL ONCOL, V8, P55, DOI 10.1016/j.tranon.2015.01.001
   Oudkerk M, 2021, NAT REV CLIN ONCOL, V18, P135, DOI 10.1038/s41571-020-00432-6
   Özmen G, 2018, NEURAL COMPUT APPL, V29, P263, DOI 10.1007/s00521-017-2995-7
   Park HS, 2019, IEEE ACCESS, V7, P110414, DOI 10.1109/ACCESS.2019.2934178
   Rehman NU, 2016, EUR SIGNAL PR CONF, P1548, DOI 10.1109/EUSIPCO.2016.7760508
   Remenyi N, 2013, MULTISCALE SIGNAL AN, DOI 10.1007/978-1-4614-4145-8_14
   Safari A, 2013, ADV MECH ELECT ENG, V178, DOI 10.1007/978-3-642-31528-2_71
   Satheeskumaran S, 2014, NATL ACAD SCI LETT, V37, P341, DOI 10.1007/s40009-014-0238-3
   Singh P, 2018, AUSTRALAS PHYS ENG S, V41, P891, DOI 10.1007/s13246-018-0685-0
   Vikhe P. S., 2009, Proceedings of the 2009 International Conference on Advances in Computing, Control, & Telecommunication Technologies (ACT 2009), P367, DOI 10.1109/ACT.2009.97
   Xiao F, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.749
   Yang Qiang, 2011, 2011 International Conference on Electronics and Optoelectronics (ICEOE 2011), P129, DOI 10.1109/ICEOE.2011.6013318
   Yasmeen Fauzia, 2021, SN Comput Sci, V2, P82, DOI 10.1007/s42979-021-00478-y
   Zhang Fengjun, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P1090
NR 30
TC 0
Z9 0
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17095
EP 17110
DI 10.1007/s11042-022-12529-4
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200015
DA 2024-07-18
ER

PT J
AU Ng, SM
   Yazid, H
   Mustafa, N
AF Ng, Suit Mun
   Yazid, Haniza
   Mustafa, Nazahah
TI Performance analysis on dictionary learning and sparse representation
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Super-resolution (SR); Dictionary learning; Sparse
   representation
ID SIGNAL RECOVERY; SUPERRESOLUTION; BIOMETRICS
AB Theoretically, the Super-Resolution (SR) reconstruction scheme is a method which is performed by many applications nowadays for the purpose of generating a High-Resolution (HR) image using the input Low-Resolution (LR) images by filling in the missing high frequency information. In addition, the SR reconstruction implemented based on the theory of sparse representation techniques is known as an effective way to produce HR images using images patches generated from the LR images. In order to improve the quality of denoised images produced by using the sparse representation techniques, a scheme called dictionary learning algorithms could be considered. Thus, the objective of this paper is to provide a performance comparison on the effectiveness of applying the dictionary learning steps with sparse representation algorithms in producing a better denoised image. In this case, the average Peak Signal-to-Noise ratio (PSNR) and Structural Similarity Index Metric (SSIM) values of the denoised image obtained by using Algorithms 1, 2, and 3 which combined the use of dictionary learning and sparse representation algorithms were compared with the values obtained from images produced by applying only sparse regularisation methods. As a conclusion, the denoised images produced by Algorithm 1 in this paper had the greatest average PSNR and SSIM values. Hence, the algorithm with the implementation of the dictionary learning process with sparse representation methods is able to achieve a better result in enhancing the low-resolution images.
C1 [Ng, Suit Mun] Univ Malaysia Perlis, Fac Elect Engn Technol, Kampus Pauh Putra, Perlis 02600, Arau, Malaysia.
   [Yazid, Haniza; Mustafa, Nazahah] Univ Malaysia Perlis, Fac Elect Engn Technol, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis
RP Yazid, H (corresponding author), Univ Malaysia Perlis, Fac Elect Engn Technol, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
EM hanizayazid@unimap.edu.my
RI Yazid, Haniza/D-3830-2015
FU Fundamental Research Grant Scheme (FRGS)
   [FRGS/1/2019/TK04/UNIMAP/02/23]; Ministry of Higher Education Malaysia
FX The authors would like to acknowledge the support from the Fundamental
   Research Grant Scheme (FRGS) under the grant number of
   FRGS/1/2019/TK04/UNIMAP/02/23 from the Ministry of Higher Education
   Malaysia.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alonso-Fernandez F, 2019, IEEE ACCESS, V7, P6519, DOI 10.1109/ACCESS.2018.2889395
   [Anonymous], 2018, Kaggle
   [Anonymous], 2001, Image Databases
   Bannore V, 2009, STUD COMPUT INTELL, V195, P1
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217
   Chalmers A, 2000, SIGGRAPH
   Chan SH, 2011, INT CONF ACOUST SPEE, P941
   Combettes PL, 2011, SPRINGER SER OPTIM A, V49, P185, DOI 10.1007/978-1-4419-9569-8_10
   Deng QY, 2019, SIGNAL PROCESS, V157, P280, DOI 10.1016/j.sigpro.2018.12.007
   Trinh DH, 2014, IEEE T IMAGE PROCESS, V23, P1882, DOI 10.1109/TIP.2014.2308422
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Ekanadham C, 2011, IEEE T SIGNAL PROCES, V59, P4735, DOI 10.1109/TSP.2011.2160058
   Goyal M, 2015, INT J ADV RES ENG AP, V5, P108
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Huang GaryB., 2007, Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Jiang CH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27261-z
   KANAFIAH SNA, 2018, J BIOMIMETICS BIOMAT
   Nguyen K, 2018, PATTERN RECOGN, V78, P23, DOI 10.1016/j.patcog.2018.01.002
   Li J, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103171
   Li SJ, 2015, IEEE T IMAGE PROCESS, V24, P4240, DOI 10.1109/TIP.2015.2459653
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Haut JM, 2018, IEEE T GEOSCI REMOTE, V56, P6792, DOI 10.1109/TGRS.2018.2843525
   Messai M, 2019, SIGNAL PROCESS, V157, P73, DOI 10.1016/j.sigpro.2018.11.007
   MMU, 2020, IR DAT
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Niu B., 2020, EUR C COMP VIS, P191, DOI [10.1007/978-3-030-58610-2_47, DOI 10.1007/978-3-030-58610-2_12]
   Peyre, 2019, NUMERICAL TOUR DATA
   Rambhatla S, 2019, 7 INT C LEARN REPR I
   Rasti P, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON AEROSPACE ELECTRONICS AND REMOTE SENSING TECHNOLOGY (ICARES), P185, DOI 10.1109/ICARES.2014.7024405
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Selesnick I, 2017, IEEE T SIGNAL PROCES, V65, P4481, DOI 10.1109/TSP.2017.2711501
   Shehu Y. I., 2018, Sokoto coventry fingerprint dataset
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Umehara K, 2018, J DIGIT IMAGING, V31, P441, DOI 10.1007/s10278-017-0033-z
   Umehara K, 2017, PROC SPIE, V10133, DOI 10.1117/12.2249969
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yue LW, 2016, SIGNAL PROCESS, V128, P389, DOI 10.1016/j.sigpro.2016.05.002
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang Z, 2015, IEEE ACCESS, V3, P490, DOI 10.1109/ACCESS.2015.2430359
NR 42
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16455
EP 16476
DI 10.1007/s11042-022-12375-4
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256300005
DA 2024-07-18
ER

PT J
AU Gasch, C
   Sotoca, JM
   Chover, M
   Remolar, I
   Rebollo, C
AF Gasch, Cristina
   Martinez Sotoca, Jose
   Chover, Miguel
   Remolar, Inmaculada
   Rebollo, Cristina
TI Procedural modeling of plant ecosystems maximizing vegetation cover
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimization; Inequality systems; Plant ecosystem; Procedural
   distribution; Botanical constraints; Visual Realism
ID COMPETITIVE ASYMMETRY; GROWTH
AB Vegetation plays a major role in the realistic display of outdoor scenes. However, manual plant placement can be tedious. For this reason this paper presents a new proposal in the field of procedural modeling of natural scenes. This method creates plant ecosystems that maximizes the covered space by optimizing an objective function subject to a series of constraints defined by a system of inequalities. This system includes the constraints of the environment taking into account characteristics of the terrain and the plant species involved. Once the inequality system has been defined, a solution will be obtained that tries to maximize the radius of the projected area of the trees and therefore the extension of the vegetation cover on the ground. The technique eliminates the trees that do not achieve a minimum growth radius, simulating the typical competitive process of nature. Results show the good performance and the high visual quality of the ecosystems obtained by the proposed technique. The use of this kind of optimization techniques could be used to solve other procedural modeling problems in other fields of application.
C1 [Gasch, Cristina; Martinez Sotoca, Jose; Chover, Miguel; Remolar, Inmaculada; Rebollo, Cristina] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
C3 Universitat Jaume I
RP Remolar, I (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana 12006, Spain.
EM cgasch@uji.es; sotoca@uji.es; chover@uji.es; remolar@uji.es;
   rebollo@uji.es
RI Rebollo Santamaría, Cristina/T-1272-2017; Remolar Quintana,
   Inmaculada/T-1268-2017
OI Rebollo Santamaría, Cristina/0000-0002-1328-2110; Remolar Quintana,
   Inmaculada/0000-0002-7743-2579; Gasch, Cristina/0000-0003-2013-2839
FU CRUE-CSIC agreement; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR Aikio S, 2004, OIKOS, V104, P51, DOI 10.1111/j.0030-1299.2004.12083.x
   Aikio S, 2003, OIKOS, V100, P283, DOI 10.1034/j.1600-0706.2003.11814.x
   Alsweis M, 2006, LECT NOTES COMPUT SC, V4035, P1
   Alsweis Monssef, 2005, EurographicsWorkshop on Natural Phenomena, P83
   Andújar C, 2014, COMPUT GRAPH FORUM, V33, P101, DOI 10.1111/cgf.12281
   [Anonymous], 1996, The Algorithmic Beauty of Plants
   [Anonymous], 2021, ARBOLAPP ES
   Bauer S, 2002, P ROY SOC B-BIOL SCI, V269, P2443, DOI 10.1098/rspb.2002.2186
   Benes B., 2011, S INTERACTIVE 3D GRA, P167
   Benes Bedrich., 2009, Eurographics Workshop on Natural Phenomena, P9
   Bravo F, 1997, ECOLOG A, V11, P177
   Chauchard L., 2001, Bosque, V22, P3
   Cordonnier G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073667
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Damgaard C, 2002, J ECOL, V90, P666, DOI 10.1046/j.1365-2745.2002.00700.x
   de G., BIOMETRICS FOREST GR
   Deussen O., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P275, DOI 10.1145/280814.280898
   Dietrich A, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P169
   FIRBANK LG, 1985, J THEOR BIOL, V116, P291, DOI 10.1016/S0022-5193(85)80269-1
   FLOYD RW, 1976, P SID, V17, P75
   Gain J, 2017, COMPUT GRAPH FORUM, V36, P63, DOI 10.1111/cgf.13107
   Galin E, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13657
   Games V., 2021, LANDSCAPE AUTOMATERI
   Gasch C, 2017, SPAN COMP GRAPH C CE, P131
   Gasch C, 2020, MULTIMED TOOLS APPL, V79, P31125, DOI 10.1007/s11042-020-09476-3
   Gimeno V, 2020, J INEQUAL APPL, V2020, DOI 10.1186/s13660-020-02362-4
   Griffon S, 2011, VIRTUAL REAL-LONDON, V15, P279, DOI 10.1007/s10055-010-0160-z
   Grigore SV, 2017, P INT C HUM COMP INT, P159
   Lagae A, 2008, COMPUT GRAPH FORUM, V27, P114, DOI 10.1111/j.1467-8659.2007.01100.x
   Lane B, 2002, PROC GRAPH INTERF, P69
   Li J, 2018, ISPRS INT J GEO-INF, V7
   Makowski M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323039
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Onrust B, 2017, INT J COMPUT GAMES T, V2017, DOI 10.1155/2017/7057141
   Onrust B, 2015, WEB3D 2015, P133, DOI 10.1145/2775292.2775306
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pretzsch H, 2012, ECOL STUD-ANAL SYNTH, V220, P287, DOI 10.1007/978-3-642-30645-7_13
   Pretzsch H, 2015, URBAN FOR URBAN GREE, V14, P466, DOI 10.1016/j.ufug.2015.04.006
   Rebollo C, 2004, LECT NOTES COMPUT SC, V3044, P703
   Rietkerk M, 2008, TRENDS ECOL EVOL, V23, P169, DOI 10.1016/j.tree.2007.10.013
   Smelik RM, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12276
   Temmerman S, 2007, GEOLOGY, V35, P631, DOI 10.1130/G23502A.1
   Weier M, 2013, J VIRT REALITY BROAD, V10, P1860
   Zegers CD, 1997, ECOLOGIA FORESTAL BO
NR 44
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16195
EP 16217
DI 10.1007/s11042-022-12107-8
EA MAR 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763256600015
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Dawood, H
   Daud, A
   Dawood, H
   Azhar, M
AF Dawood, Hussain
   Daud, Ali
   Dawood, Hassan
   Azhar, Marium
TI Reduction of random-valued impulse noise by using multi-structured
   textons
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texton; Impulse noise; Random-valued impulse noise; Multi-structured
   texton; Biomedical images; Directional similarity; Reflectional symmetry
ID MEDIAN FILTERS; REMOVAL
AB In this paper, an iterative two-stage image denoising technique based on multi-structured textons for noise identification while spatially linked directional similarity for noise restoration (MTNI-SDSNR) is presented for the denoising of random-valued impulse noise (RVIN). Multiple textons oriented at various directions of a sliding window are proposed for the identification of noisy pixels, via an adaptable threshold range computed from their local statistics. Whereas the spatially similar noise-free pixels in the 4 spatially linked directional neighboring pixels obtained by computing the local similarity among them, are used for noise restoration. As the textons are elementary for texture perception, so they are proposed to be oriented based on reflectional symmetry to ensure the effective preservation of salient edges. The proposed MTNI-SDSNR is compared with state-of-the-art denoising methods using standard benchmark grayscale and biomedical images taken from MedPix dataset, by corrupting them with various RVIN intensities. The supremacy of proposed method with similar benchmark RVIN denoising methods can be depicted in quantitative results by showing an increment of 2% (on average) in the values of Peak-signal-to-noise-ratio (PSNR), structural similarity index measurement (SSIM). The visual results represent the edge-preserving capability for both lower and higher intensities of random noise.
C1 [Dawood, Hussain; Daud, Ali] Univ Jeddah, Coll Comp Sci & Engn, Dept Comp & Network Engn, Jeddah, Saudi Arabia.
   [Dawood, Hassan] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
   [Azhar, Marium] Univ Wah, Dept Comp Sci, Quaid Ave, Wah Cantt, Pakistan.
C3 University of Jeddah; University of Engineering & Technology Taxila
RP Dawood, H (corresponding author), Univ Jeddah, Coll Comp Sci & Engn, Dept Comp & Network Engn, Jeddah, Saudi Arabia.
EM hdaoud@uj.edu.sa
RI Dawood, Hassan/AAZ-8114-2021; Daud, Ali/ABA-8422-2020; Dawood,
   Hussain/G-7453-2017
OI Dawood, Hassan/0000-0003-1355-6457; Daud, Ali/0000-0002-8284-6354;
   Dawood, Hussain/0000-0003-2653-9541
FU University of Jeddah, Saudi Arabia [UJ-20-054-DR]
FX The work was funded by the University of Jeddah, Saudi Arabia under
   Grant No (UJ-20-054-DR). The authors, therefore, acknowledge with thanks
   the university's technical and financial support.
CR Akkoul S, 2010, IEEE SIGNAL PROC LET, V17, P587, DOI 10.1109/LSP.2010.2048646
   [Anonymous], 2018, J AMBIENT INTELLIGEN
   Azhar M, 2018, J AMB INTEL HUM COMP, P1
   Azhar M, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033028
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen DF, 2020, MED BIOL ENG COMPUT, V58, P131, DOI 10.1007/s11517-019-02069-9
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Dawood Hussain, 2015, 2015 Asia Pacific Conference on Multimedia and Broadcasting (APMediaCast). Proceedings, P1, DOI 10.1109/APMediaCast.2015.7210268
   Dawood H, 2017, INT ARAB J INF TECHN
   Dawood H, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.2.023103
   Dawood H, 2015, MULTIMED TOOLS APPL, V74, P11485, DOI 10.1007/s11042-014-2246-1
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   GRUBBS FE, 1969, TECHNOMETRICS, V11, P1, DOI 10.2307/1266761
   Habib M, 2015, APPL SOFT COMPUT, V29, P471, DOI 10.1016/j.asoc.2015.01.010
   HosseinKhani Z, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1074-7
   Hussain A, 2017, MULTIMED TOOLS APPL, V76, P22001, DOI 10.1007/s11042-017-4757-z
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Iqbal N, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030395
   Jena B, 2018, INT J ROUGH SETS DAT, V5, P148, DOI DOI 10.4018/IJRSDA.2018040108
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Jin QY, 2020, INVERSE PROBL IMAG, V14, P171, DOI 10.3934/ipi.2020009
   JULESZ B, 1986, BIOL CYBERN, V54, P245, DOI 10.1007/BF00318420
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kang M, 2019, MULTIDIM SYST SIGN P, V30, P1063, DOI 10.1007/s11045-018-0587-z
   Karthik B, 2021, J AMB INTEL HUM COMP, V12, P3901, DOI 10.1007/s12652-020-01737-1
   Khan NU, 2020, MULTIMED TOOLS APPL, V79, P33811, DOI 10.1007/s11042-020-08707-x
   Kumar S, 2020, IEEE IJCNN, DOI [10.1109/IRMMW-THz46771.2020.9370950, 10.1109/ijcnn48605.2020.9207482]
   Li GY, 2020, PATTERN ANAL APPL, V23, P1263, DOI 10.1007/s10044-020-00871-y
   Lin C, 2020, IEEE ACCESS, V8, P222001, DOI 10.1109/ACCESS.2020.3040760
   Ma CB, 2019, MULTIMED TOOLS APPL, V78, P1131, DOI 10.1007/s11042-018-6442-2
   Marudhachalam R, 2020, AIP C P, V2270
   Murugan K, 2018, CLUSTER COMPUT, P1
   Nadeem M, 2020, SIGNAL PROCESS, V169, DOI 10.1016/j.sigpro.2019.107403
   Patel Punyaban, 2021, Intelligent System Design. Proceedings of Intelligent System Design: INDIA 2019. Advances in Intelligent Systems and Computing (AISC 1171), P759, DOI 10.1007/978-981-15-5400-1_72
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Rao GS, 2018, INT C ISMAC COMP VIS, P355
   Soleimany S, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P165, DOI 10.1109/RIOS.2017.7956461
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Turkmen I, 2016, J VIS COMMUN IMAGE R, V34, P28, DOI 10.1016/j.jvcir.2015.10.011
   Turkmen I, 2013, AEU-INT J ELECTRON C, V67, P771, DOI 10.1016/j.aeue.2013.03.006
   Veerakumar T, 2019, EXPERT SYST APPL, V121, P18, DOI 10.1016/j.eswa.2018.12.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2014, SIGNAL PROCESS, V103, P45, DOI 10.1016/j.sigpro.2014.01.007
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Xu S., 2005, J ELECTRON IMAGING, V27
   Xu YD, 2011, J NUCL MED, V52, P2009, DOI 10.2967/jnumed.111.092965
NR 49
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15303
EP 15331
DI 10.1007/s11042-022-12578-9
EA FEB 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600004
DA 2024-07-18
ER

PT J
AU Tang, QS
   Feng, XX
   Zhang, XD
AF Tang, Qingsong
   Feng, Xiaoxu
   Zhang, Xiangde
TI A spatial feature adaptive network for text detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text detection; Desubpixel convolution; Convolution neural network;
   Spatial adaptive convolutional network
AB Due to the capacity of detection arbitrary shapes of text and the robustness in practical applications, scene text detection methods based on segmentation have attached more attention. More accurate segmentation and better feature extraction are the core of segmentation-based detection. In order to refine the result of segmentation, we replace the convolution in the first block of the ResNet50 by desubpixel convolution to enhance the feature extraction capabilities of the network. We also propose a spatial adaptive convolutional network to adjust the features extracted by the backbone so that the network can extract features more suitable for natural scene text detection. We implement the presented network based on PSENet. The results on ICDAR2015 and SCUT-CTW1500 demonstrate that our module can improve the performance of text detection. The precision, recall and F-measure have reached 87.27%, 84.88% and 86.06% on ICDAR2015. And they have reached 81.99%, 82.63% and 82.31% on CTW1500. Our code will be available at https://github.com/fengdashuai/Ada-PSENet.
C1 [Tang, Qingsong; Feng, Xiaoxu; Zhang, Xiangde] Northeastern Univ, Coll Sci, Shenyang, Peoples R China.
C3 Northeastern University - China
RP Tang, QS (corresponding author), Northeastern Univ, Coll Sci, Shenyang, Peoples R China.
EM tangqs@mail.neu.edu.cn; fengxiaoxu_1234@163.com;
   zhangxiangde@mail.neu.edu.cn
CR Busta M, 2015, IEEE I CONF COMP VIS, P1206, DOI 10.1109/ICCV.2015.143
   Chen H, 2017, MED IMAGE ANAL, V36, P135, DOI 10.1016/j.media.2016.11.004
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Gao H., 2020, IEEE ACCESS, P99
   Guan HY, 2016, IEEE GEOSCI REMOTE S, V13, P520, DOI 10.1109/LGRS.2016.2521684
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao MH, 2020, AAAI CONF ARTIF INTE, V34, P11474
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P494, DOI 10.1109/TPAMI.2019.2894422
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Vu T, 2019, LECT NOTES COMPUT SC, V11133, P243, DOI 10.1007/978-3-030-11021-5_16
   Wang WH, 2019, IEEE I CONF COMP VIS, P8439, DOI 10.1109/ICCV.2019.00853
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Yuliang L., 2017, ARXIV171202170
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu YX, 2018, INT C PATT RECOG, P3735, DOI 10.1109/ICPR.2018.8545067
NR 39
TC 1
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15285
EP 15302
DI 10.1007/s11042-022-12619-3
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000761747600001
DA 2024-07-18
ER

PT J
AU Deng, YP
   Liu, Q
   Ikenaga, T
AF Deng, Yipeng
   Liu, Qin
   Ikenaga, Takeshi
TI Attention-guided network with inverse tone-mapping guided up-sampling
   for HDR imaging of dynamic scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
AB The Ghost-like artifact caused by motion and ill-exposed areas is one of the most challenging problems in high dynamic range (HDR) image reconstruction. Previous deep learning methods produce HDR results with high-quality in challenging scenes where large foreground motions exist via complicated network design. However, they are too resource-consuming when the resolution of the input image is large. To this end, an attention-guided network with inverse tone-mapping guided up-sampling is proposed for improving the efficiency. The proposed network consists of two main modules: fusion module (SK-AHDRNet) and inverse tone-mapping guided up-sampling module. In the fusion module, low-resolution low dynamic range (LDR) images are used to obtain low-resolution HDR via an attention guided network. In the up-sampling module, inverse tone-mapping is adopted to generate the High-resolution HDR from the reference image that guides the generation of the final HDR result. The proposed fusion module scores 43.17 with PSNR metric and 61.02 with HDR-VDP-2 metric on test which outperforms all conventional works. Compared with the plain fusion module, the running time of up-sampling network is reduced by 81.5% while the PSNR value is decreased from 43.17 to 38.18 with of the original resolution.
C1 [Deng, Yipeng; Liu, Qin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Deng, Yipeng; Ikenaga, Takeshi] Waseda Univ, Grad Sch IPS, Kitakyushu, Fukuoka, Japan.
C3 Nanjing University; Waseda University
RP Liu, Q (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM dengyipeng@asagi.waseda.jp; qinliu@nju.edu.cn; ikenaga@waseda.jp
OI LIU, Qin/0000-0002-1064-2221
FU Grants-in-Aid for Scientific Research [21K11816] Funding Source: KAKEN
CR Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   Deng YP, 2021, INT C PATT RECOG, P8976, DOI 10.1109/ICPR48806.2021.9412973
   Deng YP, 2020, PROC SPIE, V11519, DOI 10.1117/12.2572977
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Fan HQ, 2018, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2018.00118
   Granados M, 2010, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2010.5540208
   Heidrich Wolfgang, ERIK REINHARD
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Huo YQ, 2014, VISUAL COMPUT, V30, P507, DOI 10.1007/s00371-013-0875-4
   Ji YZ, 2018, NEUROCOMPUTING, V322, P130, DOI 10.1016/j.neucom.2018.09.061
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   King DB, 2015, ACS SYM SER, V1214, P1
   Kovaleski RP, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P49, DOI 10.1109/SIBGRAPI.2014.29
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Masia B, 2017, MULTIMED TOOLS APPL, V76, P631, DOI 10.1007/s11042-015-3036-0
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Nayar SK, 2000, PROC CVPR IEEE, P472, DOI 10.1109/CVPR.2000.855857
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Prabhakar K. Ram, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P497, DOI 10.1007/978-3-030-58589-1_30
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Tocci MD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964936
   Tumblin J, 2005, PROC CVPR IEEE, P103
   Vaswani A, 2017, ADV NEUR IN, V30
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HK, 2018, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2018.00197
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yu F., 2015, ARXIV
   Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x
NR 35
TC 1
Z9 1
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12925
EP 12944
DI 10.1007/s11042-021-11717-y
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973300001
DA 2024-07-18
ER

PT J
AU Agrawal, R
   Kulkarni, S
   Walambe, R
   Deshpande, M
   Kotecha, K
AF Agrawal, Ranjana
   Kulkarni, Sucheta
   Walambe, Rahee
   Deshpande, Madan
   Kotecha, Ketan
TI Deep dive in retinal fundus image segmentation using deep learning for
   retinopathy of prematurity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Retinopathy of prematurity; Segmentation; U-net;
   Demarcation line; Ridge
AB Segmentation of retinal structures, namely optic disc, vessel, demarcation line, and ridge, is essential for describing the characteristics of Retinopathy of Prematurity (ROP). Computerized systems are being developed for automatic segmentation in fundus images to assist the medical experts and bring consistency in the diagnosis. There are multiple challenges in the segmentation task of premature infants' fundus images. The annotation and ground truth preparation required for the segmentation is complex, challenging, and expensive. Further, ROP datasets are not available publicly, and hence carrying out such a task needs a primary dataset and significant assistance from the domain expert. To address this gap, two primary datasets named HVDROPDB-BV and HVDROPDB-RIDGE were developed. The datasets consist of images captured by two different imaging systems, having different sizes, resolutions, and illumination. This made the trained models generic and robust to data variability and heterogeneity. We propose the modified U-Net architectures by incorporating squeeze and excitation (SE) blocks and attention gates (AG) to segment the demarcation line/ridge and vessel from these datasets. These modifications were tested and validated by ROP experts. The performance of all the three networks (U-Net, AG U-Net, and SE U-Net) was promising, with a variation of 1 to 6% in the dice coefficient for the HVDROPDB datasets. The area under the curve (AUC) obtained for all three networks was above 0.94, indicating them as excellent models. AG U-Net outperformed the other two networks, with a sensitivity of 96% and specificity of 89% for stage detection via new test images.
C1 [Agrawal, Ranjana; Walambe, Rahee; Kotecha, Ketan] Symbiosis Int Deemed Univ SIU, Symbiosis Inst Technol SIT, Pune, Maharashtra, India.
   [Agrawal, Ranjana] Dr Vishwanath Karad MIT World Peace Univ, Pune, Maharashtra, India.
   [Kulkarni, Sucheta; Deshpande, Madan] PBMAs HV Desai Eye Hosp, Pune, Maharashtra, India.
   [Walambe, Rahee; Kotecha, Ketan] Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence SCAAI, Pune, Maharashtra, India.
C3 Symbiosis International University; Symbiosis Institute of Technology
   (SIT); Dr. Vishwanath Karad MIT World Peace University; Symbiosis
   International University
RP Kotecha, K (corresponding author), Symbiosis Int Deemed Univ SIU, Symbiosis Inst Technol SIT, Pune, Maharashtra, India.; Kotecha, K (corresponding author), Symbiosis Int Deemed Univ, Symbiosis Ctr Appl Artificial Intelligence SCAAI, Pune, Maharashtra, India.
EM director@sitpune.edu.in
RI Walambe, Rahee/AAR-8150-2021; Kotecha, K/U-3927-2017
OI Walambe, Rahee/0000-0003-1745-5231; Kulkarni,
   Sucheta/0000-0002-3217-8108; Kotecha, K/0000-0003-2653-3780; Agrawal,
   Ranjana/0000-0002-7082-596X
CR Agrawal R, 2021, LIB PHILOS PRACT, P1
   Agrawal R, 2021, J DIGIT IMAGING, V34, P932, DOI 10.1007/s10278-021-00477-8
   Ahmed, 2020, MED IMAGE SEGMENTATI
   Brown JM, 2018, JAMA OPHTHALMOL, V136, P803, DOI 10.1001/jamaophthalmol.2018.1934
   Chen C, 2020, FRONT CARDIOVASC MED, V7, DOI 10.3389/fcvm.2020.00025
   Chen CH, 2021, IEEE ACCESS, V9, P111985, DOI 10.1109/ACCESS.2021.3102176
   Chen GZ, 2019, LECT NOTES COMPUT SC, V11855, P173, DOI 10.1007/978-3-030-32956-3_21
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Ding A., 2020, 2020 International Joint Conference on Neural Networks (IJCNN), P1
   Du GT, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.2.020508
   Gojic Gorana, 2020, 2020 IEEE 18th International Symposium on Intelligent Systems and Informatics (SISY), P131, DOI 10.1109/SISY50555.2020.9217082
   Gole GA, 2005, ARCH OPHTHALMOL-CHIC, V123, P991, DOI 10.1001/archopht.123.7.991
   Guan Q., 2018, ARXIV PREPRINT ARXIV
   Harouni M., 2018, ENCY IMAGE PROCESSIN, V95
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JJ, 2019, IEEE T MED IMAGING, V38, P269, DOI 10.1109/TMI.2018.2863562
   Huang YP, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091444
   Imran A, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2935912
   Jetley S., 2018, P INT C LEARN REPR
   Lei BY, 2021, MULTIMED TOOLS APPL, V80, P36341, DOI 10.1007/s11042-021-11208-0
   Milletari F., 2018, THESIS TU MUNCHEN
   Mittal K, 2020, MULTIMED TOOLS APPL, V79, P22389, DOI 10.1007/s11042-020-09041-y
   Molinari Andrea, 2017, Community Eye Health, V30, P55
   Mulay S, 2019, PROC SPIE, V10950, DOI 10.1117/12.2512719
   Murki Srinivas, 2018, Community Eye Health, V31, pS11
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Siddique N., 2020, U NET ITS VARIANTS M
   Singh N., 2020, ADV MATH SCI J, V9, P3827, DOI DOI 10.37418/AMSJ.9.6.62
   Soomro TA, 2019, IEEE ACCESS, V7, P71696, DOI 10.1109/ACCESS.2019.2920616
   Tan LZ, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.6.23
   Taylor S, 2019, JAMA OPHTHALMOL, V137, P1022, DOI 10.1001/jamaophthalmol.2019.2433
   Tiwari S. S., 2020, C INT SYST, P275
   Tong Y, 2020, EYE VISION, V7, DOI 10.1186/s40662-020-00183-6
   Khanh TLB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10175729
   Uysal E, 2021, MULTIMED TOOLS APPL, V80, P3505, DOI 10.1007/s11042-020-09372-w
   Vijayalakshmi C, 2020, TELEMED E-HEALTH, V26, P354, DOI 10.1089/tmj.2019.0004
   Wang J., 2021, ARXIV PREPRINT ARXIV
   Yu Y, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00546-6
NR 44
TC 9
Z9 9
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11441
EP 11460
DI 10.1007/s11042-022-12396-z
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400005
DA 2024-07-18
ER

PT J
AU Alipour-Vaezi, M
   Tavakkoli-Moghaddam, R
   Mohammadnazari, Z
AF Alipour-Vaezi, M.
   Tavakkoli-Moghaddam, R.
   Mohammadnazari, Z.
TI Optimization of a television advertisement scheduling problem by
   multi-criteria decision making and dispatching rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Advertisement effectiveness; Television advertising; Optimization;
   Scheduling; Multi-attribute decision making
ID SUPPLY CHAIN; TV; COMMERCIALS; EFFICIENT; RETAILER; SYSTEM
AB To increase brand awareness, there is no doubt that advertisement can pave the path. This is due mainly to its impact on buyers' decisions and is regarded as advertisement effectiveness. The more effective the advertisement, the steeper its revenue increase. Among all the advertising ways, television is enumerated as one of the most eminent ones. This study focuses on the scheduling problem for a television advertisement. This paper presents a scheduling problem considering Multi-Attribute Decision Making (MADM) and multi-objective mathematical models. In the first stage, the effectiveness of different categories of advertisements in multifarious timeslots is obtained using a hybrid MADM method, namely the Best-Worst Method (BWM) and Weighted Aggregated Sum Product Assessment (WASPAS). In the second stage, we use the weights mentioned above as an input for a multi-objective mathematical model to maximize the display effectiveness of advertisements in line by maximizing the total income. In the last step, the advertisement scheduling is scrutinized using several dispatching rules. The validity of the proposed methodology for identifying the best advertisements' planning is discussed using three test problems. The results of all test problems as mentioned above and their comparison with the presented real-life case study show that the proposed methodology highlights an optimal solution.
C1 [Alipour-Vaezi, M.; Tavakkoli-Moghaddam, R.; Mohammadnazari, Z.] Univ Tehran, Sch Ind Engn, Coll Engn, Tehran, Iran.
C3 University of Tehran
RP Tavakkoli-Moghaddam, R (corresponding author), Univ Tehran, Sch Ind Engn, Coll Engn, Tehran, Iran.
EM tavakoli@ut.ac.ir
RI Tavakkoli-Moghaddam, Reza/P-1948-2015; Alipour-Vaezi,
   Mohammad/AEV-7550-2022
OI Tavakkoli-Moghaddam, Reza/0000-0002-6757-926X; Alipour-Vaezi,
   Mohammad/0000-0002-7529-1848
CR Alipour Vaezi M., 2020, J IND SYSTEMS ENG, V13, P35
   Alipour-Vaezi M, 2022, SOFT COMPUT, V26, P2883, DOI 10.1007/s00500-021-06609-0
   [Anonymous], 1986, MARKETING SCI
   Bansal N, 2017, J SCHEDULING, V20, P239, DOI 10.1007/s10951-015-0466-5
   Benoist T, 2007, EUR J OPER RES, V176, P1371, DOI 10.1016/j.ejor.2005.09.027
   Bergquist Sharon H, 2020, SN Compr Clin Med, V2, P1349, DOI [10.1145/3384441.3395981, 10.1007/s42399-020-00453-3]
   Bollapragada S, 2004, OPER RES, V52, P337, DOI 10.1287/opre.1030.0083
   Chaab J, 2016, COMPUT IND ENG, V99, P112, DOI 10.1016/j.cie.2016.07.007
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Deane J, 2012, OMEGA-INT J MANAGE S, V40, P562, DOI 10.1016/j.omega.2011.11.001
   Díaz-Núñez F, 2019, OPTIM LETT, V13, P81, DOI 10.1007/s11590-018-1251-0
   Farshbaf-Geranmayeh A, 2018, J OPTIMIZ THEORY APP, V176, P509, DOI 10.1007/s10957-018-1217-5
   Guitart IA, 2019, J ACAD MARKET SCI, P1
   Gupta H, 2018, SCI TOTAL ENVIRON, V633, P122, DOI 10.1016/j.scitotenv.2018.03.173
   Hou SJ, 2018, MULTIMED TOOLS APPL, V77, P25475, DOI 10.1007/s11042-018-5801-3
   Karray S, 2015, INT J PROD RES, V53, P88, DOI 10.1080/00207543.2014.925602
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Lim J, 2008, MULTIMED TOOLS APPL, V36, P11, DOI 10.1007/s11042-006-0079-2
   Luo JK, 2020, INTELL DATA ANAL, V24, P581, DOI 10.3233/IDA-194641
   Mamoudan MM, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03585-z
   Martín-Herrán G, 2017, J BUS RES, V78, P93, DOI 10.1016/j.jbusres.2017.05.002
   Masoumi M, 2022, J HUMANIT LOGIST SUP, V12, P182, DOI 10.1108/JHLSCM-12-2020-0119
   Mohammadnazari Z, 2021, ENVIRON DEV SUSTAIN, V23, P10937, DOI 10.1007/s10668-020-01095-0
   PANWALKAR SS, 1977, OPER RES, V25, P45, DOI 10.1287/opre.25.1.45
   Purnamawati S, 2018, J PHYS CONF SER, V978, DOI 10.1088/1742-6596/978/1/012113
   Ren JZ, 2018, CHEMOSPHERE, V191, P747, DOI 10.1016/j.chemosphere.2017.10.053
   Rezaei J, 2018, TRANSPORT POLICY, V68, P158, DOI 10.1016/j.tranpol.2018.05.007
   Rezaei J, 2015, OMEGA-INT J MANAGE S, V53, P49, DOI 10.1016/j.omega.2014.11.009
   Salimi N, 2018, EVAL PROGRAM PLANN, V66, P147, DOI 10.1016/j.evalprogplan.2017.10.002
   Shi Y, 2019, J INTERACT MARK, V48, P120, DOI 10.1016/j.intmar.2019.05.005
   SIMON H, 1982, J MARKETING RES, V19, P352, DOI 10.2307/3151569
   Tari FG, 2013, INT J PROD RES, V51, P4921, DOI 10.1080/00207543.2013.778431
   Tavakkoli-Moghaddam R., 2020, IFIP INT C ADV PROD
   Vásquez OC, 2015, OPTIM LETT, V9, P663, DOI 10.1007/s11590-014-0758-2
   Velusamy S, 2008, MULTIMEDIA SYST, V14, P73, DOI 10.1007/s00530-008-0117-1
   Zavadskas EK, 2012, ELEKTRON ELEKTROTECH, V122, P3, DOI 10.5755/j01.eee.122.6.1810
NR 36
TC 4
Z9 4
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11755
EP 11772
DI 10.1007/s11042-022-12027-7
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400010
DA 2024-07-18
ER

PT J
AU Öztekin, A
   Ertugrul, ÖF
   Aldemir, E
   Acar, E
AF Oztekin, Abdulkerim
   Ertugrul, Omer Faruk
   Aldemir, Erdogan
   Acar, Emrullah
TI Determining the most relevant frequency bands in motion identification
   by accelerometer sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Frequency band; Feature extraction; Feature
   selection
ID EXTREME LEARNING-MACHINE; ACTIVITY RECOGNITION; PATTERNS
AB Sensors embedded in wearable technologies and smartphones provide a massive amount of data that has huge potential to be exploited in human motion identification/authentication systems. The accelerometer is one of the most common sensors that hold significant information about human actions. Acceleration signals show distinctive characteristics in time and frequency domains. In this study, public dataset consisting of eighteen diverse human activities is analyzed in wavelet subband space, and the resulting features are employed for classification by the Randomized Neural Network (RNN). The goal of this research is to determine the unique and dominant characteristics of each physical activity. This study proposes a methodology that combines RNN and wavelet-subband features to improve the achievement of human action recognition systems. The contribution resides in enlarging the application of human action recognition systems by employing robust classification and feature extraction techniques utilizing subband wavelet space, which has not been applied in the literature before, to the best of our knowledge. The results indicate to have a high potential to be exploited in applications of human-activity-based identification/authentication and remote health monitoring systems. The proposed method achieves an accuracy rate of over 95% for each movement by determining proper subbands of wavelet spaces.
C1 [Oztekin, Abdulkerim; Ertugrul, Omer Faruk; Aldemir, Erdogan; Acar, Emrullah] Batman Univ, Dept Elect & Elect Engn, TR-72000 Batman, Turkey.
C3 Batman University
RP Öztekin, A (corresponding author), Batman Univ, Dept Elect & Elect Engn, TR-72000 Batman, Turkey.
EM abdulkerimoztekin@gmail.com
RI Acar, Emrullah/KIB-2501-2024; Aldemir, Erdoğan/HKO-1767-2023; Acar,
   Emrullah/AAH-8231-2019; Öztekin, Abdulkerim/ABA-6749-2020; ERTUGRUL,
   Ömer Faruk/F-7057-2015
OI Acar, Emrullah/0000-0002-1897-9830; Aldemir,
   Erdoğan/0000-0003-4772-8317; Acar, Emrullah/0000-0002-1897-9830;
   Öztekin, Abdulkerim/0000-0002-0698-3525; ERTUGRUL, Ömer
   Faruk/0000-0003-0710-0867
CR Abidi MH, 2021, COMPUT STAND INTER, V76, DOI 10.1016/j.csi.2021.103518
   Altun K, 2010, PATTERN RECOGN, V43, P3605, DOI 10.1016/j.patcog.2010.04.019
   [Anonymous], 2006, BIOMETRICS PERSONAL
   Atallah Louis., 2010, P 2010 INT C BODY SE, P24, DOI DOI 10.1109/BSN.2010.23
   Bayat A, 2014, PROCEDIA COMPUT SCI, V34, P450, DOI 10.1016/j.procs.2014.07.009
   Bidargaddi N, 2007, P ANN INT IEEE EMBS, P1884, DOI 10.1109/IEMBS.2007.4352683
   Bouchrika Imed, 2018, SURVEILLANCE ACTION, P1, DOI DOI 10.1007/978-3-319-68533-5_1
   Brajdic A, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P225, DOI 10.1145/2493432.2493449
   Cuppens K, 2014, IEEE J BIOMED HEALTH, V18, P1026, DOI 10.1109/JBHI.2013.2285015
   Dargie W, 2009, CH CRC STUD INFO SER, P1
   Dua D, 2019, UCI MACHINE LEARNING
   Ejupi A, 2017, IEEE T BIO-MED ENG, V64, P1602, DOI 10.1109/TBME.2016.2614230
   Ertugrul ÖF, 2017, TURK J ELECTR ENG CO, V25, P3409, DOI 10.3906/elk-1606-122
   Heng X, 2016, INT J COMMUN SYST, V29, P1981, DOI 10.1002/dac.2888
   Hoang T, 2013, J INF PROCESS SYST, V9, P333, DOI 10.3745/JIPS.2013.9.2.333
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kang XM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010297
   Khan A, 2010, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET TECHNOLOGIES (CFI10), P55, DOI 10.1145/1853079.1853095
   Klassen TD, 2016, PHYS THER, V96, P355, DOI 10.2522/ptj.20140611
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Li M, 2017, INFORM SCIENCES, V382, P170, DOI 10.1016/j.ins.2016.12.007
   Luca S, 2014, ARTIF INTELL MED, V60, P89, DOI 10.1016/j.artmed.2013.11.007
   Majala, 2017, FREQUENCY ANAL ACCEL
   Malekzadeh M, 2015, PROCEEDINGS OF THE WORKSHOP ON PRIVACY BY DESIGN IN DISTRIBUTED SYSTEMS (P2DS'18), DOI 10.1145/3195258.3195260
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Mysore P., 2005, AAAI, V5, P1541
   Nyan MN, 2006, J BIOMECH, V39, P2647, DOI 10.1016/j.jbiomech.2005.08.014
   Ponce H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111715
   Ramchandran K, 1996, P IEEE, V84, P541, DOI 10.1109/5.488699
   Rogers MJ, 1997, 19970034695 NASA
   Sekine M, 2002, IEEE T NEUR SYS REH, V10, P188, DOI 10.1109/TNSRE.2002.802879
   Su X, 2014, TSINGHUA SCI TECHNOL, V19, P235, DOI 10.1109/TST.2014.6838194
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tapia EM, 2007, ELEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P37
   Walse KH, 2016, IIOAB J, V7, P68
   Wang AG, 2016, IEEE SENS J, V16, P4566, DOI 10.1109/JSEN.2016.2545708
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Weiss GM, 2019, IEEE ACCESS, V7, P133190, DOI 10.1109/ACCESS.2019.2940729
   Yoneda K, 2017, 2017 IEEE 8TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (UEMCON), P584, DOI 10.1109/UEMCON.2017.8249001
   Zhang L, 2016, INFORM SCIENCES, V367, P1094, DOI 10.1016/j.ins.2015.09.025
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 42
TC 2
Z9 2
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11639
EP 11663
DI 10.1007/s11042-022-12099-5
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757777400004
DA 2024-07-18
ER

PT J
AU Chanchal, AK
   Lal, S
   Kini, J
AF Chanchal, Amit Kumar
   Lal, Shyam
   Kini, Jyoti
TI Deep structured residual encoder-decoder network with a novel loss
   function for nuclei segmentation of kidney and breast histopathology
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kidney cancer diagnosis and prognosis; Nuclei segmentation; Residual
   learning; Histopathology images
ID ARCHITECTURE
AB To improve the process of diagnosis and treatment of cancer disease, automatic segmentation of haematoxylin and eosin (H & E) stained cell nuclei from histopathology images is the first step in digital pathology. The proposed deep structured residual encoder-decoder network (DSREDN) focuses on two aspects: first, it effectively utilized residual connections throughout the network and provides a wide and deep encoder-decoder path, which results to capture relevant context and more localized features. Second, vanished boundary of detected nuclei is addressed by proposing an efficient loss function that better train our proposed model and reduces the false prediction which is undesirable especially in healthcare applications. The proposed architecture experimented on three different publicly available H&E stained histopathological datasets namely: (I) Kidney (RCC) (II) Triple Negative Breast Cancer (TNBC) (III) MoNuSeg-2018. We have considered F1-score, Aggregated Jaccard Index (AJI), the total number of parameters, and FLOPs (Floating point operations), which are mostly preferred performance measure metrics for comparison of nuclei segmentation. The evaluated score of nuclei segmentation indicated that the proposed architecture achieved a considerable margin over five state-of-the-art deep learning models on three different histopathology datasets. Visual segmentation results show that the proposed DSREDN model accurately segment the nuclear regions than those of the state-of-the-art methods.
C1 [Chanchal, Amit Kumar; Lal, Shyam] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.
   [Kini, Jyoti] Manipal Acad Higher Educ, Kasturba Med Coll Mangalore, Dept Pathol, Manipal, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; Manipal Academy of Higher Education (MAHE);
   Kasturba Medical College, Mangalore
RP Lal, S (corresponding author), Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.; Kini, J (corresponding author), Manipal Acad Higher Educ, Kasturba Med Coll Mangalore, Dept Pathol, Manipal, India.
EM amit.chanchal01@gmail.com; shyam.mtec@gmail.com; kinijyoti@gmail.com
OI Chanchal, Amit Kumar/0000-0002-2224-1863; Lal, Dr.
   Shyam/0000-0002-4355-6354
FU Science Engineering and Research Board, Department of Science and
   Technology [EEG/2018/000323]
FX This research work was supported in part by the Science Engineering and
   Research Board, Department of Science and Technology, Govt. of India
   under Grant No. EEG/2018/000323, 2019.
CR Aatresh AA, 2021, COMPUT MED IMAG GRAP, V93, DOI 10.1016/j.compmedimag.2021.101975
   Albayrak A, 2019, MED BIOL ENG COMPUT, V57, P653, DOI 10.1007/s11517-018-1906-0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chanchal AK, 2021, INT J COMPUT ASS RAD, V16, P2159, DOI 10.1007/s11548-021-02497-9
   Chanchal AK, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107177
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hanif MS, 2020, ICT EXPRESS, V6, P28, DOI 10.1016/j.icte.2019.06.001
   Hashemi SR, 2019, IEEE ACCESS, V7, P1721, DOI 10.1109/ACCESS.2018.2886371
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Irshad H, 2015, BIOCOMPUT-PAC SYM, P294
   Jadon S, 2020, 2020 IEEE CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY (CIBCB), P115, DOI 10.1109/cibcb48159.2020.9277638
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Khodatars M, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104949
   Kingma D. P., 2014, arXiv
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Lal Shyam, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P453, DOI 10.1109/SPIN48934.2020.9070874
   Lal S, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104075
   Malekijoo A, 2019, MULTIMED TOOLS APPL, V78, P32379, DOI 10.1007/s11042-019-07990-7
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Nogues Isabella, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P388, DOI 10.1007/978-3-319-46723-8_45
   Rezaei M., 2021, ARXIV210504881
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadeghi Delaram, 2021, ARXIV210303081
   Salehi SSM, 2017, LECT NOTES COMPUT SC, V10541, P379, DOI 10.1007/978-3-319-67389-9_44
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Shoeibi A, 2020, AUTOMATED DETECTION
   Slaoui M, 2011, METHODS MOL BIOL, V691, P69, DOI 10.1007/978-1-60761-849-2_4
   Song TH, 2017, IEEE T BIO-MED ENG, V64, P2913, DOI 10.1109/TBME.2017.2690863
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Sugino T, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9080938
   Veit A, 2016, ADV NEUR IN, V29
   Win KY, 2017, PROC INT CONF ADV, P265, DOI 10.1109/ATC.2017.8167630
   Zhou SH, 2020, IEEE T IMAGE PROCESS, V29, P461, DOI 10.1109/TIP.2019.2919937
   Zhou SH, 2018, LECT NOTES COMPUT SC, V11073, P488, DOI 10.1007/978-3-030-00937-3_56
NR 39
TC 16
Z9 16
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9201
EP 9224
DI 10.1007/s11042-021-11873-1
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000749966800010
PM 35125928
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kang, SC
AF Kang, Sucheng
TI Deep learning-based automatic annotation and online classification of
   remote multimedia images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Remote multimedia; Automatic image annotation; Online
   classification
ID MULTISENSOR DATA FUSION
AB In this paper, based on in-depth analysis of remote multimedia images, the automatic annotation and classification of graphics are tested and analyzed by algorithms of deep learning. To reduce the time of remote multimedia image labeling and online classification, and improve efficiency, we study the use of deep learning methods to automate annotation and online classification of remote multimedia images. An image is re-labeling algorithm based on modeling the correlation of hidden feature dimensions is proposed to improve the effect of hidden feature models by modeling the correlation between hid feature dimensions. The algorithm constructs the correlation between each pair of dimensions in the hidden features through the outer product operation to form a two-dimensional interactive graph. The information in the interaction graph is refined layer by layer by using the ability of the convolutional neural network to model local features, and finally, a representation of the correlation of all dimensions in the hidden features is formed to realize the re-labeling of social images. The experimental results show that this method can utilize the hidden feature information more effectively and improve the image re-labeling results. The light-weight feature extraction network significantly reduces the number of model parameters at the expense of a small amount of detection accuracy, and the FPN pyramid structure enhances the feature characterization ability of the feature extraction network. The performance is close to that of the Yolo algorithm.
C1 [Kang, Sucheng] Yancheng Teachers Univ, Sch Phys & Elect Engn, Yancheng 224007, Jiangsu, Peoples R China.
C3 Yancheng Teachers University
RP Kang, SC (corresponding author), Yancheng Teachers Univ, Sch Phys & Elect Engn, Yancheng 224007, Jiangsu, Peoples R China.
EM kangsc@yctu.edu.cn
CR Al-Jarrah MA, 2019, IEEE T VEH TECHNOL, V68, P797, DOI 10.1109/TVT.2018.2879413
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Bihari A., 2020, ACM T MANAG INF SYST, V11, P1
   De S, 2018, IEEE J-STARS, V11, P154, DOI 10.1109/JSTARS.2017.2752282
   Farasat A, 2016, IEEE T COMPUT SOC SY, V3, P88, DOI 10.1109/TCSS.2016.2613563
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Hülsmann J, 2020, PROC VLDB ENDOW, V13, P2801, DOI 10.14778/3415478.3415479
   Jalali A, 2020, MULTIMED TOOLS APPL, V79, P1821, DOI 10.1007/s11042-019-08233-5
   Jiang L, 2017, IEEE T AERO ELEC SYS, V53, P2427, DOI 10.1109/TAES.2017.2697598
   Li LZ, 2018, IEEE T IND INFORM, V14, P4665, DOI 10.1109/TII.2018.2842821
   Mittal N, 2019, WIREL NETW, V25, P5151, DOI 10.1007/s11276-019-02123-2
   Nada D, 2018, INT J AUTOM COMPUT, V15, P207, DOI 10.1007/s11633-017-1065-z
   Pierson HA, 2017, ADV ROBOTICS, V31, P821, DOI 10.1080/01691864.2017.1365009
   Pourshamsi M, 2018, IEEE J-STARS, V11, P3453, DOI 10.1109/JSTARS.2018.2868119
   Radu Valentin, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161174
   Song H, 2018, IEEE T NEUR NET LEAR, V29, P5528, DOI 10.1109/TNNLS.2018.2804895
   Wu H, 2019, IEEE INTERNET THINGS, V6, P8215, DOI 10.1109/JIOT.2019.2919225
   Yuan X, 2018, OPT EXPRESS, V26, P1962, DOI 10.1364/OE.26.001962
   Zappone A, 2019, IEEE T COMMUN, V67, P7331, DOI 10.1109/TCOMM.2019.2924010
   Zhang H, 2019, IEEE T CYBERNETICS, V49, P1580, DOI 10.1109/TCYB.2018.2805717
   Zhao ZM, 2019, IEEE T INSTRUM MEAS, V68, P1089, DOI 10.1109/TIM.2018.2861107
   Zhou Q, 2020, INT J WIREL INF NETW, V27, P241, DOI 10.1007/s10776-019-00452-9
NR 22
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36239
EP 36255
DI 10.1007/s11042-021-11854-4
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000749055500010
DA 2024-07-18
ER

PT J
AU Patil, RS
   Biradar, N
   Pawar, R
AF Patil, Rajeshwari S.
   Biradar, Nagashettappa
   Pawar, Rashmi
TI A new automated segmentation and classification of mammogram images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram image processing; Region growing with adaptive fuzzy C-means
   clustering; Optimal trained recurrent neural networks; Average
   fitness-based new updating based grasshopper optimisation algorithm
ID BREAST-CANCER SEGMENTATION; ALGORITHM; FRAMEWORK; NUCLEI
AB Early-stage recognition of lesions is the better probable manner for fighting against breast cancer to find a disease with the highest ratio of malignancy around women. Existing approaches are generally based on deep learning that has been designed for the segmentation of tumors, however, it is complex because of the false positives and the inaccurate detection of boundaries for segmentation, as the existing models incorrectly predict the positive classes, thus affecting the overall classification. In this paper, an enhanced mammogram image classification is proposed by introducing novel segmentation and classification approaches. The initial process of the proposed model is pre-processing, which is performed by the median filtering that tends to remove the noise from the images. The preprocessed images are subjected to segment the tumor from the mammogram images by a new segmentation approach termed Region growing with Adaptive Fuzzy C-Means Clustering (RG-AFCM). Once the segmentation of the tumor is done, feature extraction is performed, where the features are extracted using Gray-Level Run-Length Matrix (GLRM) and Grey Level Co-occurrence Matrix (GLCM) approaches. Furthermore, the extracted features are classified using optimal trained Recurrent Neural Networks (RNN). Here, a new algorithm named Average Fitness New Updating-based Grasshopper Optimization Algorithm (AFU-GOA) is proposed for enhancing both the segmentation and classification phases. Finally, the performance of RG-AFCM-based segmentation is compared over the stat-of-the-art segmentation approaches, and optimal trained RNN is compared over the existing classifiers and deep learning models to prove the reliability of the proposed model. The accuracy of the developed AFU-GOA-RNN is 1%, 2%, 1%, and 3% enhanced than PSO-RNN, GWO-RNN, FF-RNN, and GOA-RNN. Hence, the proposed classification using AFU-GOA-based trained RNN establishes a better performance than existing models.
C1 [Patil, Rajeshwari S.] Visvesvaraya Technol Univ, Dept Elect & Commun, BLDEAs VPDr PGH Coll Engg & Tech, Vijayapur, India.
   [Biradar, Nagashettappa] Bheemanna Khandre Inst Technol, Dept Elect & Commun Engn, Bhalki, India.
   [Pawar, Rashmi] Visvesvaraya Technol Univ, Dept Elect & Elect, BLDEAs VP Dr PG Halakatti Coll Engn & Technol, Vijayapur, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Patil, RS (corresponding author), Visvesvaraya Technol Univ, Dept Elect & Commun, BLDEAs VPDr PGH Coll Engg & Tech, Vijayapur, India.
EM rspatill272014@gmail.com; nmbiradar@gmail.com; rashmi.ajadhav@gmail.com
RI Jadhav, Ambaji/JDW-7611-2023; Patil, Rajeshwari/JBH-2114-2023
OI Jadhav, Ambaji/0000-0001-5990-8476; 
CR Adhikari SK, 2015, APPL SOFT COMPUT, V34, P758, DOI 10.1016/j.asoc.2015.05.038
   Al-antari MA, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105584
   Ashraf AB, 2013, IEEE T MED IMAGING, V32, P637, DOI 10.1109/TMI.2012.2219589
   Basha TSG, 2012, IET MICROW ANTENNA P, V6, P773, DOI 10.1049/iet-map.2011.0356
   Bonyadi MR, 2016, IEEE T EVOLUT COMPUT, V20, P370, DOI 10.1109/TEVC.2015.2460753
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   Duraisamy S, 2017, IET COMPUT VIS, V11, P656, DOI 10.1049/iet-cvi.2016.0425
   Feng X, 2019, IEEE ACCESS, V7, P134697, DOI 10.1109/ACCESS.2019.2941543
   Gao XB, 2010, IEEE T NEURAL NETWOR, V21, P918, DOI 10.1109/TNN.2010.2045129
   Geweid GGN, 2019, IEEE ACCESS, V7, P136343, DOI 10.1109/ACCESS.2019.2941990
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Ibrahim A, 2020, IEEE ACCESS, V8, P122121, DOI 10.1109/ACCESS.2020.3007336
   Jameel S., 2021, IEEE ACCESS, V9, P55312
   Kao TJ, 2008, IEEE T MED IMAGING, V27, P1762, DOI 10.1109/TMI.2008.926049
   Kaura P., 2019, PARMINDER KAUR INTEL, V16
   Lee H, 2020, IEEE T ULTRASON FERR, V67, P1344, DOI 10.1109/TUFFC.2020.2972573
   Li F, 2019, J NEUROSCI METH, V323, P108, DOI 10.1016/j.jneumeth.2019.05.006
   Lim HB, 2008, IEEE T BIO-MED ENG, V55, P1697, DOI 10.1109/TBME.2008.919716
   Mahmood T, 2020, IEEE ACCESS, V8, P165779, DOI 10.1109/ACCESS.2020.3021343
   Malebary SJ, 2021, IEEE ACCESS, V9, P55312, DOI 10.1109/ACCESS.2021.3071297
   Malipatil S., 2020, AREA OPTIMIZATION CM, P192
   Manne R., 2020, Int J Modern Trends Sci Technol, P2455, DOI [10.46501/IJMTST061118, DOI 10.46501/IJMTST061118]
   Michael E, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/9962109
   Muduli D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101912
   Ong CJ, 2010, IEEE T NEURAL NETWOR, V21, P451, DOI 10.1109/TNN.2009.2039000
   Pinker K, 2010, BREAST CANCER RES, V12, DOI 10.1186/bcr2657
   Pramanik S, 2020, IEEE T INSTRUM MEAS, V69, P4785, DOI 10.1109/TIM.2019.2956362
   Priya E., 2021, TURKISH J COMPUTER M, V12, P1147, DOI [10.17762/turcomat.v12i2.1136, DOI 10.17762/TURCOMAT.V12I2.1136]
   Quellec G, 2010, IEEE T INF TECHNOL B, V14, P1227, DOI 10.1109/TITB.2010.2053716
   Radhakrishnan M., 2012, IJCSI INT J COMPUTER, V9
   Rajeshwari S., 2020, INT J INTELL COMPUT
   Rajeshwari S, 2020, EVOL INTEL
   Roslidar R, 2020, IEEE ACCESS, V8, P116176, DOI 10.1109/ACCESS.2020.3004056
   Saha M, 2018, IEEE T IMAGE PROCESS, V27, P2189, DOI 10.1109/TIP.2018.2795742
   Salama WM, 2021, ALEX ENG J, V60, P4701, DOI 10.1016/j.aej.2021.03.048
   Salih AM, 2019, AL-MUSTANS J SCI, V29
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Tang JS, 2009, IEEE T INF TECHNOL B, V13, P236, DOI 10.1109/TITB.2008.2009441
   Vijayarajeswari R, 2019, MEASUREMENT, V146, P800, DOI 10.1016/j.measurement.2019.05.083
   Wang YQ, 2010, IEEE SIGNAL PROC LET, V17, P875, DOI 10.1109/LSP.2010.2060482
   Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795
   Woten DA, 2007, IEEE MICROW WIREL CO, V17, P825, DOI 10.1109/LMWC.2007.910466
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yang XS, 2013, ENG COMPUT-GERMANY, V29, P175, DOI 10.1007/s00366-012-0254-1
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Zheng J, 2020, IEEE ACCESS, V8, P96946, DOI 10.1109/ACCESS.2020.2993536
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 48
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7783
EP 7816
DI 10.1007/s11042-022-11932-1
EA JAN 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865600010
DA 2024-07-18
ER

PT J
AU Raman, S
   Soni, M
   Ramaprasad, R
   Chamola, V
AF Raman, Sundaresan
   Soni, Manan
   Ramaprasad, Rohit
   Chamola, Vinay
TI LWCNN: a lightweight convolutional neural network for agricultural crop
   protection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Classification; Model interpretability; Object detection;
   Crop Protection
AB Automatic identification of plant diseases is critical for agricultural crop protection so as to enhance the crop yield. The recent advances in deep learning and image processing gives hope for the development of efficient algorithms to address this issue. In this manuscript, we make use of these schemes to develop a Light-Weight Convolutional Neural Network (LWCNN) for identifying diseases in the leaves and ears of pearl millets. Although many models exist in the literature, the total number of parameters employed by our model is far fewer, by an order of thousand as compared to many other light-weight networks such as MobileNet(v2), EfficientNet, NASNet etc. Hence our scheme can be employed and run directly on devices with much lesser compute power. It is noteworthy that despite using few parameters, the proposed model achieves an accuracy of 97.4% in detecting the existence of the downy mildew disease in pearl millets, and takes the least time for both training and testing as compared to other models. To eliminate most of the pre-processing steps and to make our system suitable for on-field detection, we explore three single stage object detectors namely SSD, YOLOv3 and RetinaNet which localize and classify multiple instances of healthy and diseased leaves and ears in the image. We present a comparative analysis of the models and our experiments indicate that SSD is most suitable outperforming the other two models by a significant margin.
C1 [Raman, Sundaresan; Soni, Manan; Ramaprasad, Rohit] BITS Pilani, Dept Comp Sci & Informat Syst, Pilani, Rajasthan, India.
   [Chamola, Vinay] BITS Pilani, Dept Elect & Elect Engn, Pilani, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); Birla
   Institute of Technology & Science Pilani (BITS Pilani)
RP Raman, S (corresponding author), BITS Pilani, Dept Comp Sci & Informat Syst, Pilani, Rajasthan, India.
EM sundaresan.raman@pilani.bitspilani.ac.in
OI Raman, Sundaresan/0000-0003-4975-4121
FU DST-SYST (Scheme for Young Scientists and Technologist) [SP-YO-688-2018]
FX This research was funded by DST-SYST (Scheme for Young Scientists and
   Technologist) funding, under Project Grant File No: SP-YO-688-2018.
CR Akhtar A, 2013, INT CONF FRONT INFO, P60, DOI 10.1109/FIT.2013.19
   Amara J., 2017, DATENBANKSYSTEME BUS
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Coulibaly S, 2019, COMPUT IND, V108, P115, DOI 10.1016/j.compind.2019.02.003
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Kale AP, 2019, COMPUT ELECTRON AGR, V161, P225, DOI 10.1016/j.compag.2018.04.027
   Liakos KG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082674
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu Y, 2017, NEUROCOMPUTING, V267, P378, DOI 10.1016/j.neucom.2017.06.023
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Ning X, 2020, IEEE SIGNAL PROC LET, V27, P1944, DOI 10.1109/LSP.2020.3032277
   Ning X, 2020, IEEE ACCESS, V8, P8834, DOI 10.1109/ACCESS.2020.2964838
   Ning X, 2017, IEICE T INF SYST, VE100D, P211, DOI 10.1587/transinf.2016EDL8180
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Redmon J., 2018, P IEEE C COMP VIS PA
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Singh SD, 1993, INFORM B, V37, P36
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang HB, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P246
   Wolfert S, 2017, AGR SYST, V153, P69, DOI 10.1016/j.agsy.2017.01.023
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 29
TC 4
Z9 5
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22323
EP 22334
DI 10.1007/s11042-021-11866-0
EA JAN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000750865600004
DA 2024-07-18
ER

PT J
AU Ahmed, M
   Laskar, RH
AF Ahmed, Manir
   Laskar, Rabul Hussain
TI Eye center localization using gradient and intensity information under
   uncontrolled environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Eye center localization; Iris shape feature; Image gradients; Eye
   detection; Shape analysis; Feature-level fusion
ID FACE DETECTION; ROBUST
AB Accurate localization of eyes in low-resolution facial images is a challenging problem in computer vision community. The existing techniques provides inaccurate results for eye center localization in an uncontrolled environment, e.g. low resolution, low contrast, scale, pose and illumination variations etc. This study proposes a hybrid method for accurate eye center localization which shows robustness to above-mentioned problems. The proposed hybrid method is a two stage method. In the first stage, a new operator based on gradient and intensity information is proposed to extract the coarse eye candidates. The proposed operator uses the integral image and the dot product operations that make the system computationally efficient. The likelihood of eye centers are further verified in the second stage using a convolutional neural network architecture. In the verification stage, the normalized region of interest is adopted to solve the variations of different scales. The eye pair satisfying the predefined constraints is selected as the true eye pair. The proposed method is extensively tested on various databases to check its accuracy to the uncontrolled environment. The experimental analysis suggests that the proposed hybrid method can localize the eye center more precisely and eventually shows superior performance over some of the competitive state-of-the-art methods.
C1 [Ahmed, Manir] CMR Coll Engn & Technol, Dept ECE, Hyderabad 501401, Telangana, India.
   [Laskar, Rabul Hussain] Natl Inst Technol Silchar, Dept ECE, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Ahmed, M (corresponding author), CMR Coll Engn & Technol, Dept ECE, Hyderabad 501401, Telangana, India.
EM manirahmed02@gmail.com
RI Laskar, Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Ahmed,
   Manir/0000-0003-2775-7452
FU Visvesvaraya Ph.D. Scheme of MeitY, Government of India
   [PhD-MLA/4(74)/2015-16]
FX This research work has been carried out in the department of R&D, CMR
   College of Engineering & Technology, Hyderabad, India, and in the Speech
   and Image Processing Lab, NIT Silchar, India, and is supported by
   Visvesvaraya Ph.D. Scheme of MeitY, Government of India (Ref. No.:
   PhD-MLA/4(74)/2015-16).
CR Abiyev RH, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12398
   AHMED M, 2019, IMAGE VIS COMPUT
   Ahmed M, 2021, MULTIMEDIA SYST, V27, P429, DOI 10.1007/s00530-020-00744-8
   Ahmed M, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033009
   Ahmed NY, 2021, J REAL-TIME IMAGE PR, V18, P193, DOI 10.1007/s11554-020-00955-2
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   [Anonymous], 2015, INT J COMPUT APPL
   Asadifard M, 2010, LECT NOTES ENG COMP, P130
   BF Database, DAT FAC DET FAC BIOI
   Borza D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071105
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Choi JH, 2020, MULTIMED TOOLS APPL, V79, P32563, DOI 10.1007/s11042-020-09711-x
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   de Oliveira LS, 2012, IEEE SYS MAN CYBERN, P840, DOI 10.1109/ICSMC.2012.6377832
   Drewes, 2014, EYE GAZE TRACKING IN, P251
   Duchowski A. T., 2017, EYE TRACKING METHODO, DOI [10.1007/978-3-319-57883-5, DOI 10.1007/978-3-319-57883-5]
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Hassaballah M, 2010, IET COMPUT VIS, V4, P261, DOI 10.1049/iet-cvi.2009.0097
   Hsu WY, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108078
   Ito Y, 2012, INT C PATT RECOG, P1795
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Jing MQ, 2010, INT J PATTERN RECOGN, V24, P475, DOI 10.1142/S0218001410008020
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Jo J, 2014, EXPERT SYST APPL, V41, P1139, DOI 10.1016/j.eswa.2013.07.108
   Kim BS, 2010, IEEE T CONSUM ELECTR, V56, P2498, DOI 10.1109/TCE.2010.5681133
   Kim H, 2017, IMAGE VISION COMPUT, V57, P147, DOI 10.1016/j.imavis.2016.10.003
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Levinshtein A, 2018, IMAGE VISION COMPUT, V71, P17, DOI 10.1016/j.imavis.2018.01.003
   Liu ZT, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107565
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Monzo D, 2011, MACH VISION APPL, V22, P471, DOI 10.1007/s00138-010-0273-0
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Ponz V, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P681
   Ren Y, 2014, IEEE T IMAGE PROCESS, V23, P226, DOI 10.1109/TIP.2013.2287614
   Savakis A, 2014, PROC SPIE, V9027, DOI 10.1117/12.2036824
   Seung-Jin Baek, 2013, IEEE Transactions on Consumer Electronics, V59, P125, DOI 10.1109/TCE.2013.6531125
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Tan XY, 2009, PROC CVPR IEEE, P1621, DOI 10.1109/CVPRW.2009.5206818
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136
   Wang P, 2007, COMPUT VIS IMAGE UND, V105, P99, DOI 10.1016/j.cviu.2006.08.008
   Wang PQ, 2005, PROCEEDINGS OF THE 2ND INTERNATIONAL YELLOW RIVER FORUM ON KEEPING HEALTHY LIFE OF THE RIVER, VOL III, P3
   Xia YF, 2020, MULTIMED TOOLS APPL, V79, P805, DOI 10.1007/s11042-019-08160-5
   Young D, 1995, SPECIALIZED HOUGH TR
   Zhao SY, 2006, INT C PATT RECOG, P481
NR 60
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7145
EP 7168
DI 10.1007/s11042-021-11805-z
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746780700001
DA 2024-07-18
ER

PT J
AU Wan, L
   Dong, CB
   Pei, XB
AF Wan, Lin
   Dong, Chengbin
   Pei, Xiaobing
TI Self-paced learning-based multi-graphs semi-supervised learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-paced learning; Label propagation; Semi-supervised learning
ID NONNEGATIVE MATRIX FACTORIZATION; LABEL PROPAGATION; NETWORK
AB Graph-based semi-supervised learning has received considerable attention in machine learning community. The performance of existing methods highly depends on the input weight graph, which is related to the choice of hyper-parameters, such as the number of neighbors and the weight function. Multiple weights graphs can be easily built by selecting different hyper-parameters. In addition, there are multiple weights graphs representations for the same data set in many real-world applications. A key challenge is how to obtain better performance for graph-based semi-supervised learning by introducing multiple graphs. In this paper, we focus on multi-modal semi-supervised learning. A novel graph-based multi-modal semi-supervised learning framework, self-paced multi-modal label propagation learning (SPLP), is proposed. The main idea of SPLP is to take each type of weights graph as one modality and train "easy" modality first, then "complex" ones by self-paced learning. SPLP has the ability to select different weight coefficients in a purely self-paced way for multiple graphs and has good robustness against noisy or irrelevant graphs which cannot be rightly achieved by existing methods. We apply the proposed learning framework to solve the classification task on benchmark datasets including non-network datasets (MNIST, PIE, Sector and Reuters-21578) and network datasets (Cora and Citeseer). Experimental results show that our method achieves more than 2% improvement with regard to the several graph based state-of-the-art semi-supervised learning methods.
C1 [Wan, Lin; Dong, Chengbin; Pei, Xiaobing] Huazhong Univ Sci & Technol, Sch Software, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Dong, CB; Pei, XB (corresponding author), Huazhong Univ Sci & Technol, Sch Software, Wuhan 430074, Peoples R China.
EM dcb@hust.edu.cn; xiaobingp@hust.edu.cn
RI pei, xiaobing/AAH-4133-2019
OI Dong, Chengbin/0000-0001-8253-1590
CR Cai D, 2008, IEEE DATA MINING, P63, DOI 10.1109/ICDM.2008.57
   Cai X, 2013, IEEE I CONF COMP VIS, P1737, DOI 10.1109/ICCV.2013.218
   Nguyen CH, 2011, IEEE T NEURAL NETWOR, V22, P1395, DOI 10.1109/TNN.2011.2160873
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chen YD, 2018, MULTIMED TOOLS APPL, V77, P6117, DOI 10.1007/s11042-017-4520-5
   Chen Y, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P420, DOI [10.1145/3287624.3287685, 10.1109/TCAD.2019.2912948]
   Chowdhury SR, 2018, IEEE T NETW SERV MAN, V15, P1132, DOI 10.1109/TNSM.2018.2834315
   Dizaji KG, 2019, PROC CVPR IEEE, P4386, DOI 10.1109/CVPR.2019.00452
   Fan MY, 2018, IEEE T CYBERNETICS, V48, P1486, DOI 10.1109/TCYB.2017.2703610
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Fujiwara Y, 2014, PR MACH LEARN RES, V32, P784
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2148, DOI 10.1109/TNNLS.2014.2376963
   GUILLAUMIN M, 2010, PROC CVPR IEEE, P902, DOI DOI 10.1109/CVPR.2010.5540120
   Hou CP, 2011, IEEE T NEURAL NETWOR, V22, P420, DOI 10.1109/TNN.2010.2099237
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hwang I, 2017, MULTIMED TOOLS APPL, V76, P2111, DOI 10.1007/s11042-015-3171-7
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Jiang L, 2015, AAAI CONF ARTIF INTE, P2694
   Jiang L, 2014, ADV NEUR IN, V27
   Kejani MT, 2020, NEURAL NETWORKS, V127, P160, DOI 10.1016/j.neunet.2020.04.016
   Kipf TN, 2017, INT C LEARN REPR
   Kumar MP, 2011, IEEE I CONF COMP VIS, P1800, DOI 10.1109/ICCV.2011.6126446
   Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523
   Li JJ, 2017, IEEE ACCESS, V5, P2955, DOI 10.1109/ACCESS.2017.2676761
   Li L, 2020, NEURAL PROCESS LETT, V52, P1723, DOI 10.1007/s11063-020-10286-9
   Liang LY, 2017, IEEE T CIRC SYST VID, V27, P125, DOI 10.1109/TCSVT.2016.2602812
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Liu WY, 2017, INT CONF DAT MIN WOR, P134, DOI 10.1109/ICDMW.2017.23
   Lu J, 2018, PATTERN RECOGN, V76, P228, DOI 10.1016/j.patcog.2017.11.004
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Meng Deyu, 2015, ARXIV151106049
   Ni BB, 2012, IEEE T KNOWL DATA EN, V24, P114, DOI 10.1109/TKDE.2010.209
   Pawan Kumar M., 2010, NIPS
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tsuda K, 2005, BIOINFORMATICS, V21, P59, DOI 10.1093/bioinformatics/bti1110
   Wang B, 2013, IEEE I CONF COMP VIS, P425, DOI 10.1109/ICCV.2013.60
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang QY, 2019, NEURAL PROCESS LETT, V50, P1303, DOI 10.1007/s11063-018-9918-1
   Xu PF, 2018, MULTIMED TOOLS APPL, V77, P3143, DOI 10.1007/s11042-017-4984-3
   Xu XY, 2019, SIGNAL PROCESS, V165, P186, DOI 10.1016/j.sigpro.2019.06.026
   Yang Z., 2016, P INT C MACHINE LEAR, P48
   Yi YG, 2018, SOFT COMPUT, V22, P3545, DOI 10.1007/s00500-018-3109-x
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhao J, 2020, INFORM SCIENCES, V537, P380, DOI 10.1016/j.ins.2020.03.113
   Zhao Q, 2015, AAAI CONF ARTIF INTE, P3196
   Zheng FF, 2021, INT J PROD RES, V59, P6579, DOI 10.1080/00207543.2020.1821118
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou DY, 2004, LECT NOTES COMPUT SC, V3175, P237
   Zhou JB, 2016, NEURAL PROCESS LETT, V44, P681, DOI 10.1007/s11063-015-9488-4
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 55
TC 1
Z9 1
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7025
EP 7046
DI 10.1007/s11042-022-11931-2
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000001
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, B
AF Kumar, Shailesh
   Kumar, Basant
TI Automatic early glaucoma detection by extracting parapapillary atrophy
   and optic disc from fundus image using SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Cup to disc ratio; Para-papillary atrophy; K- means
   clustering; polar transform; direct least-square fitting algorithm of an
   ellipse; SVM
ID SEGMENTATION; CUP
AB This paper presents early-automated glaucoma detection algorithm by extracting early diagnostic parameters, namely, parapapillary atrophy and Cup to Disc ratio using DIP. Glaucoma is optic neuropathy chronic eye diseases, which is progressed as intraocular pressure inside eyeball increases. Proposed method mainly consists of five stages, namely ROI extraction, pre-processing, diagnostic parameter extraction, feature extraction, and classification. First, optic disc region is extracted from fundus image because diagnostic parameters lie around OD. ROI is extracted using the horizontal and vertical edge of vascular tree in OD region. Diagnostic parameters such as CDR and PPA are extracted from ROI region. CDR is calculated using K-means clustering and polar transform. PPA is earliest sign of glaucoma. In many cases, occurrence of PPA before the increased CDR value gives indication of early glaucoma. PPA detection and extraction are accomplished using polar transform method and direct least-square fitting algorithm of an ellipse. Optimal categorization of PPA area and residue area is done by K-means clustering. Features of diagnostic parameters such as CDR and area of PPA are extracted for classification model. Features of fundus images are taken as input and labels as output for training parameters of SVM. SVM model is trained with five-fold validation on 141 images, which consists of healthy and glaucoma due to PPA and CDR. Thirty-nine images are used for testing of SVM model and sensitivity, specificity, and accuracy values are 100%, 88.2%, and 97.3% respectively. Diagnostic results obtained by proposed algorithm, about early glaucoma presence is further validated by ophthalmologist.
C1 [Kumar, Shailesh; Kumar, Basant] ECED MNNIT Allahabad, Prayagraj, Uttar Pradesh, India.
RP Kumar, B (corresponding author), ECED MNNIT Allahabad, Prayagraj, Uttar Pradesh, India.
EM Shailesh@mnnit.ac.in; singhbasant@mnnit.ac.in
RI Kumar, Shailesh/AAU-2978-2020
CR Abbas Q, 2017, INT J ADV COMPUT SC, V8, P41
   [Anonymous], 1998, STAT LEARNING THEORY
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Budde WM, 2003, INVEST OPHTH VIS SCI, V44, P170, DOI 10.1167/iovs.02-0651
   Chakravarty A, 2016, I S BIOMED IMAGING, P689, DOI 10.1109/ISBI.2016.7493360
   Christopher M, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.27
   Claro M, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102597
   Das P, 2016, NETW MODEL ANAL HLTH, V5, DOI 10.1007/s13721-015-0110-5
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Geetha R., 2017, INT J COMPUT APPL, V166, P38, DOI 10.5120/ijca2017914130
   Gonzale RC, 1974, DIGITAL IMAGE PROCES, V7
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   Orlando JI, 2017, PROC SPIE, V10160, DOI 10.1117/12.2255740
   Issac A, 2015, COMPUT METH PROG BIO, V122, P229, DOI 10.1016/j.cmpb.2015.08.002
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Kavya N, 2017, CONF REC ASILOMAR C, P1471, DOI 10.1109/ACSSC.2017.8335600
   Kirar BS, 2022, IETE J RES, V68, P4421, DOI 10.1080/03772063.2020.1795934
   Li AN, 2016, IEEE ENG MED BIO, P1328, DOI 10.1109/EMBC.2016.7590952
   Li L, 2019, PROC CVPR IEEE, P10563, DOI 10.1109/CVPR.2019.01082
   Lu CK, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.10.106010
   Mahfouz AE, 2009, LECT NOTES COMPUT SC, V5762, P985, DOI 10.1007/978-3-642-04271-3_119
   Majumdar, 2015, THRESHOLD BASED ALGO, V126, P1
   Mittapalli PS, 2016, BIOMED SIGNAL PROCES, V24, P34, DOI 10.1016/j.bspc.2015.09.003
   Narasimhan K., 2011, Journal of Theoretical and Applied Information Technology, V33, P104
   Nelles O., 2021, Nonlinear System Identification : From Classical Approaches toNeural Networks Fuzzy Models and Gaussian Processes, V2nd
   Phan S, 2019, JPN J OPHTHALMOL, V63, P276, DOI 10.1007/s10384-019-00659-6
   PINTO AD, 2019, BIOMED ENG ONLINE, P1
   Pruthi J, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.102004
   Ricci E, 2007, IEEE T MED IMAGING, V26, P1357, DOI 10.1109/TMI.2007.898551
   Srivastava R, 2015, I S BIOMED IMAGING, P768, DOI 10.1109/ISBI.2015.7163985
   Tt, HANDS ON MORPHOLOGIC
   VanderBeek BL, 2010, GRAEF ARCH CLIN EXP, V248, P1313, DOI 10.1007/s00417-010-1376-z
   Yu S, 2019, COMPUT MED IMAG GRAP, V74, P61, DOI 10.1016/j.compmedimag.2019.02.005
   Zahoor MN, 2018, IEEE ACCESS, V6, P4845, DOI 10.1109/ACCESS.2018.2790040
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 36
TC 2
Z9 2
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13513
EP 13535
DI 10.1007/s11042-021-11023-7
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000742319000009
DA 2024-07-18
ER

PT J
AU Romero-Garcés, A
   De Freitas, RS
   Marfil, R
   Vicente-Chicote, C
   Martínez, J
   Inglés-Romero, JF
   Bandera, A
AF Romero-Garces, A.
   Salles De Freitas, R.
   Marfil, R.
   Vicente-Chicote, C.
   Martinez, J.
   Ingles-Romero, J. F.
   Bandera, A.
TI QoS metrics-in-the-loop for endowing runtime self-adaptation to robotic
   software architectures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Runtime self-adaptation; Model-driven software engineering for robotics;
   Quality-of-Service metrics
AB The design of robots capable of operating autonomously in changing and unstructured environments, requires using complex software architectures in which, typically, robot engineers manually hard-code adaptation mechanisms allowing the robot to deal with certain situations. As adaptation is closely related with context monitoring, deliberation and actuation, its implementation typically spreads across several architecture components. Therefore, fine-tuning or extending the adaptation logic (e.g., to cope with new contingencies not foreseen at design-time) results in a very expensive and cumbersome process. This paper proposes a novel approach to deal with self-adaptation based on modeling behavior variability at design-time so that the robot can configure it at runtime, according to the contextual information only then available. This approach is supported by a model-based framework allowing robotic engineers to specify (1) the robot behavior variation points (open decision space); (2) the internal and external contextual information available; and (3) the non-functional properties (e.g. safety, performance, or energy consumption) in terms of which the robot Quality-of-Service (QoS) will be measured. Then, from these models, the framework will automatically generate the runtime infrastructure allowing the robot to self-adapt its behavior to achieve the best QoS possible according to its current context. The framework has been validated in two scenarios using two different well-known robotic software architectures.
C1 [Romero-Garces, A.; Marfil, R.; Martinez, J.; Bandera, A.] Univ Malaga, Avda Cervantes, Malaga 29071, Spain.
   [Salles De Freitas, R.] Rapyuta Robot Co Ltd, 4 Chome 10-5 Hirano, Koto City, Tokyo 1350023, Japan.
   [Vicente-Chicote, C.] EPCC Univ Extremadura, Avda Univ S-N, Caceres 10003, Spain.
   [Ingles-Romero, J. F.] Biometr Vox SL, Murcia 30100, Spain.
C3 Universidad de Malaga
RP Bandera, A (corresponding author), Univ Malaga, Avda Cervantes, Malaga 29071, Spain.
EM argarces@uma.es; rebeca@uma.es; cristinav@unex.es;
   juanfran.ingles@biometricvox.com; ajbandera@uma.es
RI Vicente-Chicote, Cristina/A-7648-2008; Bandera, Antonio/H-2111-2015;
   Inglés-Romero, Juan Francisco/IQU-0845-2023; Marfil, Rebeca/I-3313-2018
OI Vicente-Chicote, Cristina/0000-0002-9553-3461; Bandera,
   Antonio/0000-0003-3147-0307; Inglés-Romero, Juan
   Francisco/0000-0002-3648-0267; Marfil, Rebeca/0000-0003-1573-5096
FU MIRoN; EU [732410, 780265]; Gobierno de Espana [RTI2018-099522-B-C4X];
   FEDER funds
FX This work has been partially funded by MIRoN (an Integrated Technical
   Project funded by EU H2020 RobMoSys Project under Grant Agreement
   732410), SA3IR (an experiment funded by EU H2020 ESMERA Project under
   Grant Agreement 780265), and the project RTI2018-099522-B-C4X, funded by
   the Gobierno de Espana and FEDER funds.
CR Bischoff R, 2010, ISR ROBOTIK 2010
   Brugali D, 2016, STUD COMPUT INTELL, V625, P509, DOI 10.1007/978-3-319-26054-9_20
   Bustos P, 2019, COGN SYST RES, V55, P107, DOI 10.1016/j.cogsys.2019.01.003
   Clements P., 2002, Software product lines
   Colledanchise M., 2018, BEHAV TREES ROBOTICS
   Cyberbotics Ltd, WEB OP SOURC ROB SIM
   Dromey RG, 2003, I C SOFTW ENG FORM M, P2, DOI 10.1109/SEFM.2003.1236202
   Faconti, GROOT INTEGRATED DEV
   Hendrich N, 2015, ENGINEERING-PRC, V1, P27, DOI 10.15302/J-ENG-2015007
   Hernandez Christopher, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092139
   Hernández C, 2018, INTEGR COMPUT-AID E, V25, P157, DOI 10.3233/ICA-180565
   Hernandez-Corbato C, 2020, MROS RUNTIME ADAPTAT
   Jumel F., 2018, ROBOT WORLD CUP, P205
   Lotz A, 2014, INT J INF SYST MODEL, V5, P55, DOI 10.4018/ijismd.2014070103
   Lotz A, 2013, LECT NOTES BUS INF P, V147, P441
   Lutz M., 2019, NEW PERSPECTIVES INF, P274, DOI [10.4018/978-1-5225-7271-8.ch012, DOI 10.4018/978-1-5225-7271-8.CH012]
   Marfil R, 2020, COGN COMPUT, V12, P479, DOI 10.1007/s12559-019-09685-5
   Martinet P, 2008, 3 NAT C CONTR ARCH R
   Mou WH, 2012, IEEE INT C INT ROBOT, P329, DOI 10.1109/IROS.2012.6385791
   Ogren P, 2018, BEHAV TREES ROBOTICS
   Pereira R.d.P., 2015, ARXIV PREPRINT ARXIV
   Romero-Garcés A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186618
   Salles De Freitas Renan, 2021, Advances in Physical Agents. Proceedings of the 21st International Workshop of Physical Agents (WAF 2020). Advances in Intelligent Systems and Computing (AISC 1285), P94, DOI 10.1007/978-3-030-62579-5_7
   Schmidt DC, 2006, COMPUTER, V39, P25, DOI 10.1109/MC.2006.58
   Subagyo WP, 2016, 2016 1ST INTERNATIONAL SEMINAR ON APPLICATION FOR TECHNOLOGY OF INFORMATION AND COMMUNICATION (ISEMANTIC): SCIENCE AND TECHNOLOGY FOR A BETTER FUTURE, P184, DOI 10.1109/ISEMANTIC.2016.7873835
   Vicente-Chicote C, 2018, MODELS WORKSH
   Vicente-Chicote C, 2019, LECT NOTES COMPUT SC, V11487, P380, DOI 10.1007/978-3-030-19651-6_37
   Wenchao Ding, 2019, 2019 International Conference on Robotics and Automation (ICRA), P9610, DOI 10.1109/ICRA.2019.8793568
NR 28
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3603
EP 3628
DI 10.1007/s11042-021-11603-7
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000003
DA 2024-07-18
ER

PT J
AU Mir, M
   Yaghoobi, M
   Khairabadi, M
AF Mir, Masoomeh
   Yaghoobi, Mahdi
   Khairabadi, Maryam
TI A new approach to energy-aware routing in the Internet of Things using
   improved Grasshopper Metaheuristic Algorithm with Chaos theory and Fuzzy
   Logic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Routing; Internet of Things; Chaos Theory; Fuzzy Logic; Grasshopper
   Optimization Algorithm
ID CHALLENGES; SECURE; IOT
AB In most Internet of Things (IoT) applications, network nodes are limited in terms of energy source. Therefore, the need for innovative methods to eliminate energy loss which shortens the life of networks is fully felt in such networks. One of the optimization techniques of energy consumption on the Internet of things is efficient energy routing that the required energy can be reduced by choosing an optimal path. In this paper, an informed or efficient energy approach is proposed for routing on the Internet of Things in which focus is on the sleep-wake schedule of nodes; therefore, a new optimization algorithm called chaos fuzzy grasshopper optimization algorithm was used. In chaos fuzzy grasshopper algorithm, the initial population of grasshoppers is generated by Lorenz chaos theory and the input and output parameters of the algorithm are adjusted by fuzzy approach. To evaluate the efficiency of the proposed method, three criteria of evaluation of remaining energy, network life and coverage rate were used. Investigating the findings in two different scenarios (efficiency over time and efficiency per number of different nodes) showed that the proposed method always is better than the base methods in all scenarios and for all performance evaluation criteria. So that in the study of the death of 30% of nodes which indicates the life of the network, results showed that the proposed method of the paper (FLGOA) has 9% better efficiency than FGOA, 12% better than GOA and 16% better than GSO. Also, the findings about the remaining energy of the network showed that the proposed method has 16% better efficiency than FGOA method, 21% better than GOA and 22% better than GSO. Finally, studies in the coverage rate evaluation criterion showed that the proposed method has 12% coverage rate better than FGOA method, 15% better than GOA and 16% better than GSO.
C1 [Mir, Masoomeh; Yaghoobi, Mahdi; Khairabadi, Maryam] Islamic Azad Univ, Neyshabour Branch, Neyshabour, Iran.
   [Yaghoobi, Mahdi] Islamic Azad Univ, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Yaghoobi, M (corresponding author), Islamic Azad Univ, Neyshabour Branch, Neyshabour, Iran.; Yaghoobi, M (corresponding author), Islamic Azad Univ, Mashhad Branch, Mashhad, Razavi Khorasan, Iran.
EM masoomeh.mir@gmail.com; yaghoobi@mshdiau.ac.ir;
   m.kheirabadi@iau-neyshabur.ac.ir
RI mir, massoomeh/JMQ-1262-2023
OI mir, masoumeh/0009-0000-1909-2185
CR Abbasi M, 2021, IEEE T INTELL TRANSP, V22, P4141, DOI 10.1109/TITS.2020.3014044
   Abbasi M, 2020, J SUPERCOMPUT, V76, P3105, DOI 10.1007/s11227-019-03090-3
   Abbasi M, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.185
   Abd El-Latif AA, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102549
   Airehrour D, 2016, J NETW COMPUT APPL, V66, P198, DOI 10.1016/j.jnca.2016.03.006
   Aslani Z., 2017, J COMPUT ROBOT, V10, P69
   Chen E.T, 2017, The internet of things in the modern business environment, V167, P187, DOI [10.4018/978-1-5225-2104-4.ch009, DOI 10.4018/978-1-5225-2104-4.CH009]
   Chhabra A, 2018, ARXIV PREPRINT ARXIV
   Conti M, 2018, FUTURE GENER COMP SY, V78, P544, DOI 10.1016/j.future.2017.07.060
   Elgendy IA, 2021, WIREL NETW, V27, P2023, DOI 10.1007/s11276-021-02554-w
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Guo B, 2016, IEEE COMMUN MAG, V54, P131, DOI 10.1109/MCOM.2016.7402272
   Jaiswal K., 2019, WIRELESS PERS COMMUN, V111, P1
   Machado K, 2013, SENSORS-BASEL, V13, P1942, DOI 10.3390/s130201942
   Mehta Rishika, 2018, Procedia Computer Science, V132, P1263, DOI 10.1016/j.procs.2018.05.042
   Muneer B, 2017, INT J COMMUN ANTENNA, V7
   Ng ICL, 2017, INT J RES MARK, V34, P3, DOI 10.1016/j.ijresmar.2016.11.003
   Park SH, 2014, J APPL MATH, DOI 10.1155/2014/213106
   Ray PP, 2018, J KING SAUD UNIV-COM, V30, P291, DOI 10.1016/j.jksuci.2016.10.003
   Shiravan BR, 2015, THESIS ISLAMIC AZAD
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Vellanki M, 2016, J THEOR COMPUT SCI, V3
   Wang XJ, 2018, IEEE COMMUN MAG, V56, P19, DOI 10.1109/MCOM.2018.1701065
   Yaghoubi, 2017, THESIS ISLAMIC AZAD
   Yin YH, 2016, J IND INF INTEGR, V1, P3, DOI 10.1016/j.jii.2016.03.004
   Zarpelao BB, 2017, J NETW COMPUT APPL, V84, P25, DOI 10.1016/j.jnca.2017.02.009
   Zhang WZ, 2021, IEEE INTERNET THINGS, V8, P8119, DOI 10.1109/JIOT.2020.3042433
NR 27
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5133
EP 5159
DI 10.1007/s11042-021-11841-9
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000740419000004
DA 2024-07-18
ER

PT J
AU Chavda, S
   Goyani, M
AF Chavda, Sagar
   Goyani, Mahesh
TI Robust image retrieval using CCV, GCH, and MS-LBP descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Feature extraction; Color coherence vector; Global color
   histogram; Multi-scale local binary pattern; Optimal feature selection;
   Principal component analysis; Linear discriminant analysis
ID DOMINANT COLOR DESCRIPTOR; BINARY PATTERNS; INTEGRATION; HISTOGRAM;
   FEATURES; WAVELET; SCALE; CBIR; CLASSIFICATION; RECOGNITION
AB Content-Based Image Retrieval (CBIR) is a well-known research topic from the computer vision domain which helps retrieve similar images from a dataset as per the specified query image. The retrieval performance is inadequate for benchmark datasets viz., Corel-1k, Corel-5k, Corel-10k, and Ghim-10k. In this paper, we have encountered the problem of the low retrieval rates of the CBIR system and the high dimensionality of the feature vectors. We have proposed the hybrid framework consisting of three different feature descriptors for robust retrieval performance. We have propounded the use of modified Multi-Scale Local Binary Pattern (MS-LBP), Color Coherence Vector (CCV), and Global Color Histogram (GCH) for image retrieval. We have exerted the modified MS-LBP because of its ability to capture more texture detail than Local Binary Pattern (LBP) at multiple scales. This larger filter size of MS-LBP makes it less vulnerable to noise and illumination than the conventional LBP descriptor. The CCV captures color with location information well enough, but it's vulnerable to the brightened images whereas, the GCH operator covers brightness (less sensitive to brightness than CCV), rotation, scale, translation, camera viewpoint invariant features, but lacks spatial information. The proposed framework improves the feature selection process by blending the strength of each of these descriptors. This paper also targets the high dimensionality of the feature vector of the MS-LBP and GCH descriptors by exerting Principal Component Analysis (PCA). Moreover, Linear Discriminant Analysis (LDA) selects robust and optimal features for retrieval. The proposed method is compared with state-of-the-art literature on four benchmark datasets in terms of Average Retrieval Precision (ARP), Average Retrieval Rate (ARR), and Retrieval Time (RT). Experimental results show that the proposed method excels the examined research practices.
C1 [Chavda, Sagar; Goyani, Mahesh] Gujarat Technol Univ, Ahmadabad 382424, Gujarat, India.
   [Chavda, Sagar; Goyani, Mahesh] Govt Engn Coll, Modasa 383315, India.
C3 Gujarat Technological University; Government Engineering College Modasa
RP Chavda, S (corresponding author), Gujarat Technol Univ, Ahmadabad 382424, Gujarat, India.; Chavda, S (corresponding author), Govt Engn Coll, Modasa 383315, India.
OI Chavda, Sagar/0000-0002-7478-6814
CR Abate AF, 2004, J VISUAL LANG COMPUT, V15, P373, DOI 10.1016/j.jvlc.2003.11.004
   Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   [Anonymous], 2006, INT C IM PROC, DOI DOI 10.1109/ICIP.2007.4379597
   [Anonymous], 2017, COMMUNICATION COMPUT
   [Anonymous], 2008, P 2008 INT C CONTENT, DOI DOI 10.1145/1386352.1386436
   [Anonymous], 2015, INT J RES STUDIES CO
   [Anonymous], 2013, Int. J. Sci. Res.
   Antani SL, 2008, COMP MED SY, P4, DOI 10.1109/CBMS.2008.133
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Boparai NK, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P944, DOI 10.1109/NGCT.2015.7375260
   Cai D, 2008, IEEE T KNOWL DATA EN, V20, P1, DOI 10.1109/TKDE.2007.190669
   Chavda S., 2020, SN Comput. Sci., V1, P305
   Chavda S, 2019, INT J NEXT-GENER COM, V10, P193
   Che C, 2017, EURASIP J ADV SIG PR, DOI 10.1186/s13634-017-0456-1
   Chen YH, 2020, CONNECT SCI, V32, P431, DOI 10.1080/09540091.2020.1753174
   Choras Ryszard S., 2010, Proceedings of the 9th WSEAS International Conference on Signal Processing (SIP 2010), P52
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Chuctaya H, 2012, P INT C CHIL COMPUT, P135, DOI 10.1109/SCCC.2011.18
   Colombo C., 2002, IMAGE DATABASES, P11, DOI DOI 10.1002/0471224634.CH2
   Davatzikos C, 2003, IEEE T MED IMAGING, V22, P414, DOI 10.1109/TMI.2003.809688
   Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   Duanmu X., 2010, 7 INT C INF TECHN, P200, DOI DOI 10.1109/ITNG.2010.231
   Dubey SR, 2015, 2015 IEEE UP SECTION CONFERENCE ON ELECTRICAL COMPUTER AND ELECTRONICS (UPCON), DOI 10.1109/UPCON.2015.7456703
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Eakins JP, 1998, IEEE MULTIMEDIA, V5, P53, DOI 10.1109/93.682526
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Enser PGB, 2006, LECT NOTES COMPUT SC, V3736, P177
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Graham M.E., 2001, ART LIB J, V26, P22, DOI DOI 10.1017/S0307472200012001
   Hafiane A, 2006, PATTERN RECOGN LETT, V27, P259, DOI 10.1016/j.patrec.2005.08.007
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HOLT B, 1994, ASLIB PROC, V46, P243, DOI 10.1108/eb051371
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   Ivanova K, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN MULTIMEDIA, P180, DOI 10.1109/MMEDIA.2009.41
   Jabid Taskeed, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P482, DOI 10.1109/AVSS.2010.17
   Jacob IJ, 2020, PATTERN ANAL APPL, V23, P239, DOI 10.1007/s10044-019-00780-9
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   JIANG XY, 1991, PATTERN RECOGN, V24, P801, DOI 10.1016/0031-3203(91)90047-9
   JOLLIFFE I., 2011, International Encyclopedia of Statistical Science, DOI DOI 10.1007/978-3-642-04898-2_455
   Jones BF, 2004, P ANN INT IEEE EMBS, V26, P1186
   KANAMADI M, 2010, J XIAN U POSTS TELEC, V3, P651, DOI DOI 10.1016/S1005-8885(11)60221-5
   Kaushik C., 2000, SIMILAR SHAPE RETRIE
   Koteswara Rao L., 2019, Innovations in Electronics and Communication Engineering. Proceedings of the 7th ICIECE 2018. Lecture Notes in Networks and Systems (LNNS 65), P115, DOI 10.1007/978-981-13-3765-9_13
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kumar TGS, 2019, PATTERN ANAL APPL, V22, P1233, DOI 10.1007/s10044-018-0724-1
   Kumar TGS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1190, DOI 10.1109/ICCSP.2015.7322694
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P2289, DOI 10.1007/s11042-014-2129-5
   Lei Zhu, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P969, DOI 10.1109/ICIG.2011.121
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   List J, 2007, WORLD PAT INF, V29, P210, DOI 10.1016/j.wpi.2007.01.001
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Liu Y, 2017, C IND ELECT APPL, P149, DOI 10.1109/ICIEA.2017.8282831
   Lopes Ana P. B., 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1552
   Lopes APB, 2009, SIBGRAPI, P224, DOI 10.1109/SIBGRAPI.2009.32
   Lu FX, 2016, INT CONF ACOUST SPEE, P1308, DOI 10.1109/ICASSP.2016.7471888
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mathew SP, 2015, ACTA POLYTECH HUNG, V12, P103
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Mohiuddin F, 2017, 2017 20TH INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATION TECHNOLOGY (ICCIT)
   Müller S, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P23, DOI 10.1109/IVL.1999.781118
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Niu DM, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115911
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Pardede J, 2018, 2018 19TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P58, DOI 10.1109/SNPD.2018.8441075
   Pass G, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P96, DOI 10.1109/ACV.1996.572008
   Pass G., 1996, Proceedings ACM Multimedia 96, P65, DOI 10.1145/244130.244148
   Pavithra LK, 2020, MULTIDIM SYST SIGN P, V31, P1411, DOI 10.1007/s11045-020-00713-4
   Pradhan J, 2020, VISUAL COMPUT, V36, P1847, DOI 10.1007/s00371-019-01773-9
   Pradhan J, 2018, DIGIT SIGNAL PROCESS, V82, P258, DOI 10.1016/j.dsp.2018.07.016
   Rao LK, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2664-9
   Raza A, 2019, MULTIMED TOOLS APPL, V78, P2719, DOI 10.1007/s11042-018-5795-x
   Rohini P., 2019, Innovations in Electronics and Communication Engineering. Proceedings of the 7th ICIECE 2018. Lecture Notes in Networks and Systems (LNNS 65), P107, DOI 10.1007/978-981-13-3765-9_12
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Ruiz Miguel E, 2006, AMIA Annu Symp Proc, P674
   Shriram K. V., 2015, International Journal of Advanced Intelligence Paradigms, V7, P264
   Shyu CR, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P102, DOI 10.1109/IVL.1999.781132
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Soni D, 2015, INT CONF COMM SYST, P488, DOI 10.1109/CSNT.2015.80
   Srivastava P, 2014, 2 INT C CONT AW SYST, P228, DOI DOI 10.1007/978-3-319-05939-6_23
   Srivastava P., 2018, INT J COMPUTATIONAL, V8, P375, DOI [10.1504/IJCVR.2018.093967, DOI 10.1504/IJCVR.2018.093967]
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Sun JD, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P139
   Suresh M. B., 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P3399, DOI 10.1109/ICECDS.2017.8390091
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tiwari A, 2004, SHAPING BUSINESS STRATEGY IN A NETWORKED WORLD, VOLS 1 AND 2, PROCEEDINGS, P1167
   Tuanase-Avuatavului M., 2005, ASCI DISSERTATION SE, V112, P1
   Umamaheswaran S, 2020, INT J SPEECH TECHNOL, V23, P243, DOI 10.1007/s10772-019-09663-0
   Van Der Merwe JS., 2005, 16 ANN S PATT REC AS, V1, P24
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Vipparthi SK, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0006-x
   Vrochidis S, 2010, WORLD PAT INF, V32, P94, DOI 10.1016/j.wpi.2009.05.010
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang Y, 2007, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P3
   Xia Y, 2013, LECT NOTES COMPUT SC, V8210, P423, DOI 10.1007/978-3-319-02750-0_45
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Yu J, 2013, NEUROCOMPUTING, V120, P355, DOI 10.1016/j.neucom.2012.08.061
   Yuan BH, 2020, NEURAL COMPUT APPL, V32, P11717, DOI 10.1007/s00521-019-04657-0
   Zhang D.S., 2001, Proceedings of International Conference on Intelligent Multimedia and Distance Education(ICIMADE01), P1
   Zhang L., 2004, MULTIMEDIA 04, P716
   Zhou JX, 2018, INT J MACH LEARN CYB, V9, P677, DOI 10.1007/s13042-016-0597-9
   Zhou JX, 2019, MULTIMED TOOLS APPL, V78, P6163, DOI 10.1007/s11042-018-6192-1
NR 109
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4039
EP 4072
DI 10.1007/s11042-021-11698-y
EA NOV 2021
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000723529100001
DA 2024-07-18
ER

PT J
AU Charmouti, B
   Junoh, AK
   Abdurrazzaq, A
   Mashor, MY
AF Charmouti, Bilal
   Junoh, Ahmad Kadri
   Abdurrazzaq, Achmad
   Mashor, Mohd Yusoff
TI A new denoising method for removing salt & pepper noise from image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Image restoration; Salt and pepper noise; Sequence;
   Digital image
ID ANISOTROPIC 2ND; MEDIAN FILTER; REGULARIZATION; TRANSFORM
AB Digital image has a significant importance in many fields in human life such as, in medicine, photography, biology, astronomy, industry and defense. Thus, it attracts the attention of large number of researchers, among them those interested in preserving the image features from any factors that may reduce the image quality. One of these factors is the noise. Thus far, solving this noise problem remains a challenge point for the researchers in this field, a huge number of image denoising techniques have been introduced in order to remove the noise with taking care of the image features (edges, sharpness). However, besides that, the findings proved to be inconclusive yet. From this point, the current paper aims to introduce a new denoising method for removing salt & pepper noise from the digital image through spatial way. This denoising method exploits the relationship between pixel's values when the image changes color. Which gives ordered sequences of values in the four directions, horizontal, vertical and diagonals of the window. The proposed method relays on this concept to change the corrupted pixel, by using the neighbors in the window to extracts the truest value (subjects to this sequence) of the treated pixel. This method has been proven to be simple, effective and performing well comparing with the existing restoration methods with low computational cost.
C1 [Charmouti, Bilal; Junoh, Ahmad Kadri] Univ Malaysia Perlis, Ctr Excellence Social Innovat & Sustainabil CoESI, Cluster Math Sci & Data Analyt, Arau 02600, Perlis, Malaysia.
   [Abdurrazzaq, Achmad] Indonesia Def Univ, Fac Mil Math & Nat Sci, Dept Math, IPSC Area, Bogor 16810, Indonesia.
   [Mashor, Mohd Yusoff] Univ Malaysia Perlis, Sch Mechatron, Arau 02600, Perlis, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Malaysia Perlis
RP Abdurrazzaq, A (corresponding author), Indonesia Def Univ, Fac Mil Math & Nat Sci, Dept Math, IPSC Area, Bogor 16810, Indonesia.
RI Abdurrazzaq, Achmad/AAD-5753-2021
OI Abdurrazzaq, Achmad/0000-0002-9227-023X
CR Abdurrazzaq A, 2020, MULTIMED TOOLS APPL, V79, P19659, DOI 10.1007/s11042-020-08847-0
   Abdurrazzaq A, 2019, IET IMAGE PROCESS, V13, P2790, DOI 10.1049/iet-ipr.2018.6201
   Abdurrazzaq A, 2019, TURK J ELECTR ENG CO, V27, P1667, DOI 10.3906/elk-1807-93
   Ajay K.B., 2015, Signal & Image Processing, V6, P63, DOI [DOI 10.5121/SIPIJ.2015.6206, 10.5121/sipij.2015.6206]
   [Anonymous], 1998, P IEEE INT C COMP VI
   [Anonymous], 2012, IMAGE RESTORATION FU
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Charmouti B., 2019, Telkomnika, V17, P2959, DOI [10.12928/telkomnika.v17i6.11301, DOI 10.12928/TELKOMNIKA.V17I6.11301]
   Demanet L, 2007, APPL COMPUT HARMON A, V23, P368, DOI 10.1016/j.acha.2007.03.003
   Ding Y, 2015, IEEE SIGNAL PROC LET, V22, P1364, DOI 10.1109/LSP.2015.2406314
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Elyasi I, 2016, OPTIK, V127, P11732, DOI 10.1016/j.ijleo.2016.09.054
   Erkan U, 2018, COMPUT ELECTR ENG, V70, P789, DOI 10.1016/j.compeleceng.2018.01.019
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   LINDENBAUM M, 1994, PATTERN RECOGN, V27, P1, DOI 10.1016/0031-3203(94)90013-2
   Liu J, 2013, IEEE T IMAGE PROCESS, V22, P1108, DOI 10.1109/TIP.2012.2227766
   Liu LC, 2017, IEEE T CYBERNETICS, V47, P600, DOI 10.1109/TCYB.2016.2521428
   Lv XG, 2015, J COMPUT APPL MATH, V290, P553, DOI 10.1016/j.cam.2015.06.006
   Mallat S, 2009, WAVELET TOUR OF SIGNAL PROCESSING: THE SPARSE WAY, P1
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Singh V, 2018, IEEE T FUZZY SYST, V26, P3170, DOI 10.1109/TFUZZ.2018.2805289
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sun, 2013, FAST GUIDED FILTERIN
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Wang HB, 2012, COMPUT SCI INF SYST, V9, P1493, DOI 10.2298/CSIS120219060W
   Wang YQ, 2013, COMPUT MATH APPL, V66, P1729, DOI 10.1016/j.camwa.2013.08.034
   Xiao, 2016, SHOCK VIB, V2016, P1
   Yan M, 2013, SIAM J IMAGING SCI, V6, P1227, DOI 10.1137/12087178X
   Yaroslavsky L.P., 1986, Appl. Opt., V25, P3127
   Zhu, 2014, APPL MECH MAT
NR 36
TC 6
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3981
EP 3993
DI 10.1007/s11042-021-11615-3
EA NOV 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722981800001
DA 2024-07-18
ER

PT J
AU Yang, B
   Xiang, XQ
   Kong, WZ
   Peng, Y
   Yao, JL
AF Yang, Bing
   Xiang, Xueqin
   Kong, Wanzeng
   Peng, Yong
   Yao, Jinliang
TI Adaptive multi-task learning using lagrange multiplier for automatic art
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic art analysis; Multi-task learning; lagrange multiplier
   strategy
ID CLASSIFICATION
AB Numerous computer vision applications, such as image classification, have benefited from multi-task learning techniques. However, the relative weighting between each task's loss is hard to be tuned by hand, causing multi-task learning prohibitive in real applications. In this paper, we present a novel and principled adaptive multi-task learning method that weights multiple loss functions based on lagrange multiplier strategy. Our method starts from the standard multi-task learning model. Based on Gaussian likelihood and lagrange multiplier, we then design an adaptive multi-task learning model to learn suitable weightings of each task and boost performance. In order to validate the feasibility of proposed method, we conduct automatic art analysis tests, including art classification and cross-modal art retrieval. Experimental results demonstrate that our method outperforms several state-of-the-art techniques, showing that performance is improved by up to 4.2% in art classification and 8.7% in cross-modal art retrieval when compared with the latest automatic loss weights learning method.
C1 [Yang, Bing; Kong, Wanzeng; Peng, Yong; Yao, Jinliang] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
   [Xiang, Xueqin] uSens Inc, Nanhuan Rd, Hangzhou 310007, Peoples R China.
C3 Hangzhou Dianzi University
RP Xiang, XQ (corresponding author), uSens Inc, Nanhuan Rd, Hangzhou 310007, Peoples R China.
EM xxueq@aliyun.com
RI Peng, Yong/JCO-0601-2023
OI Peng, Yong/0000-0003-1208-972X; yang, bing/0000-0002-0585-0579; xiang,
   xueqin/0009-0004-4767-8078
FU National Natural Science Foundation of China [U1909202]; Key Laboratory
   of Brain Machine Collaborative Intelligence of Zhejiang Province
   [2020E10010]; Fundamental Research Funds for the Provincial Universities
   of Zhejiang, China [GK209907299001-008]
FX This work was supported by the National Natural Science Foundation of
   China (U1909202), Key Laboratory of Brain Machine Collaborative
   Intelligence of Zhejiang Province (2020E10010) and Fundamental Research
   Funds for the Provincial Universities of Zhejiang, China
   (GK209907299001-008).
CR [Anonymous], 2015, Large-scale classification of fine-art paintings: Learning the right metric on the right feature, DOI 10
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2016, CORR
   Bar Y, 2015, LECT NOTES COMPUT SC, V8925, P71, DOI 10.1007/978-3-319-16178-5_5
   Bilen H., 2016, ADV NEURAL INFORM PR, P235
   Carneiro G, 2012, LECT NOTES COMPUT SC, V7575, P143, DOI 10.1007/978-3-642-33765-9_11
   Chen Z, 2018, PR MACH LEARN RES, V80
   Chu WT, 2018, IEEE T MULTIMEDIA, V20, P2491, DOI 10.1109/TMM.2018.2801718
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Collomosse J, 2017, IEEE I CONF COMP VIS, P2679, DOI 10.1109/ICCV.2017.290
   Crowley E., 2014, BRIT MACH VIS C BMVC
   Crowley Elliot J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P721, DOI 10.1007/978-3-319-46604-0_50
   Garcia N, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P25, DOI 10.1145/3323873.3325028
   Garcia N, 2019, LECT NOTES COMPUT SC, V11130, P676, DOI 10.1007/978-3-030-11012-3_52
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Johnson CR, 2008, IEEE SIGNAL PROC MAG, V25, P37, DOI 10.1109/MSP.2008.923513
   Kalman D., 2009, Math. Mag, V82, P186, DOI [DOI 10.1080/0025570X.2009.11953617, 10.1080/0025570X.2009.11953617]
   Karayev S., 2014, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.28.122, 10.5244/c.28.122, 10.5244%2Fc.28.122, 10.5244/C.28.122]
   Kendall A, 2017, 31 ANN C NEURAL INFO, V30
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Li LQ, 2020, MULTIMED TOOLS APPL, V79, P14509, DOI 10.1007/s11042-018-6970-9
   Li XT, 2019, IEEE T CYBERNETICS, V49, P1680, DOI 10.1109/TCYB.2018.2817480
   Long M, 2015, ABS1506021173 CORR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma DQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1174, DOI 10.1145/3123266.3123325
   Mao H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1183, DOI 10.1145/3123266.3123405
   Mensink T, 2014, P INT C MULT RETR, P451, DOI DOI 10.1145/2578726.2578791
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Ruder S., 2016, ARXIV
   Sanakoyeu A, 2018, LECT NOTES COMPUT SC, V11212, P715, DOI 10.1007/978-3-030-01237-3_43
   Seguin Benoit, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P753, DOI 10.1007/978-3-319-46604-0_52
   Sener O, 2018, ADV NEUR IN, V31
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strezoski G, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3273022
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu YL, 2018, IEEE T NEUR NET LEAR, V29, P5408, DOI 10.1109/TNNLS.2018.2802469
   Yang Y., 2017, ICLR
   Yang YQ, 2020, MULTIMED TOOLS APPL, V79, P26787, DOI 10.1007/s11042-020-09185-x
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhao YC, 2019, MULTIMED TOOLS APPL, V78, P13131, DOI 10.1007/s11042-018-5609-1
NR 45
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3715
EP 3733
DI 10.1007/s11042-021-11360-7
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000720701700001
DA 2024-07-18
ER

PT J
AU Ohtomo, K
   Harakawa, R
   Ogawa, T
   Haseyama, M
   Iwahashi, M
AF Ohtomo, Kazuma
   Harakawa, Ryosuke
   Ogawa, Takahiro
   Haseyama, Miki
   Iwahashi, Masahiro
TI User-centric multimodal feature extraction for personalized retrieval of
   tumblr posts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social networking services; Multimedia information retrieval; Multimodal
   analysis; Deep metric learning
ID HUMAN ACTIVITY RECOGNITION; TRACKING; ENGINE
AB Tumblr is one of the most popular micro-blogging services worldwide on which users can share posts consisting of texts and images. This paper proposes a user-centric method of multimodal feature extraction for the personalized retrieval of Tumblr posts. To implement personalized retrieval, we formulate each user's preferences as a triplet loss by using Likes as metadata as well as the text- and image-related features of posts. Furthermore, we develop a personalized multivariational autoencoder (PMVAE) by introducing a triplet loss into multivariational autoencoder (MVAE), which is among the most effective methods of multimodal feature extraction. Previously proposed variants of MVAE can project multiple kinds of features into the single latent features. However, because the latent features do not reflect each user's preferences, retrieval performance when using the previous methods is limited. On the contrary, our PMVAE can extract relationships between text- and image-related features of posts by considering class-related information that represents whether a user prefers a given post. As a result, user-centric multimodal features, which separate a post that a user prefer and a post that a user does not prefer in the latent feature space, can be obtained. Because user-centric multimodal features have high discriminating power, the personalized retrieval of posts desired by each user becomes feasible by using them in such retrieval algorithms as the k-nearest neighbors and Annoy, which is a technique for approximate nearest neighbor search. We conduct experiments using 10 users and 150,947 contents, to verify the performance of k-NN and Annoy. The results show that our PMVAE increased normalized discounted cumulative gain (nDCG) compared with existing methods. The nDCG becomes 0.253 when using term frequency-inverse document frequency based text features and our end-to-end image features.
C1 [Ohtomo, Kazuma; Harakawa, Ryosuke; Iwahashi, Masahiro] Nagaoka Univ Technol, Dept Elect Elect & Informat Engn, Nagaoka, Niigata, Japan.
   [Ogawa, Takahiro; Haseyama, Miki] Hokkaido Univ, Fac Informat Sci & Technol, Sapporo, Hokkaido, Japan.
C3 Nagaoka University of Technology; Hokkaido University
RP Ohtomo, K (corresponding author), Nagaoka Univ Technol, Dept Elect Elect & Informat Engn, Nagaoka, Niigata, Japan.
EM ohtomo@stn.nagaokaut.ac.jp
RI Ohtomo, Kazuma/IQU-8687-2023
OI Ohtomo, Kazuma/0000-0003-3217-3662
FU JSPS KAKENHI [JP21K17861]; MIC/SCOPE [181601001]; Grants-in-Aid for
   Scientific Research [21K17861, 21H03456] Funding Source: KAKEN
FX We thank Saad Anis, PhD, from Edanz Group
   (https://en-author-services.edanzgroup.com/) for editing a draft of this
   manuscript. This work was partly supported by JSPS KAKENHI Grant Number
   JP21K17861, and the MIC/SCOPE #181601001.
CR Ahmed A, 2020, INT BHURBAN C APPL S, P290, DOI [10.1109/ibcast47879.2020.9044545, 10.1109/IBCAST47879.2020.9044545]
   Ai QY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P645, DOI 10.1145/3077136.3080813
   Almatarneh S., 2019, P 13 INT WORKSH SEM P 13 INT WORKSHOP SE, P387, DOI DOI 10.18653/V1/S19-2068
   [Anonymous], 2012, INT S SUST HLTH BUIL
   [Anonymous], USER CENTRIC SOCIAL
   [Anonymous], 2017, P 2017 IEEEACM INT C
   [Anonymous], BIOCH J
   Chang Yi., 2014, ACM SIGKDD EXPLORATI, V16, P21, DOI DOI 10.1145/2674026.2674030
   Chen YT, 2018, AAAI CONF ARTIF INTE, P2852
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P125, DOI 10.1145/2911451.2911491
   Devlin J., 2018, BERT PRE TRAINING DE
   Farooq A, 2015, KSII T INTERNET INF, V9, P1856, DOI 10.3837/tiis.2015.05.017
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Harakawa R, 2019, IEEE ACCESS, V7, P116207, DOI 10.1109/ACCESS.2019.2936404
   Harakawa R, 2018, MULTIMED TOOLS APPL, V77, P18741, DOI 10.1007/s11042-018-5876-x
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu N, 2009, COMMUN ACM, V52, P144, DOI 10.1145/1562764.1562800
   Isaac Sparling E., 2011, P 5 ACM C REC SYST R, P149, DOI [10.1145/2043932.2043961, DOI 10.1145/2043932.2043961]
   Jala A, 2019, J ELECTR ENG TECHNOL, V14, P1733
   Jalal A., 2014, 5 INT C COMPUTING CO, P1, DOI DOI 10.1109/ICCCNT.2014.6963015
   Jalal A, 2016, J COMPUT NETW COMMUN, V2016, DOI 10.1155/2016/8087545
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jalal A, 2015, INT CONF UBIQ ROBOT, P294, DOI 10.1109/URAI.2015.7358957
   Jalal A, 2015, 2015 IEEE 29TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS WAINA 2015, P445, DOI 10.1109/WAINA.2015.38
   Jalal A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P119, DOI 10.1109/AVSS.2014.6918654
   Jalal A, 2014, SENSORS-BASEL, V14, P11735, DOI 10.3390/s140711735
   Jalal A, 2013, INDOOR BUILT ENVIRON, V22, P271, DOI 10.1177/1420326X12469714
   Jian Wang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2612, DOI 10.1109/ICCV.2017.283
   Jin ZW, 2017, LECT NOTES COMPUT SC, V10354, P14, DOI 10.1007/978-3-319-60240-0_2
   Kamal S, 2016, J ELECTR ENG TECHNOL, V11, P1857, DOI 10.5370/JEET.2016.11.6.1857
   Kamal S, 2016, ARAB J SCI ENG, V41, P1043, DOI 10.1007/s13369-015-1955-8
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kim K, 2019, J ELECTR ENG TECHNOL, V14, P2567, DOI 10.1007/s42835-019-00278-8
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   Lee J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P481, DOI 10.1145/3219819.3219856
   Li W, 2020, IEEE T KNOWL DATA EN, V32, P1475, DOI 10.1109/TKDE.2019.2909204
   Liang JQ, 2018, PATTERN RECOGN, V75, P188, DOI 10.1016/j.patcog.2017.02.032
   Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1571, DOI 10.1145/3240508.3240646
   Lin XD, 2018, LECT NOTES COMPUT SC, V11219, P714, DOI 10.1007/978-3-030-01267-0_42
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Mahmood M, 2020, MULTIMED TOOLS APPL, V79, P6919, DOI 10.1007/s11042-019-08527-8
   Mekala Dheeraj, 2016, ARXIV PREPRINT ARXIV
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nadeem A, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055951
   Osterland S, 2019, INT J HYDROMECHATRON, V2, P32
   Passalis N, 2020, PATTERN RECOGN LETT, V131, P8, DOI 10.1016/j.patrec.2019.11.041
   Quaid MAK, 2020, MULTIMED TOOLS APPL, V79, P6061, DOI 10.1007/s11042-019-08463-7
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Ramachandran P., 2017, Searching for activation functions
   Rizwan S. A., 2020, 2020 3 INT C ADV COM, P1
   Roostaiyan SM, 2017, INTELL DATA ANAL, V21, P1351, DOI 10.3233/IDA-163196
   Roy A, 2017, PROC INT C TOOLS ART, P772, DOI 10.1109/ICTAI.2017.00122
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Seyedin S., 2009, 2009 7 INT C INF COM, V1, P1
   Shi Y., 2019, ADV NEURAL INFORM PR, P15718
   Shokri M, 2019, INT J HYDROMECHATRON, V2, P178
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sonderby C. K., 2016, 33 INT C MACH LEARN, P1
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Susan S, 2019, CAAI T INTELL TECHNO, V4, P101, DOI 10.1049/trit.2019.0002
   Suzuki M., 2016, ARXIV161101891
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tabrizi SA, 2018, INFORM PROCESS MANAG, V54, P630, DOI 10.1016/j.ipm.2018.04.004
   Tahir SBUD, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055944
   Tautkute I, 2019, IEEE ACCESS, V7, P84613, DOI 10.1109/ACCESS.2019.2923552
   Vedantam R., 2017, ARXIV170510762
   Vicente-López E, 2016, KNOWL-BASED SYST, V112, P127, DOI 10.1016/j.knosys.2016.09.005
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang W., 2016, ARXIV161003454
   Wiens T, 2019, INT J HYDROMECHATRON, V2, P16
   Wu MK, 2018, ADV NEUR IN, V31
   Wu Y, 2017, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2017.424
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yaacob N. I., 2012, 2012 IEEE Symposium on Humanities, Science and Engineering Research (SHUSER), P379, DOI 10.1109/SHUSER.2012.6268871
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu TT, 2019, CAAI T INTELL TECHNO, V4, P122, DOI 10.1049/trit.2019.0017
   Zhao W., 2017, EAI ENDORSED T COLLA, V3, P12, DOI [10.4108/eai.9-10-2017.154549, DOI 10.4108/EAI.9-10-2017.154549]
   Zhu CM, 2019, CAAI T INTELL TECHNO, V4, P255, DOI 10.1049/trit.2019.0036
NR 83
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2979
EP 3003
DI 10.1007/s11042-021-11634-0
EA NOV 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000717417200001
DA 2024-07-18
ER

PT J
AU Lefevre, F
   Bombardier, V
   Charpentier, P
   Krommenacker, N
AF Lefevre, Florent
   Bombardier, Vincent
   Charpentier, Patrick
   Krommenacker, Nicolas
TI Context-based camera selection from multiple video streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge modelling; Camera selection; Automatic editing
ID BROADCAST
AB Multi-camera systems are often used for broadcasting various events such as sports, education, concerts or meetings. In such systems, automatic editing is necessary to choose the camera to broadcast according to the main action in the scene. However, automatic camera selection methods often are specific to a particular event. In this work, we propose to model the functionalities of automatic editing systems based on the analysis of the state of the art in order to isolate the application context. This allows us to propose an automatic camera selection method based on a knowledge-model. This model aims to represent the specification and formalisation of the knowledge of an application context. The proposed method has been successfully applied for municipal councils broadcast. This leads to create a context event ontology - Person Of Interest (POI), Action Of Interest (AOI) - related to municipal council. Moreover, in order to offer live broadcasting, a new speaker detection method is proposed. The speaker detection method has been checked on a large ground truth with an accuracy better than 98%.
C1 [Lefevre, Florent; Bombardier, Vincent; Charpentier, Patrick; Krommenacker, Nicolas] Univ Lorraine, CRAN CNRS UMR 7039, F-54506 Vandoeuvre Les Nancy, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Lorraine
RP Bombardier, V (corresponding author), Univ Lorraine, CRAN CNRS UMR 7039, F-54506 Vandoeuvre Les Nancy, France.
EM vincent.bombardier@univ-loraine.fr
RI Krommenacker, Nicolas/IAR-4851-2023
OI , Vincent/0000-0002-3482-2008
CR ADearden, 2007, P ART AMB INT S, P227
   Almecija B., 2012, IFAC P VOLUMES, V45, P1190, DOI [10.3182/20120523-3-RO-2023.00361, DOI 10.3182/20120523-3-RO-2023.00361]
   [Anonymous], 1998, P JOINT DARPA NIST S
   Ariki Y, 2006, IEEE INT SYM MULTIM, P851
   Armansyah RF, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND SMART DEVICES (ISESD), P315, DOI 10.1109/ISESD.2016.7886741
   Bano S, 2016, MULTIMED TOOLS APPL, V75, P7187, DOI 10.1007/s11042-015-2641-2
   Benarab D-E., 2016, THESIS U BRETAGNE OC
   Changsong Shen, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P193
   Chen C., 2013, 2013 IEEE INT C MULT, P1, DOI DOI 10.1109/NSSMIC.2013.6829480
   Chen F, 2011, IEEE T MULTIMEDIA, V13, P1381, DOI 10.1109/TMM.2011.2166379
   Chen F, 2010, COMPUT VIS IMAGE UND, V114, P667, DOI 10.1016/j.cviu.2010.01.005
   Chen J., 2018, Ph.D. Thesis
   ChenJ CarrP, 2014, WORKSH 28 AAAI C ART, P18
   Cricri F, 2014, MULTIMED TOOLS APPL, V70, P119, DOI 10.1007/s11042-012-1085-1
   Cutler R, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1589, DOI 10.1109/ICME.2000.871073
   D'Arca Eleonora, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1532, DOI 10.1109/ICASSP.2014.6853854
   Daigo S., 2004, Proceedings of the 12th annual ACM international conference on Multimedia, P444
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Dee HM, 2008, MACH VISION APPL, V19, P329, DOI 10.1007/s00138-007-0077-z
   DiBiase JH, 2001, DIGITAL SIGNAL PROC, P157
   Doubek P., 2004, P WORKSHOP OMNIDIREC, P17
   Falelakis M., 2012, P 2012 INT WORKSH SO, P25, DOI DOI 10.1145/2390876.2390886EVENT-PLACE:NARA,JAPAN
   Gaddam VR, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2744411
   Gandhi, 2014, THESIS U GRENOBLE
   Gatica-Perez, 2005, P INT WORKSH IM AN M, P10
   Gleicher M., 2000, Proceedings ACM Multimedia 2000, P375, DOI 10.1145/354384.354537
   Halpin, 1998, J CONCEPTUAL MODELIN, V1, P12
   Halpin T., 1998, Handbook on Architectures of Information Systems, P81
   Han L, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225145
   HodrobR, 2010, P INT C INT SEM WEB, P131
   Hulens D, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P371, DOI 10.1109/CRV.2014.57
   Joblove G.H., 1978, P 5 ANN C COMP GRAPH, VVolume 12, P20, DOI DOI 10.1145/965139.807362
   Kameda Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P677
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   Kosmopoulos DI, 2009, SIGNAL PROCESS-IMAGE, V24, P158, DOI 10.1016/j.image.2008.12.010
   Kubicek, 2008, COMPUTER VISION GRAP, P260
   Le Moigne J.-L., 1999, La modelisation des systemes complexes
   Lefevre, 2018, INT C PATTERN RECOGN
   Lefevre, 2018, 1 GLOB LIFI C PAR FR
   Madhu N., 2008, P INT WORKSH AC ECH
   Marca D.A., 1987, SADT - Structured Analysis and Design Technique
   Mate S., 2017, THESIS TEMPERE U TEC
   Mavlankar A., 2010, 2010 18th International Packet Video Workshop (PV 2010), P64, DOI 10.1109/PV.2010.5706821
   Mehmood, 2015, THESIS ECOLE CENTRAL
   Mendez-Villanueva A, 2013, INT J SPORTS MED, V34, P101, DOI 10.1055/s-0032-1306323
   Merabti B, 2016, COMPUT GRAPH FORUM, V35, P51, DOI 10.1111/cgf.12775
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Nijssen G.M., 1989, CONCEPTUAL SCHEMA RE
   Pang, 2010, AUTOMATIC VIRTUAL CA
   Parisot P, 2017, COMPUT VIS IMAGE UND, V159, P74, DOI 10.1016/j.cviu.2017.01.001
   Pinhanez C, 1995, IJCAI 95 WORKSH ENT
   Pinhanez CS, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1116
   Podlesnyy Sergey, 2020, Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery. Advances in Intelligent Systems and Computing (AISC 1074), P361, DOI 10.1007/978-3-030-32456-8_39
   Qiong Liu, 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P442
   Quek F., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P119, DOI 10.1109/RATFG.1999.799234
   Ramanathan V, 2016, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2016.332
   Rui Y, 2004, MULTIMEDIA SYST, V10, P3, DOI 10.1007/s00530-004-0132-9
   Snidaro L, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P364, DOI 10.1109/AVSS.2003.1217944
   Stillittano S, 2013, MACH VISION APPL, V24, P1, DOI 10.1007/s00138-012-0445-1
   Takemae Y., 2005, ACM CHI, P1817
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   Yamada T, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1317, DOI 10.1109/ICSLP.1996.607855
   Yus R, 2015, MULTIMED TOOLS APPL, V74, P4059, DOI 10.1007/s11042-013-1810-4
NR 64
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2803
EP 2826
DI 10.1007/s11042-021-11674-6
EA NOV 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714884800003
DA 2024-07-18
ER

PT J
AU Wang, HN
   Zhang, BC
   Chen, W
AF Wang, Hainan
   Zhang, Baochang
   Chen, Wei
TI Robust and real-time object recognition based on multiple fractal
   dimension
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object representation; Fractal dimension; Multiple fractal dimensions
ID SALIENCY DETECTION; CLASSIFICATION
AB We proposes a multiple fractal dimensions (MFD) method for robust object description. MFD is an effective feature extraction approach, which is first calculated based on a phase angle quantization method to categorize the points of the input image. And then fractal dimensions are calculated to describe the distribution of feature pattern characterized as the intrinsic property of the general objects, i.e., land scene, face and pedestrian. We theoretically proven that our MFD is shown to be invariant to local variations, i.e., Bi-Lipschitz, which is a desirable characteristic for objects, such as land-scene images, face and pedestrian due to the existence of scale variations, local variations and illumination variations in those images. The proposed method is extensively evaluated on land-use scene recognition, face recognition, expression recognition, and pedestrian detection. The experimental results on UC Merced 21-class scene dataset, AR, JAFFE and INRIA pedestrian databases show that our method achieves superior performances over several state-of-the-art methods in terms of recognition rates.
C1 [Wang, Hainan] Guiyang Univ, Sch Mech Engn, Guiyang, Peoples R China.
   [Zhang, Baochang] Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
   [Zhang, Baochang] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Chen, Wei] Beijing Jiaotong Univ, State Key Lab Rail Traff Control & Safety, Beijing, Peoples R China.
C3 Guiyang University; Nanchang Institute Technology; Beihang University;
   Beijing Jiaotong University
RP Zhang, BC (corresponding author), Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.; Zhang, BC (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
EM bczhang@139.com
FU Guiyang University;  [GYU-KY - [2021]]
FX This work is supported by "Initial funding for doctoral research of
   Guiyang University" and Project No. (GYU-KY - [2021]). We also thank
   Yanlong Hou for his work on the experiments.
CR Ansuini C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120432
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen C, 2016, SIGNAL IMAGE VIDEO P, V10, P745, DOI 10.1007/s11760-015-0804-2
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Conci A, 2000, IEEE IMAGE PROC, P792, DOI 10.1109/ICIP.2000.901078
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du QA, 2009, J REAL-TIME IMAGE PR, V4, P273, DOI 10.1007/s11554-008-0106-9
   Espinal F, 1998, OPT ENG, V37, P166, DOI 10.1117/1.601844
   Fan JQ, 2018, IEEE ACCESS, V6, P56526, DOI 10.1109/ACCESS.2018.2872691
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Huang LH, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060483
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Kam L, 2000, PROC CVPR IEEE, P58, DOI 10.1109/CVPR.2000.855799
   Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885
   Li TP, 2019, MULTIMED TOOLS APPL, V78, P21309, DOI 10.1007/s11042-019-7403-0
   Liang JZ, 2017, IEEE ACCESS, V5, P17201, DOI 10.1109/ACCESS.2017.2741223
   Liu K, 2016, J REAL-TIME IMAGE PR, V11, P201, DOI 10.1007/s11554-013-0333-6
   Martinez A., 1998, AR FACE DATABASE
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Peitgen H.O., 1993, Chaos and Fractals: New Frontiers of Sciences
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   Tolle CR, 2003, IEEE T PATTERN ANAL, V25, P32, DOI 10.1109/TPAMI.2003.1159944
   Tuzel O, 2007, PROC CVPR IEEE, P1736
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   WRIGHT J, 2008, IEEE INT C AUTOM FAC
   Xu R, 2010, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2010.5540224
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Zhang B, 2016, IEEE TCSVT
   Zhang BC, 2017, C IND ELECT APPL, P90, DOI 10.1109/ICIEA.2017.8282820
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 37
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36585
EP 36603
DI 10.1007/s11042-021-11447-1
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000714500100003
DA 2024-07-18
ER

PT J
AU Ruennak, T
   Aimmanee, P
   Makhanov, S
   Kanchanaranya, N
   Vongkittirux, S
AF Ruennak, Thayanee
   Aimmanee, Pakinee
   Makhanov, Stanislav
   Kanchanaranya, Navapol
   Vongkittirux, Sakchai
TI Diabetic eye sentinel: prescreening of diabetic retinopathy using
   retinal images obtained by a mobile phone camera
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic Eye Sentinel; Mobile phone fundus images; Exudates
   segmentation; Hemorrhage segmentation; Diabetic retinopathy
ID SOFTWARE; VALIDATION; SYSTEM
AB Currently, there are few ophthalmologists in Thailand and other developing countries, and their number has increased slowly. However, there is a rapid growth of patients suffering from diabetes mellitus. This makes conventional diabetic retinopathy (DR) prescreening a difficult task. Advances in digital technologies allow the use of portable handheld cameras connected to a mobile phone to obtain retinal fundus images. However, the quality of the mobile phone images is significantly lower and the field of view is narrower than the images from the standard slit-lamp machines. This makes the existing segmentation techniques inefficient. The purpose of this work is to verify the applicability of a hand-held camera with fast computational methods integrated into a mobile phone. Therefore, the paper offers an effective solution called the diabetic eye sentinel (DES). The system segments hemorrhages and exudates in the mobile phone fundus images and detects the DR. The DES is composed of a front-end user interface, back-end computational modules based on a decision tree, the HSV color model, and the edge map. We discuss and analyze the accuracy of the system applied to a dataset of mobile phone images (size = 134) from patients diagnosed with diabetes mellitus at the Thammasat Chalermprakiat Hospital, Pathum Thani, Thailand. The results are compared to a previous version of the algorithm that was based on adaptive thresholding and two other conventional segmentation methods. The numerical experiments show that the proposed system achieves an acceptable accuracy (95.23%), a low false-negative rate (4.76%), and good speed. The proposed system can be used under real clinical conditions.
C1 [Ruennak, Thayanee; Aimmanee, Pakinee; Makhanov, Stanislav] Thammasat Univ, Sirindhorn Int Inst Technol SIIT, Dept Informat Comp & Commun Technol ICT, Meung, Pathum Thani, Thailand.
   [Kanchanaranya, Navapol; Vongkittirux, Sakchai] Thammasat Univ, Fac Med, Dept Ophthalmol, Klongluang, Pathum Thani, Thailand.
C3 Thammasat University; Thammasat University
RP Aimmanee, P (corresponding author), Thammasat Univ, Sirindhorn Int Inst Technol SIIT, Dept Informat Comp & Commun Technol ICT, Meung, Pathum Thani, Thailand.
EM ppploykung@gmail.com; pakinee@siit.tu.ac.th; makhanov@siit.tu.ac.th;
   navapolk@gmail.com; vsakchai@hotmail.com
FU Thai Government Research Fund [33/2560, 24/2561]; National Research
   Council of Thailand (NRCT) [NRCT5-RSA63010-05]; Center of Excellence in
   Biomedical Engineering of Thammasat University
FX The authors gratefully acknowledge the financial support provided by the
   Thai Government Research Fund, contract numbers 33/2560 and 24/2561, and
   the National Research Council of Thailand (NRCT) contract number
   NRCT5-RSA63010-05. We sincerely thank the Thammasat Eye Center (TEC) for
   kindly providing the retinal datasets, ground truths, and helpful
   discussions related to the clinical experiments. We also acknowledge the
   Center of Excellence in Biomedical Engineering of Thammasat University
   for financial support and the sharing of resources.
CR Abràmoff MD, 2013, JAMA OPHTHALMOL, V131, P351, DOI 10.1001/jamaophthalmol.2013.1743
   ADCIS Inc, 2020, MESS 2
   Aimmanee P., 2019, P 23 INT COMP SCI EN
   [Anonymous], 2020, DIABETIC RETINOPATHY
   [Anonymous], 2020, DIAB PREV
   Bastawrous A., 2019, PEEK VISION
   David V., 2018, VOLK INVIEW IPHONE F
   El Abbadi N.K., 2013, JCS, V9, P1389
   Eyenuk Inc, 2020, EYEART EYE SCREEN SY
   Frcophth AT, 2017, OPHTHALMOLOGY, V124, P343, DOI 10.1016/j.ophtha.2016.11.014
   Goatman K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027524
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   KALPIYAPAN V, 2018, P 13 INT C KNOWLEDGE, P287
   Khaing TT, 2017, 2017 8TH INTERNATIONAL CONFERENCE OF INFORMATION AND COMMUNICATION TECHNOLOGY FOR EMBEDDED SYSTEMS (IC-ICTES)
   Kumar PNS, 2016, PROCEDIA COMPUT SCI, V93, P486, DOI 10.1016/j.procs.2016.07.237
   Natarajan S, 2019, JAMA OPHTHALMOL, V137, P1182, DOI 10.1001/jamaophthalmol.2019.2923
   Optomed Inc, 2020, OPT HANDH FUNDS CAM
   Rajalakshmi R, 2018, EYE, V32, P1138, DOI 10.1038/s41433-018-0064-9
   Ratanapakorn T, 2019, CLIN OPHTHALMOL, V13, P641, DOI 10.2147/OPTH.S195617
   Remidio Inc, 2020, NM FUND PHON
   Resnikoff S, 2020, BRIT J OPHTHALMOL, V104, P588, DOI 10.1136/bjophthalmol-2019-314336
   Retmarker Inc, 2020, RETM DIAB RET SCREEN
   Ribeiro L, 2015, OPHTHALMOLOGICA, V233, P96, DOI 10.1159/000368426
   Scarpa A., 2014, D EYE RET SCREEN SYS
   Solanki K, 2015, INVEST OPHTH VIS SCI, V56
   Soto-Pedre E, 2015, ACTA OPHTHALMOL, V93, pE52, DOI 10.1111/aos.12481
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Tyler, 2001, OPHTHALMIC PHOTOGRAP
   Volk Optical Inc, 2020, VOLK OPT PICT PLUS F
   Walton OB, 2016, JAMA OPHTHALMOL, V134, P204, DOI 10.1001/jamaophthalmol.2015.5083
   Xu Y, 2019, BMC OPHTHALMOL, V19, DOI 10.1186/s12886-019-1196-9
   ZEISS Inc, 2020, ZEISS VISUSCOUT 100
NR 32
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1447
EP 1466
DI 10.1007/s11042-021-11364-3
EA OCT 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000702800000002
DA 2024-07-18
ER

PT J
AU Sivananthamaitrey, P
   Kumar, PR
AF Sivananthamaitrey, P.
   Kumar, P. Rajesh
TI Performance analysis of meta-heuristics on dual watermarking of color
   images based on SWT and SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Meta-heuristics; Copyright protection; Robustness;
   Embedding capacity
ID OPTIMIZATION; ALGORITHM
AB This paper proposes a robust and high embedding capacity watermarking technique where two watermarks are embedded in a color image. A gray-scale image is embedded as one of the watermarks to identify the ownership of the host image using Stationary Wavelet Transform (SWT) and Singular Value Decomposition (SVD). A binary watermark with the help of the least significant bit method is embedded to locate the tampers. This technique is optimized to have better robustness against various attacks by employing meta-heuristics. The performance of the Genetic Algorithm (GA), Invasive Weed Optimization (IWO) and Teaching Learning Based Optimization (TLBO) is analyzed on the proposed watermarking technique. A novel fitness function is proposed to optimize color image watermarking. This technique is applied to standard images and medical images. The performance of the meta-heuristics on the proposed method is compared with respect to the imperceptibility, robustness, the number of pixels changing rate (NPCR) and computation complexity.
C1 [Sivananthamaitrey, P.; Kumar, P. Rajesh] Andhra Univ, Elect & Commun Engn, Coll Engn A, Visakhapatnam, Andhra Pradesh, India.
C3 Andhra University
RP Sivananthamaitrey, P (corresponding author), Andhra Univ, Elect & Commun Engn, Coll Engn A, Visakhapatnam, Andhra Pradesh, India.
EM psmaitrey@gmail.com
RI P, SIVANANTHAMAITREY/AAV-9959-2021
OI P, SIVANANTHAMAITREY/0000-0002-7807-518X; , RAJESH KUMAR
   P/0000-0003-1088-7920
FU Ministry of Electronics and Information Technology (MeitY), Government
   of India
FX This work is carried out with the support and encouragement by the
   Ministry of Electronics and Information Technology (MeitY), Government
   of India.
CR Abdelhakim AM, 2017, EXPERT SYST APPL, V72, P317, DOI 10.1016/j.eswa.2016.10.056
   [Anonymous], DIGITAL IMAGE PROCES
   Aslantas V, 2008, AEU-INT J ELECTRON C, V62, P386, DOI 10.1016/j.aeue.2007.02.010
   Chih-Chin Lai, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1546, DOI 10.1109/ICMLC.2012.6359595
   Darwish SM, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P640, DOI 10.1109/ICCES.2018.8639185
   Dey N, 2014, J MED IMAG HEALTH IN, V4, P384, DOI 10.1166/jmihi.2014.1265
   Haddad OB, 2017, METAHEURISTIC EVOLUT, P163
   Han JL, 2016, J AMB INTEL HUM COMP, V7, P37, DOI 10.1007/s12652-015-0298-3
   Khanna AK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1140, DOI 10.1109/CCAA.2016.7813888
   Khosravi MR, 2018, NEURAL COMPUT APPL, V30, P2017, DOI 10.1007/s00521-018-3489-y
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P7339, DOI 10.1007/s11042-019-08314-5
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Mehrabian AR, 2006, ECOL INFORM, V1, P355, DOI 10.1016/j.ecoinf.2006.07.003
   Mohananthini N., 2016, Journal of Electrical Systems and Information Technology, V3, P68, DOI 10.1016/j.jesit.2015.11.009
   Moosazadeh M, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P19, DOI 10.1109/ICWR.2016.7498441
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   Pesquet JC, 1996, IEEE T SIGNAL PROCES, V44, P1964, DOI 10.1109/78.533717
   Rao RSP, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, AND OPTIMIZATION TECHNIQUES (ICEEOT), P4568, DOI 10.1109/ICEEOT.2016.7755580
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rocha L., 2003, A Practical Approach to Microarray Data Analysis, P91, DOI [10.1007/0-306-47815-3, DOI 10.1007/0-306-47815-35, 10.1007/0-306-47815-3_5, DOI 10.1007/0-306-47815-3_5]
   Schmitt LM, 2004, THEOR COMPUT SCI, V310, P181, DOI 10.1016/S0304-3975(03)00393-1
   Singh S, 2018, STUD BIG DATA, V33, P467, DOI 10.1007/978-3-319-63639-9_20
   Sivananthamaitrey P., 2019, INT J ADV SCI TECHNO, V28, P01
   Sivananthamaitrey P, 2018, INT J ENG TECHNOL, V7, DOI DOI 10.14419/IJET.V7I3.29.18463
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Takore TT, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
NR 27
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1001
EP 1027
DI 10.1007/s11042-021-11204-4
EA SEP 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698136800001
DA 2024-07-18
ER

PT J
AU Sebastián, G
   Tesoriero, R
   Gallud, JA
AF Sebastian, Gabriel
   Tesoriero, Ricardo
   Gallud, Jose A.
TI A domain specific language notation for a language learning activity
   generation tool
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Model-driven architecture; Software Engineering; Domain Specific
   Language; Language-learning Applications
ID MODEL-DRIVEN DEVELOPMENT; DESIGN
AB Globalization has increased the need for society to master new languages. This need has encouraged the launch of many applications dedicated to language learning. This paper presents a graphical notation for a domain specific language to represent language learning activities. It describes how this notation enables developers to represent language learning activity characteristics using workflow, presentation, content, media and activity model conforming a metamodel that defines the abstract syntax of the domain specific language. This notation is implemented as part of an integrated development environment to build model-based applications. Finally, this proposal is evaluated with a framework that uses the cognitive dimensions of notations for notational systems. The proposed graphic diagram editor exceeds the experience that the user has with the reflexive model editor. In relation to the creation and editing of workflow models and presentation/activity models, the proposed graphical notation its more intuitive and easy to maintain visually than the traditional reflexive tree notation used by many model-based development frameworks.
C1 [Sebastian, Gabriel] Univ Castilla La Mancha, Albacete Res Inst Informat, Albacete, Spain.
   [Tesoriero, Ricardo; Gallud, Jose A.] Univ Castilla La Mancha, Comp Syst Dept, Albacete, Spain.
C3 Universidad de Castilla-La Mancha; Universidad de Castilla-La Mancha
RP Sebastián, G (corresponding author), Univ Castilla La Mancha, Albacete Res Inst Informat, Albacete, Spain.
EM gabriel.sebastian@uclm.es; ricardo.tesoriero@uclm.es;
   jose.gallud@uclm.es
RI Sebastián Rivera, Gabriel/HZK-6567-2023; Gallud, Jose A./L-5677-2014;
   Tesoriero Pszytula, Ricardo/I-4251-2015
OI Gallud, Jose A./0000-0002-6616-8055; Sebastian Rivera,
   Gabriel/0000-0002-1156-8000; Tesoriero Pszytula,
   Ricardo/0000-0002-4643-7094
FU CRUE-CSIC; Springer Nature; Ministry of Science, Innovation and
   Universities (Spain) [RTI2018-099942-B-I00]; project TecnoCRA - regional
   government (JCCM) [SBPLY/17/180501/000495]; project TecnoCRA - European
   Regional Development Funds (FEDER) [SBPLY/17/180501/000495]
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has been partially supported by the national
   project granted by the Ministry of Science, Innovation and Universities
   (Spain) with reference RTI2018-099942-B-I00 and by the project TecnoCRA
   (ref:SBPLY/17/180501/000495) granted by the regional government (JCCM)
   and the European Regional Development Funds (FEDER).
CR [Anonymous], 2009, DESIGNING USER INTER
   Barcena E., 2015, Critical CALL - Proceedings of the 2015 EUROCALL Conference, Padova, Italy, P36, DOI 10.14705/rpnet.2015.000307
   Bezivin J., 2003, WORKSH MET MDA YORK, P23
   Blackwell A., 2003, HCI MODELS THEORIES, P103, DOI [DOI 10.1016/B978-155860808-5/50005-8, 10.1016/B978-155860808-5/50005-8]
   Blackwell AF, 2001, LECT NOTES ARTIF INT, V2117, P325
   Blackwell AF, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P240, DOI 10.1109/VL.1996.545293
   Calderon A, 2018, INFORM SOFTWARE TECH, V95, P238, DOI 10.1016/j.infsof.2017.11.009
   Caro MF, 2015, BIOL INSPIR COGN ARC, V13, P75, DOI 10.1016/j.bica.2015.06.004
   Czarnecki K., 2003, P 2 OOPSLA WORKSH GE, V45, P1
   Dettori G, 2010, PROCD SOC BEHV, V2, P2712, DOI 10.1016/j.sbspro.2010.03.401
   Diaz, 2006, ADV LEARNING TECHNOL, P415
   Dix A., 2003, HUM-COMPUT INTERACT
   Dodero Juan Manuel, 2012, Journal of Research and Practice in Information Technology, V44, P267
   Dodero JM, 2014, IEEE REV IBEROAM TEC, V9, P72, DOI 10.1109/RITA.2014.2317532
   Fielding Roy Thomas, 2000, Architectural styles and the design of network-based software architectures, Patent No. AAI9980887
   FITTER M, 1979, INT J MAN MACH STUD, V11, P235, DOI 10.1016/S0020-7373(79)80019-X
   Fondement F, 2005, LECT NOTES COMPUT SC, V3748, P190
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Garcia, 2008, INFORM SCIENTIST
   Green T., 1992, When visual programs are harder to read than textual programs, P167
   Hernández-Leo D, 2006, EDUC TECHNOL SOC, V9, P58
   Kelly S., 2008, Domain-Specific Modeling
   Kim CH, 2015, J VISUAL LANG COMPUT, V26, P99, DOI 10.1016/j.jvlc.2014.11.005
   Koper R, 2006, EDUC TECHNOL SOC, V9, P13
   Kopp G, 2009, CAN J LEARN TECHNOL, V34, P03, DOI [10.21432/T2N30X, DOI 10.21432/T2N30X]
   Laforcade P, 2005, 5th IEEE International Conference on Advanced Learning Technologies, Proceedings, P855, DOI 10.1109/ICALT.2005.288
   Laforcade P, 2007, J LEARN DES, V2, P31
   Lanzilotti R, 2006, EDUC TECHNOL SOC, V9, P42
   Latry F., 2006, ECOOP WORKSH DOM SPE
   Dodero JM, 2010, J VISUAL LANG COMPUT, V21, P332, DOI 10.1016/j.jvlc.2010.08.007
   Marand EA, 2015, COMPUT LANG SYST STR, V44, P319, DOI 10.1016/j.cl.2015.09.002
   Martínez-Ortiz I, 2009, J NETW COMPUT APPL, V32, P1092, DOI 10.1016/j.jnca.2009.02.005
   Nielsen Jakob, 1994, USABILITY INSPECTION, P413, DOI [10.1145/259963.260531, DOI 10.1145/259963.260531]
   Norman Don, 2013, The design of everyday things
   Sampson D. G., 2005, Advanced Technology for Learning, V2, P207, DOI 10.2316/Journal.208.2005.4.208-0863
   Schmidt DC, 2006, COMPUTER, V39, P25, DOI 10.1109/MC.2006.58
   Sebastián G, 2017, IEEE LAT AM T, V15, P1771, DOI 10.1109/TLA.2017.8015084
   Sebastián G, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100935
   Rivera GS, 2018, IET SOFTW, V12, P206, DOI 10.1049/iet-sen.2017.0085
   Sierra JL, 2008, INTERACT COMPUT, V20, P112, DOI 10.1016/j.intcom.2007.09.001
   Sockett G, 2014, NEW LANG LEARN TEACH, P1
   Torres J, 2014, J KING SAUD UNIV-COM, V26, P17, DOI 10.1016/j.jksuci.2013.10.004
   Troya J, 2014, COMPUT STAND INTER, V36, P863, DOI 10.1016/j.csi.2014.01.002
   Vago A., 2005, SCI STUDENTS ASS REP
   Watts N., 1997, System, V25, P1, DOI [DOI 10.1016/S0346-251X(96)00056-5, 10.1016/s0346-251x(96)00056-5]
NR 45
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36275
EP 36304
DI 10.1007/s11042-021-11296-y
EA SEP 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000692452100003
OA hybrid
DA 2024-07-18
ER

PT J
AU Tigistu, T
   Abebe, G
AF Tigistu, Tesfahun
   Abebe, Getachew
TI Classification of rose flowers based on Fourier descriptors and color
   moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural networks; Color analysis; Pattern classification;
   Shape analysis
ID ARTIFICIAL NEURAL-NETWORKS
AB In this paper, a rose-flower variety classification scheme, using color and shape features is presented. The first three statistical moments of the R, G, and B planes of the image were calculated to describe the color, while Fourier coefficients are used to describe the shape. For shape description, signatures (wave-forms) of the boundary contour of the binary images were extracted. Fourier coefficients that are used to describe the shape were estimated using the signatures generated. Depending on the Fourier coefficients, a representation of sums of angles formed along boundaries of the flowers was defined. Using these sums and the color features as input to an artificial neural network (ANN), the flowers were classified into their respective target classes. The eighteen flower varieties considered in this study were classified with an accuracy of 95.6%, 98.9%, and 100% using their shape, color, and combination of both shape and color features, respectively. Comparing these results, it was found that the combination of the two features is an efficient criterion for rose flower variety discrimination and classification.
C1 [Tigistu, Tesfahun] Hawassa Univ, Dept Phys Computat Phys, Coll Nat & Computat Sci, POB 5, Hawassa, Ethiopia.
   [Abebe, Getachew] Haramaya Univ, Dept Phys Computat Phys, Coll Nat & Computat Sci, POB 138, Dire Dawa, Ethiopia.
C3 Hawassa University; Haramaya University
RP Tigistu, T (corresponding author), Hawassa Univ, Dept Phys Computat Phys, Coll Nat & Computat Sci, POB 5, Hawassa, Ethiopia.
EM tesfatigistu@gmail.com
OI Lejibo, Tesfahun/0000-0001-5751-107X
CR Aguado A.S., 2012, FEATURE EXTRACTION I
   Alamdar F, 2011, PROCEDIA ENVIRON SCI, V10, P777, DOI 10.1016/j.proenv.2011.09.126
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Castro W, 2019, IEEE ACCESS, V7, P27389, DOI 10.1109/ACCESS.2019.2898223
   Choras RyszardS., 2007, INT J BIO BIOMED ENG, V1, P6
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jeffrey Alan., 2001, Advanced engineering mathematics
   Kadir A, 2011, ARXIV PREPRINT ARXIV
   Karris S. T., 2003, Signals and Systems: With MATLAB Applications
   Miao ZJ, 2006, IMAGE VISION COMPUT, V24, P1115, DOI 10.1016/j.imavis.2006.04.004
   Oneil PV, 2011, CENGAGE LEARNING
   Peleshko D, 2011, 2011 11 INT C EXP DE
   Pratt W.K., 2007, DIGITAL IMAGE PROCES, V4th ed., DOI DOI 10.1002/0470097434
   Samarasinghe S, 2016, NEURAL NETWORKS APPL
   Sergyan S, 2007, 5 SLOV HUNG JOINT S
   UPOV T, 1990, 1343 UPOVT INT UN PR
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
NR 19
TC 8
Z9 8
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36143
EP 36157
DI 10.1007/s11042-021-11397-8
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000691718600004
DA 2024-07-18
ER

PT J
AU Halim, Z
   Zouq, A
AF Halim, Zahid
   Zouq, Aqsa
TI On identification of big-five personality traits through choice of
   images in a real-world setting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personality prediction; Five-factor model; Artificial intelligence;
   Big-five model; Computational model
ID ORGANIZATIONAL COMMITMENT; JOB-SATISFACTION; 5-FACTOR MODEL; INVENTORY;
   MANIFESTATIONS; EXPERIENCE; JUDGMENTS; BEHAVIOR
AB Studying multiple human personality traits utilizing modern Artificial Intelligence (AI) techniques has recently gained popularity. Past studies regarding human personality assessment have used paper pencil methods, self-reports, and questionnaires. Due to the proliferation of various technologies, advancement in the Internet and use of social media networks, the concept of utilizing images, text, and videos to model human personality is gaining popularity. This work utilizes an AI-based framework to predict human personality with respect to the Big-Five model based on the choice of images made in a real-world setting. For this, the current proposal uses a dataset of real-life images that are directly/indirectly related to positive and negative sides of each of the Big-Five personality traits. Using different image seeking tasks, a data is collected from 77 participants through a custom-built tool. For creating the ground truth (about the personality of these participants), the IPIP-NEO-120 (International Personality Item Pool Representation of the NEO) personality test is taken by the participants. Results recorded are later used to correlate with the trait percentile extracted through image selection tasks. Pearson correlation coefficient is used for computing the correlation between the personality profiles of the participants. The correlation test reveals that 82% of the results are positively correlated with a p-value of 0.02. Using this data, three AI classifiers, namely, Support Vector Machine (SVM), k-nearest neighbors (k-NN), and Artificial Neural Networks (ANN) are trained for predicting the personality traits of the participants. Initially, these classifiers are trained to categorize a person being high, average, low or very low in a personality trait. Where, the maximum average accuracy of 83% is achieved by SVM for predicting agreeableness utilizing the polynomial kernel having degree six. Later, these classifiers are trained to predict the dominant personality trait, for which five class labels (i.e., O, C, E, A, and N) are assigned based on the highest percentile among all five traits. Where, SVM outperforms kNN and ANN with an average accuracy of 70%. The results reveal that different aspects of human personality can be predicted with sufficient accuracy using an individual's choice of images in a real-world setting.
C1 [Halim, Zahid; Zouq, Aqsa] Ghulam Ishaq Khan Inst Engn Sci & Technol, Machine Intelligence Res Grp MInG, Fac Comp Sci & Engn, Topi 23460, Pakistan.
C3 GIK Institute Engineering Science & Technology
RP Halim, Z (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Machine Intelligence Res Grp MInG, Fac Comp Sci & Engn, Topi 23460, Pakistan.
EM zahid.halim@giki.edu.pk
FU GIK Institute graduate research fund under GA-1 scheme
FX The authors are indebted to the editor and anonymous reviewers for their
   helpful comments and suggestions. The authors wish to thank GIK
   Institute for providing research facilities. This work was sponsored by
   the GIK Institute graduate research fund under GA-1 scheme.
CR Allen Timothy A, 2018, J Pers, V86, P714, DOI 10.1111/jopy.12352
   André P, 2009, LECT NOTES COMPUT SC, V5727, P340, DOI 10.1007/978-3-642-03658-3_40
   Bhardwaj S, 2016, MULTIMED TOOLS APPL, V75, P13237, DOI 10.1007/s11042-015-2793-0
   Bleidorn W, 2019, PERS SOC PSYCHOL REV, V23, P190, DOI 10.1177/1088868318772990
   Buchanan T, 2005, EUR J PSYCHOL ASSESS, V21, P115, DOI 10.1027/1015-5759.21.2.115
   Connelly BS, 2010, PSYCHOL BULL, V136, P1092, DOI 10.1037/a0021212
   Crighton AH, 2014, SPINE J, V14, P2042, DOI 10.1016/j.spinee.2014.04.012
   Cunningham SJ, 2006, OPENING INFORMATION HORIZONS, P198
   de Leng WE, 2019, INT J SELECT ASSESS, V27, P235, DOI 10.1111/ijsa.12251
   Diefenbach S, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00007
   Feist G.J., 2004, EMPIR STUD ARTS, V22, P77, DOI [DOI 10.2190/Y7CA-TBY6-V7LR-76GK, 10.2190/y7ca-tby6-v7lr-76gk]
   Ferwerda Bruce, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P850, DOI 10.1007/978-3-319-27671-7_71
   Ferwerda B, 2019, MULTIMED TOOLS APPL, V78, P20157, DOI 10.1007/s11042-019-7336-7
   Ferwerda Bruce, 2015, WORKSH EM PERS SYST, P7, DOI DOI 10.1145/2809643.2809644
   Fleeson W, 2009, J PERS SOC PSYCHOL, V97, P1097, DOI 10.1037/a0016786
   Furnham A, 2013, INSTR SCI, V41, P975, DOI 10.1007/s11251-012-9259-9
   Furnham A, 2009, J MANAGE PSYCHOL, V24, P765, DOI 10.1108/02683940910996789
   Gonzales AL, 2008, MEDIA PSYCHOL, V11, P167, DOI 10.1080/15213260802023433
   Gosling SD, 2002, J PERS SOC PSYCHOL, V82, P379, DOI 10.1037//0022-3514.82.3.379
   Guntuku Sharath Chandra, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P171, DOI 10.1007/978-3-319-14442-9_15
   Guntuku SC, 2017, PROCEEDINGS OF THE 2017 ACM WEB SCIENCE CONFERENCE (WEBSCI '17), P223, DOI 10.1145/3091478.3091522
   Guntuku SC, 2018, IEEE T AFFECT COMPUT, V9, P130, DOI 10.1109/TAFFC.2016.2581168
   Guo JJ, 2021, PERS INDIV DIFFER, V168, DOI 10.1016/j.paid.2020.110369
   Halim Z, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-03415-5
   Halim Z, 2020, INFORM FUSION, V53, P66, DOI 10.1016/j.inffus.2019.06.006
   Halim Z, 2019, IEEE T AFFECT COMPUT, V10, P568, DOI 10.1109/TAFFC.2017.2751602
   Jie Nie, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9917, P640, DOI 10.1007/978-3-319-48896-7_63
   Johnson JA, 2014, J RES PERS, V51, P78, DOI 10.1016/j.jrp.2014.05.003
   Johnson Katerina V-A, 2020, Hum Microb J, V15, pNone, DOI 10.1016/j.humic.2019.100069
   Joseph DL, 2015, J APPL PSYCHOL, V100, P298, DOI 10.1037/a0037681
   Judge TA, 2002, J APPL PSYCHOL, V87, P530, DOI 10.1037//0021-9010.87.3.530
   Judge TA, 2015, ACAD MANAGE J, V58, P1149, DOI 10.5465/amj.2010.0837
   Kosinski M, 2014, MACH LEARN, V95, P357, DOI 10.1007/s10994-013-5415-y
   Lee Y, 2019, J APPL PSYCHOL, V104, P1535, DOI 10.1037/apl0000421
   Lin YP, 2021, MULTIMED TOOLS APPL, V80, P17415, DOI 10.1007/s11042-020-09297-4
   Lucas RE, 2000, J PERS SOC PSYCHOL, V79, P452, DOI 10.1037//0022-3514.79.3.452
   Manaf HA, 2018, INT J PUBLIC ADMIN, V41, P1258, DOI 10.1080/01900692.2017.1386676
   Mehl MR, 2006, J PERS SOC PSYCHOL, V90, P862, DOI 10.1037/0022-3514.90.5.862
   Meyer GJ, 2006, J PERS ASSESS, V87, P223, DOI 10.1207/s15327752jpa8703_01
   Michael J., 2003, J LEADERSHIP ORG STU, V10, P68, DOI DOI 10.1177/107179190301000106
   Morey LC, 2019, J CLIN PSYCHOL, V75, P202, DOI 10.1002/jclp.22701
   Musil B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00082
   Panaccio A, 2012, J VOCAT BEHAV, V80, P647, DOI 10.1016/j.jvb.2012.03.002
   Paradis E, 2017, MED EDUC, V51, P31, DOI 10.1111/medu.13122
   Patrick CJ, 2002, PSYCHOL ASSESSMENT, V14, P150, DOI 10.1037//1040-3590.14.2.150
   Penton-Voak IS, 2006, SOC COGNITION, V24, P607, DOI 10.1521/soco.2006.24.5.607
   Piotrowski C., 2015, Journal of the Indian Academy of Applied Psychology, V41, P9
   Poropat AE, 2011, BRIT J EDUC PSYCHOL, V81, P41, DOI 10.1348/000709910X497671
   Pu HT, 2008, J INF SCI, V34, P275, DOI 10.1177/0165551507084140
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Redi M., 2015, 9 INT AAAI C WEB SOC
   Rentfrow PJ, 2008, PERSPECT PSYCHOL SCI, V3, P339, DOI 10.1111/j.1745-6924.2008.00084.x
   Salgado J. F., 2017, The Blackwell handbook of personnel selection, P174, DOI [10.1002/9781405164221.ch8, DOI 10.1002/9781405164221.CH8]
   Schultz D.P., 2016, Theories of Personality
   Segalin C, 2017, IEEE T AFFECT COMPUT, V8, P268, DOI 10.1109/TAFFC.2016.2516994
   Segalin C, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P460, DOI 10.1145/3123266.3123331
   Segalin C, 2017, COMPUT VIS IMAGE UND, V156, P34, DOI 10.1016/j.cviu.2016.10.013
   Shiota M.N., 2006, Journal of Positive Psychology, V1, P61, DOI [DOI 10.1080/17439760500510833, 10.1080/17439760500510833]
   Tassiopoulos K, 2020, J MED INTERNET RES, V22, DOI 10.2196/18588
   Tkach C., 2006, J HAPPINESS STUD, V7, P183, DOI [10.1007/s10902-005-4754-1, DOI 10.1007/S10902-005-4754-1]
   Uzma, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106256
   Vazire S, 2011, CURR DIR PSYCHOL SCI, V20, P104, DOI 10.1177/0963721411402478
   Wald R, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P109, DOI 10.1109/IRI.2012.6302998
   Zhang LJ, 2016, PR INT CONGR SOUND V
   Ziapour A, 2017, ANN TROP MED PUBLIC, V10, P371, DOI 10.4103/1755-6783.208725
NR 65
TC 6
Z9 6
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33377
EP 33408
DI 10.1007/s11042-021-11419-5
EA AUG 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000686512900002
DA 2024-07-18
ER

PT J
AU Aiordachioae, A
   Pamparau, C
   Vatavu, RD
AF Aiordachioae, Adrian
   Pamparau, Cristian
   Vatavu, Radu-Daniel
TI Lifelogging meets alternate and cross-realities: an investigation into
   broadcasting personal visual realities to remote audiences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Augmented Reality; Mediated Reality; Cross-Reality; Alternate Reality;
   Smartglasses; Head-Mounted Displays; Broadcasting; Video streaming;
   Lifelogging; Prototypes
ID SENSECAM; MEMORY
AB We address in this work the topic of broadcasting one's visual reality, captured by the video cameras embedded in mobile and wearable devices, to a remote audience. We discuss several designs of such life broadcasting systems, which we position at the intersection of lifelogging, Alternate Reality, and Cross-Reality technology. To this end, we introduce the "Alternate Reality Broadcast-Time" matrix for the broadcasting and consumption of alternate realities, in which designs of systems that implement sharing and consumption of personal visual realities can be positioned, characterized, and compared. These design options range from simple video streaming over the web using conventional video protocols to mediated and augmented reality, to audio narration and vibrotactile rendering of concepts automatically detected from video captured by wearable cameras. To demonstrate the usefulness of our broadcast-time matrix, we describe three prototypes implementing lifelogging, concept recognition from video, augmented and mediated vision, and vibrotactile feedback. Our contributions open the way toward new applications that blend lifelogging, consumption of multimedia alternate realities, and XR technology to empower users with richer opportunities for self-expression and new means to connect with the followers of events in their lives.
C1 [Aiordachioae, Adrian; Pamparau, Cristian; Vatavu, Radu-Daniel] Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
C3 Stefan cel Mare University of Suceava
RP Vatavu, RD (corresponding author), Univ Stefan Cel Mare Suceava, MANSiD Res Ctr, MintViz Lab, Suceava 720229, Romania.
EM adrian.aiordachioae2@student.usv.ro; cristian.pamparau@usm.ro;
   radu.vatavu@usm.ro
RI Pamparau, Cristian/AAB-5215-2021; Vatavu, Radu-Daniel/AAA-3282-2022;
   Vatavu, Radu-Daniel/F-1820-2017
OI Vatavu, Radu-Daniel/0000-0002-7631-6445
FU Ministry of Research and Innovation, CNCS-UEFISCDI within PNCDI III
   [PN-III-P1-1.1-TE-2016-2173, TE141/2018]; project "Integrated center for
   research, development and innovation in Advanced Materials,
   Nanotechnologies, and Distributed Systems for fabrication and control",
   Sectoral Operational Program for Increase of the Economic
   Competitiveness [671/09.04.2015]; European Regional Development Fund
FX This work was supported by a grant of the Ministry of Research and
   Innovation, CNCS-UEFISCDI, project no. PN-III-P1-1.1-TE-2016-2173
   (TE141/2018), within PNCDI III. The work was carried out in the Machine
   Intelligence and Information Visualization Lab (MintViz) of the MANSiD
   Research Center. The infrastructure was provided by the University of
   Suceava and was partially supported from the project "Integrated center
   for research, development and innovation in Advanced Materials,
   Nanotechnologies, and Distributed Systems for fabrication and control",
   No. 671/09.04.2015, Sectoral Operational Program for Increase of the
   Economic Competitiveness, co-funded from the European Regional
   Development Fund.
CR Abdullah Miran Taha Abdullah, 2017, NETW PROTOC ALGORITH, V9, P85
   Abowd G.D., 2003, Proceedings of the 5th ACM SIGMM international workshop on Multimedia information retrieval, P1, DOI DOI 10.1145/973264.973266
   Aiordachioae Adrian, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3331157
   Aiordachioae A, 2019, E-HEALTH BIOENG CONF, DOI 10.1109/ehb47216.2019.8969871
   Aiordachioae A, 2019, PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS (EICS'19), DOI 10.1145/3319499.3328234
   Al Mahmud A., 2010, P 12 INT C HUM COMP, P391, DOI DOI 10.1145/1851600.1851680
   Alt, 2015, P CHI EA 2015 CHI EA, P2223, DOI [10.1145/2702613.2732743, DOI 10.1145/2702613.2732743]
   [Anonymous], 2015, P 17 INT C HUMAN COM, DOI DOI 10.1145/2785830.2785842
   [Anonymous], 2008, Proceeding of the 16th ACM international conference on Multimedia-MM'08, DOI [DOI 10.1145/1459359, 10.1145/1459359]
   [Anonymous], 2017, P 27 WORKSHOP NETWOR
   [Anonymous], 2019, SNAPCAM
   [Anonymous], 2019, NARRATIVE
   [Anonymous], 2015, P 2015 IEEE INT C MU, DOI DOI 10.1109/ICMEW.2015.7169860
   [Anonymous], 2019, PROTOCOL EXTENSION L
   [Anonymous], 2019, GOOGLECLIPS
   [Anonymous], 2018, HTML5 FLV PLAYER
   [Anonymous], 2012, CHI 12 EXTENDED ABST
   [Anonymous], 2015, P 5 INT C DIG HLTH
   [Anonymous], 2019, MECAM
   [Anonymous], 2015, SOCKETIO CLIENT LIB
   Aoki P.M., 2002, CHI 02, P431, DOI DOI 10.1145/503376.503454
   Azuma RT, 2016, PRESENCE-TELEOP VIRT, V25, P234, DOI 10.1162/PRES_a_00264
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barakabitze AA, 2020, IEEE COMMUN SURV TUT, V22, P526, DOI 10.1109/COMST.2019.2958784
   Barman N, 2019, IEEE ACCESS, V7, P30831, DOI 10.1109/ACCESS.2019.2901778
   Bederson B.B., 1995, ACM Human Computer in Computing Systems conference (CHI'95), P210
   Berry E, 2007, NEUROPSYCHOL REHABIL, V17, P582, DOI 10.1080/09602010601029780
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Blum M, 2006, IEEE MULTIMEDIA, V13, P40, DOI 10.1109/MMUL.2006.87
   Brewster S., 2004, C RES PRACT INF TECH, V28, P15, DOI DOI 10.1145/67880.1046599
   Choi J, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P187, DOI 10.1145/3301293.3309569
   Chowdhury Soumyadeb, 2016, P INT BCS HUM COMP P, DOI [10.14236/ewic/HCI2016.62, DOI 10.14236/EWIC/HCI2016.62]
   Clarifai, 2019, CLAR TRANSF WE SEE W
   Crandall, 2016, ECCV 2016 WORKSH, DOI [10.1007/978-3-319-46604-0_33, DOI 10.1007/978-3-319-46604-0_33]
   Cullen B, 2015, WORDCLOUD
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   Davies CJ, 2014, P 20 ACM S VIRT REAL, P213
   de Jager Dirk., 2011, Proceedings of the First ACM MobiHoc Workshop on Pervasive Wireless Healthcare (MobileHealth'11), P1, DOI DOI 10.1145/2007036.2007043
   Del Rio Mauro, 2018, P 2 INT C MED HLTH I, P218, DOI DOI 10.1145/3239438.3239444
   Denning T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2377, DOI 10.1145/2556288.2557352
   Everingham MR., 1998, INT J VIRTUAL REALIT, V3, P1, DOI [10.20870/IJVR.1998.3.4.2629, DOI 10.20870/IJVR.1998.3.4.2629]
   Faklaris C, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2016), P722, DOI 10.1145/2957265.2961845
   Fielding R., 2014, Hypertext Transfer Protocol: Message Syntax and Routing, DOI [10.17487/rfc7230, DOI 10.17487/RFC7230]
   Fleischman E, 1998, ADV STREAMING FORMAT
   Gartner, 2018, GARTNER SAYS WORLDWI
   Gemmell J., 2014, P 2014 WORKSH PHYS A, P17, DOI [10.1145/2611264.2611276, DOI 10.1145/2611264.2611276]
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Hart H, 2010, JENNICAM STARTS LIFE
   Hinbarji Z, 2016, INT C MULT MOD, P342
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Hoyle R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1645, DOI 10.1145/2702123.2702183
   Hoyle R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P571, DOI 10.1145/2632048.2632079
   Huh S, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338137
   Janzen Ryan., 2014, Games Media Entertainment (GEM), 2014 IEEE, P1
   Jenkins A., 2019, The fall and rise of VR: The struggle to make virtual reality get real
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Kekulluoglu D, 2018, ACM T INTERNET TECHN, V18, DOI 10.1145/3158373
   Kirk, 2011, P 2011 ANN C HUM F 2, P2437, DOI [10.1145/1979742.1979578, DOI 10.1145/1979742.1979578]
   Koelle M, 2018, NORDICHI'18: PROCEEDINGS OF THE 10TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION, P473, DOI 10.1145/3240167.3240174
   Koelle M, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3122123
   Kruitbosch G., 2008, Proceedings of the 3rd ACM Workshop on Human-Centered Computing, P7, DOI [10.1145/1462027.1462029, DOI 10.1145/1462027.1462029]
   Kurita Y., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P83, DOI DOI 10.1145/1643928.1643948
   Langlotz T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173964
   Liotou E, 2017, IEEE INT WORKSH COMP
   Liu CH, 2012, SIGNAL PROCESS-IMAGE, V27, P288, DOI 10.1016/j.image.2011.10.001
   Mann S., 2018, ABS180408386 CORR
   Mann Steve., 1999, LINUX J, V59es, P5
   Marr B, 2019, FORBES
   Marr B., 2020, MOST AMAZING REAL WO
   Matthias P., 2019, P 17 INT C VIRT REAL, P1
   McCullough MC, 2018, PRS-GLOB OPEN, V6, DOI 10.1097/GOX.0000000000001999
   Metsis V, 2014, PERS UBIQUIT COMPUT, V18, P19, DOI 10.1007/s00779-012-0623-1
   Microsoft, SOUNDSC
   Milgram P, 1999, MIXED REALITY, P5
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Mingliang C, 2020, ILLUSPAS NODE MEDIA
   Mori S., 2017, IPSJ Transactions on Computer Vision and Applications, V9, P17, DOI [10.1186/s41074-017-0028-1, DOI 10.1186/S41074-017-0028-1, 10.3390/electronics10080900]
   Muzaffar R, 2020, AUTON ROBOT, V44, P75, DOI 10.1007/s10514-019-09851-6
   Nakagawa R, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P6, DOI 10.1145/3355355.3361886
   Obrist M., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P3285, DOI [DOI 10.1145/2851581.2856462, 10.1145/2851581, DOI 10.1145/2851581]
   Ochi D, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P763, DOI 10.1145/2647868.2654870
   Ochi D, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P737, DOI 10.1145/2733373.2807963
   Pai Y.S., 2020, P SIGGRAPH AS TECHN, P1, DOI [10.1145/3410700.3425434, DOI 10.1145/3410700.3425434]
   Pamparau C, 2021, MULTIMED TOOLS APPL, V80, P30943, DOI 10.1007/s11042-020-10164-5
   Pantos R., 2017, Http live streaming, DOI DOI 10.17487/RFC8216
   Paradiso JA, 2009, IEEE PERVAS COMPUT, V8, P14, DOI 10.1109/MPRV.2009.47
   Parmar H., 2012, Adobe's Real Time Messaging Protocol
   Pausch R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P13, DOI 10.1145/258734.258744
   Peli E, 2007, J SOC INF DISPLAY, V15, P1037, DOI 10.1889/1.2825088
   Peli Eli., 1999, Visual Impairment Research, V1, P3
   Philo Stephy A., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0754, DOI 10.1109/ICCSP.2019.8698001
   Postel J., 1980, User datagram protocol
   Procyk J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2163, DOI 10.1145/2556288.2557198
   Redi, 2016, ALTMM 16 P 1 INT WOR, DOI [10.1145/2983298, DOI 10.1145/2983298]
   Roach AB, 2016, WEBRTC VIDEO PROCESS
   Rodriguez-Gil L, 2018, MULTIMED TOOLS APPL, V77, P6471, DOI 10.1007/s11042-017-4556-6
   Rothe S, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P25, DOI 10.1145/3317697.3323362
   Ruether T, 2019, LOW LATENCY CMAF LIV
   Ruminski J, 2015, C HUM SYST INTERACT, P187, DOI 10.1109/HSI.2015.7170664
   Saito K, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P1425
   Sani Y, 2017, IEEE COMMUN SURV TUT, V19, P2985, DOI 10.1109/COMST.2017.2725241
   Santos-González I, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040846
   Schönauer C, 2015, LECT NOTES COMPUT SC, V9299, P165, DOI 10.1007/978-3-319-22723-8_14
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Scourboutakos P, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P751, DOI 10.1145/3024969.3035534
   Sellen A, 2010, COMMUN ACM, V53, P70, DOI 10.1145/1735223.1735243
   SEO D, 2017, P 22 INT C 3D WEB TE, DOI DOI 10.1145/3055624.3075940
   Seo D, 2018, WEB3D 2018: THE 23RD INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3208806.3208808
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Singhal S., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA'16, P3197
   Singhal S, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P98, DOI 10.1145/2998181.2998247
   Smith K., 2020, 57 FASCINATING INCRE
   Snap Inc, 2020, SPECTACLES SNAPCHAT
   SOBEL K, 2019, IDC 19, P689, DOI DOI 10.1145/3311927.3325163
   Sonobe, 2020, ACM SIGGRAPH 2020 IM, DOI [10.1145/3388536.3407882, DOI 10.1145/3388536.3407882]
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Stix G., 2015, SCI AM
   Tanaka A., 2014, P ACM HYP, P324
   Tanuwidjaja E, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P799, DOI 10.1145/2632048.2632091
   Tian G., 2012, P 8 INT C EM NETW EX, P109
   Vatavu R-D, 2015, P ACM INT C INT EXP, P13, DOI [10.1145/2745197.2745207, DOI 10.1145/2745197.2745207]
   Vatavu RD, 2020, PROCEEDINGS OF THE 2020 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2020, P1, DOI 10.1145/3391614.3393660
   Vatavu RD, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P217, DOI 10.1145/2935334.2935364
   Westerlund M, 2016, REAL TIME STREAMING
   Wowza Media Systems, 2019 VID STREAM LAT
   Yang J, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P408, DOI 10.1145/3341162.3349302
   Yavoruk O, 2020, 4TH INTERNATIONAL CONFERENCE ON DIGITAL TECHNOLOGY IN EDUCATION, ICDTE 2020, P58, DOI 10.1145/3429630.3429637
   Zhao YH, 2019, ACM T ACCESS COMPUT, V12, DOI 10.1145/3361866
   Zhao YH, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300341
   Zhao YH, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P239, DOI 10.1145/2700648.2809865
   Zhou C, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zokai S, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P217, DOI 10.1109/ISMAR.2003.1240705
NR 134
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2021 AUG 14
PY 2021
DI 10.1007/s11042-021-11310-3
EA AUG 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UA1IH
UT WOS:000684916500003
OA hybrid
DA 2024-07-18
ER

PT J
AU Cheng, Z
   Li, HJ
   Duan, XL
   Zeng, XY
   He, MX
   Luo, H
AF Cheng, Zhuo
   Li, Hongjian
   Duan, Xiaolin
   Zeng, Xiangyan
   He, Mingxuan
   Luo, Hao
TI Attention cutting and padding learning for fine-grained image
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained recognition; Local features; CNNs
AB Fine-grained image recognition is an important task in the field of computer vision. In fine-grained image recognition, the difference between different categories is very small. Thus, fine-grained image recognition highly depends on local features. In this paper, a novel "Attention Cutting And Padding Learning" method is proposed to learn the local features. Firstly, the image is fed to Convolutional Neural Networks, and a saliency map is gotten. According to the saliency map, the attention image is obtained. Secondly, the attention image is cut into N * N sub-images. Every sub-image is padded by 0 and the padding size is P. All sub-images are spliced into a Cutting And Padding image. Finally, the Cutting And Padding image and the attention image are fed to CNNs to train. In this method, more local features can be learned, and the high-level semantics is not damaged. Experimental results show that the recognition accuracy of Attention Cutting And Padding Learning is 87.9%, 94.6%, and 92.4% respectively on CUB-200-2011, Stanford Cars, and FGVC-Aircraft dataset. Moreover, this method can be easily applied to biodiversity automatic monitoring, intelligent retail, intelligent transportation, and other fields to improve recognition accuracy without changing the network structure.
C1 [Cheng, Zhuo; Li, Hongjian; Duan, Xiaolin; Zeng, Xiangyan; He, Mingxuan; Luo, Hao] Chongqing Univ Posts & Telecommun, Dept Comp Sci & Technol, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Li, HJ (corresponding author), Chongqing Univ Posts & Telecommun, Dept Comp Sci & Technol, Chongqing, Peoples R China.
EM lihj@cqupt.edu.cn
RI jin, chen/KBQ-8592-2024
FU Chongqing Science and Technology Commission Project [cstc2017jcyjAX0142,
   cstc2018jcyjAX0525]; Key Research and Development Projects of Sichuan
   Science and Technology Department [2019YFG0107]
FX This work was supported by Chongqing Science and Technology Commission
   Project (Grant No:cstc2017jcyjAX0142 and cstc2018jcyjAX0525), Key
   Research and Development Projects of Sichuan Science and Technology
   Department (Grant No: 2019YFG0107).
CR [Anonymous], 2013, Tech. rep.
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cui Y, 2018, PROC CVPR IEEE, P4109, DOI 10.1109/CVPR.2018.00432
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Guillaumin M, 2014, INT J COMPUT VISION, V110, P328, DOI 10.1007/s11263-014-0713-9
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Jaderberg M, 2015, ADV NEUR IN, V28
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZC, 2017, IEEE INT CONF COMP V, P1199, DOI 10.1109/ICCVW.2017.145
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Recasens A, 2018, LECT NOTES COMPUT SC, V11213, P52, DOI 10.1007/978-3-030-01240-3_4
   Rodríguez P, 2018, LECT NOTES COMPUT SC, V11212, P357, DOI 10.1007/978-3-030-01237-3_22
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei X-S, 2016, ARXIV PREPRINT ARXIV
   Wei XS, 2018, PATTERN RECOGN, V76, P704, DOI 10.1016/j.patcog.2017.10.002
   Xiao LX, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511399
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 31
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32791
EP 32805
DI 10.1007/s11042-021-11314-z
EA AUG 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000682496300002
DA 2024-07-18
ER

PT J
AU Vidyarthi, A
   Malik, A
AF Vidyarthi, Ankit
   Malik, Aruna
TI A hybridized modified densenet deep architecture with CLAHE algorithm
   for humpback whale identification and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric identification; Pattern recognition; Security; Deep learning;
   Multimedia infformation extraction
ID PHOTOIDENTIFICATION
AB Authenticity in multimedia information retrieval system is one such parameter which is of utmost in demand. One of such parameters is the biometric based authentication system, as seen in case of human the system proves its importance in almost each and every field. But in case of animals it becomes quite complex to recognize them using unique biometric parameter. This paper presents a modified 10 layered DenseNet deep learning framework which is implemented for the identification of Humpback whale, in an online challenge conducted by the kaggle, using biometric parameter. The proposed dense model minimizes the traditional limitation of vanishing gradient problem and outperforms as compared with other methods exists in the literature. This paper also proposed an hand free flow algorithm for ROI segmentation. In addition, the proposed methodology also uses CLAHE as a preprocessing method and focused on the feature re-usability with an optimized number of parameters used for recognition. During the experimentation, validation of the proposed model is found satisfactory with an accuracy of 93.21%. The test set results are provided by the kaggle with an AUC-ROC result over public and private scoreboard with an accuracy of 94.47% and 92.54% respectively. The comparative result with other deep methodologies suggests that the highest accuracy gained is 95.55% by Se-ResNet50 by some other learderboard and proposed model is found at second place.
C1 [Vidyarthi, Ankit] Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
   [Malik, Aruna] Dr BR Ambedkar Natl Inst Technol Jalandhar, Dept CSE, Jalandhar, Punjab, India.
C3 Jaypee Institute of Information Technology (JIIT); National Institute of
   Technology (NIT System); Dr B R Ambedkar National Institute of
   Technology Jalandhar
RP Vidyarthi, A (corresponding author), Jaypee Inst Informat Technol, Dept CSE & IT, Noida, India.
EM ankit.vidyarthi@jiit.ac.in; arunacsrke@gmail.com
RI Malik, Aruna/GOH-0709-2022; Malik, Aruna/AAL-1997-2020; Vidyarthi,
   Ankit/AAD-4939-2020
OI Malik, Aruna/0000-0003-1136-6828; Vidyarthi, Ankit/0000-0002-8026-4246
CR Araabi RN., 2000, ANN BIOMED ENG, V28, P1269, DOI [10.1114/1.1317532, DOI 10.1114/1.1317532]
   Araahi RN, 2001, THESIS TEXAS A M U
   Bogucki R, 2019, CONSERV BIOL, V33, P676, DOI 10.1111/cobi.13226
   Constantine R, 2012, MAR ECOL PROG SER, V453, P249, DOI 10.3354/meps09613
   Domeier ML, 2007, MAR BIOL, V150, P977, DOI 10.1007/s00227-006-0380-7
   Duda J, 2019, ARXIV190707063, P1
   HILLMAN G, 2003, P 15 BIENN C BIOL MA
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Katona S., 1979, Behavior of Marine Animals, V3, P33
   Kehtarnavaz, 2003, P 13 SCAND C IM AN
   Kumar S, 2017, IET BIOMETRICS, V6, P139, DOI 10.1049/iet-bmt.2016.0017
   Leslie NS, 2018, 5510026 US NAV RES L
   Mizroch S., 1990, COMPUTER ASSISTED PH
   Mizroch SA., 2003, Marine Fisheries Review, V65, P25
   Ranguelova E, 2004, IEEE IMAGE PROC, P1727
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Lopes LHS, 2019, IEEE SYMP COMP COMMU, P32, DOI 10.1109/iscc47284.2019.8969698
   Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58
   Vidyarthi A, 2019, 12 INT C CONT COMP I, P1, DOI [DOI 10.1109/IC3.2019.8844937, DOI 10.1163/9789004385580_002]
   Whale Sense Identifying individualhumpback whales, STELLW BANK NAT MAR
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 21
TC 0
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19779
EP 19793
DI 10.1007/s11042-021-11034-4
EA JUL 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000671647800001
DA 2024-07-18
ER

PT J
AU Miranda, BP
   Queiroz, VF
   Araújo, TDO
   Santos, CGR
   Meiguins, BS
AF Miranda, Brunelli P.
   Queiroz, Vinicius F.
   Araujo, Tiago D. O.
   Santos, Carlos G. R.
   Meiguins, Bianchi S.
TI A low-cost multi-user augmented reality application for data
   visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile augmented reality; Information visualization; Card-based
   interaction
ID HAND
AB Among the existing platforms, the mobile platform provides most of the augmented reality experiences for users. Augmented reality solutions have been applied in several contexts due to technological advances in this area. However, many of these advances are still out of reach of more massive access by regular users due to access limitations or the cost of these new technologies. After conducting a literature review considering the application of data visualization in augmented reality environments, we have identified an evolution of equipment used in this context with a decrease of low-cost proposals. Hence, the works related to these two areas showed high use of technologies not yet accessible to the vast majority of users. Thus, we propose a low-cost augmented reality application that can be used on mobile devices for data visualization. We developed a hybrid proposal of an augmented reality prototype to interacting with cards through the mobile device to support the process of creating data visualization. The tangible cards have a design that helps the user in the visualization creation process, indicating each card's role in the interaction process. The proposed application supports a multi-user environment, allowing multiple users to interact simultaneously with data visualizations in the AR environment. The visualizations are generated on a dedicated server for this function, providing a set of seven different types of visualization. To validate the developed prototype we performed two tests, the first being a stress assessment on the server that generates data visualizations to analyze the proposed application's scalability. The second was a remote usability test with twelve participants, to evaluate the interaction and design of the cards, and the viability of this solution for augmented reality applications.
C1 [Miranda, Brunelli P.; Queiroz, Vinicius F.; Araujo, Tiago D. O.; Santos, Carlos G. R.; Meiguins, Bianchi S.] Univ Fed Para, Belem, Para, Brazil.
C3 Universidade Federal do Para
RP Miranda, BP (corresponding author), Univ Fed Para, Belem, Para, Brazil.
EM brunelli@ufpa.br; viniciusqquei@gmail.com; tiagoaraujo@ufpa.br;
   carlosresque@ufpa.br; bianchi@ufpa.br
RI Meiguins, Bianchi Serique/AAS-6851-2020; Araújo, Tiago/JMP-5425-2023
OI Meiguins, Bianchi Serique/0000-0001-5872-4827; Araújo,
   Tiago/0000-0002-4971-9951
CR Ahmed L, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P424, DOI 10.1109/IntelCIS.2015.7397255
   Alvaro-Hermana R., 2019, 2019 2 INT C SMART
   [Anonymous], 2005, Spatial Augmented Reality: Merging Real and Virtual Worlds
   Azuma RT, 2001, FUNDAMENTALS OF WEARABLE COMPUTERS AND AUGMENTED REALITY, P27
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bayu MZ, 2013, PROC TECH, V11, P396, DOI 10.1016/j.protcy.2013.12.208
   Bedoya-Rodriguez S, 2014, 2014 IEEE GAM MED EN, DOI 10.1109/gem.2014.7118433
   BELCHER D, 2003, 2 IEEE ACM INT S MIX
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   BRESSA N, 2019, DESIGNING INTERACTIV
   Büschel W, 2019, IEEE COMPUT GRAPH, V39, P29, DOI 10.1109/MCG.2019.2897927
   Buschel W, 2018, P CHI 2018 WORKSH DA, V18
   BUTCHER PWS, 2019, EXTENDED ABSTRACTS 2
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Chandra ANR, 2019, 2019 INT C COMP SCI, DOI 10.1145/3359996.3364242
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/VR.2019.8797978, 10.1109/vr.2019.8797978]
   Costa IV, 2019, 2019 23 INT C INF 2, DOI 10.1109/vr.2019.8797978
   Dabor O, 2019, 2019 11 COMP SCI EL, DOI 10.1109/iv-2.2019.00019
   Daryoush AS, 2019, IEEE PHOTON CONF
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   do Carmo RMC, 2007, 2007 11 INT C INF VI, DOI 10.1109/iv.2007.38
   Dong HW, 2015, IEEE ACCESS, V3, P543, DOI 10.1109/ACCESS.2015.2432679
   Doring T, 2007, P 1 INT C TANG EMB I, DOI 10.1145/1226969.1226986
   Drochtert D, 2015, SIGGRAPH ASIA 2015 M, DOI 10.1145/2818427.2818465
   Dua D., 2017, UCI MACHINE LEARNING
   ElSayed NAM, 2016, 28 AUSTR C HUM COMP, DOI 10.1016/j.jvlc.2016.07.006
   ElSayed NAM, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P203, DOI [10.1109/ISMAR-Adjunct.2016.0077, 10.1109/ISMAR-Adjunct.2016.68]
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Engelke U, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365715
   FULMER W, 2019, P 24 INT C INT US IN
   Gardeli A, 2019, CHALLENGES DIGITAL T, P673
   GIRAUDEAU P, 2019, P 2019 ACM INT C INT
   Goh ES, 2019, IEEE ACCESS, V7, P40581, DOI 10.1109/ACCESS.2019.2906394
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   GRASSET R, 2008, INT SYM MIX AUGMENT
   He SQ, 2017, IEEE T VIS COMPUT GR, V23, P561, DOI 10.1109/TVCG.2016.2599338
   Hürst W, 2013, MULTIMED TOOLS APPL, V62, P233, DOI 10.1007/s11042-011-0983-y
   James R, 2020, P GRAPHICS INTERFACE
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jin Q, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P611, DOI 10.1145/3202185.3210784
   Kapec P, 2015, IEEE INT CONF INTELL, P307, DOI 10.1109/INES.2015.7329727
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim SL, 2014, 2014 IEEE WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P21, DOI 10.1109/WF-IoT.2014.6803110
   Kim T., 2017, VISAR BRINGING INTER
   KIRNER C, 2006, 2006 IEEE INT C SYST
   Koca BA, 2019, 2019 3 INT S MULT ST, P1
   Krpan D, 2018, INTED2018 P IATED, DOI 10.21125/inted.2018.0979
   Magnenat S, 2015, IEEE T VIS COMPUT GR, V21, P1201, DOI 10.1109/TVCG.2015.2459871
   Mahmood T, 2018, 2018 INT S BIG DAT V, DOI 10.1109/bdva.2018.8533893
   MAHMOOD T, 2019, 2019 IEEE INT S MIX
   Marques BM, 2019, IBER CONF INF SYST
   Martedi S, 2010, 2010 IEEE INT S MIX, DOI 10.1109/ismar.2010.5643552
   Mauri M., 2017, P 12 BIANN C IT SIGC, DOI DOI 10.1145/3125571.3125585
   Meiguins BS, 2006, 10 INT C INF VIS IV, DOI 10.1145/1128923.1128996
   Meiguins BS, 2006, P 2006 ACM INT C VIR, DOI 10.1109/iv.2006.117
   MERINO L, 2018, 2018 IEEE WORK C SOF
   MERINO L, 2020, 2020 CHI C HUM FACT
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mourtzis D, 2018, PROCEDIA MANUF, V23, P207, DOI 10.1016/j.promfg.2018.04.018
   Muñoz-Saavedra L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010322
   Natephra W., 2019, P 36 INT S AUT ROB C
   NAYYAR A, 2017, P 22 INT C INT US IN
   Nguyen M, 2016, 2016 INT C IM VIS CO, DOI 10.1109/ivcnz.2016.7804458
   Nizam SS Muhammad., 2018, Int. J. Adv. Sci. Eng. Inf. Technol, V8, P1460, DOI [10.18517/ijaseit.8.4-2.6824, DOI 10.18517/IJASEIT.8.4-2.6824]
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI [DOI 10.1145/345513.345282, 10.1145/345513.345282]
   Pillat RM, 2005, P 2005 LAT AM C HUM, DOI 10.1145/1111360.1111363
   Popovici I, 2019, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR.2019.00024
   PROUZEAU A, 2019, P 2019 ACM INT C INT
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ren DH, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3231505.3233400
   REYES ACC, 2020, P 2020 4 INT C VIRT
   Ritsos PD, 2017, IMMERSIVE ANAL
   Ritsos PD, 2017, IEEE C VIS IEEE VIS
   ROBERTS JC, 1998, IEEE INFOR VIS
   Sahin D, 2016, GLOBAL J HUMAN SOC S, DOI 10.18844/gjhss.v0i0.288
   Sarosa M, 2019, J PHYS CONF SER, V1375, DOI 10.1088/1742-6596/1375/1/012035
   Schreiber A, 2019, AEROSP CONF PROC
   Shaer Orit, 2010, Foundations and Trends in Human-Computer Interaction, V3, P1, DOI 10.1561/1100000026
   Shaikh A, 2019, 2019 IEEE INT C ART, DOI 10.1109/aivr46125.2019.00028
   Shimada, 2012, P 20 ACM INT C MULT, DOI 10.1145/2393347.2396416
   Shneiderman B., 1996, IEEE S VISUAL LANGUA
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Slay H., 2001, INVIS, P71
   Spence R., 2014, Information Visualization
   SSIN SY, 2019, 2019 IEEE C VIRT REA
   Thomas BH, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P45, DOI 10.1109/3DVis.2014.7160099
   Ullmer B, 2008, P 2 INT C TANG EMB I, DOI 10.1145/1347390.1347436
   Vogel D., 2020, P 2020 CHI C HUM FAC, P1
   Wang Baldonado M. Q., 2000, PROC WORK C ADV VIS, P110, DOI DOI 10.1145/345513.345271
   Wang Xingbo, 2020, P 2020 CHI C HUM FAC, P1
   WHITE S, 2009, INT SYM MIX AUGMENT
   Whitlock M, 2019, DESIGNING MOBILE IMM
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.1582298687237, 10.1109/VR46266.2020.00-20]
   Wu GL, 2019, INT CONF COMP SCI ED, P354, DOI 10.1109/ICCSE.2019.8845385
   Wu YL, 2015, AUGMENTED REALITY IN, DOI 10.5281/ZENODO.1110752
   Xie W, 2020, INTERACTIVE MULTIUSE
   XU W, 2019, P 2019 CHI C HUM FAC
   YASOJIMA EKK, 2011, 2011 15 INT C INF VI
   Yim D, 2018, INT RADAR SYMP PROC
   Zhu Y, 2017, LECT NOTES I COMPUTE, P12
   Zhu YJ., 2017, EAI Endorsed Transactions on Creative Technologies, V4, P1, DOI [10.4108/eai.5-9-2017.1530, DOI 10.4108/EAI.5-9-2017.1530]
NR 112
TC 4
Z9 4
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 14773
EP 14801
DI 10.1007/s11042-021-11141-2
EA JUN 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000664856100003
DA 2024-07-18
ER

PT J
AU Ng, MY
   Chng, CB
   Koh, WK
   Chui, CK
   Chua, MCH
AF Ng, Mei-Ying
   Chng, Chin-Boon
   Koh, Wai-Kin
   Chui, Chee-Kong
   Chua, Matthew Chin-Heng
TI An enhanced self-attention and A2J approach for 3D hand pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; Convolution; Hand pose estimation; Neural network
ID REGRESSION; NETWORK
AB Three dimensional (3D) hand pose estimation is the task of estimating the 3D location of hand keypoints. In recent years, this task has received much research attention due to its diverse applications in human-computer interaction and virtual reality. To the best of our knowledge, there has been limited studies that model self-attention in 3D hand pose estimation despite its use in various computer vision tasks. Hence, we propose augmenting convolution with self-attention to capture long-range dependencies in a depth image. In addition, motivated by a recent work which uses anchor points set on a depth image, we extend anchor points to the depth dimension to regress 3D hand joint locations. Validation experiments using the proposed approaches are performed on various hand pose datasets, and we obtain performances that are comparable to other state-of-the-art methods. The results demonstrate the potential of these approaches in a hand-based recognition system.
C1 [Ng, Mei-Ying; Koh, Wai-Kin; Chua, Matthew Chin-Heng] Natl Univ Singapore, Inst Syst Sci, Singapore, Singapore.
   [Chng, Chin-Boon; Chui, Chee-Kong] Natl Univ Singapore, Fac Engn, Dept Mech Engn, Singapore, Singapore.
C3 National University of Singapore; National University of Singapore
RP Chng, CB (corresponding author), Natl Univ Singapore, Fac Engn, Dept Mech Engn, Singapore, Singapore.
EM e0402087@u.nus.edu; mpeccbo@nus.edu.sg; waikin_koh@nus.edu.sg;
   mpecck@nus.edu.sg; isscchm@nus.edu.sg
RI Chua, Matthew/P-6434-2014
FU Tote Board Enabling Lives Initiative Grant [GC62018NUSISS]; SG Enable
FX This study was funded by Tote Board Enabling Lives Initiative Grant
   (Grant Number: GC62018NUSISS) and supported by SG Enable.
CR [Anonymous], 2017, arXiv preprint arXiv:1707.02237
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Bouchacourt D., 2016, Advances in Neural Information Processing Systems, P352
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen XH, 2018, IEEE ACCESS, V6, P43425, DOI 10.1109/ACCESS.2018.2863540
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Deng X., 2017, CORR
   Du K, 2019, PROC CVPR IEEE, P9888, DOI 10.1109/CVPR.2019.01013
   Fourure D, 2017, NEUROCOMPUTING, V251, P68, DOI 10.1016/j.neucom.2017.04.014
   Garcia-Hernando G, 2018, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2018.00050
   Ge LH, 2018, LECT NOTES COMPUT SC, V11217, P489, DOI 10.1007/978-3-030-01261-8_29
   Ge LH, 2018, PROC CVPR IEEE, P8417, DOI 10.1109/CVPR.2018.00878
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Guo FT, 2020, IEEE ACCESS, V8, P18258, DOI 10.1109/ACCESS.2020.2968361
   Guo H., 2017, ARXIV170707248
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Huang Lang, 2019, ARXIV190712273
   Imura S, 2018, LECT NOTES COMPUT SC, V10901, P554, DOI 10.1007/978-3-319-91238-7_43
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li Wen-Jeng., 2017, 2017 INT C APPL SYST, P386, DOI [DOI 10.1109/ICASI.2017.7988433, 10.1109/ICASI.2017.7988433]
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Madadi M., 2017, ARXIV170509606
   Madadi M, 2017, IEEE INT CONF AUTOMA, P230, DOI 10.1109/FG.2017.37
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Oberweger M., 2015, Hands deep in deep learning for hand pose estimation, P21, DOI DOI 10.1177/0093650215617505
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Parmar Niki, 2018, INT C MACH LEARN STO
   Poier G, 2019, IEEE WINT CONF APPL, P1393, DOI 10.1109/WACV.2019.00153
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ren P., 2019, BMVC, P112
   Showers A, 2018, LECT NOTES COMPUT SC, V10914, P403, DOI 10.1007/978-3-319-91485-5_31
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tian Y, 2020, NEUROCOMPUTING, V417, P202, DOI 10.1016/j.neucom.2020.07.078
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan CD, 2017, PROC CVPR IEEE, P1196, DOI 10.1109/CVPR.2017.132
   Wang XH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020618
   Cejnog LWX, 2019, IEEE INT CONF AUTOMA, P569
   Xiong F, 2019, IEEE I CONF COMP VIS, P793, DOI 10.1109/ICCV.2019.00088
   Xu C, 2017, INT J COMPUT VISION, V123, P454, DOI 10.1007/s11263-017-0998-6
   Yuan SX, 2018, PROC CVPR IEEE, P2636, DOI 10.1109/CVPR.2018.00279
   Yuan SX, 2017, PROC CVPR IEEE, P2605, DOI 10.1109/CVPR.2017.279
   Zhang H., 2019, INT C MACHINE LEARNI, P12744, DOI DOI 10.48550/ARXIV.1805.08318
   Zhang Y, 2017, LECT NOTES COMPUT SC, V10324, P299, DOI 10.1007/978-3-319-60922-5_24
   Zhou X., 2016, IJCAI, P2421
NR 49
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41661
EP 41676
DI 10.1007/s11042-021-11020-w
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000661795800006
DA 2024-07-18
ER

PT J
AU Fu, B
   Wang, LY
   Wu, YC
   Wu, YF
   Fu, SL
   Ren, YG
AF Fu, Bo
   Wang, Liyan
   Wu, Yuechu
   Wu, Yufeng
   Fu, Shilin
   Ren, Yonggong
TI Weak texture information map guided image super-resolution with deep
   residual networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution; Weak texture information; Deep residual
   networks
AB Limited by the poor quality of the camera, transmission bandwidth, excessive compression and other factors, low-resolution images widely exist in our lives. Single image super-resolution method is a kind of image processing task which can obtain high-resolution image from corresponding source low-resolution image. With the development of deep learning technology, a series of deep learning methods have brought crucial improvement for SISR problem. However, we observe that no matter how deep the network structures for SISR are designed, they usually have poor performances on restoration of tiny or irregular details, we call them weak texture information. The main reason for this phenomenon is that weak texture information is not obvious relative to the salient features, so as weak texture information feature is less extracted in the process of neural network feature extraction. To address this problem, we propose a SISR method which owns unique weak texture information prediction module and call it as weak texture information map guided image super-resolution with deep residual networks. In our network structure, two auxiliary sub-networks work together to capture grab details information and predict weak texture information. Then, predicted weak texture information will be fused into main sub-network. Therefore, our network can obtain more irregular details which usually miss in deep learning based methods. Finally, both qualitative experiments and visual effects demonstrate the effectiveness of our proposed algorithm. Specifically, our method can restore more irregular image details.
C1 [Fu, Bo; Wang, Liyan; Wu, Yuechu; Wu, Yufeng; Fu, Shilin; Ren, Yonggong] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
C3 Liaoning Normal University
RP Fu, B (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Peoples R China.
EM fubo@lnnu.edu.cn; ryg@lnnu.edu.cn
OI Fu, Bo/0000-0001-7030-821X
FU National Natural Science Foundation of China (NSFC) [61702246,
   61976109]; China Postdoctoral Science Foundation [2019 M651123]; Science
   and Technology Innovation Fund (Youth Science and Technology Star) of
   Dalian, China [2018RQ65]; Liaoning Natural Science Foundation
   [20180550542]; Dalian Science and Technology Innovation Fund
   [2018J12GX047]; Dalian Key Laboratory Special Fund
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Grant No.61702246, No.61976109, China Postdoctoral Science
   Foundation, No. 2019 M651123 and Science and Technology Innovation Fund
   (Youth Science and Technology Star) of Dalian, China, No. 2018RQ65.
   Liaoning Natural Science Foundation (No.20180550542), Dalian Science and
   Technology Innovation Fund (No.2018J12GX047), Dalian Key Laboratory
   Special Fund.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Dai S., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383028
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fu B, 2019, PATTERN RECOGN LETT, V125, P780, DOI 10.1016/j.patrec.2019.06.022
   Getreuer P, 2011, IMAGE PROCESS ON LIN, V1, P238, DOI 10.5201/ipol.2011.g_Imii
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Mao XJ, 2016, 2016 P 30 INT C NEUR, P2810
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Ha VK, 2019, INT J AUTOM COMPUT, V16, P413, DOI 10.1007/s11633-019-1183-x
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2020, IEEE IFIP NETW OPER, DOI 10.1109/noms47738.2020.9110353
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Yamanaka Jin, 2017, Neural Information Processing. 24th International Conference, ICONIP 2017. Proceedings: LNCS 10635, P217, DOI 10.1007/978-3-319-70096-0_23
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WH, 2019, IEEE T CIRC SYST VID, V29, P1270, DOI 10.1109/TCSVT.2018.2838453
   Yu J, 2019, WIDE ACTIVATION EFFI
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 36
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34281
EP 34294
DI 10.1007/s11042-021-11085-7
EA JUN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000660815700001
DA 2024-07-18
ER

PT J
AU Sun, Y
   Childers, R
   Hilton, J
AF Sun, Yu
   Childers, Reese
   Hilton, Joseph
TI New bufferless rate control for high efficiency video coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rate control; PID bit controller; Bit allocation; HEVC/H.265
ID RATE CONTROL ALGORITHM; LEVEL RATE CONTROL; OPTIMIZATION
AB As a crucial component of video compression, rate control regulates the encoding bitrates of compressed bitstreams to meet channel bandwidths while obtaining optimum encoding quality. In this research, we investigate rate control techniques for High Efficiency Video Coding (HEVC/H.265) and propose a new Proportional-Integral-Derivative (PID) based direct rate control algorithm for HEVC/H.265. The objective is to achieve accurate bitrate control for real-time networked video applications. Based on the PID control theory, the proposed algorithm first performs target bit allocation, and then directly controls actual compression bitrates to get close to target encoding bitrates. Different from conventional rate control approaches, a buffer is not adopted in the proposed rate control algorithm which naturally reduces encoding delay and improves real-time response. When compared with the rate control scheme adopted by HEVC/H.265 reference software, our algorithm achieves superior performance according to the experimental results. Specifically, our proposed algorithm improves rate control accuracy up to 23.43%, and achieves higher encoding quality up to 3.47 dB.
C1 [Sun, Yu; Childers, Reese; Hilton, Joseph] Univ Cent Arkansas, Dept Comp Sci, 201 Donaghey Ave, Conway, AR 72035 USA.
C3 University of Central Arkansas
RP Sun, Y (corresponding author), Univ Cent Arkansas, Dept Comp Sci, 201 Donaghey Ave, Conway, AR 72035 USA.
EM yusun@uca.edu
FU NASA EPSCoR Award [NNX13AD32A]; University of Central Arkansas
FX This work was partially supported by NASA EPSCoR Award (No. NNX13AD32A)
   and faculty sabbatical leave fund from University of Central Arkansas.
CR Ang KH, 2005, IEEE T CONTR SYST T, V13, P559, DOI 10.1109/TCST.2005.847331
   Bossen, 2012, JCTVCH1100 ITUT SG16
   Choi H., 2012, 8 JCTVC M SAN JOS CA
   Choi H, 2013, IEEE J-STSP, V7, P1112, DOI 10.1109/JSTSP.2013.2272241
   Gao W, 2019, IEEE T BROADCAST, V65, P94, DOI 10.1109/TBC.2018.2865647
   Gao W, 2017, IEEE T IMAGE PROCESS, V26, P6074, DOI 10.1109/TIP.2017.2745099
   Gao W, 2016, IEEE T CIRC SYST VID, V26, P139, DOI 10.1109/TCSVT.2015.2444671
   Hu, 2018, P 2018 IEEE INT S CI
   Huang T, 2018, P ACM MULT C, DOI 10.1145/3240508.3240545
   Kim IK, 2012, JCT VC ITU T SG 16 I
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Liu ZY, 2019, IEEE T IMAGE PROCESS, V28, P2558, DOI 10.1109/TIP.2018.2887200
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   Sun Y, 2015, MULTIMED TOOLS APPL, V74, P6623, DOI 10.1007/s11042-014-1913-6
   Wang MH, 2016, IEEE T IMAGE PROCESS, V25, P2943, DOI 10.1109/TIP.2016.2552646
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Zhou ML, 2021, IEEE T MULTIMEDIA, V23, P1106, DOI 10.1109/TMM.2020.2992968
   Zhou ML, 2019, IEEE T MULTIMEDIA, V21, P1921, DOI 10.1109/TMM.2019.2895281
NR 21
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28761
EP 28776
DI 10.1007/s11042-021-11055-z
EA JUN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000660358100001
DA 2024-07-18
ER

PT J
AU Verma, V
   Khanna, N
AF Verma, Vinay
   Khanna, Nitin
TI Speaker-independent source cell-phone identification for re-compressed
   and noisy audio recordings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio forensics; Device signature; Cell-phone identification;
   Convolutional neural network; Audio re-compression; Additive white
   Gaussian noise
ID RECOGNITION
AB With the rapid increase in user-generated multimedia content, extensive outreach over social media, and their potential in critical applications such as law enforcement, sourcey identification from re-compressed and noisy multimedia are of great importance. This paper proposes a system for speaker-independent cell-phone identification from recorded audio. This system is capable of dealing with test audio with different speech content and a different speaker compared to the training audio. Each recorded audio has the device fingerprint implicitly embedded in it, which encourages us to design a CNN-based system for learning the device-specific signatures directly from the magnitude of discrete Fourier transform of the audio. This paper also addresses the scenario where the recorded audio is re-compressed due to efficient storage and network transmission requirements, which is a common phenomenon in this age of social media. The scenario of the cell-phone classification from the audio recordings in the presence of additive white Gaussian noise is addressed as well. We show that our proposed system performs as well as the state-of-art systems for the speaker-dependent case with clean audio recordings and exhibits much higher robustness in the speaker-independent case with clean, re-compressed, and noisy audio recordings.
C1 [Verma, Vinay; Khanna, Nitin] Indian Inst Technol Gandhinagar IITGN, Multimedia Anal & Secur MANAS Lab, Elect Engn, Ahmadabad, Gujarat, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Gandhinagar
RP Khanna, N (corresponding author), Indian Inst Technol Gandhinagar IITGN, Multimedia Anal & Secur MANAS Lab, Elect Engn, Ahmadabad, Gujarat, India.
EM vinay.verma@iitgn.ac.in; nitinkhanna@iitgn.ac.in
OI Verma, Vinay/0000-0002-6532-2997
FU Department of Science and Technology (DST), New Delhi, India
   [ECR/2015/000583]
FX This material is based upon work partially supported by a grant from the
   Department of Science and Technology (DST), New Delhi, India, under
   Award Number ECR/2015/000583.
CR Aggarwal Rachit, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1218, DOI 10.1109/ICCSP.2014.6950045
   [Anonymous], 2012, P PCC
   Baldini G, 2019, IEEE ACCESS, V7, P158685, DOI 10.1109/ACCESS.2019.2950859
   Baldini G, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2019.2923590
   Buchholz R, 2009, LECT NOTES COMPUT SC, V5806, P235, DOI 10.1007/978-3-642-04431-1_17
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cuccovillo L, 2016, INT CONF ACOUST SPEE, P2074, DOI 10.1109/ICASSP.2016.7472042
   Cuccovillo L, 2013, IEEE INT WORKSH MULT, P177, DOI 10.1109/MMSP.2013.6659284
   Eskidere Ö, 2016, TURK J ELECTR ENG CO, V24, P1942, DOI 10.3906/elk-1312-193
   Eskidere Ö, 2014, TURK J ELECTR ENG CO, V22, P754, DOI 10.3906/elk-1207-74
   Garcia-Romero D, 2010, INT CONF ACOUST SPEE, P1806, DOI 10.1109/ICASSP.2010.5495407
   Hanilci C, 2013, P 1 ACM WORKSHOP INF, P141, DOI DOI 10.1145/2482513.2482520
   Hanilçi C, 2014, DIGIT SIGNAL PROCESS, V35, P75, DOI 10.1016/j.dsp.2014.08.008
   Hanilçi C, 2012, IEEE T INF FOREN SEC, V7, P625, DOI 10.1109/TIFS.2011.2178403
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Ikram S, 2012, P 46 INT C AUD FOR
   Ioffe S., 2015, arXiv: Learning
   Jiang YC, 2019, IEEE T INF FOREN SEC, V14, P2875, DOI 10.1109/TIFS.2019.2911175
   Kingma D. P., 2014, arXiv
   Kotropoulos C., 2012, P MULTIMEDIA SECURIT, P91
   Kotropoulos C, 2014, INT CONF DIGIT SIG, P586, DOI 10.1109/ICDSP.2014.6900732
   Kraetzer C, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P49
   Kraetzer C, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P63
   Kurniawan F, 2016, INT J ELECT COMPUTER, V6
   Li YX, 2018, IEEE T INF FOREN SEC, V13, P965, DOI 10.1109/TIFS.2017.2774505
   Luo D, 2018, IEEE T INF FOREN SEC, V13, P2179, DOI 10.1109/TIFS.2018.2812185
   Luo D, 2017, IEEE T INF FOREN SEC, V12, P432, DOI 10.1109/TIFS.2016.2622012
   O'Dea S, 2020, NUMBER SMARTPHONE US
   Panagakis Y, 2012, IEEE INT WORKS INFOR, P73, DOI 10.1109/WIFS.2012.6412628
   Pandey Vinay Kumar, 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036598
   Poisel R., 2011, Proceedings of the 2011 6th International Conference on IT Security Incident Management and IT Forensics (IMF 2011), P48, DOI 10.1109/IMF.2011.14
   Qin TY, 2018, INFORMATION, V9, DOI 10.3390/info9080205
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Verma V., 2019, PROC CVPR WORKSHOPS, P53
   Verma V, 2018, NATL CONF COMMUN
   Verma V, 2018, SIGNAL PROCESS-IMAGE, V67, P22, DOI 10.1016/j.image.2018.04.014
   Vu HQ, 2012, J NETW
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wojcicki K, 2020, HTK MFCC MATLAB
   Zakariah M, 2018, MULTIMED TOOLS APPL, V77, P1009, DOI 10.1007/s11042-016-4277-2
   Zou L, 2017, DIGIT SIGNAL PROCESS, V62, P125, DOI 10.1016/j.dsp.2016.10.017
NR 43
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23581
EP 23603
DI 10.1007/s11042-020-10205-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UD4ZK
UT WOS:000687215900003
DA 2024-07-18
ER

EF